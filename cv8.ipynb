{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number=\"8-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14666, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.776, tt:27.776\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14584, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.530, tt:59.061\n",
      "Ep:2, loss:0.00014, loss_test:0.14423, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.009, tt:90.028\n",
      "Ep:3, loss:0.00013, loss_test:0.14147, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.345, tt:121.380\n",
      "Ep:4, loss:0.00013, loss_test:0.13696, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:31.030, tt:155.152\n",
      "Ep:5, loss:0.00012, loss_test:0.13102, lr:1.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:31.044, tt:186.263\n",
      "Ep:6, loss:0.00012, loss_test:0.12498, lr:1.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:31.304, tt:219.126\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00011, loss_test:0.12246, lr:1.00e-02, fs:0.69298 (r=0.798,p=0.612),  time:31.393, tt:251.144\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00011, loss_test:0.12220, lr:1.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:31.439, tt:282.952\n",
      "Ep:9, loss:0.00011, loss_test:0.12188, lr:1.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:31.388, tt:313.883\n",
      "Ep:10, loss:0.00011, loss_test:0.11882, lr:1.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:31.430, tt:345.734\n",
      "Ep:11, loss:0.00010, loss_test:0.11523, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:31.522, tt:378.260\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00010, loss_test:0.11261, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:31.600, tt:410.795\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00010, loss_test:0.11072, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:31.464, tt:440.500\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00010, loss_test:0.10836, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:31.478, tt:472.166\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00009, loss_test:0.10602, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:31.482, tt:503.716\n",
      "Ep:16, loss:0.00009, loss_test:0.10420, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:31.559, tt:536.507\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.10248, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:31.541, tt:567.740\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.10046, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:31.606, tt:600.522\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.09857, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:31.668, tt:633.355\n",
      "Ep:20, loss:0.00008, loss_test:0.09717, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:31.641, tt:664.471\n",
      "Ep:21, loss:0.00008, loss_test:0.09587, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:31.607, tt:695.363\n",
      "Ep:22, loss:0.00008, loss_test:0.09483, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:31.654, tt:728.033\n",
      "Ep:23, loss:0.00008, loss_test:0.09426, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:31.663, tt:759.916\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00007, loss_test:0.09304, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:31.628, tt:790.696\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.09256, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:31.615, tt:821.989\n",
      "Ep:26, loss:0.00007, loss_test:0.09170, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:31.634, tt:854.117\n",
      "Ep:27, loss:0.00007, loss_test:0.09103, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:31.651, tt:886.216\n",
      "Ep:28, loss:0.00007, loss_test:0.09054, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:31.620, tt:916.987\n",
      "Ep:29, loss:0.00007, loss_test:0.08933, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.603, tt:948.090\n",
      "Ep:30, loss:0.00006, loss_test:0.08859, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.612, tt:979.982\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.08925, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:31.624, tt:1011.959\n",
      "Ep:32, loss:0.00006, loss_test:0.08776, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.660, tt:1044.770\n",
      "Ep:33, loss:0.00006, loss_test:0.08815, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.743, tt:1079.246\n",
      "Ep:34, loss:0.00006, loss_test:0.08705, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:31.753, tt:1111.357\n",
      "Ep:35, loss:0.00006, loss_test:0.08658, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:31.789, tt:1144.412\n",
      "Ep:36, loss:0.00005, loss_test:0.08611, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:31.842, tt:1178.152\n",
      "Ep:37, loss:0.00005, loss_test:0.08687, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:31.904, tt:1212.340\n",
      "Ep:38, loss:0.00005, loss_test:0.08512, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:31.887, tt:1243.587\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.08565, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:31.894, tt:1275.779\n",
      "Ep:40, loss:0.00005, loss_test:0.08450, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:31.893, tt:1307.611\n",
      "Ep:41, loss:0.00005, loss_test:0.08458, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.878, tt:1338.894\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.08383, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:31.910, tt:1372.114\n",
      "Ep:43, loss:0.00004, loss_test:0.08313, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:31.939, tt:1405.297\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.08222, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.958, tt:1438.102\n",
      "Ep:45, loss:0.00004, loss_test:0.08143, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:31.991, tt:1471.572\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.08072, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:32.006, tt:1504.279\n",
      "Ep:47, loss:0.00004, loss_test:0.08144, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:32.020, tt:1536.942\n",
      "Ep:48, loss:0.00004, loss_test:0.07999, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:32.020, tt:1569.004\n",
      "Ep:49, loss:0.00004, loss_test:0.07994, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:32.024, tt:1601.224\n",
      "Ep:50, loss:0.00004, loss_test:0.08007, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:31.993, tt:1631.632\n",
      "Ep:51, loss:0.00004, loss_test:0.07768, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:31.993, tt:1663.661\n",
      "Ep:52, loss:0.00003, loss_test:0.07960, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.986, tt:1695.275\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.07746, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.986, tt:1727.256\n",
      "Ep:54, loss:0.00003, loss_test:0.07907, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.987, tt:1759.268\n",
      "Ep:55, loss:0.00003, loss_test:0.07780, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:31.992, tt:1791.568\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.07719, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.997, tt:1823.824\n",
      "Ep:57, loss:0.00003, loss_test:0.07737, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:31.987, tt:1855.252\n",
      "Ep:58, loss:0.00003, loss_test:0.07721, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:31.968, tt:1886.098\n",
      "Ep:59, loss:0.00003, loss_test:0.07631, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:31.992, tt:1919.514\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.07771, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:31.996, tt:1951.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.07596, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:31.997, tt:1983.828\n",
      "Ep:62, loss:0.00003, loss_test:0.07701, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.016, tt:2017.035\n",
      "Ep:63, loss:0.00003, loss_test:0.07549, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:32.018, tt:2049.140\n",
      "Ep:64, loss:0.00003, loss_test:0.07741, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:32.047, tt:2083.066\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.07480, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:32.075, tt:2116.958\n",
      "Ep:66, loss:0.00002, loss_test:0.07790, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.090, tt:2149.997\n",
      "Ep:67, loss:0.00002, loss_test:0.07606, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:32.135, tt:2185.156\n",
      "Ep:68, loss:0.00002, loss_test:0.07670, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:32.173, tt:2219.927\n",
      "Ep:69, loss:0.00002, loss_test:0.07556, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:32.182, tt:2252.724\n",
      "Ep:70, loss:0.00002, loss_test:0.07791, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:32.214, tt:2287.159\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.07607, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:32.222, tt:2319.993\n",
      "Ep:72, loss:0.00002, loss_test:0.07606, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.237, tt:2353.324\n",
      "Ep:73, loss:0.00002, loss_test:0.07605, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.259, tt:2387.144\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.07624, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.270, tt:2420.286\n",
      "Ep:75, loss:0.00002, loss_test:0.07697, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.288, tt:2453.886\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.07639, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:32.293, tt:2486.564\n",
      "Ep:77, loss:0.00002, loss_test:0.07617, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.293, tt:2518.851\n",
      "Ep:78, loss:0.00002, loss_test:0.07545, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:32.301, tt:2551.778\n",
      "Ep:79, loss:0.00002, loss_test:0.07719, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:32.327, tt:2586.122\n",
      "Ep:80, loss:0.00002, loss_test:0.07584, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.337, tt:2619.328\n",
      "Ep:81, loss:0.00002, loss_test:0.07804, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:32.343, tt:2652.167\n",
      "Ep:82, loss:0.00002, loss_test:0.07658, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.345, tt:2684.595\n",
      "Ep:83, loss:0.00002, loss_test:0.07767, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:32.338, tt:2716.354\n",
      "Ep:84, loss:0.00002, loss_test:0.07915, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:32.326, tt:2747.717\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.07754, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.326, tt:2780.068\n",
      "Ep:86, loss:0.00002, loss_test:0.07621, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.325, tt:2812.266\n",
      "Ep:87, loss:0.00002, loss_test:0.08112, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:32.347, tt:2846.526\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.07544, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.348, tt:2878.965\n",
      "Ep:89, loss:0.00002, loss_test:0.08051, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:32.332, tt:2909.844\n",
      "Ep:90, loss:0.00001, loss_test:0.07664, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.335, tt:2942.483\n",
      "Ep:91, loss:0.00001, loss_test:0.07885, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.341, tt:2975.410\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.07856, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.346, tt:3008.182\n",
      "Ep:93, loss:0.00001, loss_test:0.07880, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:32.358, tt:3041.657\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.07915, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.376, tt:3075.746\n",
      "Ep:95, loss:0.00001, loss_test:0.07756, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.352, tt:3105.830\n",
      "Ep:96, loss:0.00001, loss_test:0.08219, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:32.340, tt:3136.997\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.07772, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.316, tt:3166.985\n",
      "Ep:98, loss:0.00001, loss_test:0.07897, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.308, tt:3198.480\n",
      "Ep:99, loss:0.00001, loss_test:0.08026, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.302, tt:3230.195\n",
      "Ep:100, loss:0.00001, loss_test:0.07658, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.290, tt:3261.310\n",
      "Ep:101, loss:0.00001, loss_test:0.08062, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.285, tt:3293.056\n",
      "Ep:102, loss:0.00001, loss_test:0.07794, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.290, tt:3325.892\n",
      "Ep:103, loss:0.00001, loss_test:0.07927, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.291, tt:3358.215\n",
      "Ep:104, loss:0.00001, loss_test:0.07912, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:32.285, tt:3389.891\n",
      "Ep:105, loss:0.00001, loss_test:0.07907, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:32.281, tt:3421.788\n",
      "Ep:106, loss:0.00001, loss_test:0.07879, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.280, tt:3454.006\n",
      "Ep:107, loss:0.00001, loss_test:0.08165, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:32.274, tt:3485.645\n",
      "Ep:108, loss:0.00001, loss_test:0.07973, lr:9.90e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.281, tt:3518.659\n",
      "Ep:109, loss:0.00001, loss_test:0.08241, lr:9.80e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.268, tt:3549.432\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.07956, lr:9.80e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.269, tt:3581.854\n",
      "Ep:111, loss:0.00001, loss_test:0.08200, lr:9.80e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.272, tt:3614.504\n",
      "Ep:112, loss:0.00001, loss_test:0.07949, lr:9.80e-03, fs:0.85246 (r=0.788,p=0.929),  time:32.290, tt:3648.726\n",
      "Ep:113, loss:0.00001, loss_test:0.08060, lr:9.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.285, tt:3680.544\n",
      "Ep:114, loss:0.00001, loss_test:0.08201, lr:9.80e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.327, tt:3717.655\n",
      "Ep:115, loss:0.00001, loss_test:0.07857, lr:9.80e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.335, tt:3750.896\n",
      "Ep:116, loss:0.00001, loss_test:0.08083, lr:9.80e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.333, tt:3782.988\n",
      "Ep:117, loss:0.00001, loss_test:0.08042, lr:9.80e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.342, tt:3816.347\n",
      "Ep:118, loss:0.00001, loss_test:0.07899, lr:9.80e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.347, tt:3849.307\n",
      "Ep:119, loss:0.00001, loss_test:0.08238, lr:9.80e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.355, tt:3882.566\n",
      "Ep:120, loss:0.00001, loss_test:0.07813, lr:9.80e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.363, tt:3915.878\n",
      "Ep:121, loss:0.00001, loss_test:0.08210, lr:9.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.371, tt:3949.208\n",
      "Ep:122, loss:0.00001, loss_test:0.07860, lr:9.61e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.371, tt:3981.587\n",
      "Ep:123, loss:0.00001, loss_test:0.08246, lr:9.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.369, tt:4013.750\n",
      "Ep:124, loss:0.00001, loss_test:0.07981, lr:9.41e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.375, tt:4046.818\n",
      "Ep:125, loss:0.00001, loss_test:0.08107, lr:9.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.371, tt:4078.809\n",
      "Ep:126, loss:0.00001, loss_test:0.07993, lr:9.23e-03, fs:0.85246 (r=0.788,p=0.929),  time:32.367, tt:4110.646\n",
      "Ep:127, loss:0.00001, loss_test:0.08420, lr:9.14e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.354, tt:4141.265\n",
      "Ep:128, loss:0.00001, loss_test:0.07725, lr:9.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.352, tt:4173.412\n",
      "Ep:129, loss:0.00001, loss_test:0.08648, lr:8.95e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.358, tt:4206.591\n",
      "Ep:130, loss:0.00001, loss_test:0.07740, lr:8.86e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.350, tt:4237.795\n",
      "Ep:131, loss:0.00001, loss_test:0.08262, lr:8.78e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.344, tt:4269.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.08161, lr:8.69e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.350, tt:4302.571\n",
      "Ep:133, loss:0.00001, loss_test:0.08023, lr:8.60e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.346, tt:4334.341\n",
      "Ep:134, loss:0.00001, loss_test:0.08147, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.348, tt:4366.998\n",
      "Ep:135, loss:0.00001, loss_test:0.08026, lr:8.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.357, tt:4400.608\n",
      "Ep:136, loss:0.00001, loss_test:0.08155, lr:8.35e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.358, tt:4433.047\n",
      "Ep:137, loss:0.00001, loss_test:0.08088, lr:8.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.355, tt:4464.997\n",
      "Ep:138, loss:0.00001, loss_test:0.08255, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.349, tt:4496.472\n",
      "Ep:139, loss:0.00001, loss_test:0.08082, lr:8.10e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.358, tt:4530.178\n",
      "Ep:140, loss:0.00001, loss_test:0.08180, lr:8.02e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.362, tt:4563.069\n",
      "Ep:141, loss:0.00001, loss_test:0.08013, lr:7.94e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.368, tt:4596.240\n",
      "Ep:142, loss:0.00001, loss_test:0.08143, lr:7.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.389, tt:4631.683\n",
      "Ep:143, loss:0.00001, loss_test:0.08069, lr:7.78e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.393, tt:4664.569\n",
      "Ep:144, loss:0.00001, loss_test:0.08214, lr:7.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.400, tt:4698.024\n",
      "Ep:145, loss:0.00001, loss_test:0.08051, lr:7.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.414, tt:4732.483\n",
      "Ep:146, loss:0.00001, loss_test:0.08169, lr:7.55e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.417, tt:4765.276\n",
      "Ep:147, loss:0.00001, loss_test:0.08159, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.426, tt:4799.016\n",
      "Ep:148, loss:0.00001, loss_test:0.08081, lr:7.40e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.426, tt:4831.499\n",
      "Ep:149, loss:0.00001, loss_test:0.08196, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.432, tt:4864.760\n",
      "Ep:150, loss:0.00001, loss_test:0.08081, lr:7.25e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.444, tt:4899.103\n",
      "Ep:151, loss:0.00001, loss_test:0.08170, lr:7.18e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.458, tt:4933.608\n",
      "Ep:152, loss:0.00001, loss_test:0.08170, lr:7.11e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.472, tt:4968.219\n",
      "Ep:153, loss:0.00001, loss_test:0.08211, lr:7.03e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.478, tt:5001.669\n",
      "Ep:154, loss:0.00001, loss_test:0.08177, lr:6.96e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.484, tt:5035.037\n",
      "Ep:155, loss:0.00001, loss_test:0.08182, lr:6.89e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.489, tt:5068.220\n",
      "Ep:156, loss:0.00001, loss_test:0.08223, lr:6.83e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.492, tt:5101.307\n",
      "Ep:157, loss:0.00001, loss_test:0.08230, lr:6.76e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.497, tt:5134.598\n",
      "Ep:158, loss:0.00001, loss_test:0.08146, lr:6.69e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.504, tt:5168.106\n",
      "Ep:159, loss:0.00001, loss_test:0.08160, lr:6.62e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.505, tt:5200.813\n",
      "Ep:160, loss:0.00000, loss_test:0.08256, lr:6.56e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.506, tt:5233.524\n",
      "Ep:161, loss:0.00000, loss_test:0.08152, lr:6.49e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.522, tt:5268.639\n",
      "Ep:162, loss:0.00000, loss_test:0.08275, lr:6.43e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.517, tt:5300.243\n",
      "Ep:163, loss:0.00000, loss_test:0.08280, lr:6.36e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.527, tt:5334.382\n",
      "Ep:164, loss:0.00000, loss_test:0.08150, lr:6.30e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.538, tt:5368.738\n",
      "Ep:165, loss:0.00000, loss_test:0.08349, lr:6.24e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.541, tt:5401.874\n",
      "Ep:166, loss:0.00000, loss_test:0.08243, lr:6.17e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.547, tt:5435.330\n",
      "Ep:167, loss:0.00000, loss_test:0.08167, lr:6.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.536, tt:5466.129\n",
      "Ep:168, loss:0.00000, loss_test:0.08283, lr:6.05e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.536, tt:5498.660\n",
      "Ep:169, loss:0.00000, loss_test:0.08445, lr:5.99e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.536, tt:5531.083\n",
      "Ep:170, loss:0.00000, loss_test:0.08086, lr:5.93e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.533, tt:5563.103\n",
      "Ep:171, loss:0.00000, loss_test:0.08387, lr:5.87e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.547, tt:5598.087\n",
      "Ep:172, loss:0.00000, loss_test:0.08392, lr:5.81e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.546, tt:5630.466\n",
      "Ep:173, loss:0.00000, loss_test:0.08065, lr:5.75e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.550, tt:5663.761\n",
      "Ep:174, loss:0.00000, loss_test:0.08543, lr:5.70e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.553, tt:5696.797\n",
      "Ep:175, loss:0.00000, loss_test:0.08327, lr:5.64e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.560, tt:5730.553\n",
      "Ep:176, loss:0.00000, loss_test:0.08165, lr:5.58e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.559, tt:5762.968\n",
      "Ep:177, loss:0.00000, loss_test:0.08366, lr:5.53e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.556, tt:5794.918\n",
      "Ep:178, loss:0.00000, loss_test:0.08303, lr:5.47e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.538, tt:5824.369\n",
      "Ep:179, loss:0.00000, loss_test:0.08247, lr:5.42e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.540, tt:5857.196\n",
      "Ep:180, loss:0.00000, loss_test:0.08222, lr:5.36e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.538, tt:5889.343\n",
      "Ep:181, loss:0.00000, loss_test:0.08403, lr:5.31e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.532, tt:5920.802\n",
      "Ep:182, loss:0.00000, loss_test:0.08272, lr:5.26e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.522, tt:5951.589\n",
      "Ep:183, loss:0.00000, loss_test:0.08243, lr:5.20e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.522, tt:5984.080\n",
      "Ep:184, loss:0.00000, loss_test:0.08404, lr:5.15e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.515, tt:6015.196\n",
      "Ep:185, loss:0.00000, loss_test:0.08214, lr:5.10e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.516, tt:6048.022\n",
      "Ep:186, loss:0.00000, loss_test:0.08392, lr:5.05e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.520, tt:6081.195\n",
      "Ep:187, loss:0.00000, loss_test:0.08383, lr:5.00e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.516, tt:6112.914\n",
      "Ep:188, loss:0.00000, loss_test:0.08277, lr:4.95e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.509, tt:6144.129\n",
      "Ep:189, loss:0.00000, loss_test:0.08348, lr:4.90e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.505, tt:6175.932\n",
      "Ep:190, loss:0.00000, loss_test:0.08291, lr:4.85e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.502, tt:6207.911\n",
      "Ep:191, loss:0.00000, loss_test:0.08334, lr:4.80e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.495, tt:6239.078\n",
      "Ep:192, loss:0.00000, loss_test:0.08333, lr:4.75e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.512, tt:6274.741\n",
      "Ep:193, loss:0.00000, loss_test:0.08348, lr:4.71e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.509, tt:6306.691\n",
      "Ep:194, loss:0.00000, loss_test:0.08332, lr:4.66e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.508, tt:6339.102\n",
      "Ep:195, loss:0.00000, loss_test:0.08330, lr:4.61e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.507, tt:6371.413\n",
      "Ep:196, loss:0.00000, loss_test:0.08342, lr:4.57e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.498, tt:6402.036\n",
      "Ep:197, loss:0.00000, loss_test:0.08374, lr:4.52e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.498, tt:6434.538\n",
      "Ep:198, loss:0.00000, loss_test:0.08373, lr:4.48e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.492, tt:6465.906\n",
      "Ep:199, loss:0.00000, loss_test:0.08302, lr:4.43e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.487, tt:6497.421\n",
      "Ep:200, loss:0.00000, loss_test:0.08377, lr:4.39e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.465, tt:6525.377\n",
      "Ep:201, loss:0.00000, loss_test:0.08395, lr:4.34e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.440, tt:6552.975\n",
      "Ep:202, loss:0.00000, loss_test:0.08373, lr:4.30e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.414, tt:6580.010\n",
      "Ep:203, loss:0.00000, loss_test:0.08360, lr:4.26e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.396, tt:6608.866\n",
      "Ep:204, loss:0.00000, loss_test:0.08373, lr:4.21e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.337, tt:6629.107\n",
      "Ep:205, loss:0.00000, loss_test:0.08398, lr:4.17e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.258, tt:6645.178\n",
      "Ep:206, loss:0.00000, loss_test:0.08356, lr:4.13e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.157, tt:6656.519\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14336, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:28.856, tt:28.856\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14246, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.990, tt:59.981\n",
      "Ep:2, loss:0.00014, loss_test:0.14091, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:30.620, tt:91.860\n",
      "Ep:3, loss:0.00014, loss_test:0.13854, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:31.096, tt:124.383\n",
      "Ep:4, loss:0.00013, loss_test:0.13524, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:31.391, tt:156.957\n",
      "Ep:5, loss:0.00013, loss_test:0.13017, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:31.266, tt:187.596\n",
      "Ep:6, loss:0.00013, loss_test:0.12243, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:31.200, tt:218.398\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00012, loss_test:0.11515, lr:1.00e-02, fs:0.65179 (r=0.737,p=0.584),  time:31.213, tt:249.701\n",
      "Ep:8, loss:0.00011, loss_test:0.11264, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:31.291, tt:281.622\n",
      "Ep:9, loss:0.00011, loss_test:0.11100, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:31.303, tt:313.025\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00011, loss_test:0.10868, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:31.414, tt:345.551\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00011, loss_test:0.10760, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:31.436, tt:377.229\n",
      "Ep:12, loss:0.00010, loss_test:0.10522, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:31.378, tt:407.916\n",
      "Ep:13, loss:0.00010, loss_test:0.10285, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:31.377, tt:439.284\n",
      "Ep:14, loss:0.00010, loss_test:0.10113, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:31.338, tt:470.075\n",
      "Ep:15, loss:0.00010, loss_test:0.09891, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:31.366, tt:501.858\n",
      "Ep:16, loss:0.00009, loss_test:0.09679, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:31.435, tt:534.393\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.09491, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:31.499, tt:566.987\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.09348, lr:1.00e-02, fs:0.69149 (r=0.657,p=0.730),  time:31.472, tt:597.969\n",
      "Ep:19, loss:0.00009, loss_test:0.09143, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:31.410, tt:628.200\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.08935, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:31.382, tt:659.012\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.08797, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.385, tt:690.470\n",
      "Ep:22, loss:0.00008, loss_test:0.08666, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:31.529, tt:725.177\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00008, loss_test:0.08560, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:31.563, tt:757.517\n",
      "Ep:24, loss:0.00007, loss_test:0.08536, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:31.510, tt:787.757\n",
      "Ep:25, loss:0.00007, loss_test:0.08472, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:31.516, tt:819.424\n",
      "Ep:26, loss:0.00007, loss_test:0.08345, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:31.507, tt:850.702\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.08299, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:31.539, tt:883.080\n",
      "Ep:28, loss:0.00007, loss_test:0.08245, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:31.548, tt:914.903\n",
      "Ep:29, loss:0.00007, loss_test:0.08127, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:31.556, tt:946.676\n",
      "Ep:30, loss:0.00006, loss_test:0.08097, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:31.592, tt:979.358\n",
      "Ep:31, loss:0.00006, loss_test:0.08026, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:31.569, tt:1010.217\n",
      "Ep:32, loss:0.00006, loss_test:0.07923, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:31.565, tt:1041.660\n",
      "Ep:33, loss:0.00006, loss_test:0.07883, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:31.555, tt:1072.881\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.07806, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:31.552, tt:1104.305\n",
      "Ep:35, loss:0.00006, loss_test:0.07839, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:31.521, tt:1134.772\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.07658, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:31.510, tt:1165.853\n",
      "Ep:37, loss:0.00005, loss_test:0.07738, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:31.424, tt:1194.113\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.07605, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.464, tt:1227.093\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07719, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:31.449, tt:1257.958\n",
      "Ep:40, loss:0.00005, loss_test:0.07558, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.451, tt:1289.474\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.07620, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:31.428, tt:1319.991\n",
      "Ep:42, loss:0.00005, loss_test:0.07525, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.440, tt:1351.935\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.07444, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:31.433, tt:1383.034\n",
      "Ep:44, loss:0.00005, loss_test:0.07251, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:31.425, tt:1414.125\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.07358, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:31.441, tt:1446.286\n",
      "Ep:46, loss:0.00004, loss_test:0.07220, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:31.467, tt:1478.965\n",
      "Ep:47, loss:0.00004, loss_test:0.07189, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:31.431, tt:1508.684\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00004, loss_test:0.07211, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:31.396, tt:1538.400\n",
      "Ep:49, loss:0.00004, loss_test:0.06935, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.423, tt:1571.139\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.07135, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:31.421, tt:1602.455\n",
      "Ep:51, loss:0.00004, loss_test:0.06942, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.439, tt:1634.802\n",
      "Ep:52, loss:0.00004, loss_test:0.06903, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.435, tt:1666.045\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.06993, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.473, tt:1699.563\n",
      "Ep:54, loss:0.00003, loss_test:0.06705, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.497, tt:1732.355\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.06919, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.500, tt:1764.000\n",
      "Ep:56, loss:0.00003, loss_test:0.06545, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.502, tt:1795.616\n",
      "Ep:57, loss:0.00003, loss_test:0.06924, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:31.504, tt:1827.255\n",
      "Ep:58, loss:0.00003, loss_test:0.06349, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:31.511, tt:1859.159\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.07041, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:31.523, tt:1891.351\n",
      "Ep:60, loss:0.00003, loss_test:0.06413, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.532, tt:1923.438\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.06691, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:31.543, tt:1955.677\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00003, loss_test:0.06286, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.566, tt:1988.672\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.06612, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:31.574, tt:2020.719\n",
      "Ep:64, loss:0.00003, loss_test:0.06284, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.555, tt:2051.102\n",
      "Ep:65, loss:0.00003, loss_test:0.06540, lr:1.00e-02, fs:0.86188 (r=0.788,p=0.951),  time:31.562, tt:2083.113\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.06407, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.549, tt:2113.802\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.06400, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:31.521, tt:2143.421\n",
      "Ep:68, loss:0.00002, loss_test:0.06357, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:31.540, tt:2176.291\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.06336, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.543, tt:2208.027\n",
      "Ep:70, loss:0.00002, loss_test:0.06150, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.538, tt:2239.162\n",
      "Ep:71, loss:0.00002, loss_test:0.06485, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.550, tt:2271.610\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.05894, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.538, tt:2302.245\n",
      "Ep:73, loss:0.00002, loss_test:0.06313, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.540, tt:2333.955\n",
      "Ep:74, loss:0.00002, loss_test:0.06268, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.534, tt:2365.014\n",
      "Ep:75, loss:0.00002, loss_test:0.06029, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.546, tt:2397.473\n",
      "Ep:76, loss:0.00002, loss_test:0.06368, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.549, tt:2429.246\n",
      "Ep:77, loss:0.00002, loss_test:0.05829, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.542, tt:2460.256\n",
      "Ep:78, loss:0.00002, loss_test:0.06486, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.540, tt:2491.639\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.05886, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.562, tt:2524.989\n",
      "Ep:80, loss:0.00002, loss_test:0.06340, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.566, tt:2556.884\n",
      "Ep:81, loss:0.00002, loss_test:0.05862, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:31.560, tt:2587.907\n",
      "Ep:82, loss:0.00002, loss_test:0.06302, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.553, tt:2618.938\n",
      "Ep:83, loss:0.00002, loss_test:0.05831, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.547, tt:2649.937\n",
      "Ep:84, loss:0.00002, loss_test:0.06299, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.548, tt:2681.588\n",
      "Ep:85, loss:0.00002, loss_test:0.05981, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.551, tt:2713.407\n",
      "Ep:86, loss:0.00001, loss_test:0.06173, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.559, tt:2745.622\n",
      "Ep:87, loss:0.00001, loss_test:0.05889, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:31.560, tt:2777.277\n",
      "Ep:88, loss:0.00001, loss_test:0.06395, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:31.559, tt:2808.757\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.05825, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.553, tt:2839.793\n",
      "Ep:90, loss:0.00001, loss_test:0.06199, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:31.556, tt:2871.601\n",
      "Ep:91, loss:0.00001, loss_test:0.05944, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:31.565, tt:2904.020\n",
      "Ep:92, loss:0.00001, loss_test:0.06211, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.566, tt:2935.651\n",
      "Ep:93, loss:0.00001, loss_test:0.06005, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.567, tt:2967.292\n",
      "Ep:94, loss:0.00001, loss_test:0.05974, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:31.576, tt:2999.695\n",
      "Ep:95, loss:0.00001, loss_test:0.05972, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.574, tt:3031.107\n",
      "Ep:96, loss:0.00001, loss_test:0.06054, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.575, tt:3062.777\n",
      "Ep:97, loss:0.00001, loss_test:0.05909, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:31.583, tt:3095.088\n",
      "Ep:98, loss:0.00001, loss_test:0.06226, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.582, tt:3126.603\n",
      "Ep:99, loss:0.00001, loss_test:0.05806, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.571, tt:3157.144\n",
      "Ep:100, loss:0.00001, loss_test:0.06217, lr:9.90e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.588, tt:3190.407\n",
      "Ep:101, loss:0.00001, loss_test:0.05873, lr:9.80e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.590, tt:3222.209\n",
      "Ep:102, loss:0.00001, loss_test:0.06280, lr:9.70e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.586, tt:3253.372\n",
      "Ep:103, loss:0.00001, loss_test:0.05862, lr:9.61e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.587, tt:3285.078\n",
      "Ep:104, loss:0.00001, loss_test:0.06280, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.623, tt:3320.446\n",
      "Ep:105, loss:0.00001, loss_test:0.05916, lr:9.41e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.632, tt:3353.017\n",
      "Ep:106, loss:0.00001, loss_test:0.06196, lr:9.32e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.635, tt:3384.968\n",
      "Ep:107, loss:0.00001, loss_test:0.06130, lr:9.23e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.644, tt:3417.579\n",
      "Ep:108, loss:0.00001, loss_test:0.05956, lr:9.14e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.647, tt:3449.523\n",
      "Ep:109, loss:0.00001, loss_test:0.06118, lr:9.04e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.650, tt:3481.535\n",
      "Ep:110, loss:0.00001, loss_test:0.06115, lr:8.95e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.660, tt:3514.289\n",
      "Ep:111, loss:0.00001, loss_test:0.06251, lr:8.86e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.663, tt:3546.250\n",
      "Ep:112, loss:0.00001, loss_test:0.06068, lr:8.78e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.657, tt:3577.253\n",
      "Ep:113, loss:0.00001, loss_test:0.06093, lr:8.69e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.662, tt:3609.473\n",
      "Ep:114, loss:0.00001, loss_test:0.06164, lr:8.60e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.664, tt:3641.404\n",
      "Ep:115, loss:0.00001, loss_test:0.06068, lr:8.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.661, tt:3672.674\n",
      "Ep:116, loss:0.00001, loss_test:0.06251, lr:8.43e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.652, tt:3703.339\n",
      "Ep:117, loss:0.00001, loss_test:0.06244, lr:8.35e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.650, tt:3734.754\n",
      "Ep:118, loss:0.00001, loss_test:0.06267, lr:8.26e-03, fs:0.88268 (r=0.798,p=0.988),  time:31.655, tt:3766.956\n",
      "Ep:119, loss:0.00001, loss_test:0.06439, lr:8.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.660, tt:3799.247\n",
      "Ep:120, loss:0.00001, loss_test:0.05989, lr:8.10e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.652, tt:3829.842\n",
      "Ep:121, loss:0.00001, loss_test:0.06383, lr:8.02e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.640, tt:3860.046\n",
      "Ep:122, loss:0.00001, loss_test:0.06228, lr:7.94e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.637, tt:3891.357\n",
      "Ep:123, loss:0.00001, loss_test:0.06199, lr:7.86e-03, fs:0.88268 (r=0.798,p=0.988),  time:31.654, tt:3925.045\n",
      "Ep:124, loss:0.00001, loss_test:0.06459, lr:7.78e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.653, tt:3956.605\n",
      "Ep:125, loss:0.00001, loss_test:0.06128, lr:7.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:31.642, tt:3986.935\n",
      "Ep:126, loss:0.00001, loss_test:0.06306, lr:7.62e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.642, tt:4018.579\n",
      "Ep:127, loss:0.00001, loss_test:0.06227, lr:7.55e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.658, tt:4052.170\n",
      "Ep:128, loss:0.00001, loss_test:0.06215, lr:7.47e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.662, tt:4084.449\n",
      "Ep:129, loss:0.00001, loss_test:0.06372, lr:7.40e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.667, tt:4116.704\n",
      "Ep:130, loss:0.00001, loss_test:0.06259, lr:7.32e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.686, tt:4150.911\n",
      "Ep:131, loss:0.00001, loss_test:0.06278, lr:7.25e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.695, tt:4183.693\n",
      "Ep:132, loss:0.00001, loss_test:0.06329, lr:7.18e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.698, tt:4215.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.06291, lr:7.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.708, tt:4248.917\n",
      "Ep:134, loss:0.00001, loss_test:0.06430, lr:7.03e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.710, tt:4280.841\n",
      "Ep:135, loss:0.00001, loss_test:0.06309, lr:6.96e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.725, tt:4314.585\n",
      "Ep:136, loss:0.00001, loss_test:0.06314, lr:6.89e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.730, tt:4346.970\n",
      "Ep:137, loss:0.00001, loss_test:0.06358, lr:6.83e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.732, tt:4379.023\n",
      "Ep:138, loss:0.00001, loss_test:0.06201, lr:6.76e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.734, tt:4411.058\n",
      "Ep:139, loss:0.00001, loss_test:0.06545, lr:6.69e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.745, tt:4444.277\n",
      "Ep:140, loss:0.00001, loss_test:0.06293, lr:6.62e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.745, tt:4476.056\n",
      "Ep:141, loss:0.00001, loss_test:0.06448, lr:6.56e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.756, tt:4509.288\n",
      "Ep:142, loss:0.00001, loss_test:0.06507, lr:6.49e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.771, tt:4543.239\n",
      "Ep:143, loss:0.00001, loss_test:0.06255, lr:6.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.782, tt:4576.579\n",
      "Ep:144, loss:0.00001, loss_test:0.06617, lr:6.36e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.792, tt:4609.794\n",
      "Ep:145, loss:0.00001, loss_test:0.06360, lr:6.30e-03, fs:0.84393 (r=0.737,p=0.986),  time:31.810, tt:4644.285\n",
      "Ep:146, loss:0.00001, loss_test:0.06393, lr:6.24e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.824, tt:4678.200\n",
      "Ep:147, loss:0.00000, loss_test:0.06630, lr:6.17e-03, fs:0.83041 (r=0.717,p=0.986),  time:31.829, tt:4710.744\n",
      "Ep:148, loss:0.00000, loss_test:0.06339, lr:6.11e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.845, tt:4744.966\n",
      "Ep:149, loss:0.00000, loss_test:0.06489, lr:6.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.855, tt:4778.251\n",
      "Ep:150, loss:0.00000, loss_test:0.06447, lr:5.99e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.853, tt:4809.786\n",
      "Ep:151, loss:0.00000, loss_test:0.06365, lr:5.93e-03, fs:0.85714 (r=0.758,p=0.987),  time:31.893, tt:4847.693\n",
      "Ep:152, loss:0.00000, loss_test:0.06470, lr:5.87e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.888, tt:4878.935\n",
      "Ep:153, loss:0.00000, loss_test:0.06410, lr:5.81e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.898, tt:4912.270\n",
      "Ep:154, loss:0.00000, loss_test:0.06434, lr:5.75e-03, fs:0.84393 (r=0.737,p=0.986),  time:31.908, tt:4945.813\n",
      "Ep:155, loss:0.00000, loss_test:0.06514, lr:5.70e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.922, tt:4979.803\n",
      "Ep:156, loss:0.00000, loss_test:0.06454, lr:5.64e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.927, tt:5012.605\n",
      "Ep:157, loss:0.00000, loss_test:0.06455, lr:5.58e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.928, tt:5044.679\n",
      "Ep:158, loss:0.00000, loss_test:0.06506, lr:5.53e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.928, tt:5076.610\n",
      "Ep:159, loss:0.00000, loss_test:0.06508, lr:5.47e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.929, tt:5108.690\n",
      "Ep:160, loss:0.00000, loss_test:0.06505, lr:5.42e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.943, tt:5142.825\n",
      "Ep:161, loss:0.00000, loss_test:0.06449, lr:5.36e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.949, tt:5175.679\n",
      "Ep:162, loss:0.00000, loss_test:0.06552, lr:5.31e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.955, tt:5208.665\n",
      "Ep:163, loss:0.00000, loss_test:0.06430, lr:5.26e-03, fs:0.85057 (r=0.747,p=0.987),  time:31.952, tt:5240.161\n",
      "Ep:164, loss:0.00000, loss_test:0.06585, lr:5.20e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.959, tt:5273.172\n",
      "Ep:165, loss:0.00000, loss_test:0.06489, lr:5.15e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.961, tt:5305.604\n",
      "Ep:166, loss:0.00000, loss_test:0.06544, lr:5.10e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.975, tt:5339.803\n",
      "Ep:167, loss:0.00000, loss_test:0.06537, lr:5.05e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.975, tt:5371.758\n",
      "Ep:168, loss:0.00000, loss_test:0.06541, lr:5.00e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.975, tt:5403.750\n",
      "Ep:169, loss:0.00000, loss_test:0.06546, lr:4.95e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.974, tt:5435.604\n",
      "Ep:170, loss:0.00000, loss_test:0.06505, lr:4.90e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.978, tt:5468.291\n",
      "Ep:171, loss:0.00000, loss_test:0.06596, lr:4.85e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.985, tt:5501.423\n",
      "Ep:172, loss:0.00000, loss_test:0.06566, lr:4.80e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.991, tt:5534.446\n",
      "Ep:173, loss:0.00000, loss_test:0.06471, lr:4.75e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.986, tt:5565.582\n",
      "Ep:174, loss:0.00000, loss_test:0.06641, lr:4.71e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.995, tt:5599.112\n",
      "Ep:175, loss:0.00000, loss_test:0.06530, lr:4.66e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.993, tt:5630.782\n",
      "Ep:176, loss:0.00000, loss_test:0.06661, lr:4.61e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.991, tt:5662.326\n",
      "Ep:177, loss:0.00000, loss_test:0.06699, lr:4.57e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.990, tt:5694.237\n",
      "Ep:178, loss:0.00000, loss_test:0.06486, lr:4.52e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.986, tt:5725.412\n",
      "Ep:179, loss:0.00000, loss_test:0.06630, lr:4.48e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.988, tt:5757.756\n",
      "Ep:180, loss:0.00000, loss_test:0.06558, lr:4.43e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.993, tt:5790.755\n",
      "Ep:181, loss:0.00000, loss_test:0.06614, lr:4.39e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.988, tt:5821.858\n",
      "Ep:182, loss:0.00000, loss_test:0.06549, lr:4.34e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.992, tt:5854.482\n",
      "Ep:183, loss:0.00000, loss_test:0.06591, lr:4.30e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.997, tt:5887.393\n",
      "Ep:184, loss:0.00000, loss_test:0.06595, lr:4.26e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.998, tt:5919.720\n",
      "Ep:185, loss:0.00000, loss_test:0.06605, lr:4.21e-03, fs:0.84211 (r=0.727,p=1.000),  time:32.000, tt:5952.075\n",
      "Ep:186, loss:0.00000, loss_test:0.06601, lr:4.17e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.993, tt:5982.601\n",
      "Ep:187, loss:0.00000, loss_test:0.06608, lr:4.13e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.988, tt:6013.652\n",
      "Ep:188, loss:0.00000, loss_test:0.06657, lr:4.09e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.989, tt:6045.870\n",
      "Ep:189, loss:0.00000, loss_test:0.06611, lr:4.05e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.987, tt:6077.610\n",
      "Ep:190, loss:0.00000, loss_test:0.06574, lr:4.01e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.986, tt:6109.301\n",
      "Ep:191, loss:0.00000, loss_test:0.06688, lr:3.97e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.983, tt:6140.707\n",
      "Ep:192, loss:0.00000, loss_test:0.06581, lr:3.93e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.999, tt:6175.769\n",
      "Ep:193, loss:0.00000, loss_test:0.06668, lr:3.89e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.999, tt:6207.838\n",
      "Ep:194, loss:0.00000, loss_test:0.06681, lr:3.85e-03, fs:0.83529 (r=0.717,p=1.000),  time:32.001, tt:6240.264\n",
      "Ep:195, loss:0.00000, loss_test:0.06573, lr:3.81e-03, fs:0.84211 (r=0.727,p=1.000),  time:32.009, tt:6273.752\n",
      "Ep:196, loss:0.00000, loss_test:0.06664, lr:3.77e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.997, tt:6303.488\n",
      "Ep:197, loss:0.00000, loss_test:0.06671, lr:3.73e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.991, tt:6334.293\n",
      "Ep:198, loss:0.00000, loss_test:0.06603, lr:3.70e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.991, tt:6366.275\n",
      "Ep:199, loss:0.00000, loss_test:0.06652, lr:3.66e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.996, tt:6399.215\n",
      "Ep:200, loss:0.00000, loss_test:0.06658, lr:3.62e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.995, tt:6431.000\n",
      "Ep:201, loss:0.00000, loss_test:0.06644, lr:3.59e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.994, tt:6462.818\n",
      "Ep:202, loss:0.00000, loss_test:0.06671, lr:3.55e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.996, tt:6495.189\n",
      "Ep:203, loss:0.00000, loss_test:0.06643, lr:3.52e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.992, tt:6526.320\n",
      "Ep:204, loss:0.00000, loss_test:0.06640, lr:3.48e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.995, tt:6559.040\n",
      "Ep:205, loss:0.00000, loss_test:0.06798, lr:3.45e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.979, tt:6587.667\n",
      "Ep:206, loss:0.00000, loss_test:0.06636, lr:3.41e-03, fs:0.83529 (r=0.717,p=1.000),  time:31.949, tt:6613.459\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14209, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:61.851, tt:61.851\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.13892, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:63.042, tt:126.083\n",
      "Ep:2, loss:0.00054, loss_test:0.13151, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:63.954, tt:191.862\n",
      "Ep:3, loss:0.00050, loss_test:0.11543, lr:1.00e-02, fs:0.66667 (r=0.818,p=0.562),  time:64.175, tt:256.701\n",
      "Ep:4, loss:0.00046, loss_test:0.10763, lr:1.00e-02, fs:0.66667 (r=0.687,p=0.648),  time:65.092, tt:325.459\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.10607, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:65.329, tt:391.977\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00043, loss_test:0.10206, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:65.397, tt:457.782\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.09778, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:65.562, tt:524.496\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.09495, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:65.786, tt:592.074\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.09213, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:65.926, tt:659.260\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.08960, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:65.845, tt:724.297\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.08806, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:66.042, tt:792.499\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.08620, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:65.925, tt:857.031\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.08401, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:65.929, tt:923.008\n",
      "Ep:14, loss:0.00029, loss_test:0.08334, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:65.957, tt:989.355\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.08192, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:66.156, tt:1058.489\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.07968, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:66.271, tt:1126.602\n",
      "Ep:17, loss:0.00025, loss_test:0.07858, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:66.294, tt:1193.298\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.07731, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:66.323, tt:1260.131\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.07566, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:66.188, tt:1323.763\n",
      "Ep:20, loss:0.00022, loss_test:0.07385, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:66.300, tt:1392.302\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.07309, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:66.384, tt:1460.445\n",
      "Ep:22, loss:0.00020, loss_test:0.07246, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:66.317, tt:1525.290\n",
      "Ep:23, loss:0.00019, loss_test:0.07137, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:66.401, tt:1593.636\n",
      "Ep:24, loss:0.00018, loss_test:0.07041, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:66.361, tt:1659.015\n",
      "Ep:25, loss:0.00017, loss_test:0.06961, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:66.393, tt:1726.219\n",
      "Ep:26, loss:0.00017, loss_test:0.06979, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:66.411, tt:1793.102\n",
      "Ep:27, loss:0.00016, loss_test:0.06698, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:66.461, tt:1860.900\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.06736, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:66.485, tt:1928.053\n",
      "Ep:29, loss:0.00015, loss_test:0.06752, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:66.543, tt:1996.278\n",
      "Ep:30, loss:0.00014, loss_test:0.06397, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:66.468, tt:2060.496\n",
      "Ep:31, loss:0.00014, loss_test:0.06541, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:66.449, tt:2126.376\n",
      "Ep:32, loss:0.00013, loss_test:0.06433, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:66.415, tt:2191.688\n",
      "Ep:33, loss:0.00012, loss_test:0.06453, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:66.397, tt:2257.489\n",
      "Ep:34, loss:0.00012, loss_test:0.06309, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:66.356, tt:2322.472\n",
      "Ep:35, loss:0.00011, loss_test:0.06106, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:66.297, tt:2386.695\n",
      "Ep:36, loss:0.00011, loss_test:0.06168, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:66.343, tt:2454.680\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.06151, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:66.366, tt:2521.925\n",
      "Ep:38, loss:0.00010, loss_test:0.06140, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:66.398, tt:2589.504\n",
      "Ep:39, loss:0.00009, loss_test:0.06111, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:66.431, tt:2657.239\n",
      "Ep:40, loss:0.00009, loss_test:0.05877, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:66.467, tt:2725.142\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.05838, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:66.465, tt:2791.545\n",
      "Ep:42, loss:0.00008, loss_test:0.06116, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:66.431, tt:2856.517\n",
      "Ep:43, loss:0.00008, loss_test:0.06073, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:66.412, tt:2922.110\n",
      "Ep:44, loss:0.00008, loss_test:0.05626, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:66.370, tt:2986.651\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.05876, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:66.398, tt:3054.328\n",
      "Ep:46, loss:0.00007, loss_test:0.05714, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:66.392, tt:3120.426\n",
      "Ep:47, loss:0.00007, loss_test:0.05617, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:66.431, tt:3188.674\n",
      "Ep:48, loss:0.00006, loss_test:0.05851, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:66.447, tt:3255.890\n",
      "Ep:49, loss:0.00006, loss_test:0.05797, lr:1.00e-02, fs:0.86188 (r=0.788,p=0.951),  time:66.457, tt:3322.837\n",
      "Ep:50, loss:0.00006, loss_test:0.05617, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:66.420, tt:3387.420\n",
      "Ep:51, loss:0.00006, loss_test:0.05572, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:66.434, tt:3454.555\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.05819, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:66.367, tt:3517.447\n",
      "Ep:53, loss:0.00005, loss_test:0.05707, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:66.352, tt:3582.988\n",
      "Ep:54, loss:0.00005, loss_test:0.05467, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:66.355, tt:3649.500\n",
      "Ep:55, loss:0.00005, loss_test:0.05732, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:66.333, tt:3714.623\n",
      "Ep:56, loss:0.00005, loss_test:0.05833, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:66.317, tt:3780.098\n",
      "Ep:57, loss:0.00004, loss_test:0.05635, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:66.290, tt:3844.799\n",
      "Ep:58, loss:0.00004, loss_test:0.05657, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:66.242, tt:3908.291\n",
      "Ep:59, loss:0.00004, loss_test:0.05647, lr:1.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:66.298, tt:3977.856\n",
      "Ep:60, loss:0.00004, loss_test:0.05713, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:66.300, tt:4044.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00004, loss_test:0.05568, lr:1.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:66.309, tt:4111.161\n",
      "Ep:62, loss:0.00004, loss_test:0.05486, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:66.297, tt:4176.716\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.05722, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:66.308, tt:4243.735\n",
      "Ep:64, loss:0.00004, loss_test:0.05606, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:66.281, tt:4308.261\n",
      "Ep:65, loss:0.00003, loss_test:0.05641, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:66.289, tt:4375.088\n",
      "Ep:66, loss:0.00003, loss_test:0.05683, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:66.321, tt:4443.480\n",
      "Ep:67, loss:0.00003, loss_test:0.05839, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:66.321, tt:4509.825\n",
      "Ep:68, loss:0.00003, loss_test:0.05546, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:66.303, tt:4574.933\n",
      "Ep:69, loss:0.00003, loss_test:0.05602, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:66.312, tt:4641.859\n",
      "Ep:70, loss:0.00003, loss_test:0.05665, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:66.324, tt:4708.998\n",
      "Ep:71, loss:0.00003, loss_test:0.05672, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:66.327, tt:4775.517\n",
      "Ep:72, loss:0.00003, loss_test:0.05831, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:66.327, tt:4841.859\n",
      "Ep:73, loss:0.00003, loss_test:0.05717, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:66.341, tt:4909.230\n",
      "Ep:74, loss:0.00003, loss_test:0.05911, lr:9.90e-03, fs:0.87778 (r=0.798,p=0.975),  time:66.327, tt:4974.542\n",
      "Ep:75, loss:0.00003, loss_test:0.06012, lr:9.80e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.315, tt:5039.921\n",
      "Ep:76, loss:0.00003, loss_test:0.05688, lr:9.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:66.307, tt:5105.660\n",
      "Ep:77, loss:0.00003, loss_test:0.05607, lr:9.61e-03, fs:0.83237 (r=0.727,p=0.973),  time:66.305, tt:5171.783\n",
      "Ep:78, loss:0.00002, loss_test:0.05986, lr:9.51e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.261, tt:5234.600\n",
      "Ep:79, loss:0.00002, loss_test:0.05682, lr:9.41e-03, fs:0.83721 (r=0.727,p=0.986),  time:66.251, tt:5300.088\n",
      "Ep:80, loss:0.00002, loss_test:0.05666, lr:9.32e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.254, tt:5366.579\n",
      "Ep:81, loss:0.00002, loss_test:0.05887, lr:9.23e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.261, tt:5433.390\n",
      "Ep:82, loss:0.00002, loss_test:0.05694, lr:9.14e-03, fs:0.83237 (r=0.727,p=0.973),  time:66.253, tt:5499.020\n",
      "Ep:83, loss:0.00002, loss_test:0.05790, lr:9.04e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.267, tt:5566.387\n",
      "Ep:84, loss:0.00002, loss_test:0.05738, lr:8.95e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.255, tt:5631.678\n",
      "Ep:85, loss:0.00002, loss_test:0.05899, lr:8.86e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.248, tt:5697.293\n",
      "Ep:86, loss:0.00002, loss_test:0.05855, lr:8.78e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.214, tt:5760.584\n",
      "Ep:87, loss:0.00002, loss_test:0.05863, lr:8.69e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.202, tt:5825.750\n",
      "Ep:88, loss:0.00002, loss_test:0.05993, lr:8.60e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.197, tt:5891.561\n",
      "Ep:89, loss:0.00002, loss_test:0.05738, lr:8.51e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.180, tt:5956.244\n",
      "Ep:90, loss:0.00002, loss_test:0.05848, lr:8.43e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.167, tt:6021.207\n",
      "Ep:91, loss:0.00002, loss_test:0.05996, lr:8.35e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.143, tt:6085.145\n",
      "Ep:92, loss:0.00002, loss_test:0.05878, lr:8.26e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.152, tt:6152.160\n",
      "Ep:93, loss:0.00002, loss_test:0.05935, lr:8.18e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.150, tt:6218.127\n",
      "Ep:94, loss:0.00002, loss_test:0.05974, lr:8.10e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.154, tt:6284.613\n",
      "Ep:95, loss:0.00002, loss_test:0.05909, lr:8.02e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.149, tt:6350.324\n",
      "Ep:96, loss:0.00002, loss_test:0.05904, lr:7.94e-03, fs:0.82558 (r=0.717,p=0.973),  time:66.150, tt:6416.593\n",
      "Ep:97, loss:0.00002, loss_test:0.05960, lr:7.86e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.153, tt:6482.976\n",
      "Ep:98, loss:0.00001, loss_test:0.06038, lr:7.78e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.180, tt:6551.815\n",
      "Ep:99, loss:0.00001, loss_test:0.05918, lr:7.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:66.161, tt:6616.085\n",
      "Ep:100, loss:0.00001, loss_test:0.06138, lr:7.62e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.155, tt:6681.648\n",
      "Ep:101, loss:0.00001, loss_test:0.05835, lr:7.55e-03, fs:0.82558 (r=0.717,p=0.973),  time:66.141, tt:6746.419\n",
      "Ep:102, loss:0.00001, loss_test:0.06048, lr:7.47e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.129, tt:6811.273\n",
      "Ep:103, loss:0.00001, loss_test:0.06103, lr:7.40e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.116, tt:6876.088\n",
      "Ep:104, loss:0.00001, loss_test:0.05914, lr:7.32e-03, fs:0.82558 (r=0.717,p=0.973),  time:66.128, tt:6943.475\n",
      "Ep:105, loss:0.00001, loss_test:0.06090, lr:7.25e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.121, tt:7008.878\n",
      "Ep:106, loss:0.00001, loss_test:0.06008, lr:7.18e-03, fs:0.82558 (r=0.717,p=0.973),  time:66.116, tt:7074.431\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.13895, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.995, tt:13.995\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.13846, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.519, tt:27.039\n",
      "Ep:2, loss:0.00014, loss_test:0.13772, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.341, tt:43.022\n",
      "Ep:3, loss:0.00014, loss_test:0.13668, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.715, tt:58.861\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00014, loss_test:0.13535, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.926, tt:74.630\n",
      "Ep:5, loss:0.00013, loss_test:0.13370, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:15.215, tt:91.292\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00013, loss_test:0.13159, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:15.309, tt:107.161\n",
      "Ep:7, loss:0.00013, loss_test:0.12898, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:15.363, tt:122.902\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00013, loss_test:0.12579, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:15.402, tt:138.619\n",
      "Ep:9, loss:0.00013, loss_test:0.12208, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:15.430, tt:154.297\n",
      "Ep:10, loss:0.00012, loss_test:0.11810, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:15.401, tt:169.408\n",
      "Ep:11, loss:0.00012, loss_test:0.11501, lr:1.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:15.577, tt:186.923\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00012, loss_test:0.11252, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:15.636, tt:203.265\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00012, loss_test:0.11129, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:15.646, tt:219.047\n",
      "Ep:14, loss:0.00012, loss_test:0.11031, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:15.642, tt:234.630\n",
      "Ep:15, loss:0.00011, loss_test:0.10900, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:15.663, tt:250.605\n",
      "Ep:16, loss:0.00011, loss_test:0.10786, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:15.654, tt:266.123\n",
      "Ep:17, loss:0.00011, loss_test:0.10719, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:15.689, tt:282.403\n",
      "Ep:18, loss:0.00011, loss_test:0.10641, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:15.651, tt:297.375\n",
      "Ep:19, loss:0.00011, loss_test:0.10531, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:15.587, tt:311.743\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.10345, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:15.625, tt:328.125\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.10146, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:15.591, tt:343.006\n",
      "Ep:22, loss:0.00010, loss_test:0.10041, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:15.610, tt:359.036\n",
      "Ep:23, loss:0.00010, loss_test:0.09983, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:15.604, tt:374.489\n",
      "Ep:24, loss:0.00010, loss_test:0.09881, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:15.603, tt:390.084\n",
      "Ep:25, loss:0.00010, loss_test:0.09727, lr:1.00e-02, fs:0.69110 (r=0.667,p=0.717),  time:15.618, tt:406.064\n",
      "Ep:26, loss:0.00010, loss_test:0.09575, lr:1.00e-02, fs:0.69744 (r=0.687,p=0.708),  time:15.650, tt:422.559\n",
      "Ep:27, loss:0.00010, loss_test:0.09467, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:15.689, tt:439.281\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.09364, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:15.722, tt:455.933\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.09271, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:15.732, tt:471.967\n",
      "Ep:30, loss:0.00009, loss_test:0.09191, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:15.764, tt:488.693\n",
      "Ep:31, loss:0.00009, loss_test:0.09095, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:15.804, tt:505.712\n",
      "Ep:32, loss:0.00009, loss_test:0.08973, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:15.837, tt:522.611\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.08881, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:15.868, tt:539.496\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.08801, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:15.877, tt:555.689\n",
      "Ep:35, loss:0.00008, loss_test:0.08713, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.880, tt:571.664\n",
      "Ep:36, loss:0.00008, loss_test:0.08640, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:15.882, tt:587.628\n",
      "Ep:37, loss:0.00008, loss_test:0.08575, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:15.879, tt:603.391\n",
      "Ep:38, loss:0.00008, loss_test:0.08502, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:15.869, tt:618.894\n",
      "Ep:39, loss:0.00008, loss_test:0.08424, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:15.892, tt:635.693\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.08357, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:15.873, tt:650.789\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08301, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:15.889, tt:667.334\n",
      "Ep:42, loss:0.00008, loss_test:0.08247, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:15.868, tt:682.344\n",
      "Ep:43, loss:0.00007, loss_test:0.08218, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:15.866, tt:698.123\n",
      "Ep:44, loss:0.00007, loss_test:0.08178, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:15.869, tt:714.083\n",
      "Ep:45, loss:0.00007, loss_test:0.08139, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:15.895, tt:731.154\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.08107, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:15.883, tt:746.511\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.08066, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:15.869, tt:761.704\n",
      "Ep:48, loss:0.00007, loss_test:0.08034, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:15.867, tt:777.463\n",
      "Ep:49, loss:0.00007, loss_test:0.07996, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:15.837, tt:791.866\n",
      "Ep:50, loss:0.00007, loss_test:0.07953, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:15.826, tt:807.111\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.07914, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:15.815, tt:822.386\n",
      "Ep:52, loss:0.00007, loss_test:0.07886, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:15.796, tt:837.214\n",
      "Ep:53, loss:0.00006, loss_test:0.07869, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:15.792, tt:852.745\n",
      "Ep:54, loss:0.00006, loss_test:0.07855, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:15.787, tt:868.277\n",
      "Ep:55, loss:0.00006, loss_test:0.07812, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:15.801, tt:884.864\n",
      "Ep:56, loss:0.00006, loss_test:0.07756, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:15.805, tt:900.875\n",
      "Ep:57, loss:0.00006, loss_test:0.07713, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:15.797, tt:916.228\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.07685, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.806, tt:932.542\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.07653, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.806, tt:948.373\n",
      "Ep:60, loss:0.00006, loss_test:0.07617, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.802, tt:963.915\n",
      "Ep:61, loss:0.00006, loss_test:0.07595, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.786, tt:978.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00006, loss_test:0.07570, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.776, tt:993.871\n",
      "Ep:63, loss:0.00006, loss_test:0.07551, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.776, tt:1009.696\n",
      "Ep:64, loss:0.00006, loss_test:0.07539, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:15.792, tt:1026.496\n",
      "Ep:65, loss:0.00005, loss_test:0.07517, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:15.787, tt:1041.932\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.07487, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:15.767, tt:1056.396\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.07469, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:15.767, tt:1072.182\n",
      "Ep:68, loss:0.00005, loss_test:0.07440, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:15.740, tt:1086.044\n",
      "Ep:69, loss:0.00005, loss_test:0.07413, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:15.725, tt:1100.750\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.07392, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:15.709, tt:1115.309\n",
      "Ep:71, loss:0.00005, loss_test:0.07367, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:15.703, tt:1130.625\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.07363, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:15.709, tt:1146.721\n",
      "Ep:73, loss:0.00005, loss_test:0.07341, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:15.707, tt:1162.307\n",
      "Ep:74, loss:0.00005, loss_test:0.07308, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:15.695, tt:1177.130\n",
      "Ep:75, loss:0.00005, loss_test:0.07306, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:15.684, tt:1191.950\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00005, loss_test:0.07301, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:15.697, tt:1208.642\n",
      "Ep:77, loss:0.00005, loss_test:0.07269, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:15.689, tt:1223.776\n",
      "Ep:78, loss:0.00005, loss_test:0.07260, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:15.683, tt:1238.956\n",
      "Ep:79, loss:0.00005, loss_test:0.07241, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:15.687, tt:1254.963\n",
      "Ep:80, loss:0.00004, loss_test:0.07238, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:15.669, tt:1269.178\n",
      "Ep:81, loss:0.00004, loss_test:0.07217, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:15.654, tt:1283.642\n",
      "Ep:82, loss:0.00004, loss_test:0.07220, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:15.655, tt:1299.354\n",
      "Ep:83, loss:0.00004, loss_test:0.07196, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:15.657, tt:1315.177\n",
      "Ep:84, loss:0.00004, loss_test:0.07175, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:15.654, tt:1330.607\n",
      "Ep:85, loss:0.00004, loss_test:0.07183, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:15.665, tt:1347.174\n",
      "Ep:86, loss:0.00004, loss_test:0.07150, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:15.667, tt:1362.996\n",
      "Ep:87, loss:0.00004, loss_test:0.07114, lr:9.90e-03, fs:0.84848 (r=0.848,p=0.848),  time:15.647, tt:1376.919\n",
      "Ep:88, loss:0.00004, loss_test:0.07118, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.646, tt:1392.538\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.07075, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.644, tt:1407.998\n",
      "Ep:90, loss:0.00004, loss_test:0.07053, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.642, tt:1423.418\n",
      "Ep:91, loss:0.00004, loss_test:0.07034, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.650, tt:1439.793\n",
      "Ep:92, loss:0.00004, loss_test:0.07022, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.659, tt:1456.285\n",
      "Ep:93, loss:0.00004, loss_test:0.06998, lr:9.80e-03, fs:0.86869 (r=0.869,p=0.869),  time:15.669, tt:1472.857\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00004, loss_test:0.07018, lr:9.80e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.673, tt:1488.967\n",
      "Ep:95, loss:0.00004, loss_test:0.06972, lr:9.80e-03, fs:0.87437 (r=0.879,p=0.870),  time:15.668, tt:1504.143\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00004, loss_test:0.06999, lr:9.80e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.664, tt:1519.446\n",
      "Ep:97, loss:0.00004, loss_test:0.06966, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.657, tt:1534.426\n",
      "Ep:98, loss:0.00004, loss_test:0.06957, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.648, tt:1549.173\n",
      "Ep:99, loss:0.00003, loss_test:0.06930, lr:9.80e-03, fs:0.87310 (r=0.869,p=0.878),  time:15.646, tt:1564.576\n",
      "Ep:100, loss:0.00003, loss_test:0.06972, lr:9.80e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.646, tt:1580.251\n",
      "Ep:101, loss:0.00003, loss_test:0.06916, lr:9.80e-03, fs:0.86735 (r=0.859,p=0.876),  time:15.650, tt:1596.318\n",
      "Ep:102, loss:0.00003, loss_test:0.06949, lr:9.80e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.646, tt:1611.501\n",
      "Ep:103, loss:0.00003, loss_test:0.06907, lr:9.80e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.633, tt:1625.841\n",
      "Ep:104, loss:0.00003, loss_test:0.06850, lr:9.80e-03, fs:0.87310 (r=0.869,p=0.878),  time:15.635, tt:1641.712\n",
      "Ep:105, loss:0.00003, loss_test:0.06977, lr:9.80e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.632, tt:1657.035\n",
      "Ep:106, loss:0.00003, loss_test:0.06957, lr:9.80e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.638, tt:1673.297\n",
      "Ep:107, loss:0.00003, loss_test:0.06831, lr:9.70e-03, fs:0.86869 (r=0.869,p=0.869),  time:15.644, tt:1689.580\n",
      "Ep:108, loss:0.00003, loss_test:0.06906, lr:9.61e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.642, tt:1704.955\n",
      "Ep:109, loss:0.00003, loss_test:0.06972, lr:9.51e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.635, tt:1719.838\n",
      "Ep:110, loss:0.00003, loss_test:0.06919, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.631, tt:1735.045\n",
      "Ep:111, loss:0.00003, loss_test:0.06876, lr:9.32e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.635, tt:1751.124\n",
      "Ep:112, loss:0.00003, loss_test:0.06919, lr:9.23e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.623, tt:1765.351\n",
      "Ep:113, loss:0.00003, loss_test:0.06903, lr:9.14e-03, fs:0.85714 (r=0.848,p=0.866),  time:15.617, tt:1780.380\n",
      "Ep:114, loss:0.00003, loss_test:0.06858, lr:9.04e-03, fs:0.86294 (r=0.859,p=0.867),  time:15.610, tt:1795.155\n",
      "Ep:115, loss:0.00003, loss_test:0.06947, lr:8.95e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.599, tt:1809.461\n",
      "Ep:116, loss:0.00003, loss_test:0.06936, lr:8.86e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.602, tt:1825.477\n",
      "Ep:117, loss:0.00003, loss_test:0.06821, lr:8.78e-03, fs:0.86869 (r=0.869,p=0.869),  time:15.607, tt:1841.653\n",
      "Ep:118, loss:0.00003, loss_test:0.06911, lr:8.69e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.618, tt:1858.580\n",
      "Ep:119, loss:0.00003, loss_test:0.06955, lr:8.60e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.604, tt:1872.467\n",
      "Ep:120, loss:0.00003, loss_test:0.06875, lr:8.51e-03, fs:0.86869 (r=0.869,p=0.869),  time:15.611, tt:1888.911\n",
      "Ep:121, loss:0.00003, loss_test:0.06847, lr:8.43e-03, fs:0.86869 (r=0.869,p=0.869),  time:15.611, tt:1904.502\n",
      "Ep:122, loss:0.00003, loss_test:0.06909, lr:8.35e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.616, tt:1920.817\n",
      "Ep:123, loss:0.00003, loss_test:0.06873, lr:8.26e-03, fs:0.86294 (r=0.859,p=0.867),  time:15.619, tt:1936.732\n",
      "Ep:124, loss:0.00003, loss_test:0.06807, lr:8.18e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.622, tt:1952.799\n",
      "Ep:125, loss:0.00003, loss_test:0.06910, lr:8.10e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.628, tt:1969.079\n",
      "Ep:126, loss:0.00003, loss_test:0.06891, lr:8.02e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.624, tt:1984.190\n",
      "Ep:127, loss:0.00003, loss_test:0.06779, lr:7.94e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.619, tt:1999.232\n",
      "Ep:128, loss:0.00003, loss_test:0.06846, lr:7.86e-03, fs:0.85859 (r=0.859,p=0.859),  time:15.622, tt:2015.183\n",
      "Ep:129, loss:0.00003, loss_test:0.06907, lr:7.78e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.612, tt:2029.583\n",
      "Ep:130, loss:0.00003, loss_test:0.06835, lr:7.70e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.611, tt:2045.090\n",
      "Ep:131, loss:0.00003, loss_test:0.06770, lr:7.62e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.610, tt:2060.501\n",
      "Ep:132, loss:0.00002, loss_test:0.06886, lr:7.55e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.610, tt:2076.140\n",
      "Ep:133, loss:0.00002, loss_test:0.06905, lr:7.47e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.611, tt:2091.840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.06800, lr:7.40e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.607, tt:2106.952\n",
      "Ep:135, loss:0.00002, loss_test:0.06779, lr:7.32e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.606, tt:2122.455\n",
      "Ep:136, loss:0.00002, loss_test:0.06889, lr:7.25e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.596, tt:2136.680\n",
      "Ep:137, loss:0.00002, loss_test:0.06881, lr:7.18e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.593, tt:2151.835\n",
      "Ep:138, loss:0.00002, loss_test:0.06767, lr:7.11e-03, fs:0.86432 (r=0.869,p=0.860),  time:15.591, tt:2167.146\n",
      "Ep:139, loss:0.00002, loss_test:0.06796, lr:7.03e-03, fs:0.86294 (r=0.859,p=0.867),  time:15.586, tt:2182.037\n",
      "Ep:140, loss:0.00002, loss_test:0.06848, lr:6.96e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.579, tt:2196.660\n",
      "Ep:141, loss:0.00002, loss_test:0.06833, lr:6.89e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.576, tt:2211.759\n",
      "Ep:142, loss:0.00002, loss_test:0.06764, lr:6.83e-03, fs:0.86869 (r=0.869,p=0.869),  time:15.575, tt:2227.250\n",
      "Ep:143, loss:0.00002, loss_test:0.06823, lr:6.76e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.609, tt:2247.741\n",
      "Ep:144, loss:0.00002, loss_test:0.06847, lr:6.69e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.606, tt:2262.836\n",
      "Ep:145, loss:0.00002, loss_test:0.06810, lr:6.62e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.591, tt:2276.271\n",
      "Ep:146, loss:0.00002, loss_test:0.06776, lr:6.56e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.584, tt:2290.810\n",
      "Ep:147, loss:0.00002, loss_test:0.06855, lr:6.49e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.584, tt:2306.468\n",
      "Ep:148, loss:0.00002, loss_test:0.06840, lr:6.43e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.573, tt:2320.375\n",
      "Ep:149, loss:0.00002, loss_test:0.06776, lr:6.36e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.561, tt:2334.103\n",
      "Ep:150, loss:0.00002, loss_test:0.06825, lr:6.30e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.550, tt:2348.054\n",
      "Ep:151, loss:0.00002, loss_test:0.06827, lr:6.24e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.539, tt:2361.925\n",
      "Ep:152, loss:0.00002, loss_test:0.06790, lr:6.17e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.532, tt:2376.338\n",
      "Ep:153, loss:0.00002, loss_test:0.06806, lr:6.11e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.522, tt:2390.426\n",
      "Ep:154, loss:0.00002, loss_test:0.06814, lr:6.05e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.501, tt:2402.705\n",
      "Ep:155, loss:0.00002, loss_test:0.06776, lr:5.99e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.498, tt:2417.715\n",
      "Ep:156, loss:0.00002, loss_test:0.06785, lr:5.93e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.490, tt:2431.958\n",
      "Ep:157, loss:0.00002, loss_test:0.06821, lr:5.87e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.485, tt:2446.657\n",
      "Ep:158, loss:0.00002, loss_test:0.06791, lr:5.81e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.480, tt:2461.400\n",
      "Ep:159, loss:0.00002, loss_test:0.06742, lr:5.75e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.474, tt:2475.806\n",
      "Ep:160, loss:0.00002, loss_test:0.06863, lr:5.70e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.463, tt:2489.617\n",
      "Ep:161, loss:0.00002, loss_test:0.06860, lr:5.64e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.455, tt:2503.700\n",
      "Ep:162, loss:0.00002, loss_test:0.06751, lr:5.58e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.443, tt:2517.195\n",
      "Ep:163, loss:0.00002, loss_test:0.06734, lr:5.53e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.437, tt:2531.719\n",
      "Ep:164, loss:0.00002, loss_test:0.06847, lr:5.47e-03, fs:0.84211 (r=0.808,p=0.879),  time:15.431, tt:2546.038\n",
      "Ep:165, loss:0.00002, loss_test:0.06846, lr:5.42e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.426, tt:2560.645\n",
      "Ep:166, loss:0.00002, loss_test:0.06749, lr:5.36e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.417, tt:2574.564\n",
      "Ep:167, loss:0.00002, loss_test:0.06749, lr:5.31e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.410, tt:2588.851\n",
      "Ep:168, loss:0.00002, loss_test:0.06798, lr:5.26e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.404, tt:2603.354\n",
      "Ep:169, loss:0.00002, loss_test:0.06788, lr:5.20e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.392, tt:2616.587\n",
      "Ep:170, loss:0.00002, loss_test:0.06741, lr:5.15e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.383, tt:2630.567\n",
      "Ep:171, loss:0.00002, loss_test:0.06777, lr:5.10e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.372, tt:2643.907\n",
      "Ep:172, loss:0.00002, loss_test:0.06806, lr:5.05e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.364, tt:2658.039\n",
      "Ep:173, loss:0.00002, loss_test:0.06780, lr:5.00e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.353, tt:2671.476\n",
      "Ep:174, loss:0.00002, loss_test:0.06772, lr:4.95e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.344, tt:2685.143\n",
      "Ep:175, loss:0.00002, loss_test:0.06779, lr:4.90e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.327, tt:2697.556\n",
      "Ep:176, loss:0.00002, loss_test:0.06779, lr:4.85e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.312, tt:2710.163\n",
      "Ep:177, loss:0.00002, loss_test:0.06745, lr:4.80e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.297, tt:2722.802\n",
      "Ep:178, loss:0.00002, loss_test:0.06722, lr:4.75e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.287, tt:2736.425\n",
      "Ep:179, loss:0.00002, loss_test:0.06791, lr:4.71e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.276, tt:2749.737\n",
      "Ep:180, loss:0.00002, loss_test:0.06793, lr:4.66e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.269, tt:2763.680\n",
      "Ep:181, loss:0.00002, loss_test:0.06727, lr:4.61e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.257, tt:2776.848\n",
      "Ep:182, loss:0.00002, loss_test:0.06719, lr:4.57e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.247, tt:2790.175\n",
      "Ep:183, loss:0.00002, loss_test:0.06780, lr:4.52e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.229, tt:2802.091\n",
      "Ep:184, loss:0.00002, loss_test:0.06775, lr:4.48e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.222, tt:2816.014\n",
      "Ep:185, loss:0.00002, loss_test:0.06716, lr:4.43e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.214, tt:2829.813\n",
      "Ep:186, loss:0.00002, loss_test:0.06727, lr:4.39e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.207, tt:2843.628\n",
      "Ep:187, loss:0.00002, loss_test:0.06745, lr:4.34e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.189, tt:2855.463\n",
      "Ep:188, loss:0.00002, loss_test:0.06742, lr:4.30e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.180, tt:2869.019\n",
      "Ep:189, loss:0.00002, loss_test:0.06736, lr:4.26e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.176, tt:2883.513\n",
      "Ep:190, loss:0.00002, loss_test:0.06719, lr:4.21e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.163, tt:2896.169\n",
      "Ep:191, loss:0.00002, loss_test:0.06732, lr:4.17e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.160, tt:2910.679\n",
      "Ep:192, loss:0.00002, loss_test:0.06737, lr:4.13e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.157, tt:2925.251\n",
      "Ep:193, loss:0.00002, loss_test:0.06741, lr:4.09e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.153, tt:2939.722\n",
      "Ep:194, loss:0.00002, loss_test:0.06723, lr:4.05e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.147, tt:2953.705\n",
      "Ep:195, loss:0.00002, loss_test:0.06756, lr:4.01e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.145, tt:2968.495\n",
      "Ep:196, loss:0.00002, loss_test:0.06753, lr:3.97e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.142, tt:2983.034\n",
      "Ep:197, loss:0.00002, loss_test:0.06714, lr:3.93e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.133, tt:2996.311\n",
      "Ep:198, loss:0.00002, loss_test:0.06761, lr:3.89e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.134, tt:3011.626\n",
      "Ep:199, loss:0.00002, loss_test:0.06744, lr:3.85e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.133, tt:3026.593\n",
      "Ep:200, loss:0.00002, loss_test:0.06721, lr:3.81e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.127, tt:3040.448\n",
      "Ep:201, loss:0.00002, loss_test:0.06748, lr:3.77e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.122, tt:3054.609\n",
      "Ep:202, loss:0.00002, loss_test:0.06750, lr:3.73e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.102, tt:3065.708\n",
      "Ep:203, loss:0.00002, loss_test:0.06739, lr:3.70e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.088, tt:3078.035\n",
      "Ep:204, loss:0.00002, loss_test:0.06737, lr:3.66e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.069, tt:3089.174\n",
      "Ep:205, loss:0.00002, loss_test:0.06739, lr:3.62e-03, fs:0.83770 (r=0.808,p=0.870),  time:15.035, tt:3097.291\n",
      "Ep:206, loss:0.00002, loss_test:0.06716, lr:3.59e-03, fs:0.84375 (r=0.818,p=0.871),  time:14.989, tt:3102.826\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14607, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.956, tt:27.956\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14554, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.561, tt:59.123\n",
      "Ep:2, loss:0.00028, loss_test:0.14472, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.465, tt:91.395\n",
      "Ep:3, loss:0.00028, loss_test:0.14348, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.801, tt:123.204\n",
      "Ep:4, loss:0.00028, loss_test:0.14162, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.888, tt:154.439\n",
      "Ep:5, loss:0.00027, loss_test:0.13885, lr:1.00e-02, fs:0.65823 (r=0.963,p=0.500),  time:30.717, tt:184.302\n",
      "Ep:6, loss:0.00026, loss_test:0.13456, lr:1.00e-02, fs:0.66667 (r=0.963,p=0.510),  time:30.781, tt:215.464\n",
      "Ep:7, loss:0.00026, loss_test:0.12913, lr:1.00e-02, fs:0.67586 (r=0.907,p=0.538),  time:30.842, tt:246.739\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12259, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:30.853, tt:277.680\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11839, lr:1.00e-02, fs:0.73846 (r=0.889,p=0.632),  time:30.859, tt:308.595\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.11596, lr:1.00e-02, fs:0.70866 (r=0.833,p=0.616),  time:30.815, tt:338.962\n",
      "Ep:11, loss:0.00023, loss_test:0.11592, lr:1.00e-02, fs:0.71318 (r=0.852,p=0.613),  time:30.823, tt:369.881\n",
      "Ep:12, loss:0.00022, loss_test:0.11596, lr:1.00e-02, fs:0.69173 (r=0.852,p=0.582),  time:30.857, tt:401.145\n",
      "Ep:13, loss:0.00022, loss_test:0.11290, lr:1.00e-02, fs:0.72441 (r=0.852,p=0.630),  time:30.902, tt:432.628\n",
      "Ep:14, loss:0.00021, loss_test:0.10966, lr:1.00e-02, fs:0.70968 (r=0.815,p=0.629),  time:30.829, tt:462.432\n",
      "Ep:15, loss:0.00021, loss_test:0.10725, lr:1.00e-02, fs:0.72881 (r=0.796,p=0.672),  time:30.900, tt:494.402\n",
      "Ep:16, loss:0.00020, loss_test:0.10555, lr:1.00e-02, fs:0.73333 (r=0.815,p=0.667),  time:31.022, tt:527.368\n",
      "Ep:17, loss:0.00020, loss_test:0.10392, lr:1.00e-02, fs:0.75806 (r=0.870,p=0.671),  time:30.976, tt:557.563\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.10109, lr:1.00e-02, fs:0.75214 (r=0.815,p=0.698),  time:31.075, tt:590.428\n",
      "Ep:19, loss:0.00018, loss_test:0.09842, lr:1.00e-02, fs:0.74783 (r=0.796,p=0.705),  time:31.153, tt:623.055\n",
      "Ep:20, loss:0.00018, loss_test:0.09597, lr:1.00e-02, fs:0.76923 (r=0.833,p=0.714),  time:31.218, tt:655.587\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09366, lr:1.00e-02, fs:0.76923 (r=0.833,p=0.714),  time:31.187, tt:686.117\n",
      "Ep:22, loss:0.00017, loss_test:0.09199, lr:1.00e-02, fs:0.77966 (r=0.852,p=0.719),  time:31.136, tt:716.137\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.09041, lr:1.00e-02, fs:0.76923 (r=0.833,p=0.714),  time:31.195, tt:748.670\n",
      "Ep:24, loss:0.00016, loss_test:0.08838, lr:1.00e-02, fs:0.77966 (r=0.852,p=0.719),  time:31.237, tt:780.921\n",
      "Ep:25, loss:0.00016, loss_test:0.08637, lr:1.00e-02, fs:0.78992 (r=0.870,p=0.723),  time:31.282, tt:813.329\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08399, lr:1.00e-02, fs:0.80342 (r=0.870,p=0.746),  time:31.315, tt:845.517\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.08222, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:31.415, tt:879.617\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.08180, lr:1.00e-02, fs:0.82645 (r=0.926,p=0.746),  time:31.369, tt:909.710\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.07941, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:31.393, tt:941.783\n",
      "Ep:30, loss:0.00014, loss_test:0.07783, lr:1.00e-02, fs:0.84746 (r=0.926,p=0.781),  time:31.473, tt:975.670\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.07604, lr:1.00e-02, fs:0.85714 (r=0.944,p=0.785),  time:31.512, tt:1008.378\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.07427, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.573, tt:1041.910\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07286, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.560, tt:1073.044\n",
      "Ep:34, loss:0.00013, loss_test:0.07141, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.567, tt:1104.840\n",
      "Ep:35, loss:0.00012, loss_test:0.07012, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.586, tt:1137.081\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.06894, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.601, tt:1169.248\n",
      "Ep:37, loss:0.00012, loss_test:0.06777, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.611, tt:1201.210\n",
      "Ep:38, loss:0.00011, loss_test:0.06621, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.649, tt:1234.298\n",
      "Ep:39, loss:0.00011, loss_test:0.06479, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.679, tt:1267.170\n",
      "Ep:40, loss:0.00011, loss_test:0.06397, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.684, tt:1299.057\n",
      "Ep:41, loss:0.00011, loss_test:0.06281, lr:1.00e-02, fs:0.89286 (r=0.926,p=0.862),  time:31.739, tt:1333.049\n",
      "Ep:42, loss:0.00010, loss_test:0.06131, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.752, tt:1365.340\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.06040, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.770, tt:1397.887\n",
      "Ep:44, loss:0.00010, loss_test:0.05929, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.811, tt:1431.487\n",
      "Ep:45, loss:0.00010, loss_test:0.05829, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.835, tt:1464.394\n",
      "Ep:46, loss:0.00009, loss_test:0.05820, lr:1.00e-02, fs:0.90909 (r=0.926,p=0.893),  time:31.831, tt:1496.057\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.05655, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.870, tt:1529.777\n",
      "Ep:48, loss:0.00009, loss_test:0.05600, lr:1.00e-02, fs:0.90909 (r=0.926,p=0.893),  time:31.883, tt:1562.271\n",
      "Ep:49, loss:0.00009, loss_test:0.05495, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.897, tt:1594.841\n",
      "Ep:50, loss:0.00008, loss_test:0.05421, lr:1.00e-02, fs:0.91892 (r=0.944,p=0.895),  time:31.903, tt:1627.033\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.05373, lr:1.00e-02, fs:0.91892 (r=0.944,p=0.895),  time:31.905, tt:1659.085\n",
      "Ep:52, loss:0.00008, loss_test:0.05262, lr:1.00e-02, fs:0.91892 (r=0.944,p=0.895),  time:31.922, tt:1691.872\n",
      "Ep:53, loss:0.00008, loss_test:0.05203, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:31.912, tt:1723.223\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.05161, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:31.895, tt:1754.251\n",
      "Ep:55, loss:0.00008, loss_test:0.05043, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:31.900, tt:1786.406\n",
      "Ep:56, loss:0.00007, loss_test:0.04996, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:31.884, tt:1817.401\n",
      "Ep:57, loss:0.00007, loss_test:0.04918, lr:1.00e-02, fs:0.91892 (r=0.944,p=0.895),  time:31.911, tt:1850.856\n",
      "Ep:58, loss:0.00007, loss_test:0.04930, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:31.921, tt:1883.331\n",
      "Ep:59, loss:0.00007, loss_test:0.04818, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:31.941, tt:1916.439\n",
      "Ep:60, loss:0.00007, loss_test:0.04769, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:31.950, tt:1948.934\n",
      "Ep:61, loss:0.00007, loss_test:0.04654, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:31.942, tt:1980.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00007, loss_test:0.04612, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:31.949, tt:2012.807\n",
      "Ep:63, loss:0.00006, loss_test:0.04539, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:31.940, tt:2044.149\n",
      "Ep:64, loss:0.00006, loss_test:0.04473, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:31.957, tt:2077.188\n",
      "Ep:65, loss:0.00006, loss_test:0.04474, lr:9.90e-03, fs:0.92727 (r=0.944,p=0.911),  time:31.963, tt:2109.591\n",
      "Ep:66, loss:0.00006, loss_test:0.04349, lr:9.80e-03, fs:0.91743 (r=0.926,p=0.909),  time:31.974, tt:2142.289\n",
      "Ep:67, loss:0.00006, loss_test:0.04369, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:31.973, tt:2174.179\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.04360, lr:9.70e-03, fs:0.91743 (r=0.926,p=0.909),  time:31.972, tt:2206.098\n",
      "Ep:69, loss:0.00006, loss_test:0.04246, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.002, tt:2240.130\n",
      "Ep:70, loss:0.00006, loss_test:0.04323, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.005, tt:2272.385\n",
      "Ep:71, loss:0.00005, loss_test:0.04143, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.013, tt:2304.931\n",
      "Ep:72, loss:0.00005, loss_test:0.04240, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.004, tt:2336.314\n",
      "Ep:73, loss:0.00005, loss_test:0.04039, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.025, tt:2369.873\n",
      "Ep:74, loss:0.00005, loss_test:0.04058, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.038, tt:2402.816\n",
      "Ep:75, loss:0.00005, loss_test:0.03983, lr:9.70e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.029, tt:2434.170\n",
      "Ep:76, loss:0.00005, loss_test:0.03984, lr:9.70e-03, fs:0.90909 (r=0.926,p=0.893),  time:32.044, tt:2467.422\n",
      "Ep:77, loss:0.00005, loss_test:0.03924, lr:9.70e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.035, tt:2498.741\n",
      "Ep:78, loss:0.00005, loss_test:0.03927, lr:9.70e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.027, tt:2530.153\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00005, loss_test:0.03895, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.041, tt:2563.316\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00005, loss_test:0.03860, lr:9.70e-03, fs:0.91743 (r=0.926,p=0.909),  time:32.035, tt:2594.873\n",
      "Ep:81, loss:0.00005, loss_test:0.03790, lr:9.70e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.051, tt:2628.195\n",
      "Ep:82, loss:0.00004, loss_test:0.03719, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.059, tt:2660.921\n",
      "Ep:83, loss:0.00004, loss_test:0.03697, lr:9.70e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.068, tt:2693.705\n",
      "Ep:84, loss:0.00004, loss_test:0.03689, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.069, tt:2725.860\n",
      "Ep:85, loss:0.00004, loss_test:0.03622, lr:9.70e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.075, tt:2758.464\n",
      "Ep:86, loss:0.00004, loss_test:0.03564, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.090, tt:2791.815\n",
      "Ep:87, loss:0.00004, loss_test:0.03515, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.097, tt:2824.516\n",
      "Ep:88, loss:0.00004, loss_test:0.03569, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.093, tt:2856.283\n",
      "Ep:89, loss:0.00004, loss_test:0.03462, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.101, tt:2889.124\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00004, loss_test:0.03492, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.122, tt:2923.059\n",
      "Ep:91, loss:0.00004, loss_test:0.03401, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.126, tt:2955.556\n",
      "Ep:92, loss:0.00004, loss_test:0.03418, lr:9.70e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.137, tt:2988.723\n",
      "Ep:93, loss:0.00004, loss_test:0.03362, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.149, tt:3022.020\n",
      "Ep:94, loss:0.00004, loss_test:0.03319, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.153, tt:3054.508\n",
      "Ep:95, loss:0.00004, loss_test:0.03314, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.201, tt:3091.339\n",
      "Ep:96, loss:0.00003, loss_test:0.03279, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.220, tt:3125.366\n",
      "Ep:97, loss:0.00003, loss_test:0.03274, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.247, tt:3160.216\n",
      "Ep:98, loss:0.00003, loss_test:0.03206, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.263, tt:3194.019\n",
      "Ep:99, loss:0.00003, loss_test:0.03185, lr:9.70e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.283, tt:3228.321\n",
      "Ep:100, loss:0.00003, loss_test:0.03127, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.292, tt:3261.492\n",
      "Ep:101, loss:0.00003, loss_test:0.03126, lr:9.61e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.304, tt:3295.050\n",
      "Ep:102, loss:0.00003, loss_test:0.03084, lr:9.51e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.318, tt:3328.726\n",
      "Ep:103, loss:0.00003, loss_test:0.03100, lr:9.41e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.327, tt:3362.009\n",
      "Ep:104, loss:0.00003, loss_test:0.03028, lr:9.32e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.338, tt:3395.470\n",
      "Ep:105, loss:0.00003, loss_test:0.03030, lr:9.23e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.339, tt:3427.933\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00003, loss_test:0.02993, lr:9.23e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.354, tt:3461.889\n",
      "Ep:107, loss:0.00003, loss_test:0.02973, lr:9.23e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.349, tt:3493.680\n",
      "Ep:108, loss:0.00003, loss_test:0.02982, lr:9.23e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.357, tt:3526.883\n",
      "Ep:109, loss:0.00003, loss_test:0.02918, lr:9.23e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.371, tt:3560.802\n",
      "Ep:110, loss:0.00003, loss_test:0.02974, lr:9.23e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.369, tt:3592.919\n",
      "Ep:111, loss:0.00003, loss_test:0.02896, lr:9.23e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.371, tt:3625.571\n",
      "Ep:112, loss:0.00003, loss_test:0.02912, lr:9.23e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.373, tt:3658.115\n",
      "Ep:113, loss:0.00003, loss_test:0.02863, lr:9.23e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.358, tt:3688.783\n",
      "Ep:114, loss:0.00002, loss_test:0.02850, lr:9.23e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.355, tt:3720.786\n",
      "Ep:115, loss:0.00002, loss_test:0.02792, lr:9.23e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.365, tt:3754.341\n",
      "Ep:116, loss:0.00002, loss_test:0.02877, lr:9.23e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.371, tt:3787.452\n",
      "Ep:117, loss:0.00002, loss_test:0.02787, lr:9.14e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.364, tt:3818.995\n",
      "Ep:118, loss:0.00002, loss_test:0.02745, lr:9.04e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.368, tt:3851.754\n",
      "Ep:119, loss:0.00002, loss_test:0.02708, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.357, tt:3882.841\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00002, loss_test:0.02734, lr:8.95e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.367, tt:3916.407\n",
      "Ep:121, loss:0.00002, loss_test:0.02705, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.360, tt:3947.950\n",
      "Ep:122, loss:0.00002, loss_test:0.02681, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.349, tt:3978.982\n",
      "Ep:123, loss:0.00002, loss_test:0.02663, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.355, tt:4012.048\n",
      "Ep:124, loss:0.00002, loss_test:0.02638, lr:8.95e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.361, tt:4045.064\n",
      "Ep:125, loss:0.00002, loss_test:0.02634, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.356, tt:4076.795\n",
      "Ep:126, loss:0.00002, loss_test:0.02620, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.367, tt:4110.654\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.02603, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.365, tt:4142.720\n",
      "Ep:128, loss:0.00002, loss_test:0.02566, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.363, tt:4174.815\n",
      "Ep:129, loss:0.00002, loss_test:0.02568, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.364, tt:4207.279\n",
      "Ep:130, loss:0.00002, loss_test:0.02571, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.366, tt:4239.967\n",
      "Ep:131, loss:0.00002, loss_test:0.02526, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.382, tt:4274.390\n",
      "Ep:132, loss:0.00002, loss_test:0.02505, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.387, tt:4307.413\n",
      "Ep:133, loss:0.00002, loss_test:0.02517, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.392, tt:4340.532\n",
      "Ep:134, loss:0.00002, loss_test:0.02521, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.395, tt:4373.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00002, loss_test:0.02450, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.413, tt:4408.138\n",
      "Ep:136, loss:0.00002, loss_test:0.02449, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.416, tt:4441.021\n",
      "Ep:137, loss:0.00002, loss_test:0.02442, lr:8.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.414, tt:4473.144\n",
      "Ep:138, loss:0.00002, loss_test:0.02446, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.419, tt:4506.194\n",
      "Ep:139, loss:0.00002, loss_test:0.02405, lr:8.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.430, tt:4540.209\n",
      "Ep:140, loss:0.00002, loss_test:0.02440, lr:8.69e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.433, tt:4573.016\n",
      "Ep:141, loss:0.00002, loss_test:0.02403, lr:8.60e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.446, tt:4607.348\n",
      "Ep:142, loss:0.00002, loss_test:0.02375, lr:8.51e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.450, tt:4640.399\n",
      "Ep:143, loss:0.00002, loss_test:0.02358, lr:8.43e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.463, tt:4674.652\n",
      "Ep:144, loss:0.00002, loss_test:0.02385, lr:8.35e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.459, tt:4706.616\n",
      "Ep:145, loss:0.00001, loss_test:0.02344, lr:8.26e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.463, tt:4739.610\n",
      "Ep:146, loss:0.00001, loss_test:0.02317, lr:8.18e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.464, tt:4772.203\n",
      "Ep:147, loss:0.00001, loss_test:0.02323, lr:8.10e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.468, tt:4805.301\n",
      "Ep:148, loss:0.00001, loss_test:0.02322, lr:8.02e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.467, tt:4837.656\n",
      "Ep:149, loss:0.00001, loss_test:0.02326, lr:7.94e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.474, tt:4871.055\n",
      "Ep:150, loss:0.00001, loss_test:0.02287, lr:7.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.461, tt:4901.601\n",
      "Ep:151, loss:0.00001, loss_test:0.02282, lr:7.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.452, tt:4932.652\n",
      "Ep:152, loss:0.00001, loss_test:0.02254, lr:7.70e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.456, tt:4965.700\n",
      "Ep:153, loss:0.00001, loss_test:0.02253, lr:7.62e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.447, tt:4996.879\n",
      "Ep:154, loss:0.00001, loss_test:0.02257, lr:7.55e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.446, tt:5029.146\n",
      "Ep:155, loss:0.00001, loss_test:0.02278, lr:7.47e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.441, tt:5060.806\n",
      "Ep:156, loss:0.00001, loss_test:0.02261, lr:7.40e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.445, tt:5093.893\n",
      "Ep:157, loss:0.00001, loss_test:0.02232, lr:7.32e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.480, tt:5131.871\n",
      "Ep:158, loss:0.00001, loss_test:0.02205, lr:7.25e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.488, tt:5165.623\n",
      "Ep:159, loss:0.00001, loss_test:0.02219, lr:7.18e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.484, tt:5197.369\n",
      "Ep:160, loss:0.00001, loss_test:0.02197, lr:7.11e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.497, tt:5231.944\n",
      "Ep:161, loss:0.00001, loss_test:0.02186, lr:7.03e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.497, tt:5264.443\n",
      "Ep:162, loss:0.00001, loss_test:0.02150, lr:6.96e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.496, tt:5296.885\n",
      "Ep:163, loss:0.00001, loss_test:0.02155, lr:6.89e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.508, tt:5331.341\n",
      "Ep:164, loss:0.00001, loss_test:0.02168, lr:6.83e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.503, tt:5363.024\n",
      "Ep:165, loss:0.00001, loss_test:0.02149, lr:6.76e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.504, tt:5395.708\n",
      "Ep:166, loss:0.00001, loss_test:0.02122, lr:6.69e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.513, tt:5429.707\n",
      "Ep:167, loss:0.00001, loss_test:0.02158, lr:6.62e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.508, tt:5461.293\n",
      "Ep:168, loss:0.00001, loss_test:0.02133, lr:6.56e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.510, tt:5494.112\n",
      "Ep:169, loss:0.00001, loss_test:0.02109, lr:6.49e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.514, tt:5527.423\n",
      "Ep:170, loss:0.00001, loss_test:0.02114, lr:6.43e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.515, tt:5560.051\n",
      "Ep:171, loss:0.00001, loss_test:0.02108, lr:6.36e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.516, tt:5592.829\n",
      "Ep:172, loss:0.00001, loss_test:0.02086, lr:6.30e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.519, tt:5625.728\n",
      "Ep:173, loss:0.00001, loss_test:0.02083, lr:6.24e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.522, tt:5658.816\n",
      "Ep:174, loss:0.00001, loss_test:0.02098, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.521, tt:5691.248\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00001, loss_test:0.02053, lr:6.17e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.526, tt:5724.575\n",
      "Ep:176, loss:0.00001, loss_test:0.02074, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.523, tt:5756.583\n",
      "Ep:177, loss:0.00001, loss_test:0.02073, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.530, tt:5790.271\n",
      "Ep:178, loss:0.00001, loss_test:0.02069, lr:6.17e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.534, tt:5823.662\n",
      "Ep:179, loss:0.00001, loss_test:0.02057, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.538, tt:5856.776\n",
      "Ep:180, loss:0.00001, loss_test:0.02047, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.540, tt:5889.823\n",
      "Ep:181, loss:0.00001, loss_test:0.02057, lr:6.17e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.551, tt:5924.249\n",
      "Ep:182, loss:0.00001, loss_test:0.02043, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.553, tt:5957.172\n",
      "Ep:183, loss:0.00001, loss_test:0.02041, lr:6.17e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.559, tt:5990.918\n",
      "Ep:184, loss:0.00001, loss_test:0.02039, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.556, tt:6022.845\n",
      "Ep:185, loss:0.00001, loss_test:0.02024, lr:6.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.556, tt:6055.360\n",
      "Ep:186, loss:0.00001, loss_test:0.01988, lr:6.11e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.556, tt:6088.013\n",
      "Ep:187, loss:0.00001, loss_test:0.02023, lr:6.05e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.563, tt:6121.864\n",
      "Ep:188, loss:0.00001, loss_test:0.02035, lr:5.99e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.565, tt:6154.721\n",
      "Ep:189, loss:0.00001, loss_test:0.01998, lr:5.93e-03, fs:0.97196 (r=0.963,p=0.981),  time:32.571, tt:6188.395\n",
      "Ep:190, loss:0.00001, loss_test:0.01966, lr:5.87e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.577, tt:6222.233\n",
      "Ep:191, loss:0.00001, loss_test:0.01985, lr:5.81e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.576, tt:6254.521\n",
      "Ep:192, loss:0.00001, loss_test:0.02011, lr:5.75e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.578, tt:6287.560\n",
      "Ep:193, loss:0.00001, loss_test:0.01976, lr:5.70e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.582, tt:6320.992\n",
      "Ep:194, loss:0.00001, loss_test:0.01956, lr:5.64e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.583, tt:6353.744\n",
      "Ep:195, loss:0.00001, loss_test:0.01968, lr:5.58e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.584, tt:6386.559\n",
      "Ep:196, loss:0.00001, loss_test:0.01953, lr:5.53e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.584, tt:6419.065\n",
      "Ep:197, loss:0.00001, loss_test:0.01951, lr:5.47e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.582, tt:6451.200\n",
      "Ep:198, loss:0.00001, loss_test:0.01931, lr:5.42e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.580, tt:6483.355\n",
      "Ep:199, loss:0.00001, loss_test:0.01945, lr:5.36e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.581, tt:6516.279\n",
      "Ep:200, loss:0.00001, loss_test:0.01951, lr:5.31e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.584, tt:6549.298\n",
      "Ep:201, loss:0.00001, loss_test:0.01904, lr:5.26e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.584, tt:6581.962\n",
      "Ep:202, loss:0.00001, loss_test:0.01921, lr:5.20e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.586, tt:6614.884\n",
      "Ep:203, loss:0.00001, loss_test:0.01929, lr:5.15e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.588, tt:6647.959\n",
      "Ep:204, loss:0.00001, loss_test:0.01909, lr:5.10e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.592, tt:6681.379\n",
      "Ep:205, loss:0.00001, loss_test:0.01906, lr:5.05e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.563, tt:6707.882\n",
      "Ep:206, loss:0.00001, loss_test:0.01882, lr:5.00e-03, fs:0.98113 (r=0.963,p=1.000),  time:32.459, tt:6718.950\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13994, lr:1.00e-02, fs:0.67081 (r=1.000,p=0.505),  time:34.720, tt:34.720\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13778, lr:1.00e-02, fs:0.67949 (r=0.981,p=0.520),  time:34.618, tt:69.236\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13404, lr:1.00e-02, fs:0.68421 (r=0.963,p=0.531),  time:35.250, tt:105.750\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12990, lr:1.00e-02, fs:0.67550 (r=0.944,p=0.526),  time:35.203, tt:140.812\n",
      "Ep:4, loss:0.00026, loss_test:0.12740, lr:1.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:35.355, tt:176.775\n",
      "Ep:5, loss:0.00025, loss_test:0.12351, lr:1.00e-02, fs:0.67606 (r=0.889,p=0.545),  time:35.547, tt:213.282\n",
      "Ep:6, loss:0.00024, loss_test:0.11928, lr:1.00e-02, fs:0.69065 (r=0.889,p=0.565),  time:35.626, tt:249.384\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11538, lr:1.00e-02, fs:0.70073 (r=0.889,p=0.578),  time:35.831, tt:286.644\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11197, lr:1.00e-02, fs:0.70588 (r=0.889,p=0.585),  time:35.648, tt:320.831\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10776, lr:1.00e-02, fs:0.72180 (r=0.889,p=0.608),  time:35.694, tt:356.935\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10462, lr:1.00e-02, fs:0.75591 (r=0.889,p=0.658),  time:35.624, tt:391.868\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10176, lr:1.00e-02, fs:0.79687 (r=0.944,p=0.689),  time:35.607, tt:427.280\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09925, lr:1.00e-02, fs:0.80315 (r=0.944,p=0.699),  time:35.573, tt:462.448\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09710, lr:1.00e-02, fs:0.80952 (r=0.944,p=0.708),  time:35.767, tt:500.733\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09430, lr:1.00e-02, fs:0.80328 (r=0.907,p=0.721),  time:35.884, tt:538.257\n",
      "Ep:15, loss:0.00018, loss_test:0.09192, lr:1.00e-02, fs:0.80992 (r=0.907,p=0.731),  time:36.009, tt:576.140\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09014, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.146, tt:614.485\n",
      "Ep:17, loss:0.00017, loss_test:0.08849, lr:1.00e-02, fs:0.81667 (r=0.907,p=0.742),  time:36.182, tt:651.272\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08735, lr:1.00e-02, fs:0.80672 (r=0.889,p=0.738),  time:36.169, tt:687.212\n",
      "Ep:19, loss:0.00016, loss_test:0.08662, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.275, tt:725.491\n",
      "Ep:20, loss:0.00016, loss_test:0.08528, lr:1.00e-02, fs:0.80992 (r=0.907,p=0.731),  time:36.312, tt:762.547\n",
      "Ep:21, loss:0.00015, loss_test:0.08415, lr:1.00e-02, fs:0.80992 (r=0.907,p=0.731),  time:36.384, tt:800.450\n",
      "Ep:22, loss:0.00015, loss_test:0.08242, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.437, tt:838.049\n",
      "Ep:23, loss:0.00014, loss_test:0.08118, lr:1.00e-02, fs:0.81667 (r=0.907,p=0.742),  time:36.439, tt:874.536\n",
      "Ep:24, loss:0.00014, loss_test:0.07877, lr:1.00e-02, fs:0.81356 (r=0.889,p=0.750),  time:36.468, tt:911.707\n",
      "Ep:25, loss:0.00013, loss_test:0.07754, lr:1.00e-02, fs:0.82759 (r=0.889,p=0.774),  time:36.454, tt:947.814\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07614, lr:1.00e-02, fs:0.83478 (r=0.889,p=0.787),  time:36.435, tt:983.754\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07415, lr:1.00e-02, fs:0.84483 (r=0.907,p=0.790),  time:36.504, tt:1022.099\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07248, lr:1.00e-02, fs:0.83478 (r=0.889,p=0.787),  time:36.548, tt:1059.889\n",
      "Ep:29, loss:0.00012, loss_test:0.07040, lr:1.00e-02, fs:0.84034 (r=0.926,p=0.769),  time:36.542, tt:1096.256\n",
      "Ep:30, loss:0.00011, loss_test:0.06847, lr:1.00e-02, fs:0.86441 (r=0.944,p=0.797),  time:36.591, tt:1134.335\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.06674, lr:1.00e-02, fs:0.84746 (r=0.926,p=0.781),  time:36.563, tt:1170.003\n",
      "Ep:32, loss:0.00011, loss_test:0.06570, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:36.568, tt:1206.743\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.06407, lr:1.00e-02, fs:0.85470 (r=0.926,p=0.794),  time:36.566, tt:1243.244\n",
      "Ep:34, loss:0.00010, loss_test:0.06324, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:36.558, tt:1279.539\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.06116, lr:1.00e-02, fs:0.88496 (r=0.926,p=0.847),  time:36.569, tt:1316.476\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.06246, lr:1.00e-02, fs:0.87395 (r=0.963,p=0.800),  time:36.557, tt:1352.596\n",
      "Ep:37, loss:0.00010, loss_test:0.05950, lr:1.00e-02, fs:0.89286 (r=0.926,p=0.862),  time:36.557, tt:1389.176\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.05993, lr:1.00e-02, fs:0.87179 (r=0.944,p=0.810),  time:36.554, tt:1425.620\n",
      "Ep:39, loss:0.00009, loss_test:0.05607, lr:1.00e-02, fs:0.91743 (r=0.926,p=0.909),  time:36.608, tt:1464.339\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.05445, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:36.612, tt:1501.095\n",
      "Ep:41, loss:0.00008, loss_test:0.05135, lr:1.00e-02, fs:0.92593 (r=0.926,p=0.926),  time:36.615, tt:1537.837\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.04996, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:36.631, tt:1575.153\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.04779, lr:1.00e-02, fs:0.92593 (r=0.926,p=0.926),  time:36.620, tt:1611.262\n",
      "Ep:44, loss:0.00007, loss_test:0.04631, lr:1.00e-02, fs:0.92593 (r=0.926,p=0.926),  time:36.641, tt:1648.846\n",
      "Ep:45, loss:0.00007, loss_test:0.04546, lr:1.00e-02, fs:0.93578 (r=0.944,p=0.927),  time:36.676, tt:1687.112\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.04502, lr:1.00e-02, fs:0.92593 (r=0.926,p=0.926),  time:36.689, tt:1724.404\n",
      "Ep:47, loss:0.00007, loss_test:0.04442, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:36.700, tt:1761.612\n",
      "Ep:48, loss:0.00006, loss_test:0.04328, lr:1.00e-02, fs:0.93458 (r=0.926,p=0.943),  time:36.707, tt:1798.648\n",
      "Ep:49, loss:0.00006, loss_test:0.04175, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:36.703, tt:1835.147\n",
      "Ep:50, loss:0.00006, loss_test:0.04099, lr:1.00e-02, fs:0.93458 (r=0.926,p=0.943),  time:36.690, tt:1871.202\n",
      "Ep:51, loss:0.00006, loss_test:0.04081, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:36.698, tt:1908.287\n",
      "Ep:52, loss:0.00006, loss_test:0.03842, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.678, tt:1943.914\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.03769, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:36.656, tt:1979.410\n",
      "Ep:54, loss:0.00005, loss_test:0.03706, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.645, tt:2015.453\n",
      "Ep:55, loss:0.00005, loss_test:0.03666, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:36.660, tt:2052.985\n",
      "Ep:56, loss:0.00005, loss_test:0.03564, lr:1.00e-02, fs:0.95327 (r=0.944,p=0.962),  time:36.645, tt:2088.744\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00005, loss_test:0.03402, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.652, tt:2199.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.03369, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.637, tt:2234.883\n",
      "Ep:61, loss:0.00004, loss_test:0.03229, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.635, tt:2271.358\n",
      "Ep:62, loss:0.00004, loss_test:0.03547, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.646, tt:2308.679\n",
      "Ep:63, loss:0.00004, loss_test:0.03152, lr:1.00e-02, fs:0.92727 (r=0.944,p=0.911),  time:36.661, tt:2346.282\n",
      "Ep:64, loss:0.00004, loss_test:0.03259, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.678, tt:2384.069\n",
      "Ep:65, loss:0.00004, loss_test:0.03084, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.703, tt:2422.408\n",
      "Ep:66, loss:0.00004, loss_test:0.03076, lr:1.00e-02, fs:0.94444 (r=0.944,p=0.944),  time:36.709, tt:2459.523\n",
      "Ep:67, loss:0.00004, loss_test:0.02964, lr:1.00e-02, fs:0.93578 (r=0.944,p=0.927),  time:36.690, tt:2494.934\n",
      "Ep:68, loss:0.00004, loss_test:0.02987, lr:9.90e-03, fs:0.94444 (r=0.944,p=0.944),  time:36.703, tt:2532.496\n",
      "Ep:69, loss:0.00003, loss_test:0.02884, lr:9.80e-03, fs:0.94444 (r=0.944,p=0.944),  time:36.690, tt:2568.288\n",
      "Ep:70, loss:0.00003, loss_test:0.02854, lr:9.70e-03, fs:0.94444 (r=0.944,p=0.944),  time:36.715, tt:2606.731\n",
      "Ep:71, loss:0.00003, loss_test:0.02973, lr:9.61e-03, fs:0.94444 (r=0.944,p=0.944),  time:36.743, tt:2645.483\n",
      "Ep:72, loss:0.00003, loss_test:0.02717, lr:9.51e-03, fs:0.95327 (r=0.944,p=0.962),  time:36.736, tt:2681.743\n",
      "Ep:73, loss:0.00003, loss_test:0.02769, lr:9.41e-03, fs:0.95327 (r=0.944,p=0.962),  time:36.743, tt:2718.998\n",
      "Ep:74, loss:0.00003, loss_test:0.02848, lr:9.32e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.741, tt:2755.594\n",
      "Ep:75, loss:0.00003, loss_test:0.02901, lr:9.23e-03, fs:0.95327 (r=0.944,p=0.962),  time:36.735, tt:2791.889\n",
      "Ep:76, loss:0.00003, loss_test:0.02591, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.747, tt:2829.487\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00003, loss_test:0.02793, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.739, tt:2865.638\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.02585, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.726, tt:2901.376\n",
      "Ep:79, loss:0.00003, loss_test:0.02665, lr:9.14e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.728, tt:2938.264\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00003, loss_test:0.02498, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.725, tt:2974.738\n",
      "Ep:81, loss:0.00003, loss_test:0.02725, lr:9.14e-03, fs:0.96226 (r=0.944,p=0.981),  time:36.726, tt:3011.498\n",
      "Ep:82, loss:0.00003, loss_test:0.02524, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.734, tt:3048.901\n",
      "Ep:83, loss:0.00003, loss_test:0.02545, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.714, tt:3084.007\n",
      "Ep:84, loss:0.00003, loss_test:0.02504, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.727, tt:3121.809\n",
      "Ep:85, loss:0.00002, loss_test:0.02471, lr:9.14e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.739, tt:3159.553\n",
      "Ep:86, loss:0.00002, loss_test:0.02478, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.737, tt:3196.092\n",
      "Ep:87, loss:0.00002, loss_test:0.02616, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.749, tt:3233.884\n",
      "Ep:88, loss:0.00002, loss_test:0.02375, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.747, tt:3270.499\n",
      "Ep:89, loss:0.00002, loss_test:0.02382, lr:9.14e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.749, tt:3307.403\n",
      "Ep:90, loss:0.00002, loss_test:0.02485, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.751, tt:3344.311\n",
      "Ep:91, loss:0.00002, loss_test:0.02385, lr:9.04e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.757, tt:3381.623\n",
      "Ep:92, loss:0.00002, loss_test:0.02276, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.758, tt:3418.514\n",
      "Ep:93, loss:0.00002, loss_test:0.02464, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.752, tt:3454.684\n",
      "Ep:94, loss:0.00002, loss_test:0.02241, lr:8.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.738, tt:3490.081\n",
      "Ep:95, loss:0.00002, loss_test:0.02295, lr:8.69e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.747, tt:3527.714\n",
      "Ep:96, loss:0.00002, loss_test:0.02242, lr:8.60e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.764, tt:3566.121\n",
      "Ep:97, loss:0.00002, loss_test:0.02287, lr:8.51e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.781, tt:3604.586\n",
      "Ep:98, loss:0.00002, loss_test:0.02234, lr:8.43e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.786, tt:3641.830\n",
      "Ep:99, loss:0.00002, loss_test:0.02188, lr:8.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.785, tt:3678.518\n",
      "Ep:100, loss:0.00002, loss_test:0.02185, lr:8.26e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.796, tt:3716.352\n",
      "Ep:101, loss:0.00002, loss_test:0.02197, lr:8.18e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.804, tt:3754.028\n",
      "Ep:102, loss:0.00002, loss_test:0.02104, lr:8.10e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.814, tt:3791.808\n",
      "Ep:103, loss:0.00002, loss_test:0.02231, lr:8.02e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.812, tt:3828.452\n",
      "Ep:104, loss:0.00002, loss_test:0.02068, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.800, tt:3864.023\n",
      "Ep:105, loss:0.00002, loss_test:0.02215, lr:7.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.783, tt:3899.050\n",
      "Ep:106, loss:0.00002, loss_test:0.02219, lr:7.78e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.785, tt:3936.001\n",
      "Ep:107, loss:0.00002, loss_test:0.02110, lr:7.70e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.769, tt:3971.000\n",
      "Ep:108, loss:0.00002, loss_test:0.02134, lr:7.62e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.738, tt:4004.473\n",
      "Ep:109, loss:0.00002, loss_test:0.02062, lr:7.55e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.697, tt:4036.624\n",
      "Ep:110, loss:0.00002, loss_test:0.02139, lr:7.47e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.685, tt:4072.008\n",
      "Ep:111, loss:0.00002, loss_test:0.02020, lr:7.40e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.666, tt:4106.627\n",
      "Ep:112, loss:0.00002, loss_test:0.02100, lr:7.32e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.649, tt:4141.313\n",
      "Ep:113, loss:0.00001, loss_test:0.01988, lr:7.25e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.641, tt:4177.091\n",
      "Ep:114, loss:0.00001, loss_test:0.02027, lr:7.18e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.640, tt:4213.634\n",
      "Ep:115, loss:0.00001, loss_test:0.01991, lr:7.11e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.633, tt:4249.485\n",
      "Ep:116, loss:0.00001, loss_test:0.02012, lr:7.03e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.630, tt:4285.704\n",
      "Ep:117, loss:0.00001, loss_test:0.01945, lr:6.96e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.608, tt:4319.773\n",
      "Ep:118, loss:0.00001, loss_test:0.02025, lr:6.89e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.633, tt:4359.385\n",
      "Ep:119, loss:0.00001, loss_test:0.01912, lr:6.83e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.627, tt:4395.245\n",
      "Ep:120, loss:0.00001, loss_test:0.02002, lr:6.76e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.624, tt:4431.452\n",
      "Ep:121, loss:0.00001, loss_test:0.01898, lr:6.69e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.614, tt:4466.892\n",
      "Ep:122, loss:0.00001, loss_test:0.01902, lr:6.62e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.601, tt:4501.878\n",
      "Ep:123, loss:0.00001, loss_test:0.01972, lr:6.56e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.596, tt:4537.965\n",
      "Ep:124, loss:0.00001, loss_test:0.01880, lr:6.49e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.580, tt:4572.465\n",
      "Ep:125, loss:0.00001, loss_test:0.01938, lr:6.43e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.574, tt:4608.265\n",
      "Ep:126, loss:0.00001, loss_test:0.01825, lr:6.36e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.566, tt:4643.833\n",
      "Ep:127, loss:0.00001, loss_test:0.01928, lr:6.30e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.556, tt:4679.173\n",
      "Ep:128, loss:0.00001, loss_test:0.01811, lr:6.24e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.560, tt:4716.208\n",
      "Ep:129, loss:0.00001, loss_test:0.01863, lr:6.17e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.563, tt:4753.201\n",
      "Ep:130, loss:0.00001, loss_test:0.01817, lr:6.11e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.561, tt:4789.492\n",
      "Ep:131, loss:0.00001, loss_test:0.01788, lr:6.05e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.553, tt:4824.955\n",
      "Ep:132, loss:0.00001, loss_test:0.01896, lr:5.99e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.545, tt:4860.422\n",
      "Ep:133, loss:0.00001, loss_test:0.01769, lr:5.93e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.535, tt:4895.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.01942, lr:5.87e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.537, tt:4932.482\n",
      "Ep:135, loss:0.00001, loss_test:0.01741, lr:5.81e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.544, tt:4969.922\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.01926, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.578, tt:5011.227\n",
      "Ep:137, loss:0.00001, loss_test:0.01727, lr:5.81e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.581, tt:5048.220\n",
      "Ep:138, loss:0.00001, loss_test:0.01798, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.582, tt:5084.953\n",
      "Ep:139, loss:0.00001, loss_test:0.01792, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.589, tt:5122.525\n",
      "Ep:140, loss:0.00001, loss_test:0.01828, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.587, tt:5158.825\n",
      "Ep:141, loss:0.00001, loss_test:0.01813, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.582, tt:5194.609\n",
      "Ep:142, loss:0.00001, loss_test:0.01731, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.580, tt:5231.008\n",
      "Ep:143, loss:0.00001, loss_test:0.01823, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.588, tt:5268.627\n",
      "Ep:144, loss:0.00001, loss_test:0.01751, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.570, tt:5302.686\n",
      "Ep:145, loss:0.00001, loss_test:0.01766, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.566, tt:5338.589\n",
      "Ep:146, loss:0.00001, loss_test:0.01788, lr:5.81e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.543, tt:5371.880\n",
      "Ep:147, loss:0.00001, loss_test:0.01766, lr:5.75e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.516, tt:5404.431\n",
      "Ep:148, loss:0.00001, loss_test:0.01795, lr:5.70e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.520, tt:5441.405\n",
      "Ep:149, loss:0.00001, loss_test:0.01736, lr:5.64e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.519, tt:5477.857\n",
      "Ep:150, loss:0.00001, loss_test:0.01748, lr:5.58e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.523, tt:5514.948\n",
      "Ep:151, loss:0.00001, loss_test:0.01780, lr:5.53e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.521, tt:5551.239\n",
      "Ep:152, loss:0.00001, loss_test:0.01708, lr:5.47e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.521, tt:5587.692\n",
      "Ep:153, loss:0.00001, loss_test:0.01820, lr:5.42e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.518, tt:5623.712\n",
      "Ep:154, loss:0.00001, loss_test:0.01660, lr:5.36e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.525, tt:5661.424\n",
      "Ep:155, loss:0.00001, loss_test:0.01815, lr:5.31e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.529, tt:5698.546\n",
      "Ep:156, loss:0.00001, loss_test:0.01715, lr:5.26e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.532, tt:5735.549\n",
      "Ep:157, loss:0.00001, loss_test:0.01664, lr:5.20e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.527, tt:5771.323\n",
      "Ep:158, loss:0.00001, loss_test:0.01790, lr:5.15e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.527, tt:5807.790\n",
      "Ep:159, loss:0.00001, loss_test:0.01658, lr:5.10e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.528, tt:5844.541\n",
      "Ep:160, loss:0.00001, loss_test:0.01761, lr:5.05e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.530, tt:5881.280\n",
      "Ep:161, loss:0.00001, loss_test:0.01703, lr:5.00e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.526, tt:5917.204\n",
      "Ep:162, loss:0.00001, loss_test:0.01682, lr:4.95e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.525, tt:5953.503\n",
      "Ep:163, loss:0.00001, loss_test:0.01691, lr:4.90e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.517, tt:5988.796\n",
      "Ep:164, loss:0.00001, loss_test:0.01708, lr:4.85e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.508, tt:6023.823\n",
      "Ep:165, loss:0.00001, loss_test:0.01700, lr:4.80e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.504, tt:6059.727\n",
      "Ep:166, loss:0.00001, loss_test:0.01678, lr:4.75e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.485, tt:6092.954\n",
      "Ep:167, loss:0.00001, loss_test:0.01701, lr:4.71e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.491, tt:6130.508\n",
      "Ep:168, loss:0.00001, loss_test:0.01663, lr:4.66e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.485, tt:6166.012\n",
      "Ep:169, loss:0.00001, loss_test:0.01693, lr:4.61e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.493, tt:6203.752\n",
      "Ep:170, loss:0.00001, loss_test:0.01642, lr:4.57e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.495, tt:6240.725\n",
      "Ep:171, loss:0.00001, loss_test:0.01689, lr:4.52e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.491, tt:6276.485\n",
      "Ep:172, loss:0.00001, loss_test:0.01686, lr:4.48e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.494, tt:6313.405\n",
      "Ep:173, loss:0.00001, loss_test:0.01651, lr:4.43e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.493, tt:6349.702\n",
      "Ep:174, loss:0.00001, loss_test:0.01668, lr:4.39e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.492, tt:6386.150\n",
      "Ep:175, loss:0.00001, loss_test:0.01655, lr:4.34e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.492, tt:6422.533\n",
      "Ep:176, loss:0.00001, loss_test:0.01656, lr:4.30e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.492, tt:6458.996\n",
      "Ep:177, loss:0.00001, loss_test:0.01663, lr:4.26e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.495, tt:6496.128\n",
      "Ep:178, loss:0.00001, loss_test:0.01647, lr:4.21e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.496, tt:6532.820\n",
      "Ep:179, loss:0.00001, loss_test:0.01638, lr:4.17e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.505, tt:6570.904\n",
      "Ep:180, loss:0.00001, loss_test:0.01669, lr:4.13e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.507, tt:6607.773\n",
      "Ep:181, loss:0.00001, loss_test:0.01616, lr:4.09e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.510, tt:6644.883\n",
      "Ep:182, loss:0.00001, loss_test:0.01684, lr:4.05e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.515, tt:6682.236\n",
      "Ep:183, loss:0.00001, loss_test:0.01628, lr:4.01e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.515, tt:6718.747\n",
      "Ep:184, loss:0.00001, loss_test:0.01634, lr:3.97e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.518, tt:6755.848\n",
      "Ep:185, loss:0.00001, loss_test:0.01631, lr:3.93e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.527, tt:6794.035\n",
      "Ep:186, loss:0.00001, loss_test:0.01636, lr:3.89e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.523, tt:6829.769\n",
      "Ep:187, loss:0.00001, loss_test:0.01643, lr:3.85e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.530, tt:6867.616\n",
      "Ep:188, loss:0.00001, loss_test:0.01592, lr:3.81e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.526, tt:6903.395\n",
      "Ep:189, loss:0.00001, loss_test:0.01655, lr:3.77e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.533, tt:6941.338\n",
      "Ep:190, loss:0.00001, loss_test:0.01619, lr:3.73e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.532, tt:6977.637\n",
      "Ep:191, loss:0.00001, loss_test:0.01619, lr:3.70e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.538, tt:7015.237\n",
      "Ep:192, loss:0.00001, loss_test:0.01618, lr:3.66e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.544, tt:7052.977\n",
      "Ep:193, loss:0.00001, loss_test:0.01598, lr:3.62e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.542, tt:7089.212\n",
      "Ep:194, loss:0.00001, loss_test:0.01654, lr:3.59e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.539, tt:7125.149\n",
      "Ep:195, loss:0.00001, loss_test:0.01593, lr:3.55e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.547, tt:7163.272\n",
      "Ep:196, loss:0.00001, loss_test:0.01619, lr:3.52e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.545, tt:7199.447\n",
      "Ep:197, loss:0.00001, loss_test:0.01611, lr:3.48e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.542, tt:7235.242\n",
      "Ep:198, loss:0.00001, loss_test:0.01614, lr:3.45e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.540, tt:7271.501\n",
      "Ep:199, loss:0.00001, loss_test:0.01583, lr:3.41e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.540, tt:7308.017\n",
      "Ep:200, loss:0.00001, loss_test:0.01596, lr:3.38e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.544, tt:7345.324\n",
      "Ep:201, loss:0.00001, loss_test:0.01606, lr:3.34e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.548, tt:7382.717\n",
      "Ep:202, loss:0.00001, loss_test:0.01591, lr:3.31e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.546, tt:7418.744\n",
      "Ep:203, loss:0.00001, loss_test:0.01600, lr:3.28e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.541, tt:7454.403\n",
      "Ep:204, loss:0.00001, loss_test:0.01598, lr:3.24e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.467, tt:7475.819\n",
      "Ep:205, loss:0.00001, loss_test:0.01600, lr:3.21e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.365, tt:7491.204\n",
      "Ep:206, loss:0.00001, loss_test:0.01582, lr:3.18e-03, fs:0.98113 (r=0.963,p=1.000),  time:36.258, tt:7505.397\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02509, lr:6.00e-02, fs:0.67647 (r=0.852,p=0.561),  time:31.665, tt:31.665\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02680, lr:6.00e-02, fs:0.67089 (r=0.981,p=0.510),  time:32.055, tt:64.110\n",
      "Ep:2, loss:0.00005, loss_test:0.02949, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.733, tt:98.199\n",
      "Ep:3, loss:0.00006, loss_test:0.03009, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.302, tt:137.208\n",
      "Ep:4, loss:0.00006, loss_test:0.02996, lr:6.00e-02, fs:0.67089 (r=0.981,p=0.510),  time:34.441, tt:172.205\n",
      "Ep:5, loss:0.00005, loss_test:0.02949, lr:6.00e-02, fs:0.67089 (r=0.981,p=0.510),  time:33.922, tt:203.531\n",
      "Ep:6, loss:0.00005, loss_test:0.02871, lr:6.00e-02, fs:0.67949 (r=0.981,p=0.520),  time:33.613, tt:235.292\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02795, lr:6.00e-02, fs:0.67105 (r=0.944,p=0.520),  time:33.420, tt:267.360\n",
      "Ep:8, loss:0.00005, loss_test:0.02739, lr:6.00e-02, fs:0.66225 (r=0.926,p=0.515),  time:33.333, tt:299.994\n",
      "Ep:9, loss:0.00005, loss_test:0.02695, lr:6.00e-02, fs:0.66667 (r=0.926,p=0.521),  time:33.439, tt:334.390\n",
      "Ep:10, loss:0.00005, loss_test:0.02660, lr:6.00e-02, fs:0.67105 (r=0.944,p=0.520),  time:33.837, tt:372.202\n",
      "Ep:11, loss:0.00005, loss_test:0.02626, lr:6.00e-02, fs:0.66667 (r=0.944,p=0.515),  time:33.949, tt:407.383\n",
      "Ep:12, loss:0.00005, loss_test:0.02576, lr:6.00e-02, fs:0.67532 (r=0.963,p=0.520),  time:34.068, tt:442.890\n",
      "Ep:13, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.67105 (r=0.944,p=0.520),  time:33.992, tt:475.888\n",
      "Ep:14, loss:0.00005, loss_test:0.02398, lr:6.00e-02, fs:0.67550 (r=0.944,p=0.526),  time:34.017, tt:510.262\n",
      "Ep:15, loss:0.00005, loss_test:0.02294, lr:6.00e-02, fs:0.68000 (r=0.944,p=0.531),  time:34.030, tt:544.478\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.67550 (r=0.944,p=0.526),  time:34.135, tt:580.298\n",
      "Ep:17, loss:0.00004, loss_test:0.02191, lr:6.00e-02, fs:0.67550 (r=0.944,p=0.526),  time:34.157, tt:614.818\n",
      "Ep:18, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66667 (r=0.926,p=0.521),  time:34.194, tt:649.695\n",
      "Ep:19, loss:0.00004, loss_test:0.02044, lr:6.00e-02, fs:0.67114 (r=0.926,p=0.526),  time:34.222, tt:684.447\n",
      "Ep:20, loss:0.00004, loss_test:0.01976, lr:6.00e-02, fs:0.67568 (r=0.926,p=0.532),  time:34.303, tt:720.357\n",
      "Ep:21, loss:0.00004, loss_test:0.01933, lr:6.00e-02, fs:0.67114 (r=0.926,p=0.526),  time:34.391, tt:756.593\n",
      "Ep:22, loss:0.00004, loss_test:0.01884, lr:6.00e-02, fs:0.69863 (r=0.944,p=0.554),  time:34.435, tt:791.997\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01814, lr:6.00e-02, fs:0.70345 (r=0.944,p=0.560),  time:34.460, tt:827.046\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01784, lr:6.00e-02, fs:0.71831 (r=0.944,p=0.580),  time:34.497, tt:862.422\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01774, lr:6.00e-02, fs:0.72340 (r=0.944,p=0.586),  time:34.530, tt:897.773\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.72340 (r=0.944,p=0.586),  time:34.544, tt:932.690\n",
      "Ep:27, loss:0.00003, loss_test:0.01718, lr:6.00e-02, fs:0.72340 (r=0.944,p=0.586),  time:34.538, tt:967.068\n",
      "Ep:28, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.73381 (r=0.944,p=0.600),  time:34.594, tt:1003.235\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.73759 (r=0.963,p=0.598),  time:34.636, tt:1039.073\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.74820 (r=0.963,p=0.612),  time:34.656, tt:1074.328\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.75912 (r=0.963,p=0.627),  time:34.639, tt:1108.456\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01616, lr:6.00e-02, fs:0.75000 (r=0.944,p=0.622),  time:34.670, tt:1144.096\n",
      "Ep:33, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.75556 (r=0.944,p=0.630),  time:34.700, tt:1179.785\n",
      "Ep:34, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.76119 (r=0.944,p=0.637),  time:34.732, tt:1215.631\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.76119 (r=0.944,p=0.637),  time:34.750, tt:1251.012\n",
      "Ep:36, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.76692 (r=0.944,p=0.646),  time:34.725, tt:1284.832\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.76923 (r=0.926,p=0.658),  time:34.771, tt:1321.302\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.75758 (r=0.926,p=0.641),  time:34.792, tt:1356.888\n",
      "Ep:39, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.76923 (r=0.926,p=0.658),  time:34.771, tt:1390.835\n",
      "Ep:40, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.77519 (r=0.926,p=0.667),  time:34.751, tt:1424.796\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01455, lr:6.00e-02, fs:0.76562 (r=0.907,p=0.662),  time:34.746, tt:1459.338\n",
      "Ep:42, loss:0.00002, loss_test:0.01409, lr:6.00e-02, fs:0.78740 (r=0.926,p=0.685),  time:34.749, tt:1494.222\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.79032 (r=0.907,p=0.700),  time:34.758, tt:1529.363\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.80000 (r=0.926,p=0.704),  time:34.767, tt:1564.522\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.82258 (r=0.944,p=0.729),  time:34.760, tt:1598.964\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.80645 (r=0.926,p=0.714),  time:34.764, tt:1633.911\n",
      "Ep:47, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.83871 (r=0.963,p=0.743),  time:34.805, tt:1670.620\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01241, lr:6.00e-02, fs:0.83871 (r=0.963,p=0.743),  time:34.795, tt:1704.955\n",
      "Ep:49, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.82645 (r=0.926,p=0.746),  time:34.796, tt:1739.804\n",
      "Ep:50, loss:0.00002, loss_test:0.01181, lr:6.00e-02, fs:0.83871 (r=0.963,p=0.743),  time:34.799, tt:1774.729\n",
      "Ep:51, loss:0.00002, loss_test:0.01192, lr:6.00e-02, fs:0.83200 (r=0.963,p=0.732),  time:34.761, tt:1807.565\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02973, lr:6.00e-02, fs:0.64135 (r=0.768,p=0.551),  time:29.346, tt:29.346\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02654, lr:6.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:30.668, tt:61.335\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02832, lr:6.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:30.102, tt:90.307\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02924, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:29.620, tt:118.481\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02934, lr:6.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:30.058, tt:150.292\n",
      "Ep:5, loss:0.00005, loss_test:0.02936, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:30.249, tt:181.495\n",
      "Ep:6, loss:0.00005, loss_test:0.03013, lr:6.00e-02, fs:0.63636 (r=0.848,p=0.509),  time:30.265, tt:211.858\n",
      "Ep:7, loss:0.00005, loss_test:0.03095, lr:6.00e-02, fs:0.62308 (r=0.818,p=0.503),  time:30.261, tt:242.092\n",
      "Ep:8, loss:0.00005, loss_test:0.03176, lr:6.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:30.369, tt:273.318\n",
      "Ep:9, loss:0.00005, loss_test:0.03216, lr:6.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:30.519, tt:305.186\n",
      "Ep:10, loss:0.00005, loss_test:0.03167, lr:6.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:30.502, tt:335.522\n",
      "Ep:11, loss:0.00005, loss_test:0.03055, lr:6.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:30.624, tt:367.486\n",
      "Ep:12, loss:0.00005, loss_test:0.02953, lr:6.00e-02, fs:0.62791 (r=0.818,p=0.509),  time:30.642, tt:398.346\n",
      "Ep:13, loss:0.00005, loss_test:0.02883, lr:6.00e-02, fs:0.63878 (r=0.848,p=0.512),  time:30.753, tt:430.549\n",
      "Ep:14, loss:0.00005, loss_test:0.02830, lr:6.00e-02, fs:0.63878 (r=0.848,p=0.512),  time:30.939, tt:464.089\n",
      "Ep:15, loss:0.00005, loss_test:0.02795, lr:5.94e-02, fs:0.64341 (r=0.838,p=0.522),  time:30.945, tt:495.112\n",
      "Ep:16, loss:0.00005, loss_test:0.02773, lr:5.88e-02, fs:0.64286 (r=0.818,p=0.529),  time:30.968, tt:526.448\n",
      "Ep:17, loss:0.00005, loss_test:0.02740, lr:5.82e-02, fs:0.64800 (r=0.818,p=0.536),  time:30.963, tt:557.326\n",
      "Ep:18, loss:0.00004, loss_test:0.02684, lr:5.76e-02, fs:0.63934 (r=0.788,p=0.538),  time:30.865, tt:586.432\n",
      "Ep:19, loss:0.00004, loss_test:0.02601, lr:5.71e-02, fs:0.63333 (r=0.768,p=0.539),  time:30.840, tt:616.792\n",
      "Ep:20, loss:0.00004, loss_test:0.02525, lr:5.65e-02, fs:0.62447 (r=0.747,p=0.536),  time:30.852, tt:647.887\n",
      "Ep:21, loss:0.00004, loss_test:0.02489, lr:5.59e-02, fs:0.60684 (r=0.717,p=0.526),  time:30.870, tt:679.133\n",
      "Ep:22, loss:0.00004, loss_test:0.02490, lr:5.54e-02, fs:0.60262 (r=0.697,p=0.531),  time:30.896, tt:710.619\n",
      "Ep:23, loss:0.00004, loss_test:0.02501, lr:5.48e-02, fs:0.60714 (r=0.687,p=0.544),  time:30.908, tt:741.789\n",
      "Ep:24, loss:0.00004, loss_test:0.02480, lr:5.43e-02, fs:0.61333 (r=0.697,p=0.548),  time:30.934, tt:773.346\n",
      "Ep:25, loss:0.00004, loss_test:0.02466, lr:5.37e-02, fs:0.61333 (r=0.697,p=0.548),  time:30.955, tt:804.840\n",
      "Ep:26, loss:0.00004, loss_test:0.02436, lr:5.32e-02, fs:0.61947 (r=0.707,p=0.551),  time:30.951, tt:835.672\n",
      "Ep:27, loss:0.00004, loss_test:0.02424, lr:5.27e-02, fs:0.61947 (r=0.707,p=0.551),  time:30.889, tt:864.891\n",
      "Ep:28, loss:0.00004, loss_test:0.02402, lr:5.21e-02, fs:0.62832 (r=0.717,p=0.559),  time:30.811, tt:893.526\n",
      "Ep:29, loss:0.00004, loss_test:0.02367, lr:5.16e-02, fs:0.63158 (r=0.727,p=0.558),  time:30.798, tt:923.948\n",
      "Ep:30, loss:0.00004, loss_test:0.02340, lr:5.11e-02, fs:0.63717 (r=0.727,p=0.567),  time:30.799, tt:954.784\n",
      "Ep:31, loss:0.00004, loss_test:0.02330, lr:5.06e-02, fs:0.63063 (r=0.707,p=0.569),  time:30.819, tt:986.222\n",
      "Ep:32, loss:0.00004, loss_test:0.02305, lr:5.01e-02, fs:0.63063 (r=0.707,p=0.569),  time:30.804, tt:1016.548\n",
      "Ep:33, loss:0.00003, loss_test:0.02274, lr:4.96e-02, fs:0.64574 (r=0.727,p=0.581),  time:30.772, tt:1046.263\n",
      "Ep:34, loss:0.00003, loss_test:0.02262, lr:4.91e-02, fs:0.63964 (r=0.717,p=0.577),  time:30.742, tt:1075.967\n",
      "Ep:35, loss:0.00003, loss_test:0.02246, lr:4.86e-02, fs:0.63964 (r=0.717,p=0.577),  time:30.694, tt:1104.995\n",
      "Ep:36, loss:0.00003, loss_test:0.02210, lr:4.81e-02, fs:0.65471 (r=0.737,p=0.589),  time:30.722, tt:1136.699\n",
      "Ep:37, loss:0.00003, loss_test:0.02204, lr:4.76e-02, fs:0.65753 (r=0.727,p=0.600),  time:30.736, tt:1167.973\n",
      "Ep:38, loss:0.00003, loss_test:0.02194, lr:4.71e-02, fs:0.65138 (r=0.717,p=0.597),  time:30.725, tt:1198.257\n",
      "Ep:39, loss:0.00003, loss_test:0.02158, lr:4.67e-02, fs:0.66364 (r=0.737,p=0.603),  time:30.695, tt:1227.811\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.02134, lr:4.67e-02, fs:0.69027 (r=0.788,p=0.614),  time:30.716, tt:1259.375\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.02131, lr:4.67e-02, fs:0.68161 (r=0.768,p=0.613),  time:30.731, tt:1290.693\n",
      "Ep:42, loss:0.00003, loss_test:0.02111, lr:4.67e-02, fs:0.69333 (r=0.788,p=0.619),  time:30.731, tt:1321.432\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.02096, lr:4.67e-02, fs:0.69333 (r=0.788,p=0.619),  time:30.718, tt:1351.580\n",
      "Ep:44, loss:0.00003, loss_test:0.02086, lr:4.67e-02, fs:0.68750 (r=0.778,p=0.616),  time:30.731, tt:1382.899\n",
      "Ep:45, loss:0.00003, loss_test:0.02063, lr:4.67e-02, fs:0.69912 (r=0.798,p=0.622),  time:30.768, tt:1415.329\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.02052, lr:4.67e-02, fs:0.69058 (r=0.778,p=0.621),  time:30.767, tt:1446.034\n",
      "Ep:47, loss:0.00003, loss_test:0.02042, lr:4.67e-02, fs:0.68493 (r=0.758,p=0.625),  time:30.785, tt:1477.697\n",
      "Ep:48, loss:0.00003, loss_test:0.02032, lr:4.67e-02, fs:0.66977 (r=0.727,p=0.621),  time:30.788, tt:1508.606\n",
      "Ep:49, loss:0.00003, loss_test:0.02024, lr:4.67e-02, fs:0.67290 (r=0.727,p=0.626),  time:30.808, tt:1540.399\n",
      "Ep:50, loss:0.00003, loss_test:0.01994, lr:4.67e-02, fs:0.69124 (r=0.758,p=0.636),  time:30.821, tt:1571.848\n",
      "Ep:51, loss:0.00003, loss_test:0.02022, lr:4.67e-02, fs:0.68246 (r=0.727,p=0.643),  time:30.832, tt:1603.284\n",
      "Ep:52, loss:0.00003, loss_test:0.01990, lr:4.67e-02, fs:0.67593 (r=0.737,p=0.624),  time:30.869, tt:1636.059\n",
      "Ep:53, loss:0.00002, loss_test:0.01961, lr:4.67e-02, fs:0.68778 (r=0.768,p=0.623),  time:30.858, tt:1666.341\n",
      "Ep:54, loss:0.00002, loss_test:0.02002, lr:4.67e-02, fs:0.66667 (r=0.707,p=0.631),  time:30.842, tt:1696.290\n",
      "Ep:55, loss:0.00002, loss_test:0.02002, lr:4.67e-02, fs:0.66351 (r=0.707,p=0.625),  time:30.858, tt:1728.048\n",
      "Ep:56, loss:0.00002, loss_test:0.01986, lr:4.67e-02, fs:0.66355 (r=0.717,p=0.617),  time:30.865, tt:1759.309\n",
      "Ep:57, loss:0.00002, loss_test:0.02006, lr:4.62e-02, fs:0.66355 (r=0.717,p=0.617),  time:30.868, tt:1790.342\n",
      "Ep:58, loss:0.00002, loss_test:0.02024, lr:4.57e-02, fs:0.64762 (r=0.687,p=0.613),  time:30.877, tt:1821.727\n",
      "Ep:59, loss:0.00002, loss_test:0.02016, lr:4.53e-02, fs:0.67593 (r=0.737,p=0.624),  time:30.893, tt:1853.551\n",
      "Ep:60, loss:0.00002, loss_test:0.02022, lr:4.48e-02, fs:0.66977 (r=0.727,p=0.621),  time:30.892, tt:1884.381\n",
      "Ep:61, loss:0.00002, loss_test:0.02071, lr:4.44e-02, fs:0.67907 (r=0.737,p=0.629),  time:30.895, tt:1915.493\n",
      "Ep:62, loss:0.00002, loss_test:0.02080, lr:4.39e-02, fs:0.68224 (r=0.737,p=0.635),  time:30.879, tt:1945.400\n",
      "Ep:63, loss:0.00002, loss_test:0.02054, lr:4.35e-02, fs:0.65714 (r=0.697,p=0.622),  time:30.865, tt:1975.368\n",
      "Ep:64, loss:0.00002, loss_test:0.02121, lr:4.31e-02, fs:0.66667 (r=0.707,p=0.631),  time:30.861, tt:2005.942\n",
      "Ep:65, loss:0.00002, loss_test:0.02106, lr:4.26e-02, fs:0.66986 (r=0.707,p=0.636),  time:30.863, tt:2036.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.02114, lr:4.22e-02, fs:0.67299 (r=0.717,p=0.634),  time:30.862, tt:2067.727\n",
      "Ep:67, loss:0.00002, loss_test:0.02122, lr:4.18e-02, fs:0.66981 (r=0.717,p=0.628),  time:30.855, tt:2098.129\n",
      "Ep:68, loss:0.00002, loss_test:0.02142, lr:4.14e-02, fs:0.65714 (r=0.697,p=0.622),  time:30.858, tt:2129.215\n",
      "Ep:69, loss:0.00002, loss_test:0.02163, lr:4.10e-02, fs:0.66986 (r=0.707,p=0.636),  time:30.861, tt:2160.246\n",
      "Ep:70, loss:0.00002, loss_test:0.02136, lr:4.05e-02, fs:0.68868 (r=0.737,p=0.646),  time:30.851, tt:2190.434\n",
      "Ep:71, loss:0.00002, loss_test:0.02219, lr:4.01e-02, fs:0.66990 (r=0.697,p=0.645),  time:30.859, tt:2221.827\n",
      "Ep:72, loss:0.00002, loss_test:0.02207, lr:3.97e-02, fs:0.68571 (r=0.727,p=0.649),  time:30.867, tt:2253.296\n",
      "Ep:73, loss:0.00001, loss_test:0.02233, lr:3.93e-02, fs:0.68900 (r=0.727,p=0.655),  time:30.862, tt:2283.799\n",
      "Ep:74, loss:0.00001, loss_test:0.02285, lr:3.89e-02, fs:0.66010 (r=0.677,p=0.644),  time:30.860, tt:2314.467\n",
      "Ep:75, loss:0.00001, loss_test:0.02285, lr:3.86e-02, fs:0.68627 (r=0.707,p=0.667),  time:30.869, tt:2346.028\n",
      "Ep:76, loss:0.00001, loss_test:0.02273, lr:3.82e-02, fs:0.68599 (r=0.717,p=0.657),  time:30.863, tt:2376.470\n",
      "Ep:77, loss:0.00001, loss_test:0.02362, lr:3.78e-02, fs:0.67662 (r=0.687,p=0.667),  time:30.860, tt:2407.113\n",
      "Ep:78, loss:0.00001, loss_test:0.02350, lr:3.74e-02, fs:0.69268 (r=0.717,p=0.670),  time:30.859, tt:2437.825\n",
      "Ep:79, loss:0.00001, loss_test:0.02325, lr:3.70e-02, fs:0.69565 (r=0.727,p=0.667),  time:30.863, tt:2469.041\n",
      "Ep:80, loss:0.00001, loss_test:0.02405, lr:3.67e-02, fs:0.69307 (r=0.707,p=0.680),  time:30.858, tt:2499.488\n",
      "Ep:81, loss:0.00001, loss_test:0.02334, lr:3.63e-02, fs:0.68342 (r=0.687,p=0.680),  time:30.850, tt:2529.710\n",
      "Ep:82, loss:0.00001, loss_test:0.02428, lr:3.59e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.856, tt:2561.013\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.02380, lr:3.59e-02, fs:0.68657 (r=0.697,p=0.676),  time:30.854, tt:2591.775\n",
      "Ep:84, loss:0.00001, loss_test:0.02536, lr:3.59e-02, fs:0.69036 (r=0.687,p=0.694),  time:30.850, tt:2622.271\n",
      "Ep:85, loss:0.00001, loss_test:0.02405, lr:3.59e-02, fs:0.68687 (r=0.687,p=0.687),  time:30.864, tt:2654.302\n",
      "Ep:86, loss:0.00001, loss_test:0.02585, lr:3.59e-02, fs:0.69388 (r=0.687,p=0.701),  time:30.867, tt:2685.461\n",
      "Ep:87, loss:0.00001, loss_test:0.02456, lr:3.59e-02, fs:0.69347 (r=0.697,p=0.690),  time:30.857, tt:2715.413\n",
      "Ep:88, loss:0.00001, loss_test:0.02590, lr:3.59e-02, fs:0.70352 (r=0.707,p=0.700),  time:30.864, tt:2746.855\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.02554, lr:3.59e-02, fs:0.69036 (r=0.687,p=0.694),  time:30.873, tt:2778.527\n",
      "Ep:90, loss:0.00001, loss_test:0.02639, lr:3.59e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.876, tt:2809.745\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.02546, lr:3.59e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.883, tt:2841.276\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.02639, lr:3.59e-02, fs:0.71357 (r=0.717,p=0.710),  time:30.892, tt:2872.961\n",
      "Ep:93, loss:0.00001, loss_test:0.02629, lr:3.59e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.902, tt:2904.762\n",
      "Ep:94, loss:0.00001, loss_test:0.02667, lr:3.59e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.909, tt:2936.370\n",
      "Ep:95, loss:0.00001, loss_test:0.02767, lr:3.59e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.914, tt:2967.721\n",
      "Ep:96, loss:0.00001, loss_test:0.02610, lr:3.59e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.905, tt:2997.753\n",
      "Ep:97, loss:0.00001, loss_test:0.02771, lr:3.59e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.921, tt:3030.249\n",
      "Ep:98, loss:0.00001, loss_test:0.02861, lr:3.59e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.930, tt:3062.101\n",
      "Ep:99, loss:0.00001, loss_test:0.02469, lr:3.59e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.940, tt:3094.036\n",
      "Ep:100, loss:0.00001, loss_test:0.02824, lr:3.59e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.955, tt:3126.448\n",
      "Ep:101, loss:0.00001, loss_test:0.02728, lr:3.59e-02, fs:0.71429 (r=0.707,p=0.722),  time:30.962, tt:3158.140\n",
      "Ep:102, loss:0.00001, loss_test:0.02726, lr:3.59e-02, fs:0.72449 (r=0.717,p=0.732),  time:30.967, tt:3189.648\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.02933, lr:3.59e-02, fs:0.71503 (r=0.697,p=0.734),  time:30.967, tt:3220.549\n",
      "Ep:104, loss:0.00001, loss_test:0.02740, lr:3.59e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.974, tt:3252.270\n",
      "Ep:105, loss:0.00001, loss_test:0.02794, lr:3.59e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.981, tt:3283.942\n",
      "Ep:106, loss:0.00001, loss_test:0.03049, lr:3.59e-02, fs:0.70833 (r=0.687,p=0.731),  time:30.984, tt:3315.238\n",
      "Ep:107, loss:0.00001, loss_test:0.02752, lr:3.59e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.988, tt:3346.713\n",
      "Ep:108, loss:0.00001, loss_test:0.02852, lr:3.59e-02, fs:0.71204 (r=0.687,p=0.739),  time:30.976, tt:3376.369\n",
      "Ep:109, loss:0.00001, loss_test:0.03167, lr:3.59e-02, fs:0.70833 (r=0.687,p=0.731),  time:30.982, tt:3408.066\n",
      "Ep:110, loss:0.00001, loss_test:0.02694, lr:3.59e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.988, tt:3439.661\n",
      "Ep:111, loss:0.00001, loss_test:0.03049, lr:3.59e-02, fs:0.70157 (r=0.677,p=0.728),  time:31.004, tt:3472.400\n",
      "Ep:112, loss:0.00001, loss_test:0.03202, lr:3.59e-02, fs:0.69841 (r=0.667,p=0.733),  time:31.007, tt:3503.783\n",
      "Ep:113, loss:0.00001, loss_test:0.02593, lr:3.59e-02, fs:0.70157 (r=0.677,p=0.728),  time:31.026, tt:3537.002\n",
      "Ep:114, loss:0.00001, loss_test:0.03256, lr:3.56e-02, fs:0.69792 (r=0.677,p=0.720),  time:31.036, tt:3569.181\n",
      "Ep:115, loss:0.00001, loss_test:0.02736, lr:3.52e-02, fs:0.72449 (r=0.717,p=0.732),  time:31.044, tt:3601.052\n",
      "Ep:116, loss:0.00001, loss_test:0.03072, lr:3.49e-02, fs:0.72165 (r=0.707,p=0.737),  time:31.042, tt:3631.898\n",
      "Ep:117, loss:0.00001, loss_test:0.02985, lr:3.45e-02, fs:0.70157 (r=0.677,p=0.728),  time:31.047, tt:3663.556\n",
      "Ep:118, loss:0.00001, loss_test:0.03022, lr:3.42e-02, fs:0.73016 (r=0.697,p=0.767),  time:31.041, tt:3693.843\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.03255, lr:3.42e-02, fs:0.69841 (r=0.667,p=0.733),  time:31.036, tt:3724.325\n",
      "Ep:120, loss:0.00001, loss_test:0.02896, lr:3.42e-02, fs:0.73016 (r=0.697,p=0.767),  time:31.043, tt:3756.160\n",
      "Ep:121, loss:0.00001, loss_test:0.03436, lr:3.42e-02, fs:0.69189 (r=0.646,p=0.744),  time:31.045, tt:3787.479\n",
      "Ep:122, loss:0.00001, loss_test:0.03073, lr:3.42e-02, fs:0.72043 (r=0.677,p=0.770),  time:31.048, tt:3818.931\n",
      "Ep:123, loss:0.00001, loss_test:0.03378, lr:3.42e-02, fs:0.69189 (r=0.646,p=0.744),  time:31.047, tt:3849.813\n",
      "Ep:124, loss:0.00001, loss_test:0.03264, lr:3.42e-02, fs:0.70652 (r=0.657,p=0.765),  time:31.030, tt:3878.761\n",
      "Ep:125, loss:0.00001, loss_test:0.03345, lr:3.42e-02, fs:0.70968 (r=0.667,p=0.759),  time:31.039, tt:3910.950\n",
      "Ep:126, loss:0.00001, loss_test:0.03582, lr:3.42e-02, fs:0.68852 (r=0.636,p=0.750),  time:31.038, tt:3941.839\n",
      "Ep:127, loss:0.00001, loss_test:0.03352, lr:3.42e-02, fs:0.71038 (r=0.657,p=0.774),  time:31.042, tt:3973.329\n",
      "Ep:128, loss:0.00001, loss_test:0.03406, lr:3.42e-02, fs:0.70652 (r=0.657,p=0.765),  time:31.047, tt:4005.069\n",
      "Ep:129, loss:0.00000, loss_test:0.03465, lr:3.42e-02, fs:0.70652 (r=0.657,p=0.765),  time:31.043, tt:4035.570\n",
      "Ep:130, loss:0.00000, loss_test:0.03352, lr:3.38e-02, fs:0.71351 (r=0.667,p=0.767),  time:31.044, tt:4066.706\n",
      "Ep:131, loss:0.00000, loss_test:0.03551, lr:3.35e-02, fs:0.69945 (r=0.646,p=0.762),  time:31.043, tt:4097.654\n",
      "Ep:132, loss:0.00000, loss_test:0.03730, lr:3.32e-02, fs:0.67778 (r=0.616,p=0.753),  time:31.049, tt:4129.495\n",
      "Ep:133, loss:0.00000, loss_test:0.03664, lr:3.28e-02, fs:0.69231 (r=0.636,p=0.759),  time:31.050, tt:4160.729\n",
      "Ep:134, loss:0.00000, loss_test:0.03605, lr:3.25e-02, fs:0.69945 (r=0.646,p=0.762),  time:31.039, tt:4190.237\n",
      "Ep:135, loss:0.00000, loss_test:0.03819, lr:3.22e-02, fs:0.67416 (r=0.606,p=0.759),  time:31.042, tt:4221.734\n",
      "Ep:136, loss:0.00000, loss_test:0.03916, lr:3.19e-02, fs:0.66292 (r=0.596,p=0.747),  time:31.048, tt:4253.575\n",
      "Ep:137, loss:0.00000, loss_test:0.03725, lr:3.15e-02, fs:0.67039 (r=0.606,p=0.750),  time:31.060, tt:4286.320\n",
      "Ep:138, loss:0.00000, loss_test:0.03524, lr:3.12e-02, fs:0.69231 (r=0.636,p=0.759),  time:31.060, tt:4317.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.04064, lr:3.09e-02, fs:0.65537 (r=0.586,p=0.744),  time:31.061, tt:4348.582\n",
      "Ep:140, loss:0.00000, loss_test:0.03755, lr:3.06e-02, fs:0.66286 (r=0.586,p=0.763),  time:31.064, tt:4379.977\n",
      "Ep:141, loss:0.00000, loss_test:0.03447, lr:3.03e-02, fs:0.69231 (r=0.636,p=0.759),  time:31.064, tt:4411.032\n",
      "Ep:142, loss:0.00000, loss_test:0.04051, lr:3.00e-02, fs:0.66667 (r=0.596,p=0.756),  time:31.058, tt:4441.363\n",
      "Ep:143, loss:0.00000, loss_test:0.03893, lr:2.97e-02, fs:0.65537 (r=0.586,p=0.744),  time:31.062, tt:4472.980\n",
      "Ep:144, loss:0.00000, loss_test:0.03762, lr:2.94e-02, fs:0.66667 (r=0.596,p=0.756),  time:31.047, tt:4501.849\n",
      "Ep:145, loss:0.00000, loss_test:0.04080, lr:2.91e-02, fs:0.66667 (r=0.576,p=0.792),  time:31.040, tt:4531.783\n",
      "Ep:146, loss:0.00000, loss_test:0.03847, lr:2.88e-02, fs:0.67429 (r=0.596,p=0.776),  time:31.040, tt:4562.857\n",
      "Ep:147, loss:0.00000, loss_test:0.03893, lr:2.85e-02, fs:0.67045 (r=0.596,p=0.766),  time:31.037, tt:4593.525\n",
      "Ep:148, loss:0.00000, loss_test:0.04168, lr:2.82e-02, fs:0.66667 (r=0.576,p=0.792),  time:31.036, tt:4624.324\n",
      "Ep:149, loss:0.00000, loss_test:0.03854, lr:2.80e-02, fs:0.67429 (r=0.596,p=0.776),  time:31.027, tt:4654.061\n",
      "Ep:150, loss:0.00000, loss_test:0.03975, lr:2.77e-02, fs:0.67816 (r=0.596,p=0.787),  time:31.024, tt:4684.631\n",
      "Ep:151, loss:0.00000, loss_test:0.04161, lr:2.74e-02, fs:0.66667 (r=0.576,p=0.792),  time:31.014, tt:4714.200\n",
      "Ep:152, loss:0.00000, loss_test:0.03932, lr:2.71e-02, fs:0.67816 (r=0.596,p=0.787),  time:31.011, tt:4744.686\n",
      "Ep:153, loss:0.00000, loss_test:0.04190, lr:2.69e-02, fs:0.67059 (r=0.576,p=0.803),  time:31.005, tt:4774.742\n",
      "Ep:154, loss:0.00000, loss_test:0.04299, lr:2.66e-02, fs:0.66279 (r=0.576,p=0.781),  time:31.006, tt:4805.872\n",
      "Ep:155, loss:0.00000, loss_test:0.03957, lr:2.63e-02, fs:0.69006 (r=0.596,p=0.819),  time:31.000, tt:4836.009\n",
      "Ep:156, loss:0.00000, loss_test:0.04224, lr:2.61e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.994, tt:4865.994\n",
      "Ep:157, loss:0.00000, loss_test:0.04253, lr:2.58e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.996, tt:4897.360\n",
      "Ep:158, loss:0.00000, loss_test:0.04164, lr:2.55e-02, fs:0.68605 (r=0.596,p=0.808),  time:30.990, tt:4927.442\n",
      "Ep:159, loss:0.00000, loss_test:0.04431, lr:2.53e-02, fs:0.66667 (r=0.576,p=0.792),  time:30.984, tt:4957.445\n",
      "Ep:160, loss:0.00000, loss_test:0.04163, lr:2.50e-02, fs:0.69006 (r=0.596,p=0.819),  time:30.988, tt:4989.119\n",
      "Ep:161, loss:0.00000, loss_test:0.04498, lr:2.48e-02, fs:0.66667 (r=0.576,p=0.792),  time:30.978, tt:5018.371\n",
      "Ep:162, loss:0.00000, loss_test:0.04296, lr:2.45e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.968, tt:5047.795\n",
      "Ep:163, loss:0.00000, loss_test:0.04313, lr:2.43e-02, fs:0.68605 (r=0.596,p=0.808),  time:30.973, tt:5079.494\n",
      "Ep:164, loss:0.00000, loss_test:0.04622, lr:2.40e-02, fs:0.66667 (r=0.576,p=0.792),  time:30.986, tt:5112.668\n",
      "Ep:165, loss:0.00000, loss_test:0.04170, lr:2.38e-02, fs:0.68605 (r=0.596,p=0.808),  time:30.990, tt:5144.348\n",
      "Ep:166, loss:0.00000, loss_test:0.04522, lr:2.36e-02, fs:0.66667 (r=0.576,p=0.792),  time:30.999, tt:5176.874\n",
      "Ep:167, loss:0.00000, loss_test:0.04531, lr:2.33e-02, fs:0.67059 (r=0.576,p=0.803),  time:31.008, tt:5209.421\n",
      "Ep:168, loss:0.00000, loss_test:0.04281, lr:2.31e-02, fs:0.69822 (r=0.596,p=0.843),  time:31.017, tt:5241.891\n",
      "Ep:169, loss:0.00000, loss_test:0.04642, lr:2.29e-02, fs:0.66667 (r=0.576,p=0.792),  time:31.021, tt:5273.546\n",
      "Ep:170, loss:0.00000, loss_test:0.04518, lr:2.26e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.026, tt:5305.363\n",
      "Ep:171, loss:0.00000, loss_test:0.04369, lr:2.24e-02, fs:0.69006 (r=0.596,p=0.819),  time:31.041, tt:5338.976\n",
      "Ep:172, loss:0.00000, loss_test:0.04650, lr:2.22e-02, fs:0.67059 (r=0.576,p=0.803),  time:31.059, tt:5373.129\n",
      "Ep:173, loss:0.00000, loss_test:0.04390, lr:2.20e-02, fs:0.69412 (r=0.596,p=0.831),  time:31.066, tt:5405.425\n",
      "Ep:174, loss:0.00000, loss_test:0.04712, lr:2.17e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.081, tt:5439.254\n",
      "Ep:175, loss:0.00000, loss_test:0.04546, lr:2.15e-02, fs:0.69412 (r=0.596,p=0.831),  time:31.091, tt:5472.046\n",
      "Ep:176, loss:0.00000, loss_test:0.04667, lr:2.13e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.096, tt:5504.008\n",
      "Ep:177, loss:0.00000, loss_test:0.04738, lr:2.11e-02, fs:0.67456 (r=0.576,p=0.814),  time:31.107, tt:5537.041\n",
      "Ep:178, loss:0.00000, loss_test:0.04347, lr:2.09e-02, fs:0.69412 (r=0.596,p=0.831),  time:31.114, tt:5569.397\n",
      "Ep:179, loss:0.00000, loss_test:0.05042, lr:2.07e-02, fs:0.65476 (r=0.556,p=0.797),  time:31.114, tt:5600.514\n",
      "Ep:180, loss:0.00000, loss_test:0.04376, lr:2.05e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.120, tt:5632.780\n",
      "Ep:181, loss:0.00000, loss_test:0.04966, lr:2.03e-02, fs:0.66667 (r=0.566,p=0.812),  time:31.124, tt:5664.517\n",
      "Ep:182, loss:0.00000, loss_test:0.04556, lr:2.01e-02, fs:0.69412 (r=0.596,p=0.831),  time:31.125, tt:5695.921\n",
      "Ep:183, loss:0.00000, loss_test:0.04854, lr:1.99e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.125, tt:5727.067\n",
      "Ep:184, loss:0.00000, loss_test:0.04894, lr:1.97e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.128, tt:5758.595\n",
      "Ep:185, loss:0.00000, loss_test:0.04585, lr:1.95e-02, fs:0.70238 (r=0.596,p=0.855),  time:31.127, tt:5789.651\n",
      "Ep:186, loss:0.00000, loss_test:0.04985, lr:1.93e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.131, tt:5821.547\n",
      "Ep:187, loss:0.00000, loss_test:0.04566, lr:1.91e-02, fs:0.69822 (r=0.596,p=0.843),  time:31.121, tt:5850.755\n",
      "Ep:188, loss:0.00000, loss_test:0.04997, lr:1.89e-02, fs:0.67857 (r=0.576,p=0.826),  time:31.122, tt:5881.971\n",
      "Ep:189, loss:0.00000, loss_test:0.04687, lr:1.87e-02, fs:0.69822 (r=0.596,p=0.843),  time:31.124, tt:5913.471\n",
      "Ep:190, loss:0.00000, loss_test:0.04954, lr:1.85e-02, fs:0.68675 (r=0.576,p=0.851),  time:31.131, tt:5946.008\n",
      "Ep:191, loss:0.00000, loss_test:0.04882, lr:1.83e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.137, tt:5978.351\n",
      "Ep:192, loss:0.00000, loss_test:0.04927, lr:1.81e-02, fs:0.68675 (r=0.576,p=0.851),  time:31.143, tt:6010.548\n",
      "Ep:193, loss:0.00000, loss_test:0.04882, lr:1.80e-02, fs:0.69048 (r=0.586,p=0.841),  time:31.146, tt:6042.355\n",
      "Ep:194, loss:0.00000, loss_test:0.04888, lr:1.78e-02, fs:0.69048 (r=0.586,p=0.841),  time:31.161, tt:6076.351\n",
      "Ep:195, loss:0.00000, loss_test:0.05000, lr:1.76e-02, fs:0.68675 (r=0.576,p=0.851),  time:31.156, tt:6106.574\n",
      "Ep:196, loss:0.00000, loss_test:0.04879, lr:1.74e-02, fs:0.69822 (r=0.596,p=0.843),  time:31.148, tt:6136.080\n",
      "Ep:197, loss:0.00000, loss_test:0.05131, lr:1.73e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.152, tt:6168.136\n",
      "Ep:198, loss:0.00000, loss_test:0.04909, lr:1.71e-02, fs:0.69822 (r=0.596,p=0.843),  time:31.156, tt:6200.085\n",
      "Ep:199, loss:0.00000, loss_test:0.05124, lr:1.69e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.156, tt:6231.192\n",
      "Ep:200, loss:0.00000, loss_test:0.04966, lr:1.67e-02, fs:0.68675 (r=0.576,p=0.851),  time:31.147, tt:6260.500\n",
      "Ep:201, loss:0.00000, loss_test:0.05224, lr:1.66e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.145, tt:6291.285\n",
      "Ep:202, loss:0.00000, loss_test:0.04967, lr:1.64e-02, fs:0.69461 (r=0.586,p=0.853),  time:31.145, tt:6322.509\n",
      "Ep:203, loss:0.00000, loss_test:0.05167, lr:1.62e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.129, tt:6350.238\n",
      "Ep:204, loss:0.00000, loss_test:0.05059, lr:1.61e-02, fs:0.69048 (r=0.586,p=0.841),  time:31.086, tt:6372.622\n",
      "Ep:205, loss:0.00000, loss_test:0.05165, lr:1.59e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.076, tt:6401.614\n",
      "Ep:206, loss:0.00000, loss_test:0.05114, lr:1.58e-02, fs:0.68263 (r=0.576,p=0.838),  time:31.072, tt:6431.826\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13352, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:30.119, tt:30.119\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13308, lr:1.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:29.934, tt:59.868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00026, loss_test:0.13306, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:30.722, tt:92.165\n",
      "Ep:3, loss:0.00025, loss_test:0.13263, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:30.934, tt:123.736\n",
      "Ep:4, loss:0.00025, loss_test:0.13160, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:30.999, tt:154.994\n",
      "Ep:5, loss:0.00025, loss_test:0.13060, lr:1.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:31.073, tt:186.438\n",
      "Ep:6, loss:0.00025, loss_test:0.12972, lr:1.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:31.133, tt:217.934\n",
      "Ep:7, loss:0.00025, loss_test:0.12863, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:31.236, tt:249.888\n",
      "Ep:8, loss:0.00024, loss_test:0.12757, lr:1.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:31.211, tt:280.899\n",
      "Ep:9, loss:0.00024, loss_test:0.12648, lr:1.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:31.233, tt:312.331\n",
      "Ep:10, loss:0.00024, loss_test:0.12530, lr:1.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:31.234, tt:343.575\n",
      "Ep:11, loss:0.00023, loss_test:0.12417, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:31.227, tt:374.718\n",
      "Ep:12, loss:0.00023, loss_test:0.12255, lr:9.90e-03, fs:0.66094 (r=0.778,p=0.575),  time:31.288, tt:406.747\n",
      "Ep:13, loss:0.00023, loss_test:0.12042, lr:9.80e-03, fs:0.65789 (r=0.758,p=0.581),  time:31.419, tt:439.861\n",
      "Ep:14, loss:0.00022, loss_test:0.11866, lr:9.70e-03, fs:0.65487 (r=0.747,p=0.583),  time:31.491, tt:472.358\n",
      "Ep:15, loss:0.00022, loss_test:0.11708, lr:9.61e-03, fs:0.65179 (r=0.737,p=0.584),  time:31.512, tt:504.192\n",
      "Ep:16, loss:0.00021, loss_test:0.11557, lr:9.51e-03, fs:0.65421 (r=0.707,p=0.609),  time:31.532, tt:536.039\n",
      "Ep:17, loss:0.00020, loss_test:0.11380, lr:9.41e-03, fs:0.66038 (r=0.707,p=0.619),  time:31.549, tt:567.891\n",
      "Ep:18, loss:0.00020, loss_test:0.11263, lr:9.32e-03, fs:0.65728 (r=0.707,p=0.614),  time:31.599, tt:600.387\n",
      "Ep:19, loss:0.00019, loss_test:0.11212, lr:9.23e-03, fs:0.66351 (r=0.707,p=0.625),  time:31.618, tt:632.352\n",
      "Ep:20, loss:0.00019, loss_test:0.11165, lr:9.14e-03, fs:0.64734 (r=0.677,p=0.620),  time:31.660, tt:664.864\n",
      "Ep:21, loss:0.00018, loss_test:0.11060, lr:9.04e-03, fs:0.66029 (r=0.697,p=0.627),  time:31.673, tt:696.811\n",
      "Ep:22, loss:0.00018, loss_test:0.10842, lr:8.95e-03, fs:0.67619 (r=0.717,p=0.640),  time:31.688, tt:728.824\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.10888, lr:8.95e-03, fs:0.66010 (r=0.677,p=0.644),  time:31.666, tt:759.982\n",
      "Ep:24, loss:0.00017, loss_test:0.10732, lr:8.95e-03, fs:0.62245 (r=0.616,p=0.629),  time:31.742, tt:793.544\n",
      "Ep:25, loss:0.00016, loss_test:0.10725, lr:8.95e-03, fs:0.63212 (r=0.616,p=0.649),  time:31.742, tt:825.304\n",
      "Ep:26, loss:0.00015, loss_test:0.10598, lr:8.95e-03, fs:0.66990 (r=0.697,p=0.645),  time:31.746, tt:857.151\n",
      "Ep:27, loss:0.00015, loss_test:0.10553, lr:8.95e-03, fs:0.68342 (r=0.687,p=0.680),  time:31.768, tt:889.515\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.10651, lr:8.95e-03, fs:0.69072 (r=0.677,p=0.705),  time:31.800, tt:922.210\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.10540, lr:8.95e-03, fs:0.72222 (r=0.788,p=0.667),  time:31.841, tt:955.245\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.10321, lr:8.95e-03, fs:0.70899 (r=0.677,p=0.744),  time:31.871, tt:988.000\n",
      "Ep:31, loss:0.00013, loss_test:0.10441, lr:8.95e-03, fs:0.71749 (r=0.808,p=0.645),  time:31.841, tt:1018.928\n",
      "Ep:32, loss:0.00013, loss_test:0.10452, lr:8.95e-03, fs:0.67403 (r=0.616,p=0.744),  time:31.869, tt:1051.673\n",
      "Ep:33, loss:0.00012, loss_test:0.10433, lr:8.95e-03, fs:0.72727 (r=0.808,p=0.661),  time:31.886, tt:1084.123\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.10194, lr:8.95e-03, fs:0.68927 (r=0.616,p=0.782),  time:31.868, tt:1115.377\n",
      "Ep:35, loss:0.00012, loss_test:0.10289, lr:8.95e-03, fs:0.73267 (r=0.747,p=0.718),  time:31.872, tt:1147.408\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.10153, lr:8.95e-03, fs:0.70769 (r=0.697,p=0.719),  time:31.846, tt:1178.316\n",
      "Ep:37, loss:0.00011, loss_test:0.10452, lr:8.95e-03, fs:0.72816 (r=0.758,p=0.701),  time:31.854, tt:1210.465\n",
      "Ep:38, loss:0.00010, loss_test:0.10224, lr:8.95e-03, fs:0.69110 (r=0.667,p=0.717),  time:31.848, tt:1242.067\n",
      "Ep:39, loss:0.00010, loss_test:0.10365, lr:8.95e-03, fs:0.72986 (r=0.778,p=0.688),  time:31.835, tt:1273.387\n",
      "Ep:40, loss:0.00010, loss_test:0.10332, lr:8.95e-03, fs:0.71875 (r=0.697,p=0.742),  time:31.901, tt:1307.930\n",
      "Ep:41, loss:0.00009, loss_test:0.10555, lr:8.95e-03, fs:0.71264 (r=0.626,p=0.827),  time:31.894, tt:1339.543\n",
      "Ep:42, loss:0.00009, loss_test:0.10601, lr:8.95e-03, fs:0.72464 (r=0.758,p=0.694),  time:31.881, tt:1370.880\n",
      "Ep:43, loss:0.00008, loss_test:0.10780, lr:8.95e-03, fs:0.68639 (r=0.586,p=0.829),  time:31.891, tt:1403.199\n",
      "Ep:44, loss:0.00008, loss_test:0.10369, lr:8.95e-03, fs:0.72038 (r=0.768,p=0.679),  time:31.846, tt:1433.060\n",
      "Ep:45, loss:0.00007, loss_test:0.10973, lr:8.95e-03, fs:0.72093 (r=0.626,p=0.849),  time:31.830, tt:1464.183\n",
      "Ep:46, loss:0.00007, loss_test:0.10660, lr:8.95e-03, fs:0.71795 (r=0.707,p=0.729),  time:31.823, tt:1495.702\n",
      "Ep:47, loss:0.00007, loss_test:0.10587, lr:8.86e-03, fs:0.68639 (r=0.586,p=0.829),  time:31.816, tt:1527.159\n",
      "Ep:48, loss:0.00008, loss_test:0.10444, lr:8.78e-03, fs:0.71066 (r=0.707,p=0.714),  time:31.816, tt:1558.981\n",
      "Ep:49, loss:0.00006, loss_test:0.11231, lr:8.69e-03, fs:0.68927 (r=0.616,p=0.782),  time:31.816, tt:1590.820\n",
      "Ep:50, loss:0.00006, loss_test:0.10164, lr:8.60e-03, fs:0.74490 (r=0.737,p=0.753),  time:31.848, tt:1624.250\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.11469, lr:8.60e-03, fs:0.68108 (r=0.636,p=0.733),  time:31.849, tt:1656.125\n",
      "Ep:52, loss:0.00006, loss_test:0.10649, lr:8.60e-03, fs:0.69149 (r=0.657,p=0.730),  time:31.873, tt:1689.274\n",
      "Ep:53, loss:0.00005, loss_test:0.09839, lr:8.60e-03, fs:0.70391 (r=0.636,p=0.787),  time:31.851, tt:1719.977\n",
      "Ep:54, loss:0.00006, loss_test:0.10554, lr:8.60e-03, fs:0.71579 (r=0.687,p=0.747),  time:31.817, tt:1749.952\n",
      "Ep:55, loss:0.00006, loss_test:0.10685, lr:8.60e-03, fs:0.67052 (r=0.586,p=0.784),  time:31.811, tt:1781.398\n",
      "Ep:56, loss:0.00005, loss_test:0.10848, lr:8.60e-03, fs:0.69231 (r=0.636,p=0.759),  time:31.774, tt:1811.125\n",
      "Ep:57, loss:0.00005, loss_test:0.10893, lr:8.60e-03, fs:0.64242 (r=0.535,p=0.803),  time:31.767, tt:1842.457\n",
      "Ep:58, loss:0.00004, loss_test:0.10906, lr:8.60e-03, fs:0.67403 (r=0.616,p=0.744),  time:31.768, tt:1874.318\n",
      "Ep:59, loss:0.00004, loss_test:0.10723, lr:8.60e-03, fs:0.68235 (r=0.586,p=0.817),  time:31.755, tt:1905.305\n",
      "Ep:60, loss:0.00004, loss_test:0.10153, lr:8.60e-03, fs:0.72432 (r=0.677,p=0.779),  time:31.749, tt:1936.683\n",
      "Ep:61, loss:0.00004, loss_test:0.10532, lr:8.60e-03, fs:0.64634 (r=0.535,p=0.815),  time:31.746, tt:1968.268\n",
      "Ep:62, loss:0.00004, loss_test:0.10279, lr:8.51e-03, fs:0.71429 (r=0.657,p=0.783),  time:31.732, tt:1999.100\n",
      "Ep:63, loss:0.00004, loss_test:0.10680, lr:8.43e-03, fs:0.63158 (r=0.545,p=0.750),  time:31.724, tt:2030.344\n",
      "Ep:64, loss:0.00004, loss_test:0.10616, lr:8.35e-03, fs:0.67033 (r=0.616,p=0.735),  time:31.703, tt:2060.709\n",
      "Ep:65, loss:0.00003, loss_test:0.10064, lr:8.26e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.701, tt:2092.263\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.10705, lr:8.26e-03, fs:0.70056 (r=0.626,p=0.795),  time:31.689, tt:2123.167\n",
      "Ep:67, loss:0.00003, loss_test:0.10573, lr:8.26e-03, fs:0.65455 (r=0.545,p=0.818),  time:31.673, tt:2153.778\n",
      "Ep:68, loss:0.00003, loss_test:0.10808, lr:8.26e-03, fs:0.70056 (r=0.626,p=0.795),  time:31.680, tt:2185.906\n",
      "Ep:69, loss:0.00003, loss_test:0.10069, lr:8.26e-03, fs:0.72727 (r=0.646,p=0.831),  time:31.659, tt:2216.136\n",
      "Ep:70, loss:0.00003, loss_test:0.10687, lr:8.26e-03, fs:0.68208 (r=0.596,p=0.797),  time:31.637, tt:2246.210\n",
      "Ep:71, loss:0.00003, loss_test:0.10570, lr:8.26e-03, fs:0.65476 (r=0.556,p=0.797),  time:31.638, tt:2277.931\n",
      "Ep:72, loss:0.00003, loss_test:0.10785, lr:8.26e-03, fs:0.65060 (r=0.545,p=0.806),  time:31.635, tt:2309.335\n",
      "Ep:73, loss:0.00003, loss_test:0.10460, lr:8.26e-03, fs:0.71264 (r=0.626,p=0.827),  time:31.612, tt:2339.275\n",
      "Ep:74, loss:0.00003, loss_test:0.10400, lr:8.26e-03, fs:0.72832 (r=0.636,p=0.851),  time:31.608, tt:2370.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00003, loss_test:0.11226, lr:8.26e-03, fs:0.63855 (r=0.535,p=0.791),  time:31.611, tt:2402.437\n",
      "Ep:76, loss:0.00003, loss_test:0.10772, lr:8.26e-03, fs:0.61250 (r=0.495,p=0.803),  time:31.606, tt:2433.672\n",
      "Ep:77, loss:0.00003, loss_test:0.10576, lr:8.18e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.611, tt:2465.620\n",
      "Ep:78, loss:0.00003, loss_test:0.11064, lr:8.10e-03, fs:0.62963 (r=0.515,p=0.810),  time:31.614, tt:2497.543\n",
      "Ep:79, loss:0.00002, loss_test:0.11034, lr:8.02e-03, fs:0.62112 (r=0.505,p=0.806),  time:31.624, tt:2529.919\n",
      "Ep:80, loss:0.00002, loss_test:0.10684, lr:7.94e-03, fs:0.71676 (r=0.626,p=0.838),  time:31.642, tt:2562.979\n",
      "Ep:81, loss:0.00002, loss_test:0.10492, lr:7.86e-03, fs:0.65409 (r=0.525,p=0.867),  time:31.652, tt:2595.440\n",
      "Ep:82, loss:0.00002, loss_test:0.11496, lr:7.78e-03, fs:0.58896 (r=0.485,p=0.750),  time:31.666, tt:2628.261\n",
      "Ep:83, loss:0.00003, loss_test:0.10310, lr:7.70e-03, fs:0.65806 (r=0.515,p=0.911),  time:31.665, tt:2659.835\n",
      "Ep:84, loss:0.00002, loss_test:0.10450, lr:7.62e-03, fs:0.62577 (r=0.515,p=0.797),  time:31.662, tt:2691.265\n",
      "Ep:85, loss:0.00002, loss_test:0.11209, lr:7.55e-03, fs:0.65806 (r=0.515,p=0.911),  time:31.661, tt:2722.869\n",
      "Ep:86, loss:0.00002, loss_test:0.10294, lr:7.47e-03, fs:0.67073 (r=0.556,p=0.846),  time:31.682, tt:2756.370\n",
      "Ep:87, loss:0.00002, loss_test:0.11493, lr:7.40e-03, fs:0.61146 (r=0.485,p=0.828),  time:31.677, tt:2787.590\n",
      "Ep:88, loss:0.00002, loss_test:0.10828, lr:7.32e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.674, tt:2818.978\n",
      "Ep:89, loss:0.00002, loss_test:0.11191, lr:7.25e-03, fs:0.61635 (r=0.495,p=0.817),  time:31.715, tt:2854.323\n",
      "Ep:90, loss:0.00002, loss_test:0.11844, lr:7.18e-03, fs:0.64935 (r=0.505,p=0.909),  time:31.753, tt:2889.536\n",
      "Ep:91, loss:0.00002, loss_test:0.10023, lr:7.11e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.789, tt:2924.589\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.11263, lr:7.11e-03, fs:0.64968 (r=0.515,p=0.879),  time:31.818, tt:2959.063\n",
      "Ep:93, loss:0.00002, loss_test:0.10818, lr:7.11e-03, fs:0.64968 (r=0.515,p=0.879),  time:31.852, tt:2994.103\n",
      "Ep:94, loss:0.00002, loss_test:0.09867, lr:7.11e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.882, tt:3028.774\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.11503, lr:7.11e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.906, tt:3063.021\n",
      "Ep:96, loss:0.00002, loss_test:0.11726, lr:7.11e-03, fs:0.62252 (r=0.475,p=0.904),  time:31.941, tt:3098.249\n",
      "Ep:97, loss:0.00002, loss_test:0.09255, lr:7.11e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.967, tt:3132.804\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00002, loss_test:0.11177, lr:7.11e-03, fs:0.61039 (r=0.475,p=0.855),  time:31.992, tt:3167.180\n",
      "Ep:99, loss:0.00002, loss_test:0.09947, lr:7.11e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.031, tt:3203.070\n",
      "Ep:100, loss:0.00002, loss_test:0.09810, lr:7.11e-03, fs:0.70440 (r=0.566,p=0.933),  time:32.055, tt:3237.597\n",
      "Ep:101, loss:0.00002, loss_test:0.11232, lr:7.11e-03, fs:0.61438 (r=0.475,p=0.870),  time:32.093, tt:3273.443\n",
      "Ep:102, loss:0.00001, loss_test:0.09807, lr:7.11e-03, fs:0.66234 (r=0.515,p=0.927),  time:32.134, tt:3309.760\n",
      "Ep:103, loss:0.00002, loss_test:0.10615, lr:7.11e-03, fs:0.61333 (r=0.465,p=0.902),  time:32.171, tt:3345.750\n",
      "Ep:104, loss:0.00001, loss_test:0.10092, lr:7.11e-03, fs:0.66667 (r=0.515,p=0.944),  time:32.191, tt:3380.007\n",
      "Ep:105, loss:0.00001, loss_test:0.10206, lr:7.11e-03, fs:0.66667 (r=0.515,p=0.944),  time:32.216, tt:3414.912\n",
      "Ep:106, loss:0.00001, loss_test:0.09986, lr:7.11e-03, fs:0.64901 (r=0.495,p=0.942),  time:32.243, tt:3449.952\n",
      "Ep:107, loss:0.00001, loss_test:0.10219, lr:7.11e-03, fs:0.65806 (r=0.515,p=0.911),  time:32.265, tt:3484.568\n",
      "Ep:108, loss:0.00001, loss_test:0.09588, lr:7.11e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.299, tt:3520.573\n",
      "Ep:109, loss:0.00001, loss_test:0.10337, lr:7.03e-03, fs:0.64000 (r=0.485,p=0.941),  time:32.327, tt:3555.985\n",
      "Ep:110, loss:0.00001, loss_test:0.09891, lr:6.96e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.372, tt:3593.329\n",
      "Ep:111, loss:0.00001, loss_test:0.10059, lr:6.89e-03, fs:0.63576 (r=0.485,p=0.923),  time:32.392, tt:3627.934\n",
      "Ep:112, loss:0.00001, loss_test:0.10826, lr:6.83e-03, fs:0.62162 (r=0.465,p=0.939),  time:32.415, tt:3662.846\n",
      "Ep:113, loss:0.00001, loss_test:0.10056, lr:6.76e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.448, tt:3699.092\n",
      "Ep:114, loss:0.00001, loss_test:0.10276, lr:6.69e-03, fs:0.63087 (r=0.475,p=0.940),  time:32.486, tt:3735.871\n",
      "Ep:115, loss:0.00001, loss_test:0.10413, lr:6.62e-03, fs:0.64000 (r=0.485,p=0.941),  time:32.507, tt:3770.863\n",
      "Ep:116, loss:0.00001, loss_test:0.09725, lr:6.56e-03, fs:0.67105 (r=0.515,p=0.962),  time:32.532, tt:3806.300\n",
      "Ep:117, loss:0.00001, loss_test:0.10131, lr:6.49e-03, fs:0.62667 (r=0.475,p=0.922),  time:32.564, tt:3842.512\n",
      "Ep:118, loss:0.00001, loss_test:0.10210, lr:6.43e-03, fs:0.66667 (r=0.515,p=0.944),  time:32.587, tt:3877.881\n",
      "Ep:119, loss:0.00001, loss_test:0.09722, lr:6.36e-03, fs:0.65333 (r=0.495,p=0.961),  time:32.613, tt:3913.614\n",
      "Ep:120, loss:0.00001, loss_test:0.09873, lr:6.30e-03, fs:0.67105 (r=0.515,p=0.962),  time:32.623, tt:3947.411\n",
      "Ep:121, loss:0.00001, loss_test:0.10439, lr:6.24e-03, fs:0.62162 (r=0.465,p=0.939),  time:32.646, tt:3982.832\n",
      "Ep:122, loss:0.00001, loss_test:0.10494, lr:6.17e-03, fs:0.64000 (r=0.485,p=0.941),  time:32.671, tt:4018.549\n",
      "Ep:123, loss:0.00001, loss_test:0.09701, lr:6.11e-03, fs:0.67105 (r=0.515,p=0.962),  time:32.702, tt:4055.011\n",
      "Ep:124, loss:0.00001, loss_test:0.10407, lr:6.05e-03, fs:0.63087 (r=0.475,p=0.940),  time:32.723, tt:4090.353\n",
      "Ep:125, loss:0.00001, loss_test:0.10166, lr:5.99e-03, fs:0.63514 (r=0.475,p=0.959),  time:32.746, tt:4125.962\n",
      "Ep:126, loss:0.00001, loss_test:0.09622, lr:5.93e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.770, tt:4161.788\n",
      "Ep:127, loss:0.00001, loss_test:0.11094, lr:5.87e-03, fs:0.62162 (r=0.465,p=0.939),  time:32.794, tt:4197.593\n",
      "Ep:128, loss:0.00001, loss_test:0.09504, lr:5.81e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.819, tt:4233.706\n",
      "Ep:129, loss:0.00001, loss_test:0.10924, lr:5.75e-03, fs:0.61745 (r=0.465,p=0.920),  time:32.837, tt:4268.815\n",
      "Ep:130, loss:0.00001, loss_test:0.09596, lr:5.70e-03, fs:0.68000 (r=0.515,p=1.000),  time:32.861, tt:4304.730\n",
      "Ep:131, loss:0.00001, loss_test:0.10307, lr:5.64e-03, fs:0.63946 (r=0.475,p=0.979),  time:32.879, tt:4340.041\n",
      "Ep:132, loss:0.00001, loss_test:0.10083, lr:5.58e-03, fs:0.66216 (r=0.495,p=1.000),  time:32.910, tt:4376.991\n",
      "Ep:133, loss:0.00001, loss_test:0.10317, lr:5.53e-03, fs:0.63014 (r=0.465,p=0.979),  time:32.928, tt:4412.306\n",
      "Ep:134, loss:0.00001, loss_test:0.09978, lr:5.47e-03, fs:0.66216 (r=0.495,p=1.000),  time:32.950, tt:4448.235\n",
      "Ep:135, loss:0.00001, loss_test:0.10461, lr:5.42e-03, fs:0.63448 (r=0.465,p=1.000),  time:32.977, tt:4484.835\n",
      "Ep:136, loss:0.00001, loss_test:0.09666, lr:5.36e-03, fs:0.65306 (r=0.485,p=1.000),  time:32.996, tt:4520.487\n",
      "Ep:137, loss:0.00001, loss_test:0.10136, lr:5.31e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.018, tt:4556.439\n",
      "Ep:138, loss:0.00001, loss_test:0.10075, lr:5.26e-03, fs:0.68000 (r=0.515,p=1.000),  time:33.043, tt:4592.998\n",
      "Ep:139, loss:0.00001, loss_test:0.10133, lr:5.20e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.076, tt:4630.644\n",
      "Ep:140, loss:0.00001, loss_test:0.10187, lr:5.15e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.093, tt:4666.108\n",
      "Ep:141, loss:0.00001, loss_test:0.10352, lr:5.10e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.119, tt:4702.965\n",
      "Ep:142, loss:0.00001, loss_test:0.10314, lr:5.05e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.138, tt:4738.745\n",
      "Ep:143, loss:0.00001, loss_test:0.10112, lr:5.00e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.154, tt:4774.233\n",
      "Ep:144, loss:0.00001, loss_test:0.10177, lr:4.95e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.173, tt:4810.073\n",
      "Ep:145, loss:0.00001, loss_test:0.10301, lr:4.90e-03, fs:0.65306 (r=0.485,p=1.000),  time:33.180, tt:4844.231\n",
      "Ep:146, loss:0.00001, loss_test:0.10125, lr:4.85e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.191, tt:4879.019\n",
      "Ep:147, loss:0.00001, loss_test:0.10232, lr:4.80e-03, fs:0.69281 (r=0.535,p=0.981),  time:33.206, tt:4914.510\n",
      "Ep:148, loss:0.00001, loss_test:0.10386, lr:4.75e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.225, tt:4950.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:149, loss:0.00001, loss_test:0.10703, lr:4.71e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.243, tt:4986.439\n",
      "Ep:150, loss:0.00001, loss_test:0.10308, lr:4.66e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.260, tt:5022.247\n",
      "Ep:151, loss:0.00001, loss_test:0.10570, lr:4.61e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.284, tt:5059.221\n",
      "Ep:152, loss:0.00000, loss_test:0.10169, lr:4.57e-03, fs:0.68000 (r=0.515,p=1.000),  time:33.298, tt:5094.591\n",
      "Ep:153, loss:0.00001, loss_test:0.10413, lr:4.52e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.327, tt:5132.404\n",
      "Ep:154, loss:0.00000, loss_test:0.10235, lr:4.48e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.346, tt:5168.590\n",
      "Ep:155, loss:0.00000, loss_test:0.10492, lr:4.43e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.368, tt:5205.406\n",
      "Ep:156, loss:0.00000, loss_test:0.10317, lr:4.39e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.382, tt:5241.009\n",
      "Ep:157, loss:0.00000, loss_test:0.10197, lr:4.34e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.405, tt:5277.915\n",
      "Ep:158, loss:0.00000, loss_test:0.10716, lr:4.30e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.424, tt:5314.438\n",
      "Ep:159, loss:0.00000, loss_test:0.09996, lr:4.26e-03, fs:0.68874 (r=0.525,p=1.000),  time:33.448, tt:5351.677\n",
      "Ep:160, loss:0.00000, loss_test:0.11097, lr:4.21e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.472, tt:5389.064\n",
      "Ep:161, loss:0.00000, loss_test:0.09959, lr:4.17e-03, fs:0.66216 (r=0.495,p=1.000),  time:33.500, tt:5427.001\n",
      "Ep:162, loss:0.00001, loss_test:0.11215, lr:4.13e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.522, tt:5464.046\n",
      "Ep:163, loss:0.00000, loss_test:0.10123, lr:4.09e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.536, tt:5499.869\n",
      "Ep:164, loss:0.00000, loss_test:0.11001, lr:4.05e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.559, tt:5537.160\n",
      "Ep:165, loss:0.00000, loss_test:0.09867, lr:4.01e-03, fs:0.68874 (r=0.525,p=1.000),  time:33.575, tt:5573.485\n",
      "Ep:166, loss:0.00000, loss_test:0.11432, lr:3.97e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.586, tt:5608.926\n",
      "Ep:167, loss:0.00000, loss_test:0.09959, lr:3.93e-03, fs:0.68000 (r=0.515,p=1.000),  time:33.608, tt:5646.194\n",
      "Ep:168, loss:0.00000, loss_test:0.11037, lr:3.89e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.626, tt:5682.857\n",
      "Ep:169, loss:0.00000, loss_test:0.10117, lr:3.85e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.644, tt:5719.532\n",
      "Ep:170, loss:0.00000, loss_test:0.10889, lr:3.81e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.664, tt:5756.460\n",
      "Ep:171, loss:0.00000, loss_test:0.10314, lr:3.77e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.676, tt:5792.358\n",
      "Ep:172, loss:0.00000, loss_test:0.10451, lr:3.73e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.702, tt:5830.486\n",
      "Ep:173, loss:0.00000, loss_test:0.10422, lr:3.70e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.714, tt:5866.270\n",
      "Ep:174, loss:0.00000, loss_test:0.10434, lr:3.66e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.728, tt:5902.394\n",
      "Ep:175, loss:0.00000, loss_test:0.10547, lr:3.62e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.754, tt:5940.762\n",
      "Ep:176, loss:0.00000, loss_test:0.10466, lr:3.59e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.773, tt:5977.817\n",
      "Ep:177, loss:0.00000, loss_test:0.10802, lr:3.55e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.787, tt:6014.118\n",
      "Ep:178, loss:0.00000, loss_test:0.10313, lr:3.52e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.805, tt:6051.154\n",
      "Ep:179, loss:0.00000, loss_test:0.10831, lr:3.48e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.824, tt:6088.374\n",
      "Ep:180, loss:0.00000, loss_test:0.10366, lr:3.45e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.841, tt:6125.186\n",
      "Ep:181, loss:0.00000, loss_test:0.10451, lr:3.41e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.852, tt:6161.080\n",
      "Ep:182, loss:0.00000, loss_test:0.10575, lr:3.38e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.869, tt:6198.016\n",
      "Ep:183, loss:0.00000, loss_test:0.10506, lr:3.34e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.887, tt:6235.202\n",
      "Ep:184, loss:0.00000, loss_test:0.10488, lr:3.31e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.896, tt:6270.831\n",
      "Ep:185, loss:0.00000, loss_test:0.10574, lr:3.28e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.904, tt:6306.131\n",
      "Ep:186, loss:0.00000, loss_test:0.10439, lr:3.24e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.909, tt:6340.941\n",
      "Ep:187, loss:0.00000, loss_test:0.10871, lr:3.21e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.927, tt:6378.245\n",
      "Ep:188, loss:0.00000, loss_test:0.10474, lr:3.18e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.942, tt:6415.010\n",
      "Ep:189, loss:0.00000, loss_test:0.10497, lr:3.15e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.951, tt:6450.651\n",
      "Ep:190, loss:0.00000, loss_test:0.10595, lr:3.12e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.963, tt:6487.016\n",
      "Ep:191, loss:0.00000, loss_test:0.10609, lr:3.09e-03, fs:0.64384 (r=0.475,p=1.000),  time:33.980, tt:6524.191\n",
      "Ep:192, loss:0.00000, loss_test:0.10844, lr:3.05e-03, fs:0.63448 (r=0.465,p=1.000),  time:33.991, tt:6560.195\n",
      "Ep:193, loss:0.00000, loss_test:0.10433, lr:3.02e-03, fs:0.64384 (r=0.475,p=1.000),  time:34.003, tt:6596.658\n",
      "Ep:194, loss:0.00000, loss_test:0.10688, lr:2.99e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.019, tt:6633.682\n",
      "Ep:195, loss:0.00000, loss_test:0.10424, lr:2.96e-03, fs:0.64384 (r=0.475,p=1.000),  time:34.035, tt:6670.938\n",
      "Ep:196, loss:0.00000, loss_test:0.10639, lr:2.93e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.051, tt:6708.137\n",
      "Ep:197, loss:0.00000, loss_test:0.10428, lr:2.90e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.065, tt:6744.816\n",
      "Ep:198, loss:0.00000, loss_test:0.10729, lr:2.88e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.081, tt:6782.184\n",
      "Ep:199, loss:0.00000, loss_test:0.10573, lr:2.85e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.090, tt:6817.934\n",
      "Ep:200, loss:0.00000, loss_test:0.10599, lr:2.82e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.097, tt:6853.439\n",
      "Ep:201, loss:0.00000, loss_test:0.10763, lr:2.79e-03, fs:0.64384 (r=0.475,p=1.000),  time:34.113, tt:6890.861\n",
      "Ep:202, loss:0.00000, loss_test:0.10482, lr:2.76e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.123, tt:6927.021\n",
      "Ep:203, loss:0.00000, loss_test:0.10790, lr:2.73e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.138, tt:6964.143\n",
      "Ep:204, loss:0.00000, loss_test:0.10471, lr:2.71e-03, fs:0.64384 (r=0.475,p=1.000),  time:34.130, tt:6996.621\n",
      "Ep:205, loss:0.00000, loss_test:0.10617, lr:2.68e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.094, tt:7023.391\n",
      "Ep:206, loss:0.00000, loss_test:0.10473, lr:2.65e-03, fs:0.63448 (r=0.465,p=1.000),  time:34.066, tt:7051.704\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.03201, lr:6.00e-02, fs:0.60550 (r=0.667,p=0.555),  time:28.116, tt:28.116\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02584, lr:6.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:30.156, tt:60.312\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02768, lr:6.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:31.942, tt:95.826\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02817, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:32.953, tt:131.812\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02822, lr:6.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:33.128, tt:165.641\n",
      "Ep:5, loss:0.00005, loss_test:0.02829, lr:6.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:33.523, tt:201.140\n",
      "Ep:6, loss:0.00005, loss_test:0.02882, lr:6.00e-02, fs:0.63602 (r=0.838,p=0.512),  time:33.807, tt:236.648\n",
      "Ep:7, loss:0.00005, loss_test:0.02944, lr:6.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:33.925, tt:271.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00005, loss_test:0.02985, lr:6.00e-02, fs:0.62400 (r=0.788,p=0.517),  time:34.113, tt:307.021\n",
      "Ep:9, loss:0.00005, loss_test:0.02966, lr:6.00e-02, fs:0.63158 (r=0.788,p=0.527),  time:34.266, tt:342.658\n",
      "Ep:10, loss:0.00005, loss_test:0.02863, lr:6.00e-02, fs:0.62651 (r=0.788,p=0.520),  time:34.420, tt:378.617\n",
      "Ep:11, loss:0.00005, loss_test:0.02768, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:34.468, tt:413.617\n",
      "Ep:12, loss:0.00005, loss_test:0.02687, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:34.535, tt:448.949\n",
      "Ep:13, loss:0.00005, loss_test:0.02633, lr:6.00e-02, fs:0.64591 (r=0.838,p=0.525),  time:34.588, tt:484.229\n",
      "Ep:14, loss:0.00005, loss_test:0.02596, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:34.602, tt:519.037\n",
      "Ep:15, loss:0.00005, loss_test:0.02580, lr:5.94e-02, fs:0.63710 (r=0.798,p=0.530),  time:34.695, tt:555.118\n",
      "Ep:16, loss:0.00004, loss_test:0.02588, lr:5.88e-02, fs:0.61983 (r=0.758,p=0.524),  time:34.824, tt:592.002\n",
      "Ep:17, loss:0.00004, loss_test:0.02596, lr:5.82e-02, fs:0.59072 (r=0.707,p=0.507),  time:34.784, tt:626.114\n",
      "Ep:18, loss:0.00004, loss_test:0.02588, lr:5.76e-02, fs:0.58120 (r=0.687,p=0.504),  time:34.831, tt:661.788\n",
      "Ep:19, loss:0.00004, loss_test:0.02559, lr:5.71e-02, fs:0.59574 (r=0.707,p=0.515),  time:34.874, tt:697.490\n",
      "Ep:20, loss:0.00004, loss_test:0.02551, lr:5.65e-02, fs:0.60086 (r=0.707,p=0.522),  time:34.883, tt:732.533\n",
      "Ep:21, loss:0.00004, loss_test:0.02551, lr:5.59e-02, fs:0.62447 (r=0.747,p=0.536),  time:34.888, tt:767.543\n",
      "Ep:22, loss:0.00004, loss_test:0.02557, lr:5.54e-02, fs:0.62447 (r=0.747,p=0.536),  time:34.885, tt:802.354\n",
      "Ep:23, loss:0.00004, loss_test:0.02558, lr:5.48e-02, fs:0.61277 (r=0.727,p=0.529),  time:34.914, tt:837.946\n",
      "Ep:24, loss:0.00004, loss_test:0.02550, lr:5.43e-02, fs:0.61207 (r=0.717,p=0.534),  time:34.934, tt:873.354\n",
      "Ep:25, loss:0.00004, loss_test:0.02522, lr:5.37e-02, fs:0.61472 (r=0.717,p=0.538),  time:34.986, tt:909.646\n",
      "Ep:26, loss:0.00004, loss_test:0.02484, lr:5.32e-02, fs:0.61207 (r=0.717,p=0.534),  time:35.057, tt:946.530\n",
      "Ep:27, loss:0.00004, loss_test:0.02445, lr:5.27e-02, fs:0.60944 (r=0.717,p=0.530),  time:35.093, tt:982.608\n",
      "Ep:28, loss:0.00004, loss_test:0.02419, lr:5.21e-02, fs:0.62338 (r=0.727,p=0.545),  time:35.077, tt:1017.224\n",
      "Ep:29, loss:0.00004, loss_test:0.02419, lr:5.16e-02, fs:0.61739 (r=0.717,p=0.542),  time:35.037, tt:1051.118\n",
      "Ep:30, loss:0.00004, loss_test:0.02418, lr:5.11e-02, fs:0.61739 (r=0.717,p=0.542),  time:35.065, tt:1087.000\n",
      "Ep:31, loss:0.00004, loss_test:0.02400, lr:5.06e-02, fs:0.60526 (r=0.697,p=0.535),  time:35.063, tt:1122.014\n",
      "Ep:32, loss:0.00004, loss_test:0.02372, lr:5.01e-02, fs:0.60793 (r=0.697,p=0.539),  time:35.099, tt:1158.262\n",
      "Ep:33, loss:0.00004, loss_test:0.02347, lr:4.96e-02, fs:0.59556 (r=0.677,p=0.532),  time:35.087, tt:1192.962\n",
      "Ep:34, loss:0.00004, loss_test:0.02322, lr:4.91e-02, fs:0.60444 (r=0.687,p=0.540),  time:35.119, tt:1229.153\n",
      "Ep:35, loss:0.00003, loss_test:0.02304, lr:4.86e-02, fs:0.60444 (r=0.687,p=0.540),  time:35.126, tt:1264.552\n",
      "Ep:36, loss:0.00003, loss_test:0.02276, lr:4.81e-02, fs:0.60444 (r=0.687,p=0.540),  time:35.135, tt:1300.004\n",
      "Ep:37, loss:0.00003, loss_test:0.02258, lr:4.76e-02, fs:0.60090 (r=0.677,p=0.540),  time:35.150, tt:1335.696\n",
      "Ep:38, loss:0.00003, loss_test:0.02239, lr:4.71e-02, fs:0.60360 (r=0.677,p=0.545),  time:35.127, tt:1369.944\n",
      "Ep:39, loss:0.00003, loss_test:0.02217, lr:4.67e-02, fs:0.60633 (r=0.677,p=0.549),  time:35.140, tt:1405.601\n",
      "Ep:40, loss:0.00003, loss_test:0.02192, lr:4.62e-02, fs:0.60633 (r=0.677,p=0.549),  time:35.164, tt:1441.723\n",
      "Ep:41, loss:0.00003, loss_test:0.02164, lr:4.57e-02, fs:0.61261 (r=0.687,p=0.553),  time:35.184, tt:1477.746\n",
      "Ep:42, loss:0.00003, loss_test:0.02149, lr:4.53e-02, fs:0.63111 (r=0.717,p=0.563),  time:35.148, tt:1511.358\n",
      "Ep:43, loss:0.00003, loss_test:0.02140, lr:4.48e-02, fs:0.62443 (r=0.697,p=0.566),  time:35.107, tt:1544.710\n",
      "Ep:44, loss:0.00003, loss_test:0.02118, lr:4.44e-02, fs:0.63063 (r=0.707,p=0.569),  time:35.095, tt:1579.264\n",
      "Ep:45, loss:0.00003, loss_test:0.02087, lr:4.39e-02, fs:0.63063 (r=0.707,p=0.569),  time:35.100, tt:1614.612\n",
      "Ep:46, loss:0.00003, loss_test:0.02076, lr:4.35e-02, fs:0.63677 (r=0.717,p=0.573),  time:35.072, tt:1648.361\n",
      "Ep:47, loss:0.00003, loss_test:0.02056, lr:4.31e-02, fs:0.65778 (r=0.747,p=0.587),  time:35.044, tt:1682.125\n",
      "Ep:48, loss:0.00003, loss_test:0.02047, lr:4.26e-02, fs:0.66063 (r=0.737,p=0.598),  time:35.044, tt:1717.145\n",
      "Ep:49, loss:0.00003, loss_test:0.02030, lr:4.22e-02, fs:0.66364 (r=0.737,p=0.603),  time:35.030, tt:1751.517\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.02004, lr:4.22e-02, fs:0.66364 (r=0.737,p=0.603),  time:35.013, tt:1785.650\n",
      "Ep:51, loss:0.00003, loss_test:0.01991, lr:4.22e-02, fs:0.66667 (r=0.737,p=0.608),  time:34.983, tt:1819.126\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.01986, lr:4.22e-02, fs:0.66667 (r=0.737,p=0.608),  time:34.967, tt:1853.231\n",
      "Ep:53, loss:0.00003, loss_test:0.01960, lr:4.22e-02, fs:0.68182 (r=0.758,p=0.620),  time:34.956, tt:1887.641\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.01949, lr:4.22e-02, fs:0.68182 (r=0.758,p=0.620),  time:34.932, tt:1921.258\n",
      "Ep:55, loss:0.00003, loss_test:0.01930, lr:4.22e-02, fs:0.69091 (r=0.768,p=0.628),  time:34.911, tt:1954.997\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.01924, lr:4.22e-02, fs:0.70000 (r=0.778,p=0.636),  time:34.925, tt:1990.738\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01910, lr:4.22e-02, fs:0.71171 (r=0.798,p=0.642),  time:34.937, tt:2026.350\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01888, lr:4.22e-02, fs:0.70588 (r=0.788,p=0.639),  time:34.913, tt:2059.877\n",
      "Ep:59, loss:0.00002, loss_test:0.01882, lr:4.22e-02, fs:0.70642 (r=0.778,p=0.647),  time:34.907, tt:2094.434\n",
      "Ep:60, loss:0.00002, loss_test:0.01890, lr:4.22e-02, fs:0.69484 (r=0.747,p=0.649),  time:34.895, tt:2128.592\n",
      "Ep:61, loss:0.00002, loss_test:0.01862, lr:4.22e-02, fs:0.71560 (r=0.788,p=0.655),  time:34.886, tt:2162.960\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01874, lr:4.22e-02, fs:0.71028 (r=0.768,p=0.661),  time:34.874, tt:2197.042\n",
      "Ep:63, loss:0.00002, loss_test:0.01852, lr:4.22e-02, fs:0.70755 (r=0.758,p=0.664),  time:34.886, tt:2232.678\n",
      "Ep:64, loss:0.00002, loss_test:0.01837, lr:4.22e-02, fs:0.72897 (r=0.788,p=0.678),  time:34.860, tt:2265.888\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01867, lr:4.22e-02, fs:0.70936 (r=0.727,p=0.692),  time:34.842, tt:2299.605\n",
      "Ep:66, loss:0.00002, loss_test:0.01857, lr:4.22e-02, fs:0.70244 (r=0.727,p=0.679),  time:34.823, tt:2333.117\n",
      "Ep:67, loss:0.00002, loss_test:0.01820, lr:4.22e-02, fs:0.72381 (r=0.768,p=0.685),  time:34.821, tt:2367.811\n",
      "Ep:68, loss:0.00002, loss_test:0.01831, lr:4.22e-02, fs:0.71287 (r=0.727,p=0.699),  time:34.825, tt:2402.933\n",
      "Ep:69, loss:0.00002, loss_test:0.01804, lr:4.22e-02, fs:0.71845 (r=0.747,p=0.692),  time:34.805, tt:2436.343\n",
      "Ep:70, loss:0.00002, loss_test:0.01801, lr:4.22e-02, fs:0.73684 (r=0.778,p=0.700),  time:34.805, tt:2471.167\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.01834, lr:4.22e-02, fs:0.71845 (r=0.747,p=0.692),  time:34.791, tt:2504.918\n",
      "Ep:72, loss:0.00002, loss_test:0.01817, lr:4.22e-02, fs:0.71845 (r=0.747,p=0.692),  time:34.796, tt:2540.116\n",
      "Ep:73, loss:0.00002, loss_test:0.01833, lr:4.22e-02, fs:0.72195 (r=0.747,p=0.698),  time:34.797, tt:2574.952\n",
      "Ep:74, loss:0.00002, loss_test:0.01890, lr:4.22e-02, fs:0.69036 (r=0.687,p=0.694),  time:34.787, tt:2609.008\n",
      "Ep:75, loss:0.00002, loss_test:0.01841, lr:4.22e-02, fs:0.73430 (r=0.768,p=0.704),  time:34.797, tt:2644.601\n",
      "Ep:76, loss:0.00002, loss_test:0.01878, lr:4.22e-02, fs:0.69697 (r=0.697,p=0.697),  time:34.790, tt:2678.817\n",
      "Ep:77, loss:0.00002, loss_test:0.01868, lr:4.22e-02, fs:0.70352 (r=0.707,p=0.700),  time:34.765, tt:2711.688\n",
      "Ep:78, loss:0.00002, loss_test:0.01888, lr:4.22e-02, fs:0.70051 (r=0.697,p=0.704),  time:34.773, tt:2747.102\n",
      "Ep:79, loss:0.00002, loss_test:0.01863, lr:4.22e-02, fs:0.70352 (r=0.707,p=0.700),  time:34.754, tt:2780.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00002, loss_test:0.01933, lr:4.22e-02, fs:0.69430 (r=0.677,p=0.713),  time:34.749, tt:2814.660\n",
      "Ep:81, loss:0.00002, loss_test:0.01836, lr:4.22e-02, fs:0.73529 (r=0.758,p=0.714),  time:34.764, tt:2850.640\n",
      "Ep:82, loss:0.00002, loss_test:0.01979, lr:4.18e-02, fs:0.68421 (r=0.657,p=0.714),  time:34.749, tt:2884.180\n",
      "Ep:83, loss:0.00002, loss_test:0.01892, lr:4.14e-02, fs:0.67347 (r=0.667,p=0.680),  time:34.705, tt:2915.260\n",
      "Ep:84, loss:0.00001, loss_test:0.02006, lr:4.10e-02, fs:0.61111 (r=0.556,p=0.679),  time:34.685, tt:2948.264\n",
      "Ep:85, loss:0.00001, loss_test:0.01900, lr:4.05e-02, fs:0.68394 (r=0.667,p=0.702),  time:34.690, tt:2983.357\n",
      "Ep:86, loss:0.00001, loss_test:0.02010, lr:4.01e-02, fs:0.62222 (r=0.566,p=0.691),  time:34.682, tt:3017.317\n",
      "Ep:87, loss:0.00001, loss_test:0.01927, lr:3.97e-02, fs:0.69110 (r=0.667,p=0.717),  time:34.669, tt:3050.911\n",
      "Ep:88, loss:0.00001, loss_test:0.02042, lr:3.93e-02, fs:0.63687 (r=0.576,p=0.713),  time:34.668, tt:3085.458\n",
      "Ep:89, loss:0.00001, loss_test:0.01945, lr:3.89e-02, fs:0.68750 (r=0.667,p=0.710),  time:34.665, tt:3119.881\n",
      "Ep:90, loss:0.00001, loss_test:0.02187, lr:3.86e-02, fs:0.61714 (r=0.545,p=0.711),  time:34.660, tt:3154.015\n",
      "Ep:91, loss:0.00001, loss_test:0.01969, lr:3.82e-02, fs:0.69744 (r=0.687,p=0.708),  time:34.641, tt:3186.986\n",
      "Ep:92, loss:0.00001, loss_test:0.02180, lr:3.78e-02, fs:0.60920 (r=0.535,p=0.707),  time:34.637, tt:3221.258\n",
      "Ep:93, loss:0.00001, loss_test:0.01984, lr:3.74e-02, fs:0.68063 (r=0.657,p=0.707),  time:34.642, tt:3256.311\n",
      "Ep:94, loss:0.00001, loss_test:0.02178, lr:3.70e-02, fs:0.62500 (r=0.556,p=0.714),  time:34.630, tt:3289.895\n",
      "Ep:95, loss:0.00001, loss_test:0.02014, lr:3.67e-02, fs:0.63333 (r=0.576,p=0.704),  time:34.638, tt:3325.292\n",
      "Ep:96, loss:0.00001, loss_test:0.02155, lr:3.63e-02, fs:0.61878 (r=0.566,p=0.683),  time:34.630, tt:3359.104\n",
      "Ep:97, loss:0.00001, loss_test:0.02129, lr:3.59e-02, fs:0.61714 (r=0.545,p=0.711),  time:34.613, tt:3392.033\n",
      "Ep:98, loss:0.00001, loss_test:0.02098, lr:3.56e-02, fs:0.60571 (r=0.535,p=0.697),  time:34.607, tt:3426.089\n",
      "Ep:99, loss:0.00001, loss_test:0.02069, lr:3.52e-02, fs:0.61111 (r=0.556,p=0.679),  time:34.594, tt:3459.438\n",
      "Ep:100, loss:0.00001, loss_test:0.02322, lr:3.49e-02, fs:0.60227 (r=0.535,p=0.688),  time:34.595, tt:3494.100\n",
      "Ep:101, loss:0.00001, loss_test:0.02156, lr:3.45e-02, fs:0.61957 (r=0.576,p=0.671),  time:34.580, tt:3527.182\n",
      "Ep:102, loss:0.00001, loss_test:0.02310, lr:3.42e-02, fs:0.59429 (r=0.525,p=0.684),  time:34.568, tt:3560.516\n",
      "Ep:103, loss:0.00001, loss_test:0.02115, lr:3.38e-02, fs:0.60000 (r=0.545,p=0.667),  time:34.550, tt:3593.165\n",
      "Ep:104, loss:0.00001, loss_test:0.02237, lr:3.35e-02, fs:0.60465 (r=0.525,p=0.712),  time:34.537, tt:3626.369\n",
      "Ep:105, loss:0.00001, loss_test:0.02103, lr:3.32e-02, fs:0.59429 (r=0.525,p=0.684),  time:34.530, tt:3660.170\n",
      "Ep:106, loss:0.00001, loss_test:0.02266, lr:3.28e-02, fs:0.60227 (r=0.535,p=0.688),  time:34.512, tt:3692.822\n",
      "Ep:107, loss:0.00001, loss_test:0.02112, lr:3.25e-02, fs:0.59887 (r=0.535,p=0.679),  time:34.499, tt:3725.924\n",
      "Ep:108, loss:0.00001, loss_test:0.02322, lr:3.22e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.489, tt:3759.249\n",
      "Ep:109, loss:0.00001, loss_test:0.02193, lr:3.19e-02, fs:0.60227 (r=0.535,p=0.688),  time:34.466, tt:3791.288\n",
      "Ep:110, loss:0.00001, loss_test:0.02307, lr:3.15e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.464, tt:3825.504\n",
      "Ep:111, loss:0.00001, loss_test:0.02279, lr:3.12e-02, fs:0.60571 (r=0.535,p=0.697),  time:34.460, tt:3859.538\n",
      "Ep:112, loss:0.00001, loss_test:0.02291, lr:3.09e-02, fs:0.60116 (r=0.525,p=0.703),  time:34.456, tt:3893.480\n",
      "Ep:113, loss:0.00001, loss_test:0.02343, lr:3.06e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.471, tt:3929.642\n",
      "Ep:114, loss:0.00001, loss_test:0.02345, lr:3.03e-02, fs:0.60465 (r=0.525,p=0.712),  time:34.474, tt:3964.553\n",
      "Ep:115, loss:0.00001, loss_test:0.02336, lr:3.00e-02, fs:0.61272 (r=0.535,p=0.716),  time:34.474, tt:3999.011\n",
      "Ep:116, loss:0.00001, loss_test:0.02343, lr:2.97e-02, fs:0.60465 (r=0.525,p=0.712),  time:34.460, tt:4031.787\n",
      "Ep:117, loss:0.00001, loss_test:0.02409, lr:2.94e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.477, tt:4068.337\n",
      "Ep:118, loss:0.00001, loss_test:0.02242, lr:2.91e-02, fs:0.60920 (r=0.535,p=0.707),  time:34.482, tt:4103.325\n",
      "Ep:119, loss:0.00001, loss_test:0.02648, lr:2.88e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.471, tt:4136.508\n",
      "Ep:120, loss:0.00001, loss_test:0.02413, lr:2.85e-02, fs:0.60116 (r=0.525,p=0.703),  time:34.480, tt:4172.124\n",
      "Ep:121, loss:0.00001, loss_test:0.02541, lr:2.82e-02, fs:0.60465 (r=0.525,p=0.712),  time:34.469, tt:4205.273\n",
      "Ep:122, loss:0.00001, loss_test:0.02298, lr:2.80e-02, fs:0.60227 (r=0.535,p=0.688),  time:34.473, tt:4240.137\n",
      "Ep:123, loss:0.00001, loss_test:0.02505, lr:2.77e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.465, tt:4273.681\n",
      "Ep:124, loss:0.00001, loss_test:0.02193, lr:2.74e-02, fs:0.61714 (r=0.545,p=0.711),  time:34.468, tt:4308.486\n",
      "Ep:125, loss:0.00001, loss_test:0.02565, lr:2.71e-02, fs:0.61538 (r=0.525,p=0.743),  time:34.466, tt:4342.741\n",
      "Ep:126, loss:0.00001, loss_test:0.02251, lr:2.69e-02, fs:0.60920 (r=0.535,p=0.707),  time:34.462, tt:4376.655\n",
      "Ep:127, loss:0.00001, loss_test:0.02509, lr:2.66e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.463, tt:4411.204\n",
      "Ep:128, loss:0.00001, loss_test:0.02371, lr:2.63e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.452, tt:4444.357\n",
      "Ep:129, loss:0.00001, loss_test:0.02504, lr:2.61e-02, fs:0.61176 (r=0.525,p=0.732),  time:34.449, tt:4478.433\n",
      "Ep:130, loss:0.00001, loss_test:0.02336, lr:2.58e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.443, tt:4512.090\n",
      "Ep:131, loss:0.00001, loss_test:0.02647, lr:2.55e-02, fs:0.61176 (r=0.525,p=0.732),  time:34.440, tt:4546.061\n",
      "Ep:132, loss:0.00001, loss_test:0.02449, lr:2.53e-02, fs:0.60116 (r=0.525,p=0.703),  time:34.432, tt:4579.406\n",
      "Ep:133, loss:0.00001, loss_test:0.02641, lr:2.50e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.445, tt:4615.569\n",
      "Ep:134, loss:0.00001, loss_test:0.02439, lr:2.48e-02, fs:0.60819 (r=0.525,p=0.722),  time:34.458, tt:4651.863\n",
      "Ep:135, loss:0.00001, loss_test:0.02705, lr:2.45e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.461, tt:4686.692\n",
      "Ep:136, loss:0.00001, loss_test:0.02488, lr:2.43e-02, fs:0.59649 (r=0.515,p=0.708),  time:34.458, tt:4720.708\n",
      "Ep:137, loss:0.00001, loss_test:0.02676, lr:2.40e-02, fs:0.60000 (r=0.515,p=0.718),  time:34.454, tt:4754.616\n",
      "Ep:138, loss:0.00001, loss_test:0.02623, lr:2.38e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.455, tt:4789.304\n",
      "Ep:139, loss:0.00001, loss_test:0.02628, lr:2.36e-02, fs:0.60000 (r=0.515,p=0.718),  time:34.467, tt:4825.407\n",
      "Ep:140, loss:0.00001, loss_test:0.02662, lr:2.33e-02, fs:0.60000 (r=0.515,p=0.718),  time:34.474, tt:4860.810\n",
      "Ep:141, loss:0.00001, loss_test:0.02694, lr:2.31e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.480, tt:4896.174\n",
      "Ep:142, loss:0.00001, loss_test:0.02670, lr:2.29e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.489, tt:4931.901\n",
      "Ep:143, loss:0.00001, loss_test:0.02628, lr:2.26e-02, fs:0.60000 (r=0.515,p=0.718),  time:34.494, tt:4967.201\n",
      "Ep:144, loss:0.00001, loss_test:0.02766, lr:2.24e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.499, tt:5002.321\n",
      "Ep:145, loss:0.00001, loss_test:0.02656, lr:2.22e-02, fs:0.59649 (r=0.515,p=0.708),  time:34.501, tt:5037.167\n",
      "Ep:146, loss:0.00001, loss_test:0.02803, lr:2.20e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.503, tt:5071.979\n",
      "Ep:147, loss:0.00001, loss_test:0.02631, lr:2.17e-02, fs:0.61176 (r=0.525,p=0.732),  time:34.503, tt:5106.399\n",
      "Ep:148, loss:0.00001, loss_test:0.02789, lr:2.15e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.497, tt:5140.043\n",
      "Ep:149, loss:0.00000, loss_test:0.02649, lr:2.13e-02, fs:0.61905 (r=0.525,p=0.754),  time:34.491, tt:5173.679\n",
      "Ep:150, loss:0.00001, loss_test:0.02785, lr:2.11e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.491, tt:5208.132\n",
      "Ep:151, loss:0.00000, loss_test:0.02662, lr:2.09e-02, fs:0.60000 (r=0.515,p=0.718),  time:34.492, tt:5242.771\n",
      "Ep:152, loss:0.00000, loss_test:0.02842, lr:2.07e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.491, tt:5277.151\n",
      "Ep:153, loss:0.00000, loss_test:0.02735, lr:2.05e-02, fs:0.60000 (r=0.515,p=0.718),  time:34.487, tt:5311.013\n",
      "Ep:154, loss:0.00000, loss_test:0.02880, lr:2.03e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.495, tt:5346.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.02761, lr:2.01e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.501, tt:5382.231\n",
      "Ep:156, loss:0.00000, loss_test:0.02878, lr:1.99e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.509, tt:5417.975\n",
      "Ep:157, loss:0.00000, loss_test:0.02806, lr:1.97e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.510, tt:5452.529\n",
      "Ep:158, loss:0.00000, loss_test:0.02828, lr:1.95e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.517, tt:5488.201\n",
      "Ep:159, loss:0.00000, loss_test:0.02810, lr:1.93e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.528, tt:5524.404\n",
      "Ep:160, loss:0.00000, loss_test:0.02900, lr:1.91e-02, fs:0.61905 (r=0.525,p=0.754),  time:34.529, tt:5559.104\n",
      "Ep:161, loss:0.00000, loss_test:0.02826, lr:1.89e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.532, tt:5594.105\n",
      "Ep:162, loss:0.00000, loss_test:0.02906, lr:1.87e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.535, tt:5629.204\n",
      "Ep:163, loss:0.00000, loss_test:0.02851, lr:1.85e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.538, tt:5664.218\n",
      "Ep:164, loss:0.00000, loss_test:0.02948, lr:1.83e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.539, tt:5698.994\n",
      "Ep:165, loss:0.00000, loss_test:0.02857, lr:1.81e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.542, tt:5733.937\n",
      "Ep:166, loss:0.00000, loss_test:0.02972, lr:1.80e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.551, tt:5769.976\n",
      "Ep:167, loss:0.00000, loss_test:0.02873, lr:1.78e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.556, tt:5805.365\n",
      "Ep:168, loss:0.00000, loss_test:0.02984, lr:1.76e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.547, tt:5838.498\n",
      "Ep:169, loss:0.00000, loss_test:0.02929, lr:1.74e-02, fs:0.60355 (r=0.515,p=0.729),  time:34.549, tt:5873.386\n",
      "Ep:170, loss:0.00000, loss_test:0.03027, lr:1.73e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.556, tt:5909.074\n",
      "Ep:171, loss:0.00000, loss_test:0.02904, lr:1.71e-02, fs:0.60714 (r=0.515,p=0.739),  time:34.557, tt:5943.767\n",
      "Ep:172, loss:0.00000, loss_test:0.02923, lr:1.69e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.560, tt:5978.882\n",
      "Ep:173, loss:0.00000, loss_test:0.02983, lr:1.67e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.550, tt:6011.786\n",
      "Ep:174, loss:0.00000, loss_test:0.02994, lr:1.66e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.551, tt:6046.435\n",
      "Ep:175, loss:0.00000, loss_test:0.02974, lr:1.64e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.550, tt:6080.756\n",
      "Ep:176, loss:0.00000, loss_test:0.02985, lr:1.62e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.538, tt:6113.205\n",
      "Ep:177, loss:0.00000, loss_test:0.02971, lr:1.61e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.533, tt:6146.825\n",
      "Ep:178, loss:0.00000, loss_test:0.03033, lr:1.59e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.534, tt:6181.669\n",
      "Ep:179, loss:0.00000, loss_test:0.03037, lr:1.58e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.527, tt:6214.864\n",
      "Ep:180, loss:0.00000, loss_test:0.03061, lr:1.56e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.543, tt:6252.228\n",
      "Ep:181, loss:0.00000, loss_test:0.03067, lr:1.54e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.538, tt:6286.007\n",
      "Ep:182, loss:0.00000, loss_test:0.03088, lr:1.53e-02, fs:0.61446 (r=0.515,p=0.761),  time:34.537, tt:6320.251\n",
      "Ep:183, loss:0.00000, loss_test:0.03125, lr:1.51e-02, fs:0.61818 (r=0.515,p=0.773),  time:34.529, tt:6353.255\n",
      "Ep:184, loss:0.00000, loss_test:0.03092, lr:1.50e-02, fs:0.61078 (r=0.515,p=0.750),  time:34.527, tt:6387.568\n",
      "Ep:185, loss:0.00000, loss_test:0.03124, lr:1.48e-02, fs:0.61818 (r=0.515,p=0.773),  time:34.522, tt:6421.052\n",
      "Ep:186, loss:0.00000, loss_test:0.03127, lr:1.47e-02, fs:0.60241 (r=0.505,p=0.746),  time:34.518, tt:6454.934\n",
      "Ep:187, loss:0.00000, loss_test:0.03169, lr:1.45e-02, fs:0.60976 (r=0.505,p=0.769),  time:34.512, tt:6488.173\n",
      "Ep:188, loss:0.00000, loss_test:0.03146, lr:1.44e-02, fs:0.60606 (r=0.505,p=0.758),  time:34.500, tt:6520.417\n",
      "Ep:189, loss:0.00000, loss_test:0.03163, lr:1.43e-02, fs:0.60976 (r=0.505,p=0.769),  time:34.500, tt:6555.029\n",
      "Ep:190, loss:0.00000, loss_test:0.03152, lr:1.41e-02, fs:0.60976 (r=0.505,p=0.769),  time:34.494, tt:6588.347\n",
      "Ep:191, loss:0.00000, loss_test:0.03172, lr:1.40e-02, fs:0.60606 (r=0.505,p=0.758),  time:34.496, tt:6623.139\n",
      "Ep:192, loss:0.00000, loss_test:0.03223, lr:1.38e-02, fs:0.60976 (r=0.505,p=0.769),  time:34.493, tt:6657.196\n",
      "Ep:193, loss:0.00000, loss_test:0.03206, lr:1.37e-02, fs:0.59756 (r=0.495,p=0.754),  time:34.488, tt:6690.646\n",
      "Ep:194, loss:0.00000, loss_test:0.03208, lr:1.36e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.484, tt:6724.293\n",
      "Ep:195, loss:0.00000, loss_test:0.03257, lr:1.34e-02, fs:0.60976 (r=0.505,p=0.769),  time:34.483, tt:6758.757\n",
      "Ep:196, loss:0.00000, loss_test:0.03231, lr:1.33e-02, fs:0.59756 (r=0.495,p=0.754),  time:34.481, tt:6792.823\n",
      "Ep:197, loss:0.00000, loss_test:0.03266, lr:1.32e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.478, tt:6826.576\n",
      "Ep:198, loss:0.00000, loss_test:0.03262, lr:1.30e-02, fs:0.60123 (r=0.495,p=0.766),  time:34.477, tt:6860.895\n",
      "Ep:199, loss:0.00000, loss_test:0.03292, lr:1.29e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.471, tt:6894.115\n",
      "Ep:200, loss:0.00000, loss_test:0.03273, lr:1.28e-02, fs:0.58896 (r=0.485,p=0.750),  time:34.461, tt:6926.598\n",
      "Ep:201, loss:0.00000, loss_test:0.03272, lr:1.26e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.458, tt:6960.417\n",
      "Ep:202, loss:0.00000, loss_test:0.03282, lr:1.25e-02, fs:0.58896 (r=0.485,p=0.750),  time:34.450, tt:6993.322\n",
      "Ep:203, loss:0.00000, loss_test:0.03358, lr:1.24e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.440, tt:7025.688\n",
      "Ep:204, loss:0.00000, loss_test:0.03247, lr:1.23e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.432, tt:7058.560\n",
      "Ep:205, loss:0.00000, loss_test:0.03348, lr:1.21e-02, fs:0.60000 (r=0.485,p=0.787),  time:34.430, tt:7092.483\n",
      "Ep:206, loss:0.00000, loss_test:0.03299, lr:1.20e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.425, tt:7126.039\n",
      "Ep:207, loss:0.00000, loss_test:0.03362, lr:1.19e-02, fs:0.60377 (r=0.485,p=0.800),  time:34.416, tt:7158.456\n",
      "Ep:208, loss:0.00000, loss_test:0.03291, lr:1.18e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.412, tt:7192.011\n",
      "Ep:209, loss:0.00000, loss_test:0.03358, lr:1.17e-02, fs:0.60000 (r=0.485,p=0.787),  time:34.397, tt:7223.441\n",
      "Ep:210, loss:0.00000, loss_test:0.03368, lr:1.15e-02, fs:0.60494 (r=0.495,p=0.778),  time:34.369, tt:7251.791\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13307, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:30.759, tt:30.759\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13243, lr:1.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:28.958, tt:57.915\n",
      "Ep:2, loss:0.00026, loss_test:0.13289, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:29.801, tt:89.403\n",
      "Ep:3, loss:0.00026, loss_test:0.13371, lr:1.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:30.520, tt:122.079\n",
      "Ep:4, loss:0.00025, loss_test:0.13397, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:31.301, tt:156.507\n",
      "Ep:5, loss:0.00025, loss_test:0.13362, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:31.788, tt:190.729\n",
      "Ep:6, loss:0.00025, loss_test:0.13255, lr:1.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:32.136, tt:224.951\n",
      "Ep:7, loss:0.00025, loss_test:0.13115, lr:1.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:32.453, tt:259.622\n",
      "Ep:8, loss:0.00025, loss_test:0.12995, lr:1.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:33.230, tt:299.070\n",
      "Ep:9, loss:0.00025, loss_test:0.12882, lr:1.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:33.282, tt:332.815\n",
      "Ep:10, loss:0.00024, loss_test:0.12810, lr:1.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:33.356, tt:366.915\n",
      "Ep:11, loss:0.00024, loss_test:0.12687, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:33.516, tt:402.190\n",
      "Ep:12, loss:0.00024, loss_test:0.12617, lr:9.90e-03, fs:0.66667 (r=0.808,p=0.567),  time:33.677, tt:437.805\n",
      "Ep:13, loss:0.00024, loss_test:0.12577, lr:9.80e-03, fs:0.66116 (r=0.808,p=0.559),  time:33.726, tt:472.159\n",
      "Ep:14, loss:0.00023, loss_test:0.12481, lr:9.70e-03, fs:0.66116 (r=0.808,p=0.559),  time:33.793, tt:506.899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00023, loss_test:0.12319, lr:9.61e-03, fs:0.66949 (r=0.798,p=0.577),  time:33.906, tt:542.498\n",
      "Ep:16, loss:0.00023, loss_test:0.12210, lr:9.51e-03, fs:0.67797 (r=0.808,p=0.584),  time:33.902, tt:576.330\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.12162, lr:9.51e-03, fs:0.68067 (r=0.818,p=0.583),  time:34.043, tt:612.782\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.12054, lr:9.51e-03, fs:0.68085 (r=0.808,p=0.588),  time:34.158, tt:648.998\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.11935, lr:9.51e-03, fs:0.66953 (r=0.788,p=0.582),  time:34.268, tt:685.366\n",
      "Ep:20, loss:0.00021, loss_test:0.11861, lr:9.51e-03, fs:0.66087 (r=0.768,p=0.580),  time:34.292, tt:720.140\n",
      "Ep:21, loss:0.00021, loss_test:0.11703, lr:9.51e-03, fs:0.65158 (r=0.727,p=0.590),  time:34.273, tt:754.004\n",
      "Ep:22, loss:0.00020, loss_test:0.11642, lr:9.51e-03, fs:0.64574 (r=0.727,p=0.581),  time:34.314, tt:789.223\n",
      "Ep:23, loss:0.00020, loss_test:0.11419, lr:9.51e-03, fs:0.60287 (r=0.636,p=0.573),  time:34.321, tt:823.711\n",
      "Ep:24, loss:0.00019, loss_test:0.11324, lr:9.51e-03, fs:0.62500 (r=0.657,p=0.596),  time:34.315, tt:857.871\n",
      "Ep:25, loss:0.00019, loss_test:0.11243, lr:9.51e-03, fs:0.63415 (r=0.657,p=0.613),  time:34.303, tt:891.879\n",
      "Ep:26, loss:0.00019, loss_test:0.11036, lr:9.51e-03, fs:0.63959 (r=0.636,p=0.643),  time:34.250, tt:924.751\n",
      "Ep:27, loss:0.00018, loss_test:0.11141, lr:9.51e-03, fs:0.64789 (r=0.697,p=0.605),  time:34.293, tt:960.191\n",
      "Ep:28, loss:0.00018, loss_test:0.10692, lr:9.51e-03, fs:0.65957 (r=0.626,p=0.697),  time:34.282, tt:994.178\n",
      "Ep:29, loss:0.00017, loss_test:0.10704, lr:9.51e-03, fs:0.68317 (r=0.697,p=0.670),  time:34.325, tt:1029.742\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.10315, lr:9.51e-03, fs:0.67016 (r=0.646,p=0.696),  time:34.276, tt:1062.550\n",
      "Ep:31, loss:0.00016, loss_test:0.10121, lr:9.51e-03, fs:0.66310 (r=0.626,p=0.705),  time:34.263, tt:1096.404\n",
      "Ep:32, loss:0.00016, loss_test:0.09925, lr:9.51e-03, fs:0.69110 (r=0.667,p=0.717),  time:34.443, tt:1136.633\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.10700, lr:9.51e-03, fs:0.72558 (r=0.788,p=0.672),  time:34.438, tt:1170.879\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.10042, lr:9.51e-03, fs:0.69474 (r=0.667,p=0.725),  time:34.417, tt:1204.612\n",
      "Ep:35, loss:0.00015, loss_test:0.10282, lr:9.51e-03, fs:0.74178 (r=0.798,p=0.693),  time:34.421, tt:1239.142\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.09709, lr:9.51e-03, fs:0.74257 (r=0.758,p=0.728),  time:34.416, tt:1273.385\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00013, loss_test:0.09609, lr:9.51e-03, fs:0.74227 (r=0.727,p=0.758),  time:34.437, tt:1308.617\n",
      "Ep:38, loss:0.00013, loss_test:0.10055, lr:9.51e-03, fs:0.75701 (r=0.818,p=0.704),  time:34.452, tt:1343.645\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.09852, lr:9.51e-03, fs:0.76018 (r=0.848,p=0.689),  time:34.460, tt:1378.416\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00012, loss_test:0.09788, lr:9.51e-03, fs:0.73514 (r=0.687,p=0.791),  time:34.474, tt:1413.447\n",
      "Ep:41, loss:0.00013, loss_test:0.09298, lr:9.51e-03, fs:0.75829 (r=0.808,p=0.714),  time:34.527, tt:1450.143\n",
      "Ep:42, loss:0.00012, loss_test:0.09431, lr:9.51e-03, fs:0.77833 (r=0.798,p=0.760),  time:34.524, tt:1484.535\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.08806, lr:9.51e-03, fs:0.78431 (r=0.808,p=0.762),  time:34.557, tt:1520.522\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.09137, lr:9.51e-03, fs:0.76142 (r=0.758,p=0.765),  time:34.524, tt:1553.558\n",
      "Ep:45, loss:0.00010, loss_test:0.08786, lr:9.51e-03, fs:0.77209 (r=0.838,p=0.716),  time:34.550, tt:1589.316\n",
      "Ep:46, loss:0.00010, loss_test:0.09001, lr:9.51e-03, fs:0.74074 (r=0.707,p=0.778),  time:34.534, tt:1623.080\n",
      "Ep:47, loss:0.00009, loss_test:0.08882, lr:9.51e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.472, tt:1654.680\n",
      "Ep:48, loss:0.00010, loss_test:0.09701, lr:9.51e-03, fs:0.75510 (r=0.747,p=0.763),  time:34.455, tt:1688.292\n",
      "Ep:49, loss:0.00011, loss_test:0.11423, lr:9.51e-03, fs:0.70042 (r=0.838,p=0.601),  time:34.467, tt:1723.366\n",
      "Ep:50, loss:0.00012, loss_test:0.09483, lr:9.51e-03, fs:0.73737 (r=0.737,p=0.737),  time:34.439, tt:1756.403\n",
      "Ep:51, loss:0.00010, loss_test:0.10326, lr:9.51e-03, fs:0.71111 (r=0.808,p=0.635),  time:34.472, tt:1792.526\n",
      "Ep:52, loss:0.00010, loss_test:0.09066, lr:9.51e-03, fs:0.70787 (r=0.636,p=0.797),  time:34.449, tt:1825.779\n",
      "Ep:53, loss:0.00009, loss_test:0.09127, lr:9.51e-03, fs:0.72449 (r=0.717,p=0.732),  time:34.458, tt:1860.756\n",
      "Ep:54, loss:0.00008, loss_test:0.08836, lr:9.51e-03, fs:0.79412 (r=0.818,p=0.771),  time:34.440, tt:1894.207\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.09077, lr:9.51e-03, fs:0.75897 (r=0.747,p=0.771),  time:34.431, tt:1928.143\n",
      "Ep:56, loss:0.00008, loss_test:0.09095, lr:9.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:34.435, tt:1962.780\n",
      "Ep:57, loss:0.00007, loss_test:0.09453, lr:9.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:34.451, tt:1998.157\n",
      "Ep:58, loss:0.00007, loss_test:0.09679, lr:9.51e-03, fs:0.72432 (r=0.677,p=0.779),  time:34.440, tt:2031.970\n",
      "Ep:59, loss:0.00006, loss_test:0.09010, lr:9.51e-03, fs:0.78607 (r=0.798,p=0.775),  time:34.458, tt:2067.478\n",
      "Ep:60, loss:0.00006, loss_test:0.09128, lr:9.51e-03, fs:0.76087 (r=0.707,p=0.824),  time:34.450, tt:2101.435\n",
      "Ep:61, loss:0.00006, loss_test:0.09567, lr:9.51e-03, fs:0.74396 (r=0.778,p=0.713),  time:34.457, tt:2136.318\n",
      "Ep:62, loss:0.00006, loss_test:0.09046, lr:9.51e-03, fs:0.73034 (r=0.657,p=0.823),  time:34.441, tt:2169.809\n",
      "Ep:63, loss:0.00006, loss_test:0.09217, lr:9.51e-03, fs:0.75258 (r=0.737,p=0.768),  time:34.444, tt:2204.432\n",
      "Ep:64, loss:0.00005, loss_test:0.09842, lr:9.51e-03, fs:0.75281 (r=0.677,p=0.848),  time:34.438, tt:2238.452\n",
      "Ep:65, loss:0.00005, loss_test:0.09516, lr:9.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:34.422, tt:2271.870\n",
      "Ep:66, loss:0.00005, loss_test:0.10126, lr:9.41e-03, fs:0.73256 (r=0.636,p=0.863),  time:34.408, tt:2305.310\n",
      "Ep:67, loss:0.00005, loss_test:0.09737, lr:9.32e-03, fs:0.74866 (r=0.707,p=0.795),  time:34.419, tt:2340.494\n",
      "Ep:68, loss:0.00004, loss_test:0.09938, lr:9.23e-03, fs:0.74725 (r=0.687,p=0.819),  time:34.428, tt:2375.535\n",
      "Ep:69, loss:0.00004, loss_test:0.10733, lr:9.14e-03, fs:0.69945 (r=0.646,p=0.762),  time:34.421, tt:2409.504\n",
      "Ep:70, loss:0.00005, loss_test:0.10510, lr:9.04e-03, fs:0.71186 (r=0.636,p=0.808),  time:34.430, tt:2444.538\n",
      "Ep:71, loss:0.00004, loss_test:0.09808, lr:8.95e-03, fs:0.77949 (r=0.768,p=0.792),  time:34.440, tt:2479.696\n",
      "Ep:72, loss:0.00004, loss_test:0.10520, lr:8.86e-03, fs:0.67879 (r=0.566,p=0.848),  time:34.426, tt:2513.081\n",
      "Ep:73, loss:0.00004, loss_test:0.09462, lr:8.78e-03, fs:0.77720 (r=0.758,p=0.798),  time:34.410, tt:2546.372\n",
      "Ep:74, loss:0.00004, loss_test:0.10698, lr:8.69e-03, fs:0.73373 (r=0.626,p=0.886),  time:34.426, tt:2581.955\n",
      "Ep:75, loss:0.00004, loss_test:0.09138, lr:8.60e-03, fs:0.76596 (r=0.727,p=0.809),  time:34.418, tt:2615.762\n",
      "Ep:76, loss:0.00004, loss_test:0.11559, lr:8.51e-03, fs:0.69880 (r=0.586,p=0.866),  time:34.427, tt:2650.916\n",
      "Ep:77, loss:0.00003, loss_test:0.09899, lr:8.43e-03, fs:0.72222 (r=0.657,p=0.802),  time:34.423, tt:2684.999\n",
      "Ep:78, loss:0.00003, loss_test:0.11126, lr:8.35e-03, fs:0.70520 (r=0.616,p=0.824),  time:34.430, tt:2720.005\n",
      "Ep:79, loss:0.00003, loss_test:0.10780, lr:8.26e-03, fs:0.72832 (r=0.636,p=0.851),  time:34.453, tt:2756.252\n",
      "Ep:80, loss:0.00003, loss_test:0.09928, lr:8.18e-03, fs:0.74444 (r=0.677,p=0.827),  time:34.458, tt:2791.116\n",
      "Ep:81, loss:0.00003, loss_test:0.11360, lr:8.10e-03, fs:0.71264 (r=0.626,p=0.827),  time:34.498, tt:2828.816\n",
      "Ep:82, loss:0.00003, loss_test:0.10067, lr:8.02e-03, fs:0.71910 (r=0.646,p=0.810),  time:34.496, tt:2863.168\n",
      "Ep:83, loss:0.00003, loss_test:0.11065, lr:7.94e-03, fs:0.66667 (r=0.535,p=0.883),  time:34.509, tt:2898.773\n",
      "Ep:84, loss:0.00003, loss_test:0.10415, lr:7.86e-03, fs:0.72941 (r=0.626,p=0.873),  time:34.503, tt:2932.737\n",
      "Ep:85, loss:0.00003, loss_test:0.10644, lr:7.78e-03, fs:0.72000 (r=0.636,p=0.829),  time:34.519, tt:2968.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00002, loss_test:0.11227, lr:7.70e-03, fs:0.73373 (r=0.626,p=0.886),  time:34.540, tt:3004.941\n",
      "Ep:87, loss:0.00002, loss_test:0.10045, lr:7.62e-03, fs:0.73143 (r=0.646,p=0.842),  time:34.526, tt:3038.305\n",
      "Ep:88, loss:0.00002, loss_test:0.11199, lr:7.55e-03, fs:0.69512 (r=0.576,p=0.877),  time:34.486, tt:3069.295\n",
      "Ep:89, loss:0.00002, loss_test:0.10482, lr:7.47e-03, fs:0.67470 (r=0.566,p=0.836),  time:34.462, tt:3101.554\n",
      "Ep:90, loss:0.00002, loss_test:0.10908, lr:7.40e-03, fs:0.74118 (r=0.636,p=0.887),  time:34.443, tt:3134.340\n",
      "Ep:91, loss:0.00002, loss_test:0.11015, lr:7.32e-03, fs:0.69939 (r=0.576,p=0.891),  time:34.444, tt:3168.828\n",
      "Ep:92, loss:0.00002, loss_test:0.10636, lr:7.25e-03, fs:0.70303 (r=0.586,p=0.879),  time:34.434, tt:3202.390\n",
      "Ep:93, loss:0.00002, loss_test:0.11354, lr:7.18e-03, fs:0.74118 (r=0.636,p=0.887),  time:34.443, tt:3237.611\n",
      "Ep:94, loss:0.00002, loss_test:0.10810, lr:7.11e-03, fs:0.72941 (r=0.626,p=0.873),  time:34.442, tt:3272.028\n",
      "Ep:95, loss:0.00002, loss_test:0.11881, lr:7.03e-03, fs:0.71765 (r=0.616,p=0.859),  time:34.463, tt:3308.464\n",
      "Ep:96, loss:0.00002, loss_test:0.10380, lr:6.96e-03, fs:0.68263 (r=0.576,p=0.838),  time:34.466, tt:3343.247\n",
      "Ep:97, loss:0.00002, loss_test:0.11356, lr:6.89e-03, fs:0.69512 (r=0.576,p=0.877),  time:34.440, tt:3375.104\n",
      "Ep:98, loss:0.00002, loss_test:0.11055, lr:6.83e-03, fs:0.71345 (r=0.616,p=0.847),  time:34.455, tt:3411.010\n",
      "Ep:99, loss:0.00002, loss_test:0.11199, lr:6.76e-03, fs:0.69512 (r=0.576,p=0.877),  time:34.460, tt:3446.036\n",
      "Ep:100, loss:0.00002, loss_test:0.11492, lr:6.69e-03, fs:0.70370 (r=0.576,p=0.905),  time:34.474, tt:3481.829\n",
      "Ep:101, loss:0.00002, loss_test:0.11545, lr:6.62e-03, fs:0.73684 (r=0.636,p=0.875),  time:34.482, tt:3517.202\n",
      "Ep:102, loss:0.00002, loss_test:0.11541, lr:6.56e-03, fs:0.67089 (r=0.535,p=0.898),  time:34.487, tt:3552.152\n",
      "Ep:103, loss:0.00001, loss_test:0.11400, lr:6.49e-03, fs:0.68712 (r=0.566,p=0.875),  time:34.497, tt:3587.641\n",
      "Ep:104, loss:0.00001, loss_test:0.11806, lr:6.43e-03, fs:0.72619 (r=0.616,p=0.884),  time:34.499, tt:3622.373\n",
      "Ep:105, loss:0.00001, loss_test:0.11341, lr:6.36e-03, fs:0.67089 (r=0.535,p=0.898),  time:34.512, tt:3658.237\n",
      "Ep:106, loss:0.00001, loss_test:0.11400, lr:6.30e-03, fs:0.73684 (r=0.636,p=0.875),  time:34.516, tt:3693.167\n",
      "Ep:107, loss:0.00001, loss_test:0.11447, lr:6.24e-03, fs:0.65823 (r=0.525,p=0.881),  time:34.518, tt:3727.949\n",
      "Ep:108, loss:0.00001, loss_test:0.11471, lr:6.17e-03, fs:0.68750 (r=0.556,p=0.902),  time:34.508, tt:3761.317\n",
      "Ep:109, loss:0.00001, loss_test:0.11720, lr:6.11e-03, fs:0.67081 (r=0.545,p=0.871),  time:34.503, tt:3795.289\n",
      "Ep:110, loss:0.00001, loss_test:0.11809, lr:6.05e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.509, tt:3830.486\n",
      "Ep:111, loss:0.00001, loss_test:0.11292, lr:5.99e-03, fs:0.65839 (r=0.535,p=0.855),  time:34.509, tt:3865.049\n",
      "Ep:112, loss:0.00001, loss_test:0.12146, lr:5.93e-03, fs:0.66667 (r=0.535,p=0.883),  time:34.516, tt:3900.277\n",
      "Ep:113, loss:0.00001, loss_test:0.11969, lr:5.87e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.510, tt:3934.095\n",
      "Ep:114, loss:0.00001, loss_test:0.11692, lr:5.81e-03, fs:0.68323 (r=0.556,p=0.887),  time:34.489, tt:3966.199\n",
      "Ep:115, loss:0.00001, loss_test:0.12392, lr:5.75e-03, fs:0.71951 (r=0.596,p=0.908),  time:34.499, tt:4001.923\n",
      "Ep:116, loss:0.00001, loss_test:0.12101, lr:5.70e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.508, tt:4037.460\n",
      "Ep:117, loss:0.00001, loss_test:0.12139, lr:5.64e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.507, tt:4071.807\n",
      "Ep:118, loss:0.00001, loss_test:0.12613, lr:5.58e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.500, tt:4105.448\n",
      "Ep:119, loss:0.00001, loss_test:0.12059, lr:5.53e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.529, tt:4143.539\n",
      "Ep:120, loss:0.00001, loss_test:0.12452, lr:5.47e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.531, tt:4178.282\n",
      "Ep:121, loss:0.00001, loss_test:0.12446, lr:5.42e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.532, tt:4212.865\n",
      "Ep:122, loss:0.00001, loss_test:0.12414, lr:5.36e-03, fs:0.65409 (r=0.525,p=0.867),  time:34.531, tt:4247.354\n",
      "Ep:123, loss:0.00001, loss_test:0.12576, lr:5.31e-03, fs:0.65823 (r=0.525,p=0.881),  time:34.554, tt:4284.667\n",
      "Ep:124, loss:0.00001, loss_test:0.12313, lr:5.26e-03, fs:0.67516 (r=0.535,p=0.914),  time:34.536, tt:4316.943\n",
      "Ep:125, loss:0.00001, loss_test:0.12934, lr:5.20e-03, fs:0.71951 (r=0.596,p=0.908),  time:34.524, tt:4350.006\n",
      "Ep:126, loss:0.00001, loss_test:0.12556, lr:5.15e-03, fs:0.66242 (r=0.525,p=0.897),  time:34.525, tt:4384.690\n",
      "Ep:127, loss:0.00001, loss_test:0.12274, lr:5.10e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.527, tt:4419.490\n",
      "Ep:128, loss:0.00001, loss_test:0.12872, lr:5.05e-03, fs:0.67089 (r=0.535,p=0.898),  time:34.535, tt:4455.068\n",
      "Ep:129, loss:0.00001, loss_test:0.12407, lr:5.00e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.538, tt:4490.002\n",
      "Ep:130, loss:0.00001, loss_test:0.12634, lr:4.95e-03, fs:0.71166 (r=0.586,p=0.906),  time:34.535, tt:4524.062\n",
      "Ep:131, loss:0.00001, loss_test:0.12652, lr:4.90e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.541, tt:4559.431\n",
      "Ep:132, loss:0.00001, loss_test:0.12790, lr:4.85e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.531, tt:4592.627\n",
      "Ep:133, loss:0.00001, loss_test:0.12592, lr:4.80e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.527, tt:4626.656\n",
      "Ep:134, loss:0.00001, loss_test:0.12890, lr:4.75e-03, fs:0.71515 (r=0.596,p=0.894),  time:34.522, tt:4660.451\n",
      "Ep:135, loss:0.00001, loss_test:0.12760, lr:4.71e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.524, tt:4695.259\n",
      "Ep:136, loss:0.00001, loss_test:0.12942, lr:4.66e-03, fs:0.72393 (r=0.596,p=0.922),  time:34.526, tt:4730.112\n",
      "Ep:137, loss:0.00001, loss_test:0.12709, lr:4.61e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.551, tt:4768.058\n",
      "Ep:138, loss:0.00001, loss_test:0.12656, lr:4.57e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.551, tt:4802.591\n",
      "Ep:139, loss:0.00001, loss_test:0.13036, lr:4.52e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.552, tt:4837.324\n",
      "Ep:140, loss:0.00001, loss_test:0.13109, lr:4.48e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.540, tt:4870.201\n",
      "Ep:141, loss:0.00001, loss_test:0.12971, lr:4.43e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.525, tt:4902.537\n",
      "Ep:142, loss:0.00001, loss_test:0.13086, lr:4.39e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.530, tt:4937.753\n",
      "Ep:143, loss:0.00001, loss_test:0.13105, lr:4.34e-03, fs:0.67516 (r=0.535,p=0.914),  time:34.533, tt:4972.798\n",
      "Ep:144, loss:0.00001, loss_test:0.13049, lr:4.30e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.541, tt:5008.420\n",
      "Ep:145, loss:0.00001, loss_test:0.13544, lr:4.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:34.541, tt:5042.986\n",
      "Ep:146, loss:0.00001, loss_test:0.13276, lr:4.21e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.537, tt:5077.000\n",
      "Ep:147, loss:0.00001, loss_test:0.13226, lr:4.17e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.534, tt:5111.020\n",
      "Ep:148, loss:0.00001, loss_test:0.13181, lr:4.13e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.555, tt:5148.704\n",
      "Ep:149, loss:0.00001, loss_test:0.13097, lr:4.09e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.556, tt:5183.342\n",
      "Ep:150, loss:0.00001, loss_test:0.13258, lr:4.05e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.555, tt:5217.796\n",
      "Ep:151, loss:0.00001, loss_test:0.13101, lr:4.01e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.551, tt:5251.804\n",
      "Ep:152, loss:0.00001, loss_test:0.13161, lr:3.97e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.552, tt:5286.386\n",
      "Ep:153, loss:0.00001, loss_test:0.13229, lr:3.93e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.548, tt:5320.355\n",
      "Ep:154, loss:0.00001, loss_test:0.13301, lr:3.89e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.550, tt:5355.289\n",
      "Ep:155, loss:0.00001, loss_test:0.13314, lr:3.85e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.558, tt:5391.045\n",
      "Ep:156, loss:0.00001, loss_test:0.13509, lr:3.81e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.565, tt:5426.651\n",
      "Ep:157, loss:0.00000, loss_test:0.13229, lr:3.77e-03, fs:0.66667 (r=0.525,p=0.912),  time:34.560, tt:5460.404\n",
      "Ep:158, loss:0.00000, loss_test:0.13036, lr:3.73e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.547, tt:5492.971\n",
      "Ep:159, loss:0.00000, loss_test:0.13261, lr:3.70e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.554, tt:5528.655\n",
      "Ep:160, loss:0.00000, loss_test:0.13376, lr:3.66e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.559, tt:5564.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:161, loss:0.00000, loss_test:0.13383, lr:3.62e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.555, tt:5597.897\n",
      "Ep:162, loss:0.00000, loss_test:0.13289, lr:3.59e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.564, tt:5633.977\n",
      "Ep:163, loss:0.00000, loss_test:0.13281, lr:3.55e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.563, tt:5668.393\n",
      "Ep:164, loss:0.00000, loss_test:0.13277, lr:3.52e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.556, tt:5701.693\n",
      "Ep:165, loss:0.00000, loss_test:0.13511, lr:3.48e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.556, tt:5736.273\n",
      "Ep:166, loss:0.00000, loss_test:0.13379, lr:3.45e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.554, tt:5770.532\n",
      "Ep:167, loss:0.00000, loss_test:0.13618, lr:3.41e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.561, tt:5806.244\n",
      "Ep:168, loss:0.00000, loss_test:0.13478, lr:3.38e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.570, tt:5842.312\n",
      "Ep:169, loss:0.00000, loss_test:0.13569, lr:3.34e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.559, tt:5875.052\n",
      "Ep:170, loss:0.00000, loss_test:0.13380, lr:3.31e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.562, tt:5910.113\n",
      "Ep:171, loss:0.00000, loss_test:0.13627, lr:3.28e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.569, tt:5945.869\n",
      "Ep:172, loss:0.00000, loss_test:0.13478, lr:3.24e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.568, tt:5980.197\n",
      "Ep:173, loss:0.00000, loss_test:0.13617, lr:3.21e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.559, tt:6013.350\n",
      "Ep:174, loss:0.00000, loss_test:0.13382, lr:3.18e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.559, tt:6047.885\n",
      "Ep:175, loss:0.00000, loss_test:0.13402, lr:3.15e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.557, tt:6082.055\n",
      "Ep:176, loss:0.00000, loss_test:0.13458, lr:3.12e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.555, tt:6116.210\n",
      "Ep:177, loss:0.00000, loss_test:0.13534, lr:3.09e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.559, tt:6151.473\n",
      "Ep:178, loss:0.00000, loss_test:0.13551, lr:3.05e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.567, tt:6187.508\n",
      "Ep:179, loss:0.00000, loss_test:0.13575, lr:3.02e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.563, tt:6221.372\n",
      "Ep:180, loss:0.00000, loss_test:0.13546, lr:2.99e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.563, tt:6255.846\n",
      "Ep:181, loss:0.00000, loss_test:0.13480, lr:2.96e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.562, tt:6290.265\n",
      "Ep:182, loss:0.00000, loss_test:0.13481, lr:2.93e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.557, tt:6323.949\n",
      "Ep:183, loss:0.00000, loss_test:0.13433, lr:2.90e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.553, tt:6357.762\n",
      "Ep:184, loss:0.00000, loss_test:0.13388, lr:2.88e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.562, tt:6393.978\n",
      "Ep:185, loss:0.00000, loss_test:0.13562, lr:2.85e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.567, tt:6429.458\n",
      "Ep:186, loss:0.00000, loss_test:0.13525, lr:2.82e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.569, tt:6464.347\n",
      "Ep:187, loss:0.00000, loss_test:0.13664, lr:2.79e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.582, tt:6501.463\n",
      "Ep:188, loss:0.00000, loss_test:0.13689, lr:2.76e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.586, tt:6536.786\n",
      "Ep:189, loss:0.00000, loss_test:0.13730, lr:2.73e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.578, tt:6569.780\n",
      "Ep:190, loss:0.00000, loss_test:0.13551, lr:2.71e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.577, tt:6604.291\n",
      "Ep:191, loss:0.00000, loss_test:0.13658, lr:2.68e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.577, tt:6638.853\n",
      "Ep:192, loss:0.00000, loss_test:0.13607, lr:2.65e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.578, tt:6673.585\n",
      "Ep:193, loss:0.00000, loss_test:0.13786, lr:2.63e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.581, tt:6708.665\n",
      "Ep:194, loss:0.00000, loss_test:0.13691, lr:2.60e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.585, tt:6744.085\n",
      "Ep:195, loss:0.00000, loss_test:0.13726, lr:2.57e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.585, tt:6778.583\n",
      "Ep:196, loss:0.00000, loss_test:0.13471, lr:2.55e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.581, tt:6812.400\n",
      "Ep:197, loss:0.00000, loss_test:0.13589, lr:2.52e-03, fs:0.67974 (r=0.525,p=0.963),  time:34.575, tt:6845.779\n",
      "Ep:198, loss:0.00000, loss_test:0.13510, lr:2.50e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.571, tt:6879.571\n",
      "Ep:199, loss:0.00000, loss_test:0.13606, lr:2.47e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.572, tt:6914.319\n",
      "Ep:200, loss:0.00000, loss_test:0.13640, lr:2.45e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.572, tt:6948.972\n",
      "Ep:201, loss:0.00000, loss_test:0.13533, lr:2.42e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.575, tt:6984.075\n",
      "Ep:202, loss:0.00000, loss_test:0.13562, lr:2.40e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.586, tt:7020.956\n",
      "Ep:203, loss:0.00000, loss_test:0.13579, lr:2.38e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.589, tt:7056.177\n",
      "Ep:204, loss:0.00000, loss_test:0.13639, lr:2.35e-03, fs:0.67532 (r=0.525,p=0.945),  time:34.589, tt:7090.654\n",
      "Ep:205, loss:0.00000, loss_test:0.13550, lr:2.33e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.590, tt:7125.632\n",
      "Ep:206, loss:0.00000, loss_test:0.13488, lr:2.31e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.600, tt:7162.269\n",
      "Ep:207, loss:0.00000, loss_test:0.13424, lr:2.28e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.596, tt:7195.917\n",
      "Ep:208, loss:0.00000, loss_test:0.13441, lr:2.26e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.599, tt:7231.146\n",
      "Ep:209, loss:0.00000, loss_test:0.13506, lr:2.24e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.591, tt:7264.202\n",
      "Ep:210, loss:0.00000, loss_test:0.13594, lr:2.21e-03, fs:0.67097 (r=0.525,p=0.929),  time:34.566, tt:7293.430\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.03119, lr:6.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:26.730, tt:26.730\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02599, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:27.156, tt:54.312\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02784, lr:6.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:27.930, tt:83.788\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02836, lr:6.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:29.128, tt:116.512\n",
      "Ep:4, loss:0.00005, loss_test:0.02842, lr:6.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:29.938, tt:149.689\n",
      "Ep:5, loss:0.00005, loss_test:0.02854, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:30.602, tt:183.610\n",
      "Ep:6, loss:0.00005, loss_test:0.02893, lr:6.00e-02, fs:0.63878 (r=0.848,p=0.512),  time:30.812, tt:215.686\n",
      "Ep:7, loss:0.00005, loss_test:0.02932, lr:6.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:31.078, tt:248.628\n",
      "Ep:8, loss:0.00005, loss_test:0.02973, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:31.201, tt:280.806\n",
      "Ep:9, loss:0.00005, loss_test:0.02988, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:31.572, tt:315.721\n",
      "Ep:10, loss:0.00005, loss_test:0.02927, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:31.851, tt:350.357\n",
      "Ep:11, loss:0.00005, loss_test:0.02832, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:31.971, tt:383.654\n",
      "Ep:12, loss:0.00005, loss_test:0.02751, lr:6.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:32.107, tt:417.392\n",
      "Ep:13, loss:0.00005, loss_test:0.02690, lr:6.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:32.276, tt:451.870\n",
      "Ep:14, loss:0.00005, loss_test:0.02645, lr:5.94e-02, fs:0.64062 (r=0.828,p=0.522),  time:32.401, tt:486.021\n",
      "Ep:15, loss:0.00005, loss_test:0.02621, lr:5.88e-02, fs:0.63780 (r=0.818,p=0.523),  time:32.487, tt:519.786\n",
      "Ep:16, loss:0.00004, loss_test:0.02607, lr:5.82e-02, fs:0.63200 (r=0.798,p=0.523),  time:32.565, tt:553.612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00004, loss_test:0.02581, lr:5.76e-02, fs:0.62295 (r=0.768,p=0.524),  time:32.658, tt:587.843\n",
      "Ep:18, loss:0.00004, loss_test:0.02561, lr:5.71e-02, fs:0.59664 (r=0.717,p=0.511),  time:32.679, tt:620.907\n",
      "Ep:19, loss:0.00004, loss_test:0.02541, lr:5.65e-02, fs:0.59916 (r=0.717,p=0.514),  time:32.786, tt:655.728\n",
      "Ep:20, loss:0.00004, loss_test:0.02539, lr:5.59e-02, fs:0.60169 (r=0.717,p=0.518),  time:32.824, tt:689.303\n",
      "Ep:21, loss:0.00004, loss_test:0.02551, lr:5.54e-02, fs:0.60944 (r=0.717,p=0.530),  time:32.937, tt:724.618\n",
      "Ep:22, loss:0.00004, loss_test:0.02568, lr:5.48e-02, fs:0.61803 (r=0.727,p=0.537),  time:33.010, tt:759.224\n",
      "Ep:23, loss:0.00004, loss_test:0.02564, lr:5.43e-02, fs:0.61803 (r=0.727,p=0.537),  time:33.014, tt:792.337\n",
      "Ep:24, loss:0.00004, loss_test:0.02550, lr:5.37e-02, fs:0.61538 (r=0.727,p=0.533),  time:33.085, tt:827.124\n",
      "Ep:25, loss:0.00004, loss_test:0.02537, lr:5.32e-02, fs:0.61207 (r=0.717,p=0.534),  time:33.089, tt:860.319\n",
      "Ep:26, loss:0.00004, loss_test:0.02539, lr:5.27e-02, fs:0.61207 (r=0.717,p=0.534),  time:33.121, tt:894.275\n",
      "Ep:27, loss:0.00004, loss_test:0.02542, lr:5.21e-02, fs:0.60606 (r=0.707,p=0.530),  time:33.154, tt:928.304\n",
      "Ep:28, loss:0.00004, loss_test:0.02539, lr:5.16e-02, fs:0.60606 (r=0.707,p=0.530),  time:33.122, tt:960.547\n",
      "Ep:29, loss:0.00004, loss_test:0.02528, lr:5.11e-02, fs:0.61207 (r=0.717,p=0.534),  time:33.104, tt:993.118\n",
      "Ep:30, loss:0.00004, loss_test:0.02494, lr:5.06e-02, fs:0.62069 (r=0.727,p=0.541),  time:33.078, tt:1025.423\n",
      "Ep:31, loss:0.00004, loss_test:0.02472, lr:5.01e-02, fs:0.62338 (r=0.727,p=0.545),  time:33.118, tt:1059.771\n",
      "Ep:32, loss:0.00004, loss_test:0.02457, lr:4.96e-02, fs:0.62281 (r=0.717,p=0.550),  time:33.133, tt:1093.390\n",
      "Ep:33, loss:0.00004, loss_test:0.02444, lr:4.91e-02, fs:0.63158 (r=0.727,p=0.558),  time:33.190, tt:1128.462\n",
      "Ep:34, loss:0.00004, loss_test:0.02431, lr:4.86e-02, fs:0.63436 (r=0.727,p=0.562),  time:33.230, tt:1163.058\n",
      "Ep:35, loss:0.00004, loss_test:0.02418, lr:4.81e-02, fs:0.63717 (r=0.727,p=0.567),  time:33.198, tt:1195.140\n",
      "Ep:36, loss:0.00003, loss_test:0.02395, lr:4.76e-02, fs:0.64000 (r=0.727,p=0.571),  time:33.231, tt:1229.550\n",
      "Ep:37, loss:0.00003, loss_test:0.02381, lr:4.71e-02, fs:0.63964 (r=0.717,p=0.577),  time:33.244, tt:1263.278\n",
      "Ep:38, loss:0.00003, loss_test:0.02348, lr:4.67e-02, fs:0.64286 (r=0.727,p=0.576),  time:33.322, tt:1299.542\n",
      "Ep:39, loss:0.00003, loss_test:0.02326, lr:4.62e-02, fs:0.66079 (r=0.758,p=0.586),  time:33.348, tt:1333.906\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.02323, lr:4.62e-02, fs:0.65471 (r=0.737,p=0.589),  time:33.359, tt:1367.732\n",
      "Ep:41, loss:0.00003, loss_test:0.02314, lr:4.62e-02, fs:0.64865 (r=0.727,p=0.585),  time:33.318, tt:1399.352\n",
      "Ep:42, loss:0.00003, loss_test:0.02287, lr:4.62e-02, fs:0.66063 (r=0.737,p=0.598),  time:33.380, tt:1435.340\n",
      "Ep:43, loss:0.00003, loss_test:0.02257, lr:4.62e-02, fs:0.68722 (r=0.788,p=0.609),  time:33.400, tt:1469.607\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.02229, lr:4.62e-02, fs:0.68421 (r=0.788,p=0.605),  time:33.398, tt:1502.911\n",
      "Ep:45, loss:0.00003, loss_test:0.02213, lr:4.62e-02, fs:0.67556 (r=0.768,p=0.603),  time:33.412, tt:1536.951\n",
      "Ep:46, loss:0.00003, loss_test:0.02184, lr:4.62e-02, fs:0.68722 (r=0.788,p=0.609),  time:33.418, tt:1570.665\n",
      "Ep:47, loss:0.00003, loss_test:0.02162, lr:4.62e-02, fs:0.68722 (r=0.788,p=0.609),  time:33.436, tt:1604.916\n",
      "Ep:48, loss:0.00003, loss_test:0.02143, lr:4.62e-02, fs:0.69027 (r=0.788,p=0.614),  time:33.460, tt:1639.541\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.02116, lr:4.62e-02, fs:0.69027 (r=0.788,p=0.614),  time:33.454, tt:1672.710\n",
      "Ep:50, loss:0.00003, loss_test:0.02084, lr:4.62e-02, fs:0.69027 (r=0.788,p=0.614),  time:33.432, tt:1705.020\n",
      "Ep:51, loss:0.00003, loss_test:0.02055, lr:4.62e-02, fs:0.69333 (r=0.788,p=0.619),  time:33.439, tt:1738.829\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.02050, lr:4.62e-02, fs:0.69643 (r=0.788,p=0.624),  time:33.422, tt:1771.344\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.02046, lr:4.62e-02, fs:0.69643 (r=0.788,p=0.624),  time:33.460, tt:1806.827\n",
      "Ep:54, loss:0.00003, loss_test:0.02030, lr:4.62e-02, fs:0.71171 (r=0.798,p=0.642),  time:33.464, tt:1840.506\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.02012, lr:4.62e-02, fs:0.70536 (r=0.798,p=0.632),  time:33.473, tt:1874.471\n",
      "Ep:56, loss:0.00003, loss_test:0.02000, lr:4.62e-02, fs:0.71171 (r=0.798,p=0.642),  time:33.495, tt:1909.191\n",
      "Ep:57, loss:0.00002, loss_test:0.02004, lr:4.62e-02, fs:0.70046 (r=0.768,p=0.644),  time:33.500, tt:1943.009\n",
      "Ep:58, loss:0.00002, loss_test:0.02005, lr:4.62e-02, fs:0.67925 (r=0.727,p=0.637),  time:33.496, tt:1976.288\n",
      "Ep:59, loss:0.00002, loss_test:0.01999, lr:4.62e-02, fs:0.67299 (r=0.717,p=0.634),  time:33.514, tt:2010.845\n",
      "Ep:60, loss:0.00002, loss_test:0.01995, lr:4.62e-02, fs:0.65072 (r=0.687,p=0.618),  time:33.540, tt:2045.937\n",
      "Ep:61, loss:0.00002, loss_test:0.02023, lr:4.62e-02, fs:0.65403 (r=0.697,p=0.616),  time:33.577, tt:2081.785\n",
      "Ep:62, loss:0.00002, loss_test:0.02012, lr:4.62e-02, fs:0.66346 (r=0.697,p=0.633),  time:33.599, tt:2116.751\n",
      "Ep:63, loss:0.00002, loss_test:0.02020, lr:4.62e-02, fs:0.65366 (r=0.677,p=0.632),  time:33.603, tt:2150.589\n",
      "Ep:64, loss:0.00002, loss_test:0.02060, lr:4.62e-02, fs:0.66019 (r=0.687,p=0.636),  time:33.629, tt:2185.880\n",
      "Ep:65, loss:0.00002, loss_test:0.02055, lr:4.62e-02, fs:0.65700 (r=0.687,p=0.630),  time:33.667, tt:2221.995\n",
      "Ep:66, loss:0.00002, loss_test:0.02073, lr:4.57e-02, fs:0.65049 (r=0.677,p=0.626),  time:33.691, tt:2257.284\n",
      "Ep:67, loss:0.00002, loss_test:0.02102, lr:4.53e-02, fs:0.66019 (r=0.687,p=0.636),  time:33.701, tt:2291.691\n",
      "Ep:68, loss:0.00002, loss_test:0.02110, lr:4.48e-02, fs:0.64000 (r=0.646,p=0.634),  time:33.711, tt:2326.036\n",
      "Ep:69, loss:0.00002, loss_test:0.02199, lr:4.44e-02, fs:0.66000 (r=0.667,p=0.653),  time:33.727, tt:2360.899\n",
      "Ep:70, loss:0.00002, loss_test:0.02143, lr:4.39e-02, fs:0.65327 (r=0.657,p=0.650),  time:33.729, tt:2394.726\n",
      "Ep:71, loss:0.00002, loss_test:0.02225, lr:4.35e-02, fs:0.66327 (r=0.657,p=0.670),  time:33.730, tt:2428.533\n",
      "Ep:72, loss:0.00002, loss_test:0.02171, lr:4.31e-02, fs:0.65306 (r=0.646,p=0.660),  time:33.739, tt:2462.914\n",
      "Ep:73, loss:0.00002, loss_test:0.02214, lr:4.26e-02, fs:0.67005 (r=0.667,p=0.673),  time:33.740, tt:2496.777\n",
      "Ep:74, loss:0.00002, loss_test:0.02203, lr:4.22e-02, fs:0.64975 (r=0.646,p=0.653),  time:33.743, tt:2530.700\n",
      "Ep:75, loss:0.00002, loss_test:0.02229, lr:4.18e-02, fs:0.65641 (r=0.646,p=0.667),  time:33.744, tt:2564.552\n",
      "Ep:76, loss:0.00002, loss_test:0.02336, lr:4.14e-02, fs:0.62766 (r=0.596,p=0.663),  time:33.760, tt:2599.524\n",
      "Ep:77, loss:0.00002, loss_test:0.02244, lr:4.10e-02, fs:0.64615 (r=0.636,p=0.656),  time:33.759, tt:2633.196\n",
      "Ep:78, loss:0.00001, loss_test:0.02458, lr:4.05e-02, fs:0.61780 (r=0.596,p=0.641),  time:33.794, tt:2669.736\n",
      "Ep:79, loss:0.00001, loss_test:0.02338, lr:4.01e-02, fs:0.62703 (r=0.586,p=0.674),  time:33.795, tt:2703.614\n",
      "Ep:80, loss:0.00001, loss_test:0.02512, lr:3.97e-02, fs:0.63043 (r=0.586,p=0.682),  time:33.807, tt:2738.404\n",
      "Ep:81, loss:0.00001, loss_test:0.02284, lr:3.93e-02, fs:0.64894 (r=0.616,p=0.685),  time:33.813, tt:2772.628\n",
      "Ep:82, loss:0.00001, loss_test:0.02464, lr:3.89e-02, fs:0.61957 (r=0.576,p=0.671),  time:33.826, tt:2807.574\n",
      "Ep:83, loss:0.00001, loss_test:0.02340, lr:3.86e-02, fs:0.60773 (r=0.556,p=0.671),  time:33.829, tt:2841.619\n",
      "Ep:84, loss:0.00001, loss_test:0.02507, lr:3.82e-02, fs:0.62366 (r=0.586,p=0.667),  time:33.838, tt:2876.232\n",
      "Ep:85, loss:0.00001, loss_test:0.02301, lr:3.78e-02, fs:0.64130 (r=0.596,p=0.694),  time:33.861, tt:2912.012\n",
      "Ep:86, loss:0.00001, loss_test:0.02600, lr:3.74e-02, fs:0.63043 (r=0.586,p=0.682),  time:33.843, tt:2944.324\n",
      "Ep:87, loss:0.00001, loss_test:0.02418, lr:3.70e-02, fs:0.64130 (r=0.596,p=0.694),  time:33.849, tt:2978.754\n",
      "Ep:88, loss:0.00001, loss_test:0.02590, lr:3.67e-02, fs:0.63388 (r=0.586,p=0.690),  time:33.857, tt:3013.316\n",
      "Ep:89, loss:0.00001, loss_test:0.02485, lr:3.63e-02, fs:0.64835 (r=0.596,p=0.711),  time:33.872, tt:3048.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.02566, lr:3.59e-02, fs:0.64444 (r=0.586,p=0.716),  time:33.875, tt:3082.602\n",
      "Ep:91, loss:0.00001, loss_test:0.02560, lr:3.56e-02, fs:0.61364 (r=0.545,p=0.701),  time:33.889, tt:3117.810\n",
      "Ep:92, loss:0.00001, loss_test:0.02714, lr:3.52e-02, fs:0.64045 (r=0.576,p=0.722),  time:33.896, tt:3152.332\n",
      "Ep:93, loss:0.00001, loss_test:0.02512, lr:3.49e-02, fs:0.63043 (r=0.586,p=0.682),  time:33.913, tt:3187.815\n",
      "Ep:94, loss:0.00001, loss_test:0.02759, lr:3.45e-02, fs:0.62637 (r=0.576,p=0.687),  time:33.938, tt:3224.128\n",
      "Ep:95, loss:0.00001, loss_test:0.02525, lr:3.42e-02, fs:0.64088 (r=0.586,p=0.707),  time:33.955, tt:3259.688\n",
      "Ep:96, loss:0.00001, loss_test:0.02802, lr:3.38e-02, fs:0.62222 (r=0.566,p=0.691),  time:33.969, tt:3294.993\n",
      "Ep:97, loss:0.00001, loss_test:0.02597, lr:3.35e-02, fs:0.63388 (r=0.586,p=0.690),  time:33.980, tt:3330.039\n",
      "Ep:98, loss:0.00001, loss_test:0.02710, lr:3.32e-02, fs:0.61017 (r=0.545,p=0.692),  time:33.992, tt:3365.159\n",
      "Ep:99, loss:0.00001, loss_test:0.02700, lr:3.28e-02, fs:0.63333 (r=0.576,p=0.704),  time:34.004, tt:3400.416\n",
      "Ep:100, loss:0.00001, loss_test:0.02787, lr:3.25e-02, fs:0.60227 (r=0.535,p=0.688),  time:34.027, tt:3436.724\n",
      "Ep:101, loss:0.00001, loss_test:0.02766, lr:3.22e-02, fs:0.64773 (r=0.576,p=0.740),  time:34.039, tt:3472.015\n",
      "Ep:102, loss:0.00001, loss_test:0.02746, lr:3.19e-02, fs:0.60571 (r=0.535,p=0.697),  time:34.052, tt:3507.325\n",
      "Ep:103, loss:0.00001, loss_test:0.02802, lr:3.15e-02, fs:0.62791 (r=0.545,p=0.740),  time:34.055, tt:3541.723\n",
      "Ep:104, loss:0.00001, loss_test:0.02746, lr:3.12e-02, fs:0.61988 (r=0.535,p=0.736),  time:34.059, tt:3576.171\n",
      "Ep:105, loss:0.00001, loss_test:0.02835, lr:3.09e-02, fs:0.61176 (r=0.525,p=0.732),  time:34.071, tt:3611.555\n",
      "Ep:106, loss:0.00001, loss_test:0.02803, lr:3.06e-02, fs:0.62353 (r=0.535,p=0.746),  time:34.084, tt:3646.967\n",
      "Ep:107, loss:0.00001, loss_test:0.02833, lr:3.03e-02, fs:0.63584 (r=0.556,p=0.743),  time:34.097, tt:3682.521\n",
      "Ep:108, loss:0.00001, loss_test:0.02854, lr:3.00e-02, fs:0.62722 (r=0.535,p=0.757),  time:34.114, tt:3718.414\n",
      "Ep:109, loss:0.00001, loss_test:0.02921, lr:2.97e-02, fs:0.63095 (r=0.535,p=0.768),  time:34.127, tt:3753.915\n",
      "Ep:110, loss:0.00001, loss_test:0.02733, lr:2.94e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.126, tt:3788.036\n",
      "Ep:111, loss:0.00001, loss_test:0.02976, lr:2.91e-02, fs:0.63158 (r=0.545,p=0.750),  time:34.139, tt:3823.539\n",
      "Ep:112, loss:0.00001, loss_test:0.02792, lr:2.88e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.143, tt:3858.139\n",
      "Ep:113, loss:0.00001, loss_test:0.03107, lr:2.85e-02, fs:0.63473 (r=0.535,p=0.779),  time:34.138, tt:3891.748\n",
      "Ep:114, loss:0.00001, loss_test:0.02720, lr:2.82e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.135, tt:3925.483\n",
      "Ep:115, loss:0.00001, loss_test:0.03090, lr:2.80e-02, fs:0.62791 (r=0.545,p=0.740),  time:34.142, tt:3960.437\n",
      "Ep:116, loss:0.00001, loss_test:0.02780, lr:2.77e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.153, tt:3995.888\n",
      "Ep:117, loss:0.00001, loss_test:0.03201, lr:2.74e-02, fs:0.64286 (r=0.545,p=0.783),  time:34.161, tt:4031.003\n",
      "Ep:118, loss:0.00001, loss_test:0.02746, lr:2.71e-02, fs:0.62651 (r=0.525,p=0.776),  time:34.184, tt:4067.884\n",
      "Ep:119, loss:0.00001, loss_test:0.03255, lr:2.69e-02, fs:0.62791 (r=0.545,p=0.740),  time:34.191, tt:4102.916\n",
      "Ep:120, loss:0.00001, loss_test:0.02770, lr:2.66e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.202, tt:4138.395\n",
      "Ep:121, loss:0.00001, loss_test:0.03185, lr:2.63e-02, fs:0.63473 (r=0.535,p=0.779),  time:34.215, tt:4174.232\n",
      "Ep:122, loss:0.00001, loss_test:0.02823, lr:2.61e-02, fs:0.62275 (r=0.525,p=0.765),  time:34.252, tt:4213.024\n",
      "Ep:123, loss:0.00001, loss_test:0.03251, lr:2.58e-02, fs:0.62651 (r=0.525,p=0.776),  time:34.270, tt:4249.441\n",
      "Ep:124, loss:0.00001, loss_test:0.02879, lr:2.55e-02, fs:0.62651 (r=0.525,p=0.776),  time:34.286, tt:4285.755\n",
      "Ep:125, loss:0.00001, loss_test:0.03199, lr:2.53e-02, fs:0.63030 (r=0.525,p=0.788),  time:34.312, tt:4323.311\n",
      "Ep:126, loss:0.00001, loss_test:0.02939, lr:2.50e-02, fs:0.63030 (r=0.525,p=0.788),  time:34.323, tt:4359.052\n",
      "Ep:127, loss:0.00001, loss_test:0.03273, lr:2.48e-02, fs:0.63415 (r=0.525,p=0.800),  time:34.339, tt:4395.433\n",
      "Ep:128, loss:0.00001, loss_test:0.02925, lr:2.45e-02, fs:0.62651 (r=0.525,p=0.776),  time:34.341, tt:4429.991\n",
      "Ep:129, loss:0.00001, loss_test:0.03217, lr:2.43e-02, fs:0.63030 (r=0.525,p=0.788),  time:34.344, tt:4464.673\n",
      "Ep:130, loss:0.00001, loss_test:0.03156, lr:2.40e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.354, tt:4500.378\n",
      "Ep:131, loss:0.00001, loss_test:0.03258, lr:2.38e-02, fs:0.63415 (r=0.525,p=0.800),  time:34.368, tt:4536.511\n",
      "Ep:132, loss:0.00001, loss_test:0.03083, lr:2.36e-02, fs:0.63030 (r=0.525,p=0.788),  time:34.377, tt:4572.131\n",
      "Ep:133, loss:0.00001, loss_test:0.03265, lr:2.33e-02, fs:0.63415 (r=0.525,p=0.800),  time:34.392, tt:4608.567\n",
      "Ep:134, loss:0.00001, loss_test:0.03238, lr:2.31e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.404, tt:4644.554\n",
      "Ep:135, loss:0.00000, loss_test:0.03234, lr:2.29e-02, fs:0.63415 (r=0.525,p=0.800),  time:34.409, tt:4679.639\n",
      "Ep:136, loss:0.00000, loss_test:0.03264, lr:2.26e-02, fs:0.63415 (r=0.525,p=0.800),  time:34.423, tt:4715.916\n",
      "Ep:137, loss:0.00000, loss_test:0.03235, lr:2.24e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.445, tt:4753.428\n",
      "Ep:138, loss:0.00000, loss_test:0.03359, lr:2.22e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.455, tt:4789.268\n",
      "Ep:139, loss:0.00000, loss_test:0.03232, lr:2.20e-02, fs:0.62577 (r=0.515,p=0.797),  time:34.469, tt:4825.689\n",
      "Ep:140, loss:0.00000, loss_test:0.03427, lr:2.17e-02, fs:0.62963 (r=0.515,p=0.810),  time:34.478, tt:4861.461\n",
      "Ep:141, loss:0.00000, loss_test:0.03303, lr:2.15e-02, fs:0.62577 (r=0.515,p=0.797),  time:34.486, tt:4897.022\n",
      "Ep:142, loss:0.00000, loss_test:0.03326, lr:2.13e-02, fs:0.62112 (r=0.505,p=0.806),  time:34.498, tt:4933.234\n",
      "Ep:143, loss:0.00000, loss_test:0.03425, lr:2.11e-02, fs:0.61728 (r=0.505,p=0.794),  time:34.498, tt:4967.644\n",
      "Ep:144, loss:0.00000, loss_test:0.03336, lr:2.09e-02, fs:0.61728 (r=0.505,p=0.794),  time:34.500, tt:5002.462\n",
      "Ep:145, loss:0.00000, loss_test:0.03462, lr:2.07e-02, fs:0.62500 (r=0.505,p=0.820),  time:34.506, tt:5037.826\n",
      "Ep:146, loss:0.00000, loss_test:0.03365, lr:2.05e-02, fs:0.62500 (r=0.505,p=0.820),  time:34.518, tt:5074.122\n",
      "Ep:147, loss:0.00000, loss_test:0.03391, lr:2.03e-02, fs:0.62112 (r=0.505,p=0.806),  time:34.518, tt:5108.720\n",
      "Ep:148, loss:0.00000, loss_test:0.03426, lr:2.01e-02, fs:0.61250 (r=0.495,p=0.803),  time:34.526, tt:5144.422\n",
      "Ep:149, loss:0.00000, loss_test:0.03344, lr:1.99e-02, fs:0.62500 (r=0.505,p=0.820),  time:34.535, tt:5180.189\n",
      "Ep:150, loss:0.00000, loss_test:0.03536, lr:1.97e-02, fs:0.61250 (r=0.495,p=0.803),  time:34.539, tt:5215.418\n",
      "Ep:151, loss:0.00000, loss_test:0.03340, lr:1.95e-02, fs:0.62893 (r=0.505,p=0.833),  time:34.534, tt:5249.098\n",
      "Ep:152, loss:0.00000, loss_test:0.03568, lr:1.93e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.536, tt:5284.034\n",
      "Ep:153, loss:0.00000, loss_test:0.03446, lr:1.91e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.550, tt:5320.682\n",
      "Ep:154, loss:0.00000, loss_test:0.03525, lr:1.89e-02, fs:0.62893 (r=0.505,p=0.833),  time:34.562, tt:5357.166\n",
      "Ep:155, loss:0.00000, loss_test:0.03522, lr:1.87e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.567, tt:5392.507\n",
      "Ep:156, loss:0.00000, loss_test:0.03538, lr:1.85e-02, fs:0.62893 (r=0.505,p=0.833),  time:34.590, tt:5430.648\n",
      "Ep:157, loss:0.00000, loss_test:0.03490, lr:1.83e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.609, tt:5468.269\n",
      "Ep:158, loss:0.00000, loss_test:0.03524, lr:1.81e-02, fs:0.62893 (r=0.505,p=0.833),  time:34.625, tt:5505.373\n",
      "Ep:159, loss:0.00000, loss_test:0.03527, lr:1.80e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.630, tt:5540.747\n",
      "Ep:160, loss:0.00000, loss_test:0.03544, lr:1.78e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.635, tt:5576.201\n",
      "Ep:161, loss:0.00000, loss_test:0.03581, lr:1.76e-02, fs:0.62025 (r=0.495,p=0.831),  time:34.638, tt:5611.406\n",
      "Ep:162, loss:0.00000, loss_test:0.03540, lr:1.74e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.643, tt:5646.733\n",
      "Ep:163, loss:0.00000, loss_test:0.03581, lr:1.73e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.651, tt:5682.804\n",
      "Ep:164, loss:0.00000, loss_test:0.03655, lr:1.71e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.661, tt:5719.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:165, loss:0.00000, loss_test:0.03576, lr:1.69e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.660, tt:5753.618\n",
      "Ep:166, loss:0.00000, loss_test:0.03620, lr:1.67e-02, fs:0.62420 (r=0.495,p=0.845),  time:34.677, tt:5790.989\n",
      "Ep:167, loss:0.00000, loss_test:0.03629, lr:1.66e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.686, tt:5827.266\n",
      "Ep:168, loss:0.00000, loss_test:0.03674, lr:1.64e-02, fs:0.62025 (r=0.495,p=0.831),  time:34.702, tt:5864.646\n",
      "Ep:169, loss:0.00000, loss_test:0.03620, lr:1.62e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.707, tt:5900.249\n",
      "Ep:170, loss:0.00000, loss_test:0.03697, lr:1.61e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.720, tt:5937.052\n",
      "Ep:171, loss:0.00000, loss_test:0.03612, lr:1.59e-02, fs:0.61635 (r=0.495,p=0.817),  time:34.723, tt:5972.340\n",
      "Ep:172, loss:0.00000, loss_test:0.03713, lr:1.58e-02, fs:0.61146 (r=0.485,p=0.828),  time:34.717, tt:6006.060\n",
      "Ep:173, loss:0.00000, loss_test:0.03599, lr:1.56e-02, fs:0.62025 (r=0.495,p=0.831),  time:34.719, tt:6041.184\n",
      "Ep:174, loss:0.00000, loss_test:0.03731, lr:1.54e-02, fs:0.61146 (r=0.485,p=0.828),  time:34.712, tt:6074.651\n",
      "Ep:175, loss:0.00000, loss_test:0.03614, lr:1.53e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.714, tt:6109.598\n",
      "Ep:176, loss:0.00000, loss_test:0.03728, lr:1.51e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.712, tt:6144.080\n",
      "Ep:177, loss:0.00000, loss_test:0.03698, lr:1.50e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.701, tt:6176.720\n",
      "Ep:178, loss:0.00000, loss_test:0.03696, lr:1.48e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.705, tt:6212.183\n",
      "Ep:179, loss:0.00000, loss_test:0.03689, lr:1.47e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.710, tt:6247.725\n",
      "Ep:180, loss:0.00000, loss_test:0.03790, lr:1.45e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.708, tt:6282.136\n",
      "Ep:181, loss:0.00000, loss_test:0.03698, lr:1.44e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.711, tt:6317.468\n",
      "Ep:182, loss:0.00000, loss_test:0.03758, lr:1.43e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.710, tt:6352.020\n",
      "Ep:183, loss:0.00000, loss_test:0.03720, lr:1.41e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.707, tt:6386.007\n",
      "Ep:184, loss:0.00000, loss_test:0.03738, lr:1.40e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.714, tt:6422.006\n",
      "Ep:185, loss:0.00000, loss_test:0.03735, lr:1.38e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.719, tt:6457.715\n",
      "Ep:186, loss:0.00000, loss_test:0.03762, lr:1.37e-02, fs:0.60759 (r=0.485,p=0.814),  time:34.719, tt:6492.495\n",
      "Ep:187, loss:0.00000, loss_test:0.03777, lr:1.36e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.722, tt:6527.766\n",
      "Ep:188, loss:0.00000, loss_test:0.03764, lr:1.34e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.727, tt:6563.372\n",
      "Ep:189, loss:0.00000, loss_test:0.03735, lr:1.33e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.729, tt:6598.532\n",
      "Ep:190, loss:0.00000, loss_test:0.03821, lr:1.32e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.730, tt:6633.349\n",
      "Ep:191, loss:0.00000, loss_test:0.03760, lr:1.30e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.740, tt:6670.152\n",
      "Ep:192, loss:0.00000, loss_test:0.03804, lr:1.29e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.740, tt:6704.880\n",
      "Ep:193, loss:0.00000, loss_test:0.03758, lr:1.28e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.746, tt:6740.814\n",
      "Ep:194, loss:0.00000, loss_test:0.03822, lr:1.26e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.751, tt:6776.382\n",
      "Ep:195, loss:0.00000, loss_test:0.03809, lr:1.25e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.752, tt:6811.333\n",
      "Ep:196, loss:0.00000, loss_test:0.03767, lr:1.24e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.756, tt:6846.869\n",
      "Ep:197, loss:0.00000, loss_test:0.03871, lr:1.23e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.765, tt:6883.536\n",
      "Ep:198, loss:0.00000, loss_test:0.03746, lr:1.21e-02, fs:0.62338 (r=0.485,p=0.873),  time:34.772, tt:6919.570\n",
      "Ep:199, loss:0.00000, loss_test:0.03847, lr:1.20e-02, fs:0.61146 (r=0.485,p=0.828),  time:34.780, tt:6956.052\n",
      "Ep:200, loss:0.00000, loss_test:0.03840, lr:1.19e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.779, tt:6990.636\n",
      "Ep:201, loss:0.00000, loss_test:0.03850, lr:1.18e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.772, tt:7024.039\n",
      "Ep:202, loss:0.00000, loss_test:0.03791, lr:1.17e-02, fs:0.62338 (r=0.485,p=0.873),  time:34.774, tt:7059.031\n",
      "Ep:203, loss:0.00000, loss_test:0.03860, lr:1.15e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.774, tt:7093.940\n",
      "Ep:204, loss:0.00000, loss_test:0.03837, lr:1.14e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.776, tt:7128.997\n",
      "Ep:205, loss:0.00000, loss_test:0.03855, lr:1.13e-02, fs:0.62338 (r=0.485,p=0.873),  time:34.777, tt:7163.970\n",
      "Ep:206, loss:0.00000, loss_test:0.03880, lr:1.12e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.784, tt:7200.316\n",
      "Ep:207, loss:0.00000, loss_test:0.03846, lr:1.11e-02, fs:0.62338 (r=0.485,p=0.873),  time:34.788, tt:7235.799\n",
      "Ep:208, loss:0.00000, loss_test:0.03929, lr:1.10e-02, fs:0.62338 (r=0.485,p=0.873),  time:34.782, tt:7269.360\n",
      "Ep:209, loss:0.00000, loss_test:0.03817, lr:1.09e-02, fs:0.61438 (r=0.475,p=0.870),  time:34.785, tt:7304.751\n",
      "Ep:210, loss:0.00000, loss_test:0.03913, lr:1.08e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.760, tt:7334.346\n",
      "Ep:211, loss:0.00000, loss_test:0.03868, lr:1.07e-02, fs:0.61438 (r=0.475,p=0.870),  time:34.745, tt:7365.930\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13257, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:31.774, tt:31.774\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13178, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:29.839, tt:59.678\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13147, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:31.566, tt:94.698\n",
      "Ep:3, loss:0.00026, loss_test:0.13207, lr:1.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:31.848, tt:127.391\n",
      "Ep:4, loss:0.00025, loss_test:0.13274, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:32.955, tt:164.773\n",
      "Ep:5, loss:0.00025, loss_test:0.13267, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:33.632, tt:201.794\n",
      "Ep:6, loss:0.00025, loss_test:0.13175, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:33.829, tt:236.805\n",
      "Ep:7, loss:0.00025, loss_test:0.13069, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:34.071, tt:272.569\n",
      "Ep:8, loss:0.00025, loss_test:0.12962, lr:1.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:34.585, tt:311.264\n",
      "Ep:9, loss:0.00025, loss_test:0.12907, lr:1.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:34.711, tt:347.105\n",
      "Ep:10, loss:0.00024, loss_test:0.12814, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:34.918, tt:384.095\n",
      "Ep:11, loss:0.00024, loss_test:0.12759, lr:1.00e-02, fs:0.65844 (r=0.808,p=0.556),  time:35.079, tt:420.944\n",
      "Ep:12, loss:0.00024, loss_test:0.12694, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:35.126, tt:456.638\n",
      "Ep:13, loss:0.00024, loss_test:0.12694, lr:9.90e-03, fs:0.64706 (r=0.778,p=0.554),  time:35.172, tt:492.412\n",
      "Ep:14, loss:0.00023, loss_test:0.12623, lr:9.80e-03, fs:0.64103 (r=0.758,p=0.556),  time:35.280, tt:529.193\n",
      "Ep:15, loss:0.00023, loss_test:0.12530, lr:9.70e-03, fs:0.62882 (r=0.727,p=0.554),  time:35.350, tt:565.598\n",
      "Ep:16, loss:0.00022, loss_test:0.12452, lr:9.61e-03, fs:0.62281 (r=0.717,p=0.550),  time:35.356, tt:601.058\n",
      "Ep:17, loss:0.00022, loss_test:0.12374, lr:9.51e-03, fs:0.62500 (r=0.707,p=0.560),  time:35.405, tt:637.283\n",
      "Ep:18, loss:0.00022, loss_test:0.12243, lr:9.41e-03, fs:0.62162 (r=0.697,p=0.561),  time:35.474, tt:673.999\n",
      "Ep:19, loss:0.00021, loss_test:0.12163, lr:9.32e-03, fs:0.62385 (r=0.687,p=0.571),  time:35.607, tt:712.149\n",
      "Ep:20, loss:0.00021, loss_test:0.12058, lr:9.23e-03, fs:0.62385 (r=0.687,p=0.571),  time:35.661, tt:748.873\n",
      "Ep:21, loss:0.00020, loss_test:0.11987, lr:9.14e-03, fs:0.64186 (r=0.697,p=0.595),  time:35.741, tt:786.305\n",
      "Ep:22, loss:0.00020, loss_test:0.11827, lr:9.04e-03, fs:0.64486 (r=0.697,p=0.600),  time:35.707, tt:821.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00019, loss_test:0.11702, lr:8.95e-03, fs:0.65714 (r=0.697,p=0.622),  time:35.783, tt:858.784\n",
      "Ep:24, loss:0.00018, loss_test:0.11589, lr:8.86e-03, fs:0.65700 (r=0.687,p=0.630),  time:35.812, tt:895.287\n",
      "Ep:25, loss:0.00018, loss_test:0.11336, lr:8.78e-03, fs:0.65686 (r=0.677,p=0.638),  time:35.880, tt:932.891\n",
      "Ep:26, loss:0.00017, loss_test:0.11053, lr:8.69e-03, fs:0.66667 (r=0.697,p=0.639),  time:35.950, tt:970.641\n",
      "Ep:27, loss:0.00017, loss_test:0.10824, lr:8.60e-03, fs:0.66990 (r=0.697,p=0.645),  time:36.086, tt:1010.410\n",
      "Ep:28, loss:0.00016, loss_test:0.10587, lr:8.51e-03, fs:0.66667 (r=0.687,p=0.648),  time:36.130, tt:1047.775\n",
      "Ep:29, loss:0.00016, loss_test:0.10283, lr:8.43e-03, fs:0.66995 (r=0.687,p=0.654),  time:36.153, tt:1084.580\n",
      "Ep:30, loss:0.00015, loss_test:0.10080, lr:8.35e-03, fs:0.69951 (r=0.717,p=0.683),  time:36.122, tt:1119.767\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.09939, lr:8.35e-03, fs:0.71569 (r=0.737,p=0.695),  time:36.170, tt:1157.434\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.09752, lr:8.35e-03, fs:0.73632 (r=0.747,p=0.725),  time:36.180, tt:1193.943\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.09531, lr:8.35e-03, fs:0.75829 (r=0.808,p=0.714),  time:36.163, tt:1229.555\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.09401, lr:8.35e-03, fs:0.75598 (r=0.798,p=0.718),  time:36.187, tt:1266.553\n",
      "Ep:35, loss:0.00013, loss_test:0.09180, lr:8.35e-03, fs:0.77833 (r=0.798,p=0.760),  time:36.223, tt:1304.021\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.09010, lr:8.35e-03, fs:0.81517 (r=0.869,p=0.768),  time:36.226, tt:1340.369\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.09039, lr:8.35e-03, fs:0.80193 (r=0.838,p=0.769),  time:36.226, tt:1376.603\n",
      "Ep:38, loss:0.00012, loss_test:0.08851, lr:8.35e-03, fs:0.81951 (r=0.848,p=0.792),  time:36.244, tt:1413.531\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.09130, lr:8.35e-03, fs:0.80930 (r=0.879,p=0.750),  time:36.217, tt:1448.664\n",
      "Ep:40, loss:0.00011, loss_test:0.08616, lr:8.35e-03, fs:0.80383 (r=0.848,p=0.764),  time:36.250, tt:1486.237\n",
      "Ep:41, loss:0.00011, loss_test:0.09293, lr:8.35e-03, fs:0.77358 (r=0.828,p=0.726),  time:36.277, tt:1523.616\n",
      "Ep:42, loss:0.00010, loss_test:0.08591, lr:8.35e-03, fs:0.79208 (r=0.808,p=0.777),  time:36.292, tt:1560.560\n",
      "Ep:43, loss:0.00010, loss_test:0.09381, lr:8.35e-03, fs:0.77143 (r=0.818,p=0.730),  time:36.326, tt:1598.332\n",
      "Ep:44, loss:0.00010, loss_test:0.08280, lr:8.35e-03, fs:0.81407 (r=0.818,p=0.810),  time:36.355, tt:1635.982\n",
      "Ep:45, loss:0.00009, loss_test:0.08730, lr:8.35e-03, fs:0.80383 (r=0.848,p=0.764),  time:36.359, tt:1672.493\n",
      "Ep:46, loss:0.00009, loss_test:0.08761, lr:8.35e-03, fs:0.81443 (r=0.798,p=0.832),  time:36.384, tt:1710.069\n",
      "Ep:47, loss:0.00009, loss_test:0.08729, lr:8.35e-03, fs:0.79208 (r=0.808,p=0.777),  time:36.389, tt:1746.654\n",
      "Ep:48, loss:0.00009, loss_test:0.08717, lr:8.35e-03, fs:0.79397 (r=0.798,p=0.790),  time:36.379, tt:1782.587\n",
      "Ep:49, loss:0.00008, loss_test:0.08558, lr:8.35e-03, fs:0.75132 (r=0.717,p=0.789),  time:36.387, tt:1819.367\n",
      "Ep:50, loss:0.00008, loss_test:0.08590, lr:8.26e-03, fs:0.79000 (r=0.798,p=0.782),  time:36.385, tt:1855.655\n",
      "Ep:51, loss:0.00007, loss_test:0.08564, lr:8.18e-03, fs:0.78974 (r=0.778,p=0.802),  time:36.399, tt:1892.733\n",
      "Ep:52, loss:0.00007, loss_test:0.08221, lr:8.10e-03, fs:0.79397 (r=0.798,p=0.790),  time:36.418, tt:1930.164\n",
      "Ep:53, loss:0.00007, loss_test:0.08086, lr:8.02e-03, fs:0.79793 (r=0.778,p=0.819),  time:36.428, tt:1967.093\n",
      "Ep:54, loss:0.00007, loss_test:0.08735, lr:7.94e-03, fs:0.78607 (r=0.798,p=0.775),  time:36.442, tt:2004.313\n",
      "Ep:55, loss:0.00006, loss_test:0.08201, lr:7.86e-03, fs:0.80000 (r=0.788,p=0.812),  time:36.446, tt:2040.990\n",
      "Ep:56, loss:0.00006, loss_test:0.08237, lr:7.78e-03, fs:0.80000 (r=0.788,p=0.812),  time:36.464, tt:2078.450\n",
      "Ep:57, loss:0.00006, loss_test:0.07993, lr:7.70e-03, fs:0.80402 (r=0.808,p=0.800),  time:36.483, tt:2115.986\n",
      "Ep:58, loss:0.00006, loss_test:0.08969, lr:7.62e-03, fs:0.78974 (r=0.778,p=0.802),  time:36.485, tt:2152.616\n",
      "Ep:59, loss:0.00006, loss_test:0.09089, lr:7.55e-03, fs:0.77387 (r=0.778,p=0.770),  time:36.495, tt:2189.706\n",
      "Ep:60, loss:0.00005, loss_test:0.07903, lr:7.47e-03, fs:0.81407 (r=0.818,p=0.810),  time:36.463, tt:2224.270\n",
      "Ep:61, loss:0.00005, loss_test:0.08477, lr:7.40e-03, fs:0.79793 (r=0.778,p=0.819),  time:36.490, tt:2262.378\n",
      "Ep:62, loss:0.00005, loss_test:0.08330, lr:7.32e-03, fs:0.81443 (r=0.798,p=0.832),  time:36.507, tt:2299.969\n",
      "Ep:63, loss:0.00005, loss_test:0.09355, lr:7.25e-03, fs:0.73267 (r=0.747,p=0.718),  time:36.499, tt:2335.905\n",
      "Ep:64, loss:0.00005, loss_test:0.08689, lr:7.18e-03, fs:0.80435 (r=0.747,p=0.871),  time:36.495, tt:2372.150\n",
      "Ep:65, loss:0.00005, loss_test:0.07998, lr:7.11e-03, fs:0.80597 (r=0.818,p=0.794),  time:36.512, tt:2409.810\n",
      "Ep:66, loss:0.00005, loss_test:0.09676, lr:7.03e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.512, tt:2446.310\n",
      "Ep:67, loss:0.00005, loss_test:0.07961, lr:6.96e-03, fs:0.80597 (r=0.818,p=0.794),  time:36.512, tt:2482.804\n",
      "Ep:68, loss:0.00005, loss_test:0.08854, lr:6.89e-03, fs:0.74576 (r=0.667,p=0.846),  time:36.511, tt:2519.293\n",
      "Ep:69, loss:0.00004, loss_test:0.08412, lr:6.83e-03, fs:0.80423 (r=0.768,p=0.844),  time:36.518, tt:2556.241\n",
      "Ep:70, loss:0.00004, loss_test:0.08387, lr:6.76e-03, fs:0.81675 (r=0.788,p=0.848),  time:36.510, tt:2592.193\n",
      "Ep:71, loss:0.00004, loss_test:0.10114, lr:6.69e-03, fs:0.68687 (r=0.687,p=0.687),  time:36.517, tt:2629.207\n",
      "Ep:72, loss:0.00005, loss_test:0.08155, lr:6.62e-03, fs:0.82292 (r=0.798,p=0.849),  time:36.510, tt:2665.237\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00005, loss_test:0.09096, lr:6.62e-03, fs:0.74317 (r=0.687,p=0.810),  time:36.536, tt:2703.678\n",
      "Ep:74, loss:0.00004, loss_test:0.09544, lr:6.62e-03, fs:0.71287 (r=0.727,p=0.699),  time:36.529, tt:2739.676\n",
      "Ep:75, loss:0.00005, loss_test:0.09434, lr:6.62e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.539, tt:2776.948\n",
      "Ep:76, loss:0.00004, loss_test:0.09423, lr:6.62e-03, fs:0.68108 (r=0.636,p=0.733),  time:36.519, tt:2811.995\n",
      "Ep:77, loss:0.00004, loss_test:0.08866, lr:6.62e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.515, tt:2848.154\n",
      "Ep:78, loss:0.00004, loss_test:0.09084, lr:6.62e-03, fs:0.72222 (r=0.657,p=0.802),  time:36.514, tt:2884.611\n",
      "Ep:79, loss:0.00004, loss_test:0.09041, lr:6.62e-03, fs:0.82474 (r=0.808,p=0.842),  time:36.517, tt:2921.374\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00004, loss_test:0.08751, lr:6.62e-03, fs:0.82105 (r=0.788,p=0.857),  time:36.529, tt:2958.886\n",
      "Ep:81, loss:0.00004, loss_test:0.09086, lr:6.62e-03, fs:0.75936 (r=0.717,p=0.807),  time:36.528, tt:2995.332\n",
      "Ep:82, loss:0.00003, loss_test:0.09257, lr:6.62e-03, fs:0.78261 (r=0.727,p=0.847),  time:36.549, tt:3033.587\n",
      "Ep:83, loss:0.00003, loss_test:0.09271, lr:6.62e-03, fs:0.67797 (r=0.606,p=0.769),  time:36.557, tt:3070.798\n",
      "Ep:84, loss:0.00003, loss_test:0.09246, lr:6.62e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.561, tt:3107.710\n",
      "Ep:85, loss:0.00003, loss_test:0.09818, lr:6.62e-03, fs:0.75132 (r=0.717,p=0.789),  time:36.562, tt:3144.363\n",
      "Ep:86, loss:0.00004, loss_test:0.10177, lr:6.62e-03, fs:0.69189 (r=0.646,p=0.744),  time:36.564, tt:3181.097\n",
      "Ep:87, loss:0.00004, loss_test:0.08822, lr:6.62e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.554, tt:3216.763\n",
      "Ep:88, loss:0.00004, loss_test:0.09626, lr:6.62e-03, fs:0.73737 (r=0.737,p=0.737),  time:36.573, tt:3255.031\n",
      "Ep:89, loss:0.00004, loss_test:0.08050, lr:6.62e-03, fs:0.80874 (r=0.747,p=0.881),  time:36.544, tt:3288.982\n",
      "Ep:90, loss:0.00004, loss_test:0.09139, lr:6.62e-03, fs:0.78788 (r=0.788,p=0.788),  time:36.540, tt:3325.182\n",
      "Ep:91, loss:0.00003, loss_test:0.09463, lr:6.56e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.524, tt:3360.218\n",
      "Ep:92, loss:0.00003, loss_test:0.09819, lr:6.49e-03, fs:0.66667 (r=0.606,p=0.741),  time:36.524, tt:3396.717\n",
      "Ep:93, loss:0.00003, loss_test:0.09076, lr:6.43e-03, fs:0.79348 (r=0.737,p=0.859),  time:36.536, tt:3434.364\n",
      "Ep:94, loss:0.00003, loss_test:0.10128, lr:6.36e-03, fs:0.72222 (r=0.657,p=0.802),  time:36.531, tt:3470.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00003, loss_test:0.08476, lr:6.30e-03, fs:0.79348 (r=0.737,p=0.859),  time:36.535, tt:3507.354\n",
      "Ep:96, loss:0.00003, loss_test:0.09555, lr:6.24e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.549, tt:3545.243\n",
      "Ep:97, loss:0.00002, loss_test:0.09113, lr:6.17e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.553, tt:3582.198\n",
      "Ep:98, loss:0.00002, loss_test:0.09456, lr:6.11e-03, fs:0.75281 (r=0.677,p=0.848),  time:36.551, tt:3618.535\n",
      "Ep:99, loss:0.00002, loss_test:0.09583, lr:6.05e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.538, tt:3653.789\n",
      "Ep:100, loss:0.00002, loss_test:0.09270, lr:5.99e-03, fs:0.68966 (r=0.606,p=0.800),  time:36.522, tt:3688.749\n",
      "Ep:101, loss:0.00002, loss_test:0.09574, lr:5.93e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.527, tt:3725.758\n",
      "Ep:102, loss:0.00002, loss_test:0.10063, lr:5.87e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.522, tt:3761.764\n",
      "Ep:103, loss:0.00002, loss_test:0.08706, lr:5.81e-03, fs:0.82162 (r=0.768,p=0.884),  time:36.518, tt:3797.841\n",
      "Ep:104, loss:0.00002, loss_test:0.10048, lr:5.75e-03, fs:0.72414 (r=0.636,p=0.840),  time:36.521, tt:3834.693\n",
      "Ep:105, loss:0.00002, loss_test:0.08954, lr:5.70e-03, fs:0.72832 (r=0.636,p=0.851),  time:36.537, tt:3872.968\n",
      "Ep:106, loss:0.00002, loss_test:0.09697, lr:5.64e-03, fs:0.74157 (r=0.667,p=0.835),  time:36.541, tt:3909.924\n",
      "Ep:107, loss:0.00002, loss_test:0.09282, lr:5.58e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.538, tt:3946.136\n",
      "Ep:108, loss:0.00002, loss_test:0.09419, lr:5.53e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.547, tt:3983.592\n",
      "Ep:109, loss:0.00002, loss_test:0.09369, lr:5.47e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.540, tt:4019.396\n",
      "Ep:110, loss:0.00002, loss_test:0.09348, lr:5.42e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.537, tt:4055.646\n",
      "Ep:111, loss:0.00002, loss_test:0.09455, lr:5.36e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.529, tt:4091.221\n",
      "Ep:112, loss:0.00002, loss_test:0.09401, lr:5.31e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.503, tt:4124.889\n",
      "Ep:113, loss:0.00002, loss_test:0.09408, lr:5.26e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.497, tt:4160.608\n",
      "Ep:114, loss:0.00002, loss_test:0.09515, lr:5.20e-03, fs:0.72515 (r=0.626,p=0.861),  time:36.525, tt:4200.325\n",
      "Ep:115, loss:0.00002, loss_test:0.09524, lr:5.15e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.527, tt:4237.125\n",
      "Ep:116, loss:0.00002, loss_test:0.09397, lr:5.10e-03, fs:0.71006 (r=0.606,p=0.857),  time:36.521, tt:4273.005\n",
      "Ep:117, loss:0.00002, loss_test:0.09777, lr:5.05e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.523, tt:4309.716\n",
      "Ep:118, loss:0.00002, loss_test:0.08959, lr:5.00e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.524, tt:4346.321\n",
      "Ep:119, loss:0.00001, loss_test:0.10322, lr:4.95e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.514, tt:4381.632\n",
      "Ep:120, loss:0.00002, loss_test:0.09257, lr:4.90e-03, fs:0.71856 (r=0.606,p=0.882),  time:36.512, tt:4417.979\n",
      "Ep:121, loss:0.00001, loss_test:0.09943, lr:4.85e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.515, tt:4454.825\n",
      "Ep:122, loss:0.00001, loss_test:0.09391, lr:4.80e-03, fs:0.70807 (r=0.576,p=0.919),  time:36.509, tt:4490.622\n",
      "Ep:123, loss:0.00001, loss_test:0.09638, lr:4.75e-03, fs:0.72515 (r=0.626,p=0.861),  time:36.500, tt:4525.975\n",
      "Ep:124, loss:0.00001, loss_test:0.09319, lr:4.71e-03, fs:0.69880 (r=0.586,p=0.866),  time:36.498, tt:4562.218\n",
      "Ep:125, loss:0.00001, loss_test:0.09665, lr:4.66e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.494, tt:4598.238\n",
      "Ep:126, loss:0.00001, loss_test:0.09475, lr:4.61e-03, fs:0.69091 (r=0.576,p=0.864),  time:36.498, tt:4635.269\n",
      "Ep:127, loss:0.00001, loss_test:0.09607, lr:4.57e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.487, tt:4670.343\n",
      "Ep:128, loss:0.00001, loss_test:0.09584, lr:4.52e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.481, tt:4706.009\n",
      "Ep:129, loss:0.00001, loss_test:0.09739, lr:4.48e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.481, tt:4742.491\n",
      "Ep:130, loss:0.00001, loss_test:0.09657, lr:4.43e-03, fs:0.65409 (r=0.525,p=0.867),  time:36.478, tt:4778.593\n",
      "Ep:131, loss:0.00001, loss_test:0.09847, lr:4.39e-03, fs:0.68712 (r=0.566,p=0.875),  time:36.473, tt:4814.453\n",
      "Ep:132, loss:0.00001, loss_test:0.09464, lr:4.34e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.476, tt:4851.354\n",
      "Ep:133, loss:0.00001, loss_test:0.09791, lr:4.30e-03, fs:0.67901 (r=0.556,p=0.873),  time:36.474, tt:4887.458\n",
      "Ep:134, loss:0.00001, loss_test:0.09534, lr:4.26e-03, fs:0.64103 (r=0.505,p=0.877),  time:36.477, tt:4924.445\n",
      "Ep:135, loss:0.00001, loss_test:0.09758, lr:4.21e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.466, tt:4959.341\n",
      "Ep:136, loss:0.00001, loss_test:0.09572, lr:4.17e-03, fs:0.67081 (r=0.545,p=0.871),  time:36.476, tt:4997.210\n",
      "Ep:137, loss:0.00001, loss_test:0.09827, lr:4.13e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.476, tt:5033.723\n",
      "Ep:138, loss:0.00001, loss_test:0.09606, lr:4.09e-03, fs:0.64103 (r=0.505,p=0.877),  time:36.482, tt:5071.059\n",
      "Ep:139, loss:0.00001, loss_test:0.09902, lr:4.05e-03, fs:0.68712 (r=0.566,p=0.875),  time:36.485, tt:5107.894\n",
      "Ep:140, loss:0.00001, loss_test:0.09375, lr:4.01e-03, fs:0.67500 (r=0.545,p=0.885),  time:36.475, tt:5142.956\n",
      "Ep:141, loss:0.00001, loss_test:0.09910, lr:3.97e-03, fs:0.68712 (r=0.566,p=0.875),  time:36.475, tt:5179.388\n",
      "Ep:142, loss:0.00001, loss_test:0.09419, lr:3.93e-03, fs:0.66667 (r=0.535,p=0.883),  time:36.472, tt:5215.562\n",
      "Ep:143, loss:0.00001, loss_test:0.09961, lr:3.89e-03, fs:0.69512 (r=0.576,p=0.877),  time:36.468, tt:5251.378\n",
      "Ep:144, loss:0.00001, loss_test:0.09290, lr:3.85e-03, fs:0.67901 (r=0.556,p=0.873),  time:36.468, tt:5287.805\n",
      "Ep:145, loss:0.00001, loss_test:0.09916, lr:3.81e-03, fs:0.64557 (r=0.515,p=0.864),  time:36.464, tt:5323.712\n",
      "Ep:146, loss:0.00001, loss_test:0.09573, lr:3.77e-03, fs:0.67081 (r=0.545,p=0.871),  time:36.462, tt:5359.867\n",
      "Ep:147, loss:0.00001, loss_test:0.09535, lr:3.73e-03, fs:0.69091 (r=0.576,p=0.864),  time:36.458, tt:5395.793\n",
      "Ep:148, loss:0.00001, loss_test:0.09620, lr:3.70e-03, fs:0.68750 (r=0.556,p=0.902),  time:36.463, tt:5432.946\n",
      "Ep:149, loss:0.00001, loss_test:0.09715, lr:3.66e-03, fs:0.62745 (r=0.485,p=0.889),  time:36.471, tt:5470.721\n",
      "Ep:150, loss:0.00001, loss_test:0.09530, lr:3.62e-03, fs:0.67081 (r=0.545,p=0.871),  time:36.463, tt:5505.981\n",
      "Ep:151, loss:0.00001, loss_test:0.09806, lr:3.59e-03, fs:0.62745 (r=0.485,p=0.889),  time:36.453, tt:5540.872\n",
      "Ep:152, loss:0.00001, loss_test:0.09604, lr:3.55e-03, fs:0.68712 (r=0.566,p=0.875),  time:36.447, tt:5576.329\n",
      "Ep:153, loss:0.00001, loss_test:0.09659, lr:3.52e-03, fs:0.66667 (r=0.535,p=0.883),  time:36.456, tt:5614.211\n",
      "Ep:154, loss:0.00001, loss_test:0.09559, lr:3.48e-03, fs:0.69136 (r=0.566,p=0.889),  time:36.456, tt:5650.678\n",
      "Ep:155, loss:0.00001, loss_test:0.09697, lr:3.45e-03, fs:0.65409 (r=0.525,p=0.867),  time:36.456, tt:5687.122\n",
      "Ep:156, loss:0.00001, loss_test:0.09583, lr:3.41e-03, fs:0.63226 (r=0.495,p=0.875),  time:36.454, tt:5723.209\n",
      "Ep:157, loss:0.00001, loss_test:0.09742, lr:3.38e-03, fs:0.69565 (r=0.566,p=0.903),  time:36.446, tt:5758.429\n",
      "Ep:158, loss:0.00001, loss_test:0.09490, lr:3.34e-03, fs:0.64935 (r=0.505,p=0.909),  time:36.440, tt:5793.930\n",
      "Ep:159, loss:0.00001, loss_test:0.09637, lr:3.31e-03, fs:0.68750 (r=0.556,p=0.902),  time:36.444, tt:5831.070\n",
      "Ep:160, loss:0.00001, loss_test:0.09574, lr:3.28e-03, fs:0.64052 (r=0.495,p=0.907),  time:36.437, tt:5866.303\n",
      "Ep:161, loss:0.00001, loss_test:0.09554, lr:3.24e-03, fs:0.64968 (r=0.515,p=0.879),  time:36.437, tt:5902.714\n",
      "Ep:162, loss:0.00001, loss_test:0.09604, lr:3.21e-03, fs:0.64052 (r=0.495,p=0.907),  time:36.432, tt:5938.380\n",
      "Ep:163, loss:0.00001, loss_test:0.09583, lr:3.18e-03, fs:0.67925 (r=0.545,p=0.900),  time:36.433, tt:5975.092\n",
      "Ep:164, loss:0.00001, loss_test:0.09478, lr:3.15e-03, fs:0.63158 (r=0.485,p=0.906),  time:36.428, tt:6010.584\n",
      "Ep:165, loss:0.00001, loss_test:0.09648, lr:3.12e-03, fs:0.64516 (r=0.505,p=0.893),  time:36.429, tt:6047.212\n",
      "Ep:166, loss:0.00001, loss_test:0.09493, lr:3.09e-03, fs:0.64052 (r=0.495,p=0.907),  time:36.434, tt:6084.428\n",
      "Ep:167, loss:0.00001, loss_test:0.09672, lr:3.05e-03, fs:0.63158 (r=0.485,p=0.906),  time:36.449, tt:6123.443\n",
      "Ep:168, loss:0.00001, loss_test:0.09514, lr:3.02e-03, fs:0.63694 (r=0.505,p=0.862),  time:36.455, tt:6160.839\n",
      "Ep:169, loss:0.00001, loss_test:0.09435, lr:2.99e-03, fs:0.63158 (r=0.485,p=0.906),  time:36.455, tt:6197.428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:170, loss:0.00001, loss_test:0.09653, lr:2.96e-03, fs:0.65823 (r=0.525,p=0.881),  time:36.447, tt:6232.379\n",
      "Ep:171, loss:0.00001, loss_test:0.09553, lr:2.93e-03, fs:0.62745 (r=0.485,p=0.889),  time:36.451, tt:6269.614\n",
      "Ep:172, loss:0.00001, loss_test:0.09472, lr:2.90e-03, fs:0.65385 (r=0.515,p=0.895),  time:36.456, tt:6306.863\n",
      "Ep:173, loss:0.00001, loss_test:0.09701, lr:2.88e-03, fs:0.64516 (r=0.505,p=0.893),  time:36.463, tt:6344.631\n",
      "Ep:174, loss:0.00001, loss_test:0.09483, lr:2.85e-03, fs:0.62745 (r=0.485,p=0.889),  time:36.459, tt:6380.252\n",
      "Ep:175, loss:0.00001, loss_test:0.09588, lr:2.82e-03, fs:0.66242 (r=0.525,p=0.897),  time:36.453, tt:6415.741\n",
      "Ep:176, loss:0.00001, loss_test:0.09817, lr:2.79e-03, fs:0.60526 (r=0.465,p=0.868),  time:36.453, tt:6452.248\n",
      "Ep:177, loss:0.00001, loss_test:0.09506, lr:2.76e-03, fs:0.61842 (r=0.475,p=0.887),  time:36.464, tt:6490.665\n",
      "Ep:178, loss:0.00001, loss_test:0.09656, lr:2.73e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.456, tt:6525.639\n",
      "Ep:179, loss:0.00001, loss_test:0.09700, lr:2.71e-03, fs:0.62338 (r=0.485,p=0.873),  time:36.450, tt:6560.996\n",
      "Ep:180, loss:0.00001, loss_test:0.09494, lr:2.68e-03, fs:0.63158 (r=0.485,p=0.906),  time:36.453, tt:6597.960\n",
      "Ep:181, loss:0.00001, loss_test:0.09740, lr:2.65e-03, fs:0.63226 (r=0.495,p=0.875),  time:36.461, tt:6635.938\n",
      "Ep:182, loss:0.00001, loss_test:0.09610, lr:2.63e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.462, tt:6672.471\n",
      "Ep:183, loss:0.00001, loss_test:0.09531, lr:2.60e-03, fs:0.62745 (r=0.485,p=0.889),  time:36.460, tt:6708.620\n",
      "Ep:184, loss:0.00001, loss_test:0.09606, lr:2.57e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.465, tt:6746.071\n",
      "Ep:185, loss:0.00001, loss_test:0.09501, lr:2.55e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.466, tt:6782.694\n",
      "Ep:186, loss:0.00001, loss_test:0.09588, lr:2.52e-03, fs:0.61438 (r=0.475,p=0.870),  time:36.465, tt:6818.979\n",
      "Ep:187, loss:0.00001, loss_test:0.09525, lr:2.50e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.471, tt:6856.622\n",
      "Ep:188, loss:0.00001, loss_test:0.09639, lr:2.47e-03, fs:0.63226 (r=0.495,p=0.875),  time:36.471, tt:6893.092\n",
      "Ep:189, loss:0.00001, loss_test:0.09541, lr:2.45e-03, fs:0.61333 (r=0.465,p=0.902),  time:36.468, tt:6928.883\n",
      "Ep:190, loss:0.00001, loss_test:0.09650, lr:2.42e-03, fs:0.61438 (r=0.475,p=0.870),  time:36.471, tt:6965.958\n",
      "Ep:191, loss:0.00001, loss_test:0.09546, lr:2.40e-03, fs:0.62252 (r=0.475,p=0.904),  time:36.472, tt:7002.637\n",
      "Ep:192, loss:0.00001, loss_test:0.09634, lr:2.38e-03, fs:0.63226 (r=0.495,p=0.875),  time:36.477, tt:7040.151\n",
      "Ep:193, loss:0.00001, loss_test:0.09648, lr:2.35e-03, fs:0.62252 (r=0.475,p=0.904),  time:36.478, tt:7076.663\n",
      "Ep:194, loss:0.00001, loss_test:0.09525, lr:2.33e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.475, tt:7112.720\n",
      "Ep:195, loss:0.00001, loss_test:0.09598, lr:2.31e-03, fs:0.61333 (r=0.465,p=0.902),  time:36.471, tt:7148.228\n",
      "Ep:196, loss:0.00001, loss_test:0.09832, lr:2.28e-03, fs:0.61333 (r=0.465,p=0.902),  time:36.472, tt:7184.911\n",
      "Ep:197, loss:0.00001, loss_test:0.09531, lr:2.26e-03, fs:0.61842 (r=0.475,p=0.887),  time:36.465, tt:7220.167\n",
      "Ep:198, loss:0.00001, loss_test:0.09772, lr:2.24e-03, fs:0.65359 (r=0.505,p=0.926),  time:36.461, tt:7255.660\n",
      "Ep:199, loss:0.00001, loss_test:0.09753, lr:2.21e-03, fs:0.61438 (r=0.475,p=0.870),  time:36.457, tt:7291.346\n",
      "Ep:200, loss:0.00001, loss_test:0.09692, lr:2.19e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.454, tt:7327.266\n",
      "Ep:201, loss:0.00001, loss_test:0.09665, lr:2.17e-03, fs:0.63576 (r=0.485,p=0.923),  time:36.457, tt:7364.349\n",
      "Ep:202, loss:0.00001, loss_test:0.09677, lr:2.15e-03, fs:0.65823 (r=0.525,p=0.881),  time:36.458, tt:7401.029\n",
      "Ep:203, loss:0.00001, loss_test:0.09703, lr:2.13e-03, fs:0.62667 (r=0.475,p=0.922),  time:36.455, tt:7436.832\n",
      "Ep:204, loss:0.00001, loss_test:0.09608, lr:2.11e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.457, tt:7473.668\n",
      "Ep:205, loss:0.00001, loss_test:0.09655, lr:2.08e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.466, tt:7511.964\n",
      "Ep:206, loss:0.00001, loss_test:0.09749, lr:2.06e-03, fs:0.61745 (r=0.465,p=0.920),  time:36.461, tt:7547.451\n",
      "Ep:207, loss:0.00001, loss_test:0.09604, lr:2.04e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.464, tt:7584.611\n",
      "Ep:208, loss:0.00001, loss_test:0.09799, lr:2.02e-03, fs:0.60927 (r=0.465,p=0.885),  time:36.461, tt:7620.258\n",
      "Ep:209, loss:0.00000, loss_test:0.09643, lr:2.00e-03, fs:0.61333 (r=0.465,p=0.902),  time:36.450, tt:7654.506\n",
      "Ep:210, loss:0.00000, loss_test:0.09586, lr:1.98e-03, fs:0.61333 (r=0.465,p=0.902),  time:36.434, tt:7687.637\n",
      "Ep:211, loss:0.00000, loss_test:0.09791, lr:1.96e-03, fs:0.61333 (r=0.465,p=0.902),  time:36.399, tt:7716.626\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.03391, lr:6.00e-02, fs:0.57277 (r=0.616,p=0.535),  time:23.852, tt:23.852\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02474, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:25.432, tt:50.863\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02451, lr:6.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:27.193, tt:81.579\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02485, lr:6.00e-02, fs:0.68310 (r=0.980,p=0.524),  time:28.267, tt:113.069\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02453, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:29.601, tt:148.006\n",
      "Ep:5, loss:0.00005, loss_test:0.02472, lr:6.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:30.317, tt:181.899\n",
      "Ep:6, loss:0.00005, loss_test:0.02502, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:30.949, tt:216.641\n",
      "Ep:7, loss:0.00005, loss_test:0.02497, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:31.319, tt:250.556\n",
      "Ep:8, loss:0.00005, loss_test:0.02471, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:31.723, tt:285.508\n",
      "Ep:9, loss:0.00005, loss_test:0.02448, lr:6.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:32.011, tt:320.107\n",
      "Ep:10, loss:0.00005, loss_test:0.02419, lr:6.00e-02, fs:0.64591 (r=0.838,p=0.525),  time:32.284, tt:355.119\n",
      "Ep:11, loss:0.00004, loss_test:0.02385, lr:6.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:32.537, tt:390.447\n",
      "Ep:12, loss:0.00004, loss_test:0.02353, lr:6.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:32.765, tt:425.944\n",
      "Ep:13, loss:0.00004, loss_test:0.02316, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:32.896, tt:460.548\n",
      "Ep:14, loss:0.00004, loss_test:0.02279, lr:6.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:33.052, tt:495.784\n",
      "Ep:15, loss:0.00004, loss_test:0.02250, lr:5.94e-02, fs:0.64435 (r=0.778,p=0.550),  time:33.079, tt:529.267\n",
      "Ep:16, loss:0.00004, loss_test:0.02232, lr:5.88e-02, fs:0.63559 (r=0.758,p=0.547),  time:33.265, tt:565.499\n",
      "Ep:17, loss:0.00004, loss_test:0.02225, lr:5.82e-02, fs:0.62338 (r=0.727,p=0.545),  time:33.336, tt:600.051\n",
      "Ep:18, loss:0.00003, loss_test:0.02221, lr:5.76e-02, fs:0.62069 (r=0.727,p=0.541),  time:33.405, tt:634.688\n",
      "Ep:19, loss:0.00003, loss_test:0.02205, lr:5.71e-02, fs:0.64348 (r=0.747,p=0.565),  time:33.456, tt:669.128\n",
      "Ep:20, loss:0.00003, loss_test:0.02175, lr:5.65e-02, fs:0.64912 (r=0.747,p=0.574),  time:33.476, tt:702.993\n",
      "Ep:21, loss:0.00003, loss_test:0.02161, lr:5.59e-02, fs:0.66957 (r=0.778,p=0.588),  time:33.628, tt:739.806\n",
      "Ep:22, loss:0.00003, loss_test:0.02175, lr:5.54e-02, fs:0.66376 (r=0.768,p=0.585),  time:33.699, tt:775.080\n",
      "Ep:23, loss:0.00003, loss_test:0.02192, lr:5.48e-02, fs:0.65471 (r=0.737,p=0.589),  time:33.719, tt:809.248\n",
      "Ep:24, loss:0.00003, loss_test:0.02178, lr:5.43e-02, fs:0.63964 (r=0.717,p=0.577),  time:33.806, tt:845.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00003, loss_test:0.02163, lr:5.37e-02, fs:0.65778 (r=0.747,p=0.587),  time:33.851, tt:880.131\n",
      "Ep:26, loss:0.00003, loss_test:0.02166, lr:5.32e-02, fs:0.66071 (r=0.747,p=0.592),  time:33.844, tt:913.793\n",
      "Ep:27, loss:0.00002, loss_test:0.02177, lr:5.27e-02, fs:0.66368 (r=0.747,p=0.597),  time:33.925, tt:949.914\n",
      "Ep:28, loss:0.00002, loss_test:0.02173, lr:5.21e-02, fs:0.65158 (r=0.727,p=0.590),  time:33.987, tt:985.623\n",
      "Ep:29, loss:0.00002, loss_test:0.02171, lr:5.16e-02, fs:0.65741 (r=0.717,p=0.607),  time:34.004, tt:1020.132\n",
      "Ep:30, loss:0.00002, loss_test:0.02168, lr:5.11e-02, fs:0.65741 (r=0.717,p=0.607),  time:33.999, tt:1053.960\n",
      "Ep:31, loss:0.00002, loss_test:0.02157, lr:5.06e-02, fs:0.65728 (r=0.707,p=0.614),  time:33.990, tt:1087.675\n",
      "Ep:32, loss:0.00002, loss_test:0.02169, lr:5.01e-02, fs:0.66029 (r=0.697,p=0.627),  time:34.093, tt:1125.078\n",
      "Ep:33, loss:0.00002, loss_test:0.02185, lr:4.96e-02, fs:0.65366 (r=0.677,p=0.632),  time:34.124, tt:1160.230\n",
      "Ep:34, loss:0.00002, loss_test:0.02185, lr:4.91e-02, fs:0.64390 (r=0.667,p=0.623),  time:34.200, tt:1196.994\n",
      "Ep:35, loss:0.00002, loss_test:0.02187, lr:4.86e-02, fs:0.64390 (r=0.667,p=0.623),  time:34.208, tt:1231.478\n",
      "Ep:36, loss:0.00002, loss_test:0.02193, lr:4.81e-02, fs:0.63415 (r=0.657,p=0.613),  time:34.233, tt:1266.618\n",
      "Ep:37, loss:0.00002, loss_test:0.02203, lr:4.76e-02, fs:0.63107 (r=0.657,p=0.607),  time:34.237, tt:1300.996\n",
      "Ep:38, loss:0.00001, loss_test:0.02213, lr:4.71e-02, fs:0.63415 (r=0.657,p=0.613),  time:34.255, tt:1335.964\n",
      "Ep:39, loss:0.00001, loss_test:0.02228, lr:4.67e-02, fs:0.63682 (r=0.646,p=0.627),  time:34.266, tt:1370.641\n",
      "Ep:40, loss:0.00001, loss_test:0.02251, lr:4.62e-02, fs:0.63000 (r=0.636,p=0.624),  time:34.304, tt:1406.472\n",
      "Ep:41, loss:0.00001, loss_test:0.02276, lr:4.57e-02, fs:0.63959 (r=0.636,p=0.643),  time:34.275, tt:1439.535\n",
      "Ep:42, loss:0.00001, loss_test:0.02302, lr:4.53e-02, fs:0.64286 (r=0.636,p=0.649),  time:34.291, tt:1474.527\n",
      "Ep:43, loss:0.00001, loss_test:0.02325, lr:4.48e-02, fs:0.64948 (r=0.636,p=0.663),  time:34.324, tt:1510.263\n",
      "Ep:44, loss:0.00001, loss_test:0.02362, lr:4.44e-02, fs:0.65263 (r=0.626,p=0.681),  time:34.335, tt:1545.080\n",
      "Ep:45, loss:0.00001, loss_test:0.02401, lr:4.39e-02, fs:0.66310 (r=0.626,p=0.705),  time:34.349, tt:1580.070\n",
      "Ep:46, loss:0.00001, loss_test:0.02415, lr:4.35e-02, fs:0.66310 (r=0.626,p=0.705),  time:34.363, tt:1615.052\n",
      "Ep:47, loss:0.00001, loss_test:0.02406, lr:4.31e-02, fs:0.65957 (r=0.626,p=0.697),  time:34.408, tt:1651.582\n",
      "Ep:48, loss:0.00001, loss_test:0.02447, lr:4.26e-02, fs:0.65957 (r=0.626,p=0.697),  time:34.449, tt:1688.013\n",
      "Ep:49, loss:0.00001, loss_test:0.02478, lr:4.22e-02, fs:0.66667 (r=0.626,p=0.713),  time:34.483, tt:1724.145\n",
      "Ep:50, loss:0.00001, loss_test:0.02504, lr:4.18e-02, fs:0.65591 (r=0.616,p=0.701),  time:34.505, tt:1759.736\n",
      "Ep:51, loss:0.00001, loss_test:0.02533, lr:4.14e-02, fs:0.66304 (r=0.616,p=0.718),  time:34.514, tt:1794.740\n",
      "Ep:52, loss:0.00001, loss_test:0.02540, lr:4.10e-02, fs:0.65946 (r=0.616,p=0.709),  time:34.558, tt:1831.596\n",
      "Ep:53, loss:0.00001, loss_test:0.02581, lr:4.05e-02, fs:0.65591 (r=0.616,p=0.701),  time:34.579, tt:1867.262\n",
      "Ep:54, loss:0.00001, loss_test:0.02638, lr:4.01e-02, fs:0.66667 (r=0.616,p=0.726),  time:34.597, tt:1902.822\n",
      "Ep:55, loss:0.00001, loss_test:0.02649, lr:3.97e-02, fs:0.66667 (r=0.616,p=0.726),  time:34.619, tt:1938.643\n",
      "Ep:56, loss:0.00001, loss_test:0.02655, lr:3.93e-02, fs:0.66667 (r=0.616,p=0.726),  time:34.644, tt:1974.716\n",
      "Ep:57, loss:0.00001, loss_test:0.02676, lr:3.89e-02, fs:0.67033 (r=0.616,p=0.735),  time:34.653, tt:2009.854\n",
      "Ep:58, loss:0.00001, loss_test:0.02732, lr:3.86e-02, fs:0.67403 (r=0.616,p=0.744),  time:34.646, tt:2044.137\n",
      "Ep:59, loss:0.00001, loss_test:0.02722, lr:3.82e-02, fs:0.66667 (r=0.616,p=0.726),  time:34.661, tt:2079.680\n",
      "Ep:60, loss:0.00001, loss_test:0.02747, lr:3.78e-02, fs:0.66298 (r=0.606,p=0.732),  time:34.660, tt:2114.248\n",
      "Ep:61, loss:0.00001, loss_test:0.02779, lr:3.74e-02, fs:0.67039 (r=0.606,p=0.750),  time:34.686, tt:2150.559\n",
      "Ep:62, loss:0.00001, loss_test:0.02790, lr:3.70e-02, fs:0.67416 (r=0.606,p=0.759),  time:34.703, tt:2186.292\n",
      "Ep:63, loss:0.00001, loss_test:0.02829, lr:3.67e-02, fs:0.67416 (r=0.606,p=0.759),  time:34.726, tt:2222.448\n",
      "Ep:64, loss:0.00001, loss_test:0.02862, lr:3.63e-02, fs:0.67797 (r=0.606,p=0.769),  time:34.715, tt:2256.472\n",
      "Ep:65, loss:0.00001, loss_test:0.02870, lr:3.59e-02, fs:0.67416 (r=0.606,p=0.759),  time:34.730, tt:2292.157\n",
      "Ep:66, loss:0.00001, loss_test:0.02914, lr:3.56e-02, fs:0.67797 (r=0.606,p=0.769),  time:34.744, tt:2327.830\n",
      "Ep:67, loss:0.00001, loss_test:0.02942, lr:3.52e-02, fs:0.67797 (r=0.606,p=0.769),  time:34.761, tt:2363.776\n",
      "Ep:68, loss:0.00001, loss_test:0.02943, lr:3.49e-02, fs:0.67045 (r=0.596,p=0.766),  time:34.790, tt:2400.485\n",
      "Ep:69, loss:0.00001, loss_test:0.02987, lr:3.45e-02, fs:0.66667 (r=0.586,p=0.773),  time:34.792, tt:2435.451\n",
      "Ep:70, loss:0.00001, loss_test:0.02999, lr:3.42e-02, fs:0.66667 (r=0.586,p=0.773),  time:34.805, tt:2471.170\n",
      "Ep:71, loss:0.00001, loss_test:0.03007, lr:3.38e-02, fs:0.65909 (r=0.586,p=0.753),  time:34.805, tt:2505.957\n",
      "Ep:72, loss:0.00001, loss_test:0.03032, lr:3.35e-02, fs:0.66667 (r=0.586,p=0.773),  time:34.806, tt:2540.833\n",
      "Ep:73, loss:0.00000, loss_test:0.03044, lr:3.32e-02, fs:0.66279 (r=0.576,p=0.781),  time:34.819, tt:2576.606\n",
      "Ep:74, loss:0.00000, loss_test:0.03054, lr:3.28e-02, fs:0.65896 (r=0.576,p=0.770),  time:34.802, tt:2610.146\n",
      "Ep:75, loss:0.00000, loss_test:0.03078, lr:3.25e-02, fs:0.65896 (r=0.576,p=0.770),  time:34.786, tt:2643.736\n",
      "Ep:76, loss:0.00000, loss_test:0.03096, lr:3.22e-02, fs:0.66279 (r=0.576,p=0.781),  time:34.790, tt:2678.852\n",
      "Ep:77, loss:0.00000, loss_test:0.03067, lr:3.19e-02, fs:0.65896 (r=0.576,p=0.770),  time:34.803, tt:2714.636\n",
      "Ep:78, loss:0.00000, loss_test:0.03100, lr:3.15e-02, fs:0.65896 (r=0.576,p=0.770),  time:34.828, tt:2751.384\n",
      "Ep:79, loss:0.00000, loss_test:0.03132, lr:3.12e-02, fs:0.67059 (r=0.576,p=0.803),  time:34.835, tt:2786.814\n",
      "Ep:80, loss:0.00000, loss_test:0.03108, lr:3.09e-02, fs:0.65896 (r=0.576,p=0.770),  time:34.846, tt:2822.531\n",
      "Ep:81, loss:0.00000, loss_test:0.03125, lr:3.06e-02, fs:0.66279 (r=0.576,p=0.781),  time:34.842, tt:2857.056\n",
      "Ep:82, loss:0.00000, loss_test:0.03146, lr:3.03e-02, fs:0.65896 (r=0.576,p=0.770),  time:34.839, tt:2891.619\n",
      "Ep:83, loss:0.00000, loss_test:0.03145, lr:3.00e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.846, tt:2927.068\n",
      "Ep:84, loss:0.00000, loss_test:0.03154, lr:2.97e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.861, tt:2963.203\n",
      "Ep:85, loss:0.00000, loss_test:0.03162, lr:2.94e-02, fs:0.66279 (r=0.576,p=0.781),  time:34.849, tt:2997.035\n",
      "Ep:86, loss:0.00000, loss_test:0.03169, lr:2.91e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.866, tt:3033.331\n",
      "Ep:87, loss:0.00000, loss_test:0.03183, lr:2.88e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.879, tt:3069.372\n",
      "Ep:88, loss:0.00000, loss_test:0.03201, lr:2.85e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.884, tt:3104.658\n",
      "Ep:89, loss:0.00000, loss_test:0.03205, lr:2.82e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.883, tt:3139.435\n",
      "Ep:90, loss:0.00000, loss_test:0.03215, lr:2.80e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.889, tt:3174.889\n",
      "Ep:91, loss:0.00000, loss_test:0.03226, lr:2.77e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.930, tt:3213.601\n",
      "Ep:92, loss:0.00000, loss_test:0.03241, lr:2.74e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.937, tt:3249.177\n",
      "Ep:93, loss:0.00000, loss_test:0.03246, lr:2.71e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.938, tt:3284.212\n",
      "Ep:94, loss:0.00000, loss_test:0.03254, lr:2.69e-02, fs:0.66667 (r=0.576,p=0.792),  time:34.945, tt:3319.800\n",
      "Ep:95, loss:0.00000, loss_test:0.03268, lr:2.66e-02, fs:0.67059 (r=0.576,p=0.803),  time:34.956, tt:3355.769\n",
      "Ep:96, loss:0.00000, loss_test:0.03282, lr:2.63e-02, fs:0.67059 (r=0.576,p=0.803),  time:34.961, tt:3391.182\n",
      "Ep:97, loss:0.00000, loss_test:0.03284, lr:2.61e-02, fs:0.67059 (r=0.576,p=0.803),  time:34.963, tt:3426.417\n",
      "Ep:98, loss:0.00000, loss_test:0.03288, lr:2.58e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.967, tt:3461.697\n",
      "Ep:99, loss:0.00000, loss_test:0.03301, lr:2.55e-02, fs:0.67059 (r=0.576,p=0.803),  time:34.980, tt:3497.950\n",
      "Ep:100, loss:0.00000, loss_test:0.03315, lr:2.53e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.989, tt:3533.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00000, loss_test:0.03322, lr:2.50e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.011, tt:3571.169\n",
      "Ep:102, loss:0.00000, loss_test:0.03321, lr:2.48e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.031, tt:3608.144\n",
      "Ep:103, loss:0.00000, loss_test:0.03328, lr:2.45e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.028, tt:3642.943\n",
      "Ep:104, loss:0.00000, loss_test:0.03349, lr:2.43e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.032, tt:3678.309\n",
      "Ep:105, loss:0.00000, loss_test:0.03361, lr:2.40e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.036, tt:3713.795\n",
      "Ep:106, loss:0.00000, loss_test:0.03366, lr:2.38e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.033, tt:3748.541\n",
      "Ep:107, loss:0.00000, loss_test:0.03361, lr:2.36e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.041, tt:3784.470\n",
      "Ep:108, loss:0.00000, loss_test:0.03380, lr:2.33e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.048, tt:3820.216\n",
      "Ep:109, loss:0.00000, loss_test:0.03389, lr:2.31e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.063, tt:3856.936\n",
      "Ep:110, loss:0.00000, loss_test:0.03394, lr:2.29e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.073, tt:3893.132\n",
      "Ep:111, loss:0.00000, loss_test:0.03402, lr:2.26e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.094, tt:3930.583\n",
      "Ep:112, loss:0.00000, loss_test:0.03408, lr:2.24e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.098, tt:3966.029\n",
      "Ep:113, loss:0.00000, loss_test:0.03404, lr:2.22e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.089, tt:4000.116\n",
      "Ep:114, loss:0.00000, loss_test:0.03411, lr:2.20e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.100, tt:4036.456\n",
      "Ep:115, loss:0.00000, loss_test:0.03425, lr:2.17e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.103, tt:4071.908\n",
      "Ep:116, loss:0.00000, loss_test:0.03431, lr:2.15e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.111, tt:4107.986\n",
      "Ep:117, loss:0.00000, loss_test:0.03426, lr:2.13e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.117, tt:4143.856\n",
      "Ep:118, loss:0.00000, loss_test:0.03440, lr:2.11e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.120, tt:4179.304\n",
      "Ep:119, loss:0.00000, loss_test:0.03442, lr:2.09e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.121, tt:4214.530\n",
      "Ep:120, loss:0.00000, loss_test:0.03450, lr:2.07e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.121, tt:4249.672\n",
      "Ep:121, loss:0.00000, loss_test:0.03451, lr:2.05e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.124, tt:4285.125\n",
      "Ep:122, loss:0.00000, loss_test:0.03456, lr:2.03e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.129, tt:4320.874\n",
      "Ep:123, loss:0.00000, loss_test:0.03465, lr:2.01e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.141, tt:4357.531\n",
      "Ep:124, loss:0.00000, loss_test:0.03465, lr:1.99e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.141, tt:4392.590\n",
      "Ep:125, loss:0.00000, loss_test:0.03470, lr:1.97e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.152, tt:4429.094\n",
      "Ep:126, loss:0.00000, loss_test:0.03474, lr:1.95e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.156, tt:4464.767\n",
      "Ep:127, loss:0.00000, loss_test:0.03478, lr:1.93e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.156, tt:4499.925\n",
      "Ep:128, loss:0.00000, loss_test:0.03478, lr:1.91e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.161, tt:4535.733\n",
      "Ep:129, loss:0.00000, loss_test:0.03489, lr:1.89e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.163, tt:4571.211\n",
      "Ep:130, loss:0.00000, loss_test:0.03490, lr:1.87e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.183, tt:4608.964\n",
      "Ep:131, loss:0.00000, loss_test:0.03489, lr:1.85e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.193, tt:4645.538\n",
      "Ep:132, loss:0.00000, loss_test:0.03492, lr:1.83e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.200, tt:4681.631\n",
      "Ep:133, loss:0.00000, loss_test:0.03499, lr:1.81e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.214, tt:4718.714\n",
      "Ep:134, loss:0.00000, loss_test:0.03505, lr:1.80e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.225, tt:4755.313\n",
      "Ep:135, loss:0.00000, loss_test:0.03509, lr:1.78e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.232, tt:4791.549\n",
      "Ep:136, loss:0.00000, loss_test:0.03513, lr:1.76e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.228, tt:4826.205\n",
      "Ep:137, loss:0.00000, loss_test:0.03513, lr:1.74e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.228, tt:4861.441\n",
      "Ep:138, loss:0.00000, loss_test:0.03519, lr:1.73e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.230, tt:4897.000\n",
      "Ep:139, loss:0.00000, loss_test:0.03522, lr:1.71e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.237, tt:4933.143\n",
      "Ep:140, loss:0.00000, loss_test:0.03524, lr:1.69e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.228, tt:4967.171\n",
      "Ep:141, loss:0.00000, loss_test:0.03524, lr:1.67e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.235, tt:5003.380\n",
      "Ep:142, loss:0.00000, loss_test:0.03531, lr:1.66e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.238, tt:5038.973\n",
      "Ep:143, loss:0.00000, loss_test:0.03539, lr:1.64e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.239, tt:5074.475\n",
      "Ep:144, loss:0.00000, loss_test:0.03539, lr:1.62e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.237, tt:5109.324\n",
      "Ep:145, loss:0.00000, loss_test:0.03543, lr:1.61e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.247, tt:5146.013\n",
      "Ep:146, loss:0.00000, loss_test:0.03546, lr:1.59e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.256, tt:5182.621\n",
      "Ep:147, loss:0.00000, loss_test:0.03552, lr:1.58e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.260, tt:5218.513\n",
      "Ep:148, loss:0.00000, loss_test:0.03551, lr:1.56e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.262, tt:5254.011\n",
      "Ep:149, loss:0.00000, loss_test:0.03560, lr:1.54e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.267, tt:5290.109\n",
      "Ep:150, loss:0.00000, loss_test:0.03559, lr:1.53e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.287, tt:5328.274\n",
      "Ep:151, loss:0.00000, loss_test:0.03561, lr:1.51e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.288, tt:5363.787\n",
      "Ep:152, loss:0.00000, loss_test:0.03568, lr:1.50e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.292, tt:5399.625\n",
      "Ep:153, loss:0.00000, loss_test:0.03572, lr:1.48e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.301, tt:5436.398\n",
      "Ep:154, loss:0.00000, loss_test:0.03574, lr:1.47e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.306, tt:5472.423\n",
      "Ep:155, loss:0.00000, loss_test:0.03579, lr:1.45e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.315, tt:5509.167\n",
      "Ep:156, loss:0.00000, loss_test:0.03583, lr:1.44e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.318, tt:5544.985\n",
      "Ep:157, loss:0.00000, loss_test:0.03587, lr:1.43e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.324, tt:5581.121\n",
      "Ep:158, loss:0.00000, loss_test:0.03589, lr:1.41e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.325, tt:5616.630\n",
      "Ep:159, loss:0.00000, loss_test:0.03591, lr:1.40e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.328, tt:5652.522\n",
      "Ep:160, loss:0.00000, loss_test:0.03594, lr:1.38e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.327, tt:5687.667\n",
      "Ep:161, loss:0.00000, loss_test:0.03597, lr:1.37e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.330, tt:5723.471\n",
      "Ep:162, loss:0.00000, loss_test:0.03600, lr:1.36e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.343, tt:5760.984\n",
      "Ep:163, loss:0.00000, loss_test:0.03601, lr:1.34e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.343, tt:5796.294\n",
      "Ep:164, loss:0.00000, loss_test:0.03609, lr:1.33e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.340, tt:5831.081\n",
      "Ep:165, loss:0.00000, loss_test:0.03613, lr:1.32e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.340, tt:5866.377\n",
      "Ep:166, loss:0.00000, loss_test:0.03613, lr:1.30e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.332, tt:5900.374\n",
      "Ep:167, loss:0.00000, loss_test:0.03615, lr:1.29e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.326, tt:5934.820\n",
      "Ep:168, loss:0.00000, loss_test:0.03620, lr:1.28e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.317, tt:5968.584\n",
      "Ep:169, loss:0.00000, loss_test:0.03620, lr:1.26e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.316, tt:6003.775\n",
      "Ep:170, loss:0.00000, loss_test:0.03625, lr:1.25e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.315, tt:6038.895\n",
      "Ep:171, loss:0.00000, loss_test:0.03626, lr:1.24e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.317, tt:6074.607\n",
      "Ep:172, loss:0.00000, loss_test:0.03628, lr:1.23e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.313, tt:6109.223\n",
      "Ep:173, loss:0.00000, loss_test:0.03634, lr:1.21e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.317, tt:6145.227\n",
      "Ep:174, loss:0.00000, loss_test:0.03637, lr:1.20e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.314, tt:6179.870\n",
      "Ep:175, loss:0.00000, loss_test:0.03637, lr:1.19e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.307, tt:6214.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:176, loss:0.00000, loss_test:0.03637, lr:1.18e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.311, tt:6250.090\n",
      "Ep:177, loss:0.00000, loss_test:0.03642, lr:1.17e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.313, tt:6285.734\n",
      "Ep:178, loss:0.00000, loss_test:0.03648, lr:1.15e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.315, tt:6321.317\n",
      "Ep:179, loss:0.00000, loss_test:0.03647, lr:1.14e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.307, tt:6355.178\n",
      "Ep:180, loss:0.00000, loss_test:0.03648, lr:1.13e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.308, tt:6390.684\n",
      "Ep:181, loss:0.00000, loss_test:0.03655, lr:1.12e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.300, tt:6424.635\n",
      "Ep:182, loss:0.00000, loss_test:0.03659, lr:1.11e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.303, tt:6460.500\n",
      "Ep:183, loss:0.00000, loss_test:0.03658, lr:1.10e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.297, tt:6494.654\n",
      "Ep:184, loss:0.00000, loss_test:0.03662, lr:1.09e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.301, tt:6530.624\n",
      "Ep:185, loss:0.00000, loss_test:0.03665, lr:1.08e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.299, tt:6565.620\n",
      "Ep:186, loss:0.00000, loss_test:0.03666, lr:1.07e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.299, tt:6600.832\n",
      "Ep:187, loss:0.00000, loss_test:0.03670, lr:1.05e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.296, tt:6635.675\n",
      "Ep:188, loss:0.00000, loss_test:0.03671, lr:1.04e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.306, tt:6672.759\n",
      "Ep:189, loss:0.00000, loss_test:0.03674, lr:1.03e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.313, tt:6709.420\n",
      "Ep:190, loss:0.00000, loss_test:0.03674, lr:1.02e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.329, tt:6747.778\n",
      "Ep:191, loss:0.00000, loss_test:0.03676, lr:1.01e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.345, tt:6786.293\n",
      "Ep:192, loss:0.00000, loss_test:0.03679, lr:1.00e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.355, tt:6823.473\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00000, loss_test:0.03680, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.356, tt:6859.112\n",
      "Ep:194, loss:0.00000, loss_test:0.03682, lr:1.00e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.356, tt:6894.494\n",
      "Ep:195, loss:0.00000, loss_test:0.03686, lr:1.00e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.358, tt:6930.209\n",
      "Ep:196, loss:0.00000, loss_test:0.03686, lr:1.00e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.359, tt:6965.821\n",
      "Ep:197, loss:0.00000, loss_test:0.03686, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.365, tt:7002.259\n",
      "Ep:198, loss:0.00000, loss_test:0.03689, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.364, tt:7037.505\n",
      "Ep:199, loss:0.00000, loss_test:0.03690, lr:1.00e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.365, tt:7073.035\n",
      "Ep:200, loss:0.00000, loss_test:0.03691, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.356, tt:7106.605\n",
      "Ep:201, loss:0.00000, loss_test:0.03694, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.326, tt:7135.890\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00029, loss_test:0.13825, lr:1.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:32.993, tt:32.993\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13552, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:30.481, tt:60.961\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13347, lr:1.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:31.082, tt:93.246\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13215, lr:1.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:31.650, tt:126.602\n",
      "Ep:4, loss:0.00027, loss_test:0.13148, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:32.553, tt:162.766\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.13148, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:33.055, tt:198.332\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.13168, lr:1.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:33.442, tt:234.097\n",
      "Ep:7, loss:0.00026, loss_test:0.13177, lr:1.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:33.830, tt:270.637\n",
      "Ep:8, loss:0.00026, loss_test:0.13171, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:34.126, tt:307.137\n",
      "Ep:9, loss:0.00026, loss_test:0.13191, lr:1.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:34.316, tt:343.158\n",
      "Ep:10, loss:0.00025, loss_test:0.13225, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:34.580, tt:380.382\n",
      "Ep:11, loss:0.00025, loss_test:0.13244, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:34.736, tt:416.835\n",
      "Ep:12, loss:0.00025, loss_test:0.13244, lr:1.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:34.889, tt:453.552\n",
      "Ep:13, loss:0.00025, loss_test:0.13232, lr:1.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:34.958, tt:489.407\n",
      "Ep:14, loss:0.00025, loss_test:0.13204, lr:1.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:35.033, tt:525.491\n",
      "Ep:15, loss:0.00025, loss_test:0.13166, lr:1.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:35.300, tt:564.807\n",
      "Ep:16, loss:0.00025, loss_test:0.13098, lr:1.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:35.384, tt:601.522\n",
      "Ep:17, loss:0.00024, loss_test:0.13009, lr:9.90e-03, fs:0.66129 (r=0.828,p=0.550),  time:35.417, tt:637.502\n",
      "Ep:18, loss:0.00024, loss_test:0.12906, lr:9.80e-03, fs:0.66667 (r=0.838,p=0.553),  time:35.491, tt:674.337\n",
      "Ep:19, loss:0.00024, loss_test:0.12798, lr:9.70e-03, fs:0.66667 (r=0.838,p=0.553),  time:35.549, tt:710.988\n",
      "Ep:20, loss:0.00024, loss_test:0.12698, lr:9.61e-03, fs:0.67470 (r=0.848,p=0.560),  time:35.585, tt:747.291\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00024, loss_test:0.12628, lr:9.61e-03, fs:0.67742 (r=0.848,p=0.564),  time:35.595, tt:783.085\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.12604, lr:9.61e-03, fs:0.67742 (r=0.848,p=0.564),  time:35.661, tt:820.195\n",
      "Ep:23, loss:0.00023, loss_test:0.12542, lr:9.61e-03, fs:0.67742 (r=0.848,p=0.564),  time:35.699, tt:856.777\n",
      "Ep:24, loss:0.00023, loss_test:0.12373, lr:9.61e-03, fs:0.68016 (r=0.848,p=0.568),  time:35.687, tt:892.165\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00022, loss_test:0.12129, lr:9.61e-03, fs:0.68826 (r=0.859,p=0.574),  time:35.722, tt:928.768\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00022, loss_test:0.11957, lr:9.61e-03, fs:0.69106 (r=0.859,p=0.578),  time:35.734, tt:964.823\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00022, loss_test:0.11828, lr:9.61e-03, fs:0.69388 (r=0.859,p=0.582),  time:35.723, tt:1000.255\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00021, loss_test:0.11536, lr:9.61e-03, fs:0.70000 (r=0.848,p=0.596),  time:35.718, tt:1035.814\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00020, loss_test:0.11172, lr:9.61e-03, fs:0.71967 (r=0.869,p=0.614),  time:35.744, tt:1072.322\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00020, loss_test:0.10882, lr:9.61e-03, fs:0.72269 (r=0.869,p=0.619),  time:35.766, tt:1108.733\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00019, loss_test:0.10826, lr:9.61e-03, fs:0.73504 (r=0.869,p=0.637),  time:35.787, tt:1145.184\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00018, loss_test:0.10432, lr:9.61e-03, fs:0.73593 (r=0.859,p=0.644),  time:35.762, tt:1180.160\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00017, loss_test:0.10250, lr:9.61e-03, fs:0.73973 (r=0.818,p=0.675),  time:35.753, tt:1215.602\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.10489, lr:9.61e-03, fs:0.67633 (r=0.707,p=0.648),  time:35.765, tt:1251.788\n",
      "Ep:35, loss:0.00016, loss_test:0.09809, lr:9.61e-03, fs:0.70297 (r=0.717,p=0.689),  time:35.744, tt:1286.788\n",
      "Ep:36, loss:0.00015, loss_test:0.10281, lr:9.61e-03, fs:0.72986 (r=0.778,p=0.688),  time:35.777, tt:1323.744\n",
      "Ep:37, loss:0.00015, loss_test:0.09928, lr:9.61e-03, fs:0.73430 (r=0.768,p=0.704),  time:35.773, tt:1359.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00014, loss_test:0.09839, lr:9.61e-03, fs:0.72906 (r=0.747,p=0.712),  time:35.778, tt:1395.359\n",
      "Ep:39, loss:0.00013, loss_test:0.10790, lr:9.61e-03, fs:0.70423 (r=0.758,p=0.658),  time:35.766, tt:1430.632\n",
      "Ep:40, loss:0.00013, loss_test:0.10055, lr:9.61e-03, fs:0.71845 (r=0.747,p=0.692),  time:35.775, tt:1466.765\n",
      "Ep:41, loss:0.00012, loss_test:0.10721, lr:9.61e-03, fs:0.68627 (r=0.707,p=0.667),  time:35.736, tt:1500.914\n",
      "Ep:42, loss:0.00012, loss_test:0.10077, lr:9.61e-03, fs:0.70297 (r=0.717,p=0.689),  time:35.766, tt:1537.919\n",
      "Ep:43, loss:0.00011, loss_test:0.10488, lr:9.61e-03, fs:0.68599 (r=0.717,p=0.657),  time:35.765, tt:1573.643\n",
      "Ep:44, loss:0.00011, loss_test:0.10474, lr:9.61e-03, fs:0.69608 (r=0.717,p=0.676),  time:35.777, tt:1609.987\n",
      "Ep:45, loss:0.00010, loss_test:0.09147, lr:9.51e-03, fs:0.72632 (r=0.697,p=0.758),  time:35.756, tt:1644.798\n",
      "Ep:46, loss:0.00010, loss_test:0.09734, lr:9.41e-03, fs:0.72727 (r=0.727,p=0.727),  time:35.757, tt:1680.602\n",
      "Ep:47, loss:0.00009, loss_test:0.10184, lr:9.32e-03, fs:0.70707 (r=0.707,p=0.707),  time:35.753, tt:1716.154\n",
      "Ep:48, loss:0.00008, loss_test:0.09857, lr:9.23e-03, fs:0.72917 (r=0.707,p=0.753),  time:35.753, tt:1751.910\n",
      "Ep:49, loss:0.00008, loss_test:0.09532, lr:9.14e-03, fs:0.74468 (r=0.707,p=0.787),  time:35.720, tt:1786.009\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.10525, lr:9.14e-03, fs:0.68041 (r=0.667,p=0.695),  time:35.732, tt:1822.317\n",
      "Ep:51, loss:0.00007, loss_test:0.09877, lr:9.14e-03, fs:0.74468 (r=0.707,p=0.787),  time:35.725, tt:1857.696\n",
      "Ep:52, loss:0.00007, loss_test:0.10319, lr:9.14e-03, fs:0.68783 (r=0.657,p=0.722),  time:35.716, tt:1892.932\n",
      "Ep:53, loss:0.00006, loss_test:0.09588, lr:9.14e-03, fs:0.75936 (r=0.717,p=0.807),  time:35.701, tt:1927.854\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.09911, lr:9.14e-03, fs:0.70588 (r=0.667,p=0.750),  time:35.692, tt:1963.040\n",
      "Ep:55, loss:0.00006, loss_test:0.09086, lr:9.14e-03, fs:0.74033 (r=0.677,p=0.817),  time:35.691, tt:1998.681\n",
      "Ep:56, loss:0.00006, loss_test:0.09939, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:35.687, tt:2034.154\n",
      "Ep:57, loss:0.00005, loss_test:0.09757, lr:9.14e-03, fs:0.72527 (r=0.667,p=0.795),  time:35.683, tt:2069.596\n",
      "Ep:58, loss:0.00005, loss_test:0.09558, lr:9.14e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.696, tt:2106.076\n",
      "Ep:59, loss:0.00005, loss_test:0.09535, lr:9.14e-03, fs:0.73743 (r=0.667,p=0.825),  time:35.683, tt:2140.995\n",
      "Ep:60, loss:0.00005, loss_test:0.09565, lr:9.14e-03, fs:0.73143 (r=0.646,p=0.842),  time:35.677, tt:2176.311\n",
      "Ep:61, loss:0.00004, loss_test:0.10030, lr:9.14e-03, fs:0.72928 (r=0.667,p=0.805),  time:35.642, tt:2209.774\n",
      "Ep:62, loss:0.00004, loss_test:0.08889, lr:9.14e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.613, tt:2243.622\n",
      "Ep:63, loss:0.00004, loss_test:0.10143, lr:9.14e-03, fs:0.73743 (r=0.667,p=0.825),  time:35.604, tt:2278.654\n",
      "Ep:64, loss:0.00004, loss_test:0.08656, lr:9.14e-03, fs:0.74286 (r=0.657,p=0.855),  time:35.575, tt:2312.388\n",
      "Ep:65, loss:0.00004, loss_test:0.10097, lr:9.04e-03, fs:0.73333 (r=0.667,p=0.815),  time:35.556, tt:2346.725\n",
      "Ep:66, loss:0.00003, loss_test:0.09085, lr:8.95e-03, fs:0.73143 (r=0.646,p=0.842),  time:35.557, tt:2382.290\n",
      "Ep:67, loss:0.00003, loss_test:0.09734, lr:8.86e-03, fs:0.73864 (r=0.657,p=0.844),  time:35.576, tt:2419.178\n",
      "Ep:68, loss:0.00003, loss_test:0.09192, lr:8.78e-03, fs:0.73743 (r=0.667,p=0.825),  time:35.584, tt:2455.309\n",
      "Ep:69, loss:0.00003, loss_test:0.09330, lr:8.69e-03, fs:0.73864 (r=0.657,p=0.844),  time:35.587, tt:2491.068\n",
      "Ep:70, loss:0.00003, loss_test:0.10329, lr:8.60e-03, fs:0.74157 (r=0.667,p=0.835),  time:35.568, tt:2525.314\n",
      "Ep:71, loss:0.00003, loss_test:0.09030, lr:8.51e-03, fs:0.74286 (r=0.657,p=0.855),  time:35.577, tt:2561.563\n",
      "Ep:72, loss:0.00003, loss_test:0.09566, lr:8.43e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.574, tt:2596.894\n",
      "Ep:73, loss:0.00002, loss_test:0.09679, lr:8.35e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.589, tt:2633.557\n",
      "Ep:74, loss:0.00002, loss_test:0.09605, lr:8.26e-03, fs:0.74157 (r=0.667,p=0.835),  time:35.594, tt:2669.521\n",
      "Ep:75, loss:0.00002, loss_test:0.09872, lr:8.18e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.593, tt:2705.039\n",
      "Ep:76, loss:0.00002, loss_test:0.10384, lr:8.10e-03, fs:0.74157 (r=0.667,p=0.835),  time:35.611, tt:2742.016\n",
      "Ep:77, loss:0.00002, loss_test:0.09386, lr:8.02e-03, fs:0.74713 (r=0.657,p=0.867),  time:35.603, tt:2777.016\n",
      "Ep:78, loss:0.00002, loss_test:0.10320, lr:7.94e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.596, tt:2812.049\n",
      "Ep:79, loss:0.00002, loss_test:0.10232, lr:7.86e-03, fs:0.71676 (r=0.626,p=0.838),  time:35.576, tt:2846.073\n",
      "Ep:80, loss:0.00002, loss_test:0.09850, lr:7.78e-03, fs:0.74157 (r=0.667,p=0.835),  time:35.572, tt:2881.329\n",
      "Ep:81, loss:0.00002, loss_test:0.10338, lr:7.70e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.586, tt:2918.078\n",
      "Ep:82, loss:0.00002, loss_test:0.09979, lr:7.62e-03, fs:0.75000 (r=0.667,p=0.857),  time:35.573, tt:2952.522\n",
      "Ep:83, loss:0.00002, loss_test:0.10512, lr:7.55e-03, fs:0.72832 (r=0.636,p=0.851),  time:35.576, tt:2988.354\n",
      "Ep:84, loss:0.00002, loss_test:0.10414, lr:7.47e-03, fs:0.71676 (r=0.626,p=0.838),  time:35.576, tt:3023.946\n",
      "Ep:85, loss:0.00002, loss_test:0.09815, lr:7.40e-03, fs:0.74419 (r=0.646,p=0.877),  time:35.569, tt:3058.935\n",
      "Ep:86, loss:0.00002, loss_test:0.10557, lr:7.32e-03, fs:0.72832 (r=0.636,p=0.851),  time:35.559, tt:3093.655\n",
      "Ep:87, loss:0.00002, loss_test:0.10042, lr:7.25e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.568, tt:3129.968\n",
      "Ep:88, loss:0.00002, loss_test:0.10291, lr:7.18e-03, fs:0.73684 (r=0.636,p=0.875),  time:35.569, tt:3165.596\n",
      "Ep:89, loss:0.00002, loss_test:0.10505, lr:7.11e-03, fs:0.72000 (r=0.636,p=0.829),  time:35.576, tt:3201.844\n",
      "Ep:90, loss:0.00001, loss_test:0.09879, lr:7.03e-03, fs:0.74419 (r=0.646,p=0.877),  time:35.588, tt:3238.543\n",
      "Ep:91, loss:0.00001, loss_test:0.10694, lr:6.96e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.584, tt:3273.715\n",
      "Ep:92, loss:0.00001, loss_test:0.10177, lr:6.89e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.596, tt:3310.418\n",
      "Ep:93, loss:0.00001, loss_test:0.10541, lr:6.83e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.621, tt:3348.386\n",
      "Ep:94, loss:0.00001, loss_test:0.10143, lr:6.76e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.645, tt:3386.263\n",
      "Ep:95, loss:0.00001, loss_test:0.10495, lr:6.69e-03, fs:0.73684 (r=0.636,p=0.875),  time:35.677, tt:3424.979\n",
      "Ep:96, loss:0.00001, loss_test:0.10981, lr:6.62e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.690, tt:3461.969\n",
      "Ep:97, loss:0.00001, loss_test:0.10013, lr:6.56e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.691, tt:3497.732\n",
      "Ep:98, loss:0.00001, loss_test:0.10902, lr:6.49e-03, fs:0.72832 (r=0.636,p=0.851),  time:35.674, tt:3531.759\n",
      "Ep:99, loss:0.00001, loss_test:0.10023, lr:6.43e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.676, tt:3567.623\n",
      "Ep:100, loss:0.00001, loss_test:0.10989, lr:6.36e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.691, tt:3604.826\n",
      "Ep:101, loss:0.00001, loss_test:0.10816, lr:6.30e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.748, tt:3646.342\n",
      "Ep:102, loss:0.00001, loss_test:0.10134, lr:6.24e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.760, tt:3683.295\n",
      "Ep:103, loss:0.00001, loss_test:0.10848, lr:6.17e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.778, tt:3720.881\n",
      "Ep:104, loss:0.00001, loss_test:0.10343, lr:6.11e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.804, tt:3759.401\n",
      "Ep:105, loss:0.00001, loss_test:0.10605, lr:6.05e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.825, tt:3797.462\n",
      "Ep:106, loss:0.00001, loss_test:0.10652, lr:5.99e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.850, tt:3836.002\n",
      "Ep:107, loss:0.00001, loss_test:0.10390, lr:5.93e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.874, tt:3874.365\n",
      "Ep:108, loss:0.00001, loss_test:0.10761, lr:5.87e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.862, tt:3908.977\n",
      "Ep:109, loss:0.00001, loss_test:0.10346, lr:5.81e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.862, tt:3944.778\n",
      "Ep:110, loss:0.00001, loss_test:0.10948, lr:5.75e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.864, tt:3980.867\n",
      "Ep:111, loss:0.00001, loss_test:0.11040, lr:5.70e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.860, tt:4016.340\n",
      "Ep:112, loss:0.00001, loss_test:0.10988, lr:5.64e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.854, tt:4051.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00001, loss_test:0.10519, lr:5.58e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.843, tt:4086.082\n",
      "Ep:114, loss:0.00001, loss_test:0.11230, lr:5.53e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.831, tt:4120.559\n",
      "Ep:115, loss:0.00001, loss_test:0.10546, lr:5.47e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.830, tt:4156.273\n",
      "Ep:116, loss:0.00001, loss_test:0.11089, lr:5.42e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.833, tt:4192.404\n",
      "Ep:117, loss:0.00001, loss_test:0.10921, lr:5.36e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.829, tt:4227.832\n",
      "Ep:118, loss:0.00001, loss_test:0.11745, lr:5.31e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.825, tt:4263.228\n",
      "Ep:119, loss:0.00001, loss_test:0.10618, lr:5.26e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.823, tt:4298.740\n",
      "Ep:120, loss:0.00001, loss_test:0.11335, lr:5.20e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.832, tt:4335.726\n",
      "Ep:121, loss:0.00001, loss_test:0.11569, lr:5.15e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.833, tt:4371.633\n",
      "Ep:122, loss:0.00001, loss_test:0.11324, lr:5.10e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.836, tt:4407.877\n",
      "Ep:123, loss:0.00001, loss_test:0.11505, lr:5.05e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.830, tt:4442.911\n",
      "Ep:124, loss:0.00001, loss_test:0.11521, lr:5.00e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.826, tt:4478.239\n",
      "Ep:125, loss:0.00001, loss_test:0.11578, lr:4.95e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.817, tt:4512.941\n",
      "Ep:126, loss:0.00001, loss_test:0.11408, lr:4.90e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.823, tt:4549.569\n",
      "Ep:127, loss:0.00001, loss_test:0.11462, lr:4.85e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.830, tt:4586.300\n",
      "Ep:128, loss:0.00001, loss_test:0.12019, lr:4.80e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.823, tt:4621.108\n",
      "Ep:129, loss:0.00001, loss_test:0.11607, lr:4.75e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.815, tt:4655.977\n",
      "Ep:130, loss:0.00001, loss_test:0.11955, lr:4.71e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.820, tt:4692.424\n",
      "Ep:131, loss:0.00001, loss_test:0.11118, lr:4.66e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.817, tt:4727.818\n",
      "Ep:132, loss:0.00001, loss_test:0.11836, lr:4.61e-03, fs:0.72093 (r=0.626,p=0.849),  time:35.828, tt:4765.163\n",
      "Ep:133, loss:0.00001, loss_test:0.11570, lr:4.57e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.839, tt:4802.436\n",
      "Ep:134, loss:0.00001, loss_test:0.11987, lr:4.52e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.871, tt:4842.600\n",
      "Ep:135, loss:0.00001, loss_test:0.12134, lr:4.48e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.880, tt:4879.617\n",
      "Ep:136, loss:0.00001, loss_test:0.11541, lr:4.43e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.884, tt:4916.122\n",
      "Ep:137, loss:0.00001, loss_test:0.11656, lr:4.39e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.880, tt:4951.411\n",
      "Ep:138, loss:0.00001, loss_test:0.11478, lr:4.34e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.890, tt:4988.742\n",
      "Ep:139, loss:0.00001, loss_test:0.11998, lr:4.30e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.890, tt:5024.582\n",
      "Ep:140, loss:0.00001, loss_test:0.11868, lr:4.26e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.888, tt:5060.187\n",
      "Ep:141, loss:0.00001, loss_test:0.11338, lr:4.21e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.885, tt:5095.681\n",
      "Ep:142, loss:0.00001, loss_test:0.12144, lr:4.17e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.880, tt:5130.796\n",
      "Ep:143, loss:0.00001, loss_test:0.11511, lr:4.13e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.886, tt:5167.624\n",
      "Ep:144, loss:0.00001, loss_test:0.11423, lr:4.09e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.876, tt:5202.061\n",
      "Ep:145, loss:0.00001, loss_test:0.11805, lr:4.05e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.886, tt:5239.320\n",
      "Ep:146, loss:0.00001, loss_test:0.11814, lr:4.01e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.885, tt:5275.094\n",
      "Ep:147, loss:0.00001, loss_test:0.11624, lr:3.97e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.884, tt:5310.807\n",
      "Ep:148, loss:0.00001, loss_test:0.11670, lr:3.93e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.881, tt:5346.319\n",
      "Ep:149, loss:0.00001, loss_test:0.11679, lr:3.89e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.876, tt:5381.429\n",
      "Ep:150, loss:0.00001, loss_test:0.11602, lr:3.85e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.870, tt:5416.337\n",
      "Ep:151, loss:0.00001, loss_test:0.11811, lr:3.81e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.872, tt:5452.598\n",
      "Ep:154, loss:0.00001, loss_test:0.12084, lr:3.70e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.865, tt:5559.107\n",
      "Ep:155, loss:0.00001, loss_test:0.11628, lr:3.66e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.866, tt:5595.082\n",
      "Ep:156, loss:0.00001, loss_test:0.11672, lr:3.62e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.868, tt:5631.327\n",
      "Ep:157, loss:0.00001, loss_test:0.11824, lr:3.59e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.869, tt:5667.344\n",
      "Ep:158, loss:0.00001, loss_test:0.11740, lr:3.55e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.888, tt:5706.139\n",
      "Ep:159, loss:0.00001, loss_test:0.12051, lr:3.52e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.884, tt:5741.373\n",
      "Ep:160, loss:0.00001, loss_test:0.11841, lr:3.48e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.883, tt:5777.229\n",
      "Ep:161, loss:0.00001, loss_test:0.11582, lr:3.45e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.883, tt:5813.057\n",
      "Ep:162, loss:0.00000, loss_test:0.11679, lr:3.41e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.878, tt:5848.161\n",
      "Ep:163, loss:0.00000, loss_test:0.11559, lr:3.38e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.880, tt:5884.320\n",
      "Ep:164, loss:0.00000, loss_test:0.11506, lr:3.34e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.872, tt:5918.865\n",
      "Ep:165, loss:0.00000, loss_test:0.11731, lr:3.31e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.863, tt:5953.226\n",
      "Ep:166, loss:0.00000, loss_test:0.11459, lr:3.28e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.869, tt:5990.131\n",
      "Ep:167, loss:0.00000, loss_test:0.11524, lr:3.24e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.875, tt:6027.069\n",
      "Ep:168, loss:0.00000, loss_test:0.11694, lr:3.21e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.883, tt:6064.159\n",
      "Ep:169, loss:0.00000, loss_test:0.11573, lr:3.18e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.879, tt:6099.491\n",
      "Ep:170, loss:0.00000, loss_test:0.11537, lr:3.15e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.880, tt:6135.462\n",
      "Ep:171, loss:0.00000, loss_test:0.11555, lr:3.12e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.886, tt:6172.384\n",
      "Ep:172, loss:0.00000, loss_test:0.11420, lr:3.09e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.884, tt:6207.981\n",
      "Ep:173, loss:0.00000, loss_test:0.11581, lr:3.05e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.881, tt:6243.229\n",
      "Ep:174, loss:0.00000, loss_test:0.11653, lr:3.02e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.875, tt:6278.049\n",
      "Ep:175, loss:0.00000, loss_test:0.11638, lr:2.99e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.874, tt:6313.793\n",
      "Ep:176, loss:0.00000, loss_test:0.11810, lr:2.96e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.869, tt:6348.813\n",
      "Ep:177, loss:0.00000, loss_test:0.11617, lr:2.93e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.875, tt:6385.810\n",
      "Ep:178, loss:0.00000, loss_test:0.11423, lr:2.90e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.871, tt:6420.884\n",
      "Ep:179, loss:0.00000, loss_test:0.12039, lr:2.88e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.867, tt:6456.038\n",
      "Ep:180, loss:0.00000, loss_test:0.11850, lr:2.85e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.872, tt:6492.887\n",
      "Ep:181, loss:0.00000, loss_test:0.11459, lr:2.82e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.868, tt:6528.035\n",
      "Ep:182, loss:0.00000, loss_test:0.11650, lr:2.79e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.894, tt:6568.547\n",
      "Ep:183, loss:0.00000, loss_test:0.11634, lr:2.76e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.897, tt:6605.060\n",
      "Ep:184, loss:0.00000, loss_test:0.11362, lr:2.73e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.891, tt:6639.813\n",
      "Ep:185, loss:0.00000, loss_test:0.11490, lr:2.71e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.887, tt:6675.072\n",
      "Ep:186, loss:0.00000, loss_test:0.11578, lr:2.68e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.879, tt:6709.463\n",
      "Ep:187, loss:0.00000, loss_test:0.11464, lr:2.65e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.879, tt:6745.226\n",
      "Ep:188, loss:0.00000, loss_test:0.11589, lr:2.63e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.880, tt:6781.281\n",
      "Ep:189, loss:0.00000, loss_test:0.11726, lr:2.60e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.876, tt:6816.481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.11519, lr:2.57e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.873, tt:6851.695\n",
      "Ep:191, loss:0.00000, loss_test:0.11524, lr:2.55e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.870, tt:6886.963\n",
      "Ep:192, loss:0.00000, loss_test:0.11537, lr:2.52e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.863, tt:6921.488\n",
      "Ep:193, loss:0.00000, loss_test:0.11517, lr:2.50e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.862, tt:6957.215\n",
      "Ep:194, loss:0.00000, loss_test:0.11455, lr:2.47e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.864, tt:6993.574\n",
      "Ep:195, loss:0.00000, loss_test:0.11501, lr:2.45e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.863, tt:7029.188\n",
      "Ep:196, loss:0.00000, loss_test:0.11474, lr:2.42e-03, fs:0.72941 (r=0.626,p=0.873),  time:35.859, tt:7064.160\n",
      "Ep:197, loss:0.00000, loss_test:0.11379, lr:2.40e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.855, tt:7099.286\n",
      "Ep:198, loss:0.00000, loss_test:0.11430, lr:2.38e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.847, tt:7133.604\n",
      "Ep:199, loss:0.00000, loss_test:0.11609, lr:2.35e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.850, tt:7169.982\n",
      "Ep:200, loss:0.00000, loss_test:0.11546, lr:2.33e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.835, tt:7202.834\n",
      "Ep:201, loss:0.00000, loss_test:0.11437, lr:2.31e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.804, tt:7232.478\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.03213, lr:6.00e-02, fs:0.61111 (r=0.667,p=0.564),  time:22.892, tt:22.892\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02437, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:22.841, tt:45.682\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:22.480, tt:67.439\n",
      "Ep:3, loss:0.00005, loss_test:0.02525, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:23.128, tt:92.514\n",
      "Ep:4, loss:0.00005, loss_test:0.02544, lr:6.00e-02, fs:0.64615 (r=0.848,p=0.522),  time:24.489, tt:122.446\n",
      "Ep:5, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:25.476, tt:152.856\n",
      "Ep:6, loss:0.00005, loss_test:0.02621, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:26.179, tt:183.252\n",
      "Ep:7, loss:0.00005, loss_test:0.02617, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:26.579, tt:212.632\n",
      "Ep:8, loss:0.00005, loss_test:0.02569, lr:6.00e-02, fs:0.64542 (r=0.818,p=0.533),  time:26.989, tt:242.899\n",
      "Ep:9, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:27.420, tt:274.199\n",
      "Ep:10, loss:0.00004, loss_test:0.02449, lr:6.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:27.629, tt:303.923\n",
      "Ep:11, loss:0.00004, loss_test:0.02411, lr:6.00e-02, fs:0.63071 (r=0.768,p=0.535),  time:27.815, tt:333.775\n",
      "Ep:12, loss:0.00004, loss_test:0.02414, lr:6.00e-02, fs:0.61135 (r=0.707,p=0.538),  time:28.090, tt:365.167\n",
      "Ep:13, loss:0.00004, loss_test:0.02426, lr:5.94e-02, fs:0.60177 (r=0.687,p=0.535),  time:28.159, tt:394.227\n",
      "Ep:14, loss:0.00004, loss_test:0.02424, lr:5.88e-02, fs:0.60444 (r=0.687,p=0.540),  time:28.310, tt:424.647\n",
      "Ep:15, loss:0.00004, loss_test:0.02390, lr:5.82e-02, fs:0.60526 (r=0.697,p=0.535),  time:28.425, tt:454.797\n",
      "Ep:16, loss:0.00004, loss_test:0.02355, lr:5.76e-02, fs:0.59227 (r=0.697,p=0.515),  time:28.590, tt:486.032\n",
      "Ep:17, loss:0.00004, loss_test:0.02336, lr:5.71e-02, fs:0.60504 (r=0.727,p=0.518),  time:28.704, tt:516.665\n",
      "Ep:18, loss:0.00004, loss_test:0.02331, lr:5.65e-02, fs:0.61088 (r=0.737,p=0.521),  time:28.828, tt:547.741\n",
      "Ep:19, loss:0.00004, loss_test:0.02334, lr:5.59e-02, fs:0.60606 (r=0.707,p=0.530),  time:28.894, tt:577.881\n",
      "Ep:20, loss:0.00004, loss_test:0.02329, lr:5.54e-02, fs:0.60526 (r=0.697,p=0.535),  time:28.946, tt:607.864\n",
      "Ep:21, loss:0.00004, loss_test:0.02304, lr:5.48e-02, fs:0.60870 (r=0.707,p=0.534),  time:29.003, tt:638.072\n",
      "Ep:22, loss:0.00004, loss_test:0.02267, lr:5.43e-02, fs:0.61277 (r=0.727,p=0.529),  time:29.056, tt:668.295\n",
      "Ep:23, loss:0.00004, loss_test:0.02241, lr:5.37e-02, fs:0.62447 (r=0.747,p=0.536),  time:29.067, tt:697.603\n",
      "Ep:24, loss:0.00004, loss_test:0.02225, lr:5.32e-02, fs:0.62979 (r=0.747,p=0.544),  time:29.090, tt:727.249\n",
      "Ep:25, loss:0.00004, loss_test:0.02200, lr:5.27e-02, fs:0.62979 (r=0.747,p=0.544),  time:29.153, tt:757.979\n",
      "Ep:26, loss:0.00003, loss_test:0.02173, lr:5.21e-02, fs:0.63248 (r=0.747,p=0.548),  time:29.178, tt:787.815\n",
      "Ep:27, loss:0.00003, loss_test:0.02147, lr:5.16e-02, fs:0.63793 (r=0.747,p=0.556),  time:29.215, tt:818.023\n",
      "Ep:28, loss:0.00003, loss_test:0.02120, lr:5.11e-02, fs:0.63793 (r=0.747,p=0.556),  time:29.190, tt:846.514\n",
      "Ep:29, loss:0.00003, loss_test:0.02091, lr:5.06e-02, fs:0.64957 (r=0.768,p=0.563),  time:29.231, tt:876.925\n",
      "Ep:30, loss:0.00003, loss_test:0.02068, lr:5.01e-02, fs:0.64957 (r=0.768,p=0.563),  time:29.294, tt:908.113\n",
      "Ep:31, loss:0.00003, loss_test:0.02040, lr:4.96e-02, fs:0.66667 (r=0.798,p=0.572),  time:29.328, tt:938.482\n",
      "Ep:32, loss:0.00003, loss_test:0.02001, lr:4.91e-02, fs:0.67227 (r=0.808,p=0.576),  time:29.367, tt:969.118\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01973, lr:4.91e-02, fs:0.68354 (r=0.818,p=0.587),  time:29.431, tt:1000.640\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01955, lr:4.91e-02, fs:0.68085 (r=0.808,p=0.588),  time:29.462, tt:1031.155\n",
      "Ep:35, loss:0.00003, loss_test:0.01926, lr:4.91e-02, fs:0.68398 (r=0.798,p=0.598),  time:29.480, tt:1061.285\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01886, lr:4.91e-02, fs:0.71967 (r=0.869,p=0.614),  time:29.493, tt:1091.226\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01861, lr:4.91e-02, fs:0.72500 (r=0.879,p=0.617),  time:29.535, tt:1122.322\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01839, lr:4.91e-02, fs:0.74167 (r=0.899,p=0.631),  time:29.575, tt:1153.410\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01814, lr:4.91e-02, fs:0.74262 (r=0.889,p=0.638),  time:29.607, tt:1184.261\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01785, lr:4.91e-02, fs:0.75207 (r=0.919,p=0.636),  time:29.610, tt:1214.000\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01770, lr:4.91e-02, fs:0.75424 (r=0.899,p=0.650),  time:29.609, tt:1243.559\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01750, lr:4.91e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.656, tt:1275.191\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01723, lr:4.91e-02, fs:0.74043 (r=0.879,p=0.640),  time:29.660, tt:1305.027\n",
      "Ep:44, loss:0.00002, loss_test:0.01717, lr:4.91e-02, fs:0.72174 (r=0.838,p=0.634),  time:29.675, tt:1335.367\n",
      "Ep:45, loss:0.00002, loss_test:0.01697, lr:4.91e-02, fs:0.71681 (r=0.818,p=0.638),  time:29.698, tt:1366.129\n",
      "Ep:46, loss:0.00002, loss_test:0.01724, lr:4.91e-02, fs:0.72072 (r=0.808,p=0.650),  time:29.744, tt:1397.968\n",
      "Ep:47, loss:0.00002, loss_test:0.01683, lr:4.91e-02, fs:0.74561 (r=0.859,p=0.659),  time:29.764, tt:1428.672\n",
      "Ep:48, loss:0.00002, loss_test:0.01663, lr:4.91e-02, fs:0.75556 (r=0.859,p=0.675),  time:29.780, tt:1459.231\n",
      "Ep:49, loss:0.00002, loss_test:0.01709, lr:4.91e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.796, tt:1489.811\n",
      "Ep:50, loss:0.00002, loss_test:0.01669, lr:4.91e-02, fs:0.77778 (r=0.848,p=0.718),  time:29.815, tt:1520.589\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00002, loss_test:0.01661, lr:4.91e-02, fs:0.76712 (r=0.848,p=0.700),  time:29.832, tt:1551.255\n",
      "Ep:52, loss:0.00002, loss_test:0.01707, lr:4.91e-02, fs:0.76777 (r=0.818,p=0.723),  time:29.851, tt:1582.112\n",
      "Ep:53, loss:0.00002, loss_test:0.01670, lr:4.91e-02, fs:0.76415 (r=0.818,p=0.717),  time:29.877, tt:1613.374\n",
      "Ep:54, loss:0.00002, loss_test:0.01652, lr:4.91e-02, fs:0.77143 (r=0.818,p=0.730),  time:29.887, tt:1643.782\n",
      "Ep:55, loss:0.00002, loss_test:0.01665, lr:4.91e-02, fs:0.76777 (r=0.818,p=0.723),  time:29.909, tt:1674.889\n",
      "Ep:56, loss:0.00002, loss_test:0.01660, lr:4.91e-02, fs:0.77358 (r=0.828,p=0.726),  time:29.914, tt:1705.071\n",
      "Ep:57, loss:0.00001, loss_test:0.01663, lr:4.91e-02, fs:0.74396 (r=0.778,p=0.713),  time:29.908, tt:1734.667\n",
      "Ep:58, loss:0.00001, loss_test:0.01658, lr:4.91e-02, fs:0.74641 (r=0.788,p=0.709),  time:29.920, tt:1765.279\n",
      "Ep:59, loss:0.00001, loss_test:0.01663, lr:4.91e-02, fs:0.75000 (r=0.788,p=0.716),  time:29.927, tt:1795.593\n",
      "Ep:60, loss:0.00001, loss_test:0.01659, lr:4.91e-02, fs:0.73684 (r=0.778,p=0.700),  time:29.927, tt:1825.541\n",
      "Ep:61, loss:0.00001, loss_test:0.01674, lr:4.91e-02, fs:0.73171 (r=0.758,p=0.708),  time:29.923, tt:1855.253\n",
      "Ep:62, loss:0.00001, loss_test:0.01670, lr:4.86e-02, fs:0.74757 (r=0.778,p=0.720),  time:29.908, tt:1884.199\n",
      "Ep:63, loss:0.00001, loss_test:0.01676, lr:4.81e-02, fs:0.73529 (r=0.758,p=0.714),  time:29.895, tt:1913.261\n",
      "Ep:64, loss:0.00001, loss_test:0.01663, lr:4.76e-02, fs:0.74510 (r=0.768,p=0.724),  time:29.910, tt:1944.133\n",
      "Ep:65, loss:0.00001, loss_test:0.01704, lr:4.71e-02, fs:0.73529 (r=0.758,p=0.714),  time:29.902, tt:1973.511\n",
      "Ep:66, loss:0.00001, loss_test:0.01696, lr:4.67e-02, fs:0.73892 (r=0.758,p=0.721),  time:29.898, tt:2003.134\n",
      "Ep:67, loss:0.00001, loss_test:0.01755, lr:4.62e-02, fs:0.71717 (r=0.717,p=0.717),  time:29.911, tt:2033.963\n",
      "Ep:68, loss:0.00001, loss_test:0.01706, lr:4.57e-02, fs:0.72727 (r=0.727,p=0.727),  time:29.908, tt:2063.658\n",
      "Ep:69, loss:0.00001, loss_test:0.01731, lr:4.53e-02, fs:0.71134 (r=0.697,p=0.726),  time:29.903, tt:2093.190\n",
      "Ep:70, loss:0.00001, loss_test:0.01808, lr:4.48e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.899, tt:2122.820\n",
      "Ep:71, loss:0.00001, loss_test:0.01703, lr:4.44e-02, fs:0.70769 (r=0.697,p=0.719),  time:29.913, tt:2153.756\n",
      "Ep:72, loss:0.00001, loss_test:0.01802, lr:4.39e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.913, tt:2183.677\n",
      "Ep:73, loss:0.00001, loss_test:0.01799, lr:4.35e-02, fs:0.71134 (r=0.697,p=0.726),  time:29.939, tt:2215.458\n",
      "Ep:74, loss:0.00001, loss_test:0.01820, lr:4.31e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.937, tt:2245.307\n",
      "Ep:75, loss:0.00001, loss_test:0.01824, lr:4.26e-02, fs:0.70103 (r=0.687,p=0.716),  time:29.963, tt:2277.161\n",
      "Ep:76, loss:0.00001, loss_test:0.01854, lr:4.22e-02, fs:0.69072 (r=0.677,p=0.705),  time:29.966, tt:2307.404\n",
      "Ep:77, loss:0.00001, loss_test:0.01841, lr:4.18e-02, fs:0.69430 (r=0.677,p=0.713),  time:29.983, tt:2338.689\n",
      "Ep:78, loss:0.00001, loss_test:0.01890, lr:4.14e-02, fs:0.69792 (r=0.677,p=0.720),  time:29.984, tt:2368.753\n",
      "Ep:79, loss:0.00001, loss_test:0.01900, lr:4.10e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.002, tt:2400.194\n",
      "Ep:80, loss:0.00001, loss_test:0.01922, lr:4.05e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.006, tt:2430.479\n",
      "Ep:81, loss:0.00001, loss_test:0.01919, lr:4.01e-02, fs:0.70526 (r=0.677,p=0.736),  time:30.001, tt:2460.110\n",
      "Ep:82, loss:0.00001, loss_test:0.01969, lr:3.97e-02, fs:0.70526 (r=0.677,p=0.736),  time:29.991, tt:2489.238\n",
      "Ep:83, loss:0.00001, loss_test:0.01958, lr:3.93e-02, fs:0.69841 (r=0.667,p=0.733),  time:29.988, tt:2519.019\n",
      "Ep:84, loss:0.00001, loss_test:0.02013, lr:3.89e-02, fs:0.69841 (r=0.667,p=0.733),  time:29.992, tt:2549.341\n",
      "Ep:85, loss:0.00001, loss_test:0.02024, lr:3.86e-02, fs:0.70213 (r=0.667,p=0.742),  time:30.000, tt:2580.016\n",
      "Ep:86, loss:0.00001, loss_test:0.02038, lr:3.82e-02, fs:0.70213 (r=0.667,p=0.742),  time:30.001, tt:2610.097\n",
      "Ep:87, loss:0.00001, loss_test:0.02070, lr:3.78e-02, fs:0.69519 (r=0.657,p=0.739),  time:30.011, tt:2640.943\n",
      "Ep:88, loss:0.00001, loss_test:0.02076, lr:3.74e-02, fs:0.69519 (r=0.657,p=0.739),  time:30.009, tt:2670.811\n",
      "Ep:89, loss:0.00001, loss_test:0.02093, lr:3.70e-02, fs:0.69519 (r=0.657,p=0.739),  time:30.013, tt:2701.137\n",
      "Ep:90, loss:0.00001, loss_test:0.02128, lr:3.67e-02, fs:0.69519 (r=0.657,p=0.739),  time:30.020, tt:2731.853\n",
      "Ep:91, loss:0.00001, loss_test:0.02112, lr:3.63e-02, fs:0.69189 (r=0.646,p=0.744),  time:30.012, tt:2761.062\n",
      "Ep:92, loss:0.00001, loss_test:0.02128, lr:3.59e-02, fs:0.68817 (r=0.646,p=0.736),  time:30.009, tt:2790.799\n",
      "Ep:93, loss:0.00001, loss_test:0.02205, lr:3.56e-02, fs:0.68478 (r=0.636,p=0.741),  time:30.008, tt:2820.710\n",
      "Ep:94, loss:0.00001, loss_test:0.02145, lr:3.52e-02, fs:0.69189 (r=0.646,p=0.744),  time:30.012, tt:2851.125\n",
      "Ep:95, loss:0.00001, loss_test:0.02214, lr:3.49e-02, fs:0.69231 (r=0.636,p=0.759),  time:30.006, tt:2880.565\n",
      "Ep:96, loss:0.00001, loss_test:0.02259, lr:3.45e-02, fs:0.69565 (r=0.646,p=0.753),  time:30.006, tt:2910.606\n",
      "Ep:97, loss:0.00001, loss_test:0.02189, lr:3.42e-02, fs:0.69565 (r=0.646,p=0.753),  time:30.001, tt:2940.050\n",
      "Ep:98, loss:0.00000, loss_test:0.02274, lr:3.38e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.002, tt:2970.171\n",
      "Ep:99, loss:0.00000, loss_test:0.02284, lr:3.35e-02, fs:0.69231 (r=0.636,p=0.759),  time:30.021, tt:3002.111\n",
      "Ep:100, loss:0.00000, loss_test:0.02296, lr:3.32e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.037, tt:3033.740\n",
      "Ep:101, loss:0.00000, loss_test:0.02314, lr:3.28e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.043, tt:3064.425\n",
      "Ep:102, loss:0.00000, loss_test:0.02353, lr:3.25e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.059, tt:3096.046\n",
      "Ep:103, loss:0.00000, loss_test:0.02310, lr:3.22e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.053, tt:3125.482\n",
      "Ep:104, loss:0.00000, loss_test:0.02384, lr:3.19e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.055, tt:3155.821\n",
      "Ep:105, loss:0.00000, loss_test:0.02408, lr:3.15e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.066, tt:3187.016\n",
      "Ep:106, loss:0.00000, loss_test:0.02377, lr:3.12e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.084, tt:3218.957\n",
      "Ep:107, loss:0.00000, loss_test:0.02423, lr:3.09e-02, fs:0.69274 (r=0.626,p=0.775),  time:30.093, tt:3250.076\n",
      "Ep:108, loss:0.00000, loss_test:0.02447, lr:3.06e-02, fs:0.69274 (r=0.626,p=0.775),  time:30.103, tt:3281.175\n",
      "Ep:109, loss:0.00000, loss_test:0.02429, lr:3.03e-02, fs:0.68889 (r=0.626,p=0.765),  time:30.095, tt:3310.498\n",
      "Ep:110, loss:0.00000, loss_test:0.02456, lr:3.00e-02, fs:0.69274 (r=0.626,p=0.775),  time:30.099, tt:3341.026\n",
      "Ep:111, loss:0.00000, loss_test:0.02515, lr:2.97e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.110, tt:3372.346\n",
      "Ep:112, loss:0.00000, loss_test:0.02449, lr:2.94e-02, fs:0.68889 (r=0.626,p=0.765),  time:30.098, tt:3401.119\n",
      "Ep:113, loss:0.00000, loss_test:0.02535, lr:2.91e-02, fs:0.66667 (r=0.596,p=0.756),  time:30.106, tt:3432.138\n",
      "Ep:114, loss:0.00000, loss_test:0.02543, lr:2.88e-02, fs:0.68539 (r=0.616,p=0.772),  time:30.112, tt:3462.830\n",
      "Ep:115, loss:0.00000, loss_test:0.02504, lr:2.85e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.121, tt:3494.091\n",
      "Ep:116, loss:0.00000, loss_test:0.02595, lr:2.82e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.131, tt:3525.328\n",
      "Ep:117, loss:0.00000, loss_test:0.02533, lr:2.80e-02, fs:0.68539 (r=0.616,p=0.772),  time:30.149, tt:3557.562\n",
      "Ep:118, loss:0.00000, loss_test:0.02601, lr:2.77e-02, fs:0.66667 (r=0.596,p=0.756),  time:30.158, tt:3588.814\n",
      "Ep:119, loss:0.00000, loss_test:0.02589, lr:2.74e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.161, tt:3619.342\n",
      "Ep:120, loss:0.00000, loss_test:0.02597, lr:2.71e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.163, tt:3649.692\n",
      "Ep:121, loss:0.00000, loss_test:0.02632, lr:2.69e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.169, tt:3680.663\n",
      "Ep:122, loss:0.00000, loss_test:0.02628, lr:2.66e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.181, tt:3712.320\n",
      "Ep:123, loss:0.00000, loss_test:0.02645, lr:2.63e-02, fs:0.66667 (r=0.596,p=0.756),  time:30.189, tt:3743.451\n",
      "Ep:124, loss:0.00000, loss_test:0.02656, lr:2.61e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.203, tt:3775.331\n",
      "Ep:125, loss:0.00000, loss_test:0.02677, lr:2.58e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.219, tt:3807.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00000, loss_test:0.02678, lr:2.55e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.222, tt:3838.177\n",
      "Ep:127, loss:0.00000, loss_test:0.02714, lr:2.53e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.235, tt:3870.054\n",
      "Ep:128, loss:0.00000, loss_test:0.02709, lr:2.50e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.233, tt:3900.011\n",
      "Ep:129, loss:0.00000, loss_test:0.02739, lr:2.48e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.243, tt:3931.651\n",
      "Ep:130, loss:0.00000, loss_test:0.02717, lr:2.45e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.241, tt:3961.510\n",
      "Ep:131, loss:0.00000, loss_test:0.02734, lr:2.43e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.248, tt:3992.705\n",
      "Ep:132, loss:0.00000, loss_test:0.02773, lr:2.40e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.255, tt:4023.947\n",
      "Ep:133, loss:0.00000, loss_test:0.02750, lr:2.38e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.263, tt:4055.253\n",
      "Ep:134, loss:0.00000, loss_test:0.02798, lr:2.36e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.265, tt:4085.798\n",
      "Ep:135, loss:0.00000, loss_test:0.02815, lr:2.33e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.273, tt:4117.122\n",
      "Ep:136, loss:0.00000, loss_test:0.02795, lr:2.31e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.287, tt:4149.347\n",
      "Ep:137, loss:0.00000, loss_test:0.02834, lr:2.29e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.296, tt:4180.879\n",
      "Ep:138, loss:0.00000, loss_test:0.02841, lr:2.26e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.305, tt:4212.433\n",
      "Ep:139, loss:0.00000, loss_test:0.02867, lr:2.24e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.311, tt:4243.482\n",
      "Ep:140, loss:0.00000, loss_test:0.02851, lr:2.22e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.316, tt:4274.538\n",
      "Ep:141, loss:0.00000, loss_test:0.02890, lr:2.20e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.330, tt:4306.916\n",
      "Ep:142, loss:0.00000, loss_test:0.02886, lr:2.17e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.340, tt:4338.629\n",
      "Ep:143, loss:0.00000, loss_test:0.02909, lr:2.15e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.346, tt:4369.793\n",
      "Ep:144, loss:0.00000, loss_test:0.02917, lr:2.13e-02, fs:0.67045 (r=0.596,p=0.766),  time:30.350, tt:4400.719\n",
      "Ep:145, loss:0.00000, loss_test:0.02944, lr:2.11e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.358, tt:4432.256\n",
      "Ep:146, loss:0.00000, loss_test:0.02914, lr:2.09e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.380, tt:4465.846\n",
      "Ep:147, loss:0.00000, loss_test:0.02985, lr:2.07e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.388, tt:4497.404\n",
      "Ep:148, loss:0.00000, loss_test:0.02952, lr:2.05e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.394, tt:4528.676\n",
      "Ep:149, loss:0.00000, loss_test:0.02955, lr:2.03e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.415, tt:4562.248\n",
      "Ep:150, loss:0.00000, loss_test:0.02999, lr:2.01e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.423, tt:4593.830\n",
      "Ep:151, loss:0.00000, loss_test:0.02997, lr:1.99e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.428, tt:4625.100\n",
      "Ep:152, loss:0.00000, loss_test:0.02996, lr:1.97e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.435, tt:4656.491\n",
      "Ep:153, loss:0.00000, loss_test:0.03024, lr:1.95e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.437, tt:4687.354\n",
      "Ep:154, loss:0.00000, loss_test:0.03040, lr:1.93e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.444, tt:4718.784\n",
      "Ep:155, loss:0.00000, loss_test:0.03023, lr:1.91e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.446, tt:4749.509\n",
      "Ep:156, loss:0.00000, loss_test:0.03053, lr:1.89e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.441, tt:4779.303\n",
      "Ep:157, loss:0.00000, loss_test:0.03084, lr:1.87e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.439, tt:4809.423\n",
      "Ep:158, loss:0.00000, loss_test:0.03062, lr:1.85e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.435, tt:4839.242\n",
      "Ep:159, loss:0.00000, loss_test:0.03099, lr:1.83e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.430, tt:4868.806\n",
      "Ep:160, loss:0.00000, loss_test:0.03088, lr:1.81e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.432, tt:4899.493\n",
      "Ep:161, loss:0.00000, loss_test:0.03108, lr:1.80e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.427, tt:4929.147\n",
      "Ep:162, loss:0.00000, loss_test:0.03102, lr:1.78e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.425, tt:4959.355\n",
      "Ep:163, loss:0.00000, loss_test:0.03110, lr:1.76e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.422, tt:4989.210\n",
      "Ep:164, loss:0.00000, loss_test:0.03151, lr:1.74e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.426, tt:5020.303\n",
      "Ep:165, loss:0.00000, loss_test:0.03121, lr:1.73e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.432, tt:5051.640\n",
      "Ep:166, loss:0.00000, loss_test:0.03163, lr:1.71e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.435, tt:5082.572\n",
      "Ep:167, loss:0.00000, loss_test:0.03155, lr:1.69e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.432, tt:5112.630\n",
      "Ep:168, loss:0.00000, loss_test:0.03144, lr:1.67e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.433, tt:5143.124\n",
      "Ep:169, loss:0.00000, loss_test:0.03192, lr:1.66e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.432, tt:5173.477\n",
      "Ep:170, loss:0.00000, loss_test:0.03173, lr:1.64e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.432, tt:5203.915\n",
      "Ep:171, loss:0.00000, loss_test:0.03193, lr:1.62e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.436, tt:5234.926\n",
      "Ep:172, loss:0.00000, loss_test:0.03199, lr:1.61e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.433, tt:5264.954\n",
      "Ep:173, loss:0.00000, loss_test:0.03205, lr:1.59e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.428, tt:5294.530\n",
      "Ep:174, loss:0.00000, loss_test:0.03222, lr:1.58e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.431, tt:5325.477\n",
      "Ep:175, loss:0.00000, loss_test:0.03222, lr:1.56e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.447, tt:5358.720\n",
      "Ep:176, loss:0.00000, loss_test:0.03218, lr:1.54e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.445, tt:5388.770\n",
      "Ep:177, loss:0.00000, loss_test:0.03240, lr:1.53e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.441, tt:5418.464\n",
      "Ep:178, loss:0.00000, loss_test:0.03252, lr:1.51e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.437, tt:5448.167\n",
      "Ep:179, loss:0.00000, loss_test:0.03244, lr:1.50e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.436, tt:5478.474\n",
      "Ep:180, loss:0.00000, loss_test:0.03256, lr:1.48e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.438, tt:5509.213\n",
      "Ep:181, loss:0.00000, loss_test:0.03275, lr:1.47e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.438, tt:5539.691\n",
      "Ep:182, loss:0.00000, loss_test:0.03270, lr:1.45e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.440, tt:5570.497\n",
      "Ep:183, loss:0.00000, loss_test:0.03270, lr:1.44e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.439, tt:5600.744\n",
      "Ep:184, loss:0.00000, loss_test:0.03290, lr:1.43e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.439, tt:5631.141\n",
      "Ep:185, loss:0.00000, loss_test:0.03289, lr:1.41e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.447, tt:5663.120\n",
      "Ep:186, loss:0.00000, loss_test:0.03298, lr:1.40e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.451, tt:5694.385\n",
      "Ep:187, loss:0.00000, loss_test:0.03299, lr:1.38e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.453, tt:5725.247\n",
      "Ep:188, loss:0.00000, loss_test:0.03315, lr:1.37e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.456, tt:5756.243\n",
      "Ep:189, loss:0.00000, loss_test:0.03316, lr:1.36e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.453, tt:5786.044\n",
      "Ep:190, loss:0.00000, loss_test:0.03327, lr:1.34e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.456, tt:5817.156\n",
      "Ep:191, loss:0.00000, loss_test:0.03327, lr:1.33e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.457, tt:5847.832\n",
      "Ep:192, loss:0.00000, loss_test:0.03329, lr:1.32e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.462, tt:5879.146\n",
      "Ep:193, loss:0.00000, loss_test:0.03341, lr:1.30e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.469, tt:5910.966\n",
      "Ep:194, loss:0.00000, loss_test:0.03349, lr:1.29e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.467, tt:5941.033\n",
      "Ep:195, loss:0.00000, loss_test:0.03355, lr:1.28e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.470, tt:5972.121\n",
      "Ep:196, loss:0.00000, loss_test:0.03354, lr:1.26e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.466, tt:6001.888\n",
      "Ep:197, loss:0.00000, loss_test:0.03364, lr:1.25e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.457, tt:6030.545\n",
      "Ep:198, loss:0.00000, loss_test:0.03376, lr:1.24e-02, fs:0.68208 (r=0.596,p=0.797),  time:30.455, tt:6060.521\n",
      "Ep:199, loss:0.00000, loss_test:0.03368, lr:1.23e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.446, tt:6089.181\n",
      "Ep:200, loss:0.00000, loss_test:0.03382, lr:1.21e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.435, tt:6117.486\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13248, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:26.631, tt:26.631\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13229, lr:1.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:25.475, tt:50.949\n",
      "Ep:2, loss:0.00026, loss_test:0.13272, lr:1.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:25.704, tt:77.112\n",
      "Ep:3, loss:0.00026, loss_test:0.13282, lr:1.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:26.901, tt:107.604\n",
      "Ep:4, loss:0.00026, loss_test:0.13204, lr:1.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:27.270, tt:136.351\n",
      "Ep:5, loss:0.00025, loss_test:0.13043, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:27.925, tt:167.551\n",
      "Ep:6, loss:0.00025, loss_test:0.12899, lr:1.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:28.302, tt:198.116\n",
      "Ep:7, loss:0.00025, loss_test:0.12789, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:28.743, tt:229.941\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12695, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:28.960, tt:260.641\n",
      "Ep:9, loss:0.00024, loss_test:0.12680, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:29.269, tt:292.688\n",
      "Ep:10, loss:0.00023, loss_test:0.12566, lr:1.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:29.372, tt:323.092\n",
      "Ep:11, loss:0.00023, loss_test:0.12413, lr:1.00e-02, fs:0.66960 (r=0.768,p=0.594),  time:29.440, tt:353.284\n",
      "Ep:12, loss:0.00022, loss_test:0.12316, lr:1.00e-02, fs:0.66063 (r=0.737,p=0.598),  time:29.728, tt:386.463\n",
      "Ep:13, loss:0.00022, loss_test:0.12401, lr:1.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:29.747, tt:416.455\n",
      "Ep:14, loss:0.00021, loss_test:0.12418, lr:1.00e-02, fs:0.62326 (r=0.677,p=0.578),  time:29.779, tt:446.687\n",
      "Ep:15, loss:0.00021, loss_test:0.12324, lr:1.00e-02, fs:0.61972 (r=0.667,p=0.579),  time:29.847, tt:477.545\n",
      "Ep:16, loss:0.00021, loss_test:0.12234, lr:1.00e-02, fs:0.62911 (r=0.677,p=0.588),  time:29.894, tt:508.202\n",
      "Ep:17, loss:0.00020, loss_test:0.12141, lr:1.00e-02, fs:0.65072 (r=0.687,p=0.618),  time:29.871, tt:537.679\n",
      "Ep:18, loss:0.00020, loss_test:0.12098, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:29.878, tt:567.683\n",
      "Ep:19, loss:0.00020, loss_test:0.12019, lr:9.90e-03, fs:0.65025 (r=0.667,p=0.635),  time:29.892, tt:597.847\n",
      "Ep:20, loss:0.00019, loss_test:0.11985, lr:9.80e-03, fs:0.64390 (r=0.667,p=0.623),  time:29.925, tt:628.423\n",
      "Ep:21, loss:0.00019, loss_test:0.11889, lr:9.70e-03, fs:0.66667 (r=0.717,p=0.623),  time:29.960, tt:659.122\n",
      "Ep:22, loss:0.00019, loss_test:0.11832, lr:9.61e-03, fs:0.69903 (r=0.727,p=0.673),  time:30.026, tt:690.608\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.11660, lr:9.61e-03, fs:0.69231 (r=0.727,p=0.661),  time:30.077, tt:721.839\n",
      "Ep:24, loss:0.00018, loss_test:0.11469, lr:9.61e-03, fs:0.70142 (r=0.747,p=0.661),  time:30.138, tt:753.450\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.11375, lr:9.61e-03, fs:0.67619 (r=0.717,p=0.640),  time:30.169, tt:784.398\n",
      "Ep:26, loss:0.00017, loss_test:0.11317, lr:9.61e-03, fs:0.66667 (r=0.687,p=0.648),  time:30.175, tt:814.734\n",
      "Ep:27, loss:0.00017, loss_test:0.11387, lr:9.61e-03, fs:0.65049 (r=0.677,p=0.626),  time:30.183, tt:845.135\n",
      "Ep:28, loss:0.00016, loss_test:0.11238, lr:9.61e-03, fs:0.65686 (r=0.677,p=0.638),  time:30.192, tt:875.579\n",
      "Ep:29, loss:0.00016, loss_test:0.11148, lr:9.61e-03, fs:0.65366 (r=0.677,p=0.632),  time:30.217, tt:906.504\n",
      "Ep:30, loss:0.00015, loss_test:0.11301, lr:9.61e-03, fs:0.66019 (r=0.687,p=0.636),  time:30.225, tt:936.981\n",
      "Ep:31, loss:0.00015, loss_test:0.10909, lr:9.61e-03, fs:0.65672 (r=0.667,p=0.647),  time:30.253, tt:968.100\n",
      "Ep:32, loss:0.00014, loss_test:0.11108, lr:9.61e-03, fs:0.66332 (r=0.667,p=0.660),  time:30.296, tt:999.761\n",
      "Ep:33, loss:0.00014, loss_test:0.10741, lr:9.61e-03, fs:0.66332 (r=0.667,p=0.660),  time:30.316, tt:1030.751\n",
      "Ep:34, loss:0.00013, loss_test:0.12098, lr:9.61e-03, fs:0.67249 (r=0.778,p=0.592),  time:30.321, tt:1061.241\n",
      "Ep:35, loss:0.00013, loss_test:0.10675, lr:9.61e-03, fs:0.66316 (r=0.636,p=0.692),  time:30.346, tt:1092.470\n",
      "Ep:36, loss:0.00013, loss_test:0.10652, lr:9.51e-03, fs:0.71066 (r=0.707,p=0.714),  time:30.360, tt:1123.326\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.11652, lr:9.51e-03, fs:0.69444 (r=0.758,p=0.641),  time:30.368, tt:1153.982\n",
      "Ep:38, loss:0.00011, loss_test:0.10405, lr:9.51e-03, fs:0.71000 (r=0.717,p=0.703),  time:30.375, tt:1184.635\n",
      "Ep:39, loss:0.00012, loss_test:0.10798, lr:9.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:30.399, tt:1215.941\n",
      "Ep:40, loss:0.00011, loss_test:0.13226, lr:9.51e-03, fs:0.65823 (r=0.788,p=0.565),  time:30.400, tt:1246.387\n",
      "Ep:41, loss:0.00012, loss_test:0.10196, lr:9.51e-03, fs:0.72821 (r=0.717,p=0.740),  time:30.431, tt:1278.105\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.11724, lr:9.51e-03, fs:0.68571 (r=0.727,p=0.649),  time:30.443, tt:1309.034\n",
      "Ep:43, loss:0.00010, loss_test:0.10113, lr:9.51e-03, fs:0.71134 (r=0.697,p=0.726),  time:30.462, tt:1340.319\n",
      "Ep:44, loss:0.00010, loss_test:0.11957, lr:9.51e-03, fs:0.65025 (r=0.667,p=0.635),  time:30.446, tt:1370.050\n",
      "Ep:45, loss:0.00009, loss_test:0.10523, lr:9.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:30.462, tt:1401.258\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.11349, lr:9.51e-03, fs:0.66981 (r=0.717,p=0.628),  time:30.473, tt:1432.241\n",
      "Ep:47, loss:0.00009, loss_test:0.11111, lr:9.51e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.469, tt:1462.529\n",
      "Ep:48, loss:0.00008, loss_test:0.10112, lr:9.51e-03, fs:0.77512 (r=0.818,p=0.736),  time:30.475, tt:1493.274\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.11504, lr:9.51e-03, fs:0.63736 (r=0.586,p=0.699),  time:30.506, tt:1525.323\n",
      "Ep:50, loss:0.00007, loss_test:0.09962, lr:9.51e-03, fs:0.76471 (r=0.788,p=0.743),  time:30.535, tt:1557.262\n",
      "Ep:51, loss:0.00007, loss_test:0.11330, lr:9.51e-03, fs:0.67403 (r=0.616,p=0.744),  time:30.558, tt:1589.036\n",
      "Ep:52, loss:0.00006, loss_test:0.10368, lr:9.51e-03, fs:0.69149 (r=0.657,p=0.730),  time:30.565, tt:1619.971\n",
      "Ep:53, loss:0.00006, loss_test:0.10651, lr:9.51e-03, fs:0.68085 (r=0.646,p=0.719),  time:30.587, tt:1651.707\n",
      "Ep:54, loss:0.00006, loss_test:0.10591, lr:9.51e-03, fs:0.66304 (r=0.616,p=0.718),  time:30.589, tt:1682.384\n",
      "Ep:55, loss:0.00006, loss_test:0.10376, lr:9.51e-03, fs:0.69231 (r=0.636,p=0.759),  time:30.584, tt:1712.712\n",
      "Ep:56, loss:0.00005, loss_test:0.10828, lr:9.51e-03, fs:0.70270 (r=0.657,p=0.756),  time:30.578, tt:1742.928\n",
      "Ep:57, loss:0.00005, loss_test:0.11223, lr:9.51e-03, fs:0.68156 (r=0.616,p=0.762),  time:30.582, tt:1773.772\n",
      "Ep:58, loss:0.00005, loss_test:0.10700, lr:9.51e-03, fs:0.68817 (r=0.646,p=0.736),  time:30.616, tt:1806.334\n",
      "Ep:59, loss:0.00005, loss_test:0.11331, lr:9.51e-03, fs:0.72826 (r=0.677,p=0.788),  time:30.607, tt:1836.407\n",
      "Ep:60, loss:0.00005, loss_test:0.09348, lr:9.41e-03, fs:0.72826 (r=0.677,p=0.788),  time:30.611, tt:1867.250\n",
      "Ep:61, loss:0.00005, loss_test:0.11250, lr:9.32e-03, fs:0.74737 (r=0.717,p=0.780),  time:30.599, tt:1897.154\n",
      "Ep:62, loss:0.00005, loss_test:0.10930, lr:9.23e-03, fs:0.67033 (r=0.616,p=0.735),  time:30.585, tt:1926.853\n",
      "Ep:63, loss:0.00004, loss_test:0.09631, lr:9.14e-03, fs:0.71591 (r=0.636,p=0.818),  time:30.593, tt:1957.949\n",
      "Ep:64, loss:0.00004, loss_test:0.10394, lr:9.04e-03, fs:0.71875 (r=0.697,p=0.742),  time:30.617, tt:1990.118\n",
      "Ep:65, loss:0.00004, loss_test:0.09893, lr:8.95e-03, fs:0.68966 (r=0.606,p=0.800),  time:30.625, tt:2021.234\n",
      "Ep:66, loss:0.00004, loss_test:0.10297, lr:8.86e-03, fs:0.73404 (r=0.697,p=0.775),  time:30.633, tt:2052.383\n",
      "Ep:67, loss:0.00004, loss_test:0.10895, lr:8.78e-03, fs:0.66667 (r=0.596,p=0.756),  time:30.622, tt:2082.295\n",
      "Ep:68, loss:0.00003, loss_test:0.10512, lr:8.69e-03, fs:0.71186 (r=0.636,p=0.808),  time:30.605, tt:2111.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00003, loss_test:0.10647, lr:8.60e-03, fs:0.66667 (r=0.606,p=0.741),  time:30.601, tt:2142.063\n",
      "Ep:70, loss:0.00003, loss_test:0.10752, lr:8.51e-03, fs:0.69364 (r=0.606,p=0.811),  time:30.604, tt:2172.888\n",
      "Ep:71, loss:0.00003, loss_test:0.09889, lr:8.43e-03, fs:0.71658 (r=0.677,p=0.761),  time:30.599, tt:2203.156\n",
      "Ep:72, loss:0.00003, loss_test:0.11494, lr:8.35e-03, fs:0.67429 (r=0.596,p=0.776),  time:30.595, tt:2233.437\n",
      "Ep:73, loss:0.00003, loss_test:0.10276, lr:8.26e-03, fs:0.74444 (r=0.677,p=0.827),  time:30.603, tt:2264.616\n",
      "Ep:74, loss:0.00003, loss_test:0.10585, lr:8.18e-03, fs:0.66667 (r=0.596,p=0.756),  time:30.600, tt:2294.984\n",
      "Ep:75, loss:0.00003, loss_test:0.11093, lr:8.10e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.637, tt:2328.412\n",
      "Ep:76, loss:0.00003, loss_test:0.11298, lr:8.02e-03, fs:0.67045 (r=0.596,p=0.766),  time:30.650, tt:2360.044\n",
      "Ep:77, loss:0.00003, loss_test:0.10332, lr:7.94e-03, fs:0.68182 (r=0.606,p=0.779),  time:30.669, tt:2392.217\n",
      "Ep:78, loss:0.00002, loss_test:0.10325, lr:7.86e-03, fs:0.69767 (r=0.606,p=0.822),  time:30.673, tt:2423.193\n",
      "Ep:79, loss:0.00002, loss_test:0.10411, lr:7.78e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.668, tt:2453.411\n",
      "Ep:80, loss:0.00002, loss_test:0.10017, lr:7.70e-03, fs:0.71264 (r=0.626,p=0.827),  time:30.679, tt:2485.028\n",
      "Ep:81, loss:0.00002, loss_test:0.10855, lr:7.62e-03, fs:0.69412 (r=0.596,p=0.831),  time:30.679, tt:2515.680\n",
      "Ep:82, loss:0.00002, loss_test:0.10982, lr:7.55e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.677, tt:2546.158\n",
      "Ep:83, loss:0.00002, loss_test:0.11650, lr:7.47e-03, fs:0.66667 (r=0.596,p=0.756),  time:30.673, tt:2576.512\n",
      "Ep:84, loss:0.00002, loss_test:0.10950, lr:7.40e-03, fs:0.68208 (r=0.596,p=0.797),  time:30.682, tt:2607.993\n",
      "Ep:85, loss:0.00002, loss_test:0.10518, lr:7.32e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.684, tt:2638.813\n",
      "Ep:86, loss:0.00002, loss_test:0.10816, lr:7.25e-03, fs:0.67816 (r=0.596,p=0.787),  time:30.676, tt:2668.837\n",
      "Ep:87, loss:0.00002, loss_test:0.11416, lr:7.18e-03, fs:0.68605 (r=0.596,p=0.808),  time:30.660, tt:2698.043\n",
      "Ep:88, loss:0.00002, loss_test:0.10239, lr:7.11e-03, fs:0.68605 (r=0.596,p=0.808),  time:30.653, tt:2728.094\n",
      "Ep:89, loss:0.00002, loss_test:0.11435, lr:7.03e-03, fs:0.68208 (r=0.596,p=0.797),  time:30.657, tt:2759.098\n",
      "Ep:90, loss:0.00002, loss_test:0.11722, lr:6.96e-03, fs:0.69006 (r=0.596,p=0.819),  time:30.655, tt:2789.618\n",
      "Ep:91, loss:0.00002, loss_test:0.10053, lr:6.89e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.646, tt:2819.458\n",
      "Ep:92, loss:0.00002, loss_test:0.11507, lr:6.83e-03, fs:0.67045 (r=0.596,p=0.766),  time:30.646, tt:2850.059\n",
      "Ep:93, loss:0.00002, loss_test:0.10961, lr:6.76e-03, fs:0.74854 (r=0.646,p=0.889),  time:30.642, tt:2880.387\n",
      "Ep:94, loss:0.00002, loss_test:0.11873, lr:6.69e-03, fs:0.67073 (r=0.556,p=0.846),  time:30.646, tt:2911.403\n",
      "Ep:95, loss:0.00002, loss_test:0.10711, lr:6.62e-03, fs:0.69318 (r=0.616,p=0.792),  time:30.642, tt:2941.637\n",
      "Ep:96, loss:0.00002, loss_test:0.11023, lr:6.56e-03, fs:0.69412 (r=0.596,p=0.831),  time:30.638, tt:2971.841\n",
      "Ep:97, loss:0.00002, loss_test:0.11671, lr:6.49e-03, fs:0.71084 (r=0.596,p=0.881),  time:30.640, tt:3002.747\n",
      "Ep:98, loss:0.00002, loss_test:0.12074, lr:6.43e-03, fs:0.67816 (r=0.596,p=0.787),  time:30.633, tt:3032.619\n",
      "Ep:99, loss:0.00002, loss_test:0.10628, lr:6.36e-03, fs:0.70659 (r=0.596,p=0.868),  time:30.629, tt:3062.856\n",
      "Ep:100, loss:0.00002, loss_test:0.12088, lr:6.30e-03, fs:0.69006 (r=0.596,p=0.819),  time:30.614, tt:3092.001\n",
      "Ep:101, loss:0.00001, loss_test:0.11406, lr:6.24e-03, fs:0.76404 (r=0.687,p=0.861),  time:30.609, tt:3122.151\n",
      "Ep:102, loss:0.00001, loss_test:0.11748, lr:6.17e-03, fs:0.68605 (r=0.596,p=0.808),  time:30.610, tt:3152.796\n",
      "Ep:103, loss:0.00001, loss_test:0.11604, lr:6.11e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.625, tt:3185.034\n",
      "Ep:104, loss:0.00001, loss_test:0.11761, lr:6.05e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.620, tt:3215.055\n",
      "Ep:105, loss:0.00001, loss_test:0.10897, lr:5.99e-03, fs:0.69412 (r=0.596,p=0.831),  time:30.616, tt:3245.301\n",
      "Ep:106, loss:0.00001, loss_test:0.12306, lr:5.93e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.601, tt:3274.300\n",
      "Ep:107, loss:0.00001, loss_test:0.11598, lr:5.87e-03, fs:0.70659 (r=0.596,p=0.868),  time:30.594, tt:3304.139\n",
      "Ep:108, loss:0.00001, loss_test:0.11504, lr:5.81e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.586, tt:3333.847\n",
      "Ep:109, loss:0.00001, loss_test:0.11216, lr:5.75e-03, fs:0.70659 (r=0.596,p=0.868),  time:30.589, tt:3364.798\n",
      "Ep:110, loss:0.00001, loss_test:0.12249, lr:5.70e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.584, tt:3394.860\n",
      "Ep:111, loss:0.00001, loss_test:0.11373, lr:5.64e-03, fs:0.70659 (r=0.596,p=0.868),  time:30.582, tt:3425.135\n",
      "Ep:112, loss:0.00001, loss_test:0.11510, lr:5.58e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.560, tt:3453.282\n",
      "Ep:113, loss:0.00001, loss_test:0.11458, lr:5.53e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.548, tt:3482.500\n",
      "Ep:114, loss:0.00001, loss_test:0.12408, lr:5.47e-03, fs:0.67485 (r=0.556,p=0.859),  time:30.539, tt:3512.001\n",
      "Ep:115, loss:0.00001, loss_test:0.11687, lr:5.42e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.530, tt:3541.442\n",
      "Ep:116, loss:0.00001, loss_test:0.12267, lr:5.36e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.538, tt:3572.982\n",
      "Ep:117, loss:0.00001, loss_test:0.12526, lr:5.31e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.533, tt:3602.865\n",
      "Ep:118, loss:0.00001, loss_test:0.12345, lr:5.26e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.530, tt:3633.114\n",
      "Ep:119, loss:0.00001, loss_test:0.12344, lr:5.20e-03, fs:0.66667 (r=0.545,p=0.857),  time:30.522, tt:3662.582\n",
      "Ep:120, loss:0.00001, loss_test:0.12841, lr:5.15e-03, fs:0.66667 (r=0.545,p=0.857),  time:30.517, tt:3692.562\n",
      "Ep:121, loss:0.00001, loss_test:0.12917, lr:5.10e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.517, tt:3723.071\n",
      "Ep:122, loss:0.00001, loss_test:0.12678, lr:5.05e-03, fs:0.65432 (r=0.535,p=0.841),  time:30.516, tt:3753.529\n",
      "Ep:123, loss:0.00001, loss_test:0.12444, lr:5.00e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.522, tt:3784.712\n",
      "Ep:124, loss:0.00001, loss_test:0.12922, lr:4.95e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.524, tt:3815.509\n",
      "Ep:125, loss:0.00001, loss_test:0.12175, lr:4.90e-03, fs:0.68712 (r=0.566,p=0.875),  time:30.551, tt:3849.381\n",
      "Ep:126, loss:0.00001, loss_test:0.12397, lr:4.85e-03, fs:0.67879 (r=0.566,p=0.848),  time:30.561, tt:3881.261\n",
      "Ep:127, loss:0.00001, loss_test:0.11916, lr:4.80e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.576, tt:3913.672\n",
      "Ep:128, loss:0.00001, loss_test:0.13008, lr:4.75e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.589, tt:3945.936\n",
      "Ep:129, loss:0.00001, loss_test:0.11893, lr:4.71e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.601, tt:3978.164\n",
      "Ep:130, loss:0.00001, loss_test:0.12574, lr:4.66e-03, fs:0.65432 (r=0.535,p=0.841),  time:30.605, tt:4009.312\n",
      "Ep:131, loss:0.00001, loss_test:0.12059, lr:4.61e-03, fs:0.72189 (r=0.616,p=0.871),  time:30.612, tt:4040.746\n",
      "Ep:132, loss:0.00001, loss_test:0.13312, lr:4.57e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.618, tt:4072.198\n",
      "Ep:133, loss:0.00001, loss_test:0.12573, lr:4.52e-03, fs:0.70303 (r=0.586,p=0.879),  time:30.623, tt:4103.486\n",
      "Ep:134, loss:0.00001, loss_test:0.12717, lr:4.48e-03, fs:0.65839 (r=0.535,p=0.855),  time:30.625, tt:4134.393\n",
      "Ep:135, loss:0.00001, loss_test:0.12949, lr:4.43e-03, fs:0.68712 (r=0.566,p=0.875),  time:30.635, tt:4166.326\n",
      "Ep:136, loss:0.00001, loss_test:0.13155, lr:4.39e-03, fs:0.64198 (r=0.525,p=0.825),  time:30.640, tt:4197.714\n",
      "Ep:137, loss:0.00001, loss_test:0.12451, lr:4.34e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.652, tt:4229.922\n",
      "Ep:138, loss:0.00001, loss_test:0.13400, lr:4.30e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.657, tt:4261.318\n",
      "Ep:139, loss:0.00001, loss_test:0.13059, lr:4.26e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.661, tt:4292.583\n",
      "Ep:140, loss:0.00001, loss_test:0.13242, lr:4.21e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.662, tt:4323.343\n",
      "Ep:141, loss:0.00001, loss_test:0.13052, lr:4.17e-03, fs:0.65432 (r=0.535,p=0.841),  time:30.662, tt:4354.052\n",
      "Ep:142, loss:0.00001, loss_test:0.12891, lr:4.13e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.666, tt:4385.175\n",
      "Ep:143, loss:0.00001, loss_test:0.13316, lr:4.09e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.676, tt:4417.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.13066, lr:4.05e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.686, tt:4449.522\n",
      "Ep:145, loss:0.00001, loss_test:0.12967, lr:4.01e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.701, tt:4482.371\n",
      "Ep:146, loss:0.00000, loss_test:0.13263, lr:3.97e-03, fs:0.68675 (r=0.576,p=0.851),  time:30.705, tt:4513.662\n",
      "Ep:147, loss:0.00000, loss_test:0.13152, lr:3.93e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.704, tt:4544.154\n",
      "Ep:148, loss:0.00001, loss_test:0.12989, lr:3.89e-03, fs:0.67485 (r=0.556,p=0.859),  time:30.721, tt:4577.486\n",
      "Ep:149, loss:0.00000, loss_test:0.13391, lr:3.85e-03, fs:0.67485 (r=0.556,p=0.859),  time:30.727, tt:4609.064\n",
      "Ep:150, loss:0.00000, loss_test:0.12822, lr:3.81e-03, fs:0.67073 (r=0.556,p=0.846),  time:30.730, tt:4640.236\n",
      "Ep:151, loss:0.00001, loss_test:0.13632, lr:3.77e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.723, tt:4669.959\n",
      "Ep:152, loss:0.00001, loss_test:0.13092, lr:3.73e-03, fs:0.68675 (r=0.576,p=0.851),  time:30.714, tt:4699.241\n",
      "Ep:153, loss:0.00001, loss_test:0.13253, lr:3.70e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.713, tt:4729.756\n",
      "Ep:154, loss:0.00001, loss_test:0.13330, lr:3.66e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.714, tt:4760.634\n",
      "Ep:155, loss:0.00001, loss_test:0.13245, lr:3.62e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.714, tt:4791.369\n",
      "Ep:156, loss:0.00000, loss_test:0.12904, lr:3.59e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.718, tt:4822.705\n",
      "Ep:157, loss:0.00000, loss_test:0.13181, lr:3.55e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.717, tt:4853.297\n",
      "Ep:158, loss:0.00000, loss_test:0.12833, lr:3.52e-03, fs:0.69512 (r=0.576,p=0.877),  time:30.717, tt:4883.927\n",
      "Ep:159, loss:0.00000, loss_test:0.13561, lr:3.48e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.715, tt:4914.377\n",
      "Ep:160, loss:0.00000, loss_test:0.13329, lr:3.45e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.724, tt:4946.576\n",
      "Ep:161, loss:0.00000, loss_test:0.13314, lr:3.41e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.736, tt:4979.253\n",
      "Ep:162, loss:0.00000, loss_test:0.13245, lr:3.38e-03, fs:0.66667 (r=0.545,p=0.857),  time:30.745, tt:5011.454\n",
      "Ep:163, loss:0.00000, loss_test:0.13028, lr:3.34e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.743, tt:5041.873\n",
      "Ep:164, loss:0.00000, loss_test:0.13284, lr:3.31e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.748, tt:5073.388\n",
      "Ep:165, loss:0.00000, loss_test:0.13222, lr:3.28e-03, fs:0.69512 (r=0.576,p=0.877),  time:30.752, tt:5104.754\n",
      "Ep:166, loss:0.00000, loss_test:0.13196, lr:3.24e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.757, tt:5136.396\n",
      "Ep:167, loss:0.00000, loss_test:0.12966, lr:3.21e-03, fs:0.69512 (r=0.576,p=0.877),  time:30.756, tt:5166.958\n",
      "Ep:168, loss:0.00000, loss_test:0.13302, lr:3.18e-03, fs:0.65409 (r=0.525,p=0.867),  time:30.765, tt:5199.299\n",
      "Ep:169, loss:0.00000, loss_test:0.12990, lr:3.15e-03, fs:0.68675 (r=0.576,p=0.851),  time:30.770, tt:5230.865\n",
      "Ep:170, loss:0.00000, loss_test:0.13134, lr:3.12e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.783, tt:5263.834\n",
      "Ep:171, loss:0.00000, loss_test:0.13182, lr:3.09e-03, fs:0.69512 (r=0.576,p=0.877),  time:30.776, tt:5293.417\n",
      "Ep:172, loss:0.00000, loss_test:0.13280, lr:3.05e-03, fs:0.64596 (r=0.525,p=0.839),  time:30.770, tt:5323.229\n",
      "Ep:173, loss:0.00000, loss_test:0.13054, lr:3.02e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.773, tt:5354.573\n",
      "Ep:174, loss:0.00000, loss_test:0.13170, lr:2.99e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.777, tt:5385.993\n",
      "Ep:175, loss:0.00000, loss_test:0.13128, lr:2.96e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.777, tt:5416.740\n",
      "Ep:176, loss:0.00000, loss_test:0.13337, lr:2.93e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.783, tt:5448.658\n",
      "Ep:177, loss:0.00000, loss_test:0.13494, lr:2.90e-03, fs:0.65823 (r=0.525,p=0.881),  time:30.788, tt:5480.287\n",
      "Ep:178, loss:0.00000, loss_test:0.13301, lr:2.88e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.792, tt:5511.830\n",
      "Ep:179, loss:0.00000, loss_test:0.13053, lr:2.85e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.795, tt:5543.045\n",
      "Ep:180, loss:0.00000, loss_test:0.13139, lr:2.82e-03, fs:0.69939 (r=0.576,p=0.891),  time:30.799, tt:5574.661\n",
      "Ep:181, loss:0.00000, loss_test:0.13483, lr:2.79e-03, fs:0.66667 (r=0.535,p=0.883),  time:30.804, tt:5606.349\n",
      "Ep:182, loss:0.00000, loss_test:0.13200, lr:2.76e-03, fs:0.69939 (r=0.576,p=0.891),  time:30.807, tt:5637.591\n",
      "Ep:183, loss:0.00000, loss_test:0.13098, lr:2.73e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.809, tt:5668.928\n",
      "Ep:184, loss:0.00000, loss_test:0.13075, lr:2.71e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.811, tt:5700.036\n",
      "Ep:185, loss:0.00000, loss_test:0.13200, lr:2.68e-03, fs:0.67485 (r=0.556,p=0.859),  time:30.825, tt:5733.372\n",
      "Ep:186, loss:0.00000, loss_test:0.12938, lr:2.65e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.829, tt:5765.068\n",
      "Ep:187, loss:0.00000, loss_test:0.13253, lr:2.63e-03, fs:0.67485 (r=0.556,p=0.859),  time:30.841, tt:5798.097\n",
      "Ep:188, loss:0.00000, loss_test:0.13136, lr:2.60e-03, fs:0.69939 (r=0.576,p=0.891),  time:30.839, tt:5828.650\n",
      "Ep:189, loss:0.00000, loss_test:0.13063, lr:2.57e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.845, tt:5860.482\n",
      "Ep:190, loss:0.00000, loss_test:0.13086, lr:2.55e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.851, tt:5892.452\n",
      "Ep:191, loss:0.00000, loss_test:0.13075, lr:2.52e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.851, tt:5923.412\n",
      "Ep:192, loss:0.00000, loss_test:0.13086, lr:2.50e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.847, tt:5953.539\n",
      "Ep:193, loss:0.00000, loss_test:0.13139, lr:2.47e-03, fs:0.69939 (r=0.576,p=0.891),  time:30.845, tt:5983.890\n",
      "Ep:194, loss:0.00000, loss_test:0.13152, lr:2.45e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.840, tt:6013.782\n",
      "Ep:195, loss:0.00000, loss_test:0.12892, lr:2.42e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.844, tt:6045.362\n",
      "Ep:196, loss:0.00000, loss_test:0.13143, lr:2.40e-03, fs:0.65000 (r=0.525,p=0.852),  time:30.846, tt:6076.609\n",
      "Ep:197, loss:0.00000, loss_test:0.13090, lr:2.38e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.842, tt:6106.725\n",
      "Ep:198, loss:0.00000, loss_test:0.13064, lr:2.35e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.828, tt:6134.837\n",
      "Ep:199, loss:0.00000, loss_test:0.13109, lr:2.33e-03, fs:0.68293 (r=0.566,p=0.862),  time:30.809, tt:6161.756\n",
      "Ep:200, loss:0.00000, loss_test:0.12989, lr:2.31e-03, fs:0.69091 (r=0.576,p=0.864),  time:30.785, tt:6187.702\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02489, lr:6.00e-02, fs:0.60177 (r=0.687,p=0.535),  time:23.358, tt:23.358\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02248, lr:6.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:22.522, tt:45.044\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02330, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:23.548, tt:70.645\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02330, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.639, tt:98.555\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02273, lr:6.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:25.709, tt:128.544\n",
      "Ep:5, loss:0.00004, loss_test:0.02200, lr:6.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:26.738, tt:160.427\n",
      "Ep:6, loss:0.00004, loss_test:0.02162, lr:6.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:27.317, tt:191.218\n",
      "Ep:7, loss:0.00004, loss_test:0.02215, lr:6.00e-02, fs:0.63203 (r=0.737,p=0.553),  time:27.944, tt:223.553\n",
      "Ep:8, loss:0.00003, loss_test:0.02343, lr:6.00e-02, fs:0.62385 (r=0.687,p=0.571),  time:28.293, tt:254.636\n",
      "Ep:9, loss:0.00003, loss_test:0.02439, lr:6.00e-02, fs:0.62559 (r=0.667,p=0.589),  time:28.680, tt:286.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00003, loss_test:0.02391, lr:6.00e-02, fs:0.63208 (r=0.677,p=0.593),  time:28.969, tt:318.654\n",
      "Ep:11, loss:0.00003, loss_test:0.02235, lr:6.00e-02, fs:0.62963 (r=0.687,p=0.581),  time:29.255, tt:351.058\n",
      "Ep:12, loss:0.00003, loss_test:0.02106, lr:6.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:29.401, tt:382.214\n",
      "Ep:13, loss:0.00003, loss_test:0.02033, lr:6.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:29.573, tt:414.018\n",
      "Ep:14, loss:0.00003, loss_test:0.02001, lr:6.00e-02, fs:0.64629 (r=0.747,p=0.569),  time:29.646, tt:444.685\n",
      "Ep:15, loss:0.00003, loss_test:0.01995, lr:5.94e-02, fs:0.66071 (r=0.747,p=0.592),  time:29.772, tt:476.348\n",
      "Ep:16, loss:0.00003, loss_test:0.02011, lr:5.88e-02, fs:0.65158 (r=0.727,p=0.590),  time:30.025, tt:510.419\n",
      "Ep:17, loss:0.00003, loss_test:0.02030, lr:5.82e-02, fs:0.65438 (r=0.717,p=0.602),  time:30.147, tt:542.650\n",
      "Ep:18, loss:0.00003, loss_test:0.02030, lr:5.76e-02, fs:0.61611 (r=0.657,p=0.580),  time:30.367, tt:576.973\n",
      "Ep:19, loss:0.00003, loss_test:0.01999, lr:5.71e-02, fs:0.60952 (r=0.646,p=0.577),  time:30.423, tt:608.467\n",
      "Ep:20, loss:0.00003, loss_test:0.01955, lr:5.65e-02, fs:0.62617 (r=0.677,p=0.583),  time:30.452, tt:639.493\n",
      "Ep:21, loss:0.00003, loss_test:0.01923, lr:5.59e-02, fs:0.65455 (r=0.727,p=0.595),  time:30.601, tt:673.216\n",
      "Ep:22, loss:0.00003, loss_test:0.01905, lr:5.54e-02, fs:0.67857 (r=0.768,p=0.608),  time:30.652, tt:704.987\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01902, lr:5.54e-02, fs:0.67265 (r=0.758,p=0.605),  time:30.743, tt:737.832\n",
      "Ep:24, loss:0.00002, loss_test:0.01914, lr:5.54e-02, fs:0.67568 (r=0.758,p=0.610),  time:30.796, tt:769.891\n",
      "Ep:25, loss:0.00002, loss_test:0.01934, lr:5.54e-02, fs:0.66968 (r=0.747,p=0.607),  time:30.801, tt:800.827\n",
      "Ep:26, loss:0.00002, loss_test:0.01941, lr:5.54e-02, fs:0.67281 (r=0.737,p=0.619),  time:30.857, tt:833.150\n",
      "Ep:27, loss:0.00002, loss_test:0.01935, lr:5.54e-02, fs:0.67890 (r=0.747,p=0.622),  time:30.867, tt:864.278\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01922, lr:5.54e-02, fs:0.68493 (r=0.758,p=0.625),  time:30.891, tt:895.841\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01914, lr:5.54e-02, fs:0.69091 (r=0.768,p=0.628),  time:30.917, tt:927.510\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01916, lr:5.54e-02, fs:0.69091 (r=0.768,p=0.628),  time:30.967, tt:959.981\n",
      "Ep:31, loss:0.00002, loss_test:0.01925, lr:5.54e-02, fs:0.69406 (r=0.768,p=0.633),  time:31.011, tt:992.346\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01936, lr:5.54e-02, fs:0.69406 (r=0.768,p=0.633),  time:30.970, tt:1022.008\n",
      "Ep:33, loss:0.00002, loss_test:0.01938, lr:5.54e-02, fs:0.68807 (r=0.758,p=0.630),  time:30.951, tt:1052.323\n",
      "Ep:34, loss:0.00002, loss_test:0.01942, lr:5.54e-02, fs:0.69406 (r=0.768,p=0.633),  time:30.971, tt:1083.994\n",
      "Ep:35, loss:0.00002, loss_test:0.01934, lr:5.54e-02, fs:0.70000 (r=0.778,p=0.636),  time:30.976, tt:1115.125\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01930, lr:5.54e-02, fs:0.70588 (r=0.788,p=0.639),  time:30.965, tt:1145.706\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01934, lr:5.54e-02, fs:0.70588 (r=0.788,p=0.639),  time:30.911, tt:1174.613\n",
      "Ep:38, loss:0.00002, loss_test:0.01940, lr:5.54e-02, fs:0.70588 (r=0.788,p=0.639),  time:30.887, tt:1204.574\n",
      "Ep:39, loss:0.00002, loss_test:0.01942, lr:5.54e-02, fs:0.70642 (r=0.778,p=0.647),  time:30.863, tt:1234.505\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01939, lr:5.54e-02, fs:0.70968 (r=0.778,p=0.653),  time:30.829, tt:1263.996\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01936, lr:5.54e-02, fs:0.71296 (r=0.778,p=0.658),  time:30.834, tt:1295.012\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01936, lr:5.54e-02, fs:0.71889 (r=0.788,p=0.661),  time:30.858, tt:1326.906\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01936, lr:5.54e-02, fs:0.72558 (r=0.788,p=0.672),  time:30.833, tt:1356.654\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01934, lr:5.54e-02, fs:0.72222 (r=0.788,p=0.667),  time:30.842, tt:1387.907\n",
      "Ep:45, loss:0.00002, loss_test:0.01934, lr:5.54e-02, fs:0.72222 (r=0.788,p=0.667),  time:30.839, tt:1418.614\n",
      "Ep:46, loss:0.00002, loss_test:0.01930, lr:5.54e-02, fs:0.72558 (r=0.788,p=0.672),  time:30.832, tt:1449.093\n",
      "Ep:47, loss:0.00002, loss_test:0.01931, lr:5.54e-02, fs:0.71963 (r=0.778,p=0.670),  time:30.820, tt:1479.380\n",
      "Ep:48, loss:0.00002, loss_test:0.01929, lr:5.54e-02, fs:0.72897 (r=0.788,p=0.678),  time:30.809, tt:1509.635\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01931, lr:5.54e-02, fs:0.72642 (r=0.778,p=0.681),  time:30.795, tt:1539.741\n",
      "Ep:50, loss:0.00002, loss_test:0.01931, lr:5.54e-02, fs:0.72986 (r=0.778,p=0.688),  time:30.816, tt:1571.636\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01927, lr:5.54e-02, fs:0.73585 (r=0.788,p=0.690),  time:30.826, tt:1602.975\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01933, lr:5.54e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.861, tt:1635.636\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01935, lr:5.54e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.862, tt:1666.562\n",
      "Ep:54, loss:0.00002, loss_test:0.01938, lr:5.54e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.819, tt:1695.041\n",
      "Ep:55, loss:0.00001, loss_test:0.01938, lr:5.54e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.851, tt:1727.680\n",
      "Ep:56, loss:0.00001, loss_test:0.01938, lr:5.54e-02, fs:0.74286 (r=0.788,p=0.703),  time:30.801, tt:1755.659\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01937, lr:5.54e-02, fs:0.74286 (r=0.788,p=0.703),  time:30.787, tt:1785.633\n",
      "Ep:58, loss:0.00001, loss_test:0.01938, lr:5.54e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.805, tt:1817.503\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01938, lr:5.54e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.786, tt:1847.138\n",
      "Ep:60, loss:0.00001, loss_test:0.01938, lr:5.54e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.780, tt:1877.560\n",
      "Ep:61, loss:0.00001, loss_test:0.01943, lr:5.54e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.759, tt:1907.075\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01942, lr:5.54e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.766, tt:1938.250\n",
      "Ep:63, loss:0.00001, loss_test:0.01940, lr:5.54e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.769, tt:1969.225\n",
      "Ep:64, loss:0.00001, loss_test:0.01940, lr:5.54e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.749, tt:1998.684\n",
      "Ep:65, loss:0.00001, loss_test:0.01939, lr:5.54e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.742, tt:2028.992\n",
      "Ep:66, loss:0.00001, loss_test:0.01940, lr:5.54e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.761, tt:2060.972\n",
      "Ep:67, loss:0.00001, loss_test:0.01943, lr:5.54e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.755, tt:2091.371\n",
      "Ep:68, loss:0.00001, loss_test:0.01949, lr:5.54e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.753, tt:2121.954\n",
      "Ep:69, loss:0.00001, loss_test:0.01954, lr:5.54e-02, fs:0.74146 (r=0.768,p=0.717),  time:30.726, tt:2150.849\n",
      "Ep:70, loss:0.00001, loss_test:0.01951, lr:5.54e-02, fs:0.74146 (r=0.768,p=0.717),  time:30.724, tt:2181.384\n",
      "Ep:71, loss:0.00001, loss_test:0.01945, lr:5.54e-02, fs:0.74146 (r=0.768,p=0.717),  time:30.714, tt:2211.405\n",
      "Ep:72, loss:0.00001, loss_test:0.01949, lr:5.54e-02, fs:0.73529 (r=0.758,p=0.714),  time:30.708, tt:2241.660\n",
      "Ep:73, loss:0.00001, loss_test:0.01952, lr:5.48e-02, fs:0.73529 (r=0.758,p=0.714),  time:30.694, tt:2271.367\n",
      "Ep:74, loss:0.00001, loss_test:0.01949, lr:5.43e-02, fs:0.72906 (r=0.747,p=0.712),  time:30.679, tt:2300.925\n",
      "Ep:75, loss:0.00001, loss_test:0.01949, lr:5.37e-02, fs:0.73267 (r=0.747,p=0.718),  time:30.676, tt:2331.364\n",
      "Ep:76, loss:0.00001, loss_test:0.01954, lr:5.32e-02, fs:0.73267 (r=0.747,p=0.718),  time:30.663, tt:2361.051\n",
      "Ep:77, loss:0.00001, loss_test:0.01956, lr:5.27e-02, fs:0.74372 (r=0.747,p=0.740),  time:30.675, tt:2392.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00001, loss_test:0.01952, lr:5.21e-02, fs:0.74000 (r=0.747,p=0.733),  time:30.665, tt:2422.502\n",
      "Ep:79, loss:0.00001, loss_test:0.01954, lr:5.16e-02, fs:0.74372 (r=0.747,p=0.740),  time:30.640, tt:2451.182\n",
      "Ep:80, loss:0.00001, loss_test:0.01955, lr:5.11e-02, fs:0.74372 (r=0.747,p=0.740),  time:30.644, tt:2482.139\n",
      "Ep:81, loss:0.00001, loss_test:0.01960, lr:5.06e-02, fs:0.74747 (r=0.747,p=0.747),  time:30.626, tt:2511.363\n",
      "Ep:82, loss:0.00001, loss_test:0.01963, lr:5.01e-02, fs:0.74747 (r=0.747,p=0.747),  time:30.632, tt:2542.450\n",
      "Ep:83, loss:0.00001, loss_test:0.01963, lr:4.96e-02, fs:0.74747 (r=0.747,p=0.747),  time:30.628, tt:2572.734\n",
      "Ep:84, loss:0.00001, loss_test:0.01968, lr:4.91e-02, fs:0.74112 (r=0.737,p=0.745),  time:30.651, tt:2605.337\n",
      "Ep:85, loss:0.00001, loss_test:0.01967, lr:4.86e-02, fs:0.74490 (r=0.737,p=0.753),  time:30.646, tt:2635.580\n",
      "Ep:86, loss:0.00001, loss_test:0.01973, lr:4.81e-02, fs:0.73846 (r=0.727,p=0.750),  time:30.643, tt:2665.966\n",
      "Ep:87, loss:0.00001, loss_test:0.01973, lr:4.76e-02, fs:0.74490 (r=0.737,p=0.753),  time:30.619, tt:2694.449\n",
      "Ep:88, loss:0.00001, loss_test:0.01975, lr:4.71e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.606, tt:2723.953\n",
      "Ep:89, loss:0.00001, loss_test:0.01977, lr:4.67e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.594, tt:2753.424\n",
      "Ep:90, loss:0.00001, loss_test:0.01981, lr:4.62e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.572, tt:2782.040\n",
      "Ep:91, loss:0.00001, loss_test:0.01983, lr:4.57e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.558, tt:2811.311\n",
      "Ep:92, loss:0.00001, loss_test:0.01988, lr:4.53e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.539, tt:2840.108\n",
      "Ep:93, loss:0.00001, loss_test:0.01991, lr:4.48e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.560, tt:2872.595\n",
      "Ep:94, loss:0.00001, loss_test:0.01991, lr:4.44e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.565, tt:2903.643\n",
      "Ep:95, loss:0.00001, loss_test:0.01993, lr:4.39e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.562, tt:2933.974\n",
      "Ep:96, loss:0.00001, loss_test:0.01990, lr:4.35e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.548, tt:2963.181\n",
      "Ep:97, loss:0.00001, loss_test:0.01994, lr:4.31e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.536, tt:2992.540\n",
      "Ep:98, loss:0.00001, loss_test:0.01999, lr:4.26e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.535, tt:3022.927\n",
      "Ep:99, loss:0.00001, loss_test:0.02003, lr:4.22e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.538, tt:3053.763\n",
      "Ep:100, loss:0.00001, loss_test:0.02004, lr:4.18e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.518, tt:3082.366\n",
      "Ep:101, loss:0.00001, loss_test:0.02007, lr:4.14e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.525, tt:3113.539\n",
      "Ep:102, loss:0.00001, loss_test:0.02007, lr:4.10e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.522, tt:3143.787\n",
      "Ep:103, loss:0.00001, loss_test:0.02008, lr:4.05e-02, fs:0.73298 (r=0.707,p=0.761),  time:30.523, tt:3174.358\n",
      "Ep:104, loss:0.00001, loss_test:0.02017, lr:4.01e-02, fs:0.73298 (r=0.707,p=0.761),  time:30.514, tt:3203.961\n",
      "Ep:105, loss:0.00001, loss_test:0.02020, lr:3.97e-02, fs:0.73016 (r=0.697,p=0.767),  time:30.500, tt:3232.967\n",
      "Ep:106, loss:0.00001, loss_test:0.02017, lr:3.93e-02, fs:0.73016 (r=0.697,p=0.767),  time:30.503, tt:3263.855\n",
      "Ep:107, loss:0.00001, loss_test:0.02016, lr:3.89e-02, fs:0.73684 (r=0.707,p=0.769),  time:30.504, tt:3294.464\n",
      "Ep:108, loss:0.00001, loss_test:0.02021, lr:3.86e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.518, tt:3326.467\n",
      "Ep:109, loss:0.00001, loss_test:0.02024, lr:3.82e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.514, tt:3356.519\n",
      "Ep:110, loss:0.00001, loss_test:0.02026, lr:3.78e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.504, tt:3385.986\n",
      "Ep:111, loss:0.00001, loss_test:0.02034, lr:3.74e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.496, tt:3415.497\n",
      "Ep:112, loss:0.00001, loss_test:0.02039, lr:3.70e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.500, tt:3446.477\n",
      "Ep:113, loss:0.00001, loss_test:0.02039, lr:3.67e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.493, tt:3476.155\n",
      "Ep:114, loss:0.00001, loss_test:0.02035, lr:3.63e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.484, tt:3505.626\n",
      "Ep:115, loss:0.00001, loss_test:0.02042, lr:3.59e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.486, tt:3536.325\n",
      "Ep:116, loss:0.00001, loss_test:0.02034, lr:3.56e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.471, tt:3565.080\n",
      "Ep:117, loss:0.00001, loss_test:0.02040, lr:3.52e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.471, tt:3595.567\n",
      "Ep:118, loss:0.00001, loss_test:0.02053, lr:3.49e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.458, tt:3624.541\n",
      "Ep:119, loss:0.00001, loss_test:0.02049, lr:3.45e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.461, tt:3655.315\n",
      "Ep:120, loss:0.00001, loss_test:0.02048, lr:3.42e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.442, tt:3683.435\n",
      "Ep:121, loss:0.00001, loss_test:0.02048, lr:3.38e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.437, tt:3713.355\n",
      "Ep:122, loss:0.00001, loss_test:0.02055, lr:3.35e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.446, tt:3744.881\n",
      "Ep:123, loss:0.00001, loss_test:0.02055, lr:3.32e-02, fs:0.72727 (r=0.687,p=0.773),  time:30.428, tt:3773.052\n",
      "Ep:124, loss:0.00001, loss_test:0.02052, lr:3.28e-02, fs:0.72727 (r=0.687,p=0.773),  time:30.426, tt:3803.284\n",
      "Ep:125, loss:0.00001, loss_test:0.02059, lr:3.25e-02, fs:0.72727 (r=0.687,p=0.773),  time:30.420, tt:3832.967\n",
      "Ep:126, loss:0.00001, loss_test:0.02065, lr:3.22e-02, fs:0.72727 (r=0.687,p=0.773),  time:30.428, tt:3864.298\n",
      "Ep:127, loss:0.00001, loss_test:0.02066, lr:3.19e-02, fs:0.72727 (r=0.687,p=0.773),  time:30.427, tt:3894.661\n",
      "Ep:128, loss:0.00001, loss_test:0.02065, lr:3.15e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.415, tt:3923.521\n",
      "Ep:129, loss:0.00001, loss_test:0.02064, lr:3.12e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.422, tt:3954.888\n",
      "Ep:130, loss:0.00001, loss_test:0.02067, lr:3.09e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.412, tt:3983.938\n",
      "Ep:131, loss:0.00001, loss_test:0.02069, lr:3.06e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.423, tt:4015.800\n",
      "Ep:132, loss:0.00001, loss_test:0.02072, lr:3.03e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.424, tt:4046.443\n",
      "Ep:133, loss:0.00001, loss_test:0.02074, lr:3.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.422, tt:4076.558\n",
      "Ep:134, loss:0.00001, loss_test:0.02074, lr:2.97e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.411, tt:4105.523\n",
      "Ep:135, loss:0.00001, loss_test:0.02076, lr:2.94e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.405, tt:4135.087\n",
      "Ep:136, loss:0.00001, loss_test:0.02078, lr:2.91e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.433, tt:4169.367\n",
      "Ep:137, loss:0.00001, loss_test:0.02081, lr:2.88e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.439, tt:4200.549\n",
      "Ep:138, loss:0.00001, loss_test:0.02087, lr:2.85e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.441, tt:4231.332\n",
      "Ep:139, loss:0.00001, loss_test:0.02084, lr:2.82e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.445, tt:4262.335\n",
      "Ep:140, loss:0.00001, loss_test:0.02088, lr:2.80e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.443, tt:4292.498\n",
      "Ep:141, loss:0.00001, loss_test:0.02085, lr:2.77e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.450, tt:4323.961\n",
      "Ep:142, loss:0.00001, loss_test:0.02091, lr:2.74e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.453, tt:4354.835\n",
      "Ep:143, loss:0.00001, loss_test:0.02095, lr:2.71e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.458, tt:4386.014\n",
      "Ep:144, loss:0.00001, loss_test:0.02095, lr:2.69e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.467, tt:4417.762\n",
      "Ep:145, loss:0.00001, loss_test:0.02092, lr:2.66e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.471, tt:4448.726\n",
      "Ep:146, loss:0.00001, loss_test:0.02094, lr:2.63e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.476, tt:4479.901\n",
      "Ep:147, loss:0.00001, loss_test:0.02098, lr:2.61e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.482, tt:4511.312\n",
      "Ep:148, loss:0.00001, loss_test:0.02099, lr:2.58e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.485, tt:4542.246\n",
      "Ep:149, loss:0.00001, loss_test:0.02103, lr:2.55e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.484, tt:4572.590\n",
      "Ep:150, loss:0.00001, loss_test:0.02101, lr:2.53e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.476, tt:4601.945\n",
      "Ep:151, loss:0.00001, loss_test:0.02104, lr:2.50e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.488, tt:4634.200\n",
      "Ep:152, loss:0.00001, loss_test:0.02107, lr:2.48e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.496, tt:4665.895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00001, loss_test:0.02109, lr:2.45e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.500, tt:4696.994\n",
      "Ep:154, loss:0.00001, loss_test:0.02110, lr:2.43e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.511, tt:4729.228\n",
      "Ep:155, loss:0.00001, loss_test:0.02111, lr:2.40e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.502, tt:4758.339\n",
      "Ep:156, loss:0.00001, loss_test:0.02111, lr:2.38e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.505, tt:4789.338\n",
      "Ep:157, loss:0.00001, loss_test:0.02112, lr:2.36e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.516, tt:4821.474\n",
      "Ep:158, loss:0.00001, loss_test:0.02116, lr:2.33e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.529, tt:4854.090\n",
      "Ep:159, loss:0.00001, loss_test:0.02121, lr:2.31e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.538, tt:4886.108\n",
      "Ep:160, loss:0.00001, loss_test:0.02118, lr:2.29e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.553, tt:4919.006\n",
      "Ep:161, loss:0.00001, loss_test:0.02120, lr:2.26e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.559, tt:4950.546\n",
      "Ep:162, loss:0.00001, loss_test:0.02121, lr:2.24e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.554, tt:4980.337\n",
      "Ep:163, loss:0.00001, loss_test:0.02121, lr:2.22e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.557, tt:5011.315\n",
      "Ep:164, loss:0.00001, loss_test:0.02126, lr:2.20e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.561, tt:5042.570\n",
      "Ep:165, loss:0.00001, loss_test:0.02127, lr:2.17e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.572, tt:5075.020\n",
      "Ep:166, loss:0.00001, loss_test:0.02129, lr:2.15e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.576, tt:5106.186\n",
      "Ep:167, loss:0.00001, loss_test:0.02131, lr:2.13e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.582, tt:5137.838\n",
      "Ep:168, loss:0.00001, loss_test:0.02131, lr:2.11e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.584, tt:5168.725\n",
      "Ep:169, loss:0.00001, loss_test:0.02131, lr:2.09e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.586, tt:5199.623\n",
      "Ep:170, loss:0.00001, loss_test:0.02136, lr:2.07e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.594, tt:5231.591\n",
      "Ep:171, loss:0.00001, loss_test:0.02139, lr:2.05e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.602, tt:5263.562\n",
      "Ep:172, loss:0.00001, loss_test:0.02138, lr:2.03e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.600, tt:5293.849\n",
      "Ep:173, loss:0.00001, loss_test:0.02137, lr:2.01e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.604, tt:5325.093\n",
      "Ep:174, loss:0.00001, loss_test:0.02138, lr:1.99e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.606, tt:5356.098\n",
      "Ep:175, loss:0.00001, loss_test:0.02142, lr:1.97e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.612, tt:5387.707\n",
      "Ep:176, loss:0.00001, loss_test:0.02141, lr:1.95e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.623, tt:5420.307\n",
      "Ep:177, loss:0.00001, loss_test:0.02141, lr:1.93e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.634, tt:5452.824\n",
      "Ep:178, loss:0.00001, loss_test:0.02145, lr:1.91e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.639, tt:5484.377\n",
      "Ep:179, loss:0.00001, loss_test:0.02147, lr:1.89e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.639, tt:5514.989\n",
      "Ep:180, loss:0.00001, loss_test:0.02146, lr:1.87e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.643, tt:5546.325\n",
      "Ep:181, loss:0.00001, loss_test:0.02154, lr:1.85e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.638, tt:5576.188\n",
      "Ep:182, loss:0.00001, loss_test:0.02157, lr:1.83e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.638, tt:5606.771\n",
      "Ep:183, loss:0.00001, loss_test:0.02155, lr:1.81e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.632, tt:5636.213\n",
      "Ep:184, loss:0.00001, loss_test:0.02152, lr:1.80e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.634, tt:5667.216\n",
      "Ep:185, loss:0.00001, loss_test:0.02155, lr:1.78e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.634, tt:5697.947\n",
      "Ep:186, loss:0.00001, loss_test:0.02158, lr:1.76e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.642, tt:5730.126\n",
      "Ep:187, loss:0.00001, loss_test:0.02160, lr:1.74e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.646, tt:5761.433\n",
      "Ep:188, loss:0.00001, loss_test:0.02163, lr:1.73e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.646, tt:5792.024\n",
      "Ep:189, loss:0.00001, loss_test:0.02160, lr:1.71e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.645, tt:5822.539\n",
      "Ep:190, loss:0.00001, loss_test:0.02163, lr:1.69e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.644, tt:5853.042\n",
      "Ep:191, loss:0.00001, loss_test:0.02163, lr:1.67e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.645, tt:5883.802\n",
      "Ep:192, loss:0.00001, loss_test:0.02164, lr:1.66e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.652, tt:5915.852\n",
      "Ep:193, loss:0.00001, loss_test:0.02166, lr:1.64e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.649, tt:5945.967\n",
      "Ep:194, loss:0.00001, loss_test:0.02169, lr:1.62e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.645, tt:5975.746\n",
      "Ep:195, loss:0.00001, loss_test:0.02170, lr:1.61e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.657, tt:6008.789\n",
      "Ep:196, loss:0.00001, loss_test:0.02170, lr:1.59e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.658, tt:6039.711\n",
      "Ep:197, loss:0.00001, loss_test:0.02172, lr:1.58e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.659, tt:6070.466\n",
      "Ep:198, loss:0.00001, loss_test:0.02171, lr:1.56e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.665, tt:6102.340\n",
      "Ep:199, loss:0.00001, loss_test:0.02172, lr:1.54e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.665, tt:6132.923\n",
      "Ep:200, loss:0.00001, loss_test:0.02175, lr:1.53e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.670, tt:6164.593\n",
      "Ep:201, loss:0.00001, loss_test:0.02177, lr:1.51e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.663, tt:6193.881\n",
      "Ep:202, loss:0.00001, loss_test:0.02173, lr:1.50e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.657, tt:6223.376\n",
      "Ep:203, loss:0.00001, loss_test:0.02174, lr:1.48e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.650, tt:6252.543\n",
      "Ep:204, loss:0.00001, loss_test:0.02176, lr:1.47e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.640, tt:6281.166\n",
      "Ep:205, loss:0.00001, loss_test:0.02181, lr:1.45e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.640, tt:6311.809\n",
      "Ep:206, loss:0.00001, loss_test:0.02182, lr:1.44e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.658, tt:6346.188\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14504, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.631, tt:25.631\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14438, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.380, tt:56.761\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.14323, lr:1.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:28.670, tt:86.011\n",
      "Ep:3, loss:0.00027, loss_test:0.14139, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:29.869, tt:119.474\n",
      "Ep:4, loss:0.00026, loss_test:0.13892, lr:1.00e-02, fs:0.63670 (r=0.859,p=0.506),  time:30.404, tt:152.018\n",
      "Ep:5, loss:0.00025, loss_test:0.13740, lr:1.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:30.787, tt:184.721\n",
      "Ep:6, loss:0.00024, loss_test:0.13685, lr:1.00e-02, fs:0.63248 (r=0.747,p=0.548),  time:30.945, tt:216.616\n",
      "Ep:7, loss:0.00023, loss_test:0.13634, lr:1.00e-02, fs:0.60099 (r=0.616,p=0.587),  time:31.049, tt:248.396\n",
      "Ep:8, loss:0.00022, loss_test:0.13588, lr:1.00e-02, fs:0.59794 (r=0.586,p=0.611),  time:30.981, tt:278.827\n",
      "Ep:9, loss:0.00022, loss_test:0.13314, lr:1.00e-02, fs:0.60914 (r=0.606,p=0.612),  time:31.241, tt:312.406\n",
      "Ep:10, loss:0.00021, loss_test:0.12951, lr:1.00e-02, fs:0.60396 (r=0.616,p=0.592),  time:31.351, tt:344.858\n",
      "Ep:11, loss:0.00021, loss_test:0.12830, lr:1.00e-02, fs:0.62376 (r=0.636,p=0.612),  time:31.470, tt:377.637\n",
      "Ep:12, loss:0.00020, loss_test:0.12871, lr:1.00e-02, fs:0.60104 (r=0.586,p=0.617),  time:31.410, tt:408.325\n",
      "Ep:13, loss:0.00019, loss_test:0.12657, lr:9.90e-03, fs:0.56989 (r=0.535,p=0.609),  time:31.394, tt:439.519\n",
      "Ep:14, loss:0.00019, loss_test:0.12285, lr:9.80e-03, fs:0.59259 (r=0.566,p=0.622),  time:31.323, tt:469.842\n",
      "Ep:15, loss:0.00018, loss_test:0.12023, lr:9.70e-03, fs:0.58511 (r=0.556,p=0.618),  time:31.403, tt:502.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00018, loss_test:0.11914, lr:9.61e-03, fs:0.57923 (r=0.535,p=0.631),  time:31.456, tt:534.750\n",
      "Ep:17, loss:0.00017, loss_test:0.11771, lr:9.51e-03, fs:0.57923 (r=0.535,p=0.631),  time:31.406, tt:565.313\n",
      "Ep:18, loss:0.00017, loss_test:0.11600, lr:9.41e-03, fs:0.60541 (r=0.566,p=0.651),  time:31.453, tt:597.613\n",
      "Ep:19, loss:0.00016, loss_test:0.11538, lr:9.32e-03, fs:0.60870 (r=0.566,p=0.659),  time:31.476, tt:629.520\n",
      "Ep:20, loss:0.00016, loss_test:0.11396, lr:9.23e-03, fs:0.60440 (r=0.556,p=0.663),  time:31.459, tt:660.631\n",
      "Ep:21, loss:0.00016, loss_test:0.11185, lr:9.14e-03, fs:0.60870 (r=0.566,p=0.659),  time:31.464, tt:692.215\n",
      "Ep:22, loss:0.00015, loss_test:0.11127, lr:9.04e-03, fs:0.60870 (r=0.566,p=0.659),  time:31.515, tt:724.838\n",
      "Ep:23, loss:0.00015, loss_test:0.11032, lr:8.95e-03, fs:0.61957 (r=0.576,p=0.671),  time:31.537, tt:756.886\n",
      "Ep:24, loss:0.00015, loss_test:0.10882, lr:8.86e-03, fs:0.63043 (r=0.586,p=0.682),  time:31.650, tt:791.245\n",
      "Ep:25, loss:0.00014, loss_test:0.10741, lr:8.78e-03, fs:0.64171 (r=0.606,p=0.682),  time:31.658, tt:823.109\n",
      "Ep:26, loss:0.00014, loss_test:0.10717, lr:8.69e-03, fs:0.65574 (r=0.606,p=0.714),  time:31.644, tt:854.384\n",
      "Ep:27, loss:0.00014, loss_test:0.10572, lr:8.60e-03, fs:0.69110 (r=0.667,p=0.717),  time:31.662, tt:886.535\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.10479, lr:8.60e-03, fs:0.69792 (r=0.677,p=0.720),  time:31.661, tt:918.164\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.10412, lr:8.60e-03, fs:0.70833 (r=0.687,p=0.731),  time:31.699, tt:950.976\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.10228, lr:8.60e-03, fs:0.71717 (r=0.717,p=0.717),  time:31.716, tt:983.191\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.10202, lr:8.60e-03, fs:0.71503 (r=0.697,p=0.734),  time:31.691, tt:1014.104\n",
      "Ep:32, loss:0.00012, loss_test:0.10091, lr:8.60e-03, fs:0.72165 (r=0.707,p=0.737),  time:31.704, tt:1046.227\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.10002, lr:8.60e-03, fs:0.75510 (r=0.747,p=0.763),  time:31.717, tt:1078.371\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.09928, lr:8.60e-03, fs:0.75377 (r=0.758,p=0.750),  time:31.697, tt:1109.384\n",
      "Ep:35, loss:0.00011, loss_test:0.09804, lr:8.60e-03, fs:0.75622 (r=0.768,p=0.745),  time:31.758, tt:1143.280\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.09762, lr:8.60e-03, fs:0.77000 (r=0.778,p=0.762),  time:31.738, tt:1174.318\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.09676, lr:8.60e-03, fs:0.76617 (r=0.778,p=0.755),  time:31.733, tt:1205.849\n",
      "Ep:38, loss:0.00011, loss_test:0.09645, lr:8.60e-03, fs:0.77000 (r=0.778,p=0.762),  time:31.737, tt:1237.745\n",
      "Ep:41, loss:0.00010, loss_test:0.09401, lr:8.60e-03, fs:0.78218 (r=0.798,p=0.767),  time:31.710, tt:1331.838\n",
      "Ep:42, loss:0.00010, loss_test:0.09389, lr:8.60e-03, fs:0.80628 (r=0.778,p=0.837),  time:31.710, tt:1363.551\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.09273, lr:8.60e-03, fs:0.80203 (r=0.798,p=0.806),  time:31.730, tt:1396.133\n",
      "Ep:44, loss:0.00009, loss_test:0.09241, lr:8.60e-03, fs:0.80412 (r=0.788,p=0.821),  time:31.777, tt:1429.980\n",
      "Ep:45, loss:0.00009, loss_test:0.09119, lr:8.60e-03, fs:0.81633 (r=0.808,p=0.825),  time:31.782, tt:1461.978\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.09056, lr:8.60e-03, fs:0.81053 (r=0.778,p=0.846),  time:31.777, tt:1493.513\n",
      "Ep:47, loss:0.00009, loss_test:0.08976, lr:8.60e-03, fs:0.80208 (r=0.778,p=0.828),  time:31.787, tt:1525.792\n",
      "Ep:48, loss:0.00008, loss_test:0.08969, lr:8.60e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.789, tt:1557.680\n",
      "Ep:49, loss:0.00008, loss_test:0.08861, lr:8.60e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.802, tt:1590.114\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.08749, lr:8.60e-03, fs:0.81026 (r=0.798,p=0.823),  time:31.828, tt:1623.204\n",
      "Ep:51, loss:0.00008, loss_test:0.08732, lr:8.60e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.837, tt:1655.508\n",
      "Ep:52, loss:0.00008, loss_test:0.08739, lr:8.60e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.834, tt:1687.181\n",
      "Ep:53, loss:0.00008, loss_test:0.08686, lr:8.60e-03, fs:0.82105 (r=0.788,p=0.857),  time:31.840, tt:1719.381\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.08629, lr:8.60e-03, fs:0.81633 (r=0.808,p=0.825),  time:31.865, tt:1752.565\n",
      "Ep:55, loss:0.00007, loss_test:0.08506, lr:8.60e-03, fs:0.83333 (r=0.808,p=0.860),  time:31.906, tt:1786.749\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.08408, lr:8.60e-03, fs:0.81633 (r=0.808,p=0.825),  time:31.915, tt:1819.146\n",
      "Ep:57, loss:0.00007, loss_test:0.08432, lr:8.60e-03, fs:0.83770 (r=0.808,p=0.870),  time:31.930, tt:1851.967\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.08308, lr:8.60e-03, fs:0.82587 (r=0.838,p=0.814),  time:31.915, tt:1882.992\n",
      "Ep:59, loss:0.00007, loss_test:0.08385, lr:8.60e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.915, tt:1914.910\n",
      "Ep:60, loss:0.00007, loss_test:0.08241, lr:8.60e-03, fs:0.82828 (r=0.828,p=0.828),  time:31.946, tt:1948.725\n",
      "Ep:61, loss:0.00006, loss_test:0.08255, lr:8.60e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.973, tt:1982.328\n",
      "Ep:62, loss:0.00006, loss_test:0.08123, lr:8.60e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.943, tt:2012.427\n",
      "Ep:63, loss:0.00006, loss_test:0.08309, lr:8.60e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.956, tt:2045.178\n",
      "Ep:64, loss:0.00006, loss_test:0.08030, lr:8.60e-03, fs:0.85000 (r=0.859,p=0.842),  time:31.987, tt:2079.163\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.08150, lr:8.60e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.996, tt:2111.724\n",
      "Ep:66, loss:0.00006, loss_test:0.08089, lr:8.60e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.992, tt:2143.434\n",
      "Ep:67, loss:0.00006, loss_test:0.08174, lr:8.60e-03, fs:0.84817 (r=0.818,p=0.880),  time:31.977, tt:2174.445\n",
      "Ep:68, loss:0.00006, loss_test:0.08093, lr:8.60e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.969, tt:2205.890\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00006, loss_test:0.07986, lr:8.60e-03, fs:0.87255 (r=0.899,p=0.848),  time:31.974, tt:2238.182\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.08439, lr:8.60e-03, fs:0.84324 (r=0.788,p=0.907),  time:31.984, tt:2270.874\n",
      "Ep:71, loss:0.00005, loss_test:0.07911, lr:8.60e-03, fs:0.86829 (r=0.899,p=0.840),  time:31.986, tt:2302.994\n",
      "Ep:72, loss:0.00005, loss_test:0.08288, lr:8.60e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.979, tt:2334.497\n",
      "Ep:73, loss:0.00005, loss_test:0.07964, lr:8.60e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.982, tt:2366.638\n",
      "Ep:74, loss:0.00005, loss_test:0.07998, lr:8.60e-03, fs:0.85417 (r=0.828,p=0.882),  time:31.969, tt:2397.687\n",
      "Ep:75, loss:0.00005, loss_test:0.08149, lr:8.60e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.974, tt:2430.014\n",
      "Ep:76, loss:0.00005, loss_test:0.07838, lr:8.60e-03, fs:0.86000 (r=0.869,p=0.851),  time:31.990, tt:2463.245\n",
      "Ep:77, loss:0.00005, loss_test:0.08510, lr:8.60e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.015, tt:2497.145\n",
      "Ep:78, loss:0.00005, loss_test:0.07729, lr:8.60e-03, fs:0.86139 (r=0.879,p=0.845),  time:32.013, tt:2528.993\n",
      "Ep:79, loss:0.00005, loss_test:0.08236, lr:8.60e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.994, tt:2559.528\n",
      "Ep:80, loss:0.00004, loss_test:0.07913, lr:8.60e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.992, tt:2591.359\n",
      "Ep:81, loss:0.00004, loss_test:0.07846, lr:8.51e-03, fs:0.87179 (r=0.859,p=0.885),  time:31.993, tt:2623.419\n",
      "Ep:82, loss:0.00004, loss_test:0.08240, lr:8.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.976, tt:2654.001\n",
      "Ep:83, loss:0.00004, loss_test:0.07718, lr:8.35e-03, fs:0.88670 (r=0.909,p=0.865),  time:31.983, tt:2686.556\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00004, loss_test:0.08403, lr:8.35e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.954, tt:2716.110\n",
      "Ep:85, loss:0.00004, loss_test:0.07697, lr:8.35e-03, fs:0.89000 (r=0.899,p=0.881),  time:31.945, tt:2747.299\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00004, loss_test:0.08036, lr:8.35e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.969, tt:2781.324\n",
      "Ep:87, loss:0.00004, loss_test:0.08144, lr:8.35e-03, fs:0.85106 (r=0.808,p=0.899),  time:31.983, tt:2814.483\n",
      "Ep:88, loss:0.00004, loss_test:0.07747, lr:8.35e-03, fs:0.91089 (r=0.929,p=0.893),  time:31.992, tt:2847.319\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.08396, lr:8.35e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.995, tt:2879.566\n",
      "Ep:90, loss:0.00004, loss_test:0.07718, lr:8.35e-03, fs:0.90196 (r=0.929,p=0.876),  time:31.981, tt:2910.289\n",
      "Ep:91, loss:0.00003, loss_test:0.08176, lr:8.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.974, tt:2941.654\n",
      "Ep:92, loss:0.00003, loss_test:0.07819, lr:8.35e-03, fs:0.90547 (r=0.919,p=0.892),  time:31.967, tt:2972.885\n",
      "Ep:93, loss:0.00003, loss_test:0.08025, lr:8.35e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.976, tt:3005.704\n",
      "Ep:94, loss:0.00003, loss_test:0.07818, lr:8.35e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.963, tt:3036.479\n",
      "Ep:95, loss:0.00003, loss_test:0.07849, lr:8.35e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.954, tt:3067.554\n",
      "Ep:96, loss:0.00003, loss_test:0.07955, lr:8.35e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.945, tt:3098.697\n",
      "Ep:97, loss:0.00003, loss_test:0.07794, lr:8.35e-03, fs:0.86911 (r=0.838,p=0.902),  time:31.931, tt:3129.260\n",
      "Ep:98, loss:0.00003, loss_test:0.07951, lr:8.35e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.919, tt:3159.984\n",
      "Ep:99, loss:0.00003, loss_test:0.07758, lr:8.35e-03, fs:0.88660 (r=0.869,p=0.905),  time:31.919, tt:3191.943\n",
      "Ep:100, loss:0.00003, loss_test:0.08002, lr:8.26e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.923, tt:3224.234\n",
      "Ep:101, loss:0.00003, loss_test:0.07819, lr:8.18e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.916, tt:3255.445\n",
      "Ep:102, loss:0.00003, loss_test:0.07945, lr:8.10e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.913, tt:3287.027\n",
      "Ep:103, loss:0.00003, loss_test:0.07873, lr:8.02e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.903, tt:3317.873\n",
      "Ep:104, loss:0.00003, loss_test:0.07972, lr:7.94e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.905, tt:3350.000\n",
      "Ep:105, loss:0.00003, loss_test:0.07675, lr:7.86e-03, fs:0.88660 (r=0.869,p=0.905),  time:31.896, tt:3380.995\n",
      "Ep:106, loss:0.00003, loss_test:0.08142, lr:7.78e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.891, tt:3412.294\n",
      "Ep:107, loss:0.00003, loss_test:0.07717, lr:7.70e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.891, tt:3444.269\n",
      "Ep:108, loss:0.00003, loss_test:0.07977, lr:7.62e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.901, tt:3477.220\n",
      "Ep:109, loss:0.00002, loss_test:0.07819, lr:7.55e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.902, tt:3509.239\n",
      "Ep:110, loss:0.00002, loss_test:0.07821, lr:7.47e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.876, tt:3538.246\n",
      "Ep:111, loss:0.00002, loss_test:0.08034, lr:7.40e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.863, tt:3568.605\n",
      "Ep:112, loss:0.00002, loss_test:0.07889, lr:7.32e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.828, tt:3596.560\n",
      "Ep:113, loss:0.00002, loss_test:0.07922, lr:7.25e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.824, tt:3627.903\n",
      "Ep:114, loss:0.00002, loss_test:0.08052, lr:7.18e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.826, tt:3660.013\n",
      "Ep:115, loss:0.00002, loss_test:0.07757, lr:7.11e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.826, tt:3691.869\n",
      "Ep:116, loss:0.00002, loss_test:0.08093, lr:7.03e-03, fs:0.82486 (r=0.737,p=0.936),  time:31.834, tt:3724.599\n",
      "Ep:117, loss:0.00002, loss_test:0.07854, lr:6.96e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.832, tt:3756.201\n",
      "Ep:118, loss:0.00002, loss_test:0.08081, lr:6.89e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.833, tt:3788.082\n",
      "Ep:119, loss:0.00002, loss_test:0.07950, lr:6.83e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.825, tt:3818.957\n",
      "Ep:120, loss:0.00002, loss_test:0.07933, lr:6.76e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.819, tt:3850.143\n",
      "Ep:121, loss:0.00002, loss_test:0.07974, lr:6.69e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.827, tt:3882.842\n",
      "Ep:122, loss:0.00002, loss_test:0.07874, lr:6.62e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.834, tt:3915.576\n",
      "Ep:123, loss:0.00002, loss_test:0.08013, lr:6.56e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.829, tt:3946.848\n",
      "Ep:124, loss:0.00002, loss_test:0.07913, lr:6.49e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.837, tt:3979.592\n",
      "Ep:125, loss:0.00002, loss_test:0.07964, lr:6.43e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.842, tt:4012.091\n",
      "Ep:126, loss:0.00002, loss_test:0.08041, lr:6.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.845, tt:4044.310\n",
      "Ep:127, loss:0.00002, loss_test:0.07875, lr:6.30e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.846, tt:4076.251\n",
      "Ep:128, loss:0.00002, loss_test:0.08026, lr:6.24e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.854, tt:4109.142\n",
      "Ep:129, loss:0.00002, loss_test:0.07850, lr:6.17e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.852, tt:4140.738\n",
      "Ep:130, loss:0.00002, loss_test:0.07916, lr:6.11e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.850, tt:4172.384\n",
      "Ep:131, loss:0.00002, loss_test:0.07911, lr:6.05e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.848, tt:4203.917\n",
      "Ep:132, loss:0.00002, loss_test:0.07883, lr:5.99e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.849, tt:4235.892\n",
      "Ep:133, loss:0.00002, loss_test:0.07873, lr:5.93e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.851, tt:4267.995\n",
      "Ep:134, loss:0.00002, loss_test:0.07946, lr:5.87e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.858, tt:4300.846\n",
      "Ep:135, loss:0.00002, loss_test:0.08073, lr:5.81e-03, fs:0.82955 (r=0.737,p=0.948),  time:31.861, tt:4333.086\n",
      "Ep:136, loss:0.00002, loss_test:0.07889, lr:5.75e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.866, tt:4365.689\n",
      "Ep:137, loss:0.00002, loss_test:0.07827, lr:5.70e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.871, tt:4398.167\n",
      "Ep:138, loss:0.00002, loss_test:0.07921, lr:5.64e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.874, tt:4430.439\n",
      "Ep:139, loss:0.00002, loss_test:0.07829, lr:5.58e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.878, tt:4462.946\n",
      "Ep:140, loss:0.00002, loss_test:0.07857, lr:5.53e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.878, tt:4494.857\n",
      "Ep:141, loss:0.00002, loss_test:0.07996, lr:5.47e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.886, tt:4527.840\n",
      "Ep:142, loss:0.00002, loss_test:0.07778, lr:5.42e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.898, tt:4561.371\n",
      "Ep:143, loss:0.00002, loss_test:0.07943, lr:5.36e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.934, tt:4598.547\n",
      "Ep:144, loss:0.00002, loss_test:0.07996, lr:5.31e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.941, tt:4631.425\n",
      "Ep:145, loss:0.00002, loss_test:0.07776, lr:5.26e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.935, tt:4662.500\n",
      "Ep:146, loss:0.00001, loss_test:0.07974, lr:5.20e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.925, tt:4692.937\n",
      "Ep:147, loss:0.00001, loss_test:0.07855, lr:5.15e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.934, tt:4726.160\n",
      "Ep:148, loss:0.00001, loss_test:0.07893, lr:5.10e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.923, tt:4756.475\n",
      "Ep:149, loss:0.00001, loss_test:0.07923, lr:5.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.916, tt:4787.414\n",
      "Ep:150, loss:0.00001, loss_test:0.07936, lr:5.00e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.909, tt:4818.309\n",
      "Ep:151, loss:0.00001, loss_test:0.07784, lr:4.95e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.915, tt:4851.115\n",
      "Ep:152, loss:0.00001, loss_test:0.07957, lr:4.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.922, tt:4884.012\n",
      "Ep:153, loss:0.00001, loss_test:0.07864, lr:4.85e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.927, tt:4916.834\n",
      "Ep:154, loss:0.00001, loss_test:0.07863, lr:4.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.923, tt:4948.117\n",
      "Ep:155, loss:0.00001, loss_test:0.07861, lr:4.75e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.939, tt:4982.500\n",
      "Ep:156, loss:0.00001, loss_test:0.07859, lr:4.71e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.942, tt:5014.926\n",
      "Ep:157, loss:0.00001, loss_test:0.07919, lr:4.66e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.927, tt:5044.412\n",
      "Ep:158, loss:0.00001, loss_test:0.07814, lr:4.61e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.933, tt:5077.410\n",
      "Ep:159, loss:0.00001, loss_test:0.07883, lr:4.57e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.927, tt:5108.389\n",
      "Ep:160, loss:0.00001, loss_test:0.07891, lr:4.52e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.911, tt:5137.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:161, loss:0.00001, loss_test:0.07982, lr:4.48e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.900, tt:5167.826\n",
      "Ep:162, loss:0.00001, loss_test:0.07847, lr:4.43e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.901, tt:5199.874\n",
      "Ep:163, loss:0.00001, loss_test:0.07896, lr:4.39e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.900, tt:5231.669\n",
      "Ep:164, loss:0.00001, loss_test:0.07852, lr:4.34e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.903, tt:5264.040\n",
      "Ep:165, loss:0.00001, loss_test:0.08002, lr:4.30e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.907, tt:5296.499\n",
      "Ep:166, loss:0.00001, loss_test:0.07923, lr:4.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.912, tt:5329.259\n",
      "Ep:167, loss:0.00001, loss_test:0.07934, lr:4.21e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.915, tt:5361.685\n",
      "Ep:168, loss:0.00001, loss_test:0.07956, lr:4.17e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.914, tt:5393.468\n",
      "Ep:169, loss:0.00001, loss_test:0.07795, lr:4.13e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.937, tt:5429.295\n",
      "Ep:170, loss:0.00001, loss_test:0.07900, lr:4.09e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.943, tt:5462.220\n",
      "Ep:171, loss:0.00001, loss_test:0.07883, lr:4.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.948, tt:5495.089\n",
      "Ep:172, loss:0.00001, loss_test:0.07833, lr:4.01e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.956, tt:5528.365\n",
      "Ep:173, loss:0.00001, loss_test:0.07882, lr:3.97e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.962, tt:5561.360\n",
      "Ep:174, loss:0.00001, loss_test:0.07822, lr:3.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.966, tt:5594.127\n",
      "Ep:175, loss:0.00001, loss_test:0.07896, lr:3.89e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.967, tt:5626.181\n",
      "Ep:176, loss:0.00001, loss_test:0.07874, lr:3.85e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.962, tt:5657.212\n",
      "Ep:177, loss:0.00001, loss_test:0.07910, lr:3.81e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.950, tt:5687.044\n",
      "Ep:178, loss:0.00001, loss_test:0.07822, lr:3.77e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.951, tt:5719.287\n",
      "Ep:179, loss:0.00001, loss_test:0.07876, lr:3.73e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.952, tt:5751.311\n",
      "Ep:180, loss:0.00001, loss_test:0.07891, lr:3.70e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.957, tt:5784.203\n",
      "Ep:181, loss:0.00001, loss_test:0.07797, lr:3.66e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.955, tt:5815.786\n",
      "Ep:182, loss:0.00001, loss_test:0.07896, lr:3.62e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.957, tt:5848.062\n",
      "Ep:183, loss:0.00001, loss_test:0.07872, lr:3.59e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.955, tt:5879.748\n",
      "Ep:184, loss:0.00001, loss_test:0.07873, lr:3.55e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.950, tt:5910.796\n",
      "Ep:185, loss:0.00001, loss_test:0.07865, lr:3.52e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.954, tt:5943.533\n",
      "Ep:186, loss:0.00001, loss_test:0.07836, lr:3.48e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.952, tt:5974.964\n",
      "Ep:187, loss:0.00001, loss_test:0.07893, lr:3.45e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.947, tt:6005.967\n",
      "Ep:188, loss:0.00001, loss_test:0.07847, lr:3.41e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.946, tt:6037.861\n",
      "Ep:189, loss:0.00001, loss_test:0.07952, lr:3.38e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.946, tt:6069.690\n",
      "Ep:190, loss:0.00001, loss_test:0.07861, lr:3.34e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.947, tt:6101.831\n",
      "Ep:191, loss:0.00001, loss_test:0.07954, lr:3.31e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.952, tt:6134.837\n",
      "Ep:192, loss:0.00001, loss_test:0.07908, lr:3.28e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.959, tt:6168.128\n",
      "Ep:193, loss:0.00001, loss_test:0.07894, lr:3.24e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.960, tt:6200.176\n",
      "Ep:194, loss:0.00001, loss_test:0.08048, lr:3.21e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.957, tt:6231.616\n",
      "Ep:195, loss:0.00001, loss_test:0.07914, lr:3.18e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.960, tt:6264.080\n",
      "Ep:196, loss:0.00001, loss_test:0.07886, lr:3.15e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.953, tt:6294.660\n",
      "Ep:197, loss:0.00001, loss_test:0.07918, lr:3.12e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.946, tt:6325.220\n",
      "Ep:198, loss:0.00001, loss_test:0.07866, lr:3.09e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.945, tt:6356.966\n",
      "Ep:199, loss:0.00001, loss_test:0.08036, lr:3.05e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.938, tt:6387.525\n",
      "Ep:200, loss:0.00001, loss_test:0.07973, lr:3.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.942, tt:6420.404\n",
      "Ep:201, loss:0.00001, loss_test:0.07942, lr:2.99e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.933, tt:6450.444\n",
      "Ep:202, loss:0.00001, loss_test:0.07945, lr:2.96e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.928, tt:6481.359\n",
      "Ep:203, loss:0.00001, loss_test:0.07882, lr:2.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.904, tt:6508.418\n",
      "Ep:204, loss:0.00001, loss_test:0.07947, lr:2.90e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.883, tt:6535.926\n",
      "Ep:205, loss:0.00001, loss_test:0.07925, lr:2.88e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.868, tt:6564.841\n",
      "Ep:206, loss:0.00001, loss_test:0.07983, lr:2.85e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.855, tt:6594.067\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02431, lr:6.00e-02, fs:0.62762 (r=0.758,p=0.536),  time:25.252, tt:25.252\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02339, lr:6.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:25.216, tt:50.431\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02500, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.319, tt:78.958\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.793, tt:107.173\n",
      "Ep:4, loss:0.00005, loss_test:0.02447, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.784, tt:138.921\n",
      "Ep:5, loss:0.00004, loss_test:0.02353, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:28.388, tt:170.331\n",
      "Ep:6, loss:0.00004, loss_test:0.02281, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:28.810, tt:201.673\n",
      "Ep:7, loss:0.00004, loss_test:0.02272, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:29.141, tt:233.125\n",
      "Ep:8, loss:0.00004, loss_test:0.02343, lr:6.00e-02, fs:0.61088 (r=0.737,p=0.521),  time:29.296, tt:263.664\n",
      "Ep:9, loss:0.00004, loss_test:0.02439, lr:6.00e-02, fs:0.58667 (r=0.667,p=0.524),  time:29.584, tt:295.838\n",
      "Ep:10, loss:0.00004, loss_test:0.02464, lr:6.00e-02, fs:0.60274 (r=0.667,p=0.550),  time:29.811, tt:327.925\n",
      "Ep:11, loss:0.00004, loss_test:0.02377, lr:6.00e-02, fs:0.60185 (r=0.657,p=0.556),  time:29.870, tt:358.439\n",
      "Ep:12, loss:0.00003, loss_test:0.02251, lr:6.00e-02, fs:0.63158 (r=0.727,p=0.558),  time:29.958, tt:389.451\n",
      "Ep:13, loss:0.00003, loss_test:0.02158, lr:6.00e-02, fs:0.65000 (r=0.788,p=0.553),  time:30.129, tt:421.810\n",
      "Ep:14, loss:0.00003, loss_test:0.02108, lr:5.94e-02, fs:0.66397 (r=0.828,p=0.554),  time:30.240, tt:453.600\n",
      "Ep:15, loss:0.00003, loss_test:0.02079, lr:5.88e-02, fs:0.67742 (r=0.848,p=0.564),  time:30.332, tt:485.307\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.02065, lr:5.88e-02, fs:0.69672 (r=0.859,p=0.586),  time:30.353, tt:516.002\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.02062, lr:5.88e-02, fs:0.71130 (r=0.859,p=0.607),  time:30.422, tt:547.603\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.02064, lr:5.88e-02, fs:0.68142 (r=0.778,p=0.606),  time:30.495, tt:579.408\n",
      "Ep:19, loss:0.00003, loss_test:0.02051, lr:5.88e-02, fs:0.67568 (r=0.758,p=0.610),  time:30.532, tt:610.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00003, loss_test:0.02017, lr:5.88e-02, fs:0.67873 (r=0.758,p=0.615),  time:30.558, tt:641.727\n",
      "Ep:21, loss:0.00003, loss_test:0.01975, lr:5.88e-02, fs:0.69369 (r=0.778,p=0.626),  time:30.551, tt:672.112\n",
      "Ep:22, loss:0.00003, loss_test:0.01938, lr:5.88e-02, fs:0.73362 (r=0.848,p=0.646),  time:30.571, tt:703.144\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01907, lr:5.88e-02, fs:0.74459 (r=0.869,p=0.652),  time:30.634, tt:735.212\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01888, lr:5.88e-02, fs:0.74783 (r=0.869,p=0.656),  time:30.599, tt:764.972\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01878, lr:5.88e-02, fs:0.75109 (r=0.869,p=0.662),  time:30.530, tt:793.782\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01871, lr:5.88e-02, fs:0.75439 (r=0.869,p=0.667),  time:30.528, tt:824.244\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01860, lr:5.88e-02, fs:0.75439 (r=0.869,p=0.667),  time:30.567, tt:855.877\n",
      "Ep:28, loss:0.00003, loss_test:0.01844, lr:5.88e-02, fs:0.75771 (r=0.869,p=0.672),  time:30.593, tt:887.185\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01824, lr:5.88e-02, fs:0.75439 (r=0.869,p=0.667),  time:30.598, tt:917.955\n",
      "Ep:30, loss:0.00002, loss_test:0.01805, lr:5.88e-02, fs:0.75109 (r=0.869,p=0.662),  time:30.627, tt:949.439\n",
      "Ep:31, loss:0.00002, loss_test:0.01791, lr:5.88e-02, fs:0.75109 (r=0.869,p=0.662),  time:30.637, tt:980.394\n",
      "Ep:32, loss:0.00002, loss_test:0.01782, lr:5.88e-02, fs:0.75771 (r=0.869,p=0.672),  time:30.646, tt:1011.320\n",
      "Ep:33, loss:0.00002, loss_test:0.01776, lr:5.88e-02, fs:0.75556 (r=0.859,p=0.675),  time:30.653, tt:1042.204\n",
      "Ep:34, loss:0.00002, loss_test:0.01770, lr:5.88e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.617, tt:1071.600\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01762, lr:5.88e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.643, tt:1103.146\n",
      "Ep:36, loss:0.00002, loss_test:0.01754, lr:5.88e-02, fs:0.75000 (r=0.848,p=0.672),  time:30.632, tt:1133.380\n",
      "Ep:37, loss:0.00002, loss_test:0.01744, lr:5.88e-02, fs:0.75336 (r=0.848,p=0.677),  time:30.638, tt:1164.255\n",
      "Ep:38, loss:0.00002, loss_test:0.01732, lr:5.88e-02, fs:0.75113 (r=0.838,p=0.680),  time:30.643, tt:1195.074\n",
      "Ep:39, loss:0.00002, loss_test:0.01721, lr:5.88e-02, fs:0.75229 (r=0.828,p=0.689),  time:30.635, tt:1225.400\n",
      "Ep:40, loss:0.00002, loss_test:0.01716, lr:5.88e-02, fs:0.74654 (r=0.818,p=0.686),  time:30.652, tt:1256.735\n",
      "Ep:41, loss:0.00002, loss_test:0.01711, lr:5.88e-02, fs:0.72897 (r=0.788,p=0.678),  time:30.684, tt:1288.746\n",
      "Ep:42, loss:0.00002, loss_test:0.01707, lr:5.88e-02, fs:0.71698 (r=0.768,p=0.673),  time:30.678, tt:1319.161\n",
      "Ep:43, loss:0.00002, loss_test:0.01702, lr:5.88e-02, fs:0.71090 (r=0.758,p=0.670),  time:30.695, tt:1350.580\n",
      "Ep:44, loss:0.00002, loss_test:0.01698, lr:5.88e-02, fs:0.71090 (r=0.758,p=0.670),  time:30.716, tt:1382.203\n",
      "Ep:45, loss:0.00002, loss_test:0.01701, lr:5.88e-02, fs:0.71090 (r=0.758,p=0.670),  time:30.713, tt:1412.809\n",
      "Ep:46, loss:0.00002, loss_test:0.01699, lr:5.82e-02, fs:0.71090 (r=0.758,p=0.670),  time:30.752, tt:1445.365\n",
      "Ep:47, loss:0.00002, loss_test:0.01700, lr:5.76e-02, fs:0.71090 (r=0.758,p=0.670),  time:30.774, tt:1477.175\n",
      "Ep:48, loss:0.00002, loss_test:0.01692, lr:5.71e-02, fs:0.71429 (r=0.758,p=0.676),  time:30.778, tt:1508.118\n",
      "Ep:49, loss:0.00002, loss_test:0.01688, lr:5.65e-02, fs:0.71429 (r=0.758,p=0.676),  time:30.758, tt:1537.883\n",
      "Ep:50, loss:0.00002, loss_test:0.01693, lr:5.59e-02, fs:0.71770 (r=0.758,p=0.682),  time:30.751, tt:1568.314\n",
      "Ep:51, loss:0.00002, loss_test:0.01693, lr:5.54e-02, fs:0.71770 (r=0.758,p=0.682),  time:30.734, tt:1598.169\n",
      "Ep:52, loss:0.00002, loss_test:0.01687, lr:5.48e-02, fs:0.72115 (r=0.758,p=0.688),  time:30.713, tt:1627.802\n",
      "Ep:53, loss:0.00002, loss_test:0.01680, lr:5.43e-02, fs:0.71498 (r=0.747,p=0.685),  time:30.719, tt:1658.845\n",
      "Ep:54, loss:0.00002, loss_test:0.01677, lr:5.37e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.722, tt:1689.689\n",
      "Ep:55, loss:0.00002, loss_test:0.01681, lr:5.32e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.724, tt:1720.520\n",
      "Ep:56, loss:0.00002, loss_test:0.01686, lr:5.27e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.735, tt:1751.887\n",
      "Ep:57, loss:0.00002, loss_test:0.01678, lr:5.21e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.722, tt:1781.897\n",
      "Ep:58, loss:0.00002, loss_test:0.01671, lr:5.16e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.729, tt:1813.016\n",
      "Ep:59, loss:0.00002, loss_test:0.01673, lr:5.11e-02, fs:0.70244 (r=0.727,p=0.679),  time:30.721, tt:1843.256\n",
      "Ep:60, loss:0.00002, loss_test:0.01677, lr:5.06e-02, fs:0.70244 (r=0.727,p=0.679),  time:30.716, tt:1873.650\n",
      "Ep:61, loss:0.00002, loss_test:0.01676, lr:5.01e-02, fs:0.70588 (r=0.727,p=0.686),  time:30.725, tt:1904.978\n",
      "Ep:62, loss:0.00002, loss_test:0.01673, lr:4.96e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.729, tt:1935.909\n",
      "Ep:63, loss:0.00002, loss_test:0.01674, lr:4.91e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.731, tt:1966.783\n",
      "Ep:64, loss:0.00002, loss_test:0.01671, lr:4.86e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.731, tt:1997.530\n",
      "Ep:65, loss:0.00002, loss_test:0.01672, lr:4.81e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.718, tt:2027.391\n",
      "Ep:66, loss:0.00002, loss_test:0.01673, lr:4.76e-02, fs:0.70588 (r=0.727,p=0.686),  time:30.707, tt:2057.358\n",
      "Ep:67, loss:0.00002, loss_test:0.01673, lr:4.71e-02, fs:0.70588 (r=0.727,p=0.686),  time:30.707, tt:2088.085\n",
      "Ep:68, loss:0.00002, loss_test:0.01676, lr:4.67e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.724, tt:2119.930\n",
      "Ep:69, loss:0.00001, loss_test:0.01674, lr:4.62e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.729, tt:2151.053\n",
      "Ep:70, loss:0.00001, loss_test:0.01673, lr:4.57e-02, fs:0.69951 (r=0.717,p=0.683),  time:30.730, tt:2181.824\n",
      "Ep:71, loss:0.00001, loss_test:0.01680, lr:4.53e-02, fs:0.70297 (r=0.717,p=0.689),  time:30.735, tt:2212.903\n",
      "Ep:72, loss:0.00001, loss_test:0.01680, lr:4.48e-02, fs:0.70936 (r=0.727,p=0.692),  time:30.738, tt:2243.846\n",
      "Ep:73, loss:0.00001, loss_test:0.01680, lr:4.44e-02, fs:0.70936 (r=0.727,p=0.692),  time:30.748, tt:2275.329\n",
      "Ep:74, loss:0.00001, loss_test:0.01674, lr:4.39e-02, fs:0.71569 (r=0.737,p=0.695),  time:30.768, tt:2307.596\n",
      "Ep:75, loss:0.00001, loss_test:0.01675, lr:4.35e-02, fs:0.71287 (r=0.727,p=0.699),  time:30.756, tt:2337.471\n",
      "Ep:76, loss:0.00001, loss_test:0.01680, lr:4.31e-02, fs:0.71642 (r=0.727,p=0.706),  time:30.762, tt:2368.659\n",
      "Ep:77, loss:0.00001, loss_test:0.01684, lr:4.26e-02, fs:0.71642 (r=0.727,p=0.706),  time:30.764, tt:2399.555\n",
      "Ep:78, loss:0.00001, loss_test:0.01689, lr:4.22e-02, fs:0.71642 (r=0.727,p=0.706),  time:30.741, tt:2428.530\n",
      "Ep:79, loss:0.00001, loss_test:0.01687, lr:4.18e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.736, tt:2458.892\n",
      "Ep:80, loss:0.00001, loss_test:0.01687, lr:4.14e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.723, tt:2488.567\n",
      "Ep:81, loss:0.00001, loss_test:0.01689, lr:4.10e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.720, tt:2519.066\n",
      "Ep:82, loss:0.00001, loss_test:0.01688, lr:4.05e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.725, tt:2550.204\n",
      "Ep:83, loss:0.00001, loss_test:0.01689, lr:4.01e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.715, tt:2580.039\n",
      "Ep:84, loss:0.00001, loss_test:0.01693, lr:3.97e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.716, tt:2610.885\n",
      "Ep:85, loss:0.00001, loss_test:0.01694, lr:3.93e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.693, tt:2639.616\n",
      "Ep:86, loss:0.00001, loss_test:0.01702, lr:3.89e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.690, tt:2670.008\n",
      "Ep:87, loss:0.00001, loss_test:0.01700, lr:3.86e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.692, tt:2700.863\n",
      "Ep:88, loss:0.00001, loss_test:0.01702, lr:3.82e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.697, tt:2732.019\n",
      "Ep:89, loss:0.00001, loss_test:0.01704, lr:3.78e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.712, tt:2764.038\n",
      "Ep:90, loss:0.00001, loss_test:0.01711, lr:3.74e-02, fs:0.72637 (r=0.737,p=0.716),  time:30.704, tt:2794.069\n",
      "Ep:91, loss:0.00001, loss_test:0.01713, lr:3.70e-02, fs:0.72277 (r=0.737,p=0.709),  time:30.702, tt:2824.580\n",
      "Ep:92, loss:0.00001, loss_test:0.01715, lr:3.67e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.700, tt:2855.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00001, loss_test:0.01716, lr:3.63e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.681, tt:2884.005\n",
      "Ep:94, loss:0.00001, loss_test:0.01720, lr:3.59e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.662, tt:2912.904\n",
      "Ep:95, loss:0.00001, loss_test:0.01722, lr:3.56e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.657, tt:2943.026\n",
      "Ep:96, loss:0.00001, loss_test:0.01727, lr:3.52e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.659, tt:2973.889\n",
      "Ep:97, loss:0.00001, loss_test:0.01729, lr:3.49e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.647, tt:3003.370\n",
      "Ep:98, loss:0.00001, loss_test:0.01730, lr:3.45e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.639, tt:3033.290\n",
      "Ep:99, loss:0.00001, loss_test:0.01731, lr:3.42e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.640, tt:3064.049\n",
      "Ep:100, loss:0.00001, loss_test:0.01735, lr:3.38e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.639, tt:3094.512\n",
      "Ep:101, loss:0.00001, loss_test:0.01735, lr:3.35e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.650, tt:3126.307\n",
      "Ep:102, loss:0.00001, loss_test:0.01742, lr:3.32e-02, fs:0.72362 (r=0.727,p=0.720),  time:30.653, tt:3157.281\n",
      "Ep:103, loss:0.00001, loss_test:0.01747, lr:3.28e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.652, tt:3187.768\n",
      "Ep:104, loss:0.00001, loss_test:0.01751, lr:3.25e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.646, tt:3217.875\n",
      "Ep:105, loss:0.00001, loss_test:0.01748, lr:3.22e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.650, tt:3248.943\n",
      "Ep:106, loss:0.00001, loss_test:0.01746, lr:3.19e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.658, tt:3280.380\n",
      "Ep:107, loss:0.00001, loss_test:0.01745, lr:3.15e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.654, tt:3310.608\n",
      "Ep:108, loss:0.00001, loss_test:0.01752, lr:3.12e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.647, tt:3340.531\n",
      "Ep:109, loss:0.00001, loss_test:0.01758, lr:3.09e-02, fs:0.71717 (r=0.717,p=0.717),  time:30.631, tt:3369.415\n",
      "Ep:110, loss:0.00001, loss_test:0.01761, lr:3.06e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.616, tt:3398.333\n",
      "Ep:111, loss:0.00001, loss_test:0.01763, lr:3.03e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.612, tt:3428.516\n",
      "Ep:112, loss:0.00001, loss_test:0.01768, lr:3.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.612, tt:3459.207\n",
      "Ep:113, loss:0.00001, loss_test:0.01764, lr:2.97e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.621, tt:3490.769\n",
      "Ep:114, loss:0.00001, loss_test:0.01766, lr:2.94e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.607, tt:3519.852\n",
      "Ep:115, loss:0.00001, loss_test:0.01771, lr:2.91e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.619, tt:3551.838\n",
      "Ep:116, loss:0.00001, loss_test:0.01779, lr:2.88e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.624, tt:3583.014\n",
      "Ep:117, loss:0.00001, loss_test:0.01782, lr:2.85e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.625, tt:3613.753\n",
      "Ep:118, loss:0.00001, loss_test:0.01784, lr:2.82e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.630, tt:3644.983\n",
      "Ep:119, loss:0.00001, loss_test:0.01785, lr:2.80e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.628, tt:3675.311\n",
      "Ep:120, loss:0.00001, loss_test:0.01786, lr:2.77e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.631, tt:3706.379\n",
      "Ep:121, loss:0.00001, loss_test:0.01788, lr:2.74e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.638, tt:3737.844\n",
      "Ep:122, loss:0.00001, loss_test:0.01792, lr:2.71e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.631, tt:3767.583\n",
      "Ep:123, loss:0.00001, loss_test:0.01792, lr:2.69e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.635, tt:3798.730\n",
      "Ep:124, loss:0.00001, loss_test:0.01797, lr:2.66e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.627, tt:3828.413\n",
      "Ep:125, loss:0.00001, loss_test:0.01800, lr:2.63e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.616, tt:3857.595\n",
      "Ep:126, loss:0.00001, loss_test:0.01802, lr:2.61e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.602, tt:3886.490\n",
      "Ep:127, loss:0.00001, loss_test:0.01803, lr:2.58e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.602, tt:3917.098\n",
      "Ep:128, loss:0.00001, loss_test:0.01809, lr:2.55e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.609, tt:3948.556\n",
      "Ep:129, loss:0.00001, loss_test:0.01811, lr:2.53e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.606, tt:3978.768\n",
      "Ep:130, loss:0.00001, loss_test:0.01812, lr:2.50e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.618, tt:4010.975\n",
      "Ep:131, loss:0.00001, loss_test:0.01812, lr:2.48e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.623, tt:4042.211\n",
      "Ep:132, loss:0.00001, loss_test:0.01813, lr:2.45e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.632, tt:4073.991\n",
      "Ep:133, loss:0.00001, loss_test:0.01817, lr:2.43e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.633, tt:4104.769\n",
      "Ep:134, loss:0.00001, loss_test:0.01823, lr:2.40e-02, fs:0.70408 (r=0.697,p=0.711),  time:30.634, tt:4135.561\n",
      "Ep:135, loss:0.00001, loss_test:0.01826, lr:2.38e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.638, tt:4166.805\n",
      "Ep:136, loss:0.00001, loss_test:0.01825, lr:2.36e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.636, tt:4197.123\n",
      "Ep:137, loss:0.00001, loss_test:0.01827, lr:2.33e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.636, tt:4227.788\n",
      "Ep:138, loss:0.00001, loss_test:0.01830, lr:2.31e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.634, tt:4258.062\n",
      "Ep:139, loss:0.00001, loss_test:0.01834, lr:2.29e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.633, tt:4288.594\n",
      "Ep:140, loss:0.00001, loss_test:0.01832, lr:2.26e-02, fs:0.70769 (r=0.697,p=0.719),  time:30.641, tt:4320.317\n",
      "Ep:141, loss:0.00001, loss_test:0.01835, lr:2.24e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.626, tt:4348.876\n",
      "Ep:142, loss:0.00001, loss_test:0.01836, lr:2.22e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.622, tt:4378.958\n",
      "Ep:143, loss:0.00001, loss_test:0.01840, lr:2.20e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.616, tt:4408.761\n",
      "Ep:144, loss:0.00001, loss_test:0.01841, lr:2.17e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.620, tt:4439.891\n",
      "Ep:145, loss:0.00001, loss_test:0.01840, lr:2.15e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.614, tt:4469.690\n",
      "Ep:146, loss:0.00001, loss_test:0.01841, lr:2.13e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.598, tt:4497.928\n",
      "Ep:147, loss:0.00001, loss_test:0.01846, lr:2.11e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.591, tt:4527.534\n",
      "Ep:148, loss:0.00001, loss_test:0.01849, lr:2.09e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.594, tt:4558.442\n",
      "Ep:149, loss:0.00001, loss_test:0.01850, lr:2.07e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.600, tt:4589.938\n",
      "Ep:150, loss:0.00001, loss_test:0.01854, lr:2.05e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.600, tt:4620.531\n",
      "Ep:151, loss:0.00001, loss_test:0.01853, lr:2.03e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.590, tt:4649.638\n",
      "Ep:152, loss:0.00001, loss_test:0.01856, lr:2.01e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.588, tt:4680.021\n",
      "Ep:153, loss:0.00001, loss_test:0.01862, lr:1.99e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.585, tt:4710.152\n",
      "Ep:154, loss:0.00001, loss_test:0.01862, lr:1.97e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.582, tt:4740.163\n",
      "Ep:155, loss:0.00001, loss_test:0.01864, lr:1.95e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.574, tt:4769.582\n",
      "Ep:156, loss:0.00001, loss_test:0.01864, lr:1.93e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.574, tt:4800.184\n",
      "Ep:157, loss:0.00001, loss_test:0.01867, lr:1.91e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.571, tt:4830.287\n",
      "Ep:158, loss:0.00001, loss_test:0.01870, lr:1.89e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.567, tt:4860.202\n",
      "Ep:159, loss:0.00001, loss_test:0.01875, lr:1.87e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.569, tt:4891.058\n",
      "Ep:160, loss:0.00001, loss_test:0.01877, lr:1.85e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.570, tt:4921.766\n",
      "Ep:161, loss:0.00001, loss_test:0.01875, lr:1.83e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.574, tt:4952.929\n",
      "Ep:162, loss:0.00001, loss_test:0.01876, lr:1.81e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.578, tt:4984.292\n",
      "Ep:163, loss:0.00001, loss_test:0.01878, lr:1.80e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.575, tt:5014.251\n",
      "Ep:164, loss:0.00001, loss_test:0.01882, lr:1.78e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.568, tt:5043.661\n",
      "Ep:165, loss:0.00001, loss_test:0.01888, lr:1.76e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.560, tt:5072.896\n",
      "Ep:166, loss:0.00001, loss_test:0.01888, lr:1.74e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.558, tt:5103.227\n",
      "Ep:167, loss:0.00001, loss_test:0.01887, lr:1.73e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.561, tt:5134.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00001, loss_test:0.01890, lr:1.71e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.562, tt:5164.925\n",
      "Ep:169, loss:0.00001, loss_test:0.01892, lr:1.69e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.566, tt:5196.177\n",
      "Ep:170, loss:0.00001, loss_test:0.01894, lr:1.67e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.553, tt:5224.561\n",
      "Ep:171, loss:0.00001, loss_test:0.01895, lr:1.66e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.555, tt:5255.528\n",
      "Ep:172, loss:0.00001, loss_test:0.01897, lr:1.64e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.557, tt:5286.338\n",
      "Ep:173, loss:0.00001, loss_test:0.01900, lr:1.62e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.556, tt:5316.778\n",
      "Ep:174, loss:0.00001, loss_test:0.01902, lr:1.61e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.558, tt:5347.701\n",
      "Ep:175, loss:0.00001, loss_test:0.01902, lr:1.59e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.559, tt:5378.352\n",
      "Ep:176, loss:0.00001, loss_test:0.01905, lr:1.58e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.550, tt:5407.396\n",
      "Ep:177, loss:0.00001, loss_test:0.01903, lr:1.56e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.555, tt:5438.747\n",
      "Ep:178, loss:0.00001, loss_test:0.01905, lr:1.54e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.550, tt:5468.517\n",
      "Ep:179, loss:0.00001, loss_test:0.01905, lr:1.53e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.549, tt:5498.797\n",
      "Ep:180, loss:0.00001, loss_test:0.01909, lr:1.51e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.558, tt:5530.995\n",
      "Ep:181, loss:0.00001, loss_test:0.01911, lr:1.50e-02, fs:0.71134 (r=0.697,p=0.726),  time:30.559, tt:5561.661\n",
      "Ep:182, loss:0.00001, loss_test:0.01913, lr:1.48e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.563, tt:5593.005\n",
      "Ep:183, loss:0.00001, loss_test:0.01914, lr:1.47e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.562, tt:5623.421\n",
      "Ep:184, loss:0.00001, loss_test:0.01915, lr:1.45e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.565, tt:5654.536\n",
      "Ep:185, loss:0.00001, loss_test:0.01918, lr:1.44e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.564, tt:5684.869\n",
      "Ep:186, loss:0.00001, loss_test:0.01917, lr:1.43e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.557, tt:5714.120\n",
      "Ep:187, loss:0.00001, loss_test:0.01919, lr:1.41e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.554, tt:5744.232\n",
      "Ep:188, loss:0.00001, loss_test:0.01921, lr:1.40e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.555, tt:5774.808\n",
      "Ep:189, loss:0.00001, loss_test:0.01920, lr:1.38e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.560, tt:5806.367\n",
      "Ep:190, loss:0.00001, loss_test:0.01921, lr:1.37e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.566, tt:5838.106\n",
      "Ep:191, loss:0.00001, loss_test:0.01924, lr:1.36e-02, fs:0.69792 (r=0.677,p=0.720),  time:30.573, tt:5869.945\n",
      "Ep:192, loss:0.00001, loss_test:0.01926, lr:1.34e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.566, tt:5899.152\n",
      "Ep:193, loss:0.00001, loss_test:0.01926, lr:1.33e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.573, tt:5931.171\n",
      "Ep:194, loss:0.00001, loss_test:0.01925, lr:1.32e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.573, tt:5961.717\n",
      "Ep:195, loss:0.00001, loss_test:0.01927, lr:1.30e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.575, tt:5992.687\n",
      "Ep:196, loss:0.00001, loss_test:0.01932, lr:1.29e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.569, tt:6022.183\n",
      "Ep:197, loss:0.00001, loss_test:0.01933, lr:1.28e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.566, tt:6052.020\n",
      "Ep:198, loss:0.00001, loss_test:0.01931, lr:1.26e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.560, tt:6081.484\n",
      "Ep:199, loss:0.00001, loss_test:0.01932, lr:1.25e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.556, tt:6111.291\n",
      "Ep:200, loss:0.00001, loss_test:0.01935, lr:1.24e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.550, tt:6140.518\n",
      "Ep:201, loss:0.00001, loss_test:0.01935, lr:1.23e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.545, tt:6170.116\n",
      "Ep:202, loss:0.00001, loss_test:0.01935, lr:1.21e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.550, tt:6201.643\n",
      "Ep:203, loss:0.00001, loss_test:0.01935, lr:1.20e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.556, tt:6233.439\n",
      "Ep:204, loss:0.00001, loss_test:0.01935, lr:1.19e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.560, tt:6264.791\n",
      "Ep:205, loss:0.00001, loss_test:0.01938, lr:1.18e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.556, tt:6294.610\n",
      "Ep:206, loss:0.00001, loss_test:0.01941, lr:1.17e-02, fs:0.69474 (r=0.667,p=0.725),  time:30.547, tt:6323.273\n",
      "Ep:207, loss:0.00001, loss_test:0.01940, lr:1.15e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.546, tt:6353.468\n",
      "Ep:208, loss:0.00001, loss_test:0.01941, lr:1.14e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.539, tt:6382.577\n",
      "Ep:209, loss:0.00001, loss_test:0.01942, lr:1.13e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.530, tt:6411.232\n",
      "Ep:210, loss:0.00001, loss_test:0.01945, lr:1.12e-02, fs:0.69474 (r=0.667,p=0.725),  time:30.513, tt:6438.243\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14485, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.111, tt:30.111\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14409, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.748, tt:59.496\n",
      "Ep:2, loss:0.00028, loss_test:0.14273, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.479, tt:91.437\n",
      "Ep:3, loss:0.00027, loss_test:0.14046, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.032, tt:124.127\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13696, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:30.932, tt:154.658\n",
      "Ep:5, loss:0.00026, loss_test:0.13234, lr:1.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:30.794, tt:184.766\n",
      "Ep:6, loss:0.00024, loss_test:0.12914, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:30.939, tt:216.573\n",
      "Ep:7, loss:0.00023, loss_test:0.13084, lr:1.00e-02, fs:0.61468 (r=0.677,p=0.563),  time:31.120, tt:248.960\n",
      "Ep:8, loss:0.00022, loss_test:0.13252, lr:1.00e-02, fs:0.60396 (r=0.616,p=0.592),  time:31.141, tt:280.271\n",
      "Ep:9, loss:0.00022, loss_test:0.12999, lr:1.00e-02, fs:0.59813 (r=0.646,p=0.557),  time:31.231, tt:312.307\n",
      "Ep:10, loss:0.00022, loss_test:0.12803, lr:1.00e-02, fs:0.61607 (r=0.697,p=0.552),  time:31.302, tt:344.323\n",
      "Ep:11, loss:0.00021, loss_test:0.12709, lr:1.00e-02, fs:0.61818 (r=0.687,p=0.562),  time:31.260, tt:375.117\n",
      "Ep:12, loss:0.00021, loss_test:0.12668, lr:1.00e-02, fs:0.59804 (r=0.616,p=0.581),  time:31.471, tt:409.121\n",
      "Ep:13, loss:0.00020, loss_test:0.12551, lr:1.00e-02, fs:0.61616 (r=0.616,p=0.616),  time:31.536, tt:441.500\n",
      "Ep:14, loss:0.00020, loss_test:0.12282, lr:1.00e-02, fs:0.62439 (r=0.646,p=0.604),  time:31.924, tt:478.855\n",
      "Ep:15, loss:0.00019, loss_test:0.12074, lr:9.90e-03, fs:0.65072 (r=0.687,p=0.618),  time:31.893, tt:510.290\n",
      "Ep:16, loss:0.00019, loss_test:0.11960, lr:9.80e-03, fs:0.65385 (r=0.687,p=0.624),  time:31.968, tt:543.449\n",
      "Ep:17, loss:0.00018, loss_test:0.11967, lr:9.70e-03, fs:0.61224 (r=0.606,p=0.619),  time:32.010, tt:576.180\n",
      "Ep:18, loss:0.00018, loss_test:0.11790, lr:9.61e-03, fs:0.59067 (r=0.576,p=0.606),  time:32.045, tt:608.847\n",
      "Ep:19, loss:0.00018, loss_test:0.11465, lr:9.51e-03, fs:0.61224 (r=0.606,p=0.619),  time:31.980, tt:639.606\n",
      "Ep:20, loss:0.00017, loss_test:0.11254, lr:9.41e-03, fs:0.62564 (r=0.616,p=0.635),  time:31.961, tt:671.181\n",
      "Ep:21, loss:0.00017, loss_test:0.11189, lr:9.32e-03, fs:0.61780 (r=0.596,p=0.641),  time:31.968, tt:703.300\n",
      "Ep:22, loss:0.00016, loss_test:0.11129, lr:9.23e-03, fs:0.62434 (r=0.596,p=0.656),  time:32.065, tt:737.492\n",
      "Ep:23, loss:0.00016, loss_test:0.11025, lr:9.14e-03, fs:0.64948 (r=0.636,p=0.663),  time:32.150, tt:771.603\n",
      "Ep:24, loss:0.00016, loss_test:0.10912, lr:9.04e-03, fs:0.68063 (r=0.657,p=0.707),  time:32.128, tt:803.190\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.10821, lr:9.04e-03, fs:0.67358 (r=0.657,p=0.691),  time:32.139, tt:835.611\n",
      "Ep:26, loss:0.00015, loss_test:0.10756, lr:9.04e-03, fs:0.67358 (r=0.657,p=0.691),  time:32.147, tt:867.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00015, loss_test:0.10733, lr:9.04e-03, fs:0.67021 (r=0.636,p=0.708),  time:32.136, tt:899.813\n",
      "Ep:28, loss:0.00014, loss_test:0.10586, lr:9.04e-03, fs:0.69036 (r=0.687,p=0.694),  time:32.188, tt:933.451\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.10522, lr:9.04e-03, fs:0.70103 (r=0.687,p=0.716),  time:32.190, tt:965.687\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.10415, lr:9.04e-03, fs:0.70157 (r=0.677,p=0.728),  time:32.172, tt:997.340\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.10310, lr:9.04e-03, fs:0.71795 (r=0.707,p=0.729),  time:32.175, tt:1029.609\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.10222, lr:9.04e-03, fs:0.71204 (r=0.687,p=0.739),  time:32.151, tt:1060.973\n",
      "Ep:33, loss:0.00013, loss_test:0.10170, lr:9.04e-03, fs:0.73846 (r=0.727,p=0.750),  time:32.154, tt:1093.241\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.10095, lr:9.04e-03, fs:0.76847 (r=0.788,p=0.750),  time:32.147, tt:1125.161\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.10041, lr:9.04e-03, fs:0.72251 (r=0.697,p=0.750),  time:32.141, tt:1157.087\n",
      "Ep:36, loss:0.00012, loss_test:0.10052, lr:9.04e-03, fs:0.78049 (r=0.808,p=0.755),  time:32.133, tt:1188.906\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.09894, lr:9.04e-03, fs:0.76000 (r=0.768,p=0.752),  time:32.120, tt:1220.567\n",
      "Ep:38, loss:0.00012, loss_test:0.09829, lr:9.04e-03, fs:0.78641 (r=0.818,p=0.757),  time:32.155, tt:1254.046\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.09770, lr:9.04e-03, fs:0.78431 (r=0.808,p=0.762),  time:32.172, tt:1286.861\n",
      "Ep:40, loss:0.00011, loss_test:0.09722, lr:9.04e-03, fs:0.77387 (r=0.778,p=0.770),  time:32.201, tt:1320.225\n",
      "Ep:41, loss:0.00011, loss_test:0.09679, lr:9.04e-03, fs:0.80569 (r=0.859,p=0.759),  time:32.204, tt:1352.565\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.09603, lr:9.04e-03, fs:0.78392 (r=0.788,p=0.780),  time:32.217, tt:1385.350\n",
      "Ep:43, loss:0.00010, loss_test:0.09556, lr:9.04e-03, fs:0.80000 (r=0.848,p=0.757),  time:32.196, tt:1416.621\n",
      "Ep:44, loss:0.00010, loss_test:0.09503, lr:9.04e-03, fs:0.80976 (r=0.838,p=0.783),  time:32.158, tt:1447.088\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.09478, lr:9.04e-03, fs:0.82297 (r=0.869,p=0.782),  time:32.185, tt:1480.489\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.09328, lr:9.04e-03, fs:0.83412 (r=0.889,p=0.786),  time:32.190, tt:1512.936\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.09333, lr:9.04e-03, fs:0.82759 (r=0.848,p=0.808),  time:32.175, tt:1544.409\n",
      "Ep:48, loss:0.00009, loss_test:0.09339, lr:9.04e-03, fs:0.83412 (r=0.889,p=0.786),  time:32.165, tt:1576.097\n",
      "Ep:49, loss:0.00009, loss_test:0.09259, lr:9.04e-03, fs:0.82759 (r=0.848,p=0.808),  time:32.155, tt:1607.759\n",
      "Ep:50, loss:0.00009, loss_test:0.09167, lr:9.04e-03, fs:0.83412 (r=0.889,p=0.786),  time:32.159, tt:1640.119\n",
      "Ep:51, loss:0.00009, loss_test:0.09131, lr:9.04e-03, fs:0.84729 (r=0.869,p=0.827),  time:32.141, tt:1671.314\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00009, loss_test:0.09093, lr:9.04e-03, fs:0.83333 (r=0.859,p=0.810),  time:32.110, tt:1701.845\n",
      "Ep:53, loss:0.00008, loss_test:0.08962, lr:9.04e-03, fs:0.84878 (r=0.879,p=0.821),  time:32.133, tt:1735.164\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.09015, lr:9.04e-03, fs:0.85308 (r=0.909,p=0.804),  time:32.126, tt:1766.936\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.08953, lr:9.04e-03, fs:0.85024 (r=0.889,p=0.815),  time:32.118, tt:1798.588\n",
      "Ep:56, loss:0.00008, loss_test:0.08995, lr:9.04e-03, fs:0.82828 (r=0.828,p=0.828),  time:32.127, tt:1831.233\n",
      "Ep:57, loss:0.00008, loss_test:0.09065, lr:9.04e-03, fs:0.83254 (r=0.879,p=0.791),  time:32.136, tt:1863.900\n",
      "Ep:58, loss:0.00008, loss_test:0.08722, lr:9.04e-03, fs:0.85854 (r=0.889,p=0.830),  time:32.138, tt:1896.113\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00007, loss_test:0.09114, lr:9.04e-03, fs:0.83962 (r=0.899,p=0.788),  time:32.153, tt:1929.172\n",
      "Ep:60, loss:0.00007, loss_test:0.08791, lr:9.04e-03, fs:0.82828 (r=0.828,p=0.828),  time:32.152, tt:1961.258\n",
      "Ep:61, loss:0.00007, loss_test:0.08797, lr:9.04e-03, fs:0.85167 (r=0.899,p=0.809),  time:32.150, tt:1993.297\n",
      "Ep:62, loss:0.00007, loss_test:0.08867, lr:9.04e-03, fs:0.84422 (r=0.848,p=0.840),  time:32.157, tt:2025.895\n",
      "Ep:63, loss:0.00007, loss_test:0.08640, lr:9.04e-03, fs:0.84878 (r=0.879,p=0.821),  time:32.160, tt:2058.231\n",
      "Ep:64, loss:0.00007, loss_test:0.08880, lr:9.04e-03, fs:0.82759 (r=0.848,p=0.808),  time:32.154, tt:2089.990\n",
      "Ep:65, loss:0.00007, loss_test:0.08721, lr:9.04e-03, fs:0.84878 (r=0.879,p=0.821),  time:32.149, tt:2121.845\n",
      "Ep:66, loss:0.00006, loss_test:0.08674, lr:9.04e-03, fs:0.84422 (r=0.848,p=0.840),  time:32.151, tt:2154.087\n",
      "Ep:67, loss:0.00006, loss_test:0.09010, lr:9.04e-03, fs:0.82692 (r=0.869,p=0.789),  time:32.147, tt:2186.006\n",
      "Ep:68, loss:0.00006, loss_test:0.08453, lr:9.04e-03, fs:0.86139 (r=0.879,p=0.845),  time:32.143, tt:2217.897\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00006, loss_test:0.09063, lr:9.04e-03, fs:0.80198 (r=0.818,p=0.786),  time:32.162, tt:2251.335\n",
      "Ep:70, loss:0.00006, loss_test:0.08883, lr:9.04e-03, fs:0.82828 (r=0.828,p=0.828),  time:32.178, tt:2284.602\n",
      "Ep:71, loss:0.00006, loss_test:0.08493, lr:9.04e-03, fs:0.85308 (r=0.909,p=0.804),  time:32.181, tt:2317.039\n",
      "Ep:72, loss:0.00006, loss_test:0.08923, lr:9.04e-03, fs:0.83249 (r=0.828,p=0.837),  time:32.201, tt:2350.699\n",
      "Ep:73, loss:0.00006, loss_test:0.08685, lr:9.04e-03, fs:0.84058 (r=0.879,p=0.806),  time:32.214, tt:2383.851\n",
      "Ep:74, loss:0.00006, loss_test:0.08786, lr:9.04e-03, fs:0.82474 (r=0.808,p=0.842),  time:32.223, tt:2416.697\n",
      "Ep:75, loss:0.00005, loss_test:0.08913, lr:9.04e-03, fs:0.83417 (r=0.838,p=0.830),  time:32.238, tt:2450.102\n",
      "Ep:76, loss:0.00005, loss_test:0.08624, lr:9.04e-03, fs:0.83505 (r=0.818,p=0.853),  time:32.253, tt:2483.510\n",
      "Ep:77, loss:0.00005, loss_test:0.08843, lr:9.04e-03, fs:0.84422 (r=0.848,p=0.840),  time:32.266, tt:2516.761\n",
      "Ep:78, loss:0.00005, loss_test:0.08762, lr:9.04e-03, fs:0.80214 (r=0.758,p=0.852),  time:32.271, tt:2549.439\n",
      "Ep:79, loss:0.00005, loss_test:0.08531, lr:9.04e-03, fs:0.85572 (r=0.869,p=0.843),  time:32.277, tt:2582.167\n",
      "Ep:80, loss:0.00005, loss_test:0.09352, lr:8.95e-03, fs:0.77596 (r=0.717,p=0.845),  time:32.294, tt:2615.795\n",
      "Ep:81, loss:0.00005, loss_test:0.08438, lr:8.86e-03, fs:0.85859 (r=0.859,p=0.859),  time:32.295, tt:2648.186\n",
      "Ep:82, loss:0.00005, loss_test:0.08827, lr:8.78e-03, fs:0.80628 (r=0.778,p=0.837),  time:32.302, tt:2681.074\n",
      "Ep:83, loss:0.00005, loss_test:0.08852, lr:8.69e-03, fs:0.80000 (r=0.768,p=0.835),  time:32.292, tt:2712.561\n",
      "Ep:84, loss:0.00005, loss_test:0.08456, lr:8.60e-03, fs:0.86154 (r=0.848,p=0.875),  time:32.294, tt:2745.032\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.09059, lr:8.60e-03, fs:0.76404 (r=0.687,p=0.861),  time:32.304, tt:2778.177\n",
      "Ep:86, loss:0.00004, loss_test:0.08734, lr:8.60e-03, fs:0.84848 (r=0.848,p=0.848),  time:32.321, tt:2811.956\n",
      "Ep:87, loss:0.00004, loss_test:0.08695, lr:8.60e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.331, tt:2845.123\n",
      "Ep:88, loss:0.00004, loss_test:0.08881, lr:8.60e-03, fs:0.78947 (r=0.758,p=0.824),  time:32.338, tt:2878.094\n",
      "Ep:89, loss:0.00004, loss_test:0.08814, lr:8.60e-03, fs:0.78495 (r=0.737,p=0.839),  time:32.325, tt:2909.290\n",
      "Ep:90, loss:0.00004, loss_test:0.08857, lr:8.60e-03, fs:0.80435 (r=0.747,p=0.871),  time:32.327, tt:2941.718\n",
      "Ep:91, loss:0.00004, loss_test:0.08647, lr:8.60e-03, fs:0.82474 (r=0.808,p=0.842),  time:32.328, tt:2974.190\n",
      "Ep:92, loss:0.00004, loss_test:0.08720, lr:8.60e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.343, tt:3007.945\n",
      "Ep:93, loss:0.00004, loss_test:0.08694, lr:8.60e-03, fs:0.85000 (r=0.859,p=0.842),  time:32.341, tt:3040.034\n",
      "Ep:94, loss:0.00004, loss_test:0.08767, lr:8.60e-03, fs:0.78889 (r=0.717,p=0.877),  time:32.339, tt:3072.196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00004, loss_test:0.08611, lr:8.60e-03, fs:0.84264 (r=0.838,p=0.847),  time:32.358, tt:3106.356\n",
      "Ep:96, loss:0.00004, loss_test:0.09083, lr:8.51e-03, fs:0.79775 (r=0.717,p=0.899),  time:32.360, tt:3138.921\n",
      "Ep:97, loss:0.00004, loss_test:0.08681, lr:8.43e-03, fs:0.81053 (r=0.778,p=0.846),  time:32.363, tt:3171.536\n",
      "Ep:98, loss:0.00004, loss_test:0.08821, lr:8.35e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.356, tt:3203.254\n",
      "Ep:99, loss:0.00003, loss_test:0.08774, lr:8.26e-03, fs:0.80628 (r=0.778,p=0.837),  time:32.357, tt:3235.706\n",
      "Ep:100, loss:0.00003, loss_test:0.09014, lr:8.18e-03, fs:0.78161 (r=0.687,p=0.907),  time:32.363, tt:3268.701\n",
      "Ep:101, loss:0.00003, loss_test:0.08715, lr:8.10e-03, fs:0.81675 (r=0.788,p=0.848),  time:32.379, tt:3302.707\n",
      "Ep:102, loss:0.00003, loss_test:0.08953, lr:8.02e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.398, tt:3337.010\n",
      "Ep:103, loss:0.00003, loss_test:0.08985, lr:7.94e-03, fs:0.77596 (r=0.717,p=0.845),  time:32.411, tt:3370.696\n",
      "Ep:104, loss:0.00003, loss_test:0.08574, lr:7.86e-03, fs:0.78689 (r=0.727,p=0.857),  time:32.424, tt:3404.561\n",
      "Ep:105, loss:0.00003, loss_test:0.08936, lr:7.78e-03, fs:0.78453 (r=0.717,p=0.866),  time:32.420, tt:3436.544\n",
      "Ep:106, loss:0.00003, loss_test:0.08808, lr:7.70e-03, fs:0.79121 (r=0.727,p=0.867),  time:32.414, tt:3468.282\n",
      "Ep:107, loss:0.00003, loss_test:0.08859, lr:7.62e-03, fs:0.79096 (r=0.707,p=0.897),  time:32.406, tt:3499.821\n",
      "Ep:108, loss:0.00003, loss_test:0.09051, lr:7.55e-03, fs:0.78022 (r=0.717,p=0.855),  time:32.404, tt:3532.080\n",
      "Ep:109, loss:0.00003, loss_test:0.08528, lr:7.47e-03, fs:0.80226 (r=0.717,p=0.910),  time:32.406, tt:3564.709\n",
      "Ep:110, loss:0.00003, loss_test:0.09000, lr:7.40e-03, fs:0.78689 (r=0.727,p=0.857),  time:32.382, tt:3594.379\n",
      "Ep:111, loss:0.00003, loss_test:0.09055, lr:7.32e-03, fs:0.78409 (r=0.697,p=0.896),  time:32.385, tt:3627.117\n",
      "Ep:112, loss:0.00003, loss_test:0.08491, lr:7.25e-03, fs:0.80220 (r=0.737,p=0.880),  time:32.376, tt:3658.480\n",
      "Ep:113, loss:0.00003, loss_test:0.09193, lr:7.18e-03, fs:0.76404 (r=0.687,p=0.861),  time:32.357, tt:3688.672\n",
      "Ep:114, loss:0.00003, loss_test:0.08692, lr:7.11e-03, fs:0.79330 (r=0.717,p=0.887),  time:32.344, tt:3719.549\n",
      "Ep:115, loss:0.00003, loss_test:0.08878, lr:7.03e-03, fs:0.79545 (r=0.707,p=0.909),  time:32.347, tt:3752.200\n",
      "Ep:116, loss:0.00003, loss_test:0.09080, lr:6.96e-03, fs:0.76836 (r=0.687,p=0.872),  time:32.343, tt:3784.080\n",
      "Ep:117, loss:0.00003, loss_test:0.08571, lr:6.89e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.344, tt:3816.594\n",
      "Ep:118, loss:0.00003, loss_test:0.09003, lr:6.83e-03, fs:0.77966 (r=0.697,p=0.885),  time:32.343, tt:3848.858\n",
      "Ep:119, loss:0.00003, loss_test:0.08947, lr:6.76e-03, fs:0.79096 (r=0.707,p=0.897),  time:32.349, tt:3881.916\n",
      "Ep:120, loss:0.00003, loss_test:0.08835, lr:6.69e-03, fs:0.79096 (r=0.707,p=0.897),  time:32.351, tt:3914.447\n",
      "Ep:121, loss:0.00002, loss_test:0.09150, lr:6.62e-03, fs:0.77528 (r=0.697,p=0.873),  time:32.354, tt:3947.210\n",
      "Ep:122, loss:0.00002, loss_test:0.08695, lr:6.56e-03, fs:0.79330 (r=0.717,p=0.887),  time:32.344, tt:3978.274\n",
      "Ep:123, loss:0.00002, loss_test:0.09014, lr:6.49e-03, fs:0.78652 (r=0.707,p=0.886),  time:32.344, tt:4010.648\n",
      "Ep:124, loss:0.00002, loss_test:0.09109, lr:6.43e-03, fs:0.77273 (r=0.687,p=0.883),  time:32.347, tt:4043.331\n",
      "Ep:125, loss:0.00002, loss_test:0.08645, lr:6.36e-03, fs:0.78453 (r=0.717,p=0.866),  time:32.345, tt:4075.422\n",
      "Ep:126, loss:0.00002, loss_test:0.09166, lr:6.30e-03, fs:0.75145 (r=0.657,p=0.878),  time:32.343, tt:4107.565\n",
      "Ep:127, loss:0.00002, loss_test:0.08872, lr:6.24e-03, fs:0.79096 (r=0.707,p=0.897),  time:32.343, tt:4139.899\n",
      "Ep:128, loss:0.00002, loss_test:0.08679, lr:6.17e-03, fs:0.79330 (r=0.717,p=0.887),  time:32.357, tt:4174.066\n",
      "Ep:129, loss:0.00002, loss_test:0.09196, lr:6.11e-03, fs:0.77273 (r=0.687,p=0.883),  time:32.346, tt:4205.032\n",
      "Ep:130, loss:0.00002, loss_test:0.08895, lr:6.05e-03, fs:0.78857 (r=0.697,p=0.908),  time:32.345, tt:4237.243\n",
      "Ep:131, loss:0.00002, loss_test:0.08659, lr:5.99e-03, fs:0.78453 (r=0.717,p=0.866),  time:32.351, tt:4270.397\n",
      "Ep:132, loss:0.00002, loss_test:0.09264, lr:5.93e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.351, tt:4302.676\n",
      "Ep:133, loss:0.00002, loss_test:0.08930, lr:5.87e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.347, tt:4334.542\n",
      "Ep:134, loss:0.00002, loss_test:0.08850, lr:5.81e-03, fs:0.78161 (r=0.687,p=0.907),  time:32.347, tt:4366.816\n",
      "Ep:135, loss:0.00002, loss_test:0.09169, lr:5.75e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.352, tt:4399.906\n",
      "Ep:136, loss:0.00002, loss_test:0.08866, lr:5.70e-03, fs:0.76667 (r=0.697,p=0.852),  time:32.338, tt:4430.368\n",
      "Ep:137, loss:0.00002, loss_test:0.08823, lr:5.64e-03, fs:0.78857 (r=0.697,p=0.908),  time:32.340, tt:4462.944\n",
      "Ep:138, loss:0.00002, loss_test:0.09087, lr:5.58e-03, fs:0.77273 (r=0.687,p=0.883),  time:32.328, tt:4493.611\n",
      "Ep:139, loss:0.00002, loss_test:0.09058, lr:5.53e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.337, tt:4527.150\n",
      "Ep:140, loss:0.00002, loss_test:0.08712, lr:5.47e-03, fs:0.79545 (r=0.707,p=0.909),  time:32.337, tt:4559.553\n",
      "Ep:141, loss:0.00002, loss_test:0.09161, lr:5.42e-03, fs:0.75000 (r=0.636,p=0.913),  time:32.327, tt:4590.385\n",
      "Ep:142, loss:0.00002, loss_test:0.09021, lr:5.36e-03, fs:0.77714 (r=0.687,p=0.895),  time:32.324, tt:4622.388\n",
      "Ep:143, loss:0.00002, loss_test:0.08823, lr:5.31e-03, fs:0.78161 (r=0.687,p=0.907),  time:32.326, tt:4654.975\n",
      "Ep:144, loss:0.00002, loss_test:0.08862, lr:5.26e-03, fs:0.77714 (r=0.687,p=0.895),  time:32.323, tt:4686.830\n",
      "Ep:145, loss:0.00002, loss_test:0.09144, lr:5.20e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.327, tt:4719.793\n",
      "Ep:146, loss:0.00002, loss_test:0.09022, lr:5.15e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.333, tt:4752.941\n",
      "Ep:147, loss:0.00002, loss_test:0.08964, lr:5.10e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.323, tt:4783.836\n",
      "Ep:148, loss:0.00002, loss_test:0.09004, lr:5.05e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.322, tt:4816.047\n",
      "Ep:149, loss:0.00002, loss_test:0.09120, lr:5.00e-03, fs:0.75000 (r=0.636,p=0.913),  time:32.337, tt:4850.560\n",
      "Ep:150, loss:0.00002, loss_test:0.08970, lr:4.95e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.338, tt:4883.001\n",
      "Ep:151, loss:0.00002, loss_test:0.09111, lr:4.90e-03, fs:0.75294 (r=0.646,p=0.901),  time:32.343, tt:4916.168\n",
      "Ep:152, loss:0.00002, loss_test:0.08946, lr:4.85e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.341, tt:4948.198\n",
      "Ep:153, loss:0.00002, loss_test:0.09014, lr:4.80e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.339, tt:4980.200\n",
      "Ep:154, loss:0.00002, loss_test:0.09025, lr:4.75e-03, fs:0.76836 (r=0.687,p=0.872),  time:32.343, tt:5013.197\n",
      "Ep:155, loss:0.00002, loss_test:0.09206, lr:4.71e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.349, tt:5046.376\n",
      "Ep:156, loss:0.00002, loss_test:0.09005, lr:4.66e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.343, tt:5077.852\n",
      "Ep:157, loss:0.00002, loss_test:0.09093, lr:4.61e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.350, tt:5111.306\n",
      "Ep:158, loss:0.00002, loss_test:0.08963, lr:4.57e-03, fs:0.74854 (r=0.646,p=0.889),  time:32.340, tt:5142.058\n",
      "Ep:159, loss:0.00002, loss_test:0.09116, lr:4.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.335, tt:5173.617\n",
      "Ep:160, loss:0.00002, loss_test:0.09161, lr:4.48e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.332, tt:5205.459\n",
      "Ep:161, loss:0.00002, loss_test:0.09062, lr:4.43e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.328, tt:5237.181\n",
      "Ep:162, loss:0.00002, loss_test:0.09071, lr:4.39e-03, fs:0.73373 (r=0.626,p=0.886),  time:32.320, tt:5268.204\n",
      "Ep:163, loss:0.00002, loss_test:0.09050, lr:4.34e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.323, tt:5300.894\n",
      "Ep:164, loss:0.00002, loss_test:0.09122, lr:4.30e-03, fs:0.75000 (r=0.636,p=0.913),  time:32.329, tt:5334.325\n",
      "Ep:165, loss:0.00001, loss_test:0.09069, lr:4.26e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.328, tt:5366.376\n",
      "Ep:166, loss:0.00001, loss_test:0.09115, lr:4.21e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.325, tt:5398.336\n",
      "Ep:167, loss:0.00001, loss_test:0.09061, lr:4.17e-03, fs:0.75862 (r=0.667,p=0.880),  time:32.332, tt:5431.763\n",
      "Ep:168, loss:0.00001, loss_test:0.09209, lr:4.13e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.332, tt:5464.170\n",
      "Ep:169, loss:0.00001, loss_test:0.09038, lr:4.09e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.329, tt:5495.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:170, loss:0.00001, loss_test:0.09192, lr:4.05e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.331, tt:5528.641\n",
      "Ep:171, loss:0.00001, loss_test:0.09206, lr:4.01e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.331, tt:5560.987\n",
      "Ep:172, loss:0.00001, loss_test:0.09109, lr:3.97e-03, fs:0.75000 (r=0.636,p=0.913),  time:32.327, tt:5592.586\n",
      "Ep:173, loss:0.00001, loss_test:0.09145, lr:3.93e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.330, tt:5625.372\n",
      "Ep:174, loss:0.00001, loss_test:0.09214, lr:3.89e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.330, tt:5657.812\n",
      "Ep:175, loss:0.00001, loss_test:0.09135, lr:3.85e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.333, tt:5690.624\n",
      "Ep:176, loss:0.00001, loss_test:0.09136, lr:3.81e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.330, tt:5722.495\n",
      "Ep:177, loss:0.00001, loss_test:0.09289, lr:3.77e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.320, tt:5753.030\n",
      "Ep:178, loss:0.00001, loss_test:0.09312, lr:3.73e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.326, tt:5786.305\n",
      "Ep:179, loss:0.00001, loss_test:0.09143, lr:3.70e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.322, tt:5817.869\n",
      "Ep:180, loss:0.00001, loss_test:0.09106, lr:3.66e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.316, tt:5849.184\n",
      "Ep:181, loss:0.00001, loss_test:0.09254, lr:3.62e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.319, tt:5881.987\n",
      "Ep:182, loss:0.00001, loss_test:0.09333, lr:3.59e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.318, tt:5914.186\n",
      "Ep:183, loss:0.00001, loss_test:0.09106, lr:3.55e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.311, tt:5945.253\n",
      "Ep:184, loss:0.00001, loss_test:0.09122, lr:3.52e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.305, tt:5976.391\n",
      "Ep:185, loss:0.00001, loss_test:0.09193, lr:3.48e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.309, tt:6009.487\n",
      "Ep:186, loss:0.00001, loss_test:0.09262, lr:3.45e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.304, tt:6040.809\n",
      "Ep:187, loss:0.00001, loss_test:0.09228, lr:3.41e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.307, tt:6073.708\n",
      "Ep:188, loss:0.00001, loss_test:0.09271, lr:3.38e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.306, tt:6105.882\n",
      "Ep:189, loss:0.00001, loss_test:0.09353, lr:3.34e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.301, tt:6137.231\n",
      "Ep:190, loss:0.00001, loss_test:0.09155, lr:3.31e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.299, tt:6169.090\n",
      "Ep:191, loss:0.00001, loss_test:0.09330, lr:3.28e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.298, tt:6201.252\n",
      "Ep:192, loss:0.00001, loss_test:0.09301, lr:3.24e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.298, tt:6233.568\n",
      "Ep:193, loss:0.00001, loss_test:0.09298, lr:3.21e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.299, tt:6266.060\n",
      "Ep:194, loss:0.00001, loss_test:0.09404, lr:3.18e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.302, tt:6298.980\n",
      "Ep:195, loss:0.00001, loss_test:0.09253, lr:3.15e-03, fs:0.74419 (r=0.646,p=0.877),  time:32.298, tt:6330.462\n",
      "Ep:196, loss:0.00001, loss_test:0.09255, lr:3.12e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.288, tt:6360.689\n",
      "Ep:197, loss:0.00001, loss_test:0.09267, lr:3.09e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.282, tt:6391.784\n",
      "Ep:198, loss:0.00001, loss_test:0.09337, lr:3.05e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.290, tt:6425.619\n",
      "Ep:199, loss:0.00001, loss_test:0.09335, lr:3.02e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.280, tt:6455.957\n",
      "Ep:200, loss:0.00001, loss_test:0.09330, lr:2.99e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.283, tt:6488.924\n",
      "Ep:201, loss:0.00001, loss_test:0.09302, lr:2.96e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.267, tt:6517.962\n",
      "Ep:202, loss:0.00001, loss_test:0.09281, lr:2.93e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.275, tt:6551.812\n",
      "Ep:203, loss:0.00001, loss_test:0.09345, lr:2.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.275, tt:6584.147\n",
      "Ep:204, loss:0.00001, loss_test:0.09361, lr:2.88e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.280, tt:6617.410\n",
      "Ep:205, loss:0.00001, loss_test:0.09372, lr:2.85e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.269, tt:6647.393\n",
      "Ep:206, loss:0.00001, loss_test:0.09245, lr:2.82e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.280, tt:6681.879\n",
      "Ep:207, loss:0.00001, loss_test:0.09373, lr:2.79e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.273, tt:6712.769\n",
      "Ep:208, loss:0.00001, loss_test:0.09382, lr:2.76e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.256, tt:6741.596\n",
      "Ep:209, loss:0.00001, loss_test:0.09324, lr:2.73e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.243, tt:6771.051\n",
      "Ep:210, loss:0.00001, loss_test:0.09296, lr:2.71e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.220, tt:6798.322\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02466, lr:6.00e-02, fs:0.60944 (r=0.717,p=0.530),  time:27.076, tt:27.076\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02259, lr:6.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:29.624, tt:59.249\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02323, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:30.025, tt:90.075\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02308, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:29.849, tt:119.396\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:29.845, tt:149.225\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02165, lr:6.00e-02, fs:0.65660 (r=0.879,p=0.524),  time:29.806, tt:178.835\n",
      "Ep:6, loss:0.00004, loss_test:0.02170, lr:6.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:29.979, tt:209.856\n",
      "Ep:7, loss:0.00003, loss_test:0.02239, lr:6.00e-02, fs:0.61538 (r=0.727,p=0.533),  time:30.202, tt:241.614\n",
      "Ep:8, loss:0.00003, loss_test:0.02293, lr:6.00e-02, fs:0.58716 (r=0.646,p=0.538),  time:30.145, tt:271.301\n",
      "Ep:9, loss:0.00003, loss_test:0.02263, lr:6.00e-02, fs:0.60274 (r=0.667,p=0.550),  time:30.173, tt:301.728\n",
      "Ep:10, loss:0.00003, loss_test:0.02176, lr:6.00e-02, fs:0.62555 (r=0.717,p=0.555),  time:30.167, tt:331.835\n",
      "Ep:11, loss:0.00003, loss_test:0.02087, lr:6.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:30.122, tt:361.467\n",
      "Ep:12, loss:0.00003, loss_test:0.02028, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:30.204, tt:392.651\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01995, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:30.136, tt:421.909\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01975, lr:6.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:30.113, tt:451.699\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01964, lr:6.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:30.118, tt:481.881\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01965, lr:6.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:30.130, tt:512.206\n",
      "Ep:17, loss:0.00003, loss_test:0.01961, lr:6.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:30.161, tt:542.896\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01937, lr:6.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:30.161, tt:573.057\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01900, lr:6.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:30.112, tt:602.237\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01861, lr:6.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:30.109, tt:632.282\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01835, lr:6.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:30.146, tt:663.208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00003, loss_test:0.01820, lr:6.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:30.118, tt:692.712\n",
      "Ep:23, loss:0.00003, loss_test:0.01808, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:30.140, tt:723.352\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01799, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:30.168, tt:754.210\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:30.146, tt:783.803\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01769, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:30.156, tt:814.225\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01752, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:30.136, tt:843.810\n",
      "Ep:28, loss:0.00002, loss_test:0.01739, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:30.141, tt:874.084\n",
      "Ep:29, loss:0.00002, loss_test:0.01734, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:30.161, tt:904.835\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01730, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:30.132, tt:934.097\n",
      "Ep:31, loss:0.00002, loss_test:0.01723, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:30.119, tt:963.792\n",
      "Ep:32, loss:0.00002, loss_test:0.01713, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:30.124, tt:994.079\n",
      "Ep:33, loss:0.00002, loss_test:0.01703, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:30.172, tt:1025.854\n",
      "Ep:34, loss:0.00002, loss_test:0.01695, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:30.167, tt:1055.861\n",
      "Ep:35, loss:0.00002, loss_test:0.01690, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:30.153, tt:1085.524\n",
      "Ep:36, loss:0.00002, loss_test:0.01683, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:30.163, tt:1116.031\n",
      "Ep:37, loss:0.00002, loss_test:0.01678, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:30.194, tt:1147.384\n",
      "Ep:38, loss:0.00002, loss_test:0.01672, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:30.161, tt:1176.291\n",
      "Ep:39, loss:0.00002, loss_test:0.01667, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:30.198, tt:1207.907\n",
      "Ep:40, loss:0.00002, loss_test:0.01663, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:30.220, tt:1239.002\n",
      "Ep:41, loss:0.00002, loss_test:0.01661, lr:5.94e-02, fs:0.73733 (r=0.808,p=0.678),  time:30.212, tt:1268.898\n",
      "Ep:42, loss:0.00002, loss_test:0.01662, lr:5.88e-02, fs:0.73733 (r=0.808,p=0.678),  time:30.226, tt:1299.704\n",
      "Ep:43, loss:0.00002, loss_test:0.01657, lr:5.82e-02, fs:0.73733 (r=0.808,p=0.678),  time:30.209, tt:1329.208\n",
      "Ep:44, loss:0.00002, loss_test:0.01654, lr:5.76e-02, fs:0.73733 (r=0.808,p=0.678),  time:30.210, tt:1359.455\n",
      "Ep:45, loss:0.00002, loss_test:0.01655, lr:5.71e-02, fs:0.73733 (r=0.808,p=0.678),  time:30.238, tt:1390.945\n",
      "Ep:46, loss:0.00002, loss_test:0.01651, lr:5.65e-02, fs:0.74074 (r=0.808,p=0.684),  time:30.226, tt:1420.641\n",
      "Ep:47, loss:0.00002, loss_test:0.01651, lr:5.59e-02, fs:0.74074 (r=0.808,p=0.684),  time:30.218, tt:1450.456\n",
      "Ep:48, loss:0.00002, loss_test:0.01649, lr:5.54e-02, fs:0.74074 (r=0.808,p=0.684),  time:30.234, tt:1481.483\n",
      "Ep:49, loss:0.00002, loss_test:0.01647, lr:5.48e-02, fs:0.74419 (r=0.808,p=0.690),  time:30.255, tt:1512.726\n",
      "Ep:50, loss:0.00002, loss_test:0.01647, lr:5.43e-02, fs:0.74419 (r=0.808,p=0.690),  time:30.246, tt:1542.549\n",
      "Ep:51, loss:0.00002, loss_test:0.01646, lr:5.37e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.230, tt:1571.951\n",
      "Ep:52, loss:0.00002, loss_test:0.01643, lr:5.32e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.247, tt:1603.098\n",
      "Ep:53, loss:0.00002, loss_test:0.01643, lr:5.27e-02, fs:0.74419 (r=0.808,p=0.690),  time:30.241, tt:1632.998\n",
      "Ep:54, loss:0.00002, loss_test:0.01645, lr:5.21e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.205, tt:1661.257\n",
      "Ep:55, loss:0.00002, loss_test:0.01645, lr:5.16e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.167, tt:1689.362\n",
      "Ep:56, loss:0.00002, loss_test:0.01644, lr:5.11e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.163, tt:1719.288\n",
      "Ep:57, loss:0.00002, loss_test:0.01643, lr:5.06e-02, fs:0.74419 (r=0.808,p=0.690),  time:30.151, tt:1748.751\n",
      "Ep:58, loss:0.00002, loss_test:0.01648, lr:5.01e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.169, tt:1779.946\n",
      "Ep:59, loss:0.00002, loss_test:0.01645, lr:4.96e-02, fs:0.74766 (r=0.808,p=0.696),  time:30.177, tt:1810.629\n",
      "Ep:60, loss:0.00001, loss_test:0.01645, lr:4.91e-02, fs:0.74178 (r=0.798,p=0.693),  time:30.171, tt:1840.405\n",
      "Ep:61, loss:0.00001, loss_test:0.01645, lr:4.86e-02, fs:0.74528 (r=0.798,p=0.699),  time:30.184, tt:1871.427\n",
      "Ep:62, loss:0.00001, loss_test:0.01646, lr:4.81e-02, fs:0.74882 (r=0.798,p=0.705),  time:30.198, tt:1902.449\n",
      "Ep:63, loss:0.00001, loss_test:0.01646, lr:4.76e-02, fs:0.74882 (r=0.798,p=0.705),  time:30.212, tt:1933.540\n",
      "Ep:64, loss:0.00001, loss_test:0.01644, lr:4.71e-02, fs:0.74286 (r=0.788,p=0.703),  time:30.207, tt:1963.452\n",
      "Ep:65, loss:0.00001, loss_test:0.01651, lr:4.67e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.201, tt:1993.247\n",
      "Ep:66, loss:0.00001, loss_test:0.01653, lr:4.62e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.221, tt:2024.829\n",
      "Ep:67, loss:0.00001, loss_test:0.01655, lr:4.57e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.199, tt:2053.532\n",
      "Ep:68, loss:0.00001, loss_test:0.01654, lr:4.53e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.210, tt:2084.515\n",
      "Ep:69, loss:0.00001, loss_test:0.01653, lr:4.48e-02, fs:0.74641 (r=0.788,p=0.709),  time:30.219, tt:2115.339\n",
      "Ep:70, loss:0.00001, loss_test:0.01657, lr:4.44e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.201, tt:2144.289\n",
      "Ep:71, loss:0.00001, loss_test:0.01662, lr:4.39e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.196, tt:2174.136\n",
      "Ep:72, loss:0.00001, loss_test:0.01663, lr:4.35e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.201, tt:2204.708\n",
      "Ep:73, loss:0.00001, loss_test:0.01657, lr:4.31e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.207, tt:2235.344\n",
      "Ep:74, loss:0.00001, loss_test:0.01658, lr:4.26e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.189, tt:2264.155\n",
      "Ep:75, loss:0.00001, loss_test:0.01660, lr:4.22e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.194, tt:2294.742\n",
      "Ep:76, loss:0.00001, loss_test:0.01663, lr:4.18e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.192, tt:2324.794\n",
      "Ep:77, loss:0.00001, loss_test:0.01663, lr:4.14e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.210, tt:2356.401\n",
      "Ep:78, loss:0.00001, loss_test:0.01661, lr:4.10e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.220, tt:2387.356\n",
      "Ep:79, loss:0.00001, loss_test:0.01665, lr:4.05e-02, fs:0.76329 (r=0.798,p=0.731),  time:30.235, tt:2418.763\n",
      "Ep:80, loss:0.00001, loss_test:0.01667, lr:4.01e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.246, tt:2449.957\n",
      "Ep:81, loss:0.00001, loss_test:0.01669, lr:3.97e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.269, tt:2482.049\n",
      "Ep:82, loss:0.00001, loss_test:0.01670, lr:3.93e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.294, tt:2514.396\n",
      "Ep:83, loss:0.00001, loss_test:0.01673, lr:3.89e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.307, tt:2545.794\n",
      "Ep:84, loss:0.00001, loss_test:0.01676, lr:3.86e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.301, tt:2575.591\n",
      "Ep:85, loss:0.00001, loss_test:0.01679, lr:3.82e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.304, tt:2606.154\n",
      "Ep:86, loss:0.00001, loss_test:0.01678, lr:3.78e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.300, tt:2636.098\n",
      "Ep:87, loss:0.00001, loss_test:0.01677, lr:3.74e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.306, tt:2666.926\n",
      "Ep:88, loss:0.00001, loss_test:0.01677, lr:3.70e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.310, tt:2697.612\n",
      "Ep:89, loss:0.00001, loss_test:0.01677, lr:3.67e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.315, tt:2728.351\n",
      "Ep:90, loss:0.00001, loss_test:0.01681, lr:3.63e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.331, tt:2760.118\n",
      "Ep:91, loss:0.00001, loss_test:0.01683, lr:3.59e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.322, tt:2789.602\n",
      "Ep:92, loss:0.00001, loss_test:0.01685, lr:3.56e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.327, tt:2820.397\n",
      "Ep:93, loss:0.00001, loss_test:0.01685, lr:3.52e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.323, tt:2850.348\n",
      "Ep:94, loss:0.00001, loss_test:0.01687, lr:3.49e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.325, tt:2880.910\n",
      "Ep:95, loss:0.00001, loss_test:0.01691, lr:3.45e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.329, tt:2911.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00001, loss_test:0.01693, lr:3.42e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.335, tt:2942.533\n",
      "Ep:97, loss:0.00001, loss_test:0.01690, lr:3.38e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.355, tt:2974.832\n",
      "Ep:98, loss:0.00001, loss_test:0.01687, lr:3.35e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.348, tt:3004.451\n",
      "Ep:99, loss:0.00001, loss_test:0.01691, lr:3.32e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.347, tt:3034.677\n",
      "Ep:100, loss:0.00001, loss_test:0.01695, lr:3.28e-02, fs:0.75862 (r=0.778,p=0.740),  time:30.344, tt:3064.763\n",
      "Ep:101, loss:0.00001, loss_test:0.01701, lr:3.25e-02, fs:0.75862 (r=0.778,p=0.740),  time:30.339, tt:3094.555\n",
      "Ep:102, loss:0.00001, loss_test:0.01698, lr:3.22e-02, fs:0.75862 (r=0.778,p=0.740),  time:30.350, tt:3126.054\n",
      "Ep:103, loss:0.00001, loss_test:0.01702, lr:3.19e-02, fs:0.75862 (r=0.778,p=0.740),  time:30.371, tt:3158.548\n",
      "Ep:104, loss:0.00001, loss_test:0.01704, lr:3.15e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.382, tt:3190.149\n",
      "Ep:105, loss:0.00001, loss_test:0.01705, lr:3.12e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.370, tt:3219.247\n",
      "Ep:106, loss:0.00001, loss_test:0.01703, lr:3.09e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.354, tt:3247.837\n",
      "Ep:107, loss:0.00001, loss_test:0.01706, lr:3.06e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.363, tt:3279.229\n",
      "Ep:108, loss:0.00001, loss_test:0.01710, lr:3.03e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.343, tt:3307.396\n",
      "Ep:109, loss:0.00001, loss_test:0.01713, lr:3.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.335, tt:3336.880\n",
      "Ep:110, loss:0.00001, loss_test:0.01714, lr:2.97e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.339, tt:3367.588\n",
      "Ep:111, loss:0.00001, loss_test:0.01711, lr:2.94e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.343, tt:3398.450\n",
      "Ep:112, loss:0.00001, loss_test:0.01714, lr:2.91e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.351, tt:3429.620\n",
      "Ep:113, loss:0.00001, loss_test:0.01718, lr:2.88e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.370, tt:3462.223\n",
      "Ep:114, loss:0.00001, loss_test:0.01719, lr:2.85e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.354, tt:3490.662\n",
      "Ep:115, loss:0.00001, loss_test:0.01721, lr:2.82e-02, fs:0.76617 (r=0.778,p=0.755),  time:30.346, tt:3520.098\n",
      "Ep:116, loss:0.00001, loss_test:0.01724, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.350, tt:3550.892\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01726, lr:2.80e-02, fs:0.77000 (r=0.778,p=0.762),  time:30.345, tt:3580.676\n",
      "Ep:118, loss:0.00001, loss_test:0.01728, lr:2.80e-02, fs:0.77000 (r=0.778,p=0.762),  time:30.327, tt:3608.924\n",
      "Ep:119, loss:0.00001, loss_test:0.01729, lr:2.80e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.321, tt:3638.556\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.01731, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.314, tt:3668.000\n",
      "Ep:121, loss:0.00001, loss_test:0.01731, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.309, tt:3697.691\n",
      "Ep:122, loss:0.00001, loss_test:0.01733, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.322, tt:3729.563\n",
      "Ep:123, loss:0.00001, loss_test:0.01738, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.320, tt:3759.742\n",
      "Ep:124, loss:0.00001, loss_test:0.01739, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.318, tt:3789.786\n",
      "Ep:125, loss:0.00001, loss_test:0.01737, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.346, tt:3823.610\n",
      "Ep:126, loss:0.00001, loss_test:0.01740, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.333, tt:3852.231\n",
      "Ep:127, loss:0.00001, loss_test:0.01742, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.338, tt:3883.310\n",
      "Ep:128, loss:0.00001, loss_test:0.01744, lr:2.80e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.339, tt:3913.713\n",
      "Ep:129, loss:0.00001, loss_test:0.01746, lr:2.80e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.339, tt:3944.025\n",
      "Ep:130, loss:0.00001, loss_test:0.01749, lr:2.80e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.334, tt:3973.691\n",
      "Ep:131, loss:0.00001, loss_test:0.01750, lr:2.77e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.339, tt:4004.791\n",
      "Ep:132, loss:0.00001, loss_test:0.01753, lr:2.74e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.339, tt:4035.041\n",
      "Ep:133, loss:0.00001, loss_test:0.01755, lr:2.71e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.327, tt:4063.769\n",
      "Ep:134, loss:0.00001, loss_test:0.01757, lr:2.69e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.334, tt:4095.151\n",
      "Ep:135, loss:0.00001, loss_test:0.01758, lr:2.66e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.343, tt:4126.646\n",
      "Ep:136, loss:0.00001, loss_test:0.01758, lr:2.63e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.337, tt:4156.225\n",
      "Ep:137, loss:0.00001, loss_test:0.01759, lr:2.61e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.329, tt:4185.470\n",
      "Ep:138, loss:0.00001, loss_test:0.01762, lr:2.58e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.321, tt:4214.646\n",
      "Ep:139, loss:0.00001, loss_test:0.01763, lr:2.55e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.318, tt:4244.564\n",
      "Ep:140, loss:0.00001, loss_test:0.01766, lr:2.53e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.315, tt:4274.457\n",
      "Ep:141, loss:0.00001, loss_test:0.01768, lr:2.50e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.305, tt:4303.326\n",
      "Ep:142, loss:0.00001, loss_test:0.01770, lr:2.48e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.300, tt:4332.873\n",
      "Ep:143, loss:0.00001, loss_test:0.01771, lr:2.45e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.293, tt:4362.217\n",
      "Ep:144, loss:0.00001, loss_test:0.01772, lr:2.43e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.301, tt:4393.584\n",
      "Ep:145, loss:0.00001, loss_test:0.01773, lr:2.40e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.302, tt:4424.111\n",
      "Ep:146, loss:0.00001, loss_test:0.01776, lr:2.38e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.302, tt:4454.322\n",
      "Ep:147, loss:0.00001, loss_test:0.01777, lr:2.36e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.300, tt:4484.369\n",
      "Ep:148, loss:0.00001, loss_test:0.01777, lr:2.33e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.305, tt:4515.383\n",
      "Ep:149, loss:0.00001, loss_test:0.01778, lr:2.31e-02, fs:0.77157 (r=0.768,p=0.776),  time:30.307, tt:4546.026\n",
      "Ep:150, loss:0.00001, loss_test:0.01785, lr:2.29e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.306, tt:4576.254\n",
      "Ep:151, loss:0.00001, loss_test:0.01783, lr:2.26e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.306, tt:4606.462\n",
      "Ep:152, loss:0.00001, loss_test:0.01781, lr:2.24e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.316, tt:4638.329\n",
      "Ep:153, loss:0.00001, loss_test:0.01785, lr:2.22e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.309, tt:4667.531\n",
      "Ep:154, loss:0.00001, loss_test:0.01790, lr:2.20e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.306, tt:4697.402\n",
      "Ep:155, loss:0.00001, loss_test:0.01793, lr:2.17e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.310, tt:4728.352\n",
      "Ep:156, loss:0.00001, loss_test:0.01794, lr:2.15e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.304, tt:4757.682\n",
      "Ep:157, loss:0.00001, loss_test:0.01794, lr:2.13e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.298, tt:4787.078\n",
      "Ep:158, loss:0.00001, loss_test:0.01795, lr:2.11e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.296, tt:4817.082\n",
      "Ep:159, loss:0.00001, loss_test:0.01798, lr:2.09e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.287, tt:4845.920\n",
      "Ep:160, loss:0.00001, loss_test:0.01801, lr:2.07e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.284, tt:4875.783\n",
      "Ep:161, loss:0.00001, loss_test:0.01801, lr:2.05e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.285, tt:4906.211\n",
      "Ep:162, loss:0.00001, loss_test:0.01802, lr:2.03e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.289, tt:4937.114\n",
      "Ep:163, loss:0.00001, loss_test:0.01806, lr:2.01e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.293, tt:4968.033\n",
      "Ep:164, loss:0.00001, loss_test:0.01807, lr:1.99e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.295, tt:4998.743\n",
      "Ep:165, loss:0.00001, loss_test:0.01808, lr:1.97e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.288, tt:5027.765\n",
      "Ep:166, loss:0.00001, loss_test:0.01810, lr:1.95e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.287, tt:5057.935\n",
      "Ep:167, loss:0.00001, loss_test:0.01811, lr:1.93e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.291, tt:5088.971\n",
      "Ep:168, loss:0.00001, loss_test:0.01812, lr:1.91e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.304, tt:5121.443\n",
      "Ep:169, loss:0.00001, loss_test:0.01810, lr:1.89e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.302, tt:5151.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:170, loss:0.00001, loss_test:0.01813, lr:1.87e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.299, tt:5181.177\n",
      "Ep:171, loss:0.00001, loss_test:0.01815, lr:1.85e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.299, tt:5211.441\n",
      "Ep:172, loss:0.00001, loss_test:0.01815, lr:1.83e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.292, tt:5240.508\n",
      "Ep:173, loss:0.00001, loss_test:0.01815, lr:1.81e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.296, tt:5271.579\n",
      "Ep:174, loss:0.00001, loss_test:0.01820, lr:1.80e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.297, tt:5301.930\n",
      "Ep:175, loss:0.00001, loss_test:0.01820, lr:1.78e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.299, tt:5332.609\n",
      "Ep:176, loss:0.00001, loss_test:0.01820, lr:1.76e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.302, tt:5363.533\n",
      "Ep:177, loss:0.00001, loss_test:0.01823, lr:1.74e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.304, tt:5394.094\n",
      "Ep:178, loss:0.00001, loss_test:0.01825, lr:1.73e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.306, tt:5424.716\n",
      "Ep:179, loss:0.00001, loss_test:0.01826, lr:1.71e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.301, tt:5454.199\n",
      "Ep:180, loss:0.00001, loss_test:0.01824, lr:1.69e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.293, tt:5483.119\n",
      "Ep:181, loss:0.00001, loss_test:0.01826, lr:1.67e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.296, tt:5513.900\n",
      "Ep:182, loss:0.00001, loss_test:0.01828, lr:1.66e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.302, tt:5545.215\n",
      "Ep:183, loss:0.00001, loss_test:0.01829, lr:1.64e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.310, tt:5577.082\n",
      "Ep:184, loss:0.00001, loss_test:0.01833, lr:1.62e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.308, tt:5606.973\n",
      "Ep:185, loss:0.00001, loss_test:0.01833, lr:1.61e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.309, tt:5637.484\n",
      "Ep:186, loss:0.00001, loss_test:0.01831, lr:1.59e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.312, tt:5668.283\n",
      "Ep:187, loss:0.00001, loss_test:0.01833, lr:1.58e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.317, tt:5699.606\n",
      "Ep:188, loss:0.00001, loss_test:0.01835, lr:1.56e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.316, tt:5729.738\n",
      "Ep:189, loss:0.00001, loss_test:0.01836, lr:1.54e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.322, tt:5761.166\n",
      "Ep:190, loss:0.00001, loss_test:0.01839, lr:1.53e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.331, tt:5793.125\n",
      "Ep:191, loss:0.00001, loss_test:0.01839, lr:1.51e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.336, tt:5824.560\n",
      "Ep:192, loss:0.00001, loss_test:0.01838, lr:1.50e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.341, tt:5855.795\n",
      "Ep:193, loss:0.00001, loss_test:0.01841, lr:1.48e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.342, tt:5886.329\n",
      "Ep:194, loss:0.00001, loss_test:0.01844, lr:1.47e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.342, tt:5916.684\n",
      "Ep:195, loss:0.00001, loss_test:0.01846, lr:1.45e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.344, tt:5947.486\n",
      "Ep:196, loss:0.00001, loss_test:0.01847, lr:1.44e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.348, tt:5978.512\n",
      "Ep:197, loss:0.00001, loss_test:0.01848, lr:1.43e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.350, tt:6009.315\n",
      "Ep:198, loss:0.00001, loss_test:0.01849, lr:1.41e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.347, tt:6039.102\n",
      "Ep:199, loss:0.00001, loss_test:0.01848, lr:1.40e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.349, tt:6069.864\n",
      "Ep:200, loss:0.00001, loss_test:0.01849, lr:1.38e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.349, tt:6100.123\n",
      "Ep:201, loss:0.00001, loss_test:0.01850, lr:1.37e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.346, tt:6129.933\n",
      "Ep:202, loss:0.00001, loss_test:0.01854, lr:1.36e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.344, tt:6159.888\n",
      "Ep:203, loss:0.00001, loss_test:0.01854, lr:1.34e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.345, tt:6190.303\n",
      "Ep:204, loss:0.00001, loss_test:0.01853, lr:1.33e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.347, tt:6221.081\n",
      "Ep:205, loss:0.00001, loss_test:0.01854, lr:1.32e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.350, tt:6252.036\n",
      "Ep:206, loss:0.00001, loss_test:0.01855, lr:1.30e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.362, tt:6284.891\n",
      "Ep:207, loss:0.00001, loss_test:0.01856, lr:1.29e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.368, tt:6316.519\n",
      "Ep:208, loss:0.00001, loss_test:0.01859, lr:1.28e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.365, tt:6346.301\n",
      "Ep:209, loss:0.00001, loss_test:0.01861, lr:1.26e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.359, tt:6375.289\n",
      "Ep:210, loss:0.00001, loss_test:0.01860, lr:1.25e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.341, tt:6402.021\n",
      "Ep:211, loss:0.00001, loss_test:0.01861, lr:1.24e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.324, tt:6428.629\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14497, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.371, tt:29.371\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14393, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.318, tt:58.637\n",
      "Ep:2, loss:0.00027, loss_test:0.14223, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:29.891, tt:89.673\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13961, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:30.255, tt:121.019\n",
      "Ep:4, loss:0.00026, loss_test:0.13650, lr:1.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:30.389, tt:151.947\n",
      "Ep:5, loss:0.00025, loss_test:0.13568, lr:1.00e-02, fs:0.61847 (r=0.778,p=0.513),  time:30.408, tt:182.446\n",
      "Ep:9, loss:0.00021, loss_test:0.12832, lr:1.00e-02, fs:0.61611 (r=0.657,p=0.580),  time:30.626, tt:306.262\n",
      "Ep:10, loss:0.00021, loss_test:0.12774, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:30.718, tt:337.898\n",
      "Ep:11, loss:0.00020, loss_test:0.12886, lr:1.00e-02, fs:0.59596 (r=0.596,p=0.596),  time:30.738, tt:368.856\n",
      "Ep:12, loss:0.00020, loss_test:0.12774, lr:1.00e-02, fs:0.61765 (r=0.636,p=0.600),  time:30.805, tt:400.464\n",
      "Ep:13, loss:0.00019, loss_test:0.12482, lr:1.00e-02, fs:0.61836 (r=0.646,p=0.593),  time:30.769, tt:430.771\n",
      "Ep:14, loss:0.00019, loss_test:0.12282, lr:9.90e-03, fs:0.62745 (r=0.646,p=0.610),  time:30.764, tt:461.454\n",
      "Ep:15, loss:0.00018, loss_test:0.12233, lr:9.80e-03, fs:0.57447 (r=0.545,p=0.607),  time:30.707, tt:491.312\n",
      "Ep:16, loss:0.00018, loss_test:0.12065, lr:9.70e-03, fs:0.59000 (r=0.596,p=0.584),  time:30.623, tt:520.585\n",
      "Ep:17, loss:0.00017, loss_test:0.12040, lr:9.61e-03, fs:0.58883 (r=0.586,p=0.592),  time:30.607, tt:550.928\n",
      "Ep:18, loss:0.00017, loss_test:0.11948, lr:9.51e-03, fs:0.60000 (r=0.576,p=0.626),  time:30.589, tt:581.192\n",
      "Ep:19, loss:0.00016, loss_test:0.11787, lr:9.41e-03, fs:0.60513 (r=0.596,p=0.615),  time:30.611, tt:612.223\n",
      "Ep:20, loss:0.00016, loss_test:0.11780, lr:9.32e-03, fs:0.61140 (r=0.596,p=0.628),  time:30.599, tt:642.578\n",
      "Ep:21, loss:0.00016, loss_test:0.11712, lr:9.23e-03, fs:0.62176 (r=0.606,p=0.638),  time:30.593, tt:673.038\n",
      "Ep:22, loss:0.00015, loss_test:0.11525, lr:9.14e-03, fs:0.65000 (r=0.657,p=0.644),  time:30.574, tt:703.194\n",
      "Ep:23, loss:0.00015, loss_test:0.11401, lr:9.04e-03, fs:0.66327 (r=0.657,p=0.670),  time:30.578, tt:733.865\n",
      "Ep:24, loss:0.00015, loss_test:0.11235, lr:8.95e-03, fs:0.67005 (r=0.667,p=0.673),  time:30.633, tt:765.836\n",
      "Ep:25, loss:0.00014, loss_test:0.11128, lr:8.86e-03, fs:0.68657 (r=0.697,p=0.676),  time:30.631, tt:796.400\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.11035, lr:8.86e-03, fs:0.70051 (r=0.697,p=0.704),  time:30.656, tt:827.706\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.10973, lr:8.86e-03, fs:0.70647 (r=0.717,p=0.696),  time:30.703, tt:859.675\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.10917, lr:8.86e-03, fs:0.71642 (r=0.727,p=0.706),  time:30.737, tt:891.363\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.10871, lr:8.86e-03, fs:0.72165 (r=0.707,p=0.737),  time:30.728, tt:921.837\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00013, loss_test:0.10830, lr:8.86e-03, fs:0.72449 (r=0.717,p=0.732),  time:30.729, tt:952.607\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.10719, lr:8.86e-03, fs:0.73096 (r=0.727,p=0.735),  time:30.834, tt:986.694\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.10631, lr:8.86e-03, fs:0.73958 (r=0.717,p=0.763),  time:30.838, tt:1017.666\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.10588, lr:8.86e-03, fs:0.74877 (r=0.768,p=0.731),  time:30.839, tt:1048.518\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.10532, lr:8.86e-03, fs:0.72539 (r=0.707,p=0.745),  time:30.859, tt:1080.058\n",
      "Ep:35, loss:0.00012, loss_test:0.10435, lr:8.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:30.882, tt:1111.758\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.10332, lr:8.86e-03, fs:0.74611 (r=0.727,p=0.766),  time:30.892, tt:1143.009\n",
      "Ep:37, loss:0.00011, loss_test:0.10332, lr:8.86e-03, fs:0.76923 (r=0.808,p=0.734),  time:30.902, tt:1174.292\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.10263, lr:8.86e-03, fs:0.73575 (r=0.717,p=0.755),  time:30.914, tt:1205.645\n",
      "Ep:39, loss:0.00011, loss_test:0.10172, lr:8.86e-03, fs:0.76923 (r=0.808,p=0.734),  time:30.913, tt:1236.509\n",
      "Ep:40, loss:0.00011, loss_test:0.10094, lr:8.86e-03, fs:0.77387 (r=0.778,p=0.770),  time:30.908, tt:1267.213\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.10033, lr:8.86e-03, fs:0.77670 (r=0.808,p=0.748),  time:30.875, tt:1296.741\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.09966, lr:8.86e-03, fs:0.77512 (r=0.818,p=0.736),  time:30.898, tt:1328.606\n",
      "Ep:43, loss:0.00010, loss_test:0.09947, lr:8.86e-03, fs:0.77778 (r=0.778,p=0.778),  time:30.912, tt:1360.150\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.09874, lr:8.86e-03, fs:0.79245 (r=0.848,p=0.743),  time:30.928, tt:1391.779\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.09855, lr:8.86e-03, fs:0.79188 (r=0.788,p=0.796),  time:30.946, tt:1423.529\n",
      "Ep:46, loss:0.00009, loss_test:0.09848, lr:8.86e-03, fs:0.79245 (r=0.848,p=0.743),  time:30.980, tt:1456.045\n",
      "Ep:47, loss:0.00009, loss_test:0.09710, lr:8.86e-03, fs:0.80612 (r=0.798,p=0.814),  time:31.027, tt:1489.316\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.09702, lr:8.86e-03, fs:0.80769 (r=0.848,p=0.771),  time:31.060, tt:1521.963\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.09752, lr:8.86e-03, fs:0.81159 (r=0.848,p=0.778),  time:31.067, tt:1553.325\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00009, loss_test:0.09534, lr:8.86e-03, fs:0.81633 (r=0.808,p=0.825),  time:31.068, tt:1584.491\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.09559, lr:8.86e-03, fs:0.82297 (r=0.869,p=0.782),  time:31.071, tt:1615.688\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.09513, lr:8.86e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.134, tt:1650.085\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.09473, lr:8.86e-03, fs:0.83092 (r=0.869,p=0.796),  time:31.164, tt:1682.844\n",
      "Ep:54, loss:0.00008, loss_test:0.09494, lr:8.86e-03, fs:0.83417 (r=0.838,p=0.830),  time:31.165, tt:1714.078\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.09439, lr:8.86e-03, fs:0.82791 (r=0.899,p=0.767),  time:31.159, tt:1744.895\n",
      "Ep:56, loss:0.00008, loss_test:0.09642, lr:8.86e-03, fs:0.78173 (r=0.778,p=0.786),  time:31.178, tt:1777.160\n",
      "Ep:57, loss:0.00008, loss_test:0.09367, lr:8.86e-03, fs:0.82927 (r=0.859,p=0.802),  time:31.199, tt:1809.556\n",
      "Ep:58, loss:0.00008, loss_test:0.09290, lr:8.86e-03, fs:0.83333 (r=0.859,p=0.810),  time:31.209, tt:1841.327\n",
      "Ep:59, loss:0.00007, loss_test:0.09763, lr:8.86e-03, fs:0.79000 (r=0.798,p=0.782),  time:31.220, tt:1873.215\n",
      "Ep:60, loss:0.00007, loss_test:0.09307, lr:8.86e-03, fs:0.86256 (r=0.919,p=0.812),  time:31.254, tt:1906.506\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00007, loss_test:0.09389, lr:8.86e-03, fs:0.81443 (r=0.798,p=0.832),  time:31.247, tt:1937.317\n",
      "Ep:62, loss:0.00007, loss_test:0.09469, lr:8.86e-03, fs:0.83568 (r=0.899,p=0.781),  time:31.271, tt:1970.099\n",
      "Ep:63, loss:0.00007, loss_test:0.09095, lr:8.86e-03, fs:0.86000 (r=0.869,p=0.851),  time:31.287, tt:2002.365\n",
      "Ep:64, loss:0.00007, loss_test:0.09600, lr:8.86e-03, fs:0.79188 (r=0.788,p=0.796),  time:31.296, tt:2034.212\n",
      "Ep:65, loss:0.00007, loss_test:0.09140, lr:8.86e-03, fs:0.86538 (r=0.909,p=0.826),  time:31.299, tt:2065.711\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00007, loss_test:0.09584, lr:8.86e-03, fs:0.77778 (r=0.778,p=0.778),  time:31.280, tt:2095.759\n",
      "Ep:67, loss:0.00006, loss_test:0.09266, lr:8.86e-03, fs:0.82828 (r=0.828,p=0.828),  time:31.318, tt:2129.618\n",
      "Ep:68, loss:0.00006, loss_test:0.09228, lr:8.86e-03, fs:0.85714 (r=0.909,p=0.811),  time:31.319, tt:2160.990\n",
      "Ep:69, loss:0.00006, loss_test:0.09596, lr:8.86e-03, fs:0.78218 (r=0.798,p=0.767),  time:31.291, tt:2190.401\n",
      "Ep:70, loss:0.00006, loss_test:0.09137, lr:8.86e-03, fs:0.84314 (r=0.869,p=0.819),  time:31.302, tt:2222.467\n",
      "Ep:71, loss:0.00006, loss_test:0.09668, lr:8.86e-03, fs:0.76923 (r=0.758,p=0.781),  time:31.311, tt:2254.376\n",
      "Ep:72, loss:0.00006, loss_test:0.09470, lr:8.86e-03, fs:0.80000 (r=0.808,p=0.792),  time:31.330, tt:2287.124\n",
      "Ep:73, loss:0.00006, loss_test:0.09321, lr:8.86e-03, fs:0.82178 (r=0.838,p=0.806),  time:31.340, tt:2319.149\n",
      "Ep:74, loss:0.00006, loss_test:0.09478, lr:8.86e-03, fs:0.76842 (r=0.737,p=0.802),  time:31.350, tt:2351.284\n",
      "Ep:75, loss:0.00006, loss_test:0.09390, lr:8.86e-03, fs:0.82407 (r=0.899,p=0.761),  time:31.364, tt:2383.685\n",
      "Ep:76, loss:0.00006, loss_test:0.09457, lr:8.86e-03, fs:0.77660 (r=0.737,p=0.820),  time:31.370, tt:2415.493\n",
      "Ep:77, loss:0.00005, loss_test:0.09532, lr:8.78e-03, fs:0.77000 (r=0.778,p=0.762),  time:31.384, tt:2447.978\n",
      "Ep:78, loss:0.00005, loss_test:0.09564, lr:8.69e-03, fs:0.76190 (r=0.727,p=0.800),  time:31.411, tt:2481.477\n",
      "Ep:79, loss:0.00005, loss_test:0.09572, lr:8.60e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.421, tt:2513.680\n",
      "Ep:80, loss:0.00005, loss_test:0.09308, lr:8.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:31.411, tt:2544.266\n",
      "Ep:81, loss:0.00005, loss_test:0.09860, lr:8.43e-03, fs:0.74227 (r=0.727,p=0.758),  time:31.417, tt:2576.165\n",
      "Ep:82, loss:0.00005, loss_test:0.09103, lr:8.35e-03, fs:0.80628 (r=0.778,p=0.837),  time:31.426, tt:2608.391\n",
      "Ep:83, loss:0.00005, loss_test:0.09838, lr:8.26e-03, fs:0.74490 (r=0.737,p=0.753),  time:31.436, tt:2640.662\n",
      "Ep:84, loss:0.00005, loss_test:0.09022, lr:8.18e-03, fs:0.82105 (r=0.788,p=0.857),  time:31.434, tt:2671.862\n",
      "Ep:85, loss:0.00005, loss_test:0.09945, lr:8.10e-03, fs:0.74227 (r=0.727,p=0.758),  time:31.438, tt:2703.670\n",
      "Ep:86, loss:0.00005, loss_test:0.09210, lr:8.02e-03, fs:0.77838 (r=0.727,p=0.837),  time:31.456, tt:2736.629\n",
      "Ep:87, loss:0.00005, loss_test:0.09653, lr:7.94e-03, fs:0.75676 (r=0.707,p=0.814),  time:31.469, tt:2769.241\n",
      "Ep:88, loss:0.00005, loss_test:0.09627, lr:7.86e-03, fs:0.74611 (r=0.727,p=0.766),  time:31.474, tt:2801.159\n",
      "Ep:89, loss:0.00005, loss_test:0.09232, lr:7.78e-03, fs:0.76836 (r=0.687,p=0.872),  time:31.497, tt:2834.729\n",
      "Ep:90, loss:0.00005, loss_test:0.10091, lr:7.70e-03, fs:0.73367 (r=0.737,p=0.730),  time:31.516, tt:2867.988\n",
      "Ep:91, loss:0.00005, loss_test:0.08876, lr:7.62e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.512, tt:2899.127\n",
      "Ep:92, loss:0.00005, loss_test:0.10219, lr:7.55e-03, fs:0.73575 (r=0.717,p=0.755),  time:31.510, tt:2930.426\n",
      "Ep:93, loss:0.00005, loss_test:0.09098, lr:7.47e-03, fs:0.81053 (r=0.778,p=0.846),  time:31.507, tt:2961.630\n",
      "Ep:94, loss:0.00004, loss_test:0.09691, lr:7.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.517, tt:2994.096\n",
      "Ep:95, loss:0.00004, loss_test:0.09783, lr:7.32e-03, fs:0.74490 (r=0.737,p=0.753),  time:31.521, tt:3026.013\n",
      "Ep:96, loss:0.00004, loss_test:0.09087, lr:7.25e-03, fs:0.76836 (r=0.687,p=0.872),  time:31.523, tt:3057.769\n",
      "Ep:97, loss:0.00004, loss_test:0.09828, lr:7.18e-03, fs:0.74611 (r=0.727,p=0.766),  time:31.541, tt:3091.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:98, loss:0.00004, loss_test:0.09440, lr:7.11e-03, fs:0.76190 (r=0.727,p=0.800),  time:31.531, tt:3121.555\n",
      "Ep:99, loss:0.00004, loss_test:0.09419, lr:7.03e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.539, tt:3153.887\n",
      "Ep:100, loss:0.00004, loss_test:0.09758, lr:6.96e-03, fs:0.73846 (r=0.727,p=0.750),  time:31.532, tt:3184.682\n",
      "Ep:101, loss:0.00004, loss_test:0.09532, lr:6.89e-03, fs:0.75978 (r=0.687,p=0.850),  time:31.534, tt:3216.465\n",
      "Ep:102, loss:0.00004, loss_test:0.09467, lr:6.83e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.544, tt:3248.995\n",
      "Ep:103, loss:0.00004, loss_test:0.09671, lr:6.76e-03, fs:0.76190 (r=0.727,p=0.800),  time:31.539, tt:3280.050\n",
      "Ep:104, loss:0.00004, loss_test:0.09378, lr:6.69e-03, fs:0.77174 (r=0.717,p=0.835),  time:31.539, tt:3311.558\n",
      "Ep:105, loss:0.00004, loss_test:0.09754, lr:6.62e-03, fs:0.74860 (r=0.677,p=0.838),  time:31.542, tt:3343.433\n",
      "Ep:106, loss:0.00004, loss_test:0.09427, lr:6.56e-03, fs:0.76596 (r=0.727,p=0.809),  time:31.549, tt:3375.776\n",
      "Ep:107, loss:0.00004, loss_test:0.09487, lr:6.49e-03, fs:0.76923 (r=0.707,p=0.843),  time:31.554, tt:3407.799\n",
      "Ep:108, loss:0.00004, loss_test:0.09566, lr:6.43e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.555, tt:3439.507\n",
      "Ep:109, loss:0.00004, loss_test:0.09350, lr:6.36e-03, fs:0.76596 (r=0.727,p=0.809),  time:31.560, tt:3471.642\n",
      "Ep:110, loss:0.00004, loss_test:0.09599, lr:6.30e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.564, tt:3503.613\n",
      "Ep:111, loss:0.00004, loss_test:0.09384, lr:6.24e-03, fs:0.77838 (r=0.727,p=0.837),  time:31.560, tt:3534.680\n",
      "Ep:112, loss:0.00004, loss_test:0.09862, lr:6.17e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.543, tt:3564.407\n",
      "Ep:113, loss:0.00003, loss_test:0.09619, lr:6.11e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.540, tt:3595.540\n",
      "Ep:114, loss:0.00003, loss_test:0.09478, lr:6.05e-03, fs:0.76596 (r=0.727,p=0.809),  time:31.541, tt:3627.267\n",
      "Ep:115, loss:0.00003, loss_test:0.09825, lr:5.99e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.542, tt:3658.882\n",
      "Ep:116, loss:0.00003, loss_test:0.09166, lr:5.93e-03, fs:0.78261 (r=0.727,p=0.847),  time:31.549, tt:3691.244\n",
      "Ep:117, loss:0.00003, loss_test:0.09881, lr:5.87e-03, fs:0.74866 (r=0.707,p=0.795),  time:31.560, tt:3724.025\n",
      "Ep:118, loss:0.00003, loss_test:0.09404, lr:5.81e-03, fs:0.75824 (r=0.697,p=0.831),  time:31.544, tt:3753.724\n",
      "Ep:119, loss:0.00003, loss_test:0.09607, lr:5.75e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.542, tt:3785.095\n",
      "Ep:120, loss:0.00003, loss_test:0.09558, lr:5.70e-03, fs:0.77174 (r=0.717,p=0.835),  time:31.543, tt:3816.690\n",
      "Ep:121, loss:0.00003, loss_test:0.09366, lr:5.64e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.535, tt:3847.282\n",
      "Ep:122, loss:0.00003, loss_test:0.09756, lr:5.58e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.524, tt:3877.417\n",
      "Ep:123, loss:0.00003, loss_test:0.09374, lr:5.53e-03, fs:0.77174 (r=0.717,p=0.835),  time:31.521, tt:3908.592\n",
      "Ep:124, loss:0.00003, loss_test:0.09664, lr:5.47e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.535, tt:3941.887\n",
      "Ep:125, loss:0.00003, loss_test:0.09257, lr:5.42e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.533, tt:3973.162\n",
      "Ep:126, loss:0.00003, loss_test:0.09660, lr:5.36e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.518, tt:4002.761\n",
      "Ep:127, loss:0.00003, loss_test:0.09427, lr:5.31e-03, fs:0.76923 (r=0.707,p=0.843),  time:31.518, tt:4034.365\n",
      "Ep:128, loss:0.00003, loss_test:0.09495, lr:5.26e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.519, tt:4065.922\n",
      "Ep:129, loss:0.00003, loss_test:0.09653, lr:5.20e-03, fs:0.75978 (r=0.687,p=0.850),  time:31.513, tt:4096.705\n",
      "Ep:130, loss:0.00003, loss_test:0.09251, lr:5.15e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.517, tt:4128.740\n",
      "Ep:131, loss:0.00003, loss_test:0.09643, lr:5.10e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.504, tt:4158.511\n",
      "Ep:132, loss:0.00003, loss_test:0.09319, lr:5.05e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.498, tt:4189.223\n",
      "Ep:133, loss:0.00003, loss_test:0.09646, lr:5.00e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.485, tt:4218.934\n",
      "Ep:134, loss:0.00003, loss_test:0.09302, lr:4.95e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.484, tt:4250.359\n",
      "Ep:135, loss:0.00003, loss_test:0.09557, lr:4.90e-03, fs:0.75978 (r=0.687,p=0.850),  time:31.488, tt:4282.398\n",
      "Ep:136, loss:0.00003, loss_test:0.09442, lr:4.85e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.494, tt:4314.650\n",
      "Ep:137, loss:0.00003, loss_test:0.09400, lr:4.80e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.485, tt:4344.927\n",
      "Ep:138, loss:0.00003, loss_test:0.09409, lr:4.75e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.485, tt:4376.478\n",
      "Ep:139, loss:0.00003, loss_test:0.09417, lr:4.71e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.476, tt:4406.598\n",
      "Ep:140, loss:0.00003, loss_test:0.09457, lr:4.66e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.480, tt:4438.677\n",
      "Ep:141, loss:0.00003, loss_test:0.09397, lr:4.61e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.468, tt:4468.491\n",
      "Ep:142, loss:0.00003, loss_test:0.09401, lr:4.57e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.463, tt:4499.166\n",
      "Ep:143, loss:0.00003, loss_test:0.09512, lr:4.52e-03, fs:0.75978 (r=0.687,p=0.850),  time:31.458, tt:4529.893\n",
      "Ep:144, loss:0.00003, loss_test:0.09466, lr:4.48e-03, fs:0.75978 (r=0.687,p=0.850),  time:31.439, tt:4558.656\n",
      "Ep:145, loss:0.00003, loss_test:0.09483, lr:4.43e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.434, tt:4589.371\n",
      "Ep:146, loss:0.00003, loss_test:0.09368, lr:4.39e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.440, tt:4621.669\n",
      "Ep:147, loss:0.00003, loss_test:0.09390, lr:4.34e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.440, tt:4653.067\n",
      "Ep:148, loss:0.00003, loss_test:0.09612, lr:4.30e-03, fs:0.73143 (r=0.646,p=0.842),  time:31.434, tt:4683.691\n",
      "Ep:149, loss:0.00003, loss_test:0.09583, lr:4.26e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.428, tt:4714.265\n",
      "Ep:150, loss:0.00003, loss_test:0.09195, lr:4.21e-03, fs:0.76923 (r=0.707,p=0.843),  time:31.428, tt:4745.588\n",
      "Ep:151, loss:0.00003, loss_test:0.09622, lr:4.17e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.429, tt:4777.263\n",
      "Ep:152, loss:0.00002, loss_test:0.09266, lr:4.13e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.434, tt:4809.360\n",
      "Ep:153, loss:0.00002, loss_test:0.09434, lr:4.09e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.419, tt:4838.587\n",
      "Ep:154, loss:0.00002, loss_test:0.09514, lr:4.05e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.421, tt:4870.239\n",
      "Ep:155, loss:0.00002, loss_test:0.09176, lr:4.01e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.413, tt:4900.438\n",
      "Ep:156, loss:0.00002, loss_test:0.09573, lr:3.97e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.409, tt:4931.249\n",
      "Ep:157, loss:0.00002, loss_test:0.09353, lr:3.93e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.406, tt:4962.160\n",
      "Ep:158, loss:0.00002, loss_test:0.09319, lr:3.89e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.412, tt:4994.444\n",
      "Ep:159, loss:0.00002, loss_test:0.09489, lr:3.85e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.410, tt:5025.591\n",
      "Ep:160, loss:0.00002, loss_test:0.09278, lr:3.81e-03, fs:0.75978 (r=0.687,p=0.850),  time:31.400, tt:5055.434\n",
      "Ep:161, loss:0.00002, loss_test:0.09507, lr:3.77e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.401, tt:5087.000\n",
      "Ep:162, loss:0.00002, loss_test:0.09326, lr:3.73e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.401, tt:5118.355\n",
      "Ep:163, loss:0.00002, loss_test:0.09433, lr:3.70e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.403, tt:5150.049\n",
      "Ep:164, loss:0.00002, loss_test:0.09581, lr:3.66e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.403, tt:5181.516\n",
      "Ep:165, loss:0.00002, loss_test:0.09203, lr:3.62e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.404, tt:5213.068\n",
      "Ep:166, loss:0.00002, loss_test:0.09573, lr:3.59e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.405, tt:5244.664\n",
      "Ep:167, loss:0.00002, loss_test:0.09312, lr:3.55e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.412, tt:5277.294\n",
      "Ep:168, loss:0.00002, loss_test:0.09423, lr:3.52e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.399, tt:5306.380\n",
      "Ep:169, loss:0.00002, loss_test:0.09487, lr:3.48e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.384, tt:5335.356\n",
      "Ep:170, loss:0.00002, loss_test:0.09283, lr:3.45e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.387, tt:5367.262\n",
      "Ep:171, loss:0.00002, loss_test:0.09531, lr:3.41e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.392, tt:5399.340\n",
      "Ep:172, loss:0.00002, loss_test:0.09484, lr:3.38e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.387, tt:5429.892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:173, loss:0.00002, loss_test:0.09311, lr:3.34e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.379, tt:5459.940\n",
      "Ep:174, loss:0.00002, loss_test:0.09436, lr:3.31e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.381, tt:5491.751\n",
      "Ep:175, loss:0.00002, loss_test:0.09345, lr:3.28e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.377, tt:5522.422\n",
      "Ep:176, loss:0.00002, loss_test:0.09284, lr:3.24e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.378, tt:5553.821\n",
      "Ep:177, loss:0.00002, loss_test:0.09284, lr:3.21e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.376, tt:5584.900\n",
      "Ep:178, loss:0.00002, loss_test:0.09485, lr:3.18e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.374, tt:5615.864\n",
      "Ep:179, loss:0.00002, loss_test:0.09626, lr:3.15e-03, fs:0.74286 (r=0.657,p=0.855),  time:31.370, tt:5646.587\n",
      "Ep:180, loss:0.00002, loss_test:0.09237, lr:3.12e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.370, tt:5677.884\n",
      "Ep:181, loss:0.00002, loss_test:0.09513, lr:3.09e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.377, tt:5710.551\n",
      "Ep:182, loss:0.00002, loss_test:0.09518, lr:3.05e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.369, tt:5740.486\n",
      "Ep:183, loss:0.00002, loss_test:0.09321, lr:3.02e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.371, tt:5772.305\n",
      "Ep:184, loss:0.00002, loss_test:0.09421, lr:2.99e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.369, tt:5803.235\n",
      "Ep:185, loss:0.00002, loss_test:0.09379, lr:2.96e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.352, tt:5831.378\n",
      "Ep:186, loss:0.00002, loss_test:0.09331, lr:2.93e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.350, tt:5862.378\n",
      "Ep:187, loss:0.00002, loss_test:0.09444, lr:2.90e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.345, tt:5892.869\n",
      "Ep:188, loss:0.00002, loss_test:0.09368, lr:2.88e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.355, tt:5926.174\n",
      "Ep:189, loss:0.00002, loss_test:0.09412, lr:2.85e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.353, tt:5957.033\n",
      "Ep:190, loss:0.00002, loss_test:0.09473, lr:2.82e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.355, tt:5988.845\n",
      "Ep:191, loss:0.00002, loss_test:0.09357, lr:2.79e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.348, tt:6018.865\n",
      "Ep:192, loss:0.00002, loss_test:0.09432, lr:2.76e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.340, tt:6048.700\n",
      "Ep:193, loss:0.00002, loss_test:0.09485, lr:2.73e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.340, tt:6080.020\n",
      "Ep:194, loss:0.00002, loss_test:0.09236, lr:2.71e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.336, tt:6110.534\n",
      "Ep:195, loss:0.00002, loss_test:0.09573, lr:2.68e-03, fs:0.73988 (r=0.646,p=0.865),  time:31.338, tt:6142.249\n",
      "Ep:196, loss:0.00002, loss_test:0.09641, lr:2.65e-03, fs:0.73563 (r=0.646,p=0.853),  time:31.339, tt:6173.696\n",
      "Ep:197, loss:0.00002, loss_test:0.09216, lr:2.63e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.341, tt:6205.573\n",
      "Ep:198, loss:0.00002, loss_test:0.09570, lr:2.60e-03, fs:0.74713 (r=0.657,p=0.867),  time:31.342, tt:6237.101\n",
      "Ep:199, loss:0.00002, loss_test:0.09644, lr:2.57e-03, fs:0.74286 (r=0.657,p=0.855),  time:31.337, tt:6267.463\n",
      "Ep:200, loss:0.00002, loss_test:0.09279, lr:2.55e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.336, tt:6298.461\n",
      "Ep:201, loss:0.00002, loss_test:0.09446, lr:2.52e-03, fs:0.74713 (r=0.657,p=0.867),  time:31.334, tt:6329.547\n",
      "Ep:202, loss:0.00002, loss_test:0.09743, lr:2.50e-03, fs:0.73988 (r=0.646,p=0.865),  time:31.334, tt:6360.772\n",
      "Ep:203, loss:0.00002, loss_test:0.09397, lr:2.47e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.335, tt:6392.307\n",
      "Ep:204, loss:0.00002, loss_test:0.09305, lr:2.45e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.331, tt:6422.766\n",
      "Ep:205, loss:0.00002, loss_test:0.09694, lr:2.42e-03, fs:0.73988 (r=0.646,p=0.865),  time:31.329, tt:6453.758\n",
      "Ep:206, loss:0.00002, loss_test:0.09581, lr:2.40e-03, fs:0.73988 (r=0.646,p=0.865),  time:31.331, tt:6485.613\n",
      "Ep:207, loss:0.00002, loss_test:0.09355, lr:2.38e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.326, tt:6515.707\n",
      "Ep:208, loss:0.00002, loss_test:0.09373, lr:2.35e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.318, tt:6545.526\n",
      "Ep:209, loss:0.00002, loss_test:0.09515, lr:2.33e-03, fs:0.75145 (r=0.657,p=0.878),  time:31.319, tt:6577.033\n",
      "Ep:210, loss:0.00002, loss_test:0.09514, lr:2.31e-03, fs:0.75145 (r=0.657,p=0.878),  time:31.312, tt:6606.788\n",
      "Ep:211, loss:0.00002, loss_test:0.09352, lr:2.28e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.293, tt:6634.063\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02345, lr:6.00e-02, fs:0.60000 (r=0.667,p=0.545),  time:25.804, tt:25.804\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:27.331, tt:54.662\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02491, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.185, tt:84.555\n",
      "Ep:3, loss:0.00005, loss_test:0.02607, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.182, tt:112.728\n",
      "Ep:4, loss:0.00005, loss_test:0.02626, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.321, tt:141.603\n",
      "Ep:5, loss:0.00005, loss_test:0.02583, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.486, tt:170.919\n",
      "Ep:6, loss:0.00005, loss_test:0.02491, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.347, tt:198.429\n",
      "Ep:7, loss:0.00005, loss_test:0.02373, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.511, tt:228.091\n",
      "Ep:8, loss:0.00004, loss_test:0.02251, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:28.676, tt:258.087\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02141, lr:6.00e-02, fs:0.68293 (r=0.990,p=0.521),  time:28.974, tt:289.745\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:29.178, tt:320.962\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02124, lr:6.00e-02, fs:0.63866 (r=0.768,p=0.547),  time:29.126, tt:349.510\n",
      "Ep:12, loss:0.00003, loss_test:0.02234, lr:6.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:29.089, tt:378.161\n",
      "Ep:13, loss:0.00003, loss_test:0.02335, lr:6.00e-02, fs:0.64516 (r=0.707,p=0.593),  time:29.224, tt:409.140\n",
      "Ep:14, loss:0.00003, loss_test:0.02344, lr:6.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:29.338, tt:440.063\n",
      "Ep:15, loss:0.00003, loss_test:0.02252, lr:6.00e-02, fs:0.63551 (r=0.687,p=0.591),  time:29.480, tt:471.678\n",
      "Ep:16, loss:0.00003, loss_test:0.02139, lr:6.00e-02, fs:0.63014 (r=0.697,p=0.575),  time:29.611, tt:503.391\n",
      "Ep:17, loss:0.00003, loss_test:0.02051, lr:6.00e-02, fs:0.63717 (r=0.727,p=0.567),  time:29.832, tt:536.974\n",
      "Ep:18, loss:0.00003, loss_test:0.02005, lr:6.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:29.825, tt:566.681\n",
      "Ep:19, loss:0.00003, loss_test:0.01980, lr:6.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:29.830, tt:596.605\n",
      "Ep:20, loss:0.00003, loss_test:0.01969, lr:6.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:29.883, tt:627.552\n",
      "Ep:21, loss:0.00003, loss_test:0.01969, lr:6.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:29.889, tt:657.562\n",
      "Ep:22, loss:0.00003, loss_test:0.01977, lr:5.94e-02, fs:0.67544 (r=0.778,p=0.597),  time:29.953, tt:688.914\n",
      "Ep:23, loss:0.00003, loss_test:0.01986, lr:5.88e-02, fs:0.67265 (r=0.758,p=0.605),  time:30.064, tt:721.532\n",
      "Ep:24, loss:0.00003, loss_test:0.01988, lr:5.82e-02, fs:0.67873 (r=0.758,p=0.615),  time:30.087, tt:752.172\n",
      "Ep:25, loss:0.00003, loss_test:0.01978, lr:5.76e-02, fs:0.70588 (r=0.788,p=0.639),  time:30.059, tt:781.534\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01958, lr:5.76e-02, fs:0.71749 (r=0.808,p=0.645),  time:30.130, tt:813.504\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00003, loss_test:0.01934, lr:5.76e-02, fs:0.71681 (r=0.818,p=0.638),  time:30.163, tt:844.577\n",
      "Ep:28, loss:0.00002, loss_test:0.01909, lr:5.76e-02, fs:0.72489 (r=0.838,p=0.638),  time:30.161, tt:874.675\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01889, lr:5.76e-02, fs:0.73362 (r=0.848,p=0.646),  time:30.172, tt:905.155\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01875, lr:5.76e-02, fs:0.73913 (r=0.859,p=0.649),  time:30.183, tt:935.676\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01866, lr:5.76e-02, fs:0.73362 (r=0.848,p=0.646),  time:30.219, tt:967.023\n",
      "Ep:32, loss:0.00002, loss_test:0.01860, lr:5.76e-02, fs:0.73684 (r=0.848,p=0.651),  time:30.222, tt:997.341\n",
      "Ep:33, loss:0.00002, loss_test:0.01854, lr:5.76e-02, fs:0.74009 (r=0.848,p=0.656),  time:30.228, tt:1027.764\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01846, lr:5.76e-02, fs:0.74336 (r=0.848,p=0.661),  time:30.242, tt:1058.475\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01835, lr:5.76e-02, fs:0.75000 (r=0.848,p=0.672),  time:30.260, tt:1089.376\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01822, lr:5.76e-02, fs:0.75336 (r=0.848,p=0.677),  time:30.285, tt:1120.560\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01810, lr:5.76e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.288, tt:1150.940\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01799, lr:5.76e-02, fs:0.76233 (r=0.859,p=0.685),  time:30.251, tt:1179.777\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01788, lr:5.76e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.245, tt:1209.790\n",
      "Ep:40, loss:0.00002, loss_test:0.01778, lr:5.76e-02, fs:0.76786 (r=0.869,p=0.688),  time:30.201, tt:1238.245\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01770, lr:5.76e-02, fs:0.77130 (r=0.869,p=0.694),  time:30.186, tt:1267.813\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01763, lr:5.76e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.178, tt:1297.649\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01755, lr:5.76e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.169, tt:1327.446\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01748, lr:5.76e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.129, tt:1355.799\n",
      "Ep:45, loss:0.00002, loss_test:0.01743, lr:5.76e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.149, tt:1386.835\n",
      "Ep:46, loss:0.00002, loss_test:0.01738, lr:5.76e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.147, tt:1416.931\n",
      "Ep:47, loss:0.00002, loss_test:0.01734, lr:5.76e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.152, tt:1447.287\n",
      "Ep:48, loss:0.00002, loss_test:0.01728, lr:5.76e-02, fs:0.79638 (r=0.889,p=0.721),  time:30.150, tt:1477.362\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01723, lr:5.76e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.156, tt:1507.821\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01718, lr:5.76e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.167, tt:1538.541\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01713, lr:5.76e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.158, tt:1568.191\n",
      "Ep:52, loss:0.00002, loss_test:0.01708, lr:5.76e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.173, tt:1599.146\n",
      "Ep:53, loss:0.00002, loss_test:0.01703, lr:5.76e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.147, tt:1627.937\n",
      "Ep:54, loss:0.00002, loss_test:0.01699, lr:5.76e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.133, tt:1657.328\n",
      "Ep:55, loss:0.00001, loss_test:0.01696, lr:5.76e-02, fs:0.79817 (r=0.879,p=0.731),  time:30.129, tt:1687.215\n",
      "Ep:56, loss:0.00001, loss_test:0.01694, lr:5.76e-02, fs:0.80556 (r=0.879,p=0.744),  time:30.156, tt:1718.887\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01691, lr:5.76e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.150, tt:1748.688\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01685, lr:5.76e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.150, tt:1778.835\n",
      "Ep:59, loss:0.00001, loss_test:0.01682, lr:5.76e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.147, tt:1808.793\n",
      "Ep:60, loss:0.00001, loss_test:0.01677, lr:5.76e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.168, tt:1840.273\n",
      "Ep:61, loss:0.00001, loss_test:0.01673, lr:5.76e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.157, tt:1869.756\n",
      "Ep:62, loss:0.00001, loss_test:0.01669, lr:5.76e-02, fs:0.81860 (r=0.889,p=0.759),  time:30.146, tt:1899.179\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01668, lr:5.76e-02, fs:0.81308 (r=0.879,p=0.757),  time:30.146, tt:1929.335\n",
      "Ep:64, loss:0.00001, loss_test:0.01668, lr:5.76e-02, fs:0.80751 (r=0.869,p=0.754),  time:30.155, tt:1960.047\n",
      "Ep:65, loss:0.00001, loss_test:0.01666, lr:5.76e-02, fs:0.80751 (r=0.869,p=0.754),  time:30.138, tt:1989.139\n",
      "Ep:66, loss:0.00001, loss_test:0.01665, lr:5.76e-02, fs:0.81308 (r=0.879,p=0.757),  time:30.134, tt:2019.006\n",
      "Ep:67, loss:0.00001, loss_test:0.01663, lr:5.76e-02, fs:0.80189 (r=0.859,p=0.752),  time:30.126, tt:2048.591\n",
      "Ep:68, loss:0.00001, loss_test:0.01662, lr:5.76e-02, fs:0.80189 (r=0.859,p=0.752),  time:30.131, tt:2079.047\n",
      "Ep:69, loss:0.00001, loss_test:0.01660, lr:5.76e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.098, tt:2106.866\n",
      "Ep:70, loss:0.00001, loss_test:0.01658, lr:5.76e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.111, tt:2137.872\n",
      "Ep:71, loss:0.00001, loss_test:0.01658, lr:5.76e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.100, tt:2167.175\n",
      "Ep:72, loss:0.00001, loss_test:0.01657, lr:5.76e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.106, tt:2197.730\n",
      "Ep:73, loss:0.00001, loss_test:0.01654, lr:5.76e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.110, tt:2228.117\n",
      "Ep:74, loss:0.00001, loss_test:0.01650, lr:5.71e-02, fs:0.78641 (r=0.818,p=0.757),  time:30.124, tt:2259.332\n",
      "Ep:75, loss:0.00001, loss_test:0.01649, lr:5.65e-02, fs:0.78641 (r=0.818,p=0.757),  time:30.135, tt:2290.271\n",
      "Ep:76, loss:0.00001, loss_test:0.01649, lr:5.59e-02, fs:0.78049 (r=0.808,p=0.755),  time:30.127, tt:2319.765\n",
      "Ep:77, loss:0.00001, loss_test:0.01650, lr:5.54e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.132, tt:2350.325\n",
      "Ep:78, loss:0.00001, loss_test:0.01650, lr:5.48e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.124, tt:2379.819\n",
      "Ep:79, loss:0.00001, loss_test:0.01648, lr:5.43e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.134, tt:2410.689\n",
      "Ep:80, loss:0.00001, loss_test:0.01648, lr:5.37e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.148, tt:2442.028\n",
      "Ep:81, loss:0.00001, loss_test:0.01648, lr:5.32e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.155, tt:2472.683\n",
      "Ep:82, loss:0.00001, loss_test:0.01651, lr:5.27e-02, fs:0.75622 (r=0.768,p=0.745),  time:30.181, tt:2505.019\n",
      "Ep:83, loss:0.00001, loss_test:0.01652, lr:5.21e-02, fs:0.74372 (r=0.747,p=0.740),  time:30.176, tt:2534.815\n",
      "Ep:84, loss:0.00001, loss_test:0.01651, lr:5.16e-02, fs:0.74747 (r=0.747,p=0.747),  time:30.198, tt:2566.809\n",
      "Ep:85, loss:0.00001, loss_test:0.01651, lr:5.11e-02, fs:0.74747 (r=0.747,p=0.747),  time:30.175, tt:2595.092\n",
      "Ep:86, loss:0.00001, loss_test:0.01652, lr:5.06e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.183, tt:2625.939\n",
      "Ep:87, loss:0.00001, loss_test:0.01654, lr:5.01e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.202, tt:2657.811\n",
      "Ep:88, loss:0.00001, loss_test:0.01654, lr:4.96e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.218, tt:2689.442\n",
      "Ep:89, loss:0.00001, loss_test:0.01654, lr:4.91e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.219, tt:2719.701\n",
      "Ep:90, loss:0.00001, loss_test:0.01653, lr:4.86e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.217, tt:2749.779\n",
      "Ep:91, loss:0.00001, loss_test:0.01653, lr:4.81e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.210, tt:2779.347\n",
      "Ep:92, loss:0.00001, loss_test:0.01653, lr:4.76e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.198, tt:2808.383\n",
      "Ep:93, loss:0.00001, loss_test:0.01656, lr:4.71e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.200, tt:2838.753\n",
      "Ep:94, loss:0.00001, loss_test:0.01658, lr:4.67e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.190, tt:2868.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00001, loss_test:0.01658, lr:4.62e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.197, tt:2898.953\n",
      "Ep:96, loss:0.00001, loss_test:0.01658, lr:4.57e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.181, tt:2927.600\n",
      "Ep:97, loss:0.00001, loss_test:0.01659, lr:4.53e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.158, tt:2955.443\n",
      "Ep:98, loss:0.00001, loss_test:0.01661, lr:4.48e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.164, tt:2986.209\n",
      "Ep:99, loss:0.00001, loss_test:0.01663, lr:4.44e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.147, tt:3014.716\n",
      "Ep:100, loss:0.00001, loss_test:0.01664, lr:4.39e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.145, tt:3044.688\n",
      "Ep:101, loss:0.00001, loss_test:0.01666, lr:4.35e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.138, tt:3074.067\n",
      "Ep:102, loss:0.00001, loss_test:0.01669, lr:4.31e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.138, tt:3104.222\n",
      "Ep:103, loss:0.00001, loss_test:0.01669, lr:4.26e-02, fs:0.75258 (r=0.737,p=0.768),  time:30.153, tt:3135.954\n",
      "Ep:104, loss:0.00001, loss_test:0.01669, lr:4.22e-02, fs:0.75258 (r=0.737,p=0.768),  time:30.141, tt:3164.805\n",
      "Ep:105, loss:0.00001, loss_test:0.01669, lr:4.18e-02, fs:0.75258 (r=0.737,p=0.768),  time:30.121, tt:3192.861\n",
      "Ep:106, loss:0.00001, loss_test:0.01671, lr:4.14e-02, fs:0.75258 (r=0.737,p=0.768),  time:30.117, tt:3222.572\n",
      "Ep:107, loss:0.00001, loss_test:0.01671, lr:4.10e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.094, tt:3250.151\n",
      "Ep:108, loss:0.00001, loss_test:0.01672, lr:4.05e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.072, tt:3277.862\n",
      "Ep:109, loss:0.00001, loss_test:0.01674, lr:4.01e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.074, tt:3308.158\n",
      "Ep:110, loss:0.00001, loss_test:0.01677, lr:3.97e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.062, tt:3336.881\n",
      "Ep:111, loss:0.00001, loss_test:0.01677, lr:3.93e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.072, tt:3368.068\n",
      "Ep:112, loss:0.00001, loss_test:0.01677, lr:3.89e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.079, tt:3398.947\n",
      "Ep:113, loss:0.00001, loss_test:0.01678, lr:3.86e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.093, tt:3430.593\n",
      "Ep:114, loss:0.00001, loss_test:0.01681, lr:3.82e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.100, tt:3461.480\n",
      "Ep:115, loss:0.00001, loss_test:0.01682, lr:3.78e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.102, tt:3491.819\n",
      "Ep:116, loss:0.00001, loss_test:0.01682, lr:3.74e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.091, tt:3520.590\n",
      "Ep:117, loss:0.00001, loss_test:0.01685, lr:3.70e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.086, tt:3550.188\n",
      "Ep:118, loss:0.00001, loss_test:0.01688, lr:3.67e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.088, tt:3580.491\n",
      "Ep:119, loss:0.00001, loss_test:0.01690, lr:3.63e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.085, tt:3610.195\n",
      "Ep:120, loss:0.00001, loss_test:0.01691, lr:3.59e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.087, tt:3640.562\n",
      "Ep:121, loss:0.00001, loss_test:0.01691, lr:3.56e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.116, tt:3674.100\n",
      "Ep:122, loss:0.00001, loss_test:0.01692, lr:3.52e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.117, tt:3704.410\n",
      "Ep:123, loss:0.00001, loss_test:0.01695, lr:3.49e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.122, tt:3735.157\n",
      "Ep:124, loss:0.00001, loss_test:0.01698, lr:3.45e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.123, tt:3765.338\n",
      "Ep:125, loss:0.00001, loss_test:0.01699, lr:3.42e-02, fs:0.74737 (r=0.717,p=0.780),  time:30.117, tt:3794.788\n",
      "Ep:126, loss:0.00001, loss_test:0.01700, lr:3.38e-02, fs:0.74737 (r=0.717,p=0.780),  time:30.127, tt:3826.083\n",
      "Ep:127, loss:0.00001, loss_test:0.01700, lr:3.35e-02, fs:0.74737 (r=0.717,p=0.780),  time:30.125, tt:3856.020\n",
      "Ep:128, loss:0.00001, loss_test:0.01701, lr:3.32e-02, fs:0.74737 (r=0.717,p=0.780),  time:30.128, tt:3886.534\n",
      "Ep:129, loss:0.00001, loss_test:0.01703, lr:3.28e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.131, tt:3916.967\n",
      "Ep:130, loss:0.00001, loss_test:0.01704, lr:3.25e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.125, tt:3946.430\n",
      "Ep:131, loss:0.00001, loss_test:0.01707, lr:3.22e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.126, tt:3976.657\n",
      "Ep:132, loss:0.00001, loss_test:0.01710, lr:3.19e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.126, tt:4006.715\n",
      "Ep:133, loss:0.00001, loss_test:0.01710, lr:3.15e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.124, tt:4036.610\n",
      "Ep:134, loss:0.00001, loss_test:0.01711, lr:3.12e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.122, tt:4066.489\n",
      "Ep:135, loss:0.00001, loss_test:0.01712, lr:3.09e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.123, tt:4096.743\n",
      "Ep:136, loss:0.00001, loss_test:0.01714, lr:3.06e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.132, tt:4128.070\n",
      "Ep:137, loss:0.00001, loss_test:0.01715, lr:3.03e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.143, tt:4159.725\n",
      "Ep:138, loss:0.00001, loss_test:0.01717, lr:3.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.146, tt:4190.244\n",
      "Ep:139, loss:0.00001, loss_test:0.01719, lr:2.97e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.143, tt:4220.047\n",
      "Ep:140, loss:0.00001, loss_test:0.01721, lr:2.94e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.144, tt:4250.267\n",
      "Ep:141, loss:0.00001, loss_test:0.01724, lr:2.91e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.142, tt:4280.204\n",
      "Ep:142, loss:0.00001, loss_test:0.01725, lr:2.88e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.146, tt:4310.857\n",
      "Ep:143, loss:0.00001, loss_test:0.01728, lr:2.85e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.148, tt:4341.363\n",
      "Ep:144, loss:0.00001, loss_test:0.01730, lr:2.82e-02, fs:0.73404 (r=0.697,p=0.775),  time:30.149, tt:4371.669\n",
      "Ep:145, loss:0.00001, loss_test:0.01732, lr:2.80e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.148, tt:4401.668\n",
      "Ep:146, loss:0.00001, loss_test:0.01732, lr:2.77e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.157, tt:4433.120\n",
      "Ep:147, loss:0.00001, loss_test:0.01732, lr:2.74e-02, fs:0.73118 (r=0.687,p=0.782),  time:30.162, tt:4463.995\n",
      "Ep:148, loss:0.00001, loss_test:0.01732, lr:2.71e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.166, tt:4494.758\n",
      "Ep:149, loss:0.00001, loss_test:0.01733, lr:2.69e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.168, tt:4525.245\n",
      "Ep:150, loss:0.00001, loss_test:0.01733, lr:2.66e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.176, tt:4556.585\n",
      "Ep:151, loss:0.00001, loss_test:0.01734, lr:2.63e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.184, tt:4588.042\n",
      "Ep:152, loss:0.00001, loss_test:0.01736, lr:2.61e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.181, tt:4617.640\n",
      "Ep:153, loss:0.00001, loss_test:0.01737, lr:2.58e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.189, tt:4649.043\n",
      "Ep:154, loss:0.00001, loss_test:0.01739, lr:2.55e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.197, tt:4680.566\n",
      "Ep:155, loss:0.00001, loss_test:0.01740, lr:2.53e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.203, tt:4711.617\n",
      "Ep:156, loss:0.00001, loss_test:0.01741, lr:2.50e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.200, tt:4741.473\n",
      "Ep:157, loss:0.00001, loss_test:0.01742, lr:2.48e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.207, tt:4772.668\n",
      "Ep:158, loss:0.00001, loss_test:0.01744, lr:2.45e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.209, tt:4803.187\n",
      "Ep:159, loss:0.00001, loss_test:0.01745, lr:2.43e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.210, tt:4833.581\n",
      "Ep:160, loss:0.00001, loss_test:0.01747, lr:2.40e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.211, tt:4863.896\n",
      "Ep:161, loss:0.00001, loss_test:0.01749, lr:2.38e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.210, tt:4893.992\n",
      "Ep:162, loss:0.00001, loss_test:0.01750, lr:2.36e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.200, tt:4922.538\n",
      "Ep:163, loss:0.00001, loss_test:0.01751, lr:2.33e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.210, tt:4954.389\n",
      "Ep:164, loss:0.00001, loss_test:0.01753, lr:2.31e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.219, tt:4986.180\n",
      "Ep:165, loss:0.00001, loss_test:0.01752, lr:2.29e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.225, tt:5017.363\n",
      "Ep:166, loss:0.00001, loss_test:0.01753, lr:2.26e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.231, tt:5048.519\n",
      "Ep:167, loss:0.00001, loss_test:0.01755, lr:2.24e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.232, tt:5078.972\n",
      "Ep:168, loss:0.00001, loss_test:0.01755, lr:2.22e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.225, tt:5107.950\n",
      "Ep:169, loss:0.00001, loss_test:0.01756, lr:2.20e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.227, tt:5138.634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:170, loss:0.00001, loss_test:0.01758, lr:2.17e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.223, tt:5168.129\n",
      "Ep:171, loss:0.00001, loss_test:0.01759, lr:2.15e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.219, tt:5197.752\n",
      "Ep:172, loss:0.00000, loss_test:0.01760, lr:2.13e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.219, tt:5227.888\n",
      "Ep:173, loss:0.00000, loss_test:0.01761, lr:2.11e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.221, tt:5258.462\n",
      "Ep:174, loss:0.00000, loss_test:0.01761, lr:2.09e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.227, tt:5289.653\n",
      "Ep:175, loss:0.00000, loss_test:0.01762, lr:2.07e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.234, tt:5321.204\n",
      "Ep:176, loss:0.00000, loss_test:0.01763, lr:2.05e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.236, tt:5351.848\n",
      "Ep:177, loss:0.00000, loss_test:0.01764, lr:2.03e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.239, tt:5382.491\n",
      "Ep:178, loss:0.00000, loss_test:0.01765, lr:2.01e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.243, tt:5413.546\n",
      "Ep:179, loss:0.00000, loss_test:0.01766, lr:1.99e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.246, tt:5444.341\n",
      "Ep:180, loss:0.00000, loss_test:0.01767, lr:1.97e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.244, tt:5474.109\n",
      "Ep:181, loss:0.00000, loss_test:0.01767, lr:1.95e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.256, tt:5506.638\n",
      "Ep:182, loss:0.00000, loss_test:0.01769, lr:1.93e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.261, tt:5537.697\n",
      "Ep:183, loss:0.00000, loss_test:0.01771, lr:1.91e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.270, tt:5569.737\n",
      "Ep:184, loss:0.00000, loss_test:0.01771, lr:1.89e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.279, tt:5601.684\n",
      "Ep:185, loss:0.00000, loss_test:0.01771, lr:1.87e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.282, tt:5632.436\n",
      "Ep:186, loss:0.00000, loss_test:0.01772, lr:1.85e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.291, tt:5664.511\n",
      "Ep:187, loss:0.00000, loss_test:0.01773, lr:1.83e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.302, tt:5696.698\n",
      "Ep:188, loss:0.00000, loss_test:0.01774, lr:1.81e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.311, tt:5728.760\n",
      "Ep:189, loss:0.00000, loss_test:0.01773, lr:1.80e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.319, tt:5760.527\n",
      "Ep:190, loss:0.00000, loss_test:0.01774, lr:1.78e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.330, tt:5792.938\n",
      "Ep:191, loss:0.00000, loss_test:0.01775, lr:1.76e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.336, tt:5824.545\n",
      "Ep:192, loss:0.00000, loss_test:0.01776, lr:1.74e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.337, tt:5855.043\n",
      "Ep:193, loss:0.00000, loss_test:0.01777, lr:1.73e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.344, tt:5886.691\n",
      "Ep:194, loss:0.00000, loss_test:0.01777, lr:1.71e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.344, tt:5916.989\n",
      "Ep:195, loss:0.00000, loss_test:0.01778, lr:1.69e-02, fs:0.72626 (r=0.657,p=0.812),  time:30.340, tt:5946.664\n",
      "Ep:196, loss:0.00000, loss_test:0.01778, lr:1.67e-02, fs:0.72626 (r=0.657,p=0.812),  time:30.345, tt:5978.043\n",
      "Ep:197, loss:0.00000, loss_test:0.01780, lr:1.66e-02, fs:0.72626 (r=0.657,p=0.812),  time:30.336, tt:6006.546\n",
      "Ep:198, loss:0.00000, loss_test:0.01781, lr:1.64e-02, fs:0.72626 (r=0.657,p=0.812),  time:30.332, tt:6035.986\n",
      "Ep:199, loss:0.00000, loss_test:0.01781, lr:1.62e-02, fs:0.72626 (r=0.657,p=0.812),  time:30.331, tt:6066.157\n",
      "Ep:200, loss:0.00000, loss_test:0.01782, lr:1.61e-02, fs:0.72626 (r=0.657,p=0.812),  time:30.315, tt:6093.294\n",
      "Ep:201, loss:0.00000, loss_test:0.01782, lr:1.59e-02, fs:0.73034 (r=0.657,p=0.823),  time:30.294, tt:6119.485\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13874, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:26.081, tt:26.081\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13557, lr:1.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:27.260, tt:54.519\n",
      "Ep:2, loss:0.00025, loss_test:0.13243, lr:1.00e-02, fs:0.63478 (r=0.737,p=0.557),  time:28.261, tt:84.782\n",
      "Ep:3, loss:0.00023, loss_test:0.13350, lr:1.00e-02, fs:0.63542 (r=0.616,p=0.656),  time:28.662, tt:114.648\n",
      "Ep:4, loss:0.00022, loss_test:0.13442, lr:1.00e-02, fs:0.51534 (r=0.424,p=0.656),  time:29.094, tt:145.472\n",
      "Ep:5, loss:0.00022, loss_test:0.12663, lr:1.00e-02, fs:0.58065 (r=0.545,p=0.621),  time:29.624, tt:177.747\n",
      "Ep:6, loss:0.00021, loss_test:0.12342, lr:1.00e-02, fs:0.63366 (r=0.646,p=0.621),  time:29.784, tt:208.489\n",
      "Ep:7, loss:0.00020, loss_test:0.12370, lr:1.00e-02, fs:0.60417 (r=0.586,p=0.624),  time:29.556, tt:236.452\n",
      "Ep:8, loss:0.00019, loss_test:0.12635, lr:1.00e-02, fs:0.58757 (r=0.525,p=0.667),  time:29.716, tt:267.447\n",
      "Ep:9, loss:0.00019, loss_test:0.12357, lr:1.00e-02, fs:0.59783 (r=0.556,p=0.647),  time:29.946, tt:299.460\n",
      "Ep:10, loss:0.00018, loss_test:0.12010, lr:1.00e-02, fs:0.61616 (r=0.616,p=0.616),  time:30.165, tt:331.819\n",
      "Ep:11, loss:0.00018, loss_test:0.11988, lr:1.00e-02, fs:0.59686 (r=0.576,p=0.620),  time:30.419, tt:365.025\n",
      "Ep:12, loss:0.00017, loss_test:0.12066, lr:9.90e-03, fs:0.58889 (r=0.535,p=0.654),  time:30.368, tt:394.778\n",
      "Ep:13, loss:0.00016, loss_test:0.11919, lr:9.80e-03, fs:0.57303 (r=0.515,p=0.646),  time:30.475, tt:426.653\n",
      "Ep:14, loss:0.00016, loss_test:0.11674, lr:9.70e-03, fs:0.62434 (r=0.596,p=0.656),  time:30.618, tt:459.273\n",
      "Ep:15, loss:0.00015, loss_test:0.11590, lr:9.61e-03, fs:0.61957 (r=0.576,p=0.671),  time:30.658, tt:490.532\n",
      "Ep:16, loss:0.00015, loss_test:0.11504, lr:9.51e-03, fs:0.63333 (r=0.576,p=0.704),  time:30.750, tt:522.743\n",
      "Ep:17, loss:0.00014, loss_test:0.11327, lr:9.41e-03, fs:0.63736 (r=0.586,p=0.699),  time:30.760, tt:553.675\n",
      "Ep:18, loss:0.00014, loss_test:0.11140, lr:9.32e-03, fs:0.65608 (r=0.626,p=0.689),  time:30.818, tt:585.547\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.11023, lr:9.32e-03, fs:0.68449 (r=0.646,p=0.727),  time:30.915, tt:618.308\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.10945, lr:9.32e-03, fs:0.69565 (r=0.646,p=0.753),  time:30.978, tt:650.548\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.10798, lr:9.32e-03, fs:0.71658 (r=0.677,p=0.761),  time:31.032, tt:682.699\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.10689, lr:9.32e-03, fs:0.73404 (r=0.697,p=0.775),  time:31.018, tt:713.414\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.10570, lr:9.32e-03, fs:0.73684 (r=0.707,p=0.769),  time:31.023, tt:744.548\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.10495, lr:9.32e-03, fs:0.74074 (r=0.707,p=0.778),  time:31.072, tt:776.809\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.10430, lr:9.32e-03, fs:0.74074 (r=0.707,p=0.778),  time:31.151, tt:809.931\n",
      "Ep:26, loss:0.00011, loss_test:0.10314, lr:9.32e-03, fs:0.74074 (r=0.707,p=0.778),  time:31.202, tt:842.466\n",
      "Ep:27, loss:0.00011, loss_test:0.10185, lr:9.32e-03, fs:0.73298 (r=0.707,p=0.761),  time:31.208, tt:873.833\n",
      "Ep:28, loss:0.00010, loss_test:0.10110, lr:9.32e-03, fs:0.73684 (r=0.707,p=0.769),  time:31.274, tt:906.933\n",
      "Ep:29, loss:0.00010, loss_test:0.10019, lr:9.32e-03, fs:0.73684 (r=0.707,p=0.769),  time:31.296, tt:938.868\n",
      "Ep:30, loss:0.00010, loss_test:0.09938, lr:9.32e-03, fs:0.74346 (r=0.717,p=0.772),  time:31.334, tt:971.343\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.09878, lr:9.32e-03, fs:0.74866 (r=0.707,p=0.795),  time:31.321, tt:1002.265\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.09769, lr:9.32e-03, fs:0.75132 (r=0.717,p=0.789),  time:31.275, tt:1032.077\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.09648, lr:9.32e-03, fs:0.75897 (r=0.747,p=0.771),  time:31.283, tt:1063.610\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.09605, lr:9.32e-03, fs:0.76440 (r=0.737,p=0.793),  time:31.265, tt:1094.287\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:35, loss:0.00008, loss_test:0.09565, lr:9.32e-03, fs:0.75789 (r=0.727,p=0.791),  time:31.207, tt:1123.468\n",
      "Ep:36, loss:0.00008, loss_test:0.09471, lr:9.32e-03, fs:0.76042 (r=0.737,p=0.785),  time:31.241, tt:1155.926\n",
      "Ep:37, loss:0.00008, loss_test:0.09412, lr:9.32e-03, fs:0.76344 (r=0.717,p=0.816),  time:31.276, tt:1188.494\n",
      "Ep:38, loss:0.00008, loss_test:0.09339, lr:9.32e-03, fs:0.75936 (r=0.717,p=0.807),  time:31.275, tt:1219.732\n",
      "Ep:39, loss:0.00008, loss_test:0.09311, lr:9.32e-03, fs:0.76596 (r=0.727,p=0.809),  time:31.321, tt:1252.825\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.09257, lr:9.32e-03, fs:0.77419 (r=0.727,p=0.828),  time:31.323, tt:1284.251\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.09181, lr:9.32e-03, fs:0.75936 (r=0.717,p=0.807),  time:31.318, tt:1315.343\n",
      "Ep:42, loss:0.00007, loss_test:0.09142, lr:9.32e-03, fs:0.76344 (r=0.717,p=0.816),  time:31.317, tt:1346.610\n",
      "Ep:43, loss:0.00007, loss_test:0.09096, lr:9.32e-03, fs:0.76757 (r=0.717,p=0.826),  time:31.351, tt:1379.465\n",
      "Ep:44, loss:0.00007, loss_test:0.09033, lr:9.32e-03, fs:0.76757 (r=0.717,p=0.826),  time:31.339, tt:1410.260\n",
      "Ep:45, loss:0.00006, loss_test:0.08992, lr:9.32e-03, fs:0.76087 (r=0.707,p=0.824),  time:31.352, tt:1442.194\n",
      "Ep:46, loss:0.00006, loss_test:0.08897, lr:9.32e-03, fs:0.76087 (r=0.707,p=0.824),  time:31.370, tt:1474.385\n",
      "Ep:47, loss:0.00006, loss_test:0.08851, lr:9.32e-03, fs:0.76757 (r=0.717,p=0.826),  time:31.415, tt:1507.928\n",
      "Ep:48, loss:0.00006, loss_test:0.08829, lr:9.32e-03, fs:0.76087 (r=0.707,p=0.824),  time:31.434, tt:1540.276\n",
      "Ep:49, loss:0.00006, loss_test:0.08753, lr:9.32e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.483, tt:1574.145\n",
      "Ep:50, loss:0.00006, loss_test:0.08710, lr:9.32e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.492, tt:1606.084\n",
      "Ep:51, loss:0.00006, loss_test:0.08690, lr:9.32e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.481, tt:1637.035\n",
      "Ep:52, loss:0.00005, loss_test:0.08641, lr:9.23e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.475, tt:1668.151\n",
      "Ep:53, loss:0.00005, loss_test:0.08584, lr:9.14e-03, fs:0.76087 (r=0.707,p=0.824),  time:31.490, tt:1700.462\n",
      "Ep:54, loss:0.00005, loss_test:0.08580, lr:9.04e-03, fs:0.75824 (r=0.697,p=0.831),  time:31.511, tt:1733.110\n",
      "Ep:55, loss:0.00005, loss_test:0.08550, lr:8.95e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.511, tt:1764.601\n",
      "Ep:56, loss:0.00005, loss_test:0.08552, lr:8.86e-03, fs:0.75824 (r=0.697,p=0.831),  time:31.504, tt:1795.725\n",
      "Ep:57, loss:0.00005, loss_test:0.08530, lr:8.78e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.511, tt:1827.623\n",
      "Ep:58, loss:0.00005, loss_test:0.08454, lr:8.69e-03, fs:0.76344 (r=0.717,p=0.816),  time:31.514, tt:1859.318\n",
      "Ep:59, loss:0.00005, loss_test:0.08492, lr:8.60e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.527, tt:1891.646\n",
      "Ep:60, loss:0.00005, loss_test:0.08516, lr:8.51e-03, fs:0.76836 (r=0.687,p=0.872),  time:31.547, tt:1924.358\n",
      "Ep:61, loss:0.00005, loss_test:0.08435, lr:8.43e-03, fs:0.76757 (r=0.717,p=0.826),  time:31.551, tt:1956.151\n",
      "Ep:62, loss:0.00005, loss_test:0.08359, lr:8.35e-03, fs:0.76923 (r=0.707,p=0.843),  time:31.573, tt:1989.086\n",
      "Ep:63, loss:0.00004, loss_test:0.08430, lr:8.26e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.575, tt:2020.821\n",
      "Ep:64, loss:0.00004, loss_test:0.08394, lr:8.18e-03, fs:0.76503 (r=0.707,p=0.833),  time:31.565, tt:2051.735\n",
      "Ep:65, loss:0.00004, loss_test:0.08385, lr:8.10e-03, fs:0.77174 (r=0.717,p=0.835),  time:31.557, tt:2082.762\n",
      "Ep:66, loss:0.00004, loss_test:0.08320, lr:8.02e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.580, tt:2115.833\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.08335, lr:8.02e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.629, tt:2150.784\n",
      "Ep:68, loss:0.00004, loss_test:0.08345, lr:8.02e-03, fs:0.77174 (r=0.717,p=0.835),  time:31.636, tt:2182.864\n",
      "Ep:69, loss:0.00004, loss_test:0.08369, lr:8.02e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.638, tt:2214.670\n",
      "Ep:70, loss:0.00004, loss_test:0.08312, lr:8.02e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.629, tt:2245.658\n",
      "Ep:71, loss:0.00004, loss_test:0.08303, lr:8.02e-03, fs:0.77174 (r=0.717,p=0.835),  time:31.611, tt:2276.022\n",
      "Ep:72, loss:0.00004, loss_test:0.08334, lr:8.02e-03, fs:0.78022 (r=0.717,p=0.855),  time:31.621, tt:2308.312\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00004, loss_test:0.08326, lr:8.02e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.643, tt:2341.571\n",
      "Ep:74, loss:0.00004, loss_test:0.08282, lr:8.02e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.637, tt:2372.794\n",
      "Ep:75, loss:0.00004, loss_test:0.08346, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.632, tt:2404.061\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00003, loss_test:0.08315, lr:8.02e-03, fs:0.78022 (r=0.717,p=0.855),  time:31.634, tt:2435.831\n",
      "Ep:77, loss:0.00003, loss_test:0.08302, lr:8.02e-03, fs:0.78022 (r=0.717,p=0.855),  time:31.647, tt:2468.475\n",
      "Ep:78, loss:0.00003, loss_test:0.08351, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.646, tt:2500.047\n",
      "Ep:79, loss:0.00003, loss_test:0.08334, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.640, tt:2531.190\n",
      "Ep:80, loss:0.00003, loss_test:0.08320, lr:8.02e-03, fs:0.78022 (r=0.717,p=0.855),  time:31.629, tt:2561.961\n",
      "Ep:81, loss:0.00003, loss_test:0.08368, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.626, tt:2593.364\n",
      "Ep:82, loss:0.00003, loss_test:0.08366, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.616, tt:2624.163\n",
      "Ep:83, loss:0.00003, loss_test:0.08349, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.649, tt:2658.514\n",
      "Ep:84, loss:0.00003, loss_test:0.08369, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.653, tt:2690.524\n",
      "Ep:85, loss:0.00003, loss_test:0.08348, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.663, tt:2722.983\n",
      "Ep:86, loss:0.00003, loss_test:0.08370, lr:8.02e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.663, tt:2754.638\n",
      "Ep:87, loss:0.00003, loss_test:0.08354, lr:7.94e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.664, tt:2786.453\n",
      "Ep:88, loss:0.00003, loss_test:0.08326, lr:7.86e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.676, tt:2819.176\n",
      "Ep:89, loss:0.00003, loss_test:0.08378, lr:7.78e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.675, tt:2850.778\n",
      "Ep:90, loss:0.00003, loss_test:0.08324, lr:7.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.683, tt:2883.116\n",
      "Ep:91, loss:0.00003, loss_test:0.08342, lr:7.62e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.697, tt:2916.078\n",
      "Ep:92, loss:0.00003, loss_test:0.08351, lr:7.55e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.677, tt:2945.920\n",
      "Ep:93, loss:0.00003, loss_test:0.08361, lr:7.47e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.669, tt:2976.875\n",
      "Ep:94, loss:0.00003, loss_test:0.08362, lr:7.40e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.673, tt:3008.917\n",
      "Ep:95, loss:0.00003, loss_test:0.08311, lr:7.32e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.676, tt:3040.899\n",
      "Ep:96, loss:0.00002, loss_test:0.08358, lr:7.25e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.684, tt:3073.310\n",
      "Ep:97, loss:0.00002, loss_test:0.08328, lr:7.18e-03, fs:0.78022 (r=0.717,p=0.855),  time:31.671, tt:3103.794\n",
      "Ep:98, loss:0.00002, loss_test:0.08343, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.661, tt:3134.400\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00002, loss_test:0.08381, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.666, tt:3166.632\n",
      "Ep:100, loss:0.00002, loss_test:0.08326, lr:7.11e-03, fs:0.78022 (r=0.717,p=0.855),  time:31.664, tt:3198.038\n",
      "Ep:101, loss:0.00002, loss_test:0.08343, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.669, tt:3230.277\n",
      "Ep:102, loss:0.00002, loss_test:0.08358, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.674, tt:3262.380\n",
      "Ep:103, loss:0.00002, loss_test:0.08340, lr:7.11e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.672, tt:3293.862\n",
      "Ep:104, loss:0.00002, loss_test:0.08353, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.684, tt:3326.860\n",
      "Ep:105, loss:0.00002, loss_test:0.08338, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.688, tt:3358.937\n",
      "Ep:106, loss:0.00002, loss_test:0.08328, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.693, tt:3391.189\n",
      "Ep:107, loss:0.00002, loss_test:0.08346, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.702, tt:3423.827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00002, loss_test:0.08354, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.680, tt:3453.102\n",
      "Ep:109, loss:0.00002, loss_test:0.08350, lr:7.11e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.682, tt:3485.048\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.08344, lr:7.11e-03, fs:0.78889 (r=0.717,p=0.877),  time:31.684, tt:3516.893\n",
      "Ep:111, loss:0.00002, loss_test:0.08379, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.679, tt:3548.064\n",
      "Ep:112, loss:0.00002, loss_test:0.08364, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.671, tt:3578.822\n",
      "Ep:113, loss:0.00002, loss_test:0.08397, lr:7.11e-03, fs:0.78889 (r=0.717,p=0.877),  time:31.678, tt:3611.313\n",
      "Ep:114, loss:0.00002, loss_test:0.08408, lr:7.11e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.673, tt:3642.401\n",
      "Ep:115, loss:0.00002, loss_test:0.08333, lr:7.11e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.662, tt:3672.741\n",
      "Ep:116, loss:0.00002, loss_test:0.08407, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.661, tt:3704.360\n",
      "Ep:117, loss:0.00002, loss_test:0.08446, lr:7.11e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.663, tt:3736.219\n",
      "Ep:118, loss:0.00002, loss_test:0.08353, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.660, tt:3767.571\n",
      "Ep:119, loss:0.00002, loss_test:0.08372, lr:7.11e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.651, tt:3798.126\n",
      "Ep:120, loss:0.00002, loss_test:0.08437, lr:7.11e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.635, tt:3827.825\n",
      "Ep:121, loss:0.00002, loss_test:0.08376, lr:7.03e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.614, tt:3856.960\n",
      "Ep:122, loss:0.00002, loss_test:0.08374, lr:6.96e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.607, tt:3887.654\n",
      "Ep:123, loss:0.00002, loss_test:0.08441, lr:6.89e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.611, tt:3919.777\n",
      "Ep:124, loss:0.00002, loss_test:0.08443, lr:6.83e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.606, tt:3950.692\n",
      "Ep:125, loss:0.00002, loss_test:0.08374, lr:6.76e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.598, tt:3981.375\n",
      "Ep:126, loss:0.00002, loss_test:0.08419, lr:6.69e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.592, tt:4012.164\n",
      "Ep:127, loss:0.00002, loss_test:0.08427, lr:6.62e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.586, tt:4042.956\n",
      "Ep:128, loss:0.00002, loss_test:0.08392, lr:6.56e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.584, tt:4074.290\n",
      "Ep:129, loss:0.00002, loss_test:0.08415, lr:6.49e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.583, tt:4105.810\n",
      "Ep:130, loss:0.00002, loss_test:0.08442, lr:6.43e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.585, tt:4137.673\n",
      "Ep:131, loss:0.00002, loss_test:0.08396, lr:6.36e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.600, tt:4171.217\n",
      "Ep:132, loss:0.00002, loss_test:0.08408, lr:6.30e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.603, tt:4203.136\n",
      "Ep:133, loss:0.00002, loss_test:0.08409, lr:6.24e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.590, tt:4233.126\n",
      "Ep:134, loss:0.00002, loss_test:0.08430, lr:6.17e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.602, tt:4266.256\n",
      "Ep:135, loss:0.00001, loss_test:0.08446, lr:6.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.609, tt:4298.874\n",
      "Ep:136, loss:0.00001, loss_test:0.08415, lr:6.05e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.621, tt:4332.085\n",
      "Ep:137, loss:0.00001, loss_test:0.08469, lr:5.99e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.624, tt:4364.075\n",
      "Ep:138, loss:0.00001, loss_test:0.08456, lr:5.93e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.624, tt:4395.727\n",
      "Ep:139, loss:0.00001, loss_test:0.08402, lr:5.87e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.620, tt:4426.861\n",
      "Ep:140, loss:0.00001, loss_test:0.08444, lr:5.81e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.621, tt:4458.508\n",
      "Ep:141, loss:0.00001, loss_test:0.08447, lr:5.75e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.621, tt:4490.134\n",
      "Ep:142, loss:0.00001, loss_test:0.08414, lr:5.70e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.620, tt:4521.725\n",
      "Ep:143, loss:0.00001, loss_test:0.08436, lr:5.64e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.620, tt:4553.220\n",
      "Ep:144, loss:0.00001, loss_test:0.08421, lr:5.58e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.623, tt:4585.276\n",
      "Ep:145, loss:0.00001, loss_test:0.08401, lr:5.53e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.625, tt:4617.207\n",
      "Ep:146, loss:0.00001, loss_test:0.08448, lr:5.47e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.633, tt:4650.048\n",
      "Ep:147, loss:0.00001, loss_test:0.08415, lr:5.42e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.622, tt:4680.067\n",
      "Ep:148, loss:0.00001, loss_test:0.08395, lr:5.36e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.634, tt:4713.397\n",
      "Ep:149, loss:0.00001, loss_test:0.08417, lr:5.31e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.641, tt:4746.208\n",
      "Ep:150, loss:0.00001, loss_test:0.08417, lr:5.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.642, tt:4777.979\n",
      "Ep:151, loss:0.00001, loss_test:0.08411, lr:5.20e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.659, tt:4812.124\n",
      "Ep:152, loss:0.00001, loss_test:0.08432, lr:5.15e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.660, tt:4843.904\n",
      "Ep:153, loss:0.00001, loss_test:0.08420, lr:5.10e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.665, tt:4876.338\n",
      "Ep:154, loss:0.00001, loss_test:0.08414, lr:5.05e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.666, tt:4908.233\n",
      "Ep:155, loss:0.00001, loss_test:0.08420, lr:5.00e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.658, tt:4938.697\n",
      "Ep:156, loss:0.00001, loss_test:0.08443, lr:4.95e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.652, tt:4969.427\n",
      "Ep:157, loss:0.00001, loss_test:0.08435, lr:4.90e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.655, tt:5001.487\n",
      "Ep:158, loss:0.00001, loss_test:0.08422, lr:4.85e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.659, tt:5033.854\n",
      "Ep:159, loss:0.00001, loss_test:0.08449, lr:4.80e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.659, tt:5065.472\n",
      "Ep:160, loss:0.00001, loss_test:0.08415, lr:4.75e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.667, tt:5098.384\n",
      "Ep:161, loss:0.00001, loss_test:0.08423, lr:4.71e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.671, tt:5130.766\n",
      "Ep:162, loss:0.00001, loss_test:0.08445, lr:4.66e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.675, tt:5162.959\n",
      "Ep:163, loss:0.00001, loss_test:0.08414, lr:4.61e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.680, tt:5195.446\n",
      "Ep:164, loss:0.00001, loss_test:0.08450, lr:4.57e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.678, tt:5226.833\n",
      "Ep:165, loss:0.00001, loss_test:0.08462, lr:4.52e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.673, tt:5257.660\n",
      "Ep:166, loss:0.00001, loss_test:0.08408, lr:4.48e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.675, tt:5289.712\n",
      "Ep:167, loss:0.00001, loss_test:0.08431, lr:4.43e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.686, tt:5323.316\n",
      "Ep:168, loss:0.00001, loss_test:0.08462, lr:4.39e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.693, tt:5356.128\n",
      "Ep:169, loss:0.00001, loss_test:0.08436, lr:4.34e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.693, tt:5387.759\n",
      "Ep:170, loss:0.00001, loss_test:0.08416, lr:4.30e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.698, tt:5420.442\n",
      "Ep:171, loss:0.00001, loss_test:0.08442, lr:4.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.694, tt:5451.382\n",
      "Ep:172, loss:0.00001, loss_test:0.08433, lr:4.21e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.684, tt:5481.381\n",
      "Ep:173, loss:0.00001, loss_test:0.08419, lr:4.17e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.682, tt:5512.743\n",
      "Ep:174, loss:0.00001, loss_test:0.08429, lr:4.13e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.691, tt:5545.906\n",
      "Ep:175, loss:0.00001, loss_test:0.08422, lr:4.09e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.691, tt:5577.585\n",
      "Ep:176, loss:0.00001, loss_test:0.08433, lr:4.05e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.697, tt:5610.424\n",
      "Ep:177, loss:0.00001, loss_test:0.08436, lr:4.01e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.713, tt:5644.875\n",
      "Ep:178, loss:0.00001, loss_test:0.08409, lr:3.97e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.718, tt:5677.578\n",
      "Ep:179, loss:0.00001, loss_test:0.08444, lr:3.93e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.726, tt:5710.634\n",
      "Ep:180, loss:0.00001, loss_test:0.08447, lr:3.89e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.722, tt:5741.770\n",
      "Ep:181, loss:0.00001, loss_test:0.08422, lr:3.85e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.718, tt:5772.612\n",
      "Ep:182, loss:0.00001, loss_test:0.08454, lr:3.81e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.720, tt:5804.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:183, loss:0.00001, loss_test:0.08471, lr:3.77e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.719, tt:5836.297\n",
      "Ep:184, loss:0.00001, loss_test:0.08430, lr:3.73e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.723, tt:5868.728\n",
      "Ep:185, loss:0.00001, loss_test:0.08443, lr:3.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.735, tt:5902.691\n",
      "Ep:186, loss:0.00001, loss_test:0.08473, lr:3.66e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.742, tt:5935.786\n",
      "Ep:187, loss:0.00001, loss_test:0.08462, lr:3.62e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.735, tt:5966.169\n",
      "Ep:188, loss:0.00001, loss_test:0.08422, lr:3.59e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.736, tt:5998.088\n",
      "Ep:189, loss:0.00001, loss_test:0.08460, lr:3.55e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.738, tt:6030.179\n",
      "Ep:190, loss:0.00001, loss_test:0.08466, lr:3.52e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.728, tt:6060.050\n",
      "Ep:191, loss:0.00001, loss_test:0.08423, lr:3.48e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.727, tt:6091.513\n",
      "Ep:192, loss:0.00001, loss_test:0.08433, lr:3.45e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.725, tt:6122.905\n",
      "Ep:193, loss:0.00001, loss_test:0.08463, lr:3.41e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.725, tt:6154.689\n",
      "Ep:194, loss:0.00001, loss_test:0.08457, lr:3.38e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.724, tt:6186.095\n",
      "Ep:195, loss:0.00001, loss_test:0.08419, lr:3.34e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.727, tt:6218.434\n",
      "Ep:196, loss:0.00001, loss_test:0.08449, lr:3.31e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.728, tt:6250.492\n",
      "Ep:197, loss:0.00001, loss_test:0.08462, lr:3.28e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.733, tt:6283.152\n",
      "Ep:198, loss:0.00001, loss_test:0.08441, lr:3.24e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.723, tt:6312.970\n",
      "Ep:199, loss:0.00001, loss_test:0.08443, lr:3.21e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.719, tt:6343.889\n",
      "Ep:200, loss:0.00001, loss_test:0.08447, lr:3.18e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.700, tt:6371.777\n",
      "Ep:201, loss:0.00001, loss_test:0.08442, lr:3.15e-03, fs:0.77095 (r=0.697,p=0.863),  time:31.675, tt:6398.444\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02424, lr:6.00e-02, fs:0.60377 (r=0.646,p=0.566),  time:22.061, tt:22.061\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:21.290, tt:42.581\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02419, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.008, tt:66.023\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02463, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.743, tt:90.973\n",
      "Ep:4, loss:0.00005, loss_test:0.02419, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.197, tt:115.984\n",
      "Ep:5, loss:0.00004, loss_test:0.02342, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.663, tt:141.979\n",
      "Ep:6, loss:0.00004, loss_test:0.02258, lr:6.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:23.815, tt:166.706\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02219, lr:6.00e-02, fs:0.62500 (r=0.808,p=0.510),  time:23.834, tt:190.674\n",
      "Ep:8, loss:0.00004, loss_test:0.02269, lr:6.00e-02, fs:0.61472 (r=0.717,p=0.538),  time:23.789, tt:214.101\n",
      "Ep:9, loss:0.00004, loss_test:0.02398, lr:6.00e-02, fs:0.60909 (r=0.677,p=0.554),  time:23.834, tt:238.341\n",
      "Ep:10, loss:0.00004, loss_test:0.02495, lr:6.00e-02, fs:0.60377 (r=0.646,p=0.566),  time:24.004, tt:264.048\n",
      "Ep:11, loss:0.00004, loss_test:0.02471, lr:6.00e-02, fs:0.61682 (r=0.667,p=0.574),  time:24.103, tt:289.239\n",
      "Ep:12, loss:0.00004, loss_test:0.02351, lr:6.00e-02, fs:0.61187 (r=0.677,p=0.558),  time:24.223, tt:314.897\n",
      "Ep:13, loss:0.00003, loss_test:0.02243, lr:6.00e-02, fs:0.62009 (r=0.717,p=0.546),  time:24.371, tt:341.187\n",
      "Ep:14, loss:0.00003, loss_test:0.02180, lr:6.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:24.484, tt:367.265\n",
      "Ep:15, loss:0.00003, loss_test:0.02143, lr:6.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:24.570, tt:393.125\n",
      "Ep:16, loss:0.00003, loss_test:0.02126, lr:6.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:24.656, tt:419.148\n",
      "Ep:17, loss:0.00003, loss_test:0.02126, lr:6.00e-02, fs:0.65000 (r=0.788,p=0.553),  time:24.756, tt:445.614\n",
      "Ep:18, loss:0.00003, loss_test:0.02133, lr:5.94e-02, fs:0.64378 (r=0.758,p=0.560),  time:24.871, tt:472.541\n",
      "Ep:19, loss:0.00003, loss_test:0.02134, lr:5.88e-02, fs:0.64912 (r=0.747,p=0.574),  time:24.919, tt:498.377\n",
      "Ep:20, loss:0.00003, loss_test:0.02118, lr:5.82e-02, fs:0.64912 (r=0.747,p=0.574),  time:24.865, tt:522.159\n",
      "Ep:21, loss:0.00003, loss_test:0.02081, lr:5.76e-02, fs:0.66079 (r=0.758,p=0.586),  time:24.906, tt:547.923\n",
      "Ep:22, loss:0.00003, loss_test:0.02040, lr:5.71e-02, fs:0.66379 (r=0.778,p=0.579),  time:24.907, tt:572.859\n",
      "Ep:23, loss:0.00003, loss_test:0.02002, lr:5.65e-02, fs:0.66667 (r=0.798,p=0.572),  time:24.963, tt:599.102\n",
      "Ep:24, loss:0.00003, loss_test:0.01979, lr:5.59e-02, fs:0.68880 (r=0.838,p=0.585),  time:25.037, tt:625.922\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01968, lr:5.59e-02, fs:0.66667 (r=0.798,p=0.572),  time:25.065, tt:651.703\n",
      "Ep:26, loss:0.00003, loss_test:0.01962, lr:5.59e-02, fs:0.65812 (r=0.778,p=0.570),  time:25.168, tt:679.522\n",
      "Ep:27, loss:0.00003, loss_test:0.01961, lr:5.59e-02, fs:0.66960 (r=0.768,p=0.594),  time:25.209, tt:705.864\n",
      "Ep:28, loss:0.00003, loss_test:0.01953, lr:5.59e-02, fs:0.67857 (r=0.768,p=0.608),  time:25.223, tt:731.471\n",
      "Ep:29, loss:0.00003, loss_test:0.01935, lr:5.59e-02, fs:0.66964 (r=0.758,p=0.600),  time:25.252, tt:757.566\n",
      "Ep:30, loss:0.00002, loss_test:0.01914, lr:5.59e-02, fs:0.66376 (r=0.768,p=0.585),  time:25.261, tt:783.091\n",
      "Ep:31, loss:0.00002, loss_test:0.01898, lr:5.59e-02, fs:0.67532 (r=0.788,p=0.591),  time:25.267, tt:808.539\n",
      "Ep:32, loss:0.00002, loss_test:0.01888, lr:5.59e-02, fs:0.68122 (r=0.788,p=0.600),  time:25.299, tt:834.881\n",
      "Ep:33, loss:0.00002, loss_test:0.01882, lr:5.59e-02, fs:0.68696 (r=0.798,p=0.603),  time:25.323, tt:860.969\n",
      "Ep:34, loss:0.00002, loss_test:0.01878, lr:5.59e-02, fs:0.68996 (r=0.798,p=0.608),  time:25.359, tt:887.569\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01867, lr:5.59e-02, fs:0.69869 (r=0.808,p=0.615),  time:25.368, tt:913.243\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01855, lr:5.59e-02, fs:0.70742 (r=0.818,p=0.623),  time:25.393, tt:939.540\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01842, lr:5.59e-02, fs:0.72414 (r=0.848,p=0.632),  time:25.424, tt:966.130\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01831, lr:5.59e-02, fs:0.72414 (r=0.848,p=0.632),  time:25.420, tt:991.385\n",
      "Ep:39, loss:0.00002, loss_test:0.01822, lr:5.59e-02, fs:0.72727 (r=0.848,p=0.636),  time:25.449, tt:1017.945\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01818, lr:5.59e-02, fs:0.73362 (r=0.848,p=0.646),  time:25.483, tt:1044.804\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01809, lr:5.59e-02, fs:0.74336 (r=0.848,p=0.661),  time:25.478, tt:1070.069\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01803, lr:5.59e-02, fs:0.75221 (r=0.859,p=0.669),  time:25.483, tt:1095.782\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01795, lr:5.59e-02, fs:0.75556 (r=0.859,p=0.675),  time:25.484, tt:1121.288\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00002, loss_test:0.01788, lr:5.59e-02, fs:0.75893 (r=0.859,p=0.680),  time:25.511, tt:1147.986\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01780, lr:5.59e-02, fs:0.75893 (r=0.859,p=0.680),  time:25.511, tt:1173.484\n",
      "Ep:46, loss:0.00002, loss_test:0.01777, lr:5.59e-02, fs:0.76577 (r=0.859,p=0.691),  time:25.506, tt:1198.780\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01768, lr:5.59e-02, fs:0.76233 (r=0.859,p=0.685),  time:25.523, tt:1225.127\n",
      "Ep:48, loss:0.00002, loss_test:0.01759, lr:5.59e-02, fs:0.76233 (r=0.859,p=0.685),  time:25.515, tt:1250.218\n",
      "Ep:49, loss:0.00002, loss_test:0.01759, lr:5.59e-02, fs:0.77273 (r=0.859,p=0.702),  time:25.548, tt:1277.404\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01755, lr:5.59e-02, fs:0.77273 (r=0.859,p=0.702),  time:25.550, tt:1303.032\n",
      "Ep:51, loss:0.00002, loss_test:0.01753, lr:5.59e-02, fs:0.77273 (r=0.859,p=0.702),  time:25.541, tt:1328.119\n",
      "Ep:52, loss:0.00002, loss_test:0.01748, lr:5.59e-02, fs:0.78378 (r=0.879,p=0.707),  time:25.618, tt:1357.765\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01741, lr:5.59e-02, fs:0.78924 (r=0.889,p=0.710),  time:25.627, tt:1383.843\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01737, lr:5.59e-02, fs:0.78924 (r=0.889,p=0.710),  time:25.631, tt:1409.724\n",
      "Ep:55, loss:0.00002, loss_test:0.01736, lr:5.59e-02, fs:0.79091 (r=0.879,p=0.719),  time:25.637, tt:1435.673\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01736, lr:5.59e-02, fs:0.79091 (r=0.879,p=0.719),  time:25.654, tt:1462.273\n",
      "Ep:57, loss:0.00001, loss_test:0.01731, lr:5.59e-02, fs:0.79091 (r=0.879,p=0.719),  time:25.674, tt:1489.108\n",
      "Ep:58, loss:0.00001, loss_test:0.01724, lr:5.59e-02, fs:0.79452 (r=0.879,p=0.725),  time:25.680, tt:1515.136\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01720, lr:5.59e-02, fs:0.78899 (r=0.869,p=0.723),  time:25.678, tt:1540.657\n",
      "Ep:60, loss:0.00001, loss_test:0.01724, lr:5.59e-02, fs:0.79263 (r=0.869,p=0.729),  time:25.700, tt:1567.707\n",
      "Ep:61, loss:0.00001, loss_test:0.01726, lr:5.59e-02, fs:0.79263 (r=0.869,p=0.729),  time:25.699, tt:1593.339\n",
      "Ep:62, loss:0.00001, loss_test:0.01726, lr:5.59e-02, fs:0.79263 (r=0.869,p=0.729),  time:25.712, tt:1619.826\n",
      "Ep:63, loss:0.00001, loss_test:0.01722, lr:5.59e-02, fs:0.79630 (r=0.869,p=0.735),  time:25.727, tt:1646.502\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01722, lr:5.59e-02, fs:0.79630 (r=0.869,p=0.735),  time:25.730, tt:1672.455\n",
      "Ep:65, loss:0.00001, loss_test:0.01719, lr:5.59e-02, fs:0.79630 (r=0.869,p=0.735),  time:25.746, tt:1699.237\n",
      "Ep:66, loss:0.00001, loss_test:0.01722, lr:5.59e-02, fs:0.79439 (r=0.859,p=0.739),  time:25.766, tt:1726.347\n",
      "Ep:67, loss:0.00001, loss_test:0.01725, lr:5.59e-02, fs:0.80000 (r=0.848,p=0.757),  time:25.757, tt:1751.476\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01728, lr:5.59e-02, fs:0.80769 (r=0.848,p=0.771),  time:25.751, tt:1776.815\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01726, lr:5.59e-02, fs:0.80583 (r=0.838,p=0.776),  time:25.746, tt:1802.199\n",
      "Ep:70, loss:0.00001, loss_test:0.01724, lr:5.59e-02, fs:0.80583 (r=0.838,p=0.776),  time:25.755, tt:1828.610\n",
      "Ep:71, loss:0.00001, loss_test:0.01723, lr:5.59e-02, fs:0.80583 (r=0.838,p=0.776),  time:25.744, tt:1853.569\n",
      "Ep:72, loss:0.00001, loss_test:0.01721, lr:5.59e-02, fs:0.80976 (r=0.838,p=0.783),  time:25.728, tt:1878.127\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01727, lr:5.59e-02, fs:0.80976 (r=0.838,p=0.783),  time:25.717, tt:1903.087\n",
      "Ep:74, loss:0.00001, loss_test:0.01732, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:25.718, tt:1928.863\n",
      "Ep:75, loss:0.00001, loss_test:0.01734, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:25.724, tt:1954.994\n",
      "Ep:76, loss:0.00001, loss_test:0.01739, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:25.741, tt:1982.020\n",
      "Ep:77, loss:0.00001, loss_test:0.01737, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:25.763, tt:2009.478\n",
      "Ep:78, loss:0.00001, loss_test:0.01741, lr:5.59e-02, fs:0.79803 (r=0.818,p=0.779),  time:25.794, tt:2037.719\n",
      "Ep:79, loss:0.00001, loss_test:0.01744, lr:5.59e-02, fs:0.79803 (r=0.818,p=0.779),  time:25.788, tt:2063.070\n",
      "Ep:80, loss:0.00001, loss_test:0.01744, lr:5.59e-02, fs:0.79803 (r=0.818,p=0.779),  time:25.776, tt:2087.837\n",
      "Ep:81, loss:0.00001, loss_test:0.01745, lr:5.59e-02, fs:0.79803 (r=0.818,p=0.779),  time:25.774, tt:2113.468\n",
      "Ep:82, loss:0.00001, loss_test:0.01753, lr:5.59e-02, fs:0.79602 (r=0.808,p=0.784),  time:25.757, tt:2137.791\n",
      "Ep:83, loss:0.00001, loss_test:0.01757, lr:5.59e-02, fs:0.79397 (r=0.798,p=0.790),  time:25.773, tt:2164.934\n",
      "Ep:84, loss:0.00001, loss_test:0.01758, lr:5.54e-02, fs:0.79397 (r=0.798,p=0.790),  time:25.764, tt:2189.911\n",
      "Ep:85, loss:0.00001, loss_test:0.01759, lr:5.48e-02, fs:0.79397 (r=0.798,p=0.790),  time:25.765, tt:2215.820\n",
      "Ep:86, loss:0.00001, loss_test:0.01756, lr:5.43e-02, fs:0.78788 (r=0.788,p=0.788),  time:25.764, tt:2241.443\n",
      "Ep:87, loss:0.00001, loss_test:0.01760, lr:5.37e-02, fs:0.78788 (r=0.788,p=0.788),  time:25.763, tt:2267.159\n",
      "Ep:88, loss:0.00001, loss_test:0.01767, lr:5.32e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.764, tt:2293.012\n",
      "Ep:89, loss:0.00001, loss_test:0.01768, lr:5.27e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.769, tt:2319.171\n",
      "Ep:90, loss:0.00001, loss_test:0.01776, lr:5.21e-02, fs:0.78974 (r=0.778,p=0.802),  time:25.766, tt:2344.690\n",
      "Ep:91, loss:0.00001, loss_test:0.01778, lr:5.16e-02, fs:0.78974 (r=0.778,p=0.802),  time:25.770, tt:2370.833\n",
      "Ep:92, loss:0.00001, loss_test:0.01780, lr:5.11e-02, fs:0.79381 (r=0.778,p=0.811),  time:25.767, tt:2396.357\n",
      "Ep:93, loss:0.00001, loss_test:0.01785, lr:5.06e-02, fs:0.79381 (r=0.778,p=0.811),  time:25.761, tt:2421.526\n",
      "Ep:94, loss:0.00001, loss_test:0.01786, lr:5.01e-02, fs:0.79381 (r=0.778,p=0.811),  time:25.749, tt:2446.121\n",
      "Ep:95, loss:0.00001, loss_test:0.01786, lr:4.96e-02, fs:0.78125 (r=0.758,p=0.806),  time:25.741, tt:2471.172\n",
      "Ep:96, loss:0.00001, loss_test:0.01789, lr:4.91e-02, fs:0.78125 (r=0.758,p=0.806),  time:25.737, tt:2496.519\n",
      "Ep:97, loss:0.00001, loss_test:0.01794, lr:4.86e-02, fs:0.78125 (r=0.758,p=0.806),  time:25.735, tt:2522.062\n",
      "Ep:98, loss:0.00001, loss_test:0.01795, lr:4.81e-02, fs:0.78534 (r=0.758,p=0.815),  time:25.740, tt:2548.253\n",
      "Ep:99, loss:0.00001, loss_test:0.01801, lr:4.76e-02, fs:0.77895 (r=0.747,p=0.813),  time:25.745, tt:2574.507\n",
      "Ep:100, loss:0.00001, loss_test:0.01802, lr:4.71e-02, fs:0.77660 (r=0.737,p=0.820),  time:25.742, tt:2599.928\n",
      "Ep:101, loss:0.00001, loss_test:0.01803, lr:4.67e-02, fs:0.77660 (r=0.737,p=0.820),  time:25.738, tt:2625.231\n",
      "Ep:102, loss:0.00001, loss_test:0.01806, lr:4.62e-02, fs:0.77005 (r=0.727,p=0.818),  time:25.729, tt:2650.093\n",
      "Ep:103, loss:0.00001, loss_test:0.01806, lr:4.57e-02, fs:0.77005 (r=0.727,p=0.818),  time:25.725, tt:2675.364\n",
      "Ep:104, loss:0.00001, loss_test:0.01807, lr:4.53e-02, fs:0.77005 (r=0.727,p=0.818),  time:25.731, tt:2701.724\n",
      "Ep:105, loss:0.00001, loss_test:0.01813, lr:4.48e-02, fs:0.75676 (r=0.707,p=0.814),  time:25.731, tt:2727.474\n",
      "Ep:106, loss:0.00001, loss_test:0.01823, lr:4.44e-02, fs:0.76087 (r=0.707,p=0.824),  time:25.728, tt:2752.925\n",
      "Ep:107, loss:0.00001, loss_test:0.01825, lr:4.39e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.727, tt:2778.464\n",
      "Ep:108, loss:0.00001, loss_test:0.01823, lr:4.35e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.725, tt:2804.015\n",
      "Ep:109, loss:0.00001, loss_test:0.01823, lr:4.31e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.723, tt:2829.518\n",
      "Ep:110, loss:0.00001, loss_test:0.01824, lr:4.26e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.720, tt:2854.931\n",
      "Ep:111, loss:0.00001, loss_test:0.01828, lr:4.22e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.732, tt:2881.991\n",
      "Ep:112, loss:0.00001, loss_test:0.01832, lr:4.18e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.736, tt:2908.204\n",
      "Ep:113, loss:0.00001, loss_test:0.01834, lr:4.14e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.725, tt:2932.664\n",
      "Ep:114, loss:0.00001, loss_test:0.01841, lr:4.10e-02, fs:0.74033 (r=0.677,p=0.817),  time:25.726, tt:2958.484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00001, loss_test:0.01846, lr:4.05e-02, fs:0.74033 (r=0.677,p=0.817),  time:25.728, tt:2984.467\n",
      "Ep:116, loss:0.00001, loss_test:0.01843, lr:4.01e-02, fs:0.74033 (r=0.677,p=0.817),  time:25.726, tt:3009.961\n",
      "Ep:117, loss:0.00001, loss_test:0.01843, lr:3.97e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.738, tt:3037.040\n",
      "Ep:118, loss:0.00001, loss_test:0.01847, lr:3.93e-02, fs:0.74725 (r=0.687,p=0.819),  time:25.746, tt:3063.806\n",
      "Ep:119, loss:0.00001, loss_test:0.01854, lr:3.89e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.736, tt:3088.365\n",
      "Ep:120, loss:0.00001, loss_test:0.01855, lr:3.86e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.743, tt:3114.868\n",
      "Ep:121, loss:0.00001, loss_test:0.01856, lr:3.82e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.748, tt:3141.271\n",
      "Ep:122, loss:0.00001, loss_test:0.01858, lr:3.78e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.739, tt:3165.842\n",
      "Ep:123, loss:0.00001, loss_test:0.01860, lr:3.74e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.737, tt:3191.361\n",
      "Ep:124, loss:0.00001, loss_test:0.01863, lr:3.70e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.727, tt:3215.836\n",
      "Ep:125, loss:0.00001, loss_test:0.01866, lr:3.67e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.725, tt:3241.342\n",
      "Ep:126, loss:0.00001, loss_test:0.01867, lr:3.63e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.732, tt:3267.962\n",
      "Ep:127, loss:0.00001, loss_test:0.01869, lr:3.59e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.728, tt:3293.144\n",
      "Ep:128, loss:0.00001, loss_test:0.01872, lr:3.56e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.728, tt:3318.920\n",
      "Ep:129, loss:0.00001, loss_test:0.01876, lr:3.52e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.724, tt:3344.107\n",
      "Ep:130, loss:0.00001, loss_test:0.01875, lr:3.49e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.746, tt:3372.731\n",
      "Ep:131, loss:0.00001, loss_test:0.01876, lr:3.45e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.752, tt:3399.238\n",
      "Ep:132, loss:0.00001, loss_test:0.01879, lr:3.42e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.746, tt:3424.221\n",
      "Ep:133, loss:0.00001, loss_test:0.01884, lr:3.38e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.746, tt:3449.926\n",
      "Ep:134, loss:0.00001, loss_test:0.01886, lr:3.35e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.746, tt:3475.684\n",
      "Ep:135, loss:0.00001, loss_test:0.01885, lr:3.32e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.746, tt:3501.477\n",
      "Ep:136, loss:0.00001, loss_test:0.01892, lr:3.28e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.751, tt:3527.915\n",
      "Ep:137, loss:0.00001, loss_test:0.01894, lr:3.25e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.742, tt:3552.411\n",
      "Ep:138, loss:0.00001, loss_test:0.01896, lr:3.22e-02, fs:0.73333 (r=0.667,p=0.815),  time:25.736, tt:3577.278\n",
      "Ep:139, loss:0.00001, loss_test:0.01898, lr:3.19e-02, fs:0.72626 (r=0.657,p=0.812),  time:25.716, tt:3600.194\n",
      "Ep:140, loss:0.00001, loss_test:0.01901, lr:3.15e-02, fs:0.72626 (r=0.657,p=0.812),  time:25.706, tt:3624.484\n",
      "Ep:141, loss:0.00001, loss_test:0.01901, lr:3.12e-02, fs:0.72626 (r=0.657,p=0.812),  time:25.697, tt:3648.980\n",
      "Ep:142, loss:0.00001, loss_test:0.01904, lr:3.09e-02, fs:0.72626 (r=0.657,p=0.812),  time:25.702, tt:3675.348\n",
      "Ep:143, loss:0.00001, loss_test:0.01907, lr:3.06e-02, fs:0.72626 (r=0.657,p=0.812),  time:25.704, tt:3701.307\n",
      "Ep:144, loss:0.00001, loss_test:0.01908, lr:3.03e-02, fs:0.72626 (r=0.657,p=0.812),  time:25.705, tt:3727.213\n",
      "Ep:145, loss:0.00001, loss_test:0.01909, lr:3.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.702, tt:3752.532\n",
      "Ep:146, loss:0.00001, loss_test:0.01912, lr:2.97e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.696, tt:3777.372\n",
      "Ep:147, loss:0.00001, loss_test:0.01916, lr:2.94e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.687, tt:3801.631\n",
      "Ep:148, loss:0.00001, loss_test:0.01920, lr:2.91e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.686, tt:3827.190\n",
      "Ep:149, loss:0.00001, loss_test:0.01921, lr:2.88e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.685, tt:3852.737\n",
      "Ep:150, loss:0.00001, loss_test:0.01918, lr:2.85e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.688, tt:3878.892\n",
      "Ep:151, loss:0.00001, loss_test:0.01919, lr:2.82e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.692, tt:3905.223\n",
      "Ep:152, loss:0.00001, loss_test:0.01920, lr:2.80e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.701, tt:3932.290\n",
      "Ep:153, loss:0.00001, loss_test:0.01922, lr:2.77e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.708, tt:3959.009\n",
      "Ep:154, loss:0.00001, loss_test:0.01923, lr:2.74e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.699, tt:3983.324\n",
      "Ep:155, loss:0.00001, loss_test:0.01924, lr:2.71e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.707, tt:4010.252\n",
      "Ep:156, loss:0.00001, loss_test:0.01927, lr:2.69e-02, fs:0.73034 (r=0.657,p=0.823),  time:25.725, tt:4038.775\n",
      "Ep:157, loss:0.00001, loss_test:0.01931, lr:2.66e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.732, tt:4065.625\n",
      "Ep:158, loss:0.00001, loss_test:0.01933, lr:2.63e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.718, tt:4089.099\n",
      "Ep:159, loss:0.00001, loss_test:0.01932, lr:2.61e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.715, tt:4114.440\n",
      "Ep:160, loss:0.00001, loss_test:0.01934, lr:2.58e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.704, tt:4138.292\n",
      "Ep:161, loss:0.00001, loss_test:0.01936, lr:2.55e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.705, tt:4164.232\n",
      "Ep:162, loss:0.00001, loss_test:0.01939, lr:2.53e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.707, tt:4190.298\n",
      "Ep:163, loss:0.00001, loss_test:0.01938, lr:2.50e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.701, tt:4214.989\n",
      "Ep:164, loss:0.00001, loss_test:0.01938, lr:2.48e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.704, tt:4241.228\n",
      "Ep:165, loss:0.00001, loss_test:0.01940, lr:2.45e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.701, tt:4266.423\n",
      "Ep:166, loss:0.00001, loss_test:0.01945, lr:2.43e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.699, tt:4291.734\n",
      "Ep:167, loss:0.00001, loss_test:0.01948, lr:2.40e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.701, tt:4317.809\n",
      "Ep:168, loss:0.00001, loss_test:0.01948, lr:2.38e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.701, tt:4343.552\n",
      "Ep:169, loss:0.00001, loss_test:0.01947, lr:2.36e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.704, tt:4369.652\n",
      "Ep:170, loss:0.00001, loss_test:0.01946, lr:2.33e-02, fs:0.72316 (r=0.646,p=0.821),  time:25.710, tt:4396.467\n",
      "Ep:171, loss:0.00001, loss_test:0.01951, lr:2.31e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.713, tt:4422.552\n",
      "Ep:172, loss:0.00001, loss_test:0.01953, lr:2.29e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.716, tt:4448.900\n",
      "Ep:173, loss:0.00001, loss_test:0.01953, lr:2.26e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.717, tt:4474.831\n",
      "Ep:174, loss:0.00000, loss_test:0.01954, lr:2.24e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.714, tt:4499.951\n",
      "Ep:175, loss:0.00000, loss_test:0.01954, lr:2.22e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.714, tt:4525.613\n",
      "Ep:176, loss:0.00000, loss_test:0.01954, lr:2.20e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.712, tt:4551.004\n",
      "Ep:177, loss:0.00000, loss_test:0.01955, lr:2.17e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.714, tt:4577.087\n",
      "Ep:178, loss:0.00000, loss_test:0.01959, lr:2.15e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.716, tt:4603.147\n",
      "Ep:179, loss:0.00000, loss_test:0.01962, lr:2.13e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.712, tt:4628.238\n",
      "Ep:180, loss:0.00000, loss_test:0.01963, lr:2.11e-02, fs:0.72727 (r=0.646,p=0.831),  time:25.712, tt:4653.929\n",
      "Ep:181, loss:0.00000, loss_test:0.01965, lr:2.09e-02, fs:0.72000 (r=0.636,p=0.829),  time:25.708, tt:4678.803\n",
      "Ep:182, loss:0.00000, loss_test:0.01967, lr:2.07e-02, fs:0.72000 (r=0.636,p=0.829),  time:25.719, tt:4706.570\n",
      "Ep:183, loss:0.00000, loss_test:0.01967, lr:2.05e-02, fs:0.72000 (r=0.636,p=0.829),  time:25.715, tt:4731.616\n",
      "Ep:184, loss:0.00000, loss_test:0.01968, lr:2.03e-02, fs:0.72000 (r=0.636,p=0.829),  time:25.719, tt:4758.055\n",
      "Ep:185, loss:0.00000, loss_test:0.01972, lr:2.01e-02, fs:0.72414 (r=0.636,p=0.840),  time:25.714, tt:4782.715\n",
      "Ep:186, loss:0.00000, loss_test:0.01973, lr:1.99e-02, fs:0.72414 (r=0.636,p=0.840),  time:25.715, tt:4808.778\n",
      "Ep:187, loss:0.00000, loss_test:0.01976, lr:1.97e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.711, tt:4833.707\n",
      "Ep:188, loss:0.00000, loss_test:0.01975, lr:1.95e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.710, tt:4859.134\n",
      "Ep:189, loss:0.00000, loss_test:0.01975, lr:1.93e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.707, tt:4884.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.01976, lr:1.91e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.705, tt:4909.734\n",
      "Ep:191, loss:0.00000, loss_test:0.01979, lr:1.89e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.704, tt:4935.256\n",
      "Ep:192, loss:0.00000, loss_test:0.01980, lr:1.87e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.701, tt:4960.204\n",
      "Ep:193, loss:0.00000, loss_test:0.01980, lr:1.85e-02, fs:0.72832 (r=0.636,p=0.851),  time:25.703, tt:4986.387\n",
      "Ep:194, loss:0.00000, loss_test:0.01981, lr:1.83e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.701, tt:5011.757\n",
      "Ep:195, loss:0.00000, loss_test:0.01984, lr:1.81e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.688, tt:5034.808\n",
      "Ep:196, loss:0.00000, loss_test:0.01987, lr:1.80e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.686, tt:5060.241\n",
      "Ep:197, loss:0.00000, loss_test:0.01988, lr:1.78e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.682, tt:5085.003\n",
      "Ep:198, loss:0.00000, loss_test:0.01988, lr:1.76e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.665, tt:5107.342\n",
      "Ep:199, loss:0.00000, loss_test:0.01988, lr:1.74e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.654, tt:5130.747\n",
      "Ep:200, loss:0.00000, loss_test:0.01989, lr:1.73e-02, fs:0.72093 (r=0.626,p=0.849),  time:25.653, tt:5156.212\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14632, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.658, tt:24.658\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14568, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.892, tt:49.783\n",
      "Ep:2, loss:0.00028, loss_test:0.14458, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.995, tt:74.986\n",
      "Ep:3, loss:0.00027, loss_test:0.14299, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:24.532, tt:98.127\n",
      "Ep:4, loss:0.00026, loss_test:0.14075, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:24.622, tt:123.110\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.13710, lr:1.00e-02, fs:0.61719 (r=0.798,p=0.503),  time:24.855, tt:149.129\n",
      "Ep:6, loss:0.00024, loss_test:0.13510, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:25.201, tt:176.408\n",
      "Ep:7, loss:0.00023, loss_test:0.13933, lr:1.00e-02, fs:0.61463 (r=0.636,p=0.594),  time:25.321, tt:202.569\n",
      "Ep:8, loss:0.00022, loss_test:0.14123, lr:1.00e-02, fs:0.60606 (r=0.606,p=0.606),  time:25.256, tt:227.308\n",
      "Ep:9, loss:0.00022, loss_test:0.13704, lr:1.00e-02, fs:0.61386 (r=0.626,p=0.602),  time:25.361, tt:253.608\n",
      "Ep:10, loss:0.00022, loss_test:0.13338, lr:1.00e-02, fs:0.62857 (r=0.667,p=0.595),  time:25.476, tt:280.235\n",
      "Ep:11, loss:0.00021, loss_test:0.13240, lr:1.00e-02, fs:0.62963 (r=0.687,p=0.581),  time:25.624, tt:307.482\n",
      "Ep:12, loss:0.00021, loss_test:0.13161, lr:1.00e-02, fs:0.63850 (r=0.687,p=0.596),  time:25.714, tt:334.281\n",
      "Ep:13, loss:0.00020, loss_test:0.13129, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:25.853, tt:361.942\n",
      "Ep:14, loss:0.00020, loss_test:0.13170, lr:1.00e-02, fs:0.62000 (r=0.626,p=0.614),  time:25.936, tt:389.033\n",
      "Ep:15, loss:0.00020, loss_test:0.13132, lr:1.00e-02, fs:0.58333 (r=0.566,p=0.602),  time:25.943, tt:415.087\n",
      "Ep:16, loss:0.00019, loss_test:0.13087, lr:9.90e-03, fs:0.57292 (r=0.556,p=0.591),  time:26.070, tt:443.182\n",
      "Ep:17, loss:0.00019, loss_test:0.13029, lr:9.80e-03, fs:0.58031 (r=0.566,p=0.596),  time:26.165, tt:470.977\n",
      "Ep:18, loss:0.00019, loss_test:0.12934, lr:9.70e-03, fs:0.57732 (r=0.566,p=0.589),  time:26.232, tt:498.404\n",
      "Ep:19, loss:0.00018, loss_test:0.12793, lr:9.61e-03, fs:0.57732 (r=0.566,p=0.589),  time:26.272, tt:525.443\n",
      "Ep:20, loss:0.00018, loss_test:0.12633, lr:9.51e-03, fs:0.56995 (r=0.556,p=0.585),  time:26.352, tt:553.382\n",
      "Ep:21, loss:0.00017, loss_test:0.12461, lr:9.41e-03, fs:0.59898 (r=0.596,p=0.602),  time:26.404, tt:580.896\n",
      "Ep:22, loss:0.00017, loss_test:0.12321, lr:9.32e-03, fs:0.61616 (r=0.616,p=0.616),  time:26.452, tt:608.399\n",
      "Ep:23, loss:0.00017, loss_test:0.12202, lr:9.23e-03, fs:0.62626 (r=0.626,p=0.626),  time:26.465, tt:635.164\n",
      "Ep:24, loss:0.00016, loss_test:0.12089, lr:9.14e-03, fs:0.63959 (r=0.636,p=0.643),  time:26.495, tt:662.383\n",
      "Ep:25, loss:0.00016, loss_test:0.11997, lr:9.04e-03, fs:0.65990 (r=0.657,p=0.663),  time:26.518, tt:689.474\n",
      "Ep:26, loss:0.00016, loss_test:0.11912, lr:8.95e-03, fs:0.66667 (r=0.667,p=0.667),  time:26.508, tt:715.714\n",
      "Ep:27, loss:0.00015, loss_test:0.11857, lr:8.86e-03, fs:0.66327 (r=0.657,p=0.670),  time:26.476, tt:741.337\n",
      "Ep:28, loss:0.00015, loss_test:0.11819, lr:8.78e-03, fs:0.66327 (r=0.657,p=0.670),  time:26.449, tt:767.009\n",
      "Ep:29, loss:0.00015, loss_test:0.11735, lr:8.69e-03, fs:0.67005 (r=0.667,p=0.673),  time:26.449, tt:793.464\n",
      "Ep:30, loss:0.00014, loss_test:0.11610, lr:8.60e-03, fs:0.69652 (r=0.707,p=0.686),  time:26.575, tt:823.831\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.11507, lr:8.60e-03, fs:0.70647 (r=0.717,p=0.696),  time:26.604, tt:851.316\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.11382, lr:8.60e-03, fs:0.71357 (r=0.717,p=0.710),  time:26.658, tt:879.700\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.11278, lr:8.60e-03, fs:0.72081 (r=0.717,p=0.724),  time:26.660, tt:906.433\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.11207, lr:8.60e-03, fs:0.73000 (r=0.737,p=0.723),  time:26.675, tt:933.622\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.11099, lr:8.60e-03, fs:0.73096 (r=0.727,p=0.735),  time:26.710, tt:961.544\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.11047, lr:8.60e-03, fs:0.72449 (r=0.717,p=0.732),  time:26.714, tt:988.420\n",
      "Ep:37, loss:0.00012, loss_test:0.10979, lr:8.60e-03, fs:0.73367 (r=0.737,p=0.730),  time:26.720, tt:1015.371\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.10853, lr:8.60e-03, fs:0.73096 (r=0.727,p=0.735),  time:26.701, tt:1041.329\n",
      "Ep:39, loss:0.00011, loss_test:0.10801, lr:8.60e-03, fs:0.74490 (r=0.737,p=0.753),  time:26.709, tt:1068.367\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.10705, lr:8.60e-03, fs:0.73096 (r=0.727,p=0.735),  time:26.665, tt:1093.244\n",
      "Ep:41, loss:0.00011, loss_test:0.10636, lr:8.60e-03, fs:0.73737 (r=0.737,p=0.737),  time:26.676, tt:1120.396\n",
      "Ep:42, loss:0.00011, loss_test:0.10470, lr:8.60e-03, fs:0.74490 (r=0.737,p=0.753),  time:26.652, tt:1146.034\n",
      "Ep:43, loss:0.00010, loss_test:0.10496, lr:8.60e-03, fs:0.73469 (r=0.727,p=0.742),  time:26.647, tt:1172.489\n",
      "Ep:44, loss:0.00010, loss_test:0.10397, lr:8.60e-03, fs:0.75862 (r=0.778,p=0.740),  time:26.667, tt:1200.019\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.10308, lr:8.60e-03, fs:0.74747 (r=0.747,p=0.747),  time:26.668, tt:1226.710\n",
      "Ep:46, loss:0.00010, loss_test:0.10277, lr:8.60e-03, fs:0.71204 (r=0.687,p=0.739),  time:26.664, tt:1253.218\n",
      "Ep:47, loss:0.00009, loss_test:0.10219, lr:8.60e-03, fs:0.74627 (r=0.758,p=0.735),  time:26.652, tt:1279.298\n",
      "Ep:48, loss:0.00009, loss_test:0.10068, lr:8.60e-03, fs:0.75377 (r=0.758,p=0.750),  time:26.653, tt:1306.013\n",
      "Ep:49, loss:0.00009, loss_test:0.10138, lr:8.60e-03, fs:0.73846 (r=0.727,p=0.750),  time:26.680, tt:1333.988\n",
      "Ep:50, loss:0.00009, loss_test:0.10023, lr:8.60e-03, fs:0.73846 (r=0.727,p=0.750),  time:26.719, tt:1362.677\n",
      "Ep:51, loss:0.00009, loss_test:0.09958, lr:8.60e-03, fs:0.73958 (r=0.717,p=0.763),  time:26.757, tt:1391.380\n",
      "Ep:52, loss:0.00008, loss_test:0.09968, lr:8.60e-03, fs:0.73958 (r=0.717,p=0.763),  time:26.750, tt:1417.772\n",
      "Ep:53, loss:0.00008, loss_test:0.09908, lr:8.60e-03, fs:0.73514 (r=0.687,p=0.791),  time:26.710, tt:1442.340\n",
      "Ep:54, loss:0.00008, loss_test:0.09821, lr:8.60e-03, fs:0.75393 (r=0.727,p=0.783),  time:26.717, tt:1469.442\n",
      "Ep:55, loss:0.00008, loss_test:0.09867, lr:8.60e-03, fs:0.72826 (r=0.677,p=0.788),  time:26.751, tt:1498.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00008, loss_test:0.09864, lr:8.51e-03, fs:0.72826 (r=0.677,p=0.788),  time:26.750, tt:1524.737\n",
      "Ep:57, loss:0.00007, loss_test:0.09895, lr:8.43e-03, fs:0.74737 (r=0.717,p=0.780),  time:26.765, tt:1552.354\n",
      "Ep:58, loss:0.00007, loss_test:0.09782, lr:8.35e-03, fs:0.73224 (r=0.677,p=0.798),  time:26.763, tt:1578.998\n",
      "Ep:59, loss:0.00007, loss_test:0.09628, lr:8.26e-03, fs:0.73224 (r=0.677,p=0.798),  time:26.756, tt:1605.360\n",
      "Ep:60, loss:0.00007, loss_test:0.09809, lr:8.18e-03, fs:0.73684 (r=0.707,p=0.769),  time:26.762, tt:1632.464\n",
      "Ep:61, loss:0.00007, loss_test:0.09499, lr:8.10e-03, fs:0.74860 (r=0.677,p=0.838),  time:26.771, tt:1659.776\n",
      "Ep:62, loss:0.00007, loss_test:0.09721, lr:8.02e-03, fs:0.73626 (r=0.677,p=0.807),  time:26.765, tt:1686.215\n",
      "Ep:63, loss:0.00006, loss_test:0.09750, lr:7.94e-03, fs:0.73797 (r=0.697,p=0.784),  time:26.775, tt:1713.582\n",
      "Ep:64, loss:0.00006, loss_test:0.09409, lr:7.86e-03, fs:0.74444 (r=0.677,p=0.827),  time:26.801, tt:1742.097\n",
      "Ep:65, loss:0.00006, loss_test:0.09760, lr:7.78e-03, fs:0.73743 (r=0.667,p=0.825),  time:26.814, tt:1769.714\n",
      "Ep:66, loss:0.00006, loss_test:0.09531, lr:7.70e-03, fs:0.74346 (r=0.717,p=0.772),  time:26.819, tt:1796.867\n",
      "Ep:67, loss:0.00006, loss_test:0.09420, lr:7.62e-03, fs:0.74576 (r=0.667,p=0.846),  time:26.816, tt:1823.456\n",
      "Ep:68, loss:0.00006, loss_test:0.09798, lr:7.55e-03, fs:0.73333 (r=0.667,p=0.815),  time:26.832, tt:1851.438\n",
      "Ep:69, loss:0.00006, loss_test:0.09571, lr:7.47e-03, fs:0.74346 (r=0.717,p=0.772),  time:26.843, tt:1879.005\n",
      "Ep:70, loss:0.00006, loss_test:0.09420, lr:7.40e-03, fs:0.73864 (r=0.657,p=0.844),  time:26.841, tt:1905.733\n",
      "Ep:71, loss:0.00006, loss_test:0.09907, lr:7.32e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.848, tt:1933.066\n",
      "Ep:72, loss:0.00006, loss_test:0.09484, lr:7.25e-03, fs:0.73514 (r=0.687,p=0.791),  time:26.850, tt:1960.046\n",
      "Ep:73, loss:0.00005, loss_test:0.09294, lr:7.18e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.852, tt:1987.075\n",
      "Ep:74, loss:0.00005, loss_test:0.09763, lr:7.11e-03, fs:0.73913 (r=0.687,p=0.800),  time:26.860, tt:2014.526\n",
      "Ep:75, loss:0.00005, loss_test:0.09599, lr:7.03e-03, fs:0.74444 (r=0.677,p=0.827),  time:26.859, tt:2041.299\n",
      "Ep:76, loss:0.00005, loss_test:0.09312, lr:6.96e-03, fs:0.73743 (r=0.667,p=0.825),  time:26.843, tt:2066.902\n",
      "Ep:77, loss:0.00005, loss_test:0.09601, lr:6.89e-03, fs:0.74595 (r=0.697,p=0.802),  time:26.829, tt:2092.628\n",
      "Ep:78, loss:0.00005, loss_test:0.09611, lr:6.83e-03, fs:0.74286 (r=0.657,p=0.855),  time:26.823, tt:2119.039\n",
      "Ep:79, loss:0.00005, loss_test:0.09333, lr:6.76e-03, fs:0.74317 (r=0.687,p=0.810),  time:26.826, tt:2146.094\n",
      "Ep:80, loss:0.00005, loss_test:0.09557, lr:6.69e-03, fs:0.74317 (r=0.687,p=0.810),  time:26.839, tt:2173.996\n",
      "Ep:81, loss:0.00005, loss_test:0.09395, lr:6.62e-03, fs:0.74157 (r=0.667,p=0.835),  time:26.845, tt:2201.285\n",
      "Ep:82, loss:0.00005, loss_test:0.09484, lr:6.56e-03, fs:0.75269 (r=0.707,p=0.805),  time:26.831, tt:2226.999\n",
      "Ep:83, loss:0.00005, loss_test:0.09549, lr:6.49e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.837, tt:2254.342\n",
      "Ep:84, loss:0.00005, loss_test:0.09448, lr:6.43e-03, fs:0.73034 (r=0.657,p=0.823),  time:26.832, tt:2280.681\n",
      "Ep:85, loss:0.00004, loss_test:0.09346, lr:6.36e-03, fs:0.75676 (r=0.707,p=0.814),  time:26.838, tt:2308.064\n",
      "Ep:86, loss:0.00004, loss_test:0.09551, lr:6.30e-03, fs:0.71910 (r=0.646,p=0.810),  time:26.853, tt:2336.183\n",
      "Ep:87, loss:0.00004, loss_test:0.09392, lr:6.24e-03, fs:0.73034 (r=0.657,p=0.823),  time:26.857, tt:2363.395\n",
      "Ep:88, loss:0.00004, loss_test:0.09202, lr:6.17e-03, fs:0.76344 (r=0.717,p=0.816),  time:26.869, tt:2391.354\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.09554, lr:6.17e-03, fs:0.71910 (r=0.646,p=0.810),  time:26.869, tt:2418.229\n",
      "Ep:90, loss:0.00004, loss_test:0.09603, lr:6.17e-03, fs:0.71591 (r=0.636,p=0.818),  time:26.875, tt:2445.604\n",
      "Ep:91, loss:0.00004, loss_test:0.09331, lr:6.17e-03, fs:0.76344 (r=0.717,p=0.816),  time:26.875, tt:2472.477\n",
      "Ep:92, loss:0.00004, loss_test:0.09442, lr:6.17e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.861, tt:2498.028\n",
      "Ep:93, loss:0.00004, loss_test:0.09519, lr:6.17e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.867, tt:2525.543\n",
      "Ep:94, loss:0.00004, loss_test:0.09378, lr:6.17e-03, fs:0.74317 (r=0.687,p=0.810),  time:26.866, tt:2552.313\n",
      "Ep:95, loss:0.00004, loss_test:0.09488, lr:6.17e-03, fs:0.71591 (r=0.636,p=0.818),  time:26.876, tt:2580.119\n",
      "Ep:96, loss:0.00004, loss_test:0.09539, lr:6.17e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.889, tt:2608.267\n",
      "Ep:97, loss:0.00004, loss_test:0.09245, lr:6.17e-03, fs:0.72928 (r=0.667,p=0.805),  time:26.889, tt:2635.079\n",
      "Ep:98, loss:0.00004, loss_test:0.09490, lr:6.17e-03, fs:0.71591 (r=0.636,p=0.818),  time:26.885, tt:2661.602\n",
      "Ep:99, loss:0.00004, loss_test:0.09639, lr:6.17e-03, fs:0.72414 (r=0.636,p=0.840),  time:26.884, tt:2688.414\n",
      "Ep:100, loss:0.00004, loss_test:0.09272, lr:6.11e-03, fs:0.72928 (r=0.667,p=0.805),  time:26.868, tt:2713.686\n",
      "Ep:101, loss:0.00004, loss_test:0.09499, lr:6.05e-03, fs:0.72928 (r=0.667,p=0.805),  time:26.878, tt:2741.553\n",
      "Ep:102, loss:0.00004, loss_test:0.09523, lr:5.99e-03, fs:0.72414 (r=0.636,p=0.840),  time:26.886, tt:2769.207\n",
      "Ep:103, loss:0.00004, loss_test:0.09391, lr:5.93e-03, fs:0.71591 (r=0.636,p=0.818),  time:26.882, tt:2795.772\n",
      "Ep:104, loss:0.00004, loss_test:0.09558, lr:5.87e-03, fs:0.71508 (r=0.646,p=0.800),  time:26.905, tt:2824.982\n",
      "Ep:105, loss:0.00004, loss_test:0.09323, lr:5.81e-03, fs:0.72316 (r=0.646,p=0.821),  time:26.899, tt:2851.292\n",
      "Ep:106, loss:0.00003, loss_test:0.09457, lr:5.75e-03, fs:0.72832 (r=0.636,p=0.851),  time:26.894, tt:2877.690\n",
      "Ep:107, loss:0.00003, loss_test:0.09549, lr:5.70e-03, fs:0.72222 (r=0.657,p=0.802),  time:26.892, tt:2904.314\n",
      "Ep:108, loss:0.00003, loss_test:0.09276, lr:5.64e-03, fs:0.73034 (r=0.657,p=0.823),  time:26.906, tt:2932.706\n",
      "Ep:109, loss:0.00003, loss_test:0.09640, lr:5.58e-03, fs:0.71186 (r=0.636,p=0.808),  time:26.913, tt:2960.413\n",
      "Ep:110, loss:0.00003, loss_test:0.09480, lr:5.53e-03, fs:0.71591 (r=0.636,p=0.818),  time:26.917, tt:2987.836\n",
      "Ep:111, loss:0.00003, loss_test:0.09372, lr:5.47e-03, fs:0.72222 (r=0.657,p=0.802),  time:26.910, tt:3013.895\n",
      "Ep:112, loss:0.00003, loss_test:0.09611, lr:5.42e-03, fs:0.71186 (r=0.636,p=0.808),  time:26.901, tt:3039.829\n",
      "Ep:113, loss:0.00003, loss_test:0.09454, lr:5.36e-03, fs:0.72000 (r=0.636,p=0.829),  time:26.905, tt:3067.184\n",
      "Ep:114, loss:0.00003, loss_test:0.09375, lr:5.31e-03, fs:0.72626 (r=0.657,p=0.812),  time:26.902, tt:3093.700\n",
      "Ep:115, loss:0.00003, loss_test:0.09580, lr:5.26e-03, fs:0.71186 (r=0.636,p=0.808),  time:26.905, tt:3120.951\n",
      "Ep:116, loss:0.00003, loss_test:0.09408, lr:5.20e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.903, tt:3147.629\n",
      "Ep:117, loss:0.00003, loss_test:0.09445, lr:5.15e-03, fs:0.71508 (r=0.646,p=0.800),  time:26.898, tt:3173.944\n",
      "Ep:118, loss:0.00003, loss_test:0.09536, lr:5.10e-03, fs:0.72000 (r=0.636,p=0.829),  time:26.899, tt:3200.947\n",
      "Ep:119, loss:0.00003, loss_test:0.09432, lr:5.05e-03, fs:0.73034 (r=0.657,p=0.823),  time:26.901, tt:3228.093\n",
      "Ep:120, loss:0.00003, loss_test:0.09524, lr:5.00e-03, fs:0.72316 (r=0.646,p=0.821),  time:26.891, tt:3253.765\n",
      "Ep:121, loss:0.00003, loss_test:0.09438, lr:4.95e-03, fs:0.73034 (r=0.657,p=0.823),  time:26.884, tt:3279.817\n",
      "Ep:122, loss:0.00003, loss_test:0.09452, lr:4.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.888, tt:3307.196\n",
      "Ep:123, loss:0.00003, loss_test:0.09516, lr:4.85e-03, fs:0.72626 (r=0.657,p=0.812),  time:26.893, tt:3334.771\n",
      "Ep:124, loss:0.00003, loss_test:0.09396, lr:4.80e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.900, tt:3362.486\n",
      "Ep:125, loss:0.00003, loss_test:0.09523, lr:4.75e-03, fs:0.72000 (r=0.636,p=0.829),  time:26.901, tt:3389.495\n",
      "Ep:126, loss:0.00003, loss_test:0.09473, lr:4.71e-03, fs:0.73864 (r=0.657,p=0.844),  time:26.915, tt:3418.229\n",
      "Ep:127, loss:0.00003, loss_test:0.09406, lr:4.66e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.916, tt:3445.255\n",
      "Ep:128, loss:0.00003, loss_test:0.09535, lr:4.61e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.912, tt:3471.658\n",
      "Ep:129, loss:0.00003, loss_test:0.09470, lr:4.57e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.945, tt:3502.815\n",
      "Ep:130, loss:0.00003, loss_test:0.09409, lr:4.52e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.937, tt:3528.802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00003, loss_test:0.09523, lr:4.48e-03, fs:0.72626 (r=0.657,p=0.812),  time:26.921, tt:3553.612\n",
      "Ep:132, loss:0.00003, loss_test:0.09419, lr:4.43e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.927, tt:3581.257\n",
      "Ep:133, loss:0.00003, loss_test:0.09460, lr:4.39e-03, fs:0.72414 (r=0.636,p=0.840),  time:26.933, tt:3609.081\n",
      "Ep:134, loss:0.00003, loss_test:0.09728, lr:4.34e-03, fs:0.72000 (r=0.636,p=0.829),  time:26.931, tt:3635.715\n",
      "Ep:135, loss:0.00003, loss_test:0.09506, lr:4.30e-03, fs:0.74286 (r=0.657,p=0.855),  time:26.932, tt:3662.795\n",
      "Ep:136, loss:0.00003, loss_test:0.09507, lr:4.26e-03, fs:0.73034 (r=0.657,p=0.823),  time:26.931, tt:3689.550\n",
      "Ep:137, loss:0.00003, loss_test:0.09601, lr:4.21e-03, fs:0.73143 (r=0.646,p=0.842),  time:26.929, tt:3716.178\n",
      "Ep:138, loss:0.00003, loss_test:0.09471, lr:4.17e-03, fs:0.73864 (r=0.657,p=0.844),  time:26.937, tt:3744.177\n",
      "Ep:139, loss:0.00003, loss_test:0.09559, lr:4.13e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.945, tt:3772.242\n",
      "Ep:140, loss:0.00003, loss_test:0.09544, lr:4.09e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.938, tt:3798.246\n",
      "Ep:141, loss:0.00003, loss_test:0.09584, lr:4.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.930, tt:3824.053\n",
      "Ep:142, loss:0.00003, loss_test:0.09503, lr:4.01e-03, fs:0.73446 (r=0.657,p=0.833),  time:26.941, tt:3852.564\n",
      "Ep:143, loss:0.00003, loss_test:0.09607, lr:3.97e-03, fs:0.73143 (r=0.646,p=0.842),  time:26.942, tt:3879.695\n",
      "Ep:144, loss:0.00002, loss_test:0.09582, lr:3.93e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.944, tt:3906.947\n",
      "Ep:145, loss:0.00002, loss_test:0.09485, lr:3.89e-03, fs:0.74286 (r=0.657,p=0.855),  time:26.945, tt:3933.915\n",
      "Ep:146, loss:0.00002, loss_test:0.09636, lr:3.85e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.943, tt:3960.665\n",
      "Ep:147, loss:0.00002, loss_test:0.09679, lr:3.81e-03, fs:0.72832 (r=0.636,p=0.851),  time:26.940, tt:3987.127\n",
      "Ep:148, loss:0.00002, loss_test:0.09414, lr:3.77e-03, fs:0.73864 (r=0.657,p=0.844),  time:26.930, tt:4012.501\n",
      "Ep:149, loss:0.00002, loss_test:0.09681, lr:3.73e-03, fs:0.72832 (r=0.636,p=0.851),  time:26.932, tt:4039.756\n",
      "Ep:150, loss:0.00002, loss_test:0.09794, lr:3.70e-03, fs:0.71345 (r=0.616,p=0.847),  time:26.935, tt:4067.198\n",
      "Ep:151, loss:0.00002, loss_test:0.09488, lr:3.66e-03, fs:0.74286 (r=0.657,p=0.855),  time:26.937, tt:4094.470\n",
      "Ep:152, loss:0.00002, loss_test:0.09626, lr:3.62e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.934, tt:4120.864\n",
      "Ep:153, loss:0.00002, loss_test:0.09709, lr:3.59e-03, fs:0.72832 (r=0.636,p=0.851),  time:26.934, tt:4147.895\n",
      "Ep:154, loss:0.00002, loss_test:0.09583, lr:3.55e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.945, tt:4176.542\n",
      "Ep:155, loss:0.00002, loss_test:0.09629, lr:3.52e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.951, tt:4204.349\n",
      "Ep:156, loss:0.00002, loss_test:0.09745, lr:3.48e-03, fs:0.72093 (r=0.626,p=0.849),  time:26.958, tt:4232.461\n",
      "Ep:157, loss:0.00002, loss_test:0.09553, lr:3.45e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.959, tt:4259.582\n",
      "Ep:158, loss:0.00002, loss_test:0.09610, lr:3.41e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.964, tt:4287.333\n",
      "Ep:159, loss:0.00002, loss_test:0.09623, lr:3.38e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.959, tt:4313.364\n",
      "Ep:160, loss:0.00002, loss_test:0.09660, lr:3.34e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.956, tt:4339.988\n",
      "Ep:161, loss:0.00002, loss_test:0.09645, lr:3.31e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.950, tt:4365.893\n",
      "Ep:162, loss:0.00002, loss_test:0.09625, lr:3.28e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.954, tt:4393.467\n",
      "Ep:163, loss:0.00002, loss_test:0.09584, lr:3.24e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.956, tt:4420.810\n",
      "Ep:164, loss:0.00002, loss_test:0.09640, lr:3.21e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.962, tt:4448.721\n",
      "Ep:165, loss:0.00002, loss_test:0.09672, lr:3.18e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.968, tt:4476.697\n",
      "Ep:166, loss:0.00002, loss_test:0.09586, lr:3.15e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.967, tt:4503.557\n",
      "Ep:167, loss:0.00002, loss_test:0.09643, lr:3.12e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.966, tt:4530.276\n",
      "Ep:168, loss:0.00002, loss_test:0.09660, lr:3.09e-03, fs:0.73988 (r=0.646,p=0.865),  time:26.961, tt:4556.463\n",
      "Ep:169, loss:0.00002, loss_test:0.09615, lr:3.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.962, tt:4583.547\n",
      "Ep:170, loss:0.00002, loss_test:0.09666, lr:3.02e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.965, tt:4610.933\n",
      "Ep:171, loss:0.00002, loss_test:0.09654, lr:2.99e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.971, tt:4638.935\n",
      "Ep:172, loss:0.00002, loss_test:0.09606, lr:2.96e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.975, tt:4666.719\n",
      "Ep:173, loss:0.00002, loss_test:0.09677, lr:2.93e-03, fs:0.73988 (r=0.646,p=0.865),  time:26.969, tt:4692.654\n",
      "Ep:174, loss:0.00002, loss_test:0.09654, lr:2.90e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.967, tt:4719.152\n",
      "Ep:175, loss:0.00002, loss_test:0.09609, lr:2.88e-03, fs:0.73563 (r=0.646,p=0.853),  time:26.961, tt:4745.149\n",
      "Ep:176, loss:0.00002, loss_test:0.09710, lr:2.85e-03, fs:0.72832 (r=0.636,p=0.851),  time:26.957, tt:4771.439\n",
      "Ep:177, loss:0.00002, loss_test:0.09679, lr:2.82e-03, fs:0.73988 (r=0.646,p=0.865),  time:26.972, tt:4801.005\n",
      "Ep:178, loss:0.00002, loss_test:0.09577, lr:2.79e-03, fs:0.75145 (r=0.657,p=0.878),  time:26.972, tt:4827.961\n",
      "Ep:179, loss:0.00002, loss_test:0.09701, lr:2.76e-03, fs:0.72832 (r=0.636,p=0.851),  time:26.959, tt:4852.563\n",
      "Ep:180, loss:0.00002, loss_test:0.09701, lr:2.73e-03, fs:0.73256 (r=0.636,p=0.863),  time:26.946, tt:4877.299\n",
      "Ep:181, loss:0.00002, loss_test:0.09622, lr:2.71e-03, fs:0.73988 (r=0.646,p=0.865),  time:26.941, tt:4903.291\n",
      "Ep:182, loss:0.00002, loss_test:0.09640, lr:2.68e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.940, tt:4929.969\n",
      "Ep:183, loss:0.00002, loss_test:0.09737, lr:2.65e-03, fs:0.73256 (r=0.636,p=0.863),  time:26.934, tt:4955.816\n",
      "Ep:184, loss:0.00002, loss_test:0.09682, lr:2.63e-03, fs:0.73988 (r=0.646,p=0.865),  time:26.946, tt:4985.087\n",
      "Ep:185, loss:0.00002, loss_test:0.09650, lr:2.60e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.944, tt:5011.512\n",
      "Ep:186, loss:0.00002, loss_test:0.09731, lr:2.57e-03, fs:0.73256 (r=0.636,p=0.863),  time:26.943, tt:5038.371\n",
      "Ep:187, loss:0.00002, loss_test:0.09664, lr:2.55e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.949, tt:5066.427\n",
      "Ep:188, loss:0.00002, loss_test:0.09637, lr:2.52e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.954, tt:5094.391\n",
      "Ep:189, loss:0.00002, loss_test:0.09747, lr:2.50e-03, fs:0.73684 (r=0.636,p=0.875),  time:26.960, tt:5122.339\n",
      "Ep:190, loss:0.00002, loss_test:0.09708, lr:2.47e-03, fs:0.73684 (r=0.636,p=0.875),  time:26.962, tt:5149.658\n",
      "Ep:191, loss:0.00002, loss_test:0.09613, lr:2.45e-03, fs:0.75145 (r=0.657,p=0.878),  time:26.963, tt:5176.945\n",
      "Ep:192, loss:0.00002, loss_test:0.09701, lr:2.42e-03, fs:0.73684 (r=0.636,p=0.875),  time:26.966, tt:5204.443\n",
      "Ep:193, loss:0.00002, loss_test:0.09749, lr:2.40e-03, fs:0.73684 (r=0.636,p=0.875),  time:26.969, tt:5232.078\n",
      "Ep:194, loss:0.00002, loss_test:0.09635, lr:2.38e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.977, tt:5260.453\n",
      "Ep:195, loss:0.00002, loss_test:0.09662, lr:2.35e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.966, tt:5285.284\n",
      "Ep:196, loss:0.00002, loss_test:0.09752, lr:2.33e-03, fs:0.73684 (r=0.636,p=0.875),  time:26.948, tt:5308.847\n",
      "Ep:197, loss:0.00002, loss_test:0.09702, lr:2.31e-03, fs:0.74118 (r=0.636,p=0.887),  time:26.932, tt:5332.574\n",
      "Ep:198, loss:0.00002, loss_test:0.09656, lr:2.28e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.920, tt:5357.002\n",
      "Ep:199, loss:0.00002, loss_test:0.09702, lr:2.26e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.904, tt:5380.768\n",
      "Ep:200, loss:0.00002, loss_test:0.09671, lr:2.24e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.889, tt:5404.763\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02615, lr:6.00e-02, fs:0.62698 (r=0.798,p=0.516),  time:29.824, tt:29.824\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02610, lr:6.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:29.510, tt:59.020\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02736, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.623, tt:91.869\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02743, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.963, tt:123.851\n",
      "Ep:4, loss:0.00005, loss_test:0.02682, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:31.116, tt:155.581\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02568, lr:6.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:31.497, tt:188.981\n",
      "Ep:6, loss:0.00005, loss_test:0.02480, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:31.918, tt:223.428\n",
      "Ep:7, loss:0.00004, loss_test:0.02488, lr:6.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:32.500, tt:260.003\n",
      "Ep:8, loss:0.00004, loss_test:0.02549, lr:6.00e-02, fs:0.61983 (r=0.758,p=0.524),  time:32.769, tt:294.922\n",
      "Ep:9, loss:0.00004, loss_test:0.02549, lr:6.00e-02, fs:0.62555 (r=0.717,p=0.555),  time:33.000, tt:329.997\n",
      "Ep:10, loss:0.00004, loss_test:0.02442, lr:6.00e-02, fs:0.60987 (r=0.687,p=0.548),  time:33.477, tt:368.244\n",
      "Ep:11, loss:0.00004, loss_test:0.02335, lr:6.00e-02, fs:0.63677 (r=0.717,p=0.573),  time:33.684, tt:404.204\n",
      "Ep:12, loss:0.00004, loss_test:0.02268, lr:6.00e-02, fs:0.62832 (r=0.717,p=0.559),  time:33.855, tt:440.110\n",
      "Ep:13, loss:0.00003, loss_test:0.02231, lr:6.00e-02, fs:0.62281 (r=0.717,p=0.550),  time:33.850, tt:473.901\n",
      "Ep:14, loss:0.00003, loss_test:0.02218, lr:6.00e-02, fs:0.64602 (r=0.737,p=0.575),  time:33.934, tt:509.015\n",
      "Ep:15, loss:0.00003, loss_test:0.02193, lr:6.00e-02, fs:0.65179 (r=0.737,p=0.584),  time:34.000, tt:543.998\n",
      "Ep:16, loss:0.00003, loss_test:0.02145, lr:5.94e-02, fs:0.65179 (r=0.737,p=0.584),  time:34.042, tt:578.721\n",
      "Ep:17, loss:0.00003, loss_test:0.02093, lr:5.88e-02, fs:0.66372 (r=0.758,p=0.591),  time:33.990, tt:611.828\n",
      "Ep:18, loss:0.00003, loss_test:0.02042, lr:5.82e-02, fs:0.66667 (r=0.758,p=0.595),  time:34.064, tt:647.208\n",
      "Ep:19, loss:0.00003, loss_test:0.02013, lr:5.76e-02, fs:0.67265 (r=0.758,p=0.605),  time:34.110, tt:682.194\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01986, lr:5.76e-02, fs:0.67873 (r=0.758,p=0.615),  time:34.190, tt:717.998\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01959, lr:5.76e-02, fs:0.66667 (r=0.737,p=0.608),  time:34.224, tt:752.918\n",
      "Ep:22, loss:0.00003, loss_test:0.01937, lr:5.76e-02, fs:0.66667 (r=0.727,p=0.615),  time:34.281, tt:788.458\n",
      "Ep:23, loss:0.00003, loss_test:0.01921, lr:5.76e-02, fs:0.64789 (r=0.697,p=0.605),  time:34.307, tt:823.370\n",
      "Ep:24, loss:0.00003, loss_test:0.01904, lr:5.76e-02, fs:0.67281 (r=0.737,p=0.619),  time:34.392, tt:859.789\n",
      "Ep:25, loss:0.00003, loss_test:0.01883, lr:5.76e-02, fs:0.68203 (r=0.747,p=0.627),  time:34.363, tt:893.440\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01866, lr:5.76e-02, fs:0.69406 (r=0.768,p=0.633),  time:34.344, tt:927.288\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01862, lr:5.76e-02, fs:0.68519 (r=0.747,p=0.632),  time:34.338, tt:961.461\n",
      "Ep:28, loss:0.00002, loss_test:0.01856, lr:5.76e-02, fs:0.69444 (r=0.758,p=0.641),  time:34.289, tt:994.384\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01860, lr:5.76e-02, fs:0.69444 (r=0.758,p=0.641),  time:34.328, tt:1029.836\n",
      "Ep:30, loss:0.00002, loss_test:0.01851, lr:5.76e-02, fs:0.69725 (r=0.768,p=0.639),  time:34.331, tt:1064.251\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01845, lr:5.76e-02, fs:0.69725 (r=0.768,p=0.639),  time:34.367, tt:1099.729\n",
      "Ep:32, loss:0.00002, loss_test:0.01850, lr:5.76e-02, fs:0.70698 (r=0.768,p=0.655),  time:34.399, tt:1135.163\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01844, lr:5.76e-02, fs:0.70698 (r=0.768,p=0.655),  time:34.386, tt:1169.133\n",
      "Ep:34, loss:0.00002, loss_test:0.01839, lr:5.76e-02, fs:0.70698 (r=0.768,p=0.655),  time:34.416, tt:1204.572\n",
      "Ep:35, loss:0.00002, loss_test:0.01839, lr:5.76e-02, fs:0.71963 (r=0.778,p=0.670),  time:34.464, tt:1240.688\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01838, lr:5.76e-02, fs:0.71963 (r=0.778,p=0.670),  time:34.505, tt:1276.668\n",
      "Ep:37, loss:0.00002, loss_test:0.01833, lr:5.76e-02, fs:0.71362 (r=0.768,p=0.667),  time:34.557, tt:1313.171\n",
      "Ep:38, loss:0.00002, loss_test:0.01835, lr:5.76e-02, fs:0.71698 (r=0.768,p=0.673),  time:34.557, tt:1347.730\n",
      "Ep:39, loss:0.00002, loss_test:0.01834, lr:5.76e-02, fs:0.72381 (r=0.768,p=0.685),  time:34.594, tt:1383.752\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01835, lr:5.76e-02, fs:0.73077 (r=0.768,p=0.697),  time:34.621, tt:1419.473\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01832, lr:5.76e-02, fs:0.73077 (r=0.768,p=0.697),  time:34.660, tt:1455.739\n",
      "Ep:42, loss:0.00002, loss_test:0.01828, lr:5.76e-02, fs:0.72727 (r=0.768,p=0.691),  time:34.657, tt:1490.269\n",
      "Ep:43, loss:0.00002, loss_test:0.01845, lr:5.76e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.668, tt:1525.376\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01851, lr:5.76e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.676, tt:1560.412\n",
      "Ep:45, loss:0.00002, loss_test:0.01841, lr:5.76e-02, fs:0.74038 (r=0.778,p=0.706),  time:34.701, tt:1596.264\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01865, lr:5.76e-02, fs:0.73077 (r=0.768,p=0.697),  time:34.688, tt:1630.313\n",
      "Ep:47, loss:0.00001, loss_test:0.01860, lr:5.76e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.701, tt:1665.649\n",
      "Ep:48, loss:0.00001, loss_test:0.01868, lr:5.76e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.760, tt:1703.264\n",
      "Ep:49, loss:0.00001, loss_test:0.01873, lr:5.76e-02, fs:0.73529 (r=0.758,p=0.714),  time:34.819, tt:1740.974\n",
      "Ep:50, loss:0.00001, loss_test:0.01869, lr:5.76e-02, fs:0.74757 (r=0.778,p=0.720),  time:34.836, tt:1776.616\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01886, lr:5.76e-02, fs:0.74396 (r=0.778,p=0.713),  time:34.801, tt:1809.674\n",
      "Ep:52, loss:0.00001, loss_test:0.01898, lr:5.76e-02, fs:0.75122 (r=0.778,p=0.726),  time:34.819, tt:1845.422\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01898, lr:5.76e-02, fs:0.74757 (r=0.778,p=0.720),  time:34.818, tt:1880.153\n",
      "Ep:54, loss:0.00001, loss_test:0.01919, lr:5.76e-02, fs:0.73529 (r=0.758,p=0.714),  time:34.834, tt:1915.848\n",
      "Ep:55, loss:0.00001, loss_test:0.01924, lr:5.76e-02, fs:0.75122 (r=0.778,p=0.726),  time:34.821, tt:1949.997\n",
      "Ep:56, loss:0.00001, loss_test:0.01944, lr:5.76e-02, fs:0.73892 (r=0.758,p=0.721),  time:34.836, tt:1985.673\n",
      "Ep:57, loss:0.00001, loss_test:0.01932, lr:5.76e-02, fs:0.75490 (r=0.778,p=0.733),  time:34.873, tt:2022.632\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01964, lr:5.76e-02, fs:0.74000 (r=0.747,p=0.733),  time:34.884, tt:2058.160\n",
      "Ep:59, loss:0.00001, loss_test:0.01969, lr:5.76e-02, fs:0.75758 (r=0.758,p=0.758),  time:34.910, tt:2094.573\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01992, lr:5.76e-02, fs:0.74490 (r=0.737,p=0.753),  time:34.911, tt:2129.576\n",
      "Ep:61, loss:0.00001, loss_test:0.02005, lr:5.76e-02, fs:0.73958 (r=0.717,p=0.763),  time:34.908, tt:2164.297\n",
      "Ep:62, loss:0.00001, loss_test:0.02011, lr:5.76e-02, fs:0.73298 (r=0.707,p=0.761),  time:34.931, tt:2200.669\n",
      "Ep:63, loss:0.00001, loss_test:0.02016, lr:5.76e-02, fs:0.75000 (r=0.727,p=0.774),  time:34.964, tt:2237.700\n",
      "Ep:64, loss:0.00001, loss_test:0.02049, lr:5.76e-02, fs:0.71658 (r=0.677,p=0.761),  time:34.949, tt:2271.704\n",
      "Ep:65, loss:0.00001, loss_test:0.02041, lr:5.76e-02, fs:0.71658 (r=0.677,p=0.761),  time:34.971, tt:2308.088\n",
      "Ep:66, loss:0.00001, loss_test:0.02063, lr:5.76e-02, fs:0.71658 (r=0.677,p=0.761),  time:35.003, tt:2345.183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.02088, lr:5.76e-02, fs:0.70968 (r=0.667,p=0.759),  time:35.021, tt:2381.458\n",
      "Ep:68, loss:0.00001, loss_test:0.02086, lr:5.76e-02, fs:0.70968 (r=0.667,p=0.759),  time:35.033, tt:2417.296\n",
      "Ep:69, loss:0.00001, loss_test:0.02129, lr:5.76e-02, fs:0.70270 (r=0.657,p=0.756),  time:35.049, tt:2453.421\n",
      "Ep:70, loss:0.00001, loss_test:0.02139, lr:5.76e-02, fs:0.70270 (r=0.657,p=0.756),  time:35.051, tt:2488.609\n",
      "Ep:71, loss:0.00001, loss_test:0.02152, lr:5.71e-02, fs:0.71038 (r=0.657,p=0.774),  time:35.075, tt:2525.412\n",
      "Ep:72, loss:0.00001, loss_test:0.02167, lr:5.65e-02, fs:0.70330 (r=0.646,p=0.771),  time:35.085, tt:2561.238\n",
      "Ep:73, loss:0.00001, loss_test:0.02192, lr:5.59e-02, fs:0.69613 (r=0.636,p=0.768),  time:35.097, tt:2597.149\n",
      "Ep:74, loss:0.00001, loss_test:0.02189, lr:5.54e-02, fs:0.69613 (r=0.636,p=0.768),  time:35.125, tt:2634.360\n",
      "Ep:75, loss:0.00001, loss_test:0.02238, lr:5.48e-02, fs:0.68539 (r=0.616,p=0.772),  time:35.120, tt:2669.149\n",
      "Ep:76, loss:0.00001, loss_test:0.02241, lr:5.43e-02, fs:0.68156 (r=0.616,p=0.762),  time:35.143, tt:2705.996\n",
      "Ep:77, loss:0.00001, loss_test:0.02270, lr:5.37e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.152, tt:2741.832\n",
      "Ep:78, loss:0.00001, loss_test:0.02274, lr:5.32e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.174, tt:2778.715\n",
      "Ep:79, loss:0.00001, loss_test:0.02298, lr:5.27e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.174, tt:2813.898\n",
      "Ep:80, loss:0.00001, loss_test:0.02309, lr:5.21e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.190, tt:2850.422\n",
      "Ep:81, loss:0.00001, loss_test:0.02353, lr:5.16e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.203, tt:2886.681\n",
      "Ep:82, loss:0.00001, loss_test:0.02314, lr:5.11e-02, fs:0.68539 (r=0.616,p=0.772),  time:35.213, tt:2922.652\n",
      "Ep:83, loss:0.00001, loss_test:0.02358, lr:5.06e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.221, tt:2958.527\n",
      "Ep:84, loss:0.00001, loss_test:0.02349, lr:5.01e-02, fs:0.68571 (r=0.606,p=0.789),  time:35.221, tt:2993.807\n",
      "Ep:85, loss:0.00001, loss_test:0.02408, lr:4.96e-02, fs:0.68182 (r=0.606,p=0.779),  time:35.236, tt:3030.282\n",
      "Ep:86, loss:0.00001, loss_test:0.02377, lr:4.91e-02, fs:0.67816 (r=0.596,p=0.787),  time:35.248, tt:3066.573\n",
      "Ep:87, loss:0.00001, loss_test:0.02441, lr:4.86e-02, fs:0.68571 (r=0.606,p=0.789),  time:35.279, tt:3104.534\n",
      "Ep:88, loss:0.00001, loss_test:0.02400, lr:4.81e-02, fs:0.67816 (r=0.596,p=0.787),  time:35.282, tt:3140.142\n",
      "Ep:89, loss:0.00001, loss_test:0.02434, lr:4.76e-02, fs:0.67816 (r=0.596,p=0.787),  time:35.297, tt:3176.722\n",
      "Ep:90, loss:0.00001, loss_test:0.02446, lr:4.71e-02, fs:0.67816 (r=0.596,p=0.787),  time:35.298, tt:3212.081\n",
      "Ep:91, loss:0.00001, loss_test:0.02480, lr:4.67e-02, fs:0.68208 (r=0.596,p=0.797),  time:35.312, tt:3248.659\n",
      "Ep:92, loss:0.00001, loss_test:0.02473, lr:4.62e-02, fs:0.68208 (r=0.596,p=0.797),  time:35.320, tt:3284.798\n",
      "Ep:93, loss:0.00001, loss_test:0.02495, lr:4.57e-02, fs:0.68208 (r=0.596,p=0.797),  time:35.326, tt:3320.613\n",
      "Ep:94, loss:0.00001, loss_test:0.02520, lr:4.53e-02, fs:0.68208 (r=0.596,p=0.797),  time:35.335, tt:3356.789\n",
      "Ep:95, loss:0.00001, loss_test:0.02527, lr:4.48e-02, fs:0.68605 (r=0.596,p=0.808),  time:35.351, tt:3393.705\n",
      "Ep:96, loss:0.00001, loss_test:0.02524, lr:4.44e-02, fs:0.67836 (r=0.586,p=0.806),  time:35.351, tt:3429.061\n",
      "Ep:97, loss:0.00001, loss_test:0.02568, lr:4.39e-02, fs:0.67836 (r=0.586,p=0.806),  time:35.367, tt:3465.920\n",
      "Ep:98, loss:0.00001, loss_test:0.02563, lr:4.35e-02, fs:0.67836 (r=0.586,p=0.806),  time:35.371, tt:3501.752\n",
      "Ep:99, loss:0.00001, loss_test:0.02602, lr:4.31e-02, fs:0.67836 (r=0.586,p=0.806),  time:35.378, tt:3537.848\n",
      "Ep:100, loss:0.00000, loss_test:0.02572, lr:4.26e-02, fs:0.67836 (r=0.586,p=0.806),  time:35.405, tt:3575.935\n",
      "Ep:101, loss:0.00000, loss_test:0.02636, lr:4.22e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.415, tt:3612.369\n",
      "Ep:102, loss:0.00000, loss_test:0.02592, lr:4.18e-02, fs:0.67836 (r=0.586,p=0.806),  time:35.410, tt:3647.213\n",
      "Ep:103, loss:0.00000, loss_test:0.02661, lr:4.14e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.409, tt:3682.560\n",
      "Ep:104, loss:0.00000, loss_test:0.02599, lr:4.10e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.395, tt:3716.460\n",
      "Ep:105, loss:0.00000, loss_test:0.02717, lr:4.05e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.407, tt:3753.192\n",
      "Ep:106, loss:0.00000, loss_test:0.02630, lr:4.01e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.428, tt:3790.842\n",
      "Ep:107, loss:0.00000, loss_test:0.02699, lr:3.97e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.429, tt:3826.285\n",
      "Ep:108, loss:0.00000, loss_test:0.02689, lr:3.93e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.435, tt:3862.377\n",
      "Ep:109, loss:0.00000, loss_test:0.02678, lr:3.89e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.432, tt:3897.531\n",
      "Ep:110, loss:0.00000, loss_test:0.02733, lr:3.86e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.438, tt:3933.574\n",
      "Ep:111, loss:0.00000, loss_test:0.02712, lr:3.82e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.449, tt:3970.277\n",
      "Ep:112, loss:0.00000, loss_test:0.02788, lr:3.78e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.454, tt:4006.323\n",
      "Ep:113, loss:0.00000, loss_test:0.02731, lr:3.74e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.453, tt:4041.625\n",
      "Ep:114, loss:0.00000, loss_test:0.02776, lr:3.70e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.462, tt:4078.124\n",
      "Ep:115, loss:0.00000, loss_test:0.02771, lr:3.67e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.472, tt:4114.756\n",
      "Ep:116, loss:0.00000, loss_test:0.02783, lr:3.63e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.470, tt:4149.959\n",
      "Ep:117, loss:0.00000, loss_test:0.02794, lr:3.59e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.467, tt:4185.125\n",
      "Ep:118, loss:0.00000, loss_test:0.02813, lr:3.56e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.474, tt:4221.388\n",
      "Ep:119, loss:0.00000, loss_test:0.02837, lr:3.52e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.495, tt:4259.459\n",
      "Ep:120, loss:0.00000, loss_test:0.02824, lr:3.49e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.510, tt:4296.665\n",
      "Ep:121, loss:0.00000, loss_test:0.02837, lr:3.45e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.516, tt:4332.949\n",
      "Ep:122, loss:0.00000, loss_test:0.02849, lr:3.42e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.524, tt:4369.400\n",
      "Ep:123, loss:0.00000, loss_test:0.02859, lr:3.38e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.522, tt:4404.703\n",
      "Ep:124, loss:0.00000, loss_test:0.02881, lr:3.35e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.518, tt:4439.778\n",
      "Ep:125, loss:0.00000, loss_test:0.02872, lr:3.32e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.503, tt:4473.348\n",
      "Ep:126, loss:0.00000, loss_test:0.02880, lr:3.28e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.511, tt:4509.888\n",
      "Ep:127, loss:0.00000, loss_test:0.02902, lr:3.25e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.520, tt:4546.575\n",
      "Ep:128, loss:0.00000, loss_test:0.02899, lr:3.22e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.526, tt:4582.835\n",
      "Ep:129, loss:0.00000, loss_test:0.02920, lr:3.19e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.523, tt:4617.930\n",
      "Ep:130, loss:0.00000, loss_test:0.02910, lr:3.15e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.548, tt:4656.776\n",
      "Ep:131, loss:0.00000, loss_test:0.02955, lr:3.12e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.543, tt:4691.623\n",
      "Ep:132, loss:0.00000, loss_test:0.02926, lr:3.09e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.525, tt:4724.878\n",
      "Ep:133, loss:0.00000, loss_test:0.02948, lr:3.06e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.532, tt:4761.229\n",
      "Ep:134, loss:0.00000, loss_test:0.02974, lr:3.03e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.539, tt:4797.773\n",
      "Ep:135, loss:0.00000, loss_test:0.02966, lr:3.00e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.549, tt:4834.657\n",
      "Ep:136, loss:0.00000, loss_test:0.02991, lr:2.97e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.537, tt:4868.529\n",
      "Ep:137, loss:0.00000, loss_test:0.02959, lr:2.94e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.545, tt:4905.279\n",
      "Ep:138, loss:0.00000, loss_test:0.03032, lr:2.91e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.547, tt:4941.054\n",
      "Ep:139, loss:0.00000, loss_test:0.02976, lr:2.88e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.570, tt:4979.869\n",
      "Ep:140, loss:0.00000, loss_test:0.03027, lr:2.85e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.578, tt:5016.517\n",
      "Ep:141, loss:0.00000, loss_test:0.03014, lr:2.82e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.577, tt:5051.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.03030, lr:2.80e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.582, tt:5088.220\n",
      "Ep:143, loss:0.00000, loss_test:0.03058, lr:2.77e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.588, tt:5124.630\n",
      "Ep:144, loss:0.00000, loss_test:0.03026, lr:2.74e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.594, tt:5161.135\n",
      "Ep:145, loss:0.00000, loss_test:0.03073, lr:2.71e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.609, tt:5198.906\n",
      "Ep:146, loss:0.00000, loss_test:0.03031, lr:2.69e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.605, tt:5233.964\n",
      "Ep:147, loss:0.00000, loss_test:0.03102, lr:2.66e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.610, tt:5270.208\n",
      "Ep:148, loss:0.00000, loss_test:0.03068, lr:2.63e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.601, tt:5304.589\n",
      "Ep:149, loss:0.00000, loss_test:0.03090, lr:2.61e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.609, tt:5341.356\n",
      "Ep:150, loss:0.00000, loss_test:0.03100, lr:2.58e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.604, tt:5376.250\n",
      "Ep:151, loss:0.00000, loss_test:0.03099, lr:2.55e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.597, tt:5410.789\n",
      "Ep:152, loss:0.00000, loss_test:0.03122, lr:2.53e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.600, tt:5446.780\n",
      "Ep:153, loss:0.00000, loss_test:0.03120, lr:2.50e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.599, tt:5482.182\n",
      "Ep:154, loss:0.00000, loss_test:0.03139, lr:2.48e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.593, tt:5516.897\n",
      "Ep:155, loss:0.00000, loss_test:0.03129, lr:2.45e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.589, tt:5551.929\n",
      "Ep:156, loss:0.00000, loss_test:0.03148, lr:2.43e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.589, tt:5587.536\n",
      "Ep:157, loss:0.00000, loss_test:0.03144, lr:2.40e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.589, tt:5623.081\n",
      "Ep:158, loss:0.00000, loss_test:0.03159, lr:2.38e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.584, tt:5657.817\n",
      "Ep:159, loss:0.00000, loss_test:0.03177, lr:2.36e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.597, tt:5695.530\n",
      "Ep:160, loss:0.00000, loss_test:0.03146, lr:2.33e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.590, tt:5729.924\n",
      "Ep:161, loss:0.00000, loss_test:0.03201, lr:2.31e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.592, tt:5765.934\n",
      "Ep:162, loss:0.00000, loss_test:0.03176, lr:2.29e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.598, tt:5802.526\n",
      "Ep:163, loss:0.00000, loss_test:0.03189, lr:2.26e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.594, tt:5837.448\n",
      "Ep:164, loss:0.00000, loss_test:0.03189, lr:2.24e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.602, tt:5874.408\n",
      "Ep:165, loss:0.00000, loss_test:0.03217, lr:2.22e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.592, tt:5908.231\n",
      "Ep:166, loss:0.00000, loss_test:0.03188, lr:2.20e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:5943.479\n",
      "Ep:167, loss:0.00000, loss_test:0.03233, lr:2.17e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.589, tt:5978.933\n",
      "Ep:168, loss:0.00000, loss_test:0.03203, lr:2.15e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:6014.684\n",
      "Ep:169, loss:0.00000, loss_test:0.03223, lr:2.13e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.598, tt:6051.603\n",
      "Ep:170, loss:0.00000, loss_test:0.03236, lr:2.11e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.594, tt:6086.643\n",
      "Ep:171, loss:0.00000, loss_test:0.03238, lr:2.09e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.597, tt:6122.632\n",
      "Ep:172, loss:0.00000, loss_test:0.03254, lr:2.07e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.586, tt:6156.422\n",
      "Ep:173, loss:0.00000, loss_test:0.03241, lr:2.05e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:6192.621\n",
      "Ep:174, loss:0.00000, loss_test:0.03267, lr:2.03e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.594, tt:6228.906\n",
      "Ep:175, loss:0.00000, loss_test:0.03260, lr:2.01e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.596, tt:6264.813\n",
      "Ep:176, loss:0.00000, loss_test:0.03264, lr:1.99e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.602, tt:6301.512\n",
      "Ep:177, loss:0.00000, loss_test:0.03284, lr:1.97e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:6335.065\n",
      "Ep:178, loss:0.00000, loss_test:0.03280, lr:1.95e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.597, tt:6371.800\n",
      "Ep:179, loss:0.00000, loss_test:0.03282, lr:1.93e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.599, tt:6407.779\n",
      "Ep:180, loss:0.00000, loss_test:0.03290, lr:1.91e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.599, tt:6443.355\n",
      "Ep:181, loss:0.00000, loss_test:0.03291, lr:1.89e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.594, tt:6478.118\n",
      "Ep:182, loss:0.00000, loss_test:0.03288, lr:1.87e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.597, tt:6514.193\n",
      "Ep:183, loss:0.00000, loss_test:0.03320, lr:1.85e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.597, tt:6549.886\n",
      "Ep:184, loss:0.00000, loss_test:0.03306, lr:1.83e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.587, tt:6583.680\n",
      "Ep:185, loss:0.00000, loss_test:0.03306, lr:1.81e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.588, tt:6619.278\n",
      "Ep:186, loss:0.00000, loss_test:0.03338, lr:1.80e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.586, tt:6654.510\n",
      "Ep:187, loss:0.00000, loss_test:0.03311, lr:1.78e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.588, tt:6690.465\n",
      "Ep:188, loss:0.00000, loss_test:0.03325, lr:1.76e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:6726.432\n",
      "Ep:189, loss:0.00000, loss_test:0.03340, lr:1.74e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.586, tt:6761.283\n",
      "Ep:190, loss:0.00000, loss_test:0.03326, lr:1.73e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.592, tt:6798.024\n",
      "Ep:191, loss:0.00000, loss_test:0.03333, lr:1.71e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.587, tt:6832.760\n",
      "Ep:192, loss:0.00000, loss_test:0.03356, lr:1.69e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:6868.802\n",
      "Ep:193, loss:0.00000, loss_test:0.03333, lr:1.67e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.591, tt:6904.677\n",
      "Ep:194, loss:0.00000, loss_test:0.03364, lr:1.66e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.601, tt:6942.100\n",
      "Ep:195, loss:0.00000, loss_test:0.03360, lr:1.64e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.607, tt:6978.935\n",
      "Ep:196, loss:0.00000, loss_test:0.03349, lr:1.62e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.602, tt:7013.537\n",
      "Ep:197, loss:0.00000, loss_test:0.03380, lr:1.61e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.591, tt:7046.940\n",
      "Ep:198, loss:0.00000, loss_test:0.03360, lr:1.59e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.596, tt:7083.702\n",
      "Ep:199, loss:0.00000, loss_test:0.03380, lr:1.58e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.596, tt:7119.215\n",
      "Ep:200, loss:0.00000, loss_test:0.03385, lr:1.56e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.598, tt:7155.286\n",
      "Ep:201, loss:0.00000, loss_test:0.03366, lr:1.54e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.590, tt:7189.196\n",
      "Ep:202, loss:0.00000, loss_test:0.03399, lr:1.53e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.584, tt:7223.564\n",
      "Ep:203, loss:0.00000, loss_test:0.03382, lr:1.51e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.580, tt:7258.348\n",
      "Ep:204, loss:0.00000, loss_test:0.03391, lr:1.50e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.548, tt:7287.339\n",
      "Ep:205, loss:0.00000, loss_test:0.03403, lr:1.48e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.543, tt:7321.832\n",
      "Ep:206, loss:0.00000, loss_test:0.03382, lr:1.47e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.537, tt:7356.141\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14273, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:36.014, tt:36.014\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13943, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:34.233, tt:68.467\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13515, lr:1.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:35.165, tt:105.494\n",
      "Ep:3, loss:0.00025, loss_test:0.13292, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:34.800, tt:139.198\n",
      "Ep:4, loss:0.00024, loss_test:0.13218, lr:1.00e-02, fs:0.64706 (r=0.778,p=0.554),  time:34.876, tt:174.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00024, loss_test:0.13147, lr:1.00e-02, fs:0.64912 (r=0.747,p=0.574),  time:35.023, tt:210.138\n",
      "Ep:6, loss:0.00023, loss_test:0.13055, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:35.324, tt:247.269\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.12724, lr:1.00e-02, fs:0.66055 (r=0.727,p=0.605),  time:35.405, tt:283.238\n",
      "Ep:8, loss:0.00021, loss_test:0.12516, lr:1.00e-02, fs:0.65714 (r=0.697,p=0.622),  time:35.413, tt:318.716\n",
      "Ep:9, loss:0.00021, loss_test:0.12349, lr:1.00e-02, fs:0.66029 (r=0.697,p=0.627),  time:35.512, tt:355.116\n",
      "Ep:10, loss:0.00020, loss_test:0.12241, lr:1.00e-02, fs:0.66667 (r=0.717,p=0.623),  time:35.582, tt:391.403\n",
      "Ep:11, loss:0.00019, loss_test:0.12231, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:35.513, tt:426.154\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.12135, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:35.624, tt:463.107\n",
      "Ep:13, loss:0.00018, loss_test:0.11885, lr:1.00e-02, fs:0.62687 (r=0.636,p=0.618),  time:35.577, tt:498.075\n",
      "Ep:14, loss:0.00017, loss_test:0.11710, lr:1.00e-02, fs:0.62312 (r=0.626,p=0.620),  time:35.597, tt:533.959\n",
      "Ep:15, loss:0.00017, loss_test:0.11501, lr:1.00e-02, fs:0.62626 (r=0.626,p=0.626),  time:35.526, tt:568.418\n",
      "Ep:16, loss:0.00016, loss_test:0.11285, lr:1.00e-02, fs:0.62312 (r=0.626,p=0.620),  time:35.542, tt:604.221\n",
      "Ep:17, loss:0.00016, loss_test:0.11068, lr:1.00e-02, fs:0.64000 (r=0.646,p=0.634),  time:35.505, tt:639.097\n",
      "Ep:18, loss:0.00015, loss_test:0.10920, lr:1.00e-02, fs:0.64583 (r=0.626,p=0.667),  time:35.480, tt:674.125\n",
      "Ep:19, loss:0.00015, loss_test:0.10858, lr:1.00e-02, fs:0.64322 (r=0.646,p=0.640),  time:35.531, tt:710.624\n",
      "Ep:20, loss:0.00014, loss_test:0.10796, lr:1.00e-02, fs:0.64583 (r=0.626,p=0.667),  time:35.497, tt:745.432\n",
      "Ep:21, loss:0.00014, loss_test:0.10658, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:35.491, tt:780.795\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.10569, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:35.551, tt:817.675\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.10526, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:35.556, tt:853.352\n",
      "Ep:24, loss:0.00013, loss_test:0.10560, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:35.480, tt:886.993\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.10448, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:35.432, tt:921.230\n",
      "Ep:26, loss:0.00012, loss_test:0.10449, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:35.405, tt:955.923\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.10368, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:35.359, tt:990.050\n",
      "Ep:28, loss:0.00011, loss_test:0.10436, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:35.369, tt:1025.697\n",
      "Ep:29, loss:0.00011, loss_test:0.10446, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:35.366, tt:1060.981\n",
      "Ep:30, loss:0.00010, loss_test:0.10308, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:35.385, tt:1096.941\n",
      "Ep:31, loss:0.00010, loss_test:0.10367, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:35.398, tt:1132.724\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.10137, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:35.418, tt:1168.786\n",
      "Ep:33, loss:0.00010, loss_test:0.10198, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:35.405, tt:1203.774\n",
      "Ep:34, loss:0.00009, loss_test:0.10101, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:35.414, tt:1239.490\n",
      "Ep:35, loss:0.00009, loss_test:0.09748, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:35.435, tt:1275.665\n",
      "Ep:36, loss:0.00009, loss_test:0.10028, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:35.423, tt:1310.654\n",
      "Ep:37, loss:0.00008, loss_test:0.09741, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:35.444, tt:1346.869\n",
      "Ep:38, loss:0.00009, loss_test:0.10033, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:35.449, tt:1382.513\n",
      "Ep:39, loss:0.00009, loss_test:0.09715, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:35.426, tt:1417.040\n",
      "Ep:40, loss:0.00008, loss_test:0.10068, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:35.469, tt:1454.247\n",
      "Ep:41, loss:0.00008, loss_test:0.09935, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:35.477, tt:1490.030\n",
      "Ep:42, loss:0.00007, loss_test:0.09644, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:35.496, tt:1526.347\n",
      "Ep:43, loss:0.00007, loss_test:0.10105, lr:9.90e-03, fs:0.72727 (r=0.768,p=0.691),  time:35.529, tt:1563.258\n",
      "Ep:44, loss:0.00007, loss_test:0.09554, lr:9.80e-03, fs:0.71277 (r=0.677,p=0.753),  time:35.520, tt:1598.381\n",
      "Ep:45, loss:0.00007, loss_test:0.09914, lr:9.70e-03, fs:0.70707 (r=0.707,p=0.707),  time:35.512, tt:1633.572\n",
      "Ep:46, loss:0.00006, loss_test:0.09700, lr:9.61e-03, fs:0.71204 (r=0.687,p=0.739),  time:35.540, tt:1670.393\n",
      "Ep:47, loss:0.00006, loss_test:0.10023, lr:9.51e-03, fs:0.70000 (r=0.707,p=0.693),  time:35.574, tt:1707.568\n",
      "Ep:48, loss:0.00006, loss_test:0.09977, lr:9.41e-03, fs:0.72340 (r=0.687,p=0.764),  time:35.594, tt:1744.104\n",
      "Ep:49, loss:0.00006, loss_test:0.09921, lr:9.32e-03, fs:0.69841 (r=0.667,p=0.733),  time:35.593, tt:1779.674\n",
      "Ep:50, loss:0.00006, loss_test:0.09943, lr:9.23e-03, fs:0.71066 (r=0.707,p=0.714),  time:35.642, tt:1817.725\n",
      "Ep:51, loss:0.00006, loss_test:0.09869, lr:9.14e-03, fs:0.70270 (r=0.657,p=0.756),  time:35.682, tt:1855.476\n",
      "Ep:52, loss:0.00006, loss_test:0.09932, lr:9.04e-03, fs:0.69388 (r=0.687,p=0.701),  time:35.675, tt:1890.763\n",
      "Ep:53, loss:0.00005, loss_test:0.09975, lr:8.95e-03, fs:0.70968 (r=0.667,p=0.759),  time:35.704, tt:1928.042\n",
      "Ep:54, loss:0.00005, loss_test:0.10005, lr:8.86e-03, fs:0.68394 (r=0.667,p=0.702),  time:35.715, tt:1964.338\n",
      "Ep:55, loss:0.00005, loss_test:0.09787, lr:8.78e-03, fs:0.69841 (r=0.667,p=0.733),  time:35.710, tt:1999.762\n",
      "Ep:56, loss:0.00005, loss_test:0.10116, lr:8.69e-03, fs:0.69519 (r=0.657,p=0.739),  time:35.701, tt:2034.966\n",
      "Ep:57, loss:0.00005, loss_test:0.09816, lr:8.60e-03, fs:0.69072 (r=0.677,p=0.705),  time:35.740, tt:2072.938\n",
      "Ep:58, loss:0.00005, loss_test:0.10134, lr:8.51e-03, fs:0.71429 (r=0.657,p=0.783),  time:35.754, tt:2109.457\n",
      "Ep:59, loss:0.00005, loss_test:0.09917, lr:8.43e-03, fs:0.69110 (r=0.667,p=0.717),  time:35.788, tt:2147.264\n",
      "Ep:60, loss:0.00004, loss_test:0.09913, lr:8.35e-03, fs:0.69519 (r=0.657,p=0.739),  time:35.823, tt:2185.210\n",
      "Ep:61, loss:0.00004, loss_test:0.10096, lr:8.26e-03, fs:0.68783 (r=0.657,p=0.722),  time:35.837, tt:2221.902\n",
      "Ep:62, loss:0.00004, loss_test:0.09940, lr:8.18e-03, fs:0.68421 (r=0.657,p=0.714),  time:35.855, tt:2258.896\n",
      "Ep:63, loss:0.00004, loss_test:0.09956, lr:8.10e-03, fs:0.70270 (r=0.657,p=0.756),  time:35.884, tt:2296.596\n",
      "Ep:64, loss:0.00004, loss_test:0.10087, lr:8.02e-03, fs:0.68063 (r=0.657,p=0.707),  time:35.900, tt:2333.471\n",
      "Ep:65, loss:0.00004, loss_test:0.09714, lr:7.94e-03, fs:0.71823 (r=0.657,p=0.793),  time:35.939, tt:2371.941\n",
      "Ep:66, loss:0.00004, loss_test:0.10062, lr:7.86e-03, fs:0.68421 (r=0.657,p=0.714),  time:35.927, tt:2407.119\n",
      "Ep:67, loss:0.00004, loss_test:0.09708, lr:7.78e-03, fs:0.71038 (r=0.657,p=0.774),  time:35.920, tt:2442.571\n",
      "Ep:68, loss:0.00004, loss_test:0.09991, lr:7.70e-03, fs:0.68421 (r=0.657,p=0.714),  time:35.944, tt:2480.154\n",
      "Ep:69, loss:0.00004, loss_test:0.10090, lr:7.62e-03, fs:0.69149 (r=0.657,p=0.730),  time:35.952, tt:2516.614\n",
      "Ep:70, loss:0.00004, loss_test:0.09793, lr:7.55e-03, fs:0.69149 (r=0.657,p=0.730),  time:35.948, tt:2552.299\n",
      "Ep:71, loss:0.00004, loss_test:0.10167, lr:7.47e-03, fs:0.69149 (r=0.657,p=0.730),  time:35.942, tt:2587.818\n",
      "Ep:72, loss:0.00004, loss_test:0.10062, lr:7.40e-03, fs:0.68783 (r=0.657,p=0.722),  time:35.934, tt:2623.158\n",
      "Ep:73, loss:0.00004, loss_test:0.09780, lr:7.32e-03, fs:0.69519 (r=0.657,p=0.739),  time:35.951, tt:2660.373\n",
      "Ep:74, loss:0.00004, loss_test:0.10009, lr:7.25e-03, fs:0.69892 (r=0.657,p=0.747),  time:35.940, tt:2695.495\n",
      "Ep:75, loss:0.00003, loss_test:0.09870, lr:7.18e-03, fs:0.70652 (r=0.657,p=0.765),  time:35.930, tt:2730.660\n",
      "Ep:76, loss:0.00003, loss_test:0.09850, lr:7.11e-03, fs:0.68783 (r=0.657,p=0.722),  time:35.929, tt:2766.499\n",
      "Ep:77, loss:0.00003, loss_test:0.10123, lr:7.03e-03, fs:0.71429 (r=0.657,p=0.783),  time:35.917, tt:2801.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00003, loss_test:0.09834, lr:6.96e-03, fs:0.69519 (r=0.657,p=0.739),  time:35.956, tt:2840.496\n",
      "Ep:79, loss:0.00003, loss_test:0.09718, lr:6.89e-03, fs:0.69892 (r=0.657,p=0.747),  time:35.969, tt:2877.543\n",
      "Ep:80, loss:0.00003, loss_test:0.10157, lr:6.83e-03, fs:0.69149 (r=0.657,p=0.730),  time:35.976, tt:2914.086\n",
      "Ep:81, loss:0.00003, loss_test:0.09888, lr:6.76e-03, fs:0.71823 (r=0.657,p=0.793),  time:35.992, tt:2951.312\n",
      "Ep:82, loss:0.00003, loss_test:0.09815, lr:6.69e-03, fs:0.68421 (r=0.657,p=0.714),  time:35.992, tt:2987.356\n",
      "Ep:83, loss:0.00003, loss_test:0.09940, lr:6.62e-03, fs:0.73034 (r=0.657,p=0.823),  time:36.002, tt:3024.195\n",
      "Ep:84, loss:0.00003, loss_test:0.09982, lr:6.56e-03, fs:0.69149 (r=0.657,p=0.730),  time:36.027, tt:3062.270\n",
      "Ep:85, loss:0.00003, loss_test:0.09693, lr:6.49e-03, fs:0.69892 (r=0.657,p=0.747),  time:36.027, tt:3098.308\n",
      "Ep:86, loss:0.00003, loss_test:0.09877, lr:6.43e-03, fs:0.69519 (r=0.657,p=0.739),  time:36.002, tt:3132.142\n",
      "Ep:87, loss:0.00003, loss_test:0.09878, lr:6.36e-03, fs:0.71429 (r=0.657,p=0.783),  time:35.984, tt:3166.589\n",
      "Ep:88, loss:0.00003, loss_test:0.09745, lr:6.30e-03, fs:0.71038 (r=0.657,p=0.774),  time:36.002, tt:3204.160\n",
      "Ep:89, loss:0.00003, loss_test:0.09908, lr:6.24e-03, fs:0.69149 (r=0.657,p=0.730),  time:35.993, tt:3239.391\n",
      "Ep:90, loss:0.00003, loss_test:0.09931, lr:6.17e-03, fs:0.70652 (r=0.657,p=0.765),  time:36.005, tt:3276.438\n",
      "Ep:91, loss:0.00003, loss_test:0.09746, lr:6.11e-03, fs:0.71429 (r=0.657,p=0.783),  time:36.020, tt:3313.861\n",
      "Ep:92, loss:0.00003, loss_test:0.10020, lr:6.05e-03, fs:0.70270 (r=0.657,p=0.756),  time:36.076, tt:3355.038\n",
      "Ep:93, loss:0.00003, loss_test:0.09955, lr:5.99e-03, fs:0.74713 (r=0.657,p=0.867),  time:36.081, tt:3391.609\n",
      "Ep:94, loss:0.00003, loss_test:0.09789, lr:5.93e-03, fs:0.69519 (r=0.657,p=0.739),  time:36.090, tt:3428.541\n",
      "Ep:95, loss:0.00003, loss_test:0.09881, lr:5.87e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.089, tt:3464.516\n",
      "Ep:96, loss:0.00003, loss_test:0.10097, lr:5.81e-03, fs:0.70391 (r=0.636,p=0.787),  time:36.111, tt:3502.813\n",
      "Ep:97, loss:0.00003, loss_test:0.09800, lr:5.75e-03, fs:0.72626 (r=0.657,p=0.812),  time:36.101, tt:3537.927\n",
      "Ep:98, loss:0.00003, loss_test:0.09813, lr:5.70e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.102, tt:3574.075\n",
      "Ep:99, loss:0.00003, loss_test:0.10077, lr:5.64e-03, fs:0.72222 (r=0.657,p=0.802),  time:36.101, tt:3610.061\n",
      "Ep:100, loss:0.00003, loss_test:0.09685, lr:5.58e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.103, tt:3646.451\n",
      "Ep:101, loss:0.00002, loss_test:0.09916, lr:5.53e-03, fs:0.71038 (r=0.657,p=0.774),  time:36.124, tt:3684.669\n",
      "Ep:102, loss:0.00002, loss_test:0.09943, lr:5.47e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.121, tt:3720.489\n",
      "Ep:103, loss:0.00002, loss_test:0.09966, lr:5.42e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.137, tt:3758.230\n",
      "Ep:104, loss:0.00002, loss_test:0.09802, lr:5.36e-03, fs:0.74713 (r=0.657,p=0.867),  time:36.148, tt:3795.589\n",
      "Ep:105, loss:0.00002, loss_test:0.09953, lr:5.31e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.153, tt:3832.200\n",
      "Ep:106, loss:0.00002, loss_test:0.10135, lr:5.26e-03, fs:0.72000 (r=0.636,p=0.829),  time:36.160, tt:3869.141\n",
      "Ep:107, loss:0.00002, loss_test:0.09777, lr:5.20e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.172, tt:3906.628\n",
      "Ep:108, loss:0.00002, loss_test:0.10042, lr:5.15e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.174, tt:3942.979\n",
      "Ep:109, loss:0.00002, loss_test:0.09968, lr:5.10e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.182, tt:3979.971\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.09999, lr:5.10e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.188, tt:4016.819\n",
      "Ep:111, loss:0.00002, loss_test:0.10019, lr:5.10e-03, fs:0.74713 (r=0.657,p=0.867),  time:36.204, tt:4054.889\n",
      "Ep:112, loss:0.00002, loss_test:0.10019, lr:5.10e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.207, tt:4091.382\n",
      "Ep:113, loss:0.00002, loss_test:0.09943, lr:5.10e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.218, tt:4128.825\n",
      "Ep:114, loss:0.00002, loss_test:0.09987, lr:5.10e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.236, tt:4167.108\n",
      "Ep:115, loss:0.00002, loss_test:0.10069, lr:5.10e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.255, tt:4205.536\n",
      "Ep:116, loss:0.00002, loss_test:0.09967, lr:5.10e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.254, tt:4241.693\n",
      "Ep:117, loss:0.00002, loss_test:0.10102, lr:5.10e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.239, tt:4276.196\n",
      "Ep:118, loss:0.00002, loss_test:0.09995, lr:5.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.240, tt:4312.513\n",
      "Ep:119, loss:0.00002, loss_test:0.10171, lr:5.10e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.228, tt:4347.365\n",
      "Ep:120, loss:0.00002, loss_test:0.09660, lr:5.10e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.233, tt:4384.182\n",
      "Ep:121, loss:0.00002, loss_test:0.10623, lr:5.05e-03, fs:0.72414 (r=0.636,p=0.840),  time:36.239, tt:4421.140\n",
      "Ep:122, loss:0.00002, loss_test:0.09735, lr:5.00e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.245, tt:4458.135\n",
      "Ep:123, loss:0.00002, loss_test:0.10230, lr:4.95e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.245, tt:4494.322\n",
      "Ep:124, loss:0.00002, loss_test:0.10179, lr:4.90e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.250, tt:4531.234\n",
      "Ep:125, loss:0.00002, loss_test:0.10126, lr:4.85e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.251, tt:4567.569\n",
      "Ep:126, loss:0.00002, loss_test:0.09942, lr:4.80e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.242, tt:4602.690\n",
      "Ep:127, loss:0.00002, loss_test:0.10303, lr:4.75e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.240, tt:4638.730\n",
      "Ep:128, loss:0.00002, loss_test:0.10054, lr:4.71e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.255, tt:4676.845\n",
      "Ep:129, loss:0.00002, loss_test:0.10105, lr:4.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.266, tt:4714.548\n",
      "Ep:130, loss:0.00002, loss_test:0.10244, lr:4.61e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.269, tt:4751.204\n",
      "Ep:131, loss:0.00002, loss_test:0.10096, lr:4.57e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.276, tt:4788.376\n",
      "Ep:132, loss:0.00002, loss_test:0.10029, lr:4.52e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.277, tt:4824.889\n",
      "Ep:133, loss:0.00002, loss_test:0.10311, lr:4.48e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.286, tt:4862.282\n",
      "Ep:134, loss:0.00002, loss_test:0.10119, lr:4.43e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.287, tt:4898.793\n",
      "Ep:135, loss:0.00002, loss_test:0.09998, lr:4.39e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.275, tt:4933.416\n",
      "Ep:136, loss:0.00002, loss_test:0.10151, lr:4.34e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.270, tt:4969.002\n",
      "Ep:137, loss:0.00002, loss_test:0.09981, lr:4.30e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.278, tt:5006.357\n",
      "Ep:138, loss:0.00002, loss_test:0.10149, lr:4.26e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.272, tt:5041.858\n",
      "Ep:139, loss:0.00002, loss_test:0.10037, lr:4.21e-03, fs:0.71515 (r=0.596,p=0.894),  time:36.273, tt:5078.183\n",
      "Ep:140, loss:0.00002, loss_test:0.10207, lr:4.17e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.281, tt:5115.570\n",
      "Ep:141, loss:0.00002, loss_test:0.09849, lr:4.13e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.286, tt:5152.650\n",
      "Ep:142, loss:0.00002, loss_test:0.10239, lr:4.09e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.289, tt:5189.287\n",
      "Ep:143, loss:0.00002, loss_test:0.10040, lr:4.05e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.292, tt:5225.998\n",
      "Ep:144, loss:0.00002, loss_test:0.10201, lr:4.01e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.297, tt:5263.012\n",
      "Ep:145, loss:0.00002, loss_test:0.10241, lr:3.97e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.298, tt:5299.444\n",
      "Ep:146, loss:0.00001, loss_test:0.10243, lr:3.93e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.291, tt:5334.727\n",
      "Ep:147, loss:0.00001, loss_test:0.10213, lr:3.89e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.290, tt:5370.866\n",
      "Ep:148, loss:0.00001, loss_test:0.10085, lr:3.85e-03, fs:0.71166 (r=0.586,p=0.906),  time:36.293, tt:5407.674\n",
      "Ep:149, loss:0.00001, loss_test:0.10354, lr:3.81e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.292, tt:5443.767\n",
      "Ep:150, loss:0.00001, loss_test:0.10101, lr:3.77e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.303, tt:5481.695\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00001, loss_test:0.10176, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.307, tt:5518.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00001, loss_test:0.10242, lr:3.77e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.310, tt:5555.503\n",
      "Ep:153, loss:0.00001, loss_test:0.10027, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.313, tt:5592.217\n",
      "Ep:154, loss:0.00001, loss_test:0.10307, lr:3.77e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.309, tt:5627.929\n",
      "Ep:155, loss:0.00001, loss_test:0.10089, lr:3.77e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.314, tt:5664.919\n",
      "Ep:156, loss:0.00001, loss_test:0.10135, lr:3.77e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.322, tt:5702.522\n",
      "Ep:157, loss:0.00001, loss_test:0.10224, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.324, tt:5739.220\n",
      "Ep:158, loss:0.00001, loss_test:0.10137, lr:3.77e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.319, tt:5774.671\n",
      "Ep:159, loss:0.00001, loss_test:0.09941, lr:3.77e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.325, tt:5811.982\n",
      "Ep:160, loss:0.00001, loss_test:0.10276, lr:3.77e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.331, tt:5849.298\n",
      "Ep:161, loss:0.00001, loss_test:0.10071, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.343, tt:5887.562\n",
      "Ep:162, loss:0.00001, loss_test:0.10144, lr:3.73e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.350, tt:5924.997\n",
      "Ep:163, loss:0.00001, loss_test:0.10135, lr:3.70e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.356, tt:5962.409\n",
      "Ep:164, loss:0.00001, loss_test:0.10055, lr:3.66e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.351, tt:5997.968\n",
      "##########Best model found so far##########\n",
      "Ep:165, loss:0.00001, loss_test:0.10267, lr:3.66e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.368, tt:6037.090\n",
      "Ep:166, loss:0.00001, loss_test:0.09973, lr:3.66e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.373, tt:6074.233\n",
      "Ep:167, loss:0.00001, loss_test:0.10371, lr:3.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.372, tt:6110.484\n",
      "Ep:168, loss:0.00001, loss_test:0.09961, lr:3.66e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.369, tt:6146.303\n",
      "Ep:169, loss:0.00001, loss_test:0.10349, lr:3.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.367, tt:6182.470\n",
      "Ep:170, loss:0.00001, loss_test:0.09856, lr:3.66e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.362, tt:6217.882\n",
      "Ep:171, loss:0.00001, loss_test:0.10323, lr:3.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.366, tt:6254.981\n",
      "Ep:172, loss:0.00001, loss_test:0.10117, lr:3.66e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.362, tt:6290.633\n",
      "Ep:173, loss:0.00001, loss_test:0.10056, lr:3.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.367, tt:6327.819\n",
      "Ep:174, loss:0.00001, loss_test:0.10260, lr:3.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.358, tt:6362.686\n",
      "Ep:175, loss:0.00001, loss_test:0.10005, lr:3.66e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.361, tt:6399.453\n",
      "Ep:176, loss:0.00001, loss_test:0.10243, lr:3.62e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.353, tt:6434.405\n",
      "Ep:177, loss:0.00001, loss_test:0.09947, lr:3.59e-03, fs:0.71166 (r=0.586,p=0.906),  time:36.357, tt:6471.467\n",
      "Ep:178, loss:0.00001, loss_test:0.10522, lr:3.55e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.357, tt:6507.852\n",
      "Ep:179, loss:0.00001, loss_test:0.09727, lr:3.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.371, tt:6546.696\n",
      "Ep:180, loss:0.00001, loss_test:0.10355, lr:3.48e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.357, tt:6580.534\n",
      "Ep:181, loss:0.00001, loss_test:0.10150, lr:3.45e-03, fs:0.71166 (r=0.586,p=0.906),  time:36.362, tt:6617.796\n",
      "Ep:182, loss:0.00001, loss_test:0.10393, lr:3.41e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.358, tt:6653.547\n",
      "Ep:183, loss:0.00001, loss_test:0.09841, lr:3.38e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.369, tt:6691.825\n",
      "Ep:184, loss:0.00001, loss_test:0.10456, lr:3.34e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.364, tt:6727.255\n",
      "Ep:185, loss:0.00001, loss_test:0.10222, lr:3.31e-03, fs:0.71166 (r=0.586,p=0.906),  time:36.361, tt:6763.171\n",
      "Ep:186, loss:0.00001, loss_test:0.10271, lr:3.28e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.358, tt:6798.922\n",
      "Ep:187, loss:0.00001, loss_test:0.09976, lr:3.24e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.368, tt:6837.198\n",
      "Ep:188, loss:0.00001, loss_test:0.10306, lr:3.21e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.370, tt:6873.949\n",
      "Ep:189, loss:0.00001, loss_test:0.10140, lr:3.18e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.370, tt:6910.340\n",
      "Ep:190, loss:0.00001, loss_test:0.10042, lr:3.15e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.369, tt:6946.515\n",
      "Ep:191, loss:0.00001, loss_test:0.10067, lr:3.12e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.371, tt:6983.323\n",
      "Ep:192, loss:0.00001, loss_test:0.10371, lr:3.09e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.366, tt:7018.685\n",
      "Ep:193, loss:0.00001, loss_test:0.10014, lr:3.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.360, tt:7053.928\n",
      "Ep:194, loss:0.00001, loss_test:0.10079, lr:3.02e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.365, tt:7091.238\n",
      "Ep:195, loss:0.00001, loss_test:0.10110, lr:2.99e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.370, tt:7128.613\n",
      "Ep:196, loss:0.00001, loss_test:0.10103, lr:2.96e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.368, tt:7164.567\n",
      "Ep:197, loss:0.00001, loss_test:0.10156, lr:2.93e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.374, tt:7202.149\n",
      "Ep:198, loss:0.00001, loss_test:0.09963, lr:2.90e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.375, tt:7238.551\n",
      "Ep:199, loss:0.00001, loss_test:0.10317, lr:2.88e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.371, tt:7274.163\n",
      "Ep:200, loss:0.00001, loss_test:0.10074, lr:2.85e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.370, tt:7310.397\n",
      "Ep:201, loss:0.00001, loss_test:0.09952, lr:2.82e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.371, tt:7347.004\n",
      "Ep:202, loss:0.00001, loss_test:0.10113, lr:2.79e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.358, tt:7380.586\n",
      "Ep:203, loss:0.00001, loss_test:0.10160, lr:2.76e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.341, tt:7413.515\n",
      "Ep:204, loss:0.00001, loss_test:0.10081, lr:2.73e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.325, tt:7446.679\n",
      "Ep:205, loss:0.00001, loss_test:0.10101, lr:2.71e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.300, tt:7477.867\n",
      "Ep:206, loss:0.00001, loss_test:0.09941, lr:2.68e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.263, tt:7506.385\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02558, lr:6.00e-02, fs:0.63374 (r=0.778,p=0.535),  time:32.269, tt:32.269\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02468, lr:6.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:32.571, tt:65.143\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02563, lr:6.00e-02, fs:0.65493 (r=0.939,p=0.503),  time:31.454, tt:94.361\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02519, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:31.244, tt:124.977\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02405, lr:6.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:31.559, tt:157.796\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02317, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:31.584, tt:189.504\n",
      "Ep:6, loss:0.00004, loss_test:0.02364, lr:6.00e-02, fs:0.63374 (r=0.778,p=0.535),  time:31.623, tt:221.363\n",
      "Ep:7, loss:0.00004, loss_test:0.02398, lr:6.00e-02, fs:0.58515 (r=0.677,p=0.515),  time:31.870, tt:254.962\n",
      "Ep:8, loss:0.00004, loss_test:0.02336, lr:6.00e-02, fs:0.59912 (r=0.687,p=0.531),  time:32.116, tt:289.045\n",
      "Ep:9, loss:0.00004, loss_test:0.02245, lr:6.00e-02, fs:0.61135 (r=0.707,p=0.538),  time:32.343, tt:323.432\n",
      "Ep:10, loss:0.00004, loss_test:0.02201, lr:6.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:32.590, tt:358.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00004, loss_test:0.02180, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:32.775, tt:393.301\n",
      "Ep:12, loss:0.00003, loss_test:0.02165, lr:6.00e-02, fs:0.63291 (r=0.758,p=0.543),  time:32.977, tt:428.704\n",
      "Ep:13, loss:0.00003, loss_test:0.02159, lr:6.00e-02, fs:0.61947 (r=0.707,p=0.551),  time:33.038, tt:462.527\n",
      "Ep:14, loss:0.00003, loss_test:0.02131, lr:6.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:33.046, tt:495.686\n",
      "Ep:15, loss:0.00003, loss_test:0.02087, lr:6.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:33.055, tt:528.884\n",
      "Ep:16, loss:0.00003, loss_test:0.02037, lr:5.94e-02, fs:0.64629 (r=0.747,p=0.569),  time:33.081, tt:562.376\n",
      "Ep:17, loss:0.00003, loss_test:0.01983, lr:5.88e-02, fs:0.64629 (r=0.747,p=0.569),  time:33.062, tt:595.115\n",
      "Ep:18, loss:0.00003, loss_test:0.01950, lr:5.82e-02, fs:0.64912 (r=0.747,p=0.574),  time:33.074, tt:628.415\n",
      "Ep:19, loss:0.00003, loss_test:0.01940, lr:5.76e-02, fs:0.66667 (r=0.768,p=0.589),  time:33.250, tt:664.994\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01921, lr:5.76e-02, fs:0.68161 (r=0.768,p=0.613),  time:33.297, tt:699.234\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01892, lr:5.76e-02, fs:0.69643 (r=0.788,p=0.624),  time:33.324, tt:733.126\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01857, lr:5.76e-02, fs:0.70485 (r=0.808,p=0.625),  time:33.277, tt:765.368\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01820, lr:5.76e-02, fs:0.73043 (r=0.848,p=0.641),  time:33.265, tt:798.366\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01794, lr:5.76e-02, fs:0.73913 (r=0.859,p=0.649),  time:33.297, tt:832.429\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01778, lr:5.76e-02, fs:0.73913 (r=0.859,p=0.649),  time:33.283, tt:865.349\n",
      "Ep:26, loss:0.00002, loss_test:0.01770, lr:5.76e-02, fs:0.73684 (r=0.848,p=0.651),  time:33.264, tt:898.139\n",
      "Ep:27, loss:0.00002, loss_test:0.01757, lr:5.76e-02, fs:0.73684 (r=0.848,p=0.651),  time:33.294, tt:932.222\n",
      "Ep:28, loss:0.00002, loss_test:0.01751, lr:5.76e-02, fs:0.74667 (r=0.848,p=0.667),  time:33.368, tt:967.682\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01727, lr:5.76e-02, fs:0.75556 (r=0.859,p=0.675),  time:33.392, tt:1001.755\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01699, lr:5.76e-02, fs:0.75000 (r=0.848,p=0.672),  time:33.392, tt:1035.139\n",
      "Ep:31, loss:0.00002, loss_test:0.01679, lr:5.76e-02, fs:0.75771 (r=0.869,p=0.672),  time:33.414, tt:1069.238\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01668, lr:5.76e-02, fs:0.75893 (r=0.859,p=0.680),  time:33.418, tt:1102.779\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01662, lr:5.76e-02, fs:0.75676 (r=0.848,p=0.683),  time:33.407, tt:1135.854\n",
      "Ep:34, loss:0.00002, loss_test:0.01643, lr:5.76e-02, fs:0.72222 (r=0.788,p=0.667),  time:33.404, tt:1169.133\n",
      "Ep:35, loss:0.00002, loss_test:0.01622, lr:5.76e-02, fs:0.72222 (r=0.788,p=0.667),  time:33.402, tt:1202.455\n",
      "Ep:36, loss:0.00002, loss_test:0.01615, lr:5.76e-02, fs:0.71628 (r=0.778,p=0.664),  time:33.395, tt:1235.618\n",
      "Ep:37, loss:0.00002, loss_test:0.01604, lr:5.76e-02, fs:0.71296 (r=0.778,p=0.658),  time:33.402, tt:1269.280\n",
      "Ep:38, loss:0.00002, loss_test:0.01595, lr:5.76e-02, fs:0.72222 (r=0.788,p=0.667),  time:33.376, tt:1301.681\n",
      "Ep:39, loss:0.00002, loss_test:0.01595, lr:5.76e-02, fs:0.72558 (r=0.788,p=0.672),  time:33.393, tt:1335.717\n",
      "Ep:40, loss:0.00002, loss_test:0.01607, lr:5.76e-02, fs:0.71963 (r=0.778,p=0.670),  time:33.392, tt:1369.076\n",
      "Ep:41, loss:0.00002, loss_test:0.01605, lr:5.76e-02, fs:0.72897 (r=0.788,p=0.678),  time:33.404, tt:1402.987\n",
      "Ep:42, loss:0.00002, loss_test:0.01603, lr:5.76e-02, fs:0.73488 (r=0.798,p=0.681),  time:33.414, tt:1436.811\n",
      "Ep:43, loss:0.00002, loss_test:0.01608, lr:5.76e-02, fs:0.73239 (r=0.788,p=0.684),  time:33.421, tt:1470.541\n",
      "Ep:44, loss:0.00002, loss_test:0.01608, lr:5.71e-02, fs:0.74766 (r=0.808,p=0.696),  time:33.484, tt:1506.776\n",
      "Ep:45, loss:0.00002, loss_test:0.01611, lr:5.65e-02, fs:0.74766 (r=0.808,p=0.696),  time:33.508, tt:1541.348\n",
      "Ep:46, loss:0.00001, loss_test:0.01619, lr:5.59e-02, fs:0.73934 (r=0.788,p=0.696),  time:33.544, tt:1576.574\n",
      "Ep:47, loss:0.00001, loss_test:0.01629, lr:5.54e-02, fs:0.74286 (r=0.788,p=0.703),  time:33.550, tt:1610.377\n",
      "Ep:48, loss:0.00001, loss_test:0.01632, lr:5.48e-02, fs:0.73077 (r=0.768,p=0.697),  time:33.583, tt:1645.564\n",
      "Ep:49, loss:0.00001, loss_test:0.01618, lr:5.43e-02, fs:0.75238 (r=0.798,p=0.712),  time:33.599, tt:1679.962\n",
      "Ep:50, loss:0.00001, loss_test:0.01628, lr:5.37e-02, fs:0.74641 (r=0.788,p=0.709),  time:33.583, tt:1712.719\n",
      "Ep:51, loss:0.00001, loss_test:0.01653, lr:5.32e-02, fs:0.73786 (r=0.768,p=0.710),  time:33.602, tt:1747.311\n",
      "Ep:52, loss:0.00001, loss_test:0.01657, lr:5.27e-02, fs:0.74396 (r=0.778,p=0.713),  time:33.639, tt:1782.883\n",
      "Ep:53, loss:0.00001, loss_test:0.01661, lr:5.21e-02, fs:0.74146 (r=0.768,p=0.717),  time:33.643, tt:1816.702\n",
      "Ep:54, loss:0.00001, loss_test:0.01654, lr:5.16e-02, fs:0.74882 (r=0.798,p=0.705),  time:33.663, tt:1851.453\n",
      "Ep:55, loss:0.00001, loss_test:0.01677, lr:5.11e-02, fs:0.74757 (r=0.778,p=0.720),  time:33.673, tt:1885.672\n",
      "Ep:56, loss:0.00001, loss_test:0.01694, lr:5.06e-02, fs:0.75122 (r=0.778,p=0.726),  time:33.677, tt:1919.578\n",
      "Ep:57, loss:0.00001, loss_test:0.01689, lr:5.01e-02, fs:0.75000 (r=0.788,p=0.716),  time:33.655, tt:1952.015\n",
      "Ep:58, loss:0.00001, loss_test:0.01705, lr:4.96e-02, fs:0.76098 (r=0.788,p=0.736),  time:33.654, tt:1985.562\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01710, lr:4.96e-02, fs:0.76699 (r=0.798,p=0.738),  time:33.648, tt:2018.880\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01712, lr:4.96e-02, fs:0.75962 (r=0.798,p=0.725),  time:33.661, tt:2053.309\n",
      "Ep:61, loss:0.00001, loss_test:0.01750, lr:4.96e-02, fs:0.76238 (r=0.778,p=0.748),  time:33.654, tt:2086.564\n",
      "Ep:62, loss:0.00001, loss_test:0.01737, lr:4.96e-02, fs:0.76471 (r=0.788,p=0.743),  time:33.665, tt:2120.907\n",
      "Ep:63, loss:0.00001, loss_test:0.01750, lr:4.96e-02, fs:0.76847 (r=0.788,p=0.750),  time:33.665, tt:2154.555\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01763, lr:4.96e-02, fs:0.76847 (r=0.788,p=0.750),  time:33.649, tt:2187.180\n",
      "Ep:65, loss:0.00001, loss_test:0.01756, lr:4.96e-02, fs:0.76471 (r=0.788,p=0.743),  time:33.646, tt:2220.667\n",
      "Ep:66, loss:0.00001, loss_test:0.01784, lr:4.96e-02, fs:0.75622 (r=0.768,p=0.745),  time:33.658, tt:2255.105\n",
      "Ep:67, loss:0.00001, loss_test:0.01794, lr:4.96e-02, fs:0.76238 (r=0.778,p=0.748),  time:33.649, tt:2288.100\n",
      "Ep:68, loss:0.00001, loss_test:0.01792, lr:4.96e-02, fs:0.76238 (r=0.778,p=0.748),  time:33.672, tt:2323.390\n",
      "Ep:69, loss:0.00001, loss_test:0.01805, lr:4.96e-02, fs:0.76617 (r=0.778,p=0.755),  time:33.640, tt:2354.825\n",
      "Ep:70, loss:0.00001, loss_test:0.01823, lr:4.96e-02, fs:0.76617 (r=0.778,p=0.755),  time:33.664, tt:2390.152\n",
      "Ep:71, loss:0.00001, loss_test:0.01825, lr:4.96e-02, fs:0.77000 (r=0.778,p=0.762),  time:33.685, tt:2425.315\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01828, lr:4.96e-02, fs:0.76617 (r=0.778,p=0.755),  time:33.695, tt:2459.740\n",
      "Ep:73, loss:0.00001, loss_test:0.01850, lr:4.96e-02, fs:0.76617 (r=0.778,p=0.755),  time:33.688, tt:2492.940\n",
      "Ep:74, loss:0.00001, loss_test:0.01863, lr:4.96e-02, fs:0.77387 (r=0.778,p=0.770),  time:33.689, tt:2526.658\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01865, lr:4.96e-02, fs:0.76617 (r=0.778,p=0.755),  time:33.713, tt:2562.209\n",
      "Ep:76, loss:0.00001, loss_test:0.01876, lr:4.96e-02, fs:0.77387 (r=0.778,p=0.770),  time:33.725, tt:2596.799\n",
      "Ep:77, loss:0.00001, loss_test:0.01877, lr:4.96e-02, fs:0.76382 (r=0.768,p=0.760),  time:33.741, tt:2631.787\n",
      "Ep:78, loss:0.00001, loss_test:0.01911, lr:4.96e-02, fs:0.76142 (r=0.758,p=0.765),  time:33.738, tt:2665.290\n",
      "Ep:79, loss:0.00001, loss_test:0.01906, lr:4.96e-02, fs:0.76142 (r=0.758,p=0.765),  time:33.720, tt:2697.606\n",
      "Ep:80, loss:0.00001, loss_test:0.01922, lr:4.96e-02, fs:0.73846 (r=0.727,p=0.750),  time:33.728, tt:2731.931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:81, loss:0.00001, loss_test:0.01939, lr:4.96e-02, fs:0.74872 (r=0.737,p=0.760),  time:33.721, tt:2765.142\n",
      "Ep:82, loss:0.00001, loss_test:0.01937, lr:4.96e-02, fs:0.73575 (r=0.717,p=0.755),  time:33.727, tt:2799.345\n",
      "Ep:83, loss:0.00001, loss_test:0.01951, lr:4.96e-02, fs:0.72917 (r=0.707,p=0.753),  time:33.720, tt:2832.492\n",
      "Ep:84, loss:0.00001, loss_test:0.01964, lr:4.96e-02, fs:0.71277 (r=0.677,p=0.753),  time:33.735, tt:2867.434\n",
      "Ep:85, loss:0.00001, loss_test:0.01971, lr:4.96e-02, fs:0.71658 (r=0.677,p=0.761),  time:33.748, tt:2902.309\n",
      "Ep:86, loss:0.00001, loss_test:0.02000, lr:4.91e-02, fs:0.70588 (r=0.667,p=0.750),  time:33.754, tt:2936.617\n",
      "Ep:87, loss:0.00001, loss_test:0.01992, lr:4.86e-02, fs:0.70968 (r=0.667,p=0.759),  time:33.776, tt:2972.327\n",
      "Ep:88, loss:0.00001, loss_test:0.01990, lr:4.81e-02, fs:0.70968 (r=0.667,p=0.759),  time:33.787, tt:3007.046\n",
      "Ep:89, loss:0.00001, loss_test:0.02024, lr:4.76e-02, fs:0.71351 (r=0.667,p=0.767),  time:33.818, tt:3043.645\n",
      "Ep:90, loss:0.00001, loss_test:0.02040, lr:4.71e-02, fs:0.71038 (r=0.657,p=0.774),  time:33.839, tt:3079.352\n",
      "Ep:91, loss:0.00001, loss_test:0.02033, lr:4.67e-02, fs:0.71351 (r=0.667,p=0.767),  time:33.851, tt:3114.320\n",
      "Ep:92, loss:0.00001, loss_test:0.02046, lr:4.62e-02, fs:0.71038 (r=0.657,p=0.774),  time:33.874, tt:3150.259\n",
      "Ep:93, loss:0.00001, loss_test:0.02062, lr:4.57e-02, fs:0.70718 (r=0.646,p=0.780),  time:33.891, tt:3185.770\n",
      "Ep:94, loss:0.00001, loss_test:0.02084, lr:4.53e-02, fs:0.70718 (r=0.646,p=0.780),  time:33.908, tt:3221.227\n",
      "Ep:95, loss:0.00001, loss_test:0.02068, lr:4.48e-02, fs:0.70718 (r=0.646,p=0.780),  time:33.940, tt:3258.239\n",
      "Ep:96, loss:0.00001, loss_test:0.02087, lr:4.44e-02, fs:0.70330 (r=0.646,p=0.771),  time:33.953, tt:3293.431\n",
      "Ep:97, loss:0.00001, loss_test:0.02100, lr:4.39e-02, fs:0.70718 (r=0.646,p=0.780),  time:33.967, tt:3328.782\n",
      "Ep:98, loss:0.00001, loss_test:0.02112, lr:4.35e-02, fs:0.71111 (r=0.646,p=0.790),  time:33.986, tt:3364.566\n",
      "Ep:99, loss:0.00001, loss_test:0.02118, lr:4.31e-02, fs:0.71111 (r=0.646,p=0.790),  time:33.979, tt:3397.898\n",
      "Ep:100, loss:0.00001, loss_test:0.02118, lr:4.26e-02, fs:0.71111 (r=0.646,p=0.790),  time:33.987, tt:3432.653\n",
      "Ep:101, loss:0.00001, loss_test:0.02124, lr:4.22e-02, fs:0.71111 (r=0.646,p=0.790),  time:33.995, tt:3467.452\n",
      "Ep:102, loss:0.00001, loss_test:0.02154, lr:4.18e-02, fs:0.71508 (r=0.646,p=0.800),  time:33.998, tt:3501.755\n",
      "Ep:103, loss:0.00001, loss_test:0.02148, lr:4.14e-02, fs:0.71508 (r=0.646,p=0.800),  time:33.997, tt:3535.715\n",
      "Ep:104, loss:0.00001, loss_test:0.02158, lr:4.10e-02, fs:0.71508 (r=0.646,p=0.800),  time:33.999, tt:3569.889\n",
      "Ep:105, loss:0.00001, loss_test:0.02170, lr:4.05e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.008, tt:3604.856\n",
      "Ep:106, loss:0.00001, loss_test:0.02181, lr:4.01e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.035, tt:3641.760\n",
      "Ep:107, loss:0.00001, loss_test:0.02198, lr:3.97e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.038, tt:3676.071\n",
      "Ep:108, loss:0.00001, loss_test:0.02192, lr:3.93e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.061, tt:3712.646\n",
      "Ep:109, loss:0.00001, loss_test:0.02186, lr:3.89e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.068, tt:3747.462\n",
      "Ep:110, loss:0.00001, loss_test:0.02232, lr:3.86e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.073, tt:3782.078\n",
      "Ep:111, loss:0.00001, loss_test:0.02222, lr:3.82e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.071, tt:3815.966\n",
      "Ep:112, loss:0.00001, loss_test:0.02217, lr:3.78e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.090, tt:3852.159\n",
      "Ep:113, loss:0.00000, loss_test:0.02250, lr:3.74e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.088, tt:3885.978\n",
      "Ep:114, loss:0.00000, loss_test:0.02250, lr:3.70e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.107, tt:3922.286\n",
      "Ep:115, loss:0.00000, loss_test:0.02259, lr:3.67e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.109, tt:3956.682\n",
      "Ep:116, loss:0.00000, loss_test:0.02259, lr:3.63e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.111, tt:3991.036\n",
      "Ep:117, loss:0.00000, loss_test:0.02278, lr:3.59e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.122, tt:4026.391\n",
      "Ep:118, loss:0.00000, loss_test:0.02277, lr:3.56e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.136, tt:4062.210\n",
      "Ep:119, loss:0.00000, loss_test:0.02279, lr:3.52e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.154, tt:4098.426\n",
      "Ep:120, loss:0.00000, loss_test:0.02319, lr:3.49e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.180, tt:4135.741\n",
      "Ep:121, loss:0.00000, loss_test:0.02283, lr:3.45e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.199, tt:4172.284\n",
      "Ep:122, loss:0.00000, loss_test:0.02321, lr:3.42e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.221, tt:4209.207\n",
      "Ep:123, loss:0.00000, loss_test:0.02337, lr:3.38e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.254, tt:4247.455\n",
      "Ep:124, loss:0.00000, loss_test:0.02326, lr:3.35e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.269, tt:4283.634\n",
      "Ep:125, loss:0.00000, loss_test:0.02334, lr:3.32e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.272, tt:4318.278\n",
      "Ep:126, loss:0.00000, loss_test:0.02342, lr:3.28e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.273, tt:4352.629\n",
      "Ep:127, loss:0.00000, loss_test:0.02364, lr:3.25e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.284, tt:4388.317\n",
      "Ep:128, loss:0.00000, loss_test:0.02364, lr:3.22e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.269, tt:4420.756\n",
      "Ep:129, loss:0.00000, loss_test:0.02367, lr:3.19e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.262, tt:4454.017\n",
      "Ep:130, loss:0.00000, loss_test:0.02381, lr:3.15e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.254, tt:4487.233\n",
      "Ep:131, loss:0.00000, loss_test:0.02384, lr:3.12e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.248, tt:4520.679\n",
      "Ep:132, loss:0.00000, loss_test:0.02393, lr:3.09e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.265, tt:4557.211\n",
      "Ep:133, loss:0.00000, loss_test:0.02398, lr:3.06e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.280, tt:4593.492\n",
      "Ep:134, loss:0.00000, loss_test:0.02405, lr:3.03e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.272, tt:4626.775\n",
      "Ep:135, loss:0.00000, loss_test:0.02417, lr:3.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.283, tt:4662.507\n",
      "Ep:136, loss:0.00000, loss_test:0.02426, lr:2.97e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.289, tt:4697.573\n",
      "Ep:137, loss:0.00000, loss_test:0.02429, lr:2.94e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.302, tt:4733.729\n",
      "Ep:138, loss:0.00000, loss_test:0.02435, lr:2.91e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.307, tt:4768.677\n",
      "Ep:139, loss:0.00000, loss_test:0.02447, lr:2.88e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.322, tt:4805.093\n",
      "Ep:140, loss:0.00000, loss_test:0.02448, lr:2.85e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.330, tt:4840.548\n",
      "Ep:141, loss:0.00000, loss_test:0.02461, lr:2.82e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.338, tt:4875.980\n",
      "Ep:142, loss:0.00000, loss_test:0.02475, lr:2.80e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.341, tt:4910.735\n",
      "Ep:143, loss:0.00000, loss_test:0.02464, lr:2.77e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.343, tt:4945.343\n",
      "Ep:144, loss:0.00000, loss_test:0.02475, lr:2.74e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.345, tt:4980.038\n",
      "Ep:145, loss:0.00000, loss_test:0.02475, lr:2.71e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.347, tt:5014.610\n",
      "Ep:146, loss:0.00000, loss_test:0.02489, lr:2.69e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.368, tt:5052.149\n",
      "Ep:147, loss:0.00000, loss_test:0.02488, lr:2.66e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.371, tt:5086.857\n",
      "Ep:148, loss:0.00000, loss_test:0.02504, lr:2.63e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.372, tt:5121.468\n",
      "Ep:149, loss:0.00000, loss_test:0.02518, lr:2.61e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.371, tt:5155.651\n",
      "Ep:150, loss:0.00000, loss_test:0.02500, lr:2.58e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.380, tt:5191.336\n",
      "Ep:151, loss:0.00000, loss_test:0.02521, lr:2.55e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.396, tt:5228.187\n",
      "Ep:152, loss:0.00000, loss_test:0.02531, lr:2.53e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.404, tt:5263.819\n",
      "Ep:153, loss:0.00000, loss_test:0.02515, lr:2.50e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.420, tt:5300.710\n",
      "Ep:154, loss:0.00000, loss_test:0.02541, lr:2.48e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.418, tt:5334.750\n",
      "Ep:155, loss:0.00000, loss_test:0.02529, lr:2.45e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.428, tt:5370.841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:156, loss:0.00000, loss_test:0.02545, lr:2.43e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.438, tt:5406.745\n",
      "Ep:157, loss:0.00000, loss_test:0.02545, lr:2.40e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.438, tt:5441.180\n",
      "Ep:158, loss:0.00000, loss_test:0.02549, lr:2.38e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.440, tt:5475.891\n",
      "Ep:159, loss:0.00000, loss_test:0.02563, lr:2.36e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.441, tt:5510.550\n",
      "Ep:160, loss:0.00000, loss_test:0.02565, lr:2.33e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.445, tt:5545.604\n",
      "Ep:161, loss:0.00000, loss_test:0.02575, lr:2.31e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.451, tt:5580.996\n",
      "Ep:162, loss:0.00000, loss_test:0.02573, lr:2.29e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.452, tt:5615.742\n",
      "Ep:163, loss:0.00000, loss_test:0.02583, lr:2.26e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.455, tt:5650.582\n",
      "Ep:164, loss:0.00000, loss_test:0.02576, lr:2.24e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.461, tt:5686.065\n",
      "Ep:165, loss:0.00000, loss_test:0.02590, lr:2.22e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.457, tt:5719.795\n",
      "Ep:166, loss:0.00000, loss_test:0.02592, lr:2.20e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.459, tt:5754.719\n",
      "Ep:167, loss:0.00000, loss_test:0.02590, lr:2.17e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.467, tt:5790.430\n",
      "Ep:168, loss:0.00000, loss_test:0.02612, lr:2.15e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.465, tt:5824.653\n",
      "Ep:169, loss:0.00000, loss_test:0.02598, lr:2.13e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.462, tt:5858.497\n",
      "Ep:170, loss:0.00000, loss_test:0.02613, lr:2.11e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.467, tt:5893.839\n",
      "Ep:171, loss:0.00000, loss_test:0.02616, lr:2.09e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.468, tt:5928.570\n",
      "Ep:172, loss:0.00000, loss_test:0.02612, lr:2.07e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.472, tt:5963.613\n",
      "Ep:173, loss:0.00000, loss_test:0.02624, lr:2.05e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.483, tt:6000.087\n",
      "Ep:174, loss:0.00000, loss_test:0.02622, lr:2.03e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.491, tt:6035.910\n",
      "Ep:175, loss:0.00000, loss_test:0.02633, lr:2.01e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.501, tt:6072.234\n",
      "Ep:176, loss:0.00000, loss_test:0.02632, lr:1.99e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.507, tt:6107.721\n",
      "Ep:177, loss:0.00000, loss_test:0.02631, lr:1.97e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.513, tt:6143.354\n",
      "Ep:178, loss:0.00000, loss_test:0.02652, lr:1.95e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.521, tt:6179.190\n",
      "Ep:179, loss:0.00000, loss_test:0.02643, lr:1.93e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.530, tt:6215.370\n",
      "Ep:180, loss:0.00000, loss_test:0.02645, lr:1.91e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.546, tt:6252.737\n",
      "Ep:181, loss:0.00000, loss_test:0.02667, lr:1.89e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.560, tt:6289.860\n",
      "Ep:182, loss:0.00000, loss_test:0.02659, lr:1.87e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.566, tt:6325.539\n",
      "Ep:183, loss:0.00000, loss_test:0.02664, lr:1.85e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.576, tt:6361.993\n",
      "Ep:184, loss:0.00000, loss_test:0.02671, lr:1.83e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.586, tt:6398.408\n",
      "Ep:185, loss:0.00000, loss_test:0.02664, lr:1.81e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.594, tt:6434.396\n",
      "Ep:186, loss:0.00000, loss_test:0.02674, lr:1.80e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.599, tt:6470.086\n",
      "Ep:187, loss:0.00000, loss_test:0.02682, lr:1.78e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.608, tt:6506.220\n",
      "Ep:188, loss:0.00000, loss_test:0.02674, lr:1.76e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.618, tt:6542.713\n",
      "Ep:189, loss:0.00000, loss_test:0.02678, lr:1.74e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.629, tt:6579.486\n",
      "Ep:190, loss:0.00000, loss_test:0.02696, lr:1.73e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.639, tt:6616.049\n",
      "Ep:191, loss:0.00000, loss_test:0.02695, lr:1.71e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.655, tt:6653.748\n",
      "Ep:192, loss:0.00000, loss_test:0.02686, lr:1.69e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.656, tt:6688.656\n",
      "Ep:193, loss:0.00000, loss_test:0.02694, lr:1.67e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.663, tt:6724.603\n",
      "Ep:194, loss:0.00000, loss_test:0.02706, lr:1.66e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.666, tt:6759.894\n",
      "Ep:195, loss:0.00000, loss_test:0.02707, lr:1.64e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.672, tt:6795.751\n",
      "Ep:196, loss:0.00000, loss_test:0.02703, lr:1.62e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.674, tt:6830.784\n",
      "Ep:197, loss:0.00000, loss_test:0.02711, lr:1.61e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.674, tt:6865.503\n",
      "Ep:198, loss:0.00000, loss_test:0.02713, lr:1.59e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.677, tt:6900.690\n",
      "Ep:199, loss:0.00000, loss_test:0.02713, lr:1.58e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.692, tt:6938.405\n",
      "Ep:200, loss:0.00000, loss_test:0.02720, lr:1.56e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.694, tt:6973.489\n",
      "Ep:201, loss:0.00000, loss_test:0.02722, lr:1.54e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.709, tt:7011.296\n",
      "Ep:202, loss:0.00000, loss_test:0.02727, lr:1.53e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.717, tt:7047.560\n",
      "Ep:203, loss:0.00000, loss_test:0.02728, lr:1.51e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.721, tt:7083.047\n",
      "Ep:204, loss:0.00000, loss_test:0.02732, lr:1.50e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.720, tt:7117.675\n",
      "Ep:205, loss:0.00000, loss_test:0.02732, lr:1.48e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.727, tt:7153.849\n",
      "Ep:206, loss:0.00000, loss_test:0.02730, lr:1.47e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.735, tt:7190.192\n",
      "Ep:207, loss:0.00000, loss_test:0.02738, lr:1.45e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.732, tt:7224.156\n",
      "Ep:208, loss:0.00000, loss_test:0.02745, lr:1.44e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.717, tt:7255.787\n",
      "Ep:209, loss:0.00000, loss_test:0.02744, lr:1.43e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.709, tt:7288.802\n",
      "Ep:210, loss:0.00000, loss_test:0.02748, lr:1.41e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.715, tt:7324.801\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14308, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:30.160, tt:30.160\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14119, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:33.406, tt:66.812\n",
      "Ep:2, loss:0.00027, loss_test:0.13862, lr:1.00e-02, fs:0.63910 (r=0.859,p=0.509),  time:34.170, tt:102.511\n",
      "Ep:3, loss:0.00026, loss_test:0.13668, lr:1.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:34.276, tt:137.103\n",
      "Ep:4, loss:0.00025, loss_test:0.13548, lr:1.00e-02, fs:0.63900 (r=0.778,p=0.542),  time:34.835, tt:174.174\n",
      "Ep:5, loss:0.00025, loss_test:0.13491, lr:1.00e-02, fs:0.62069 (r=0.727,p=0.541),  time:34.830, tt:208.978\n",
      "Ep:6, loss:0.00024, loss_test:0.13313, lr:1.00e-02, fs:0.62281 (r=0.717,p=0.550),  time:34.952, tt:244.662\n",
      "Ep:7, loss:0.00024, loss_test:0.13159, lr:1.00e-02, fs:0.61333 (r=0.697,p=0.548),  time:35.367, tt:282.933\n",
      "Ep:8, loss:0.00023, loss_test:0.13020, lr:1.00e-02, fs:0.60714 (r=0.687,p=0.544),  time:35.529, tt:319.760\n",
      "Ep:9, loss:0.00023, loss_test:0.12865, lr:1.00e-02, fs:0.60748 (r=0.657,p=0.565),  time:35.691, tt:356.912\n",
      "Ep:10, loss:0.00022, loss_test:0.12711, lr:1.00e-02, fs:0.59903 (r=0.626,p=0.574),  time:35.937, tt:395.303\n",
      "Ep:11, loss:0.00022, loss_test:0.12644, lr:1.00e-02, fs:0.60488 (r=0.626,p=0.585),  time:36.092, tt:433.106\n",
      "Ep:12, loss:0.00021, loss_test:0.12471, lr:9.90e-03, fs:0.60488 (r=0.626,p=0.585),  time:36.246, tt:471.197\n",
      "Ep:13, loss:0.00021, loss_test:0.12271, lr:9.80e-03, fs:0.60194 (r=0.626,p=0.579),  time:36.399, tt:509.586\n",
      "Ep:14, loss:0.00020, loss_test:0.12151, lr:9.70e-03, fs:0.61765 (r=0.636,p=0.600),  time:36.498, tt:547.471\n",
      "Ep:15, loss:0.00020, loss_test:0.12006, lr:9.61e-03, fs:0.62687 (r=0.636,p=0.618),  time:36.489, tt:583.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00019, loss_test:0.11805, lr:9.51e-03, fs:0.63000 (r=0.636,p=0.624),  time:36.596, tt:622.138\n",
      "Ep:17, loss:0.00019, loss_test:0.11563, lr:9.41e-03, fs:0.63317 (r=0.636,p=0.630),  time:36.641, tt:659.541\n",
      "Ep:18, loss:0.00018, loss_test:0.11365, lr:9.32e-03, fs:0.63000 (r=0.636,p=0.624),  time:36.672, tt:696.769\n",
      "Ep:19, loss:0.00018, loss_test:0.11235, lr:9.23e-03, fs:0.65700 (r=0.687,p=0.630),  time:36.688, tt:733.757\n",
      "Ep:20, loss:0.00017, loss_test:0.11111, lr:9.14e-03, fs:0.67327 (r=0.687,p=0.660),  time:36.759, tt:771.943\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.10959, lr:9.14e-03, fs:0.67980 (r=0.697,p=0.663),  time:36.758, tt:808.673\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.10777, lr:9.14e-03, fs:0.67647 (r=0.697,p=0.657),  time:36.734, tt:844.874\n",
      "Ep:23, loss:0.00016, loss_test:0.10584, lr:9.14e-03, fs:0.68020 (r=0.677,p=0.684),  time:36.750, tt:881.989\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.10415, lr:9.14e-03, fs:0.68687 (r=0.687,p=0.687),  time:36.797, tt:919.930\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.10324, lr:9.14e-03, fs:0.71845 (r=0.747,p=0.692),  time:36.860, tt:958.350\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.10173, lr:9.14e-03, fs:0.74146 (r=0.768,p=0.717),  time:36.909, tt:996.539\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.10059, lr:9.14e-03, fs:0.74757 (r=0.778,p=0.720),  time:36.970, tt:1035.165\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.09915, lr:9.14e-03, fs:0.75362 (r=0.788,p=0.722),  time:36.945, tt:1071.410\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09803, lr:9.14e-03, fs:0.75248 (r=0.768,p=0.738),  time:36.955, tt:1108.650\n",
      "Ep:30, loss:0.00014, loss_test:0.09668, lr:9.14e-03, fs:0.76329 (r=0.798,p=0.731),  time:36.970, tt:1146.068\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09551, lr:9.14e-03, fs:0.76699 (r=0.798,p=0.738),  time:36.933, tt:1181.851\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.09460, lr:9.14e-03, fs:0.76329 (r=0.798,p=0.731),  time:36.959, tt:1219.646\n",
      "Ep:33, loss:0.00013, loss_test:0.09316, lr:9.14e-03, fs:0.78261 (r=0.818,p=0.750),  time:36.998, tt:1257.934\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.09313, lr:9.14e-03, fs:0.77778 (r=0.778,p=0.778),  time:37.041, tt:1296.446\n",
      "Ep:35, loss:0.00012, loss_test:0.09208, lr:9.14e-03, fs:0.78302 (r=0.838,p=0.735),  time:37.051, tt:1333.825\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.09120, lr:9.14e-03, fs:0.79000 (r=0.798,p=0.782),  time:37.066, tt:1371.458\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.09147, lr:9.14e-03, fs:0.75127 (r=0.747,p=0.755),  time:37.035, tt:1407.346\n",
      "Ep:38, loss:0.00011, loss_test:0.08913, lr:9.14e-03, fs:0.80000 (r=0.828,p=0.774),  time:37.041, tt:1444.585\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.09035, lr:9.14e-03, fs:0.74112 (r=0.737,p=0.745),  time:37.058, tt:1482.321\n",
      "Ep:40, loss:0.00011, loss_test:0.08834, lr:9.14e-03, fs:0.78351 (r=0.768,p=0.800),  time:37.077, tt:1520.144\n",
      "Ep:41, loss:0.00010, loss_test:0.08855, lr:9.14e-03, fs:0.76617 (r=0.778,p=0.755),  time:37.043, tt:1555.788\n",
      "Ep:42, loss:0.00010, loss_test:0.08816, lr:9.14e-03, fs:0.76382 (r=0.768,p=0.760),  time:37.042, tt:1592.815\n",
      "Ep:43, loss:0.00010, loss_test:0.08691, lr:9.14e-03, fs:0.77387 (r=0.778,p=0.770),  time:37.045, tt:1629.990\n",
      "Ep:44, loss:0.00010, loss_test:0.09053, lr:9.14e-03, fs:0.75248 (r=0.768,p=0.738),  time:37.039, tt:1666.745\n",
      "Ep:45, loss:0.00009, loss_test:0.08738, lr:9.14e-03, fs:0.77949 (r=0.768,p=0.792),  time:37.040, tt:1703.848\n",
      "Ep:46, loss:0.00009, loss_test:0.09039, lr:9.14e-03, fs:0.76329 (r=0.798,p=0.731),  time:37.066, tt:1742.092\n",
      "Ep:47, loss:0.00009, loss_test:0.08521, lr:9.14e-03, fs:0.77778 (r=0.778,p=0.778),  time:37.032, tt:1777.532\n",
      "Ep:48, loss:0.00009, loss_test:0.09144, lr:9.14e-03, fs:0.77451 (r=0.798,p=0.752),  time:37.047, tt:1815.291\n",
      "Ep:49, loss:0.00008, loss_test:0.08546, lr:9.14e-03, fs:0.77720 (r=0.758,p=0.798),  time:37.078, tt:1853.891\n",
      "Ep:50, loss:0.00008, loss_test:0.08803, lr:9.04e-03, fs:0.78607 (r=0.798,p=0.775),  time:37.089, tt:1891.553\n",
      "Ep:51, loss:0.00008, loss_test:0.08567, lr:8.95e-03, fs:0.78218 (r=0.798,p=0.767),  time:37.106, tt:1929.515\n",
      "Ep:52, loss:0.00008, loss_test:0.08731, lr:8.86e-03, fs:0.78351 (r=0.768,p=0.800),  time:37.107, tt:1966.653\n",
      "Ep:53, loss:0.00007, loss_test:0.08449, lr:8.78e-03, fs:0.79798 (r=0.798,p=0.798),  time:37.126, tt:2004.780\n",
      "Ep:54, loss:0.00007, loss_test:0.08763, lr:8.69e-03, fs:0.77612 (r=0.788,p=0.765),  time:37.133, tt:2042.338\n",
      "Ep:55, loss:0.00007, loss_test:0.08467, lr:8.60e-03, fs:0.81407 (r=0.818,p=0.810),  time:37.146, tt:2080.182\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.08209, lr:8.60e-03, fs:0.79208 (r=0.808,p=0.777),  time:37.135, tt:2116.681\n",
      "Ep:57, loss:0.00007, loss_test:0.08884, lr:8.60e-03, fs:0.79000 (r=0.798,p=0.782),  time:37.132, tt:2153.644\n",
      "Ep:58, loss:0.00006, loss_test:0.08126, lr:8.60e-03, fs:0.78756 (r=0.768,p=0.809),  time:37.149, tt:2191.787\n",
      "Ep:59, loss:0.00006, loss_test:0.08915, lr:8.60e-03, fs:0.74611 (r=0.727,p=0.766),  time:37.154, tt:2229.242\n",
      "Ep:60, loss:0.00007, loss_test:0.08417, lr:8.60e-03, fs:0.78607 (r=0.798,p=0.775),  time:37.128, tt:2264.813\n",
      "Ep:61, loss:0.00006, loss_test:0.08336, lr:8.60e-03, fs:0.77660 (r=0.737,p=0.820),  time:37.141, tt:2302.748\n",
      "Ep:62, loss:0.00006, loss_test:0.08466, lr:8.60e-03, fs:0.76768 (r=0.768,p=0.768),  time:37.152, tt:2340.561\n",
      "Ep:63, loss:0.00006, loss_test:0.08227, lr:8.60e-03, fs:0.77249 (r=0.737,p=0.811),  time:37.199, tt:2380.712\n",
      "Ep:64, loss:0.00005, loss_test:0.08433, lr:8.60e-03, fs:0.77083 (r=0.747,p=0.796),  time:37.208, tt:2418.492\n",
      "Ep:65, loss:0.00005, loss_test:0.08339, lr:8.60e-03, fs:0.75393 (r=0.727,p=0.783),  time:37.236, tt:2457.599\n",
      "Ep:66, loss:0.00005, loss_test:0.08036, lr:8.60e-03, fs:0.82126 (r=0.859,p=0.787),  time:37.228, tt:2494.291\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.08254, lr:8.60e-03, fs:0.76190 (r=0.727,p=0.800),  time:37.247, tt:2532.781\n",
      "Ep:68, loss:0.00005, loss_test:0.08522, lr:8.60e-03, fs:0.77320 (r=0.758,p=0.789),  time:37.268, tt:2571.512\n",
      "Ep:69, loss:0.00005, loss_test:0.08013, lr:8.60e-03, fs:0.77249 (r=0.737,p=0.811),  time:37.262, tt:2608.342\n",
      "Ep:70, loss:0.00005, loss_test:0.07945, lr:8.60e-03, fs:0.77348 (r=0.707,p=0.854),  time:37.241, tt:2644.077\n",
      "Ep:71, loss:0.00005, loss_test:0.08598, lr:8.60e-03, fs:0.74490 (r=0.737,p=0.753),  time:37.227, tt:2680.367\n",
      "Ep:72, loss:0.00005, loss_test:0.08248, lr:8.60e-03, fs:0.76087 (r=0.707,p=0.824),  time:37.223, tt:2717.251\n",
      "Ep:73, loss:0.00005, loss_test:0.07665, lr:8.60e-03, fs:0.83333 (r=0.859,p=0.810),  time:37.223, tt:2754.539\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.08056, lr:8.60e-03, fs:0.75936 (r=0.717,p=0.807),  time:37.213, tt:2790.940\n",
      "Ep:75, loss:0.00004, loss_test:0.08071, lr:8.60e-03, fs:0.77320 (r=0.758,p=0.789),  time:37.221, tt:2828.817\n",
      "Ep:76, loss:0.00004, loss_test:0.08457, lr:8.60e-03, fs:0.75532 (r=0.717,p=0.798),  time:37.216, tt:2865.637\n",
      "Ep:77, loss:0.00004, loss_test:0.08478, lr:8.60e-03, fs:0.76190 (r=0.727,p=0.800),  time:37.195, tt:2901.240\n",
      "Ep:78, loss:0.00004, loss_test:0.07889, lr:8.60e-03, fs:0.78947 (r=0.758,p=0.824),  time:37.219, tt:2940.320\n",
      "Ep:79, loss:0.00004, loss_test:0.08249, lr:8.60e-03, fs:0.75132 (r=0.717,p=0.789),  time:37.219, tt:2977.507\n",
      "Ep:80, loss:0.00004, loss_test:0.09254, lr:8.60e-03, fs:0.73846 (r=0.727,p=0.750),  time:37.205, tt:3013.594\n",
      "Ep:81, loss:0.00004, loss_test:0.07273, lr:8.60e-03, fs:0.87619 (r=0.929,p=0.829),  time:37.191, tt:3049.677\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00005, loss_test:0.08462, lr:8.60e-03, fs:0.75676 (r=0.707,p=0.814),  time:37.176, tt:3085.583\n",
      "Ep:83, loss:0.00004, loss_test:0.08682, lr:8.60e-03, fs:0.75393 (r=0.727,p=0.783),  time:37.141, tt:3119.877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:84, loss:0.00004, loss_test:0.07560, lr:8.60e-03, fs:0.83838 (r=0.838,p=0.838),  time:37.141, tt:3157.024\n",
      "Ep:85, loss:0.00005, loss_test:0.09523, lr:8.60e-03, fs:0.72727 (r=0.727,p=0.727),  time:37.123, tt:3192.599\n",
      "Ep:86, loss:0.00005, loss_test:0.07608, lr:8.60e-03, fs:0.84878 (r=0.879,p=0.821),  time:37.122, tt:3229.631\n",
      "Ep:87, loss:0.00005, loss_test:0.09442, lr:8.60e-03, fs:0.75000 (r=0.697,p=0.812),  time:37.086, tt:3263.531\n",
      "Ep:88, loss:0.00004, loss_test:0.07568, lr:8.60e-03, fs:0.85981 (r=0.929,p=0.800),  time:37.052, tt:3297.634\n",
      "Ep:89, loss:0.00004, loss_test:0.09327, lr:8.60e-03, fs:0.75132 (r=0.717,p=0.789),  time:37.011, tt:3330.945\n",
      "Ep:90, loss:0.00004, loss_test:0.07903, lr:8.60e-03, fs:0.82126 (r=0.859,p=0.787),  time:37.004, tt:3367.356\n",
      "Ep:91, loss:0.00004, loss_test:0.08523, lr:8.60e-03, fs:0.76190 (r=0.727,p=0.800),  time:37.000, tt:3403.983\n",
      "Ep:92, loss:0.00004, loss_test:0.08394, lr:8.60e-03, fs:0.75000 (r=0.697,p=0.812),  time:37.016, tt:3442.478\n",
      "Ep:93, loss:0.00003, loss_test:0.07636, lr:8.51e-03, fs:0.79188 (r=0.788,p=0.796),  time:37.014, tt:3479.291\n",
      "Ep:94, loss:0.00003, loss_test:0.08630, lr:8.43e-03, fs:0.75410 (r=0.697,p=0.821),  time:37.010, tt:3515.975\n",
      "Ep:95, loss:0.00003, loss_test:0.07996, lr:8.35e-03, fs:0.75132 (r=0.717,p=0.789),  time:36.990, tt:3551.078\n",
      "Ep:96, loss:0.00003, loss_test:0.08339, lr:8.26e-03, fs:0.76596 (r=0.727,p=0.809),  time:36.979, tt:3586.969\n",
      "Ep:97, loss:0.00003, loss_test:0.08290, lr:8.18e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.974, tt:3623.476\n",
      "Ep:98, loss:0.00003, loss_test:0.08032, lr:8.10e-03, fs:0.75789 (r=0.727,p=0.791),  time:36.970, tt:3660.056\n",
      "Ep:99, loss:0.00003, loss_test:0.08389, lr:8.02e-03, fs:0.75000 (r=0.697,p=0.812),  time:36.957, tt:3695.723\n",
      "Ep:100, loss:0.00003, loss_test:0.08646, lr:7.94e-03, fs:0.75269 (r=0.707,p=0.805),  time:36.954, tt:3732.334\n",
      "Ep:101, loss:0.00003, loss_test:0.07613, lr:7.86e-03, fs:0.76596 (r=0.727,p=0.809),  time:36.941, tt:3767.931\n",
      "Ep:102, loss:0.00003, loss_test:0.08788, lr:7.78e-03, fs:0.75269 (r=0.707,p=0.805),  time:36.932, tt:3804.034\n",
      "Ep:103, loss:0.00003, loss_test:0.07572, lr:7.70e-03, fs:0.78261 (r=0.727,p=0.847),  time:36.919, tt:3839.575\n",
      "Ep:104, loss:0.00003, loss_test:0.08566, lr:7.62e-03, fs:0.75936 (r=0.717,p=0.807),  time:36.910, tt:3875.555\n",
      "Ep:105, loss:0.00003, loss_test:0.08022, lr:7.55e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.894, tt:3910.722\n",
      "Ep:106, loss:0.00003, loss_test:0.08149, lr:7.47e-03, fs:0.75936 (r=0.717,p=0.807),  time:36.905, tt:3948.814\n",
      "Ep:107, loss:0.00003, loss_test:0.08242, lr:7.40e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.903, tt:3985.518\n",
      "Ep:108, loss:0.00003, loss_test:0.08470, lr:7.32e-03, fs:0.74595 (r=0.697,p=0.802),  time:36.898, tt:4021.829\n",
      "Ep:109, loss:0.00002, loss_test:0.08049, lr:7.25e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.893, tt:4058.268\n",
      "Ep:110, loss:0.00002, loss_test:0.08445, lr:7.18e-03, fs:0.75269 (r=0.707,p=0.805),  time:36.892, tt:4095.019\n",
      "Ep:111, loss:0.00002, loss_test:0.08207, lr:7.11e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.880, tt:4130.597\n",
      "Ep:112, loss:0.00002, loss_test:0.08451, lr:7.03e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.882, tt:4167.707\n",
      "Ep:113, loss:0.00002, loss_test:0.08012, lr:6.96e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.878, tt:4204.075\n",
      "Ep:114, loss:0.00002, loss_test:0.08650, lr:6.89e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.903, tt:4243.889\n",
      "Ep:115, loss:0.00002, loss_test:0.08137, lr:6.83e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.919, tt:4282.657\n",
      "Ep:116, loss:0.00002, loss_test:0.08636, lr:6.76e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.936, tt:4321.538\n",
      "Ep:117, loss:0.00002, loss_test:0.08121, lr:6.69e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.931, tt:4357.870\n",
      "Ep:118, loss:0.00002, loss_test:0.08326, lr:6.62e-03, fs:0.76503 (r=0.707,p=0.833),  time:36.934, tt:4395.142\n",
      "Ep:119, loss:0.00002, loss_test:0.08274, lr:6.56e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.943, tt:4433.104\n",
      "Ep:120, loss:0.00002, loss_test:0.08342, lr:6.49e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.938, tt:4469.461\n",
      "Ep:121, loss:0.00002, loss_test:0.08436, lr:6.43e-03, fs:0.76923 (r=0.707,p=0.843),  time:36.928, tt:4505.183\n",
      "Ep:122, loss:0.00002, loss_test:0.08402, lr:6.36e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.920, tt:4541.151\n",
      "Ep:123, loss:0.00002, loss_test:0.08495, lr:6.30e-03, fs:0.77174 (r=0.717,p=0.835),  time:36.910, tt:4576.875\n",
      "Ep:124, loss:0.00002, loss_test:0.08265, lr:6.24e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.898, tt:4612.253\n",
      "Ep:125, loss:0.00002, loss_test:0.08650, lr:6.17e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.884, tt:4647.412\n",
      "Ep:126, loss:0.00002, loss_test:0.07945, lr:6.11e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.876, tt:4683.311\n",
      "Ep:127, loss:0.00002, loss_test:0.08745, lr:6.05e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.878, tt:4720.435\n",
      "Ep:128, loss:0.00002, loss_test:0.08135, lr:5.99e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.871, tt:4756.310\n",
      "Ep:129, loss:0.00002, loss_test:0.08370, lr:5.93e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.864, tt:4792.276\n",
      "Ep:130, loss:0.00002, loss_test:0.08780, lr:5.87e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.862, tt:4828.924\n",
      "Ep:131, loss:0.00002, loss_test:0.08013, lr:5.81e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.859, tt:4865.450\n",
      "Ep:132, loss:0.00002, loss_test:0.08621, lr:5.75e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.891, tt:4906.471\n",
      "Ep:133, loss:0.00002, loss_test:0.08351, lr:5.70e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.894, tt:4943.822\n",
      "Ep:134, loss:0.00002, loss_test:0.08378, lr:5.64e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.903, tt:4981.872\n",
      "Ep:135, loss:0.00002, loss_test:0.08371, lr:5.58e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.886, tt:5016.555\n",
      "Ep:136, loss:0.00002, loss_test:0.08332, lr:5.53e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.887, tt:5053.535\n",
      "Ep:137, loss:0.00002, loss_test:0.08216, lr:5.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.887, tt:5090.463\n",
      "Ep:138, loss:0.00002, loss_test:0.08516, lr:5.42e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.891, tt:5127.804\n",
      "Ep:139, loss:0.00002, loss_test:0.08526, lr:5.36e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.892, tt:5164.876\n",
      "Ep:140, loss:0.00002, loss_test:0.08065, lr:5.31e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.884, tt:5200.617\n",
      "Ep:141, loss:0.00002, loss_test:0.08580, lr:5.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.884, tt:5237.531\n",
      "Ep:142, loss:0.00002, loss_test:0.08003, lr:5.20e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.875, tt:5273.189\n",
      "Ep:143, loss:0.00002, loss_test:0.08707, lr:5.15e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.872, tt:5309.545\n",
      "Ep:144, loss:0.00002, loss_test:0.08151, lr:5.10e-03, fs:0.79330 (r=0.717,p=0.887),  time:36.870, tt:5346.178\n",
      "Ep:145, loss:0.00002, loss_test:0.08421, lr:5.05e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.858, tt:5381.199\n",
      "Ep:146, loss:0.00002, loss_test:0.08790, lr:5.00e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.856, tt:5417.817\n",
      "Ep:147, loss:0.00002, loss_test:0.08044, lr:4.95e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.845, tt:5452.996\n",
      "Ep:148, loss:0.00002, loss_test:0.08876, lr:4.90e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.840, tt:5489.106\n",
      "Ep:149, loss:0.00002, loss_test:0.08129, lr:4.85e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.835, tt:5525.264\n",
      "Ep:150, loss:0.00002, loss_test:0.08648, lr:4.80e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.832, tt:5561.611\n",
      "Ep:151, loss:0.00002, loss_test:0.08296, lr:4.75e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.830, tt:5598.118\n",
      "Ep:152, loss:0.00002, loss_test:0.08565, lr:4.71e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.821, tt:5633.538\n",
      "Ep:153, loss:0.00002, loss_test:0.08237, lr:4.66e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.819, tt:5670.085\n",
      "Ep:154, loss:0.00001, loss_test:0.08322, lr:4.61e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.811, tt:5705.765\n",
      "Ep:155, loss:0.00001, loss_test:0.08887, lr:4.57e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.812, tt:5742.740\n",
      "Ep:156, loss:0.00001, loss_test:0.08073, lr:4.52e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.814, tt:5779.760\n",
      "Ep:157, loss:0.00001, loss_test:0.08614, lr:4.48e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.815, tt:5816.746\n",
      "Ep:158, loss:0.00001, loss_test:0.08488, lr:4.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.815, tt:5853.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:159, loss:0.00001, loss_test:0.08336, lr:4.39e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.816, tt:5890.625\n",
      "Ep:160, loss:0.00001, loss_test:0.08712, lr:4.34e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.825, tt:5928.752\n",
      "Ep:161, loss:0.00001, loss_test:0.08188, lr:4.30e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.815, tt:5964.040\n",
      "Ep:162, loss:0.00001, loss_test:0.08474, lr:4.26e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.818, tt:6001.334\n",
      "Ep:163, loss:0.00001, loss_test:0.08618, lr:4.21e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.820, tt:6038.481\n",
      "Ep:164, loss:0.00001, loss_test:0.08347, lr:4.17e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.821, tt:6075.396\n",
      "Ep:165, loss:0.00001, loss_test:0.08571, lr:4.13e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.832, tt:6114.135\n",
      "Ep:166, loss:0.00001, loss_test:0.08252, lr:4.09e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.836, tt:6151.598\n",
      "Ep:167, loss:0.00001, loss_test:0.08370, lr:4.05e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.839, tt:6189.002\n",
      "Ep:168, loss:0.00001, loss_test:0.08493, lr:4.01e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.846, tt:6226.993\n",
      "Ep:169, loss:0.00001, loss_test:0.08369, lr:3.97e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.855, tt:6265.278\n",
      "Ep:170, loss:0.00001, loss_test:0.08438, lr:3.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.857, tt:6302.537\n",
      "Ep:171, loss:0.00001, loss_test:0.08309, lr:3.89e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.857, tt:6339.444\n",
      "Ep:172, loss:0.00001, loss_test:0.08552, lr:3.85e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.847, tt:6374.491\n",
      "Ep:173, loss:0.00001, loss_test:0.08305, lr:3.81e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.846, tt:6411.199\n",
      "Ep:174, loss:0.00001, loss_test:0.08587, lr:3.77e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.839, tt:6446.898\n",
      "Ep:175, loss:0.00001, loss_test:0.08300, lr:3.73e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.838, tt:6483.412\n",
      "Ep:176, loss:0.00001, loss_test:0.08376, lr:3.70e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.824, tt:6517.878\n",
      "Ep:177, loss:0.00001, loss_test:0.08489, lr:3.66e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.822, tt:6554.234\n",
      "Ep:178, loss:0.00001, loss_test:0.08321, lr:3.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.826, tt:6591.846\n",
      "Ep:179, loss:0.00001, loss_test:0.08326, lr:3.59e-03, fs:0.79330 (r=0.717,p=0.887),  time:36.824, tt:6628.353\n",
      "Ep:180, loss:0.00001, loss_test:0.08517, lr:3.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.823, tt:6664.898\n",
      "Ep:181, loss:0.00001, loss_test:0.08384, lr:3.52e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.828, tt:6702.754\n",
      "Ep:182, loss:0.00001, loss_test:0.08401, lr:3.48e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.815, tt:6737.054\n",
      "Ep:183, loss:0.00001, loss_test:0.08140, lr:3.45e-03, fs:0.79330 (r=0.717,p=0.887),  time:36.808, tt:6772.653\n",
      "Ep:184, loss:0.00001, loss_test:0.08546, lr:3.41e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.806, tt:6809.189\n",
      "Ep:185, loss:0.00001, loss_test:0.08383, lr:3.38e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.791, tt:6843.039\n",
      "Ep:186, loss:0.00001, loss_test:0.08256, lr:3.34e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.785, tt:6878.821\n",
      "Ep:187, loss:0.00001, loss_test:0.08552, lr:3.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.783, tt:6915.137\n",
      "Ep:188, loss:0.00001, loss_test:0.08287, lr:3.28e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.784, tt:6952.194\n",
      "Ep:189, loss:0.00001, loss_test:0.08338, lr:3.24e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.791, tt:6990.228\n",
      "Ep:190, loss:0.00001, loss_test:0.08407, lr:3.21e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.787, tt:7026.320\n",
      "Ep:191, loss:0.00001, loss_test:0.08352, lr:3.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.783, tt:7062.318\n",
      "Ep:192, loss:0.00001, loss_test:0.08381, lr:3.15e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.785, tt:7099.490\n",
      "Ep:193, loss:0.00001, loss_test:0.08400, lr:3.12e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.791, tt:7137.420\n",
      "Ep:194, loss:0.00001, loss_test:0.08450, lr:3.09e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.788, tt:7173.571\n",
      "Ep:195, loss:0.00001, loss_test:0.08282, lr:3.05e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.794, tt:7211.645\n",
      "Ep:196, loss:0.00001, loss_test:0.08484, lr:3.02e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.783, tt:7246.336\n",
      "Ep:197, loss:0.00001, loss_test:0.08435, lr:2.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.779, tt:7282.298\n",
      "Ep:198, loss:0.00001, loss_test:0.08280, lr:2.96e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.775, tt:7318.189\n",
      "Ep:199, loss:0.00001, loss_test:0.08465, lr:2.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.777, tt:7355.483\n",
      "Ep:200, loss:0.00001, loss_test:0.08371, lr:2.90e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.773, tt:7391.315\n",
      "Ep:201, loss:0.00001, loss_test:0.08415, lr:2.88e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.777, tt:7428.962\n",
      "Ep:202, loss:0.00001, loss_test:0.08367, lr:2.85e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.784, tt:7467.060\n",
      "Ep:203, loss:0.00001, loss_test:0.08455, lr:2.82e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.781, tt:7503.367\n",
      "Ep:204, loss:0.00001, loss_test:0.08402, lr:2.79e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.765, tt:7536.873\n",
      "Ep:205, loss:0.00001, loss_test:0.08311, lr:2.76e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.748, tt:7570.028\n",
      "Ep:206, loss:0.00001, loss_test:0.08506, lr:2.73e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.733, tt:7603.703\n",
      "Ep:207, loss:0.00001, loss_test:0.08299, lr:2.71e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.714, tt:7636.501\n",
      "Ep:208, loss:0.00001, loss_test:0.08460, lr:2.68e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.692, tt:7668.539\n",
      "Ep:209, loss:0.00001, loss_test:0.08364, lr:2.65e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.673, tt:7701.296\n",
      "Ep:210, loss:0.00001, loss_test:0.08475, lr:2.63e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.660, tt:7735.227\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02576, lr:6.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:30.559, tt:30.559\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02685, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:32.440, tt:64.880\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02834, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.578, tt:97.733\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02807, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.382, tt:129.526\n",
      "Ep:4, loss:0.00005, loss_test:0.02721, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.787, tt:158.934\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02594, lr:6.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:31.947, tt:191.682\n",
      "Ep:6, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:32.277, tt:225.940\n",
      "Ep:7, loss:0.00004, loss_test:0.02397, lr:6.00e-02, fs:0.65370 (r=0.848,p=0.532),  time:32.509, tt:260.072\n",
      "Ep:8, loss:0.00004, loss_test:0.02412, lr:6.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:32.961, tt:296.650\n",
      "Ep:9, loss:0.00004, loss_test:0.02412, lr:6.00e-02, fs:0.62661 (r=0.737,p=0.545),  time:33.376, tt:333.757\n",
      "Ep:10, loss:0.00004, loss_test:0.02331, lr:6.00e-02, fs:0.61803 (r=0.727,p=0.537),  time:33.484, tt:368.328\n",
      "Ep:11, loss:0.00004, loss_test:0.02222, lr:6.00e-02, fs:0.62185 (r=0.747,p=0.532),  time:33.543, tt:402.515\n",
      "Ep:12, loss:0.00004, loss_test:0.02193, lr:6.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:33.609, tt:436.919\n",
      "Ep:13, loss:0.00004, loss_test:0.02187, lr:6.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:33.661, tt:471.261\n",
      "Ep:14, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:33.841, tt:507.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00003, loss_test:0.02201, lr:6.00e-02, fs:0.63598 (r=0.768,p=0.543),  time:33.950, tt:543.201\n",
      "Ep:16, loss:0.00003, loss_test:0.02180, lr:5.94e-02, fs:0.63519 (r=0.747,p=0.552),  time:34.029, tt:578.497\n",
      "Ep:17, loss:0.00003, loss_test:0.02122, lr:5.88e-02, fs:0.64629 (r=0.747,p=0.569),  time:34.112, tt:614.020\n",
      "Ep:18, loss:0.00003, loss_test:0.02057, lr:5.82e-02, fs:0.64629 (r=0.747,p=0.569),  time:34.171, tt:649.240\n",
      "Ep:19, loss:0.00003, loss_test:0.01992, lr:5.76e-02, fs:0.66379 (r=0.778,p=0.579),  time:34.212, tt:684.234\n",
      "Ep:20, loss:0.00003, loss_test:0.01936, lr:5.71e-02, fs:0.68936 (r=0.818,p=0.596),  time:34.286, tt:720.013\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01895, lr:5.71e-02, fs:0.69231 (r=0.818,p=0.600),  time:34.315, tt:754.938\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01866, lr:5.71e-02, fs:0.71489 (r=0.848,p=0.618),  time:34.392, tt:791.017\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01850, lr:5.71e-02, fs:0.71861 (r=0.838,p=0.629),  time:34.500, tt:828.009\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01832, lr:5.71e-02, fs:0.72174 (r=0.838,p=0.634),  time:34.562, tt:864.060\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01808, lr:5.71e-02, fs:0.71861 (r=0.838,p=0.629),  time:34.625, tt:900.260\n",
      "Ep:26, loss:0.00003, loss_test:0.01785, lr:5.71e-02, fs:0.73043 (r=0.848,p=0.641),  time:34.652, tt:935.604\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01755, lr:5.71e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.772, tt:973.621\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01723, lr:5.71e-02, fs:0.75536 (r=0.889,p=0.657),  time:34.809, tt:1009.450\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01701, lr:5.71e-02, fs:0.75536 (r=0.889,p=0.657),  time:34.842, tt:1045.251\n",
      "Ep:30, loss:0.00002, loss_test:0.01682, lr:5.71e-02, fs:0.76395 (r=0.899,p=0.664),  time:34.877, tt:1081.176\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01666, lr:5.71e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.898, tt:1116.740\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01654, lr:5.71e-02, fs:0.75771 (r=0.869,p=0.672),  time:34.940, tt:1153.034\n",
      "Ep:33, loss:0.00002, loss_test:0.01636, lr:5.71e-02, fs:0.75221 (r=0.859,p=0.669),  time:34.942, tt:1188.022\n",
      "Ep:34, loss:0.00002, loss_test:0.01628, lr:5.71e-02, fs:0.75221 (r=0.859,p=0.669),  time:34.945, tt:1223.062\n",
      "Ep:35, loss:0.00002, loss_test:0.01614, lr:5.71e-02, fs:0.75221 (r=0.859,p=0.669),  time:34.968, tt:1258.853\n",
      "Ep:36, loss:0.00002, loss_test:0.01615, lr:5.71e-02, fs:0.76106 (r=0.869,p=0.677),  time:34.996, tt:1294.852\n",
      "Ep:37, loss:0.00002, loss_test:0.01602, lr:5.71e-02, fs:0.76856 (r=0.889,p=0.677),  time:35.000, tt:1330.003\n",
      "Ep:38, loss:0.00002, loss_test:0.01608, lr:5.71e-02, fs:0.77679 (r=0.879,p=0.696),  time:34.983, tt:1364.333\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01612, lr:5.71e-02, fs:0.77679 (r=0.879,p=0.696),  time:34.974, tt:1398.961\n",
      "Ep:40, loss:0.00002, loss_test:0.01613, lr:5.71e-02, fs:0.77679 (r=0.879,p=0.696),  time:35.002, tt:1435.065\n",
      "Ep:41, loss:0.00002, loss_test:0.01624, lr:5.71e-02, fs:0.78027 (r=0.879,p=0.702),  time:34.994, tt:1469.745\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01624, lr:5.71e-02, fs:0.77982 (r=0.859,p=0.714),  time:35.014, tt:1505.593\n",
      "Ep:43, loss:0.00002, loss_test:0.01626, lr:5.71e-02, fs:0.78182 (r=0.869,p=0.711),  time:34.997, tt:1539.856\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01639, lr:5.71e-02, fs:0.78182 (r=0.869,p=0.711),  time:35.021, tt:1575.959\n",
      "Ep:45, loss:0.00002, loss_test:0.01643, lr:5.71e-02, fs:0.78899 (r=0.869,p=0.723),  time:35.052, tt:1612.390\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01643, lr:5.71e-02, fs:0.78899 (r=0.869,p=0.723),  time:35.054, tt:1647.542\n",
      "Ep:47, loss:0.00001, loss_test:0.01655, lr:5.71e-02, fs:0.77982 (r=0.859,p=0.714),  time:35.071, tt:1683.401\n",
      "Ep:48, loss:0.00001, loss_test:0.01682, lr:5.71e-02, fs:0.78704 (r=0.859,p=0.726),  time:35.093, tt:1719.568\n",
      "Ep:49, loss:0.00001, loss_test:0.01692, lr:5.71e-02, fs:0.78704 (r=0.859,p=0.726),  time:35.099, tt:1754.966\n",
      "Ep:50, loss:0.00001, loss_test:0.01681, lr:5.71e-02, fs:0.78341 (r=0.859,p=0.720),  time:35.097, tt:1789.926\n",
      "Ep:51, loss:0.00001, loss_test:0.01705, lr:5.71e-02, fs:0.78341 (r=0.859,p=0.720),  time:35.101, tt:1825.241\n",
      "Ep:52, loss:0.00001, loss_test:0.01717, lr:5.71e-02, fs:0.77778 (r=0.848,p=0.718),  time:35.113, tt:1860.981\n",
      "Ep:53, loss:0.00001, loss_test:0.01705, lr:5.71e-02, fs:0.77778 (r=0.848,p=0.718),  time:35.114, tt:1896.145\n",
      "Ep:54, loss:0.00001, loss_test:0.01756, lr:5.71e-02, fs:0.77209 (r=0.838,p=0.716),  time:35.106, tt:1930.821\n",
      "Ep:55, loss:0.00001, loss_test:0.01743, lr:5.71e-02, fs:0.78140 (r=0.848,p=0.724),  time:35.091, tt:1965.118\n",
      "Ep:56, loss:0.00001, loss_test:0.01769, lr:5.71e-02, fs:0.78505 (r=0.848,p=0.730),  time:35.050, tt:1997.829\n",
      "Ep:57, loss:0.00001, loss_test:0.01786, lr:5.65e-02, fs:0.78505 (r=0.848,p=0.730),  time:35.064, tt:2033.684\n",
      "Ep:58, loss:0.00001, loss_test:0.01760, lr:5.59e-02, fs:0.77778 (r=0.848,p=0.718),  time:35.037, tt:2067.211\n",
      "Ep:59, loss:0.00001, loss_test:0.01833, lr:5.54e-02, fs:0.78095 (r=0.828,p=0.739),  time:35.020, tt:2101.173\n",
      "Ep:60, loss:0.00001, loss_test:0.01766, lr:5.48e-02, fs:0.79245 (r=0.848,p=0.743),  time:35.040, tt:2137.412\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01819, lr:5.48e-02, fs:0.79245 (r=0.848,p=0.743),  time:35.078, tt:2174.819\n",
      "Ep:62, loss:0.00001, loss_test:0.01844, lr:5.48e-02, fs:0.77885 (r=0.818,p=0.743),  time:35.086, tt:2210.393\n",
      "Ep:63, loss:0.00001, loss_test:0.01803, lr:5.48e-02, fs:0.79426 (r=0.838,p=0.755),  time:35.087, tt:2245.579\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01853, lr:5.48e-02, fs:0.79024 (r=0.818,p=0.764),  time:35.104, tt:2281.745\n",
      "Ep:65, loss:0.00001, loss_test:0.01848, lr:5.48e-02, fs:0.79612 (r=0.828,p=0.766),  time:35.122, tt:2318.060\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01857, lr:5.48e-02, fs:0.78846 (r=0.828,p=0.752),  time:35.126, tt:2353.449\n",
      "Ep:67, loss:0.00001, loss_test:0.01873, lr:5.48e-02, fs:0.78049 (r=0.808,p=0.755),  time:35.139, tt:2389.451\n",
      "Ep:68, loss:0.00001, loss_test:0.01918, lr:5.48e-02, fs:0.75622 (r=0.768,p=0.745),  time:35.156, tt:2425.758\n",
      "Ep:69, loss:0.00001, loss_test:0.01882, lr:5.48e-02, fs:0.80000 (r=0.828,p=0.774),  time:35.174, tt:2462.189\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01930, lr:5.48e-02, fs:0.75000 (r=0.758,p=0.743),  time:35.176, tt:2497.487\n",
      "Ep:71, loss:0.00001, loss_test:0.01871, lr:5.48e-02, fs:0.79000 (r=0.798,p=0.782),  time:35.205, tt:2534.754\n",
      "Ep:72, loss:0.00001, loss_test:0.01967, lr:5.48e-02, fs:0.74112 (r=0.737,p=0.745),  time:35.215, tt:2570.701\n",
      "Ep:73, loss:0.00001, loss_test:0.01929, lr:5.48e-02, fs:0.75897 (r=0.747,p=0.771),  time:35.231, tt:2607.072\n",
      "Ep:74, loss:0.00001, loss_test:0.01983, lr:5.48e-02, fs:0.74490 (r=0.737,p=0.753),  time:35.241, tt:2643.063\n",
      "Ep:75, loss:0.00001, loss_test:0.01954, lr:5.48e-02, fs:0.75000 (r=0.727,p=0.774),  time:35.271, tt:2680.586\n",
      "Ep:76, loss:0.00001, loss_test:0.01967, lr:5.48e-02, fs:0.75000 (r=0.727,p=0.774),  time:35.266, tt:2715.489\n",
      "Ep:77, loss:0.00001, loss_test:0.02021, lr:5.48e-02, fs:0.74468 (r=0.707,p=0.787),  time:35.272, tt:2751.197\n",
      "Ep:78, loss:0.00001, loss_test:0.01989, lr:5.48e-02, fs:0.73016 (r=0.697,p=0.767),  time:35.259, tt:2785.469\n",
      "Ep:79, loss:0.00001, loss_test:0.02090, lr:5.48e-02, fs:0.73016 (r=0.697,p=0.767),  time:35.250, tt:2820.000\n",
      "Ep:80, loss:0.00001, loss_test:0.02018, lr:5.48e-02, fs:0.73797 (r=0.697,p=0.784),  time:35.263, tt:2856.299\n",
      "Ep:81, loss:0.00001, loss_test:0.02045, lr:5.43e-02, fs:0.73797 (r=0.697,p=0.784),  time:35.277, tt:2892.723\n",
      "Ep:82, loss:0.00001, loss_test:0.02096, lr:5.37e-02, fs:0.73797 (r=0.697,p=0.784),  time:35.289, tt:2928.987\n",
      "Ep:83, loss:0.00001, loss_test:0.02047, lr:5.32e-02, fs:0.73016 (r=0.697,p=0.767),  time:35.261, tt:2961.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:84, loss:0.00001, loss_test:0.02187, lr:5.27e-02, fs:0.73797 (r=0.697,p=0.784),  time:35.241, tt:2995.471\n",
      "Ep:85, loss:0.00001, loss_test:0.02027, lr:5.21e-02, fs:0.73797 (r=0.697,p=0.784),  time:35.239, tt:3030.586\n",
      "Ep:86, loss:0.00001, loss_test:0.02198, lr:5.16e-02, fs:0.73797 (r=0.697,p=0.784),  time:35.244, tt:3066.246\n",
      "Ep:87, loss:0.00001, loss_test:0.02062, lr:5.11e-02, fs:0.73404 (r=0.697,p=0.775),  time:35.249, tt:3101.905\n",
      "Ep:88, loss:0.00001, loss_test:0.02162, lr:5.06e-02, fs:0.73514 (r=0.687,p=0.791),  time:35.268, tt:3138.887\n",
      "Ep:89, loss:0.00001, loss_test:0.02118, lr:5.01e-02, fs:0.73514 (r=0.687,p=0.791),  time:35.281, tt:3175.310\n",
      "Ep:90, loss:0.00001, loss_test:0.02186, lr:4.96e-02, fs:0.73913 (r=0.687,p=0.800),  time:35.292, tt:3211.529\n",
      "Ep:91, loss:0.00001, loss_test:0.02217, lr:4.91e-02, fs:0.74317 (r=0.687,p=0.810),  time:35.297, tt:3247.340\n",
      "Ep:92, loss:0.00001, loss_test:0.02204, lr:4.86e-02, fs:0.74317 (r=0.687,p=0.810),  time:35.290, tt:3281.930\n",
      "Ep:93, loss:0.00001, loss_test:0.02181, lr:4.81e-02, fs:0.74725 (r=0.687,p=0.819),  time:35.283, tt:3316.602\n",
      "Ep:94, loss:0.00001, loss_test:0.02237, lr:4.76e-02, fs:0.74725 (r=0.687,p=0.819),  time:35.286, tt:3352.193\n",
      "Ep:95, loss:0.00001, loss_test:0.02215, lr:4.71e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.295, tt:3388.290\n",
      "Ep:96, loss:0.00001, loss_test:0.02280, lr:4.67e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.309, tt:3424.941\n",
      "Ep:97, loss:0.00001, loss_test:0.02227, lr:4.62e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.319, tt:3461.220\n",
      "Ep:98, loss:0.00001, loss_test:0.02372, lr:4.57e-02, fs:0.74725 (r=0.687,p=0.819),  time:35.330, tt:3497.633\n",
      "Ep:99, loss:0.00001, loss_test:0.02198, lr:4.53e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.349, tt:3534.864\n",
      "Ep:100, loss:0.00001, loss_test:0.02369, lr:4.48e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.358, tt:3571.143\n",
      "Ep:101, loss:0.00001, loss_test:0.02288, lr:4.44e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.378, tt:3608.506\n",
      "Ep:102, loss:0.00000, loss_test:0.02335, lr:4.39e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.404, tt:3646.577\n",
      "Ep:103, loss:0.00000, loss_test:0.02370, lr:4.35e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.416, tt:3683.302\n",
      "Ep:104, loss:0.00000, loss_test:0.02339, lr:4.31e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.432, tt:3720.402\n",
      "Ep:105, loss:0.00000, loss_test:0.02376, lr:4.26e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.432, tt:3755.801\n",
      "Ep:106, loss:0.00000, loss_test:0.02351, lr:4.22e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.429, tt:3790.900\n",
      "Ep:107, loss:0.00000, loss_test:0.02424, lr:4.18e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.437, tt:3827.144\n",
      "Ep:108, loss:0.00000, loss_test:0.02417, lr:4.14e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.436, tt:3862.515\n",
      "Ep:109, loss:0.00000, loss_test:0.02388, lr:4.10e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.454, tt:3899.987\n",
      "Ep:110, loss:0.00000, loss_test:0.02452, lr:4.05e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.458, tt:3935.795\n",
      "Ep:111, loss:0.00000, loss_test:0.02402, lr:4.01e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.457, tt:3971.151\n",
      "Ep:112, loss:0.00000, loss_test:0.02524, lr:3.97e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.449, tt:4005.790\n",
      "Ep:113, loss:0.00000, loss_test:0.02332, lr:3.93e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.449, tt:4041.204\n",
      "Ep:114, loss:0.00000, loss_test:0.02612, lr:3.89e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.434, tt:4074.883\n",
      "Ep:115, loss:0.00000, loss_test:0.02372, lr:3.86e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.435, tt:4110.405\n",
      "Ep:116, loss:0.00000, loss_test:0.02667, lr:3.82e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.437, tt:4146.140\n",
      "Ep:117, loss:0.00000, loss_test:0.02350, lr:3.78e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.428, tt:4180.514\n",
      "Ep:118, loss:0.00000, loss_test:0.02679, lr:3.74e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.422, tt:4215.234\n",
      "Ep:119, loss:0.00000, loss_test:0.02380, lr:3.70e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.420, tt:4250.358\n",
      "Ep:120, loss:0.00000, loss_test:0.02639, lr:3.67e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.430, tt:4287.044\n",
      "Ep:121, loss:0.00000, loss_test:0.02499, lr:3.63e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.438, tt:4323.451\n",
      "Ep:122, loss:0.00000, loss_test:0.02570, lr:3.59e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.433, tt:4358.211\n",
      "Ep:123, loss:0.00000, loss_test:0.02525, lr:3.56e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.442, tt:4394.805\n",
      "Ep:124, loss:0.00000, loss_test:0.02611, lr:3.52e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.436, tt:4429.561\n",
      "Ep:125, loss:0.00000, loss_test:0.02552, lr:3.49e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.450, tt:4466.740\n",
      "Ep:126, loss:0.00000, loss_test:0.02596, lr:3.45e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.456, tt:4502.926\n",
      "Ep:127, loss:0.00000, loss_test:0.02611, lr:3.42e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.448, tt:4537.406\n",
      "Ep:128, loss:0.00000, loss_test:0.02611, lr:3.38e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.446, tt:4572.553\n",
      "Ep:129, loss:0.00000, loss_test:0.02673, lr:3.35e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.454, tt:4609.056\n",
      "Ep:130, loss:0.00000, loss_test:0.02637, lr:3.32e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.456, tt:4644.768\n",
      "Ep:131, loss:0.00000, loss_test:0.02644, lr:3.28e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.448, tt:4679.168\n",
      "Ep:132, loss:0.00000, loss_test:0.02670, lr:3.25e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.441, tt:4713.668\n",
      "Ep:133, loss:0.00000, loss_test:0.02653, lr:3.22e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.444, tt:4749.517\n",
      "Ep:134, loss:0.00000, loss_test:0.02697, lr:3.19e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.447, tt:4785.368\n",
      "Ep:135, loss:0.00000, loss_test:0.02702, lr:3.15e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.459, tt:4822.358\n",
      "Ep:136, loss:0.00000, loss_test:0.02699, lr:3.12e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.456, tt:4857.460\n",
      "Ep:137, loss:0.00000, loss_test:0.02709, lr:3.09e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.454, tt:4892.599\n",
      "Ep:138, loss:0.00000, loss_test:0.02720, lr:3.06e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.457, tt:4928.484\n",
      "Ep:139, loss:0.00000, loss_test:0.02736, lr:3.03e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.452, tt:4963.347\n",
      "Ep:140, loss:0.00000, loss_test:0.02733, lr:3.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.442, tt:4997.296\n",
      "Ep:141, loss:0.00000, loss_test:0.02742, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.438, tt:5032.137\n",
      "Ep:142, loss:0.00000, loss_test:0.02759, lr:2.94e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.436, tt:5067.312\n",
      "Ep:143, loss:0.00000, loss_test:0.02736, lr:2.91e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.430, tt:5101.977\n",
      "Ep:144, loss:0.00000, loss_test:0.02773, lr:2.88e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.425, tt:5136.656\n",
      "Ep:145, loss:0.00000, loss_test:0.02756, lr:2.85e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.422, tt:5171.551\n",
      "Ep:146, loss:0.00000, loss_test:0.02781, lr:2.82e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.406, tt:5204.722\n",
      "Ep:147, loss:0.00000, loss_test:0.02801, lr:2.80e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.386, tt:5237.144\n",
      "Ep:148, loss:0.00000, loss_test:0.02771, lr:2.77e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.382, tt:5271.895\n",
      "Ep:149, loss:0.00000, loss_test:0.02833, lr:2.74e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.374, tt:5306.079\n",
      "Ep:150, loss:0.00000, loss_test:0.02801, lr:2.71e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.358, tt:5339.067\n",
      "Ep:151, loss:0.00000, loss_test:0.02797, lr:2.69e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.341, tt:5371.899\n",
      "Ep:152, loss:0.00000, loss_test:0.02840, lr:2.66e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.329, tt:5405.351\n",
      "Ep:153, loss:0.00000, loss_test:0.02797, lr:2.63e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.317, tt:5438.810\n",
      "Ep:154, loss:0.00000, loss_test:0.02830, lr:2.61e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.308, tt:5472.769\n",
      "Ep:155, loss:0.00000, loss_test:0.02848, lr:2.58e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.292, tt:5505.488\n",
      "Ep:156, loss:0.00000, loss_test:0.02840, lr:2.55e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.290, tt:5540.462\n",
      "Ep:157, loss:0.00000, loss_test:0.02849, lr:2.53e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.272, tt:5572.987\n",
      "Ep:158, loss:0.00000, loss_test:0.02859, lr:2.50e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.266, tt:5607.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:159, loss:0.00000, loss_test:0.02866, lr:2.48e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.265, tt:5642.335\n",
      "Ep:160, loss:0.00000, loss_test:0.02809, lr:2.45e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.255, tt:5675.978\n",
      "Ep:161, loss:0.00000, loss_test:0.02918, lr:2.43e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.242, tt:5709.217\n",
      "Ep:162, loss:0.00000, loss_test:0.02828, lr:2.40e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.244, tt:5744.693\n",
      "Ep:163, loss:0.00000, loss_test:0.02905, lr:2.38e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.243, tt:5779.932\n",
      "Ep:164, loss:0.00000, loss_test:0.02838, lr:2.36e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.233, tt:5813.398\n",
      "Ep:165, loss:0.00000, loss_test:0.02892, lr:2.33e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.227, tt:5847.710\n",
      "Ep:166, loss:0.00000, loss_test:0.02897, lr:2.31e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.217, tt:5881.241\n",
      "Ep:167, loss:0.00000, loss_test:0.02849, lr:2.29e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.205, tt:5914.385\n",
      "Ep:168, loss:0.00000, loss_test:0.02946, lr:2.26e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.198, tt:5948.515\n",
      "Ep:169, loss:0.00000, loss_test:0.02840, lr:2.24e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.196, tt:5983.314\n",
      "Ep:170, loss:0.00000, loss_test:0.02965, lr:2.22e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.185, tt:6016.560\n",
      "Ep:171, loss:0.00000, loss_test:0.02867, lr:2.20e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.183, tt:6051.399\n",
      "Ep:172, loss:0.00000, loss_test:0.02949, lr:2.17e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.175, tt:6085.338\n",
      "Ep:173, loss:0.00000, loss_test:0.02904, lr:2.15e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.178, tt:6120.949\n",
      "Ep:174, loss:0.00000, loss_test:0.02900, lr:2.13e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.175, tt:6155.637\n",
      "Ep:175, loss:0.00000, loss_test:0.02928, lr:2.11e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.171, tt:6190.104\n",
      "Ep:176, loss:0.00000, loss_test:0.02914, lr:2.09e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.179, tt:6226.623\n",
      "Ep:177, loss:0.00000, loss_test:0.02965, lr:2.07e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.181, tt:6262.131\n",
      "Ep:178, loss:0.00000, loss_test:0.02878, lr:2.05e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.183, tt:6297.738\n",
      "Ep:179, loss:0.00000, loss_test:0.02958, lr:2.03e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.178, tt:6332.106\n",
      "Ep:180, loss:0.00000, loss_test:0.02925, lr:2.01e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.179, tt:6367.378\n",
      "Ep:181, loss:0.00000, loss_test:0.02944, lr:1.99e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.178, tt:6402.389\n",
      "Ep:182, loss:0.00000, loss_test:0.02966, lr:1.97e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.173, tt:6436.636\n",
      "Ep:183, loss:0.00000, loss_test:0.02913, lr:1.95e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.174, tt:6472.036\n",
      "Ep:184, loss:0.00000, loss_test:0.02978, lr:1.93e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.162, tt:6504.899\n",
      "Ep:185, loss:0.00000, loss_test:0.02928, lr:1.91e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.162, tt:6540.065\n",
      "Ep:186, loss:0.00000, loss_test:0.02969, lr:1.89e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.177, tt:6578.156\n",
      "Ep:187, loss:0.00000, loss_test:0.02961, lr:1.87e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.171, tt:6612.101\n",
      "Ep:188, loss:0.00000, loss_test:0.02959, lr:1.85e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.175, tt:6648.145\n",
      "Ep:189, loss:0.00000, loss_test:0.02993, lr:1.83e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.177, tt:6683.634\n",
      "Ep:190, loss:0.00000, loss_test:0.02965, lr:1.81e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.171, tt:6717.584\n",
      "Ep:191, loss:0.00000, loss_test:0.02984, lr:1.80e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.164, tt:6751.457\n",
      "Ep:192, loss:0.00000, loss_test:0.02971, lr:1.78e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.165, tt:6786.802\n",
      "Ep:193, loss:0.00000, loss_test:0.02976, lr:1.76e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.169, tt:6822.837\n",
      "Ep:194, loss:0.00000, loss_test:0.02989, lr:1.74e-02, fs:0.74419 (r=0.646,p=0.877),  time:35.160, tt:6856.251\n",
      "Ep:195, loss:0.00000, loss_test:0.02994, lr:1.73e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.153, tt:6890.010\n",
      "Ep:196, loss:0.00000, loss_test:0.02976, lr:1.71e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.150, tt:6924.510\n",
      "Ep:197, loss:0.00000, loss_test:0.03005, lr:1.69e-02, fs:0.73684 (r=0.636,p=0.875),  time:35.147, tt:6959.065\n",
      "Ep:198, loss:0.00000, loss_test:0.03000, lr:1.67e-02, fs:0.73684 (r=0.636,p=0.875),  time:35.152, tt:6995.167\n",
      "Ep:199, loss:0.00000, loss_test:0.02991, lr:1.66e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.150, tt:7029.989\n",
      "Ep:200, loss:0.00000, loss_test:0.03026, lr:1.64e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.149, tt:7064.902\n",
      "Ep:201, loss:0.00000, loss_test:0.02986, lr:1.62e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.153, tt:7100.842\n",
      "Ep:202, loss:0.00000, loss_test:0.03028, lr:1.61e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.153, tt:7135.960\n",
      "Ep:203, loss:0.00000, loss_test:0.02990, lr:1.59e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.154, tt:7171.327\n",
      "Ep:204, loss:0.00000, loss_test:0.03024, lr:1.58e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.155, tt:7206.875\n",
      "Ep:205, loss:0.00000, loss_test:0.03010, lr:1.56e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.167, tt:7244.407\n",
      "Ep:206, loss:0.00000, loss_test:0.03003, lr:1.54e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.153, tt:7276.755\n",
      "Ep:207, loss:0.00000, loss_test:0.03049, lr:1.53e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.150, tt:7311.099\n",
      "Ep:208, loss:0.00000, loss_test:0.02993, lr:1.51e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.137, tt:7343.690\n",
      "Ep:209, loss:0.00000, loss_test:0.03027, lr:1.50e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.126, tt:7376.469\n",
      "Ep:210, loss:0.00000, loss_test:0.03031, lr:1.48e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.113, tt:7408.828\n",
      "Ep:211, loss:0.00000, loss_test:0.03016, lr:1.47e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.102, tt:7441.531\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13922, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:34.547, tt:34.547\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13689, lr:1.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:36.484, tt:72.969\n",
      "Ep:2, loss:0.00026, loss_test:0.13454, lr:1.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:36.660, tt:109.980\n",
      "Ep:3, loss:0.00025, loss_test:0.13511, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:36.457, tt:145.830\n",
      "Ep:4, loss:0.00025, loss_test:0.13531, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:35.596, tt:177.981\n",
      "Ep:5, loss:0.00025, loss_test:0.13378, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:35.281, tt:211.684\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.13157, lr:1.00e-02, fs:0.65560 (r=0.798,p=0.556),  time:35.516, tt:248.614\n",
      "Ep:7, loss:0.00024, loss_test:0.13017, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:35.545, tt:284.363\n",
      "Ep:8, loss:0.00023, loss_test:0.12933, lr:1.00e-02, fs:0.64135 (r=0.768,p=0.551),  time:35.387, tt:318.483\n",
      "Ep:9, loss:0.00023, loss_test:0.12831, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:35.620, tt:356.195\n",
      "Ep:10, loss:0.00022, loss_test:0.12691, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:35.699, tt:392.691\n",
      "Ep:11, loss:0.00022, loss_test:0.12583, lr:1.00e-02, fs:0.62100 (r=0.687,p=0.567),  time:35.672, tt:428.058\n",
      "Ep:12, loss:0.00021, loss_test:0.12490, lr:1.00e-02, fs:0.62385 (r=0.687,p=0.571),  time:35.839, tt:465.906\n",
      "Ep:13, loss:0.00021, loss_test:0.12477, lr:1.00e-02, fs:0.62673 (r=0.687,p=0.576),  time:35.946, tt:503.241\n",
      "Ep:14, loss:0.00020, loss_test:0.12488, lr:1.00e-02, fs:0.62264 (r=0.667,p=0.584),  time:36.064, tt:540.960\n",
      "Ep:15, loss:0.00020, loss_test:0.12510, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:36.120, tt:577.915\n",
      "Ep:16, loss:0.00019, loss_test:0.12467, lr:1.00e-02, fs:0.63415 (r=0.657,p=0.613),  time:36.172, tt:614.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00019, loss_test:0.12371, lr:9.90e-03, fs:0.63107 (r=0.657,p=0.607),  time:36.175, tt:651.148\n",
      "Ep:18, loss:0.00018, loss_test:0.12233, lr:9.80e-03, fs:0.63768 (r=0.667,p=0.611),  time:36.108, tt:686.043\n",
      "Ep:19, loss:0.00018, loss_test:0.12103, lr:9.70e-03, fs:0.63462 (r=0.667,p=0.606),  time:36.208, tt:724.162\n",
      "Ep:20, loss:0.00017, loss_test:0.11986, lr:9.61e-03, fs:0.65347 (r=0.667,p=0.641),  time:36.235, tt:760.925\n",
      "Ep:21, loss:0.00017, loss_test:0.11903, lr:9.51e-03, fs:0.66000 (r=0.667,p=0.653),  time:36.304, tt:798.681\n",
      "Ep:22, loss:0.00016, loss_test:0.11720, lr:9.41e-03, fs:0.66327 (r=0.657,p=0.670),  time:36.308, tt:835.077\n",
      "Ep:23, loss:0.00016, loss_test:0.11579, lr:9.32e-03, fs:0.66337 (r=0.677,p=0.650),  time:36.335, tt:872.045\n",
      "Ep:24, loss:0.00016, loss_test:0.11472, lr:9.23e-03, fs:0.67010 (r=0.657,p=0.684),  time:36.356, tt:908.895\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.11257, lr:9.23e-03, fs:0.67347 (r=0.667,p=0.680),  time:36.337, tt:944.759\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.11188, lr:9.23e-03, fs:0.67662 (r=0.687,p=0.667),  time:36.352, tt:981.510\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.11015, lr:9.23e-03, fs:0.68342 (r=0.687,p=0.680),  time:36.301, tt:1016.428\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.10934, lr:9.23e-03, fs:0.67016 (r=0.646,p=0.696),  time:36.307, tt:1052.904\n",
      "Ep:29, loss:0.00014, loss_test:0.10793, lr:9.23e-03, fs:0.67708 (r=0.657,p=0.699),  time:36.326, tt:1089.781\n",
      "Ep:30, loss:0.00013, loss_test:0.10649, lr:9.23e-03, fs:0.71066 (r=0.707,p=0.714),  time:36.409, tt:1128.687\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.10592, lr:9.23e-03, fs:0.65957 (r=0.626,p=0.697),  time:36.432, tt:1165.832\n",
      "Ep:32, loss:0.00013, loss_test:0.10471, lr:9.23e-03, fs:0.68449 (r=0.646,p=0.727),  time:36.475, tt:1203.664\n",
      "Ep:33, loss:0.00013, loss_test:0.10322, lr:9.23e-03, fs:0.69388 (r=0.687,p=0.701),  time:36.465, tt:1239.805\n",
      "Ep:34, loss:0.00012, loss_test:0.10289, lr:9.23e-03, fs:0.69519 (r=0.657,p=0.739),  time:36.438, tt:1275.348\n",
      "Ep:35, loss:0.00012, loss_test:0.10266, lr:9.23e-03, fs:0.70526 (r=0.677,p=0.736),  time:36.449, tt:1312.163\n",
      "Ep:36, loss:0.00012, loss_test:0.10043, lr:9.23e-03, fs:0.71277 (r=0.677,p=0.753),  time:36.465, tt:1349.203\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.10184, lr:9.23e-03, fs:0.68132 (r=0.626,p=0.747),  time:36.476, tt:1386.072\n",
      "Ep:38, loss:0.00011, loss_test:0.09907, lr:9.23e-03, fs:0.73196 (r=0.717,p=0.747),  time:36.513, tt:1424.024\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.10013, lr:9.23e-03, fs:0.68132 (r=0.626,p=0.747),  time:36.545, tt:1461.808\n",
      "Ep:40, loss:0.00010, loss_test:0.09975, lr:9.23e-03, fs:0.71875 (r=0.697,p=0.742),  time:36.557, tt:1498.855\n",
      "Ep:41, loss:0.00010, loss_test:0.09756, lr:9.23e-03, fs:0.70652 (r=0.657,p=0.765),  time:36.546, tt:1534.942\n",
      "Ep:42, loss:0.00010, loss_test:0.09728, lr:9.23e-03, fs:0.69945 (r=0.646,p=0.762),  time:36.511, tt:1569.973\n",
      "Ep:43, loss:0.00010, loss_test:0.09749, lr:9.23e-03, fs:0.72251 (r=0.697,p=0.750),  time:36.512, tt:1606.547\n",
      "Ep:44, loss:0.00009, loss_test:0.09658, lr:9.23e-03, fs:0.71111 (r=0.646,p=0.790),  time:36.496, tt:1642.330\n",
      "Ep:45, loss:0.00009, loss_test:0.09517, lr:9.23e-03, fs:0.73404 (r=0.697,p=0.775),  time:36.468, tt:1677.508\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.10505, lr:9.23e-03, fs:0.67039 (r=0.606,p=0.750),  time:36.453, tt:1713.303\n",
      "Ep:47, loss:0.00009, loss_test:0.09454, lr:9.23e-03, fs:0.75000 (r=0.727,p=0.774),  time:36.476, tt:1750.829\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.10026, lr:9.23e-03, fs:0.65476 (r=0.556,p=0.797),  time:36.492, tt:1788.129\n",
      "Ep:49, loss:0.00008, loss_test:0.09844, lr:9.23e-03, fs:0.72043 (r=0.677,p=0.770),  time:36.485, tt:1824.245\n",
      "Ep:50, loss:0.00008, loss_test:0.09572, lr:9.23e-03, fs:0.72928 (r=0.667,p=0.805),  time:36.493, tt:1861.168\n",
      "Ep:51, loss:0.00008, loss_test:0.09065, lr:9.23e-03, fs:0.78947 (r=0.758,p=0.824),  time:36.461, tt:1895.979\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.10272, lr:9.23e-03, fs:0.67416 (r=0.606,p=0.759),  time:36.467, tt:1932.752\n",
      "Ep:53, loss:0.00007, loss_test:0.09118, lr:9.23e-03, fs:0.76596 (r=0.727,p=0.809),  time:36.493, tt:1970.607\n",
      "Ep:54, loss:0.00007, loss_test:0.09711, lr:9.23e-03, fs:0.66667 (r=0.566,p=0.812),  time:36.501, tt:2007.533\n",
      "Ep:55, loss:0.00007, loss_test:0.09284, lr:9.23e-03, fs:0.76190 (r=0.727,p=0.800),  time:36.475, tt:2042.593\n",
      "Ep:56, loss:0.00007, loss_test:0.09864, lr:9.23e-03, fs:0.71277 (r=0.677,p=0.753),  time:36.482, tt:2079.491\n",
      "Ep:57, loss:0.00006, loss_test:0.09462, lr:9.23e-03, fs:0.72131 (r=0.667,p=0.786),  time:36.467, tt:2115.083\n",
      "Ep:58, loss:0.00006, loss_test:0.09083, lr:9.23e-03, fs:0.79397 (r=0.798,p=0.790),  time:36.461, tt:2151.198\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.10730, lr:9.23e-03, fs:0.65909 (r=0.586,p=0.753),  time:36.451, tt:2187.061\n",
      "Ep:60, loss:0.00006, loss_test:0.08687, lr:9.23e-03, fs:0.82000 (r=0.828,p=0.812),  time:36.432, tt:2222.371\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.10252, lr:9.23e-03, fs:0.70968 (r=0.667,p=0.759),  time:36.443, tt:2259.452\n",
      "Ep:62, loss:0.00006, loss_test:0.09671, lr:9.23e-03, fs:0.72251 (r=0.697,p=0.750),  time:36.414, tt:2294.074\n",
      "Ep:63, loss:0.00005, loss_test:0.09331, lr:9.23e-03, fs:0.66279 (r=0.576,p=0.781),  time:36.412, tt:2330.385\n",
      "Ep:64, loss:0.00005, loss_test:0.09148, lr:9.23e-03, fs:0.70718 (r=0.646,p=0.780),  time:36.380, tt:2364.732\n",
      "Ep:65, loss:0.00005, loss_test:0.10044, lr:9.23e-03, fs:0.69474 (r=0.667,p=0.725),  time:36.363, tt:2399.976\n",
      "Ep:66, loss:0.00006, loss_test:0.10508, lr:9.23e-03, fs:0.70588 (r=0.667,p=0.750),  time:36.375, tt:2437.127\n",
      "Ep:67, loss:0.00005, loss_test:0.08912, lr:9.23e-03, fs:0.70857 (r=0.626,p=0.816),  time:36.391, tt:2474.613\n",
      "Ep:68, loss:0.00005, loss_test:0.10124, lr:9.23e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.383, tt:2510.428\n",
      "Ep:69, loss:0.00005, loss_test:0.09186, lr:9.23e-03, fs:0.69189 (r=0.646,p=0.744),  time:36.389, tt:2547.255\n",
      "Ep:70, loss:0.00004, loss_test:0.09162, lr:9.23e-03, fs:0.65476 (r=0.556,p=0.797),  time:36.387, tt:2583.498\n",
      "Ep:71, loss:0.00004, loss_test:0.10520, lr:9.23e-03, fs:0.68783 (r=0.657,p=0.722),  time:36.374, tt:2618.937\n",
      "Ep:72, loss:0.00005, loss_test:0.09296, lr:9.14e-03, fs:0.70175 (r=0.606,p=0.833),  time:36.401, tt:2657.292\n",
      "Ep:73, loss:0.00005, loss_test:0.09502, lr:9.04e-03, fs:0.63218 (r=0.556,p=0.733),  time:36.384, tt:2692.446\n",
      "Ep:74, loss:0.00004, loss_test:0.10107, lr:8.95e-03, fs:0.68132 (r=0.626,p=0.747),  time:36.369, tt:2727.686\n",
      "Ep:75, loss:0.00004, loss_test:0.09794, lr:8.86e-03, fs:0.61078 (r=0.515,p=0.750),  time:36.365, tt:2763.729\n",
      "Ep:76, loss:0.00004, loss_test:0.09330, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:36.368, tt:2800.368\n",
      "Ep:77, loss:0.00004, loss_test:0.10500, lr:8.69e-03, fs:0.70588 (r=0.606,p=0.845),  time:36.370, tt:2836.872\n",
      "Ep:78, loss:0.00004, loss_test:0.08753, lr:8.60e-03, fs:0.76847 (r=0.788,p=0.750),  time:36.380, tt:2874.003\n",
      "Ep:79, loss:0.00004, loss_test:0.10410, lr:8.51e-03, fs:0.69714 (r=0.616,p=0.803),  time:36.382, tt:2910.539\n",
      "Ep:80, loss:0.00004, loss_test:0.09708, lr:8.43e-03, fs:0.68889 (r=0.626,p=0.765),  time:36.406, tt:2948.914\n",
      "Ep:81, loss:0.00004, loss_test:0.09250, lr:8.35e-03, fs:0.68966 (r=0.606,p=0.800),  time:36.402, tt:2984.964\n",
      "Ep:82, loss:0.00004, loss_test:0.11040, lr:8.26e-03, fs:0.68508 (r=0.626,p=0.756),  time:36.415, tt:3022.415\n",
      "Ep:83, loss:0.00004, loss_test:0.08837, lr:8.18e-03, fs:0.77083 (r=0.747,p=0.796),  time:36.409, tt:3058.378\n",
      "Ep:84, loss:0.00004, loss_test:0.11094, lr:8.10e-03, fs:0.69231 (r=0.636,p=0.759),  time:36.417, tt:3095.450\n",
      "Ep:85, loss:0.00004, loss_test:0.08789, lr:8.02e-03, fs:0.75000 (r=0.697,p=0.812),  time:36.409, tt:3131.135\n",
      "Ep:86, loss:0.00004, loss_test:0.11201, lr:7.94e-03, fs:0.67760 (r=0.626,p=0.738),  time:36.390, tt:3165.898\n",
      "Ep:87, loss:0.00004, loss_test:0.09062, lr:7.86e-03, fs:0.71676 (r=0.626,p=0.838),  time:36.353, tt:3199.029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:88, loss:0.00003, loss_test:0.10601, lr:7.78e-03, fs:0.68852 (r=0.636,p=0.750),  time:36.353, tt:3235.400\n",
      "Ep:89, loss:0.00003, loss_test:0.10023, lr:7.70e-03, fs:0.64327 (r=0.556,p=0.764),  time:36.355, tt:3271.990\n",
      "Ep:90, loss:0.00003, loss_test:0.10209, lr:7.62e-03, fs:0.68156 (r=0.616,p=0.762),  time:36.338, tt:3306.779\n",
      "Ep:91, loss:0.00003, loss_test:0.09777, lr:7.55e-03, fs:0.67816 (r=0.596,p=0.787),  time:36.333, tt:3342.633\n",
      "Ep:92, loss:0.00003, loss_test:0.11009, lr:7.47e-03, fs:0.67033 (r=0.616,p=0.735),  time:36.337, tt:3379.360\n",
      "Ep:93, loss:0.00003, loss_test:0.09051, lr:7.40e-03, fs:0.72316 (r=0.646,p=0.821),  time:36.342, tt:3416.171\n",
      "Ep:94, loss:0.00003, loss_test:0.11120, lr:7.32e-03, fs:0.67760 (r=0.626,p=0.738),  time:36.326, tt:3450.961\n",
      "Ep:95, loss:0.00003, loss_test:0.09362, lr:7.25e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.315, tt:3486.255\n",
      "Ep:96, loss:0.00003, loss_test:0.10577, lr:7.18e-03, fs:0.67778 (r=0.616,p=0.753),  time:36.311, tt:3522.130\n",
      "Ep:97, loss:0.00003, loss_test:0.09925, lr:7.11e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.301, tt:3557.505\n",
      "Ep:98, loss:0.00003, loss_test:0.10930, lr:7.03e-03, fs:0.67033 (r=0.616,p=0.735),  time:36.287, tt:3592.455\n",
      "Ep:99, loss:0.00003, loss_test:0.09412, lr:6.96e-03, fs:0.71186 (r=0.636,p=0.808),  time:36.285, tt:3628.466\n",
      "Ep:100, loss:0.00003, loss_test:0.10906, lr:6.89e-03, fs:0.68156 (r=0.616,p=0.762),  time:36.278, tt:3664.112\n",
      "Ep:101, loss:0.00003, loss_test:0.09948, lr:6.83e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.266, tt:3699.099\n",
      "Ep:102, loss:0.00003, loss_test:0.10639, lr:6.76e-03, fs:0.69274 (r=0.626,p=0.775),  time:36.265, tt:3735.334\n",
      "Ep:103, loss:0.00003, loss_test:0.09930, lr:6.69e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.251, tt:3770.142\n",
      "Ep:104, loss:0.00002, loss_test:0.10288, lr:6.62e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.250, tt:3806.250\n",
      "Ep:105, loss:0.00002, loss_test:0.10130, lr:6.56e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.242, tt:3841.611\n",
      "Ep:106, loss:0.00002, loss_test:0.10227, lr:6.49e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.227, tt:3876.244\n",
      "Ep:107, loss:0.00002, loss_test:0.10274, lr:6.43e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.216, tt:3911.289\n",
      "Ep:108, loss:0.00002, loss_test:0.10294, lr:6.36e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.220, tt:3947.937\n",
      "Ep:109, loss:0.00002, loss_test:0.10032, lr:6.30e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.219, tt:3984.042\n",
      "Ep:110, loss:0.00002, loss_test:0.10460, lr:6.24e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.219, tt:4020.285\n",
      "Ep:111, loss:0.00002, loss_test:0.10102, lr:6.17e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.214, tt:4055.973\n",
      "Ep:112, loss:0.00002, loss_test:0.10259, lr:6.11e-03, fs:0.69274 (r=0.626,p=0.775),  time:36.207, tt:4091.435\n",
      "Ep:113, loss:0.00002, loss_test:0.10400, lr:6.05e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.214, tt:4128.381\n",
      "Ep:114, loss:0.00002, loss_test:0.10286, lr:5.99e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.198, tt:4162.717\n",
      "Ep:115, loss:0.00002, loss_test:0.10417, lr:5.93e-03, fs:0.69274 (r=0.626,p=0.775),  time:36.200, tt:4199.228\n",
      "Ep:116, loss:0.00002, loss_test:0.09994, lr:5.87e-03, fs:0.72093 (r=0.626,p=0.849),  time:36.177, tt:4232.671\n",
      "Ep:117, loss:0.00002, loss_test:0.10466, lr:5.81e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.166, tt:4267.645\n",
      "Ep:118, loss:0.00002, loss_test:0.10254, lr:5.75e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.168, tt:4303.987\n",
      "Ep:119, loss:0.00002, loss_test:0.10446, lr:5.70e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.154, tt:4338.536\n",
      "Ep:120, loss:0.00002, loss_test:0.10246, lr:5.64e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.149, tt:4374.087\n",
      "Ep:121, loss:0.00002, loss_test:0.10573, lr:5.58e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.144, tt:4409.614\n",
      "Ep:122, loss:0.00002, loss_test:0.10342, lr:5.53e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.147, tt:4446.045\n",
      "Ep:123, loss:0.00002, loss_test:0.10425, lr:5.47e-03, fs:0.69663 (r=0.626,p=0.785),  time:36.129, tt:4479.960\n",
      "Ep:124, loss:0.00002, loss_test:0.10442, lr:5.42e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.136, tt:4516.975\n",
      "Ep:125, loss:0.00002, loss_test:0.10248, lr:5.36e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.125, tt:4551.699\n",
      "Ep:126, loss:0.00002, loss_test:0.10328, lr:5.31e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.113, tt:4586.395\n",
      "Ep:127, loss:0.00002, loss_test:0.10348, lr:5.26e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.105, tt:4621.443\n",
      "Ep:128, loss:0.00002, loss_test:0.10472, lr:5.20e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.100, tt:4656.918\n",
      "Ep:129, loss:0.00002, loss_test:0.10310, lr:5.15e-03, fs:0.70056 (r=0.626,p=0.795),  time:36.097, tt:4692.565\n",
      "Ep:130, loss:0.00002, loss_test:0.10402, lr:5.10e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.090, tt:4727.726\n",
      "Ep:131, loss:0.00002, loss_test:0.10461, lr:5.05e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.091, tt:4763.948\n",
      "Ep:132, loss:0.00002, loss_test:0.10569, lr:5.00e-03, fs:0.70455 (r=0.626,p=0.805),  time:36.085, tt:4799.319\n",
      "Ep:133, loss:0.00002, loss_test:0.10367, lr:4.95e-03, fs:0.71264 (r=0.626,p=0.827),  time:36.083, tt:4835.105\n",
      "Ep:134, loss:0.00002, loss_test:0.10312, lr:4.90e-03, fs:0.69714 (r=0.616,p=0.803),  time:36.076, tt:4870.287\n",
      "Ep:135, loss:0.00002, loss_test:0.10480, lr:4.85e-03, fs:0.70857 (r=0.626,p=0.816),  time:36.063, tt:4904.569\n",
      "Ep:136, loss:0.00002, loss_test:0.10383, lr:4.80e-03, fs:0.70857 (r=0.626,p=0.816),  time:36.062, tt:4940.477\n",
      "Ep:137, loss:0.00002, loss_test:0.10486, lr:4.75e-03, fs:0.69714 (r=0.616,p=0.803),  time:36.054, tt:4975.392\n",
      "Ep:138, loss:0.00002, loss_test:0.10238, lr:4.71e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.038, tt:5009.352\n",
      "Ep:139, loss:0.00002, loss_test:0.10806, lr:4.66e-03, fs:0.70115 (r=0.616,p=0.813),  time:36.032, tt:5044.441\n",
      "Ep:140, loss:0.00002, loss_test:0.10186, lr:4.61e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.025, tt:5079.503\n",
      "Ep:141, loss:0.00002, loss_test:0.10775, lr:4.57e-03, fs:0.70115 (r=0.616,p=0.813),  time:36.015, tt:5114.122\n",
      "Ep:142, loss:0.00002, loss_test:0.10480, lr:4.52e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.015, tt:5150.145\n",
      "Ep:143, loss:0.00002, loss_test:0.10538, lr:4.48e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.012, tt:5185.676\n",
      "Ep:144, loss:0.00002, loss_test:0.10808, lr:4.43e-03, fs:0.70520 (r=0.616,p=0.824),  time:36.012, tt:5221.698\n",
      "Ep:145, loss:0.00002, loss_test:0.10255, lr:4.39e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.995, tt:5255.311\n",
      "Ep:146, loss:0.00002, loss_test:0.11062, lr:4.34e-03, fs:0.69364 (r=0.606,p=0.811),  time:36.000, tt:5292.010\n",
      "Ep:147, loss:0.00002, loss_test:0.10282, lr:4.30e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.995, tt:5327.266\n",
      "Ep:148, loss:0.00002, loss_test:0.10773, lr:4.26e-03, fs:0.70115 (r=0.616,p=0.813),  time:35.991, tt:5362.593\n",
      "Ep:149, loss:0.00001, loss_test:0.10740, lr:4.21e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.984, tt:5397.576\n",
      "Ep:150, loss:0.00001, loss_test:0.10384, lr:4.17e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.978, tt:5432.728\n",
      "Ep:151, loss:0.00001, loss_test:0.10895, lr:4.13e-03, fs:0.70115 (r=0.616,p=0.813),  time:35.972, tt:5467.783\n",
      "Ep:152, loss:0.00001, loss_test:0.10472, lr:4.09e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.968, tt:5503.086\n",
      "Ep:153, loss:0.00001, loss_test:0.10688, lr:4.05e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.956, tt:5537.212\n",
      "Ep:154, loss:0.00001, loss_test:0.10544, lr:4.01e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.946, tt:5571.591\n",
      "Ep:155, loss:0.00001, loss_test:0.10555, lr:3.97e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.947, tt:5607.707\n",
      "Ep:156, loss:0.00001, loss_test:0.10633, lr:3.93e-03, fs:0.70520 (r=0.616,p=0.824),  time:35.936, tt:5642.026\n",
      "Ep:157, loss:0.00001, loss_test:0.10501, lr:3.89e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.947, tt:5679.628\n",
      "Ep:158, loss:0.00001, loss_test:0.10606, lr:3.85e-03, fs:0.70520 (r=0.616,p=0.824),  time:35.956, tt:5716.967\n",
      "Ep:159, loss:0.00001, loss_test:0.10456, lr:3.81e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.952, tt:5752.359\n",
      "Ep:160, loss:0.00001, loss_test:0.10668, lr:3.77e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.961, tt:5789.762\n",
      "Ep:161, loss:0.00001, loss_test:0.10483, lr:3.73e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.965, tt:5826.325\n",
      "Ep:162, loss:0.00001, loss_test:0.10653, lr:3.70e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.972, tt:5863.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00001, loss_test:0.10563, lr:3.66e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.979, tt:5900.632\n",
      "Ep:164, loss:0.00001, loss_test:0.10624, lr:3.62e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.994, tt:5938.975\n",
      "Ep:165, loss:0.00001, loss_test:0.10523, lr:3.59e-03, fs:0.73054 (r=0.616,p=0.897),  time:35.996, tt:5975.349\n",
      "Ep:166, loss:0.00001, loss_test:0.10644, lr:3.55e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.997, tt:6011.504\n",
      "Ep:167, loss:0.00001, loss_test:0.10576, lr:3.52e-03, fs:0.70930 (r=0.616,p=0.836),  time:35.999, tt:6047.783\n",
      "Ep:168, loss:0.00001, loss_test:0.10588, lr:3.48e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.003, tt:6084.568\n",
      "Ep:169, loss:0.00001, loss_test:0.10585, lr:3.45e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.009, tt:6121.572\n",
      "Ep:170, loss:0.00001, loss_test:0.10574, lr:3.41e-03, fs:0.70930 (r=0.616,p=0.836),  time:36.019, tt:6159.246\n",
      "Ep:171, loss:0.00001, loss_test:0.10569, lr:3.38e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.025, tt:6196.360\n",
      "Ep:172, loss:0.00001, loss_test:0.10656, lr:3.34e-03, fs:0.70930 (r=0.616,p=0.836),  time:36.030, tt:6233.187\n",
      "Ep:173, loss:0.00001, loss_test:0.10575, lr:3.31e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.029, tt:6269.125\n",
      "Ep:174, loss:0.00001, loss_test:0.10614, lr:3.28e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.035, tt:6306.127\n",
      "Ep:175, loss:0.00001, loss_test:0.10555, lr:3.24e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.041, tt:6343.223\n",
      "Ep:176, loss:0.00001, loss_test:0.10650, lr:3.21e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.037, tt:6378.561\n",
      "Ep:177, loss:0.00001, loss_test:0.10561, lr:3.18e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.037, tt:6414.575\n",
      "Ep:178, loss:0.00001, loss_test:0.10665, lr:3.15e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.027, tt:6448.890\n",
      "Ep:179, loss:0.00001, loss_test:0.10682, lr:3.12e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.025, tt:6484.564\n",
      "Ep:180, loss:0.00001, loss_test:0.10521, lr:3.09e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.027, tt:6520.975\n",
      "Ep:181, loss:0.00001, loss_test:0.10749, lr:3.05e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.031, tt:6557.623\n",
      "Ep:182, loss:0.00001, loss_test:0.10509, lr:3.02e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.031, tt:6593.594\n",
      "Ep:183, loss:0.00001, loss_test:0.10722, lr:2.99e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.025, tt:6628.681\n",
      "Ep:184, loss:0.00001, loss_test:0.10722, lr:2.96e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.024, tt:6664.373\n",
      "Ep:185, loss:0.00001, loss_test:0.10501, lr:2.93e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.029, tt:6701.339\n",
      "Ep:186, loss:0.00001, loss_test:0.10786, lr:2.90e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.034, tt:6738.339\n",
      "Ep:187, loss:0.00001, loss_test:0.10540, lr:2.88e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.026, tt:6772.966\n",
      "Ep:188, loss:0.00001, loss_test:0.10551, lr:2.85e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.028, tt:6809.243\n",
      "Ep:189, loss:0.00001, loss_test:0.10803, lr:2.82e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.031, tt:6845.826\n",
      "Ep:190, loss:0.00001, loss_test:0.10563, lr:2.79e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.039, tt:6883.373\n",
      "Ep:191, loss:0.00001, loss_test:0.10605, lr:2.76e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.036, tt:6918.985\n",
      "Ep:192, loss:0.00001, loss_test:0.10679, lr:2.73e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.042, tt:6956.016\n",
      "Ep:193, loss:0.00001, loss_test:0.10514, lr:2.71e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.044, tt:6992.546\n",
      "Ep:194, loss:0.00001, loss_test:0.10651, lr:2.68e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.049, tt:7029.557\n",
      "Ep:195, loss:0.00001, loss_test:0.10574, lr:2.65e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.044, tt:7064.639\n",
      "Ep:196, loss:0.00001, loss_test:0.10596, lr:2.63e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.047, tt:7101.206\n",
      "Ep:197, loss:0.00001, loss_test:0.10643, lr:2.60e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.046, tt:7137.120\n",
      "Ep:198, loss:0.00001, loss_test:0.10547, lr:2.57e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.047, tt:7173.311\n",
      "Ep:199, loss:0.00001, loss_test:0.10547, lr:2.55e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.043, tt:7208.507\n",
      "Ep:200, loss:0.00001, loss_test:0.10648, lr:2.52e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.042, tt:7244.533\n",
      "Ep:201, loss:0.00001, loss_test:0.10557, lr:2.50e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.045, tt:7280.996\n",
      "Ep:202, loss:0.00001, loss_test:0.10614, lr:2.47e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.050, tt:7318.116\n",
      "Ep:203, loss:0.00001, loss_test:0.10592, lr:2.45e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.049, tt:7353.952\n",
      "Ep:204, loss:0.00001, loss_test:0.10587, lr:2.42e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.054, tt:7390.983\n",
      "Ep:205, loss:0.00001, loss_test:0.10589, lr:2.40e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.052, tt:7426.727\n",
      "Ep:206, loss:0.00001, loss_test:0.10613, lr:2.38e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.044, tt:7461.118\n",
      "Ep:207, loss:0.00001, loss_test:0.10526, lr:2.35e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.032, tt:7494.749\n",
      "Ep:208, loss:0.00001, loss_test:0.10616, lr:2.33e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.007, tt:7525.420\n",
      "Ep:209, loss:0.00001, loss_test:0.10588, lr:2.31e-03, fs:0.72619 (r=0.616,p=0.884),  time:35.992, tt:7558.419\n",
      "Ep:210, loss:0.00001, loss_test:0.10661, lr:2.28e-03, fs:0.73054 (r=0.616,p=0.897),  time:35.980, tt:7591.765\n",
      "Ep:211, loss:0.00001, loss_test:0.10660, lr:2.26e-03, fs:0.73054 (r=0.616,p=0.897),  time:35.964, tt:7624.300\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02989, lr:6.00e-02, fs:0.59903 (r=0.626,p=0.574),  time:32.756, tt:32.756\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02300, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:32.997, tt:65.994\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02504, lr:6.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:33.689, tt:101.067\n",
      "Ep:3, loss:0.00005, loss_test:0.02637, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.832, tt:135.329\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02654, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.532, tt:167.661\n",
      "Ep:5, loss:0.00005, loss_test:0.02621, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:32.897, tt:197.380\n",
      "Ep:6, loss:0.00005, loss_test:0.02545, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:32.744, tt:229.207\n",
      "Ep:7, loss:0.00005, loss_test:0.02463, lr:6.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:32.739, tt:261.910\n",
      "Ep:8, loss:0.00005, loss_test:0.02410, lr:6.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:33.008, tt:297.069\n",
      "Ep:9, loss:0.00004, loss_test:0.02424, lr:6.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:33.216, tt:332.158\n",
      "Ep:10, loss:0.00004, loss_test:0.02502, lr:6.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:33.346, tt:366.806\n",
      "Ep:11, loss:0.00004, loss_test:0.02550, lr:6.00e-02, fs:0.63830 (r=0.758,p=0.551),  time:33.533, tt:402.396\n",
      "Ep:12, loss:0.00004, loss_test:0.02503, lr:6.00e-02, fs:0.62281 (r=0.717,p=0.550),  time:33.694, tt:438.024\n",
      "Ep:13, loss:0.00004, loss_test:0.02403, lr:6.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:33.803, tt:473.238\n",
      "Ep:14, loss:0.00004, loss_test:0.02309, lr:6.00e-02, fs:0.63248 (r=0.747,p=0.548),  time:33.989, tt:509.837\n",
      "Ep:15, loss:0.00004, loss_test:0.02249, lr:5.94e-02, fs:0.65000 (r=0.788,p=0.553),  time:34.083, tt:545.325\n",
      "Ep:16, loss:0.00004, loss_test:0.02216, lr:5.88e-02, fs:0.66116 (r=0.808,p=0.559),  time:34.159, tt:580.705\n",
      "Ep:17, loss:0.00004, loss_test:0.02206, lr:5.82e-02, fs:0.66109 (r=0.798,p=0.564),  time:34.260, tt:616.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00004, loss_test:0.02210, lr:5.76e-02, fs:0.65236 (r=0.768,p=0.567),  time:34.314, tt:651.968\n",
      "Ep:19, loss:0.00003, loss_test:0.02214, lr:5.71e-02, fs:0.66376 (r=0.768,p=0.585),  time:34.348, tt:686.956\n",
      "Ep:20, loss:0.00003, loss_test:0.02207, lr:5.65e-02, fs:0.66071 (r=0.747,p=0.592),  time:34.354, tt:721.439\n",
      "Ep:21, loss:0.00003, loss_test:0.02192, lr:5.59e-02, fs:0.63014 (r=0.697,p=0.575),  time:34.416, tt:757.148\n",
      "Ep:22, loss:0.00003, loss_test:0.02171, lr:5.54e-02, fs:0.62727 (r=0.697,p=0.570),  time:34.399, tt:791.181\n",
      "Ep:23, loss:0.00003, loss_test:0.02148, lr:5.48e-02, fs:0.62162 (r=0.697,p=0.561),  time:34.439, tt:826.535\n",
      "Ep:24, loss:0.00003, loss_test:0.02127, lr:5.43e-02, fs:0.61883 (r=0.697,p=0.556),  time:34.452, tt:861.294\n",
      "Ep:25, loss:0.00003, loss_test:0.02112, lr:5.37e-02, fs:0.61947 (r=0.707,p=0.551),  time:34.527, tt:897.690\n",
      "Ep:26, loss:0.00003, loss_test:0.02105, lr:5.32e-02, fs:0.62222 (r=0.707,p=0.556),  time:34.528, tt:932.249\n",
      "Ep:27, loss:0.00003, loss_test:0.02103, lr:5.27e-02, fs:0.63348 (r=0.707,p=0.574),  time:34.594, tt:968.641\n",
      "Ep:28, loss:0.00003, loss_test:0.02094, lr:5.21e-02, fs:0.63964 (r=0.717,p=0.577),  time:34.675, tt:1005.584\n",
      "Ep:29, loss:0.00003, loss_test:0.02080, lr:5.16e-02, fs:0.66063 (r=0.737,p=0.598),  time:34.762, tt:1042.854\n",
      "Ep:30, loss:0.00003, loss_test:0.02067, lr:5.11e-02, fs:0.69333 (r=0.788,p=0.619),  time:34.797, tt:1078.707\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.02057, lr:5.11e-02, fs:0.71930 (r=0.828,p=0.636),  time:34.817, tt:1114.156\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.02053, lr:5.11e-02, fs:0.73684 (r=0.848,p=0.651),  time:34.830, tt:1149.376\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.02051, lr:5.11e-02, fs:0.73684 (r=0.848,p=0.651),  time:34.875, tt:1185.760\n",
      "Ep:34, loss:0.00002, loss_test:0.02051, lr:5.11e-02, fs:0.73684 (r=0.848,p=0.651),  time:34.876, tt:1220.671\n",
      "Ep:35, loss:0.00002, loss_test:0.02039, lr:5.11e-02, fs:0.74009 (r=0.848,p=0.656),  time:34.899, tt:1256.381\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.02032, lr:5.11e-02, fs:0.74667 (r=0.848,p=0.667),  time:34.959, tt:1293.488\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.02030, lr:5.11e-02, fs:0.75221 (r=0.859,p=0.669),  time:34.967, tt:1328.754\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.02032, lr:5.11e-02, fs:0.74667 (r=0.848,p=0.667),  time:35.002, tt:1365.070\n",
      "Ep:39, loss:0.00002, loss_test:0.02033, lr:5.11e-02, fs:0.75000 (r=0.848,p=0.672),  time:35.030, tt:1401.182\n",
      "Ep:40, loss:0.00002, loss_test:0.02037, lr:5.11e-02, fs:0.74208 (r=0.828,p=0.672),  time:35.067, tt:1437.765\n",
      "Ep:41, loss:0.00002, loss_test:0.02038, lr:5.11e-02, fs:0.74775 (r=0.838,p=0.675),  time:35.053, tt:1472.224\n",
      "Ep:42, loss:0.00002, loss_test:0.02032, lr:5.11e-02, fs:0.76018 (r=0.848,p=0.689),  time:35.030, tt:1506.285\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.02022, lr:5.11e-02, fs:0.76923 (r=0.859,p=0.697),  time:35.045, tt:1542.000\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.02023, lr:5.11e-02, fs:0.76923 (r=0.859,p=0.697),  time:35.058, tt:1577.610\n",
      "Ep:45, loss:0.00002, loss_test:0.02024, lr:5.11e-02, fs:0.76364 (r=0.848,p=0.694),  time:35.043, tt:1611.997\n",
      "Ep:46, loss:0.00002, loss_test:0.02027, lr:5.11e-02, fs:0.76923 (r=0.859,p=0.697),  time:35.060, tt:1647.836\n",
      "Ep:47, loss:0.00002, loss_test:0.02040, lr:5.11e-02, fs:0.77626 (r=0.859,p=0.708),  time:35.075, tt:1683.594\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.02050, lr:5.11e-02, fs:0.77626 (r=0.859,p=0.708),  time:35.071, tt:1718.487\n",
      "Ep:49, loss:0.00001, loss_test:0.02046, lr:5.11e-02, fs:0.77982 (r=0.859,p=0.714),  time:35.113, tt:1755.662\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.02054, lr:5.11e-02, fs:0.76995 (r=0.828,p=0.719),  time:35.119, tt:1791.058\n",
      "Ep:51, loss:0.00001, loss_test:0.02058, lr:5.11e-02, fs:0.76995 (r=0.828,p=0.719),  time:35.140, tt:1827.293\n",
      "Ep:52, loss:0.00001, loss_test:0.02059, lr:5.11e-02, fs:0.77725 (r=0.828,p=0.732),  time:35.145, tt:1862.665\n",
      "Ep:53, loss:0.00001, loss_test:0.02065, lr:5.11e-02, fs:0.76923 (r=0.808,p=0.734),  time:35.127, tt:1896.864\n",
      "Ep:54, loss:0.00001, loss_test:0.02069, lr:5.11e-02, fs:0.76699 (r=0.798,p=0.738),  time:35.144, tt:1932.908\n",
      "Ep:55, loss:0.00001, loss_test:0.02066, lr:5.11e-02, fs:0.77295 (r=0.808,p=0.741),  time:35.154, tt:1968.630\n",
      "Ep:56, loss:0.00001, loss_test:0.02077, lr:5.11e-02, fs:0.77295 (r=0.808,p=0.741),  time:35.170, tt:2004.718\n",
      "Ep:57, loss:0.00001, loss_test:0.02093, lr:5.11e-02, fs:0.77073 (r=0.798,p=0.745),  time:35.173, tt:2040.052\n",
      "Ep:58, loss:0.00001, loss_test:0.02099, lr:5.11e-02, fs:0.76098 (r=0.788,p=0.736),  time:35.156, tt:2074.196\n",
      "Ep:59, loss:0.00001, loss_test:0.02108, lr:5.11e-02, fs:0.75862 (r=0.778,p=0.740),  time:35.144, tt:2108.631\n",
      "Ep:60, loss:0.00001, loss_test:0.02126, lr:5.11e-02, fs:0.76000 (r=0.768,p=0.752),  time:35.137, tt:2143.328\n",
      "Ep:61, loss:0.00001, loss_test:0.02124, lr:5.06e-02, fs:0.75248 (r=0.768,p=0.738),  time:35.155, tt:2179.634\n",
      "Ep:62, loss:0.00001, loss_test:0.02134, lr:5.01e-02, fs:0.75622 (r=0.768,p=0.745),  time:35.166, tt:2215.487\n",
      "Ep:63, loss:0.00001, loss_test:0.02159, lr:4.96e-02, fs:0.76142 (r=0.758,p=0.765),  time:35.178, tt:2251.381\n",
      "Ep:64, loss:0.00001, loss_test:0.02175, lr:4.91e-02, fs:0.74872 (r=0.737,p=0.760),  time:35.193, tt:2287.515\n",
      "Ep:65, loss:0.00001, loss_test:0.02179, lr:4.86e-02, fs:0.75510 (r=0.747,p=0.763),  time:35.252, tt:2326.663\n",
      "Ep:66, loss:0.00001, loss_test:0.02198, lr:4.81e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.257, tt:2362.230\n",
      "Ep:67, loss:0.00001, loss_test:0.02218, lr:4.76e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.256, tt:2397.430\n",
      "Ep:68, loss:0.00001, loss_test:0.02220, lr:4.71e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.247, tt:2432.062\n",
      "Ep:69, loss:0.00001, loss_test:0.02237, lr:4.67e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.244, tt:2467.107\n",
      "Ep:70, loss:0.00001, loss_test:0.02257, lr:4.62e-02, fs:0.74074 (r=0.707,p=0.778),  time:35.251, tt:2502.841\n",
      "Ep:71, loss:0.00001, loss_test:0.02266, lr:4.57e-02, fs:0.74074 (r=0.707,p=0.778),  time:35.257, tt:2538.481\n",
      "Ep:72, loss:0.00001, loss_test:0.02281, lr:4.53e-02, fs:0.74194 (r=0.697,p=0.793),  time:35.247, tt:2573.043\n",
      "Ep:73, loss:0.00001, loss_test:0.02297, lr:4.48e-02, fs:0.74194 (r=0.697,p=0.793),  time:35.260, tt:2609.250\n",
      "Ep:74, loss:0.00001, loss_test:0.02315, lr:4.44e-02, fs:0.75000 (r=0.697,p=0.812),  time:35.270, tt:2645.281\n",
      "Ep:75, loss:0.00001, loss_test:0.02327, lr:4.39e-02, fs:0.74317 (r=0.687,p=0.810),  time:35.266, tt:2680.200\n",
      "Ep:76, loss:0.00001, loss_test:0.02341, lr:4.35e-02, fs:0.74725 (r=0.687,p=0.819),  time:35.261, tt:2715.127\n",
      "Ep:77, loss:0.00001, loss_test:0.02358, lr:4.31e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.278, tt:2751.681\n",
      "Ep:78, loss:0.00001, loss_test:0.02368, lr:4.26e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.264, tt:2785.864\n",
      "Ep:79, loss:0.00001, loss_test:0.02376, lr:4.22e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.285, tt:2822.775\n",
      "Ep:80, loss:0.00001, loss_test:0.02391, lr:4.18e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.282, tt:2857.849\n",
      "Ep:81, loss:0.00001, loss_test:0.02413, lr:4.14e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.266, tt:2891.790\n",
      "Ep:82, loss:0.00001, loss_test:0.02432, lr:4.10e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.250, tt:2925.726\n",
      "Ep:83, loss:0.00001, loss_test:0.02444, lr:4.05e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.268, tt:2962.531\n",
      "Ep:84, loss:0.00001, loss_test:0.02455, lr:4.01e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.274, tt:2998.322\n",
      "Ep:85, loss:0.00001, loss_test:0.02476, lr:3.97e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.263, tt:3032.658\n",
      "Ep:86, loss:0.00001, loss_test:0.02481, lr:3.93e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.270, tt:3068.472\n",
      "Ep:87, loss:0.00001, loss_test:0.02491, lr:3.89e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.269, tt:3103.640\n",
      "Ep:88, loss:0.00001, loss_test:0.02512, lr:3.86e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.267, tt:3138.803\n",
      "Ep:89, loss:0.00001, loss_test:0.02528, lr:3.82e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.265, tt:3173.826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.02543, lr:3.78e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.263, tt:3208.927\n",
      "Ep:91, loss:0.00001, loss_test:0.02552, lr:3.74e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.263, tt:3244.239\n",
      "Ep:92, loss:0.00001, loss_test:0.02571, lr:3.70e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.263, tt:3279.431\n",
      "Ep:93, loss:0.00001, loss_test:0.02590, lr:3.67e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.253, tt:3313.776\n",
      "Ep:94, loss:0.00001, loss_test:0.02603, lr:3.63e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.258, tt:3349.492\n",
      "Ep:95, loss:0.00001, loss_test:0.02614, lr:3.59e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.251, tt:3384.143\n",
      "Ep:96, loss:0.00001, loss_test:0.02629, lr:3.56e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.247, tt:3418.974\n",
      "Ep:97, loss:0.00001, loss_test:0.02645, lr:3.52e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.263, tt:3455.745\n",
      "Ep:98, loss:0.00001, loss_test:0.02658, lr:3.49e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.250, tt:3489.725\n",
      "Ep:99, loss:0.00001, loss_test:0.02670, lr:3.45e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.267, tt:3526.687\n",
      "Ep:100, loss:0.00001, loss_test:0.02686, lr:3.42e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.269, tt:3562.174\n",
      "Ep:101, loss:0.00001, loss_test:0.02702, lr:3.38e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.260, tt:3596.541\n",
      "Ep:102, loss:0.00000, loss_test:0.02712, lr:3.35e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.251, tt:3630.875\n",
      "Ep:103, loss:0.00000, loss_test:0.02726, lr:3.32e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.258, tt:3666.831\n",
      "Ep:104, loss:0.00000, loss_test:0.02743, lr:3.28e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.253, tt:3701.610\n",
      "Ep:105, loss:0.00000, loss_test:0.02755, lr:3.25e-02, fs:0.75294 (r=0.646,p=0.901),  time:35.255, tt:3737.037\n",
      "Ep:106, loss:0.00000, loss_test:0.02771, lr:3.22e-02, fs:0.75294 (r=0.646,p=0.901),  time:35.264, tt:3773.207\n",
      "Ep:107, loss:0.00000, loss_test:0.02781, lr:3.19e-02, fs:0.75294 (r=0.646,p=0.901),  time:35.260, tt:3808.027\n",
      "Ep:108, loss:0.00000, loss_test:0.02794, lr:3.15e-02, fs:0.75294 (r=0.646,p=0.901),  time:35.260, tt:3843.293\n",
      "Ep:109, loss:0.00000, loss_test:0.02807, lr:3.12e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.259, tt:3878.477\n",
      "Ep:110, loss:0.00000, loss_test:0.02821, lr:3.09e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.272, tt:3915.205\n",
      "Ep:111, loss:0.00000, loss_test:0.02838, lr:3.06e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.290, tt:3952.509\n",
      "Ep:112, loss:0.00000, loss_test:0.02853, lr:3.03e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.291, tt:3987.832\n",
      "Ep:113, loss:0.00000, loss_test:0.02859, lr:3.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.297, tt:4023.807\n",
      "Ep:114, loss:0.00000, loss_test:0.02870, lr:2.97e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.299, tt:4059.351\n",
      "Ep:115, loss:0.00000, loss_test:0.02880, lr:2.94e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.297, tt:4094.460\n",
      "Ep:116, loss:0.00000, loss_test:0.02893, lr:2.91e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.311, tt:4131.400\n",
      "Ep:117, loss:0.00000, loss_test:0.02908, lr:2.88e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.325, tt:4168.349\n",
      "Ep:118, loss:0.00000, loss_test:0.02920, lr:2.85e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.328, tt:4203.975\n",
      "Ep:119, loss:0.00000, loss_test:0.02929, lr:2.82e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.336, tt:4240.374\n",
      "Ep:120, loss:0.00000, loss_test:0.02944, lr:2.80e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.338, tt:4275.900\n",
      "Ep:121, loss:0.00000, loss_test:0.02955, lr:2.77e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.340, tt:4311.514\n",
      "Ep:122, loss:0.00000, loss_test:0.02965, lr:2.74e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.338, tt:4346.597\n",
      "Ep:123, loss:0.00000, loss_test:0.02976, lr:2.71e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.341, tt:4382.313\n",
      "Ep:124, loss:0.00000, loss_test:0.02993, lr:2.69e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.351, tt:4418.936\n",
      "Ep:125, loss:0.00000, loss_test:0.03003, lr:2.66e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.356, tt:4454.894\n",
      "Ep:126, loss:0.00000, loss_test:0.03012, lr:2.63e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.359, tt:4490.569\n",
      "Ep:127, loss:0.00000, loss_test:0.03023, lr:2.61e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.369, tt:4527.209\n",
      "Ep:128, loss:0.00000, loss_test:0.03034, lr:2.58e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.369, tt:4562.583\n",
      "Ep:129, loss:0.00000, loss_test:0.03049, lr:2.55e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.374, tt:4598.557\n",
      "Ep:130, loss:0.00000, loss_test:0.03056, lr:2.53e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.374, tt:4633.969\n",
      "Ep:131, loss:0.00000, loss_test:0.03066, lr:2.50e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.375, tt:4669.542\n",
      "Ep:132, loss:0.00000, loss_test:0.03075, lr:2.48e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.379, tt:4705.436\n",
      "Ep:133, loss:0.00000, loss_test:0.03085, lr:2.45e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.382, tt:4741.124\n",
      "Ep:134, loss:0.00000, loss_test:0.03097, lr:2.43e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.381, tt:4776.382\n",
      "Ep:135, loss:0.00000, loss_test:0.03109, lr:2.40e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.371, tt:4810.390\n",
      "Ep:136, loss:0.00000, loss_test:0.03115, lr:2.38e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.365, tt:4845.049\n",
      "Ep:137, loss:0.00000, loss_test:0.03122, lr:2.36e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.358, tt:4879.464\n",
      "Ep:138, loss:0.00000, loss_test:0.03137, lr:2.33e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.358, tt:4914.811\n",
      "Ep:139, loss:0.00000, loss_test:0.03147, lr:2.31e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.352, tt:4949.294\n",
      "Ep:140, loss:0.00000, loss_test:0.03152, lr:2.29e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.345, tt:4983.608\n",
      "Ep:141, loss:0.00000, loss_test:0.03161, lr:2.26e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.343, tt:5018.731\n",
      "Ep:142, loss:0.00000, loss_test:0.03171, lr:2.24e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.336, tt:5052.978\n",
      "Ep:143, loss:0.00000, loss_test:0.03178, lr:2.22e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.330, tt:5087.541\n",
      "Ep:144, loss:0.00000, loss_test:0.03186, lr:2.20e-02, fs:0.73939 (r=0.616,p=0.924),  time:35.320, tt:5121.453\n",
      "Ep:145, loss:0.00000, loss_test:0.03195, lr:2.17e-02, fs:0.73939 (r=0.616,p=0.924),  time:35.309, tt:5155.067\n",
      "Ep:146, loss:0.00000, loss_test:0.03202, lr:2.15e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.303, tt:5189.540\n",
      "Ep:147, loss:0.00000, loss_test:0.03212, lr:2.13e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.294, tt:5223.452\n",
      "Ep:148, loss:0.00000, loss_test:0.03221, lr:2.11e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.284, tt:5257.319\n",
      "Ep:149, loss:0.00000, loss_test:0.03230, lr:2.09e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.277, tt:5291.621\n",
      "Ep:150, loss:0.00000, loss_test:0.03235, lr:2.07e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.257, tt:5323.808\n",
      "Ep:151, loss:0.00000, loss_test:0.03243, lr:2.05e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.267, tt:5360.539\n",
      "Ep:152, loss:0.00000, loss_test:0.03252, lr:2.03e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.254, tt:5393.908\n",
      "Ep:153, loss:0.00000, loss_test:0.03260, lr:2.01e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.256, tt:5429.384\n",
      "Ep:154, loss:0.00000, loss_test:0.03266, lr:1.99e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.253, tt:5464.196\n",
      "Ep:155, loss:0.00000, loss_test:0.03275, lr:1.97e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.239, tt:5497.210\n",
      "Ep:156, loss:0.00000, loss_test:0.03284, lr:1.95e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.237, tt:5532.132\n",
      "Ep:157, loss:0.00000, loss_test:0.03292, lr:1.93e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.223, tt:5565.283\n",
      "Ep:158, loss:0.00000, loss_test:0.03300, lr:1.91e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.219, tt:5599.775\n",
      "Ep:159, loss:0.00000, loss_test:0.03307, lr:1.89e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.213, tt:5634.050\n",
      "Ep:160, loss:0.00000, loss_test:0.03313, lr:1.87e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.212, tt:5669.100\n",
      "Ep:161, loss:0.00000, loss_test:0.03322, lr:1.85e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.200, tt:5702.442\n",
      "Ep:162, loss:0.00000, loss_test:0.03328, lr:1.83e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.195, tt:5736.790\n",
      "Ep:163, loss:0.00000, loss_test:0.03334, lr:1.81e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.185, tt:5770.302\n",
      "Ep:164, loss:0.00000, loss_test:0.03341, lr:1.80e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.185, tt:5805.584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:165, loss:0.00000, loss_test:0.03348, lr:1.78e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.195, tt:5842.367\n",
      "Ep:166, loss:0.00000, loss_test:0.03357, lr:1.76e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.201, tt:5878.525\n",
      "Ep:167, loss:0.00000, loss_test:0.03362, lr:1.74e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.203, tt:5914.054\n",
      "Ep:168, loss:0.00000, loss_test:0.03368, lr:1.73e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.202, tt:5949.069\n",
      "Ep:169, loss:0.00000, loss_test:0.03378, lr:1.71e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.199, tt:5983.877\n",
      "Ep:170, loss:0.00000, loss_test:0.03381, lr:1.69e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.203, tt:6019.677\n",
      "Ep:171, loss:0.00000, loss_test:0.03387, lr:1.67e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.198, tt:6054.017\n",
      "Ep:172, loss:0.00000, loss_test:0.03396, lr:1.66e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.206, tt:6090.696\n",
      "Ep:173, loss:0.00000, loss_test:0.03402, lr:1.64e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.197, tt:6124.203\n",
      "Ep:174, loss:0.00000, loss_test:0.03409, lr:1.62e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.201, tt:6160.138\n",
      "Ep:175, loss:0.00000, loss_test:0.03413, lr:1.61e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.202, tt:6195.584\n",
      "Ep:176, loss:0.00000, loss_test:0.03419, lr:1.59e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.211, tt:6232.267\n",
      "Ep:177, loss:0.00000, loss_test:0.03425, lr:1.58e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.197, tt:6265.099\n",
      "Ep:178, loss:0.00000, loss_test:0.03429, lr:1.56e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.194, tt:6299.733\n",
      "Ep:179, loss:0.00000, loss_test:0.03435, lr:1.54e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.190, tt:6334.263\n",
      "Ep:180, loss:0.00000, loss_test:0.03440, lr:1.53e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.193, tt:6369.874\n",
      "Ep:181, loss:0.00000, loss_test:0.03445, lr:1.51e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.189, tt:6404.461\n",
      "Ep:182, loss:0.00000, loss_test:0.03449, lr:1.50e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.200, tt:6441.682\n",
      "Ep:183, loss:0.00000, loss_test:0.03455, lr:1.48e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.197, tt:6476.172\n",
      "Ep:184, loss:0.00000, loss_test:0.03461, lr:1.47e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.204, tt:6512.751\n",
      "Ep:185, loss:0.00000, loss_test:0.03466, lr:1.45e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.202, tt:6547.601\n",
      "Ep:186, loss:0.00000, loss_test:0.03470, lr:1.44e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.198, tt:6581.980\n",
      "Ep:187, loss:0.00000, loss_test:0.03477, lr:1.43e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.197, tt:6617.075\n",
      "Ep:188, loss:0.00000, loss_test:0.03482, lr:1.41e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.187, tt:6650.267\n",
      "Ep:189, loss:0.00000, loss_test:0.03486, lr:1.40e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.182, tt:6684.655\n",
      "Ep:190, loss:0.00000, loss_test:0.03492, lr:1.38e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.173, tt:6718.017\n",
      "Ep:191, loss:0.00000, loss_test:0.03497, lr:1.37e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.169, tt:6752.461\n",
      "Ep:192, loss:0.00000, loss_test:0.03501, lr:1.36e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.157, tt:6785.215\n",
      "Ep:193, loss:0.00000, loss_test:0.03505, lr:1.34e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.153, tt:6819.746\n",
      "Ep:194, loss:0.00000, loss_test:0.03509, lr:1.33e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.153, tt:6854.890\n",
      "Ep:195, loss:0.00000, loss_test:0.03512, lr:1.32e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.148, tt:6889.092\n",
      "Ep:196, loss:0.00000, loss_test:0.03516, lr:1.30e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.153, tt:6925.184\n",
      "Ep:197, loss:0.00000, loss_test:0.03520, lr:1.29e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.148, tt:6959.342\n",
      "Ep:198, loss:0.00000, loss_test:0.03524, lr:1.28e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.150, tt:6994.804\n",
      "Ep:199, loss:0.00000, loss_test:0.03530, lr:1.26e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.135, tt:7026.899\n",
      "Ep:200, loss:0.00000, loss_test:0.03535, lr:1.25e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.127, tt:7060.545\n",
      "Ep:201, loss:0.00000, loss_test:0.03539, lr:1.24e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.114, tt:7093.072\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13632, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:33.136, tt:33.136\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13483, lr:1.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:36.167, tt:72.334\n",
      "Ep:2, loss:0.00026, loss_test:0.13280, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:36.835, tt:110.505\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13129, lr:1.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:37.140, tt:148.560\n",
      "Ep:4, loss:0.00026, loss_test:0.13075, lr:1.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:37.053, tt:185.267\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.13127, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:36.835, tt:221.008\n",
      "Ep:6, loss:0.00025, loss_test:0.13200, lr:1.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:36.591, tt:256.139\n",
      "Ep:7, loss:0.00025, loss_test:0.13207, lr:1.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:36.867, tt:294.935\n",
      "Ep:8, loss:0.00024, loss_test:0.13137, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:36.838, tt:331.538\n",
      "Ep:9, loss:0.00024, loss_test:0.13001, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:36.843, tt:368.433\n",
      "Ep:10, loss:0.00024, loss_test:0.12851, lr:1.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:37.232, tt:409.549\n",
      "Ep:11, loss:0.00023, loss_test:0.12657, lr:1.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:37.270, tt:447.238\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.12472, lr:1.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:37.400, tt:486.198\n",
      "Ep:13, loss:0.00022, loss_test:0.12278, lr:1.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:37.463, tt:524.481\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.12080, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:37.559, tt:563.387\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.11879, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:37.618, tt:601.883\n",
      "Ep:16, loss:0.00020, loss_test:0.11770, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:37.630, tt:639.707\n",
      "Ep:17, loss:0.00019, loss_test:0.11743, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:37.757, tt:679.622\n",
      "Ep:18, loss:0.00019, loss_test:0.11781, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:37.850, tt:719.147\n",
      "Ep:19, loss:0.00018, loss_test:0.11787, lr:1.00e-02, fs:0.65686 (r=0.677,p=0.638),  time:37.952, tt:759.036\n",
      "Ep:20, loss:0.00018, loss_test:0.11651, lr:1.00e-02, fs:0.65366 (r=0.677,p=0.632),  time:37.978, tt:797.535\n",
      "Ep:21, loss:0.00017, loss_test:0.11541, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:38.037, tt:836.814\n",
      "Ep:22, loss:0.00017, loss_test:0.11353, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:38.082, tt:875.897\n",
      "Ep:23, loss:0.00016, loss_test:0.11063, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:38.101, tt:914.419\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.11119, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:38.111, tt:952.767\n",
      "Ep:25, loss:0.00015, loss_test:0.10925, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:38.174, tt:992.515\n",
      "Ep:26, loss:0.00014, loss_test:0.10453, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:38.175, tt:1030.735\n",
      "Ep:27, loss:0.00014, loss_test:0.10657, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:38.195, tt:1069.473\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.10288, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:38.224, tt:1108.490\n",
      "Ep:29, loss:0.00013, loss_test:0.10167, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:38.231, tt:1146.926\n",
      "Ep:30, loss:0.00012, loss_test:0.10437, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:38.244, tt:1185.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00012, loss_test:0.09874, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:38.244, tt:1223.800\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.10213, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:38.246, tt:1262.115\n",
      "Ep:33, loss:0.00011, loss_test:0.09827, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:38.276, tt:1301.373\n",
      "Ep:34, loss:0.00010, loss_test:0.09937, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:38.252, tt:1338.816\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.09810, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:38.221, tt:1375.968\n",
      "Ep:36, loss:0.00009, loss_test:0.09641, lr:1.00e-02, fs:0.69474 (r=0.667,p=0.725),  time:38.208, tt:1413.713\n",
      "Ep:37, loss:0.00009, loss_test:0.09626, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:38.161, tt:1450.116\n",
      "Ep:38, loss:0.00009, loss_test:0.09403, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:38.121, tt:1486.711\n",
      "Ep:39, loss:0.00008, loss_test:0.09500, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:38.104, tt:1524.142\n",
      "Ep:40, loss:0.00008, loss_test:0.09529, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:38.072, tt:1560.946\n",
      "Ep:41, loss:0.00008, loss_test:0.09156, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:38.041, tt:1597.717\n",
      "Ep:42, loss:0.00007, loss_test:0.09533, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:38.060, tt:1636.572\n",
      "Ep:43, loss:0.00007, loss_test:0.09175, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:38.025, tt:1673.097\n",
      "Ep:44, loss:0.00007, loss_test:0.09302, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:38.006, tt:1710.257\n",
      "Ep:45, loss:0.00007, loss_test:0.09057, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:37.973, tt:1746.753\n",
      "Ep:46, loss:0.00006, loss_test:0.09307, lr:9.90e-03, fs:0.69841 (r=0.667,p=0.733),  time:37.970, tt:1784.575\n",
      "Ep:47, loss:0.00006, loss_test:0.08953, lr:9.80e-03, fs:0.69892 (r=0.657,p=0.747),  time:37.972, tt:1822.642\n",
      "Ep:48, loss:0.00006, loss_test:0.09084, lr:9.70e-03, fs:0.70833 (r=0.687,p=0.731),  time:37.952, tt:1859.637\n",
      "Ep:49, loss:0.00006, loss_test:0.08898, lr:9.61e-03, fs:0.70652 (r=0.657,p=0.765),  time:37.933, tt:1896.632\n",
      "Ep:50, loss:0.00006, loss_test:0.08880, lr:9.51e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.929, tt:1934.360\n",
      "Ep:51, loss:0.00005, loss_test:0.08925, lr:9.41e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.885, tt:1970.011\n",
      "Ep:52, loss:0.00005, loss_test:0.08821, lr:9.32e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.860, tt:2006.595\n",
      "Ep:53, loss:0.00005, loss_test:0.08778, lr:9.23e-03, fs:0.72432 (r=0.677,p=0.779),  time:37.856, tt:2044.207\n",
      "Ep:54, loss:0.00005, loss_test:0.08971, lr:9.14e-03, fs:0.72432 (r=0.677,p=0.779),  time:37.845, tt:2081.478\n",
      "Ep:55, loss:0.00005, loss_test:0.08718, lr:9.04e-03, fs:0.72432 (r=0.677,p=0.779),  time:37.836, tt:2118.830\n",
      "Ep:56, loss:0.00005, loss_test:0.08955, lr:8.95e-03, fs:0.72826 (r=0.677,p=0.788),  time:37.838, tt:2156.745\n",
      "Ep:57, loss:0.00005, loss_test:0.08645, lr:8.86e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.820, tt:2193.552\n",
      "Ep:58, loss:0.00004, loss_test:0.08846, lr:8.78e-03, fs:0.73224 (r=0.677,p=0.798),  time:37.834, tt:2232.203\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00004, loss_test:0.08910, lr:8.78e-03, fs:0.71658 (r=0.677,p=0.761),  time:37.828, tt:2269.666\n",
      "Ep:60, loss:0.00004, loss_test:0.08592, lr:8.78e-03, fs:0.72826 (r=0.677,p=0.788),  time:37.817, tt:2306.833\n",
      "Ep:61, loss:0.00004, loss_test:0.08923, lr:8.78e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.803, tt:2343.804\n",
      "Ep:62, loss:0.00004, loss_test:0.08697, lr:8.78e-03, fs:0.72432 (r=0.677,p=0.779),  time:37.782, tt:2380.235\n",
      "Ep:63, loss:0.00004, loss_test:0.08779, lr:8.78e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.764, tt:2416.882\n",
      "Ep:64, loss:0.00004, loss_test:0.08709, lr:8.78e-03, fs:0.72432 (r=0.677,p=0.779),  time:37.747, tt:2453.570\n",
      "Ep:65, loss:0.00004, loss_test:0.08812, lr:8.78e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.724, tt:2489.805\n",
      "Ep:66, loss:0.00004, loss_test:0.08631, lr:8.78e-03, fs:0.72826 (r=0.677,p=0.788),  time:37.703, tt:2526.080\n",
      "Ep:67, loss:0.00003, loss_test:0.08826, lr:8.78e-03, fs:0.72043 (r=0.677,p=0.770),  time:37.673, tt:2561.779\n",
      "Ep:68, loss:0.00003, loss_test:0.08750, lr:8.78e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.658, tt:2598.370\n",
      "Ep:69, loss:0.00003, loss_test:0.08793, lr:8.78e-03, fs:0.72826 (r=0.677,p=0.788),  time:37.642, tt:2634.942\n",
      "Ep:70, loss:0.00003, loss_test:0.08653, lr:8.69e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.626, tt:2671.425\n",
      "Ep:71, loss:0.00003, loss_test:0.08727, lr:8.60e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.597, tt:2707.007\n",
      "Ep:72, loss:0.00003, loss_test:0.08757, lr:8.51e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.581, tt:2743.406\n",
      "Ep:73, loss:0.00003, loss_test:0.08729, lr:8.43e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.579, tt:2780.841\n",
      "Ep:74, loss:0.00003, loss_test:0.08704, lr:8.35e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.569, tt:2817.696\n",
      "Ep:75, loss:0.00003, loss_test:0.08785, lr:8.26e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.549, tt:2853.699\n",
      "Ep:76, loss:0.00003, loss_test:0.08564, lr:8.18e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.539, tt:2890.469\n",
      "Ep:77, loss:0.00003, loss_test:0.08751, lr:8.10e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.515, tt:2926.152\n",
      "Ep:78, loss:0.00003, loss_test:0.08751, lr:8.02e-03, fs:0.72131 (r=0.667,p=0.786),  time:37.509, tt:2963.195\n",
      "Ep:79, loss:0.00003, loss_test:0.08626, lr:7.94e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.496, tt:2999.643\n",
      "Ep:80, loss:0.00003, loss_test:0.08827, lr:7.86e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.467, tt:3034.814\n",
      "Ep:81, loss:0.00003, loss_test:0.08484, lr:7.78e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.459, tt:3071.649\n",
      "Ep:82, loss:0.00003, loss_test:0.08914, lr:7.70e-03, fs:0.72928 (r=0.667,p=0.805),  time:37.477, tt:3110.567\n",
      "Ep:83, loss:0.00003, loss_test:0.08647, lr:7.62e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.465, tt:3147.042\n",
      "Ep:84, loss:0.00003, loss_test:0.08570, lr:7.55e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.477, tt:3185.546\n",
      "Ep:85, loss:0.00002, loss_test:0.08767, lr:7.47e-03, fs:0.72928 (r=0.667,p=0.805),  time:37.461, tt:3221.637\n",
      "Ep:86, loss:0.00002, loss_test:0.08623, lr:7.40e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.444, tt:3257.660\n",
      "Ep:87, loss:0.00002, loss_test:0.08660, lr:7.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:37.439, tt:3294.622\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.08950, lr:7.32e-03, fs:0.72928 (r=0.667,p=0.805),  time:37.416, tt:3330.017\n",
      "Ep:89, loss:0.00002, loss_test:0.08447, lr:7.32e-03, fs:0.72527 (r=0.667,p=0.795),  time:37.390, tt:3365.056\n",
      "Ep:90, loss:0.00002, loss_test:0.08792, lr:7.32e-03, fs:0.72928 (r=0.667,p=0.805),  time:37.375, tt:3401.107\n",
      "Ep:91, loss:0.00002, loss_test:0.08878, lr:7.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:37.363, tt:3437.411\n",
      "Ep:92, loss:0.00002, loss_test:0.08599, lr:7.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:37.344, tt:3473.034\n",
      "Ep:93, loss:0.00002, loss_test:0.08794, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.321, tt:3508.165\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.08919, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.317, tt:3545.158\n",
      "Ep:95, loss:0.00002, loss_test:0.08441, lr:7.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:37.271, tt:3578.025\n",
      "Ep:96, loss:0.00002, loss_test:0.08788, lr:7.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:37.234, tt:3611.734\n",
      "Ep:97, loss:0.00002, loss_test:0.08797, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.236, tt:3649.132\n",
      "Ep:98, loss:0.00002, loss_test:0.08677, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.217, tt:3684.504\n",
      "Ep:99, loss:0.00002, loss_test:0.08837, lr:7.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:37.210, tt:3720.975\n",
      "Ep:100, loss:0.00002, loss_test:0.08769, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.205, tt:3757.661\n",
      "Ep:101, loss:0.00002, loss_test:0.08945, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.202, tt:3794.616\n",
      "Ep:102, loss:0.00002, loss_test:0.08788, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.218, tt:3833.483\n",
      "Ep:103, loss:0.00002, loss_test:0.08763, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.216, tt:3870.449\n",
      "Ep:104, loss:0.00002, loss_test:0.08986, lr:7.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.209, tt:3906.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00002, loss_test:0.08914, lr:7.25e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.194, tt:3942.523\n",
      "Ep:106, loss:0.00002, loss_test:0.08896, lr:7.18e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.191, tt:3979.387\n",
      "Ep:107, loss:0.00002, loss_test:0.08869, lr:7.11e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.190, tt:4016.508\n",
      "Ep:108, loss:0.00002, loss_test:0.08956, lr:7.03e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.168, tt:4051.272\n",
      "Ep:109, loss:0.00002, loss_test:0.08881, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.167, tt:4088.387\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.08898, lr:6.96e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.153, tt:4124.021\n",
      "Ep:111, loss:0.00002, loss_test:0.08771, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.142, tt:4159.867\n",
      "Ep:112, loss:0.00002, loss_test:0.09010, lr:6.96e-03, fs:0.73743 (r=0.667,p=0.825),  time:37.144, tt:4197.321\n",
      "Ep:113, loss:0.00002, loss_test:0.08932, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.140, tt:4233.952\n",
      "Ep:114, loss:0.00002, loss_test:0.08865, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.121, tt:4268.949\n",
      "Ep:115, loss:0.00002, loss_test:0.09000, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.114, tt:4305.252\n",
      "Ep:116, loss:0.00002, loss_test:0.08954, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.113, tt:4342.239\n",
      "Ep:117, loss:0.00002, loss_test:0.08725, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.108, tt:4378.714\n",
      "Ep:118, loss:0.00002, loss_test:0.09171, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.101, tt:4415.069\n",
      "Ep:119, loss:0.00002, loss_test:0.08817, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.091, tt:4450.975\n",
      "Ep:120, loss:0.00002, loss_test:0.08798, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.084, tt:4487.198\n",
      "Ep:121, loss:0.00001, loss_test:0.09147, lr:6.89e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.075, tt:4523.185\n",
      "Ep:122, loss:0.00001, loss_test:0.08738, lr:6.83e-03, fs:0.74576 (r=0.667,p=0.846),  time:37.072, tt:4559.798\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.08954, lr:6.83e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.072, tt:4596.880\n",
      "Ep:124, loss:0.00001, loss_test:0.09053, lr:6.83e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.062, tt:4632.731\n",
      "Ep:125, loss:0.00001, loss_test:0.08873, lr:6.83e-03, fs:0.74576 (r=0.667,p=0.846),  time:37.057, tt:4669.154\n",
      "Ep:126, loss:0.00001, loss_test:0.09043, lr:6.83e-03, fs:0.74157 (r=0.667,p=0.835),  time:37.050, tt:4705.378\n",
      "Ep:127, loss:0.00001, loss_test:0.08752, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.051, tt:4742.471\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.08902, lr:6.83e-03, fs:0.74576 (r=0.667,p=0.846),  time:37.046, tt:4778.907\n",
      "Ep:129, loss:0.00001, loss_test:0.08846, lr:6.83e-03, fs:0.75000 (r=0.667,p=0.857),  time:37.030, tt:4813.870\n",
      "Ep:130, loss:0.00001, loss_test:0.08767, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.034, tt:4851.498\n",
      "Ep:131, loss:0.00001, loss_test:0.09025, lr:6.83e-03, fs:0.75000 (r=0.667,p=0.857),  time:37.040, tt:4889.326\n",
      "Ep:132, loss:0.00001, loss_test:0.08724, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.047, tt:4927.185\n",
      "Ep:133, loss:0.00001, loss_test:0.08823, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.039, tt:4963.185\n",
      "Ep:134, loss:0.00001, loss_test:0.08981, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.038, tt:5000.083\n",
      "Ep:135, loss:0.00001, loss_test:0.08742, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:37.031, tt:5036.166\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.08918, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.034, tt:5073.668\n",
      "Ep:137, loss:0.00001, loss_test:0.08776, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.024, tt:5109.326\n",
      "Ep:138, loss:0.00001, loss_test:0.08819, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.011, tt:5144.461\n",
      "Ep:139, loss:0.00001, loss_test:0.08961, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.999, tt:5179.836\n",
      "Ep:140, loss:0.00001, loss_test:0.08650, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.994, tt:5216.178\n",
      "Ep:141, loss:0.00001, loss_test:0.08968, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.990, tt:5252.597\n",
      "Ep:142, loss:0.00001, loss_test:0.08877, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.986, tt:5288.991\n",
      "Ep:143, loss:0.00001, loss_test:0.08461, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.974, tt:5324.303\n",
      "Ep:144, loss:0.00001, loss_test:0.09234, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.979, tt:5361.929\n",
      "Ep:145, loss:0.00001, loss_test:0.08746, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.972, tt:5397.871\n",
      "Ep:146, loss:0.00001, loss_test:0.08616, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.974, tt:5435.231\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00001, loss_test:0.09022, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.964, tt:5470.685\n",
      "Ep:148, loss:0.00001, loss_test:0.08614, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.963, tt:5507.496\n",
      "Ep:149, loss:0.00001, loss_test:0.08581, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.959, tt:5543.867\n",
      "Ep:150, loss:0.00001, loss_test:0.09194, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.966, tt:5581.922\n",
      "Ep:151, loss:0.00001, loss_test:0.08573, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.960, tt:5617.872\n",
      "Ep:152, loss:0.00001, loss_test:0.08516, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.953, tt:5653.735\n",
      "Ep:153, loss:0.00001, loss_test:0.08969, lr:6.83e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.956, tt:5691.226\n",
      "Ep:154, loss:0.00001, loss_test:0.08727, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.965, tt:5729.534\n",
      "Ep:155, loss:0.00001, loss_test:0.08506, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.967, tt:5766.862\n",
      "Ep:156, loss:0.00001, loss_test:0.08682, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.968, tt:5803.917\n",
      "Ep:157, loss:0.00001, loss_test:0.08668, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.975, tt:5841.974\n",
      "Ep:158, loss:0.00001, loss_test:0.08651, lr:6.76e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.974, tt:5878.907\n",
      "Ep:159, loss:0.00001, loss_test:0.08574, lr:6.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.976, tt:5916.126\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00001, loss_test:0.08555, lr:6.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.974, tt:5952.858\n",
      "Ep:161, loss:0.00001, loss_test:0.08784, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.983, tt:5991.194\n",
      "Ep:162, loss:0.00001, loss_test:0.08507, lr:6.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.987, tt:6028.898\n",
      "Ep:163, loss:0.00001, loss_test:0.08691, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.984, tt:6065.309\n",
      "Ep:164, loss:0.00001, loss_test:0.08555, lr:6.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.971, tt:6100.260\n",
      "Ep:165, loss:0.00001, loss_test:0.08590, lr:6.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.967, tt:6136.523\n",
      "Ep:166, loss:0.00001, loss_test:0.08587, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.948, tt:6170.379\n",
      "Ep:167, loss:0.00001, loss_test:0.08542, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.941, tt:6206.035\n",
      "Ep:168, loss:0.00001, loss_test:0.08596, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.926, tt:6240.522\n",
      "Ep:169, loss:0.00001, loss_test:0.08635, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.922, tt:6276.681\n",
      "Ep:170, loss:0.00001, loss_test:0.08511, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.930, tt:6315.113\n",
      "Ep:171, loss:0.00001, loss_test:0.08542, lr:6.62e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.935, tt:6352.845\n",
      "Ep:172, loss:0.00001, loss_test:0.08700, lr:6.56e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.938, tt:6390.301\n",
      "Ep:173, loss:0.00001, loss_test:0.08548, lr:6.49e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.940, tt:6427.491\n",
      "Ep:174, loss:0.00001, loss_test:0.08695, lr:6.43e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.934, tt:6463.366\n",
      "Ep:175, loss:0.00001, loss_test:0.08677, lr:6.36e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.936, tt:6500.810\n",
      "Ep:176, loss:0.00001, loss_test:0.08651, lr:6.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.932, tt:6536.968\n",
      "Ep:177, loss:0.00001, loss_test:0.08556, lr:6.24e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.942, tt:6575.607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:178, loss:0.00001, loss_test:0.08733, lr:6.17e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.938, tt:6611.815\n",
      "##########Best model found so far##########\n",
      "Ep:179, loss:0.00001, loss_test:0.08454, lr:6.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.938, tt:6648.864\n",
      "##########Best model found so far##########\n",
      "Ep:180, loss:0.00001, loss_test:0.08858, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.938, tt:6685.781\n",
      "Ep:181, loss:0.00001, loss_test:0.08578, lr:6.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.931, tt:6721.376\n",
      "Ep:182, loss:0.00001, loss_test:0.08780, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.930, tt:6758.211\n",
      "Ep:183, loss:0.00001, loss_test:0.08547, lr:6.17e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.920, tt:6793.353\n",
      "##########Best model found so far##########\n",
      "Ep:184, loss:0.00001, loss_test:0.08792, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.906, tt:6827.647\n",
      "Ep:185, loss:0.00001, loss_test:0.08683, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.898, tt:6863.106\n",
      "Ep:186, loss:0.00001, loss_test:0.08532, lr:6.17e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.890, tt:6898.517\n",
      "##########Best model found so far##########\n",
      "Ep:187, loss:0.00001, loss_test:0.09066, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.884, tt:6934.238\n",
      "Ep:188, loss:0.00001, loss_test:0.08519, lr:6.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.890, tt:6972.124\n",
      "Ep:189, loss:0.00001, loss_test:0.08735, lr:6.17e-03, fs:0.81111 (r=0.737,p=0.901),  time:36.875, tt:7006.327\n",
      "##########Best model found so far##########\n",
      "Ep:190, loss:0.00001, loss_test:0.08794, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.893, tt:7046.485\n",
      "Ep:191, loss:0.00001, loss_test:0.08771, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.882, tt:7081.361\n",
      "Ep:192, loss:0.00001, loss_test:0.08547, lr:6.17e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.880, tt:7117.908\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00001, loss_test:0.08801, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.877, tt:7154.211\n",
      "Ep:194, loss:0.00001, loss_test:0.08755, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.876, tt:7190.790\n",
      "Ep:195, loss:0.00001, loss_test:0.08622, lr:6.17e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.872, tt:7226.885\n",
      "Ep:196, loss:0.00001, loss_test:0.08772, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.867, tt:7262.721\n",
      "Ep:197, loss:0.00001, loss_test:0.08576, lr:6.17e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.848, tt:7295.816\n",
      "Ep:198, loss:0.00001, loss_test:0.08941, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.837, tt:7330.466\n",
      "Ep:199, loss:0.00001, loss_test:0.08857, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.804, tt:7360.770\n",
      "Ep:200, loss:0.00001, loss_test:0.08450, lr:6.17e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.771, tt:7391.068\n",
      "Ep:201, loss:0.00001, loss_test:0.09008, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.745, tt:7422.431\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02673, lr:6.00e-02, fs:0.62931 (r=0.737,p=0.549),  time:27.675, tt:27.675\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02481, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:28.975, tt:57.950\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02662, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.556, tt:88.667\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02706, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.118, tt:120.472\n",
      "Ep:4, loss:0.00005, loss_test:0.02654, lr:6.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:29.717, tt:148.583\n",
      "Ep:5, loss:0.00005, loss_test:0.02570, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:29.544, tt:177.267\n",
      "Ep:6, loss:0.00005, loss_test:0.02484, lr:6.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:28.746, tt:201.219\n",
      "Ep:7, loss:0.00004, loss_test:0.02453, lr:6.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:28.771, tt:230.165\n",
      "Ep:8, loss:0.00004, loss_test:0.02507, lr:6.00e-02, fs:0.62447 (r=0.747,p=0.536),  time:28.726, tt:258.532\n",
      "Ep:9, loss:0.00004, loss_test:0.02601, lr:6.00e-02, fs:0.61538 (r=0.687,p=0.557),  time:28.877, tt:288.768\n",
      "Ep:10, loss:0.00004, loss_test:0.02609, lr:6.00e-02, fs:0.59908 (r=0.657,p=0.551),  time:29.048, tt:319.531\n",
      "Ep:11, loss:0.00004, loss_test:0.02507, lr:6.00e-02, fs:0.61261 (r=0.687,p=0.553),  time:29.085, tt:349.017\n",
      "Ep:12, loss:0.00004, loss_test:0.02401, lr:6.00e-02, fs:0.62069 (r=0.727,p=0.541),  time:29.217, tt:379.820\n",
      "Ep:13, loss:0.00004, loss_test:0.02340, lr:6.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:29.325, tt:410.555\n",
      "Ep:14, loss:0.00004, loss_test:0.02317, lr:5.94e-02, fs:0.64516 (r=0.808,p=0.537),  time:29.325, tt:439.874\n",
      "Ep:15, loss:0.00004, loss_test:0.02315, lr:5.88e-02, fs:0.63673 (r=0.788,p=0.534),  time:29.410, tt:470.554\n",
      "Ep:16, loss:0.00004, loss_test:0.02326, lr:5.82e-02, fs:0.63333 (r=0.768,p=0.539),  time:29.570, tt:502.690\n",
      "Ep:17, loss:0.00004, loss_test:0.02336, lr:5.76e-02, fs:0.62609 (r=0.727,p=0.550),  time:29.577, tt:532.393\n",
      "Ep:18, loss:0.00004, loss_test:0.02325, lr:5.71e-02, fs:0.62338 (r=0.727,p=0.545),  time:29.650, tt:563.353\n",
      "Ep:19, loss:0.00004, loss_test:0.02294, lr:5.65e-02, fs:0.62393 (r=0.737,p=0.541),  time:29.690, tt:593.810\n",
      "Ep:20, loss:0.00004, loss_test:0.02257, lr:5.59e-02, fs:0.63291 (r=0.758,p=0.543),  time:29.703, tt:623.761\n",
      "Ep:21, loss:0.00003, loss_test:0.02223, lr:5.54e-02, fs:0.63291 (r=0.758,p=0.543),  time:29.731, tt:654.082\n",
      "Ep:22, loss:0.00003, loss_test:0.02198, lr:5.48e-02, fs:0.63559 (r=0.758,p=0.547),  time:29.731, tt:683.822\n",
      "Ep:23, loss:0.00003, loss_test:0.02173, lr:5.43e-02, fs:0.63830 (r=0.758,p=0.551),  time:29.740, tt:713.765\n",
      "Ep:24, loss:0.00003, loss_test:0.02150, lr:5.37e-02, fs:0.64378 (r=0.758,p=0.560),  time:29.841, tt:746.018\n",
      "Ep:25, loss:0.00003, loss_test:0.02120, lr:5.32e-02, fs:0.64378 (r=0.758,p=0.560),  time:29.808, tt:775.014\n",
      "Ep:26, loss:0.00003, loss_test:0.02089, lr:5.27e-02, fs:0.64935 (r=0.758,p=0.568),  time:29.816, tt:805.041\n",
      "Ep:27, loss:0.00003, loss_test:0.02059, lr:5.21e-02, fs:0.65217 (r=0.758,p=0.573),  time:29.861, tt:836.102\n",
      "Ep:28, loss:0.00003, loss_test:0.02035, lr:5.16e-02, fs:0.66667 (r=0.778,p=0.583),  time:29.924, tt:867.784\n",
      "Ep:29, loss:0.00003, loss_test:0.02011, lr:5.11e-02, fs:0.67811 (r=0.798,p=0.590),  time:29.962, tt:898.867\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01987, lr:5.11e-02, fs:0.69528 (r=0.818,p=0.604),  time:29.990, tt:929.696\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01962, lr:5.11e-02, fs:0.69828 (r=0.818,p=0.609),  time:29.993, tt:959.788\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01935, lr:5.11e-02, fs:0.70435 (r=0.818,p=0.618),  time:30.004, tt:990.146\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01912, lr:5.11e-02, fs:0.69264 (r=0.808,p=0.606),  time:30.019, tt:1020.631\n",
      "Ep:34, loss:0.00003, loss_test:0.01889, lr:5.11e-02, fs:0.71489 (r=0.848,p=0.618),  time:30.010, tt:1050.351\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01867, lr:5.11e-02, fs:0.72881 (r=0.869,p=0.628),  time:30.036, tt:1081.307\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01843, lr:5.11e-02, fs:0.72881 (r=0.869,p=0.628),  time:30.054, tt:1111.998\n",
      "Ep:37, loss:0.00002, loss_test:0.01818, lr:5.11e-02, fs:0.73729 (r=0.879,p=0.635),  time:30.122, tt:1144.652\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00002, loss_test:0.01796, lr:5.11e-02, fs:0.74576 (r=0.889,p=0.642),  time:30.130, tt:1175.056\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01777, lr:5.11e-02, fs:0.75424 (r=0.899,p=0.650),  time:30.145, tt:1205.792\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01757, lr:5.11e-02, fs:0.76596 (r=0.909,p=0.662),  time:30.160, tt:1236.560\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01733, lr:5.11e-02, fs:0.76596 (r=0.909,p=0.662),  time:30.158, tt:1266.623\n",
      "Ep:42, loss:0.00002, loss_test:0.01718, lr:5.11e-02, fs:0.76596 (r=0.909,p=0.662),  time:30.181, tt:1297.790\n",
      "Ep:43, loss:0.00002, loss_test:0.01703, lr:5.11e-02, fs:0.76923 (r=0.909,p=0.667),  time:30.181, tt:1327.953\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01695, lr:5.11e-02, fs:0.77253 (r=0.909,p=0.672),  time:30.168, tt:1357.581\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01679, lr:5.11e-02, fs:0.77922 (r=0.909,p=0.682),  time:30.171, tt:1387.854\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01668, lr:5.11e-02, fs:0.77922 (r=0.909,p=0.682),  time:30.200, tt:1419.396\n",
      "Ep:47, loss:0.00002, loss_test:0.01659, lr:5.11e-02, fs:0.77391 (r=0.899,p=0.679),  time:30.229, tt:1451.015\n",
      "Ep:48, loss:0.00002, loss_test:0.01652, lr:5.11e-02, fs:0.76724 (r=0.899,p=0.669),  time:30.224, tt:1480.989\n",
      "Ep:49, loss:0.00002, loss_test:0.01649, lr:5.11e-02, fs:0.77391 (r=0.899,p=0.679),  time:30.198, tt:1509.904\n",
      "Ep:50, loss:0.00002, loss_test:0.01646, lr:5.11e-02, fs:0.77391 (r=0.899,p=0.679),  time:30.197, tt:1540.034\n",
      "Ep:51, loss:0.00002, loss_test:0.01648, lr:5.11e-02, fs:0.78070 (r=0.899,p=0.690),  time:30.199, tt:1570.333\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01640, lr:5.11e-02, fs:0.78070 (r=0.899,p=0.690),  time:30.203, tt:1600.737\n",
      "Ep:53, loss:0.00001, loss_test:0.01632, lr:5.11e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.206, tt:1631.109\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01635, lr:5.11e-02, fs:0.78947 (r=0.909,p=0.698),  time:30.216, tt:1661.867\n",
      "Ep:55, loss:0.00001, loss_test:0.01625, lr:5.11e-02, fs:0.78947 (r=0.909,p=0.698),  time:30.225, tt:1692.578\n",
      "Ep:56, loss:0.00001, loss_test:0.01615, lr:5.11e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.231, tt:1723.143\n",
      "Ep:57, loss:0.00001, loss_test:0.01620, lr:5.11e-02, fs:0.79646 (r=0.909,p=0.709),  time:30.226, tt:1753.099\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01622, lr:5.11e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.215, tt:1782.707\n",
      "Ep:59, loss:0.00001, loss_test:0.01624, lr:5.11e-02, fs:0.79646 (r=0.909,p=0.709),  time:30.167, tt:1810.035\n",
      "Ep:60, loss:0.00001, loss_test:0.01622, lr:5.11e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.139, tt:1838.475\n",
      "Ep:61, loss:0.00001, loss_test:0.01624, lr:5.11e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.124, tt:1867.670\n",
      "Ep:62, loss:0.00001, loss_test:0.01619, lr:5.11e-02, fs:0.79279 (r=0.889,p=0.715),  time:30.117, tt:1897.348\n",
      "Ep:63, loss:0.00001, loss_test:0.01623, lr:5.11e-02, fs:0.78733 (r=0.879,p=0.713),  time:30.133, tt:1928.483\n",
      "Ep:64, loss:0.00001, loss_test:0.01625, lr:5.11e-02, fs:0.79452 (r=0.879,p=0.725),  time:30.128, tt:1958.317\n",
      "Ep:65, loss:0.00001, loss_test:0.01614, lr:5.11e-02, fs:0.78182 (r=0.869,p=0.711),  time:30.125, tt:1988.246\n",
      "Ep:66, loss:0.00001, loss_test:0.01623, lr:5.11e-02, fs:0.79817 (r=0.879,p=0.731),  time:30.084, tt:2015.621\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01632, lr:5.11e-02, fs:0.78899 (r=0.869,p=0.723),  time:30.074, tt:2045.029\n",
      "Ep:68, loss:0.00001, loss_test:0.01625, lr:5.11e-02, fs:0.79630 (r=0.869,p=0.735),  time:30.083, tt:2075.746\n",
      "Ep:69, loss:0.00001, loss_test:0.01631, lr:5.11e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.085, tt:2105.938\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01619, lr:5.11e-02, fs:0.79439 (r=0.859,p=0.739),  time:30.068, tt:2134.808\n",
      "Ep:71, loss:0.00001, loss_test:0.01633, lr:5.11e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.065, tt:2164.647\n",
      "Ep:72, loss:0.00001, loss_test:0.01638, lr:5.11e-02, fs:0.79621 (r=0.848,p=0.750),  time:30.053, tt:2193.838\n",
      "Ep:73, loss:0.00001, loss_test:0.01635, lr:5.11e-02, fs:0.79621 (r=0.848,p=0.750),  time:30.034, tt:2222.530\n",
      "Ep:74, loss:0.00001, loss_test:0.01641, lr:5.11e-02, fs:0.79621 (r=0.848,p=0.750),  time:30.016, tt:2251.234\n",
      "Ep:75, loss:0.00001, loss_test:0.01640, lr:5.11e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.021, tt:2281.573\n",
      "Ep:76, loss:0.00001, loss_test:0.01641, lr:5.11e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.024, tt:2311.860\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01643, lr:5.11e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.030, tt:2342.374\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01639, lr:5.11e-02, fs:0.79812 (r=0.859,p=0.746),  time:30.020, tt:2371.572\n",
      "Ep:79, loss:0.00001, loss_test:0.01650, lr:5.11e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.014, tt:2401.087\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01644, lr:5.11e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.041, tt:2433.325\n",
      "Ep:81, loss:0.00001, loss_test:0.01661, lr:5.11e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.044, tt:2463.577\n",
      "Ep:82, loss:0.00001, loss_test:0.01656, lr:5.11e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.035, tt:2492.868\n",
      "Ep:83, loss:0.00001, loss_test:0.01653, lr:5.11e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.026, tt:2522.159\n",
      "Ep:84, loss:0.00001, loss_test:0.01663, lr:5.11e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.044, tt:2553.715\n",
      "Ep:85, loss:0.00001, loss_test:0.01664, lr:5.11e-02, fs:0.81340 (r=0.859,p=0.773),  time:30.036, tt:2583.134\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01681, lr:5.11e-02, fs:0.80193 (r=0.838,p=0.769),  time:30.047, tt:2614.091\n",
      "Ep:87, loss:0.00001, loss_test:0.01672, lr:5.11e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.038, tt:2643.329\n",
      "Ep:88, loss:0.00001, loss_test:0.01673, lr:5.11e-02, fs:0.81340 (r=0.859,p=0.773),  time:30.056, tt:2674.960\n",
      "Ep:89, loss:0.00001, loss_test:0.01678, lr:5.11e-02, fs:0.80193 (r=0.838,p=0.769),  time:30.059, tt:2705.347\n",
      "Ep:90, loss:0.00001, loss_test:0.01689, lr:5.11e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.066, tt:2736.026\n",
      "Ep:91, loss:0.00001, loss_test:0.01704, lr:5.11e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.067, tt:2766.186\n",
      "Ep:92, loss:0.00001, loss_test:0.01688, lr:5.11e-02, fs:0.81340 (r=0.859,p=0.773),  time:30.070, tt:2796.495\n",
      "Ep:93, loss:0.00001, loss_test:0.01697, lr:5.11e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.063, tt:2825.931\n",
      "Ep:94, loss:0.00001, loss_test:0.01711, lr:5.11e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.060, tt:2855.674\n",
      "Ep:95, loss:0.00001, loss_test:0.01701, lr:5.11e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.056, tt:2885.345\n",
      "Ep:96, loss:0.00001, loss_test:0.01707, lr:5.11e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.059, tt:2915.764\n",
      "Ep:97, loss:0.00001, loss_test:0.01711, lr:5.06e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.052, tt:2945.123\n",
      "Ep:98, loss:0.00001, loss_test:0.01731, lr:5.01e-02, fs:0.78607 (r=0.798,p=0.775),  time:30.055, tt:2975.414\n",
      "Ep:99, loss:0.00001, loss_test:0.01708, lr:4.96e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.062, tt:3006.218\n",
      "Ep:100, loss:0.00001, loss_test:0.01714, lr:4.91e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.068, tt:3036.886\n",
      "Ep:101, loss:0.00000, loss_test:0.01731, lr:4.86e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.064, tt:3066.477\n",
      "Ep:102, loss:0.00000, loss_test:0.01732, lr:4.81e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.066, tt:3096.781\n",
      "Ep:103, loss:0.00000, loss_test:0.01743, lr:4.76e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.056, tt:3125.824\n",
      "Ep:104, loss:0.00000, loss_test:0.01739, lr:4.71e-02, fs:0.79208 (r=0.808,p=0.777),  time:30.061, tt:3156.439\n",
      "Ep:105, loss:0.00000, loss_test:0.01738, lr:4.67e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.058, tt:3186.139\n",
      "Ep:106, loss:0.00000, loss_test:0.01747, lr:4.62e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.062, tt:3216.678\n",
      "Ep:107, loss:0.00000, loss_test:0.01748, lr:4.57e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.061, tt:3246.545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00000, loss_test:0.01749, lr:4.53e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.055, tt:3275.956\n",
      "Ep:109, loss:0.00000, loss_test:0.01753, lr:4.48e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.034, tt:3303.739\n",
      "Ep:110, loss:0.00000, loss_test:0.01756, lr:4.44e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.017, tt:3331.891\n",
      "Ep:111, loss:0.00000, loss_test:0.01760, lr:4.39e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.011, tt:3361.235\n",
      "Ep:112, loss:0.00000, loss_test:0.01766, lr:4.35e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.011, tt:3391.294\n",
      "Ep:113, loss:0.00000, loss_test:0.01766, lr:4.31e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.003, tt:3420.320\n",
      "Ep:114, loss:0.00000, loss_test:0.01771, lr:4.26e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.012, tt:3451.368\n",
      "Ep:115, loss:0.00000, loss_test:0.01758, lr:4.22e-02, fs:0.80000 (r=0.808,p=0.792),  time:30.009, tt:3481.011\n",
      "Ep:116, loss:0.00000, loss_test:0.01779, lr:4.18e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.001, tt:3510.158\n",
      "Ep:117, loss:0.00000, loss_test:0.01766, lr:4.14e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.001, tt:3540.139\n",
      "Ep:118, loss:0.00000, loss_test:0.01775, lr:4.10e-02, fs:0.78788 (r=0.788,p=0.788),  time:29.999, tt:3569.880\n",
      "Ep:119, loss:0.00000, loss_test:0.01782, lr:4.05e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.000, tt:3600.011\n",
      "Ep:120, loss:0.00000, loss_test:0.01791, lr:4.01e-02, fs:0.78788 (r=0.788,p=0.788),  time:29.997, tt:3629.671\n",
      "Ep:121, loss:0.00000, loss_test:0.01781, lr:3.97e-02, fs:0.78788 (r=0.788,p=0.788),  time:29.994, tt:3659.236\n",
      "Ep:122, loss:0.00000, loss_test:0.01783, lr:3.93e-02, fs:0.78788 (r=0.788,p=0.788),  time:29.993, tt:3689.159\n",
      "Ep:123, loss:0.00000, loss_test:0.01793, lr:3.89e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.993, tt:3719.118\n",
      "Ep:124, loss:0.00000, loss_test:0.01795, lr:3.86e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.000, tt:3749.959\n",
      "Ep:125, loss:0.00000, loss_test:0.01798, lr:3.82e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.999, tt:3779.854\n",
      "Ep:126, loss:0.00000, loss_test:0.01801, lr:3.78e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.004, tt:3810.463\n",
      "Ep:127, loss:0.00000, loss_test:0.01807, lr:3.74e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.006, tt:3840.718\n",
      "Ep:128, loss:0.00000, loss_test:0.01805, lr:3.70e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.999, tt:3869.832\n",
      "Ep:129, loss:0.00000, loss_test:0.01802, lr:3.67e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.003, tt:3900.397\n",
      "Ep:130, loss:0.00000, loss_test:0.01814, lr:3.63e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.005, tt:3930.630\n",
      "Ep:131, loss:0.00000, loss_test:0.01817, lr:3.59e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.997, tt:3959.569\n",
      "Ep:132, loss:0.00000, loss_test:0.01815, lr:3.56e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.992, tt:3988.927\n",
      "Ep:133, loss:0.00000, loss_test:0.01820, lr:3.52e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.000, tt:4020.020\n",
      "Ep:134, loss:0.00000, loss_test:0.01817, lr:3.49e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.006, tt:4050.828\n",
      "Ep:135, loss:0.00000, loss_test:0.01823, lr:3.45e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.000, tt:4080.040\n",
      "Ep:136, loss:0.00000, loss_test:0.01827, lr:3.42e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.993, tt:4109.067\n",
      "Ep:137, loss:0.00000, loss_test:0.01826, lr:3.38e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.988, tt:4138.349\n",
      "Ep:138, loss:0.00000, loss_test:0.01827, lr:3.35e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.985, tt:4167.921\n",
      "Ep:139, loss:0.00000, loss_test:0.01840, lr:3.32e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.987, tt:4198.169\n",
      "Ep:140, loss:0.00000, loss_test:0.01830, lr:3.28e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.987, tt:4228.233\n",
      "Ep:141, loss:0.00000, loss_test:0.01836, lr:3.25e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.988, tt:4258.292\n",
      "Ep:142, loss:0.00000, loss_test:0.01840, lr:3.22e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.978, tt:4286.898\n",
      "Ep:143, loss:0.00000, loss_test:0.01840, lr:3.19e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.985, tt:4317.845\n",
      "Ep:144, loss:0.00000, loss_test:0.01846, lr:3.15e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.986, tt:4347.920\n",
      "Ep:145, loss:0.00000, loss_test:0.01847, lr:3.12e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.988, tt:4378.307\n",
      "Ep:146, loss:0.00000, loss_test:0.01845, lr:3.09e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.979, tt:4406.961\n",
      "Ep:147, loss:0.00000, loss_test:0.01850, lr:3.06e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.986, tt:4437.913\n",
      "Ep:148, loss:0.00000, loss_test:0.01853, lr:3.03e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.994, tt:4469.085\n",
      "Ep:149, loss:0.00000, loss_test:0.01857, lr:3.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.006, tt:4500.947\n",
      "Ep:150, loss:0.00000, loss_test:0.01857, lr:2.97e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.007, tt:4531.075\n",
      "Ep:151, loss:0.00000, loss_test:0.01859, lr:2.94e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.006, tt:4560.855\n",
      "Ep:152, loss:0.00000, loss_test:0.01859, lr:2.91e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.006, tt:4590.909\n",
      "Ep:153, loss:0.00000, loss_test:0.01859, lr:2.88e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.011, tt:4621.676\n",
      "Ep:154, loss:0.00000, loss_test:0.01865, lr:2.85e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.017, tt:4652.691\n",
      "Ep:155, loss:0.00000, loss_test:0.01866, lr:2.82e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.011, tt:4681.747\n",
      "Ep:156, loss:0.00000, loss_test:0.01870, lr:2.80e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.008, tt:4711.263\n",
      "Ep:157, loss:0.00000, loss_test:0.01871, lr:2.77e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.000, tt:4740.060\n",
      "Ep:158, loss:0.00000, loss_test:0.01869, lr:2.74e-02, fs:0.79592 (r=0.788,p=0.804),  time:29.986, tt:4767.792\n",
      "Ep:159, loss:0.00000, loss_test:0.01877, lr:2.71e-02, fs:0.79592 (r=0.788,p=0.804),  time:29.995, tt:4799.193\n",
      "Ep:160, loss:0.00000, loss_test:0.01874, lr:2.69e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.004, tt:4830.621\n",
      "Ep:161, loss:0.00000, loss_test:0.01879, lr:2.66e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.006, tt:4860.956\n",
      "Ep:162, loss:0.00000, loss_test:0.01882, lr:2.63e-02, fs:0.79381 (r=0.778,p=0.811),  time:30.003, tt:4890.547\n",
      "Ep:163, loss:0.00000, loss_test:0.01879, lr:2.61e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.984, tt:4917.403\n",
      "Ep:164, loss:0.00000, loss_test:0.01882, lr:2.58e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.970, tt:4945.018\n",
      "Ep:165, loss:0.00000, loss_test:0.01886, lr:2.55e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.968, tt:4974.718\n",
      "Ep:166, loss:0.00000, loss_test:0.01882, lr:2.53e-02, fs:0.79592 (r=0.788,p=0.804),  time:29.979, tt:5006.435\n",
      "Ep:167, loss:0.00000, loss_test:0.01888, lr:2.50e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.969, tt:5034.868\n",
      "Ep:168, loss:0.00000, loss_test:0.01891, lr:2.48e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.975, tt:5065.691\n",
      "Ep:169, loss:0.00000, loss_test:0.01886, lr:2.45e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.980, tt:5096.538\n",
      "Ep:170, loss:0.00000, loss_test:0.01890, lr:2.43e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.980, tt:5126.599\n",
      "Ep:171, loss:0.00000, loss_test:0.01894, lr:2.40e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.987, tt:5157.718\n",
      "Ep:172, loss:0.00000, loss_test:0.01896, lr:2.38e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.985, tt:5187.433\n",
      "Ep:173, loss:0.00000, loss_test:0.01896, lr:2.36e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.992, tt:5218.624\n",
      "Ep:174, loss:0.00000, loss_test:0.01894, lr:2.33e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.989, tt:5248.136\n",
      "Ep:175, loss:0.00000, loss_test:0.01894, lr:2.31e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.987, tt:5277.713\n",
      "Ep:176, loss:0.00000, loss_test:0.01900, lr:2.29e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.980, tt:5306.532\n",
      "Ep:177, loss:0.00000, loss_test:0.01904, lr:2.26e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.977, tt:5335.943\n",
      "Ep:178, loss:0.00000, loss_test:0.01900, lr:2.24e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.980, tt:5366.379\n",
      "Ep:179, loss:0.00000, loss_test:0.01903, lr:2.22e-02, fs:0.79793 (r=0.778,p=0.819),  time:29.981, tt:5396.658\n",
      "Ep:180, loss:0.00000, loss_test:0.01902, lr:2.20e-02, fs:0.79793 (r=0.778,p=0.819),  time:29.978, tt:5425.985\n",
      "Ep:181, loss:0.00000, loss_test:0.01907, lr:2.17e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.969, tt:5454.344\n",
      "Ep:182, loss:0.00000, loss_test:0.01908, lr:2.15e-02, fs:0.79793 (r=0.778,p=0.819),  time:29.968, tt:5484.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:183, loss:0.00000, loss_test:0.01910, lr:2.13e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.959, tt:5512.367\n",
      "Ep:184, loss:0.00000, loss_test:0.01909, lr:2.11e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.948, tt:5540.468\n",
      "Ep:185, loss:0.00000, loss_test:0.01906, lr:2.09e-02, fs:0.79793 (r=0.778,p=0.819),  time:29.947, tt:5570.068\n",
      "Ep:186, loss:0.00000, loss_test:0.01914, lr:2.07e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.948, tt:5600.236\n",
      "Ep:187, loss:0.00000, loss_test:0.01913, lr:2.05e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.948, tt:5630.295\n",
      "Ep:188, loss:0.00000, loss_test:0.01911, lr:2.03e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.955, tt:5661.478\n",
      "Ep:189, loss:0.00000, loss_test:0.01916, lr:2.01e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.952, tt:5690.918\n",
      "Ep:190, loss:0.00000, loss_test:0.01921, lr:1.99e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.944, tt:5719.398\n",
      "Ep:191, loss:0.00000, loss_test:0.01916, lr:1.97e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.943, tt:5749.015\n",
      "Ep:192, loss:0.00000, loss_test:0.01917, lr:1.95e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.947, tt:5779.705\n",
      "Ep:193, loss:0.00000, loss_test:0.01919, lr:1.93e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.947, tt:5809.632\n",
      "Ep:194, loss:0.00000, loss_test:0.01920, lr:1.91e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.945, tt:5839.184\n",
      "Ep:195, loss:0.00000, loss_test:0.01921, lr:1.89e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.931, tt:5866.467\n",
      "Ep:196, loss:0.00000, loss_test:0.01925, lr:1.87e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.925, tt:5895.218\n",
      "Ep:197, loss:0.00000, loss_test:0.01926, lr:1.85e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.928, tt:5925.811\n",
      "Ep:198, loss:0.00000, loss_test:0.01924, lr:1.83e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.907, tt:5951.476\n",
      "Ep:199, loss:0.00000, loss_test:0.01927, lr:1.81e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.894, tt:5978.780\n",
      "Ep:200, loss:0.00000, loss_test:0.01927, lr:1.80e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.888, tt:6007.560\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13647, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:27.216, tt:27.216\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13483, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:28.067, tt:56.135\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00025, loss_test:0.13369, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:28.726, tt:86.177\n",
      "Ep:3, loss:0.00025, loss_test:0.13266, lr:1.00e-02, fs:0.64167 (r=0.778,p=0.546),  time:29.525, tt:118.101\n",
      "Ep:4, loss:0.00024, loss_test:0.13133, lr:1.00e-02, fs:0.64979 (r=0.778,p=0.558),  time:29.880, tt:149.402\n",
      "Ep:5, loss:0.00024, loss_test:0.12982, lr:1.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:30.156, tt:180.938\n",
      "Ep:6, loss:0.00023, loss_test:0.12869, lr:1.00e-02, fs:0.62963 (r=0.687,p=0.581),  time:29.963, tt:209.742\n",
      "Ep:7, loss:0.00023, loss_test:0.12809, lr:1.00e-02, fs:0.62617 (r=0.677,p=0.583),  time:30.067, tt:240.533\n",
      "Ep:8, loss:0.00022, loss_test:0.12747, lr:1.00e-02, fs:0.61972 (r=0.667,p=0.579),  time:30.135, tt:271.216\n",
      "Ep:9, loss:0.00022, loss_test:0.12687, lr:1.00e-02, fs:0.62857 (r=0.667,p=0.595),  time:30.665, tt:306.648\n",
      "Ep:10, loss:0.00021, loss_test:0.12654, lr:1.00e-02, fs:0.62857 (r=0.667,p=0.595),  time:30.890, tt:339.791\n",
      "Ep:11, loss:0.00021, loss_test:0.12593, lr:1.00e-02, fs:0.63208 (r=0.677,p=0.593),  time:30.980, tt:371.755\n",
      "Ep:12, loss:0.00021, loss_test:0.12550, lr:1.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:31.143, tt:404.862\n",
      "Ep:13, loss:0.00020, loss_test:0.12485, lr:9.90e-03, fs:0.64115 (r=0.677,p=0.609),  time:31.226, tt:437.161\n",
      "Ep:14, loss:0.00020, loss_test:0.12402, lr:9.80e-03, fs:0.65072 (r=0.687,p=0.618),  time:31.329, tt:469.936\n",
      "Ep:15, loss:0.00020, loss_test:0.12316, lr:9.70e-03, fs:0.65403 (r=0.697,p=0.616),  time:31.375, tt:501.995\n",
      "Ep:16, loss:0.00019, loss_test:0.12259, lr:9.61e-03, fs:0.66038 (r=0.707,p=0.619),  time:31.448, tt:534.610\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.12214, lr:9.61e-03, fs:0.68246 (r=0.727,p=0.643),  time:31.563, tt:568.129\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.12149, lr:9.61e-03, fs:0.68246 (r=0.727,p=0.643),  time:31.572, tt:599.862\n",
      "Ep:19, loss:0.00018, loss_test:0.12079, lr:9.61e-03, fs:0.67619 (r=0.717,p=0.640),  time:31.609, tt:632.185\n",
      "Ep:20, loss:0.00018, loss_test:0.12054, lr:9.61e-03, fs:0.65700 (r=0.687,p=0.630),  time:31.617, tt:663.965\n",
      "Ep:21, loss:0.00018, loss_test:0.11965, lr:9.61e-03, fs:0.64390 (r=0.667,p=0.623),  time:31.650, tt:696.296\n",
      "Ep:22, loss:0.00017, loss_test:0.11841, lr:9.61e-03, fs:0.65366 (r=0.677,p=0.632),  time:31.685, tt:728.756\n",
      "Ep:23, loss:0.00017, loss_test:0.11723, lr:9.61e-03, fs:0.65366 (r=0.677,p=0.632),  time:31.714, tt:761.140\n",
      "Ep:24, loss:0.00016, loss_test:0.11623, lr:9.61e-03, fs:0.65700 (r=0.687,p=0.630),  time:31.717, tt:792.915\n",
      "Ep:25, loss:0.00016, loss_test:0.11502, lr:9.61e-03, fs:0.66667 (r=0.697,p=0.639),  time:31.730, tt:824.974\n",
      "Ep:26, loss:0.00016, loss_test:0.11368, lr:9.61e-03, fs:0.68269 (r=0.717,p=0.651),  time:31.715, tt:856.299\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.11311, lr:9.61e-03, fs:0.67308 (r=0.707,p=0.642),  time:31.728, tt:888.390\n",
      "Ep:28, loss:0.00015, loss_test:0.11250, lr:9.61e-03, fs:0.67633 (r=0.707,p=0.648),  time:31.773, tt:921.421\n",
      "Ep:29, loss:0.00015, loss_test:0.11055, lr:9.61e-03, fs:0.70244 (r=0.727,p=0.679),  time:31.789, tt:953.668\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.11002, lr:9.61e-03, fs:0.71429 (r=0.758,p=0.676),  time:31.809, tt:986.080\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.10896, lr:9.61e-03, fs:0.73077 (r=0.768,p=0.697),  time:31.826, tt:1018.436\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.10860, lr:9.61e-03, fs:0.73077 (r=0.768,p=0.697),  time:31.831, tt:1050.415\n",
      "Ep:33, loss:0.00013, loss_test:0.10705, lr:9.61e-03, fs:0.74038 (r=0.778,p=0.706),  time:31.847, tt:1082.806\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.10653, lr:9.61e-03, fs:0.74510 (r=0.768,p=0.724),  time:31.873, tt:1115.567\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.10673, lr:9.61e-03, fs:0.73430 (r=0.768,p=0.704),  time:31.856, tt:1146.833\n",
      "Ep:36, loss:0.00012, loss_test:0.10418, lr:9.61e-03, fs:0.73786 (r=0.768,p=0.710),  time:31.861, tt:1178.858\n",
      "Ep:37, loss:0.00011, loss_test:0.10434, lr:9.61e-03, fs:0.72816 (r=0.758,p=0.701),  time:31.857, tt:1210.569\n",
      "Ep:38, loss:0.00011, loss_test:0.10316, lr:9.61e-03, fs:0.73892 (r=0.758,p=0.721),  time:31.836, tt:1241.617\n",
      "Ep:39, loss:0.00011, loss_test:0.10152, lr:9.61e-03, fs:0.74146 (r=0.768,p=0.717),  time:31.828, tt:1273.101\n",
      "Ep:40, loss:0.00010, loss_test:0.10259, lr:9.61e-03, fs:0.75362 (r=0.788,p=0.722),  time:31.840, tt:1305.440\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.09978, lr:9.61e-03, fs:0.74257 (r=0.758,p=0.728),  time:31.826, tt:1336.690\n",
      "Ep:42, loss:0.00009, loss_test:0.10018, lr:9.61e-03, fs:0.73684 (r=0.778,p=0.700),  time:31.876, tt:1370.668\n",
      "Ep:43, loss:0.00009, loss_test:0.09761, lr:9.61e-03, fs:0.74611 (r=0.727,p=0.766),  time:31.874, tt:1402.455\n",
      "Ep:44, loss:0.00009, loss_test:0.09361, lr:9.61e-03, fs:0.77720 (r=0.758,p=0.798),  time:31.892, tt:1435.139\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.10355, lr:9.61e-03, fs:0.71889 (r=0.788,p=0.661),  time:31.884, tt:1466.675\n",
      "Ep:46, loss:0.00009, loss_test:0.09278, lr:9.61e-03, fs:0.73797 (r=0.697,p=0.784),  time:31.837, tt:1496.362\n",
      "Ep:47, loss:0.00008, loss_test:0.09885, lr:9.61e-03, fs:0.70647 (r=0.717,p=0.696),  time:31.841, tt:1528.362\n",
      "Ep:48, loss:0.00008, loss_test:0.09049, lr:9.61e-03, fs:0.76596 (r=0.727,p=0.809),  time:31.854, tt:1560.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00007, loss_test:0.09726, lr:9.61e-03, fs:0.74227 (r=0.727,p=0.758),  time:31.861, tt:1593.046\n",
      "Ep:50, loss:0.00007, loss_test:0.08794, lr:9.61e-03, fs:0.79381 (r=0.778,p=0.811),  time:31.876, tt:1625.672\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.09479, lr:9.61e-03, fs:0.74737 (r=0.717,p=0.780),  time:31.878, tt:1657.672\n",
      "Ep:52, loss:0.00006, loss_test:0.08643, lr:9.61e-03, fs:0.77419 (r=0.727,p=0.828),  time:31.873, tt:1689.256\n",
      "Ep:53, loss:0.00006, loss_test:0.09250, lr:9.61e-03, fs:0.73846 (r=0.727,p=0.750),  time:31.868, tt:1720.892\n",
      "Ep:54, loss:0.00006, loss_test:0.08538, lr:9.61e-03, fs:0.77596 (r=0.717,p=0.845),  time:31.870, tt:1752.874\n",
      "Ep:55, loss:0.00006, loss_test:0.09319, lr:9.61e-03, fs:0.74227 (r=0.727,p=0.758),  time:31.868, tt:1784.629\n",
      "Ep:56, loss:0.00006, loss_test:0.08518, lr:9.61e-03, fs:0.76087 (r=0.707,p=0.824),  time:31.870, tt:1816.600\n",
      "Ep:57, loss:0.00005, loss_test:0.09173, lr:9.61e-03, fs:0.75532 (r=0.717,p=0.798),  time:31.869, tt:1848.389\n",
      "Ep:58, loss:0.00005, loss_test:0.08212, lr:9.61e-03, fs:0.75824 (r=0.697,p=0.831),  time:31.874, tt:1880.591\n",
      "Ep:59, loss:0.00005, loss_test:0.08990, lr:9.61e-03, fs:0.75410 (r=0.697,p=0.821),  time:31.875, tt:1912.471\n",
      "Ep:60, loss:0.00005, loss_test:0.08657, lr:9.61e-03, fs:0.75000 (r=0.697,p=0.812),  time:31.879, tt:1944.634\n",
      "Ep:61, loss:0.00005, loss_test:0.08583, lr:9.61e-03, fs:0.75556 (r=0.687,p=0.840),  time:31.879, tt:1976.513\n",
      "Ep:62, loss:0.00005, loss_test:0.08672, lr:9.51e-03, fs:0.74317 (r=0.687,p=0.810),  time:31.890, tt:2009.099\n",
      "Ep:63, loss:0.00004, loss_test:0.07972, lr:9.41e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.876, tt:2040.045\n",
      "Ep:64, loss:0.00004, loss_test:0.09302, lr:9.32e-03, fs:0.74468 (r=0.707,p=0.787),  time:31.869, tt:2071.480\n",
      "Ep:65, loss:0.00004, loss_test:0.07962, lr:9.23e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.862, tt:2102.923\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.09235, lr:9.23e-03, fs:0.74866 (r=0.707,p=0.795),  time:31.861, tt:2134.675\n",
      "Ep:67, loss:0.00004, loss_test:0.08539, lr:9.23e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.887, tt:2168.298\n",
      "Ep:68, loss:0.00004, loss_test:0.08472, lr:9.23e-03, fs:0.77005 (r=0.727,p=0.818),  time:31.883, tt:2199.922\n",
      "Ep:69, loss:0.00004, loss_test:0.08420, lr:9.23e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.882, tt:2231.745\n",
      "Ep:70, loss:0.00004, loss_test:0.08796, lr:9.23e-03, fs:0.71591 (r=0.636,p=0.818),  time:31.861, tt:2262.105\n",
      "Ep:71, loss:0.00004, loss_test:0.08057, lr:9.23e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.853, tt:2293.401\n",
      "Ep:72, loss:0.00004, loss_test:0.08470, lr:9.23e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.851, tt:2325.090\n",
      "Ep:73, loss:0.00003, loss_test:0.08667, lr:9.23e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.850, tt:2356.913\n",
      "Ep:74, loss:0.00003, loss_test:0.08133, lr:9.23e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.854, tt:2389.045\n",
      "Ep:75, loss:0.00003, loss_test:0.08412, lr:9.23e-03, fs:0.76571 (r=0.677,p=0.882),  time:31.862, tt:2421.477\n",
      "Ep:76, loss:0.00003, loss_test:0.08677, lr:9.23e-03, fs:0.72727 (r=0.646,p=0.831),  time:31.844, tt:2451.993\n",
      "Ep:77, loss:0.00003, loss_test:0.08173, lr:9.14e-03, fs:0.77273 (r=0.687,p=0.883),  time:31.814, tt:2481.528\n",
      "Ep:78, loss:0.00003, loss_test:0.08348, lr:9.04e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.802, tt:2512.327\n",
      "Ep:79, loss:0.00003, loss_test:0.08600, lr:8.95e-03, fs:0.76571 (r=0.677,p=0.882),  time:31.787, tt:2542.996\n",
      "Ep:80, loss:0.00003, loss_test:0.08224, lr:8.86e-03, fs:0.77714 (r=0.687,p=0.895),  time:31.760, tt:2572.579\n",
      "Ep:81, loss:0.00003, loss_test:0.08436, lr:8.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.773, tt:2605.390\n",
      "Ep:82, loss:0.00003, loss_test:0.08093, lr:8.69e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.753, tt:2635.529\n",
      "Ep:83, loss:0.00003, loss_test:0.08909, lr:8.60e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.755, tt:2667.401\n",
      "Ep:84, loss:0.00003, loss_test:0.08089, lr:8.51e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.751, tt:2698.848\n",
      "Ep:85, loss:0.00003, loss_test:0.08758, lr:8.43e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.747, tt:2730.247\n",
      "Ep:86, loss:0.00003, loss_test:0.07898, lr:8.35e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.746, tt:2761.919\n",
      "Ep:87, loss:0.00003, loss_test:0.08976, lr:8.26e-03, fs:0.72727 (r=0.646,p=0.831),  time:31.752, tt:2794.187\n",
      "Ep:88, loss:0.00003, loss_test:0.07927, lr:8.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.756, tt:2826.329\n",
      "Ep:89, loss:0.00003, loss_test:0.08811, lr:8.10e-03, fs:0.72727 (r=0.646,p=0.831),  time:31.758, tt:2858.252\n",
      "Ep:90, loss:0.00002, loss_test:0.08433, lr:8.02e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.741, tt:2888.427\n",
      "Ep:91, loss:0.00002, loss_test:0.08362, lr:7.94e-03, fs:0.74556 (r=0.636,p=0.900),  time:31.738, tt:2919.932\n",
      "Ep:92, loss:0.00002, loss_test:0.08470, lr:7.86e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.745, tt:2952.284\n",
      "Ep:93, loss:0.00002, loss_test:0.08397, lr:7.78e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.756, tt:2985.072\n",
      "Ep:94, loss:0.00002, loss_test:0.08637, lr:7.70e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.751, tt:3016.307\n",
      "Ep:95, loss:0.00002, loss_test:0.08084, lr:7.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.755, tt:3048.506\n",
      "Ep:96, loss:0.00002, loss_test:0.08767, lr:7.55e-03, fs:0.73373 (r=0.626,p=0.886),  time:31.769, tt:3081.561\n",
      "Ep:97, loss:0.00002, loss_test:0.08206, lr:7.47e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.777, tt:3114.152\n",
      "Ep:98, loss:0.00002, loss_test:0.08463, lr:7.40e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.785, tt:3146.706\n",
      "Ep:99, loss:0.00002, loss_test:0.08675, lr:7.32e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.782, tt:3178.187\n",
      "Ep:100, loss:0.00002, loss_test:0.08521, lr:7.25e-03, fs:0.73373 (r=0.626,p=0.886),  time:31.780, tt:3209.818\n",
      "Ep:101, loss:0.00002, loss_test:0.08469, lr:7.18e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.787, tt:3242.247\n",
      "Ep:102, loss:0.00002, loss_test:0.08744, lr:7.11e-03, fs:0.73373 (r=0.626,p=0.886),  time:31.785, tt:3273.903\n",
      "Ep:103, loss:0.00002, loss_test:0.08357, lr:7.03e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.792, tt:3306.402\n",
      "Ep:104, loss:0.00002, loss_test:0.08575, lr:6.96e-03, fs:0.77966 (r=0.697,p=0.885),  time:31.793, tt:3338.298\n",
      "Ep:105, loss:0.00002, loss_test:0.08511, lr:6.89e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.796, tt:3370.326\n",
      "Ep:106, loss:0.00002, loss_test:0.08703, lr:6.83e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.794, tt:3401.989\n",
      "Ep:107, loss:0.00002, loss_test:0.08428, lr:6.76e-03, fs:0.77714 (r=0.687,p=0.895),  time:31.790, tt:3433.358\n",
      "Ep:108, loss:0.00002, loss_test:0.08614, lr:6.69e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.793, tt:3465.426\n",
      "Ep:109, loss:0.00002, loss_test:0.08838, lr:6.62e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.783, tt:3496.142\n",
      "Ep:110, loss:0.00002, loss_test:0.08321, lr:6.56e-03, fs:0.73373 (r=0.626,p=0.886),  time:31.782, tt:3527.822\n",
      "Ep:111, loss:0.00002, loss_test:0.08744, lr:6.49e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.777, tt:3559.041\n",
      "Ep:112, loss:0.00002, loss_test:0.08560, lr:6.43e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.773, tt:3590.337\n",
      "Ep:113, loss:0.00002, loss_test:0.08485, lr:6.36e-03, fs:0.72941 (r=0.626,p=0.873),  time:31.776, tt:3622.521\n",
      "Ep:114, loss:0.00002, loss_test:0.08590, lr:6.30e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.776, tt:3654.204\n",
      "Ep:115, loss:0.00002, loss_test:0.08515, lr:6.24e-03, fs:0.73373 (r=0.626,p=0.886),  time:31.773, tt:3685.653\n",
      "Ep:116, loss:0.00001, loss_test:0.08422, lr:6.17e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.754, tt:3715.273\n",
      "Ep:117, loss:0.00001, loss_test:0.08568, lr:6.11e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.760, tt:3747.701\n",
      "Ep:118, loss:0.00001, loss_test:0.08415, lr:6.05e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.796, tt:3783.764\n",
      "Ep:119, loss:0.00001, loss_test:0.08620, lr:5.99e-03, fs:0.72941 (r=0.626,p=0.873),  time:31.797, tt:3815.697\n",
      "Ep:120, loss:0.00001, loss_test:0.08383, lr:5.93e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.788, tt:3846.295\n",
      "Ep:121, loss:0.00001, loss_test:0.08526, lr:5.87e-03, fs:0.72515 (r=0.626,p=0.861),  time:31.780, tt:3877.167\n",
      "Ep:122, loss:0.00001, loss_test:0.08415, lr:5.81e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.774, tt:3908.146\n",
      "Ep:123, loss:0.00001, loss_test:0.08407, lr:5.75e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.776, tt:3940.245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00001, loss_test:0.08614, lr:5.70e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.779, tt:3972.429\n",
      "Ep:125, loss:0.00001, loss_test:0.08428, lr:5.64e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.782, tt:4004.555\n",
      "Ep:126, loss:0.00001, loss_test:0.08521, lr:5.58e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.781, tt:4036.185\n",
      "Ep:127, loss:0.00001, loss_test:0.08625, lr:5.53e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.779, tt:4067.678\n",
      "Ep:128, loss:0.00001, loss_test:0.08428, lr:5.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.779, tt:4099.473\n",
      "Ep:129, loss:0.00001, loss_test:0.08458, lr:5.42e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.775, tt:4130.748\n",
      "Ep:130, loss:0.00001, loss_test:0.08562, lr:5.36e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.776, tt:4162.622\n",
      "Ep:131, loss:0.00001, loss_test:0.08460, lr:5.31e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.770, tt:4193.697\n",
      "Ep:132, loss:0.00001, loss_test:0.08525, lr:5.26e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.780, tt:4226.787\n",
      "Ep:133, loss:0.00001, loss_test:0.08474, lr:5.20e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.764, tt:4256.399\n",
      "Ep:134, loss:0.00001, loss_test:0.08533, lr:5.15e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.766, tt:4288.378\n",
      "Ep:135, loss:0.00001, loss_test:0.08496, lr:5.10e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.765, tt:4320.029\n",
      "Ep:136, loss:0.00001, loss_test:0.08490, lr:5.05e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.768, tt:4352.284\n",
      "Ep:137, loss:0.00001, loss_test:0.08505, lr:5.00e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.768, tt:4383.980\n",
      "Ep:138, loss:0.00001, loss_test:0.08401, lr:4.95e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.776, tt:4416.842\n",
      "Ep:139, loss:0.00001, loss_test:0.08559, lr:4.90e-03, fs:0.73373 (r=0.626,p=0.886),  time:31.783, tt:4449.652\n",
      "Ep:140, loss:0.00001, loss_test:0.08392, lr:4.85e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.809, tt:4485.029\n",
      "Ep:141, loss:0.00001, loss_test:0.08510, lr:4.80e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.813, tt:4517.496\n",
      "Ep:142, loss:0.00001, loss_test:0.08656, lr:4.75e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.811, tt:4548.902\n",
      "Ep:143, loss:0.00001, loss_test:0.08434, lr:4.71e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.824, tt:4582.703\n",
      "Ep:144, loss:0.00001, loss_test:0.08561, lr:4.66e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.828, tt:4615.117\n",
      "Ep:145, loss:0.00001, loss_test:0.08510, lr:4.61e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.828, tt:4646.919\n",
      "Ep:146, loss:0.00001, loss_test:0.08488, lr:4.57e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.817, tt:4677.113\n",
      "Ep:147, loss:0.00001, loss_test:0.08516, lr:4.52e-03, fs:0.72941 (r=0.626,p=0.873),  time:31.815, tt:4708.563\n",
      "Ep:148, loss:0.00001, loss_test:0.08458, lr:4.48e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.811, tt:4739.850\n",
      "Ep:149, loss:0.00001, loss_test:0.08645, lr:4.43e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.819, tt:4772.783\n",
      "Ep:150, loss:0.00001, loss_test:0.08427, lr:4.39e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.814, tt:4803.954\n",
      "Ep:151, loss:0.00001, loss_test:0.08504, lr:4.34e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.801, tt:4833.709\n",
      "Ep:152, loss:0.00001, loss_test:0.08652, lr:4.30e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.787, tt:4863.395\n",
      "Ep:153, loss:0.00001, loss_test:0.08427, lr:4.26e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.773, tt:4893.050\n",
      "Ep:154, loss:0.00001, loss_test:0.08590, lr:4.21e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.784, tt:4926.583\n",
      "Ep:155, loss:0.00001, loss_test:0.08546, lr:4.17e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.788, tt:4958.909\n",
      "Ep:156, loss:0.00001, loss_test:0.08460, lr:4.13e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.789, tt:4990.893\n",
      "Ep:157, loss:0.00001, loss_test:0.08559, lr:4.09e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.791, tt:5022.912\n",
      "Ep:158, loss:0.00001, loss_test:0.08558, lr:4.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.793, tt:5055.013\n",
      "Ep:159, loss:0.00001, loss_test:0.08580, lr:4.01e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.788, tt:5086.017\n",
      "Ep:160, loss:0.00001, loss_test:0.08539, lr:3.97e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.788, tt:5117.832\n",
      "Ep:161, loss:0.00001, loss_test:0.08500, lr:3.93e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.787, tt:5149.540\n",
      "Ep:162, loss:0.00001, loss_test:0.08563, lr:3.89e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.798, tt:5183.040\n",
      "Ep:163, loss:0.00001, loss_test:0.08528, lr:3.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.798, tt:5214.942\n",
      "Ep:164, loss:0.00001, loss_test:0.08479, lr:3.81e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.797, tt:5246.541\n",
      "Ep:165, loss:0.00001, loss_test:0.08526, lr:3.77e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.794, tt:5277.865\n",
      "Ep:166, loss:0.00001, loss_test:0.08631, lr:3.73e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.798, tt:5310.306\n",
      "Ep:167, loss:0.00001, loss_test:0.08524, lr:3.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.802, tt:5342.765\n",
      "Ep:168, loss:0.00001, loss_test:0.08541, lr:3.66e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.798, tt:5373.884\n",
      "Ep:169, loss:0.00001, loss_test:0.08558, lr:3.62e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.793, tt:5404.824\n",
      "Ep:170, loss:0.00001, loss_test:0.08536, lr:3.59e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.796, tt:5437.032\n",
      "Ep:171, loss:0.00001, loss_test:0.08576, lr:3.55e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.801, tt:5469.803\n",
      "Ep:172, loss:0.00001, loss_test:0.08571, lr:3.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.807, tt:5502.607\n",
      "Ep:173, loss:0.00001, loss_test:0.08620, lr:3.48e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.806, tt:5534.158\n",
      "Ep:174, loss:0.00001, loss_test:0.08486, lr:3.45e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.805, tt:5565.813\n",
      "Ep:175, loss:0.00001, loss_test:0.08568, lr:3.41e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.798, tt:5596.456\n",
      "Ep:176, loss:0.00001, loss_test:0.08579, lr:3.38e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.793, tt:5627.447\n",
      "Ep:177, loss:0.00001, loss_test:0.08538, lr:3.34e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.802, tt:5660.747\n",
      "Ep:178, loss:0.00001, loss_test:0.08501, lr:3.31e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.803, tt:5692.720\n",
      "Ep:179, loss:0.00001, loss_test:0.08588, lr:3.28e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.802, tt:5724.317\n",
      "Ep:180, loss:0.00001, loss_test:0.08549, lr:3.24e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.791, tt:5754.248\n",
      "Ep:181, loss:0.00001, loss_test:0.08470, lr:3.21e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.789, tt:5785.656\n",
      "Ep:182, loss:0.00001, loss_test:0.08622, lr:3.18e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.783, tt:5816.330\n",
      "Ep:183, loss:0.00001, loss_test:0.08515, lr:3.15e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.779, tt:5847.313\n",
      "Ep:184, loss:0.00001, loss_test:0.08518, lr:3.12e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.782, tt:5879.681\n",
      "Ep:185, loss:0.00001, loss_test:0.08634, lr:3.09e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.780, tt:5911.100\n",
      "Ep:186, loss:0.00001, loss_test:0.08503, lr:3.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.780, tt:5942.808\n",
      "Ep:187, loss:0.00001, loss_test:0.08500, lr:3.02e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.776, tt:5973.807\n",
      "Ep:188, loss:0.00001, loss_test:0.08659, lr:2.99e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.772, tt:6004.962\n",
      "Ep:189, loss:0.00001, loss_test:0.08549, lr:2.96e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.773, tt:6036.793\n",
      "Ep:190, loss:0.00001, loss_test:0.08466, lr:2.93e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.773, tt:6068.710\n",
      "Ep:191, loss:0.00001, loss_test:0.08650, lr:2.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.766, tt:6099.045\n",
      "Ep:192, loss:0.00001, loss_test:0.08660, lr:2.88e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.755, tt:6128.732\n",
      "Ep:193, loss:0.00001, loss_test:0.08476, lr:2.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.754, tt:6160.283\n",
      "Ep:194, loss:0.00001, loss_test:0.08552, lr:2.82e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.750, tt:6191.210\n",
      "Ep:195, loss:0.00001, loss_test:0.08633, lr:2.79e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.746, tt:6222.188\n",
      "Ep:196, loss:0.00001, loss_test:0.08520, lr:2.76e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.730, tt:6250.815\n",
      "Ep:197, loss:0.00001, loss_test:0.08560, lr:2.73e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.714, tt:6279.440\n",
      "Ep:198, loss:0.00001, loss_test:0.08613, lr:2.71e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.695, tt:6307.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:199, loss:0.00001, loss_test:0.08515, lr:2.68e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.684, tt:6336.863\n",
      "Ep:200, loss:0.00001, loss_test:0.08548, lr:2.65e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.665, tt:6364.764\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02181, lr:6.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:35.087, tt:35.087\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02507, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.847, tt:75.693\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02791, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.773, tt:116.318\n",
      "Ep:3, loss:0.00005, loss_test:0.02895, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.890, tt:155.561\n",
      "Ep:4, loss:0.00006, loss_test:0.02902, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.214, tt:196.068\n",
      "Ep:5, loss:0.00006, loss_test:0.02840, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.169, tt:235.012\n",
      "Ep:6, loss:0.00005, loss_test:0.02717, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.278, tt:274.946\n",
      "Ep:7, loss:0.00005, loss_test:0.02549, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.509, tt:316.068\n",
      "Ep:8, loss:0.00005, loss_test:0.02359, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:39.336, tt:354.024\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02217, lr:6.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:39.324, tt:393.236\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02210, lr:6.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:39.315, tt:432.461\n",
      "Ep:11, loss:0.00004, loss_test:0.02372, lr:6.00e-02, fs:0.64574 (r=0.727,p=0.581),  time:39.390, tt:472.676\n",
      "Ep:12, loss:0.00004, loss_test:0.02524, lr:6.00e-02, fs:0.61905 (r=0.657,p=0.586),  time:39.434, tt:512.642\n",
      "Ep:13, loss:0.00004, loss_test:0.02453, lr:6.00e-02, fs:0.63810 (r=0.677,p=0.604),  time:39.515, tt:553.205\n",
      "Ep:14, loss:0.00003, loss_test:0.02248, lr:6.00e-02, fs:0.65138 (r=0.717,p=0.597),  time:39.579, tt:593.688\n",
      "Ep:15, loss:0.00003, loss_test:0.02101, lr:6.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:39.683, tt:634.931\n",
      "Ep:16, loss:0.00003, loss_test:0.02039, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:39.631, tt:673.730\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.02019, lr:6.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:39.695, tt:714.505\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.02018, lr:6.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:39.618, tt:752.734\n",
      "Ep:19, loss:0.00003, loss_test:0.02041, lr:6.00e-02, fs:0.68421 (r=0.788,p=0.605),  time:39.570, tt:791.404\n",
      "Ep:20, loss:0.00003, loss_test:0.02070, lr:6.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:39.609, tt:831.782\n",
      "Ep:21, loss:0.00003, loss_test:0.02060, lr:6.00e-02, fs:0.65116 (r=0.707,p=0.603),  time:39.571, tt:870.562\n",
      "Ep:22, loss:0.00003, loss_test:0.02011, lr:6.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:39.561, tt:909.894\n",
      "Ep:23, loss:0.00002, loss_test:0.01952, lr:6.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:39.548, tt:949.153\n",
      "Ep:24, loss:0.00002, loss_test:0.01912, lr:6.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:39.552, tt:988.799\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01887, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:39.526, tt:1027.667\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01872, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:39.554, tt:1067.971\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01865, lr:6.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:39.605, tt:1108.944\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01861, lr:6.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:39.636, tt:1149.439\n",
      "Ep:29, loss:0.00002, loss_test:0.01847, lr:6.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:39.619, tt:1188.562\n",
      "Ep:30, loss:0.00002, loss_test:0.01825, lr:6.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:39.655, tt:1229.305\n",
      "Ep:31, loss:0.00002, loss_test:0.01800, lr:6.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:39.645, tt:1268.656\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01781, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:39.587, tt:1306.354\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01767, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:39.660, tt:1348.426\n",
      "Ep:34, loss:0.00002, loss_test:0.01759, lr:6.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:39.676, tt:1388.656\n",
      "Ep:35, loss:0.00002, loss_test:0.01751, lr:6.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:39.702, tt:1429.264\n",
      "Ep:36, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:39.745, tt:1470.582\n",
      "Ep:37, loss:0.00002, loss_test:0.01744, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:39.769, tt:1511.226\n",
      "Ep:38, loss:0.00002, loss_test:0.01735, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:39.729, tt:1549.439\n",
      "Ep:39, loss:0.00002, loss_test:0.01729, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:39.794, tt:1591.762\n",
      "Ep:40, loss:0.00001, loss_test:0.01719, lr:6.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:39.774, tt:1630.721\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01718, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:39.830, tt:1672.872\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01712, lr:6.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:39.844, tt:1713.282\n",
      "Ep:43, loss:0.00001, loss_test:0.01712, lr:6.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:39.871, tt:1754.333\n",
      "Ep:44, loss:0.00001, loss_test:0.01713, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:39.848, tt:1793.165\n",
      "Ep:45, loss:0.00001, loss_test:0.01711, lr:6.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:39.836, tt:1832.443\n",
      "Ep:46, loss:0.00001, loss_test:0.01710, lr:6.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:39.884, tt:1874.531\n",
      "Ep:47, loss:0.00001, loss_test:0.01709, lr:6.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:39.869, tt:1913.734\n",
      "Ep:48, loss:0.00001, loss_test:0.01706, lr:6.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:39.908, tt:1955.485\n",
      "Ep:49, loss:0.00001, loss_test:0.01707, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:39.918, tt:1995.919\n",
      "Ep:50, loss:0.00001, loss_test:0.01706, lr:6.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:39.921, tt:2035.986\n",
      "Ep:51, loss:0.00001, loss_test:0.01706, lr:6.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:39.916, tt:2075.634\n",
      "Ep:52, loss:0.00001, loss_test:0.01711, lr:6.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:39.987, tt:2119.300\n",
      "Ep:53, loss:0.00001, loss_test:0.01715, lr:5.94e-02, fs:0.73786 (r=0.768,p=0.710),  time:40.007, tt:2160.383\n",
      "Ep:54, loss:0.00001, loss_test:0.01714, lr:5.88e-02, fs:0.73786 (r=0.768,p=0.710),  time:40.044, tt:2202.425\n",
      "Ep:55, loss:0.00001, loss_test:0.01715, lr:5.82e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.031, tt:2241.709\n",
      "Ep:56, loss:0.00001, loss_test:0.01714, lr:5.76e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.050, tt:2282.852\n",
      "Ep:57, loss:0.00001, loss_test:0.01714, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.074, tt:2324.294\n",
      "Ep:58, loss:0.00001, loss_test:0.01717, lr:5.65e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.062, tt:2363.660\n",
      "Ep:59, loss:0.00001, loss_test:0.01723, lr:5.59e-02, fs:0.74000 (r=0.747,p=0.733),  time:40.074, tt:2404.451\n",
      "Ep:60, loss:0.00001, loss_test:0.01731, lr:5.54e-02, fs:0.72727 (r=0.727,p=0.727),  time:40.095, tt:2445.820\n",
      "Ep:61, loss:0.00001, loss_test:0.01732, lr:5.48e-02, fs:0.72727 (r=0.727,p=0.727),  time:40.122, tt:2487.595\n",
      "Ep:62, loss:0.00001, loss_test:0.01735, lr:5.43e-02, fs:0.70526 (r=0.677,p=0.736),  time:40.120, tt:2527.528\n",
      "Ep:63, loss:0.00001, loss_test:0.01736, lr:5.37e-02, fs:0.70526 (r=0.677,p=0.736),  time:40.130, tt:2568.343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01741, lr:5.32e-02, fs:0.69149 (r=0.657,p=0.730),  time:40.115, tt:2607.497\n",
      "Ep:65, loss:0.00001, loss_test:0.01745, lr:5.27e-02, fs:0.68449 (r=0.646,p=0.727),  time:40.110, tt:2647.239\n",
      "Ep:66, loss:0.00001, loss_test:0.01746, lr:5.21e-02, fs:0.68449 (r=0.646,p=0.727),  time:40.139, tt:2689.331\n",
      "Ep:67, loss:0.00001, loss_test:0.01747, lr:5.16e-02, fs:0.68449 (r=0.646,p=0.727),  time:40.136, tt:2729.251\n",
      "Ep:68, loss:0.00001, loss_test:0.01757, lr:5.11e-02, fs:0.67027 (r=0.626,p=0.721),  time:40.210, tt:2774.458\n",
      "Ep:69, loss:0.00001, loss_test:0.01761, lr:5.06e-02, fs:0.66304 (r=0.616,p=0.718),  time:40.211, tt:2814.781\n",
      "Ep:70, loss:0.00001, loss_test:0.01768, lr:5.01e-02, fs:0.66304 (r=0.616,p=0.718),  time:40.194, tt:2853.768\n",
      "Ep:71, loss:0.00001, loss_test:0.01773, lr:4.96e-02, fs:0.67033 (r=0.616,p=0.735),  time:40.184, tt:2893.230\n",
      "Ep:72, loss:0.00001, loss_test:0.01773, lr:4.91e-02, fs:0.67033 (r=0.616,p=0.735),  time:40.194, tt:2934.142\n",
      "Ep:73, loss:0.00001, loss_test:0.01778, lr:4.86e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.205, tt:2975.194\n",
      "Ep:74, loss:0.00001, loss_test:0.01785, lr:4.81e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.221, tt:3016.578\n",
      "Ep:75, loss:0.00001, loss_test:0.01782, lr:4.76e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.218, tt:3056.544\n",
      "Ep:76, loss:0.00001, loss_test:0.01787, lr:4.71e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.221, tt:3097.032\n",
      "Ep:77, loss:0.00001, loss_test:0.01793, lr:4.67e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.205, tt:3136.003\n",
      "Ep:78, loss:0.00001, loss_test:0.01793, lr:4.62e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.203, tt:3176.062\n",
      "Ep:79, loss:0.00001, loss_test:0.01800, lr:4.57e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.185, tt:3214.817\n",
      "Ep:80, loss:0.00001, loss_test:0.01803, lr:4.53e-02, fs:0.67778 (r=0.616,p=0.753),  time:40.187, tt:3255.112\n",
      "Ep:81, loss:0.00001, loss_test:0.01809, lr:4.48e-02, fs:0.67778 (r=0.616,p=0.753),  time:40.213, tt:3297.443\n",
      "Ep:82, loss:0.00001, loss_test:0.01811, lr:4.44e-02, fs:0.67778 (r=0.616,p=0.753),  time:40.198, tt:3336.434\n",
      "Ep:83, loss:0.00001, loss_test:0.01815, lr:4.39e-02, fs:0.67778 (r=0.616,p=0.753),  time:40.200, tt:3376.829\n",
      "Ep:84, loss:0.00001, loss_test:0.01819, lr:4.35e-02, fs:0.67778 (r=0.616,p=0.753),  time:40.208, tt:3417.721\n",
      "Ep:85, loss:0.00001, loss_test:0.01824, lr:4.31e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.221, tt:3458.970\n",
      "Ep:86, loss:0.00001, loss_test:0.01827, lr:4.26e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.243, tt:3501.138\n",
      "Ep:87, loss:0.00001, loss_test:0.01832, lr:4.22e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.258, tt:3542.709\n",
      "Ep:88, loss:0.00001, loss_test:0.01838, lr:4.18e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.271, tt:3584.087\n",
      "Ep:89, loss:0.00001, loss_test:0.01844, lr:4.14e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.282, tt:3625.338\n",
      "Ep:90, loss:0.00001, loss_test:0.01849, lr:4.10e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.285, tt:3665.908\n",
      "Ep:91, loss:0.00001, loss_test:0.01854, lr:4.05e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.288, tt:3706.462\n",
      "Ep:92, loss:0.00001, loss_test:0.01857, lr:4.01e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.291, tt:3747.102\n",
      "Ep:93, loss:0.00001, loss_test:0.01861, lr:3.97e-02, fs:0.68156 (r=0.616,p=0.762),  time:40.340, tt:3791.953\n",
      "Ep:94, loss:0.00001, loss_test:0.01862, lr:3.93e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.348, tt:3833.052\n",
      "Ep:95, loss:0.00001, loss_test:0.01867, lr:3.89e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.356, tt:3874.134\n",
      "Ep:96, loss:0.00001, loss_test:0.01872, lr:3.86e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.374, tt:3916.307\n",
      "Ep:97, loss:0.00001, loss_test:0.01876, lr:3.82e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.363, tt:3955.535\n",
      "Ep:98, loss:0.00001, loss_test:0.01879, lr:3.78e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.362, tt:3995.871\n",
      "Ep:99, loss:0.00001, loss_test:0.01883, lr:3.74e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.361, tt:4036.079\n",
      "Ep:100, loss:0.00001, loss_test:0.01885, lr:3.70e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.351, tt:4075.466\n",
      "Ep:101, loss:0.00001, loss_test:0.01886, lr:3.67e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.336, tt:4114.296\n",
      "Ep:102, loss:0.00000, loss_test:0.01893, lr:3.63e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.347, tt:4155.748\n",
      "Ep:103, loss:0.00000, loss_test:0.01900, lr:3.59e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.355, tt:4196.878\n",
      "Ep:104, loss:0.00000, loss_test:0.01906, lr:3.56e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.359, tt:4237.674\n",
      "Ep:105, loss:0.00000, loss_test:0.01911, lr:3.52e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.348, tt:4276.900\n",
      "Ep:106, loss:0.00000, loss_test:0.01912, lr:3.49e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.342, tt:4316.610\n",
      "Ep:107, loss:0.00000, loss_test:0.01914, lr:3.45e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.341, tt:4356.833\n",
      "Ep:108, loss:0.00000, loss_test:0.01916, lr:3.42e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.326, tt:4395.520\n",
      "Ep:109, loss:0.00000, loss_test:0.01918, lr:3.38e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.328, tt:4436.095\n",
      "Ep:110, loss:0.00000, loss_test:0.01921, lr:3.35e-02, fs:0.68539 (r=0.616,p=0.772),  time:40.375, tt:4481.596\n",
      "Ep:111, loss:0.00000, loss_test:0.01927, lr:3.32e-02, fs:0.68182 (r=0.606,p=0.779),  time:40.368, tt:4521.196\n",
      "Ep:112, loss:0.00000, loss_test:0.01930, lr:3.28e-02, fs:0.68182 (r=0.606,p=0.779),  time:40.381, tt:4563.026\n",
      "Ep:113, loss:0.00000, loss_test:0.01933, lr:3.25e-02, fs:0.67429 (r=0.596,p=0.776),  time:40.393, tt:4604.784\n",
      "Ep:114, loss:0.00000, loss_test:0.01933, lr:3.22e-02, fs:0.67429 (r=0.596,p=0.776),  time:40.399, tt:4645.934\n",
      "Ep:115, loss:0.00000, loss_test:0.01939, lr:3.19e-02, fs:0.67429 (r=0.596,p=0.776),  time:40.410, tt:4687.602\n",
      "Ep:116, loss:0.00000, loss_test:0.01945, lr:3.15e-02, fs:0.67429 (r=0.596,p=0.776),  time:40.430, tt:4730.329\n",
      "Ep:117, loss:0.00000, loss_test:0.01949, lr:3.12e-02, fs:0.67429 (r=0.596,p=0.776),  time:40.445, tt:4772.481\n",
      "Ep:118, loss:0.00000, loss_test:0.01951, lr:3.09e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.457, tt:4814.397\n",
      "Ep:119, loss:0.00000, loss_test:0.01954, lr:3.06e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.458, tt:4854.934\n",
      "Ep:120, loss:0.00000, loss_test:0.01958, lr:3.03e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.476, tt:4897.645\n",
      "Ep:121, loss:0.00000, loss_test:0.01962, lr:3.00e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.473, tt:4937.664\n",
      "Ep:122, loss:0.00000, loss_test:0.01964, lr:2.97e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.461, tt:4976.707\n",
      "Ep:123, loss:0.00000, loss_test:0.01966, lr:2.94e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.476, tt:5018.967\n",
      "Ep:124, loss:0.00000, loss_test:0.01967, lr:2.91e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.479, tt:5059.850\n",
      "Ep:125, loss:0.00000, loss_test:0.01973, lr:2.88e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.490, tt:5101.796\n",
      "Ep:126, loss:0.00000, loss_test:0.01978, lr:2.85e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.513, tt:5145.173\n",
      "Ep:127, loss:0.00000, loss_test:0.01982, lr:2.82e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.505, tt:5184.630\n",
      "Ep:128, loss:0.00000, loss_test:0.01985, lr:2.80e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.497, tt:5224.069\n",
      "Ep:129, loss:0.00000, loss_test:0.01987, lr:2.77e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.503, tt:5265.424\n",
      "Ep:130, loss:0.00000, loss_test:0.01990, lr:2.74e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.491, tt:5304.371\n",
      "Ep:131, loss:0.00000, loss_test:0.01994, lr:2.71e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.494, tt:5345.170\n",
      "Ep:132, loss:0.00000, loss_test:0.01998, lr:2.69e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.486, tt:5384.604\n",
      "Ep:133, loss:0.00000, loss_test:0.02002, lr:2.66e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.477, tt:5423.907\n",
      "Ep:134, loss:0.00000, loss_test:0.02006, lr:2.63e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.481, tt:5464.975\n",
      "Ep:135, loss:0.00000, loss_test:0.02008, lr:2.61e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.480, tt:5505.250\n",
      "Ep:136, loss:0.00000, loss_test:0.02011, lr:2.58e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.476, tt:5545.276\n",
      "Ep:137, loss:0.00000, loss_test:0.02016, lr:2.55e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.464, tt:5584.075\n",
      "Ep:138, loss:0.00000, loss_test:0.02019, lr:2.53e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.463, tt:5624.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.02023, lr:2.50e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.443, tt:5662.037\n",
      "Ep:140, loss:0.00000, loss_test:0.02025, lr:2.48e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.442, tt:5702.392\n",
      "Ep:141, loss:0.00000, loss_test:0.02028, lr:2.45e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.426, tt:5740.543\n",
      "Ep:142, loss:0.00000, loss_test:0.02032, lr:2.43e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.434, tt:5782.066\n",
      "Ep:143, loss:0.00000, loss_test:0.02034, lr:2.40e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.450, tt:5824.729\n",
      "Ep:144, loss:0.00000, loss_test:0.02038, lr:2.38e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.445, tt:5864.547\n",
      "Ep:145, loss:0.00000, loss_test:0.02041, lr:2.36e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.437, tt:5903.732\n",
      "Ep:146, loss:0.00000, loss_test:0.02043, lr:2.33e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.430, tt:5943.184\n",
      "Ep:147, loss:0.00000, loss_test:0.02046, lr:2.31e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.431, tt:5983.779\n",
      "Ep:148, loss:0.00000, loss_test:0.02048, lr:2.29e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.433, tt:6024.450\n",
      "Ep:149, loss:0.00000, loss_test:0.02049, lr:2.26e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.433, tt:6064.916\n",
      "Ep:150, loss:0.00000, loss_test:0.02052, lr:2.24e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.440, tt:6106.483\n",
      "Ep:151, loss:0.00000, loss_test:0.02055, lr:2.22e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.435, tt:6146.159\n",
      "Ep:152, loss:0.00000, loss_test:0.02058, lr:2.20e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.419, tt:6184.093\n",
      "Ep:153, loss:0.00000, loss_test:0.02060, lr:2.17e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.422, tt:6224.944\n",
      "Ep:154, loss:0.00000, loss_test:0.02061, lr:2.15e-02, fs:0.67816 (r=0.596,p=0.787),  time:40.408, tt:6263.248\n",
      "Ep:155, loss:0.00000, loss_test:0.02064, lr:2.13e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.410, tt:6303.982\n",
      "Ep:156, loss:0.00000, loss_test:0.02066, lr:2.11e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.400, tt:6342.723\n",
      "Ep:157, loss:0.00000, loss_test:0.02069, lr:2.09e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.404, tt:6383.758\n",
      "Ep:158, loss:0.00000, loss_test:0.02071, lr:2.07e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.412, tt:6425.431\n",
      "Ep:159, loss:0.00000, loss_test:0.02072, lr:2.05e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.417, tt:6466.730\n",
      "Ep:160, loss:0.00000, loss_test:0.02074, lr:2.03e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.425, tt:6508.381\n",
      "Ep:161, loss:0.00000, loss_test:0.02078, lr:2.01e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.422, tt:6548.379\n",
      "Ep:162, loss:0.00000, loss_test:0.02081, lr:1.99e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.438, tt:6591.324\n",
      "Ep:163, loss:0.00000, loss_test:0.02083, lr:1.97e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.444, tt:6632.822\n",
      "Ep:164, loss:0.00000, loss_test:0.02085, lr:1.95e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.439, tt:6672.361\n",
      "Ep:165, loss:0.00000, loss_test:0.02087, lr:1.93e-02, fs:0.67052 (r=0.586,p=0.784),  time:40.442, tt:6713.349\n",
      "Ep:166, loss:0.00000, loss_test:0.02089, lr:1.91e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.453, tt:6755.667\n",
      "Ep:167, loss:0.00000, loss_test:0.02093, lr:1.89e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.459, tt:6797.136\n",
      "Ep:168, loss:0.00000, loss_test:0.02096, lr:1.87e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.466, tt:6838.772\n",
      "Ep:169, loss:0.00000, loss_test:0.02098, lr:1.85e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.459, tt:6877.990\n",
      "Ep:170, loss:0.00000, loss_test:0.02101, lr:1.83e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.471, tt:6920.579\n",
      "Ep:171, loss:0.00000, loss_test:0.02103, lr:1.81e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.469, tt:6960.658\n",
      "Ep:172, loss:0.00000, loss_test:0.02103, lr:1.80e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.472, tt:7001.702\n",
      "Ep:173, loss:0.00000, loss_test:0.02105, lr:1.78e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.488, tt:7044.909\n",
      "Ep:174, loss:0.00000, loss_test:0.02108, lr:1.76e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.489, tt:7085.532\n",
      "Ep:175, loss:0.00000, loss_test:0.02110, lr:1.74e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.486, tt:7125.572\n",
      "Ep:176, loss:0.00000, loss_test:0.02112, lr:1.73e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.499, tt:7168.339\n",
      "Ep:177, loss:0.00000, loss_test:0.02114, lr:1.71e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.498, tt:7208.626\n",
      "Ep:178, loss:0.00000, loss_test:0.02118, lr:1.69e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.493, tt:7248.304\n",
      "Ep:179, loss:0.00000, loss_test:0.02121, lr:1.67e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.479, tt:7286.286\n",
      "Ep:180, loss:0.00000, loss_test:0.02122, lr:1.66e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.491, tt:7328.942\n",
      "Ep:181, loss:0.00000, loss_test:0.02123, lr:1.64e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.493, tt:7369.757\n",
      "Ep:182, loss:0.00000, loss_test:0.02124, lr:1.62e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.497, tt:7410.908\n",
      "Ep:183, loss:0.00000, loss_test:0.02125, lr:1.61e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.485, tt:7449.239\n",
      "Ep:184, loss:0.00000, loss_test:0.02127, lr:1.59e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.483, tt:7489.290\n",
      "Ep:185, loss:0.00000, loss_test:0.02130, lr:1.58e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.480, tt:7529.329\n",
      "Ep:186, loss:0.00000, loss_test:0.02133, lr:1.56e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.476, tt:7568.983\n",
      "Ep:187, loss:0.00000, loss_test:0.02136, lr:1.54e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.472, tt:7608.775\n",
      "Ep:188, loss:0.00000, loss_test:0.02137, lr:1.53e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.472, tt:7649.128\n",
      "Ep:189, loss:0.00000, loss_test:0.02139, lr:1.51e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.475, tt:7690.274\n",
      "Ep:190, loss:0.00000, loss_test:0.02140, lr:1.50e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.480, tt:7731.609\n",
      "Ep:191, loss:0.00000, loss_test:0.02142, lr:1.48e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.484, tt:7772.969\n",
      "Ep:192, loss:0.00000, loss_test:0.02142, lr:1.47e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.478, tt:7812.286\n",
      "Ep:193, loss:0.00000, loss_test:0.02143, lr:1.45e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.483, tt:7853.774\n",
      "Ep:194, loss:0.00000, loss_test:0.02146, lr:1.44e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.489, tt:7895.369\n",
      "Ep:195, loss:0.00000, loss_test:0.02148, lr:1.43e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.492, tt:7936.393\n",
      "Ep:196, loss:0.00000, loss_test:0.02149, lr:1.41e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.490, tt:7976.577\n",
      "Ep:197, loss:0.00000, loss_test:0.02151, lr:1.40e-02, fs:0.67442 (r=0.586,p=0.795),  time:40.512, tt:8021.339\n",
      "Ep:198, loss:0.00000, loss_test:0.02153, lr:1.38e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.507, tt:8060.978\n",
      "Ep:199, loss:0.00000, loss_test:0.02155, lr:1.37e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.499, tt:8099.840\n",
      "Ep:200, loss:0.00000, loss_test:0.02156, lr:1.36e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.469, tt:8134.323\n",
      "Ep:201, loss:0.00000, loss_test:0.02157, lr:1.34e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.430, tt:8166.857\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14208, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:39.683, tt:39.683\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14046, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:41.710, tt:83.420\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13743, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:41.206, tt:123.619\n",
      "Ep:3, loss:0.00026, loss_test:0.13455, lr:1.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:41.570, tt:166.279\n",
      "Ep:4, loss:0.00024, loss_test:0.13420, lr:1.00e-02, fs:0.63436 (r=0.727,p=0.562),  time:41.419, tt:207.097\n",
      "Ep:5, loss:0.00023, loss_test:0.13772, lr:1.00e-02, fs:0.57143 (r=0.545,p=0.600),  time:41.651, tt:249.907\n",
      "Ep:6, loss:0.00022, loss_test:0.13687, lr:1.00e-02, fs:0.57447 (r=0.545,p=0.607),  time:41.786, tt:292.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00021, loss_test:0.13225, lr:1.00e-02, fs:0.59512 (r=0.616,p=0.575),  time:41.937, tt:335.496\n",
      "Ep:8, loss:0.00021, loss_test:0.12965, lr:1.00e-02, fs:0.59512 (r=0.616,p=0.575),  time:41.868, tt:376.811\n",
      "Ep:9, loss:0.00020, loss_test:0.12979, lr:1.00e-02, fs:0.55249 (r=0.505,p=0.610),  time:41.810, tt:418.103\n",
      "Ep:10, loss:0.00019, loss_test:0.12874, lr:1.00e-02, fs:0.54651 (r=0.475,p=0.644),  time:41.904, tt:460.945\n",
      "Ep:11, loss:0.00018, loss_test:0.12452, lr:1.00e-02, fs:0.60000 (r=0.576,p=0.626),  time:41.885, tt:502.616\n",
      "Ep:12, loss:0.00017, loss_test:0.12227, lr:1.00e-02, fs:0.61458 (r=0.596,p=0.634),  time:41.895, tt:544.631\n",
      "Ep:13, loss:0.00017, loss_test:0.12173, lr:9.90e-03, fs:0.56497 (r=0.505,p=0.641),  time:42.014, tt:588.190\n",
      "Ep:14, loss:0.00016, loss_test:0.11940, lr:9.80e-03, fs:0.62366 (r=0.586,p=0.667),  time:42.046, tt:630.690\n",
      "Ep:15, loss:0.00015, loss_test:0.11670, lr:9.70e-03, fs:0.67337 (r=0.677,p=0.670),  time:42.252, tt:676.025\n",
      "Ep:16, loss:0.00015, loss_test:0.11451, lr:9.61e-03, fs:0.67368 (r=0.646,p=0.703),  time:42.246, tt:718.178\n",
      "Ep:17, loss:0.00014, loss_test:0.11238, lr:9.51e-03, fs:0.69792 (r=0.677,p=0.720),  time:42.228, tt:760.108\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.11058, lr:9.51e-03, fs:0.71642 (r=0.727,p=0.706),  time:42.194, tt:801.692\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.10882, lr:9.51e-03, fs:0.69841 (r=0.667,p=0.733),  time:42.215, tt:844.301\n",
      "Ep:20, loss:0.00012, loss_test:0.10690, lr:9.51e-03, fs:0.73529 (r=0.758,p=0.714),  time:42.125, tt:884.632\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.10522, lr:9.51e-03, fs:0.73000 (r=0.737,p=0.723),  time:42.055, tt:925.204\n",
      "Ep:22, loss:0.00011, loss_test:0.10445, lr:9.51e-03, fs:0.71875 (r=0.697,p=0.742),  time:41.992, tt:965.812\n",
      "Ep:23, loss:0.00011, loss_test:0.10259, lr:9.51e-03, fs:0.73892 (r=0.758,p=0.721),  time:42.041, tt:1008.972\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.10123, lr:9.51e-03, fs:0.73196 (r=0.717,p=0.747),  time:41.967, tt:1049.180\n",
      "Ep:25, loss:0.00010, loss_test:0.10029, lr:9.51e-03, fs:0.73958 (r=0.717,p=0.763),  time:41.895, tt:1089.272\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.10011, lr:9.51e-03, fs:0.72000 (r=0.727,p=0.713),  time:41.848, tt:1129.901\n",
      "Ep:27, loss:0.00009, loss_test:0.09810, lr:9.51e-03, fs:0.74737 (r=0.717,p=0.780),  time:41.862, tt:1172.147\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.09755, lr:9.51e-03, fs:0.75648 (r=0.737,p=0.777),  time:41.888, tt:1214.754\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.09703, lr:9.51e-03, fs:0.75132 (r=0.717,p=0.789),  time:41.922, tt:1257.662\n",
      "Ep:30, loss:0.00008, loss_test:0.09619, lr:9.51e-03, fs:0.75132 (r=0.717,p=0.789),  time:41.915, tt:1299.376\n",
      "Ep:31, loss:0.00008, loss_test:0.09547, lr:9.51e-03, fs:0.77083 (r=0.747,p=0.796),  time:41.973, tt:1343.141\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.09562, lr:9.51e-03, fs:0.74866 (r=0.707,p=0.795),  time:41.938, tt:1383.958\n",
      "Ep:33, loss:0.00007, loss_test:0.09527, lr:9.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:41.933, tt:1425.713\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.09454, lr:9.51e-03, fs:0.76344 (r=0.717,p=0.816),  time:41.907, tt:1466.744\n",
      "Ep:35, loss:0.00006, loss_test:0.09326, lr:9.51e-03, fs:0.78125 (r=0.758,p=0.806),  time:41.940, tt:1509.855\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.09426, lr:9.51e-03, fs:0.74595 (r=0.697,p=0.802),  time:41.892, tt:1549.992\n",
      "Ep:37, loss:0.00006, loss_test:0.09351, lr:9.51e-03, fs:0.75936 (r=0.717,p=0.807),  time:41.860, tt:1590.691\n",
      "Ep:38, loss:0.00006, loss_test:0.09369, lr:9.51e-03, fs:0.73333 (r=0.667,p=0.815),  time:41.836, tt:1631.611\n",
      "Ep:39, loss:0.00005, loss_test:0.09329, lr:9.51e-03, fs:0.74866 (r=0.707,p=0.795),  time:41.878, tt:1675.130\n",
      "Ep:40, loss:0.00005, loss_test:0.09368, lr:9.51e-03, fs:0.71264 (r=0.626,p=0.827),  time:41.841, tt:1715.497\n",
      "Ep:41, loss:0.00005, loss_test:0.09245, lr:9.51e-03, fs:0.74595 (r=0.697,p=0.802),  time:41.852, tt:1757.769\n",
      "Ep:42, loss:0.00005, loss_test:0.09399, lr:9.51e-03, fs:0.70857 (r=0.626,p=0.816),  time:41.853, tt:1799.700\n",
      "Ep:43, loss:0.00005, loss_test:0.09351, lr:9.51e-03, fs:0.72626 (r=0.657,p=0.812),  time:41.872, tt:1842.382\n",
      "Ep:44, loss:0.00005, loss_test:0.09188, lr:9.51e-03, fs:0.74444 (r=0.677,p=0.827),  time:41.819, tt:1881.841\n",
      "Ep:45, loss:0.00004, loss_test:0.09421, lr:9.51e-03, fs:0.71591 (r=0.636,p=0.818),  time:41.810, tt:1923.244\n",
      "Ep:46, loss:0.00004, loss_test:0.09280, lr:9.51e-03, fs:0.73034 (r=0.657,p=0.823),  time:41.810, tt:1965.060\n",
      "Ep:47, loss:0.00004, loss_test:0.09274, lr:9.41e-03, fs:0.72414 (r=0.636,p=0.840),  time:41.875, tt:2010.007\n",
      "Ep:48, loss:0.00004, loss_test:0.09341, lr:9.32e-03, fs:0.71910 (r=0.646,p=0.810),  time:41.890, tt:2052.633\n",
      "Ep:49, loss:0.00004, loss_test:0.09293, lr:9.23e-03, fs:0.72414 (r=0.636,p=0.840),  time:41.895, tt:2094.764\n",
      "Ep:50, loss:0.00004, loss_test:0.09371, lr:9.14e-03, fs:0.72727 (r=0.646,p=0.831),  time:41.907, tt:2137.282\n",
      "Ep:51, loss:0.00004, loss_test:0.09342, lr:9.04e-03, fs:0.72000 (r=0.636,p=0.829),  time:41.887, tt:2178.144\n",
      "Ep:52, loss:0.00003, loss_test:0.09301, lr:8.95e-03, fs:0.71264 (r=0.626,p=0.827),  time:41.873, tt:2219.250\n",
      "Ep:53, loss:0.00003, loss_test:0.09330, lr:8.86e-03, fs:0.71591 (r=0.636,p=0.818),  time:41.878, tt:2261.390\n",
      "Ep:54, loss:0.00003, loss_test:0.09478, lr:8.78e-03, fs:0.71345 (r=0.616,p=0.847),  time:41.877, tt:2303.248\n",
      "Ep:55, loss:0.00003, loss_test:0.09274, lr:8.69e-03, fs:0.73446 (r=0.657,p=0.833),  time:41.906, tt:2346.748\n",
      "Ep:56, loss:0.00003, loss_test:0.09623, lr:8.60e-03, fs:0.71765 (r=0.616,p=0.859),  time:41.908, tt:2388.747\n",
      "Ep:57, loss:0.00003, loss_test:0.09622, lr:8.51e-03, fs:0.71006 (r=0.606,p=0.857),  time:41.930, tt:2431.961\n",
      "Ep:58, loss:0.00003, loss_test:0.09214, lr:8.43e-03, fs:0.76344 (r=0.717,p=0.816),  time:41.976, tt:2476.588\n",
      "Ep:59, loss:0.00003, loss_test:0.09615, lr:8.35e-03, fs:0.71345 (r=0.616,p=0.847),  time:41.933, tt:2516.003\n",
      "Ep:60, loss:0.00003, loss_test:0.09472, lr:8.26e-03, fs:0.71345 (r=0.616,p=0.847),  time:41.930, tt:2557.733\n",
      "Ep:61, loss:0.00003, loss_test:0.09234, lr:8.18e-03, fs:0.75556 (r=0.687,p=0.840),  time:41.927, tt:2599.489\n",
      "Ep:62, loss:0.00003, loss_test:0.09524, lr:8.10e-03, fs:0.70588 (r=0.606,p=0.845),  time:41.902, tt:2639.822\n",
      "Ep:63, loss:0.00002, loss_test:0.09367, lr:8.02e-03, fs:0.70930 (r=0.616,p=0.836),  time:42.004, tt:2688.258\n",
      "Ep:64, loss:0.00002, loss_test:0.09313, lr:7.94e-03, fs:0.71676 (r=0.626,p=0.838),  time:42.016, tt:2731.023\n",
      "Ep:65, loss:0.00002, loss_test:0.09465, lr:7.86e-03, fs:0.70175 (r=0.606,p=0.833),  time:42.037, tt:2774.473\n",
      "Ep:66, loss:0.00002, loss_test:0.09354, lr:7.78e-03, fs:0.70930 (r=0.616,p=0.836),  time:42.004, tt:2814.260\n",
      "Ep:67, loss:0.00002, loss_test:0.09411, lr:7.70e-03, fs:0.70175 (r=0.606,p=0.833),  time:41.999, tt:2855.903\n",
      "Ep:68, loss:0.00002, loss_test:0.09565, lr:7.62e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.011, tt:2898.734\n",
      "Ep:69, loss:0.00002, loss_test:0.09357, lr:7.55e-03, fs:0.72000 (r=0.636,p=0.829),  time:42.019, tt:2941.362\n",
      "Ep:70, loss:0.00002, loss_test:0.09506, lr:7.47e-03, fs:0.68639 (r=0.586,p=0.829),  time:42.040, tt:2984.827\n",
      "Ep:71, loss:0.00002, loss_test:0.09492, lr:7.40e-03, fs:0.69006 (r=0.596,p=0.819),  time:42.044, tt:3027.198\n",
      "Ep:72, loss:0.00002, loss_test:0.09478, lr:7.32e-03, fs:0.69767 (r=0.606,p=0.822),  time:42.039, tt:3068.813\n",
      "Ep:73, loss:0.00002, loss_test:0.09484, lr:7.25e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.063, tt:3112.661\n",
      "Ep:74, loss:0.00002, loss_test:0.09477, lr:7.18e-03, fs:0.69006 (r=0.596,p=0.819),  time:42.058, tt:3154.352\n",
      "Ep:75, loss:0.00002, loss_test:0.09427, lr:7.11e-03, fs:0.69006 (r=0.596,p=0.819),  time:42.067, tt:3197.083\n",
      "Ep:76, loss:0.00002, loss_test:0.09542, lr:7.03e-03, fs:0.67456 (r=0.576,p=0.814),  time:42.058, tt:3238.478\n",
      "Ep:77, loss:0.00002, loss_test:0.09537, lr:6.96e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.039, tt:3279.081\n",
      "Ep:78, loss:0.00002, loss_test:0.09482, lr:6.89e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.032, tt:3320.541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00002, loss_test:0.09502, lr:6.83e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.013, tt:3361.001\n",
      "Ep:80, loss:0.00002, loss_test:0.09559, lr:6.76e-03, fs:0.68235 (r=0.586,p=0.817),  time:41.981, tt:3400.452\n",
      "Ep:81, loss:0.00002, loss_test:0.09501, lr:6.69e-03, fs:0.68235 (r=0.586,p=0.817),  time:41.963, tt:3440.939\n",
      "Ep:82, loss:0.00002, loss_test:0.09530, lr:6.62e-03, fs:0.67456 (r=0.576,p=0.814),  time:41.981, tt:3484.386\n",
      "Ep:83, loss:0.00002, loss_test:0.09551, lr:6.56e-03, fs:0.67456 (r=0.576,p=0.814),  time:42.033, tt:3530.806\n",
      "Ep:84, loss:0.00001, loss_test:0.09531, lr:6.49e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.046, tt:3573.869\n",
      "Ep:85, loss:0.00001, loss_test:0.09542, lr:6.43e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.059, tt:3617.047\n",
      "Ep:86, loss:0.00001, loss_test:0.09578, lr:6.36e-03, fs:0.67456 (r=0.576,p=0.814),  time:42.075, tt:3660.483\n",
      "Ep:87, loss:0.00001, loss_test:0.09518, lr:6.30e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.095, tt:3704.373\n",
      "Ep:88, loss:0.00001, loss_test:0.09603, lr:6.24e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.107, tt:3747.525\n",
      "Ep:89, loss:0.00001, loss_test:0.09531, lr:6.17e-03, fs:0.68235 (r=0.586,p=0.817),  time:42.076, tt:3786.805\n",
      "Ep:90, loss:0.00001, loss_test:0.09586, lr:6.11e-03, fs:0.67456 (r=0.576,p=0.814),  time:42.095, tt:3830.621\n",
      "Ep:91, loss:0.00001, loss_test:0.09657, lr:6.05e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.096, tt:3872.815\n",
      "Ep:92, loss:0.00001, loss_test:0.09518, lr:5.99e-03, fs:0.69767 (r=0.606,p=0.822),  time:42.126, tt:3917.726\n",
      "Ep:93, loss:0.00001, loss_test:0.09633, lr:5.93e-03, fs:0.67456 (r=0.576,p=0.814),  time:42.159, tt:3962.990\n",
      "Ep:94, loss:0.00001, loss_test:0.09692, lr:5.87e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.177, tt:4006.828\n",
      "Ep:95, loss:0.00001, loss_test:0.09582, lr:5.81e-03, fs:0.67456 (r=0.576,p=0.814),  time:42.180, tt:4049.273\n",
      "Ep:96, loss:0.00001, loss_test:0.09638, lr:5.75e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.183, tt:4091.718\n",
      "Ep:97, loss:0.00001, loss_test:0.09650, lr:5.70e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.164, tt:4132.050\n",
      "Ep:98, loss:0.00001, loss_test:0.09591, lr:5.64e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.166, tt:4174.391\n",
      "Ep:99, loss:0.00001, loss_test:0.09605, lr:5.58e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.168, tt:4216.838\n",
      "Ep:100, loss:0.00001, loss_test:0.09585, lr:5.53e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.184, tt:4260.608\n",
      "Ep:101, loss:0.00001, loss_test:0.09581, lr:5.47e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.187, tt:4303.089\n",
      "Ep:102, loss:0.00001, loss_test:0.09564, lr:5.42e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.187, tt:4345.288\n",
      "Ep:103, loss:0.00001, loss_test:0.09619, lr:5.36e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.204, tt:4389.178\n",
      "Ep:104, loss:0.00001, loss_test:0.09640, lr:5.31e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.217, tt:4432.780\n",
      "Ep:105, loss:0.00001, loss_test:0.09564, lr:5.26e-03, fs:0.68639 (r=0.586,p=0.829),  time:42.225, tt:4475.890\n",
      "Ep:106, loss:0.00001, loss_test:0.09631, lr:5.20e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.236, tt:4519.256\n",
      "Ep:107, loss:0.00001, loss_test:0.09631, lr:5.15e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.219, tt:4559.619\n",
      "Ep:108, loss:0.00001, loss_test:0.09553, lr:5.10e-03, fs:0.68639 (r=0.586,p=0.829),  time:42.222, tt:4602.198\n",
      "Ep:109, loss:0.00001, loss_test:0.09620, lr:5.05e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.230, tt:4645.323\n",
      "Ep:110, loss:0.00001, loss_test:0.09624, lr:5.00e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.227, tt:4687.232\n",
      "Ep:111, loss:0.00001, loss_test:0.09587, lr:4.95e-03, fs:0.68639 (r=0.586,p=0.829),  time:42.215, tt:4728.105\n",
      "Ep:112, loss:0.00001, loss_test:0.09657, lr:4.90e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.214, tt:4770.152\n",
      "Ep:113, loss:0.00001, loss_test:0.09620, lr:4.85e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.219, tt:4813.020\n",
      "Ep:114, loss:0.00001, loss_test:0.09598, lr:4.80e-03, fs:0.73143 (r=0.646,p=0.842),  time:42.238, tt:4857.403\n",
      "Ep:115, loss:0.00001, loss_test:0.09615, lr:4.75e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.250, tt:4901.003\n",
      "Ep:116, loss:0.00001, loss_test:0.09624, lr:4.71e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.262, tt:4944.606\n",
      "Ep:117, loss:0.00001, loss_test:0.09647, lr:4.66e-03, fs:0.68639 (r=0.586,p=0.829),  time:42.272, tt:4988.147\n",
      "Ep:118, loss:0.00001, loss_test:0.09611, lr:4.61e-03, fs:0.72093 (r=0.626,p=0.849),  time:42.289, tt:5032.394\n",
      "Ep:119, loss:0.00001, loss_test:0.09594, lr:4.57e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.291, tt:5074.910\n",
      "Ep:120, loss:0.00001, loss_test:0.09604, lr:4.52e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.283, tt:5116.299\n",
      "Ep:121, loss:0.00001, loss_test:0.09605, lr:4.48e-03, fs:0.73563 (r=0.646,p=0.853),  time:42.299, tt:5160.450\n",
      "Ep:122, loss:0.00001, loss_test:0.09625, lr:4.43e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.329, tt:5206.512\n",
      "Ep:123, loss:0.00001, loss_test:0.09632, lr:4.39e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.337, tt:5249.760\n",
      "Ep:124, loss:0.00001, loss_test:0.09602, lr:4.34e-03, fs:0.68639 (r=0.586,p=0.829),  time:42.345, tt:5293.147\n",
      "Ep:125, loss:0.00001, loss_test:0.09616, lr:4.30e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.344, tt:5335.354\n",
      "Ep:126, loss:0.00001, loss_test:0.09583, lr:4.26e-03, fs:0.69822 (r=0.596,p=0.843),  time:42.347, tt:5378.061\n",
      "Ep:127, loss:0.00001, loss_test:0.09617, lr:4.21e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.330, tt:5418.287\n",
      "Ep:128, loss:0.00001, loss_test:0.09617, lr:4.17e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.296, tt:5456.167\n",
      "Ep:129, loss:0.00001, loss_test:0.09618, lr:4.13e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.272, tt:5495.412\n",
      "Ep:130, loss:0.00001, loss_test:0.09602, lr:4.09e-03, fs:0.70588 (r=0.606,p=0.845),  time:42.278, tt:5538.432\n",
      "Ep:131, loss:0.00001, loss_test:0.09622, lr:4.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.301, tt:5583.790\n",
      "Ep:132, loss:0.00001, loss_test:0.09584, lr:4.01e-03, fs:0.70588 (r=0.606,p=0.845),  time:42.311, tt:5627.373\n",
      "Ep:133, loss:0.00001, loss_test:0.09671, lr:3.97e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.311, tt:5669.665\n",
      "Ep:134, loss:0.00001, loss_test:0.09695, lr:3.93e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.292, tt:5709.435\n",
      "Ep:135, loss:0.00001, loss_test:0.09634, lr:3.89e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.282, tt:5750.346\n",
      "Ep:136, loss:0.00001, loss_test:0.09601, lr:3.85e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.268, tt:5790.765\n",
      "Ep:137, loss:0.00001, loss_test:0.09642, lr:3.81e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.258, tt:5831.608\n",
      "Ep:138, loss:0.00001, loss_test:0.09667, lr:3.77e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.286, tt:5877.816\n",
      "Ep:139, loss:0.00001, loss_test:0.09662, lr:3.73e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.294, tt:5921.174\n",
      "Ep:140, loss:0.00001, loss_test:0.09610, lr:3.70e-03, fs:0.72093 (r=0.626,p=0.849),  time:42.280, tt:5961.494\n",
      "Ep:141, loss:0.00001, loss_test:0.09637, lr:3.66e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.280, tt:6003.728\n",
      "Ep:142, loss:0.00001, loss_test:0.09645, lr:3.62e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.271, tt:6044.815\n",
      "Ep:143, loss:0.00001, loss_test:0.09599, lr:3.59e-03, fs:0.71345 (r=0.616,p=0.847),  time:42.277, tt:6087.917\n",
      "Ep:144, loss:0.00001, loss_test:0.09597, lr:3.55e-03, fs:0.72093 (r=0.626,p=0.849),  time:42.296, tt:6132.876\n",
      "Ep:145, loss:0.00001, loss_test:0.09650, lr:3.52e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.297, tt:6175.405\n",
      "Ep:146, loss:0.00001, loss_test:0.09655, lr:3.48e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.310, tt:6219.634\n",
      "Ep:147, loss:0.00001, loss_test:0.09669, lr:3.45e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.309, tt:6261.801\n",
      "Ep:148, loss:0.00001, loss_test:0.09638, lr:3.41e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.308, tt:6303.904\n",
      "Ep:149, loss:0.00001, loss_test:0.09625, lr:3.38e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.309, tt:6346.421\n",
      "Ep:150, loss:0.00001, loss_test:0.09638, lr:3.34e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.308, tt:6388.487\n",
      "Ep:151, loss:0.00001, loss_test:0.09600, lr:3.31e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.305, tt:6430.382\n",
      "Ep:152, loss:0.00001, loss_test:0.09623, lr:3.28e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.312, tt:6473.773\n",
      "Ep:153, loss:0.00001, loss_test:0.09647, lr:3.24e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.300, tt:6514.176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00001, loss_test:0.09624, lr:3.21e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.296, tt:6555.807\n",
      "Ep:155, loss:0.00001, loss_test:0.09655, lr:3.18e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.289, tt:6597.051\n",
      "Ep:156, loss:0.00001, loss_test:0.09649, lr:3.15e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.292, tt:6639.788\n",
      "Ep:157, loss:0.00001, loss_test:0.09633, lr:3.12e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.311, tt:6685.166\n",
      "Ep:158, loss:0.00001, loss_test:0.09620, lr:3.09e-03, fs:0.69048 (r=0.586,p=0.841),  time:42.322, tt:6729.231\n",
      "Ep:159, loss:0.00001, loss_test:0.09649, lr:3.05e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.325, tt:6772.007\n",
      "Ep:160, loss:0.00001, loss_test:0.09677, lr:3.02e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.317, tt:6812.999\n",
      "Ep:161, loss:0.00001, loss_test:0.09657, lr:2.99e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.322, tt:6856.162\n",
      "Ep:162, loss:0.00001, loss_test:0.09611, lr:2.96e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.325, tt:6898.961\n",
      "Ep:163, loss:0.00001, loss_test:0.09653, lr:2.93e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.318, tt:6940.199\n",
      "Ep:164, loss:0.00001, loss_test:0.09667, lr:2.90e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.323, tt:6983.223\n",
      "Ep:165, loss:0.00001, loss_test:0.09642, lr:2.88e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.322, tt:7025.441\n",
      "Ep:166, loss:0.00001, loss_test:0.09629, lr:2.85e-03, fs:0.69461 (r=0.586,p=0.853),  time:42.326, tt:7068.436\n",
      "Ep:167, loss:0.00001, loss_test:0.09650, lr:2.82e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.325, tt:7110.611\n",
      "Ep:168, loss:0.00001, loss_test:0.09648, lr:2.79e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.316, tt:7151.379\n",
      "Ep:169, loss:0.00001, loss_test:0.09636, lr:2.76e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.301, tt:7191.186\n",
      "Ep:170, loss:0.00001, loss_test:0.09624, lr:2.73e-03, fs:0.72515 (r=0.626,p=0.861),  time:42.288, tt:7231.281\n",
      "Ep:171, loss:0.00001, loss_test:0.09652, lr:2.71e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.293, tt:7274.367\n",
      "Ep:172, loss:0.00001, loss_test:0.09656, lr:2.68e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.289, tt:7315.958\n",
      "Ep:173, loss:0.00001, loss_test:0.09676, lr:2.65e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.293, tt:7359.040\n",
      "Ep:174, loss:0.00001, loss_test:0.09670, lr:2.63e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.293, tt:7401.271\n",
      "Ep:175, loss:0.00001, loss_test:0.09654, lr:2.60e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.289, tt:7442.805\n",
      "Ep:176, loss:0.00000, loss_test:0.09647, lr:2.57e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.290, tt:7485.374\n",
      "Ep:177, loss:0.00000, loss_test:0.09628, lr:2.55e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.283, tt:7526.396\n",
      "Ep:178, loss:0.00000, loss_test:0.09633, lr:2.52e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.315, tt:7574.423\n",
      "Ep:179, loss:0.00000, loss_test:0.09644, lr:2.50e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.323, tt:7618.073\n",
      "Ep:180, loss:0.00000, loss_test:0.09668, lr:2.47e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.312, tt:7658.393\n",
      "Ep:181, loss:0.00000, loss_test:0.09683, lr:2.45e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.325, tt:7703.220\n",
      "Ep:182, loss:0.00000, loss_test:0.09674, lr:2.42e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.334, tt:7747.154\n",
      "Ep:183, loss:0.00000, loss_test:0.09632, lr:2.40e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.342, tt:7790.980\n",
      "Ep:184, loss:0.00000, loss_test:0.09678, lr:2.38e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.348, tt:7834.439\n",
      "Ep:185, loss:0.00000, loss_test:0.09724, lr:2.35e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.346, tt:7876.438\n",
      "Ep:186, loss:0.00000, loss_test:0.09717, lr:2.33e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.365, tt:7922.346\n",
      "Ep:187, loss:0.00000, loss_test:0.09698, lr:2.31e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.375, tt:7966.424\n",
      "Ep:188, loss:0.00000, loss_test:0.09675, lr:2.28e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.383, tt:8010.372\n",
      "Ep:189, loss:0.00000, loss_test:0.09684, lr:2.26e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.382, tt:8052.568\n",
      "Ep:190, loss:0.00000, loss_test:0.09678, lr:2.24e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.397, tt:8097.778\n",
      "Ep:191, loss:0.00000, loss_test:0.09654, lr:2.21e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.397, tt:8140.268\n",
      "Ep:192, loss:0.00000, loss_test:0.09666, lr:2.19e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.402, tt:8183.623\n",
      "Ep:193, loss:0.00000, loss_test:0.09671, lr:2.17e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.411, tt:8227.711\n",
      "Ep:194, loss:0.00000, loss_test:0.09673, lr:2.15e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.412, tt:8270.423\n",
      "Ep:195, loss:0.00000, loss_test:0.09656, lr:2.13e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.411, tt:8312.466\n",
      "Ep:196, loss:0.00000, loss_test:0.09662, lr:2.11e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.408, tt:8354.318\n",
      "Ep:197, loss:0.00000, loss_test:0.09663, lr:2.08e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.406, tt:8396.412\n",
      "Ep:198, loss:0.00000, loss_test:0.09665, lr:2.06e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.379, tt:8433.489\n",
      "Ep:199, loss:0.00000, loss_test:0.09653, lr:2.04e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.348, tt:8469.615\n",
      "Ep:200, loss:0.00000, loss_test:0.09670, lr:2.02e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.285, tt:8499.236\n",
      "Ep:201, loss:0.00000, loss_test:0.09664, lr:2.00e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.205, tt:8525.385\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02289, lr:6.00e-02, fs:0.62121 (r=0.828,p=0.497),  time:33.878, tt:33.878\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02410, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.263, tt:68.527\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.824, tt:104.473\n",
      "Ep:3, loss:0.00005, loss_test:0.02462, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.694, tt:138.776\n",
      "Ep:4, loss:0.00005, loss_test:0.02345, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.584, tt:172.918\n",
      "Ep:5, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:34.511, tt:207.068\n",
      "Ep:6, loss:0.00004, loss_test:0.02246, lr:6.00e-02, fs:0.62762 (r=0.758,p=0.536),  time:34.576, tt:242.032\n",
      "Ep:7, loss:0.00004, loss_test:0.02408, lr:6.00e-02, fs:0.61682 (r=0.667,p=0.574),  time:34.380, tt:275.039\n",
      "Ep:8, loss:0.00004, loss_test:0.02559, lr:6.00e-02, fs:0.61836 (r=0.646,p=0.593),  time:34.295, tt:308.658\n",
      "Ep:9, loss:0.00004, loss_test:0.02469, lr:6.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:34.250, tt:342.497\n",
      "Ep:10, loss:0.00003, loss_test:0.02287, lr:6.00e-02, fs:0.61261 (r=0.687,p=0.553),  time:34.281, tt:377.092\n",
      "Ep:11, loss:0.00003, loss_test:0.02188, lr:6.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:34.330, tt:411.958\n",
      "Ep:12, loss:0.00003, loss_test:0.02156, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:34.422, tt:447.486\n",
      "Ep:13, loss:0.00003, loss_test:0.02158, lr:5.94e-02, fs:0.65833 (r=0.798,p=0.560),  time:34.522, tt:483.302\n",
      "Ep:14, loss:0.00003, loss_test:0.02185, lr:5.88e-02, fs:0.66667 (r=0.768,p=0.589),  time:34.385, tt:515.777\n",
      "Ep:15, loss:0.00003, loss_test:0.02208, lr:5.82e-02, fs:0.65471 (r=0.737,p=0.589),  time:34.441, tt:551.059\n",
      "Ep:16, loss:0.00003, loss_test:0.02184, lr:5.76e-02, fs:0.64865 (r=0.727,p=0.585),  time:34.352, tt:583.980\n",
      "Ep:17, loss:0.00003, loss_test:0.02118, lr:5.71e-02, fs:0.63348 (r=0.707,p=0.574),  time:34.400, tt:619.202\n",
      "Ep:18, loss:0.00003, loss_test:0.02069, lr:5.65e-02, fs:0.61333 (r=0.697,p=0.548),  time:34.619, tt:657.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00003, loss_test:0.02047, lr:5.59e-02, fs:0.63478 (r=0.737,p=0.557),  time:34.645, tt:692.901\n",
      "Ep:20, loss:0.00003, loss_test:0.02046, lr:5.54e-02, fs:0.64000 (r=0.727,p=0.571),  time:34.635, tt:727.343\n",
      "Ep:21, loss:0.00003, loss_test:0.02056, lr:5.48e-02, fs:0.66667 (r=0.747,p=0.602),  time:34.588, tt:760.942\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.02058, lr:5.48e-02, fs:0.67873 (r=0.758,p=0.615),  time:34.608, tt:795.983\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.02036, lr:5.48e-02, fs:0.68468 (r=0.768,p=0.618),  time:34.574, tt:829.773\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.02008, lr:5.48e-02, fs:0.71053 (r=0.818,p=0.628),  time:34.619, tt:865.481\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01990, lr:5.48e-02, fs:0.72489 (r=0.838,p=0.638),  time:34.642, tt:900.692\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01978, lr:5.48e-02, fs:0.73913 (r=0.859,p=0.649),  time:34.580, tt:933.663\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01975, lr:5.48e-02, fs:0.73913 (r=0.859,p=0.649),  time:34.543, tt:967.207\n",
      "Ep:28, loss:0.00002, loss_test:0.01973, lr:5.48e-02, fs:0.73451 (r=0.838,p=0.654),  time:34.539, tt:1001.623\n",
      "Ep:29, loss:0.00002, loss_test:0.01964, lr:5.48e-02, fs:0.74890 (r=0.859,p=0.664),  time:34.563, tt:1036.884\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01951, lr:5.48e-02, fs:0.75439 (r=0.869,p=0.667),  time:34.600, tt:1072.594\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01945, lr:5.48e-02, fs:0.75556 (r=0.859,p=0.675),  time:34.580, tt:1106.563\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01940, lr:5.48e-02, fs:0.75336 (r=0.848,p=0.677),  time:34.599, tt:1141.779\n",
      "Ep:33, loss:0.00002, loss_test:0.01928, lr:5.48e-02, fs:0.75336 (r=0.848,p=0.677),  time:34.601, tt:1176.422\n",
      "Ep:34, loss:0.00002, loss_test:0.01918, lr:5.48e-02, fs:0.75336 (r=0.848,p=0.677),  time:34.644, tt:1212.532\n",
      "Ep:35, loss:0.00002, loss_test:0.01908, lr:5.48e-02, fs:0.75676 (r=0.848,p=0.683),  time:34.642, tt:1247.106\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01894, lr:5.48e-02, fs:0.76577 (r=0.859,p=0.691),  time:34.618, tt:1280.862\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01887, lr:5.48e-02, fs:0.77273 (r=0.859,p=0.702),  time:34.653, tt:1316.817\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01877, lr:5.48e-02, fs:0.77273 (r=0.859,p=0.702),  time:34.646, tt:1351.180\n",
      "Ep:39, loss:0.00002, loss_test:0.01868, lr:5.48e-02, fs:0.76712 (r=0.848,p=0.700),  time:34.639, tt:1385.560\n",
      "Ep:40, loss:0.00002, loss_test:0.01860, lr:5.48e-02, fs:0.77064 (r=0.848,p=0.706),  time:34.610, tt:1419.024\n",
      "Ep:41, loss:0.00002, loss_test:0.01851, lr:5.48e-02, fs:0.77064 (r=0.848,p=0.706),  time:34.566, tt:1451.781\n",
      "Ep:42, loss:0.00001, loss_test:0.01851, lr:5.48e-02, fs:0.76852 (r=0.838,p=0.709),  time:34.533, tt:1484.900\n",
      "Ep:43, loss:0.00001, loss_test:0.01847, lr:5.48e-02, fs:0.76852 (r=0.838,p=0.709),  time:34.495, tt:1517.773\n",
      "Ep:44, loss:0.00001, loss_test:0.01848, lr:5.48e-02, fs:0.77209 (r=0.838,p=0.716),  time:34.491, tt:1552.108\n",
      "Ep:45, loss:0.00001, loss_test:0.01847, lr:5.48e-02, fs:0.76636 (r=0.828,p=0.713),  time:34.495, tt:1586.759\n",
      "Ep:46, loss:0.00001, loss_test:0.01852, lr:5.48e-02, fs:0.76636 (r=0.828,p=0.713),  time:34.468, tt:1619.978\n",
      "Ep:47, loss:0.00001, loss_test:0.01861, lr:5.48e-02, fs:0.76636 (r=0.828,p=0.713),  time:34.463, tt:1654.225\n",
      "Ep:48, loss:0.00001, loss_test:0.01861, lr:5.48e-02, fs:0.77358 (r=0.828,p=0.726),  time:34.448, tt:1687.932\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01869, lr:5.48e-02, fs:0.76923 (r=0.808,p=0.734),  time:34.428, tt:1721.405\n",
      "Ep:50, loss:0.00001, loss_test:0.01870, lr:5.48e-02, fs:0.77512 (r=0.818,p=0.736),  time:34.426, tt:1755.734\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01869, lr:5.48e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.394, tt:1788.464\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01868, lr:5.48e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.387, tt:1822.504\n",
      "Ep:53, loss:0.00001, loss_test:0.01872, lr:5.48e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.383, tt:1856.668\n",
      "Ep:54, loss:0.00001, loss_test:0.01870, lr:5.48e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.355, tt:1889.506\n",
      "Ep:55, loss:0.00001, loss_test:0.01878, lr:5.48e-02, fs:0.77295 (r=0.808,p=0.741),  time:34.335, tt:1922.733\n",
      "Ep:56, loss:0.00001, loss_test:0.01884, lr:5.48e-02, fs:0.77073 (r=0.798,p=0.745),  time:34.314, tt:1955.919\n",
      "Ep:57, loss:0.00001, loss_test:0.01890, lr:5.48e-02, fs:0.75862 (r=0.778,p=0.740),  time:34.318, tt:1990.467\n",
      "Ep:58, loss:0.00001, loss_test:0.01900, lr:5.48e-02, fs:0.76238 (r=0.778,p=0.748),  time:34.322, tt:2024.997\n",
      "Ep:59, loss:0.00001, loss_test:0.01898, lr:5.48e-02, fs:0.76617 (r=0.778,p=0.755),  time:34.312, tt:2058.725\n",
      "Ep:60, loss:0.00001, loss_test:0.01899, lr:5.48e-02, fs:0.75377 (r=0.758,p=0.750),  time:34.300, tt:2092.288\n",
      "Ep:61, loss:0.00001, loss_test:0.01905, lr:5.48e-02, fs:0.74747 (r=0.747,p=0.747),  time:34.285, tt:2125.666\n",
      "Ep:62, loss:0.00001, loss_test:0.01911, lr:5.48e-02, fs:0.74747 (r=0.747,p=0.747),  time:34.298, tt:2160.758\n",
      "Ep:63, loss:0.00001, loss_test:0.01914, lr:5.43e-02, fs:0.74872 (r=0.737,p=0.760),  time:34.273, tt:2193.499\n",
      "Ep:64, loss:0.00001, loss_test:0.01931, lr:5.37e-02, fs:0.75648 (r=0.737,p=0.777),  time:34.258, tt:2226.788\n",
      "Ep:65, loss:0.00001, loss_test:0.01932, lr:5.32e-02, fs:0.74346 (r=0.717,p=0.772),  time:34.239, tt:2259.742\n",
      "Ep:66, loss:0.00001, loss_test:0.01931, lr:5.27e-02, fs:0.74346 (r=0.717,p=0.772),  time:34.222, tt:2292.869\n",
      "Ep:67, loss:0.00001, loss_test:0.01943, lr:5.21e-02, fs:0.74074 (r=0.707,p=0.778),  time:34.195, tt:2325.283\n",
      "Ep:68, loss:0.00001, loss_test:0.01949, lr:5.16e-02, fs:0.74468 (r=0.707,p=0.787),  time:34.183, tt:2358.646\n",
      "Ep:69, loss:0.00001, loss_test:0.01955, lr:5.11e-02, fs:0.74468 (r=0.707,p=0.787),  time:34.174, tt:2392.177\n",
      "Ep:70, loss:0.00001, loss_test:0.01959, lr:5.06e-02, fs:0.73797 (r=0.697,p=0.784),  time:34.171, tt:2426.165\n",
      "Ep:71, loss:0.00001, loss_test:0.01974, lr:5.01e-02, fs:0.74194 (r=0.697,p=0.793),  time:34.145, tt:2458.406\n",
      "Ep:72, loss:0.00001, loss_test:0.01973, lr:4.96e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.148, tt:2492.797\n",
      "Ep:73, loss:0.00001, loss_test:0.01973, lr:4.91e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.168, tt:2528.408\n",
      "Ep:74, loss:0.00001, loss_test:0.01986, lr:4.86e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.169, tt:2562.707\n",
      "Ep:75, loss:0.00001, loss_test:0.01997, lr:4.81e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.179, tt:2597.614\n",
      "Ep:76, loss:0.00001, loss_test:0.02006, lr:4.76e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.187, tt:2632.374\n",
      "Ep:77, loss:0.00001, loss_test:0.02013, lr:4.71e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.165, tt:2664.861\n",
      "Ep:78, loss:0.00001, loss_test:0.02013, lr:4.67e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.155, tt:2698.257\n",
      "Ep:79, loss:0.00001, loss_test:0.02014, lr:4.62e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.160, tt:2732.824\n",
      "Ep:80, loss:0.00001, loss_test:0.02026, lr:4.57e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.173, tt:2768.007\n",
      "Ep:81, loss:0.00001, loss_test:0.02036, lr:4.53e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.159, tt:2801.070\n",
      "Ep:82, loss:0.00001, loss_test:0.02036, lr:4.48e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.174, tt:2836.482\n",
      "Ep:83, loss:0.00001, loss_test:0.02034, lr:4.44e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.174, tt:2870.626\n",
      "Ep:84, loss:0.00001, loss_test:0.02048, lr:4.39e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.169, tt:2904.368\n",
      "Ep:85, loss:0.00001, loss_test:0.02058, lr:4.35e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.168, tt:2938.451\n",
      "Ep:86, loss:0.00001, loss_test:0.02068, lr:4.31e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.138, tt:2970.038\n",
      "Ep:87, loss:0.00001, loss_test:0.02076, lr:4.26e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.156, tt:3005.689\n",
      "Ep:88, loss:0.00001, loss_test:0.02072, lr:4.22e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.161, tt:3040.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00001, loss_test:0.02076, lr:4.18e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.177, tt:3075.953\n",
      "Ep:90, loss:0.00001, loss_test:0.02078, lr:4.14e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.190, tt:3111.250\n",
      "Ep:91, loss:0.00001, loss_test:0.02089, lr:4.10e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.184, tt:3144.952\n",
      "Ep:92, loss:0.00001, loss_test:0.02096, lr:4.05e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.188, tt:3179.520\n",
      "Ep:93, loss:0.00001, loss_test:0.02097, lr:4.01e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.186, tt:3213.454\n",
      "Ep:94, loss:0.00001, loss_test:0.02108, lr:3.97e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.176, tt:3246.754\n",
      "Ep:95, loss:0.00001, loss_test:0.02109, lr:3.93e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.170, tt:3280.349\n",
      "Ep:96, loss:0.00001, loss_test:0.02112, lr:3.89e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.166, tt:3314.141\n",
      "Ep:97, loss:0.00001, loss_test:0.02127, lr:3.86e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.170, tt:3348.660\n",
      "Ep:98, loss:0.00001, loss_test:0.02128, lr:3.82e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.180, tt:3383.808\n",
      "Ep:99, loss:0.00001, loss_test:0.02124, lr:3.78e-02, fs:0.73224 (r=0.677,p=0.798),  time:34.168, tt:3416.806\n",
      "Ep:100, loss:0.00001, loss_test:0.02129, lr:3.74e-02, fs:0.72527 (r=0.667,p=0.795),  time:34.181, tt:3452.327\n",
      "Ep:101, loss:0.00001, loss_test:0.02138, lr:3.70e-02, fs:0.72527 (r=0.667,p=0.795),  time:34.179, tt:3486.223\n",
      "Ep:102, loss:0.00001, loss_test:0.02150, lr:3.67e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.220, tt:3524.710\n",
      "Ep:103, loss:0.00001, loss_test:0.02155, lr:3.63e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.219, tt:3558.737\n",
      "Ep:104, loss:0.00001, loss_test:0.02150, lr:3.59e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.228, tt:3593.939\n",
      "Ep:105, loss:0.00001, loss_test:0.02152, lr:3.56e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.225, tt:3627.883\n",
      "Ep:106, loss:0.00001, loss_test:0.02158, lr:3.52e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.229, tt:3662.545\n",
      "Ep:107, loss:0.00000, loss_test:0.02168, lr:3.49e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.244, tt:3698.323\n",
      "Ep:108, loss:0.00000, loss_test:0.02176, lr:3.45e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.246, tt:3732.767\n",
      "Ep:109, loss:0.00000, loss_test:0.02175, lr:3.42e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.249, tt:3767.401\n",
      "Ep:110, loss:0.00000, loss_test:0.02178, lr:3.38e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.244, tt:3801.107\n",
      "Ep:111, loss:0.00000, loss_test:0.02183, lr:3.35e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.244, tt:3835.291\n",
      "Ep:112, loss:0.00000, loss_test:0.02183, lr:3.32e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.271, tt:3872.612\n",
      "Ep:113, loss:0.00000, loss_test:0.02194, lr:3.28e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.272, tt:3907.036\n",
      "Ep:114, loss:0.00000, loss_test:0.02194, lr:3.25e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.271, tt:3941.198\n",
      "Ep:115, loss:0.00000, loss_test:0.02202, lr:3.22e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.280, tt:3976.501\n",
      "Ep:116, loss:0.00000, loss_test:0.02210, lr:3.19e-02, fs:0.69318 (r=0.616,p=0.792),  time:34.296, tt:4012.616\n",
      "Ep:117, loss:0.00000, loss_test:0.02210, lr:3.15e-02, fs:0.70787 (r=0.636,p=0.797),  time:34.297, tt:4047.032\n",
      "Ep:118, loss:0.00000, loss_test:0.02213, lr:3.12e-02, fs:0.68571 (r=0.606,p=0.789),  time:34.300, tt:4081.737\n",
      "Ep:119, loss:0.00000, loss_test:0.02219, lr:3.09e-02, fs:0.68571 (r=0.606,p=0.789),  time:34.313, tt:4117.581\n",
      "Ep:120, loss:0.00000, loss_test:0.02222, lr:3.06e-02, fs:0.68571 (r=0.606,p=0.789),  time:34.313, tt:4151.923\n",
      "Ep:121, loss:0.00000, loss_test:0.02227, lr:3.03e-02, fs:0.68571 (r=0.606,p=0.789),  time:34.313, tt:4186.130\n",
      "Ep:122, loss:0.00000, loss_test:0.02231, lr:3.00e-02, fs:0.68571 (r=0.606,p=0.789),  time:34.327, tt:4222.205\n",
      "Ep:123, loss:0.00000, loss_test:0.02235, lr:2.97e-02, fs:0.68571 (r=0.606,p=0.789),  time:34.315, tt:4255.052\n",
      "Ep:124, loss:0.00000, loss_test:0.02245, lr:2.94e-02, fs:0.68208 (r=0.596,p=0.797),  time:34.318, tt:4289.766\n",
      "Ep:125, loss:0.00000, loss_test:0.02244, lr:2.91e-02, fs:0.68208 (r=0.596,p=0.797),  time:34.311, tt:4323.157\n",
      "Ep:126, loss:0.00000, loss_test:0.02251, lr:2.88e-02, fs:0.68208 (r=0.596,p=0.797),  time:34.322, tt:4358.937\n",
      "Ep:127, loss:0.00000, loss_test:0.02255, lr:2.85e-02, fs:0.68208 (r=0.596,p=0.797),  time:34.323, tt:4393.360\n",
      "Ep:128, loss:0.00000, loss_test:0.02262, lr:2.82e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.327, tt:4428.153\n",
      "Ep:129, loss:0.00000, loss_test:0.02257, lr:2.80e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.331, tt:4463.025\n",
      "Ep:130, loss:0.00000, loss_test:0.02267, lr:2.77e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.336, tt:4498.045\n",
      "Ep:131, loss:0.00000, loss_test:0.02273, lr:2.74e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.341, tt:4532.957\n",
      "Ep:132, loss:0.00000, loss_test:0.02276, lr:2.71e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.369, tt:4571.028\n",
      "Ep:133, loss:0.00000, loss_test:0.02279, lr:2.69e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.359, tt:4604.072\n",
      "Ep:134, loss:0.00000, loss_test:0.02281, lr:2.66e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.348, tt:4636.970\n",
      "Ep:135, loss:0.00000, loss_test:0.02288, lr:2.63e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.344, tt:4670.761\n",
      "Ep:136, loss:0.00000, loss_test:0.02294, lr:2.61e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.349, tt:4705.876\n",
      "Ep:137, loss:0.00000, loss_test:0.02295, lr:2.58e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.351, tt:4740.456\n",
      "Ep:138, loss:0.00000, loss_test:0.02299, lr:2.55e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.347, tt:4774.200\n",
      "Ep:139, loss:0.00000, loss_test:0.02306, lr:2.53e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.341, tt:4807.683\n",
      "Ep:140, loss:0.00000, loss_test:0.02310, lr:2.50e-02, fs:0.67442 (r=0.586,p=0.795),  time:34.346, tt:4842.734\n",
      "Ep:141, loss:0.00000, loss_test:0.02311, lr:2.48e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.344, tt:4876.778\n",
      "Ep:142, loss:0.00000, loss_test:0.02315, lr:2.45e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.342, tt:4910.917\n",
      "Ep:143, loss:0.00000, loss_test:0.02321, lr:2.43e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.338, tt:4944.722\n",
      "Ep:144, loss:0.00000, loss_test:0.02322, lr:2.40e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.325, tt:4977.189\n",
      "Ep:145, loss:0.00000, loss_test:0.02323, lr:2.38e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.315, tt:5009.933\n",
      "Ep:146, loss:0.00000, loss_test:0.02327, lr:2.36e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.319, tt:5044.821\n",
      "Ep:147, loss:0.00000, loss_test:0.02334, lr:2.33e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.328, tt:5080.576\n",
      "Ep:148, loss:0.00000, loss_test:0.02335, lr:2.31e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.319, tt:5113.519\n",
      "Ep:149, loss:0.00000, loss_test:0.02337, lr:2.29e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.313, tt:5146.958\n",
      "Ep:150, loss:0.00000, loss_test:0.02344, lr:2.26e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.318, tt:5182.005\n",
      "Ep:151, loss:0.00000, loss_test:0.02346, lr:2.24e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.321, tt:5216.851\n",
      "Ep:152, loss:0.00000, loss_test:0.02348, lr:2.22e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.324, tt:5251.505\n",
      "Ep:153, loss:0.00000, loss_test:0.02352, lr:2.20e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.331, tt:5286.961\n",
      "Ep:154, loss:0.00000, loss_test:0.02352, lr:2.17e-02, fs:0.66272 (r=0.566,p=0.800),  time:34.336, tt:5322.148\n",
      "Ep:155, loss:0.00000, loss_test:0.02356, lr:2.15e-02, fs:0.66272 (r=0.566,p=0.800),  time:34.340, tt:5356.964\n",
      "Ep:156, loss:0.00000, loss_test:0.02360, lr:2.13e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.338, tt:5391.117\n",
      "Ep:157, loss:0.00000, loss_test:0.02364, lr:2.11e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.351, tt:5427.481\n",
      "Ep:158, loss:0.00000, loss_test:0.02365, lr:2.09e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.355, tt:5462.403\n",
      "Ep:159, loss:0.00000, loss_test:0.02364, lr:2.07e-02, fs:0.66272 (r=0.566,p=0.800),  time:34.361, tt:5497.743\n",
      "Ep:160, loss:0.00000, loss_test:0.02370, lr:2.05e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.363, tt:5532.509\n",
      "Ep:161, loss:0.00000, loss_test:0.02376, lr:2.03e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.359, tt:5566.163\n",
      "Ep:162, loss:0.00000, loss_test:0.02374, lr:2.01e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.353, tt:5599.562\n",
      "Ep:163, loss:0.00000, loss_test:0.02378, lr:1.99e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.349, tt:5633.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:164, loss:0.00000, loss_test:0.02383, lr:1.97e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.345, tt:5666.857\n",
      "Ep:165, loss:0.00000, loss_test:0.02385, lr:1.95e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.347, tt:5701.661\n",
      "Ep:166, loss:0.00000, loss_test:0.02386, lr:1.93e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.346, tt:5735.701\n",
      "Ep:167, loss:0.00000, loss_test:0.02386, lr:1.91e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.345, tt:5769.896\n",
      "Ep:168, loss:0.00000, loss_test:0.02391, lr:1.89e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.345, tt:5804.299\n",
      "Ep:169, loss:0.00000, loss_test:0.02394, lr:1.87e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.345, tt:5838.658\n",
      "Ep:170, loss:0.00000, loss_test:0.02398, lr:1.85e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.353, tt:5874.365\n",
      "Ep:171, loss:0.00000, loss_test:0.02397, lr:1.83e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.354, tt:5908.820\n",
      "Ep:172, loss:0.00000, loss_test:0.02399, lr:1.81e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.356, tt:5943.652\n",
      "Ep:173, loss:0.00000, loss_test:0.02400, lr:1.80e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.360, tt:5978.587\n",
      "Ep:174, loss:0.00000, loss_test:0.02405, lr:1.78e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.366, tt:6013.974\n",
      "Ep:175, loss:0.00000, loss_test:0.02408, lr:1.76e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.370, tt:6049.134\n",
      "Ep:176, loss:0.00000, loss_test:0.02411, lr:1.74e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.372, tt:6083.805\n",
      "Ep:177, loss:0.00000, loss_test:0.02411, lr:1.73e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.373, tt:6118.308\n",
      "Ep:178, loss:0.00000, loss_test:0.02413, lr:1.71e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.373, tt:6152.766\n",
      "Ep:179, loss:0.00000, loss_test:0.02415, lr:1.69e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.375, tt:6187.433\n",
      "Ep:180, loss:0.00000, loss_test:0.02418, lr:1.67e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.369, tt:6220.795\n",
      "Ep:181, loss:0.00000, loss_test:0.02420, lr:1.66e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.367, tt:6254.730\n",
      "Ep:182, loss:0.00000, loss_test:0.02424, lr:1.64e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.363, tt:6288.449\n",
      "Ep:183, loss:0.00000, loss_test:0.02428, lr:1.62e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.362, tt:6322.667\n",
      "Ep:184, loss:0.00000, loss_test:0.02430, lr:1.61e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.363, tt:6357.064\n",
      "Ep:185, loss:0.00000, loss_test:0.02430, lr:1.59e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.360, tt:6390.935\n",
      "Ep:186, loss:0.00000, loss_test:0.02432, lr:1.58e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.355, tt:6424.314\n",
      "Ep:187, loss:0.00000, loss_test:0.02435, lr:1.56e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.357, tt:6459.153\n",
      "Ep:188, loss:0.00000, loss_test:0.02436, lr:1.54e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.361, tt:6494.172\n",
      "Ep:189, loss:0.00000, loss_test:0.02438, lr:1.53e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.362, tt:6528.735\n",
      "Ep:190, loss:0.00000, loss_test:0.02440, lr:1.51e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.366, tt:6563.919\n",
      "Ep:191, loss:0.00000, loss_test:0.02442, lr:1.50e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.364, tt:6597.874\n",
      "Ep:192, loss:0.00000, loss_test:0.02444, lr:1.48e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.366, tt:6632.688\n",
      "Ep:193, loss:0.00000, loss_test:0.02446, lr:1.47e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.369, tt:6667.574\n",
      "Ep:194, loss:0.00000, loss_test:0.02448, lr:1.45e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.370, tt:6702.090\n",
      "Ep:195, loss:0.00000, loss_test:0.02449, lr:1.44e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.373, tt:6737.148\n",
      "Ep:196, loss:0.00000, loss_test:0.02448, lr:1.43e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.368, tt:6770.566\n",
      "Ep:197, loss:0.00000, loss_test:0.02451, lr:1.41e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.359, tt:6803.025\n",
      "Ep:198, loss:0.00000, loss_test:0.02455, lr:1.40e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.354, tt:6836.439\n",
      "Ep:199, loss:0.00000, loss_test:0.02458, lr:1.38e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.327, tt:6865.343\n",
      "Ep:200, loss:0.00000, loss_test:0.02459, lr:1.37e-02, fs:0.66667 (r=0.566,p=0.812),  time:34.296, tt:6893.528\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13996, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:31.845, tt:31.845\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13709, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:33.406, tt:66.813\n",
      "Ep:2, loss:0.00026, loss_test:0.13426, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:34.653, tt:103.960\n",
      "Ep:3, loss:0.00024, loss_test:0.13359, lr:1.00e-02, fs:0.63478 (r=0.737,p=0.557),  time:34.710, tt:138.840\n",
      "Ep:4, loss:0.00023, loss_test:0.13588, lr:1.00e-02, fs:0.63415 (r=0.657,p=0.613),  time:34.821, tt:174.103\n",
      "Ep:5, loss:0.00023, loss_test:0.13461, lr:1.00e-02, fs:0.61692 (r=0.626,p=0.608),  time:34.811, tt:208.869\n",
      "Ep:6, loss:0.00022, loss_test:0.12780, lr:1.00e-02, fs:0.63810 (r=0.677,p=0.604),  time:35.007, tt:245.046\n",
      "Ep:7, loss:0.00021, loss_test:0.12495, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:35.295, tt:282.357\n",
      "Ep:8, loss:0.00020, loss_test:0.12429, lr:1.00e-02, fs:0.66029 (r=0.697,p=0.627),  time:35.486, tt:319.372\n",
      "Ep:9, loss:0.00020, loss_test:0.12459, lr:1.00e-02, fs:0.62500 (r=0.606,p=0.645),  time:36.052, tt:360.523\n",
      "Ep:10, loss:0.00019, loss_test:0.12099, lr:1.00e-02, fs:0.63317 (r=0.636,p=0.630),  time:36.061, tt:396.674\n",
      "Ep:11, loss:0.00019, loss_test:0.11845, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:36.153, tt:433.841\n",
      "Ep:12, loss:0.00018, loss_test:0.11719, lr:9.90e-03, fs:0.63590 (r=0.626,p=0.646),  time:36.165, tt:470.146\n",
      "Ep:13, loss:0.00018, loss_test:0.11615, lr:9.80e-03, fs:0.64921 (r=0.626,p=0.674),  time:36.228, tt:507.186\n",
      "Ep:14, loss:0.00017, loss_test:0.11411, lr:9.70e-03, fs:0.67337 (r=0.677,p=0.670),  time:36.319, tt:544.784\n",
      "Ep:15, loss:0.00017, loss_test:0.11238, lr:9.61e-03, fs:0.69000 (r=0.697,p=0.683),  time:36.432, tt:582.907\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.11092, lr:9.61e-03, fs:0.67358 (r=0.657,p=0.691),  time:36.438, tt:619.443\n",
      "Ep:17, loss:0.00016, loss_test:0.10908, lr:9.61e-03, fs:0.67358 (r=0.657,p=0.691),  time:36.495, tt:656.907\n",
      "Ep:18, loss:0.00015, loss_test:0.10728, lr:9.61e-03, fs:0.71717 (r=0.717,p=0.717),  time:36.544, tt:694.337\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.10562, lr:9.61e-03, fs:0.74227 (r=0.727,p=0.758),  time:36.575, tt:731.500\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.10352, lr:9.61e-03, fs:0.73575 (r=0.717,p=0.755),  time:36.630, tt:769.233\n",
      "Ep:21, loss:0.00014, loss_test:0.10041, lr:9.61e-03, fs:0.73575 (r=0.717,p=0.755),  time:36.653, tt:806.356\n",
      "Ep:22, loss:0.00013, loss_test:0.09955, lr:9.61e-03, fs:0.71795 (r=0.707,p=0.729),  time:36.677, tt:843.570\n",
      "Ep:23, loss:0.00013, loss_test:0.09831, lr:9.61e-03, fs:0.75127 (r=0.747,p=0.755),  time:36.690, tt:880.568\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.09646, lr:9.61e-03, fs:0.74611 (r=0.727,p=0.766),  time:36.671, tt:916.777\n",
      "Ep:25, loss:0.00012, loss_test:0.09646, lr:9.61e-03, fs:0.73298 (r=0.707,p=0.761),  time:36.672, tt:953.481\n",
      "Ep:26, loss:0.00011, loss_test:0.09416, lr:9.61e-03, fs:0.74611 (r=0.727,p=0.766),  time:36.665, tt:989.956\n",
      "Ep:27, loss:0.00011, loss_test:0.09381, lr:9.61e-03, fs:0.77895 (r=0.747,p=0.813),  time:36.650, tt:1026.188\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.09321, lr:9.61e-03, fs:0.75393 (r=0.727,p=0.783),  time:36.754, tt:1065.864\n",
      "Ep:29, loss:0.00010, loss_test:0.09089, lr:9.61e-03, fs:0.75132 (r=0.717,p=0.789),  time:36.749, tt:1102.483\n",
      "Ep:30, loss:0.00009, loss_test:0.09181, lr:9.61e-03, fs:0.76440 (r=0.737,p=0.793),  time:36.796, tt:1140.673\n",
      "Ep:31, loss:0.00009, loss_test:0.08889, lr:9.61e-03, fs:0.76190 (r=0.727,p=0.800),  time:36.831, tt:1178.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00009, loss_test:0.08912, lr:9.61e-03, fs:0.77320 (r=0.758,p=0.789),  time:36.846, tt:1215.931\n",
      "Ep:33, loss:0.00008, loss_test:0.08620, lr:9.61e-03, fs:0.76842 (r=0.737,p=0.802),  time:36.836, tt:1252.419\n",
      "Ep:34, loss:0.00008, loss_test:0.08712, lr:9.61e-03, fs:0.77720 (r=0.758,p=0.798),  time:36.824, tt:1288.840\n",
      "Ep:35, loss:0.00008, loss_test:0.08524, lr:9.61e-03, fs:0.79167 (r=0.768,p=0.817),  time:36.860, tt:1326.971\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.08431, lr:9.61e-03, fs:0.79581 (r=0.768,p=0.826),  time:36.872, tt:1364.247\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.08298, lr:9.61e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.890, tt:1401.838\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.08470, lr:9.61e-03, fs:0.79381 (r=0.778,p=0.811),  time:36.919, tt:1439.833\n",
      "Ep:39, loss:0.00007, loss_test:0.08092, lr:9.61e-03, fs:0.80628 (r=0.778,p=0.837),  time:36.877, tt:1475.061\n",
      "Ep:40, loss:0.00006, loss_test:0.08238, lr:9.61e-03, fs:0.79381 (r=0.778,p=0.811),  time:36.878, tt:1511.992\n",
      "Ep:41, loss:0.00006, loss_test:0.08030, lr:9.61e-03, fs:0.80000 (r=0.768,p=0.835),  time:36.890, tt:1549.399\n",
      "Ep:42, loss:0.00006, loss_test:0.08401, lr:9.61e-03, fs:0.80208 (r=0.778,p=0.828),  time:36.917, tt:1587.438\n",
      "Ep:43, loss:0.00006, loss_test:0.08053, lr:9.61e-03, fs:0.80628 (r=0.778,p=0.837),  time:36.940, tt:1625.350\n",
      "Ep:44, loss:0.00005, loss_test:0.07872, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:36.963, tt:1663.317\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.08095, lr:9.61e-03, fs:0.81053 (r=0.778,p=0.846),  time:37.003, tt:1702.117\n",
      "Ep:46, loss:0.00005, loss_test:0.07939, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:37.138, tt:1745.504\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00005, loss_test:0.08121, lr:9.61e-03, fs:0.80412 (r=0.788,p=0.821),  time:37.198, tt:1785.511\n",
      "Ep:48, loss:0.00005, loss_test:0.07662, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:37.165, tt:1821.065\n",
      "Ep:49, loss:0.00005, loss_test:0.08202, lr:9.61e-03, fs:0.80412 (r=0.788,p=0.821),  time:37.138, tt:1856.916\n",
      "Ep:50, loss:0.00004, loss_test:0.07651, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:37.159, tt:1895.094\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.08050, lr:9.61e-03, fs:0.80829 (r=0.788,p=0.830),  time:37.125, tt:1930.477\n",
      "Ep:52, loss:0.00004, loss_test:0.07712, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:37.156, tt:1969.260\n",
      "Ep:53, loss:0.00004, loss_test:0.08110, lr:9.61e-03, fs:0.80628 (r=0.778,p=0.837),  time:37.117, tt:2004.320\n",
      "Ep:54, loss:0.00004, loss_test:0.07574, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:37.085, tt:2039.682\n",
      "Ep:55, loss:0.00004, loss_test:0.08413, lr:9.61e-03, fs:0.81053 (r=0.778,p=0.846),  time:37.068, tt:2075.828\n",
      "Ep:56, loss:0.00004, loss_test:0.07887, lr:9.61e-03, fs:0.80851 (r=0.768,p=0.854),  time:37.013, tt:2109.760\n",
      "Ep:57, loss:0.00004, loss_test:0.07780, lr:9.61e-03, fs:0.80208 (r=0.778,p=0.828),  time:36.994, tt:2145.680\n",
      "Ep:58, loss:0.00003, loss_test:0.08223, lr:9.61e-03, fs:0.80214 (r=0.758,p=0.852),  time:36.998, tt:2182.871\n",
      "Ep:59, loss:0.00003, loss_test:0.07809, lr:9.61e-03, fs:0.81283 (r=0.768,p=0.864),  time:36.985, tt:2219.106\n",
      "Ep:60, loss:0.00003, loss_test:0.08182, lr:9.61e-03, fs:0.80208 (r=0.778,p=0.828),  time:36.978, tt:2255.657\n",
      "Ep:61, loss:0.00003, loss_test:0.07856, lr:9.61e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.951, tt:2290.932\n",
      "Ep:62, loss:0.00003, loss_test:0.08069, lr:9.51e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.941, tt:2327.300\n",
      "Ep:63, loss:0.00003, loss_test:0.07895, lr:9.41e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.920, tt:2362.850\n",
      "Ep:64, loss:0.00003, loss_test:0.08205, lr:9.32e-03, fs:0.80214 (r=0.758,p=0.852),  time:36.899, tt:2398.453\n",
      "Ep:65, loss:0.00003, loss_test:0.08183, lr:9.23e-03, fs:0.76923 (r=0.707,p=0.843),  time:36.910, tt:2436.072\n",
      "Ep:66, loss:0.00003, loss_test:0.07954, lr:9.14e-03, fs:0.81481 (r=0.778,p=0.856),  time:36.901, tt:2472.400\n",
      "Ep:67, loss:0.00002, loss_test:0.08472, lr:9.04e-03, fs:0.78689 (r=0.727,p=0.857),  time:36.886, tt:2508.240\n",
      "Ep:68, loss:0.00002, loss_test:0.08000, lr:8.95e-03, fs:0.77596 (r=0.717,p=0.845),  time:36.858, tt:2543.235\n",
      "Ep:69, loss:0.00002, loss_test:0.08303, lr:8.86e-03, fs:0.79787 (r=0.758,p=0.843),  time:36.837, tt:2578.602\n",
      "Ep:70, loss:0.00002, loss_test:0.08404, lr:8.78e-03, fs:0.76404 (r=0.687,p=0.861),  time:36.825, tt:2614.594\n",
      "Ep:71, loss:0.00002, loss_test:0.08167, lr:8.69e-03, fs:0.78919 (r=0.737,p=0.849),  time:36.809, tt:2650.241\n",
      "Ep:72, loss:0.00002, loss_test:0.08294, lr:8.60e-03, fs:0.76404 (r=0.687,p=0.861),  time:36.777, tt:2684.724\n",
      "Ep:73, loss:0.00002, loss_test:0.08367, lr:8.51e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.746, tt:2719.178\n",
      "Ep:74, loss:0.00002, loss_test:0.08286, lr:8.43e-03, fs:0.76923 (r=0.707,p=0.843),  time:36.722, tt:2754.185\n",
      "Ep:75, loss:0.00002, loss_test:0.08577, lr:8.35e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.719, tt:2790.644\n",
      "Ep:76, loss:0.00002, loss_test:0.08460, lr:8.26e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.691, tt:2825.211\n",
      "Ep:77, loss:0.00002, loss_test:0.08308, lr:8.18e-03, fs:0.75138 (r=0.687,p=0.829),  time:36.656, tt:2859.169\n",
      "Ep:78, loss:0.00002, loss_test:0.08455, lr:8.10e-03, fs:0.74860 (r=0.677,p=0.838),  time:36.657, tt:2895.928\n",
      "Ep:79, loss:0.00002, loss_test:0.08341, lr:8.02e-03, fs:0.74860 (r=0.677,p=0.838),  time:36.627, tt:2930.167\n",
      "Ep:80, loss:0.00002, loss_test:0.08478, lr:7.94e-03, fs:0.76503 (r=0.707,p=0.833),  time:36.622, tt:2966.392\n",
      "Ep:81, loss:0.00002, loss_test:0.08367, lr:7.86e-03, fs:0.77348 (r=0.707,p=0.854),  time:36.597, tt:3000.983\n",
      "Ep:82, loss:0.00001, loss_test:0.08539, lr:7.78e-03, fs:0.75138 (r=0.687,p=0.829),  time:36.609, tt:3038.547\n",
      "Ep:83, loss:0.00001, loss_test:0.08532, lr:7.70e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.597, tt:3074.134\n",
      "Ep:84, loss:0.00001, loss_test:0.08329, lr:7.62e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.572, tt:3108.601\n",
      "Ep:85, loss:0.00001, loss_test:0.08626, lr:7.55e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.560, tt:3144.148\n",
      "Ep:86, loss:0.00001, loss_test:0.08458, lr:7.47e-03, fs:0.74576 (r=0.667,p=0.846),  time:36.549, tt:3179.757\n",
      "Ep:87, loss:0.00001, loss_test:0.08279, lr:7.40e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.526, tt:3214.248\n",
      "Ep:88, loss:0.00001, loss_test:0.08568, lr:7.32e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.511, tt:3249.452\n",
      "Ep:89, loss:0.00001, loss_test:0.08463, lr:7.25e-03, fs:0.74860 (r=0.677,p=0.838),  time:36.503, tt:3285.291\n",
      "Ep:90, loss:0.00001, loss_test:0.08322, lr:7.18e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.504, tt:3321.868\n",
      "Ep:91, loss:0.00001, loss_test:0.08603, lr:7.11e-03, fs:0.73446 (r=0.657,p=0.833),  time:36.490, tt:3357.108\n",
      "Ep:92, loss:0.00001, loss_test:0.08328, lr:7.03e-03, fs:0.75281 (r=0.677,p=0.848),  time:36.462, tt:3390.948\n",
      "Ep:93, loss:0.00001, loss_test:0.08610, lr:6.96e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.456, tt:3426.834\n",
      "Ep:94, loss:0.00001, loss_test:0.08503, lr:6.89e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.436, tt:3461.405\n",
      "Ep:95, loss:0.00001, loss_test:0.08391, lr:6.83e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.429, tt:3497.205\n",
      "Ep:96, loss:0.00001, loss_test:0.08563, lr:6.76e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.426, tt:3533.292\n",
      "Ep:97, loss:0.00001, loss_test:0.08597, lr:6.69e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.409, tt:3568.069\n",
      "Ep:98, loss:0.00001, loss_test:0.08461, lr:6.62e-03, fs:0.72727 (r=0.646,p=0.831),  time:36.412, tt:3604.748\n",
      "Ep:99, loss:0.00001, loss_test:0.08558, lr:6.56e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.418, tt:3641.768\n",
      "Ep:100, loss:0.00001, loss_test:0.08705, lr:6.49e-03, fs:0.72727 (r=0.646,p=0.831),  time:36.400, tt:3676.422\n",
      "Ep:101, loss:0.00001, loss_test:0.08368, lr:6.43e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.381, tt:3710.876\n",
      "Ep:102, loss:0.00001, loss_test:0.08663, lr:6.36e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.368, tt:3745.939\n",
      "Ep:103, loss:0.00001, loss_test:0.08659, lr:6.30e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.348, tt:3780.166\n",
      "Ep:104, loss:0.00001, loss_test:0.08574, lr:6.24e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.336, tt:3815.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00001, loss_test:0.08559, lr:6.17e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.333, tt:3851.326\n",
      "Ep:106, loss:0.00001, loss_test:0.08831, lr:6.11e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.322, tt:3886.489\n",
      "Ep:107, loss:0.00001, loss_test:0.08591, lr:6.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.315, tt:3921.975\n",
      "Ep:108, loss:0.00001, loss_test:0.08697, lr:5.99e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.304, tt:3957.187\n",
      "Ep:109, loss:0.00001, loss_test:0.08835, lr:5.93e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.293, tt:3992.251\n",
      "Ep:110, loss:0.00001, loss_test:0.08516, lr:5.87e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.273, tt:4026.254\n",
      "Ep:111, loss:0.00001, loss_test:0.08722, lr:5.81e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.266, tt:4061.845\n",
      "Ep:112, loss:0.00001, loss_test:0.08673, lr:5.75e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.260, tt:4097.403\n",
      "Ep:113, loss:0.00001, loss_test:0.08586, lr:5.70e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.241, tt:4131.470\n",
      "Ep:114, loss:0.00001, loss_test:0.08757, lr:5.64e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.220, tt:4165.302\n",
      "Ep:115, loss:0.00001, loss_test:0.08656, lr:5.58e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.179, tt:4196.813\n",
      "Ep:116, loss:0.00001, loss_test:0.08658, lr:5.53e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.143, tt:4228.685\n",
      "Ep:117, loss:0.00001, loss_test:0.08610, lr:5.47e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.088, tt:4258.342\n",
      "Ep:118, loss:0.00001, loss_test:0.08734, lr:5.42e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.058, tt:4290.893\n",
      "Ep:119, loss:0.00001, loss_test:0.08635, lr:5.36e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.021, tt:4322.520\n",
      "Ep:120, loss:0.00001, loss_test:0.08649, lr:5.31e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.988, tt:4354.580\n",
      "Ep:121, loss:0.00001, loss_test:0.08857, lr:5.26e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.968, tt:4388.123\n",
      "Ep:122, loss:0.00001, loss_test:0.08699, lr:5.20e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.929, tt:4419.232\n",
      "Ep:123, loss:0.00001, loss_test:0.08674, lr:5.15e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.888, tt:4450.114\n",
      "Ep:124, loss:0.00001, loss_test:0.08758, lr:5.10e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.855, tt:4481.925\n",
      "Ep:125, loss:0.00001, loss_test:0.08712, lr:5.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.834, tt:4515.093\n",
      "Ep:126, loss:0.00001, loss_test:0.08670, lr:5.00e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.797, tt:4546.156\n",
      "Ep:127, loss:0.00001, loss_test:0.08793, lr:4.95e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.773, tt:4578.891\n",
      "Ep:128, loss:0.00001, loss_test:0.08857, lr:4.90e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.741, tt:4610.578\n",
      "Ep:129, loss:0.00001, loss_test:0.08649, lr:4.85e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.713, tt:4642.735\n",
      "Ep:130, loss:0.00001, loss_test:0.08652, lr:4.80e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.695, tt:4676.010\n",
      "Ep:131, loss:0.00001, loss_test:0.08806, lr:4.75e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.677, tt:4709.421\n",
      "Ep:132, loss:0.00001, loss_test:0.08728, lr:4.71e-03, fs:0.73988 (r=0.646,p=0.865),  time:35.661, tt:4742.968\n",
      "Ep:133, loss:0.00001, loss_test:0.08671, lr:4.66e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.642, tt:4775.975\n",
      "Ep:134, loss:0.00001, loss_test:0.08590, lr:4.61e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.615, tt:4808.017\n",
      "Ep:135, loss:0.00000, loss_test:0.08848, lr:4.57e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.582, tt:4839.129\n",
      "Ep:136, loss:0.00000, loss_test:0.08838, lr:4.52e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.557, tt:4871.332\n",
      "Ep:137, loss:0.00000, loss_test:0.08649, lr:4.48e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.528, tt:4902.852\n",
      "Ep:138, loss:0.00000, loss_test:0.08763, lr:4.43e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.502, tt:4934.727\n",
      "Ep:139, loss:0.00000, loss_test:0.08734, lr:4.39e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.476, tt:4966.622\n",
      "Ep:140, loss:0.00000, loss_test:0.08703, lr:4.34e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.461, tt:5000.062\n",
      "Ep:141, loss:0.00000, loss_test:0.08743, lr:4.30e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.447, tt:5033.445\n",
      "Ep:142, loss:0.00000, loss_test:0.08739, lr:4.26e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.424, tt:5065.687\n",
      "Ep:143, loss:0.00000, loss_test:0.08830, lr:4.21e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.396, tt:5097.093\n",
      "Ep:144, loss:0.00000, loss_test:0.08752, lr:4.17e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.374, tt:5129.257\n",
      "Ep:145, loss:0.00000, loss_test:0.08650, lr:4.13e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.345, tt:5160.343\n",
      "Ep:146, loss:0.00000, loss_test:0.08760, lr:4.09e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.323, tt:5192.486\n",
      "Ep:147, loss:0.00000, loss_test:0.08796, lr:4.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.287, tt:5222.424\n",
      "Ep:148, loss:0.00000, loss_test:0.08750, lr:4.01e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.249, tt:5252.064\n",
      "Ep:149, loss:0.00000, loss_test:0.08745, lr:3.97e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.217, tt:5282.482\n",
      "Ep:150, loss:0.00000, loss_test:0.08731, lr:3.93e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.188, tt:5313.318\n",
      "Ep:151, loss:0.00000, loss_test:0.08789, lr:3.89e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.145, tt:5342.069\n",
      "Ep:152, loss:0.00000, loss_test:0.08866, lr:3.85e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.108, tt:5371.496\n",
      "Ep:153, loss:0.00000, loss_test:0.08734, lr:3.81e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.077, tt:5401.899\n",
      "Ep:154, loss:0.00000, loss_test:0.08681, lr:3.77e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.043, tt:5431.658\n",
      "Ep:155, loss:0.00000, loss_test:0.08832, lr:3.73e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.017, tt:5462.611\n",
      "Ep:156, loss:0.00000, loss_test:0.08760, lr:3.70e-03, fs:0.74419 (r=0.646,p=0.877),  time:34.994, tt:5493.997\n",
      "Ep:157, loss:0.00000, loss_test:0.08705, lr:3.66e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.970, tt:5525.253\n",
      "Ep:158, loss:0.00000, loss_test:0.08769, lr:3.62e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.932, tt:5554.221\n",
      "Ep:159, loss:0.00000, loss_test:0.08761, lr:3.59e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.905, tt:5584.753\n",
      "Ep:160, loss:0.00000, loss_test:0.08728, lr:3.55e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.871, tt:5614.200\n",
      "Ep:161, loss:0.00000, loss_test:0.08775, lr:3.52e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.849, tt:5645.571\n",
      "Ep:162, loss:0.00000, loss_test:0.08738, lr:3.48e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.824, tt:5676.355\n",
      "Ep:163, loss:0.00000, loss_test:0.08759, lr:3.45e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.798, tt:5706.842\n",
      "Ep:164, loss:0.00000, loss_test:0.08802, lr:3.41e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.776, tt:5738.101\n",
      "Ep:165, loss:0.00000, loss_test:0.08787, lr:3.38e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.754, tt:5769.129\n",
      "Ep:166, loss:0.00000, loss_test:0.08795, lr:3.34e-03, fs:0.73988 (r=0.646,p=0.865),  time:34.733, tt:5800.468\n",
      "Ep:167, loss:0.00000, loss_test:0.08822, lr:3.31e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.715, tt:5832.144\n",
      "Ep:168, loss:0.00000, loss_test:0.08743, lr:3.28e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.688, tt:5862.327\n",
      "Ep:169, loss:0.00000, loss_test:0.08714, lr:3.24e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.669, tt:5893.690\n",
      "Ep:170, loss:0.00000, loss_test:0.08824, lr:3.21e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.650, tt:5925.130\n",
      "Ep:171, loss:0.00000, loss_test:0.08810, lr:3.18e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.626, tt:5955.756\n",
      "Ep:172, loss:0.00000, loss_test:0.08714, lr:3.15e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.601, tt:5985.992\n",
      "Ep:173, loss:0.00000, loss_test:0.08727, lr:3.12e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.589, tt:6018.527\n",
      "Ep:174, loss:0.00000, loss_test:0.08788, lr:3.09e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.562, tt:6048.279\n",
      "Ep:175, loss:0.00000, loss_test:0.08790, lr:3.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.546, tt:6080.062\n",
      "Ep:176, loss:0.00000, loss_test:0.08758, lr:3.02e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.519, tt:6109.949\n",
      "Ep:177, loss:0.00000, loss_test:0.08753, lr:2.99e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.497, tt:6140.544\n",
      "Ep:178, loss:0.00000, loss_test:0.08744, lr:2.96e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.472, tt:6170.515\n",
      "Ep:179, loss:0.00000, loss_test:0.08746, lr:2.93e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.446, tt:6200.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00000, loss_test:0.08776, lr:2.90e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.432, tt:6232.157\n",
      "Ep:181, loss:0.00000, loss_test:0.08765, lr:2.88e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.410, tt:6262.710\n",
      "Ep:182, loss:0.00000, loss_test:0.08710, lr:2.85e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.376, tt:6290.860\n",
      "Ep:183, loss:0.00000, loss_test:0.08781, lr:2.82e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.352, tt:6320.743\n",
      "Ep:184, loss:0.00000, loss_test:0.08838, lr:2.79e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.330, tt:6350.970\n",
      "Ep:185, loss:0.00000, loss_test:0.08827, lr:2.76e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.307, tt:6381.092\n",
      "Ep:186, loss:0.00000, loss_test:0.08749, lr:2.73e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.279, tt:6410.111\n",
      "Ep:187, loss:0.00000, loss_test:0.08740, lr:2.71e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.262, tt:6441.331\n",
      "Ep:188, loss:0.00000, loss_test:0.08849, lr:2.68e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.232, tt:6469.938\n",
      "Ep:189, loss:0.00000, loss_test:0.08844, lr:2.65e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.221, tt:6502.058\n",
      "Ep:190, loss:0.00000, loss_test:0.08782, lr:2.63e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.203, tt:6532.845\n",
      "Ep:191, loss:0.00000, loss_test:0.08735, lr:2.60e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.190, tt:6564.389\n",
      "Ep:192, loss:0.00000, loss_test:0.08772, lr:2.57e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.146, tt:6590.241\n",
      "Ep:193, loss:0.00000, loss_test:0.08837, lr:2.55e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.130, tt:6621.304\n",
      "Ep:194, loss:0.00000, loss_test:0.08799, lr:2.52e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.113, tt:6651.999\n",
      "Ep:195, loss:0.00000, loss_test:0.08722, lr:2.50e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.104, tt:6684.338\n",
      "Ep:196, loss:0.00000, loss_test:0.08774, lr:2.47e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.070, tt:6711.818\n",
      "Ep:197, loss:0.00000, loss_test:0.08835, lr:2.45e-03, fs:0.73563 (r=0.646,p=0.853),  time:34.036, tt:6739.123\n",
      "Ep:198, loss:0.00000, loss_test:0.08851, lr:2.42e-03, fs:0.73563 (r=0.646,p=0.853),  time:33.993, tt:6764.607\n",
      "Ep:199, loss:0.00000, loss_test:0.08835, lr:2.40e-03, fs:0.73563 (r=0.646,p=0.853),  time:33.927, tt:6785.334\n",
      "Ep:200, loss:0.00000, loss_test:0.08792, lr:2.38e-03, fs:0.73563 (r=0.646,p=0.853),  time:33.820, tt:6797.825\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02003, lr:6.00e-02, fs:0.63673 (r=0.897,p=0.494),  time:37.180, tt:37.180\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02323, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.388, tt:76.777\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02487, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.793, tt:116.378\n",
      "Ep:3, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.441, tt:153.765\n",
      "Ep:4, loss:0.00005, loss_test:0.02358, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:38.413, tt:192.065\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02206, lr:6.00e-02, fs:0.66406 (r=0.977,p=0.503),  time:38.760, tt:232.560\n",
      "Ep:6, loss:0.00004, loss_test:0.02079, lr:6.00e-02, fs:0.65854 (r=0.931,p=0.509),  time:39.284, tt:274.991\n",
      "Ep:7, loss:0.00004, loss_test:0.02017, lr:6.00e-02, fs:0.64912 (r=0.851,p=0.525),  time:39.332, tt:314.656\n",
      "Ep:8, loss:0.00004, loss_test:0.02001, lr:6.00e-02, fs:0.65714 (r=0.793,p=0.561),  time:39.358, tt:354.222\n",
      "Ep:9, loss:0.00004, loss_test:0.01943, lr:6.00e-02, fs:0.67327 (r=0.782,p=0.591),  time:39.319, tt:393.188\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01838, lr:6.00e-02, fs:0.69307 (r=0.805,p=0.609),  time:39.323, tt:432.558\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01757, lr:6.00e-02, fs:0.70476 (r=0.851,p=0.602),  time:39.371, tt:472.456\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01707, lr:6.00e-02, fs:0.71028 (r=0.874,p=0.598),  time:39.341, tt:511.435\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01660, lr:6.00e-02, fs:0.71362 (r=0.874,p=0.603),  time:39.332, tt:550.644\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.72727 (r=0.874,p=0.623),  time:39.406, tt:591.087\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.74146 (r=0.874,p=0.644),  time:39.396, tt:630.335\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.76238 (r=0.885,p=0.670),  time:39.386, tt:669.561\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.77228 (r=0.897,p=0.678),  time:39.463, tt:710.338\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.77451 (r=0.908,p=0.675),  time:39.542, tt:751.294\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01450, lr:6.00e-02, fs:0.78431 (r=0.920,p=0.684),  time:39.590, tt:791.802\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01425, lr:6.00e-02, fs:0.79208 (r=0.920,p=0.696),  time:39.588, tt:831.341\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01409, lr:6.00e-02, fs:0.79803 (r=0.931,p=0.698),  time:39.528, tt:869.616\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.79803 (r=0.931,p=0.698),  time:39.513, tt:908.800\n",
      "Ep:23, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.80392 (r=0.943,p=0.701),  time:39.579, tt:949.899\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.80788 (r=0.943,p=0.707),  time:39.621, tt:990.518\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.81188 (r=0.943,p=0.713),  time:39.683, tt:1031.762\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.82000 (r=0.943,p=0.726),  time:39.696, tt:1071.789\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.82000 (r=0.943,p=0.726),  time:39.711, tt:1111.903\n",
      "Ep:28, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.82412 (r=0.943,p=0.732),  time:39.737, tt:1152.375\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.83000 (r=0.954,p=0.735),  time:39.794, tt:1193.835\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:39.817, tt:1234.321\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01284, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:39.802, tt:1273.670\n",
      "Ep:32, loss:0.00002, loss_test:0.01276, lr:6.00e-02, fs:0.83582 (r=0.966,p=0.737),  time:39.799, tt:1313.359\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.84000 (r=0.966,p=0.743),  time:39.801, tt:1353.226\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.84577 (r=0.977,p=0.746),  time:39.807, tt:1393.250\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01254, lr:6.00e-02, fs:0.84577 (r=0.977,p=0.746),  time:39.908, tt:1436.684\n",
      "Ep:36, loss:0.00002, loss_test:0.01250, lr:6.00e-02, fs:0.84577 (r=0.977,p=0.746),  time:39.873, tt:1475.311\n",
      "Ep:37, loss:0.00002, loss_test:0.01246, lr:6.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:39.873, tt:1515.190\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:39.832, tt:1553.462\n",
      "Ep:39, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.846, tt:1593.846\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.801, tt:1631.837\n",
      "Ep:41, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.752, tt:1669.602\n",
      "Ep:42, loss:0.00002, loss_test:0.01211, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.724, tt:1708.152\n",
      "Ep:43, loss:0.00002, loss_test:0.01208, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.728, tt:1748.031\n",
      "Ep:44, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.692, tt:1786.141\n",
      "Ep:45, loss:0.00001, loss_test:0.01201, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:39.690, tt:1825.739\n",
      "Ep:46, loss:0.00001, loss_test:0.01196, lr:6.00e-02, fs:0.86735 (r=0.977,p=0.780),  time:39.662, tt:1864.131\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01197, lr:6.00e-02, fs:0.86598 (r=0.966,p=0.785),  time:39.692, tt:1905.226\n",
      "Ep:48, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.86598 (r=0.966,p=0.785),  time:39.684, tt:1944.506\n",
      "Ep:49, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:39.679, tt:1983.938\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:39.627, tt:2020.978\n",
      "Ep:51, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.625, tt:2060.481\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01191, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.603, tt:2098.940\n",
      "Ep:53, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.575, tt:2137.028\n",
      "Ep:54, loss:0.00001, loss_test:0.01191, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.595, tt:2177.736\n",
      "Ep:55, loss:0.00001, loss_test:0.01191, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.587, tt:2216.869\n",
      "Ep:56, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.555, tt:2254.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01183, lr:6.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:39.524, tt:2292.364\n",
      "Ep:58, loss:0.00001, loss_test:0.01186, lr:6.00e-02, fs:0.86316 (r=0.943,p=0.796),  time:39.550, tt:2333.436\n",
      "Ep:59, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.86316 (r=0.943,p=0.796),  time:39.550, tt:2372.994\n",
      "Ep:60, loss:0.00001, loss_test:0.01189, lr:6.00e-02, fs:0.86316 (r=0.943,p=0.796),  time:39.586, tt:2414.729\n",
      "Ep:61, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.86316 (r=0.943,p=0.796),  time:39.589, tt:2454.548\n",
      "Ep:62, loss:0.00001, loss_test:0.01192, lr:6.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.591, tt:2494.239\n",
      "Ep:63, loss:0.00001, loss_test:0.01190, lr:5.94e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.593, tt:2533.945\n",
      "Ep:64, loss:0.00001, loss_test:0.01190, lr:5.88e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.597, tt:2573.797\n",
      "Ep:65, loss:0.00001, loss_test:0.01194, lr:5.82e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.633, tt:2615.793\n",
      "Ep:66, loss:0.00001, loss_test:0.01194, lr:5.76e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.638, tt:2655.765\n",
      "Ep:67, loss:0.00001, loss_test:0.01196, lr:5.71e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.687, tt:2698.731\n",
      "Ep:68, loss:0.00001, loss_test:0.01195, lr:5.65e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.701, tt:2739.370\n",
      "Ep:69, loss:0.00001, loss_test:0.01192, lr:5.59e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.696, tt:2778.685\n",
      "Ep:70, loss:0.00001, loss_test:0.01190, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.685, tt:2817.656\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01198, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.688, tt:2857.523\n",
      "Ep:72, loss:0.00001, loss_test:0.01197, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.732, tt:2900.442\n",
      "Ep:73, loss:0.00001, loss_test:0.01203, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.744, tt:2941.089\n",
      "Ep:74, loss:0.00001, loss_test:0.01197, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.767, tt:2982.489\n",
      "Ep:75, loss:0.00001, loss_test:0.01200, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.795, tt:3024.384\n",
      "Ep:76, loss:0.00001, loss_test:0.01205, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.826, tt:3066.611\n",
      "Ep:77, loss:0.00001, loss_test:0.01199, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.834, tt:3107.062\n",
      "Ep:78, loss:0.00001, loss_test:0.01201, lr:5.54e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.854, tt:3148.466\n",
      "Ep:79, loss:0.00001, loss_test:0.01211, lr:5.54e-02, fs:0.87568 (r=0.931,p=0.827),  time:39.865, tt:3189.201\n",
      "Ep:80, loss:0.00001, loss_test:0.01209, lr:5.54e-02, fs:0.86957 (r=0.920,p=0.825),  time:39.864, tt:3229.008\n",
      "Ep:81, loss:0.00001, loss_test:0.01208, lr:5.54e-02, fs:0.86957 (r=0.920,p=0.825),  time:39.855, tt:3268.131\n",
      "Ep:82, loss:0.00001, loss_test:0.01213, lr:5.48e-02, fs:0.86957 (r=0.920,p=0.825),  time:39.887, tt:3310.659\n",
      "Ep:83, loss:0.00001, loss_test:0.01213, lr:5.43e-02, fs:0.86957 (r=0.920,p=0.825),  time:39.880, tt:3349.958\n",
      "Ep:84, loss:0.00001, loss_test:0.01215, lr:5.37e-02, fs:0.86957 (r=0.920,p=0.825),  time:39.882, tt:3389.930\n",
      "Ep:85, loss:0.00001, loss_test:0.01213, lr:5.32e-02, fs:0.86957 (r=0.920,p=0.825),  time:39.990, tt:3439.157\n",
      "Ep:86, loss:0.00001, loss_test:0.01211, lr:5.27e-02, fs:0.87568 (r=0.931,p=0.827),  time:40.000, tt:3480.039\n",
      "Ep:87, loss:0.00001, loss_test:0.01214, lr:5.21e-02, fs:0.87432 (r=0.920,p=0.833),  time:40.021, tt:3521.862\n",
      "Ep:88, loss:0.00001, loss_test:0.01217, lr:5.16e-02, fs:0.87432 (r=0.920,p=0.833),  time:40.032, tt:3562.848\n",
      "Ep:89, loss:0.00001, loss_test:0.01219, lr:5.11e-02, fs:0.87432 (r=0.920,p=0.833),  time:40.034, tt:3603.023\n",
      "Ep:90, loss:0.00001, loss_test:0.01214, lr:5.06e-02, fs:0.88525 (r=0.931,p=0.844),  time:40.052, tt:3644.722\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01210, lr:5.06e-02, fs:0.88525 (r=0.931,p=0.844),  time:40.047, tt:3684.303\n",
      "Ep:92, loss:0.00001, loss_test:0.01218, lr:5.06e-02, fs:0.87293 (r=0.908,p=0.840),  time:40.051, tt:3724.753\n",
      "Ep:93, loss:0.00001, loss_test:0.01214, lr:5.06e-02, fs:0.87912 (r=0.920,p=0.842),  time:40.063, tt:3765.960\n",
      "Ep:94, loss:0.00001, loss_test:0.01216, lr:5.06e-02, fs:0.88525 (r=0.931,p=0.844),  time:40.074, tt:3807.028\n",
      "Ep:95, loss:0.00001, loss_test:0.01218, lr:5.06e-02, fs:0.87912 (r=0.920,p=0.842),  time:40.089, tt:3848.586\n",
      "Ep:96, loss:0.00001, loss_test:0.01219, lr:5.06e-02, fs:0.87778 (r=0.908,p=0.849),  time:40.088, tt:3888.565\n",
      "Ep:97, loss:0.00001, loss_test:0.01224, lr:5.06e-02, fs:0.87151 (r=0.897,p=0.848),  time:40.087, tt:3928.484\n",
      "Ep:98, loss:0.00001, loss_test:0.01227, lr:5.06e-02, fs:0.87151 (r=0.897,p=0.848),  time:40.098, tt:3969.655\n",
      "Ep:99, loss:0.00001, loss_test:0.01223, lr:5.06e-02, fs:0.87778 (r=0.908,p=0.849),  time:40.090, tt:4009.034\n",
      "Ep:100, loss:0.00001, loss_test:0.01225, lr:5.06e-02, fs:0.87778 (r=0.908,p=0.849),  time:40.073, tt:4047.409\n",
      "Ep:101, loss:0.00001, loss_test:0.01228, lr:5.06e-02, fs:0.87778 (r=0.908,p=0.849),  time:40.069, tt:4087.025\n",
      "Ep:102, loss:0.00001, loss_test:0.01228, lr:5.01e-02, fs:0.87151 (r=0.897,p=0.848),  time:40.065, tt:4126.731\n",
      "Ep:103, loss:0.00001, loss_test:0.01232, lr:4.96e-02, fs:0.88764 (r=0.908,p=0.868),  time:40.043, tt:4164.486\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.01231, lr:4.96e-02, fs:0.88136 (r=0.897,p=0.867),  time:40.028, tt:4202.954\n",
      "Ep:105, loss:0.00001, loss_test:0.01230, lr:4.96e-02, fs:0.88764 (r=0.908,p=0.868),  time:40.028, tt:4243.005\n",
      "Ep:106, loss:0.00001, loss_test:0.01233, lr:4.96e-02, fs:0.88764 (r=0.908,p=0.868),  time:40.066, tt:4287.109\n",
      "Ep:107, loss:0.00001, loss_test:0.01232, lr:4.96e-02, fs:0.88764 (r=0.908,p=0.868),  time:40.058, tt:4326.316\n",
      "Ep:108, loss:0.00001, loss_test:0.01232, lr:4.96e-02, fs:0.89385 (r=0.920,p=0.870),  time:40.066, tt:4367.209\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.01230, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.069, tt:4407.608\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.01231, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.095, tt:4450.540\n",
      "Ep:111, loss:0.00000, loss_test:0.01230, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.088, tt:4489.907\n",
      "Ep:112, loss:0.00000, loss_test:0.01233, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.080, tt:4528.989\n",
      "Ep:113, loss:0.00000, loss_test:0.01238, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.083, tt:4569.466\n",
      "Ep:114, loss:0.00000, loss_test:0.01235, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.083, tt:4609.581\n",
      "Ep:115, loss:0.00000, loss_test:0.01237, lr:4.96e-02, fs:0.89385 (r=0.920,p=0.870),  time:40.078, tt:4649.029\n",
      "Ep:116, loss:0.00000, loss_test:0.01237, lr:4.96e-02, fs:0.90608 (r=0.943,p=0.872),  time:40.095, tt:4691.079\n",
      "Ep:117, loss:0.00000, loss_test:0.01237, lr:4.96e-02, fs:0.90000 (r=0.931,p=0.871),  time:40.103, tt:4732.129\n",
      "Ep:118, loss:0.00000, loss_test:0.01239, lr:4.96e-02, fs:0.90503 (r=0.931,p=0.880),  time:40.105, tt:4772.464\n",
      "Ep:119, loss:0.00000, loss_test:0.01240, lr:4.96e-02, fs:0.90000 (r=0.931,p=0.871),  time:40.106, tt:4812.736\n",
      "Ep:120, loss:0.00000, loss_test:0.01240, lr:4.96e-02, fs:0.89385 (r=0.920,p=0.870),  time:40.104, tt:4852.592\n",
      "Ep:121, loss:0.00000, loss_test:0.01242, lr:4.91e-02, fs:0.89266 (r=0.908,p=0.878),  time:40.098, tt:4891.907\n",
      "Ep:122, loss:0.00000, loss_test:0.01247, lr:4.86e-02, fs:0.88636 (r=0.897,p=0.876),  time:40.096, tt:4931.864\n",
      "Ep:123, loss:0.00000, loss_test:0.01242, lr:4.81e-02, fs:0.89266 (r=0.908,p=0.878),  time:40.092, tt:4971.391\n",
      "Ep:124, loss:0.00000, loss_test:0.01243, lr:4.76e-02, fs:0.88636 (r=0.897,p=0.876),  time:40.090, tt:5011.249\n",
      "Ep:125, loss:0.00000, loss_test:0.01251, lr:4.71e-02, fs:0.88000 (r=0.885,p=0.875),  time:40.099, tt:5052.526\n",
      "Ep:126, loss:0.00000, loss_test:0.01247, lr:4.67e-02, fs:0.88000 (r=0.885,p=0.875),  time:40.159, tt:5100.225\n",
      "Ep:127, loss:0.00000, loss_test:0.01247, lr:4.62e-02, fs:0.88636 (r=0.897,p=0.876),  time:40.156, tt:5140.021\n",
      "Ep:128, loss:0.00000, loss_test:0.01249, lr:4.57e-02, fs:0.88000 (r=0.885,p=0.875),  time:40.146, tt:5178.845\n",
      "Ep:129, loss:0.00000, loss_test:0.01257, lr:4.53e-02, fs:0.88000 (r=0.885,p=0.875),  time:40.142, tt:5218.467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.01256, lr:4.48e-02, fs:0.88000 (r=0.885,p=0.875),  time:40.138, tt:5258.106\n",
      "Ep:131, loss:0.00000, loss_test:0.01254, lr:4.44e-02, fs:0.88000 (r=0.885,p=0.875),  time:40.145, tt:5299.173\n",
      "Ep:132, loss:0.00000, loss_test:0.01257, lr:4.39e-02, fs:0.87356 (r=0.874,p=0.874),  time:40.142, tt:5338.861\n",
      "Ep:133, loss:0.00000, loss_test:0.01261, lr:4.35e-02, fs:0.87356 (r=0.874,p=0.874),  time:40.134, tt:5377.999\n",
      "Ep:134, loss:0.00000, loss_test:0.01257, lr:4.31e-02, fs:0.86705 (r=0.862,p=0.872),  time:40.127, tt:5417.150\n",
      "Ep:135, loss:0.00000, loss_test:0.01265, lr:4.26e-02, fs:0.86047 (r=0.851,p=0.871),  time:40.138, tt:5458.797\n",
      "Ep:136, loss:0.00000, loss_test:0.01266, lr:4.22e-02, fs:0.85380 (r=0.839,p=0.869),  time:40.140, tt:5499.140\n",
      "Ep:137, loss:0.00000, loss_test:0.01263, lr:4.18e-02, fs:0.86047 (r=0.851,p=0.871),  time:40.136, tt:5538.756\n",
      "Ep:138, loss:0.00000, loss_test:0.01268, lr:4.14e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.131, tt:5578.187\n",
      "Ep:139, loss:0.00000, loss_test:0.01270, lr:4.10e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.122, tt:5617.126\n",
      "Ep:140, loss:0.00000, loss_test:0.01268, lr:4.05e-02, fs:0.85380 (r=0.839,p=0.869),  time:40.122, tt:5657.229\n",
      "Ep:141, loss:0.00000, loss_test:0.01269, lr:4.01e-02, fs:0.85380 (r=0.839,p=0.869),  time:40.123, tt:5697.512\n",
      "Ep:142, loss:0.00000, loss_test:0.01271, lr:3.97e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.122, tt:5737.400\n",
      "Ep:143, loss:0.00000, loss_test:0.01271, lr:3.93e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.127, tt:5778.316\n",
      "Ep:144, loss:0.00000, loss_test:0.01270, lr:3.89e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.131, tt:5819.002\n",
      "Ep:145, loss:0.00000, loss_test:0.01276, lr:3.86e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.136, tt:5859.821\n",
      "Ep:146, loss:0.00000, loss_test:0.01278, lr:3.82e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.133, tt:5899.552\n",
      "Ep:147, loss:0.00000, loss_test:0.01275, lr:3.78e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.161, tt:5943.878\n",
      "Ep:148, loss:0.00000, loss_test:0.01279, lr:3.74e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.161, tt:5983.988\n",
      "Ep:149, loss:0.00000, loss_test:0.01280, lr:3.70e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.155, tt:6023.271\n",
      "Ep:150, loss:0.00000, loss_test:0.01279, lr:3.67e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.142, tt:6061.488\n",
      "Ep:151, loss:0.00000, loss_test:0.01280, lr:3.63e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.147, tt:6102.406\n",
      "Ep:152, loss:0.00000, loss_test:0.01282, lr:3.59e-02, fs:0.81928 (r=0.782,p=0.861),  time:40.143, tt:6141.882\n",
      "Ep:153, loss:0.00000, loss_test:0.01285, lr:3.56e-02, fs:0.81928 (r=0.782,p=0.861),  time:40.145, tt:6182.325\n",
      "Ep:154, loss:0.00000, loss_test:0.01286, lr:3.52e-02, fs:0.81212 (r=0.770,p=0.859),  time:40.143, tt:6222.179\n",
      "Ep:155, loss:0.00000, loss_test:0.01284, lr:3.49e-02, fs:0.81928 (r=0.782,p=0.861),  time:40.137, tt:6261.325\n",
      "Ep:156, loss:0.00000, loss_test:0.01286, lr:3.45e-02, fs:0.80488 (r=0.759,p=0.857),  time:40.134, tt:6301.080\n",
      "Ep:157, loss:0.00000, loss_test:0.01289, lr:3.42e-02, fs:0.80488 (r=0.759,p=0.857),  time:40.129, tt:6340.398\n",
      "Ep:158, loss:0.00000, loss_test:0.01288, lr:3.38e-02, fs:0.80488 (r=0.759,p=0.857),  time:40.133, tt:6381.102\n",
      "Ep:159, loss:0.00000, loss_test:0.01288, lr:3.35e-02, fs:0.81212 (r=0.770,p=0.859),  time:40.127, tt:6420.368\n",
      "Ep:160, loss:0.00000, loss_test:0.01292, lr:3.32e-02, fs:0.79755 (r=0.747,p=0.855),  time:40.134, tt:6461.635\n",
      "Ep:161, loss:0.00000, loss_test:0.01293, lr:3.28e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.143, tt:6503.178\n",
      "Ep:162, loss:0.00000, loss_test:0.01293, lr:3.25e-02, fs:0.79012 (r=0.736,p=0.853),  time:40.151, tt:6544.547\n",
      "Ep:163, loss:0.00000, loss_test:0.01295, lr:3.22e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.144, tt:6583.558\n",
      "Ep:164, loss:0.00000, loss_test:0.01295, lr:3.19e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.146, tt:6624.133\n",
      "Ep:165, loss:0.00000, loss_test:0.01298, lr:3.15e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.154, tt:6665.559\n",
      "Ep:166, loss:0.00000, loss_test:0.01298, lr:3.12e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.164, tt:6707.376\n",
      "Ep:167, loss:0.00000, loss_test:0.01297, lr:3.09e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.177, tt:6749.781\n",
      "Ep:168, loss:0.00000, loss_test:0.01300, lr:3.06e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.218, tt:6796.824\n",
      "Ep:169, loss:0.00000, loss_test:0.01302, lr:3.03e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.224, tt:6838.019\n",
      "Ep:170, loss:0.00000, loss_test:0.01301, lr:3.00e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.235, tt:6880.222\n",
      "Ep:171, loss:0.00000, loss_test:0.01301, lr:2.97e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.235, tt:6920.459\n",
      "Ep:172, loss:0.00000, loss_test:0.01303, lr:2.94e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.243, tt:6962.059\n",
      "Ep:173, loss:0.00000, loss_test:0.01307, lr:2.91e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.252, tt:7003.866\n",
      "Ep:174, loss:0.00000, loss_test:0.01308, lr:2.88e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.263, tt:7045.992\n",
      "Ep:175, loss:0.00000, loss_test:0.01306, lr:2.85e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.268, tt:7087.150\n",
      "Ep:176, loss:0.00000, loss_test:0.01309, lr:2.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.262, tt:7126.450\n",
      "Ep:177, loss:0.00000, loss_test:0.01312, lr:2.80e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.274, tt:7168.777\n",
      "Ep:178, loss:0.00000, loss_test:0.01308, lr:2.77e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.289, tt:7211.711\n",
      "Ep:179, loss:0.00000, loss_test:0.01312, lr:2.74e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.305, tt:7254.841\n",
      "Ep:180, loss:0.00000, loss_test:0.01315, lr:2.71e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.306, tt:7295.404\n",
      "Ep:181, loss:0.00000, loss_test:0.01315, lr:2.69e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.318, tt:7337.822\n",
      "Ep:182, loss:0.00000, loss_test:0.01315, lr:2.66e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.327, tt:7379.856\n",
      "Ep:183, loss:0.00000, loss_test:0.01317, lr:2.63e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.334, tt:7421.540\n",
      "Ep:184, loss:0.00000, loss_test:0.01319, lr:2.61e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.336, tt:7462.208\n",
      "Ep:185, loss:0.00000, loss_test:0.01321, lr:2.58e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.350, tt:7505.021\n",
      "Ep:186, loss:0.00000, loss_test:0.01321, lr:2.55e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.359, tt:7547.128\n",
      "Ep:187, loss:0.00000, loss_test:0.01323, lr:2.53e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.366, tt:7588.846\n",
      "Ep:188, loss:0.00000, loss_test:0.01322, lr:2.50e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.399, tt:7635.448\n",
      "Ep:189, loss:0.00000, loss_test:0.01323, lr:2.48e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.406, tt:7677.227\n",
      "Ep:190, loss:0.00000, loss_test:0.01325, lr:2.45e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.423, tt:7720.827\n",
      "Ep:191, loss:0.00000, loss_test:0.01327, lr:2.43e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.430, tt:7762.626\n",
      "Ep:192, loss:0.00000, loss_test:0.01326, lr:2.40e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.432, tt:7803.356\n",
      "Ep:193, loss:0.00000, loss_test:0.01327, lr:2.38e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.431, tt:7843.543\n",
      "Ep:194, loss:0.00000, loss_test:0.01329, lr:2.36e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.439, tt:7885.514\n",
      "Ep:195, loss:0.00000, loss_test:0.01328, lr:2.33e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.442, tt:7926.677\n",
      "Ep:196, loss:0.00000, loss_test:0.01329, lr:2.31e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.448, tt:7968.293\n",
      "Ep:197, loss:0.00000, loss_test:0.01331, lr:2.29e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.460, tt:8011.166\n",
      "Ep:198, loss:0.00000, loss_test:0.01333, lr:2.26e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.463, tt:8052.143\n",
      "Ep:199, loss:0.00000, loss_test:0.01335, lr:2.24e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.470, tt:8093.938\n",
      "Ep:200, loss:0.00000, loss_test:0.01336, lr:2.22e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.478, tt:8136.037\n",
      "Ep:201, loss:0.00000, loss_test:0.01336, lr:2.20e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.480, tt:8176.935\n",
      "Ep:202, loss:0.00000, loss_test:0.01338, lr:2.17e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.488, tt:8219.015\n",
      "Ep:203, loss:0.00000, loss_test:0.01337, lr:2.15e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.496, tt:8261.106\n",
      "Ep:204, loss:0.00000, loss_test:0.01338, lr:2.13e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.501, tt:8302.633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.01340, lr:2.11e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.504, tt:8343.925\n",
      "Ep:206, loss:0.00000, loss_test:0.01342, lr:2.09e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.520, tt:8387.605\n",
      "Ep:207, loss:0.00000, loss_test:0.01343, lr:2.07e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.518, tt:8427.668\n",
      "Ep:208, loss:0.00000, loss_test:0.01344, lr:2.05e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.516, tt:8467.922\n",
      "Ep:209, loss:0.00000, loss_test:0.01345, lr:2.03e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.523, tt:8509.927\n",
      "Ep:210, loss:0.00000, loss_test:0.01344, lr:2.01e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.509, tt:8547.486\n",
      "Ep:211, loss:0.00000, loss_test:0.01345, lr:1.99e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.482, tt:8582.190\n",
      "Ep:212, loss:0.00000, loss_test:0.01347, lr:1.97e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.462, tt:8618.322\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14269, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:41.883, tt:41.883\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14080, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:41.848, tt:83.696\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13734, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:42.618, tt:127.855\n",
      "Ep:3, loss:0.00025, loss_test:0.13211, lr:1.00e-02, fs:0.63559 (r=0.862,p=0.503),  time:42.956, tt:171.822\n",
      "Ep:4, loss:0.00024, loss_test:0.12684, lr:1.00e-02, fs:0.59341 (r=0.621,p=0.568),  time:42.969, tt:214.845\n",
      "Ep:5, loss:0.00023, loss_test:0.12581, lr:1.00e-02, fs:0.56051 (r=0.506,p=0.629),  time:43.260, tt:259.560\n",
      "Ep:6, loss:0.00022, loss_test:0.12221, lr:1.00e-02, fs:0.57803 (r=0.575,p=0.581),  time:43.162, tt:302.135\n",
      "Ep:7, loss:0.00022, loss_test:0.11930, lr:1.00e-02, fs:0.65657 (r=0.747,p=0.586),  time:43.045, tt:344.363\n",
      "Ep:8, loss:0.00021, loss_test:0.11416, lr:1.00e-02, fs:0.67725 (r=0.736,p=0.627),  time:42.890, tt:386.007\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11281, lr:1.00e-02, fs:0.65060 (r=0.621,p=0.684),  time:42.982, tt:429.821\n",
      "Ep:10, loss:0.00019, loss_test:0.11035, lr:1.00e-02, fs:0.67485 (r=0.632,p=0.724),  time:42.930, tt:472.231\n",
      "Ep:11, loss:0.00019, loss_test:0.10513, lr:1.00e-02, fs:0.68966 (r=0.690,p=0.690),  time:42.892, tt:514.707\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10093, lr:1.00e-02, fs:0.71676 (r=0.713,p=0.721),  time:42.940, tt:558.221\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09805, lr:1.00e-02, fs:0.72393 (r=0.678,p=0.776),  time:43.007, tt:602.101\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.09430, lr:1.00e-02, fs:0.73939 (r=0.701,p=0.782),  time:43.006, tt:645.094\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09208, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:43.008, tt:688.133\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09019, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:43.038, tt:731.646\n",
      "Ep:17, loss:0.00015, loss_test:0.08792, lr:1.00e-02, fs:0.76023 (r=0.747,p=0.774),  time:43.021, tt:774.381\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08716, lr:1.00e-02, fs:0.72393 (r=0.678,p=0.776),  time:43.113, tt:819.139\n",
      "Ep:19, loss:0.00013, loss_test:0.08522, lr:1.00e-02, fs:0.77907 (r=0.770,p=0.788),  time:43.123, tt:862.450\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08453, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:43.142, tt:905.975\n",
      "Ep:21, loss:0.00012, loss_test:0.08443, lr:1.00e-02, fs:0.75294 (r=0.736,p=0.771),  time:43.228, tt:951.020\n",
      "Ep:22, loss:0.00012, loss_test:0.08372, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:43.292, tt:995.718\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08322, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:43.340, tt:1040.170\n",
      "Ep:24, loss:0.00011, loss_test:0.08278, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:43.444, tt:1086.089\n",
      "Ep:25, loss:0.00010, loss_test:0.08196, lr:1.00e-02, fs:0.80682 (r=0.816,p=0.798),  time:43.404, tt:1128.508\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.08196, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:43.401, tt:1171.832\n",
      "Ep:27, loss:0.00010, loss_test:0.08036, lr:1.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:43.398, tt:1215.158\n",
      "Ep:28, loss:0.00009, loss_test:0.08110, lr:1.00e-02, fs:0.80682 (r=0.816,p=0.798),  time:43.321, tt:1256.299\n",
      "Ep:29, loss:0.00009, loss_test:0.07947, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:43.254, tt:1297.610\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08119, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:43.305, tt:1342.450\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.07931, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:43.342, tt:1386.953\n",
      "Ep:32, loss:0.00008, loss_test:0.08067, lr:1.00e-02, fs:0.79310 (r=0.793,p=0.793),  time:43.324, tt:1429.678\n",
      "Ep:33, loss:0.00008, loss_test:0.07941, lr:1.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:43.323, tt:1472.980\n",
      "Ep:34, loss:0.00008, loss_test:0.08116, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:43.267, tt:1514.360\n",
      "Ep:35, loss:0.00007, loss_test:0.07941, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:43.238, tt:1556.555\n",
      "Ep:36, loss:0.00007, loss_test:0.08180, lr:1.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:43.233, tt:1599.639\n",
      "Ep:37, loss:0.00007, loss_test:0.08186, lr:1.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:43.241, tt:1643.141\n",
      "Ep:38, loss:0.00007, loss_test:0.08043, lr:1.00e-02, fs:0.77193 (r=0.759,p=0.786),  time:43.298, tt:1688.616\n",
      "Ep:39, loss:0.00006, loss_test:0.08266, lr:1.00e-02, fs:0.73418 (r=0.667,p=0.817),  time:43.271, tt:1730.851\n",
      "Ep:40, loss:0.00006, loss_test:0.08122, lr:1.00e-02, fs:0.77108 (r=0.736,p=0.810),  time:43.271, tt:1774.114\n",
      "Ep:41, loss:0.00006, loss_test:0.08237, lr:1.00e-02, fs:0.73885 (r=0.667,p=0.829),  time:43.227, tt:1815.539\n",
      "Ep:42, loss:0.00006, loss_test:0.08416, lr:9.90e-03, fs:0.73548 (r=0.655,p=0.838),  time:43.249, tt:1859.705\n",
      "Ep:43, loss:0.00005, loss_test:0.07963, lr:9.80e-03, fs:0.75000 (r=0.690,p=0.822),  time:43.265, tt:1903.655\n",
      "Ep:44, loss:0.00005, loss_test:0.08516, lr:9.70e-03, fs:0.72727 (r=0.644,p=0.836),  time:43.260, tt:1946.700\n",
      "Ep:45, loss:0.00005, loss_test:0.08074, lr:9.61e-03, fs:0.74359 (r=0.667,p=0.841),  time:43.256, tt:1989.793\n",
      "Ep:46, loss:0.00005, loss_test:0.08088, lr:9.51e-03, fs:0.76250 (r=0.701,p=0.836),  time:43.219, tt:2031.313\n",
      "Ep:47, loss:0.00005, loss_test:0.08217, lr:9.41e-03, fs:0.73548 (r=0.655,p=0.838),  time:43.239, tt:2075.476\n",
      "Ep:48, loss:0.00005, loss_test:0.08442, lr:9.32e-03, fs:0.75000 (r=0.655,p=0.877),  time:43.230, tt:2118.246\n",
      "Ep:49, loss:0.00004, loss_test:0.07899, lr:9.23e-03, fs:0.73548 (r=0.655,p=0.838),  time:43.221, tt:2161.028\n",
      "Ep:50, loss:0.00004, loss_test:0.08670, lr:9.14e-03, fs:0.72973 (r=0.621,p=0.885),  time:43.175, tt:2201.923\n",
      "Ep:51, loss:0.00004, loss_test:0.07751, lr:9.04e-03, fs:0.75472 (r=0.690,p=0.833),  time:43.119, tt:2242.186\n",
      "Ep:52, loss:0.00004, loss_test:0.08847, lr:8.95e-03, fs:0.72603 (r=0.609,p=0.898),  time:43.080, tt:2283.243\n",
      "Ep:53, loss:0.00004, loss_test:0.07654, lr:8.86e-03, fs:0.75949 (r=0.690,p=0.845),  time:43.104, tt:2327.594\n",
      "Ep:54, loss:0.00004, loss_test:0.08801, lr:8.78e-03, fs:0.72603 (r=0.609,p=0.898),  time:43.078, tt:2369.305\n",
      "Ep:55, loss:0.00004, loss_test:0.07836, lr:8.69e-03, fs:0.73203 (r=0.644,p=0.848),  time:43.076, tt:2412.279\n",
      "Ep:56, loss:0.00003, loss_test:0.08481, lr:8.60e-03, fs:0.73826 (r=0.632,p=0.887),  time:43.083, tt:2455.732\n",
      "Ep:57, loss:0.00003, loss_test:0.07998, lr:8.51e-03, fs:0.69388 (r=0.586,p=0.850),  time:43.083, tt:2498.815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00003, loss_test:0.08546, lr:8.43e-03, fs:0.72973 (r=0.621,p=0.885),  time:43.069, tt:2541.074\n",
      "Ep:59, loss:0.00003, loss_test:0.07817, lr:8.35e-03, fs:0.72848 (r=0.632,p=0.859),  time:43.074, tt:2584.433\n",
      "Ep:60, loss:0.00003, loss_test:0.08660, lr:8.26e-03, fs:0.71831 (r=0.586,p=0.927),  time:43.042, tt:2625.569\n",
      "Ep:61, loss:0.00003, loss_test:0.07929, lr:8.18e-03, fs:0.71141 (r=0.609,p=0.855),  time:43.042, tt:2668.584\n",
      "Ep:62, loss:0.00003, loss_test:0.08506, lr:8.10e-03, fs:0.71724 (r=0.598,p=0.897),  time:43.017, tt:2710.086\n",
      "Ep:63, loss:0.00003, loss_test:0.07964, lr:8.02e-03, fs:0.69863 (r=0.586,p=0.864),  time:42.991, tt:2751.406\n",
      "Ep:64, loss:0.00003, loss_test:0.08621, lr:7.94e-03, fs:0.68571 (r=0.552,p=0.906),  time:42.982, tt:2793.832\n",
      "Ep:65, loss:0.00003, loss_test:0.07915, lr:7.86e-03, fs:0.69863 (r=0.586,p=0.864),  time:42.991, tt:2837.431\n",
      "Ep:66, loss:0.00003, loss_test:0.08610, lr:7.78e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.967, tt:2878.814\n",
      "Ep:67, loss:0.00002, loss_test:0.08148, lr:7.70e-03, fs:0.69014 (r=0.563,p=0.891),  time:42.927, tt:2919.025\n",
      "Ep:68, loss:0.00002, loss_test:0.08517, lr:7.62e-03, fs:0.69504 (r=0.563,p=0.907),  time:42.909, tt:2960.704\n",
      "Ep:69, loss:0.00002, loss_test:0.08353, lr:7.55e-03, fs:0.69504 (r=0.563,p=0.907),  time:42.898, tt:3002.831\n",
      "Ep:70, loss:0.00002, loss_test:0.08507, lr:7.47e-03, fs:0.69504 (r=0.563,p=0.907),  time:42.901, tt:3045.939\n",
      "Ep:71, loss:0.00002, loss_test:0.08425, lr:7.40e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.900, tt:3088.778\n",
      "Ep:72, loss:0.00002, loss_test:0.08015, lr:7.32e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.916, tt:3132.868\n",
      "Ep:73, loss:0.00002, loss_test:0.08595, lr:7.25e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.903, tt:3174.811\n",
      "Ep:74, loss:0.00002, loss_test:0.08176, lr:7.18e-03, fs:0.69930 (r=0.575,p=0.893),  time:42.915, tt:3218.636\n",
      "Ep:75, loss:0.00002, loss_test:0.08560, lr:7.11e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.918, tt:3261.762\n",
      "Ep:76, loss:0.00002, loss_test:0.08536, lr:7.03e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.934, tt:3305.926\n",
      "Ep:77, loss:0.00002, loss_test:0.08121, lr:6.96e-03, fs:0.70833 (r=0.586,p=0.895),  time:42.947, tt:3349.841\n",
      "Ep:78, loss:0.00002, loss_test:0.08578, lr:6.89e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.957, tt:3393.619\n",
      "Ep:79, loss:0.00002, loss_test:0.08220, lr:6.83e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.974, tt:3437.954\n",
      "Ep:80, loss:0.00002, loss_test:0.08449, lr:6.76e-03, fs:0.69504 (r=0.563,p=0.907),  time:42.990, tt:3482.156\n",
      "Ep:81, loss:0.00002, loss_test:0.08665, lr:6.69e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.028, tt:3528.264\n",
      "Ep:82, loss:0.00002, loss_test:0.08330, lr:6.62e-03, fs:0.68085 (r=0.552,p=0.889),  time:43.041, tt:3572.366\n",
      "Ep:83, loss:0.00002, loss_test:0.08650, lr:6.56e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.059, tt:3616.973\n",
      "Ep:84, loss:0.00002, loss_test:0.08435, lr:6.49e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.064, tt:3660.476\n",
      "Ep:85, loss:0.00002, loss_test:0.08518, lr:6.43e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.093, tt:3705.963\n",
      "Ep:86, loss:0.00002, loss_test:0.08656, lr:6.36e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.097, tt:3749.439\n",
      "Ep:87, loss:0.00002, loss_test:0.08426, lr:6.30e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.082, tt:3791.173\n",
      "Ep:88, loss:0.00002, loss_test:0.08654, lr:6.24e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.088, tt:3834.805\n",
      "Ep:89, loss:0.00001, loss_test:0.08605, lr:6.17e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.119, tt:3880.695\n",
      "Ep:90, loss:0.00001, loss_test:0.08499, lr:6.11e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.114, tt:3923.399\n",
      "Ep:91, loss:0.00001, loss_test:0.08731, lr:6.05e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.134, tt:3968.335\n",
      "Ep:92, loss:0.00001, loss_test:0.08682, lr:5.99e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.118, tt:4010.014\n",
      "Ep:93, loss:0.00001, loss_test:0.08659, lr:5.93e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.119, tt:4053.232\n",
      "Ep:94, loss:0.00001, loss_test:0.08766, lr:5.87e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.134, tt:4097.751\n",
      "Ep:95, loss:0.00001, loss_test:0.08679, lr:5.81e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.177, tt:4144.988\n",
      "Ep:96, loss:0.00001, loss_test:0.08575, lr:5.75e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.162, tt:4186.721\n",
      "Ep:97, loss:0.00001, loss_test:0.08926, lr:5.70e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.150, tt:4228.660\n",
      "Ep:98, loss:0.00001, loss_test:0.08409, lr:5.64e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.154, tt:4272.208\n",
      "Ep:99, loss:0.00001, loss_test:0.08898, lr:5.58e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.135, tt:4313.480\n",
      "Ep:100, loss:0.00001, loss_test:0.08740, lr:5.53e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.128, tt:4355.958\n",
      "Ep:101, loss:0.00001, loss_test:0.08835, lr:5.47e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.115, tt:4397.769\n",
      "Ep:102, loss:0.00001, loss_test:0.08870, lr:5.42e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.098, tt:4439.081\n",
      "Ep:103, loss:0.00001, loss_test:0.08656, lr:5.36e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.057, tt:4477.909\n",
      "Ep:104, loss:0.00001, loss_test:0.08789, lr:5.31e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.065, tt:4521.800\n",
      "Ep:105, loss:0.00001, loss_test:0.08753, lr:5.26e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.051, tt:4563.371\n",
      "Ep:106, loss:0.00001, loss_test:0.08883, lr:5.20e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.043, tt:4605.627\n",
      "Ep:107, loss:0.00001, loss_test:0.08845, lr:5.15e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.035, tt:4647.750\n",
      "Ep:108, loss:0.00001, loss_test:0.08876, lr:5.10e-03, fs:0.67143 (r=0.540,p=0.887),  time:43.025, tt:4689.708\n",
      "Ep:109, loss:0.00001, loss_test:0.08866, lr:5.05e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.000, tt:4729.975\n",
      "Ep:110, loss:0.00001, loss_test:0.08728, lr:5.00e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.996, tt:4772.562\n",
      "Ep:111, loss:0.00001, loss_test:0.08973, lr:4.95e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.990, tt:4814.913\n",
      "Ep:112, loss:0.00001, loss_test:0.08985, lr:4.90e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.970, tt:4855.640\n",
      "Ep:113, loss:0.00001, loss_test:0.08564, lr:4.85e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.943, tt:4895.487\n",
      "Ep:114, loss:0.00001, loss_test:0.09145, lr:4.80e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.936, tt:4937.617\n",
      "Ep:115, loss:0.00001, loss_test:0.08776, lr:4.75e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.985, tt:4986.213\n",
      "Ep:116, loss:0.00001, loss_test:0.08870, lr:4.71e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.974, tt:5028.016\n",
      "Ep:117, loss:0.00001, loss_test:0.09178, lr:4.66e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.947, tt:5067.690\n",
      "Ep:118, loss:0.00001, loss_test:0.08680, lr:4.61e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.946, tt:5110.598\n",
      "Ep:119, loss:0.00001, loss_test:0.08912, lr:4.57e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.946, tt:5153.474\n",
      "Ep:120, loss:0.00001, loss_test:0.09027, lr:4.52e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.951, tt:5197.037\n",
      "Ep:121, loss:0.00001, loss_test:0.08765, lr:4.48e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.946, tt:5239.444\n",
      "Ep:122, loss:0.00001, loss_test:0.08955, lr:4.43e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.930, tt:5280.352\n",
      "Ep:123, loss:0.00001, loss_test:0.08952, lr:4.39e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.919, tt:5321.982\n",
      "Ep:124, loss:0.00001, loss_test:0.08649, lr:4.34e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.901, tt:5362.574\n",
      "Ep:125, loss:0.00001, loss_test:0.08986, lr:4.30e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.873, tt:5402.057\n",
      "Ep:126, loss:0.00001, loss_test:0.08941, lr:4.26e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.854, tt:5442.508\n",
      "Ep:127, loss:0.00001, loss_test:0.08680, lr:4.21e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.860, tt:5486.021\n",
      "Ep:128, loss:0.00001, loss_test:0.09051, lr:4.17e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.843, tt:5526.728\n",
      "Ep:129, loss:0.00001, loss_test:0.08916, lr:4.13e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.825, tt:5567.264\n",
      "Ep:130, loss:0.00001, loss_test:0.08656, lr:4.09e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.810, tt:5608.050\n",
      "Ep:131, loss:0.00001, loss_test:0.08975, lr:4.05e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.792, tt:5648.518\n",
      "Ep:132, loss:0.00001, loss_test:0.08843, lr:4.01e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.783, tt:5690.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.08831, lr:3.97e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.779, tt:5732.385\n",
      "Ep:134, loss:0.00001, loss_test:0.08896, lr:3.93e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.768, tt:5773.717\n",
      "Ep:135, loss:0.00001, loss_test:0.08854, lr:3.89e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.757, tt:5814.968\n",
      "Ep:136, loss:0.00001, loss_test:0.08751, lr:3.85e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.741, tt:5855.490\n",
      "Ep:137, loss:0.00001, loss_test:0.08979, lr:3.81e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.730, tt:5896.711\n",
      "Ep:138, loss:0.00001, loss_test:0.08780, lr:3.77e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.730, tt:5939.489\n",
      "Ep:139, loss:0.00001, loss_test:0.08905, lr:3.73e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.724, tt:5981.399\n",
      "Ep:140, loss:0.00001, loss_test:0.08888, lr:3.70e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.720, tt:6023.566\n",
      "Ep:141, loss:0.00001, loss_test:0.08843, lr:3.66e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.706, tt:6064.230\n",
      "Ep:142, loss:0.00001, loss_test:0.08897, lr:3.62e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.696, tt:6105.516\n",
      "Ep:143, loss:0.00001, loss_test:0.08778, lr:3.59e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.659, tt:6142.947\n",
      "Ep:144, loss:0.00001, loss_test:0.08934, lr:3.55e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.647, tt:6183.750\n",
      "Ep:145, loss:0.00001, loss_test:0.08826, lr:3.52e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.630, tt:6223.913\n",
      "Ep:146, loss:0.00001, loss_test:0.08931, lr:3.48e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.612, tt:6264.036\n",
      "Ep:147, loss:0.00001, loss_test:0.08959, lr:3.45e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.596, tt:6304.205\n",
      "Ep:148, loss:0.00001, loss_test:0.08824, lr:3.41e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.579, tt:6344.227\n",
      "Ep:149, loss:0.00001, loss_test:0.08940, lr:3.38e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.558, tt:6383.660\n",
      "Ep:150, loss:0.00001, loss_test:0.08810, lr:3.34e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.541, tt:6423.679\n",
      "Ep:151, loss:0.00001, loss_test:0.08970, lr:3.31e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.531, tt:6464.685\n",
      "Ep:152, loss:0.00001, loss_test:0.08882, lr:3.28e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.528, tt:6506.751\n",
      "Ep:153, loss:0.00001, loss_test:0.08897, lr:3.24e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.520, tt:6548.011\n",
      "Ep:154, loss:0.00001, loss_test:0.08903, lr:3.21e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.526, tt:6591.534\n",
      "Ep:155, loss:0.00001, loss_test:0.08850, lr:3.18e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.528, tt:6634.406\n",
      "Ep:156, loss:0.00001, loss_test:0.08943, lr:3.15e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.532, tt:6677.543\n",
      "Ep:157, loss:0.00001, loss_test:0.08878, lr:3.12e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.527, tt:6719.230\n",
      "Ep:158, loss:0.00001, loss_test:0.08920, lr:3.09e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.516, tt:6760.111\n",
      "Ep:159, loss:0.00001, loss_test:0.08933, lr:3.05e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.522, tt:6803.478\n",
      "Ep:160, loss:0.00001, loss_test:0.08923, lr:3.02e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.513, tt:6844.589\n",
      "Ep:161, loss:0.00001, loss_test:0.08898, lr:2.99e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.518, tt:6887.977\n",
      "Ep:162, loss:0.00001, loss_test:0.08944, lr:2.96e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.517, tt:6930.319\n",
      "Ep:163, loss:0.00001, loss_test:0.08949, lr:2.93e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.519, tt:6973.082\n",
      "Ep:164, loss:0.00001, loss_test:0.08907, lr:2.90e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.508, tt:7013.862\n",
      "Ep:165, loss:0.00001, loss_test:0.08939, lr:2.88e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.496, tt:7054.340\n",
      "Ep:166, loss:0.00001, loss_test:0.08903, lr:2.85e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.492, tt:7096.247\n",
      "Ep:167, loss:0.00001, loss_test:0.08911, lr:2.82e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.494, tt:7138.947\n",
      "Ep:168, loss:0.00001, loss_test:0.08910, lr:2.79e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.512, tt:7184.517\n",
      "Ep:169, loss:0.00001, loss_test:0.08892, lr:2.76e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.517, tt:7227.840\n",
      "Ep:170, loss:0.00001, loss_test:0.08918, lr:2.73e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.515, tt:7270.127\n",
      "Ep:171, loss:0.00001, loss_test:0.08967, lr:2.71e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.503, tt:7310.591\n",
      "Ep:172, loss:0.00001, loss_test:0.08911, lr:2.68e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.507, tt:7353.629\n",
      "Ep:173, loss:0.00001, loss_test:0.08999, lr:2.65e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.506, tt:7396.063\n",
      "Ep:174, loss:0.00001, loss_test:0.08919, lr:2.63e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.508, tt:7438.828\n",
      "Ep:175, loss:0.00001, loss_test:0.08981, lr:2.60e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.505, tt:7480.861\n",
      "Ep:176, loss:0.00001, loss_test:0.09070, lr:2.57e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.496, tt:7521.761\n",
      "Ep:177, loss:0.00001, loss_test:0.08929, lr:2.55e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.496, tt:7564.363\n",
      "Ep:178, loss:0.00001, loss_test:0.08951, lr:2.52e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.505, tt:7608.378\n",
      "Ep:179, loss:0.00001, loss_test:0.09047, lr:2.50e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.502, tt:7650.281\n",
      "Ep:180, loss:0.00001, loss_test:0.08989, lr:2.47e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.508, tt:7693.941\n",
      "Ep:181, loss:0.00001, loss_test:0.08922, lr:2.45e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.506, tt:7736.152\n",
      "Ep:182, loss:0.00001, loss_test:0.08946, lr:2.42e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.498, tt:7777.145\n",
      "Ep:183, loss:0.00001, loss_test:0.08968, lr:2.40e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.493, tt:7818.765\n",
      "Ep:184, loss:0.00001, loss_test:0.08976, lr:2.38e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.509, tt:7864.100\n",
      "Ep:185, loss:0.00001, loss_test:0.08995, lr:2.35e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.507, tt:7906.287\n",
      "Ep:186, loss:0.00001, loss_test:0.08975, lr:2.33e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.506, tt:7948.654\n",
      "Ep:187, loss:0.00001, loss_test:0.08977, lr:2.31e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.513, tt:7992.448\n",
      "Ep:188, loss:0.00001, loss_test:0.09026, lr:2.28e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.512, tt:8034.766\n",
      "Ep:189, loss:0.00001, loss_test:0.09002, lr:2.26e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.520, tt:8078.789\n",
      "Ep:190, loss:0.00001, loss_test:0.08969, lr:2.24e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.522, tt:8121.641\n",
      "Ep:191, loss:0.00001, loss_test:0.08981, lr:2.21e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.534, tt:8166.547\n",
      "Ep:192, loss:0.00001, loss_test:0.08958, lr:2.19e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.546, tt:8211.413\n",
      "Ep:193, loss:0.00001, loss_test:0.09036, lr:2.17e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.554, tt:8255.453\n",
      "Ep:194, loss:0.00001, loss_test:0.09103, lr:2.15e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.560, tt:8299.164\n",
      "Ep:195, loss:0.00001, loss_test:0.08971, lr:2.13e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.567, tt:8343.060\n",
      "Ep:196, loss:0.00001, loss_test:0.08953, lr:2.11e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.575, tt:8387.262\n",
      "Ep:197, loss:0.00001, loss_test:0.09059, lr:2.08e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.565, tt:8427.897\n",
      "Ep:198, loss:0.00001, loss_test:0.09038, lr:2.06e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.575, tt:8472.432\n",
      "Ep:199, loss:0.00001, loss_test:0.08897, lr:2.04e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.575, tt:8514.978\n",
      "Ep:200, loss:0.00001, loss_test:0.09080, lr:2.02e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.571, tt:8556.742\n",
      "Ep:201, loss:0.00001, loss_test:0.09102, lr:2.00e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.560, tt:8597.080\n",
      "Ep:202, loss:0.00001, loss_test:0.08974, lr:1.98e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.559, tt:8639.480\n",
      "Ep:203, loss:0.00001, loss_test:0.09024, lr:1.96e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.560, tt:8682.256\n",
      "Ep:204, loss:0.00001, loss_test:0.09094, lr:1.94e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.562, tt:8725.196\n",
      "Ep:205, loss:0.00001, loss_test:0.09008, lr:1.92e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.551, tt:8765.582\n",
      "Ep:206, loss:0.00001, loss_test:0.08905, lr:1.90e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.557, tt:8809.223\n",
      "Ep:207, loss:0.00001, loss_test:0.09058, lr:1.89e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.553, tt:8850.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00001, loss_test:0.09070, lr:1.87e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.534, tt:8889.680\n",
      "Ep:209, loss:0.00001, loss_test:0.09007, lr:1.85e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.521, tt:8929.363\n",
      "Ep:210, loss:0.00001, loss_test:0.08944, lr:1.83e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.492, tt:8965.722\n",
      "Ep:211, loss:0.00001, loss_test:0.09006, lr:1.81e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.431, tt:8995.290\n",
      "Ep:212, loss:0.00001, loss_test:0.09082, lr:1.79e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.369, tt:9024.578\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02141, lr:6.00e-02, fs:0.61033 (r=0.747,p=0.516),  time:38.051, tt:38.051\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02219, lr:6.00e-02, fs:0.65891 (r=0.977,p=0.497),  time:39.368, tt:78.736\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02264, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.659, tt:118.977\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02180, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:40.401, tt:161.606\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02076, lr:6.00e-02, fs:0.66135 (r=0.954,p=0.506),  time:40.069, tt:200.346\n",
      "Ep:5, loss:0.00004, loss_test:0.02051, lr:6.00e-02, fs:0.63964 (r=0.816,p=0.526),  time:39.929, tt:239.576\n",
      "Ep:6, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.64948 (r=0.724,p=0.589),  time:40.002, tt:280.014\n",
      "Ep:7, loss:0.00004, loss_test:0.02142, lr:6.00e-02, fs:0.63102 (r=0.678,p=0.590),  time:40.009, tt:320.073\n",
      "Ep:8, loss:0.00003, loss_test:0.02071, lr:6.00e-02, fs:0.67347 (r=0.759,p=0.606),  time:39.853, tt:358.681\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01985, lr:6.00e-02, fs:0.67943 (r=0.816,p=0.582),  time:39.909, tt:399.088\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01923, lr:6.00e-02, fs:0.70320 (r=0.885,p=0.583),  time:39.892, tt:438.817\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01880, lr:6.00e-02, fs:0.70968 (r=0.885,p=0.592),  time:39.727, tt:476.728\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01848, lr:6.00e-02, fs:0.70244 (r=0.828,p=0.610),  time:39.704, tt:516.146\n",
      "Ep:13, loss:0.00003, loss_test:0.01821, lr:6.00e-02, fs:0.71717 (r=0.816,p=0.640),  time:39.710, tt:555.942\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01780, lr:6.00e-02, fs:0.73469 (r=0.828,p=0.661),  time:39.635, tt:594.525\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.73846 (r=0.828,p=0.667),  time:39.672, tt:634.751\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01673, lr:6.00e-02, fs:0.73529 (r=0.862,p=0.641),  time:39.594, tt:673.095\n",
      "Ep:17, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.74510 (r=0.874,p=0.650),  time:39.540, tt:711.711\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.76238 (r=0.885,p=0.670),  time:39.534, tt:751.148\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.76768 (r=0.874,p=0.685),  time:39.536, tt:790.713\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.76768 (r=0.874,p=0.685),  time:39.493, tt:829.353\n",
      "Ep:21, loss:0.00002, loss_test:0.01545, lr:6.00e-02, fs:0.77551 (r=0.874,p=0.697),  time:39.514, tt:869.308\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.77157 (r=0.874,p=0.691),  time:39.589, tt:910.540\n",
      "Ep:23, loss:0.00002, loss_test:0.01488, lr:6.00e-02, fs:0.78173 (r=0.885,p=0.700),  time:39.581, tt:949.943\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01471, lr:6.00e-02, fs:0.79592 (r=0.897,p=0.716),  time:39.533, tt:988.324\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.78974 (r=0.885,p=0.713),  time:39.485, tt:1026.605\n",
      "Ep:26, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.78756 (r=0.874,p=0.717),  time:39.532, tt:1067.364\n",
      "Ep:27, loss:0.00002, loss_test:0.01432, lr:6.00e-02, fs:0.79381 (r=0.885,p=0.720),  time:39.506, tt:1106.159\n",
      "Ep:28, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.79167 (r=0.874,p=0.724),  time:39.515, tt:1145.930\n",
      "Ep:29, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.79581 (r=0.874,p=0.731),  time:39.494, tt:1184.806\n",
      "Ep:30, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.79581 (r=0.874,p=0.731),  time:39.470, tt:1223.565\n",
      "Ep:31, loss:0.00002, loss_test:0.01380, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:39.484, tt:1263.488\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:39.440, tt:1301.510\n",
      "Ep:33, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.80412 (r=0.897,p=0.729),  time:39.424, tt:1340.407\n",
      "Ep:34, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.83422 (r=0.897,p=0.780),  time:39.414, tt:1379.486\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.83422 (r=0.897,p=0.780),  time:39.419, tt:1419.098\n",
      "Ep:36, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.84656 (r=0.920,p=0.784),  time:39.444, tt:1459.435\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.84817 (r=0.931,p=0.779),  time:39.425, tt:1498.165\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:39.477, tt:1539.602\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.85714 (r=0.931,p=0.794),  time:39.470, tt:1578.809\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.85714 (r=0.931,p=0.794),  time:39.468, tt:1618.204\n",
      "Ep:41, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:39.464, tt:1657.487\n",
      "Ep:42, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:39.474, tt:1697.394\n",
      "Ep:43, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:39.500, tt:1738.017\n",
      "Ep:44, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:39.534, tt:1779.008\n",
      "Ep:45, loss:0.00001, loss_test:0.01286, lr:6.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:39.528, tt:1818.292\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01280, lr:6.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:39.573, tt:1859.941\n",
      "Ep:47, loss:0.00001, loss_test:0.01284, lr:6.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:39.630, tt:1902.240\n",
      "Ep:48, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:39.674, tt:1944.040\n",
      "Ep:49, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:39.663, tt:1983.158\n",
      "Ep:50, loss:0.00001, loss_test:0.01270, lr:6.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:39.649, tt:2022.122\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01275, lr:6.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.669, tt:2062.790\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.651, tt:2101.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00001, loss_test:0.01267, lr:6.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:39.681, tt:2142.767\n",
      "Ep:54, loss:0.00001, loss_test:0.01270, lr:6.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:39.698, tt:2183.365\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01264, lr:6.00e-02, fs:0.88649 (r=0.943,p=0.837),  time:39.712, tt:2223.890\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01269, lr:6.00e-02, fs:0.88649 (r=0.943,p=0.837),  time:39.717, tt:2263.890\n",
      "Ep:57, loss:0.00001, loss_test:0.01267, lr:6.00e-02, fs:0.88649 (r=0.943,p=0.837),  time:39.736, tt:2304.690\n",
      "Ep:58, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:39.781, tt:2347.082\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01267, lr:6.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:39.793, tt:2387.576\n",
      "Ep:60, loss:0.00001, loss_test:0.01270, lr:6.00e-02, fs:0.89011 (r=0.931,p=0.853),  time:39.832, tt:2429.769\n",
      "Ep:61, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.89011 (r=0.931,p=0.853),  time:39.863, tt:2471.489\n",
      "Ep:62, loss:0.00001, loss_test:0.01270, lr:6.00e-02, fs:0.89011 (r=0.931,p=0.853),  time:39.870, tt:2511.804\n",
      "Ep:63, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.89011 (r=0.931,p=0.853),  time:39.887, tt:2552.784\n",
      "Ep:64, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:39.888, tt:2592.716\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01274, lr:6.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:39.872, tt:2631.566\n",
      "Ep:66, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.90000 (r=0.931,p=0.871),  time:39.875, tt:2671.605\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01283, lr:6.00e-02, fs:0.88636 (r=0.897,p=0.876),  time:39.880, tt:2711.821\n",
      "Ep:68, loss:0.00001, loss_test:0.01283, lr:6.00e-02, fs:0.88636 (r=0.897,p=0.876),  time:39.871, tt:2751.118\n",
      "Ep:69, loss:0.00001, loss_test:0.01286, lr:6.00e-02, fs:0.88000 (r=0.885,p=0.875),  time:39.895, tt:2792.628\n",
      "Ep:70, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.88000 (r=0.885,p=0.875),  time:39.900, tt:2832.883\n",
      "Ep:71, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.88000 (r=0.885,p=0.875),  time:39.863, tt:2870.138\n",
      "Ep:72, loss:0.00001, loss_test:0.01297, lr:6.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:39.854, tt:2909.365\n",
      "Ep:73, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:39.869, tt:2950.334\n",
      "Ep:74, loss:0.00001, loss_test:0.01295, lr:6.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:39.896, tt:2992.178\n",
      "Ep:75, loss:0.00001, loss_test:0.01305, lr:6.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:39.903, tt:3032.635\n",
      "Ep:76, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:39.922, tt:3073.994\n",
      "Ep:77, loss:0.00001, loss_test:0.01303, lr:6.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:39.951, tt:3116.213\n",
      "Ep:78, loss:0.00001, loss_test:0.01312, lr:5.94e-02, fs:0.85380 (r=0.839,p=0.869),  time:39.964, tt:3157.120\n",
      "Ep:79, loss:0.00001, loss_test:0.01316, lr:5.88e-02, fs:0.85380 (r=0.839,p=0.869),  time:39.960, tt:3196.807\n",
      "Ep:80, loss:0.00001, loss_test:0.01317, lr:5.82e-02, fs:0.85882 (r=0.839,p=0.880),  time:39.960, tt:3236.735\n",
      "Ep:81, loss:0.00001, loss_test:0.01315, lr:5.76e-02, fs:0.85882 (r=0.839,p=0.880),  time:39.973, tt:3277.819\n",
      "Ep:82, loss:0.00001, loss_test:0.01322, lr:5.71e-02, fs:0.85882 (r=0.839,p=0.880),  time:39.998, tt:3319.846\n",
      "Ep:83, loss:0.00001, loss_test:0.01319, lr:5.65e-02, fs:0.85882 (r=0.839,p=0.880),  time:39.998, tt:3359.839\n",
      "Ep:84, loss:0.00001, loss_test:0.01322, lr:5.59e-02, fs:0.85882 (r=0.839,p=0.880),  time:39.993, tt:3399.423\n",
      "Ep:85, loss:0.00001, loss_test:0.01333, lr:5.54e-02, fs:0.85882 (r=0.839,p=0.880),  time:40.019, tt:3441.620\n",
      "Ep:86, loss:0.00001, loss_test:0.01337, lr:5.48e-02, fs:0.85207 (r=0.828,p=0.878),  time:40.007, tt:3480.589\n",
      "Ep:87, loss:0.00001, loss_test:0.01337, lr:5.43e-02, fs:0.85207 (r=0.828,p=0.878),  time:40.016, tt:3521.434\n",
      "Ep:88, loss:0.00001, loss_test:0.01340, lr:5.37e-02, fs:0.85207 (r=0.828,p=0.878),  time:40.030, tt:3562.681\n",
      "Ep:89, loss:0.00001, loss_test:0.01343, lr:5.32e-02, fs:0.85207 (r=0.828,p=0.878),  time:40.028, tt:3602.496\n",
      "Ep:90, loss:0.00001, loss_test:0.01339, lr:5.27e-02, fs:0.84524 (r=0.816,p=0.877),  time:40.028, tt:3642.507\n",
      "Ep:91, loss:0.00001, loss_test:0.01342, lr:5.21e-02, fs:0.85030 (r=0.816,p=0.887),  time:40.042, tt:3683.892\n",
      "Ep:92, loss:0.00001, loss_test:0.01349, lr:5.16e-02, fs:0.85030 (r=0.816,p=0.887),  time:40.070, tt:3726.544\n",
      "Ep:93, loss:0.00001, loss_test:0.01357, lr:5.11e-02, fs:0.85030 (r=0.816,p=0.887),  time:40.087, tt:3768.183\n",
      "Ep:94, loss:0.00001, loss_test:0.01355, lr:5.06e-02, fs:0.85030 (r=0.816,p=0.887),  time:40.099, tt:3809.382\n",
      "Ep:95, loss:0.00001, loss_test:0.01355, lr:5.01e-02, fs:0.84337 (r=0.805,p=0.886),  time:40.098, tt:3849.391\n",
      "Ep:96, loss:0.00001, loss_test:0.01360, lr:4.96e-02, fs:0.84337 (r=0.805,p=0.886),  time:40.107, tt:3890.347\n",
      "Ep:97, loss:0.00001, loss_test:0.01365, lr:4.91e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.111, tt:3930.830\n",
      "Ep:98, loss:0.00001, loss_test:0.01364, lr:4.86e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.107, tt:3970.604\n",
      "Ep:99, loss:0.00001, loss_test:0.01370, lr:4.81e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.117, tt:4011.656\n",
      "Ep:100, loss:0.00001, loss_test:0.01374, lr:4.76e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.114, tt:4051.516\n",
      "Ep:101, loss:0.00001, loss_test:0.01371, lr:4.71e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.121, tt:4092.355\n",
      "Ep:102, loss:0.00001, loss_test:0.01385, lr:4.67e-02, fs:0.80745 (r=0.747,p=0.878),  time:40.121, tt:4132.464\n",
      "Ep:103, loss:0.00001, loss_test:0.01384, lr:4.62e-02, fs:0.81481 (r=0.759,p=0.880),  time:40.122, tt:4172.738\n",
      "Ep:104, loss:0.00001, loss_test:0.01383, lr:4.57e-02, fs:0.80745 (r=0.747,p=0.878),  time:40.124, tt:4213.058\n",
      "Ep:105, loss:0.00001, loss_test:0.01394, lr:4.53e-02, fs:0.80000 (r=0.736,p=0.877),  time:40.127, tt:4253.431\n",
      "Ep:106, loss:0.00001, loss_test:0.01393, lr:4.48e-02, fs:0.80745 (r=0.747,p=0.878),  time:40.112, tt:4291.955\n",
      "Ep:107, loss:0.00001, loss_test:0.01389, lr:4.44e-02, fs:0.80745 (r=0.747,p=0.878),  time:40.103, tt:4331.097\n",
      "Ep:108, loss:0.00001, loss_test:0.01396, lr:4.39e-02, fs:0.80000 (r=0.736,p=0.877),  time:40.085, tt:4369.260\n",
      "Ep:109, loss:0.00001, loss_test:0.01400, lr:4.35e-02, fs:0.78481 (r=0.713,p=0.873),  time:40.095, tt:4410.454\n",
      "Ep:110, loss:0.00001, loss_test:0.01394, lr:4.31e-02, fs:0.80000 (r=0.736,p=0.877),  time:40.152, tt:4456.834\n",
      "Ep:111, loss:0.00001, loss_test:0.01407, lr:4.26e-02, fs:0.78481 (r=0.713,p=0.873),  time:40.171, tt:4499.117\n",
      "Ep:112, loss:0.00001, loss_test:0.01412, lr:4.22e-02, fs:0.78481 (r=0.713,p=0.873),  time:40.167, tt:4538.851\n",
      "Ep:113, loss:0.00001, loss_test:0.01407, lr:4.18e-02, fs:0.78481 (r=0.713,p=0.873),  time:40.175, tt:4579.902\n",
      "Ep:114, loss:0.00001, loss_test:0.01416, lr:4.14e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.183, tt:4621.016\n",
      "Ep:115, loss:0.00001, loss_test:0.01423, lr:4.10e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.202, tt:4663.378\n",
      "Ep:116, loss:0.00000, loss_test:0.01416, lr:4.05e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.235, tt:4707.493\n",
      "Ep:117, loss:0.00000, loss_test:0.01416, lr:4.01e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.256, tt:4750.161\n",
      "Ep:118, loss:0.00000, loss_test:0.01426, lr:3.97e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.278, tt:4793.037\n",
      "Ep:119, loss:0.00000, loss_test:0.01430, lr:3.93e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.284, tt:4834.075\n",
      "Ep:120, loss:0.00000, loss_test:0.01425, lr:3.89e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.296, tt:4875.875\n",
      "Ep:121, loss:0.00000, loss_test:0.01432, lr:3.86e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.302, tt:4916.801\n",
      "Ep:122, loss:0.00000, loss_test:0.01433, lr:3.82e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.326, tt:4960.098\n",
      "Ep:123, loss:0.00000, loss_test:0.01436, lr:3.78e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.335, tt:5001.505\n",
      "Ep:124, loss:0.00000, loss_test:0.01439, lr:3.74e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.341, tt:5042.652\n",
      "Ep:125, loss:0.00000, loss_test:0.01439, lr:3.70e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.359, tt:5085.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00000, loss_test:0.01446, lr:3.67e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.366, tt:5126.505\n",
      "Ep:127, loss:0.00000, loss_test:0.01446, lr:3.63e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.403, tt:5171.602\n",
      "Ep:128, loss:0.00000, loss_test:0.01446, lr:3.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.416, tt:5213.729\n",
      "Ep:129, loss:0.00000, loss_test:0.01450, lr:3.56e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.423, tt:5255.044\n",
      "Ep:130, loss:0.00000, loss_test:0.01452, lr:3.52e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.439, tt:5297.526\n",
      "Ep:131, loss:0.00000, loss_test:0.01455, lr:3.49e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.449, tt:5339.202\n",
      "Ep:132, loss:0.00000, loss_test:0.01455, lr:3.45e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.444, tt:5379.102\n",
      "Ep:133, loss:0.00000, loss_test:0.01463, lr:3.42e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.455, tt:5420.962\n",
      "Ep:134, loss:0.00000, loss_test:0.01463, lr:3.38e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.444, tt:5459.970\n",
      "Ep:135, loss:0.00000, loss_test:0.01466, lr:3.35e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.450, tt:5501.253\n",
      "Ep:136, loss:0.00000, loss_test:0.01463, lr:3.32e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.465, tt:5543.676\n",
      "Ep:137, loss:0.00000, loss_test:0.01468, lr:3.28e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.474, tt:5585.362\n",
      "Ep:138, loss:0.00000, loss_test:0.01472, lr:3.25e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.476, tt:5626.097\n",
      "Ep:139, loss:0.00000, loss_test:0.01471, lr:3.22e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.492, tt:5668.859\n",
      "Ep:140, loss:0.00000, loss_test:0.01474, lr:3.19e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.495, tt:5709.855\n",
      "Ep:141, loss:0.00000, loss_test:0.01477, lr:3.15e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.509, tt:5752.280\n",
      "Ep:142, loss:0.00000, loss_test:0.01478, lr:3.12e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.512, tt:5793.279\n",
      "Ep:143, loss:0.00000, loss_test:0.01479, lr:3.09e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.514, tt:5834.005\n",
      "Ep:144, loss:0.00000, loss_test:0.01479, lr:3.06e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.519, tt:5875.288\n",
      "Ep:145, loss:0.00000, loss_test:0.01483, lr:3.03e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.534, tt:5917.954\n",
      "Ep:146, loss:0.00000, loss_test:0.01486, lr:3.00e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.511, tt:5955.076\n",
      "Ep:147, loss:0.00000, loss_test:0.01488, lr:2.97e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.504, tt:5994.551\n",
      "Ep:148, loss:0.00000, loss_test:0.01485, lr:2.94e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.499, tt:6034.305\n",
      "Ep:149, loss:0.00000, loss_test:0.01489, lr:2.91e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.504, tt:6075.619\n",
      "Ep:150, loss:0.00000, loss_test:0.01493, lr:2.88e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.494, tt:6114.633\n",
      "Ep:151, loss:0.00000, loss_test:0.01492, lr:2.85e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.495, tt:6155.173\n",
      "Ep:152, loss:0.00000, loss_test:0.01489, lr:2.82e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.501, tt:6196.682\n",
      "Ep:153, loss:0.00000, loss_test:0.01499, lr:2.80e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.509, tt:6238.437\n",
      "Ep:154, loss:0.00000, loss_test:0.01503, lr:2.77e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.512, tt:6279.340\n",
      "Ep:155, loss:0.00000, loss_test:0.01501, lr:2.74e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.521, tt:6321.254\n",
      "Ep:156, loss:0.00000, loss_test:0.01500, lr:2.71e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.513, tt:6360.615\n",
      "Ep:157, loss:0.00000, loss_test:0.01505, lr:2.69e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.515, tt:6401.347\n",
      "Ep:158, loss:0.00000, loss_test:0.01507, lr:2.66e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.508, tt:6440.797\n",
      "Ep:159, loss:0.00000, loss_test:0.01504, lr:2.63e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.497, tt:6479.533\n",
      "Ep:160, loss:0.00000, loss_test:0.01506, lr:2.61e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.498, tt:6520.217\n",
      "Ep:161, loss:0.00000, loss_test:0.01510, lr:2.58e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.503, tt:6561.466\n",
      "Ep:162, loss:0.00000, loss_test:0.01509, lr:2.55e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.503, tt:6602.020\n",
      "Ep:163, loss:0.00000, loss_test:0.01514, lr:2.53e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.505, tt:6642.811\n",
      "Ep:164, loss:0.00000, loss_test:0.01516, lr:2.50e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.517, tt:6685.301\n",
      "Ep:165, loss:0.00000, loss_test:0.01513, lr:2.48e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.515, tt:6725.477\n",
      "Ep:166, loss:0.00000, loss_test:0.01516, lr:2.45e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.522, tt:6767.201\n",
      "Ep:167, loss:0.00000, loss_test:0.01520, lr:2.43e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.529, tt:6808.832\n",
      "Ep:168, loss:0.00000, loss_test:0.01523, lr:2.40e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.535, tt:6850.434\n",
      "Ep:169, loss:0.00000, loss_test:0.01522, lr:2.38e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.533, tt:6890.565\n",
      "Ep:170, loss:0.00000, loss_test:0.01520, lr:2.36e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.535, tt:6931.448\n",
      "Ep:171, loss:0.00000, loss_test:0.01526, lr:2.33e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.523, tt:6969.919\n",
      "Ep:172, loss:0.00000, loss_test:0.01529, lr:2.31e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.511, tt:7008.423\n",
      "Ep:173, loss:0.00000, loss_test:0.01524, lr:2.29e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.512, tt:7049.006\n",
      "Ep:174, loss:0.00000, loss_test:0.01528, lr:2.26e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.501, tt:7087.722\n",
      "Ep:175, loss:0.00000, loss_test:0.01532, lr:2.24e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.502, tt:7128.361\n",
      "Ep:176, loss:0.00000, loss_test:0.01531, lr:2.22e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.498, tt:7168.165\n",
      "Ep:177, loss:0.00000, loss_test:0.01532, lr:2.20e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.510, tt:7210.731\n",
      "Ep:178, loss:0.00000, loss_test:0.01534, lr:2.17e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.509, tt:7251.164\n",
      "Ep:179, loss:0.00000, loss_test:0.01534, lr:2.15e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.512, tt:7292.237\n",
      "Ep:180, loss:0.00000, loss_test:0.01536, lr:2.13e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.497, tt:7329.987\n",
      "Ep:181, loss:0.00000, loss_test:0.01539, lr:2.11e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.486, tt:7368.390\n",
      "Ep:182, loss:0.00000, loss_test:0.01540, lr:2.09e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.484, tt:7408.496\n",
      "Ep:183, loss:0.00000, loss_test:0.01541, lr:2.07e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.467, tt:7445.846\n",
      "Ep:184, loss:0.00000, loss_test:0.01542, lr:2.05e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.459, tt:7484.999\n",
      "Ep:185, loss:0.00000, loss_test:0.01541, lr:2.03e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.466, tt:7526.726\n",
      "Ep:186, loss:0.00000, loss_test:0.01542, lr:2.01e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.456, tt:7565.366\n",
      "Ep:187, loss:0.00000, loss_test:0.01546, lr:1.99e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.452, tt:7605.053\n",
      "Ep:188, loss:0.00000, loss_test:0.01547, lr:1.97e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.462, tt:7647.283\n",
      "Ep:189, loss:0.00000, loss_test:0.01547, lr:1.95e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.464, tt:7688.162\n",
      "Ep:190, loss:0.00000, loss_test:0.01548, lr:1.93e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.465, tt:7728.859\n",
      "Ep:191, loss:0.00000, loss_test:0.01551, lr:1.91e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.466, tt:7769.510\n",
      "Ep:192, loss:0.00000, loss_test:0.01550, lr:1.89e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.468, tt:7810.285\n",
      "Ep:193, loss:0.00000, loss_test:0.01550, lr:1.87e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.468, tt:7850.712\n",
      "Ep:194, loss:0.00000, loss_test:0.01556, lr:1.85e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.466, tt:7890.962\n",
      "Ep:195, loss:0.00000, loss_test:0.01554, lr:1.83e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.465, tt:7931.166\n",
      "Ep:196, loss:0.00000, loss_test:0.01557, lr:1.81e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.473, tt:7973.087\n",
      "Ep:197, loss:0.00000, loss_test:0.01557, lr:1.80e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.481, tt:8015.163\n",
      "Ep:198, loss:0.00000, loss_test:0.01557, lr:1.78e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.493, tt:8058.033\n",
      "Ep:199, loss:0.00000, loss_test:0.01557, lr:1.76e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.496, tt:8099.270\n",
      "Ep:200, loss:0.00000, loss_test:0.01559, lr:1.74e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.501, tt:8140.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:201, loss:0.00000, loss_test:0.01561, lr:1.73e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.492, tt:8179.350\n",
      "Ep:202, loss:0.00000, loss_test:0.01562, lr:1.71e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.493, tt:8220.125\n",
      "Ep:203, loss:0.00000, loss_test:0.01564, lr:1.69e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.493, tt:8260.623\n",
      "Ep:204, loss:0.00000, loss_test:0.01565, lr:1.67e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.490, tt:8300.475\n",
      "Ep:205, loss:0.00000, loss_test:0.01565, lr:1.66e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.490, tt:8341.038\n",
      "Ep:206, loss:0.00000, loss_test:0.01564, lr:1.64e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.499, tt:8383.322\n",
      "Ep:207, loss:0.00000, loss_test:0.01565, lr:1.62e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.502, tt:8424.341\n",
      "Ep:208, loss:0.00000, loss_test:0.01567, lr:1.61e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.503, tt:8465.129\n",
      "Ep:209, loss:0.00000, loss_test:0.01570, lr:1.59e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.474, tt:8499.479\n",
      "Ep:210, loss:0.00000, loss_test:0.01568, lr:1.58e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.457, tt:8536.395\n",
      "Ep:211, loss:0.00000, loss_test:0.01570, lr:1.56e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.430, tt:8571.071\n",
      "Ep:212, loss:0.00000, loss_test:0.01571, lr:1.54e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.408, tt:8606.854\n",
      "Ep:213, loss:0.00000, loss_test:0.01570, lr:1.53e-02, fs:0.76316 (r=0.667,p=0.892),  time:40.385, tt:8642.330\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13986, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:41.807, tt:41.807\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13730, lr:1.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:41.639, tt:83.279\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13248, lr:1.00e-02, fs:0.66129 (r=0.943,p=0.509),  time:41.562, tt:124.686\n",
      "Ep:3, loss:0.00025, loss_test:0.12732, lr:1.00e-02, fs:0.65455 (r=0.828,p=0.541),  time:41.805, tt:167.221\n",
      "Ep:4, loss:0.00023, loss_test:0.12396, lr:1.00e-02, fs:0.60963 (r=0.655,p=0.570),  time:41.524, tt:207.620\n",
      "Ep:5, loss:0.00023, loss_test:0.12206, lr:1.00e-02, fs:0.61364 (r=0.621,p=0.607),  time:41.116, tt:246.696\n",
      "Ep:6, loss:0.00022, loss_test:0.11871, lr:1.00e-02, fs:0.64444 (r=0.667,p=0.624),  time:41.332, tt:289.326\n",
      "Ep:7, loss:0.00022, loss_test:0.11608, lr:1.00e-02, fs:0.66304 (r=0.701,p=0.629),  time:41.465, tt:331.718\n",
      "Ep:8, loss:0.00021, loss_test:0.11277, lr:1.00e-02, fs:0.64804 (r=0.667,p=0.630),  time:41.669, tt:375.018\n",
      "Ep:9, loss:0.00020, loss_test:0.11084, lr:1.00e-02, fs:0.65517 (r=0.655,p=0.655),  time:41.590, tt:415.904\n",
      "Ep:10, loss:0.00020, loss_test:0.10775, lr:1.00e-02, fs:0.66667 (r=0.678,p=0.656),  time:41.733, tt:459.066\n",
      "Ep:11, loss:0.00019, loss_test:0.10427, lr:1.00e-02, fs:0.67797 (r=0.690,p=0.667),  time:41.602, tt:499.229\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10252, lr:1.00e-02, fs:0.69767 (r=0.690,p=0.706),  time:41.803, tt:543.436\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09964, lr:1.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:41.836, tt:585.698\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09739, lr:1.00e-02, fs:0.73034 (r=0.747,p=0.714),  time:41.823, tt:627.339\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09469, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:41.794, tt:668.699\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09117, lr:1.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:41.709, tt:709.059\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08853, lr:1.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:41.735, tt:751.223\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08627, lr:1.00e-02, fs:0.79096 (r=0.805,p=0.778),  time:41.746, tt:793.171\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08501, lr:1.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:41.856, tt:837.110\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08384, lr:1.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:41.900, tt:879.891\n",
      "Ep:21, loss:0.00013, loss_test:0.08203, lr:1.00e-02, fs:0.85417 (r=0.943,p=0.781),  time:41.875, tt:921.257\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08125, lr:1.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:41.801, tt:961.416\n",
      "Ep:23, loss:0.00012, loss_test:0.07905, lr:1.00e-02, fs:0.86598 (r=0.966,p=0.785),  time:41.786, tt:1002.875\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07846, lr:1.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:41.766, tt:1044.146\n",
      "Ep:25, loss:0.00011, loss_test:0.07662, lr:1.00e-02, fs:0.88421 (r=0.966,p=0.816),  time:41.832, tt:1087.636\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07501, lr:1.00e-02, fs:0.89474 (r=0.977,p=0.825),  time:41.893, tt:1131.124\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07363, lr:1.00e-02, fs:0.90909 (r=0.977,p=0.850),  time:41.952, tt:1174.648\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07305, lr:1.00e-02, fs:0.90526 (r=0.989,p=0.835),  time:42.008, tt:1218.221\n",
      "Ep:29, loss:0.00010, loss_test:0.07223, lr:1.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:42.036, tt:1261.072\n",
      "Ep:30, loss:0.00009, loss_test:0.07097, lr:1.00e-02, fs:0.90155 (r=1.000,p=0.821),  time:42.034, tt:1303.061\n",
      "Ep:31, loss:0.00009, loss_test:0.07140, lr:1.00e-02, fs:0.90323 (r=0.966,p=0.848),  time:41.998, tt:1343.933\n",
      "Ep:32, loss:0.00009, loss_test:0.07006, lr:1.00e-02, fs:0.90426 (r=0.977,p=0.842),  time:41.998, tt:1385.932\n",
      "Ep:33, loss:0.00008, loss_test:0.07082, lr:1.00e-02, fs:0.89011 (r=0.931,p=0.853),  time:42.023, tt:1428.796\n",
      "Ep:34, loss:0.00008, loss_test:0.06969, lr:1.00e-02, fs:0.88889 (r=0.966,p=0.824),  time:42.130, tt:1474.537\n",
      "Ep:35, loss:0.00008, loss_test:0.07063, lr:1.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:42.100, tt:1515.592\n",
      "Ep:36, loss:0.00008, loss_test:0.06808, lr:1.00e-02, fs:0.89730 (r=0.954,p=0.847),  time:42.204, tt:1561.562\n",
      "Ep:37, loss:0.00007, loss_test:0.07197, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:42.215, tt:1604.158\n",
      "Ep:38, loss:0.00007, loss_test:0.06676, lr:1.00e-02, fs:0.87179 (r=0.977,p=0.787),  time:42.249, tt:1647.697\n",
      "Ep:39, loss:0.00007, loss_test:0.07067, lr:9.90e-03, fs:0.88764 (r=0.908,p=0.868),  time:42.204, tt:1688.144\n",
      "Ep:40, loss:0.00007, loss_test:0.06660, lr:9.80e-03, fs:0.91892 (r=0.977,p=0.867),  time:42.166, tt:1728.800\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.07040, lr:9.80e-03, fs:0.86857 (r=0.874,p=0.864),  time:42.129, tt:1769.417\n",
      "Ep:42, loss:0.00006, loss_test:0.06601, lr:9.80e-03, fs:0.88298 (r=0.954,p=0.822),  time:42.204, tt:1814.788\n",
      "Ep:43, loss:0.00006, loss_test:0.06798, lr:9.80e-03, fs:0.87356 (r=0.874,p=0.874),  time:42.207, tt:1857.095\n",
      "Ep:44, loss:0.00006, loss_test:0.06521, lr:9.80e-03, fs:0.88298 (r=0.954,p=0.822),  time:42.228, tt:1900.263\n",
      "Ep:45, loss:0.00006, loss_test:0.06607, lr:9.80e-03, fs:0.88764 (r=0.908,p=0.868),  time:42.227, tt:1942.430\n",
      "Ep:46, loss:0.00005, loss_test:0.06467, lr:9.80e-03, fs:0.90217 (r=0.954,p=0.856),  time:42.204, tt:1983.566\n",
      "Ep:47, loss:0.00005, loss_test:0.06561, lr:9.80e-03, fs:0.90395 (r=0.920,p=0.889),  time:42.209, tt:2026.037\n",
      "Ep:48, loss:0.00005, loss_test:0.06562, lr:9.80e-03, fs:0.89011 (r=0.931,p=0.853),  time:42.278, tt:2071.631\n",
      "Ep:49, loss:0.00005, loss_test:0.07127, lr:9.80e-03, fs:0.85207 (r=0.828,p=0.878),  time:42.285, tt:2114.271\n",
      "Ep:50, loss:0.00005, loss_test:0.06228, lr:9.80e-03, fs:0.90608 (r=0.943,p=0.872),  time:42.272, tt:2155.849\n",
      "Ep:51, loss:0.00005, loss_test:0.06690, lr:9.80e-03, fs:0.87356 (r=0.874,p=0.874),  time:42.246, tt:2196.788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00005, loss_test:0.06450, lr:9.70e-03, fs:0.88889 (r=0.920,p=0.860),  time:42.247, tt:2239.112\n",
      "Ep:53, loss:0.00005, loss_test:0.06356, lr:9.61e-03, fs:0.88889 (r=0.920,p=0.860),  time:42.284, tt:2283.331\n",
      "Ep:54, loss:0.00004, loss_test:0.06434, lr:9.51e-03, fs:0.90286 (r=0.908,p=0.898),  time:42.282, tt:2325.522\n",
      "Ep:55, loss:0.00004, loss_test:0.06278, lr:9.41e-03, fs:0.89011 (r=0.931,p=0.853),  time:42.290, tt:2368.234\n",
      "Ep:56, loss:0.00004, loss_test:0.06589, lr:9.32e-03, fs:0.86391 (r=0.839,p=0.890),  time:42.293, tt:2410.689\n",
      "Ep:57, loss:0.00004, loss_test:0.06339, lr:9.23e-03, fs:0.88764 (r=0.908,p=0.868),  time:42.309, tt:2453.912\n",
      "Ep:58, loss:0.00004, loss_test:0.06614, lr:9.14e-03, fs:0.84524 (r=0.816,p=0.877),  time:42.311, tt:2496.351\n",
      "Ep:59, loss:0.00004, loss_test:0.06402, lr:9.04e-03, fs:0.89143 (r=0.897,p=0.886),  time:42.322, tt:2539.298\n",
      "Ep:60, loss:0.00003, loss_test:0.06554, lr:8.95e-03, fs:0.83832 (r=0.805,p=0.875),  time:42.319, tt:2581.454\n",
      "Ep:61, loss:0.00003, loss_test:0.06490, lr:8.86e-03, fs:0.86364 (r=0.874,p=0.854),  time:42.341, tt:2625.129\n",
      "Ep:62, loss:0.00003, loss_test:0.06389, lr:8.78e-03, fs:0.86857 (r=0.874,p=0.864),  time:42.339, tt:2667.376\n",
      "Ep:63, loss:0.00003, loss_test:0.06381, lr:8.69e-03, fs:0.86550 (r=0.851,p=0.881),  time:42.346, tt:2710.170\n",
      "Ep:64, loss:0.00003, loss_test:0.06795, lr:8.60e-03, fs:0.81437 (r=0.782,p=0.850),  time:42.393, tt:2755.557\n",
      "Ep:65, loss:0.00003, loss_test:0.06339, lr:8.51e-03, fs:0.84706 (r=0.828,p=0.867),  time:42.410, tt:2799.060\n",
      "Ep:66, loss:0.00003, loss_test:0.06647, lr:8.43e-03, fs:0.83832 (r=0.805,p=0.875),  time:42.452, tt:2844.279\n",
      "Ep:67, loss:0.00003, loss_test:0.06442, lr:8.35e-03, fs:0.85714 (r=0.828,p=0.889),  time:42.456, tt:2886.992\n",
      "Ep:68, loss:0.00003, loss_test:0.06542, lr:8.26e-03, fs:0.85207 (r=0.828,p=0.878),  time:42.459, tt:2929.666\n",
      "Ep:69, loss:0.00003, loss_test:0.06494, lr:8.18e-03, fs:0.84337 (r=0.805,p=0.886),  time:42.492, tt:2974.446\n",
      "Ep:70, loss:0.00003, loss_test:0.06495, lr:8.10e-03, fs:0.84524 (r=0.816,p=0.877),  time:42.499, tt:3017.446\n",
      "Ep:71, loss:0.00003, loss_test:0.06611, lr:8.02e-03, fs:0.84337 (r=0.805,p=0.886),  time:42.518, tt:3061.312\n",
      "Ep:72, loss:0.00002, loss_test:0.06631, lr:7.94e-03, fs:0.83832 (r=0.805,p=0.875),  time:42.509, tt:3103.149\n",
      "Ep:73, loss:0.00002, loss_test:0.06663, lr:7.86e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.522, tt:3146.652\n",
      "Ep:74, loss:0.00002, loss_test:0.06682, lr:7.78e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.530, tt:3189.718\n",
      "Ep:75, loss:0.00002, loss_test:0.06633, lr:7.70e-03, fs:0.84337 (r=0.805,p=0.886),  time:42.540, tt:3233.020\n",
      "Ep:76, loss:0.00002, loss_test:0.06494, lr:7.62e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.527, tt:3274.575\n",
      "Ep:77, loss:0.00002, loss_test:0.07056, lr:7.55e-03, fs:0.81988 (r=0.759,p=0.892),  time:42.522, tt:3316.713\n",
      "Ep:78, loss:0.00002, loss_test:0.06537, lr:7.47e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.528, tt:3359.728\n",
      "Ep:79, loss:0.00002, loss_test:0.06996, lr:7.40e-03, fs:0.80000 (r=0.736,p=0.877),  time:42.513, tt:3401.016\n",
      "Ep:80, loss:0.00002, loss_test:0.06566, lr:7.32e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.522, tt:3444.319\n",
      "Ep:81, loss:0.00002, loss_test:0.07183, lr:7.25e-03, fs:0.79747 (r=0.724,p=0.887),  time:42.522, tt:3486.822\n",
      "Ep:82, loss:0.00002, loss_test:0.06431, lr:7.18e-03, fs:0.84337 (r=0.805,p=0.886),  time:42.515, tt:3528.752\n",
      "Ep:83, loss:0.00002, loss_test:0.07255, lr:7.11e-03, fs:0.81013 (r=0.736,p=0.901),  time:42.520, tt:3571.664\n",
      "Ep:84, loss:0.00002, loss_test:0.06515, lr:7.03e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.532, tt:3615.186\n",
      "Ep:85, loss:0.00002, loss_test:0.07281, lr:6.96e-03, fs:0.79747 (r=0.724,p=0.887),  time:42.539, tt:3658.340\n",
      "Ep:86, loss:0.00002, loss_test:0.06597, lr:6.89e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.538, tt:3700.804\n",
      "Ep:87, loss:0.00002, loss_test:0.07037, lr:6.83e-03, fs:0.79747 (r=0.724,p=0.887),  time:42.542, tt:3743.728\n",
      "Ep:88, loss:0.00002, loss_test:0.06647, lr:6.76e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.556, tt:3787.483\n",
      "Ep:89, loss:0.00002, loss_test:0.06957, lr:6.69e-03, fs:0.79747 (r=0.724,p=0.887),  time:42.546, tt:3829.162\n",
      "Ep:90, loss:0.00002, loss_test:0.06669, lr:6.62e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.551, tt:3872.143\n",
      "Ep:91, loss:0.00002, loss_test:0.06861, lr:6.56e-03, fs:0.84146 (r=0.793,p=0.896),  time:42.538, tt:3913.452\n",
      "Ep:92, loss:0.00002, loss_test:0.06708, lr:6.49e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.524, tt:3954.723\n",
      "Ep:93, loss:0.00002, loss_test:0.07206, lr:6.43e-03, fs:0.79747 (r=0.724,p=0.887),  time:42.498, tt:3994.815\n",
      "Ep:94, loss:0.00002, loss_test:0.06552, lr:6.36e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.485, tt:4036.058\n",
      "Ep:95, loss:0.00001, loss_test:0.07275, lr:6.30e-03, fs:0.81013 (r=0.736,p=0.901),  time:42.481, tt:4078.195\n",
      "Ep:96, loss:0.00001, loss_test:0.06570, lr:6.24e-03, fs:0.84848 (r=0.805,p=0.897),  time:42.474, tt:4119.991\n",
      "Ep:97, loss:0.00001, loss_test:0.07262, lr:6.17e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.471, tt:4162.117\n",
      "Ep:98, loss:0.00001, loss_test:0.06750, lr:6.11e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.463, tt:4203.809\n",
      "Ep:99, loss:0.00001, loss_test:0.06963, lr:6.05e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.470, tt:4246.964\n",
      "Ep:100, loss:0.00001, loss_test:0.06900, lr:5.99e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.454, tt:4287.870\n",
      "Ep:101, loss:0.00001, loss_test:0.06927, lr:5.93e-03, fs:0.84663 (r=0.793,p=0.908),  time:42.447, tt:4329.576\n",
      "Ep:102, loss:0.00001, loss_test:0.06882, lr:5.87e-03, fs:0.84663 (r=0.793,p=0.908),  time:42.428, tt:4370.103\n",
      "Ep:103, loss:0.00001, loss_test:0.06947, lr:5.81e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.441, tt:4413.845\n",
      "Ep:104, loss:0.00001, loss_test:0.06936, lr:5.75e-03, fs:0.84663 (r=0.793,p=0.908),  time:42.455, tt:4457.784\n",
      "Ep:105, loss:0.00001, loss_test:0.06922, lr:5.70e-03, fs:0.85366 (r=0.805,p=0.909),  time:42.448, tt:4499.461\n",
      "Ep:106, loss:0.00001, loss_test:0.07128, lr:5.64e-03, fs:0.84472 (r=0.782,p=0.919),  time:42.445, tt:4541.606\n",
      "Ep:107, loss:0.00001, loss_test:0.06808, lr:5.58e-03, fs:0.83951 (r=0.782,p=0.907),  time:42.413, tt:4580.566\n",
      "Ep:108, loss:0.00001, loss_test:0.07085, lr:5.53e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.398, tt:4621.434\n",
      "Ep:109, loss:0.00001, loss_test:0.07074, lr:5.47e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.359, tt:4659.537\n",
      "Ep:110, loss:0.00001, loss_test:0.06870, lr:5.42e-03, fs:0.81013 (r=0.736,p=0.901),  time:42.360, tt:4701.976\n",
      "Ep:111, loss:0.00001, loss_test:0.07159, lr:5.36e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.347, tt:4742.843\n",
      "Ep:112, loss:0.00001, loss_test:0.07067, lr:5.31e-03, fs:0.83750 (r=0.770,p=0.918),  time:42.328, tt:4783.026\n",
      "Ep:113, loss:0.00001, loss_test:0.06986, lr:5.26e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.324, tt:4824.941\n",
      "Ep:114, loss:0.00001, loss_test:0.07141, lr:5.20e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.320, tt:4866.833\n",
      "Ep:115, loss:0.00001, loss_test:0.07075, lr:5.15e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.304, tt:4907.312\n",
      "Ep:116, loss:0.00001, loss_test:0.07015, lr:5.10e-03, fs:0.84472 (r=0.782,p=0.919),  time:42.328, tt:4952.384\n",
      "Ep:117, loss:0.00001, loss_test:0.07065, lr:5.05e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.323, tt:4994.122\n",
      "Ep:118, loss:0.00001, loss_test:0.07059, lr:5.00e-03, fs:0.82278 (r=0.747,p=0.915),  time:42.328, tt:5037.036\n",
      "Ep:119, loss:0.00001, loss_test:0.07113, lr:4.95e-03, fs:0.82278 (r=0.747,p=0.915),  time:42.302, tt:5076.195\n",
      "Ep:120, loss:0.00001, loss_test:0.07101, lr:4.90e-03, fs:0.82278 (r=0.747,p=0.915),  time:42.310, tt:5119.473\n",
      "Ep:121, loss:0.00001, loss_test:0.07068, lr:4.85e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.299, tt:5160.419\n",
      "Ep:122, loss:0.00001, loss_test:0.07189, lr:4.80e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.296, tt:5202.399\n",
      "Ep:123, loss:0.00001, loss_test:0.07173, lr:4.75e-03, fs:0.83750 (r=0.770,p=0.918),  time:42.297, tt:5244.831\n",
      "Ep:124, loss:0.00001, loss_test:0.07186, lr:4.71e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.296, tt:5286.965\n",
      "Ep:125, loss:0.00001, loss_test:0.07096, lr:4.66e-03, fs:0.83019 (r=0.759,p=0.917),  time:42.304, tt:5330.299\n",
      "Ep:126, loss:0.00001, loss_test:0.07338, lr:4.61e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.298, tt:5371.841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00001, loss_test:0.07172, lr:4.57e-03, fs:0.84277 (r=0.770,p=0.931),  time:42.294, tt:5413.638\n",
      "Ep:128, loss:0.00001, loss_test:0.07295, lr:4.52e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.294, tt:5455.966\n",
      "Ep:129, loss:0.00001, loss_test:0.07207, lr:4.48e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.272, tt:5495.409\n",
      "Ep:130, loss:0.00001, loss_test:0.07271, lr:4.43e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.272, tt:5537.651\n",
      "Ep:131, loss:0.00001, loss_test:0.07225, lr:4.39e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.271, tt:5579.747\n",
      "Ep:132, loss:0.00001, loss_test:0.07303, lr:4.34e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.283, tt:5623.598\n",
      "Ep:133, loss:0.00001, loss_test:0.07260, lr:4.30e-03, fs:0.83019 (r=0.759,p=0.917),  time:42.286, tt:5666.304\n",
      "Ep:134, loss:0.00001, loss_test:0.07175, lr:4.26e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.282, tt:5708.061\n",
      "Ep:135, loss:0.00001, loss_test:0.07417, lr:4.21e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.287, tt:5751.012\n",
      "Ep:136, loss:0.00001, loss_test:0.07376, lr:4.17e-03, fs:0.83750 (r=0.770,p=0.918),  time:42.276, tt:5791.765\n",
      "Ep:137, loss:0.00001, loss_test:0.07357, lr:4.13e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.289, tt:5835.852\n",
      "Ep:138, loss:0.00001, loss_test:0.07287, lr:4.09e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.278, tt:5876.676\n",
      "Ep:139, loss:0.00001, loss_test:0.07261, lr:4.05e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.259, tt:5916.317\n",
      "Ep:140, loss:0.00001, loss_test:0.07329, lr:4.01e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.263, tt:5959.081\n",
      "Ep:141, loss:0.00001, loss_test:0.07292, lr:3.97e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.257, tt:6000.426\n",
      "Ep:142, loss:0.00001, loss_test:0.07374, lr:3.93e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.246, tt:6041.124\n",
      "Ep:143, loss:0.00001, loss_test:0.07407, lr:3.89e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.241, tt:6082.739\n",
      "Ep:144, loss:0.00001, loss_test:0.07346, lr:3.85e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.275, tt:6129.935\n",
      "Ep:145, loss:0.00001, loss_test:0.07374, lr:3.81e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.268, tt:6171.164\n",
      "Ep:146, loss:0.00001, loss_test:0.07449, lr:3.77e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.253, tt:6211.188\n",
      "Ep:147, loss:0.00001, loss_test:0.07358, lr:3.73e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.258, tt:6254.215\n",
      "Ep:148, loss:0.00001, loss_test:0.07430, lr:3.70e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.271, tt:6298.378\n",
      "Ep:149, loss:0.00001, loss_test:0.07318, lr:3.66e-03, fs:0.83019 (r=0.759,p=0.917),  time:42.269, tt:6340.325\n",
      "Ep:150, loss:0.00001, loss_test:0.07397, lr:3.62e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.276, tt:6383.716\n",
      "Ep:151, loss:0.00001, loss_test:0.07278, lr:3.59e-03, fs:0.85714 (r=0.793,p=0.932),  time:42.273, tt:6425.498\n",
      "Ep:152, loss:0.00001, loss_test:0.07546, lr:3.55e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.259, tt:6465.622\n",
      "Ep:153, loss:0.00001, loss_test:0.07533, lr:3.52e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.242, tt:6505.310\n",
      "Ep:154, loss:0.00001, loss_test:0.07343, lr:3.48e-03, fs:0.85000 (r=0.782,p=0.932),  time:42.237, tt:6546.693\n",
      "Ep:155, loss:0.00001, loss_test:0.07482, lr:3.45e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.246, tt:6590.336\n",
      "Ep:156, loss:0.00001, loss_test:0.07418, lr:3.41e-03, fs:0.85714 (r=0.793,p=0.932),  time:42.231, tt:6630.307\n",
      "Ep:157, loss:0.00001, loss_test:0.07572, lr:3.38e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.240, tt:6673.921\n",
      "Ep:158, loss:0.00001, loss_test:0.07422, lr:3.34e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.232, tt:6714.836\n",
      "Ep:159, loss:0.00001, loss_test:0.07371, lr:3.31e-03, fs:0.82278 (r=0.747,p=0.915),  time:42.222, tt:6755.509\n",
      "Ep:160, loss:0.00001, loss_test:0.07571, lr:3.28e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.228, tt:6798.672\n",
      "Ep:161, loss:0.00001, loss_test:0.07419, lr:3.24e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.233, tt:6841.756\n",
      "Ep:162, loss:0.00001, loss_test:0.07430, lr:3.21e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.235, tt:6884.242\n",
      "Ep:163, loss:0.00001, loss_test:0.07474, lr:3.18e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.235, tt:6926.561\n",
      "Ep:164, loss:0.00001, loss_test:0.07490, lr:3.15e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.262, tt:6973.165\n",
      "Ep:165, loss:0.00001, loss_test:0.07397, lr:3.12e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.263, tt:7015.699\n",
      "Ep:166, loss:0.00001, loss_test:0.07477, lr:3.09e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.262, tt:7057.787\n",
      "Ep:167, loss:0.00001, loss_test:0.07537, lr:3.05e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.253, tt:7098.507\n",
      "Ep:168, loss:0.00001, loss_test:0.07431, lr:3.02e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.268, tt:7143.345\n",
      "Ep:169, loss:0.00001, loss_test:0.07441, lr:2.99e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.270, tt:7185.917\n",
      "Ep:170, loss:0.00000, loss_test:0.07509, lr:2.96e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.268, tt:7227.877\n",
      "Ep:171, loss:0.00000, loss_test:0.07438, lr:2.93e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.259, tt:7268.550\n",
      "Ep:172, loss:0.00000, loss_test:0.07487, lr:2.90e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.255, tt:7310.050\n",
      "Ep:173, loss:0.00000, loss_test:0.07498, lr:2.88e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.249, tt:7351.288\n",
      "Ep:174, loss:0.00000, loss_test:0.07448, lr:2.85e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.248, tt:7393.469\n",
      "Ep:175, loss:0.00000, loss_test:0.07482, lr:2.82e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.248, tt:7435.607\n",
      "Ep:176, loss:0.00000, loss_test:0.07452, lr:2.79e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.251, tt:7478.363\n",
      "Ep:177, loss:0.00000, loss_test:0.07443, lr:2.76e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.246, tt:7519.865\n",
      "Ep:178, loss:0.00000, loss_test:0.07449, lr:2.73e-03, fs:0.82581 (r=0.736,p=0.941),  time:42.250, tt:7562.829\n",
      "Ep:179, loss:0.00000, loss_test:0.07529, lr:2.71e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.255, tt:7605.898\n",
      "Ep:180, loss:0.00000, loss_test:0.07494, lr:2.68e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.238, tt:7645.100\n",
      "Ep:181, loss:0.00000, loss_test:0.07508, lr:2.65e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.238, tt:7687.228\n",
      "Ep:182, loss:0.00000, loss_test:0.07585, lr:2.63e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.237, tt:7729.402\n",
      "Ep:183, loss:0.00000, loss_test:0.07519, lr:2.60e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.232, tt:7770.741\n",
      "Ep:184, loss:0.00000, loss_test:0.07544, lr:2.57e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.228, tt:7812.268\n",
      "Ep:185, loss:0.00000, loss_test:0.07502, lr:2.55e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.223, tt:7853.515\n",
      "Ep:186, loss:0.00000, loss_test:0.07488, lr:2.52e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.224, tt:7895.878\n",
      "Ep:187, loss:0.00000, loss_test:0.07533, lr:2.50e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.226, tt:7938.438\n",
      "Ep:188, loss:0.00000, loss_test:0.07481, lr:2.47e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.228, tt:7981.033\n",
      "Ep:189, loss:0.00000, loss_test:0.07437, lr:2.45e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.222, tt:8022.257\n",
      "Ep:190, loss:0.00000, loss_test:0.07505, lr:2.42e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.224, tt:8064.791\n",
      "Ep:191, loss:0.00000, loss_test:0.07498, lr:2.40e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.218, tt:8105.849\n",
      "Ep:192, loss:0.00000, loss_test:0.07478, lr:2.38e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.210, tt:8146.575\n",
      "Ep:193, loss:0.00000, loss_test:0.07539, lr:2.35e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.207, tt:8188.193\n",
      "Ep:194, loss:0.00000, loss_test:0.07505, lr:2.33e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.197, tt:8228.390\n",
      "Ep:195, loss:0.00000, loss_test:0.07559, lr:2.31e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.201, tt:8271.309\n",
      "Ep:196, loss:0.00000, loss_test:0.07587, lr:2.28e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.208, tt:8315.026\n",
      "Ep:197, loss:0.00000, loss_test:0.07519, lr:2.26e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.207, tt:8356.960\n",
      "Ep:198, loss:0.00000, loss_test:0.07522, lr:2.24e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.206, tt:8398.972\n",
      "Ep:199, loss:0.00000, loss_test:0.07516, lr:2.21e-03, fs:0.82581 (r=0.736,p=0.941),  time:42.203, tt:8440.541\n",
      "Ep:200, loss:0.00000, loss_test:0.07564, lr:2.19e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.190, tt:8480.120\n",
      "Ep:201, loss:0.00000, loss_test:0.07521, lr:2.17e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.184, tt:8521.068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00000, loss_test:0.07490, lr:2.15e-03, fs:0.82581 (r=0.736,p=0.941),  time:42.189, tt:8564.355\n",
      "Ep:203, loss:0.00000, loss_test:0.07601, lr:2.13e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.199, tt:8608.527\n",
      "Ep:204, loss:0.00000, loss_test:0.07558, lr:2.11e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.207, tt:8652.381\n",
      "Ep:205, loss:0.00000, loss_test:0.07480, lr:2.08e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.236, tt:8700.641\n",
      "Ep:206, loss:0.00000, loss_test:0.07534, lr:2.06e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.241, tt:8743.802\n",
      "Ep:207, loss:0.00000, loss_test:0.07583, lr:2.04e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.239, tt:8785.717\n",
      "Ep:208, loss:0.00000, loss_test:0.07536, lr:2.02e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.230, tt:8826.105\n",
      "Ep:209, loss:0.00000, loss_test:0.07470, lr:2.00e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.183, tt:8858.498\n",
      "Ep:210, loss:0.00000, loss_test:0.07611, lr:1.98e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.134, tt:8890.316\n",
      "Ep:211, loss:0.00000, loss_test:0.07632, lr:1.96e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.074, tt:8919.683\n",
      "Ep:212, loss:0.00000, loss_test:0.07550, lr:1.94e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.022, tt:8950.596\n",
      "Ep:213, loss:0.00000, loss_test:0.07536, lr:1.92e-03, fs:0.81818 (r=0.724,p=0.940),  time:41.989, tt:8985.731\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02189, lr:6.00e-02, fs:0.62222 (r=0.805,p=0.507),  time:41.396, tt:41.396\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02287, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:41.669, tt:83.338\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02348, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.592, tt:124.776\n",
      "Ep:3, loss:0.00004, loss_test:0.02272, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:41.738, tt:166.951\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02156, lr:6.00e-02, fs:0.67729 (r=0.977,p=0.518),  time:42.160, tt:210.798\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02093, lr:6.00e-02, fs:0.66667 (r=0.908,p=0.527),  time:41.957, tt:251.744\n",
      "Ep:6, loss:0.00004, loss_test:0.02110, lr:6.00e-02, fs:0.65403 (r=0.793,p=0.556),  time:41.950, tt:293.648\n",
      "Ep:7, loss:0.00004, loss_test:0.02093, lr:6.00e-02, fs:0.66337 (r=0.770,p=0.583),  time:42.140, tt:337.119\n",
      "Ep:8, loss:0.00004, loss_test:0.02016, lr:6.00e-02, fs:0.67633 (r=0.805,p=0.583),  time:41.976, tt:377.786\n",
      "Ep:9, loss:0.00003, loss_test:0.01960, lr:6.00e-02, fs:0.68468 (r=0.874,p=0.563),  time:42.177, tt:421.774\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01923, lr:6.00e-02, fs:0.67841 (r=0.885,p=0.550),  time:42.818, tt:471.001\n",
      "Ep:11, loss:0.00003, loss_test:0.01890, lr:6.00e-02, fs:0.69369 (r=0.885,p=0.570),  time:42.747, tt:512.959\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01859, lr:6.00e-02, fs:0.72986 (r=0.885,p=0.621),  time:42.812, tt:556.553\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01829, lr:6.00e-02, fs:0.74146 (r=0.874,p=0.644),  time:42.673, tt:597.429\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01785, lr:6.00e-02, fs:0.75000 (r=0.862,p=0.664),  time:42.759, tt:641.385\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.75000 (r=0.862,p=0.664),  time:42.580, tt:681.274\n",
      "Ep:16, loss:0.00003, loss_test:0.01681, lr:6.00e-02, fs:0.74146 (r=0.874,p=0.644),  time:42.523, tt:722.897\n",
      "Ep:17, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.74627 (r=0.862,p=0.658),  time:42.553, tt:765.956\n",
      "Ep:18, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.74747 (r=0.851,p=0.667),  time:42.590, tt:809.211\n",
      "Ep:19, loss:0.00003, loss_test:0.01595, lr:6.00e-02, fs:0.75510 (r=0.851,p=0.679),  time:42.594, tt:851.874\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.76289 (r=0.851,p=0.692),  time:42.582, tt:894.218\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.76684 (r=0.851,p=0.698),  time:42.636, tt:937.986\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.76684 (r=0.851,p=0.698),  time:42.625, tt:980.378\n",
      "Ep:23, loss:0.00002, loss_test:0.01504, lr:6.00e-02, fs:0.76684 (r=0.851,p=0.698),  time:42.602, tt:1022.451\n",
      "Ep:24, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.76289 (r=0.851,p=0.692),  time:42.714, tt:1067.857\n",
      "Ep:25, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.76289 (r=0.851,p=0.692),  time:42.650, tt:1108.905\n",
      "Ep:26, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.76042 (r=0.839,p=0.695),  time:42.693, tt:1152.703\n",
      "Ep:27, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.76440 (r=0.839,p=0.702),  time:42.744, tt:1196.846\n",
      "Ep:28, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.76042 (r=0.839,p=0.695),  time:42.764, tt:1240.149\n",
      "Ep:29, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.76042 (r=0.839,p=0.695),  time:42.818, tt:1284.550\n",
      "Ep:30, loss:0.00002, loss_test:0.01413, lr:6.00e-02, fs:0.76440 (r=0.839,p=0.702),  time:42.810, tt:1327.112\n",
      "Ep:31, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.77895 (r=0.851,p=0.718),  time:42.787, tt:1369.183\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.77249 (r=0.839,p=0.716),  time:42.792, tt:1412.120\n",
      "Ep:33, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:42.792, tt:1454.927\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:42.903, tt:1501.604\n",
      "Ep:35, loss:0.00002, loss_test:0.01375, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:42.830, tt:1541.879\n",
      "Ep:36, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.77660 (r=0.839,p=0.723),  time:42.760, tt:1582.126\n",
      "Ep:37, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:42.744, tt:1624.276\n",
      "Ep:38, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:42.706, tt:1665.523\n",
      "Ep:39, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:42.636, tt:1705.441\n",
      "Ep:40, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:42.631, tt:1747.878\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01337, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:42.629, tt:1790.410\n",
      "Ep:42, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:42.574, tt:1830.678\n",
      "Ep:43, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:42.574, tt:1873.248\n",
      "Ep:44, loss:0.00002, loss_test:0.01321, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:42.563, tt:1915.350\n",
      "Ep:45, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:42.562, tt:1957.857\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:42.604, tt:2002.400\n",
      "Ep:47, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:42.601, tt:2044.868\n",
      "Ep:48, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:42.591, tt:2086.935\n",
      "Ep:49, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:42.572, tt:2128.599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00001, loss_test:0.01320, lr:6.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:42.564, tt:2170.777\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01311, lr:6.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:42.589, tt:2214.644\n",
      "Ep:52, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:42.588, tt:2257.139\n",
      "Ep:53, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:42.548, tt:2297.586\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:42.530, tt:2339.165\n",
      "Ep:55, loss:0.00001, loss_test:0.01321, lr:6.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:42.563, tt:2383.520\n",
      "Ep:56, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:42.539, tt:2424.706\n",
      "Ep:57, loss:0.00001, loss_test:0.01303, lr:6.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:42.542, tt:2467.409\n",
      "Ep:58, loss:0.00001, loss_test:0.01307, lr:6.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:42.550, tt:2510.429\n",
      "Ep:59, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:42.550, tt:2552.991\n",
      "Ep:60, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:42.522, tt:2593.813\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01307, lr:6.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:42.531, tt:2636.916\n",
      "Ep:62, loss:0.00001, loss_test:0.01311, lr:6.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:42.520, tt:2678.751\n",
      "Ep:63, loss:0.00001, loss_test:0.01322, lr:6.00e-02, fs:0.80682 (r=0.816,p=0.798),  time:42.514, tt:2720.883\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01320, lr:6.00e-02, fs:0.80682 (r=0.816,p=0.798),  time:42.504, tt:2762.763\n",
      "Ep:65, loss:0.00001, loss_test:0.01325, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.468, tt:2802.870\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.450, tt:2844.145\n",
      "Ep:67, loss:0.00001, loss_test:0.01327, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.441, tt:2885.993\n",
      "Ep:68, loss:0.00001, loss_test:0.01328, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.437, tt:2928.122\n",
      "Ep:69, loss:0.00001, loss_test:0.01334, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.393, tt:2967.541\n",
      "Ep:70, loss:0.00001, loss_test:0.01329, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.446, tt:3013.662\n",
      "Ep:71, loss:0.00001, loss_test:0.01336, lr:6.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.430, tt:3054.993\n",
      "Ep:72, loss:0.00001, loss_test:0.01345, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.406, tt:3095.656\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01347, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.401, tt:3137.678\n",
      "Ep:74, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.379, tt:3178.439\n",
      "Ep:75, loss:0.00001, loss_test:0.01343, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.354, tt:3218.939\n",
      "Ep:76, loss:0.00001, loss_test:0.01359, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.354, tt:3261.291\n",
      "Ep:77, loss:0.00001, loss_test:0.01353, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.352, tt:3303.464\n",
      "Ep:78, loss:0.00001, loss_test:0.01362, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.318, tt:3343.103\n",
      "Ep:79, loss:0.00001, loss_test:0.01369, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.311, tt:3384.906\n",
      "Ep:80, loss:0.00001, loss_test:0.01369, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.312, tt:3427.285\n",
      "Ep:81, loss:0.00001, loss_test:0.01369, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:42.283, tt:3467.222\n",
      "Ep:82, loss:0.00001, loss_test:0.01380, lr:6.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:42.277, tt:3508.985\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01381, lr:6.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:42.290, tt:3552.321\n",
      "Ep:84, loss:0.00001, loss_test:0.01383, lr:6.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:42.299, tt:3595.436\n",
      "Ep:85, loss:0.00001, loss_test:0.01392, lr:6.00e-02, fs:0.81871 (r=0.805,p=0.833),  time:42.293, tt:3637.191\n",
      "Ep:86, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:42.287, tt:3678.978\n",
      "Ep:87, loss:0.00001, loss_test:0.01397, lr:6.00e-02, fs:0.81871 (r=0.805,p=0.833),  time:42.298, tt:3722.256\n",
      "Ep:88, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.81871 (r=0.805,p=0.833),  time:42.311, tt:3765.639\n",
      "Ep:89, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.81871 (r=0.805,p=0.833),  time:42.296, tt:3806.671\n",
      "Ep:90, loss:0.00001, loss_test:0.01404, lr:6.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:42.321, tt:3851.179\n",
      "Ep:91, loss:0.00001, loss_test:0.01403, lr:6.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:42.303, tt:3891.896\n",
      "Ep:92, loss:0.00001, loss_test:0.01420, lr:6.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:42.300, tt:3933.895\n",
      "Ep:93, loss:0.00001, loss_test:0.01430, lr:6.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:42.277, tt:3974.026\n",
      "Ep:94, loss:0.00001, loss_test:0.01428, lr:5.94e-02, fs:0.81176 (r=0.793,p=0.831),  time:42.282, tt:4016.745\n",
      "Ep:95, loss:0.00001, loss_test:0.01433, lr:5.88e-02, fs:0.79762 (r=0.770,p=0.827),  time:42.266, tt:4057.505\n",
      "Ep:96, loss:0.00001, loss_test:0.01437, lr:5.82e-02, fs:0.78313 (r=0.747,p=0.823),  time:42.277, tt:4100.912\n",
      "Ep:97, loss:0.00001, loss_test:0.01443, lr:5.76e-02, fs:0.79518 (r=0.759,p=0.835),  time:42.277, tt:4143.191\n",
      "Ep:98, loss:0.00001, loss_test:0.01455, lr:5.71e-02, fs:0.78049 (r=0.736,p=0.831),  time:42.270, tt:4184.730\n",
      "Ep:99, loss:0.00001, loss_test:0.01448, lr:5.65e-02, fs:0.78049 (r=0.736,p=0.831),  time:42.283, tt:4228.297\n",
      "Ep:100, loss:0.00001, loss_test:0.01450, lr:5.59e-02, fs:0.77301 (r=0.724,p=0.829),  time:42.267, tt:4268.948\n",
      "Ep:101, loss:0.00001, loss_test:0.01462, lr:5.54e-02, fs:0.77301 (r=0.724,p=0.829),  time:42.258, tt:4310.346\n",
      "Ep:102, loss:0.00001, loss_test:0.01462, lr:5.48e-02, fs:0.76543 (r=0.713,p=0.827),  time:42.241, tt:4350.827\n",
      "Ep:103, loss:0.00001, loss_test:0.01466, lr:5.43e-02, fs:0.75776 (r=0.701,p=0.824),  time:42.227, tt:4391.590\n",
      "Ep:104, loss:0.00001, loss_test:0.01472, lr:5.37e-02, fs:0.75000 (r=0.690,p=0.822),  time:42.202, tt:4431.180\n",
      "Ep:105, loss:0.00001, loss_test:0.01468, lr:5.32e-02, fs:0.74534 (r=0.690,p=0.811),  time:42.185, tt:4471.611\n",
      "Ep:106, loss:0.00001, loss_test:0.01472, lr:5.27e-02, fs:0.75000 (r=0.690,p=0.822),  time:42.175, tt:4512.745\n",
      "Ep:107, loss:0.00001, loss_test:0.01486, lr:5.21e-02, fs:0.75000 (r=0.690,p=0.822),  time:42.149, tt:4552.100\n",
      "Ep:108, loss:0.00001, loss_test:0.01489, lr:5.16e-02, fs:0.75472 (r=0.690,p=0.833),  time:42.137, tt:4592.886\n",
      "Ep:109, loss:0.00001, loss_test:0.01488, lr:5.11e-02, fs:0.75472 (r=0.690,p=0.833),  time:42.131, tt:4634.454\n",
      "Ep:110, loss:0.00001, loss_test:0.01496, lr:5.06e-02, fs:0.74684 (r=0.678,p=0.831),  time:42.128, tt:4676.206\n",
      "Ep:111, loss:0.00001, loss_test:0.01489, lr:5.01e-02, fs:0.74684 (r=0.678,p=0.831),  time:42.125, tt:4718.009\n",
      "Ep:112, loss:0.00000, loss_test:0.01502, lr:4.96e-02, fs:0.74684 (r=0.678,p=0.831),  time:42.132, tt:4760.859\n",
      "Ep:113, loss:0.00000, loss_test:0.01506, lr:4.91e-02, fs:0.74684 (r=0.678,p=0.831),  time:42.127, tt:4802.505\n",
      "Ep:114, loss:0.00000, loss_test:0.01507, lr:4.86e-02, fs:0.74684 (r=0.678,p=0.831),  time:42.130, tt:4844.912\n",
      "Ep:115, loss:0.00000, loss_test:0.01507, lr:4.81e-02, fs:0.74214 (r=0.678,p=0.819),  time:42.123, tt:4886.250\n",
      "Ep:116, loss:0.00000, loss_test:0.01509, lr:4.76e-02, fs:0.74684 (r=0.678,p=0.831),  time:42.123, tt:4928.342\n",
      "Ep:117, loss:0.00000, loss_test:0.01518, lr:4.71e-02, fs:0.73885 (r=0.667,p=0.829),  time:42.119, tt:4970.069\n",
      "Ep:118, loss:0.00000, loss_test:0.01523, lr:4.67e-02, fs:0.73885 (r=0.667,p=0.829),  time:42.115, tt:5011.722\n",
      "Ep:119, loss:0.00000, loss_test:0.01524, lr:4.62e-02, fs:0.73885 (r=0.667,p=0.829),  time:42.111, tt:5053.333\n",
      "Ep:120, loss:0.00000, loss_test:0.01523, lr:4.57e-02, fs:0.73418 (r=0.667,p=0.817),  time:42.114, tt:5095.767\n",
      "Ep:121, loss:0.00000, loss_test:0.01525, lr:4.53e-02, fs:0.73418 (r=0.667,p=0.817),  time:42.095, tt:5135.623\n",
      "Ep:122, loss:0.00000, loss_test:0.01531, lr:4.48e-02, fs:0.73418 (r=0.667,p=0.817),  time:42.098, tt:5178.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00000, loss_test:0.01532, lr:4.44e-02, fs:0.72611 (r=0.655,p=0.814),  time:42.097, tt:5220.030\n",
      "Ep:124, loss:0.00000, loss_test:0.01541, lr:4.39e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.102, tt:5262.797\n",
      "Ep:125, loss:0.00000, loss_test:0.01545, lr:4.35e-02, fs:0.73077 (r=0.655,p=0.826),  time:42.116, tt:5306.554\n",
      "Ep:126, loss:0.00000, loss_test:0.01543, lr:4.31e-02, fs:0.73077 (r=0.655,p=0.826),  time:42.113, tt:5348.369\n",
      "Ep:127, loss:0.00000, loss_test:0.01546, lr:4.26e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.114, tt:5390.632\n",
      "Ep:128, loss:0.00000, loss_test:0.01542, lr:4.22e-02, fs:0.72611 (r=0.655,p=0.814),  time:42.101, tt:5430.996\n",
      "Ep:129, loss:0.00000, loss_test:0.01550, lr:4.18e-02, fs:0.72611 (r=0.655,p=0.814),  time:42.103, tt:5473.366\n",
      "Ep:130, loss:0.00000, loss_test:0.01548, lr:4.14e-02, fs:0.73077 (r=0.655,p=0.826),  time:42.101, tt:5515.181\n",
      "Ep:131, loss:0.00000, loss_test:0.01554, lr:4.10e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.120, tt:5559.904\n",
      "Ep:132, loss:0.00000, loss_test:0.01561, lr:4.05e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.114, tt:5601.138\n",
      "Ep:133, loss:0.00000, loss_test:0.01563, lr:4.01e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.124, tt:5644.582\n",
      "Ep:134, loss:0.00000, loss_test:0.01567, lr:3.97e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.121, tt:5686.301\n",
      "Ep:135, loss:0.00000, loss_test:0.01566, lr:3.93e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.108, tt:5726.641\n",
      "Ep:136, loss:0.00000, loss_test:0.01569, lr:3.89e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.102, tt:5768.033\n",
      "Ep:137, loss:0.00000, loss_test:0.01575, lr:3.86e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.096, tt:5809.300\n",
      "Ep:138, loss:0.00000, loss_test:0.01570, lr:3.82e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.077, tt:5848.706\n",
      "Ep:139, loss:0.00000, loss_test:0.01572, lr:3.78e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.089, tt:5892.414\n",
      "Ep:140, loss:0.00000, loss_test:0.01577, lr:3.74e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.088, tt:5934.465\n",
      "Ep:141, loss:0.00000, loss_test:0.01579, lr:3.70e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.100, tt:5978.177\n",
      "Ep:142, loss:0.00000, loss_test:0.01579, lr:3.67e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.103, tt:6020.768\n",
      "Ep:143, loss:0.00000, loss_test:0.01590, lr:3.63e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.105, tt:6063.175\n",
      "Ep:144, loss:0.00000, loss_test:0.01588, lr:3.59e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.103, tt:6104.988\n",
      "Ep:145, loss:0.00000, loss_test:0.01588, lr:3.56e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.091, tt:6145.355\n",
      "Ep:146, loss:0.00000, loss_test:0.01592, lr:3.52e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.090, tt:6187.247\n",
      "Ep:147, loss:0.00000, loss_test:0.01593, lr:3.49e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.091, tt:6229.534\n",
      "Ep:148, loss:0.00000, loss_test:0.01593, lr:3.45e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.094, tt:6272.013\n",
      "Ep:149, loss:0.00000, loss_test:0.01593, lr:3.42e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.095, tt:6314.297\n",
      "Ep:150, loss:0.00000, loss_test:0.01596, lr:3.38e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.098, tt:6356.821\n",
      "Ep:151, loss:0.00000, loss_test:0.01600, lr:3.35e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.102, tt:6399.508\n",
      "Ep:152, loss:0.00000, loss_test:0.01596, lr:3.32e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.095, tt:6440.563\n",
      "Ep:153, loss:0.00000, loss_test:0.01599, lr:3.28e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.104, tt:6484.006\n",
      "Ep:154, loss:0.00000, loss_test:0.01605, lr:3.25e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.117, tt:6528.085\n",
      "Ep:155, loss:0.00000, loss_test:0.01602, lr:3.22e-02, fs:0.74026 (r=0.655,p=0.851),  time:42.138, tt:6573.492\n",
      "Ep:156, loss:0.00000, loss_test:0.01606, lr:3.19e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.147, tt:6617.147\n",
      "Ep:157, loss:0.00000, loss_test:0.01610, lr:3.15e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.151, tt:6659.907\n",
      "Ep:158, loss:0.00000, loss_test:0.01610, lr:3.12e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.159, tt:6703.287\n",
      "Ep:159, loss:0.00000, loss_test:0.01609, lr:3.09e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.172, tt:6747.570\n",
      "Ep:160, loss:0.00000, loss_test:0.01610, lr:3.06e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.181, tt:6791.206\n",
      "Ep:161, loss:0.00000, loss_test:0.01611, lr:3.03e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.188, tt:6834.388\n",
      "Ep:162, loss:0.00000, loss_test:0.01615, lr:3.00e-02, fs:0.72368 (r=0.632,p=0.846),  time:42.197, tt:6878.190\n",
      "Ep:163, loss:0.00000, loss_test:0.01621, lr:2.97e-02, fs:0.70667 (r=0.609,p=0.841),  time:42.215, tt:6923.217\n",
      "Ep:164, loss:0.00000, loss_test:0.01620, lr:2.94e-02, fs:0.72368 (r=0.632,p=0.846),  time:42.214, tt:6965.288\n",
      "Ep:165, loss:0.00000, loss_test:0.01618, lr:2.91e-02, fs:0.71523 (r=0.621,p=0.844),  time:42.230, tt:7010.138\n",
      "Ep:166, loss:0.00000, loss_test:0.01622, lr:2.88e-02, fs:0.70667 (r=0.609,p=0.841),  time:42.245, tt:7054.844\n",
      "Ep:167, loss:0.00000, loss_test:0.01623, lr:2.85e-02, fs:0.70667 (r=0.609,p=0.841),  time:42.259, tt:7099.432\n",
      "Ep:168, loss:0.00000, loss_test:0.01625, lr:2.82e-02, fs:0.71523 (r=0.621,p=0.844),  time:42.272, tt:7144.022\n",
      "Ep:169, loss:0.00000, loss_test:0.01627, lr:2.80e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.280, tt:7187.657\n",
      "Ep:170, loss:0.00000, loss_test:0.01625, lr:2.77e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.288, tt:7231.248\n",
      "Ep:171, loss:0.00000, loss_test:0.01631, lr:2.74e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.303, tt:7276.068\n",
      "Ep:172, loss:0.00000, loss_test:0.01633, lr:2.71e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.294, tt:7316.846\n",
      "Ep:173, loss:0.00000, loss_test:0.01632, lr:2.69e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.300, tt:7360.113\n",
      "Ep:174, loss:0.00000, loss_test:0.01634, lr:2.66e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.301, tt:7402.663\n",
      "Ep:175, loss:0.00000, loss_test:0.01637, lr:2.63e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.315, tt:7447.378\n",
      "Ep:176, loss:0.00000, loss_test:0.01637, lr:2.61e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.311, tt:7489.090\n",
      "Ep:177, loss:0.00000, loss_test:0.01636, lr:2.58e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.317, tt:7532.389\n",
      "Ep:178, loss:0.00000, loss_test:0.01639, lr:2.55e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.323, tt:7575.887\n",
      "Ep:179, loss:0.00000, loss_test:0.01641, lr:2.53e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.329, tt:7619.138\n",
      "Ep:180, loss:0.00000, loss_test:0.01641, lr:2.50e-02, fs:0.70748 (r=0.598,p=0.867),  time:42.321, tt:7660.111\n",
      "Ep:181, loss:0.00000, loss_test:0.01641, lr:2.48e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.321, tt:7702.371\n",
      "Ep:182, loss:0.00000, loss_test:0.01641, lr:2.45e-02, fs:0.70748 (r=0.598,p=0.867),  time:42.322, tt:7744.862\n",
      "Ep:183, loss:0.00000, loss_test:0.01644, lr:2.43e-02, fs:0.69863 (r=0.586,p=0.864),  time:42.318, tt:7786.429\n",
      "Ep:184, loss:0.00000, loss_test:0.01646, lr:2.40e-02, fs:0.68966 (r=0.575,p=0.862),  time:42.312, tt:7827.680\n",
      "Ep:185, loss:0.00000, loss_test:0.01647, lr:2.38e-02, fs:0.69863 (r=0.586,p=0.864),  time:42.313, tt:7870.166\n",
      "Ep:186, loss:0.00000, loss_test:0.01648, lr:2.36e-02, fs:0.69863 (r=0.586,p=0.864),  time:42.310, tt:7912.036\n",
      "Ep:187, loss:0.00000, loss_test:0.01648, lr:2.33e-02, fs:0.68966 (r=0.575,p=0.862),  time:42.323, tt:7956.747\n",
      "Ep:188, loss:0.00000, loss_test:0.01648, lr:2.31e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.333, tt:8000.976\n",
      "Ep:189, loss:0.00000, loss_test:0.01650, lr:2.29e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.334, tt:8043.522\n",
      "Ep:190, loss:0.00000, loss_test:0.01651, lr:2.26e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.333, tt:8085.569\n",
      "Ep:191, loss:0.00000, loss_test:0.01653, lr:2.24e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.335, tt:8128.271\n",
      "Ep:192, loss:0.00000, loss_test:0.01657, lr:2.22e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.337, tt:8171.010\n",
      "Ep:193, loss:0.00000, loss_test:0.01658, lr:2.20e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.347, tt:8215.389\n",
      "Ep:194, loss:0.00000, loss_test:0.01659, lr:2.17e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.343, tt:8256.850\n",
      "Ep:195, loss:0.00000, loss_test:0.01659, lr:2.15e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.338, tt:8298.244\n",
      "Ep:196, loss:0.00000, loss_test:0.01659, lr:2.13e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.344, tt:8341.819\n",
      "Ep:197, loss:0.00000, loss_test:0.01660, lr:2.11e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.342, tt:8383.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:198, loss:0.00000, loss_test:0.01660, lr:2.09e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.343, tt:8426.262\n",
      "Ep:199, loss:0.00000, loss_test:0.01662, lr:2.07e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.355, tt:8470.967\n",
      "Ep:200, loss:0.00000, loss_test:0.01662, lr:2.05e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.367, tt:8515.686\n",
      "Ep:201, loss:0.00000, loss_test:0.01665, lr:2.03e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.371, tt:8558.853\n",
      "Ep:202, loss:0.00000, loss_test:0.01667, lr:2.01e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.372, tt:8601.551\n",
      "Ep:203, loss:0.00000, loss_test:0.01665, lr:1.99e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.404, tt:8650.414\n",
      "Ep:204, loss:0.00000, loss_test:0.01666, lr:1.97e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.402, tt:8692.495\n",
      "Ep:205, loss:0.00000, loss_test:0.01668, lr:1.95e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.399, tt:8734.110\n",
      "Ep:206, loss:0.00000, loss_test:0.01668, lr:1.93e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.394, tt:8775.468\n",
      "Ep:207, loss:0.00000, loss_test:0.01671, lr:1.91e-02, fs:0.68056 (r=0.563,p=0.860),  time:42.393, tt:8817.783\n",
      "Ep:208, loss:0.00000, loss_test:0.01672, lr:1.89e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.383, tt:8858.002\n",
      "Ep:209, loss:0.00000, loss_test:0.01674, lr:1.87e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.334, tt:8890.080\n",
      "Ep:210, loss:0.00000, loss_test:0.01675, lr:1.85e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.296, tt:8924.446\n",
      "Ep:211, loss:0.00000, loss_test:0.01674, lr:1.83e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.269, tt:8961.074\n",
      "Ep:212, loss:0.00000, loss_test:0.01674, lr:1.81e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.249, tt:8999.028\n",
      "Ep:213, loss:0.00000, loss_test:0.01677, lr:1.80e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.225, tt:9036.052\n",
      "Ep:214, loss:0.00000, loss_test:0.01677, lr:1.78e-02, fs:0.67133 (r=0.552,p=0.857),  time:42.225, tt:9078.462\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14352, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:42.947, tt:42.947\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14220, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:43.370, tt:86.741\n",
      "Ep:2, loss:0.00027, loss_test:0.13982, lr:1.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:42.996, tt:128.987\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13618, lr:1.00e-02, fs:0.65863 (r=0.943,p=0.506),  time:43.236, tt:172.943\n",
      "Ep:4, loss:0.00026, loss_test:0.13176, lr:1.00e-02, fs:0.63436 (r=0.828,p=0.514),  time:43.113, tt:215.566\n",
      "Ep:5, loss:0.00024, loss_test:0.12787, lr:1.00e-02, fs:0.63000 (r=0.724,p=0.558),  time:43.113, tt:258.677\n",
      "Ep:6, loss:0.00023, loss_test:0.12511, lr:1.00e-02, fs:0.63687 (r=0.655,p=0.620),  time:43.082, tt:301.576\n",
      "Ep:7, loss:0.00022, loss_test:0.12030, lr:1.00e-02, fs:0.64835 (r=0.678,p=0.621),  time:43.116, tt:344.931\n",
      "Ep:8, loss:0.00021, loss_test:0.11734, lr:1.00e-02, fs:0.65957 (r=0.713,p=0.614),  time:43.005, tt:387.048\n",
      "Ep:9, loss:0.00021, loss_test:0.11401, lr:1.00e-02, fs:0.65556 (r=0.678,p=0.634),  time:42.921, tt:429.213\n",
      "Ep:10, loss:0.00020, loss_test:0.11343, lr:1.00e-02, fs:0.62722 (r=0.609,p=0.646),  time:43.013, tt:473.143\n",
      "Ep:11, loss:0.00019, loss_test:0.10924, lr:1.00e-02, fs:0.70391 (r=0.724,p=0.685),  time:43.020, tt:516.242\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10576, lr:1.00e-02, fs:0.72043 (r=0.770,p=0.677),  time:43.001, tt:559.016\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10438, lr:1.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:42.992, tt:601.887\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10097, lr:1.00e-02, fs:0.74033 (r=0.770,p=0.713),  time:42.779, tt:641.692\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09765, lr:1.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:42.637, tt:682.188\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09527, lr:1.00e-02, fs:0.76243 (r=0.793,p=0.734),  time:42.632, tt:724.736\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09272, lr:1.00e-02, fs:0.77174 (r=0.816,p=0.732),  time:42.721, tt:768.970\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09058, lr:1.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:42.628, tt:809.939\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08895, lr:1.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:42.653, tt:853.069\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08691, lr:1.00e-02, fs:0.80214 (r=0.862,p=0.750),  time:42.701, tt:896.712\n",
      "Ep:21, loss:0.00013, loss_test:0.08540, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:42.796, tt:941.501\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08361, lr:1.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:42.862, tt:985.829\n",
      "Ep:23, loss:0.00012, loss_test:0.08326, lr:1.00e-02, fs:0.83146 (r=0.851,p=0.813),  time:42.877, tt:1029.055\n",
      "Ep:24, loss:0.00012, loss_test:0.08073, lr:1.00e-02, fs:0.85864 (r=0.943,p=0.788),  time:42.832, tt:1070.798\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08000, lr:1.00e-02, fs:0.82222 (r=0.851,p=0.796),  time:42.830, tt:1113.582\n",
      "Ep:26, loss:0.00011, loss_test:0.07834, lr:1.00e-02, fs:0.87831 (r=0.954,p=0.814),  time:42.831, tt:1156.434\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.07823, lr:1.00e-02, fs:0.87568 (r=0.931,p=0.827),  time:42.851, tt:1199.825\n",
      "Ep:28, loss:0.00010, loss_test:0.07669, lr:1.00e-02, fs:0.88298 (r=0.954,p=0.822),  time:42.875, tt:1243.388\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.07608, lr:1.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:42.826, tt:1284.777\n",
      "Ep:30, loss:0.00010, loss_test:0.07425, lr:1.00e-02, fs:0.88298 (r=0.954,p=0.822),  time:42.935, tt:1330.973\n",
      "Ep:31, loss:0.00009, loss_test:0.07387, lr:1.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:42.901, tt:1372.840\n",
      "Ep:32, loss:0.00009, loss_test:0.07348, lr:1.00e-02, fs:0.88770 (r=0.954,p=0.830),  time:42.889, tt:1415.323\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.07262, lr:1.00e-02, fs:0.87368 (r=0.954,p=0.806),  time:42.816, tt:1455.750\n",
      "Ep:34, loss:0.00008, loss_test:0.07754, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:42.766, tt:1496.817\n",
      "Ep:35, loss:0.00008, loss_test:0.07211, lr:1.00e-02, fs:0.87368 (r=0.954,p=0.806),  time:42.746, tt:1538.861\n",
      "Ep:36, loss:0.00008, loss_test:0.07498, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:42.743, tt:1581.476\n",
      "Ep:37, loss:0.00008, loss_test:0.07022, lr:1.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:42.743, tt:1624.216\n",
      "Ep:38, loss:0.00007, loss_test:0.07289, lr:1.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:42.757, tt:1667.527\n",
      "Ep:39, loss:0.00007, loss_test:0.07092, lr:1.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:42.805, tt:1712.182\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.07215, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:42.761, tt:1753.183\n",
      "Ep:41, loss:0.00006, loss_test:0.07198, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:42.738, tt:1794.979\n",
      "Ep:42, loss:0.00006, loss_test:0.07253, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:42.658, tt:1834.311\n",
      "Ep:43, loss:0.00006, loss_test:0.07056, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:42.600, tt:1874.412\n",
      "Ep:44, loss:0.00006, loss_test:0.07370, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:42.567, tt:1915.511\n",
      "Ep:45, loss:0.00005, loss_test:0.07038, lr:1.00e-02, fs:0.86207 (r=0.862,p=0.862),  time:42.542, tt:1956.923\n",
      "Ep:46, loss:0.00005, loss_test:0.07150, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:42.474, tt:1996.262\n",
      "Ep:47, loss:0.00005, loss_test:0.07488, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:42.473, tt:2038.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00005, loss_test:0.07215, lr:1.00e-02, fs:0.81657 (r=0.793,p=0.841),  time:42.439, tt:2079.518\n",
      "Ep:49, loss:0.00005, loss_test:0.07374, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:42.416, tt:2120.778\n",
      "Ep:50, loss:0.00005, loss_test:0.07409, lr:1.00e-02, fs:0.78261 (r=0.724,p=0.851),  time:42.356, tt:2160.136\n",
      "Ep:51, loss:0.00004, loss_test:0.07398, lr:9.90e-03, fs:0.83133 (r=0.793,p=0.873),  time:42.360, tt:2202.719\n",
      "Ep:52, loss:0.00004, loss_test:0.07278, lr:9.80e-03, fs:0.79042 (r=0.759,p=0.825),  time:42.300, tt:2241.874\n",
      "Ep:53, loss:0.00004, loss_test:0.07304, lr:9.70e-03, fs:0.80982 (r=0.759,p=0.868),  time:42.279, tt:2283.090\n",
      "Ep:54, loss:0.00004, loss_test:0.07253, lr:9.61e-03, fs:0.79268 (r=0.747,p=0.844),  time:42.221, tt:2322.180\n",
      "Ep:55, loss:0.00004, loss_test:0.07314, lr:9.51e-03, fs:0.78750 (r=0.724,p=0.863),  time:42.186, tt:2362.436\n",
      "Ep:56, loss:0.00004, loss_test:0.07605, lr:9.41e-03, fs:0.78750 (r=0.724,p=0.863),  time:42.176, tt:2404.015\n",
      "Ep:57, loss:0.00003, loss_test:0.07131, lr:9.32e-03, fs:0.80247 (r=0.747,p=0.867),  time:42.166, tt:2445.615\n",
      "Ep:58, loss:0.00003, loss_test:0.07655, lr:9.23e-03, fs:0.77215 (r=0.701,p=0.859),  time:42.200, tt:2489.795\n",
      "Ep:59, loss:0.00003, loss_test:0.07128, lr:9.14e-03, fs:0.80000 (r=0.736,p=0.877),  time:42.189, tt:2531.338\n",
      "Ep:60, loss:0.00003, loss_test:0.07502, lr:9.04e-03, fs:0.77987 (r=0.713,p=0.861),  time:42.177, tt:2572.792\n",
      "Ep:61, loss:0.00003, loss_test:0.07701, lr:8.95e-03, fs:0.80000 (r=0.713,p=0.912),  time:42.167, tt:2614.374\n",
      "Ep:62, loss:0.00003, loss_test:0.07303, lr:8.86e-03, fs:0.77500 (r=0.713,p=0.849),  time:42.189, tt:2657.921\n",
      "Ep:63, loss:0.00003, loss_test:0.07618, lr:8.78e-03, fs:0.80000 (r=0.713,p=0.912),  time:42.220, tt:2702.089\n",
      "Ep:64, loss:0.00003, loss_test:0.06957, lr:8.69e-03, fs:0.80255 (r=0.724,p=0.900),  time:42.192, tt:2742.473\n",
      "Ep:65, loss:0.00003, loss_test:0.07752, lr:8.60e-03, fs:0.80263 (r=0.701,p=0.938),  time:42.226, tt:2786.912\n",
      "Ep:66, loss:0.00003, loss_test:0.07195, lr:8.51e-03, fs:0.81013 (r=0.736,p=0.901),  time:42.256, tt:2831.178\n",
      "Ep:67, loss:0.00002, loss_test:0.07558, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.262, tt:2873.838\n",
      "Ep:68, loss:0.00002, loss_test:0.07348, lr:8.35e-03, fs:0.80769 (r=0.724,p=0.913),  time:42.257, tt:2915.753\n",
      "Ep:69, loss:0.00002, loss_test:0.07340, lr:8.26e-03, fs:0.78710 (r=0.701,p=0.897),  time:42.272, tt:2959.071\n",
      "Ep:70, loss:0.00002, loss_test:0.07361, lr:8.18e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.258, tt:3000.342\n",
      "Ep:71, loss:0.00002, loss_test:0.07613, lr:8.10e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.281, tt:3044.204\n",
      "Ep:72, loss:0.00002, loss_test:0.07387, lr:8.02e-03, fs:0.80519 (r=0.713,p=0.925),  time:42.316, tt:3089.102\n",
      "Ep:73, loss:0.00002, loss_test:0.07279, lr:7.94e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.337, tt:3132.936\n",
      "Ep:74, loss:0.00002, loss_test:0.07647, lr:7.86e-03, fs:0.78947 (r=0.690,p=0.923),  time:42.356, tt:3176.723\n",
      "Ep:75, loss:0.00002, loss_test:0.07190, lr:7.78e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.401, tt:3222.499\n",
      "Ep:76, loss:0.00002, loss_test:0.07802, lr:7.70e-03, fs:0.79470 (r=0.690,p=0.938),  time:42.401, tt:3264.894\n",
      "Ep:77, loss:0.00002, loss_test:0.07341, lr:7.62e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.399, tt:3307.124\n",
      "Ep:78, loss:0.00002, loss_test:0.07630, lr:7.55e-03, fs:0.80519 (r=0.713,p=0.925),  time:42.432, tt:3352.126\n",
      "Ep:79, loss:0.00002, loss_test:0.07215, lr:7.47e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.424, tt:3393.905\n",
      "Ep:80, loss:0.00002, loss_test:0.07640, lr:7.40e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.421, tt:3436.100\n",
      "Ep:81, loss:0.00002, loss_test:0.07759, lr:7.32e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.410, tt:3477.631\n",
      "Ep:82, loss:0.00002, loss_test:0.07205, lr:7.25e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.409, tt:3519.971\n",
      "Ep:83, loss:0.00002, loss_test:0.07686, lr:7.18e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.397, tt:3561.347\n",
      "Ep:84, loss:0.00002, loss_test:0.07789, lr:7.11e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.381, tt:3602.368\n",
      "Ep:85, loss:0.00001, loss_test:0.07538, lr:7.03e-03, fs:0.80519 (r=0.713,p=0.925),  time:42.383, tt:3644.924\n",
      "Ep:86, loss:0.00001, loss_test:0.08269, lr:6.96e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.360, tt:3685.283\n",
      "Ep:87, loss:0.00001, loss_test:0.07513, lr:6.89e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.330, tt:3725.062\n",
      "Ep:88, loss:0.00001, loss_test:0.07729, lr:6.83e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.317, tt:3766.231\n",
      "Ep:89, loss:0.00001, loss_test:0.07568, lr:6.76e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.327, tt:3809.407\n",
      "Ep:90, loss:0.00001, loss_test:0.07513, lr:6.69e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.302, tt:3849.492\n",
      "Ep:91, loss:0.00001, loss_test:0.07813, lr:6.62e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.305, tt:3892.023\n",
      "Ep:92, loss:0.00001, loss_test:0.07699, lr:6.56e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.297, tt:3933.613\n",
      "Ep:93, loss:0.00001, loss_test:0.07628, lr:6.49e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.282, tt:3974.516\n",
      "Ep:94, loss:0.00001, loss_test:0.07661, lr:6.43e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.280, tt:4016.626\n",
      "Ep:95, loss:0.00001, loss_test:0.07768, lr:6.36e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.267, tt:4057.595\n",
      "Ep:96, loss:0.00001, loss_test:0.07598, lr:6.30e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.265, tt:4099.662\n",
      "Ep:97, loss:0.00001, loss_test:0.07784, lr:6.24e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.260, tt:4141.528\n",
      "Ep:98, loss:0.00001, loss_test:0.07592, lr:6.17e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.220, tt:4179.794\n",
      "Ep:99, loss:0.00001, loss_test:0.07640, lr:6.11e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.201, tt:4220.125\n",
      "Ep:100, loss:0.00001, loss_test:0.07680, lr:6.05e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.209, tt:4263.100\n",
      "Ep:101, loss:0.00001, loss_test:0.07781, lr:5.99e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.207, tt:4305.159\n",
      "Ep:102, loss:0.00001, loss_test:0.07629, lr:5.93e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.216, tt:4348.213\n",
      "Ep:103, loss:0.00001, loss_test:0.08003, lr:5.87e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.218, tt:4390.659\n",
      "Ep:104, loss:0.00001, loss_test:0.07648, lr:5.81e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.213, tt:4432.322\n",
      "Ep:105, loss:0.00001, loss_test:0.08001, lr:5.75e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.202, tt:4473.373\n",
      "Ep:106, loss:0.00001, loss_test:0.07787, lr:5.70e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.202, tt:4515.657\n",
      "Ep:107, loss:0.00001, loss_test:0.07913, lr:5.64e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.205, tt:4558.153\n",
      "Ep:108, loss:0.00001, loss_test:0.07816, lr:5.58e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.201, tt:4599.940\n",
      "Ep:109, loss:0.00001, loss_test:0.07656, lr:5.53e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.215, tt:4643.636\n",
      "Ep:110, loss:0.00001, loss_test:0.07988, lr:5.47e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.229, tt:4687.448\n",
      "Ep:111, loss:0.00001, loss_test:0.07629, lr:5.42e-03, fs:0.82353 (r=0.724,p=0.955),  time:42.231, tt:4729.818\n",
      "Ep:112, loss:0.00001, loss_test:0.07882, lr:5.36e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.240, tt:4773.086\n",
      "Ep:113, loss:0.00001, loss_test:0.07577, lr:5.31e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.228, tt:4813.957\n",
      "Ep:114, loss:0.00001, loss_test:0.08010, lr:5.26e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.196, tt:4852.517\n",
      "Ep:115, loss:0.00001, loss_test:0.07700, lr:5.20e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.192, tt:4894.227\n",
      "Ep:116, loss:0.00001, loss_test:0.07891, lr:5.15e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.184, tt:4935.469\n",
      "Ep:117, loss:0.00001, loss_test:0.07642, lr:5.10e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.150, tt:4973.668\n",
      "Ep:118, loss:0.00001, loss_test:0.07932, lr:5.05e-03, fs:0.81046 (r=0.713,p=0.939),  time:42.133, tt:5013.813\n",
      "Ep:119, loss:0.00001, loss_test:0.07921, lr:5.00e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.126, tt:5055.173\n",
      "Ep:120, loss:0.00001, loss_test:0.07838, lr:4.95e-03, fs:0.82353 (r=0.724,p=0.955),  time:42.116, tt:5096.067\n",
      "Ep:121, loss:0.00001, loss_test:0.07722, lr:4.90e-03, fs:0.81818 (r=0.724,p=0.940),  time:42.115, tt:5138.009\n",
      "Ep:122, loss:0.00001, loss_test:0.08090, lr:4.85e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.103, tt:5178.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00001, loss_test:0.07583, lr:4.80e-03, fs:0.82353 (r=0.724,p=0.955),  time:42.092, tt:5219.447\n",
      "Ep:124, loss:0.00001, loss_test:0.08141, lr:4.75e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.085, tt:5260.579\n",
      "Ep:125, loss:0.00001, loss_test:0.07699, lr:4.71e-03, fs:0.82353 (r=0.724,p=0.955),  time:42.067, tt:5300.482\n",
      "Ep:126, loss:0.00001, loss_test:0.08053, lr:4.66e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.057, tt:5341.282\n",
      "Ep:127, loss:0.00001, loss_test:0.07862, lr:4.61e-03, fs:0.82353 (r=0.724,p=0.955),  time:42.049, tt:5382.297\n",
      "Ep:128, loss:0.00001, loss_test:0.07972, lr:4.57e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.058, tt:5425.546\n",
      "Ep:129, loss:0.00001, loss_test:0.07926, lr:4.52e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.057, tt:5467.456\n",
      "Ep:130, loss:0.00001, loss_test:0.07922, lr:4.48e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.055, tt:5509.155\n",
      "Ep:131, loss:0.00001, loss_test:0.07993, lr:4.43e-03, fs:0.78378 (r=0.667,p=0.951),  time:42.036, tt:5548.817\n",
      "Ep:132, loss:0.00001, loss_test:0.07806, lr:4.39e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.028, tt:5589.749\n",
      "Ep:133, loss:0.00001, loss_test:0.08149, lr:4.34e-03, fs:0.78912 (r=0.667,p=0.967),  time:42.026, tt:5631.440\n",
      "Ep:134, loss:0.00001, loss_test:0.07988, lr:4.30e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.029, tt:5673.880\n",
      "Ep:135, loss:0.00001, loss_test:0.07813, lr:4.26e-03, fs:0.80795 (r=0.701,p=0.953),  time:42.028, tt:5715.787\n",
      "Ep:136, loss:0.00001, loss_test:0.08177, lr:4.21e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.035, tt:5758.815\n",
      "Ep:137, loss:0.00001, loss_test:0.07819, lr:4.17e-03, fs:0.78378 (r=0.667,p=0.951),  time:42.029, tt:5800.036\n",
      "Ep:138, loss:0.00001, loss_test:0.08010, lr:4.13e-03, fs:0.77241 (r=0.644,p=0.966),  time:42.017, tt:5840.363\n",
      "Ep:139, loss:0.00001, loss_test:0.08022, lr:4.09e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.015, tt:5882.139\n",
      "Ep:140, loss:0.00001, loss_test:0.07857, lr:4.05e-03, fs:0.77551 (r=0.655,p=0.950),  time:42.021, tt:5924.906\n",
      "Ep:141, loss:0.00001, loss_test:0.08049, lr:4.01e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.015, tt:5966.129\n",
      "Ep:142, loss:0.00001, loss_test:0.08035, lr:3.97e-03, fs:0.75524 (r=0.621,p=0.964),  time:41.996, tt:6005.461\n",
      "Ep:143, loss:0.00001, loss_test:0.07894, lr:3.93e-03, fs:0.75862 (r=0.632,p=0.948),  time:41.995, tt:6047.343\n",
      "Ep:144, loss:0.00001, loss_test:0.08173, lr:3.89e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.999, tt:6089.886\n",
      "Ep:145, loss:0.00001, loss_test:0.08018, lr:3.85e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.991, tt:6130.714\n",
      "Ep:146, loss:0.00001, loss_test:0.08019, lr:3.81e-03, fs:0.75000 (r=0.621,p=0.947),  time:41.983, tt:6171.459\n",
      "Ep:147, loss:0.00001, loss_test:0.08081, lr:3.77e-03, fs:0.75524 (r=0.621,p=0.964),  time:41.981, tt:6213.258\n",
      "Ep:148, loss:0.00000, loss_test:0.07901, lr:3.73e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.999, tt:6257.833\n",
      "Ep:149, loss:0.00000, loss_test:0.08128, lr:3.70e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.993, tt:6298.944\n",
      "Ep:150, loss:0.00000, loss_test:0.08140, lr:3.66e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.968, tt:6337.195\n",
      "Ep:151, loss:0.00000, loss_test:0.07890, lr:3.62e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.963, tt:6378.411\n",
      "Ep:152, loss:0.00000, loss_test:0.08050, lr:3.59e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.962, tt:6420.261\n",
      "Ep:153, loss:0.00000, loss_test:0.07955, lr:3.55e-03, fs:0.75000 (r=0.621,p=0.947),  time:41.953, tt:6460.728\n",
      "Ep:154, loss:0.00000, loss_test:0.08087, lr:3.52e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.952, tt:6502.637\n",
      "Ep:155, loss:0.00000, loss_test:0.08136, lr:3.48e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.942, tt:6542.893\n",
      "Ep:156, loss:0.00000, loss_test:0.08010, lr:3.45e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.941, tt:6584.674\n",
      "Ep:157, loss:0.00000, loss_test:0.08184, lr:3.41e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.946, tt:6627.392\n",
      "Ep:158, loss:0.00000, loss_test:0.08216, lr:3.38e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.940, tt:6668.436\n",
      "Ep:159, loss:0.00000, loss_test:0.07956, lr:3.34e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.942, tt:6710.780\n",
      "Ep:160, loss:0.00000, loss_test:0.08078, lr:3.31e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.932, tt:6751.046\n",
      "Ep:161, loss:0.00000, loss_test:0.08243, lr:3.28e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.934, tt:6793.350\n",
      "Ep:162, loss:0.00000, loss_test:0.08014, lr:3.24e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.932, tt:6834.952\n",
      "Ep:163, loss:0.00000, loss_test:0.08091, lr:3.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.927, tt:6876.063\n",
      "Ep:164, loss:0.00000, loss_test:0.08136, lr:3.18e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.921, tt:6917.042\n",
      "Ep:165, loss:0.00000, loss_test:0.07951, lr:3.15e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.924, tt:6959.429\n",
      "Ep:166, loss:0.00000, loss_test:0.08202, lr:3.12e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.907, tt:6998.457\n",
      "Ep:167, loss:0.00000, loss_test:0.08130, lr:3.09e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.903, tt:7039.728\n",
      "Ep:168, loss:0.00000, loss_test:0.07987, lr:3.05e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.901, tt:7081.235\n",
      "Ep:169, loss:0.00000, loss_test:0.08113, lr:3.02e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.922, tt:7126.788\n",
      "Ep:170, loss:0.00000, loss_test:0.08030, lr:2.99e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.920, tt:7168.342\n",
      "Ep:171, loss:0.00000, loss_test:0.08068, lr:2.96e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.917, tt:7209.741\n",
      "Ep:172, loss:0.00000, loss_test:0.08095, lr:2.93e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.922, tt:7252.489\n",
      "Ep:173, loss:0.00000, loss_test:0.08083, lr:2.90e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.927, tt:7295.311\n",
      "Ep:174, loss:0.00000, loss_test:0.08084, lr:2.88e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.912, tt:7334.646\n",
      "Ep:175, loss:0.00000, loss_test:0.08160, lr:2.85e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.903, tt:7374.864\n",
      "Ep:176, loss:0.00000, loss_test:0.08048, lr:2.82e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.895, tt:7415.476\n",
      "Ep:177, loss:0.00000, loss_test:0.08155, lr:2.79e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.895, tt:7457.343\n",
      "Ep:178, loss:0.00000, loss_test:0.08194, lr:2.76e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.895, tt:7499.262\n",
      "Ep:179, loss:0.00000, loss_test:0.08016, lr:2.73e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.888, tt:7539.889\n",
      "Ep:180, loss:0.00000, loss_test:0.08179, lr:2.71e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.891, tt:7582.246\n",
      "Ep:181, loss:0.00000, loss_test:0.08130, lr:2.68e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.886, tt:7623.241\n",
      "Ep:182, loss:0.00000, loss_test:0.08151, lr:2.65e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.881, tt:7664.164\n",
      "Ep:183, loss:0.00000, loss_test:0.08185, lr:2.63e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.874, tt:7704.798\n",
      "Ep:184, loss:0.00000, loss_test:0.08047, lr:2.60e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.877, tt:7747.246\n",
      "Ep:185, loss:0.00000, loss_test:0.08143, lr:2.57e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.882, tt:7790.014\n",
      "Ep:186, loss:0.00000, loss_test:0.08115, lr:2.55e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.874, tt:7830.462\n",
      "Ep:187, loss:0.00000, loss_test:0.08198, lr:2.52e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.870, tt:7871.631\n",
      "Ep:188, loss:0.00000, loss_test:0.08232, lr:2.50e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.860, tt:7911.617\n",
      "Ep:189, loss:0.00000, loss_test:0.08088, lr:2.47e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.865, tt:7954.297\n",
      "Ep:190, loss:0.00000, loss_test:0.08146, lr:2.45e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.860, tt:7995.290\n",
      "Ep:191, loss:0.00000, loss_test:0.08151, lr:2.42e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.861, tt:8037.408\n",
      "Ep:192, loss:0.00000, loss_test:0.08059, lr:2.40e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.861, tt:8079.167\n",
      "Ep:193, loss:0.00000, loss_test:0.08158, lr:2.38e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.851, tt:8119.162\n",
      "Ep:194, loss:0.00000, loss_test:0.08278, lr:2.35e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.849, tt:8160.638\n",
      "Ep:195, loss:0.00000, loss_test:0.08103, lr:2.33e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.841, tt:8200.752\n",
      "Ep:196, loss:0.00000, loss_test:0.08137, lr:2.31e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.842, tt:8242.788\n",
      "Ep:197, loss:0.00000, loss_test:0.08200, lr:2.28e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.854, tt:8287.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:198, loss:0.00000, loss_test:0.08137, lr:2.26e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.860, tt:8330.062\n",
      "Ep:199, loss:0.00000, loss_test:0.08128, lr:2.24e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.858, tt:8371.625\n",
      "Ep:200, loss:0.00000, loss_test:0.08275, lr:2.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.859, tt:8413.624\n",
      "Ep:201, loss:0.00000, loss_test:0.08145, lr:2.19e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.859, tt:8455.459\n",
      "Ep:202, loss:0.00000, loss_test:0.08115, lr:2.17e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.863, tt:8498.098\n",
      "Ep:203, loss:0.00000, loss_test:0.08197, lr:2.15e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.871, tt:8541.689\n",
      "Ep:204, loss:0.00000, loss_test:0.08164, lr:2.13e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.863, tt:8581.976\n",
      "Ep:205, loss:0.00000, loss_test:0.08144, lr:2.11e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.857, tt:8622.544\n",
      "Ep:206, loss:0.00000, loss_test:0.08127, lr:2.08e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.857, tt:8664.367\n",
      "Ep:207, loss:0.00000, loss_test:0.08196, lr:2.06e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.855, tt:8705.810\n",
      "Ep:208, loss:0.00000, loss_test:0.08253, lr:2.04e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.835, tt:8743.457\n",
      "Ep:209, loss:0.00000, loss_test:0.08145, lr:2.02e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.771, tt:8771.998\n",
      "Ep:210, loss:0.00000, loss_test:0.08203, lr:2.00e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.672, tt:8792.791\n",
      "Ep:211, loss:0.00000, loss_test:0.08221, lr:1.98e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.546, tt:8807.823\n",
      "Ep:212, loss:0.00000, loss_test:0.08084, lr:1.96e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.415, tt:8821.312\n",
      "Ep:213, loss:0.00000, loss_test:0.08229, lr:1.94e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.274, tt:8832.534\n",
      "Ep:214, loss:0.00000, loss_test:0.08245, lr:1.92e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.134, tt:8843.877\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02285, lr:6.00e-02, fs:0.64122 (r=0.848,p=0.515),  time:39.995, tt:39.995\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02399, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:40.231, tt:80.462\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02492, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.833, tt:119.498\n",
      "Ep:3, loss:0.00005, loss_test:0.02441, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:39.860, tt:159.442\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02329, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:40.138, tt:200.690\n",
      "Ep:5, loss:0.00004, loss_test:0.02276, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:40.184, tt:241.104\n",
      "Ep:6, loss:0.00004, loss_test:0.02355, lr:6.00e-02, fs:0.62500 (r=0.758,p=0.532),  time:40.345, tt:282.417\n",
      "Ep:7, loss:0.00004, loss_test:0.02458, lr:6.00e-02, fs:0.56481 (r=0.616,p=0.521),  time:40.251, tt:322.009\n",
      "Ep:8, loss:0.00004, loss_test:0.02395, lr:6.00e-02, fs:0.58065 (r=0.636,p=0.534),  time:40.157, tt:361.411\n",
      "Ep:9, loss:0.00003, loss_test:0.02255, lr:6.00e-02, fs:0.59649 (r=0.687,p=0.527),  time:40.390, tt:403.903\n",
      "Ep:10, loss:0.00003, loss_test:0.02177, lr:6.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:40.335, tt:443.690\n",
      "Ep:11, loss:0.00003, loss_test:0.02134, lr:6.00e-02, fs:0.65854 (r=0.818,p=0.551),  time:40.268, tt:483.213\n",
      "Ep:12, loss:0.00003, loss_test:0.02111, lr:6.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:40.295, tt:523.840\n",
      "Ep:13, loss:0.00003, loss_test:0.02111, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:40.202, tt:562.829\n",
      "Ep:14, loss:0.00003, loss_test:0.02110, lr:6.00e-02, fs:0.66071 (r=0.747,p=0.592),  time:40.174, tt:602.617\n",
      "Ep:15, loss:0.00003, loss_test:0.02088, lr:5.94e-02, fs:0.64545 (r=0.717,p=0.587),  time:40.162, tt:642.588\n",
      "Ep:16, loss:0.00003, loss_test:0.02035, lr:5.88e-02, fs:0.67857 (r=0.768,p=0.608),  time:40.075, tt:681.268\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01979, lr:5.88e-02, fs:0.69604 (r=0.798,p=0.617),  time:40.088, tt:721.585\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01939, lr:5.88e-02, fs:0.71552 (r=0.838,p=0.624),  time:40.210, tt:763.992\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01921, lr:5.88e-02, fs:0.72961 (r=0.859,p=0.634),  time:40.205, tt:804.098\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01925, lr:5.88e-02, fs:0.72247 (r=0.828,p=0.641),  time:40.312, tt:846.546\n",
      "Ep:21, loss:0.00003, loss_test:0.01916, lr:5.88e-02, fs:0.73451 (r=0.838,p=0.654),  time:40.313, tt:886.887\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01888, lr:5.88e-02, fs:0.73778 (r=0.838,p=0.659),  time:40.311, tt:927.155\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01855, lr:5.88e-02, fs:0.71171 (r=0.798,p=0.642),  time:40.254, tt:966.108\n",
      "Ep:24, loss:0.00002, loss_test:0.01830, lr:5.88e-02, fs:0.70270 (r=0.788,p=0.634),  time:40.201, tt:1005.022\n",
      "Ep:25, loss:0.00002, loss_test:0.01817, lr:5.88e-02, fs:0.70588 (r=0.788,p=0.639),  time:40.202, tt:1045.264\n",
      "Ep:26, loss:0.00002, loss_test:0.01816, lr:5.88e-02, fs:0.71233 (r=0.788,p=0.650),  time:40.282, tt:1087.602\n",
      "Ep:27, loss:0.00002, loss_test:0.01810, lr:5.88e-02, fs:0.71889 (r=0.788,p=0.661),  time:40.209, tt:1125.849\n",
      "Ep:28, loss:0.00002, loss_test:0.01802, lr:5.88e-02, fs:0.71889 (r=0.788,p=0.661),  time:40.283, tt:1168.218\n",
      "Ep:29, loss:0.00002, loss_test:0.01789, lr:5.88e-02, fs:0.72477 (r=0.798,p=0.664),  time:40.227, tt:1206.803\n",
      "Ep:30, loss:0.00002, loss_test:0.01793, lr:5.88e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.243, tt:1247.532\n",
      "Ep:31, loss:0.00002, loss_test:0.01797, lr:5.88e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.292, tt:1289.356\n",
      "Ep:32, loss:0.00002, loss_test:0.01801, lr:5.88e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.307, tt:1330.118\n",
      "Ep:33, loss:0.00002, loss_test:0.01798, lr:5.88e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.347, tt:1371.794\n",
      "Ep:34, loss:0.00002, loss_test:0.01792, lr:5.82e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.351, tt:1412.297\n",
      "Ep:35, loss:0.00002, loss_test:0.01790, lr:5.76e-02, fs:0.73303 (r=0.818,p=0.664),  time:40.369, tt:1453.280\n",
      "Ep:36, loss:0.00002, loss_test:0.01804, lr:5.71e-02, fs:0.73733 (r=0.808,p=0.678),  time:40.404, tt:1494.963\n",
      "Ep:37, loss:0.00002, loss_test:0.01813, lr:5.65e-02, fs:0.73733 (r=0.808,p=0.678),  time:40.411, tt:1535.635\n",
      "Ep:38, loss:0.00002, loss_test:0.01816, lr:5.59e-02, fs:0.73733 (r=0.808,p=0.678),  time:40.375, tt:1574.606\n",
      "Ep:39, loss:0.00002, loss_test:0.01815, lr:5.54e-02, fs:0.74545 (r=0.828,p=0.678),  time:40.443, tt:1617.734\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01817, lr:5.54e-02, fs:0.74886 (r=0.828,p=0.683),  time:40.414, tt:1656.986\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01816, lr:5.54e-02, fs:0.75229 (r=0.828,p=0.689),  time:40.403, tt:1696.922\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01825, lr:5.54e-02, fs:0.75229 (r=0.828,p=0.689),  time:40.414, tt:1737.820\n",
      "Ep:43, loss:0.00002, loss_test:0.01826, lr:5.54e-02, fs:0.75229 (r=0.828,p=0.689),  time:40.372, tt:1776.355\n",
      "Ep:44, loss:0.00002, loss_test:0.01810, lr:5.54e-02, fs:0.76364 (r=0.848,p=0.694),  time:40.342, tt:1815.409\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01820, lr:5.54e-02, fs:0.77778 (r=0.848,p=0.718),  time:40.274, tt:1852.589\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01825, lr:5.54e-02, fs:0.77778 (r=0.848,p=0.718),  time:40.286, tt:1893.443\n",
      "Ep:47, loss:0.00001, loss_test:0.01838, lr:5.54e-02, fs:0.77778 (r=0.848,p=0.718),  time:40.282, tt:1933.534\n",
      "Ep:48, loss:0.00001, loss_test:0.01842, lr:5.54e-02, fs:0.77982 (r=0.859,p=0.714),  time:40.290, tt:1974.229\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01845, lr:5.54e-02, fs:0.77419 (r=0.848,p=0.712),  time:40.287, tt:2014.357\n",
      "Ep:50, loss:0.00001, loss_test:0.01846, lr:5.54e-02, fs:0.78341 (r=0.859,p=0.720),  time:40.284, tt:2054.484\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01854, lr:5.54e-02, fs:0.78140 (r=0.848,p=0.724),  time:40.272, tt:2094.131\n",
      "Ep:52, loss:0.00001, loss_test:0.01860, lr:5.54e-02, fs:0.77778 (r=0.848,p=0.718),  time:40.260, tt:2133.799\n",
      "Ep:53, loss:0.00001, loss_test:0.01874, lr:5.54e-02, fs:0.77934 (r=0.838,p=0.728),  time:40.233, tt:2172.595\n",
      "Ep:54, loss:0.00001, loss_test:0.01882, lr:5.54e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.236, tt:2212.998\n",
      "Ep:55, loss:0.00001, loss_test:0.01878, lr:5.54e-02, fs:0.79070 (r=0.859,p=0.733),  time:40.203, tt:2251.389\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01893, lr:5.54e-02, fs:0.77934 (r=0.838,p=0.728),  time:40.215, tt:2292.229\n",
      "Ep:57, loss:0.00001, loss_test:0.01903, lr:5.54e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.219, tt:2332.697\n",
      "Ep:58, loss:0.00001, loss_test:0.01907, lr:5.54e-02, fs:0.77143 (r=0.818,p=0.730),  time:40.242, tt:2374.264\n",
      "Ep:59, loss:0.00001, loss_test:0.01914, lr:5.54e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.221, tt:2413.254\n",
      "Ep:60, loss:0.00001, loss_test:0.01913, lr:5.54e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.242, tt:2454.792\n",
      "Ep:61, loss:0.00001, loss_test:0.01930, lr:5.54e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.254, tt:2495.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01947, lr:5.54e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.269, tt:2536.965\n",
      "Ep:63, loss:0.00001, loss_test:0.01956, lr:5.54e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.298, tt:2579.084\n",
      "Ep:64, loss:0.00001, loss_test:0.01965, lr:5.54e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.314, tt:2620.401\n",
      "Ep:65, loss:0.00001, loss_test:0.01984, lr:5.54e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.328, tt:2661.675\n",
      "Ep:66, loss:0.00001, loss_test:0.01982, lr:5.54e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.327, tt:2701.890\n",
      "Ep:67, loss:0.00001, loss_test:0.01985, lr:5.48e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.325, tt:2742.073\n",
      "Ep:68, loss:0.00001, loss_test:0.01996, lr:5.43e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.314, tt:2781.686\n",
      "Ep:69, loss:0.00001, loss_test:0.02014, lr:5.37e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.311, tt:2821.782\n",
      "Ep:70, loss:0.00001, loss_test:0.02025, lr:5.32e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.320, tt:2862.748\n",
      "Ep:71, loss:0.00001, loss_test:0.02037, lr:5.27e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.353, tt:2905.442\n",
      "Ep:72, loss:0.00001, loss_test:0.02052, lr:5.21e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.392, tt:2948.613\n",
      "Ep:73, loss:0.00001, loss_test:0.02053, lr:5.16e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.394, tt:2989.141\n",
      "Ep:74, loss:0.00001, loss_test:0.02071, lr:5.11e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.383, tt:3028.747\n",
      "Ep:75, loss:0.00001, loss_test:0.02082, lr:5.06e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.384, tt:3069.218\n",
      "Ep:76, loss:0.00001, loss_test:0.02087, lr:5.01e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.361, tt:3107.807\n",
      "Ep:77, loss:0.00001, loss_test:0.02103, lr:4.96e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.353, tt:3147.538\n",
      "Ep:78, loss:0.00001, loss_test:0.02128, lr:4.91e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.345, tt:3187.282\n",
      "Ep:79, loss:0.00001, loss_test:0.02123, lr:4.86e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.348, tt:3227.854\n",
      "Ep:80, loss:0.00001, loss_test:0.02134, lr:4.81e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.352, tt:3268.504\n",
      "Ep:81, loss:0.00001, loss_test:0.02164, lr:4.76e-02, fs:0.77073 (r=0.798,p=0.745),  time:40.358, tt:3309.396\n",
      "Ep:82, loss:0.00001, loss_test:0.02175, lr:4.71e-02, fs:0.77073 (r=0.798,p=0.745),  time:40.364, tt:3350.196\n",
      "Ep:83, loss:0.00001, loss_test:0.02176, lr:4.67e-02, fs:0.77073 (r=0.798,p=0.745),  time:40.342, tt:3388.752\n",
      "Ep:84, loss:0.00001, loss_test:0.02206, lr:4.62e-02, fs:0.77073 (r=0.798,p=0.745),  time:40.351, tt:3429.873\n",
      "Ep:85, loss:0.00001, loss_test:0.02192, lr:4.57e-02, fs:0.77833 (r=0.798,p=0.760),  time:40.471, tt:3480.525\n",
      "Ep:86, loss:0.00001, loss_test:0.02208, lr:4.53e-02, fs:0.77451 (r=0.798,p=0.752),  time:40.465, tt:3520.494\n",
      "Ep:87, loss:0.00001, loss_test:0.02237, lr:4.48e-02, fs:0.74372 (r=0.747,p=0.740),  time:40.478, tt:3562.036\n",
      "Ep:88, loss:0.00001, loss_test:0.02223, lr:4.44e-02, fs:0.77833 (r=0.798,p=0.760),  time:40.451, tt:3600.170\n",
      "Ep:89, loss:0.00001, loss_test:0.02254, lr:4.39e-02, fs:0.75127 (r=0.747,p=0.755),  time:40.459, tt:3641.345\n",
      "Ep:90, loss:0.00001, loss_test:0.02264, lr:4.35e-02, fs:0.73196 (r=0.717,p=0.747),  time:40.465, tt:3682.296\n",
      "Ep:91, loss:0.00001, loss_test:0.02268, lr:4.31e-02, fs:0.75127 (r=0.747,p=0.755),  time:40.459, tt:3722.236\n",
      "Ep:92, loss:0.00001, loss_test:0.02291, lr:4.26e-02, fs:0.71875 (r=0.697,p=0.742),  time:40.448, tt:3761.679\n",
      "Ep:93, loss:0.00001, loss_test:0.02287, lr:4.22e-02, fs:0.72251 (r=0.697,p=0.750),  time:40.459, tt:3803.130\n",
      "Ep:94, loss:0.00001, loss_test:0.02306, lr:4.18e-02, fs:0.71579 (r=0.687,p=0.747),  time:40.462, tt:3843.893\n",
      "Ep:95, loss:0.00001, loss_test:0.02314, lr:4.14e-02, fs:0.71579 (r=0.687,p=0.747),  time:40.462, tt:3884.325\n",
      "Ep:96, loss:0.00001, loss_test:0.02320, lr:4.10e-02, fs:0.70899 (r=0.677,p=0.744),  time:40.462, tt:3924.789\n",
      "Ep:97, loss:0.00001, loss_test:0.02342, lr:4.05e-02, fs:0.70588 (r=0.667,p=0.750),  time:40.463, tt:3965.392\n",
      "Ep:98, loss:0.00001, loss_test:0.02355, lr:4.01e-02, fs:0.69892 (r=0.657,p=0.747),  time:40.467, tt:4006.253\n",
      "Ep:99, loss:0.00001, loss_test:0.02355, lr:3.97e-02, fs:0.70588 (r=0.667,p=0.750),  time:40.481, tt:4048.135\n",
      "Ep:100, loss:0.00001, loss_test:0.02371, lr:3.93e-02, fs:0.69189 (r=0.646,p=0.744),  time:40.487, tt:4089.218\n",
      "Ep:101, loss:0.00001, loss_test:0.02390, lr:3.89e-02, fs:0.69189 (r=0.646,p=0.744),  time:40.490, tt:4129.942\n",
      "Ep:102, loss:0.00001, loss_test:0.02390, lr:3.86e-02, fs:0.68132 (r=0.626,p=0.747),  time:40.472, tt:4168.569\n",
      "Ep:103, loss:0.00001, loss_test:0.02405, lr:3.82e-02, fs:0.68132 (r=0.626,p=0.747),  time:40.485, tt:4210.428\n",
      "Ep:104, loss:0.00001, loss_test:0.02432, lr:3.78e-02, fs:0.68132 (r=0.626,p=0.747),  time:40.504, tt:4252.871\n",
      "Ep:105, loss:0.00001, loss_test:0.02416, lr:3.74e-02, fs:0.67403 (r=0.616,p=0.744),  time:40.499, tt:4292.871\n",
      "Ep:106, loss:0.00001, loss_test:0.02448, lr:3.70e-02, fs:0.67778 (r=0.616,p=0.753),  time:40.561, tt:4340.075\n",
      "Ep:107, loss:0.00001, loss_test:0.02452, lr:3.67e-02, fs:0.67039 (r=0.606,p=0.750),  time:40.567, tt:4381.206\n",
      "Ep:108, loss:0.00001, loss_test:0.02462, lr:3.63e-02, fs:0.67045 (r=0.596,p=0.766),  time:40.571, tt:4422.201\n",
      "Ep:109, loss:0.00001, loss_test:0.02481, lr:3.59e-02, fs:0.65517 (r=0.576,p=0.760),  time:40.577, tt:4463.455\n",
      "Ep:110, loss:0.00001, loss_test:0.02492, lr:3.56e-02, fs:0.65517 (r=0.576,p=0.760),  time:40.571, tt:4503.337\n",
      "Ep:111, loss:0.00001, loss_test:0.02481, lr:3.52e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.570, tt:4543.837\n",
      "Ep:112, loss:0.00001, loss_test:0.02509, lr:3.49e-02, fs:0.65517 (r=0.576,p=0.760),  time:40.571, tt:4584.475\n",
      "Ep:113, loss:0.00001, loss_test:0.02514, lr:3.45e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.561, tt:4623.914\n",
      "Ep:114, loss:0.00001, loss_test:0.02524, lr:3.42e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.550, tt:4663.300\n",
      "Ep:115, loss:0.00001, loss_test:0.02546, lr:3.38e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.552, tt:4704.075\n",
      "Ep:116, loss:0.00001, loss_test:0.02536, lr:3.35e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.555, tt:4744.962\n",
      "Ep:117, loss:0.00001, loss_test:0.02566, lr:3.32e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.540, tt:4783.679\n",
      "Ep:118, loss:0.00001, loss_test:0.02549, lr:3.28e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.525, tt:4822.490\n",
      "Ep:119, loss:0.00001, loss_test:0.02588, lr:3.25e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.530, tt:4863.618\n",
      "Ep:120, loss:0.00001, loss_test:0.02591, lr:3.22e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.524, tt:4903.420\n",
      "Ep:121, loss:0.00001, loss_test:0.02583, lr:3.19e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.535, tt:4945.254\n",
      "Ep:122, loss:0.00000, loss_test:0.02603, lr:3.15e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.535, tt:4985.857\n",
      "Ep:123, loss:0.00000, loss_test:0.02614, lr:3.12e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.536, tt:5026.466\n",
      "Ep:124, loss:0.00000, loss_test:0.02622, lr:3.09e-02, fs:0.65896 (r=0.576,p=0.770),  time:40.538, tt:5067.237\n",
      "Ep:125, loss:0.00000, loss_test:0.02613, lr:3.06e-02, fs:0.66279 (r=0.576,p=0.781),  time:40.537, tt:5107.639\n",
      "Ep:126, loss:0.00000, loss_test:0.02648, lr:3.03e-02, fs:0.66279 (r=0.576,p=0.781),  time:40.530, tt:5147.276\n",
      "Ep:127, loss:0.00000, loss_test:0.02649, lr:3.00e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.565, tt:5192.275\n",
      "Ep:128, loss:0.00000, loss_test:0.02645, lr:2.97e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.557, tt:5231.853\n",
      "Ep:129, loss:0.00000, loss_test:0.02673, lr:2.94e-02, fs:0.66279 (r=0.576,p=0.781),  time:40.548, tt:5271.248\n",
      "Ep:130, loss:0.00000, loss_test:0.02668, lr:2.91e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.552, tt:5312.255\n",
      "Ep:131, loss:0.00000, loss_test:0.02684, lr:2.88e-02, fs:0.66667 (r=0.576,p=0.792),  time:40.542, tt:5351.482\n",
      "Ep:132, loss:0.00000, loss_test:0.02684, lr:2.85e-02, fs:0.67059 (r=0.576,p=0.803),  time:40.542, tt:5392.072\n",
      "Ep:133, loss:0.00000, loss_test:0.02681, lr:2.82e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.535, tt:5431.676\n",
      "Ep:134, loss:0.00000, loss_test:0.02715, lr:2.80e-02, fs:0.67059 (r=0.576,p=0.803),  time:40.523, tt:5470.627\n",
      "Ep:135, loss:0.00000, loss_test:0.02708, lr:2.77e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.507, tt:5508.951\n",
      "Ep:136, loss:0.00000, loss_test:0.02698, lr:2.74e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.506, tt:5549.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02729, lr:2.71e-02, fs:0.67456 (r=0.576,p=0.814),  time:40.491, tt:5587.704\n",
      "Ep:138, loss:0.00000, loss_test:0.02725, lr:2.69e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.477, tt:5626.235\n",
      "Ep:139, loss:0.00000, loss_test:0.02725, lr:2.66e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.465, tt:5665.142\n",
      "Ep:140, loss:0.00000, loss_test:0.02760, lr:2.63e-02, fs:0.67456 (r=0.576,p=0.814),  time:40.466, tt:5705.649\n",
      "Ep:141, loss:0.00000, loss_test:0.02734, lr:2.61e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.461, tt:5745.440\n",
      "Ep:142, loss:0.00000, loss_test:0.02757, lr:2.58e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.446, tt:5783.798\n",
      "Ep:143, loss:0.00000, loss_test:0.02771, lr:2.55e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.451, tt:5824.925\n",
      "Ep:144, loss:0.00000, loss_test:0.02752, lr:2.53e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.469, tt:5867.939\n",
      "Ep:145, loss:0.00000, loss_test:0.02772, lr:2.50e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.464, tt:5907.764\n",
      "Ep:146, loss:0.00000, loss_test:0.02788, lr:2.48e-02, fs:0.68263 (r=0.576,p=0.838),  time:40.464, tt:5948.134\n",
      "Ep:147, loss:0.00000, loss_test:0.02771, lr:2.45e-02, fs:0.68263 (r=0.576,p=0.838),  time:40.455, tt:5987.295\n",
      "Ep:148, loss:0.00000, loss_test:0.02809, lr:2.43e-02, fs:0.68263 (r=0.576,p=0.838),  time:40.443, tt:6026.004\n",
      "Ep:149, loss:0.00000, loss_test:0.02793, lr:2.40e-02, fs:0.67857 (r=0.576,p=0.826),  time:40.427, tt:6064.099\n",
      "Ep:150, loss:0.00000, loss_test:0.02806, lr:2.38e-02, fs:0.68263 (r=0.576,p=0.838),  time:40.415, tt:6102.736\n",
      "Ep:151, loss:0.00000, loss_test:0.02820, lr:2.36e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.407, tt:6141.926\n",
      "Ep:152, loss:0.00000, loss_test:0.02816, lr:2.33e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.399, tt:6181.029\n",
      "Ep:153, loss:0.00000, loss_test:0.02809, lr:2.31e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.376, tt:6217.832\n",
      "Ep:154, loss:0.00000, loss_test:0.02842, lr:2.29e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.370, tt:6257.387\n",
      "Ep:155, loss:0.00000, loss_test:0.02825, lr:2.26e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.363, tt:6296.591\n",
      "Ep:156, loss:0.00000, loss_test:0.02847, lr:2.24e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.352, tt:6335.239\n",
      "Ep:157, loss:0.00000, loss_test:0.02843, lr:2.22e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.340, tt:6373.757\n",
      "Ep:158, loss:0.00000, loss_test:0.02847, lr:2.20e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.337, tt:6413.518\n",
      "Ep:159, loss:0.00000, loss_test:0.02860, lr:2.17e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.322, tt:6451.587\n",
      "Ep:160, loss:0.00000, loss_test:0.02870, lr:2.15e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.316, tt:6490.874\n",
      "Ep:161, loss:0.00000, loss_test:0.02868, lr:2.13e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.309, tt:6530.097\n",
      "Ep:162, loss:0.00000, loss_test:0.02885, lr:2.11e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.307, tt:6570.043\n",
      "Ep:163, loss:0.00000, loss_test:0.02878, lr:2.09e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.282, tt:6606.326\n",
      "Ep:164, loss:0.00000, loss_test:0.02874, lr:2.07e-02, fs:0.68675 (r=0.576,p=0.851),  time:40.275, tt:6645.426\n",
      "Ep:165, loss:0.00000, loss_test:0.02900, lr:2.05e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.278, tt:6686.085\n",
      "Ep:166, loss:0.00000, loss_test:0.02902, lr:2.03e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.281, tt:6726.891\n",
      "Ep:167, loss:0.00000, loss_test:0.02888, lr:2.01e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.286, tt:6768.085\n",
      "Ep:168, loss:0.00000, loss_test:0.02904, lr:1.99e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.295, tt:6809.935\n",
      "Ep:169, loss:0.00000, loss_test:0.02931, lr:1.97e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.304, tt:6851.631\n",
      "Ep:170, loss:0.00000, loss_test:0.02907, lr:1.95e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.303, tt:6891.763\n",
      "Ep:171, loss:0.00000, loss_test:0.02912, lr:1.93e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.301, tt:6931.823\n",
      "Ep:172, loss:0.00000, loss_test:0.02944, lr:1.91e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.302, tt:6972.162\n",
      "Ep:173, loss:0.00000, loss_test:0.02919, lr:1.89e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.298, tt:7011.876\n",
      "Ep:174, loss:0.00000, loss_test:0.02923, lr:1.87e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.294, tt:7051.526\n",
      "Ep:175, loss:0.00000, loss_test:0.02938, lr:1.85e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.297, tt:7092.213\n",
      "Ep:176, loss:0.00000, loss_test:0.02947, lr:1.83e-02, fs:0.69091 (r=0.576,p=0.864),  time:40.283, tt:7130.159\n",
      "Ep:177, loss:0.00000, loss_test:0.02942, lr:1.81e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.298, tt:7173.042\n",
      "Ep:178, loss:0.00000, loss_test:0.02950, lr:1.80e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.299, tt:7213.505\n",
      "Ep:179, loss:0.00000, loss_test:0.02959, lr:1.78e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.304, tt:7254.807\n",
      "Ep:180, loss:0.00000, loss_test:0.02951, lr:1.76e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.306, tt:7295.363\n",
      "Ep:181, loss:0.00000, loss_test:0.02963, lr:1.74e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.312, tt:7336.858\n",
      "Ep:182, loss:0.00000, loss_test:0.02970, lr:1.73e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.311, tt:7376.907\n",
      "Ep:183, loss:0.00000, loss_test:0.02974, lr:1.71e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.308, tt:7416.613\n",
      "Ep:184, loss:0.00000, loss_test:0.02971, lr:1.69e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.310, tt:7457.277\n",
      "Ep:185, loss:0.00000, loss_test:0.02986, lr:1.67e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.309, tt:7497.443\n",
      "Ep:186, loss:0.00000, loss_test:0.02985, lr:1.66e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.316, tt:7539.166\n",
      "Ep:187, loss:0.00000, loss_test:0.02979, lr:1.64e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.312, tt:7578.727\n",
      "Ep:188, loss:0.00000, loss_test:0.02994, lr:1.62e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.316, tt:7619.651\n",
      "Ep:189, loss:0.00000, loss_test:0.03006, lr:1.61e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.318, tt:7660.384\n",
      "Ep:190, loss:0.00000, loss_test:0.02989, lr:1.59e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.322, tt:7701.498\n",
      "Ep:191, loss:0.00000, loss_test:0.03001, lr:1.58e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.317, tt:7740.878\n",
      "Ep:192, loss:0.00000, loss_test:0.03024, lr:1.56e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.316, tt:7780.920\n",
      "Ep:193, loss:0.00000, loss_test:0.03012, lr:1.54e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.319, tt:7821.971\n",
      "Ep:194, loss:0.00000, loss_test:0.03009, lr:1.53e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.313, tt:7861.074\n",
      "Ep:195, loss:0.00000, loss_test:0.03022, lr:1.51e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.314, tt:7901.497\n",
      "Ep:196, loss:0.00000, loss_test:0.03031, lr:1.50e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.316, tt:7942.280\n",
      "Ep:197, loss:0.00000, loss_test:0.03022, lr:1.48e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.320, tt:7983.442\n",
      "Ep:198, loss:0.00000, loss_test:0.03030, lr:1.47e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.320, tt:8023.617\n",
      "Ep:199, loss:0.00000, loss_test:0.03035, lr:1.45e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.313, tt:8062.528\n",
      "Ep:200, loss:0.00000, loss_test:0.03045, lr:1.44e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.313, tt:8102.836\n",
      "Ep:201, loss:0.00000, loss_test:0.03046, lr:1.43e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.308, tt:8142.202\n",
      "Ep:202, loss:0.00000, loss_test:0.03034, lr:1.41e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.313, tt:8183.586\n",
      "Ep:203, loss:0.00000, loss_test:0.03051, lr:1.40e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.307, tt:8222.534\n",
      "Ep:204, loss:0.00000, loss_test:0.03065, lr:1.38e-02, fs:0.69512 (r=0.576,p=0.877),  time:40.292, tt:8259.928\n",
      "Ep:205, loss:0.00000, loss_test:0.03046, lr:1.37e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.285, tt:8298.627\n",
      "Ep:206, loss:0.00000, loss_test:0.03062, lr:1.36e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.286, tt:8339.239\n",
      "Ep:207, loss:0.00000, loss_test:0.03068, lr:1.34e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.298, tt:8381.889\n",
      "Ep:208, loss:0.00000, loss_test:0.03061, lr:1.33e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.269, tt:8416.278\n",
      "Ep:209, loss:0.00000, loss_test:0.03069, lr:1.32e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.225, tt:8447.220\n",
      "Ep:210, loss:0.00000, loss_test:0.03070, lr:1.30e-02, fs:0.69939 (r=0.576,p=0.891),  time:40.180, tt:8478.067\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14548, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.527, tt:37.527\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14435, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:39.551, tt:79.102\n",
      "Ep:2, loss:0.00027, loss_test:0.14215, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:40.060, tt:120.181\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13831, lr:1.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:40.321, tt:161.285\n",
      "Ep:4, loss:0.00025, loss_test:0.13656, lr:1.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:40.701, tt:203.504\n",
      "Ep:5, loss:0.00024, loss_test:0.13641, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:40.895, tt:245.372\n",
      "Ep:6, loss:0.00023, loss_test:0.13619, lr:1.00e-02, fs:0.60784 (r=0.626,p=0.590),  time:40.909, tt:286.363\n",
      "Ep:7, loss:0.00022, loss_test:0.13352, lr:1.00e-02, fs:0.61463 (r=0.636,p=0.594),  time:41.034, tt:328.268\n",
      "Ep:8, loss:0.00021, loss_test:0.13088, lr:1.00e-02, fs:0.62617 (r=0.677,p=0.583),  time:41.179, tt:370.611\n",
      "Ep:9, loss:0.00021, loss_test:0.13085, lr:1.00e-02, fs:0.60000 (r=0.636,p=0.568),  time:41.407, tt:414.067\n",
      "Ep:10, loss:0.00020, loss_test:0.13068, lr:1.00e-02, fs:0.59596 (r=0.596,p=0.596),  time:41.378, tt:455.158\n",
      "Ep:11, loss:0.00019, loss_test:0.12547, lr:1.00e-02, fs:0.61836 (r=0.646,p=0.593),  time:41.447, tt:497.360\n",
      "Ep:12, loss:0.00018, loss_test:0.12428, lr:1.00e-02, fs:0.61463 (r=0.636,p=0.594),  time:41.422, tt:538.482\n",
      "Ep:13, loss:0.00018, loss_test:0.12167, lr:1.00e-02, fs:0.62000 (r=0.626,p=0.614),  time:41.574, tt:582.039\n",
      "Ep:14, loss:0.00017, loss_test:0.11887, lr:9.90e-03, fs:0.62312 (r=0.626,p=0.620),  time:41.575, tt:623.630\n",
      "Ep:15, loss:0.00016, loss_test:0.11724, lr:9.80e-03, fs:0.60000 (r=0.576,p=0.626),  time:41.629, tt:666.057\n",
      "Ep:16, loss:0.00016, loss_test:0.11469, lr:9.70e-03, fs:0.62887 (r=0.616,p=0.642),  time:41.684, tt:708.631\n",
      "Ep:17, loss:0.00015, loss_test:0.11338, lr:9.61e-03, fs:0.64171 (r=0.606,p=0.682),  time:41.586, tt:748.542\n",
      "Ep:18, loss:0.00015, loss_test:0.11246, lr:9.51e-03, fs:0.63874 (r=0.616,p=0.663),  time:41.542, tt:789.289\n",
      "Ep:19, loss:0.00014, loss_test:0.11116, lr:9.41e-03, fs:0.63492 (r=0.606,p=0.667),  time:41.491, tt:829.828\n",
      "Ep:20, loss:0.00014, loss_test:0.11055, lr:9.32e-03, fs:0.65285 (r=0.636,p=0.670),  time:41.423, tt:869.891\n",
      "Ep:21, loss:0.00013, loss_test:0.10963, lr:9.23e-03, fs:0.64865 (r=0.606,p=0.698),  time:41.492, tt:912.818\n",
      "Ep:22, loss:0.00013, loss_test:0.10687, lr:9.14e-03, fs:0.67380 (r=0.636,p=0.716),  time:41.477, tt:953.978\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.10611, lr:9.14e-03, fs:0.68085 (r=0.646,p=0.719),  time:41.443, tt:994.625\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.10529, lr:9.14e-03, fs:0.71429 (r=0.707,p=0.722),  time:41.377, tt:1034.428\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.10390, lr:9.14e-03, fs:0.70833 (r=0.687,p=0.731),  time:41.274, tt:1073.124\n",
      "Ep:26, loss:0.00011, loss_test:0.10508, lr:9.14e-03, fs:0.70833 (r=0.687,p=0.731),  time:41.210, tt:1112.665\n",
      "Ep:27, loss:0.00010, loss_test:0.10363, lr:9.14e-03, fs:0.72727 (r=0.727,p=0.727),  time:41.214, tt:1153.992\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.10276, lr:9.14e-03, fs:0.72222 (r=0.657,p=0.802),  time:41.299, tt:1197.675\n",
      "Ep:29, loss:0.00010, loss_test:0.10523, lr:9.14e-03, fs:0.74611 (r=0.727,p=0.766),  time:41.325, tt:1239.759\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.10111, lr:9.14e-03, fs:0.78049 (r=0.808,p=0.755),  time:41.362, tt:1282.230\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.10079, lr:9.14e-03, fs:0.72131 (r=0.667,p=0.786),  time:41.384, tt:1324.300\n",
      "Ep:32, loss:0.00009, loss_test:0.10143, lr:9.14e-03, fs:0.71508 (r=0.646,p=0.800),  time:41.412, tt:1366.604\n",
      "Ep:33, loss:0.00008, loss_test:0.09900, lr:9.14e-03, fs:0.77228 (r=0.788,p=0.757),  time:41.396, tt:1407.469\n",
      "Ep:34, loss:0.00008, loss_test:0.09868, lr:9.14e-03, fs:0.75127 (r=0.747,p=0.755),  time:41.448, tt:1450.691\n",
      "Ep:35, loss:0.00008, loss_test:0.09751, lr:9.14e-03, fs:0.74737 (r=0.717,p=0.780),  time:41.473, tt:1493.030\n",
      "Ep:36, loss:0.00007, loss_test:0.09967, lr:9.14e-03, fs:0.76382 (r=0.768,p=0.760),  time:41.475, tt:1534.557\n",
      "Ep:37, loss:0.00007, loss_test:0.09558, lr:9.14e-03, fs:0.75676 (r=0.707,p=0.814),  time:41.434, tt:1574.495\n",
      "Ep:38, loss:0.00007, loss_test:0.09872, lr:9.14e-03, fs:0.71739 (r=0.667,p=0.776),  time:41.464, tt:1617.082\n",
      "Ep:39, loss:0.00007, loss_test:0.09534, lr:9.14e-03, fs:0.78469 (r=0.828,p=0.745),  time:41.491, tt:1659.649\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.09843, lr:9.14e-03, fs:0.74713 (r=0.657,p=0.867),  time:41.540, tt:1703.130\n",
      "Ep:41, loss:0.00006, loss_test:0.09618, lr:9.14e-03, fs:0.77670 (r=0.808,p=0.748),  time:41.511, tt:1743.465\n",
      "Ep:42, loss:0.00006, loss_test:0.09634, lr:9.14e-03, fs:0.74157 (r=0.667,p=0.835),  time:41.495, tt:1784.295\n",
      "Ep:43, loss:0.00006, loss_test:0.10112, lr:9.14e-03, fs:0.72432 (r=0.677,p=0.779),  time:41.446, tt:1823.605\n",
      "Ep:44, loss:0.00006, loss_test:0.09339, lr:9.14e-03, fs:0.75258 (r=0.737,p=0.768),  time:41.463, tt:1865.844\n",
      "Ep:45, loss:0.00005, loss_test:0.09970, lr:9.14e-03, fs:0.73143 (r=0.646,p=0.842),  time:41.448, tt:1906.624\n",
      "Ep:46, loss:0.00005, loss_test:0.09619, lr:9.14e-03, fs:0.73196 (r=0.717,p=0.747),  time:41.454, tt:1948.344\n",
      "Ep:47, loss:0.00005, loss_test:0.10039, lr:9.14e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.431, tt:1988.686\n",
      "Ep:48, loss:0.00005, loss_test:0.09725, lr:9.14e-03, fs:0.71958 (r=0.687,p=0.756),  time:41.445, tt:2030.814\n",
      "Ep:49, loss:0.00005, loss_test:0.09926, lr:9.14e-03, fs:0.71084 (r=0.596,p=0.881),  time:41.437, tt:2071.864\n",
      "Ep:50, loss:0.00004, loss_test:0.09509, lr:9.14e-03, fs:0.72917 (r=0.707,p=0.753),  time:41.473, tt:2115.104\n",
      "Ep:51, loss:0.00005, loss_test:0.09442, lr:9.04e-03, fs:0.72414 (r=0.636,p=0.840),  time:41.448, tt:2155.287\n",
      "Ep:52, loss:0.00004, loss_test:0.09414, lr:8.95e-03, fs:0.74157 (r=0.667,p=0.835),  time:41.449, tt:2196.773\n",
      "Ep:53, loss:0.00004, loss_test:0.10298, lr:8.86e-03, fs:0.70520 (r=0.616,p=0.824),  time:41.462, tt:2238.964\n",
      "Ep:54, loss:0.00004, loss_test:0.09564, lr:8.78e-03, fs:0.74033 (r=0.677,p=0.817),  time:41.484, tt:2281.638\n",
      "Ep:55, loss:0.00004, loss_test:0.09866, lr:8.69e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.506, tt:2324.316\n",
      "Ep:56, loss:0.00004, loss_test:0.09221, lr:8.60e-03, fs:0.74317 (r=0.687,p=0.810),  time:41.512, tt:2366.157\n",
      "Ep:57, loss:0.00003, loss_test:0.09583, lr:8.51e-03, fs:0.73333 (r=0.667,p=0.815),  time:41.517, tt:2408.012\n",
      "Ep:58, loss:0.00003, loss_test:0.09967, lr:8.43e-03, fs:0.72000 (r=0.636,p=0.829),  time:41.482, tt:2447.411\n",
      "Ep:59, loss:0.00003, loss_test:0.09582, lr:8.35e-03, fs:0.73864 (r=0.657,p=0.844),  time:41.486, tt:2489.184\n",
      "Ep:60, loss:0.00003, loss_test:0.09763, lr:8.26e-03, fs:0.70659 (r=0.596,p=0.868),  time:41.529, tt:2533.290\n",
      "Ep:61, loss:0.00003, loss_test:0.09976, lr:8.18e-03, fs:0.71084 (r=0.596,p=0.881),  time:41.528, tt:2574.733\n",
      "Ep:62, loss:0.00003, loss_test:0.09763, lr:8.10e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.496, tt:2614.221\n",
      "Ep:63, loss:0.00003, loss_test:0.09635, lr:8.02e-03, fs:0.74576 (r=0.667,p=0.846),  time:41.486, tt:2655.108\n",
      "Ep:64, loss:0.00003, loss_test:0.09882, lr:7.94e-03, fs:0.69822 (r=0.596,p=0.843),  time:41.454, tt:2694.530\n",
      "Ep:65, loss:0.00002, loss_test:0.09761, lr:7.86e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.444, tt:2735.317\n",
      "Ep:66, loss:0.00002, loss_test:0.09788, lr:7.78e-03, fs:0.76836 (r=0.687,p=0.872),  time:41.444, tt:2776.716\n",
      "Ep:67, loss:0.00002, loss_test:0.09904, lr:7.70e-03, fs:0.73684 (r=0.636,p=0.875),  time:41.466, tt:2819.707\n",
      "Ep:68, loss:0.00002, loss_test:0.10089, lr:7.62e-03, fs:0.74419 (r=0.646,p=0.877),  time:41.465, tt:2861.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00002, loss_test:0.09617, lr:7.55e-03, fs:0.73563 (r=0.646,p=0.853),  time:41.458, tt:2902.073\n",
      "Ep:70, loss:0.00002, loss_test:0.10189, lr:7.47e-03, fs:0.70659 (r=0.596,p=0.868),  time:41.431, tt:2941.615\n",
      "Ep:71, loss:0.00002, loss_test:0.10084, lr:7.40e-03, fs:0.71515 (r=0.596,p=0.894),  time:41.442, tt:2983.794\n",
      "Ep:72, loss:0.00002, loss_test:0.09707, lr:7.32e-03, fs:0.73988 (r=0.646,p=0.865),  time:41.444, tt:3025.425\n",
      "Ep:73, loss:0.00002, loss_test:0.11362, lr:7.25e-03, fs:0.72956 (r=0.586,p=0.967),  time:41.433, tt:3066.033\n",
      "Ep:74, loss:0.00002, loss_test:0.09522, lr:7.18e-03, fs:0.74419 (r=0.646,p=0.877),  time:41.431, tt:3107.314\n",
      "Ep:75, loss:0.00002, loss_test:0.09882, lr:7.11e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.448, tt:3150.083\n",
      "Ep:76, loss:0.00002, loss_test:0.10096, lr:7.03e-03, fs:0.74576 (r=0.667,p=0.846),  time:41.461, tt:3192.526\n",
      "Ep:77, loss:0.00002, loss_test:0.09790, lr:6.96e-03, fs:0.72941 (r=0.626,p=0.873),  time:41.491, tt:3236.293\n",
      "Ep:78, loss:0.00002, loss_test:0.10207, lr:6.89e-03, fs:0.74118 (r=0.636,p=0.887),  time:41.484, tt:3277.220\n",
      "Ep:79, loss:0.00002, loss_test:0.09879, lr:6.83e-03, fs:0.73054 (r=0.616,p=0.897),  time:41.451, tt:3316.093\n",
      "Ep:80, loss:0.00001, loss_test:0.10647, lr:6.76e-03, fs:0.70732 (r=0.586,p=0.892),  time:41.457, tt:3358.024\n",
      "Ep:81, loss:0.00002, loss_test:0.10061, lr:6.69e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.428, tt:3397.129\n",
      "Ep:82, loss:0.00001, loss_test:0.09504, lr:6.62e-03, fs:0.71765 (r=0.616,p=0.859),  time:41.436, tt:3439.163\n",
      "Ep:83, loss:0.00001, loss_test:0.10770, lr:6.56e-03, fs:0.72956 (r=0.586,p=0.967),  time:41.435, tt:3480.506\n",
      "Ep:84, loss:0.00001, loss_test:0.09653, lr:6.49e-03, fs:0.76301 (r=0.667,p=0.892),  time:41.453, tt:3523.498\n",
      "Ep:85, loss:0.00001, loss_test:0.10536, lr:6.43e-03, fs:0.71951 (r=0.596,p=0.908),  time:41.493, tt:3568.410\n",
      "Ep:86, loss:0.00001, loss_test:0.10455, lr:6.36e-03, fs:0.72289 (r=0.606,p=0.896),  time:41.502, tt:3610.652\n",
      "Ep:87, loss:0.00001, loss_test:0.09917, lr:6.30e-03, fs:0.72619 (r=0.616,p=0.884),  time:41.487, tt:3650.839\n",
      "Ep:88, loss:0.00001, loss_test:0.10304, lr:6.24e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.502, tt:3693.638\n",
      "Ep:89, loss:0.00001, loss_test:0.09712, lr:6.17e-03, fs:0.71429 (r=0.606,p=0.870),  time:41.511, tt:3735.970\n",
      "Ep:90, loss:0.00001, loss_test:0.10500, lr:6.11e-03, fs:0.71951 (r=0.596,p=0.908),  time:41.528, tt:3779.089\n",
      "Ep:91, loss:0.00001, loss_test:0.10309, lr:6.05e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.542, tt:3821.877\n",
      "Ep:92, loss:0.00001, loss_test:0.09588, lr:5.99e-03, fs:0.72941 (r=0.626,p=0.873),  time:41.551, tt:3864.239\n",
      "Ep:93, loss:0.00001, loss_test:0.10759, lr:5.93e-03, fs:0.72956 (r=0.586,p=0.967),  time:41.574, tt:3907.915\n",
      "Ep:94, loss:0.00001, loss_test:0.09778, lr:5.87e-03, fs:0.73494 (r=0.616,p=0.910),  time:41.601, tt:3952.138\n",
      "Ep:95, loss:0.00001, loss_test:0.10312, lr:5.81e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.626, tt:3996.057\n",
      "Ep:96, loss:0.00001, loss_test:0.10532, lr:5.75e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.644, tt:4039.471\n",
      "Ep:97, loss:0.00001, loss_test:0.09618, lr:5.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:41.665, tt:4083.183\n",
      "Ep:98, loss:0.00001, loss_test:0.10169, lr:5.64e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.662, tt:4124.519\n",
      "Ep:99, loss:0.00001, loss_test:0.10283, lr:5.58e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.672, tt:4167.218\n",
      "Ep:100, loss:0.00001, loss_test:0.09927, lr:5.53e-03, fs:0.73054 (r=0.616,p=0.897),  time:41.677, tt:4209.337\n",
      "Ep:101, loss:0.00001, loss_test:0.10299, lr:5.47e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.686, tt:4251.982\n",
      "Ep:102, loss:0.00001, loss_test:0.10043, lr:5.42e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.687, tt:4293.775\n",
      "Ep:103, loss:0.00001, loss_test:0.09994, lr:5.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.702, tt:4337.034\n",
      "Ep:104, loss:0.00001, loss_test:0.10117, lr:5.31e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.727, tt:4381.369\n",
      "Ep:105, loss:0.00001, loss_test:0.10092, lr:5.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.741, tt:4424.528\n",
      "Ep:106, loss:0.00001, loss_test:0.10097, lr:5.20e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.738, tt:4465.996\n",
      "Ep:107, loss:0.00001, loss_test:0.10315, lr:5.15e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.735, tt:4507.375\n",
      "Ep:108, loss:0.00001, loss_test:0.10121, lr:5.10e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.747, tt:4550.470\n",
      "Ep:109, loss:0.00001, loss_test:0.10083, lr:5.05e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.764, tt:4594.062\n",
      "Ep:110, loss:0.00001, loss_test:0.10115, lr:5.00e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.760, tt:4635.327\n",
      "Ep:111, loss:0.00001, loss_test:0.10060, lr:4.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.767, tt:4677.906\n",
      "Ep:112, loss:0.00001, loss_test:0.10051, lr:4.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.786, tt:4721.849\n",
      "Ep:113, loss:0.00001, loss_test:0.10247, lr:4.85e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.797, tt:4764.876\n",
      "Ep:114, loss:0.00001, loss_test:0.10032, lr:4.80e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.816, tt:4808.875\n",
      "Ep:115, loss:0.00001, loss_test:0.10217, lr:4.75e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.833, tt:4852.570\n",
      "Ep:116, loss:0.00001, loss_test:0.10162, lr:4.71e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.846, tt:4896.025\n",
      "Ep:117, loss:0.00001, loss_test:0.10229, lr:4.66e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.867, tt:4940.315\n",
      "Ep:118, loss:0.00001, loss_test:0.10300, lr:4.61e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.879, tt:4983.575\n",
      "Ep:119, loss:0.00001, loss_test:0.10150, lr:4.57e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.879, tt:5025.438\n",
      "Ep:120, loss:0.00001, loss_test:0.10400, lr:4.52e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.897, tt:5069.477\n",
      "Ep:121, loss:0.00000, loss_test:0.10270, lr:4.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.897, tt:5111.416\n",
      "Ep:122, loss:0.00000, loss_test:0.09982, lr:4.43e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.907, tt:5154.578\n",
      "Ep:123, loss:0.00000, loss_test:0.10306, lr:4.39e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.911, tt:5196.938\n",
      "Ep:124, loss:0.00000, loss_test:0.10129, lr:4.34e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.906, tt:5238.201\n",
      "Ep:125, loss:0.00000, loss_test:0.10071, lr:4.30e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.905, tt:5279.988\n",
      "Ep:126, loss:0.00000, loss_test:0.10419, lr:4.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.908, tt:5322.373\n",
      "Ep:127, loss:0.00000, loss_test:0.10202, lr:4.21e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.899, tt:5363.125\n",
      "Ep:128, loss:0.00000, loss_test:0.10339, lr:4.17e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.894, tt:5404.322\n",
      "Ep:129, loss:0.00000, loss_test:0.10269, lr:4.13e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.887, tt:5445.269\n",
      "Ep:130, loss:0.00000, loss_test:0.10167, lr:4.09e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.884, tt:5486.814\n",
      "Ep:131, loss:0.00000, loss_test:0.10159, lr:4.05e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.873, tt:5527.234\n",
      "Ep:132, loss:0.00000, loss_test:0.10348, lr:4.01e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.862, tt:5567.638\n",
      "Ep:133, loss:0.00000, loss_test:0.10472, lr:3.97e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.853, tt:5608.365\n",
      "Ep:134, loss:0.00000, loss_test:0.10245, lr:3.93e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.854, tt:5650.320\n",
      "Ep:135, loss:0.00000, loss_test:0.10322, lr:3.89e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.861, tt:5693.116\n",
      "Ep:136, loss:0.00000, loss_test:0.10263, lr:3.85e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.866, tt:5735.578\n",
      "Ep:137, loss:0.00000, loss_test:0.10308, lr:3.81e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.859, tt:5776.554\n",
      "Ep:138, loss:0.00000, loss_test:0.10314, lr:3.77e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.873, tt:5820.309\n",
      "Ep:139, loss:0.00000, loss_test:0.10201, lr:3.73e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.868, tt:5861.526\n",
      "Ep:140, loss:0.00000, loss_test:0.10399, lr:3.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.878, tt:5904.757\n",
      "Ep:141, loss:0.00000, loss_test:0.10301, lr:3.66e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.880, tt:5946.976\n",
      "Ep:142, loss:0.00000, loss_test:0.10395, lr:3.62e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.884, tt:5989.376\n",
      "Ep:143, loss:0.00000, loss_test:0.10268, lr:3.59e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.876, tt:6030.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.10212, lr:3.55e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.878, tt:6072.381\n",
      "Ep:145, loss:0.00000, loss_test:0.10296, lr:3.52e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.864, tt:6112.080\n",
      "Ep:146, loss:0.00000, loss_test:0.10524, lr:3.48e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.876, tt:6155.715\n",
      "Ep:147, loss:0.00000, loss_test:0.10330, lr:3.45e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.890, tt:6199.702\n",
      "Ep:148, loss:0.00000, loss_test:0.10225, lr:3.41e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.885, tt:6240.876\n",
      "Ep:149, loss:0.00000, loss_test:0.10363, lr:3.38e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.873, tt:6280.929\n",
      "Ep:150, loss:0.00000, loss_test:0.10358, lr:3.34e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.876, tt:6323.299\n",
      "Ep:151, loss:0.00000, loss_test:0.10386, lr:3.31e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.888, tt:6366.925\n",
      "Ep:152, loss:0.00000, loss_test:0.10356, lr:3.28e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.888, tt:6408.927\n",
      "Ep:153, loss:0.00000, loss_test:0.10371, lr:3.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.893, tt:6451.551\n",
      "Ep:154, loss:0.00000, loss_test:0.10238, lr:3.21e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.898, tt:6494.162\n",
      "Ep:155, loss:0.00000, loss_test:0.10376, lr:3.18e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.908, tt:6537.608\n",
      "Ep:156, loss:0.00000, loss_test:0.10460, lr:3.15e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.905, tt:6579.162\n",
      "Ep:157, loss:0.00000, loss_test:0.10274, lr:3.12e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.908, tt:6621.409\n",
      "Ep:158, loss:0.00000, loss_test:0.10337, lr:3.09e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.904, tt:6662.741\n",
      "Ep:159, loss:0.00000, loss_test:0.10294, lr:3.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.924, tt:6707.881\n",
      "Ep:160, loss:0.00000, loss_test:0.10295, lr:3.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.944, tt:6753.032\n",
      "Ep:161, loss:0.00000, loss_test:0.10395, lr:2.99e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.946, tt:6795.289\n",
      "Ep:162, loss:0.00000, loss_test:0.10357, lr:2.96e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.960, tt:6839.503\n",
      "Ep:163, loss:0.00000, loss_test:0.10323, lr:2.93e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.955, tt:6880.653\n",
      "Ep:164, loss:0.00000, loss_test:0.10378, lr:2.90e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.987, tt:6927.909\n",
      "Ep:165, loss:0.00000, loss_test:0.10411, lr:2.88e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.994, tt:6970.976\n",
      "Ep:166, loss:0.00000, loss_test:0.10319, lr:2.85e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.990, tt:7012.247\n",
      "Ep:167, loss:0.00000, loss_test:0.10405, lr:2.82e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.004, tt:7056.670\n",
      "Ep:168, loss:0.00000, loss_test:0.10505, lr:2.79e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.009, tt:7099.494\n",
      "Ep:169, loss:0.00000, loss_test:0.10334, lr:2.76e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.012, tt:7141.961\n",
      "Ep:170, loss:0.00000, loss_test:0.10441, lr:2.73e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.013, tt:7184.220\n",
      "Ep:171, loss:0.00000, loss_test:0.10474, lr:2.71e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.020, tt:7227.460\n",
      "Ep:172, loss:0.00000, loss_test:0.10364, lr:2.68e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.026, tt:7270.490\n",
      "Ep:173, loss:0.00000, loss_test:0.10361, lr:2.65e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.039, tt:7314.701\n",
      "Ep:174, loss:0.00000, loss_test:0.10417, lr:2.63e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.045, tt:7357.831\n",
      "Ep:175, loss:0.00000, loss_test:0.10371, lr:2.60e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.037, tt:7398.528\n",
      "Ep:176, loss:0.00000, loss_test:0.10400, lr:2.57e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.048, tt:7442.523\n",
      "Ep:177, loss:0.00000, loss_test:0.10416, lr:2.55e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.053, tt:7485.418\n",
      "Ep:178, loss:0.00000, loss_test:0.10292, lr:2.52e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.059, tt:7528.473\n",
      "Ep:179, loss:0.00000, loss_test:0.10385, lr:2.50e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.060, tt:7570.877\n",
      "Ep:180, loss:0.00000, loss_test:0.10379, lr:2.47e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.071, tt:7614.940\n",
      "Ep:181, loss:0.00000, loss_test:0.10357, lr:2.45e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.071, tt:7656.961\n",
      "Ep:182, loss:0.00000, loss_test:0.10467, lr:2.42e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.075, tt:7699.789\n",
      "Ep:183, loss:0.00000, loss_test:0.10435, lr:2.40e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.075, tt:7741.782\n",
      "Ep:184, loss:0.00000, loss_test:0.10289, lr:2.38e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.093, tt:7787.174\n",
      "Ep:185, loss:0.00000, loss_test:0.10429, lr:2.35e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.101, tt:7830.715\n",
      "Ep:186, loss:0.00000, loss_test:0.10506, lr:2.33e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.102, tt:7873.150\n",
      "Ep:187, loss:0.00000, loss_test:0.10399, lr:2.31e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.112, tt:7917.001\n",
      "Ep:188, loss:0.00000, loss_test:0.10409, lr:2.28e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.110, tt:7958.850\n",
      "Ep:189, loss:0.00000, loss_test:0.10424, lr:2.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.117, tt:8002.146\n",
      "Ep:190, loss:0.00000, loss_test:0.10364, lr:2.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.106, tt:8042.276\n",
      "Ep:191, loss:0.00000, loss_test:0.10473, lr:2.21e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.106, tt:8084.356\n",
      "Ep:192, loss:0.00000, loss_test:0.10453, lr:2.19e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.108, tt:8126.760\n",
      "Ep:193, loss:0.00000, loss_test:0.10395, lr:2.17e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.100, tt:8167.346\n",
      "Ep:194, loss:0.00000, loss_test:0.10409, lr:2.15e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.098, tt:8209.144\n",
      "Ep:195, loss:0.00000, loss_test:0.10391, lr:2.13e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.090, tt:8249.706\n",
      "Ep:196, loss:0.00000, loss_test:0.10452, lr:2.11e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.125, tt:8298.698\n",
      "Ep:197, loss:0.00000, loss_test:0.10435, lr:2.08e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.119, tt:8339.488\n",
      "Ep:198, loss:0.00000, loss_test:0.10459, lr:2.06e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.114, tt:8380.682\n",
      "Ep:199, loss:0.00000, loss_test:0.10437, lr:2.04e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.112, tt:8422.334\n",
      "Ep:200, loss:0.00000, loss_test:0.10419, lr:2.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.113, tt:8464.636\n",
      "Ep:201, loss:0.00000, loss_test:0.10463, lr:2.00e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.105, tt:8505.208\n",
      "Ep:202, loss:0.00000, loss_test:0.10512, lr:1.98e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.112, tt:8548.738\n",
      "Ep:203, loss:0.00000, loss_test:0.10447, lr:1.96e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.107, tt:8589.855\n",
      "Ep:204, loss:0.00000, loss_test:0.10425, lr:1.94e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.101, tt:8630.768\n",
      "Ep:205, loss:0.00000, loss_test:0.10399, lr:1.92e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.102, tt:8672.988\n",
      "Ep:206, loss:0.00000, loss_test:0.10428, lr:1.90e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.112, tt:8717.270\n",
      "Ep:207, loss:0.00000, loss_test:0.10388, lr:1.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.111, tt:8759.091\n",
      "Ep:208, loss:0.00000, loss_test:0.10427, lr:1.87e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.100, tt:8798.847\n",
      "Ep:209, loss:0.00000, loss_test:0.10454, lr:1.85e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.062, tt:8832.930\n",
      "Ep:210, loss:0.00000, loss_test:0.10424, lr:1.83e-03, fs:0.74847 (r=0.616,p=0.953),  time:42.021, tt:8866.345\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02312, lr:6.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:29.656, tt:29.656\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00004, loss_test:0.02441, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:33.098, tt:66.197\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02563, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.257, tt:108.772\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02519, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.700, tt:150.798\n",
      "Ep:4, loss:0.00004, loss_test:0.02390, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:38.770, tt:193.850\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02282, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:39.094, tt:234.564\n",
      "Ep:6, loss:0.00004, loss_test:0.02303, lr:6.00e-02, fs:0.62348 (r=0.778,p=0.520),  time:39.153, tt:274.069\n",
      "Ep:7, loss:0.00004, loss_test:0.02435, lr:6.00e-02, fs:0.57759 (r=0.677,p=0.504),  time:39.308, tt:314.463\n",
      "Ep:8, loss:0.00004, loss_test:0.02468, lr:6.00e-02, fs:0.59193 (r=0.667,p=0.532),  time:39.405, tt:354.646\n",
      "Ep:9, loss:0.00004, loss_test:0.02349, lr:6.00e-02, fs:0.59292 (r=0.677,p=0.528),  time:39.324, tt:393.236\n",
      "Ep:10, loss:0.00003, loss_test:0.02226, lr:6.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:39.484, tt:434.327\n",
      "Ep:11, loss:0.00003, loss_test:0.02166, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:39.637, tt:475.646\n",
      "Ep:12, loss:0.00003, loss_test:0.02140, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:40.218, tt:522.834\n",
      "Ep:13, loss:0.00003, loss_test:0.02154, lr:6.00e-02, fs:0.65000 (r=0.788,p=0.553),  time:40.289, tt:564.041\n",
      "Ep:14, loss:0.00003, loss_test:0.02187, lr:6.00e-02, fs:0.65487 (r=0.747,p=0.583),  time:40.388, tt:605.824\n",
      "Ep:15, loss:0.00003, loss_test:0.02157, lr:6.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:40.300, tt:644.808\n",
      "Ep:16, loss:0.00003, loss_test:0.02065, lr:5.94e-02, fs:0.67544 (r=0.778,p=0.597),  time:40.287, tt:684.882\n",
      "Ep:17, loss:0.00003, loss_test:0.01997, lr:5.88e-02, fs:0.69787 (r=0.828,p=0.603),  time:40.279, tt:725.028\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01961, lr:5.88e-02, fs:0.70886 (r=0.848,p=0.609),  time:40.197, tt:763.740\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01953, lr:5.88e-02, fs:0.71186 (r=0.848,p=0.613),  time:40.254, tt:805.081\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01953, lr:5.88e-02, fs:0.71245 (r=0.838,p=0.619),  time:40.299, tt:846.269\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01930, lr:5.88e-02, fs:0.72174 (r=0.838,p=0.634),  time:40.381, tt:888.377\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01890, lr:5.88e-02, fs:0.72414 (r=0.848,p=0.632),  time:40.366, tt:928.413\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01858, lr:5.88e-02, fs:0.72414 (r=0.848,p=0.632),  time:40.419, tt:970.063\n",
      "Ep:24, loss:0.00002, loss_test:0.01846, lr:5.88e-02, fs:0.72727 (r=0.848,p=0.636),  time:40.433, tt:1010.836\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01853, lr:5.88e-02, fs:0.69683 (r=0.778,p=0.631),  time:40.395, tt:1050.278\n",
      "Ep:26, loss:0.00002, loss_test:0.01846, lr:5.88e-02, fs:0.69369 (r=0.778,p=0.626),  time:40.403, tt:1090.881\n",
      "Ep:27, loss:0.00002, loss_test:0.01824, lr:5.88e-02, fs:0.68468 (r=0.768,p=0.618),  time:40.430, tt:1132.028\n",
      "Ep:28, loss:0.00002, loss_test:0.01820, lr:5.88e-02, fs:0.68468 (r=0.768,p=0.618),  time:40.456, tt:1173.237\n",
      "Ep:29, loss:0.00002, loss_test:0.01816, lr:5.88e-02, fs:0.69091 (r=0.768,p=0.628),  time:40.465, tt:1213.947\n",
      "Ep:30, loss:0.00002, loss_test:0.01817, lr:5.88e-02, fs:0.69725 (r=0.768,p=0.639),  time:40.449, tt:1253.927\n",
      "Ep:31, loss:0.00002, loss_test:0.01814, lr:5.88e-02, fs:0.70000 (r=0.778,p=0.636),  time:40.405, tt:1292.948\n",
      "Ep:32, loss:0.00002, loss_test:0.01818, lr:5.88e-02, fs:0.70588 (r=0.788,p=0.639),  time:40.433, tt:1334.278\n",
      "Ep:33, loss:0.00002, loss_test:0.01834, lr:5.88e-02, fs:0.70909 (r=0.788,p=0.645),  time:40.498, tt:1376.933\n",
      "Ep:34, loss:0.00002, loss_test:0.01838, lr:5.88e-02, fs:0.70909 (r=0.788,p=0.645),  time:40.495, tt:1417.308\n",
      "Ep:35, loss:0.00002, loss_test:0.01839, lr:5.88e-02, fs:0.71889 (r=0.788,p=0.661),  time:40.518, tt:1458.643\n",
      "Ep:36, loss:0.00002, loss_test:0.01839, lr:5.82e-02, fs:0.71963 (r=0.778,p=0.670),  time:40.512, tt:1498.935\n",
      "Ep:37, loss:0.00002, loss_test:0.01846, lr:5.76e-02, fs:0.72642 (r=0.778,p=0.681),  time:40.542, tt:1540.598\n",
      "Ep:38, loss:0.00002, loss_test:0.01861, lr:5.71e-02, fs:0.72986 (r=0.778,p=0.688),  time:40.547, tt:1581.332\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01860, lr:5.71e-02, fs:0.72300 (r=0.778,p=0.675),  time:40.547, tt:1621.866\n",
      "Ep:40, loss:0.00002, loss_test:0.01861, lr:5.71e-02, fs:0.72300 (r=0.778,p=0.675),  time:40.620, tt:1665.409\n",
      "Ep:41, loss:0.00002, loss_test:0.01876, lr:5.71e-02, fs:0.73077 (r=0.768,p=0.697),  time:40.638, tt:1706.804\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01875, lr:5.71e-02, fs:0.72727 (r=0.768,p=0.691),  time:40.660, tt:1748.364\n",
      "Ep:43, loss:0.00001, loss_test:0.01876, lr:5.71e-02, fs:0.72727 (r=0.768,p=0.691),  time:40.695, tt:1790.599\n",
      "Ep:44, loss:0.00001, loss_test:0.01888, lr:5.71e-02, fs:0.73077 (r=0.768,p=0.697),  time:40.716, tt:1832.227\n",
      "Ep:45, loss:0.00001, loss_test:0.01894, lr:5.71e-02, fs:0.73077 (r=0.768,p=0.697),  time:40.753, tt:1874.637\n",
      "Ep:46, loss:0.00001, loss_test:0.01894, lr:5.71e-02, fs:0.73077 (r=0.768,p=0.697),  time:40.748, tt:1915.157\n",
      "Ep:47, loss:0.00001, loss_test:0.01905, lr:5.71e-02, fs:0.73077 (r=0.768,p=0.697),  time:40.750, tt:1956.008\n",
      "Ep:48, loss:0.00001, loss_test:0.01932, lr:5.71e-02, fs:0.72816 (r=0.758,p=0.701),  time:40.778, tt:1998.140\n",
      "Ep:49, loss:0.00001, loss_test:0.01930, lr:5.71e-02, fs:0.72816 (r=0.758,p=0.701),  time:40.782, tt:2039.084\n",
      "Ep:50, loss:0.00001, loss_test:0.01937, lr:5.71e-02, fs:0.72816 (r=0.758,p=0.701),  time:40.768, tt:2079.164\n",
      "Ep:51, loss:0.00001, loss_test:0.01954, lr:5.71e-02, fs:0.72816 (r=0.758,p=0.701),  time:40.791, tt:2121.113\n",
      "Ep:52, loss:0.00001, loss_test:0.01965, lr:5.71e-02, fs:0.73529 (r=0.758,p=0.714),  time:40.810, tt:2162.954\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01970, lr:5.71e-02, fs:0.73171 (r=0.758,p=0.708),  time:40.801, tt:2203.229\n",
      "Ep:54, loss:0.00001, loss_test:0.01981, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.824, tt:2245.338\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01998, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.856, tt:2287.923\n",
      "Ep:56, loss:0.00001, loss_test:0.02013, lr:5.71e-02, fs:0.75122 (r=0.778,p=0.726),  time:40.876, tt:2329.934\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.02028, lr:5.71e-02, fs:0.74510 (r=0.768,p=0.724),  time:40.906, tt:2372.533\n",
      "Ep:58, loss:0.00001, loss_test:0.02045, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.944, tt:2415.718\n",
      "Ep:59, loss:0.00001, loss_test:0.02051, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.926, tt:2455.550\n",
      "Ep:60, loss:0.00001, loss_test:0.02054, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.940, tt:2497.342\n",
      "Ep:61, loss:0.00001, loss_test:0.02067, lr:5.71e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.950, tt:2538.872\n",
      "Ep:62, loss:0.00001, loss_test:0.02086, lr:5.71e-02, fs:0.73267 (r=0.747,p=0.718),  time:40.969, tt:2581.029\n",
      "Ep:63, loss:0.00001, loss_test:0.02091, lr:5.71e-02, fs:0.73267 (r=0.747,p=0.718),  time:40.990, tt:2623.348\n",
      "Ep:64, loss:0.00001, loss_test:0.02111, lr:5.71e-02, fs:0.73267 (r=0.747,p=0.718),  time:40.979, tt:2663.631\n",
      "Ep:65, loss:0.00001, loss_test:0.02138, lr:5.71e-02, fs:0.73267 (r=0.747,p=0.718),  time:40.986, tt:2705.052\n",
      "Ep:66, loss:0.00001, loss_test:0.02140, lr:5.71e-02, fs:0.73267 (r=0.747,p=0.718),  time:41.027, tt:2748.822\n",
      "Ep:67, loss:0.00001, loss_test:0.02161, lr:5.71e-02, fs:0.73000 (r=0.737,p=0.723),  time:41.046, tt:2791.134\n",
      "Ep:68, loss:0.00001, loss_test:0.02191, lr:5.65e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.044, tt:2832.021\n",
      "Ep:69, loss:0.00001, loss_test:0.02187, lr:5.59e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.076, tt:2875.300\n",
      "Ep:70, loss:0.00001, loss_test:0.02203, lr:5.54e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.095, tt:2917.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.02232, lr:5.48e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.097, tt:2959.000\n",
      "Ep:72, loss:0.00001, loss_test:0.02228, lr:5.43e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.093, tt:2999.808\n",
      "Ep:73, loss:0.00001, loss_test:0.02251, lr:5.37e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.108, tt:3041.998\n",
      "Ep:74, loss:0.00001, loss_test:0.02260, lr:5.32e-02, fs:0.73737 (r=0.737,p=0.737),  time:41.088, tt:3081.577\n",
      "Ep:75, loss:0.00001, loss_test:0.02264, lr:5.27e-02, fs:0.74000 (r=0.747,p=0.733),  time:41.085, tt:3122.448\n",
      "Ep:76, loss:0.00001, loss_test:0.02304, lr:5.21e-02, fs:0.72449 (r=0.717,p=0.732),  time:41.079, tt:3163.092\n",
      "Ep:77, loss:0.00001, loss_test:0.02287, lr:5.16e-02, fs:0.73469 (r=0.727,p=0.742),  time:41.088, tt:3204.839\n",
      "Ep:78, loss:0.00001, loss_test:0.02321, lr:5.11e-02, fs:0.71795 (r=0.707,p=0.729),  time:41.082, tt:3245.476\n",
      "Ep:79, loss:0.00001, loss_test:0.02338, lr:5.06e-02, fs:0.71795 (r=0.707,p=0.729),  time:41.090, tt:3287.235\n",
      "Ep:80, loss:0.00001, loss_test:0.02329, lr:5.01e-02, fs:0.72165 (r=0.707,p=0.737),  time:41.073, tt:3326.910\n",
      "Ep:81, loss:0.00001, loss_test:0.02368, lr:4.96e-02, fs:0.67742 (r=0.636,p=0.724),  time:41.067, tt:3367.526\n",
      "Ep:82, loss:0.00001, loss_test:0.02383, lr:4.91e-02, fs:0.67742 (r=0.636,p=0.724),  time:41.077, tt:3409.356\n",
      "Ep:83, loss:0.00001, loss_test:0.02389, lr:4.86e-02, fs:0.67027 (r=0.626,p=0.721),  time:41.100, tt:3452.411\n",
      "Ep:84, loss:0.00001, loss_test:0.02395, lr:4.81e-02, fs:0.67027 (r=0.626,p=0.721),  time:41.086, tt:3492.278\n",
      "Ep:85, loss:0.00001, loss_test:0.02423, lr:4.76e-02, fs:0.67027 (r=0.626,p=0.721),  time:41.123, tt:3536.545\n",
      "Ep:86, loss:0.00001, loss_test:0.02434, lr:4.71e-02, fs:0.66304 (r=0.616,p=0.718),  time:41.148, tt:3579.841\n",
      "Ep:87, loss:0.00001, loss_test:0.02439, lr:4.67e-02, fs:0.66304 (r=0.616,p=0.718),  time:41.195, tt:3625.145\n",
      "Ep:88, loss:0.00001, loss_test:0.02467, lr:4.62e-02, fs:0.66304 (r=0.616,p=0.718),  time:41.203, tt:3667.083\n",
      "Ep:89, loss:0.00001, loss_test:0.02472, lr:4.57e-02, fs:0.67027 (r=0.626,p=0.721),  time:41.208, tt:3708.719\n",
      "Ep:90, loss:0.00001, loss_test:0.02491, lr:4.53e-02, fs:0.65934 (r=0.606,p=0.723),  time:41.206, tt:3749.718\n",
      "Ep:91, loss:0.00001, loss_test:0.02493, lr:4.48e-02, fs:0.66667 (r=0.616,p=0.726),  time:41.219, tt:3792.105\n",
      "Ep:92, loss:0.00001, loss_test:0.02514, lr:4.44e-02, fs:0.65556 (r=0.596,p=0.728),  time:41.230, tt:3834.368\n",
      "Ep:93, loss:0.00001, loss_test:0.02520, lr:4.39e-02, fs:0.66298 (r=0.606,p=0.732),  time:41.219, tt:3874.611\n",
      "Ep:94, loss:0.00001, loss_test:0.02529, lr:4.35e-02, fs:0.66298 (r=0.606,p=0.732),  time:41.213, tt:3915.267\n",
      "Ep:95, loss:0.00001, loss_test:0.02562, lr:4.31e-02, fs:0.65169 (r=0.586,p=0.734),  time:41.231, tt:3958.192\n",
      "Ep:96, loss:0.00001, loss_test:0.02559, lr:4.26e-02, fs:0.65169 (r=0.586,p=0.734),  time:41.232, tt:3999.462\n",
      "Ep:97, loss:0.00001, loss_test:0.02547, lr:4.22e-02, fs:0.65922 (r=0.596,p=0.738),  time:41.253, tt:4042.842\n",
      "Ep:98, loss:0.00001, loss_test:0.02599, lr:4.18e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.265, tt:4085.277\n",
      "Ep:99, loss:0.00001, loss_test:0.02586, lr:4.14e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.268, tt:4126.789\n",
      "Ep:100, loss:0.00001, loss_test:0.02598, lr:4.10e-02, fs:0.63636 (r=0.566,p=0.727),  time:41.275, tt:4168.727\n",
      "Ep:101, loss:0.00001, loss_test:0.02628, lr:4.05e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.291, tt:4211.721\n",
      "Ep:102, loss:0.00001, loss_test:0.02631, lr:4.01e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.313, tt:4255.245\n",
      "Ep:103, loss:0.00001, loss_test:0.02628, lr:3.97e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.294, tt:4294.544\n",
      "Ep:104, loss:0.00001, loss_test:0.02650, lr:3.93e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.288, tt:4335.232\n",
      "Ep:105, loss:0.00001, loss_test:0.02665, lr:3.89e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.283, tt:4375.983\n",
      "Ep:106, loss:0.00001, loss_test:0.02667, lr:3.86e-02, fs:0.64407 (r=0.576,p=0.731),  time:41.283, tt:4417.229\n",
      "Ep:107, loss:0.00001, loss_test:0.02673, lr:3.82e-02, fs:0.64000 (r=0.566,p=0.737),  time:41.285, tt:4458.810\n",
      "Ep:108, loss:0.00000, loss_test:0.02704, lr:3.78e-02, fs:0.63636 (r=0.566,p=0.727),  time:41.285, tt:4500.117\n",
      "Ep:109, loss:0.00000, loss_test:0.02697, lr:3.74e-02, fs:0.64000 (r=0.566,p=0.737),  time:41.263, tt:4538.912\n",
      "Ep:110, loss:0.00000, loss_test:0.02708, lr:3.70e-02, fs:0.63218 (r=0.556,p=0.733),  time:41.254, tt:4579.218\n",
      "Ep:111, loss:0.00000, loss_test:0.02728, lr:3.67e-02, fs:0.63218 (r=0.556,p=0.733),  time:41.237, tt:4618.572\n",
      "Ep:112, loss:0.00000, loss_test:0.02716, lr:3.63e-02, fs:0.64368 (r=0.566,p=0.747),  time:41.242, tt:4660.392\n",
      "Ep:113, loss:0.00000, loss_test:0.02754, lr:3.59e-02, fs:0.63584 (r=0.556,p=0.743),  time:41.228, tt:4699.969\n",
      "Ep:114, loss:0.00000, loss_test:0.02747, lr:3.56e-02, fs:0.64368 (r=0.566,p=0.747),  time:41.223, tt:4740.632\n",
      "Ep:115, loss:0.00000, loss_test:0.02759, lr:3.52e-02, fs:0.64368 (r=0.566,p=0.747),  time:41.227, tt:4782.284\n",
      "Ep:116, loss:0.00000, loss_test:0.02784, lr:3.49e-02, fs:0.63584 (r=0.556,p=0.743),  time:41.198, tt:4820.199\n",
      "Ep:117, loss:0.00000, loss_test:0.02772, lr:3.45e-02, fs:0.64368 (r=0.566,p=0.747),  time:41.184, tt:4859.662\n",
      "Ep:118, loss:0.00000, loss_test:0.02797, lr:3.42e-02, fs:0.63584 (r=0.556,p=0.743),  time:41.183, tt:4900.757\n",
      "Ep:119, loss:0.00000, loss_test:0.02791, lr:3.38e-02, fs:0.63584 (r=0.556,p=0.743),  time:41.188, tt:4942.599\n",
      "Ep:120, loss:0.00000, loss_test:0.02792, lr:3.35e-02, fs:0.64740 (r=0.566,p=0.757),  time:41.176, tt:4982.316\n",
      "Ep:121, loss:0.00000, loss_test:0.02826, lr:3.32e-02, fs:0.63953 (r=0.556,p=0.753),  time:41.175, tt:5023.295\n",
      "Ep:122, loss:0.00000, loss_test:0.02818, lr:3.28e-02, fs:0.62353 (r=0.535,p=0.746),  time:41.176, tt:5064.693\n",
      "Ep:123, loss:0.00000, loss_test:0.02820, lr:3.25e-02, fs:0.63158 (r=0.545,p=0.750),  time:41.172, tt:5105.365\n",
      "Ep:124, loss:0.00000, loss_test:0.02852, lr:3.22e-02, fs:0.62722 (r=0.535,p=0.757),  time:41.172, tt:5146.529\n",
      "Ep:125, loss:0.00000, loss_test:0.02835, lr:3.19e-02, fs:0.63158 (r=0.545,p=0.750),  time:41.164, tt:5186.725\n",
      "Ep:126, loss:0.00000, loss_test:0.02848, lr:3.15e-02, fs:0.62722 (r=0.535,p=0.757),  time:41.157, tt:5226.899\n",
      "Ep:127, loss:0.00000, loss_test:0.02872, lr:3.12e-02, fs:0.62722 (r=0.535,p=0.757),  time:41.144, tt:5266.370\n",
      "Ep:128, loss:0.00000, loss_test:0.02868, lr:3.09e-02, fs:0.61905 (r=0.525,p=0.754),  time:41.153, tt:5308.775\n",
      "Ep:129, loss:0.00000, loss_test:0.02866, lr:3.06e-02, fs:0.61905 (r=0.525,p=0.754),  time:41.146, tt:5349.033\n",
      "Ep:130, loss:0.00000, loss_test:0.02891, lr:3.03e-02, fs:0.61905 (r=0.525,p=0.754),  time:41.137, tt:5388.921\n",
      "Ep:131, loss:0.00000, loss_test:0.02892, lr:3.00e-02, fs:0.61078 (r=0.515,p=0.750),  time:41.134, tt:5429.624\n",
      "Ep:132, loss:0.00000, loss_test:0.02887, lr:2.97e-02, fs:0.61905 (r=0.525,p=0.754),  time:41.131, tt:5470.374\n",
      "Ep:133, loss:0.00000, loss_test:0.02920, lr:2.94e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.120, tt:5510.069\n",
      "Ep:134, loss:0.00000, loss_test:0.02906, lr:2.91e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.120, tt:5551.231\n",
      "Ep:135, loss:0.00000, loss_test:0.02915, lr:2.88e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.113, tt:5591.419\n",
      "Ep:136, loss:0.00000, loss_test:0.02943, lr:2.85e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.102, tt:5631.038\n",
      "Ep:137, loss:0.00000, loss_test:0.02908, lr:2.82e-02, fs:0.62275 (r=0.525,p=0.765),  time:41.097, tt:5671.341\n",
      "Ep:138, loss:0.00000, loss_test:0.02945, lr:2.80e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.092, tt:5711.852\n",
      "Ep:139, loss:0.00000, loss_test:0.02960, lr:2.77e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.100, tt:5753.967\n",
      "Ep:140, loss:0.00000, loss_test:0.02941, lr:2.74e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.095, tt:5794.398\n",
      "Ep:141, loss:0.00000, loss_test:0.02979, lr:2.71e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.083, tt:5833.762\n",
      "Ep:142, loss:0.00000, loss_test:0.02967, lr:2.69e-02, fs:0.61446 (r=0.515,p=0.761),  time:41.078, tt:5874.197\n",
      "Ep:143, loss:0.00000, loss_test:0.02969, lr:2.66e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.074, tt:5914.620\n",
      "Ep:144, loss:0.00000, loss_test:0.02988, lr:2.63e-02, fs:0.60606 (r=0.505,p=0.758),  time:41.074, tt:5955.755\n",
      "Ep:145, loss:0.00000, loss_test:0.02985, lr:2.61e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.075, tt:5996.907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.02988, lr:2.58e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.075, tt:6037.997\n",
      "Ep:147, loss:0.00000, loss_test:0.03007, lr:2.55e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.075, tt:6079.084\n",
      "Ep:148, loss:0.00000, loss_test:0.02996, lr:2.53e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.075, tt:6120.160\n",
      "Ep:149, loss:0.00000, loss_test:0.03013, lr:2.50e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.065, tt:6159.743\n",
      "Ep:150, loss:0.00000, loss_test:0.03026, lr:2.48e-02, fs:0.60123 (r=0.495,p=0.766),  time:41.053, tt:6199.026\n",
      "Ep:151, loss:0.00000, loss_test:0.03017, lr:2.45e-02, fs:0.60976 (r=0.505,p=0.769),  time:41.053, tt:6240.053\n",
      "Ep:152, loss:0.00000, loss_test:0.03023, lr:2.43e-02, fs:0.60606 (r=0.505,p=0.758),  time:41.046, tt:6279.963\n",
      "Ep:153, loss:0.00000, loss_test:0.03037, lr:2.40e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.053, tt:6322.230\n",
      "Ep:154, loss:0.00000, loss_test:0.03042, lr:2.38e-02, fs:0.60123 (r=0.495,p=0.766),  time:41.043, tt:6361.681\n",
      "Ep:155, loss:0.00000, loss_test:0.03041, lr:2.36e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.039, tt:6402.080\n",
      "Ep:156, loss:0.00000, loss_test:0.03050, lr:2.33e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.038, tt:6442.955\n",
      "Ep:157, loss:0.00000, loss_test:0.03043, lr:2.31e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.037, tt:6483.859\n",
      "Ep:158, loss:0.00000, loss_test:0.03063, lr:2.29e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.033, tt:6524.247\n",
      "Ep:159, loss:0.00000, loss_test:0.03069, lr:2.26e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.038, tt:6566.134\n",
      "Ep:160, loss:0.00000, loss_test:0.03067, lr:2.24e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.026, tt:6605.178\n",
      "Ep:161, loss:0.00000, loss_test:0.03075, lr:2.22e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.022, tt:6645.564\n",
      "Ep:162, loss:0.00000, loss_test:0.03072, lr:2.20e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.013, tt:6685.175\n",
      "Ep:163, loss:0.00000, loss_test:0.03071, lr:2.17e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.005, tt:6724.865\n",
      "Ep:164, loss:0.00000, loss_test:0.03098, lr:2.15e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.002, tt:6765.351\n",
      "Ep:165, loss:0.00000, loss_test:0.03083, lr:2.13e-02, fs:0.59756 (r=0.495,p=0.754),  time:40.998, tt:6805.595\n",
      "Ep:166, loss:0.00000, loss_test:0.03090, lr:2.11e-02, fs:0.59756 (r=0.495,p=0.754),  time:40.999, tt:6846.770\n",
      "Ep:167, loss:0.00000, loss_test:0.03108, lr:2.09e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.008, tt:6889.377\n",
      "Ep:168, loss:0.00000, loss_test:0.03105, lr:2.07e-02, fs:0.58896 (r=0.485,p=0.750),  time:41.006, tt:6930.077\n",
      "Ep:169, loss:0.00000, loss_test:0.03110, lr:2.05e-02, fs:0.59756 (r=0.495,p=0.754),  time:41.004, tt:6970.672\n",
      "Ep:170, loss:0.00000, loss_test:0.03114, lr:2.03e-02, fs:0.58896 (r=0.485,p=0.750),  time:41.007, tt:7012.163\n",
      "Ep:171, loss:0.00000, loss_test:0.03119, lr:2.01e-02, fs:0.58896 (r=0.485,p=0.750),  time:41.001, tt:7052.158\n",
      "Ep:172, loss:0.00000, loss_test:0.03131, lr:1.99e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.995, tt:7092.103\n",
      "Ep:173, loss:0.00000, loss_test:0.03127, lr:1.97e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.996, tt:7133.246\n",
      "Ep:174, loss:0.00000, loss_test:0.03127, lr:1.95e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.987, tt:7172.774\n",
      "Ep:175, loss:0.00000, loss_test:0.03137, lr:1.93e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.974, tt:7211.350\n",
      "Ep:176, loss:0.00000, loss_test:0.03142, lr:1.91e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.976, tt:7252.693\n",
      "Ep:177, loss:0.00000, loss_test:0.03138, lr:1.89e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.982, tt:7294.774\n",
      "Ep:178, loss:0.00000, loss_test:0.03143, lr:1.87e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.994, tt:7337.886\n",
      "Ep:179, loss:0.00000, loss_test:0.03151, lr:1.85e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.993, tt:7378.790\n",
      "Ep:180, loss:0.00000, loss_test:0.03154, lr:1.83e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.990, tt:7419.269\n",
      "Ep:181, loss:0.00000, loss_test:0.03162, lr:1.81e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.975, tt:7457.384\n",
      "Ep:182, loss:0.00000, loss_test:0.03151, lr:1.80e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.964, tt:7496.411\n",
      "Ep:183, loss:0.00000, loss_test:0.03164, lr:1.78e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.964, tt:7537.382\n",
      "Ep:184, loss:0.00000, loss_test:0.03168, lr:1.76e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.954, tt:7576.473\n",
      "Ep:185, loss:0.00000, loss_test:0.03164, lr:1.74e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.953, tt:7617.181\n",
      "Ep:186, loss:0.00000, loss_test:0.03176, lr:1.73e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.946, tt:7656.843\n",
      "Ep:187, loss:0.00000, loss_test:0.03174, lr:1.71e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.921, tt:7693.096\n",
      "Ep:188, loss:0.00000, loss_test:0.03176, lr:1.69e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.916, tt:7733.093\n",
      "Ep:189, loss:0.00000, loss_test:0.03191, lr:1.67e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.915, tt:7773.800\n",
      "Ep:190, loss:0.00000, loss_test:0.03184, lr:1.66e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.918, tt:7815.269\n",
      "Ep:191, loss:0.00000, loss_test:0.03180, lr:1.64e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.915, tt:7855.688\n",
      "Ep:192, loss:0.00000, loss_test:0.03195, lr:1.62e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.911, tt:7895.822\n",
      "Ep:193, loss:0.00000, loss_test:0.03199, lr:1.61e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.890, tt:7932.735\n",
      "Ep:194, loss:0.00000, loss_test:0.03188, lr:1.59e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.891, tt:7973.762\n",
      "Ep:195, loss:0.00000, loss_test:0.03205, lr:1.58e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.889, tt:8014.157\n",
      "Ep:196, loss:0.00000, loss_test:0.03209, lr:1.56e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.887, tt:8054.704\n",
      "Ep:197, loss:0.00000, loss_test:0.03197, lr:1.54e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.887, tt:8095.609\n",
      "Ep:198, loss:0.00000, loss_test:0.03207, lr:1.53e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.880, tt:8135.168\n",
      "Ep:199, loss:0.00000, loss_test:0.03220, lr:1.51e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.873, tt:8174.597\n",
      "Ep:200, loss:0.00000, loss_test:0.03214, lr:1.50e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.874, tt:8215.655\n",
      "Ep:201, loss:0.00000, loss_test:0.03211, lr:1.48e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.872, tt:8256.163\n",
      "Ep:202, loss:0.00000, loss_test:0.03222, lr:1.47e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.859, tt:8294.297\n",
      "Ep:203, loss:0.00000, loss_test:0.03223, lr:1.45e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.852, tt:8333.742\n",
      "Ep:204, loss:0.00000, loss_test:0.03224, lr:1.44e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.839, tt:8371.905\n",
      "Ep:205, loss:0.00000, loss_test:0.03228, lr:1.43e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.836, tt:8412.249\n",
      "Ep:206, loss:0.00000, loss_test:0.03230, lr:1.41e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.834, tt:8452.537\n",
      "Ep:207, loss:0.00000, loss_test:0.03234, lr:1.40e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.819, tt:8490.340\n",
      "Ep:208, loss:0.00000, loss_test:0.03235, lr:1.38e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.817, tt:8530.689\n",
      "Ep:209, loss:0.00000, loss_test:0.03239, lr:1.37e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.810, tt:8570.152\n",
      "Ep:210, loss:0.00000, loss_test:0.03240, lr:1.36e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.786, tt:8605.894\n",
      "Ep:211, loss:0.00000, loss_test:0.03248, lr:1.34e-02, fs:0.58896 (r=0.485,p=0.750),  time:40.778, tt:8645.012\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14377, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.869, tt:32.869\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14198, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:32.995, tt:65.990\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13856, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:35.287, tt:105.860\n",
      "Ep:3, loss:0.00026, loss_test:0.13389, lr:1.00e-02, fs:0.63433 (r=0.859,p=0.503),  time:36.959, tt:147.835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00024, loss_test:0.13096, lr:1.00e-02, fs:0.63115 (r=0.778,p=0.531),  time:37.460, tt:187.299\n",
      "Ep:5, loss:0.00023, loss_test:0.12694, lr:1.00e-02, fs:0.62162 (r=0.697,p=0.561),  time:38.572, tt:231.434\n",
      "Ep:6, loss:0.00022, loss_test:0.12275, lr:1.00e-02, fs:0.60377 (r=0.646,p=0.566),  time:39.846, tt:278.921\n",
      "Ep:7, loss:0.00021, loss_test:0.12232, lr:1.00e-02, fs:0.60465 (r=0.657,p=0.560),  time:39.866, tt:318.930\n",
      "Ep:8, loss:0.00021, loss_test:0.12077, lr:1.00e-02, fs:0.62264 (r=0.667,p=0.584),  time:39.976, tt:359.780\n",
      "Ep:9, loss:0.00020, loss_test:0.11934, lr:1.00e-02, fs:0.62687 (r=0.636,p=0.618),  time:40.175, tt:401.750\n",
      "Ep:10, loss:0.00019, loss_test:0.11708, lr:1.00e-02, fs:0.63959 (r=0.636,p=0.643),  time:40.237, tt:442.605\n",
      "Ep:11, loss:0.00018, loss_test:0.11445, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:40.292, tt:483.509\n",
      "Ep:12, loss:0.00018, loss_test:0.11296, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:40.144, tt:521.868\n",
      "Ep:13, loss:0.00017, loss_test:0.11116, lr:9.90e-03, fs:0.67005 (r=0.667,p=0.673),  time:40.190, tt:562.658\n",
      "Ep:14, loss:0.00016, loss_test:0.10877, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:40.217, tt:603.252\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.10726, lr:9.80e-03, fs:0.69388 (r=0.687,p=0.701),  time:40.134, tt:642.144\n",
      "Ep:16, loss:0.00015, loss_test:0.10507, lr:9.80e-03, fs:0.68367 (r=0.677,p=0.691),  time:40.106, tt:681.795\n",
      "Ep:17, loss:0.00015, loss_test:0.10292, lr:9.80e-03, fs:0.70051 (r=0.697,p=0.704),  time:40.150, tt:722.709\n",
      "Ep:18, loss:0.00014, loss_test:0.10097, lr:9.80e-03, fs:0.71204 (r=0.687,p=0.739),  time:40.159, tt:763.020\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09920, lr:9.80e-03, fs:0.70833 (r=0.687,p=0.731),  time:40.099, tt:801.988\n",
      "Ep:20, loss:0.00013, loss_test:0.09807, lr:9.80e-03, fs:0.70213 (r=0.667,p=0.742),  time:40.146, tt:843.072\n",
      "Ep:21, loss:0.00013, loss_test:0.09531, lr:9.80e-03, fs:0.74611 (r=0.727,p=0.766),  time:40.184, tt:884.038\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.09421, lr:9.80e-03, fs:0.73626 (r=0.677,p=0.807),  time:40.211, tt:924.861\n",
      "Ep:23, loss:0.00012, loss_test:0.09236, lr:9.80e-03, fs:0.77551 (r=0.768,p=0.784),  time:40.283, tt:966.782\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09231, lr:9.80e-03, fs:0.73743 (r=0.667,p=0.825),  time:40.184, tt:1004.592\n",
      "Ep:25, loss:0.00011, loss_test:0.09011, lr:9.80e-03, fs:0.79208 (r=0.808,p=0.777),  time:40.136, tt:1043.529\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.09220, lr:9.80e-03, fs:0.74576 (r=0.667,p=0.846),  time:40.235, tt:1086.332\n",
      "Ep:27, loss:0.00010, loss_test:0.08804, lr:9.80e-03, fs:0.80392 (r=0.828,p=0.781),  time:40.359, tt:1130.062\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.08913, lr:9.80e-03, fs:0.78788 (r=0.788,p=0.788),  time:40.395, tt:1171.458\n",
      "Ep:29, loss:0.00009, loss_test:0.08786, lr:9.80e-03, fs:0.81053 (r=0.778,p=0.846),  time:40.421, tt:1212.625\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.09104, lr:9.80e-03, fs:0.75936 (r=0.717,p=0.807),  time:40.396, tt:1252.277\n",
      "Ep:31, loss:0.00008, loss_test:0.08601, lr:9.80e-03, fs:0.82629 (r=0.889,p=0.772),  time:40.429, tt:1293.712\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08959, lr:9.80e-03, fs:0.80214 (r=0.758,p=0.852),  time:40.426, tt:1334.049\n",
      "Ep:33, loss:0.00008, loss_test:0.08713, lr:9.80e-03, fs:0.80612 (r=0.798,p=0.814),  time:40.488, tt:1376.591\n",
      "Ep:34, loss:0.00007, loss_test:0.08719, lr:9.80e-03, fs:0.80808 (r=0.808,p=0.808),  time:40.475, tt:1416.621\n",
      "Ep:35, loss:0.00007, loss_test:0.08397, lr:9.80e-03, fs:0.81026 (r=0.798,p=0.823),  time:40.489, tt:1457.617\n",
      "Ep:36, loss:0.00007, loss_test:0.09087, lr:9.80e-03, fs:0.77487 (r=0.747,p=0.804),  time:40.515, tt:1499.054\n",
      "Ep:37, loss:0.00007, loss_test:0.08099, lr:9.80e-03, fs:0.80788 (r=0.828,p=0.788),  time:40.528, tt:1540.046\n",
      "Ep:38, loss:0.00007, loss_test:0.08619, lr:9.80e-03, fs:0.80612 (r=0.798,p=0.814),  time:40.571, tt:1582.273\n",
      "Ep:39, loss:0.00006, loss_test:0.08574, lr:9.80e-03, fs:0.80000 (r=0.747,p=0.860),  time:40.552, tt:1622.098\n",
      "Ep:40, loss:0.00006, loss_test:0.08070, lr:9.80e-03, fs:0.81188 (r=0.828,p=0.796),  time:40.540, tt:1662.149\n",
      "Ep:41, loss:0.00006, loss_test:0.08924, lr:9.80e-03, fs:0.75789 (r=0.727,p=0.791),  time:40.516, tt:1701.686\n",
      "Ep:42, loss:0.00006, loss_test:0.08003, lr:9.80e-03, fs:0.83938 (r=0.818,p=0.862),  time:40.477, tt:1740.505\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.08759, lr:9.80e-03, fs:0.79000 (r=0.798,p=0.782),  time:40.442, tt:1779.455\n",
      "Ep:44, loss:0.00005, loss_test:0.08247, lr:9.80e-03, fs:0.81720 (r=0.768,p=0.874),  time:40.420, tt:1818.879\n",
      "Ep:45, loss:0.00005, loss_test:0.08142, lr:9.80e-03, fs:0.80829 (r=0.788,p=0.830),  time:40.417, tt:1859.193\n",
      "Ep:46, loss:0.00005, loss_test:0.08566, lr:9.80e-03, fs:0.77095 (r=0.697,p=0.863),  time:40.415, tt:1899.500\n",
      "Ep:47, loss:0.00005, loss_test:0.08538, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:40.432, tt:1940.752\n",
      "Ep:48, loss:0.00004, loss_test:0.08587, lr:9.80e-03, fs:0.75138 (r=0.687,p=0.829),  time:40.424, tt:1980.779\n",
      "Ep:49, loss:0.00004, loss_test:0.08246, lr:9.80e-03, fs:0.78453 (r=0.717,p=0.866),  time:40.432, tt:2021.622\n",
      "Ep:50, loss:0.00004, loss_test:0.08704, lr:9.80e-03, fs:0.77348 (r=0.707,p=0.854),  time:40.466, tt:2063.783\n",
      "Ep:51, loss:0.00004, loss_test:0.08547, lr:9.80e-03, fs:0.73224 (r=0.677,p=0.798),  time:40.500, tt:2106.021\n",
      "Ep:52, loss:0.00004, loss_test:0.08963, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:40.525, tt:2147.825\n",
      "Ep:53, loss:0.00004, loss_test:0.08196, lr:9.80e-03, fs:0.76243 (r=0.697,p=0.841),  time:40.490, tt:2186.480\n",
      "Ep:54, loss:0.00004, loss_test:0.09905, lr:9.70e-03, fs:0.75978 (r=0.687,p=0.850),  time:40.511, tt:2228.122\n",
      "Ep:55, loss:0.00004, loss_test:0.08412, lr:9.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:40.566, tt:2271.682\n",
      "Ep:56, loss:0.00003, loss_test:0.08785, lr:9.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:40.572, tt:2312.614\n",
      "Ep:57, loss:0.00003, loss_test:0.09109, lr:9.41e-03, fs:0.72093 (r=0.626,p=0.849),  time:40.549, tt:2351.837\n",
      "Ep:58, loss:0.00003, loss_test:0.09086, lr:9.32e-03, fs:0.79070 (r=0.687,p=0.932),  time:40.593, tt:2394.972\n",
      "Ep:59, loss:0.00003, loss_test:0.08928, lr:9.23e-03, fs:0.75429 (r=0.667,p=0.868),  time:40.602, tt:2436.135\n",
      "Ep:60, loss:0.00003, loss_test:0.09626, lr:9.14e-03, fs:0.78857 (r=0.697,p=0.908),  time:40.607, tt:2477.049\n",
      "Ep:61, loss:0.00003, loss_test:0.08487, lr:9.04e-03, fs:0.81111 (r=0.737,p=0.901),  time:40.659, tt:2520.871\n",
      "Ep:62, loss:0.00003, loss_test:0.10160, lr:8.95e-03, fs:0.71345 (r=0.616,p=0.847),  time:40.709, tt:2564.638\n",
      "Ep:63, loss:0.00003, loss_test:0.08544, lr:8.86e-03, fs:0.81564 (r=0.737,p=0.912),  time:40.761, tt:2608.722\n",
      "Ep:64, loss:0.00003, loss_test:0.10399, lr:8.78e-03, fs:0.73620 (r=0.606,p=0.938),  time:40.785, tt:2651.045\n",
      "Ep:65, loss:0.00003, loss_test:0.08532, lr:8.69e-03, fs:0.77714 (r=0.687,p=0.895),  time:40.838, tt:2695.317\n",
      "Ep:66, loss:0.00003, loss_test:0.09733, lr:8.60e-03, fs:0.78824 (r=0.677,p=0.944),  time:40.890, tt:2739.628\n",
      "Ep:67, loss:0.00002, loss_test:0.09457, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:40.906, tt:2781.579\n",
      "Ep:68, loss:0.00002, loss_test:0.09219, lr:8.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:40.918, tt:2823.330\n",
      "Ep:69, loss:0.00002, loss_test:0.09607, lr:8.35e-03, fs:0.77844 (r=0.657,p=0.956),  time:40.955, tt:2866.865\n",
      "Ep:70, loss:0.00002, loss_test:0.09145, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:40.971, tt:2908.932\n",
      "Ep:71, loss:0.00002, loss_test:0.10472, lr:8.18e-03, fs:0.71250 (r=0.576,p=0.934),  time:40.977, tt:2950.363\n",
      "Ep:72, loss:0.00002, loss_test:0.09467, lr:8.10e-03, fs:0.79290 (r=0.677,p=0.957),  time:40.976, tt:2991.230\n",
      "Ep:73, loss:0.00002, loss_test:0.10045, lr:8.02e-03, fs:0.75740 (r=0.646,p=0.914),  time:40.981, tt:3032.613\n",
      "Ep:74, loss:0.00002, loss_test:0.10068, lr:7.94e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.029, tt:3077.185\n",
      "Ep:75, loss:0.00002, loss_test:0.09846, lr:7.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:41.018, tt:3117.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00002, loss_test:0.09793, lr:7.78e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.029, tt:3159.236\n",
      "Ep:77, loss:0.00002, loss_test:0.10358, lr:7.70e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.007, tt:3198.507\n",
      "Ep:78, loss:0.00002, loss_test:0.09899, lr:7.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:40.996, tt:3238.724\n",
      "Ep:79, loss:0.00001, loss_test:0.10409, lr:7.55e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.035, tt:3282.830\n",
      "Ep:80, loss:0.00001, loss_test:0.10334, lr:7.47e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.056, tt:3325.570\n",
      "Ep:81, loss:0.00001, loss_test:0.10536, lr:7.40e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.065, tt:3367.296\n",
      "Ep:82, loss:0.00001, loss_test:0.10462, lr:7.32e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.077, tt:3409.390\n",
      "Ep:83, loss:0.00001, loss_test:0.10200, lr:7.25e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.111, tt:3453.308\n",
      "Ep:84, loss:0.00001, loss_test:0.10733, lr:7.18e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.125, tt:3495.651\n",
      "Ep:85, loss:0.00001, loss_test:0.10163, lr:7.11e-03, fs:0.75904 (r=0.636,p=0.940),  time:41.133, tt:3537.406\n",
      "Ep:86, loss:0.00001, loss_test:0.10719, lr:7.03e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.145, tt:3579.624\n",
      "Ep:87, loss:0.00001, loss_test:0.09968, lr:6.96e-03, fs:0.71605 (r=0.586,p=0.921),  time:41.166, tt:3622.636\n",
      "Ep:88, loss:0.00001, loss_test:0.10673, lr:6.89e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.178, tt:3664.870\n",
      "Ep:89, loss:0.00001, loss_test:0.10230, lr:6.83e-03, fs:0.71605 (r=0.586,p=0.921),  time:41.187, tt:3706.812\n",
      "Ep:90, loss:0.00001, loss_test:0.10844, lr:6.76e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.225, tt:3751.514\n",
      "Ep:91, loss:0.00001, loss_test:0.10170, lr:6.69e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.239, tt:3794.007\n",
      "Ep:92, loss:0.00001, loss_test:0.10527, lr:6.62e-03, fs:0.73171 (r=0.606,p=0.923),  time:41.231, tt:3834.520\n",
      "Ep:93, loss:0.00001, loss_test:0.10473, lr:6.56e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.230, tt:3875.655\n",
      "Ep:94, loss:0.00001, loss_test:0.10536, lr:6.49e-03, fs:0.70807 (r=0.576,p=0.919),  time:41.255, tt:3919.181\n",
      "Ep:95, loss:0.00001, loss_test:0.10010, lr:6.43e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.253, tt:3960.284\n",
      "Ep:96, loss:0.00001, loss_test:0.11226, lr:6.36e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.274, tt:4003.621\n",
      "Ep:97, loss:0.00001, loss_test:0.09763, lr:6.30e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.297, tt:4047.097\n",
      "Ep:98, loss:0.00001, loss_test:0.10905, lr:6.24e-03, fs:0.70000 (r=0.566,p=0.918),  time:41.309, tt:4089.627\n",
      "Ep:99, loss:0.00001, loss_test:0.10287, lr:6.17e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.317, tt:4131.694\n",
      "Ep:100, loss:0.00001, loss_test:0.11045, lr:6.11e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.317, tt:4173.014\n",
      "Ep:101, loss:0.00001, loss_test:0.10553, lr:6.05e-03, fs:0.74390 (r=0.616,p=0.938),  time:41.319, tt:4214.573\n",
      "Ep:102, loss:0.00001, loss_test:0.10361, lr:5.99e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.316, tt:4255.505\n",
      "Ep:103, loss:0.00001, loss_test:0.10681, lr:5.93e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.322, tt:4297.532\n",
      "Ep:104, loss:0.00001, loss_test:0.10356, lr:5.87e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.338, tt:4340.532\n",
      "Ep:105, loss:0.00001, loss_test:0.10689, lr:5.81e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.347, tt:4382.741\n",
      "Ep:106, loss:0.00001, loss_test:0.10533, lr:5.75e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.353, tt:4424.756\n",
      "Ep:107, loss:0.00001, loss_test:0.10553, lr:5.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.359, tt:4466.732\n",
      "Ep:108, loss:0.00001, loss_test:0.10399, lr:5.64e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.376, tt:4509.951\n",
      "Ep:109, loss:0.00001, loss_test:0.10760, lr:5.58e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.365, tt:4550.183\n",
      "Ep:110, loss:0.00001, loss_test:0.10682, lr:5.53e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.369, tt:4591.911\n",
      "Ep:111, loss:0.00001, loss_test:0.10452, lr:5.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.366, tt:4632.970\n",
      "Ep:112, loss:0.00001, loss_test:0.10683, lr:5.42e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.370, tt:4674.798\n",
      "Ep:113, loss:0.00001, loss_test:0.10430, lr:5.36e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.368, tt:4715.946\n",
      "Ep:114, loss:0.00001, loss_test:0.10481, lr:5.31e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.360, tt:4756.445\n",
      "Ep:115, loss:0.00001, loss_test:0.10679, lr:5.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.356, tt:4797.316\n",
      "Ep:116, loss:0.00000, loss_test:0.10373, lr:5.20e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.356, tt:4838.660\n",
      "Ep:117, loss:0.00000, loss_test:0.10688, lr:5.15e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.361, tt:4880.633\n",
      "Ep:118, loss:0.00000, loss_test:0.10354, lr:5.10e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.363, tt:4922.195\n",
      "Ep:119, loss:0.00000, loss_test:0.10709, lr:5.05e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.345, tt:4961.427\n",
      "Ep:120, loss:0.00000, loss_test:0.10636, lr:5.00e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.343, tt:5002.501\n",
      "Ep:121, loss:0.00000, loss_test:0.10490, lr:4.95e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.333, tt:5042.653\n",
      "Ep:122, loss:0.00000, loss_test:0.10673, lr:4.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.324, tt:5082.883\n",
      "Ep:123, loss:0.00000, loss_test:0.10547, lr:4.85e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.307, tt:5122.029\n",
      "Ep:124, loss:0.00000, loss_test:0.10667, lr:4.80e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.295, tt:5161.888\n",
      "Ep:125, loss:0.00000, loss_test:0.10726, lr:4.75e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.283, tt:5201.721\n",
      "Ep:126, loss:0.00000, loss_test:0.10638, lr:4.71e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.265, tt:5240.709\n",
      "Ep:127, loss:0.00000, loss_test:0.10575, lr:4.66e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.309, tt:5287.531\n",
      "Ep:128, loss:0.00000, loss_test:0.10781, lr:4.61e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.300, tt:5327.661\n",
      "Ep:129, loss:0.00000, loss_test:0.10539, lr:4.57e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.286, tt:5367.212\n",
      "Ep:130, loss:0.00000, loss_test:0.10663, lr:4.52e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.289, tt:5408.836\n",
      "Ep:131, loss:0.00000, loss_test:0.10830, lr:4.48e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.272, tt:5447.924\n",
      "Ep:132, loss:0.00000, loss_test:0.10520, lr:4.43e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.284, tt:5490.790\n",
      "Ep:133, loss:0.00000, loss_test:0.10643, lr:4.39e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.280, tt:5531.521\n",
      "Ep:134, loss:0.00000, loss_test:0.10779, lr:4.34e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.275, tt:5572.083\n",
      "Ep:135, loss:0.00000, loss_test:0.10559, lr:4.30e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.270, tt:5612.783\n",
      "Ep:136, loss:0.00000, loss_test:0.10568, lr:4.26e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.292, tt:5657.050\n",
      "Ep:137, loss:0.00000, loss_test:0.10846, lr:4.21e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.291, tt:5698.157\n",
      "Ep:138, loss:0.00000, loss_test:0.10570, lr:4.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.302, tt:5740.953\n",
      "Ep:139, loss:0.00000, loss_test:0.10758, lr:4.13e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.304, tt:5782.628\n",
      "Ep:140, loss:0.00000, loss_test:0.10965, lr:4.09e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.326, tt:5827.030\n",
      "Ep:141, loss:0.00000, loss_test:0.10576, lr:4.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.335, tt:5869.501\n",
      "Ep:142, loss:0.00000, loss_test:0.10537, lr:4.01e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.342, tt:5911.956\n",
      "Ep:143, loss:0.00000, loss_test:0.10755, lr:3.97e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.355, tt:5955.087\n",
      "Ep:144, loss:0.00000, loss_test:0.10745, lr:3.93e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.354, tt:5996.361\n",
      "Ep:145, loss:0.00000, loss_test:0.10663, lr:3.89e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.350, tt:6037.108\n",
      "Ep:146, loss:0.00000, loss_test:0.10594, lr:3.85e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.337, tt:6076.526\n",
      "Ep:147, loss:0.00000, loss_test:0.10890, lr:3.81e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.361, tt:6121.417\n",
      "Ep:148, loss:0.00000, loss_test:0.10716, lr:3.77e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.355, tt:6161.960\n",
      "Ep:149, loss:0.00000, loss_test:0.10689, lr:3.73e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.352, tt:6202.807\n",
      "Ep:150, loss:0.00000, loss_test:0.10854, lr:3.70e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.362, tt:6245.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00000, loss_test:0.10683, lr:3.66e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.367, tt:6287.709\n",
      "Ep:152, loss:0.00000, loss_test:0.10541, lr:3.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.371, tt:6329.769\n",
      "Ep:153, loss:0.00000, loss_test:0.10648, lr:3.59e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.371, tt:6371.064\n",
      "Ep:154, loss:0.00000, loss_test:0.10660, lr:3.55e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.371, tt:6412.583\n",
      "Ep:155, loss:0.00000, loss_test:0.10641, lr:3.52e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.364, tt:6452.731\n",
      "Ep:156, loss:0.00000, loss_test:0.10664, lr:3.48e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.373, tt:6495.489\n",
      "Ep:157, loss:0.00000, loss_test:0.10602, lr:3.45e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.390, tt:6539.592\n",
      "Ep:158, loss:0.00000, loss_test:0.10644, lr:3.41e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.410, tt:6584.142\n",
      "Ep:159, loss:0.00000, loss_test:0.10650, lr:3.38e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.409, tt:6625.458\n",
      "Ep:160, loss:0.00000, loss_test:0.10601, lr:3.34e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.410, tt:6667.085\n",
      "Ep:161, loss:0.00000, loss_test:0.10700, lr:3.31e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.410, tt:6708.363\n",
      "Ep:162, loss:0.00000, loss_test:0.10684, lr:3.28e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.411, tt:6749.935\n",
      "Ep:163, loss:0.00000, loss_test:0.10697, lr:3.24e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.406, tt:6790.530\n",
      "Ep:164, loss:0.00000, loss_test:0.10759, lr:3.21e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.407, tt:6832.144\n",
      "Ep:165, loss:0.00000, loss_test:0.10619, lr:3.18e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.406, tt:6873.439\n",
      "Ep:166, loss:0.00000, loss_test:0.10549, lr:3.15e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.406, tt:6914.871\n",
      "Ep:167, loss:0.00000, loss_test:0.10662, lr:3.12e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.421, tt:6958.666\n",
      "Ep:168, loss:0.00000, loss_test:0.10621, lr:3.09e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.419, tt:6999.750\n",
      "Ep:169, loss:0.00000, loss_test:0.10545, lr:3.05e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.406, tt:7038.965\n",
      "Ep:170, loss:0.00000, loss_test:0.10676, lr:3.02e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.395, tt:7078.500\n",
      "Ep:171, loss:0.00000, loss_test:0.10682, lr:2.99e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.396, tt:7120.078\n",
      "Ep:172, loss:0.00000, loss_test:0.10647, lr:2.96e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.397, tt:7161.702\n",
      "Ep:173, loss:0.00000, loss_test:0.10655, lr:2.93e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.399, tt:7203.381\n",
      "Ep:174, loss:0.00000, loss_test:0.10731, lr:2.90e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.412, tt:7247.076\n",
      "Ep:175, loss:0.00000, loss_test:0.10688, lr:2.88e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.416, tt:7289.141\n",
      "Ep:176, loss:0.00000, loss_test:0.10604, lr:2.85e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.423, tt:7331.920\n",
      "Ep:177, loss:0.00000, loss_test:0.10648, lr:2.82e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.417, tt:7372.215\n",
      "Ep:178, loss:0.00000, loss_test:0.10658, lr:2.79e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.415, tt:7413.251\n",
      "Ep:179, loss:0.00000, loss_test:0.10679, lr:2.76e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.411, tt:7453.909\n",
      "Ep:180, loss:0.00000, loss_test:0.10728, lr:2.73e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.420, tt:7497.027\n",
      "Ep:181, loss:0.00000, loss_test:0.10627, lr:2.71e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.418, tt:7538.087\n",
      "Ep:182, loss:0.00000, loss_test:0.10566, lr:2.68e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.417, tt:7579.400\n",
      "Ep:183, loss:0.00000, loss_test:0.10667, lr:2.65e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.428, tt:7622.711\n",
      "Ep:184, loss:0.00000, loss_test:0.10675, lr:2.63e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.429, tt:7664.342\n",
      "Ep:185, loss:0.00000, loss_test:0.10624, lr:2.60e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.440, tt:7707.878\n",
      "Ep:186, loss:0.00000, loss_test:0.10648, lr:2.57e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.451, tt:7751.342\n",
      "Ep:187, loss:0.00000, loss_test:0.10572, lr:2.55e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.460, tt:7794.401\n",
      "Ep:188, loss:0.00000, loss_test:0.10572, lr:2.52e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.459, tt:7835.727\n",
      "Ep:189, loss:0.00000, loss_test:0.10689, lr:2.50e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.451, tt:7875.750\n",
      "Ep:190, loss:0.00000, loss_test:0.10687, lr:2.47e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.459, tt:7918.623\n",
      "Ep:191, loss:0.00000, loss_test:0.10631, lr:2.45e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.462, tt:7960.747\n",
      "Ep:192, loss:0.00000, loss_test:0.10672, lr:2.42e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.470, tt:8003.707\n",
      "Ep:193, loss:0.00000, loss_test:0.10654, lr:2.40e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.471, tt:8045.378\n",
      "Ep:194, loss:0.00000, loss_test:0.10579, lr:2.38e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.478, tt:8088.248\n",
      "Ep:195, loss:0.00000, loss_test:0.10615, lr:2.35e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.487, tt:8131.531\n",
      "Ep:196, loss:0.00000, loss_test:0.10634, lr:2.33e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.489, tt:8173.345\n",
      "Ep:197, loss:0.00000, loss_test:0.10639, lr:2.31e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.488, tt:8214.679\n",
      "Ep:198, loss:0.00000, loss_test:0.10591, lr:2.28e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.485, tt:8255.547\n",
      "Ep:199, loss:0.00000, loss_test:0.10676, lr:2.26e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.486, tt:8297.242\n",
      "Ep:200, loss:0.00000, loss_test:0.10717, lr:2.24e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.493, tt:8340.089\n",
      "Ep:201, loss:0.00000, loss_test:0.10681, lr:2.21e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.494, tt:8381.761\n",
      "Ep:202, loss:0.00000, loss_test:0.10593, lr:2.19e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.493, tt:8423.108\n",
      "Ep:203, loss:0.00000, loss_test:0.10599, lr:2.17e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.501, tt:8466.156\n",
      "Ep:204, loss:0.00000, loss_test:0.10623, lr:2.15e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.505, tt:8508.523\n",
      "Ep:205, loss:0.00000, loss_test:0.10612, lr:2.13e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.502, tt:8549.476\n",
      "Ep:206, loss:0.00000, loss_test:0.10636, lr:2.11e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.507, tt:8592.011\n",
      "Ep:207, loss:0.00000, loss_test:0.10717, lr:2.08e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.508, tt:8633.620\n",
      "Ep:208, loss:0.00000, loss_test:0.10664, lr:2.06e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.506, tt:8674.736\n",
      "Ep:209, loss:0.00000, loss_test:0.10574, lr:2.04e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.489, tt:8712.586\n",
      "Ep:210, loss:0.00000, loss_test:0.10587, lr:2.02e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.449, tt:8745.795\n",
      "Ep:211, loss:0.00000, loss_test:0.10630, lr:2.00e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.396, tt:8775.950\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02028, lr:6.00e-02, fs:0.64865 (r=0.828,p=0.533),  time:37.619, tt:37.619\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02161, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:37.613, tt:75.227\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02236, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.719, tt:113.158\n",
      "Ep:3, loss:0.00004, loss_test:0.02129, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:37.810, tt:151.240\n",
      "Ep:4, loss:0.00004, loss_test:0.01980, lr:6.00e-02, fs:0.66932 (r=0.966,p=0.512),  time:37.596, tt:187.981\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01877, lr:6.00e-02, fs:0.67227 (r=0.920,p=0.530),  time:37.509, tt:225.052\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.71429 (r=0.862,p=0.610),  time:37.610, tt:263.268\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01814, lr:6.00e-02, fs:0.72115 (r=0.862,p=0.620),  time:38.063, tt:304.501\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01772, lr:6.00e-02, fs:0.72727 (r=0.920,p=0.602),  time:37.783, tt:340.045\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01765, lr:6.00e-02, fs:0.71552 (r=0.954,p=0.572),  time:37.912, tt:379.116\n",
      "Ep:10, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.70386 (r=0.943,p=0.562),  time:37.961, tt:417.574\n",
      "Ep:11, loss:0.00003, loss_test:0.01727, lr:6.00e-02, fs:0.71930 (r=0.943,p=0.582),  time:38.018, tt:456.214\n",
      "Ep:12, loss:0.00003, loss_test:0.01715, lr:6.00e-02, fs:0.74528 (r=0.908,p=0.632),  time:37.898, tt:492.677\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.73786 (r=0.874,p=0.639),  time:38.011, tt:532.159\n",
      "Ep:14, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.75962 (r=0.908,p=0.653),  time:37.936, tt:569.041\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.75829 (r=0.920,p=0.645),  time:37.894, tt:606.300\n",
      "Ep:16, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.76555 (r=0.920,p=0.656),  time:37.959, tt:645.307\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01603, lr:6.00e-02, fs:0.76098 (r=0.897,p=0.661),  time:38.094, tt:685.699\n",
      "Ep:18, loss:0.00002, loss_test:0.01585, lr:6.00e-02, fs:0.75862 (r=0.885,p=0.664),  time:38.133, tt:724.522\n",
      "Ep:19, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.75377 (r=0.862,p=0.670),  time:38.162, tt:763.242\n",
      "Ep:20, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.73575 (r=0.816,p=0.670),  time:38.266, tt:803.585\n",
      "Ep:21, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.72632 (r=0.793,p=0.670),  time:38.255, tt:841.615\n",
      "Ep:22, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:38.201, tt:878.634\n",
      "Ep:23, loss:0.00002, loss_test:0.01553, lr:6.00e-02, fs:0.73626 (r=0.770,p=0.705),  time:38.187, tt:916.478\n",
      "Ep:24, loss:0.00002, loss_test:0.01543, lr:6.00e-02, fs:0.74444 (r=0.770,p=0.720),  time:38.288, tt:957.189\n",
      "Ep:25, loss:0.00002, loss_test:0.01549, lr:6.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:38.312, tt:996.099\n",
      "Ep:26, loss:0.00002, loss_test:0.01534, lr:6.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:38.292, tt:1033.871\n",
      "Ep:27, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.72414 (r=0.724,p=0.724),  time:38.223, tt:1070.246\n",
      "Ep:28, loss:0.00002, loss_test:0.01548, lr:5.94e-02, fs:0.72515 (r=0.713,p=0.738),  time:38.213, tt:1108.177\n",
      "Ep:29, loss:0.00002, loss_test:0.01550, lr:5.88e-02, fs:0.72941 (r=0.713,p=0.747),  time:38.196, tt:1145.894\n",
      "Ep:30, loss:0.00001, loss_test:0.01552, lr:5.82e-02, fs:0.72619 (r=0.701,p=0.753),  time:38.188, tt:1183.837\n",
      "Ep:31, loss:0.00001, loss_test:0.01557, lr:5.76e-02, fs:0.72727 (r=0.690,p=0.769),  time:38.242, tt:1223.729\n",
      "Ep:32, loss:0.00001, loss_test:0.01556, lr:5.71e-02, fs:0.73171 (r=0.690,p=0.779),  time:38.285, tt:1263.404\n",
      "Ep:33, loss:0.00001, loss_test:0.01568, lr:5.65e-02, fs:0.72393 (r=0.678,p=0.776),  time:38.353, tt:1304.019\n",
      "Ep:34, loss:0.00001, loss_test:0.01562, lr:5.59e-02, fs:0.73620 (r=0.690,p=0.789),  time:38.340, tt:1341.917\n",
      "Ep:35, loss:0.00001, loss_test:0.01575, lr:5.54e-02, fs:0.73620 (r=0.690,p=0.789),  time:38.309, tt:1379.116\n",
      "Ep:36, loss:0.00001, loss_test:0.01584, lr:5.48e-02, fs:0.73292 (r=0.678,p=0.797),  time:38.295, tt:1416.908\n",
      "Ep:37, loss:0.00001, loss_test:0.01586, lr:5.43e-02, fs:0.72500 (r=0.667,p=0.795),  time:38.292, tt:1455.095\n",
      "Ep:38, loss:0.00001, loss_test:0.01592, lr:5.37e-02, fs:0.72152 (r=0.655,p=0.803),  time:38.315, tt:1494.273\n",
      "Ep:39, loss:0.00001, loss_test:0.01605, lr:5.32e-02, fs:0.70513 (r=0.632,p=0.797),  time:38.248, tt:1529.921\n",
      "Ep:40, loss:0.00001, loss_test:0.01609, lr:5.27e-02, fs:0.70513 (r=0.632,p=0.797),  time:38.230, tt:1567.439\n",
      "Ep:41, loss:0.00001, loss_test:0.01622, lr:5.21e-02, fs:0.70130 (r=0.621,p=0.806),  time:38.205, tt:1604.628\n",
      "Ep:42, loss:0.00001, loss_test:0.01641, lr:5.16e-02, fs:0.70588 (r=0.621,p=0.818),  time:38.220, tt:1643.467\n",
      "Ep:43, loss:0.00001, loss_test:0.01639, lr:5.11e-02, fs:0.71053 (r=0.621,p=0.831),  time:38.162, tt:1679.110\n",
      "Ep:44, loss:0.00001, loss_test:0.01659, lr:5.06e-02, fs:0.71523 (r=0.621,p=0.844),  time:38.159, tt:1717.172\n",
      "Ep:45, loss:0.00001, loss_test:0.01668, lr:5.01e-02, fs:0.71053 (r=0.621,p=0.831),  time:38.215, tt:1757.912\n",
      "Ep:46, loss:0.00001, loss_test:0.01670, lr:4.96e-02, fs:0.71053 (r=0.621,p=0.831),  time:38.227, tt:1796.648\n",
      "Ep:47, loss:0.00001, loss_test:0.01702, lr:4.91e-02, fs:0.69799 (r=0.598,p=0.839),  time:38.259, tt:1836.415\n",
      "Ep:48, loss:0.00001, loss_test:0.01693, lr:4.86e-02, fs:0.71523 (r=0.621,p=0.844),  time:38.304, tt:1876.892\n",
      "Ep:49, loss:0.00001, loss_test:0.01712, lr:4.81e-02, fs:0.70667 (r=0.609,p=0.841),  time:38.300, tt:1914.995\n",
      "Ep:50, loss:0.00001, loss_test:0.01724, lr:4.76e-02, fs:0.71141 (r=0.609,p=0.855),  time:38.338, tt:1955.246\n",
      "Ep:51, loss:0.00001, loss_test:0.01721, lr:4.71e-02, fs:0.71141 (r=0.609,p=0.855),  time:38.349, tt:1994.129\n",
      "Ep:52, loss:0.00001, loss_test:0.01744, lr:4.67e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.343, tt:2032.156\n",
      "Ep:53, loss:0.00001, loss_test:0.01742, lr:4.62e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.400, tt:2073.622\n",
      "Ep:54, loss:0.00001, loss_test:0.01752, lr:4.57e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.392, tt:2111.536\n",
      "Ep:55, loss:0.00001, loss_test:0.01769, lr:4.53e-02, fs:0.71141 (r=0.609,p=0.855),  time:38.427, tt:2151.889\n",
      "Ep:56, loss:0.00001, loss_test:0.01776, lr:4.48e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.429, tt:2190.464\n",
      "Ep:57, loss:0.00001, loss_test:0.01785, lr:4.44e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.438, tt:2229.383\n",
      "Ep:58, loss:0.00001, loss_test:0.01797, lr:4.39e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.441, tt:2268.042\n",
      "Ep:59, loss:0.00001, loss_test:0.01805, lr:4.35e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.475, tt:2308.527\n",
      "Ep:60, loss:0.00001, loss_test:0.01821, lr:4.31e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.488, tt:2347.740\n",
      "Ep:61, loss:0.00001, loss_test:0.01826, lr:4.26e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.468, tt:2385.013\n",
      "Ep:62, loss:0.00001, loss_test:0.01831, lr:4.22e-02, fs:0.71622 (r=0.609,p=0.869),  time:38.513, tt:2426.343\n",
      "Ep:63, loss:0.00001, loss_test:0.01853, lr:4.18e-02, fs:0.72109 (r=0.609,p=0.883),  time:38.563, tt:2468.026\n",
      "Ep:64, loss:0.00001, loss_test:0.01855, lr:4.14e-02, fs:0.72109 (r=0.609,p=0.883),  time:38.590, tt:2508.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.01872, lr:4.10e-02, fs:0.72109 (r=0.609,p=0.883),  time:38.591, tt:2547.001\n",
      "Ep:66, loss:0.00001, loss_test:0.01870, lr:4.05e-02, fs:0.72109 (r=0.609,p=0.883),  time:38.630, tt:2588.224\n",
      "Ep:67, loss:0.00001, loss_test:0.01889, lr:4.01e-02, fs:0.72603 (r=0.609,p=0.898),  time:38.681, tt:2630.303\n",
      "Ep:68, loss:0.00001, loss_test:0.01906, lr:3.97e-02, fs:0.71724 (r=0.598,p=0.897),  time:38.854, tt:2680.918\n",
      "Ep:69, loss:0.00001, loss_test:0.01902, lr:3.93e-02, fs:0.72603 (r=0.609,p=0.898),  time:38.883, tt:2721.814\n",
      "Ep:70, loss:0.00000, loss_test:0.01913, lr:3.89e-02, fs:0.72603 (r=0.609,p=0.898),  time:38.911, tt:2762.657\n",
      "Ep:71, loss:0.00000, loss_test:0.01925, lr:3.86e-02, fs:0.72603 (r=0.609,p=0.898),  time:38.930, tt:2802.932\n",
      "Ep:72, loss:0.00000, loss_test:0.01937, lr:3.82e-02, fs:0.71724 (r=0.598,p=0.897),  time:38.935, tt:2842.247\n",
      "Ep:73, loss:0.00000, loss_test:0.01939, lr:3.78e-02, fs:0.71724 (r=0.598,p=0.897),  time:38.978, tt:2884.393\n",
      "Ep:74, loss:0.00000, loss_test:0.01947, lr:3.74e-02, fs:0.71724 (r=0.598,p=0.897),  time:38.990, tt:2924.248\n",
      "Ep:75, loss:0.00000, loss_test:0.01955, lr:3.70e-02, fs:0.71724 (r=0.598,p=0.897),  time:39.007, tt:2964.504\n",
      "Ep:76, loss:0.00000, loss_test:0.01962, lr:3.67e-02, fs:0.72222 (r=0.598,p=0.912),  time:39.052, tt:3006.981\n",
      "Ep:77, loss:0.00000, loss_test:0.01971, lr:3.63e-02, fs:0.72222 (r=0.598,p=0.912),  time:39.068, tt:3047.292\n",
      "Ep:78, loss:0.00000, loss_test:0.01983, lr:3.59e-02, fs:0.71329 (r=0.586,p=0.911),  time:39.084, tt:3087.620\n",
      "Ep:79, loss:0.00000, loss_test:0.01993, lr:3.56e-02, fs:0.71329 (r=0.586,p=0.911),  time:39.101, tt:3128.119\n",
      "Ep:80, loss:0.00000, loss_test:0.01999, lr:3.52e-02, fs:0.71329 (r=0.586,p=0.911),  time:39.122, tt:3168.858\n",
      "Ep:81, loss:0.00000, loss_test:0.01999, lr:3.49e-02, fs:0.71831 (r=0.586,p=0.927),  time:39.150, tt:3210.279\n",
      "Ep:82, loss:0.00000, loss_test:0.02014, lr:3.45e-02, fs:0.71831 (r=0.586,p=0.927),  time:39.150, tt:3249.481\n",
      "Ep:83, loss:0.00000, loss_test:0.02027, lr:3.42e-02, fs:0.70000 (r=0.563,p=0.925),  time:39.143, tt:3288.033\n",
      "Ep:84, loss:0.00000, loss_test:0.02031, lr:3.38e-02, fs:0.71831 (r=0.586,p=0.927),  time:39.137, tt:3326.612\n",
      "Ep:85, loss:0.00000, loss_test:0.02040, lr:3.35e-02, fs:0.70922 (r=0.575,p=0.926),  time:39.147, tt:3366.647\n",
      "Ep:86, loss:0.00000, loss_test:0.02055, lr:3.32e-02, fs:0.70504 (r=0.563,p=0.942),  time:39.162, tt:3407.126\n",
      "Ep:87, loss:0.00000, loss_test:0.02050, lr:3.28e-02, fs:0.71429 (r=0.575,p=0.943),  time:39.163, tt:3446.379\n",
      "Ep:88, loss:0.00000, loss_test:0.02063, lr:3.25e-02, fs:0.70504 (r=0.563,p=0.942),  time:39.172, tt:3486.312\n",
      "Ep:89, loss:0.00000, loss_test:0.02075, lr:3.22e-02, fs:0.69118 (r=0.540,p=0.959),  time:39.189, tt:3526.975\n",
      "Ep:90, loss:0.00000, loss_test:0.02083, lr:3.19e-02, fs:0.69118 (r=0.540,p=0.959),  time:39.196, tt:3566.875\n",
      "Ep:91, loss:0.00000, loss_test:0.02097, lr:3.15e-02, fs:0.69118 (r=0.540,p=0.959),  time:39.202, tt:3606.538\n",
      "Ep:92, loss:0.00000, loss_test:0.02095, lr:3.12e-02, fs:0.69118 (r=0.540,p=0.959),  time:39.224, tt:3647.837\n",
      "Ep:93, loss:0.00000, loss_test:0.02106, lr:3.09e-02, fs:0.69118 (r=0.540,p=0.959),  time:39.242, tt:3688.774\n",
      "Ep:94, loss:0.00000, loss_test:0.02116, lr:3.06e-02, fs:0.69118 (r=0.540,p=0.959),  time:39.246, tt:3728.405\n",
      "Ep:95, loss:0.00000, loss_test:0.02122, lr:3.03e-02, fs:0.68148 (r=0.529,p=0.958),  time:39.271, tt:3769.977\n",
      "Ep:96, loss:0.00000, loss_test:0.02131, lr:3.00e-02, fs:0.68148 (r=0.529,p=0.958),  time:39.292, tt:3811.288\n",
      "Ep:97, loss:0.00000, loss_test:0.02136, lr:2.97e-02, fs:0.68148 (r=0.529,p=0.958),  time:39.299, tt:3851.283\n",
      "Ep:98, loss:0.00000, loss_test:0.02143, lr:2.94e-02, fs:0.67164 (r=0.517,p=0.957),  time:39.314, tt:3892.111\n",
      "Ep:99, loss:0.00000, loss_test:0.02150, lr:2.91e-02, fs:0.68148 (r=0.529,p=0.958),  time:39.335, tt:3933.525\n",
      "Ep:100, loss:0.00000, loss_test:0.02154, lr:2.88e-02, fs:0.68148 (r=0.529,p=0.958),  time:39.347, tt:3974.020\n",
      "Ep:101, loss:0.00000, loss_test:0.02159, lr:2.85e-02, fs:0.67164 (r=0.517,p=0.957),  time:39.371, tt:4015.858\n",
      "Ep:102, loss:0.00000, loss_test:0.02168, lr:2.82e-02, fs:0.67164 (r=0.517,p=0.957),  time:39.372, tt:4055.350\n",
      "Ep:103, loss:0.00000, loss_test:0.02170, lr:2.80e-02, fs:0.67164 (r=0.517,p=0.957),  time:39.375, tt:4095.005\n",
      "Ep:104, loss:0.00000, loss_test:0.02181, lr:2.77e-02, fs:0.67164 (r=0.517,p=0.957),  time:39.390, tt:4135.992\n",
      "Ep:105, loss:0.00000, loss_test:0.02181, lr:2.74e-02, fs:0.68148 (r=0.529,p=0.958),  time:39.400, tt:4176.368\n",
      "Ep:106, loss:0.00000, loss_test:0.02190, lr:2.71e-02, fs:0.67164 (r=0.517,p=0.957),  time:39.427, tt:4218.686\n",
      "Ep:107, loss:0.00000, loss_test:0.02193, lr:2.69e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.462, tt:4261.949\n",
      "Ep:108, loss:0.00000, loss_test:0.02202, lr:2.66e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.461, tt:4301.260\n",
      "Ep:109, loss:0.00000, loss_test:0.02206, lr:2.63e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.468, tt:4341.523\n",
      "Ep:110, loss:0.00000, loss_test:0.02212, lr:2.61e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.465, tt:4380.613\n",
      "Ep:111, loss:0.00000, loss_test:0.02220, lr:2.58e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.492, tt:4423.080\n",
      "Ep:112, loss:0.00000, loss_test:0.02225, lr:2.55e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.494, tt:4462.819\n",
      "Ep:113, loss:0.00000, loss_test:0.02231, lr:2.53e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.510, tt:4504.129\n",
      "Ep:114, loss:0.00000, loss_test:0.02235, lr:2.50e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.526, tt:4545.544\n",
      "Ep:115, loss:0.00000, loss_test:0.02241, lr:2.48e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.541, tt:4586.728\n",
      "Ep:116, loss:0.00000, loss_test:0.02251, lr:2.45e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.558, tt:4628.245\n",
      "Ep:117, loss:0.00000, loss_test:0.02250, lr:2.43e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.571, tt:4669.388\n",
      "Ep:118, loss:0.00000, loss_test:0.02258, lr:2.40e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.587, tt:4710.859\n",
      "Ep:119, loss:0.00000, loss_test:0.02259, lr:2.38e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.597, tt:4751.674\n",
      "Ep:120, loss:0.00000, loss_test:0.02269, lr:2.36e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.617, tt:4793.610\n",
      "Ep:121, loss:0.00000, loss_test:0.02272, lr:2.33e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.625, tt:4834.304\n",
      "Ep:122, loss:0.00000, loss_test:0.02274, lr:2.31e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.621, tt:4873.347\n",
      "Ep:123, loss:0.00000, loss_test:0.02282, lr:2.29e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.618, tt:4912.670\n",
      "Ep:124, loss:0.00000, loss_test:0.02285, lr:2.26e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.632, tt:4953.982\n",
      "Ep:125, loss:0.00000, loss_test:0.02287, lr:2.24e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.635, tt:4993.985\n",
      "Ep:126, loss:0.00000, loss_test:0.02290, lr:2.22e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.637, tt:5033.892\n",
      "Ep:127, loss:0.00000, loss_test:0.02299, lr:2.20e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.635, tt:5073.295\n",
      "Ep:128, loss:0.00000, loss_test:0.02300, lr:2.17e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.633, tt:5112.627\n",
      "Ep:129, loss:0.00000, loss_test:0.02304, lr:2.15e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.643, tt:5153.639\n",
      "Ep:130, loss:0.00000, loss_test:0.02311, lr:2.13e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.649, tt:5194.007\n",
      "Ep:131, loss:0.00000, loss_test:0.02308, lr:2.11e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.655, tt:5234.449\n",
      "Ep:132, loss:0.00000, loss_test:0.02314, lr:2.09e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.703, tt:5280.484\n",
      "Ep:133, loss:0.00000, loss_test:0.02319, lr:2.07e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.713, tt:5321.496\n",
      "Ep:134, loss:0.00000, loss_test:0.02320, lr:2.05e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.717, tt:5361.842\n",
      "Ep:135, loss:0.00000, loss_test:0.02326, lr:2.03e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.720, tt:5401.917\n",
      "Ep:136, loss:0.00000, loss_test:0.02332, lr:2.01e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.729, tt:5442.828\n",
      "Ep:137, loss:0.00000, loss_test:0.02333, lr:1.99e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.738, tt:5483.798\n",
      "Ep:138, loss:0.00000, loss_test:0.02336, lr:1.97e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.740, tt:5523.929\n",
      "Ep:139, loss:0.00000, loss_test:0.02340, lr:1.95e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.750, tt:5565.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.02342, lr:1.93e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.743, tt:5603.716\n",
      "Ep:141, loss:0.00000, loss_test:0.02348, lr:1.91e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.749, tt:5644.321\n",
      "Ep:142, loss:0.00000, loss_test:0.02351, lr:1.89e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.767, tt:5686.672\n",
      "Ep:143, loss:0.00000, loss_test:0.02351, lr:1.87e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.776, tt:5727.720\n",
      "Ep:144, loss:0.00000, loss_test:0.02356, lr:1.85e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.781, tt:5768.203\n",
      "Ep:145, loss:0.00000, loss_test:0.02362, lr:1.83e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.786, tt:5808.711\n",
      "Ep:146, loss:0.00000, loss_test:0.02364, lr:1.81e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.810, tt:5852.114\n",
      "Ep:147, loss:0.00000, loss_test:0.02371, lr:1.80e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.819, tt:5893.199\n",
      "Ep:148, loss:0.00000, loss_test:0.02371, lr:1.78e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.843, tt:5936.658\n",
      "Ep:149, loss:0.00000, loss_test:0.02374, lr:1.76e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.876, tt:5981.325\n",
      "Ep:150, loss:0.00000, loss_test:0.02381, lr:1.74e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.888, tt:6023.122\n",
      "Ep:151, loss:0.00000, loss_test:0.02381, lr:1.73e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.906, tt:6065.725\n",
      "Ep:152, loss:0.00000, loss_test:0.02385, lr:1.71e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.929, tt:6109.113\n",
      "Ep:153, loss:0.00000, loss_test:0.02388, lr:1.69e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.938, tt:6150.516\n",
      "Ep:154, loss:0.00000, loss_test:0.02388, lr:1.67e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.951, tt:6192.466\n",
      "Ep:155, loss:0.00000, loss_test:0.02390, lr:1.66e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.971, tt:6235.475\n",
      "Ep:156, loss:0.00000, loss_test:0.02393, lr:1.64e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.986, tt:6277.734\n",
      "Ep:157, loss:0.00000, loss_test:0.02399, lr:1.62e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.989, tt:6318.305\n",
      "Ep:158, loss:0.00000, loss_test:0.02398, lr:1.61e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.993, tt:6358.923\n",
      "Ep:159, loss:0.00000, loss_test:0.02401, lr:1.59e-02, fs:0.66165 (r=0.506,p=0.957),  time:39.998, tt:6399.754\n",
      "Ep:160, loss:0.00000, loss_test:0.02408, lr:1.58e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.016, tt:6442.556\n",
      "Ep:161, loss:0.00000, loss_test:0.02407, lr:1.56e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.024, tt:6483.901\n",
      "Ep:162, loss:0.00000, loss_test:0.02410, lr:1.54e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.037, tt:6525.955\n",
      "Ep:163, loss:0.00000, loss_test:0.02413, lr:1.53e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.046, tt:6567.502\n",
      "Ep:164, loss:0.00000, loss_test:0.02415, lr:1.51e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.044, tt:6607.308\n",
      "Ep:165, loss:0.00000, loss_test:0.02417, lr:1.50e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.059, tt:6649.751\n",
      "Ep:166, loss:0.00000, loss_test:0.02421, lr:1.48e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.084, tt:6694.046\n",
      "Ep:167, loss:0.00000, loss_test:0.02424, lr:1.47e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.092, tt:6735.432\n",
      "Ep:168, loss:0.00000, loss_test:0.02423, lr:1.45e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.101, tt:6777.051\n",
      "Ep:169, loss:0.00000, loss_test:0.02427, lr:1.44e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.097, tt:6816.521\n",
      "Ep:170, loss:0.00000, loss_test:0.02431, lr:1.43e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.093, tt:6855.967\n",
      "Ep:171, loss:0.00000, loss_test:0.02430, lr:1.41e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.094, tt:6896.131\n",
      "Ep:172, loss:0.00000, loss_test:0.02433, lr:1.40e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.103, tt:6937.861\n",
      "Ep:173, loss:0.00000, loss_test:0.02436, lr:1.38e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.100, tt:6977.394\n",
      "Ep:174, loss:0.00000, loss_test:0.02437, lr:1.37e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.099, tt:7017.243\n",
      "Ep:175, loss:0.00000, loss_test:0.02440, lr:1.36e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.098, tt:7057.317\n",
      "Ep:176, loss:0.00000, loss_test:0.02442, lr:1.34e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.102, tt:7098.024\n",
      "Ep:177, loss:0.00000, loss_test:0.02445, lr:1.33e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.106, tt:7138.887\n",
      "Ep:178, loss:0.00000, loss_test:0.02447, lr:1.32e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.103, tt:7178.437\n",
      "Ep:179, loss:0.00000, loss_test:0.02448, lr:1.30e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.102, tt:7218.269\n",
      "Ep:180, loss:0.00000, loss_test:0.02449, lr:1.29e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.106, tt:7259.158\n",
      "Ep:181, loss:0.00000, loss_test:0.02454, lr:1.28e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.110, tt:7300.101\n",
      "Ep:182, loss:0.00000, loss_test:0.02455, lr:1.26e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.110, tt:7340.079\n",
      "Ep:183, loss:0.00000, loss_test:0.02458, lr:1.25e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.109, tt:7380.060\n",
      "Ep:184, loss:0.00000, loss_test:0.02459, lr:1.24e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.105, tt:7419.416\n",
      "Ep:185, loss:0.00000, loss_test:0.02461, lr:1.23e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.114, tt:7461.191\n",
      "Ep:186, loss:0.00000, loss_test:0.02463, lr:1.21e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.117, tt:7501.867\n",
      "Ep:187, loss:0.00000, loss_test:0.02466, lr:1.20e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.128, tt:7544.062\n",
      "Ep:188, loss:0.00000, loss_test:0.02468, lr:1.19e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.127, tt:7583.970\n",
      "Ep:189, loss:0.00000, loss_test:0.02470, lr:1.18e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.121, tt:7622.945\n",
      "Ep:190, loss:0.00000, loss_test:0.02472, lr:1.17e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.115, tt:7661.977\n",
      "Ep:191, loss:0.00000, loss_test:0.02473, lr:1.15e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.112, tt:7701.444\n",
      "Ep:192, loss:0.00000, loss_test:0.02475, lr:1.14e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.115, tt:7742.204\n",
      "Ep:193, loss:0.00000, loss_test:0.02475, lr:1.13e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.123, tt:7783.880\n",
      "Ep:194, loss:0.00000, loss_test:0.02479, lr:1.12e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.116, tt:7822.706\n",
      "Ep:195, loss:0.00000, loss_test:0.02482, lr:1.11e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.134, tt:7866.216\n",
      "Ep:196, loss:0.00000, loss_test:0.02483, lr:1.10e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.127, tt:7905.043\n",
      "Ep:197, loss:0.00000, loss_test:0.02484, lr:1.09e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.121, tt:7943.989\n",
      "Ep:198, loss:0.00000, loss_test:0.02486, lr:1.08e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.119, tt:7983.717\n",
      "Ep:199, loss:0.00000, loss_test:0.02490, lr:1.07e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.118, tt:8023.516\n",
      "Ep:200, loss:0.00000, loss_test:0.02491, lr:1.05e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.115, tt:8063.123\n",
      "Ep:201, loss:0.00000, loss_test:0.02492, lr:1.04e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.112, tt:8102.574\n",
      "Ep:202, loss:0.00000, loss_test:0.02494, lr:1.03e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.112, tt:8142.668\n",
      "Ep:203, loss:0.00000, loss_test:0.02496, lr:1.02e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.117, tt:8183.773\n",
      "Ep:204, loss:0.00000, loss_test:0.02497, lr:1.01e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.091, tt:8218.574\n",
      "Ep:205, loss:0.00000, loss_test:0.02498, lr:1.00e-02, fs:0.66165 (r=0.506,p=0.957),  time:40.094, tt:8259.348\n",
      "Ep:206, loss:0.00000, loss_test:0.02502, lr:9.93e-03, fs:0.66165 (r=0.506,p=0.957),  time:40.090, tt:8298.559\n",
      "Ep:207, loss:0.00000, loss_test:0.02504, lr:9.83e-03, fs:0.66165 (r=0.506,p=0.957),  time:40.085, tt:8337.634\n",
      "Ep:208, loss:0.00000, loss_test:0.02505, lr:9.73e-03, fs:0.66165 (r=0.506,p=0.957),  time:40.065, tt:8373.570\n",
      "Ep:209, loss:0.00000, loss_test:0.02503, lr:9.63e-03, fs:0.66165 (r=0.506,p=0.957),  time:40.023, tt:8404.842\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14269, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.531, tt:36.531\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00028, loss_test:0.14156, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.776, tt:79.552\n",
      "Ep:2, loss:0.00028, loss_test:0.13950, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.509, tt:121.527\n",
      "Ep:3, loss:0.00027, loss_test:0.13600, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:40.971, tt:163.886\n",
      "Ep:4, loss:0.00026, loss_test:0.12984, lr:1.00e-02, fs:0.66135 (r=0.954,p=0.506),  time:40.936, tt:204.680\n",
      "Ep:5, loss:0.00025, loss_test:0.11937, lr:1.00e-02, fs:0.67580 (r=0.851,p=0.561),  time:41.436, tt:248.619\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11449, lr:1.00e-02, fs:0.68889 (r=0.713,p=0.667),  time:42.056, tt:294.395\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11171, lr:1.00e-02, fs:0.67039 (r=0.690,p=0.652),  time:41.792, tt:334.338\n",
      "Ep:8, loss:0.00022, loss_test:0.11228, lr:1.00e-02, fs:0.70192 (r=0.839,p=0.603),  time:41.931, tt:377.381\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10695, lr:1.00e-02, fs:0.71066 (r=0.805,p=0.636),  time:41.986, tt:419.857\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10284, lr:1.00e-02, fs:0.68639 (r=0.667,p=0.707),  time:42.167, tt:463.835\n",
      "Ep:11, loss:0.00019, loss_test:0.10143, lr:1.00e-02, fs:0.72527 (r=0.759,p=0.695),  time:42.296, tt:507.550\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09937, lr:1.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:42.279, tt:549.633\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09724, lr:1.00e-02, fs:0.71084 (r=0.678,p=0.747),  time:42.305, tt:592.271\n",
      "Ep:14, loss:0.00016, loss_test:0.09651, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:42.324, tt:634.855\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.09323, lr:1.00e-02, fs:0.72956 (r=0.667,p=0.806),  time:42.257, tt:676.113\n",
      "Ep:16, loss:0.00015, loss_test:0.09275, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:42.296, tt:719.037\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09204, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:42.343, tt:762.182\n",
      "Ep:18, loss:0.00013, loss_test:0.08980, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:42.404, tt:805.681\n",
      "Ep:19, loss:0.00013, loss_test:0.09327, lr:1.00e-02, fs:0.71795 (r=0.644,p=0.812),  time:42.357, tt:847.135\n",
      "Ep:20, loss:0.00012, loss_test:0.09184, lr:1.00e-02, fs:0.70370 (r=0.655,p=0.760),  time:42.351, tt:889.378\n",
      "Ep:21, loss:0.00011, loss_test:0.09389, lr:1.00e-02, fs:0.69388 (r=0.586,p=0.850),  time:42.351, tt:931.715\n",
      "Ep:22, loss:0.00010, loss_test:0.09261, lr:1.00e-02, fs:0.71338 (r=0.644,p=0.800),  time:42.275, tt:972.326\n",
      "Ep:23, loss:0.00010, loss_test:0.09206, lr:1.00e-02, fs:0.71338 (r=0.644,p=0.800),  time:42.190, tt:1012.553\n",
      "Ep:24, loss:0.00009, loss_test:0.09989, lr:1.00e-02, fs:0.69444 (r=0.575,p=0.877),  time:42.262, tt:1056.549\n",
      "Ep:25, loss:0.00009, loss_test:0.09033, lr:1.00e-02, fs:0.72152 (r=0.655,p=0.803),  time:42.259, tt:1098.740\n",
      "Ep:26, loss:0.00008, loss_test:0.10093, lr:1.00e-02, fs:0.72258 (r=0.644,p=0.824),  time:42.098, tt:1136.655\n",
      "Ep:27, loss:0.00008, loss_test:0.10030, lr:1.00e-02, fs:0.67626 (r=0.540,p=0.904),  time:42.042, tt:1177.175\n",
      "Ep:28, loss:0.00007, loss_test:0.09600, lr:9.90e-03, fs:0.72258 (r=0.644,p=0.824),  time:42.063, tt:1219.822\n",
      "Ep:29, loss:0.00007, loss_test:0.09189, lr:9.80e-03, fs:0.74172 (r=0.644,p=0.875),  time:42.112, tt:1263.349\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00006, loss_test:0.12073, lr:9.80e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.070, tt:1304.155\n",
      "Ep:31, loss:0.00006, loss_test:0.08909, lr:9.80e-03, fs:0.71250 (r=0.655,p=0.781),  time:42.118, tt:1347.769\n",
      "Ep:32, loss:0.00006, loss_test:0.11226, lr:9.80e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.194, tt:1392.407\n",
      "Ep:33, loss:0.00005, loss_test:0.09536, lr:9.80e-03, fs:0.73333 (r=0.632,p=0.873),  time:42.244, tt:1436.302\n",
      "Ep:34, loss:0.00005, loss_test:0.11163, lr:9.80e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.226, tt:1477.897\n",
      "Ep:35, loss:0.00005, loss_test:0.09880, lr:9.80e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.270, tt:1521.705\n",
      "Ep:36, loss:0.00004, loss_test:0.11432, lr:9.80e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.255, tt:1563.418\n",
      "Ep:37, loss:0.00004, loss_test:0.10413, lr:9.80e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.183, tt:1602.945\n",
      "Ep:38, loss:0.00003, loss_test:0.12575, lr:9.80e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.200, tt:1645.813\n",
      "Ep:39, loss:0.00003, loss_test:0.10260, lr:9.80e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.170, tt:1686.793\n",
      "Ep:40, loss:0.00003, loss_test:0.13354, lr:9.80e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.176, tt:1729.234\n",
      "Ep:41, loss:0.00003, loss_test:0.10140, lr:9.70e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.150, tt:1770.301\n",
      "Ep:42, loss:0.00003, loss_test:0.12822, lr:9.61e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.130, tt:1811.612\n",
      "Ep:43, loss:0.00002, loss_test:0.10814, lr:9.51e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.116, tt:1853.100\n",
      "Ep:44, loss:0.00002, loss_test:0.13345, lr:9.41e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.091, tt:1894.092\n",
      "Ep:45, loss:0.00002, loss_test:0.11043, lr:9.32e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.058, tt:1934.662\n",
      "Ep:46, loss:0.00002, loss_test:0.13086, lr:9.23e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.012, tt:1974.586\n",
      "Ep:47, loss:0.00002, loss_test:0.12274, lr:9.14e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.007, tt:2016.348\n",
      "Ep:48, loss:0.00001, loss_test:0.12261, lr:9.04e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.993, tt:2057.660\n",
      "Ep:49, loss:0.00001, loss_test:0.12750, lr:8.95e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.025, tt:2101.239\n",
      "Ep:50, loss:0.00001, loss_test:0.12370, lr:8.86e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.015, tt:2142.764\n",
      "Ep:51, loss:0.00001, loss_test:0.12771, lr:8.78e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.995, tt:2183.753\n",
      "Ep:52, loss:0.00001, loss_test:0.11922, lr:8.69e-03, fs:0.65672 (r=0.506,p=0.936),  time:41.965, tt:2224.128\n",
      "Ep:53, loss:0.00001, loss_test:0.13048, lr:8.60e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.948, tt:2265.191\n",
      "Ep:54, loss:0.00001, loss_test:0.13162, lr:8.51e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.945, tt:2306.973\n",
      "Ep:55, loss:0.00001, loss_test:0.12638, lr:8.43e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.931, tt:2348.112\n",
      "Ep:56, loss:0.00001, loss_test:0.13229, lr:8.35e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.857, tt:2385.823\n",
      "Ep:57, loss:0.00001, loss_test:0.12855, lr:8.26e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.818, tt:2425.459\n",
      "Ep:58, loss:0.00001, loss_test:0.13128, lr:8.18e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.807, tt:2466.639\n",
      "Ep:59, loss:0.00001, loss_test:0.12419, lr:8.10e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.779, tt:2506.726\n",
      "Ep:60, loss:0.00001, loss_test:0.13428, lr:8.02e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.764, tt:2547.593\n",
      "Ep:61, loss:0.00000, loss_test:0.12757, lr:7.94e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.784, tt:2590.612\n",
      "Ep:62, loss:0.00000, loss_test:0.12696, lr:7.86e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.808, tt:2633.910\n",
      "Ep:63, loss:0.00000, loss_test:0.12973, lr:7.78e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.800, tt:2675.193\n",
      "Ep:64, loss:0.00000, loss_test:0.12792, lr:7.70e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.761, tt:2714.483\n",
      "Ep:65, loss:0.00000, loss_test:0.12915, lr:7.62e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.739, tt:2754.765\n",
      "Ep:66, loss:0.00000, loss_test:0.12410, lr:7.55e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.723, tt:2795.448\n",
      "Ep:67, loss:0.00000, loss_test:0.13217, lr:7.47e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.701, tt:2835.647\n",
      "Ep:68, loss:0.00000, loss_test:0.12981, lr:7.40e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.696, tt:2877.042\n",
      "Ep:69, loss:0.00000, loss_test:0.12944, lr:7.32e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.703, tt:2919.177\n",
      "Ep:70, loss:0.00000, loss_test:0.13206, lr:7.25e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.693, tt:2960.225\n",
      "Ep:71, loss:0.00000, loss_test:0.12561, lr:7.18e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.692, tt:3001.857\n",
      "Ep:72, loss:0.00000, loss_test:0.13262, lr:7.11e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.686, tt:3043.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00000, loss_test:0.13109, lr:7.03e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.697, tt:3085.587\n",
      "Ep:74, loss:0.00000, loss_test:0.12615, lr:6.96e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.690, tt:3126.774\n",
      "Ep:75, loss:0.00000, loss_test:0.12888, lr:6.89e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.668, tt:3166.785\n",
      "Ep:76, loss:0.00000, loss_test:0.13041, lr:6.83e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.654, tt:3207.364\n",
      "Ep:77, loss:0.00000, loss_test:0.12745, lr:6.76e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.625, tt:3246.735\n",
      "Ep:78, loss:0.00000, loss_test:0.12678, lr:6.69e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.624, tt:3288.259\n",
      "Ep:79, loss:0.00000, loss_test:0.13051, lr:6.62e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.618, tt:3329.478\n",
      "Ep:80, loss:0.00000, loss_test:0.12911, lr:6.56e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.600, tt:3369.581\n",
      "Ep:81, loss:0.00000, loss_test:0.13001, lr:6.49e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.611, tt:3412.072\n",
      "Ep:82, loss:0.00000, loss_test:0.13002, lr:6.43e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.582, tt:3451.336\n",
      "Ep:83, loss:0.00000, loss_test:0.13057, lr:6.36e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.575, tt:3492.324\n",
      "Ep:84, loss:0.00000, loss_test:0.13368, lr:6.30e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.571, tt:3533.499\n",
      "Ep:85, loss:0.00000, loss_test:0.12936, lr:6.24e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.575, tt:3575.426\n",
      "Ep:86, loss:0.00000, loss_test:0.12994, lr:6.17e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.543, tt:3614.221\n",
      "Ep:87, loss:0.00000, loss_test:0.13190, lr:6.11e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.534, tt:3655.012\n",
      "Ep:88, loss:0.00000, loss_test:0.12968, lr:6.05e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.518, tt:3695.095\n",
      "Ep:89, loss:0.00000, loss_test:0.12781, lr:5.99e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.521, tt:3736.882\n",
      "Ep:90, loss:0.00000, loss_test:0.13282, lr:5.93e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.528, tt:3779.006\n",
      "Ep:91, loss:0.00000, loss_test:0.13041, lr:5.87e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.528, tt:3820.564\n",
      "Ep:92, loss:0.00000, loss_test:0.12734, lr:5.81e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.528, tt:3862.096\n",
      "Ep:93, loss:0.00000, loss_test:0.13066, lr:5.75e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.518, tt:3902.734\n",
      "Ep:94, loss:0.00000, loss_test:0.13027, lr:5.70e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.499, tt:3942.426\n",
      "Ep:95, loss:0.00000, loss_test:0.13010, lr:5.64e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.498, tt:3983.810\n",
      "Ep:96, loss:0.00000, loss_test:0.13191, lr:5.58e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.502, tt:4025.678\n",
      "Ep:97, loss:0.00000, loss_test:0.13114, lr:5.53e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.476, tt:4064.685\n",
      "Ep:98, loss:0.00000, loss_test:0.12874, lr:5.47e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.465, tt:4105.023\n",
      "Ep:99, loss:0.00000, loss_test:0.13057, lr:5.42e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.448, tt:4144.828\n",
      "Ep:100, loss:0.00000, loss_test:0.13052, lr:5.36e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.429, tt:4184.346\n",
      "Ep:101, loss:0.00000, loss_test:0.12715, lr:5.31e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.391, tt:4221.878\n",
      "Ep:102, loss:0.00000, loss_test:0.13079, lr:5.26e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.381, tt:4262.212\n",
      "Ep:103, loss:0.00000, loss_test:0.13325, lr:5.20e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.356, tt:4300.995\n",
      "Ep:104, loss:0.00000, loss_test:0.12780, lr:5.15e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.331, tt:4339.728\n",
      "Ep:105, loss:0.00000, loss_test:0.13093, lr:5.10e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.313, tt:4379.131\n",
      "Ep:106, loss:0.00000, loss_test:0.13698, lr:5.05e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.304, tt:4419.479\n",
      "Ep:107, loss:0.00000, loss_test:0.13198, lr:5.00e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.280, tt:4458.274\n",
      "Ep:108, loss:0.00000, loss_test:0.12757, lr:4.95e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.276, tt:4499.137\n",
      "Ep:109, loss:0.00000, loss_test:0.13107, lr:4.90e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.242, tt:4536.624\n",
      "Ep:110, loss:0.00000, loss_test:0.13294, lr:4.85e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.250, tt:4578.711\n",
      "Ep:111, loss:0.00000, loss_test:0.12891, lr:4.80e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.281, tt:4623.428\n",
      "Ep:112, loss:0.00000, loss_test:0.12788, lr:4.75e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.262, tt:4662.628\n",
      "Ep:113, loss:0.00000, loss_test:0.13250, lr:4.71e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.266, tt:4704.314\n",
      "Ep:114, loss:0.00000, loss_test:0.13080, lr:4.66e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.253, tt:4744.088\n",
      "Ep:115, loss:0.00000, loss_test:0.12615, lr:4.61e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.234, tt:4783.172\n",
      "Ep:116, loss:0.00000, loss_test:0.13086, lr:4.57e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.238, tt:4824.855\n",
      "Ep:117, loss:0.00000, loss_test:0.13197, lr:4.52e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.234, tt:4865.562\n",
      "Ep:118, loss:0.00000, loss_test:0.12842, lr:4.48e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.237, tt:4907.164\n",
      "Ep:119, loss:0.00000, loss_test:0.12755, lr:4.43e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.215, tt:4945.848\n",
      "Ep:120, loss:0.00000, loss_test:0.13087, lr:4.39e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.189, tt:4983.840\n",
      "Ep:121, loss:0.00000, loss_test:0.13082, lr:4.34e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.199, tt:5026.226\n",
      "Ep:122, loss:0.00000, loss_test:0.12728, lr:4.30e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.188, tt:5066.066\n",
      "Ep:123, loss:0.00000, loss_test:0.12954, lr:4.26e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.194, tt:5108.109\n",
      "Ep:124, loss:0.00000, loss_test:0.13344, lr:4.21e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.207, tt:5150.928\n",
      "Ep:125, loss:0.00000, loss_test:0.13067, lr:4.17e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.205, tt:5191.806\n",
      "Ep:126, loss:0.00000, loss_test:0.12649, lr:4.13e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.191, tt:5231.250\n",
      "Ep:127, loss:0.00000, loss_test:0.12977, lr:4.09e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.173, tt:5270.144\n",
      "Ep:128, loss:0.00000, loss_test:0.13157, lr:4.05e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.159, tt:5309.553\n",
      "Ep:129, loss:0.00000, loss_test:0.12959, lr:4.01e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.149, tt:5349.410\n",
      "Ep:130, loss:0.00000, loss_test:0.12794, lr:3.97e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.152, tt:5390.957\n",
      "Ep:131, loss:0.00000, loss_test:0.12871, lr:3.93e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.149, tt:5431.724\n",
      "Ep:132, loss:0.00000, loss_test:0.12958, lr:3.89e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.173, tt:5476.027\n",
      "Ep:133, loss:0.00000, loss_test:0.12836, lr:3.85e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.176, tt:5517.613\n",
      "Ep:134, loss:0.00000, loss_test:0.12721, lr:3.81e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.171, tt:5558.144\n",
      "Ep:135, loss:0.00000, loss_test:0.12955, lr:3.77e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.190, tt:5601.787\n",
      "Ep:136, loss:0.00000, loss_test:0.12928, lr:3.73e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.186, tt:5642.452\n",
      "Ep:137, loss:0.00000, loss_test:0.12752, lr:3.70e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.195, tt:5684.867\n",
      "Ep:138, loss:0.00000, loss_test:0.12681, lr:3.66e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.207, tt:5727.811\n",
      "Ep:139, loss:0.00000, loss_test:0.13176, lr:3.62e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.218, tt:5770.469\n",
      "Ep:140, loss:0.00000, loss_test:0.13206, lr:3.59e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.213, tt:5810.975\n",
      "Ep:141, loss:0.00000, loss_test:0.12914, lr:3.55e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.214, tt:5852.428\n",
      "Ep:142, loss:0.00000, loss_test:0.12687, lr:3.52e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.220, tt:5894.503\n",
      "Ep:143, loss:0.00000, loss_test:0.12840, lr:3.48e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.222, tt:5936.006\n",
      "Ep:144, loss:0.00000, loss_test:0.12902, lr:3.45e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.236, tt:5979.245\n",
      "Ep:145, loss:0.00000, loss_test:0.12797, lr:3.41e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.237, tt:6020.669\n",
      "Ep:146, loss:0.00000, loss_test:0.12681, lr:3.38e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.237, tt:6061.903\n",
      "Ep:147, loss:0.00000, loss_test:0.12863, lr:3.34e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.243, tt:6103.905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00000, loss_test:0.13030, lr:3.31e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.243, tt:6145.265\n",
      "Ep:149, loss:0.00000, loss_test:0.12963, lr:3.28e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.239, tt:6185.867\n",
      "Ep:150, loss:0.00000, loss_test:0.12746, lr:3.24e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.239, tt:6227.094\n",
      "Ep:151, loss:0.00000, loss_test:0.12762, lr:3.21e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.241, tt:6268.597\n",
      "Ep:152, loss:0.00000, loss_test:0.12847, lr:3.18e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.272, tt:6314.625\n",
      "Ep:153, loss:0.00000, loss_test:0.12814, lr:3.15e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.273, tt:6355.972\n",
      "Ep:154, loss:0.00000, loss_test:0.12735, lr:3.12e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.276, tt:6397.805\n",
      "Ep:155, loss:0.00000, loss_test:0.12904, lr:3.09e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.291, tt:6441.460\n",
      "Ep:156, loss:0.00000, loss_test:0.12889, lr:3.05e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.290, tt:6482.491\n",
      "Ep:157, loss:0.00000, loss_test:0.12761, lr:3.02e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.293, tt:6524.308\n",
      "Ep:158, loss:0.00000, loss_test:0.12745, lr:2.99e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.290, tt:6565.144\n",
      "Ep:159, loss:0.00000, loss_test:0.12753, lr:2.96e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.298, tt:6607.603\n",
      "Ep:160, loss:0.00000, loss_test:0.12767, lr:2.93e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.302, tt:6649.647\n",
      "Ep:161, loss:0.00000, loss_test:0.12753, lr:2.90e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.307, tt:6691.797\n",
      "Ep:162, loss:0.00000, loss_test:0.12681, lr:2.88e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.304, tt:6732.475\n",
      "Ep:163, loss:0.00000, loss_test:0.12654, lr:2.85e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.308, tt:6774.480\n",
      "Ep:164, loss:0.00000, loss_test:0.12678, lr:2.82e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.306, tt:6815.467\n",
      "Ep:165, loss:0.00000, loss_test:0.12828, lr:2.79e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.312, tt:6857.874\n",
      "Ep:166, loss:0.00000, loss_test:0.12812, lr:2.76e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.323, tt:6900.930\n",
      "Ep:167, loss:0.00000, loss_test:0.12695, lr:2.73e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.331, tt:6943.612\n",
      "Ep:168, loss:0.00000, loss_test:0.12622, lr:2.71e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.335, tt:6985.639\n",
      "Ep:169, loss:0.00000, loss_test:0.12831, lr:2.68e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.340, tt:7027.726\n",
      "Ep:170, loss:0.00000, loss_test:0.12920, lr:2.65e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.328, tt:7067.014\n",
      "Ep:171, loss:0.00000, loss_test:0.12822, lr:2.63e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.332, tt:7109.188\n",
      "Ep:172, loss:0.00000, loss_test:0.12669, lr:2.60e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.331, tt:7150.202\n",
      "Ep:173, loss:0.00000, loss_test:0.12724, lr:2.57e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.371, tt:7198.474\n",
      "Ep:174, loss:0.00000, loss_test:0.12829, lr:2.55e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.368, tt:7239.321\n",
      "Ep:175, loss:0.00000, loss_test:0.12785, lr:2.52e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.358, tt:7279.060\n",
      "Ep:176, loss:0.00000, loss_test:0.12644, lr:2.50e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.355, tt:7319.748\n",
      "Ep:177, loss:0.00000, loss_test:0.12732, lr:2.47e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.357, tt:7361.540\n",
      "Ep:178, loss:0.00000, loss_test:0.12791, lr:2.45e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.364, tt:7404.074\n",
      "Ep:179, loss:0.00000, loss_test:0.12763, lr:2.42e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.362, tt:7445.165\n",
      "Ep:180, loss:0.00000, loss_test:0.12681, lr:2.40e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.363, tt:7486.635\n",
      "Ep:181, loss:0.00000, loss_test:0.12660, lr:2.38e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.362, tt:7527.813\n",
      "Ep:182, loss:0.00000, loss_test:0.12685, lr:2.35e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.350, tt:7567.037\n",
      "Ep:183, loss:0.00000, loss_test:0.12714, lr:2.33e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.341, tt:7606.831\n",
      "Ep:184, loss:0.00000, loss_test:0.12671, lr:2.31e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.333, tt:7646.558\n",
      "Ep:185, loss:0.00000, loss_test:0.12660, lr:2.28e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.332, tt:7687.780\n",
      "Ep:186, loss:0.00000, loss_test:0.12711, lr:2.26e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.325, tt:7727.703\n",
      "Ep:187, loss:0.00000, loss_test:0.12703, lr:2.24e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.329, tt:7769.826\n",
      "Ep:188, loss:0.00000, loss_test:0.12687, lr:2.21e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.327, tt:7810.868\n",
      "Ep:189, loss:0.00000, loss_test:0.12694, lr:2.19e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.330, tt:7852.707\n",
      "Ep:190, loss:0.00000, loss_test:0.12744, lr:2.17e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.334, tt:7894.858\n",
      "Ep:191, loss:0.00000, loss_test:0.12781, lr:2.15e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.336, tt:7936.557\n",
      "Ep:192, loss:0.00000, loss_test:0.12733, lr:2.13e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.344, tt:7979.350\n",
      "Ep:193, loss:0.00000, loss_test:0.12653, lr:2.11e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.367, tt:8025.241\n",
      "Ep:194, loss:0.00000, loss_test:0.12663, lr:2.08e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.369, tt:8067.049\n",
      "Ep:195, loss:0.00000, loss_test:0.12726, lr:2.06e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.368, tt:8108.031\n",
      "Ep:196, loss:0.00000, loss_test:0.12715, lr:2.04e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.362, tt:8148.355\n",
      "Ep:197, loss:0.00000, loss_test:0.12674, lr:2.02e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.365, tt:8190.327\n",
      "Ep:198, loss:0.00000, loss_test:0.12674, lr:2.00e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.363, tt:8231.279\n",
      "Ep:199, loss:0.00000, loss_test:0.12683, lr:1.98e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.365, tt:8272.978\n",
      "Ep:200, loss:0.00000, loss_test:0.12697, lr:1.96e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.357, tt:8312.804\n",
      "Ep:201, loss:0.00000, loss_test:0.12699, lr:1.94e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.353, tt:8353.255\n",
      "Ep:202, loss:0.00000, loss_test:0.12691, lr:1.92e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.347, tt:8393.425\n",
      "Ep:203, loss:0.00000, loss_test:0.12671, lr:1.90e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.346, tt:8434.573\n",
      "Ep:204, loss:0.00000, loss_test:0.12616, lr:1.89e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.321, tt:8470.817\n",
      "Ep:205, loss:0.00000, loss_test:0.12725, lr:1.87e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.296, tt:8506.959\n",
      "Ep:206, loss:0.00000, loss_test:0.12760, lr:1.85e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.267, tt:8542.330\n",
      "Ep:207, loss:0.00000, loss_test:0.12718, lr:1.83e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.248, tt:8579.509\n",
      "Ep:208, loss:0.00000, loss_test:0.12685, lr:1.81e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.218, tt:8614.529\n",
      "Ep:209, loss:0.00000, loss_test:0.12660, lr:1.79e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.152, tt:8641.876\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01992, lr:6.00e-02, fs:0.65179 (r=0.839,p=0.533),  time:27.495, tt:27.495\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02234, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.928, tt:57.857\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02305, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.592, tt:88.777\n",
      "Ep:3, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.768, tt:119.074\n",
      "Ep:4, loss:0.00004, loss_test:0.02045, lr:6.00e-02, fs:0.66135 (r=0.954,p=0.506),  time:29.706, tt:148.531\n",
      "Ep:5, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.66383 (r=0.897,p=0.527),  time:30.139, tt:180.835\n",
      "Ep:6, loss:0.00004, loss_test:0.01932, lr:6.00e-02, fs:0.68493 (r=0.862,p=0.568),  time:30.236, tt:211.651\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01893, lr:6.00e-02, fs:0.69484 (r=0.851,p=0.587),  time:30.455, tt:243.636\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01852, lr:6.00e-02, fs:0.71304 (r=0.943,p=0.573),  time:30.234, tt:272.109\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01827, lr:6.00e-02, fs:0.70886 (r=0.966,p=0.560),  time:30.307, tt:303.074\n",
      "Ep:10, loss:0.00003, loss_test:0.01796, lr:6.00e-02, fs:0.71552 (r=0.954,p=0.572),  time:30.492, tt:335.415\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01767, lr:6.00e-02, fs:0.72889 (r=0.943,p=0.594),  time:30.431, tt:365.171\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01745, lr:6.00e-02, fs:0.73303 (r=0.931,p=0.604),  time:30.470, tt:396.113\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01720, lr:6.00e-02, fs:0.73874 (r=0.943,p=0.607),  time:30.565, tt:427.906\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.73874 (r=0.943,p=0.607),  time:30.667, tt:460.010\n",
      "Ep:15, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.74208 (r=0.943,p=0.612),  time:30.839, tt:493.417\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.74312 (r=0.931,p=0.618),  time:30.893, tt:525.184\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.75362 (r=0.897,p=0.650),  time:30.964, tt:557.357\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.75248 (r=0.874,p=0.661),  time:30.921, tt:587.498\n",
      "Ep:19, loss:0.00002, loss_test:0.01596, lr:6.00e-02, fs:0.76382 (r=0.874,p=0.679),  time:30.909, tt:618.174\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01577, lr:6.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:30.957, tt:650.090\n",
      "Ep:21, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.77949 (r=0.874,p=0.704),  time:31.045, tt:682.997\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.77487 (r=0.851,p=0.712),  time:30.982, tt:712.575\n",
      "Ep:23, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.75000 (r=0.793,p=0.711),  time:30.967, tt:743.197\n",
      "Ep:24, loss:0.00002, loss_test:0.01550, lr:6.00e-02, fs:0.73626 (r=0.770,p=0.705),  time:30.964, tt:774.088\n",
      "Ep:25, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:30.986, tt:805.624\n",
      "Ep:26, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:31.095, tt:839.564\n",
      "Ep:27, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.73256 (r=0.724,p=0.741),  time:31.070, tt:869.968\n",
      "Ep:28, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.72189 (r=0.701,p=0.744),  time:31.021, tt:899.618\n",
      "Ep:29, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.69880 (r=0.667,p=0.734),  time:30.907, tt:927.211\n",
      "Ep:30, loss:0.00001, loss_test:0.01549, lr:6.00e-02, fs:0.68712 (r=0.644,p=0.737),  time:30.893, tt:957.673\n",
      "Ep:31, loss:0.00001, loss_test:0.01551, lr:6.00e-02, fs:0.68712 (r=0.644,p=0.737),  time:30.862, tt:987.587\n",
      "Ep:32, loss:0.00001, loss_test:0.01538, lr:6.00e-02, fs:0.67500 (r=0.621,p=0.740),  time:30.890, tt:1019.374\n",
      "Ep:33, loss:0.00001, loss_test:0.01550, lr:5.94e-02, fs:0.67925 (r=0.621,p=0.750),  time:30.928, tt:1051.567\n",
      "Ep:34, loss:0.00001, loss_test:0.01563, lr:5.88e-02, fs:0.67089 (r=0.609,p=0.746),  time:30.962, tt:1083.662\n",
      "Ep:35, loss:0.00001, loss_test:0.01563, lr:5.82e-02, fs:0.67516 (r=0.609,p=0.757),  time:31.043, tt:1117.534\n",
      "Ep:36, loss:0.00001, loss_test:0.01578, lr:5.76e-02, fs:0.65806 (r=0.586,p=0.750),  time:31.080, tt:1149.978\n",
      "Ep:37, loss:0.00001, loss_test:0.01592, lr:5.71e-02, fs:0.65806 (r=0.586,p=0.750),  time:31.070, tt:1180.666\n",
      "Ep:38, loss:0.00001, loss_test:0.01585, lr:5.65e-02, fs:0.66234 (r=0.586,p=0.761),  time:31.055, tt:1211.156\n",
      "Ep:39, loss:0.00001, loss_test:0.01604, lr:5.59e-02, fs:0.66234 (r=0.586,p=0.761),  time:31.091, tt:1243.639\n",
      "Ep:40, loss:0.00001, loss_test:0.01631, lr:5.54e-02, fs:0.64901 (r=0.563,p=0.766),  time:31.021, tt:1271.859\n",
      "Ep:41, loss:0.00001, loss_test:0.01621, lr:5.48e-02, fs:0.65789 (r=0.575,p=0.769),  time:30.995, tt:1301.778\n",
      "Ep:42, loss:0.00001, loss_test:0.01643, lr:5.43e-02, fs:0.63946 (r=0.540,p=0.783),  time:30.979, tt:1332.081\n",
      "Ep:43, loss:0.00001, loss_test:0.01654, lr:5.37e-02, fs:0.63946 (r=0.540,p=0.783),  time:30.989, tt:1363.495\n",
      "Ep:44, loss:0.00001, loss_test:0.01664, lr:5.32e-02, fs:0.63014 (r=0.529,p=0.780),  time:30.994, tt:1394.743\n",
      "Ep:45, loss:0.00001, loss_test:0.01682, lr:5.27e-02, fs:0.63014 (r=0.529,p=0.780),  time:30.983, tt:1425.240\n",
      "Ep:46, loss:0.00001, loss_test:0.01714, lr:5.21e-02, fs:0.63448 (r=0.529,p=0.793),  time:30.987, tt:1456.388\n",
      "Ep:47, loss:0.00001, loss_test:0.01703, lr:5.16e-02, fs:0.63448 (r=0.529,p=0.793),  time:30.941, tt:1485.161\n",
      "Ep:48, loss:0.00001, loss_test:0.01725, lr:5.11e-02, fs:0.63448 (r=0.529,p=0.793),  time:30.882, tt:1513.223\n",
      "Ep:49, loss:0.00001, loss_test:0.01759, lr:5.06e-02, fs:0.64336 (r=0.529,p=0.821),  time:30.851, tt:1542.570\n",
      "Ep:50, loss:0.00001, loss_test:0.01736, lr:5.01e-02, fs:0.64336 (r=0.529,p=0.821),  time:30.848, tt:1573.224\n",
      "Ep:51, loss:0.00001, loss_test:0.01767, lr:4.96e-02, fs:0.63830 (r=0.517,p=0.833),  time:30.843, tt:1603.837\n",
      "Ep:52, loss:0.00001, loss_test:0.01789, lr:4.91e-02, fs:0.63830 (r=0.517,p=0.833),  time:30.831, tt:1634.024\n",
      "Ep:53, loss:0.00001, loss_test:0.01791, lr:4.86e-02, fs:0.64286 (r=0.517,p=0.849),  time:30.841, tt:1665.437\n",
      "Ep:54, loss:0.00001, loss_test:0.01813, lr:4.81e-02, fs:0.65693 (r=0.517,p=0.900),  time:30.841, tt:1696.235\n",
      "Ep:55, loss:0.00001, loss_test:0.01816, lr:4.76e-02, fs:0.65693 (r=0.517,p=0.900),  time:30.817, tt:1725.778\n",
      "Ep:56, loss:0.00001, loss_test:0.01822, lr:4.71e-02, fs:0.65693 (r=0.517,p=0.900),  time:30.802, tt:1755.704\n",
      "Ep:57, loss:0.00001, loss_test:0.01859, lr:4.67e-02, fs:0.65693 (r=0.517,p=0.900),  time:30.773, tt:1784.854\n",
      "Ep:58, loss:0.00001, loss_test:0.01858, lr:4.62e-02, fs:0.66176 (r=0.517,p=0.918),  time:30.760, tt:1814.830\n",
      "Ep:59, loss:0.00001, loss_test:0.01867, lr:4.57e-02, fs:0.66176 (r=0.517,p=0.918),  time:30.704, tt:1842.235\n",
      "Ep:60, loss:0.00001, loss_test:0.01867, lr:4.53e-02, fs:0.65672 (r=0.506,p=0.936),  time:30.701, tt:1872.731\n",
      "Ep:61, loss:0.00001, loss_test:0.01887, lr:4.48e-02, fs:0.65672 (r=0.506,p=0.936),  time:30.690, tt:1902.754\n",
      "Ep:62, loss:0.00001, loss_test:0.01915, lr:4.44e-02, fs:0.65672 (r=0.506,p=0.936),  time:30.690, tt:1933.445\n",
      "Ep:63, loss:0.00001, loss_test:0.01911, lr:4.39e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.692, tt:1964.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.01928, lr:4.35e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.674, tt:1993.790\n",
      "Ep:65, loss:0.00000, loss_test:0.01947, lr:4.31e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.683, tt:2025.069\n",
      "Ep:66, loss:0.00000, loss_test:0.01943, lr:4.26e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.669, tt:2054.805\n",
      "Ep:67, loss:0.00000, loss_test:0.01962, lr:4.22e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.665, tt:2085.239\n",
      "Ep:68, loss:0.00000, loss_test:0.01978, lr:4.18e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.674, tt:2116.484\n",
      "Ep:69, loss:0.00000, loss_test:0.01987, lr:4.14e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.643, tt:2145.002\n",
      "Ep:70, loss:0.00000, loss_test:0.01999, lr:4.10e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.650, tt:2176.140\n",
      "Ep:71, loss:0.00000, loss_test:0.02019, lr:4.05e-02, fs:0.66165 (r=0.506,p=0.957),  time:30.649, tt:2206.750\n",
      "Ep:72, loss:0.00000, loss_test:0.02021, lr:4.01e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.667, tt:2238.721\n",
      "Ep:73, loss:0.00000, loss_test:0.02034, lr:3.97e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.651, tt:2268.183\n",
      "Ep:74, loss:0.00000, loss_test:0.02043, lr:3.93e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.650, tt:2298.773\n",
      "Ep:75, loss:0.00000, loss_test:0.02056, lr:3.89e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.629, tt:2327.841\n",
      "Ep:76, loss:0.00000, loss_test:0.02066, lr:3.86e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.624, tt:2358.067\n",
      "Ep:77, loss:0.00000, loss_test:0.02070, lr:3.82e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.609, tt:2387.486\n",
      "Ep:78, loss:0.00000, loss_test:0.02091, lr:3.78e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.604, tt:2417.753\n",
      "Ep:79, loss:0.00000, loss_test:0.02084, lr:3.74e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.605, tt:2448.379\n",
      "Ep:80, loss:0.00000, loss_test:0.02097, lr:3.70e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.624, tt:2480.514\n",
      "Ep:81, loss:0.00000, loss_test:0.02117, lr:3.67e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.659, tt:2514.000\n",
      "Ep:82, loss:0.00000, loss_test:0.02114, lr:3.63e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.634, tt:2542.586\n",
      "Ep:83, loss:0.00000, loss_test:0.02129, lr:3.59e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.656, tt:2575.107\n",
      "Ep:84, loss:0.00000, loss_test:0.02126, lr:3.56e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.642, tt:2604.559\n",
      "Ep:85, loss:0.00000, loss_test:0.02140, lr:3.52e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.666, tt:2637.290\n",
      "Ep:86, loss:0.00000, loss_test:0.02153, lr:3.49e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.666, tt:2667.907\n",
      "Ep:87, loss:0.00000, loss_test:0.02157, lr:3.45e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.656, tt:2697.695\n",
      "Ep:88, loss:0.00000, loss_test:0.02166, lr:3.42e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.641, tt:2727.082\n",
      "Ep:89, loss:0.00000, loss_test:0.02182, lr:3.38e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.632, tt:2756.877\n",
      "Ep:90, loss:0.00000, loss_test:0.02181, lr:3.35e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.633, tt:2787.612\n",
      "Ep:91, loss:0.00000, loss_test:0.02191, lr:3.32e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.615, tt:2816.606\n",
      "Ep:92, loss:0.00000, loss_test:0.02200, lr:3.28e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.627, tt:2848.337\n",
      "Ep:93, loss:0.00000, loss_test:0.02219, lr:3.25e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.620, tt:2878.288\n",
      "Ep:94, loss:0.00000, loss_test:0.02214, lr:3.22e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.601, tt:2907.115\n",
      "Ep:95, loss:0.00000, loss_test:0.02229, lr:3.19e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.598, tt:2937.422\n",
      "Ep:96, loss:0.00000, loss_test:0.02240, lr:3.15e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.583, tt:2966.598\n",
      "Ep:97, loss:0.00000, loss_test:0.02231, lr:3.12e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.585, tt:2997.362\n",
      "Ep:98, loss:0.00000, loss_test:0.02247, lr:3.09e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.602, tt:3029.624\n",
      "Ep:99, loss:0.00000, loss_test:0.02260, lr:3.06e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.582, tt:3058.202\n",
      "Ep:100, loss:0.00000, loss_test:0.02256, lr:3.03e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.571, tt:3087.654\n",
      "Ep:101, loss:0.00000, loss_test:0.02266, lr:3.00e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.572, tt:3118.394\n",
      "Ep:102, loss:0.00000, loss_test:0.02272, lr:2.97e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.571, tt:3148.856\n",
      "Ep:103, loss:0.00000, loss_test:0.02284, lr:2.94e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.569, tt:3179.161\n",
      "Ep:104, loss:0.00000, loss_test:0.02289, lr:2.91e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.562, tt:3208.991\n",
      "Ep:105, loss:0.00000, loss_test:0.02292, lr:2.88e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.564, tt:3239.767\n",
      "Ep:106, loss:0.00000, loss_test:0.02299, lr:2.85e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.558, tt:3269.708\n",
      "Ep:107, loss:0.00000, loss_test:0.02306, lr:2.82e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.547, tt:3299.125\n",
      "Ep:108, loss:0.00000, loss_test:0.02312, lr:2.80e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.544, tt:3329.271\n",
      "Ep:109, loss:0.00000, loss_test:0.02320, lr:2.77e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.530, tt:3358.331\n",
      "Ep:110, loss:0.00000, loss_test:0.02331, lr:2.74e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.520, tt:3387.693\n",
      "Ep:111, loss:0.00000, loss_test:0.02335, lr:2.71e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.499, tt:3415.898\n",
      "Ep:112, loss:0.00000, loss_test:0.02334, lr:2.69e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.489, tt:3445.234\n",
      "Ep:113, loss:0.00000, loss_test:0.02346, lr:2.66e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.497, tt:3476.610\n",
      "Ep:114, loss:0.00000, loss_test:0.02352, lr:2.63e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.486, tt:3505.933\n",
      "Ep:115, loss:0.00000, loss_test:0.02356, lr:2.61e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.472, tt:3534.773\n",
      "Ep:116, loss:0.00000, loss_test:0.02366, lr:2.58e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.459, tt:3563.731\n",
      "Ep:117, loss:0.00000, loss_test:0.02357, lr:2.55e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.471, tt:3595.567\n",
      "Ep:118, loss:0.00000, loss_test:0.02371, lr:2.53e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.472, tt:3626.154\n",
      "Ep:119, loss:0.00000, loss_test:0.02384, lr:2.50e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.488, tt:3658.549\n",
      "Ep:120, loss:0.00000, loss_test:0.02369, lr:2.48e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.525, tt:3693.546\n",
      "Ep:121, loss:0.00000, loss_test:0.02386, lr:2.45e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.536, tt:3725.337\n",
      "Ep:122, loss:0.00000, loss_test:0.02392, lr:2.43e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.545, tt:3756.977\n",
      "Ep:123, loss:0.00000, loss_test:0.02394, lr:2.40e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.550, tt:3788.164\n",
      "Ep:124, loss:0.00000, loss_test:0.02401, lr:2.38e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.550, tt:3818.730\n",
      "Ep:125, loss:0.00000, loss_test:0.02402, lr:2.36e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.559, tt:3850.497\n",
      "Ep:126, loss:0.00000, loss_test:0.02407, lr:2.33e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.550, tt:3879.802\n",
      "Ep:127, loss:0.00000, loss_test:0.02418, lr:2.31e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.564, tt:3912.142\n",
      "Ep:128, loss:0.00000, loss_test:0.02412, lr:2.29e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.557, tt:3941.793\n",
      "Ep:129, loss:0.00000, loss_test:0.02425, lr:2.26e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.571, tt:3974.280\n",
      "Ep:130, loss:0.00000, loss_test:0.02423, lr:2.24e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.582, tt:4006.219\n",
      "Ep:131, loss:0.00000, loss_test:0.02431, lr:2.22e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.579, tt:4036.491\n",
      "Ep:132, loss:0.00000, loss_test:0.02435, lr:2.20e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.584, tt:4067.698\n",
      "Ep:133, loss:0.00000, loss_test:0.02440, lr:2.17e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.599, tt:4100.285\n",
      "Ep:134, loss:0.00000, loss_test:0.02446, lr:2.15e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.612, tt:4132.677\n",
      "Ep:135, loss:0.00000, loss_test:0.02445, lr:2.13e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.631, tt:4165.783\n",
      "Ep:136, loss:0.00000, loss_test:0.02455, lr:2.11e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.635, tt:4197.010\n",
      "Ep:137, loss:0.00000, loss_test:0.02456, lr:2.09e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.646, tt:4229.160\n",
      "Ep:138, loss:0.00000, loss_test:0.02457, lr:2.07e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.647, tt:4259.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.02466, lr:2.05e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.636, tt:4288.991\n",
      "Ep:140, loss:0.00000, loss_test:0.02467, lr:2.03e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.636, tt:4319.717\n",
      "Ep:141, loss:0.00000, loss_test:0.02467, lr:2.01e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.643, tt:4351.265\n",
      "Ep:142, loss:0.00000, loss_test:0.02472, lr:1.99e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.638, tt:4381.266\n",
      "Ep:143, loss:0.00000, loss_test:0.02478, lr:1.97e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.643, tt:4412.580\n",
      "Ep:144, loss:0.00000, loss_test:0.02480, lr:1.95e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.637, tt:4442.327\n",
      "Ep:145, loss:0.00000, loss_test:0.02481, lr:1.93e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.646, tt:4474.270\n",
      "Ep:146, loss:0.00000, loss_test:0.02484, lr:1.91e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.644, tt:4504.696\n",
      "Ep:147, loss:0.00000, loss_test:0.02487, lr:1.89e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.648, tt:4535.891\n",
      "Ep:148, loss:0.00000, loss_test:0.02496, lr:1.87e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.667, tt:4569.428\n",
      "Ep:149, loss:0.00000, loss_test:0.02492, lr:1.85e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.668, tt:4600.203\n",
      "Ep:150, loss:0.00000, loss_test:0.02498, lr:1.83e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.680, tt:4632.617\n",
      "Ep:151, loss:0.00000, loss_test:0.02501, lr:1.81e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.686, tt:4664.208\n",
      "Ep:152, loss:0.00000, loss_test:0.02499, lr:1.80e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.693, tt:4696.001\n",
      "Ep:153, loss:0.00000, loss_test:0.02510, lr:1.78e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.697, tt:4727.272\n",
      "Ep:154, loss:0.00000, loss_test:0.02505, lr:1.76e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.706, tt:4759.435\n",
      "Ep:155, loss:0.00000, loss_test:0.02512, lr:1.74e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.709, tt:4790.628\n",
      "Ep:156, loss:0.00000, loss_test:0.02517, lr:1.73e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.701, tt:4820.136\n",
      "Ep:157, loss:0.00000, loss_test:0.02519, lr:1.71e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.708, tt:4851.868\n",
      "Ep:158, loss:0.00000, loss_test:0.02519, lr:1.69e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.718, tt:4884.119\n",
      "Ep:159, loss:0.00000, loss_test:0.02522, lr:1.67e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.722, tt:4915.462\n",
      "Ep:160, loss:0.00000, loss_test:0.02526, lr:1.66e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.715, tt:4945.156\n",
      "Ep:161, loss:0.00000, loss_test:0.02529, lr:1.64e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.700, tt:4973.323\n",
      "Ep:162, loss:0.00000, loss_test:0.02529, lr:1.62e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.684, tt:5001.481\n",
      "Ep:163, loss:0.00000, loss_test:0.02533, lr:1.61e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.686, tt:5032.540\n",
      "Ep:164, loss:0.00000, loss_test:0.02536, lr:1.59e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.688, tt:5063.527\n",
      "Ep:165, loss:0.00000, loss_test:0.02540, lr:1.58e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.693, tt:5095.002\n",
      "Ep:166, loss:0.00000, loss_test:0.02539, lr:1.56e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.677, tt:5123.041\n",
      "Ep:167, loss:0.00000, loss_test:0.02545, lr:1.54e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.664, tt:5151.614\n",
      "Ep:168, loss:0.00000, loss_test:0.02545, lr:1.53e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.650, tt:5179.904\n",
      "Ep:169, loss:0.00000, loss_test:0.02548, lr:1.51e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.651, tt:5210.628\n",
      "Ep:170, loss:0.00000, loss_test:0.02550, lr:1.50e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.657, tt:5242.327\n",
      "Ep:171, loss:0.00000, loss_test:0.02552, lr:1.48e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.657, tt:5273.043\n",
      "Ep:172, loss:0.00000, loss_test:0.02554, lr:1.47e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.653, tt:5302.951\n",
      "Ep:173, loss:0.00000, loss_test:0.02559, lr:1.45e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.649, tt:5332.881\n",
      "Ep:174, loss:0.00000, loss_test:0.02560, lr:1.44e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.652, tt:5364.161\n",
      "Ep:175, loss:0.00000, loss_test:0.02561, lr:1.43e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.685, tt:5400.624\n",
      "Ep:176, loss:0.00000, loss_test:0.02566, lr:1.41e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.695, tt:5433.037\n",
      "Ep:177, loss:0.00000, loss_test:0.02567, lr:1.40e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.697, tt:5464.072\n",
      "Ep:178, loss:0.00000, loss_test:0.02565, lr:1.38e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.705, tt:5496.108\n",
      "Ep:179, loss:0.00000, loss_test:0.02573, lr:1.37e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.706, tt:5527.015\n",
      "Ep:180, loss:0.00000, loss_test:0.02572, lr:1.36e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.708, tt:5558.069\n",
      "Ep:181, loss:0.00000, loss_test:0.02570, lr:1.34e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.712, tt:5589.552\n",
      "Ep:182, loss:0.00000, loss_test:0.02576, lr:1.33e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.721, tt:5622.017\n",
      "Ep:183, loss:0.00000, loss_test:0.02576, lr:1.32e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.723, tt:5653.092\n",
      "Ep:184, loss:0.00000, loss_test:0.02578, lr:1.30e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.711, tt:5681.604\n",
      "Ep:185, loss:0.00000, loss_test:0.02583, lr:1.29e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.700, tt:5710.282\n",
      "Ep:186, loss:0.00000, loss_test:0.02581, lr:1.28e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.689, tt:5738.881\n",
      "Ep:187, loss:0.00000, loss_test:0.02584, lr:1.26e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.684, tt:5768.668\n",
      "Ep:188, loss:0.00000, loss_test:0.02588, lr:1.25e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.677, tt:5798.042\n",
      "Ep:189, loss:0.00000, loss_test:0.02588, lr:1.24e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.658, tt:5825.071\n",
      "Ep:190, loss:0.00000, loss_test:0.02589, lr:1.23e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.653, tt:5854.690\n",
      "Ep:191, loss:0.00000, loss_test:0.02594, lr:1.21e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.639, tt:5882.624\n",
      "Ep:192, loss:0.00000, loss_test:0.02595, lr:1.20e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.626, tt:5910.838\n",
      "Ep:193, loss:0.00000, loss_test:0.02594, lr:1.19e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.602, tt:5936.801\n",
      "Ep:194, loss:0.00000, loss_test:0.02597, lr:1.18e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.596, tt:5966.239\n",
      "Ep:195, loss:0.00000, loss_test:0.02599, lr:1.17e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.587, tt:5994.978\n",
      "Ep:196, loss:0.00000, loss_test:0.02601, lr:1.15e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.585, tt:6025.233\n",
      "Ep:197, loss:0.00000, loss_test:0.02600, lr:1.14e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.586, tt:6055.935\n",
      "Ep:198, loss:0.00000, loss_test:0.02600, lr:1.13e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.600, tt:6089.451\n",
      "Ep:199, loss:0.00000, loss_test:0.02603, lr:1.12e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.592, tt:6118.497\n",
      "Ep:200, loss:0.00000, loss_test:0.02605, lr:1.11e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.578, tt:6146.223\n",
      "Ep:201, loss:0.00000, loss_test:0.02607, lr:1.10e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.574, tt:6175.970\n",
      "Ep:202, loss:0.00000, loss_test:0.02608, lr:1.09e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.574, tt:6206.529\n",
      "Ep:203, loss:0.00000, loss_test:0.02609, lr:1.08e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.541, tt:6230.448\n",
      "Ep:204, loss:0.00000, loss_test:0.02611, lr:1.07e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.526, tt:6257.794\n",
      "Ep:205, loss:0.00000, loss_test:0.02612, lr:1.05e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.537, tt:6290.610\n",
      "Ep:206, loss:0.00000, loss_test:0.02612, lr:1.04e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.534, tt:6320.624\n",
      "Ep:207, loss:0.00000, loss_test:0.02616, lr:1.03e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.509, tt:6345.954\n",
      "Ep:208, loss:0.00000, loss_test:0.02617, lr:1.02e-02, fs:0.67176 (r=0.506,p=1.000),  time:30.496, tt:6373.563\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14031, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.123, tt:26.123\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00028, loss_test:0.13857, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.984, tt:53.968\n",
      "Ep:2, loss:0.00027, loss_test:0.13552, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:28.452, tt:85.356\n",
      "Ep:3, loss:0.00027, loss_test:0.13047, lr:1.00e-02, fs:0.67200 (r=0.966,p=0.515),  time:28.969, tt:115.876\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12292, lr:1.00e-02, fs:0.67500 (r=0.931,p=0.529),  time:29.627, tt:148.137\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11581, lr:1.00e-02, fs:0.67619 (r=0.816,p=0.577),  time:30.012, tt:180.070\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11481, lr:1.00e-02, fs:0.64835 (r=0.678,p=0.621),  time:30.391, tt:212.740\n",
      "Ep:7, loss:0.00023, loss_test:0.11543, lr:1.00e-02, fs:0.65556 (r=0.678,p=0.634),  time:30.345, tt:242.759\n",
      "Ep:8, loss:0.00022, loss_test:0.11337, lr:1.00e-02, fs:0.64583 (r=0.713,p=0.590),  time:30.293, tt:272.639\n",
      "Ep:9, loss:0.00021, loss_test:0.11082, lr:1.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:30.357, tt:303.575\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10812, lr:1.00e-02, fs:0.68421 (r=0.747,p=0.631),  time:30.826, tt:339.087\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10578, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:30.816, tt:369.790\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10160, lr:1.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:30.974, tt:402.658\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09933, lr:1.00e-02, fs:0.74074 (r=0.805,p=0.686),  time:30.784, tt:430.976\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09826, lr:1.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:30.818, tt:462.264\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09419, lr:1.00e-02, fs:0.76667 (r=0.793,p=0.742),  time:30.768, tt:492.295\n",
      "Ep:16, loss:0.00015, loss_test:0.09320, lr:1.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:30.924, tt:525.710\n",
      "Ep:17, loss:0.00015, loss_test:0.09226, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:30.983, tt:557.697\n",
      "Ep:18, loss:0.00014, loss_test:0.08890, lr:1.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:31.014, tt:589.263\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.09047, lr:1.00e-02, fs:0.72840 (r=0.678,p=0.787),  time:31.076, tt:621.527\n",
      "Ep:20, loss:0.00013, loss_test:0.08610, lr:1.00e-02, fs:0.77714 (r=0.782,p=0.773),  time:31.123, tt:653.579\n",
      "Ep:21, loss:0.00012, loss_test:0.08782, lr:1.00e-02, fs:0.73750 (r=0.678,p=0.808),  time:31.072, tt:683.575\n",
      "Ep:22, loss:0.00012, loss_test:0.08530, lr:1.00e-02, fs:0.76364 (r=0.724,p=0.808),  time:31.101, tt:715.326\n",
      "Ep:23, loss:0.00011, loss_test:0.08588, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:31.133, tt:747.194\n",
      "Ep:24, loss:0.00010, loss_test:0.08720, lr:1.00e-02, fs:0.74026 (r=0.655,p=0.851),  time:31.138, tt:778.461\n",
      "Ep:25, loss:0.00010, loss_test:0.08458, lr:1.00e-02, fs:0.73620 (r=0.690,p=0.789),  time:31.081, tt:808.111\n",
      "Ep:26, loss:0.00009, loss_test:0.08872, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:31.058, tt:838.568\n",
      "Ep:27, loss:0.00009, loss_test:0.08556, lr:1.00e-02, fs:0.71795 (r=0.644,p=0.812),  time:31.031, tt:868.879\n",
      "Ep:28, loss:0.00008, loss_test:0.09543, lr:1.00e-02, fs:0.67133 (r=0.552,p=0.857),  time:30.925, tt:896.839\n",
      "Ep:29, loss:0.00008, loss_test:0.08622, lr:1.00e-02, fs:0.70588 (r=0.621,p=0.818),  time:30.945, tt:928.360\n",
      "Ep:30, loss:0.00007, loss_test:0.09942, lr:9.90e-03, fs:0.65248 (r=0.529,p=0.852),  time:30.948, tt:959.399\n",
      "Ep:31, loss:0.00007, loss_test:0.08699, lr:9.80e-03, fs:0.67568 (r=0.575,p=0.820),  time:30.949, tt:990.375\n",
      "Ep:32, loss:0.00007, loss_test:0.10422, lr:9.70e-03, fs:0.64286 (r=0.517,p=0.849),  time:30.975, tt:1022.163\n",
      "Ep:33, loss:0.00006, loss_test:0.08619, lr:9.61e-03, fs:0.66667 (r=0.552,p=0.842),  time:31.004, tt:1054.142\n",
      "Ep:34, loss:0.00006, loss_test:0.09967, lr:9.51e-03, fs:0.65734 (r=0.540,p=0.839),  time:31.035, tt:1086.225\n",
      "Ep:35, loss:0.00005, loss_test:0.08848, lr:9.41e-03, fs:0.66667 (r=0.552,p=0.842),  time:31.061, tt:1118.187\n",
      "Ep:36, loss:0.00005, loss_test:0.10535, lr:9.32e-03, fs:0.65714 (r=0.529,p=0.868),  time:31.038, tt:1148.393\n",
      "Ep:37, loss:0.00005, loss_test:0.09322, lr:9.23e-03, fs:0.66667 (r=0.552,p=0.842),  time:31.099, tt:1181.763\n",
      "Ep:38, loss:0.00005, loss_test:0.10876, lr:9.14e-03, fs:0.64748 (r=0.517,p=0.865),  time:31.062, tt:1211.412\n",
      "Ep:39, loss:0.00004, loss_test:0.09552, lr:9.04e-03, fs:0.66667 (r=0.552,p=0.842),  time:31.058, tt:1242.328\n",
      "Ep:40, loss:0.00004, loss_test:0.10803, lr:8.95e-03, fs:0.64748 (r=0.517,p=0.865),  time:31.005, tt:1271.203\n",
      "Ep:41, loss:0.00004, loss_test:0.10192, lr:8.86e-03, fs:0.66197 (r=0.540,p=0.855),  time:30.990, tt:1301.584\n",
      "Ep:42, loss:0.00004, loss_test:0.10498, lr:8.78e-03, fs:0.64286 (r=0.517,p=0.849),  time:30.941, tt:1330.471\n",
      "Ep:43, loss:0.00003, loss_test:0.11143, lr:8.69e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.960, tt:1362.258\n",
      "Ep:44, loss:0.00003, loss_test:0.10244, lr:8.60e-03, fs:0.66197 (r=0.540,p=0.855),  time:30.982, tt:1394.204\n",
      "Ep:45, loss:0.00003, loss_test:0.11275, lr:8.51e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.965, tt:1424.375\n",
      "Ep:46, loss:0.00003, loss_test:0.10661, lr:8.43e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.934, tt:1453.905\n",
      "Ep:47, loss:0.00003, loss_test:0.11182, lr:8.35e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.915, tt:1483.929\n",
      "Ep:48, loss:0.00003, loss_test:0.11071, lr:8.26e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.896, tt:1513.893\n",
      "Ep:49, loss:0.00002, loss_test:0.11346, lr:8.18e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.901, tt:1545.072\n",
      "Ep:50, loss:0.00002, loss_test:0.11193, lr:8.10e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.887, tt:1575.237\n",
      "Ep:51, loss:0.00002, loss_test:0.11591, lr:8.02e-03, fs:0.65693 (r=0.517,p=0.900),  time:30.904, tt:1607.000\n",
      "Ep:52, loss:0.00002, loss_test:0.11391, lr:7.94e-03, fs:0.65693 (r=0.517,p=0.900),  time:30.889, tt:1637.139\n",
      "Ep:53, loss:0.00002, loss_test:0.11149, lr:7.86e-03, fs:0.65217 (r=0.517,p=0.882),  time:30.902, tt:1668.686\n",
      "Ep:54, loss:0.00002, loss_test:0.11851, lr:7.78e-03, fs:0.65693 (r=0.517,p=0.900),  time:30.905, tt:1699.761\n",
      "Ep:55, loss:0.00002, loss_test:0.11943, lr:7.70e-03, fs:0.66176 (r=0.517,p=0.918),  time:30.875, tt:1728.999\n",
      "Ep:56, loss:0.00002, loss_test:0.11675, lr:7.62e-03, fs:0.65693 (r=0.517,p=0.900),  time:30.872, tt:1759.698\n",
      "Ep:57, loss:0.00002, loss_test:0.11875, lr:7.55e-03, fs:0.65185 (r=0.506,p=0.917),  time:30.870, tt:1790.481\n",
      "Ep:58, loss:0.00002, loss_test:0.11489, lr:7.47e-03, fs:0.66176 (r=0.517,p=0.918),  time:30.874, tt:1821.580\n",
      "Ep:59, loss:0.00001, loss_test:0.12316, lr:7.40e-03, fs:0.65185 (r=0.506,p=0.917),  time:30.898, tt:1853.908\n",
      "Ep:60, loss:0.00001, loss_test:0.11330, lr:7.32e-03, fs:0.66176 (r=0.517,p=0.918),  time:30.906, tt:1885.291\n",
      "Ep:61, loss:0.00001, loss_test:0.12499, lr:7.25e-03, fs:0.65185 (r=0.506,p=0.917),  time:30.967, tt:1919.939\n",
      "Ep:62, loss:0.00001, loss_test:0.11101, lr:7.18e-03, fs:0.67153 (r=0.529,p=0.920),  time:31.058, tt:1956.654\n",
      "Ep:63, loss:0.00001, loss_test:0.12604, lr:7.11e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.121, tt:1991.760\n",
      "Ep:64, loss:0.00001, loss_test:0.11555, lr:7.03e-03, fs:0.66176 (r=0.517,p=0.918),  time:31.175, tt:2026.399\n",
      "Ep:65, loss:0.00001, loss_test:0.12409, lr:6.96e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.269, tt:2063.782\n",
      "Ep:66, loss:0.00001, loss_test:0.11602, lr:6.89e-03, fs:0.66176 (r=0.517,p=0.918),  time:31.343, tt:2099.993\n",
      "Ep:67, loss:0.00001, loss_test:0.12120, lr:6.83e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.433, tt:2137.475\n",
      "Ep:68, loss:0.00001, loss_test:0.12149, lr:6.76e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.500, tt:2173.507\n",
      "Ep:69, loss:0.00001, loss_test:0.12194, lr:6.69e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.556, tt:2208.934\n",
      "Ep:70, loss:0.00001, loss_test:0.12257, lr:6.62e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.582, tt:2242.323\n",
      "Ep:71, loss:0.00001, loss_test:0.11949, lr:6.56e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.617, tt:2276.431\n",
      "Ep:72, loss:0.00001, loss_test:0.12321, lr:6.49e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.617, tt:2308.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00001, loss_test:0.12375, lr:6.43e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.683, tt:2344.506\n",
      "Ep:74, loss:0.00001, loss_test:0.12099, lr:6.36e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.718, tt:2378.834\n",
      "Ep:75, loss:0.00001, loss_test:0.12411, lr:6.30e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.761, tt:2413.825\n",
      "Ep:76, loss:0.00001, loss_test:0.11884, lr:6.24e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.810, tt:2449.361\n",
      "Ep:77, loss:0.00001, loss_test:0.12680, lr:6.17e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.887, tt:2487.169\n",
      "Ep:78, loss:0.00001, loss_test:0.11987, lr:6.11e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.928, tt:2522.303\n",
      "Ep:79, loss:0.00001, loss_test:0.12481, lr:6.05e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.951, tt:2556.080\n",
      "Ep:80, loss:0.00001, loss_test:0.12618, lr:5.99e-03, fs:0.65185 (r=0.506,p=0.917),  time:31.987, tt:2590.962\n",
      "Ep:81, loss:0.00001, loss_test:0.11868, lr:5.93e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.035, tt:2626.901\n",
      "Ep:82, loss:0.00001, loss_test:0.12566, lr:5.87e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.083, tt:2662.913\n",
      "Ep:83, loss:0.00001, loss_test:0.12326, lr:5.81e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.149, tt:2700.485\n",
      "Ep:84, loss:0.00001, loss_test:0.12236, lr:5.75e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.191, tt:2736.247\n",
      "Ep:85, loss:0.00001, loss_test:0.12346, lr:5.70e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.249, tt:2773.416\n",
      "Ep:86, loss:0.00001, loss_test:0.12161, lr:5.64e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.301, tt:2810.151\n",
      "Ep:87, loss:0.00001, loss_test:0.12329, lr:5.58e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.358, tt:2847.546\n",
      "Ep:88, loss:0.00001, loss_test:0.12452, lr:5.53e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.380, tt:2881.781\n",
      "Ep:89, loss:0.00001, loss_test:0.12195, lr:5.47e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.426, tt:2918.348\n",
      "Ep:90, loss:0.00000, loss_test:0.12434, lr:5.42e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.436, tt:2951.663\n",
      "Ep:91, loss:0.00000, loss_test:0.12151, lr:5.36e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.483, tt:2988.426\n",
      "Ep:92, loss:0.00000, loss_test:0.12622, lr:5.31e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.500, tt:3022.545\n",
      "Ep:93, loss:0.00000, loss_test:0.12260, lr:5.26e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.533, tt:3058.109\n",
      "Ep:94, loss:0.00000, loss_test:0.12366, lr:5.20e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.576, tt:3094.759\n",
      "Ep:95, loss:0.00000, loss_test:0.12591, lr:5.15e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.602, tt:3129.778\n",
      "Ep:96, loss:0.00000, loss_test:0.12151, lr:5.10e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.650, tt:3167.014\n",
      "Ep:97, loss:0.00000, loss_test:0.12406, lr:5.05e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.740, tt:3208.533\n",
      "Ep:98, loss:0.00000, loss_test:0.12611, lr:5.00e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.774, tt:3244.629\n",
      "Ep:99, loss:0.00000, loss_test:0.12279, lr:4.95e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.830, tt:3282.972\n",
      "Ep:100, loss:0.00000, loss_test:0.12339, lr:4.90e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.865, tt:3319.389\n",
      "Ep:101, loss:0.00000, loss_test:0.12508, lr:4.85e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.897, tt:3355.523\n",
      "Ep:102, loss:0.00000, loss_test:0.12277, lr:4.80e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.934, tt:3392.170\n",
      "Ep:103, loss:0.00000, loss_test:0.12566, lr:4.75e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.969, tt:3428.802\n",
      "Ep:104, loss:0.00000, loss_test:0.12777, lr:4.71e-03, fs:0.65185 (r=0.506,p=0.917),  time:32.996, tt:3464.589\n",
      "Ep:105, loss:0.00000, loss_test:0.12538, lr:4.66e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.033, tt:3501.460\n",
      "Ep:106, loss:0.00000, loss_test:0.12515, lr:4.61e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.057, tt:3537.115\n",
      "Ep:107, loss:0.00000, loss_test:0.12587, lr:4.57e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.077, tt:3572.362\n",
      "Ep:108, loss:0.00000, loss_test:0.12556, lr:4.52e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.118, tt:3609.849\n",
      "Ep:109, loss:0.00000, loss_test:0.12686, lr:4.48e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.149, tt:3646.364\n",
      "Ep:110, loss:0.00000, loss_test:0.12519, lr:4.43e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.185, tt:3683.480\n",
      "Ep:111, loss:0.00000, loss_test:0.12626, lr:4.39e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.218, tt:3720.379\n",
      "Ep:112, loss:0.00000, loss_test:0.12716, lr:4.34e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.250, tt:3757.306\n",
      "Ep:113, loss:0.00000, loss_test:0.12516, lr:4.30e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.262, tt:3791.921\n",
      "Ep:114, loss:0.00000, loss_test:0.12655, lr:4.26e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.274, tt:3826.531\n",
      "Ep:115, loss:0.00000, loss_test:0.12782, lr:4.21e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.319, tt:3865.006\n",
      "Ep:116, loss:0.00000, loss_test:0.12619, lr:4.17e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.354, tt:3902.400\n",
      "Ep:117, loss:0.00000, loss_test:0.12699, lr:4.13e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.371, tt:3937.835\n",
      "Ep:118, loss:0.00000, loss_test:0.12757, lr:4.09e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.406, tt:3975.362\n",
      "Ep:119, loss:0.00000, loss_test:0.12753, lr:4.05e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.444, tt:4013.221\n",
      "Ep:120, loss:0.00000, loss_test:0.12835, lr:4.01e-03, fs:0.65185 (r=0.506,p=0.917),  time:33.489, tt:4052.181\n",
      "Ep:121, loss:0.00000, loss_test:0.12917, lr:3.97e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.513, tt:4088.571\n",
      "Ep:122, loss:0.00000, loss_test:0.12807, lr:3.93e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.550, tt:4126.701\n",
      "Ep:123, loss:0.00000, loss_test:0.12914, lr:3.89e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.586, tt:4164.647\n",
      "Ep:124, loss:0.00000, loss_test:0.13007, lr:3.85e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.607, tt:4200.842\n",
      "Ep:125, loss:0.00000, loss_test:0.12888, lr:3.81e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.633, tt:4237.765\n",
      "Ep:126, loss:0.00000, loss_test:0.13028, lr:3.77e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.647, tt:4273.208\n",
      "Ep:127, loss:0.00000, loss_test:0.13080, lr:3.73e-03, fs:0.65672 (r=0.506,p=0.936),  time:33.654, tt:4307.710\n",
      "Ep:128, loss:0.00000, loss_test:0.13053, lr:3.70e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.683, tt:4345.049\n",
      "Ep:129, loss:0.00000, loss_test:0.13011, lr:3.66e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.682, tt:4378.680\n",
      "Ep:130, loss:0.00000, loss_test:0.13042, lr:3.62e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.693, tt:4413.720\n",
      "Ep:131, loss:0.00000, loss_test:0.13181, lr:3.59e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.703, tt:4448.791\n",
      "Ep:132, loss:0.00000, loss_test:0.13060, lr:3.55e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.718, tt:4484.458\n",
      "Ep:133, loss:0.00000, loss_test:0.13097, lr:3.52e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.732, tt:4520.089\n",
      "Ep:134, loss:0.00000, loss_test:0.13255, lr:3.48e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.774, tt:4559.424\n",
      "Ep:135, loss:0.00000, loss_test:0.13196, lr:3.45e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.784, tt:4594.669\n",
      "Ep:136, loss:0.00000, loss_test:0.13170, lr:3.41e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.817, tt:4632.952\n",
      "Ep:137, loss:0.00000, loss_test:0.13168, lr:3.38e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.816, tt:4666.609\n",
      "Ep:138, loss:0.00000, loss_test:0.13215, lr:3.34e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.825, tt:4701.721\n",
      "Ep:139, loss:0.00000, loss_test:0.13335, lr:3.31e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.839, tt:4737.507\n",
      "Ep:140, loss:0.00000, loss_test:0.13226, lr:3.28e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.840, tt:4771.412\n",
      "Ep:141, loss:0.00000, loss_test:0.13238, lr:3.24e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.852, tt:4806.945\n",
      "Ep:142, loss:0.00000, loss_test:0.13253, lr:3.21e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.851, tt:4840.729\n",
      "Ep:143, loss:0.00000, loss_test:0.13332, lr:3.18e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.841, tt:4873.113\n",
      "Ep:144, loss:0.00000, loss_test:0.13209, lr:3.15e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.843, tt:4907.280\n",
      "Ep:145, loss:0.00000, loss_test:0.13286, lr:3.12e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.839, tt:4940.559\n",
      "Ep:146, loss:0.00000, loss_test:0.13484, lr:3.09e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.864, tt:4978.050\n",
      "Ep:147, loss:0.00000, loss_test:0.13370, lr:3.05e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.883, tt:5014.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00000, loss_test:0.13216, lr:3.02e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.903, tt:5051.573\n",
      "Ep:149, loss:0.00000, loss_test:0.13403, lr:2.99e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.902, tt:5085.349\n",
      "Ep:150, loss:0.00000, loss_test:0.13408, lr:2.96e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.905, tt:5119.597\n",
      "Ep:151, loss:0.00000, loss_test:0.13274, lr:2.93e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.916, tt:5155.248\n",
      "Ep:152, loss:0.00000, loss_test:0.13280, lr:2.90e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.921, tt:5189.945\n",
      "Ep:153, loss:0.00000, loss_test:0.13437, lr:2.88e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.936, tt:5226.203\n",
      "Ep:154, loss:0.00000, loss_test:0.13368, lr:2.85e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.947, tt:5261.743\n",
      "Ep:155, loss:0.00000, loss_test:0.13292, lr:2.82e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.949, tt:5296.027\n",
      "Ep:156, loss:0.00000, loss_test:0.13293, lr:2.79e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.956, tt:5331.149\n",
      "Ep:157, loss:0.00000, loss_test:0.13361, lr:2.76e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.952, tt:5364.433\n",
      "Ep:158, loss:0.00000, loss_test:0.13346, lr:2.73e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.971, tt:5401.347\n",
      "Ep:159, loss:0.00000, loss_test:0.13291, lr:2.71e-03, fs:0.66165 (r=0.506,p=0.957),  time:33.983, tt:5437.310\n",
      "Ep:160, loss:0.00000, loss_test:0.13283, lr:2.68e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.004, tt:5474.594\n",
      "Ep:161, loss:0.00000, loss_test:0.13433, lr:2.65e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.028, tt:5512.493\n",
      "Ep:162, loss:0.00000, loss_test:0.13396, lr:2.63e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.026, tt:5546.291\n",
      "Ep:163, loss:0.00000, loss_test:0.13309, lr:2.60e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.041, tt:5582.765\n",
      "Ep:164, loss:0.00000, loss_test:0.13285, lr:2.57e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.059, tt:5619.667\n",
      "Ep:165, loss:0.00000, loss_test:0.13336, lr:2.55e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.046, tt:5651.576\n",
      "Ep:166, loss:0.00000, loss_test:0.13310, lr:2.52e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.052, tt:5686.740\n",
      "Ep:167, loss:0.00000, loss_test:0.13280, lr:2.50e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.063, tt:5722.550\n",
      "Ep:168, loss:0.00000, loss_test:0.13324, lr:2.47e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.071, tt:5758.050\n",
      "Ep:169, loss:0.00000, loss_test:0.13331, lr:2.45e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.091, tt:5795.508\n",
      "Ep:170, loss:0.00000, loss_test:0.13241, lr:2.42e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.102, tt:5831.419\n",
      "Ep:171, loss:0.00000, loss_test:0.13305, lr:2.40e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.109, tt:5866.798\n",
      "Ep:172, loss:0.00000, loss_test:0.13315, lr:2.38e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.159, tt:5909.533\n",
      "Ep:173, loss:0.00000, loss_test:0.13312, lr:2.35e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.167, tt:5945.132\n",
      "Ep:174, loss:0.00000, loss_test:0.13356, lr:2.33e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.183, tt:5982.070\n",
      "Ep:175, loss:0.00000, loss_test:0.13239, lr:2.31e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.205, tt:6020.038\n",
      "Ep:176, loss:0.00000, loss_test:0.13253, lr:2.28e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.212, tt:6055.592\n",
      "Ep:177, loss:0.00000, loss_test:0.13330, lr:2.26e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.235, tt:6093.842\n",
      "Ep:178, loss:0.00000, loss_test:0.13337, lr:2.24e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.232, tt:6127.582\n",
      "Ep:179, loss:0.00000, loss_test:0.13217, lr:2.21e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.256, tt:6166.128\n",
      "Ep:180, loss:0.00000, loss_test:0.13243, lr:2.19e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.278, tt:6204.340\n",
      "Ep:181, loss:0.00000, loss_test:0.13296, lr:2.17e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.276, tt:6238.251\n",
      "Ep:182, loss:0.00000, loss_test:0.13223, lr:2.15e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.278, tt:6272.915\n",
      "Ep:183, loss:0.00000, loss_test:0.13256, lr:2.13e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.287, tt:6308.895\n",
      "Ep:184, loss:0.00000, loss_test:0.13345, lr:2.11e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.298, tt:6345.091\n",
      "Ep:185, loss:0.00000, loss_test:0.13263, lr:2.08e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.311, tt:6381.787\n",
      "Ep:186, loss:0.00000, loss_test:0.13169, lr:2.06e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.317, tt:6417.344\n",
      "Ep:187, loss:0.00000, loss_test:0.13338, lr:2.04e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.335, tt:6454.999\n",
      "Ep:188, loss:0.00000, loss_test:0.13327, lr:2.02e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.328, tt:6488.042\n",
      "Ep:189, loss:0.00000, loss_test:0.13259, lr:2.00e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.333, tt:6523.305\n",
      "Ep:190, loss:0.00000, loss_test:0.13309, lr:1.98e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.343, tt:6559.444\n",
      "Ep:191, loss:0.00000, loss_test:0.13235, lr:1.96e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.362, tt:6597.580\n",
      "Ep:192, loss:0.00000, loss_test:0.13232, lr:1.94e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.367, tt:6632.824\n",
      "Ep:193, loss:0.00000, loss_test:0.13233, lr:1.92e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.383, tt:6670.295\n",
      "Ep:194, loss:0.00000, loss_test:0.13226, lr:1.90e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.398, tt:6707.642\n",
      "Ep:195, loss:0.00000, loss_test:0.13191, lr:1.89e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.410, tt:6744.303\n",
      "Ep:196, loss:0.00000, loss_test:0.13257, lr:1.87e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.432, tt:6783.034\n",
      "Ep:197, loss:0.00000, loss_test:0.13257, lr:1.85e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.435, tt:6818.194\n",
      "Ep:198, loss:0.00000, loss_test:0.13172, lr:1.83e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.447, tt:6855.008\n",
      "Ep:199, loss:0.00000, loss_test:0.13197, lr:1.81e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.439, tt:6887.720\n",
      "Ep:200, loss:0.00000, loss_test:0.13274, lr:1.79e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.445, tt:6923.447\n",
      "Ep:201, loss:0.00000, loss_test:0.13226, lr:1.78e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.456, tt:6960.042\n",
      "Ep:202, loss:0.00000, loss_test:0.13174, lr:1.76e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.462, tt:6995.703\n",
      "Ep:203, loss:0.00000, loss_test:0.13267, lr:1.74e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.468, tt:7031.464\n",
      "Ep:204, loss:0.00000, loss_test:0.13278, lr:1.72e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.445, tt:7061.160\n",
      "Ep:205, loss:0.00000, loss_test:0.13186, lr:1.71e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.403, tt:7087.046\n",
      "Ep:206, loss:0.00000, loss_test:0.13155, lr:1.69e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.368, tt:7114.153\n",
      "Ep:207, loss:0.00000, loss_test:0.13234, lr:1.67e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.310, tt:7136.577\n",
      "Ep:208, loss:0.00000, loss_test:0.13243, lr:1.65e-03, fs:0.66165 (r=0.506,p=0.957),  time:34.242, tt:7156.549\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02090, lr:6.00e-02, fs:0.62762 (r=0.862,p=0.493),  time:33.826, tt:33.826\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02372, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.025, tt:70.051\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.564, tt:106.691\n",
      "Ep:3, loss:0.00005, loss_test:0.02411, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.733, tt:142.934\n",
      "Ep:4, loss:0.00005, loss_test:0.02283, lr:6.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:36.158, tt:180.789\n",
      "Ep:5, loss:0.00004, loss_test:0.02131, lr:6.00e-02, fs:0.66929 (r=0.977,p=0.509),  time:36.191, tt:217.147\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02015, lr:6.00e-02, fs:0.66942 (r=0.931,p=0.523),  time:36.121, tt:252.850\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01991, lr:6.00e-02, fs:0.68493 (r=0.862,p=0.568),  time:35.903, tt:287.226\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.68571 (r=0.828,p=0.585),  time:35.866, tt:322.797\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01925, lr:6.00e-02, fs:0.68246 (r=0.828,p=0.581),  time:35.878, tt:358.784\n",
      "Ep:10, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.69058 (r=0.885,p=0.566),  time:35.697, tt:392.664\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01823, lr:6.00e-02, fs:0.70130 (r=0.931,p=0.562),  time:35.603, tt:427.231\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01792, lr:6.00e-02, fs:0.69828 (r=0.931,p=0.559),  time:35.605, tt:462.864\n",
      "Ep:13, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.71429 (r=0.920,p=0.584),  time:35.480, tt:496.715\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01718, lr:6.00e-02, fs:0.71028 (r=0.874,p=0.598),  time:35.400, tt:531.006\n",
      "Ep:15, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.70476 (r=0.851,p=0.602),  time:35.485, tt:567.764\n",
      "Ep:16, loss:0.00003, loss_test:0.01668, lr:6.00e-02, fs:0.71498 (r=0.851,p=0.617),  time:35.552, tt:604.376\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.72115 (r=0.862,p=0.620),  time:35.528, tt:639.498\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.72986 (r=0.885,p=0.621),  time:35.734, tt:678.949\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.74038 (r=0.885,p=0.636),  time:35.721, tt:714.421\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01594, lr:6.00e-02, fs:0.74257 (r=0.862,p=0.652),  time:35.800, tt:751.809\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01581, lr:6.00e-02, fs:0.75258 (r=0.839,p=0.682),  time:35.780, tt:787.162\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.76842 (r=0.839,p=0.709),  time:35.716, tt:821.458\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.75676 (r=0.805,p=0.714),  time:35.675, tt:856.208\n",
      "Ep:24, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.75410 (r=0.793,p=0.719),  time:35.693, tt:892.326\n",
      "Ep:25, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.75410 (r=0.793,p=0.719),  time:35.727, tt:928.893\n",
      "Ep:26, loss:0.00002, loss_test:0.01510, lr:6.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:35.713, tt:964.260\n",
      "Ep:27, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.73864 (r=0.747,p=0.730),  time:35.643, tt:998.000\n",
      "Ep:28, loss:0.00002, loss_test:0.01508, lr:6.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:35.668, tt:1034.367\n",
      "Ep:29, loss:0.00002, loss_test:0.01507, lr:6.00e-02, fs:0.73684 (r=0.724,p=0.750),  time:35.705, tt:1071.158\n",
      "Ep:30, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.73684 (r=0.724,p=0.750),  time:35.752, tt:1108.317\n",
      "Ep:31, loss:0.00002, loss_test:0.01501, lr:6.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:35.768, tt:1144.588\n",
      "Ep:32, loss:0.00001, loss_test:0.01502, lr:6.00e-02, fs:0.72189 (r=0.701,p=0.744),  time:35.814, tt:1181.867\n",
      "Ep:33, loss:0.00001, loss_test:0.01507, lr:6.00e-02, fs:0.71429 (r=0.690,p=0.741),  time:35.833, tt:1218.330\n",
      "Ep:34, loss:0.00001, loss_test:0.01513, lr:5.94e-02, fs:0.71515 (r=0.678,p=0.756),  time:35.873, tt:1255.542\n",
      "Ep:35, loss:0.00001, loss_test:0.01519, lr:5.88e-02, fs:0.69939 (r=0.655,p=0.750),  time:35.883, tt:1291.776\n",
      "Ep:36, loss:0.00001, loss_test:0.01530, lr:5.82e-02, fs:0.69565 (r=0.644,p=0.757),  time:35.881, tt:1327.611\n",
      "Ep:37, loss:0.00001, loss_test:0.01537, lr:5.76e-02, fs:0.67925 (r=0.621,p=0.750),  time:35.905, tt:1364.376\n",
      "Ep:38, loss:0.00001, loss_test:0.01554, lr:5.71e-02, fs:0.67949 (r=0.609,p=0.768),  time:35.944, tt:1401.811\n",
      "Ep:39, loss:0.00001, loss_test:0.01554, lr:5.65e-02, fs:0.68387 (r=0.609,p=0.779),  time:35.997, tt:1439.886\n",
      "Ep:40, loss:0.00001, loss_test:0.01567, lr:5.59e-02, fs:0.67532 (r=0.598,p=0.776),  time:35.970, tt:1474.769\n",
      "Ep:41, loss:0.00001, loss_test:0.01579, lr:5.54e-02, fs:0.67532 (r=0.598,p=0.776),  time:36.051, tt:1514.136\n",
      "Ep:42, loss:0.00001, loss_test:0.01586, lr:5.48e-02, fs:0.66667 (r=0.586,p=0.773),  time:36.087, tt:1551.758\n",
      "Ep:43, loss:0.00001, loss_test:0.01595, lr:5.43e-02, fs:0.67105 (r=0.586,p=0.785),  time:36.145, tt:1590.394\n",
      "Ep:44, loss:0.00001, loss_test:0.01604, lr:5.37e-02, fs:0.67105 (r=0.586,p=0.785),  time:36.183, tt:1628.236\n",
      "Ep:45, loss:0.00001, loss_test:0.01618, lr:5.32e-02, fs:0.67550 (r=0.586,p=0.797),  time:36.187, tt:1664.608\n",
      "Ep:46, loss:0.00001, loss_test:0.01629, lr:5.27e-02, fs:0.68000 (r=0.586,p=0.810),  time:36.179, tt:1700.415\n",
      "Ep:47, loss:0.00001, loss_test:0.01637, lr:5.21e-02, fs:0.68456 (r=0.586,p=0.823),  time:36.181, tt:1736.675\n",
      "Ep:48, loss:0.00001, loss_test:0.01638, lr:5.16e-02, fs:0.68456 (r=0.586,p=0.823),  time:36.152, tt:1771.442\n",
      "Ep:49, loss:0.00001, loss_test:0.01642, lr:5.11e-02, fs:0.68456 (r=0.586,p=0.823),  time:36.154, tt:1807.708\n",
      "Ep:50, loss:0.00001, loss_test:0.01657, lr:5.06e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.157, tt:1844.024\n",
      "Ep:51, loss:0.00001, loss_test:0.01673, lr:5.01e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.137, tt:1879.143\n",
      "Ep:52, loss:0.00001, loss_test:0.01674, lr:4.96e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.140, tt:1915.411\n",
      "Ep:53, loss:0.00001, loss_test:0.01684, lr:4.91e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.169, tt:1953.118\n",
      "Ep:54, loss:0.00001, loss_test:0.01694, lr:4.86e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.205, tt:1991.262\n",
      "Ep:55, loss:0.00001, loss_test:0.01702, lr:4.81e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.233, tt:2029.024\n",
      "Ep:56, loss:0.00001, loss_test:0.01715, lr:4.76e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.220, tt:2064.520\n",
      "Ep:57, loss:0.00001, loss_test:0.01717, lr:4.71e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.247, tt:2102.317\n",
      "Ep:58, loss:0.00001, loss_test:0.01721, lr:4.67e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.257, tt:2139.177\n",
      "Ep:59, loss:0.00001, loss_test:0.01733, lr:4.62e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.271, tt:2176.236\n",
      "Ep:60, loss:0.00001, loss_test:0.01735, lr:4.57e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.381, tt:2219.229\n",
      "Ep:61, loss:0.00001, loss_test:0.01747, lr:4.53e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.391, tt:2256.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01751, lr:4.48e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.406, tt:2293.554\n",
      "Ep:63, loss:0.00001, loss_test:0.01757, lr:4.44e-02, fs:0.69388 (r=0.586,p=0.850),  time:36.393, tt:2329.125\n",
      "Ep:64, loss:0.00001, loss_test:0.01772, lr:4.39e-02, fs:0.70345 (r=0.586,p=0.879),  time:36.391, tt:2365.400\n",
      "Ep:65, loss:0.00001, loss_test:0.01776, lr:4.35e-02, fs:0.70345 (r=0.586,p=0.879),  time:36.416, tt:2403.439\n",
      "Ep:66, loss:0.00001, loss_test:0.01779, lr:4.31e-02, fs:0.70345 (r=0.586,p=0.879),  time:36.408, tt:2439.361\n",
      "Ep:67, loss:0.00000, loss_test:0.01798, lr:4.26e-02, fs:0.69444 (r=0.575,p=0.877),  time:36.396, tt:2474.925\n",
      "Ep:68, loss:0.00000, loss_test:0.01802, lr:4.22e-02, fs:0.69444 (r=0.575,p=0.877),  time:36.389, tt:2510.816\n",
      "Ep:69, loss:0.00000, loss_test:0.01801, lr:4.18e-02, fs:0.69444 (r=0.575,p=0.877),  time:36.388, tt:2547.126\n",
      "Ep:70, loss:0.00000, loss_test:0.01816, lr:4.14e-02, fs:0.69930 (r=0.575,p=0.893),  time:36.401, tt:2584.506\n",
      "Ep:71, loss:0.00000, loss_test:0.01818, lr:4.10e-02, fs:0.69930 (r=0.575,p=0.893),  time:36.412, tt:2621.646\n",
      "Ep:72, loss:0.00000, loss_test:0.01818, lr:4.05e-02, fs:0.68531 (r=0.563,p=0.875),  time:36.424, tt:2658.949\n",
      "Ep:73, loss:0.00000, loss_test:0.01829, lr:4.01e-02, fs:0.69930 (r=0.575,p=0.893),  time:36.428, tt:2695.645\n",
      "Ep:74, loss:0.00000, loss_test:0.01836, lr:3.97e-02, fs:0.69930 (r=0.575,p=0.893),  time:36.435, tt:2732.623\n",
      "Ep:75, loss:0.00000, loss_test:0.01838, lr:3.93e-02, fs:0.69014 (r=0.563,p=0.891),  time:36.443, tt:2769.671\n",
      "Ep:76, loss:0.00000, loss_test:0.01847, lr:3.89e-02, fs:0.69014 (r=0.563,p=0.891),  time:36.454, tt:2806.931\n",
      "Ep:77, loss:0.00000, loss_test:0.01857, lr:3.86e-02, fs:0.69014 (r=0.563,p=0.891),  time:36.477, tt:2845.210\n",
      "Ep:78, loss:0.00000, loss_test:0.01859, lr:3.82e-02, fs:0.68085 (r=0.552,p=0.889),  time:36.479, tt:2881.863\n",
      "Ep:79, loss:0.00000, loss_test:0.01872, lr:3.78e-02, fs:0.67626 (r=0.540,p=0.904),  time:36.516, tt:2921.273\n",
      "Ep:80, loss:0.00000, loss_test:0.01882, lr:3.74e-02, fs:0.67626 (r=0.540,p=0.904),  time:36.530, tt:2958.960\n",
      "Ep:81, loss:0.00000, loss_test:0.01883, lr:3.70e-02, fs:0.67626 (r=0.540,p=0.904),  time:36.548, tt:2996.911\n",
      "Ep:82, loss:0.00000, loss_test:0.01895, lr:3.67e-02, fs:0.66667 (r=0.529,p=0.902),  time:36.553, tt:3033.921\n",
      "Ep:83, loss:0.00000, loss_test:0.01896, lr:3.63e-02, fs:0.66667 (r=0.529,p=0.902),  time:36.607, tt:3075.005\n",
      "Ep:84, loss:0.00000, loss_test:0.01903, lr:3.59e-02, fs:0.66667 (r=0.529,p=0.902),  time:36.595, tt:3110.577\n",
      "Ep:85, loss:0.00000, loss_test:0.01905, lr:3.56e-02, fs:0.66667 (r=0.529,p=0.902),  time:36.604, tt:3147.977\n",
      "Ep:86, loss:0.00000, loss_test:0.01912, lr:3.52e-02, fs:0.66667 (r=0.529,p=0.902),  time:36.605, tt:3184.625\n",
      "Ep:87, loss:0.00000, loss_test:0.01920, lr:3.49e-02, fs:0.66667 (r=0.529,p=0.902),  time:36.602, tt:3220.961\n",
      "Ep:88, loss:0.00000, loss_test:0.01927, lr:3.45e-02, fs:0.65693 (r=0.517,p=0.900),  time:36.597, tt:3257.091\n",
      "Ep:89, loss:0.00000, loss_test:0.01930, lr:3.42e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.597, tt:3293.695\n",
      "Ep:90, loss:0.00000, loss_test:0.01938, lr:3.38e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.611, tt:3331.615\n",
      "Ep:91, loss:0.00000, loss_test:0.01940, lr:3.35e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.621, tt:3369.163\n",
      "Ep:92, loss:0.00000, loss_test:0.01951, lr:3.32e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.631, tt:3406.649\n",
      "Ep:93, loss:0.00000, loss_test:0.01955, lr:3.28e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.621, tt:3442.384\n",
      "Ep:94, loss:0.00000, loss_test:0.01959, lr:3.25e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.608, tt:3477.787\n",
      "Ep:95, loss:0.00000, loss_test:0.01965, lr:3.22e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.598, tt:3513.410\n",
      "Ep:96, loss:0.00000, loss_test:0.01967, lr:3.19e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.612, tt:3551.334\n",
      "Ep:97, loss:0.00000, loss_test:0.01971, lr:3.15e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.591, tt:3585.876\n",
      "Ep:98, loss:0.00000, loss_test:0.01976, lr:3.12e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.584, tt:3621.783\n",
      "Ep:99, loss:0.00000, loss_test:0.01984, lr:3.09e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.569, tt:3656.878\n",
      "Ep:100, loss:0.00000, loss_test:0.01986, lr:3.06e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.545, tt:3691.018\n",
      "Ep:101, loss:0.00000, loss_test:0.01991, lr:3.03e-02, fs:0.66176 (r=0.517,p=0.918),  time:36.544, tt:3727.466\n",
      "Ep:102, loss:0.00000, loss_test:0.01997, lr:3.00e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.563, tt:3766.030\n",
      "Ep:103, loss:0.00000, loss_test:0.02001, lr:2.97e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.553, tt:3801.558\n",
      "Ep:104, loss:0.00000, loss_test:0.02003, lr:2.94e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.514, tt:3833.945\n",
      "Ep:105, loss:0.00000, loss_test:0.02006, lr:2.91e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.451, tt:3863.809\n",
      "Ep:106, loss:0.00000, loss_test:0.02014, lr:2.88e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.397, tt:3894.504\n",
      "Ep:107, loss:0.00000, loss_test:0.02020, lr:2.85e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.338, tt:3924.497\n",
      "Ep:108, loss:0.00000, loss_test:0.02023, lr:2.82e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.295, tt:3956.177\n",
      "Ep:109, loss:0.00000, loss_test:0.02027, lr:2.80e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.246, tt:3987.089\n",
      "Ep:110, loss:0.00000, loss_test:0.02030, lr:2.77e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.203, tt:4018.589\n",
      "Ep:111, loss:0.00000, loss_test:0.02036, lr:2.74e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.174, tt:4051.517\n",
      "Ep:112, loss:0.00000, loss_test:0.02038, lr:2.71e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.179, tt:4088.265\n",
      "Ep:113, loss:0.00000, loss_test:0.02042, lr:2.69e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.203, tt:4127.176\n",
      "Ep:114, loss:0.00000, loss_test:0.02045, lr:2.66e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.203, tt:4163.352\n",
      "Ep:115, loss:0.00000, loss_test:0.02048, lr:2.63e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.206, tt:4199.843\n",
      "Ep:116, loss:0.00000, loss_test:0.02057, lr:2.61e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.206, tt:4236.043\n",
      "Ep:117, loss:0.00000, loss_test:0.02058, lr:2.58e-02, fs:0.65185 (r=0.506,p=0.917),  time:36.200, tt:4271.571\n",
      "Ep:118, loss:0.00000, loss_test:0.02060, lr:2.55e-02, fs:0.66165 (r=0.506,p=0.957),  time:36.203, tt:4308.150\n",
      "Ep:119, loss:0.00000, loss_test:0.02067, lr:2.53e-02, fs:0.66165 (r=0.506,p=0.957),  time:36.193, tt:4343.154\n",
      "Ep:120, loss:0.00000, loss_test:0.02067, lr:2.50e-02, fs:0.66165 (r=0.506,p=0.957),  time:36.202, tt:4380.449\n",
      "Ep:121, loss:0.00000, loss_test:0.02072, lr:2.48e-02, fs:0.66165 (r=0.506,p=0.957),  time:36.209, tt:4417.448\n",
      "Ep:122, loss:0.00000, loss_test:0.02077, lr:2.45e-02, fs:0.66165 (r=0.506,p=0.957),  time:36.209, tt:4453.668\n",
      "Ep:123, loss:0.00000, loss_test:0.02082, lr:2.43e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.209, tt:4489.964\n",
      "Ep:124, loss:0.00000, loss_test:0.02084, lr:2.40e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.209, tt:4526.134\n",
      "Ep:125, loss:0.00000, loss_test:0.02087, lr:2.38e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.204, tt:4561.660\n",
      "Ep:126, loss:0.00000, loss_test:0.02090, lr:2.36e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.210, tt:4598.619\n",
      "Ep:127, loss:0.00000, loss_test:0.02094, lr:2.33e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.202, tt:4633.902\n",
      "Ep:128, loss:0.00000, loss_test:0.02097, lr:2.31e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.213, tt:4671.434\n",
      "Ep:129, loss:0.00000, loss_test:0.02102, lr:2.29e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.227, tt:4709.562\n",
      "Ep:130, loss:0.00000, loss_test:0.02104, lr:2.26e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.244, tt:4747.984\n",
      "Ep:131, loss:0.00000, loss_test:0.02108, lr:2.24e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.243, tt:4784.077\n",
      "Ep:132, loss:0.00000, loss_test:0.02111, lr:2.22e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.253, tt:4821.676\n",
      "Ep:133, loss:0.00000, loss_test:0.02116, lr:2.20e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.264, tt:4859.407\n",
      "Ep:134, loss:0.00000, loss_test:0.02118, lr:2.17e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.265, tt:4895.797\n",
      "Ep:135, loss:0.00000, loss_test:0.02122, lr:2.15e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.267, tt:4932.336\n",
      "Ep:136, loss:0.00000, loss_test:0.02125, lr:2.13e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.349, tt:4979.836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02125, lr:2.11e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.359, tt:5017.574\n",
      "Ep:138, loss:0.00000, loss_test:0.02130, lr:2.09e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.347, tt:5052.181\n",
      "Ep:139, loss:0.00000, loss_test:0.02130, lr:2.07e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.357, tt:5090.034\n",
      "Ep:140, loss:0.00000, loss_test:0.02133, lr:2.05e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.383, tt:5129.986\n",
      "Ep:141, loss:0.00000, loss_test:0.02135, lr:2.03e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.394, tt:5167.913\n",
      "Ep:142, loss:0.00000, loss_test:0.02140, lr:2.01e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.411, tt:5206.832\n",
      "Ep:143, loss:0.00000, loss_test:0.02144, lr:1.99e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.405, tt:5242.295\n",
      "Ep:144, loss:0.00000, loss_test:0.02143, lr:1.97e-02, fs:0.66667 (r=0.506,p=0.978),  time:36.405, tt:5278.661\n",
      "Ep:145, loss:0.00000, loss_test:0.02148, lr:1.95e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.397, tt:5314.016\n",
      "Ep:146, loss:0.00000, loss_test:0.02150, lr:1.93e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.397, tt:5350.382\n",
      "Ep:147, loss:0.00000, loss_test:0.02153, lr:1.91e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.392, tt:5385.977\n",
      "Ep:148, loss:0.00000, loss_test:0.02153, lr:1.89e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.390, tt:5422.112\n",
      "Ep:149, loss:0.00000, loss_test:0.02157, lr:1.87e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.381, tt:5457.158\n",
      "Ep:150, loss:0.00000, loss_test:0.02161, lr:1.85e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.375, tt:5492.693\n",
      "Ep:151, loss:0.00000, loss_test:0.02163, lr:1.83e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.366, tt:5527.673\n",
      "Ep:152, loss:0.00000, loss_test:0.02166, lr:1.81e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.360, tt:5563.136\n",
      "Ep:153, loss:0.00000, loss_test:0.02168, lr:1.80e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.350, tt:5597.839\n",
      "Ep:154, loss:0.00000, loss_test:0.02171, lr:1.78e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.358, tt:5635.517\n",
      "Ep:155, loss:0.00000, loss_test:0.02173, lr:1.76e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.351, tt:5670.780\n",
      "Ep:156, loss:0.00000, loss_test:0.02175, lr:1.74e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.349, tt:5706.851\n",
      "Ep:157, loss:0.00000, loss_test:0.02178, lr:1.73e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.339, tt:5741.509\n",
      "Ep:158, loss:0.00000, loss_test:0.02180, lr:1.71e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.341, tt:5778.222\n",
      "Ep:159, loss:0.00000, loss_test:0.02182, lr:1.69e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.333, tt:5813.346\n",
      "Ep:160, loss:0.00000, loss_test:0.02184, lr:1.67e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.330, tt:5849.058\n",
      "Ep:161, loss:0.00000, loss_test:0.02187, lr:1.66e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.320, tt:5883.818\n",
      "Ep:162, loss:0.00000, loss_test:0.02188, lr:1.64e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.329, tt:5921.686\n",
      "Ep:163, loss:0.00000, loss_test:0.02192, lr:1.62e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.330, tt:5958.149\n",
      "Ep:164, loss:0.00000, loss_test:0.02195, lr:1.61e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.324, tt:5993.428\n",
      "Ep:165, loss:0.00000, loss_test:0.02196, lr:1.59e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.314, tt:6028.055\n",
      "Ep:166, loss:0.00000, loss_test:0.02197, lr:1.58e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.319, tt:6065.190\n",
      "Ep:167, loss:0.00000, loss_test:0.02200, lr:1.56e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.311, tt:6100.258\n",
      "Ep:168, loss:0.00000, loss_test:0.02203, lr:1.54e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.333, tt:6140.252\n",
      "Ep:169, loss:0.00000, loss_test:0.02205, lr:1.53e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.336, tt:6177.123\n",
      "Ep:170, loss:0.00000, loss_test:0.02206, lr:1.51e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.341, tt:6214.359\n",
      "Ep:171, loss:0.00000, loss_test:0.02209, lr:1.50e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.330, tt:6248.730\n",
      "Ep:172, loss:0.00000, loss_test:0.02211, lr:1.48e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.326, tt:6284.370\n",
      "Ep:173, loss:0.00000, loss_test:0.02212, lr:1.47e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.320, tt:6319.602\n",
      "Ep:174, loss:0.00000, loss_test:0.02214, lr:1.45e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.315, tt:6355.111\n",
      "Ep:175, loss:0.00000, loss_test:0.02216, lr:1.44e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.325, tt:6393.161\n",
      "Ep:176, loss:0.00000, loss_test:0.02218, lr:1.43e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.320, tt:6428.605\n",
      "Ep:177, loss:0.00000, loss_test:0.02220, lr:1.41e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.333, tt:6467.285\n",
      "Ep:178, loss:0.00000, loss_test:0.02223, lr:1.40e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.323, tt:6501.829\n",
      "Ep:179, loss:0.00000, loss_test:0.02224, lr:1.38e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.331, tt:6539.563\n",
      "Ep:180, loss:0.00000, loss_test:0.02226, lr:1.37e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.332, tt:6576.151\n",
      "Ep:181, loss:0.00000, loss_test:0.02228, lr:1.36e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.329, tt:6611.869\n",
      "Ep:182, loss:0.00000, loss_test:0.02230, lr:1.34e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.327, tt:6647.893\n",
      "Ep:183, loss:0.00000, loss_test:0.02232, lr:1.33e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.331, tt:6684.925\n",
      "Ep:184, loss:0.00000, loss_test:0.02233, lr:1.32e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.330, tt:6721.108\n",
      "Ep:185, loss:0.00000, loss_test:0.02235, lr:1.30e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.327, tt:6756.789\n",
      "Ep:186, loss:0.00000, loss_test:0.02237, lr:1.29e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.308, tt:6789.504\n",
      "Ep:187, loss:0.00000, loss_test:0.02239, lr:1.28e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.294, tt:6823.356\n",
      "Ep:188, loss:0.00000, loss_test:0.02241, lr:1.26e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.295, tt:6859.815\n",
      "Ep:189, loss:0.00000, loss_test:0.02242, lr:1.25e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.297, tt:6896.499\n",
      "Ep:190, loss:0.00000, loss_test:0.02243, lr:1.24e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.290, tt:6931.469\n",
      "Ep:191, loss:0.00000, loss_test:0.02245, lr:1.23e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.288, tt:6967.261\n",
      "Ep:192, loss:0.00000, loss_test:0.02246, lr:1.21e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.283, tt:7002.569\n",
      "Ep:193, loss:0.00000, loss_test:0.02247, lr:1.20e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.280, tt:7038.360\n",
      "Ep:194, loss:0.00000, loss_test:0.02249, lr:1.19e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.273, tt:7073.246\n",
      "Ep:195, loss:0.00000, loss_test:0.02251, lr:1.18e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.267, tt:7108.318\n",
      "Ep:196, loss:0.00000, loss_test:0.02252, lr:1.17e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.264, tt:7144.090\n",
      "Ep:197, loss:0.00000, loss_test:0.02253, lr:1.15e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.268, tt:7181.102\n",
      "Ep:198, loss:0.00000, loss_test:0.02256, lr:1.14e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.265, tt:7216.792\n",
      "Ep:199, loss:0.00000, loss_test:0.02256, lr:1.13e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.263, tt:7252.635\n",
      "Ep:200, loss:0.00000, loss_test:0.02258, lr:1.12e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.267, tt:7289.606\n",
      "Ep:201, loss:0.00000, loss_test:0.02260, lr:1.11e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.250, tt:7322.559\n",
      "Ep:202, loss:0.00000, loss_test:0.02262, lr:1.10e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.237, tt:7356.062\n",
      "Ep:203, loss:0.00000, loss_test:0.02263, lr:1.09e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.225, tt:7389.970\n",
      "Ep:204, loss:0.00000, loss_test:0.02263, lr:1.08e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.210, tt:7423.145\n",
      "Ep:205, loss:0.00000, loss_test:0.02265, lr:1.07e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.205, tt:7458.223\n",
      "Ep:206, loss:0.00000, loss_test:0.02266, lr:1.05e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.171, tt:7487.354\n",
      "Ep:207, loss:0.00000, loss_test:0.02267, lr:1.04e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.157, tt:7520.744\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14556, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.464, tt:32.464\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14481, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.755, tt:67.510\n",
      "Ep:2, loss:0.00028, loss_test:0.14345, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.240, tt:99.721\n",
      "Ep:3, loss:0.00028, loss_test:0.14119, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:33.414, tt:133.657\n",
      "Ep:4, loss:0.00027, loss_test:0.13746, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:33.768, tt:168.839\n",
      "Ep:5, loss:0.00026, loss_test:0.13182, lr:1.00e-02, fs:0.63374 (r=0.885,p=0.494),  time:34.214, tt:205.283\n",
      "Ep:6, loss:0.00025, loss_test:0.12417, lr:1.00e-02, fs:0.67257 (r=0.874,p=0.547),  time:34.595, tt:242.164\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11833, lr:1.00e-02, fs:0.67708 (r=0.747,p=0.619),  time:34.750, tt:277.997\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11701, lr:1.00e-02, fs:0.64444 (r=0.667,p=0.624),  time:34.725, tt:312.525\n",
      "Ep:9, loss:0.00022, loss_test:0.11395, lr:1.00e-02, fs:0.71503 (r=0.793,p=0.651),  time:34.858, tt:348.583\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.11123, lr:1.00e-02, fs:0.73846 (r=0.828,p=0.667),  time:35.073, tt:385.799\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10682, lr:1.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:35.127, tt:421.522\n",
      "Ep:12, loss:0.00019, loss_test:0.10412, lr:1.00e-02, fs:0.72316 (r=0.736,p=0.711),  time:35.129, tt:456.676\n",
      "Ep:13, loss:0.00019, loss_test:0.10238, lr:1.00e-02, fs:0.75556 (r=0.782,p=0.731),  time:35.078, tt:491.087\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10042, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:35.280, tt:529.195\n",
      "Ep:15, loss:0.00017, loss_test:0.09794, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:35.303, tt:564.843\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09522, lr:1.00e-02, fs:0.73494 (r=0.701,p=0.772),  time:35.427, tt:602.253\n",
      "Ep:17, loss:0.00015, loss_test:0.09274, lr:1.00e-02, fs:0.75000 (r=0.724,p=0.778),  time:35.365, tt:636.575\n",
      "Ep:18, loss:0.00014, loss_test:0.09205, lr:1.00e-02, fs:0.68387 (r=0.609,p=0.779),  time:35.398, tt:672.564\n",
      "Ep:19, loss:0.00014, loss_test:0.09036, lr:1.00e-02, fs:0.70440 (r=0.644,p=0.778),  time:35.338, tt:706.755\n",
      "Ep:20, loss:0.00013, loss_test:0.08865, lr:1.00e-02, fs:0.71250 (r=0.655,p=0.781),  time:35.366, tt:742.691\n",
      "Ep:21, loss:0.00012, loss_test:0.08813, lr:1.00e-02, fs:0.72152 (r=0.655,p=0.803),  time:35.380, tt:778.367\n",
      "Ep:22, loss:0.00012, loss_test:0.08628, lr:1.00e-02, fs:0.73418 (r=0.667,p=0.817),  time:35.270, tt:811.215\n",
      "Ep:23, loss:0.00011, loss_test:0.08826, lr:1.00e-02, fs:0.68000 (r=0.586,p=0.810),  time:35.264, tt:846.343\n",
      "Ep:24, loss:0.00011, loss_test:0.08404, lr:1.00e-02, fs:0.76543 (r=0.713,p=0.827),  time:35.286, tt:882.162\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.08675, lr:1.00e-02, fs:0.67114 (r=0.575,p=0.806),  time:35.340, tt:918.832\n",
      "Ep:26, loss:0.00009, loss_test:0.08374, lr:1.00e-02, fs:0.73885 (r=0.667,p=0.829),  time:35.370, tt:954.989\n",
      "Ep:27, loss:0.00009, loss_test:0.09052, lr:1.00e-02, fs:0.64828 (r=0.540,p=0.810),  time:35.370, tt:990.351\n",
      "Ep:28, loss:0.00009, loss_test:0.08081, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:35.398, tt:1026.542\n",
      "Ep:29, loss:0.00008, loss_test:0.08579, lr:1.00e-02, fs:0.68919 (r=0.586,p=0.836),  time:35.470, tt:1064.097\n",
      "Ep:30, loss:0.00008, loss_test:0.08222, lr:1.00e-02, fs:0.65753 (r=0.552,p=0.814),  time:35.506, tt:1100.692\n",
      "Ep:31, loss:0.00007, loss_test:0.08243, lr:1.00e-02, fs:0.68493 (r=0.575,p=0.847),  time:35.558, tt:1137.867\n",
      "Ep:32, loss:0.00006, loss_test:0.08607, lr:1.00e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.549, tt:1173.122\n",
      "Ep:33, loss:0.00006, loss_test:0.08011, lr:1.00e-02, fs:0.74684 (r=0.678,p=0.831),  time:35.573, tt:1209.489\n",
      "Ep:34, loss:0.00006, loss_test:0.08859, lr:1.00e-02, fs:0.64706 (r=0.506,p=0.898),  time:35.563, tt:1244.711\n",
      "Ep:35, loss:0.00005, loss_test:0.08243, lr:1.00e-02, fs:0.73684 (r=0.644,p=0.862),  time:35.561, tt:1280.190\n",
      "Ep:36, loss:0.00005, loss_test:0.08778, lr:9.90e-03, fs:0.63309 (r=0.506,p=0.846),  time:35.603, tt:1317.317\n",
      "Ep:37, loss:0.00004, loss_test:0.08258, lr:9.80e-03, fs:0.64789 (r=0.529,p=0.836),  time:35.574, tt:1351.804\n",
      "Ep:38, loss:0.00004, loss_test:0.09048, lr:9.70e-03, fs:0.64706 (r=0.506,p=0.898),  time:35.535, tt:1385.859\n",
      "Ep:39, loss:0.00004, loss_test:0.08425, lr:9.61e-03, fs:0.62857 (r=0.506,p=0.830),  time:35.517, tt:1420.697\n",
      "Ep:40, loss:0.00003, loss_test:0.09082, lr:9.51e-03, fs:0.65185 (r=0.506,p=0.917),  time:35.529, tt:1456.681\n",
      "Ep:41, loss:0.00003, loss_test:0.08726, lr:9.41e-03, fs:0.63768 (r=0.506,p=0.863),  time:35.511, tt:1491.480\n",
      "Ep:42, loss:0.00003, loss_test:0.08410, lr:9.32e-03, fs:0.63768 (r=0.506,p=0.863),  time:35.517, tt:1527.219\n",
      "Ep:43, loss:0.00003, loss_test:0.08867, lr:9.23e-03, fs:0.64234 (r=0.506,p=0.880),  time:35.485, tt:1561.337\n",
      "Ep:44, loss:0.00002, loss_test:0.08266, lr:9.14e-03, fs:0.63768 (r=0.506,p=0.863),  time:35.469, tt:1596.100\n",
      "Ep:45, loss:0.00002, loss_test:0.08732, lr:9.04e-03, fs:0.65185 (r=0.506,p=0.917),  time:35.478, tt:1631.996\n",
      "Ep:46, loss:0.00002, loss_test:0.08308, lr:8.95e-03, fs:0.64706 (r=0.506,p=0.898),  time:35.510, tt:1668.958\n",
      "Ep:47, loss:0.00002, loss_test:0.08808, lr:8.86e-03, fs:0.66667 (r=0.506,p=0.978),  time:35.522, tt:1705.069\n",
      "Ep:48, loss:0.00002, loss_test:0.08575, lr:8.78e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.563, tt:1742.593\n",
      "Ep:49, loss:0.00002, loss_test:0.08545, lr:8.69e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.611, tt:1780.544\n",
      "Ep:50, loss:0.00002, loss_test:0.08669, lr:8.60e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.645, tt:1817.913\n",
      "Ep:51, loss:0.00002, loss_test:0.08415, lr:8.51e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.650, tt:1853.804\n",
      "Ep:52, loss:0.00002, loss_test:0.09306, lr:8.43e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.697, tt:1891.959\n",
      "Ep:53, loss:0.00001, loss_test:0.08289, lr:8.35e-03, fs:0.65672 (r=0.506,p=0.936),  time:35.730, tt:1929.403\n",
      "Ep:54, loss:0.00001, loss_test:0.08718, lr:8.26e-03, fs:0.66667 (r=0.506,p=0.978),  time:35.728, tt:1965.057\n",
      "Ep:55, loss:0.00001, loss_test:0.08494, lr:8.18e-03, fs:0.65672 (r=0.506,p=0.936),  time:35.754, tt:2002.237\n",
      "Ep:56, loss:0.00001, loss_test:0.08683, lr:8.10e-03, fs:0.65672 (r=0.506,p=0.936),  time:35.768, tt:2038.782\n",
      "Ep:57, loss:0.00001, loss_test:0.08407, lr:8.02e-03, fs:0.65672 (r=0.506,p=0.936),  time:35.733, tt:2072.539\n",
      "Ep:58, loss:0.00001, loss_test:0.08493, lr:7.94e-03, fs:0.66667 (r=0.506,p=0.978),  time:35.714, tt:2107.110\n",
      "Ep:59, loss:0.00001, loss_test:0.08897, lr:7.86e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.684, tt:2141.065\n",
      "Ep:60, loss:0.00001, loss_test:0.08805, lr:7.78e-03, fs:0.66667 (r=0.506,p=0.978),  time:35.653, tt:2174.853\n",
      "Ep:61, loss:0.00001, loss_test:0.08545, lr:7.70e-03, fs:0.65672 (r=0.506,p=0.936),  time:35.674, tt:2211.785\n",
      "Ep:62, loss:0.00001, loss_test:0.08835, lr:7.62e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.703, tt:2249.296\n",
      "Ep:63, loss:0.00001, loss_test:0.08736, lr:7.55e-03, fs:0.66667 (r=0.506,p=0.978),  time:35.704, tt:2285.027\n",
      "Ep:64, loss:0.00001, loss_test:0.08672, lr:7.47e-03, fs:0.65672 (r=0.506,p=0.936),  time:35.698, tt:2320.366\n",
      "Ep:65, loss:0.00001, loss_test:0.08955, lr:7.40e-03, fs:0.66667 (r=0.506,p=0.978),  time:35.689, tt:2355.498\n",
      "Ep:66, loss:0.00001, loss_test:0.08723, lr:7.32e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.713, tt:2392.785\n",
      "Ep:67, loss:0.00001, loss_test:0.08864, lr:7.25e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.758, tt:2431.536\n",
      "Ep:68, loss:0.00001, loss_test:0.08927, lr:7.18e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.741, tt:2466.120\n",
      "Ep:69, loss:0.00001, loss_test:0.08932, lr:7.11e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.727, tt:2500.908\n",
      "Ep:70, loss:0.00001, loss_test:0.08964, lr:7.03e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.713, tt:2535.623\n",
      "Ep:71, loss:0.00001, loss_test:0.08897, lr:6.96e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.686, tt:2569.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.09032, lr:6.89e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.677, tt:2604.455\n",
      "Ep:73, loss:0.00001, loss_test:0.08906, lr:6.83e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.675, tt:2639.919\n",
      "Ep:74, loss:0.00001, loss_test:0.09019, lr:6.76e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.658, tt:2674.374\n",
      "Ep:75, loss:0.00001, loss_test:0.08983, lr:6.69e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.642, tt:2708.798\n",
      "Ep:76, loss:0.00001, loss_test:0.08910, lr:6.62e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.661, tt:2745.913\n",
      "Ep:77, loss:0.00001, loss_test:0.09152, lr:6.56e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.676, tt:2782.742\n",
      "Ep:78, loss:0.00000, loss_test:0.08956, lr:6.49e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.689, tt:2819.469\n",
      "Ep:79, loss:0.00000, loss_test:0.09047, lr:6.43e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.700, tt:2856.004\n",
      "Ep:80, loss:0.00000, loss_test:0.09217, lr:6.36e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.734, tt:2894.432\n",
      "Ep:81, loss:0.00000, loss_test:0.09175, lr:6.30e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.738, tt:2930.496\n",
      "Ep:82, loss:0.00000, loss_test:0.09184, lr:6.24e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.735, tt:2966.035\n",
      "Ep:83, loss:0.00000, loss_test:0.09199, lr:6.17e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.747, tt:3002.743\n",
      "Ep:84, loss:0.00000, loss_test:0.09246, lr:6.11e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.765, tt:3040.041\n",
      "Ep:85, loss:0.00000, loss_test:0.09325, lr:6.05e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.784, tt:3077.429\n",
      "Ep:86, loss:0.00000, loss_test:0.09259, lr:5.99e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.809, tt:3115.359\n",
      "Ep:87, loss:0.00000, loss_test:0.09261, lr:5.93e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.827, tt:3152.742\n",
      "Ep:88, loss:0.00000, loss_test:0.09300, lr:5.87e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.861, tt:3191.609\n",
      "Ep:89, loss:0.00000, loss_test:0.09308, lr:5.81e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.886, tt:3229.713\n",
      "Ep:90, loss:0.00000, loss_test:0.09277, lr:5.75e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.914, tt:3268.155\n",
      "Ep:91, loss:0.00000, loss_test:0.09406, lr:5.70e-03, fs:0.66165 (r=0.506,p=0.957),  time:35.938, tt:3306.296\n",
      "Ep:92, loss:0.00000, loss_test:0.09439, lr:5.64e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.957, tt:3343.990\n",
      "Ep:93, loss:0.00000, loss_test:0.09412, lr:5.58e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.938, tt:3378.161\n",
      "Ep:94, loss:0.00000, loss_test:0.09439, lr:5.53e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.941, tt:3414.381\n",
      "Ep:95, loss:0.00000, loss_test:0.09439, lr:5.47e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.928, tt:3449.089\n",
      "Ep:96, loss:0.00000, loss_test:0.09652, lr:5.42e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.920, tt:3484.284\n",
      "Ep:97, loss:0.00000, loss_test:0.09652, lr:5.36e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.899, tt:3518.098\n",
      "Ep:98, loss:0.00000, loss_test:0.09608, lr:5.31e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.895, tt:3553.610\n",
      "Ep:99, loss:0.00000, loss_test:0.09698, lr:5.26e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.887, tt:3588.676\n",
      "Ep:100, loss:0.00000, loss_test:0.09707, lr:5.20e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.882, tt:3624.055\n",
      "Ep:101, loss:0.00000, loss_test:0.09764, lr:5.15e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.873, tt:3659.052\n",
      "Ep:102, loss:0.00000, loss_test:0.09830, lr:5.10e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.857, tt:3693.278\n",
      "Ep:103, loss:0.00000, loss_test:0.09795, lr:5.05e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.801, tt:3723.257\n",
      "Ep:104, loss:0.00000, loss_test:0.09878, lr:5.00e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.742, tt:3752.857\n",
      "Ep:105, loss:0.00000, loss_test:0.10005, lr:4.95e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.699, tt:3784.142\n",
      "Ep:106, loss:0.00000, loss_test:0.09951, lr:4.90e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.657, tt:3815.290\n",
      "Ep:107, loss:0.00000, loss_test:0.09941, lr:4.85e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.593, tt:3844.042\n",
      "Ep:108, loss:0.00000, loss_test:0.10014, lr:4.80e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.549, tt:3874.871\n",
      "Ep:109, loss:0.00000, loss_test:0.09972, lr:4.75e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.502, tt:3905.183\n",
      "Ep:110, loss:0.00000, loss_test:0.10019, lr:4.71e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.444, tt:3934.327\n",
      "Ep:111, loss:0.00000, loss_test:0.10061, lr:4.66e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.408, tt:3965.691\n",
      "Ep:112, loss:0.00000, loss_test:0.10065, lr:4.61e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.368, tt:3996.562\n",
      "Ep:113, loss:0.00000, loss_test:0.10073, lr:4.57e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.331, tt:4027.678\n",
      "Ep:114, loss:0.00000, loss_test:0.10103, lr:4.52e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.301, tt:4059.586\n",
      "Ep:115, loss:0.00000, loss_test:0.10075, lr:4.48e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.249, tt:4088.877\n",
      "Ep:116, loss:0.00000, loss_test:0.10126, lr:4.43e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.199, tt:4118.238\n",
      "Ep:117, loss:0.00000, loss_test:0.10141, lr:4.39e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.166, tt:4149.528\n",
      "Ep:118, loss:0.00000, loss_test:0.10160, lr:4.34e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.147, tt:4182.479\n",
      "Ep:119, loss:0.00000, loss_test:0.10172, lr:4.30e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.117, tt:4214.026\n",
      "Ep:120, loss:0.00000, loss_test:0.10185, lr:4.26e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.074, tt:4243.956\n",
      "Ep:121, loss:0.00000, loss_test:0.10224, lr:4.21e-03, fs:0.67176 (r=0.506,p=1.000),  time:35.033, tt:4274.025\n",
      "Ep:122, loss:0.00000, loss_test:0.10233, lr:4.17e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.993, tt:4304.187\n",
      "Ep:123, loss:0.00000, loss_test:0.10250, lr:4.13e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.976, tt:4337.074\n",
      "Ep:124, loss:0.00000, loss_test:0.10267, lr:4.09e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.925, tt:4365.605\n",
      "Ep:125, loss:0.00000, loss_test:0.10265, lr:4.05e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.881, tt:4395.063\n",
      "Ep:126, loss:0.00000, loss_test:0.10263, lr:4.01e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.841, tt:4424.755\n",
      "Ep:127, loss:0.00000, loss_test:0.10277, lr:3.97e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.818, tt:4456.650\n",
      "Ep:128, loss:0.00000, loss_test:0.10247, lr:3.93e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.786, tt:4487.378\n",
      "Ep:129, loss:0.00000, loss_test:0.10287, lr:3.89e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.757, tt:4518.385\n",
      "Ep:130, loss:0.00000, loss_test:0.10313, lr:3.85e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.714, tt:4547.521\n",
      "Ep:131, loss:0.00000, loss_test:0.10324, lr:3.81e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.696, tt:4579.911\n",
      "Ep:132, loss:0.00000, loss_test:0.10317, lr:3.77e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.686, tt:4613.175\n",
      "Ep:133, loss:0.00000, loss_test:0.10338, lr:3.73e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.670, tt:4645.768\n",
      "Ep:134, loss:0.00000, loss_test:0.10305, lr:3.70e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.662, tt:4679.330\n",
      "Ep:135, loss:0.00000, loss_test:0.10314, lr:3.66e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.645, tt:4711.669\n",
      "Ep:136, loss:0.00000, loss_test:0.10351, lr:3.62e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.615, tt:4742.189\n",
      "Ep:137, loss:0.00000, loss_test:0.10336, lr:3.59e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.585, tt:4772.744\n",
      "Ep:138, loss:0.00000, loss_test:0.10371, lr:3.55e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.573, tt:4805.708\n",
      "Ep:139, loss:0.00000, loss_test:0.10401, lr:3.52e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.570, tt:4839.839\n",
      "Ep:140, loss:0.00000, loss_test:0.10372, lr:3.48e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.543, tt:4870.535\n",
      "Ep:141, loss:0.00000, loss_test:0.10357, lr:3.45e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.511, tt:4900.595\n",
      "Ep:142, loss:0.00000, loss_test:0.10395, lr:3.41e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.496, tt:4932.897\n",
      "Ep:143, loss:0.00000, loss_test:0.10392, lr:3.38e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.482, tt:4965.410\n",
      "Ep:144, loss:0.00000, loss_test:0.10346, lr:3.34e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.449, tt:4995.163\n",
      "Ep:145, loss:0.00000, loss_test:0.10321, lr:3.31e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.436, tt:5027.655\n",
      "Ep:146, loss:0.00000, loss_test:0.10345, lr:3.28e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.411, tt:5058.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.10373, lr:3.24e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.383, tt:5088.688\n",
      "Ep:148, loss:0.00000, loss_test:0.10344, lr:3.21e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.364, tt:5120.265\n",
      "Ep:149, loss:0.00000, loss_test:0.10345, lr:3.18e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.347, tt:5151.982\n",
      "Ep:150, loss:0.00000, loss_test:0.10403, lr:3.15e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.338, tt:5185.097\n",
      "Ep:151, loss:0.00000, loss_test:0.10428, lr:3.12e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.317, tt:5216.153\n",
      "Ep:152, loss:0.00000, loss_test:0.10383, lr:3.09e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.310, tt:5249.414\n",
      "Ep:153, loss:0.00000, loss_test:0.10390, lr:3.05e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.306, tt:5283.068\n",
      "Ep:154, loss:0.00000, loss_test:0.10431, lr:3.02e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.293, tt:5315.347\n",
      "Ep:155, loss:0.00000, loss_test:0.10431, lr:2.99e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.271, tt:5346.202\n",
      "Ep:156, loss:0.00000, loss_test:0.10380, lr:2.96e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.249, tt:5377.107\n",
      "Ep:157, loss:0.00000, loss_test:0.10356, lr:2.93e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.244, tt:5410.577\n",
      "Ep:158, loss:0.00000, loss_test:0.10394, lr:2.90e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.239, tt:5444.004\n",
      "Ep:159, loss:0.00000, loss_test:0.10437, lr:2.88e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.228, tt:5476.547\n",
      "Ep:160, loss:0.00000, loss_test:0.10420, lr:2.85e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.211, tt:5507.925\n",
      "Ep:161, loss:0.00000, loss_test:0.10375, lr:2.82e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.184, tt:5537.802\n",
      "Ep:162, loss:0.00000, loss_test:0.10379, lr:2.79e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.170, tt:5569.644\n",
      "Ep:163, loss:0.00000, loss_test:0.10406, lr:2.76e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.166, tt:5603.245\n",
      "Ep:164, loss:0.00000, loss_test:0.10386, lr:2.73e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.175, tt:5638.898\n",
      "Ep:165, loss:0.00000, loss_test:0.10376, lr:2.71e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.150, tt:5668.881\n",
      "Ep:166, loss:0.00000, loss_test:0.10406, lr:2.68e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.124, tt:5698.696\n",
      "Ep:167, loss:0.00000, loss_test:0.10392, lr:2.65e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.109, tt:5730.252\n",
      "Ep:168, loss:0.00000, loss_test:0.10373, lr:2.63e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.081, tt:5759.759\n",
      "Ep:169, loss:0.00000, loss_test:0.10388, lr:2.60e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.073, tt:5792.439\n",
      "Ep:170, loss:0.00000, loss_test:0.10419, lr:2.57e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.054, tt:5823.282\n",
      "Ep:171, loss:0.00000, loss_test:0.10393, lr:2.55e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.025, tt:5852.313\n",
      "Ep:172, loss:0.00000, loss_test:0.10349, lr:2.52e-03, fs:0.67176 (r=0.506,p=1.000),  time:34.010, tt:5883.680\n",
      "Ep:173, loss:0.00000, loss_test:0.10355, lr:2.50e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.995, tt:5915.167\n",
      "Ep:174, loss:0.00000, loss_test:0.10406, lr:2.47e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.983, tt:5947.034\n",
      "Ep:175, loss:0.00000, loss_test:0.10414, lr:2.45e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.969, tt:5978.597\n",
      "Ep:176, loss:0.00000, loss_test:0.10374, lr:2.42e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.938, tt:6007.098\n",
      "Ep:177, loss:0.00000, loss_test:0.10346, lr:2.40e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.930, tt:6039.469\n",
      "Ep:178, loss:0.00000, loss_test:0.10375, lr:2.38e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.924, tt:6072.337\n",
      "Ep:179, loss:0.00000, loss_test:0.10400, lr:2.35e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.908, tt:6103.528\n",
      "Ep:180, loss:0.00000, loss_test:0.10377, lr:2.33e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.890, tt:6134.145\n",
      "Ep:181, loss:0.00000, loss_test:0.10346, lr:2.31e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.874, tt:6165.045\n",
      "Ep:182, loss:0.00000, loss_test:0.10345, lr:2.28e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.853, tt:6195.121\n",
      "Ep:183, loss:0.00000, loss_test:0.10377, lr:2.26e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.837, tt:6226.057\n",
      "Ep:184, loss:0.00000, loss_test:0.10355, lr:2.24e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.811, tt:6255.000\n",
      "Ep:185, loss:0.00000, loss_test:0.10342, lr:2.21e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.784, tt:6283.851\n",
      "Ep:186, loss:0.00000, loss_test:0.10368, lr:2.19e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.768, tt:6314.598\n",
      "Ep:187, loss:0.00000, loss_test:0.10372, lr:2.17e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.759, tt:6346.765\n",
      "Ep:188, loss:0.00000, loss_test:0.10374, lr:2.15e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.752, tt:6379.168\n",
      "Ep:189, loss:0.00000, loss_test:0.10367, lr:2.13e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.750, tt:6412.425\n",
      "Ep:190, loss:0.00000, loss_test:0.10384, lr:2.11e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.737, tt:6443.836\n",
      "Ep:191, loss:0.00000, loss_test:0.10388, lr:2.08e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.725, tt:6475.132\n",
      "Ep:192, loss:0.00000, loss_test:0.10358, lr:2.06e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.711, tt:6506.219\n",
      "Ep:193, loss:0.00000, loss_test:0.10350, lr:2.04e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.688, tt:6535.543\n",
      "Ep:194, loss:0.00000, loss_test:0.10363, lr:2.02e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.676, tt:6566.796\n",
      "Ep:195, loss:0.00000, loss_test:0.10374, lr:2.00e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.666, tt:6598.535\n",
      "Ep:196, loss:0.00000, loss_test:0.10380, lr:1.98e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.654, tt:6629.911\n",
      "Ep:197, loss:0.00000, loss_test:0.10366, lr:1.96e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.629, tt:6658.515\n",
      "Ep:198, loss:0.00000, loss_test:0.10331, lr:1.94e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.602, tt:6686.699\n",
      "Ep:199, loss:0.00000, loss_test:0.10350, lr:1.92e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.592, tt:6718.371\n",
      "Ep:200, loss:0.00000, loss_test:0.10384, lr:1.90e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.573, tt:6748.144\n",
      "Ep:201, loss:0.00000, loss_test:0.10385, lr:1.89e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.565, tt:6780.058\n",
      "Ep:202, loss:0.00000, loss_test:0.10352, lr:1.87e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.555, tt:6811.709\n",
      "Ep:203, loss:0.00000, loss_test:0.10340, lr:1.85e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.536, tt:6841.419\n",
      "Ep:204, loss:0.00000, loss_test:0.10347, lr:1.83e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.504, tt:6868.413\n",
      "Ep:205, loss:0.00000, loss_test:0.10352, lr:1.81e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.461, tt:6892.865\n",
      "Ep:206, loss:0.00000, loss_test:0.10353, lr:1.79e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.422, tt:6918.308\n",
      "Ep:207, loss:0.00000, loss_test:0.10348, lr:1.78e-03, fs:0.67176 (r=0.506,p=1.000),  time:33.379, tt:6942.928\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02355, lr:6.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:12.446, tt:12.446\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02377, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:12.300, tt:24.601\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02464, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.288, tt:36.863\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02402, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.234, tt:48.935\n",
      "Ep:4, loss:0.00004, loss_test:0.02289, lr:6.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:12.229, tt:61.144\n",
      "Ep:5, loss:0.00004, loss_test:0.02189, lr:6.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:12.213, tt:73.277\n",
      "Ep:6, loss:0.00004, loss_test:0.02210, lr:6.00e-02, fs:0.63866 (r=0.768,p=0.547),  time:12.222, tt:85.553\n",
      "Ep:7, loss:0.00003, loss_test:0.02336, lr:6.00e-02, fs:0.61468 (r=0.677,p=0.563),  time:12.231, tt:97.851\n",
      "Ep:8, loss:0.00003, loss_test:0.02348, lr:6.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:12.245, tt:110.203\n",
      "Ep:9, loss:0.00003, loss_test:0.02193, lr:6.00e-02, fs:0.61682 (r=0.667,p=0.574),  time:12.239, tt:122.393\n",
      "Ep:10, loss:0.00003, loss_test:0.02056, lr:6.00e-02, fs:0.63677 (r=0.717,p=0.573),  time:12.261, tt:134.867\n",
      "Ep:11, loss:0.00003, loss_test:0.01988, lr:6.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:12.242, tt:146.899\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01951, lr:6.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:12.218, tt:158.839\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01935, lr:6.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:12.193, tt:170.696\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01944, lr:6.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:12.190, tt:182.857\n",
      "Ep:15, loss:0.00003, loss_test:0.01951, lr:6.00e-02, fs:0.64815 (r=0.707,p=0.598),  time:12.207, tt:195.310\n",
      "Ep:16, loss:0.00003, loss_test:0.01918, lr:6.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:12.196, tt:207.338\n",
      "Ep:17, loss:0.00003, loss_test:0.01864, lr:6.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:12.195, tt:219.506\n",
      "Ep:18, loss:0.00003, loss_test:0.01826, lr:6.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:12.210, tt:231.983\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01810, lr:6.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:12.220, tt:244.399\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01813, lr:6.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:12.228, tt:256.788\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01825, lr:6.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:12.243, tt:269.339\n",
      "Ep:22, loss:0.00002, loss_test:0.01826, lr:6.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:12.378, tt:284.683\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01812, lr:6.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:12.387, tt:297.278\n",
      "Ep:24, loss:0.00002, loss_test:0.01804, lr:6.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:12.384, tt:309.600\n",
      "Ep:25, loss:0.00002, loss_test:0.01807, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:12.376, tt:321.771\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01814, lr:6.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:12.355, tt:333.578\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01820, lr:6.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:12.346, tt:345.698\n",
      "Ep:28, loss:0.00002, loss_test:0.01816, lr:6.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:12.336, tt:357.740\n",
      "Ep:29, loss:0.00002, loss_test:0.01809, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:12.329, tt:369.885\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01808, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:12.325, tt:382.060\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01809, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:12.310, tt:393.925\n",
      "Ep:32, loss:0.00002, loss_test:0.01806, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:12.301, tt:405.936\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01805, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:12.284, tt:417.668\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01804, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:12.283, tt:429.914\n",
      "Ep:35, loss:0.00002, loss_test:0.01805, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:12.278, tt:442.017\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01803, lr:6.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:12.281, tt:454.394\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01805, lr:6.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:12.278, tt:466.547\n",
      "Ep:38, loss:0.00002, loss_test:0.01804, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:12.271, tt:478.551\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01794, lr:6.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:12.268, tt:490.711\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01788, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:12.263, tt:502.764\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:12.262, tt:514.998\n",
      "Ep:42, loss:0.00001, loss_test:0.01786, lr:6.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:12.265, tt:527.383\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01787, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:12.261, tt:539.470\n",
      "Ep:44, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:12.260, tt:551.695\n",
      "Ep:45, loss:0.00001, loss_test:0.01790, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:12.263, tt:564.119\n",
      "Ep:46, loss:0.00001, loss_test:0.01783, lr:6.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:12.265, tt:576.446\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01776, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:12.258, tt:588.386\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01779, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:12.255, tt:600.517\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01774, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:12.254, tt:612.697\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01780, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:12.252, tt:624.862\n",
      "Ep:51, loss:0.00001, loss_test:0.01778, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:12.249, tt:636.939\n",
      "Ep:52, loss:0.00001, loss_test:0.01782, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:12.241, tt:648.752\n",
      "Ep:53, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:12.234, tt:660.645\n",
      "Ep:54, loss:0.00001, loss_test:0.01787, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:12.237, tt:673.048\n",
      "Ep:55, loss:0.00001, loss_test:0.01778, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:12.231, tt:684.941\n",
      "Ep:56, loss:0.00001, loss_test:0.01786, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:12.231, tt:697.157\n",
      "Ep:57, loss:0.00001, loss_test:0.01794, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:12.231, tt:709.399\n",
      "Ep:58, loss:0.00001, loss_test:0.01792, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:12.233, tt:721.765\n",
      "Ep:59, loss:0.00001, loss_test:0.01789, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:12.238, tt:734.296\n",
      "Ep:60, loss:0.00001, loss_test:0.01796, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:12.238, tt:746.531\n",
      "Ep:61, loss:0.00001, loss_test:0.01804, lr:5.94e-02, fs:0.80383 (r=0.848,p=0.764),  time:12.242, tt:758.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01798, lr:5.88e-02, fs:0.81731 (r=0.859,p=0.780),  time:12.237, tt:770.919\n",
      "Ep:63, loss:0.00001, loss_test:0.01797, lr:5.82e-02, fs:0.81731 (r=0.859,p=0.780),  time:12.234, tt:782.957\n",
      "Ep:64, loss:0.00001, loss_test:0.01810, lr:5.76e-02, fs:0.80583 (r=0.838,p=0.776),  time:12.232, tt:795.105\n",
      "Ep:65, loss:0.00001, loss_test:0.01817, lr:5.71e-02, fs:0.80392 (r=0.828,p=0.781),  time:12.231, tt:807.269\n",
      "Ep:66, loss:0.00001, loss_test:0.01812, lr:5.65e-02, fs:0.80392 (r=0.828,p=0.781),  time:12.233, tt:819.617\n",
      "Ep:67, loss:0.00001, loss_test:0.01809, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:12.232, tt:831.788\n",
      "Ep:68, loss:0.00001, loss_test:0.01827, lr:5.54e-02, fs:0.79602 (r=0.808,p=0.784),  time:12.226, tt:843.594\n",
      "Ep:69, loss:0.00001, loss_test:0.01822, lr:5.48e-02, fs:0.80198 (r=0.818,p=0.786),  time:12.227, tt:855.892\n",
      "Ep:70, loss:0.00001, loss_test:0.01820, lr:5.43e-02, fs:0.80198 (r=0.818,p=0.786),  time:12.230, tt:868.347\n",
      "Ep:71, loss:0.00001, loss_test:0.01832, lr:5.37e-02, fs:0.79602 (r=0.808,p=0.784),  time:12.235, tt:880.887\n",
      "Ep:72, loss:0.00001, loss_test:0.01833, lr:5.32e-02, fs:0.80000 (r=0.808,p=0.792),  time:12.238, tt:893.340\n",
      "Ep:73, loss:0.00001, loss_test:0.01840, lr:5.27e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.239, tt:905.684\n",
      "Ep:74, loss:0.00001, loss_test:0.01852, lr:5.21e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.241, tt:918.051\n",
      "Ep:75, loss:0.00001, loss_test:0.01846, lr:5.16e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.267, tt:932.277\n",
      "Ep:76, loss:0.00001, loss_test:0.01851, lr:5.11e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.270, tt:944.759\n",
      "Ep:77, loss:0.00001, loss_test:0.01855, lr:5.06e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.272, tt:957.203\n",
      "Ep:78, loss:0.00001, loss_test:0.01868, lr:5.01e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.275, tt:969.736\n",
      "Ep:79, loss:0.00001, loss_test:0.01870, lr:4.96e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.279, tt:982.347\n",
      "Ep:80, loss:0.00001, loss_test:0.01873, lr:4.91e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.283, tt:994.957\n",
      "Ep:81, loss:0.00001, loss_test:0.01875, lr:4.86e-02, fs:0.80402 (r=0.808,p=0.800),  time:12.288, tt:1007.613\n",
      "Ep:82, loss:0.00001, loss_test:0.01890, lr:4.81e-02, fs:0.80808 (r=0.808,p=0.808),  time:12.291, tt:1020.184\n",
      "Ep:83, loss:0.00001, loss_test:0.01895, lr:4.76e-02, fs:0.80808 (r=0.808,p=0.808),  time:12.295, tt:1032.771\n",
      "Ep:84, loss:0.00001, loss_test:0.01896, lr:4.71e-02, fs:0.80203 (r=0.798,p=0.806),  time:12.296, tt:1045.179\n",
      "Ep:85, loss:0.00001, loss_test:0.01904, lr:4.67e-02, fs:0.80203 (r=0.798,p=0.806),  time:12.299, tt:1057.676\n",
      "Ep:86, loss:0.00001, loss_test:0.01904, lr:4.62e-02, fs:0.80203 (r=0.798,p=0.806),  time:12.302, tt:1070.280\n",
      "Ep:87, loss:0.00001, loss_test:0.01912, lr:4.57e-02, fs:0.80203 (r=0.798,p=0.806),  time:12.303, tt:1082.666\n",
      "Ep:88, loss:0.00001, loss_test:0.01924, lr:4.53e-02, fs:0.80203 (r=0.798,p=0.806),  time:12.302, tt:1094.852\n",
      "Ep:89, loss:0.00001, loss_test:0.01931, lr:4.48e-02, fs:0.80612 (r=0.798,p=0.814),  time:12.303, tt:1107.238\n",
      "Ep:90, loss:0.00001, loss_test:0.01937, lr:4.44e-02, fs:0.81026 (r=0.798,p=0.823),  time:12.304, tt:1119.650\n",
      "Ep:91, loss:0.00001, loss_test:0.01932, lr:4.39e-02, fs:0.81026 (r=0.798,p=0.823),  time:12.306, tt:1132.128\n",
      "Ep:92, loss:0.00001, loss_test:0.01946, lr:4.35e-02, fs:0.81443 (r=0.798,p=0.832),  time:12.308, tt:1144.671\n",
      "Ep:93, loss:0.00001, loss_test:0.01948, lr:4.31e-02, fs:0.81026 (r=0.798,p=0.823),  time:12.311, tt:1157.204\n",
      "Ep:94, loss:0.00001, loss_test:0.01956, lr:4.26e-02, fs:0.81443 (r=0.798,p=0.832),  time:12.314, tt:1169.846\n",
      "Ep:95, loss:0.00001, loss_test:0.01959, lr:4.22e-02, fs:0.81443 (r=0.798,p=0.832),  time:12.313, tt:1182.032\n",
      "Ep:96, loss:0.00001, loss_test:0.01967, lr:4.18e-02, fs:0.81443 (r=0.798,p=0.832),  time:12.313, tt:1194.330\n",
      "Ep:97, loss:0.00001, loss_test:0.01966, lr:4.14e-02, fs:0.81443 (r=0.798,p=0.832),  time:12.313, tt:1206.677\n",
      "Ep:98, loss:0.00001, loss_test:0.01975, lr:4.10e-02, fs:0.81865 (r=0.798,p=0.840),  time:12.311, tt:1218.762\n",
      "Ep:99, loss:0.00001, loss_test:0.01988, lr:4.05e-02, fs:0.81865 (r=0.798,p=0.840),  time:12.307, tt:1230.662\n",
      "Ep:100, loss:0.00001, loss_test:0.01991, lr:4.01e-02, fs:0.81865 (r=0.798,p=0.840),  time:12.307, tt:1243.000\n",
      "Ep:101, loss:0.00001, loss_test:0.01994, lr:3.97e-02, fs:0.81865 (r=0.798,p=0.840),  time:12.307, tt:1255.285\n",
      "Ep:102, loss:0.00001, loss_test:0.02004, lr:3.93e-02, fs:0.81865 (r=0.798,p=0.840),  time:12.307, tt:1267.655\n",
      "Ep:103, loss:0.00001, loss_test:0.02004, lr:3.89e-02, fs:0.81865 (r=0.798,p=0.840),  time:12.307, tt:1279.903\n",
      "Ep:104, loss:0.00001, loss_test:0.02012, lr:3.86e-02, fs:0.81675 (r=0.788,p=0.848),  time:12.306, tt:1292.085\n",
      "Ep:105, loss:0.00001, loss_test:0.02015, lr:3.82e-02, fs:0.82105 (r=0.788,p=0.857),  time:12.308, tt:1304.652\n",
      "Ep:106, loss:0.00001, loss_test:0.02025, lr:3.78e-02, fs:0.82105 (r=0.788,p=0.857),  time:12.306, tt:1316.781\n",
      "Ep:107, loss:0.00001, loss_test:0.02026, lr:3.74e-02, fs:0.82105 (r=0.788,p=0.857),  time:12.306, tt:1329.032\n",
      "Ep:108, loss:0.00001, loss_test:0.02035, lr:3.70e-02, fs:0.82105 (r=0.788,p=0.857),  time:12.305, tt:1341.260\n",
      "Ep:109, loss:0.00001, loss_test:0.02039, lr:3.67e-02, fs:0.82105 (r=0.788,p=0.857),  time:12.303, tt:1353.377\n",
      "Ep:110, loss:0.00001, loss_test:0.02042, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.305, tt:1365.803\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.02047, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.305, tt:1378.116\n",
      "Ep:112, loss:0.00001, loss_test:0.02050, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.304, tt:1390.356\n",
      "Ep:113, loss:0.00001, loss_test:0.02055, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.304, tt:1402.685\n",
      "Ep:114, loss:0.00001, loss_test:0.02060, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.303, tt:1414.794\n",
      "Ep:115, loss:0.00001, loss_test:0.02070, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.300, tt:1426.766\n",
      "Ep:116, loss:0.00001, loss_test:0.02073, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.299, tt:1438.991\n",
      "Ep:117, loss:0.00001, loss_test:0.02081, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.299, tt:1451.333\n",
      "Ep:118, loss:0.00001, loss_test:0.02090, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.298, tt:1463.517\n",
      "Ep:119, loss:0.00001, loss_test:0.02102, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.296, tt:1475.544\n",
      "Ep:120, loss:0.00001, loss_test:0.02097, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.296, tt:1487.851\n",
      "Ep:121, loss:0.00000, loss_test:0.02109, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.294, tt:1499.809\n",
      "Ep:122, loss:0.00000, loss_test:0.02114, lr:3.59e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.292, tt:1511.924\n",
      "Ep:123, loss:0.00000, loss_test:0.02112, lr:3.56e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.292, tt:1524.260\n",
      "Ep:124, loss:0.00000, loss_test:0.02118, lr:3.52e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.292, tt:1536.460\n",
      "Ep:125, loss:0.00000, loss_test:0.02125, lr:3.49e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.290, tt:1548.551\n",
      "Ep:126, loss:0.00000, loss_test:0.02131, lr:3.45e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.297, tt:1561.749\n",
      "Ep:127, loss:0.00000, loss_test:0.02136, lr:3.42e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.298, tt:1574.118\n",
      "Ep:128, loss:0.00000, loss_test:0.02144, lr:3.38e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.298, tt:1586.402\n",
      "Ep:129, loss:0.00000, loss_test:0.02149, lr:3.35e-02, fs:0.82540 (r=0.788,p=0.867),  time:12.298, tt:1598.775\n",
      "Ep:130, loss:0.00000, loss_test:0.02157, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.298, tt:1611.074\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00000, loss_test:0.02161, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.298, tt:1623.305\n",
      "Ep:132, loss:0.00000, loss_test:0.02156, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.297, tt:1635.439\n",
      "Ep:133, loss:0.00000, loss_test:0.02167, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.295, tt:1647.507\n",
      "Ep:134, loss:0.00000, loss_test:0.02179, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.294, tt:1659.713\n",
      "Ep:135, loss:0.00000, loss_test:0.02188, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.292, tt:1671.748\n",
      "Ep:136, loss:0.00000, loss_test:0.02190, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.290, tt:1683.723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02194, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.288, tt:1695.698\n",
      "Ep:138, loss:0.00000, loss_test:0.02203, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.286, tt:1707.798\n",
      "Ep:139, loss:0.00000, loss_test:0.02208, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.285, tt:1719.850\n",
      "Ep:140, loss:0.00000, loss_test:0.02209, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.284, tt:1732.092\n",
      "Ep:141, loss:0.00000, loss_test:0.02215, lr:3.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.284, tt:1744.271\n",
      "Ep:142, loss:0.00000, loss_test:0.02222, lr:3.28e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.283, tt:1756.511\n",
      "Ep:143, loss:0.00000, loss_test:0.02224, lr:3.25e-02, fs:0.82979 (r=0.788,p=0.876),  time:12.282, tt:1768.667\n",
      "Ep:144, loss:0.00000, loss_test:0.02227, lr:3.22e-02, fs:0.82353 (r=0.778,p=0.875),  time:12.283, tt:1781.081\n",
      "Ep:145, loss:0.00000, loss_test:0.02238, lr:3.19e-02, fs:0.82353 (r=0.778,p=0.875),  time:12.282, tt:1793.183\n",
      "Ep:146, loss:0.00000, loss_test:0.02240, lr:3.15e-02, fs:0.81081 (r=0.758,p=0.872),  time:12.282, tt:1805.461\n",
      "Ep:147, loss:0.00000, loss_test:0.02244, lr:3.12e-02, fs:0.81720 (r=0.768,p=0.874),  time:12.280, tt:1817.509\n",
      "Ep:148, loss:0.00000, loss_test:0.02253, lr:3.09e-02, fs:0.81081 (r=0.758,p=0.872),  time:12.281, tt:1829.815\n",
      "Ep:149, loss:0.00000, loss_test:0.02254, lr:3.06e-02, fs:0.81081 (r=0.758,p=0.872),  time:12.280, tt:1841.953\n",
      "Ep:150, loss:0.00000, loss_test:0.02263, lr:3.03e-02, fs:0.81720 (r=0.768,p=0.874),  time:12.280, tt:1854.281\n",
      "Ep:151, loss:0.00000, loss_test:0.02260, lr:3.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:12.279, tt:1866.381\n",
      "Ep:152, loss:0.00000, loss_test:0.02266, lr:2.97e-02, fs:0.81081 (r=0.758,p=0.872),  time:12.279, tt:1878.743\n",
      "Ep:153, loss:0.00000, loss_test:0.02275, lr:2.94e-02, fs:0.80435 (r=0.747,p=0.871),  time:12.280, tt:1891.150\n",
      "Ep:154, loss:0.00000, loss_test:0.02278, lr:2.91e-02, fs:0.80435 (r=0.747,p=0.871),  time:12.281, tt:1903.536\n",
      "Ep:155, loss:0.00000, loss_test:0.02283, lr:2.88e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.281, tt:1915.870\n",
      "Ep:156, loss:0.00000, loss_test:0.02293, lr:2.85e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.282, tt:1928.350\n",
      "Ep:157, loss:0.00000, loss_test:0.02293, lr:2.82e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.281, tt:1940.420\n",
      "Ep:158, loss:0.00000, loss_test:0.02294, lr:2.80e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.281, tt:1952.615\n",
      "Ep:159, loss:0.00000, loss_test:0.02303, lr:2.77e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.281, tt:1964.919\n",
      "Ep:160, loss:0.00000, loss_test:0.02302, lr:2.74e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.281, tt:1977.208\n",
      "Ep:161, loss:0.00000, loss_test:0.02306, lr:2.71e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.282, tt:1989.654\n",
      "Ep:162, loss:0.00000, loss_test:0.02313, lr:2.69e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.282, tt:2001.920\n",
      "Ep:163, loss:0.00000, loss_test:0.02315, lr:2.66e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.282, tt:2014.171\n",
      "Ep:164, loss:0.00000, loss_test:0.02325, lr:2.63e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.283, tt:2026.639\n",
      "Ep:165, loss:0.00000, loss_test:0.02328, lr:2.61e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.283, tt:2038.927\n",
      "Ep:166, loss:0.00000, loss_test:0.02325, lr:2.58e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.284, tt:2051.494\n",
      "Ep:167, loss:0.00000, loss_test:0.02332, lr:2.55e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.285, tt:2063.854\n",
      "Ep:168, loss:0.00000, loss_test:0.02337, lr:2.53e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.285, tt:2076.239\n",
      "Ep:169, loss:0.00000, loss_test:0.02345, lr:2.50e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.284, tt:2088.351\n",
      "Ep:170, loss:0.00000, loss_test:0.02346, lr:2.48e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.284, tt:2100.573\n",
      "Ep:171, loss:0.00000, loss_test:0.02351, lr:2.45e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.284, tt:2112.825\n",
      "Ep:172, loss:0.00000, loss_test:0.02355, lr:2.43e-02, fs:0.79781 (r=0.737,p=0.869),  time:12.283, tt:2124.981\n",
      "Ep:173, loss:0.00000, loss_test:0.02358, lr:2.40e-02, fs:0.79121 (r=0.727,p=0.867),  time:12.283, tt:2137.297\n",
      "Ep:174, loss:0.00000, loss_test:0.02364, lr:2.38e-02, fs:0.78453 (r=0.717,p=0.866),  time:12.286, tt:2149.980\n",
      "Ep:175, loss:0.00000, loss_test:0.02365, lr:2.36e-02, fs:0.78453 (r=0.717,p=0.866),  time:12.285, tt:2162.245\n",
      "Ep:176, loss:0.00000, loss_test:0.02365, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:12.284, tt:2174.317\n",
      "Ep:177, loss:0.00000, loss_test:0.02375, lr:2.31e-02, fs:0.78453 (r=0.717,p=0.866),  time:12.283, tt:2186.376\n",
      "Ep:178, loss:0.00000, loss_test:0.02379, lr:2.29e-02, fs:0.78453 (r=0.717,p=0.866),  time:12.285, tt:2198.975\n",
      "Ep:179, loss:0.00000, loss_test:0.02380, lr:2.26e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.286, tt:2211.469\n",
      "Ep:180, loss:0.00000, loss_test:0.02383, lr:2.24e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.288, tt:2224.052\n",
      "Ep:181, loss:0.00000, loss_test:0.02389, lr:2.22e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.289, tt:2236.682\n",
      "Ep:182, loss:0.00000, loss_test:0.02391, lr:2.20e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.291, tt:2249.309\n",
      "Ep:183, loss:0.00000, loss_test:0.02393, lr:2.17e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.293, tt:2261.889\n",
      "Ep:184, loss:0.00000, loss_test:0.02397, lr:2.15e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.294, tt:2274.351\n",
      "Ep:185, loss:0.00000, loss_test:0.02400, lr:2.13e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.301, tt:2287.921\n",
      "Ep:186, loss:0.00000, loss_test:0.02406, lr:2.11e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.302, tt:2300.436\n",
      "Ep:187, loss:0.00000, loss_test:0.02411, lr:2.09e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.303, tt:2312.986\n",
      "Ep:188, loss:0.00000, loss_test:0.02412, lr:2.07e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.305, tt:2325.584\n",
      "Ep:189, loss:0.00000, loss_test:0.02416, lr:2.05e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.306, tt:2338.182\n",
      "Ep:190, loss:0.00000, loss_test:0.02418, lr:2.03e-02, fs:0.78889 (r=0.717,p=0.877),  time:12.307, tt:2350.726\n",
      "Ep:191, loss:0.00000, loss_test:0.02418, lr:2.01e-02, fs:0.78212 (r=0.707,p=0.875),  time:12.299, tt:2361.312\n",
      "Ep:192, loss:0.00000, loss_test:0.02424, lr:1.99e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.293, tt:2372.481\n",
      "Ep:193, loss:0.00000, loss_test:0.02430, lr:1.97e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.284, tt:2383.064\n",
      "Ep:194, loss:0.00000, loss_test:0.02432, lr:1.95e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.275, tt:2393.611\n",
      "Ep:195, loss:0.00000, loss_test:0.02435, lr:1.93e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.267, tt:2404.256\n",
      "Ep:196, loss:0.00000, loss_test:0.02435, lr:1.91e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.261, tt:2415.373\n",
      "Ep:197, loss:0.00000, loss_test:0.02439, lr:1.89e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.260, tt:2427.508\n",
      "Ep:198, loss:0.00000, loss_test:0.02444, lr:1.87e-02, fs:0.77966 (r=0.697,p=0.885),  time:12.303, tt:2448.297\n",
      "Ep:199, loss:0.00000, loss_test:0.02443, lr:1.85e-02, fs:0.78652 (r=0.707,p=0.886),  time:12.424, tt:2484.887\n",
      "Ep:200, loss:0.00000, loss_test:0.02447, lr:1.83e-02, fs:0.77966 (r=0.697,p=0.885),  time:12.534, tt:2519.410\n",
      "Ep:201, loss:0.00000, loss_test:0.02452, lr:1.81e-02, fs:0.77966 (r=0.697,p=0.885),  time:12.650, tt:2555.224\n",
      "Ep:202, loss:0.00000, loss_test:0.02454, lr:1.80e-02, fs:0.77966 (r=0.697,p=0.885),  time:12.792, tt:2596.839\n",
      "Ep:203, loss:0.00000, loss_test:0.02456, lr:1.78e-02, fs:0.77966 (r=0.697,p=0.885),  time:12.928, tt:2637.311\n",
      "Ep:204, loss:0.00000, loss_test:0.02458, lr:1.76e-02, fs:0.77966 (r=0.697,p=0.885),  time:13.061, tt:2677.413\n",
      "Ep:205, loss:0.00000, loss_test:0.02463, lr:1.74e-02, fs:0.77966 (r=0.697,p=0.885),  time:13.212, tt:2721.596\n",
      "Ep:206, loss:0.00000, loss_test:0.02465, lr:1.73e-02, fs:0.77966 (r=0.697,p=0.885),  time:13.345, tt:2762.368\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.04795, lr:1.00e-02, fs:0.52761 (r=0.434,p=0.672),  time:28.367, tt:28.367\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.03254, lr:1.00e-02, fs:0.59908 (r=0.657,p=0.551),  time:31.267, tt:62.534\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02643, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:32.751, tt:98.254\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02467, lr:1.00e-02, fs:0.63118 (r=0.838,p=0.506),  time:33.722, tt:134.886\n",
      "Ep:4, loss:0.00004, loss_test:0.02439, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:34.081, tt:170.407\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02449, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:34.407, tt:206.444\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02453, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:34.526, tt:241.682\n",
      "Ep:7, loss:0.00004, loss_test:0.02437, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:34.468, tt:275.744\n",
      "Ep:8, loss:0.00004, loss_test:0.02406, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:34.672, tt:312.049\n",
      "Ep:9, loss:0.00004, loss_test:0.02367, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:34.796, tt:347.957\n",
      "Ep:10, loss:0.00004, loss_test:0.02327, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:34.874, tt:383.616\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02292, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:35.037, tt:420.442\n",
      "Ep:12, loss:0.00004, loss_test:0.02267, lr:1.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:35.118, tt:456.530\n",
      "Ep:13, loss:0.00004, loss_test:0.02252, lr:1.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:35.200, tt:492.805\n",
      "Ep:14, loss:0.00004, loss_test:0.02244, lr:1.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:35.253, tt:528.796\n",
      "Ep:15, loss:0.00004, loss_test:0.02245, lr:1.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:35.212, tt:563.396\n",
      "Ep:16, loss:0.00004, loss_test:0.02252, lr:1.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:35.206, tt:598.495\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02261, lr:1.00e-02, fs:0.64135 (r=0.768,p=0.551),  time:35.240, tt:634.321\n",
      "Ep:18, loss:0.00004, loss_test:0.02266, lr:1.00e-02, fs:0.62979 (r=0.747,p=0.544),  time:35.375, tt:672.116\n",
      "Ep:19, loss:0.00003, loss_test:0.02266, lr:1.00e-02, fs:0.62281 (r=0.717,p=0.550),  time:35.411, tt:708.212\n",
      "Ep:20, loss:0.00003, loss_test:0.02257, lr:1.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:35.400, tt:743.400\n",
      "Ep:21, loss:0.00003, loss_test:0.02243, lr:1.00e-02, fs:0.62832 (r=0.717,p=0.559),  time:35.505, tt:781.107\n",
      "Ep:22, loss:0.00003, loss_test:0.02222, lr:1.00e-02, fs:0.62832 (r=0.717,p=0.559),  time:35.436, tt:815.018\n",
      "Ep:23, loss:0.00003, loss_test:0.02199, lr:1.00e-02, fs:0.64035 (r=0.737,p=0.566),  time:35.351, tt:848.431\n",
      "Ep:24, loss:0.00003, loss_test:0.02176, lr:1.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:35.366, tt:884.158\n",
      "Ep:25, loss:0.00003, loss_test:0.02156, lr:1.00e-02, fs:0.63793 (r=0.747,p=0.556),  time:35.325, tt:918.439\n",
      "Ep:26, loss:0.00003, loss_test:0.02139, lr:1.00e-02, fs:0.63519 (r=0.747,p=0.552),  time:35.328, tt:953.860\n",
      "Ep:27, loss:0.00003, loss_test:0.02127, lr:1.00e-02, fs:0.63793 (r=0.747,p=0.556),  time:35.361, tt:990.096\n",
      "Ep:28, loss:0.00003, loss_test:0.02115, lr:9.90e-03, fs:0.64348 (r=0.747,p=0.565),  time:35.420, tt:1027.172\n",
      "Ep:29, loss:0.00003, loss_test:0.02106, lr:9.80e-03, fs:0.63478 (r=0.737,p=0.557),  time:35.454, tt:1063.619\n",
      "Ep:30, loss:0.00003, loss_test:0.02098, lr:9.70e-03, fs:0.63478 (r=0.737,p=0.557),  time:35.419, tt:1097.982\n",
      "Ep:31, loss:0.00003, loss_test:0.02090, lr:9.61e-03, fs:0.63478 (r=0.737,p=0.557),  time:35.455, tt:1134.574\n",
      "Ep:32, loss:0.00003, loss_test:0.02084, lr:9.51e-03, fs:0.63478 (r=0.737,p=0.557),  time:35.505, tt:1171.670\n",
      "Ep:33, loss:0.00003, loss_test:0.02079, lr:9.41e-03, fs:0.64035 (r=0.737,p=0.566),  time:35.500, tt:1206.997\n",
      "Ep:34, loss:0.00003, loss_test:0.02073, lr:9.32e-03, fs:0.64317 (r=0.737,p=0.570),  time:35.522, tt:1243.259\n",
      "Ep:35, loss:0.00003, loss_test:0.02067, lr:9.23e-03, fs:0.64317 (r=0.737,p=0.570),  time:35.487, tt:1277.538\n",
      "Ep:36, loss:0.00003, loss_test:0.02061, lr:9.14e-03, fs:0.64317 (r=0.737,p=0.570),  time:35.479, tt:1312.709\n",
      "Ep:37, loss:0.00003, loss_test:0.02055, lr:9.04e-03, fs:0.64317 (r=0.737,p=0.570),  time:35.452, tt:1347.172\n",
      "Ep:38, loss:0.00003, loss_test:0.02047, lr:8.95e-03, fs:0.64317 (r=0.737,p=0.570),  time:35.443, tt:1382.287\n",
      "Ep:39, loss:0.00003, loss_test:0.02040, lr:8.86e-03, fs:0.64317 (r=0.737,p=0.570),  time:35.497, tt:1419.886\n",
      "Ep:40, loss:0.00003, loss_test:0.02033, lr:8.78e-03, fs:0.64602 (r=0.737,p=0.575),  time:35.528, tt:1456.628\n",
      "Ep:41, loss:0.00003, loss_test:0.02027, lr:8.69e-03, fs:0.64286 (r=0.727,p=0.576),  time:35.489, tt:1490.525\n",
      "Ep:42, loss:0.00003, loss_test:0.02020, lr:8.60e-03, fs:0.64574 (r=0.727,p=0.581),  time:35.477, tt:1525.497\n",
      "Ep:43, loss:0.00003, loss_test:0.02014, lr:8.51e-03, fs:0.63964 (r=0.717,p=0.577),  time:35.464, tt:1560.424\n",
      "Ep:44, loss:0.00003, loss_test:0.02009, lr:8.43e-03, fs:0.63964 (r=0.717,p=0.577),  time:35.475, tt:1596.388\n",
      "Ep:45, loss:0.00003, loss_test:0.02003, lr:8.35e-03, fs:0.63964 (r=0.717,p=0.577),  time:35.442, tt:1630.337\n",
      "Ep:46, loss:0.00003, loss_test:0.01998, lr:8.26e-03, fs:0.63063 (r=0.707,p=0.569),  time:35.425, tt:1664.988\n",
      "Ep:47, loss:0.00003, loss_test:0.01993, lr:8.18e-03, fs:0.63063 (r=0.707,p=0.569),  time:35.488, tt:1703.404\n",
      "Ep:48, loss:0.00003, loss_test:0.01989, lr:8.10e-03, fs:0.63063 (r=0.707,p=0.569),  time:35.498, tt:1739.397\n",
      "Ep:49, loss:0.00003, loss_test:0.01986, lr:8.02e-03, fs:0.62443 (r=0.697,p=0.566),  time:35.497, tt:1774.868\n",
      "Ep:50, loss:0.00003, loss_test:0.01982, lr:7.94e-03, fs:0.62100 (r=0.687,p=0.567),  time:35.468, tt:1808.883\n",
      "Ep:51, loss:0.00003, loss_test:0.01979, lr:7.86e-03, fs:0.63063 (r=0.707,p=0.569),  time:35.438, tt:1842.768\n",
      "Ep:52, loss:0.00003, loss_test:0.01975, lr:7.78e-03, fs:0.63677 (r=0.717,p=0.573),  time:35.416, tt:1877.028\n",
      "Ep:53, loss:0.00003, loss_test:0.01971, lr:7.70e-03, fs:0.63677 (r=0.717,p=0.573),  time:35.398, tt:1911.496\n",
      "Ep:54, loss:0.00003, loss_test:0.01968, lr:7.62e-03, fs:0.63677 (r=0.717,p=0.573),  time:35.350, tt:1944.243\n",
      "Ep:55, loss:0.00003, loss_test:0.01964, lr:7.55e-03, fs:0.64286 (r=0.727,p=0.576),  time:35.335, tt:1978.779\n",
      "Ep:56, loss:0.00003, loss_test:0.01960, lr:7.47e-03, fs:0.64286 (r=0.727,p=0.576),  time:35.289, tt:2011.501\n",
      "Ep:57, loss:0.00003, loss_test:0.01956, lr:7.40e-03, fs:0.64286 (r=0.727,p=0.576),  time:35.298, tt:2047.293\n",
      "Ep:58, loss:0.00003, loss_test:0.01953, lr:7.32e-03, fs:0.64286 (r=0.727,p=0.576),  time:35.295, tt:2082.383\n",
      "Ep:59, loss:0.00003, loss_test:0.01949, lr:7.25e-03, fs:0.65487 (r=0.747,p=0.583),  time:35.282, tt:2116.890\n",
      "Ep:60, loss:0.00003, loss_test:0.01946, lr:7.18e-03, fs:0.65487 (r=0.747,p=0.583),  time:35.273, tt:2151.669\n",
      "Ep:61, loss:0.00003, loss_test:0.01943, lr:7.11e-03, fs:0.65487 (r=0.747,p=0.583),  time:35.284, tt:2187.632\n",
      "Ep:62, loss:0.00003, loss_test:0.01940, lr:7.03e-03, fs:0.65487 (r=0.747,p=0.583),  time:35.258, tt:2221.260\n",
      "Ep:63, loss:0.00003, loss_test:0.01937, lr:6.96e-03, fs:0.65487 (r=0.747,p=0.583),  time:35.256, tt:2256.387\n",
      "Ep:64, loss:0.00003, loss_test:0.01934, lr:6.89e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.256, tt:2291.634\n",
      "Ep:65, loss:0.00003, loss_test:0.01931, lr:6.83e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.240, tt:2325.857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.01928, lr:6.76e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.225, tt:2360.047\n",
      "Ep:67, loss:0.00002, loss_test:0.01925, lr:6.69e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.230, tt:2395.627\n",
      "Ep:68, loss:0.00002, loss_test:0.01922, lr:6.62e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.230, tt:2430.896\n",
      "Ep:69, loss:0.00002, loss_test:0.01920, lr:6.56e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.213, tt:2464.944\n",
      "Ep:70, loss:0.00002, loss_test:0.01917, lr:6.49e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.217, tt:2500.428\n",
      "Ep:71, loss:0.00002, loss_test:0.01914, lr:6.43e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.232, tt:2536.705\n",
      "Ep:72, loss:0.00002, loss_test:0.01911, lr:6.36e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.211, tt:2570.383\n",
      "Ep:73, loss:0.00002, loss_test:0.01908, lr:6.30e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.229, tt:2606.960\n",
      "Ep:74, loss:0.00002, loss_test:0.01905, lr:6.24e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.217, tt:2641.308\n",
      "Ep:75, loss:0.00002, loss_test:0.01902, lr:6.17e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.220, tt:2676.707\n",
      "Ep:76, loss:0.00002, loss_test:0.01900, lr:6.11e-03, fs:0.65778 (r=0.747,p=0.587),  time:35.207, tt:2710.922\n",
      "Ep:77, loss:0.00002, loss_test:0.01898, lr:6.05e-03, fs:0.65179 (r=0.737,p=0.584),  time:35.217, tt:2746.958\n",
      "Ep:78, loss:0.00002, loss_test:0.01895, lr:5.99e-03, fs:0.65179 (r=0.737,p=0.584),  time:35.222, tt:2782.574\n",
      "Ep:79, loss:0.00002, loss_test:0.01893, lr:5.93e-03, fs:0.65471 (r=0.737,p=0.589),  time:35.238, tt:2819.037\n",
      "Ep:80, loss:0.00002, loss_test:0.01890, lr:5.87e-03, fs:0.65471 (r=0.737,p=0.589),  time:35.242, tt:2854.589\n",
      "Ep:81, loss:0.00002, loss_test:0.01888, lr:5.81e-03, fs:0.65471 (r=0.737,p=0.589),  time:35.255, tt:2890.920\n",
      "Ep:82, loss:0.00002, loss_test:0.01886, lr:5.75e-03, fs:0.65471 (r=0.737,p=0.589),  time:35.272, tt:2927.612\n",
      "Ep:83, loss:0.00002, loss_test:0.01884, lr:5.70e-03, fs:0.66071 (r=0.747,p=0.592),  time:35.278, tt:2963.356\n",
      "Ep:84, loss:0.00002, loss_test:0.01882, lr:5.64e-03, fs:0.66071 (r=0.747,p=0.592),  time:35.289, tt:2999.603\n",
      "Ep:85, loss:0.00002, loss_test:0.01880, lr:5.58e-03, fs:0.66368 (r=0.747,p=0.597),  time:35.292, tt:3035.141\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01877, lr:5.58e-03, fs:0.66368 (r=0.747,p=0.597),  time:35.312, tt:3072.127\n",
      "Ep:87, loss:0.00002, loss_test:0.01875, lr:5.58e-03, fs:0.66964 (r=0.758,p=0.600),  time:35.323, tt:3108.442\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.01873, lr:5.58e-03, fs:0.66964 (r=0.758,p=0.600),  time:35.333, tt:3144.646\n",
      "Ep:89, loss:0.00002, loss_test:0.01871, lr:5.58e-03, fs:0.67556 (r=0.768,p=0.603),  time:35.338, tt:3180.389\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.01869, lr:5.58e-03, fs:0.68142 (r=0.778,p=0.606),  time:35.337, tt:3215.638\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.01867, lr:5.58e-03, fs:0.68722 (r=0.788,p=0.609),  time:35.336, tt:3250.898\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.01865, lr:5.58e-03, fs:0.69298 (r=0.798,p=0.612),  time:35.333, tt:3285.990\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.01863, lr:5.58e-03, fs:0.69298 (r=0.798,p=0.612),  time:35.342, tt:3322.120\n",
      "Ep:94, loss:0.00002, loss_test:0.01861, lr:5.58e-03, fs:0.69298 (r=0.798,p=0.612),  time:35.341, tt:3357.363\n",
      "Ep:95, loss:0.00002, loss_test:0.01859, lr:5.58e-03, fs:0.68722 (r=0.788,p=0.609),  time:35.345, tt:3393.138\n",
      "Ep:96, loss:0.00002, loss_test:0.01857, lr:5.58e-03, fs:0.68722 (r=0.788,p=0.609),  time:35.355, tt:3429.438\n",
      "Ep:97, loss:0.00002, loss_test:0.01855, lr:5.58e-03, fs:0.68722 (r=0.788,p=0.609),  time:35.360, tt:3465.301\n",
      "Ep:98, loss:0.00002, loss_test:0.01853, lr:5.58e-03, fs:0.69027 (r=0.788,p=0.614),  time:35.375, tt:3502.128\n",
      "Ep:99, loss:0.00002, loss_test:0.01851, lr:5.58e-03, fs:0.69333 (r=0.788,p=0.619),  time:35.399, tt:3539.851\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.01849, lr:5.58e-03, fs:0.69333 (r=0.788,p=0.619),  time:35.404, tt:3575.793\n",
      "Ep:101, loss:0.00002, loss_test:0.01847, lr:5.58e-03, fs:0.69912 (r=0.798,p=0.622),  time:35.404, tt:3611.220\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00002, loss_test:0.01845, lr:5.58e-03, fs:0.70485 (r=0.808,p=0.625),  time:35.389, tt:3645.066\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00002, loss_test:0.01843, lr:5.58e-03, fs:0.70485 (r=0.808,p=0.625),  time:35.390, tt:3680.525\n",
      "Ep:104, loss:0.00002, loss_test:0.01841, lr:5.58e-03, fs:0.70485 (r=0.808,p=0.625),  time:35.404, tt:3717.468\n",
      "Ep:105, loss:0.00002, loss_test:0.01840, lr:5.58e-03, fs:0.70485 (r=0.808,p=0.625),  time:35.394, tt:3751.762\n",
      "Ep:106, loss:0.00002, loss_test:0.01838, lr:5.58e-03, fs:0.70485 (r=0.808,p=0.625),  time:35.399, tt:3787.660\n",
      "Ep:107, loss:0.00002, loss_test:0.01836, lr:5.58e-03, fs:0.71053 (r=0.818,p=0.628),  time:35.409, tt:3824.151\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00002, loss_test:0.01834, lr:5.58e-03, fs:0.71053 (r=0.818,p=0.628),  time:35.386, tt:3857.055\n",
      "Ep:109, loss:0.00002, loss_test:0.01832, lr:5.58e-03, fs:0.71053 (r=0.818,p=0.628),  time:35.378, tt:3891.529\n",
      "Ep:110, loss:0.00002, loss_test:0.01830, lr:5.58e-03, fs:0.71053 (r=0.818,p=0.628),  time:35.369, tt:3925.965\n",
      "Ep:111, loss:0.00002, loss_test:0.01828, lr:5.58e-03, fs:0.71053 (r=0.818,p=0.628),  time:35.372, tt:3961.665\n",
      "Ep:112, loss:0.00002, loss_test:0.01826, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.374, tt:3997.240\n",
      "Ep:113, loss:0.00002, loss_test:0.01825, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.369, tt:4032.021\n",
      "Ep:114, loss:0.00002, loss_test:0.01823, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.355, tt:4065.867\n",
      "Ep:115, loss:0.00002, loss_test:0.01821, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.350, tt:4100.606\n",
      "Ep:116, loss:0.00002, loss_test:0.01820, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.326, tt:4133.137\n",
      "Ep:117, loss:0.00002, loss_test:0.01818, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.330, tt:4168.995\n",
      "Ep:118, loss:0.00002, loss_test:0.01816, lr:5.58e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.327, tt:4203.926\n",
      "Ep:119, loss:0.00002, loss_test:0.01815, lr:5.53e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.335, tt:4240.209\n",
      "Ep:120, loss:0.00002, loss_test:0.01814, lr:5.47e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.342, tt:4276.332\n",
      "Ep:121, loss:0.00002, loss_test:0.01812, lr:5.42e-03, fs:0.70742 (r=0.818,p=0.623),  time:35.334, tt:4310.786\n",
      "Ep:122, loss:0.00002, loss_test:0.01812, lr:5.36e-03, fs:0.71053 (r=0.818,p=0.628),  time:35.336, tt:4346.328\n",
      "Ep:123, loss:0.00002, loss_test:0.01810, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.328, tt:4380.719\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.01809, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.333, tt:4416.634\n",
      "Ep:125, loss:0.00002, loss_test:0.01807, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.331, tt:4451.646\n",
      "Ep:126, loss:0.00002, loss_test:0.01806, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.332, tt:4487.213\n",
      "Ep:127, loss:0.00002, loss_test:0.01805, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.322, tt:4521.215\n",
      "Ep:128, loss:0.00002, loss_test:0.01804, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.319, tt:4556.166\n",
      "Ep:129, loss:0.00002, loss_test:0.01803, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.319, tt:4591.489\n",
      "Ep:130, loss:0.00002, loss_test:0.01802, lr:5.31e-03, fs:0.71366 (r=0.818,p=0.633),  time:35.312, tt:4625.931\n",
      "Ep:131, loss:0.00002, loss_test:0.01801, lr:5.31e-03, fs:0.71681 (r=0.818,p=0.638),  time:35.304, tt:4660.091\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00002, loss_test:0.01801, lr:5.31e-03, fs:0.72000 (r=0.818,p=0.643),  time:35.300, tt:4694.847\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00002, loss_test:0.01800, lr:5.31e-03, fs:0.72000 (r=0.818,p=0.643),  time:35.294, tt:4729.442\n",
      "Ep:134, loss:0.00002, loss_test:0.01799, lr:5.31e-03, fs:0.72000 (r=0.818,p=0.643),  time:35.293, tt:4764.509\n",
      "Ep:135, loss:0.00002, loss_test:0.01798, lr:5.31e-03, fs:0.72646 (r=0.818,p=0.653),  time:35.283, tt:4798.524\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00002, loss_test:0.01798, lr:5.31e-03, fs:0.72646 (r=0.818,p=0.653),  time:35.270, tt:4831.989\n",
      "Ep:137, loss:0.00002, loss_test:0.01797, lr:5.31e-03, fs:0.72646 (r=0.818,p=0.653),  time:35.256, tt:4865.292\n",
      "Ep:138, loss:0.00002, loss_test:0.01797, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.257, tt:4900.727\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00002, loss_test:0.01796, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.249, tt:4934.837\n",
      "Ep:140, loss:0.00002, loss_test:0.01796, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.248, tt:4969.993\n",
      "Ep:141, loss:0.00002, loss_test:0.01794, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.254, tt:5006.022\n",
      "Ep:142, loss:0.00002, loss_test:0.01793, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.243, tt:5039.714\n",
      "Ep:143, loss:0.00002, loss_test:0.01792, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.238, tt:5074.316\n",
      "Ep:144, loss:0.00002, loss_test:0.01792, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.236, tt:5109.235\n",
      "Ep:145, loss:0.00002, loss_test:0.01791, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.240, tt:5145.026\n",
      "Ep:146, loss:0.00002, loss_test:0.01790, lr:5.31e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.231, tt:5178.921\n",
      "Ep:147, loss:0.00002, loss_test:0.01790, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.230, tt:5214.064\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00002, loss_test:0.01789, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.226, tt:5248.685\n",
      "Ep:149, loss:0.00002, loss_test:0.01788, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.226, tt:5283.972\n",
      "Ep:150, loss:0.00002, loss_test:0.01788, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.230, tt:5319.714\n",
      "Ep:151, loss:0.00002, loss_test:0.01788, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.225, tt:5354.229\n",
      "Ep:152, loss:0.00002, loss_test:0.01787, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.221, tt:5388.808\n",
      "Ep:153, loss:0.00002, loss_test:0.01786, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.213, tt:5422.759\n",
      "Ep:154, loss:0.00002, loss_test:0.01785, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.212, tt:5457.898\n",
      "Ep:155, loss:0.00002, loss_test:0.01785, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.207, tt:5492.312\n",
      "Ep:156, loss:0.00002, loss_test:0.01785, lr:5.31e-03, fs:0.73874 (r=0.828,p=0.667),  time:35.207, tt:5527.563\n",
      "Ep:157, loss:0.00002, loss_test:0.01785, lr:5.31e-03, fs:0.74208 (r=0.828,p=0.672),  time:35.212, tt:5563.502\n",
      "##########Best model found so far##########\n",
      "Ep:158, loss:0.00002, loss_test:0.01784, lr:5.31e-03, fs:0.74208 (r=0.828,p=0.672),  time:35.215, tt:5599.247\n",
      "Ep:159, loss:0.00002, loss_test:0.01783, lr:5.31e-03, fs:0.74208 (r=0.828,p=0.672),  time:35.225, tt:5636.074\n",
      "Ep:160, loss:0.00002, loss_test:0.01782, lr:5.31e-03, fs:0.74208 (r=0.828,p=0.672),  time:35.235, tt:5672.805\n",
      "Ep:161, loss:0.00002, loss_test:0.01781, lr:5.31e-03, fs:0.74545 (r=0.828,p=0.678),  time:35.229, tt:5707.129\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00002, loss_test:0.01779, lr:5.31e-03, fs:0.74545 (r=0.828,p=0.678),  time:35.227, tt:5741.991\n",
      "Ep:163, loss:0.00002, loss_test:0.01778, lr:5.31e-03, fs:0.75113 (r=0.838,p=0.680),  time:35.229, tt:5777.509\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00002, loss_test:0.01776, lr:5.31e-03, fs:0.75113 (r=0.838,p=0.680),  time:35.225, tt:5812.140\n",
      "Ep:165, loss:0.00002, loss_test:0.01776, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.218, tt:5846.199\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00002, loss_test:0.01775, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.214, tt:5880.660\n",
      "Ep:167, loss:0.00002, loss_test:0.01774, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.209, tt:5915.190\n",
      "Ep:168, loss:0.00002, loss_test:0.01774, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.206, tt:5949.798\n",
      "Ep:169, loss:0.00002, loss_test:0.01773, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.201, tt:5984.181\n",
      "Ep:170, loss:0.00002, loss_test:0.01773, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.193, tt:6018.024\n",
      "Ep:171, loss:0.00002, loss_test:0.01772, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.192, tt:6053.095\n",
      "Ep:172, loss:0.00002, loss_test:0.01771, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.200, tt:6089.639\n",
      "Ep:173, loss:0.00002, loss_test:0.01771, lr:5.31e-03, fs:0.75455 (r=0.838,p=0.686),  time:35.192, tt:6123.342\n",
      "Ep:174, loss:0.00002, loss_test:0.01770, lr:5.31e-03, fs:0.75799 (r=0.838,p=0.692),  time:35.188, tt:6157.978\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00002, loss_test:0.01769, lr:5.31e-03, fs:0.75799 (r=0.838,p=0.692),  time:35.183, tt:6192.294\n",
      "Ep:176, loss:0.00002, loss_test:0.01769, lr:5.31e-03, fs:0.75799 (r=0.838,p=0.692),  time:35.185, tt:6227.745\n",
      "Ep:177, loss:0.00002, loss_test:0.01768, lr:5.31e-03, fs:0.75799 (r=0.838,p=0.692),  time:35.187, tt:6263.264\n",
      "Ep:178, loss:0.00002, loss_test:0.01768, lr:5.31e-03, fs:0.75799 (r=0.838,p=0.692),  time:35.178, tt:6296.892\n",
      "Ep:179, loss:0.00002, loss_test:0.01767, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.182, tt:6332.688\n",
      "##########Best model found so far##########\n",
      "Ep:180, loss:0.00002, loss_test:0.01766, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.184, tt:6368.387\n",
      "Ep:181, loss:0.00002, loss_test:0.01766, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.189, tt:6404.327\n",
      "Ep:182, loss:0.00002, loss_test:0.01766, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.184, tt:6438.714\n",
      "Ep:183, loss:0.00002, loss_test:0.01765, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.193, tt:6475.493\n",
      "Ep:184, loss:0.00002, loss_test:0.01763, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.193, tt:6510.784\n",
      "Ep:185, loss:0.00002, loss_test:0.01762, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.200, tt:6547.256\n",
      "Ep:186, loss:0.00002, loss_test:0.01761, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.198, tt:6582.027\n",
      "Ep:187, loss:0.00002, loss_test:0.01761, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.195, tt:6616.619\n",
      "Ep:188, loss:0.00002, loss_test:0.01761, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.188, tt:6650.503\n",
      "Ep:189, loss:0.00002, loss_test:0.01760, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.191, tt:6686.318\n",
      "Ep:190, loss:0.00002, loss_test:0.01760, lr:5.31e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.189, tt:6721.149\n",
      "Ep:191, loss:0.00002, loss_test:0.01759, lr:5.26e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.186, tt:6755.696\n",
      "Ep:192, loss:0.00002, loss_test:0.01758, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.171, tt:6788.000\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00002, loss_test:0.01758, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.164, tt:6821.866\n",
      "Ep:194, loss:0.00002, loss_test:0.01758, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.155, tt:6855.248\n",
      "Ep:195, loss:0.00002, loss_test:0.01757, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.150, tt:6889.346\n",
      "Ep:196, loss:0.00002, loss_test:0.01756, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.155, tt:6925.587\n",
      "Ep:197, loss:0.00002, loss_test:0.01756, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.156, tt:6960.959\n",
      "Ep:198, loss:0.00002, loss_test:0.01755, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.154, tt:6995.670\n",
      "Ep:199, loss:0.00002, loss_test:0.01754, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.153, tt:7030.691\n",
      "Ep:200, loss:0.00002, loss_test:0.01754, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.150, tt:7065.211\n",
      "Ep:201, loss:0.00002, loss_test:0.01753, lr:5.20e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.147, tt:7099.657\n",
      "Ep:202, loss:0.00002, loss_test:0.01753, lr:5.20e-03, fs:0.77273 (r=0.859,p=0.702),  time:35.143, tt:7134.125\n",
      "##########Best model found so far##########\n",
      "Ep:203, loss:0.00002, loss_test:0.01752, lr:5.20e-03, fs:0.77626 (r=0.859,p=0.708),  time:35.139, tt:7168.391\n",
      "##########Best model found so far##########\n",
      "Ep:204, loss:0.00002, loss_test:0.01751, lr:5.20e-03, fs:0.77626 (r=0.859,p=0.708),  time:35.133, tt:7202.323\n",
      "Ep:205, loss:0.00002, loss_test:0.01751, lr:5.20e-03, fs:0.77626 (r=0.859,p=0.708),  time:35.108, tt:7232.199\n",
      "Ep:206, loss:0.00002, loss_test:0.01751, lr:5.20e-03, fs:0.77626 (r=0.859,p=0.708),  time:35.062, tt:7257.919\n",
      "Model and results saved\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.03212, lr:1.00e-02, fs:0.58621 (r=0.515,p=0.680),  time:31.967, tt:31.967\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02560, lr:1.00e-02, fs:0.59434 (r=0.636,p=0.558),  time:33.788, tt:67.575\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02240, lr:1.00e-02, fs:0.59836 (r=0.737,p=0.503),  time:35.444, tt:106.333\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02154, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:36.294, tt:145.178\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02146, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:36.792, tt:183.959\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02146, lr:1.00e-02, fs:0.64111 (r=0.929,p=0.489),  time:37.841, tt:227.048\n",
      "Ep:6, loss:0.00004, loss_test:0.02136, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:38.032, tt:266.225\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02111, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:38.134, tt:305.073\n",
      "Ep:8, loss:0.00004, loss_test:0.02082, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:38.396, tt:345.564\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02052, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:38.344, tt:383.439\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02029, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:38.319, tt:421.504\n",
      "Ep:11, loss:0.00004, loss_test:0.02015, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:38.264, tt:459.163\n",
      "Ep:12, loss:0.00004, loss_test:0.02010, lr:1.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:38.417, tt:499.425\n",
      "Ep:13, loss:0.00003, loss_test:0.02014, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:38.499, tt:538.987\n",
      "Ep:14, loss:0.00003, loss_test:0.02022, lr:1.00e-02, fs:0.63519 (r=0.747,p=0.552),  time:38.520, tt:577.799\n",
      "Ep:15, loss:0.00003, loss_test:0.02031, lr:1.00e-02, fs:0.63717 (r=0.727,p=0.567),  time:38.478, tt:615.642\n",
      "Ep:16, loss:0.00003, loss_test:0.02034, lr:1.00e-02, fs:0.63303 (r=0.697,p=0.580),  time:38.457, tt:653.773\n",
      "Ep:17, loss:0.00003, loss_test:0.02029, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:38.452, tt:692.140\n",
      "Ep:18, loss:0.00003, loss_test:0.02014, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:38.398, tt:729.560\n",
      "Ep:19, loss:0.00003, loss_test:0.01993, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:38.338, tt:766.756\n",
      "Ep:20, loss:0.00003, loss_test:0.01970, lr:1.00e-02, fs:0.65438 (r=0.717,p=0.602),  time:38.396, tt:806.310\n",
      "Ep:21, loss:0.00003, loss_test:0.01947, lr:9.90e-03, fs:0.65138 (r=0.717,p=0.597),  time:38.404, tt:844.898\n",
      "Ep:22, loss:0.00003, loss_test:0.01927, lr:9.80e-03, fs:0.66968 (r=0.747,p=0.607),  time:38.484, tt:885.140\n",
      "Ep:23, loss:0.00003, loss_test:0.01910, lr:9.70e-03, fs:0.67265 (r=0.758,p=0.605),  time:38.528, tt:924.663\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01896, lr:9.70e-03, fs:0.69298 (r=0.798,p=0.612),  time:38.562, tt:964.051\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01886, lr:9.70e-03, fs:0.70175 (r=0.808,p=0.620),  time:38.744, tt:1007.350\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01878, lr:9.70e-03, fs:0.70742 (r=0.818,p=0.623),  time:38.736, tt:1045.864\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01872, lr:9.70e-03, fs:0.70742 (r=0.818,p=0.623),  time:38.774, tt:1085.664\n",
      "Ep:28, loss:0.00003, loss_test:0.01867, lr:9.70e-03, fs:0.71053 (r=0.818,p=0.628),  time:38.806, tt:1125.371\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01863, lr:9.70e-03, fs:0.71681 (r=0.818,p=0.638),  time:38.774, tt:1163.219\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01858, lr:9.70e-03, fs:0.72247 (r=0.828,p=0.641),  time:38.769, tt:1201.839\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01852, lr:9.70e-03, fs:0.72247 (r=0.828,p=0.641),  time:38.742, tt:1239.732\n",
      "Ep:32, loss:0.00003, loss_test:0.01846, lr:9.70e-03, fs:0.72566 (r=0.828,p=0.646),  time:38.764, tt:1279.203\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01839, lr:9.70e-03, fs:0.72566 (r=0.828,p=0.646),  time:38.771, tt:1318.217\n",
      "Ep:34, loss:0.00003, loss_test:0.01832, lr:9.70e-03, fs:0.72566 (r=0.828,p=0.646),  time:38.778, tt:1357.244\n",
      "Ep:35, loss:0.00003, loss_test:0.01824, lr:9.70e-03, fs:0.72889 (r=0.828,p=0.651),  time:38.748, tt:1394.944\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01817, lr:9.70e-03, fs:0.72889 (r=0.828,p=0.651),  time:38.796, tt:1435.453\n",
      "Ep:37, loss:0.00003, loss_test:0.01811, lr:9.70e-03, fs:0.72889 (r=0.828,p=0.651),  time:38.818, tt:1475.070\n",
      "Ep:38, loss:0.00003, loss_test:0.01804, lr:9.70e-03, fs:0.72889 (r=0.828,p=0.651),  time:38.838, tt:1514.690\n",
      "Ep:39, loss:0.00003, loss_test:0.01799, lr:9.70e-03, fs:0.73778 (r=0.838,p=0.659),  time:38.879, tt:1555.157\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01794, lr:9.70e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.849, tt:1592.829\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01790, lr:9.70e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.860, tt:1632.123\n",
      "Ep:42, loss:0.00003, loss_test:0.01785, lr:9.70e-03, fs:0.74667 (r=0.848,p=0.667),  time:38.872, tt:1671.478\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01781, lr:9.70e-03, fs:0.75000 (r=0.848,p=0.672),  time:38.842, tt:1709.028\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01776, lr:9.70e-03, fs:0.76106 (r=0.869,p=0.677),  time:38.885, tt:1749.837\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01771, lr:9.70e-03, fs:0.76106 (r=0.869,p=0.677),  time:38.929, tt:1790.714\n",
      "Ep:46, loss:0.00003, loss_test:0.01766, lr:9.70e-03, fs:0.76106 (r=0.869,p=0.677),  time:38.985, tt:1832.297\n",
      "Ep:47, loss:0.00003, loss_test:0.01762, lr:9.70e-03, fs:0.76106 (r=0.869,p=0.677),  time:38.987, tt:1871.360\n",
      "Ep:48, loss:0.00003, loss_test:0.01758, lr:9.70e-03, fs:0.75771 (r=0.869,p=0.672),  time:38.993, tt:1910.660\n",
      "Ep:49, loss:0.00003, loss_test:0.01754, lr:9.70e-03, fs:0.75771 (r=0.869,p=0.672),  time:39.033, tt:1951.644\n",
      "Ep:50, loss:0.00003, loss_test:0.01749, lr:9.70e-03, fs:0.75771 (r=0.869,p=0.672),  time:39.023, tt:1990.174\n",
      "Ep:51, loss:0.00003, loss_test:0.01745, lr:9.70e-03, fs:0.75771 (r=0.869,p=0.672),  time:38.982, tt:2027.090\n",
      "Ep:52, loss:0.00003, loss_test:0.01741, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:39.027, tt:2068.424\n",
      "Ep:53, loss:0.00003, loss_test:0.01738, lr:9.70e-03, fs:0.74667 (r=0.848,p=0.667),  time:39.033, tt:2107.801\n",
      "Ep:54, loss:0.00002, loss_test:0.01735, lr:9.70e-03, fs:0.74667 (r=0.848,p=0.667),  time:39.065, tt:2148.600\n",
      "Ep:55, loss:0.00002, loss_test:0.01731, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:39.079, tt:2188.427\n",
      "Ep:56, loss:0.00002, loss_test:0.01727, lr:9.61e-03, fs:0.74107 (r=0.838,p=0.664),  time:39.085, tt:2227.856\n",
      "Ep:57, loss:0.00002, loss_test:0.01723, lr:9.51e-03, fs:0.74107 (r=0.838,p=0.664),  time:39.100, tt:2267.819\n",
      "Ep:58, loss:0.00002, loss_test:0.01720, lr:9.41e-03, fs:0.74667 (r=0.848,p=0.667),  time:39.108, tt:2307.354\n",
      "Ep:59, loss:0.00002, loss_test:0.01716, lr:9.32e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.126, tt:2347.586\n",
      "Ep:60, loss:0.00002, loss_test:0.01713, lr:9.23e-03, fs:0.74107 (r=0.838,p=0.664),  time:39.078, tt:2383.733\n",
      "Ep:61, loss:0.00002, loss_test:0.01710, lr:9.14e-03, fs:0.74107 (r=0.838,p=0.664),  time:39.106, tt:2424.557\n",
      "Ep:62, loss:0.00002, loss_test:0.01707, lr:9.04e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.093, tt:2462.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00002, loss_test:0.01704, lr:8.95e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.085, tt:2501.435\n",
      "Ep:64, loss:0.00002, loss_test:0.01701, lr:8.86e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.074, tt:2539.817\n",
      "Ep:65, loss:0.00002, loss_test:0.01698, lr:8.78e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.128, tt:2582.440\n",
      "Ep:66, loss:0.00002, loss_test:0.01694, lr:8.69e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.141, tt:2622.459\n",
      "Ep:67, loss:0.00002, loss_test:0.01691, lr:8.60e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.128, tt:2660.687\n",
      "Ep:68, loss:0.00002, loss_test:0.01689, lr:8.51e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.128, tt:2699.805\n",
      "Ep:69, loss:0.00002, loss_test:0.01687, lr:8.43e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.134, tt:2739.372\n",
      "Ep:70, loss:0.00002, loss_test:0.01685, lr:8.35e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.142, tt:2779.055\n",
      "Ep:71, loss:0.00002, loss_test:0.01683, lr:8.26e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.113, tt:2816.142\n",
      "Ep:72, loss:0.00002, loss_test:0.01682, lr:8.18e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.121, tt:2855.866\n",
      "Ep:73, loss:0.00002, loss_test:0.01680, lr:8.10e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.114, tt:2894.428\n",
      "Ep:74, loss:0.00002, loss_test:0.01679, lr:8.02e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.091, tt:2931.844\n",
      "Ep:75, loss:0.00002, loss_test:0.01676, lr:7.94e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.086, tt:2970.520\n",
      "Ep:76, loss:0.00002, loss_test:0.01675, lr:7.86e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.067, tt:3008.137\n",
      "Ep:77, loss:0.00002, loss_test:0.01673, lr:7.78e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.092, tt:3049.156\n",
      "Ep:78, loss:0.00002, loss_test:0.01671, lr:7.70e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.087, tt:3087.874\n",
      "Ep:79, loss:0.00002, loss_test:0.01669, lr:7.62e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.092, tt:3127.350\n",
      "Ep:80, loss:0.00002, loss_test:0.01667, lr:7.55e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.110, tt:3167.904\n",
      "Ep:81, loss:0.00002, loss_test:0.01665, lr:7.47e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.112, tt:3207.148\n",
      "Ep:82, loss:0.00002, loss_test:0.01664, lr:7.40e-03, fs:0.73874 (r=0.828,p=0.667),  time:39.121, tt:3247.043\n",
      "Ep:83, loss:0.00002, loss_test:0.01661, lr:7.32e-03, fs:0.74208 (r=0.828,p=0.672),  time:39.127, tt:3286.691\n",
      "Ep:84, loss:0.00002, loss_test:0.01660, lr:7.25e-03, fs:0.74208 (r=0.828,p=0.672),  time:39.137, tt:3326.662\n",
      "Ep:85, loss:0.00002, loss_test:0.01658, lr:7.18e-03, fs:0.74208 (r=0.828,p=0.672),  time:39.126, tt:3364.797\n",
      "Ep:86, loss:0.00002, loss_test:0.01657, lr:7.11e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.118, tt:3403.288\n",
      "Ep:87, loss:0.00002, loss_test:0.01655, lr:7.03e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.112, tt:3441.899\n",
      "Ep:88, loss:0.00002, loss_test:0.01654, lr:6.96e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.107, tt:3480.557\n",
      "Ep:89, loss:0.00002, loss_test:0.01652, lr:6.89e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.092, tt:3518.304\n",
      "Ep:90, loss:0.00002, loss_test:0.01651, lr:6.83e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.092, tt:3557.416\n",
      "Ep:91, loss:0.00002, loss_test:0.01650, lr:6.76e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.096, tt:3596.878\n",
      "Ep:92, loss:0.00002, loss_test:0.01649, lr:6.69e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.084, tt:3634.845\n",
      "Ep:93, loss:0.00002, loss_test:0.01648, lr:6.62e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.078, tt:3673.287\n",
      "Ep:94, loss:0.00002, loss_test:0.01647, lr:6.56e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.068, tt:3711.496\n",
      "Ep:95, loss:0.00002, loss_test:0.01646, lr:6.49e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.092, tt:3752.819\n",
      "Ep:96, loss:0.00002, loss_test:0.01645, lr:6.43e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.090, tt:3791.758\n",
      "Ep:97, loss:0.00002, loss_test:0.01645, lr:6.36e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.100, tt:3831.837\n",
      "Ep:98, loss:0.00002, loss_test:0.01644, lr:6.30e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.094, tt:3870.303\n",
      "Ep:99, loss:0.00002, loss_test:0.01643, lr:6.24e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.113, tt:3911.338\n",
      "Ep:100, loss:0.00002, loss_test:0.01642, lr:6.17e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.128, tt:3951.897\n",
      "Ep:101, loss:0.00002, loss_test:0.01641, lr:6.11e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.127, tt:3990.911\n",
      "Ep:102, loss:0.00002, loss_test:0.01640, lr:6.05e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.159, tt:4033.387\n",
      "Ep:103, loss:0.00002, loss_test:0.01639, lr:5.99e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.155, tt:4072.166\n",
      "Ep:104, loss:0.00002, loss_test:0.01638, lr:5.93e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.144, tt:4110.124\n",
      "Ep:105, loss:0.00002, loss_test:0.01637, lr:5.87e-03, fs:0.73394 (r=0.808,p=0.672),  time:39.135, tt:4148.291\n",
      "Ep:106, loss:0.00002, loss_test:0.01636, lr:5.81e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.140, tt:4187.995\n",
      "Ep:107, loss:0.00002, loss_test:0.01635, lr:5.75e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.142, tt:4227.390\n",
      "Ep:108, loss:0.00002, loss_test:0.01635, lr:5.70e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.134, tt:4265.624\n",
      "Ep:109, loss:0.00002, loss_test:0.01634, lr:5.64e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.144, tt:4305.790\n",
      "Ep:110, loss:0.00002, loss_test:0.01632, lr:5.58e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.152, tt:4345.830\n",
      "Ep:111, loss:0.00002, loss_test:0.01631, lr:5.53e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.145, tt:4384.258\n",
      "Ep:112, loss:0.00002, loss_test:0.01631, lr:5.47e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.134, tt:4422.090\n",
      "Ep:113, loss:0.00002, loss_test:0.01630, lr:5.42e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.133, tt:4461.193\n",
      "Ep:114, loss:0.00002, loss_test:0.01629, lr:5.36e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.120, tt:4498.855\n",
      "Ep:115, loss:0.00002, loss_test:0.01629, lr:5.31e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.107, tt:4536.394\n",
      "Ep:116, loss:0.00002, loss_test:0.01628, lr:5.26e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.106, tt:4575.453\n",
      "Ep:117, loss:0.00002, loss_test:0.01627, lr:5.20e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.113, tt:4615.384\n",
      "Ep:118, loss:0.00002, loss_test:0.01626, lr:5.15e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.124, tt:4655.787\n",
      "Ep:119, loss:0.00002, loss_test:0.01625, lr:5.10e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.114, tt:4693.698\n",
      "Ep:120, loss:0.00002, loss_test:0.01624, lr:5.05e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.109, tt:4732.182\n",
      "Ep:121, loss:0.00002, loss_test:0.01624, lr:5.00e-03, fs:0.73973 (r=0.818,p=0.675),  time:39.126, tt:4773.431\n",
      "Ep:122, loss:0.00002, loss_test:0.01623, lr:4.95e-03, fs:0.74312 (r=0.818,p=0.681),  time:39.124, tt:4812.258\n",
      "Ep:123, loss:0.00002, loss_test:0.01622, lr:4.90e-03, fs:0.74654 (r=0.818,p=0.686),  time:39.130, tt:4852.149\n",
      "Ep:124, loss:0.00002, loss_test:0.01621, lr:4.85e-03, fs:0.74312 (r=0.818,p=0.681),  time:39.120, tt:4889.973\n",
      "Ep:125, loss:0.00002, loss_test:0.01620, lr:4.80e-03, fs:0.74312 (r=0.818,p=0.681),  time:39.117, tt:4928.801\n",
      "Ep:126, loss:0.00002, loss_test:0.01620, lr:4.75e-03, fs:0.74654 (r=0.818,p=0.686),  time:39.103, tt:4966.068\n",
      "Ep:127, loss:0.00002, loss_test:0.01619, lr:4.71e-03, fs:0.74654 (r=0.818,p=0.686),  time:39.095, tt:5004.127\n",
      "Ep:128, loss:0.00002, loss_test:0.01618, lr:4.66e-03, fs:0.75000 (r=0.818,p=0.692),  time:39.092, tt:5042.803\n",
      "Ep:129, loss:0.00002, loss_test:0.01617, lr:4.61e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.083, tt:5080.803\n",
      "Ep:130, loss:0.00002, loss_test:0.01617, lr:4.57e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.079, tt:5119.402\n",
      "Ep:131, loss:0.00002, loss_test:0.01617, lr:4.52e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.081, tt:5158.689\n",
      "Ep:132, loss:0.00002, loss_test:0.01616, lr:4.48e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.080, tt:5197.593\n",
      "Ep:133, loss:0.00002, loss_test:0.01615, lr:4.43e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.088, tt:5237.751\n",
      "Ep:134, loss:0.00002, loss_test:0.01615, lr:4.39e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.087, tt:5276.707\n",
      "Ep:135, loss:0.00002, loss_test:0.01614, lr:4.34e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.076, tt:5314.394\n",
      "Ep:136, loss:0.00002, loss_test:0.01613, lr:4.30e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.071, tt:5352.701\n",
      "Ep:137, loss:0.00002, loss_test:0.01613, lr:4.26e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.061, tt:5390.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00002, loss_test:0.01613, lr:4.21e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.072, tt:5431.031\n",
      "Ep:139, loss:0.00002, loss_test:0.01612, lr:4.17e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.070, tt:5469.779\n",
      "Ep:140, loss:0.00002, loss_test:0.01612, lr:4.13e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.069, tt:5508.706\n",
      "Ep:141, loss:0.00002, loss_test:0.01611, lr:4.09e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.059, tt:5546.378\n",
      "Ep:142, loss:0.00002, loss_test:0.01611, lr:4.05e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.046, tt:5583.634\n",
      "Ep:143, loss:0.00002, loss_test:0.01610, lr:4.01e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.045, tt:5622.512\n",
      "Ep:144, loss:0.00002, loss_test:0.01610, lr:3.97e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.064, tt:5664.340\n",
      "Ep:145, loss:0.00002, loss_test:0.01610, lr:3.93e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.058, tt:5702.510\n",
      "Ep:146, loss:0.00002, loss_test:0.01610, lr:3.89e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.048, tt:5740.057\n",
      "Ep:147, loss:0.00002, loss_test:0.01609, lr:3.85e-03, fs:0.75349 (r=0.818,p=0.698),  time:39.040, tt:5777.940\n",
      "Ep:148, loss:0.00002, loss_test:0.01609, lr:3.81e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.038, tt:5816.672\n",
      "Ep:149, loss:0.00002, loss_test:0.01609, lr:3.77e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.042, tt:5856.270\n",
      "Ep:150, loss:0.00002, loss_test:0.01608, lr:3.73e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.032, tt:5893.881\n",
      "Ep:151, loss:0.00002, loss_test:0.01608, lr:3.70e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.035, tt:5933.348\n",
      "Ep:152, loss:0.00002, loss_test:0.01608, lr:3.66e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.037, tt:5972.605\n",
      "Ep:153, loss:0.00002, loss_test:0.01607, lr:3.62e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.031, tt:6010.765\n",
      "Ep:154, loss:0.00002, loss_test:0.01607, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.031, tt:6049.776\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00002, loss_test:0.01607, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.021, tt:6087.321\n",
      "Ep:156, loss:0.00002, loss_test:0.01606, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.027, tt:6127.313\n",
      "Ep:157, loss:0.00002, loss_test:0.01606, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.023, tt:6165.709\n",
      "Ep:158, loss:0.00002, loss_test:0.01606, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.023, tt:6204.592\n",
      "Ep:159, loss:0.00002, loss_test:0.01605, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.023, tt:6243.723\n",
      "Ep:160, loss:0.00002, loss_test:0.01605, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.026, tt:6283.158\n",
      "Ep:161, loss:0.00002, loss_test:0.01605, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.024, tt:6321.831\n",
      "Ep:162, loss:0.00002, loss_test:0.01604, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.032, tt:6362.291\n",
      "Ep:163, loss:0.00002, loss_test:0.01604, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.038, tt:6402.154\n",
      "Ep:164, loss:0.00002, loss_test:0.01603, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.035, tt:6440.765\n",
      "Ep:165, loss:0.00002, loss_test:0.01603, lr:3.59e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.042, tt:6481.037\n",
      "Ep:166, loss:0.00002, loss_test:0.01603, lr:3.55e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.041, tt:6519.874\n",
      "Ep:167, loss:0.00002, loss_test:0.01603, lr:3.52e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.035, tt:6557.834\n",
      "Ep:168, loss:0.00002, loss_test:0.01602, lr:3.48e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.048, tt:6599.073\n",
      "Ep:169, loss:0.00002, loss_test:0.01601, lr:3.45e-03, fs:0.76636 (r=0.828,p=0.713),  time:39.055, tt:6639.285\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00002, loss_test:0.01601, lr:3.45e-03, fs:0.76636 (r=0.828,p=0.713),  time:39.059, tt:6679.057\n",
      "Ep:171, loss:0.00002, loss_test:0.01601, lr:3.45e-03, fs:0.76636 (r=0.828,p=0.713),  time:39.059, tt:6718.092\n",
      "Ep:172, loss:0.00002, loss_test:0.01600, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.062, tt:6757.735\n",
      "##########Best model found so far##########\n",
      "Ep:173, loss:0.00002, loss_test:0.01600, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.053, tt:6795.171\n",
      "Ep:174, loss:0.00002, loss_test:0.01600, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.055, tt:6834.668\n",
      "Ep:175, loss:0.00002, loss_test:0.01599, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.066, tt:6875.686\n",
      "Ep:176, loss:0.00002, loss_test:0.01599, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.067, tt:6914.866\n",
      "Ep:177, loss:0.00002, loss_test:0.01599, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.072, tt:6954.893\n",
      "Ep:178, loss:0.00002, loss_test:0.01598, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.072, tt:6993.832\n",
      "Ep:179, loss:0.00002, loss_test:0.01598, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.072, tt:7032.990\n",
      "Ep:180, loss:0.00002, loss_test:0.01597, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.071, tt:7071.910\n",
      "Ep:181, loss:0.00002, loss_test:0.01597, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.073, tt:7111.216\n",
      "Ep:182, loss:0.00002, loss_test:0.01596, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.079, tt:7151.400\n",
      "Ep:183, loss:0.00002, loss_test:0.01596, lr:3.45e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.082, tt:7191.143\n",
      "Ep:184, loss:0.00002, loss_test:0.01596, lr:3.41e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.076, tt:7229.036\n",
      "Ep:185, loss:0.00002, loss_test:0.01595, lr:3.38e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.075, tt:7267.927\n",
      "Ep:186, loss:0.00002, loss_test:0.01595, lr:3.34e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.070, tt:7306.050\n",
      "Ep:187, loss:0.00002, loss_test:0.01595, lr:3.31e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.085, tt:7348.054\n",
      "Ep:188, loss:0.00002, loss_test:0.01595, lr:3.28e-03, fs:0.76995 (r=0.828,p=0.719),  time:39.100, tt:7389.901\n",
      "Ep:189, loss:0.00002, loss_test:0.01594, lr:3.24e-03, fs:0.77570 (r=0.838,p=0.722),  time:39.106, tt:7430.172\n",
      "##########Best model found so far##########\n",
      "Ep:190, loss:0.00002, loss_test:0.01594, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.119, tt:7471.764\n",
      "##########Best model found so far##########\n",
      "Ep:191, loss:0.00002, loss_test:0.01594, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.122, tt:7511.376\n",
      "Ep:192, loss:0.00002, loss_test:0.01593, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.125, tt:7551.155\n",
      "Ep:193, loss:0.00002, loss_test:0.01593, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.135, tt:7592.117\n",
      "Ep:194, loss:0.00002, loss_test:0.01593, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.139, tt:7632.007\n",
      "Ep:195, loss:0.00002, loss_test:0.01592, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.148, tt:7672.922\n",
      "Ep:196, loss:0.00002, loss_test:0.01592, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.153, tt:7713.228\n",
      "Ep:197, loss:0.00002, loss_test:0.01592, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.166, tt:7754.827\n",
      "Ep:198, loss:0.00002, loss_test:0.01592, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.165, tt:7793.824\n",
      "Ep:199, loss:0.00002, loss_test:0.01591, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.166, tt:7833.214\n",
      "Ep:200, loss:0.00002, loss_test:0.01591, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.163, tt:7871.817\n",
      "Ep:201, loss:0.00002, loss_test:0.01590, lr:3.24e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.168, tt:7911.907\n",
      "Ep:202, loss:0.00002, loss_test:0.01591, lr:3.21e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.169, tt:7951.292\n",
      "Ep:203, loss:0.00002, loss_test:0.01590, lr:3.18e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.178, tt:7992.310\n",
      "Ep:204, loss:0.00002, loss_test:0.01590, lr:3.15e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.192, tt:8034.297\n",
      "Ep:205, loss:0.00002, loss_test:0.01590, lr:3.12e-03, fs:0.78302 (r=0.838,p=0.735),  time:39.182, tt:8071.476\n",
      "##########Best model found so far##########\n",
      "Ep:206, loss:0.00002, loss_test:0.01590, lr:3.12e-03, fs:0.78302 (r=0.838,p=0.735),  time:39.138, tt:8101.626\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.14022, lr:1.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:33.874, tt:33.874\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13814, lr:1.00e-02, fs:0.63118 (r=0.838,p=0.506),  time:33.237, tt:66.475\n",
      "Ep:2, loss:0.00025, loss_test:0.13583, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:32.864, tt:98.593\n",
      "Ep:3, loss:0.00024, loss_test:0.13578, lr:1.00e-02, fs:0.60714 (r=0.687,p=0.544),  time:33.011, tt:132.044\n",
      "Ep:4, loss:0.00024, loss_test:0.13388, lr:1.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:33.789, tt:168.947\n",
      "Ep:5, loss:0.00023, loss_test:0.13022, lr:1.00e-02, fs:0.60577 (r=0.636,p=0.578),  time:34.083, tt:204.499\n",
      "Ep:6, loss:0.00022, loss_test:0.12822, lr:1.00e-02, fs:0.62857 (r=0.667,p=0.595),  time:34.379, tt:240.655\n",
      "Ep:7, loss:0.00022, loss_test:0.12903, lr:1.00e-02, fs:0.61463 (r=0.636,p=0.594),  time:34.706, tt:277.646\n",
      "Ep:8, loss:0.00021, loss_test:0.13109, lr:1.00e-02, fs:0.61386 (r=0.626,p=0.602),  time:35.160, tt:316.436\n",
      "Ep:9, loss:0.00020, loss_test:0.13135, lr:1.00e-02, fs:0.61000 (r=0.616,p=0.604),  time:35.371, tt:353.712\n",
      "Ep:10, loss:0.00020, loss_test:0.12797, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:35.403, tt:389.431\n",
      "Ep:11, loss:0.00019, loss_test:0.12602, lr:1.00e-02, fs:0.64078 (r=0.667,p=0.617),  time:35.575, tt:426.903\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.12548, lr:1.00e-02, fs:0.61000 (r=0.616,p=0.604),  time:35.554, tt:462.204\n",
      "Ep:13, loss:0.00018, loss_test:0.12336, lr:1.00e-02, fs:0.59596 (r=0.596,p=0.596),  time:35.528, tt:497.393\n",
      "Ep:14, loss:0.00017, loss_test:0.12185, lr:1.00e-02, fs:0.61000 (r=0.616,p=0.604),  time:35.485, tt:532.276\n",
      "Ep:15, loss:0.00017, loss_test:0.11962, lr:1.00e-02, fs:0.59487 (r=0.586,p=0.604),  time:35.477, tt:567.626\n",
      "Ep:16, loss:0.00016, loss_test:0.11687, lr:1.00e-02, fs:0.63636 (r=0.636,p=0.636),  time:35.464, tt:602.882\n",
      "Ep:17, loss:0.00016, loss_test:0.11750, lr:1.00e-02, fs:0.62176 (r=0.606,p=0.638),  time:35.466, tt:638.397\n",
      "Ep:18, loss:0.00015, loss_test:0.11574, lr:1.00e-02, fs:0.62500 (r=0.606,p=0.645),  time:35.457, tt:673.680\n",
      "Ep:19, loss:0.00015, loss_test:0.11298, lr:1.00e-02, fs:0.61780 (r=0.596,p=0.641),  time:35.515, tt:710.291\n",
      "Ep:20, loss:0.00014, loss_test:0.11045, lr:1.00e-02, fs:0.62105 (r=0.596,p=0.648),  time:35.583, tt:747.243\n",
      "Ep:21, loss:0.00014, loss_test:0.10906, lr:1.00e-02, fs:0.64211 (r=0.616,p=0.670),  time:35.654, tt:784.387\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.10805, lr:1.00e-02, fs:0.65969 (r=0.636,p=0.685),  time:35.795, tt:823.274\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.10587, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:35.789, tt:858.937\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.10446, lr:1.00e-02, fs:0.69474 (r=0.667,p=0.725),  time:35.779, tt:894.481\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.10444, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:35.850, tt:932.108\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.10167, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:35.898, tt:969.258\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.10074, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:35.916, tt:1005.654\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.10200, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:35.880, tt:1040.523\n",
      "Ep:29, loss:0.00010, loss_test:0.09807, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:35.919, tt:1077.565\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.09871, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:35.900, tt:1112.912\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.09797, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:35.920, tt:1149.455\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.09682, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:35.947, tt:1186.245\n",
      "Ep:33, loss:0.00009, loss_test:0.09796, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:35.982, tt:1223.396\n",
      "Ep:34, loss:0.00008, loss_test:0.09607, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:35.995, tt:1259.831\n",
      "Ep:35, loss:0.00008, loss_test:0.09508, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:35.996, tt:1295.866\n",
      "Ep:36, loss:0.00008, loss_test:0.09495, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:36.046, tt:1333.685\n",
      "Ep:37, loss:0.00008, loss_test:0.09392, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:36.043, tt:1369.636\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.09415, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:36.049, tt:1405.907\n",
      "Ep:39, loss:0.00007, loss_test:0.09244, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:36.092, tt:1443.685\n",
      "Ep:40, loss:0.00007, loss_test:0.09122, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:36.088, tt:1479.604\n",
      "Ep:41, loss:0.00007, loss_test:0.09584, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:36.070, tt:1514.940\n",
      "Ep:42, loss:0.00006, loss_test:0.09386, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:36.040, tt:1549.719\n",
      "Ep:43, loss:0.00006, loss_test:0.09351, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:35.994, tt:1583.749\n",
      "Ep:44, loss:0.00006, loss_test:0.09527, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:36.017, tt:1620.772\n",
      "Ep:45, loss:0.00006, loss_test:0.09429, lr:1.00e-02, fs:0.69412 (r=0.596,p=0.831),  time:36.040, tt:1657.860\n",
      "Ep:46, loss:0.00006, loss_test:0.08741, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:36.021, tt:1692.967\n",
      "Ep:47, loss:0.00006, loss_test:0.09905, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:36.031, tt:1729.487\n",
      "Ep:48, loss:0.00006, loss_test:0.09009, lr:1.00e-02, fs:0.71264 (r=0.626,p=0.827),  time:36.023, tt:1765.106\n",
      "Ep:49, loss:0.00005, loss_test:0.09404, lr:9.90e-03, fs:0.74194 (r=0.697,p=0.793),  time:36.057, tt:1802.854\n",
      "Ep:50, loss:0.00005, loss_test:0.09385, lr:9.80e-03, fs:0.74346 (r=0.717,p=0.772),  time:36.095, tt:1840.824\n",
      "Ep:51, loss:0.00005, loss_test:0.09032, lr:9.70e-03, fs:0.70857 (r=0.626,p=0.816),  time:36.113, tt:1877.867\n",
      "Ep:52, loss:0.00005, loss_test:0.09691, lr:9.61e-03, fs:0.73016 (r=0.697,p=0.767),  time:36.106, tt:1913.621\n",
      "Ep:53, loss:0.00005, loss_test:0.09440, lr:9.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:36.081, tt:1948.354\n",
      "Ep:54, loss:0.00005, loss_test:0.09018, lr:9.41e-03, fs:0.74444 (r=0.677,p=0.827),  time:36.063, tt:1983.446\n",
      "Ep:55, loss:0.00005, loss_test:0.09585, lr:9.32e-03, fs:0.74227 (r=0.727,p=0.758),  time:36.078, tt:2020.385\n",
      "Ep:56, loss:0.00005, loss_test:0.09253, lr:9.23e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.072, tt:2056.088\n",
      "Ep:57, loss:0.00004, loss_test:0.09161, lr:9.14e-03, fs:0.74194 (r=0.697,p=0.793),  time:36.063, tt:2091.679\n",
      "Ep:58, loss:0.00004, loss_test:0.09207, lr:9.04e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.067, tt:2127.958\n",
      "Ep:59, loss:0.00004, loss_test:0.09062, lr:8.95e-03, fs:0.75138 (r=0.687,p=0.829),  time:36.120, tt:2167.214\n",
      "Ep:60, loss:0.00004, loss_test:0.09301, lr:8.86e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.140, tt:2204.569\n",
      "Ep:61, loss:0.00004, loss_test:0.08826, lr:8.78e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.143, tt:2240.852\n",
      "Ep:62, loss:0.00004, loss_test:0.09465, lr:8.69e-03, fs:0.74595 (r=0.697,p=0.802),  time:36.159, tt:2278.039\n",
      "Ep:63, loss:0.00004, loss_test:0.08759, lr:8.60e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.140, tt:2312.941\n",
      "Ep:64, loss:0.00004, loss_test:0.09162, lr:8.51e-03, fs:0.70520 (r=0.616,p=0.824),  time:36.155, tt:2350.049\n",
      "Ep:65, loss:0.00004, loss_test:0.09400, lr:8.43e-03, fs:0.73404 (r=0.697,p=0.775),  time:36.154, tt:2386.190\n",
      "Ep:66, loss:0.00004, loss_test:0.09017, lr:8.35e-03, fs:0.73446 (r=0.657,p=0.833),  time:36.140, tt:2421.348\n",
      "Ep:67, loss:0.00004, loss_test:0.09102, lr:8.26e-03, fs:0.74595 (r=0.697,p=0.802),  time:36.145, tt:2457.888\n",
      "Ep:68, loss:0.00003, loss_test:0.09016, lr:8.18e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.134, tt:2493.251\n",
      "Ep:69, loss:0.00003, loss_test:0.08898, lr:8.10e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.110, tt:2527.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00003, loss_test:0.09143, lr:8.02e-03, fs:0.75000 (r=0.697,p=0.812),  time:36.109, tt:2563.720\n",
      "Ep:71, loss:0.00003, loss_test:0.08958, lr:7.94e-03, fs:0.75138 (r=0.687,p=0.829),  time:36.109, tt:2599.847\n",
      "Ep:72, loss:0.00003, loss_test:0.08773, lr:7.86e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.090, tt:2634.606\n",
      "Ep:73, loss:0.00003, loss_test:0.09273, lr:7.78e-03, fs:0.74595 (r=0.697,p=0.802),  time:36.091, tt:2670.729\n",
      "Ep:74, loss:0.00003, loss_test:0.08815, lr:7.70e-03, fs:0.74444 (r=0.677,p=0.827),  time:36.061, tt:2704.544\n",
      "Ep:75, loss:0.00003, loss_test:0.08940, lr:7.62e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.037, tt:2738.815\n",
      "Ep:76, loss:0.00003, loss_test:0.09135, lr:7.55e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.033, tt:2774.510\n",
      "Ep:77, loss:0.00003, loss_test:0.08784, lr:7.47e-03, fs:0.73864 (r=0.657,p=0.844),  time:36.037, tt:2810.881\n",
      "Ep:78, loss:0.00003, loss_test:0.09259, lr:7.40e-03, fs:0.74194 (r=0.697,p=0.793),  time:36.032, tt:2846.541\n",
      "Ep:79, loss:0.00003, loss_test:0.08744, lr:7.32e-03, fs:0.71264 (r=0.626,p=0.827),  time:36.036, tt:2882.884\n",
      "Ep:80, loss:0.00003, loss_test:0.08951, lr:7.25e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.023, tt:2917.895\n",
      "Ep:81, loss:0.00003, loss_test:0.08662, lr:7.18e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.014, tt:2953.110\n",
      "Ep:82, loss:0.00003, loss_test:0.09032, lr:7.11e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.024, tt:2989.969\n",
      "Ep:83, loss:0.00003, loss_test:0.08924, lr:7.03e-03, fs:0.77095 (r=0.697,p=0.863),  time:35.996, tt:3023.665\n",
      "Ep:84, loss:0.00003, loss_test:0.08889, lr:6.96e-03, fs:0.75281 (r=0.677,p=0.848),  time:35.965, tt:3057.033\n",
      "Ep:85, loss:0.00003, loss_test:0.08741, lr:6.89e-03, fs:0.75824 (r=0.697,p=0.831),  time:35.940, tt:3090.800\n",
      "Ep:86, loss:0.00003, loss_test:0.08909, lr:6.83e-03, fs:0.77095 (r=0.697,p=0.863),  time:35.937, tt:3126.548\n",
      "Ep:87, loss:0.00002, loss_test:0.08676, lr:6.76e-03, fs:0.76503 (r=0.707,p=0.833),  time:35.915, tt:3160.540\n",
      "Ep:88, loss:0.00002, loss_test:0.09107, lr:6.69e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.911, tt:3196.119\n",
      "Ep:89, loss:0.00002, loss_test:0.08538, lr:6.62e-03, fs:0.76243 (r=0.697,p=0.841),  time:35.886, tt:3229.734\n",
      "Ep:90, loss:0.00002, loss_test:0.09066, lr:6.56e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.876, tt:3264.689\n",
      "Ep:91, loss:0.00002, loss_test:0.08699, lr:6.49e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.854, tt:3298.613\n",
      "Ep:92, loss:0.00002, loss_test:0.08769, lr:6.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.865, tt:3335.475\n",
      "Ep:93, loss:0.00002, loss_test:0.09054, lr:6.36e-03, fs:0.76404 (r=0.687,p=0.861),  time:35.857, tt:3370.539\n",
      "Ep:94, loss:0.00002, loss_test:0.08618, lr:6.30e-03, fs:0.75824 (r=0.697,p=0.831),  time:35.866, tt:3407.279\n",
      "Ep:95, loss:0.00002, loss_test:0.08952, lr:6.24e-03, fs:0.77095 (r=0.697,p=0.863),  time:35.871, tt:3443.603\n",
      "Ep:96, loss:0.00002, loss_test:0.08834, lr:6.17e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.872, tt:3479.597\n",
      "Ep:97, loss:0.00002, loss_test:0.08550, lr:6.11e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.880, tt:3516.196\n",
      "Ep:98, loss:0.00002, loss_test:0.09081, lr:6.05e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.871, tt:3551.252\n",
      "Ep:99, loss:0.00002, loss_test:0.08541, lr:5.99e-03, fs:0.78689 (r=0.727,p=0.857),  time:35.862, tt:3586.235\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.08808, lr:5.99e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.862, tt:3622.084\n",
      "Ep:101, loss:0.00002, loss_test:0.09012, lr:5.99e-03, fs:0.74286 (r=0.657,p=0.855),  time:35.848, tt:3656.471\n",
      "Ep:102, loss:0.00002, loss_test:0.08508, lr:5.99e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.848, tt:3692.350\n",
      "Ep:103, loss:0.00002, loss_test:0.09052, lr:5.99e-03, fs:0.75429 (r=0.667,p=0.868),  time:35.847, tt:3728.106\n",
      "Ep:104, loss:0.00002, loss_test:0.08786, lr:5.99e-03, fs:0.77095 (r=0.697,p=0.863),  time:35.840, tt:3763.204\n",
      "Ep:105, loss:0.00002, loss_test:0.08505, lr:5.99e-03, fs:0.77095 (r=0.697,p=0.863),  time:35.838, tt:3798.786\n",
      "Ep:106, loss:0.00002, loss_test:0.08984, lr:5.99e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.837, tt:3834.517\n",
      "Ep:107, loss:0.00002, loss_test:0.08585, lr:5.99e-03, fs:0.75706 (r=0.677,p=0.859),  time:35.836, tt:3870.284\n",
      "Ep:108, loss:0.00002, loss_test:0.08746, lr:5.99e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.832, tt:3905.668\n",
      "Ep:109, loss:0.00002, loss_test:0.08860, lr:5.99e-03, fs:0.74713 (r=0.657,p=0.867),  time:35.839, tt:3942.267\n",
      "Ep:110, loss:0.00002, loss_test:0.08643, lr:5.99e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.849, tt:3979.242\n",
      "Ep:111, loss:0.00002, loss_test:0.08748, lr:5.93e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.858, tt:4016.117\n",
      "Ep:112, loss:0.00002, loss_test:0.08754, lr:5.87e-03, fs:0.74286 (r=0.657,p=0.855),  time:35.861, tt:4052.344\n",
      "Ep:113, loss:0.00002, loss_test:0.08791, lr:5.81e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.878, tt:4090.104\n",
      "Ep:114, loss:0.00002, loss_test:0.08801, lr:5.75e-03, fs:0.71006 (r=0.606,p=0.857),  time:35.921, tt:4130.875\n",
      "Ep:115, loss:0.00002, loss_test:0.08785, lr:5.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.933, tt:4168.273\n",
      "Ep:116, loss:0.00002, loss_test:0.08704, lr:5.64e-03, fs:0.70238 (r=0.596,p=0.855),  time:35.941, tt:4205.146\n",
      "Ep:117, loss:0.00002, loss_test:0.08995, lr:5.58e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.947, tt:4241.795\n",
      "Ep:118, loss:0.00002, loss_test:0.08576, lr:5.53e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.959, tt:4279.072\n",
      "Ep:119, loss:0.00002, loss_test:0.08991, lr:5.47e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.961, tt:4315.330\n",
      "Ep:120, loss:0.00002, loss_test:0.08653, lr:5.42e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.961, tt:4351.301\n",
      "Ep:121, loss:0.00002, loss_test:0.08866, lr:5.36e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.958, tt:4386.922\n",
      "Ep:122, loss:0.00002, loss_test:0.08657, lr:5.31e-03, fs:0.72515 (r=0.626,p=0.861),  time:35.960, tt:4423.140\n",
      "Ep:123, loss:0.00002, loss_test:0.08844, lr:5.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.971, tt:4460.411\n",
      "Ep:124, loss:0.00002, loss_test:0.08856, lr:5.20e-03, fs:0.71006 (r=0.606,p=0.857),  time:35.981, tt:4497.603\n",
      "Ep:125, loss:0.00002, loss_test:0.08767, lr:5.15e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.983, tt:4533.840\n",
      "Ep:126, loss:0.00002, loss_test:0.08775, lr:5.10e-03, fs:0.73988 (r=0.646,p=0.865),  time:35.985, tt:4570.099\n",
      "Ep:127, loss:0.00002, loss_test:0.08806, lr:5.05e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.990, tt:4606.713\n",
      "Ep:128, loss:0.00002, loss_test:0.08703, lr:5.00e-03, fs:0.74713 (r=0.657,p=0.867),  time:35.999, tt:4643.917\n",
      "Ep:129, loss:0.00001, loss_test:0.08799, lr:4.95e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.008, tt:4681.013\n",
      "Ep:130, loss:0.00001, loss_test:0.08708, lr:4.90e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.015, tt:4717.948\n",
      "Ep:131, loss:0.00001, loss_test:0.08771, lr:4.85e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.014, tt:4753.871\n",
      "Ep:132, loss:0.00001, loss_test:0.08759, lr:4.80e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.035, tt:4792.675\n",
      "Ep:133, loss:0.00001, loss_test:0.08764, lr:4.75e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.030, tt:4828.010\n",
      "Ep:134, loss:0.00001, loss_test:0.08706, lr:4.71e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.030, tt:4864.010\n",
      "Ep:135, loss:0.00001, loss_test:0.08821, lr:4.66e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.038, tt:4901.153\n",
      "Ep:136, loss:0.00001, loss_test:0.08627, lr:4.61e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.048, tt:4938.592\n",
      "Ep:137, loss:0.00001, loss_test:0.08880, lr:4.57e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.044, tt:4974.135\n",
      "Ep:138, loss:0.00001, loss_test:0.08751, lr:4.52e-03, fs:0.72515 (r=0.626,p=0.861),  time:36.047, tt:5010.577\n",
      "Ep:139, loss:0.00001, loss_test:0.08799, lr:4.48e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.050, tt:5047.044\n",
      "Ep:140, loss:0.00001, loss_test:0.08785, lr:4.43e-03, fs:0.72515 (r=0.626,p=0.861),  time:36.055, tt:5083.797\n",
      "Ep:141, loss:0.00001, loss_test:0.08723, lr:4.39e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.052, tt:5119.360\n",
      "Ep:142, loss:0.00001, loss_test:0.08706, lr:4.34e-03, fs:0.72515 (r=0.626,p=0.861),  time:36.051, tt:5155.292\n",
      "Ep:143, loss:0.00001, loss_test:0.08950, lr:4.30e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.050, tt:5191.148\n",
      "Ep:144, loss:0.00001, loss_test:0.08706, lr:4.26e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.058, tt:5228.352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.08727, lr:4.21e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.065, tt:5265.438\n",
      "Ep:146, loss:0.00001, loss_test:0.08839, lr:4.17e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.051, tt:5299.549\n",
      "Ep:147, loss:0.00001, loss_test:0.08809, lr:4.13e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.057, tt:5336.407\n",
      "Ep:148, loss:0.00001, loss_test:0.08706, lr:4.09e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.052, tt:5371.742\n",
      "Ep:149, loss:0.00001, loss_test:0.08776, lr:4.05e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.042, tt:5406.297\n",
      "Ep:150, loss:0.00001, loss_test:0.08786, lr:4.01e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.053, tt:5443.956\n",
      "Ep:151, loss:0.00001, loss_test:0.08690, lr:3.97e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.062, tt:5481.368\n",
      "Ep:152, loss:0.00001, loss_test:0.08729, lr:3.93e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.074, tt:5519.302\n",
      "Ep:153, loss:0.00001, loss_test:0.08812, lr:3.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.071, tt:5554.997\n",
      "Ep:154, loss:0.00001, loss_test:0.08709, lr:3.85e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.072, tt:5591.138\n",
      "Ep:155, loss:0.00001, loss_test:0.08820, lr:3.81e-03, fs:0.76571 (r=0.677,p=0.882),  time:36.067, tt:5626.466\n",
      "Ep:156, loss:0.00001, loss_test:0.08674, lr:3.77e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.052, tt:5660.098\n",
      "Ep:157, loss:0.00001, loss_test:0.08794, lr:3.73e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.053, tt:5696.450\n",
      "Ep:158, loss:0.00001, loss_test:0.08709, lr:3.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.046, tt:5731.262\n",
      "Ep:159, loss:0.00001, loss_test:0.08793, lr:3.66e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.043, tt:5766.957\n",
      "Ep:160, loss:0.00001, loss_test:0.08794, lr:3.62e-03, fs:0.72941 (r=0.626,p=0.873),  time:36.038, tt:5802.156\n",
      "Ep:161, loss:0.00001, loss_test:0.08903, lr:3.59e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.052, tt:5840.402\n",
      "Ep:162, loss:0.00001, loss_test:0.08697, lr:3.55e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.056, tt:5877.122\n",
      "Ep:163, loss:0.00001, loss_test:0.08846, lr:3.52e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.051, tt:5912.425\n",
      "Ep:164, loss:0.00001, loss_test:0.08773, lr:3.48e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.046, tt:5947.637\n",
      "Ep:165, loss:0.00001, loss_test:0.08822, lr:3.45e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.036, tt:5982.017\n",
      "Ep:166, loss:0.00001, loss_test:0.08915, lr:3.41e-03, fs:0.76571 (r=0.677,p=0.882),  time:36.041, tt:6018.765\n",
      "Ep:167, loss:0.00001, loss_test:0.08681, lr:3.38e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.045, tt:6055.493\n",
      "Ep:168, loss:0.00001, loss_test:0.08760, lr:3.34e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.037, tt:6090.280\n",
      "Ep:169, loss:0.00001, loss_test:0.08843, lr:3.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.023, tt:6123.967\n",
      "Ep:170, loss:0.00001, loss_test:0.08688, lr:3.28e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.014, tt:6158.381\n",
      "Ep:171, loss:0.00001, loss_test:0.08819, lr:3.24e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.011, tt:6193.902\n",
      "Ep:172, loss:0.00001, loss_test:0.08801, lr:3.21e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.021, tt:6231.589\n",
      "Ep:173, loss:0.00001, loss_test:0.08676, lr:3.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.014, tt:6266.489\n",
      "Ep:174, loss:0.00001, loss_test:0.08868, lr:3.15e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.015, tt:6302.596\n",
      "Ep:175, loss:0.00001, loss_test:0.08855, lr:3.12e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.006, tt:6337.057\n",
      "Ep:176, loss:0.00001, loss_test:0.08627, lr:3.09e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.003, tt:6372.561\n",
      "Ep:177, loss:0.00001, loss_test:0.08849, lr:3.05e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.003, tt:6408.567\n",
      "Ep:178, loss:0.00001, loss_test:0.08904, lr:3.02e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.999, tt:6443.902\n",
      "Ep:179, loss:0.00001, loss_test:0.08716, lr:2.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.997, tt:6479.437\n",
      "Ep:180, loss:0.00001, loss_test:0.08807, lr:2.96e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.991, tt:6514.455\n",
      "Ep:181, loss:0.00001, loss_test:0.08922, lr:2.93e-03, fs:0.77273 (r=0.687,p=0.883),  time:35.978, tt:6547.909\n",
      "Ep:182, loss:0.00001, loss_test:0.08744, lr:2.90e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.977, tt:6583.849\n",
      "Ep:183, loss:0.00001, loss_test:0.08768, lr:2.88e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.973, tt:6618.987\n",
      "Ep:184, loss:0.00001, loss_test:0.08913, lr:2.85e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.967, tt:6653.897\n",
      "Ep:185, loss:0.00001, loss_test:0.08737, lr:2.82e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.965, tt:6689.461\n",
      "Ep:186, loss:0.00001, loss_test:0.08818, lr:2.79e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.960, tt:6724.565\n",
      "Ep:187, loss:0.00001, loss_test:0.08923, lr:2.76e-03, fs:0.76571 (r=0.677,p=0.882),  time:35.963, tt:6761.102\n",
      "Ep:188, loss:0.00001, loss_test:0.08791, lr:2.73e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.963, tt:6796.928\n",
      "Ep:189, loss:0.00001, loss_test:0.08817, lr:2.71e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.972, tt:6834.656\n",
      "Ep:190, loss:0.00001, loss_test:0.08846, lr:2.68e-03, fs:0.77273 (r=0.687,p=0.883),  time:35.976, tt:6871.394\n",
      "Ep:191, loss:0.00001, loss_test:0.08816, lr:2.65e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.987, tt:6909.422\n",
      "Ep:192, loss:0.00001, loss_test:0.08771, lr:2.63e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.988, tt:6945.628\n",
      "Ep:193, loss:0.00001, loss_test:0.08867, lr:2.60e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.994, tt:6982.815\n",
      "Ep:194, loss:0.00001, loss_test:0.08832, lr:2.57e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.985, tt:7017.123\n",
      "Ep:195, loss:0.00001, loss_test:0.08726, lr:2.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.991, tt:7054.250\n",
      "Ep:196, loss:0.00001, loss_test:0.08908, lr:2.52e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.994, tt:7090.862\n",
      "Ep:197, loss:0.00001, loss_test:0.08821, lr:2.50e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.996, tt:7127.262\n",
      "Ep:198, loss:0.00001, loss_test:0.08795, lr:2.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.005, tt:7164.945\n",
      "Ep:199, loss:0.00001, loss_test:0.08858, lr:2.45e-03, fs:0.77273 (r=0.687,p=0.883),  time:36.014, tt:7202.732\n",
      "Ep:200, loss:0.00001, loss_test:0.08834, lr:2.42e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.026, tt:7241.219\n",
      "Ep:201, loss:0.00001, loss_test:0.08812, lr:2.40e-03, fs:0.77273 (r=0.687,p=0.883),  time:36.040, tt:7280.066\n",
      "Ep:202, loss:0.00001, loss_test:0.08942, lr:2.38e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.044, tt:7316.992\n",
      "Ep:203, loss:0.00001, loss_test:0.08845, lr:2.35e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.055, tt:7355.320\n",
      "Ep:204, loss:0.00001, loss_test:0.08805, lr:2.33e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.061, tt:7392.491\n",
      "Ep:205, loss:0.00001, loss_test:0.08816, lr:2.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.053, tt:7426.905\n",
      "Ep:206, loss:0.00001, loss_test:0.08889, lr:2.28e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.057, tt:7463.743\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14560, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.063, tt:37.063\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14444, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:35.446, tt:70.893\n",
      "Ep:2, loss:0.00027, loss_test:0.14218, lr:1.00e-02, fs:0.65493 (r=0.939,p=0.503),  time:34.869, tt:104.606\n",
      "Ep:3, loss:0.00027, loss_test:0.13851, lr:1.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:35.592, tt:142.366\n",
      "Ep:4, loss:0.00025, loss_test:0.13511, lr:1.00e-02, fs:0.62400 (r=0.788,p=0.517),  time:35.871, tt:179.354\n",
      "Ep:5, loss:0.00024, loss_test:0.13400, lr:1.00e-02, fs:0.60000 (r=0.667,p=0.545),  time:36.440, tt:218.641\n",
      "Ep:6, loss:0.00023, loss_test:0.13383, lr:1.00e-02, fs:0.59686 (r=0.576,p=0.620),  time:36.751, tt:257.255\n",
      "Ep:7, loss:0.00022, loss_test:0.13112, lr:1.00e-02, fs:0.59574 (r=0.566,p=0.629),  time:37.047, tt:296.378\n",
      "Ep:8, loss:0.00021, loss_test:0.12548, lr:1.00e-02, fs:0.61463 (r=0.636,p=0.594),  time:37.072, tt:333.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00020, loss_test:0.12343, lr:1.00e-02, fs:0.61692 (r=0.626,p=0.608),  time:37.186, tt:371.860\n",
      "Ep:10, loss:0.00019, loss_test:0.12448, lr:1.00e-02, fs:0.60317 (r=0.576,p=0.633),  time:37.491, tt:412.399\n",
      "Ep:11, loss:0.00018, loss_test:0.12067, lr:1.00e-02, fs:0.60317 (r=0.576,p=0.633),  time:37.581, tt:450.976\n",
      "Ep:12, loss:0.00018, loss_test:0.11643, lr:9.90e-03, fs:0.61224 (r=0.606,p=0.619),  time:37.536, tt:487.967\n",
      "Ep:13, loss:0.00017, loss_test:0.11523, lr:9.80e-03, fs:0.58696 (r=0.545,p=0.635),  time:37.612, tt:526.562\n",
      "Ep:14, loss:0.00016, loss_test:0.11330, lr:9.70e-03, fs:0.60000 (r=0.545,p=0.667),  time:37.689, tt:565.339\n",
      "Ep:15, loss:0.00016, loss_test:0.10916, lr:9.61e-03, fs:0.62827 (r=0.606,p=0.652),  time:37.668, tt:602.693\n",
      "Ep:16, loss:0.00015, loss_test:0.10711, lr:9.51e-03, fs:0.67725 (r=0.646,p=0.711),  time:37.576, tt:638.788\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10537, lr:9.51e-03, fs:0.68449 (r=0.646,p=0.727),  time:37.581, tt:676.453\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.10320, lr:9.51e-03, fs:0.70157 (r=0.677,p=0.728),  time:37.507, tt:712.638\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.10132, lr:9.51e-03, fs:0.71795 (r=0.707,p=0.729),  time:37.490, tt:749.803\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.09981, lr:9.51e-03, fs:0.72251 (r=0.697,p=0.750),  time:37.472, tt:786.907\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09864, lr:9.51e-03, fs:0.71134 (r=0.697,p=0.726),  time:37.407, tt:822.959\n",
      "Ep:22, loss:0.00012, loss_test:0.09942, lr:9.51e-03, fs:0.72251 (r=0.697,p=0.750),  time:37.409, tt:860.404\n",
      "Ep:23, loss:0.00012, loss_test:0.09783, lr:9.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:37.414, tt:897.931\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09600, lr:9.51e-03, fs:0.75622 (r=0.768,p=0.745),  time:37.494, tt:937.358\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.09749, lr:9.51e-03, fs:0.72251 (r=0.697,p=0.750),  time:37.400, tt:972.390\n",
      "Ep:26, loss:0.00011, loss_test:0.09517, lr:9.51e-03, fs:0.74611 (r=0.727,p=0.766),  time:37.310, tt:1007.377\n",
      "Ep:27, loss:0.00010, loss_test:0.09536, lr:9.51e-03, fs:0.76768 (r=0.768,p=0.768),  time:37.351, tt:1045.816\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.09457, lr:9.51e-03, fs:0.76768 (r=0.768,p=0.768),  time:37.341, tt:1082.888\n",
      "Ep:29, loss:0.00009, loss_test:0.09252, lr:9.51e-03, fs:0.80198 (r=0.818,p=0.786),  time:37.362, tt:1120.853\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.09404, lr:9.51e-03, fs:0.76289 (r=0.747,p=0.779),  time:37.433, tt:1160.437\n",
      "Ep:31, loss:0.00009, loss_test:0.09012, lr:9.51e-03, fs:0.80203 (r=0.798,p=0.806),  time:37.503, tt:1200.089\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08929, lr:9.51e-03, fs:0.81951 (r=0.848,p=0.792),  time:37.521, tt:1238.206\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.08946, lr:9.51e-03, fs:0.83000 (r=0.838,p=0.822),  time:37.719, tt:1282.441\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.08820, lr:9.51e-03, fs:0.83000 (r=0.838,p=0.822),  time:37.649, tt:1317.718\n",
      "Ep:35, loss:0.00007, loss_test:0.08808, lr:9.51e-03, fs:0.85437 (r=0.889,p=0.822),  time:37.696, tt:1357.074\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.08782, lr:9.51e-03, fs:0.82474 (r=0.808,p=0.842),  time:37.680, tt:1394.167\n",
      "Ep:37, loss:0.00007, loss_test:0.08556, lr:9.51e-03, fs:0.84615 (r=0.889,p=0.807),  time:37.650, tt:1430.691\n",
      "Ep:38, loss:0.00007, loss_test:0.08810, lr:9.51e-03, fs:0.81818 (r=0.818,p=0.818),  time:37.647, tt:1468.238\n",
      "Ep:39, loss:0.00006, loss_test:0.08387, lr:9.51e-03, fs:0.85167 (r=0.899,p=0.809),  time:37.568, tt:1502.709\n",
      "Ep:40, loss:0.00006, loss_test:0.09032, lr:9.51e-03, fs:0.80203 (r=0.798,p=0.806),  time:37.537, tt:1539.028\n",
      "Ep:41, loss:0.00006, loss_test:0.08306, lr:9.51e-03, fs:0.85167 (r=0.899,p=0.809),  time:37.536, tt:1576.524\n",
      "Ep:42, loss:0.00006, loss_test:0.08462, lr:9.51e-03, fs:0.85572 (r=0.869,p=0.843),  time:37.507, tt:1612.780\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.08397, lr:9.51e-03, fs:0.84058 (r=0.879,p=0.806),  time:37.595, tt:1654.179\n",
      "Ep:44, loss:0.00005, loss_test:0.08334, lr:9.51e-03, fs:0.86567 (r=0.879,p=0.853),  time:37.585, tt:1691.344\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.08591, lr:9.51e-03, fs:0.82412 (r=0.828,p=0.820),  time:37.552, tt:1727.413\n",
      "Ep:46, loss:0.00005, loss_test:0.08140, lr:9.51e-03, fs:0.85572 (r=0.869,p=0.843),  time:37.501, tt:1762.559\n",
      "Ep:47, loss:0.00005, loss_test:0.08514, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:37.509, tt:1800.430\n",
      "Ep:48, loss:0.00005, loss_test:0.08156, lr:9.51e-03, fs:0.86408 (r=0.899,p=0.832),  time:37.527, tt:1838.814\n",
      "Ep:49, loss:0.00005, loss_test:0.08682, lr:9.51e-03, fs:0.76136 (r=0.677,p=0.870),  time:37.498, tt:1874.901\n",
      "Ep:50, loss:0.00005, loss_test:0.08191, lr:9.51e-03, fs:0.86829 (r=0.899,p=0.840),  time:37.542, tt:1914.656\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.08276, lr:9.51e-03, fs:0.84375 (r=0.818,p=0.871),  time:37.503, tt:1950.164\n",
      "Ep:52, loss:0.00004, loss_test:0.08308, lr:9.51e-03, fs:0.85279 (r=0.848,p=0.857),  time:37.497, tt:1987.348\n",
      "Ep:53, loss:0.00004, loss_test:0.08146, lr:9.51e-03, fs:0.83077 (r=0.818,p=0.844),  time:37.494, tt:2024.680\n",
      "Ep:54, loss:0.00004, loss_test:0.08309, lr:9.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:37.504, tt:2062.743\n",
      "Ep:55, loss:0.00004, loss_test:0.08240, lr:9.51e-03, fs:0.82105 (r=0.788,p=0.857),  time:37.531, tt:2101.758\n",
      "Ep:56, loss:0.00004, loss_test:0.08267, lr:9.51e-03, fs:0.80851 (r=0.768,p=0.854),  time:37.532, tt:2139.341\n",
      "Ep:57, loss:0.00004, loss_test:0.08414, lr:9.51e-03, fs:0.74419 (r=0.646,p=0.877),  time:37.529, tt:2176.680\n",
      "Ep:58, loss:0.00003, loss_test:0.08073, lr:9.51e-03, fs:0.83249 (r=0.828,p=0.837),  time:37.521, tt:2213.748\n",
      "Ep:59, loss:0.00003, loss_test:0.08710, lr:9.51e-03, fs:0.71429 (r=0.606,p=0.870),  time:37.536, tt:2252.147\n",
      "Ep:60, loss:0.00003, loss_test:0.08165, lr:9.51e-03, fs:0.80435 (r=0.747,p=0.871),  time:37.506, tt:2287.837\n",
      "Ep:61, loss:0.00003, loss_test:0.08499, lr:9.51e-03, fs:0.73256 (r=0.636,p=0.863),  time:37.548, tt:2327.960\n",
      "Ep:62, loss:0.00003, loss_test:0.08554, lr:9.41e-03, fs:0.71429 (r=0.606,p=0.870),  time:37.528, tt:2364.252\n",
      "Ep:63, loss:0.00003, loss_test:0.08081, lr:9.32e-03, fs:0.81522 (r=0.758,p=0.882),  time:37.530, tt:2401.915\n",
      "Ep:64, loss:0.00003, loss_test:0.08957, lr:9.23e-03, fs:0.72289 (r=0.606,p=0.896),  time:37.523, tt:2438.970\n",
      "Ep:65, loss:0.00003, loss_test:0.08171, lr:9.14e-03, fs:0.77348 (r=0.707,p=0.854),  time:37.519, tt:2476.243\n",
      "Ep:66, loss:0.00003, loss_test:0.09028, lr:9.04e-03, fs:0.72050 (r=0.586,p=0.935),  time:37.508, tt:2513.042\n",
      "Ep:67, loss:0.00003, loss_test:0.08056, lr:8.95e-03, fs:0.80000 (r=0.727,p=0.889),  time:37.533, tt:2552.245\n",
      "Ep:68, loss:0.00002, loss_test:0.09360, lr:8.86e-03, fs:0.72500 (r=0.586,p=0.951),  time:37.539, tt:2590.213\n",
      "Ep:69, loss:0.00002, loss_test:0.08071, lr:8.78e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.525, tt:2626.717\n",
      "Ep:70, loss:0.00002, loss_test:0.09358, lr:8.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:37.516, tt:2663.631\n",
      "Ep:71, loss:0.00002, loss_test:0.08285, lr:8.60e-03, fs:0.74118 (r=0.636,p=0.887),  time:37.509, tt:2700.634\n",
      "Ep:72, loss:0.00002, loss_test:0.08482, lr:8.51e-03, fs:0.72727 (r=0.606,p=0.909),  time:37.469, tt:2735.248\n",
      "Ep:73, loss:0.00002, loss_test:0.08288, lr:8.43e-03, fs:0.72727 (r=0.606,p=0.909),  time:37.459, tt:2771.995\n",
      "Ep:74, loss:0.00002, loss_test:0.08272, lr:8.35e-03, fs:0.73373 (r=0.626,p=0.886),  time:37.467, tt:2809.990\n",
      "Ep:75, loss:0.00002, loss_test:0.08754, lr:8.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.465, tt:2847.377\n",
      "Ep:76, loss:0.00002, loss_test:0.08257, lr:8.18e-03, fs:0.73373 (r=0.626,p=0.886),  time:37.449, tt:2883.588\n",
      "Ep:77, loss:0.00002, loss_test:0.08301, lr:8.10e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.437, tt:2920.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00002, loss_test:0.08660, lr:8.02e-03, fs:0.73054 (r=0.616,p=0.897),  time:37.447, tt:2958.321\n",
      "Ep:79, loss:0.00002, loss_test:0.08248, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:37.455, tt:2996.385\n",
      "Ep:80, loss:0.00002, loss_test:0.08924, lr:7.86e-03, fs:0.72393 (r=0.596,p=0.922),  time:37.445, tt:3033.050\n",
      "Ep:81, loss:0.00002, loss_test:0.08297, lr:7.78e-03, fs:0.73494 (r=0.616,p=0.910),  time:37.423, tt:3068.710\n",
      "Ep:82, loss:0.00002, loss_test:0.08715, lr:7.70e-03, fs:0.72393 (r=0.596,p=0.922),  time:37.398, tt:3104.028\n",
      "Ep:83, loss:0.00002, loss_test:0.08638, lr:7.62e-03, fs:0.73054 (r=0.616,p=0.897),  time:37.398, tt:3141.442\n",
      "Ep:84, loss:0.00001, loss_test:0.08640, lr:7.55e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.395, tt:3178.566\n",
      "Ep:85, loss:0.00001, loss_test:0.08594, lr:7.47e-03, fs:0.72393 (r=0.596,p=0.922),  time:37.386, tt:3215.196\n",
      "Ep:86, loss:0.00001, loss_test:0.08221, lr:7.40e-03, fs:0.72727 (r=0.606,p=0.909),  time:37.408, tt:3254.475\n",
      "Ep:87, loss:0.00001, loss_test:0.08716, lr:7.32e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.396, tt:3290.838\n",
      "Ep:88, loss:0.00001, loss_test:0.08260, lr:7.25e-03, fs:0.73494 (r=0.616,p=0.910),  time:37.380, tt:3326.830\n",
      "Ep:89, loss:0.00001, loss_test:0.08623, lr:7.18e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.341, tt:3360.651\n",
      "Ep:90, loss:0.00001, loss_test:0.08203, lr:7.11e-03, fs:0.73494 (r=0.616,p=0.910),  time:37.352, tt:3399.052\n",
      "Ep:91, loss:0.00001, loss_test:0.08879, lr:7.03e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.316, tt:3433.116\n",
      "Ep:92, loss:0.00001, loss_test:0.08687, lr:6.96e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.313, tt:3470.068\n",
      "Ep:93, loss:0.00001, loss_test:0.08639, lr:6.89e-03, fs:0.73620 (r=0.606,p=0.938),  time:37.311, tt:3507.252\n",
      "Ep:94, loss:0.00001, loss_test:0.08819, lr:6.83e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.286, tt:3542.157\n",
      "Ep:95, loss:0.00001, loss_test:0.08312, lr:6.76e-03, fs:0.73939 (r=0.616,p=0.924),  time:37.254, tt:3576.348\n",
      "Ep:96, loss:0.00001, loss_test:0.08769, lr:6.69e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.233, tt:3611.624\n",
      "Ep:97, loss:0.00001, loss_test:0.08328, lr:6.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:37.223, tt:3647.869\n",
      "Ep:98, loss:0.00001, loss_test:0.08632, lr:6.56e-03, fs:0.73620 (r=0.606,p=0.938),  time:37.212, tt:3683.978\n",
      "Ep:99, loss:0.00001, loss_test:0.08618, lr:6.49e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.190, tt:3718.961\n",
      "Ep:100, loss:0.00001, loss_test:0.08532, lr:6.43e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.182, tt:3755.413\n",
      "Ep:101, loss:0.00001, loss_test:0.08708, lr:6.36e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.189, tt:3793.301\n",
      "Ep:102, loss:0.00001, loss_test:0.08363, lr:6.30e-03, fs:0.74390 (r=0.616,p=0.938),  time:37.147, tt:3826.115\n",
      "Ep:103, loss:0.00001, loss_test:0.08587, lr:6.24e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.134, tt:3861.954\n",
      "Ep:104, loss:0.00001, loss_test:0.08613, lr:6.17e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.141, tt:3899.761\n",
      "Ep:105, loss:0.00001, loss_test:0.08508, lr:6.11e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.138, tt:3936.641\n",
      "Ep:106, loss:0.00001, loss_test:0.08549, lr:6.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.153, tt:3975.356\n",
      "Ep:107, loss:0.00001, loss_test:0.08405, lr:5.99e-03, fs:0.73939 (r=0.616,p=0.924),  time:37.163, tt:4013.574\n",
      "Ep:108, loss:0.00001, loss_test:0.08606, lr:5.93e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.153, tt:4049.664\n",
      "Ep:109, loss:0.00001, loss_test:0.08548, lr:5.87e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.144, tt:4085.828\n",
      "Ep:110, loss:0.00001, loss_test:0.08439, lr:5.81e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.161, tt:4124.889\n",
      "Ep:111, loss:0.00001, loss_test:0.08601, lr:5.75e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.173, tt:4163.409\n",
      "Ep:112, loss:0.00001, loss_test:0.08471, lr:5.70e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.169, tt:4200.121\n",
      "Ep:113, loss:0.00001, loss_test:0.08459, lr:5.64e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.159, tt:4236.166\n",
      "Ep:114, loss:0.00001, loss_test:0.08548, lr:5.58e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.141, tt:4271.245\n",
      "Ep:115, loss:0.00001, loss_test:0.08451, lr:5.53e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.134, tt:4307.500\n",
      "Ep:116, loss:0.00001, loss_test:0.08662, lr:5.47e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.114, tt:4342.347\n",
      "Ep:117, loss:0.00001, loss_test:0.08738, lr:5.42e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.121, tt:4380.262\n",
      "Ep:118, loss:0.00001, loss_test:0.08419, lr:5.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:37.135, tt:4419.014\n",
      "Ep:119, loss:0.00001, loss_test:0.08639, lr:5.31e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.123, tt:4454.718\n",
      "Ep:120, loss:0.00001, loss_test:0.08675, lr:5.26e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.117, tt:4491.137\n",
      "Ep:121, loss:0.00001, loss_test:0.08530, lr:5.20e-03, fs:0.74074 (r=0.606,p=0.952),  time:37.119, tt:4528.501\n",
      "Ep:122, loss:0.00001, loss_test:0.08718, lr:5.15e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.113, tt:4564.930\n",
      "Ep:123, loss:0.00001, loss_test:0.08609, lr:5.10e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.124, tt:4603.348\n",
      "Ep:124, loss:0.00001, loss_test:0.08510, lr:5.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:37.144, tt:4643.032\n",
      "Ep:125, loss:0.00001, loss_test:0.08778, lr:5.00e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.124, tt:4677.660\n",
      "Ep:126, loss:0.00001, loss_test:0.08590, lr:4.95e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.110, tt:4712.928\n",
      "Ep:127, loss:0.00001, loss_test:0.08569, lr:4.90e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.110, tt:4750.092\n",
      "Ep:128, loss:0.00001, loss_test:0.08749, lr:4.85e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.095, tt:4785.237\n",
      "Ep:129, loss:0.00001, loss_test:0.08556, lr:4.80e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.102, tt:4823.255\n",
      "Ep:130, loss:0.00001, loss_test:0.08591, lr:4.75e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.112, tt:4861.658\n",
      "Ep:131, loss:0.00001, loss_test:0.08726, lr:4.71e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.115, tt:4899.170\n",
      "Ep:132, loss:0.00001, loss_test:0.08546, lr:4.66e-03, fs:0.74534 (r=0.606,p=0.968),  time:37.125, tt:4937.660\n",
      "Ep:133, loss:0.00001, loss_test:0.08660, lr:4.61e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.134, tt:4975.899\n",
      "Ep:134, loss:0.00001, loss_test:0.08666, lr:4.57e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.134, tt:5013.059\n",
      "Ep:135, loss:0.00001, loss_test:0.08626, lr:4.52e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.127, tt:5049.219\n",
      "Ep:136, loss:0.00001, loss_test:0.08617, lr:4.48e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.118, tt:5085.114\n",
      "Ep:137, loss:0.00001, loss_test:0.08722, lr:4.43e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.117, tt:5122.174\n",
      "Ep:138, loss:0.00001, loss_test:0.08664, lr:4.39e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.118, tt:5159.457\n",
      "Ep:139, loss:0.00000, loss_test:0.08646, lr:4.34e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.120, tt:5196.733\n",
      "Ep:140, loss:0.00000, loss_test:0.08748, lr:4.30e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.122, tt:5234.252\n",
      "Ep:141, loss:0.00000, loss_test:0.08727, lr:4.26e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.128, tt:5272.203\n",
      "Ep:142, loss:0.00000, loss_test:0.08653, lr:4.21e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.130, tt:5309.599\n",
      "Ep:143, loss:0.00000, loss_test:0.08699, lr:4.17e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.137, tt:5347.762\n",
      "Ep:144, loss:0.00000, loss_test:0.08655, lr:4.13e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.128, tt:5383.610\n",
      "Ep:145, loss:0.00000, loss_test:0.08710, lr:4.09e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.120, tt:5419.582\n",
      "Ep:146, loss:0.00000, loss_test:0.08641, lr:4.05e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.103, tt:5454.114\n",
      "Ep:147, loss:0.00000, loss_test:0.08688, lr:4.01e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.108, tt:5491.926\n",
      "Ep:148, loss:0.00000, loss_test:0.08618, lr:3.97e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.114, tt:5530.029\n",
      "Ep:149, loss:0.00000, loss_test:0.08754, lr:3.93e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.117, tt:5567.576\n",
      "Ep:150, loss:0.00000, loss_test:0.08751, lr:3.89e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.134, tt:5607.238\n",
      "Ep:151, loss:0.00000, loss_test:0.08611, lr:3.85e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.133, tt:5644.208\n",
      "Ep:152, loss:0.00000, loss_test:0.08809, lr:3.81e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.144, tt:5683.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00000, loss_test:0.08682, lr:3.77e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.155, tt:5721.929\n",
      "Ep:154, loss:0.00000, loss_test:0.08689, lr:3.73e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.163, tt:5760.244\n",
      "Ep:155, loss:0.00000, loss_test:0.08774, lr:3.70e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.188, tt:5801.395\n",
      "Ep:156, loss:0.00000, loss_test:0.08724, lr:3.66e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.188, tt:5838.537\n",
      "Ep:157, loss:0.00000, loss_test:0.08720, lr:3.62e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.194, tt:5876.731\n",
      "Ep:158, loss:0.00000, loss_test:0.08761, lr:3.59e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.196, tt:5914.221\n",
      "Ep:159, loss:0.00000, loss_test:0.08690, lr:3.55e-03, fs:0.73750 (r=0.596,p=0.967),  time:37.192, tt:5950.672\n",
      "Ep:160, loss:0.00000, loss_test:0.08815, lr:3.52e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.192, tt:5987.954\n",
      "Ep:161, loss:0.00000, loss_test:0.08709, lr:3.48e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.187, tt:6024.217\n",
      "Ep:162, loss:0.00000, loss_test:0.08740, lr:3.45e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.195, tt:6062.717\n",
      "Ep:163, loss:0.00000, loss_test:0.08867, lr:3.41e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.187, tt:6098.716\n",
      "Ep:164, loss:0.00000, loss_test:0.08764, lr:3.38e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.189, tt:6136.151\n",
      "Ep:165, loss:0.00000, loss_test:0.08715, lr:3.34e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.179, tt:6171.719\n",
      "Ep:166, loss:0.00000, loss_test:0.08743, lr:3.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.167, tt:6206.930\n",
      "Ep:167, loss:0.00000, loss_test:0.08800, lr:3.28e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.167, tt:6243.973\n",
      "Ep:168, loss:0.00000, loss_test:0.08825, lr:3.24e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.163, tt:6280.585\n",
      "Ep:169, loss:0.00000, loss_test:0.08769, lr:3.21e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.174, tt:6319.599\n",
      "Ep:170, loss:0.00000, loss_test:0.08822, lr:3.18e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.171, tt:6356.205\n",
      "Ep:171, loss:0.00000, loss_test:0.08838, lr:3.15e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.166, tt:6392.635\n",
      "Ep:172, loss:0.00000, loss_test:0.08842, lr:3.12e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.153, tt:6427.518\n",
      "Ep:173, loss:0.00000, loss_test:0.08730, lr:3.09e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.144, tt:6463.038\n",
      "Ep:174, loss:0.00000, loss_test:0.08825, lr:3.05e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.150, tt:6501.332\n",
      "Ep:175, loss:0.00000, loss_test:0.08854, lr:3.02e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.153, tt:6538.842\n",
      "Ep:176, loss:0.00000, loss_test:0.08804, lr:2.99e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.158, tt:6577.049\n",
      "Ep:177, loss:0.00000, loss_test:0.08810, lr:2.96e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.157, tt:6613.999\n",
      "Ep:178, loss:0.00000, loss_test:0.08808, lr:2.93e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.158, tt:6651.302\n",
      "Ep:179, loss:0.00000, loss_test:0.08871, lr:2.90e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.144, tt:6685.909\n",
      "Ep:180, loss:0.00000, loss_test:0.08868, lr:2.88e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.142, tt:6722.644\n",
      "Ep:181, loss:0.00000, loss_test:0.08780, lr:2.85e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.149, tt:6761.071\n",
      "Ep:182, loss:0.00000, loss_test:0.08858, lr:2.82e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.147, tt:6797.978\n",
      "Ep:183, loss:0.00000, loss_test:0.08932, lr:2.79e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.149, tt:6835.386\n",
      "Ep:184, loss:0.00000, loss_test:0.08827, lr:2.76e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.151, tt:6872.937\n",
      "Ep:185, loss:0.00000, loss_test:0.08891, lr:2.73e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.153, tt:6910.376\n",
      "Ep:186, loss:0.00000, loss_test:0.08868, lr:2.71e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.153, tt:6947.535\n",
      "Ep:187, loss:0.00000, loss_test:0.08781, lr:2.68e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.171, tt:6988.081\n",
      "Ep:188, loss:0.00000, loss_test:0.08877, lr:2.65e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.183, tt:7027.570\n",
      "Ep:189, loss:0.00000, loss_test:0.08870, lr:2.63e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.184, tt:7064.981\n",
      "Ep:190, loss:0.00000, loss_test:0.08860, lr:2.60e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.183, tt:7101.881\n",
      "Ep:191, loss:0.00000, loss_test:0.08873, lr:2.57e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.182, tt:7138.944\n",
      "Ep:192, loss:0.00000, loss_test:0.08866, lr:2.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.175, tt:7174.847\n",
      "Ep:193, loss:0.00000, loss_test:0.08830, lr:2.52e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.178, tt:7212.455\n",
      "Ep:194, loss:0.00000, loss_test:0.08879, lr:2.50e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.174, tt:7248.934\n",
      "Ep:195, loss:0.00000, loss_test:0.08891, lr:2.47e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.176, tt:7286.451\n",
      "Ep:196, loss:0.00000, loss_test:0.08887, lr:2.45e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.171, tt:7322.772\n",
      "Ep:197, loss:0.00000, loss_test:0.08891, lr:2.42e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.174, tt:7360.495\n",
      "Ep:198, loss:0.00000, loss_test:0.08905, lr:2.40e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.184, tt:7399.622\n",
      "Ep:199, loss:0.00000, loss_test:0.08925, lr:2.38e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.191, tt:7438.210\n",
      "Ep:200, loss:0.00000, loss_test:0.08955, lr:2.35e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.199, tt:7477.003\n",
      "Ep:201, loss:0.00000, loss_test:0.08886, lr:2.33e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.204, tt:7515.196\n",
      "Ep:202, loss:0.00000, loss_test:0.08911, lr:2.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.208, tt:7553.252\n",
      "Ep:203, loss:0.00000, loss_test:0.08953, lr:2.28e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.221, tt:7593.097\n",
      "Ep:204, loss:0.00000, loss_test:0.08915, lr:2.26e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.215, tt:7629.117\n",
      "Ep:205, loss:0.00000, loss_test:0.08956, lr:2.24e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.208, tt:7664.862\n",
      "Ep:206, loss:0.00000, loss_test:0.08942, lr:2.21e-03, fs:0.72956 (r=0.586,p=0.967),  time:37.200, tt:7700.488\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00087, loss_test:0.01798, lr:1.00e-02, fs:0.69264 (r=0.920,p=0.556),  time:659.882, tt:659.882\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01546, lr:1.00e-02, fs:0.77512 (r=0.931,p=0.664),  time:661.546, tt:1323.091\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01395, lr:1.00e-02, fs:0.81951 (r=0.966,p=0.712),  time:663.568, tt:1990.704\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00049, loss_test:0.01307, lr:1.00e-02, fs:0.82828 (r=0.943,p=0.739),  time:660.420, tt:2641.681\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.01241, lr:1.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:659.916, tt:3299.582\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00039, loss_test:0.01212, lr:1.00e-02, fs:0.85864 (r=0.943,p=0.788),  time:659.227, tt:3955.359\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.01189, lr:1.00e-02, fs:0.86772 (r=0.943,p=0.804),  time:657.259, tt:4600.815\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.01167, lr:1.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:658.123, tt:5264.982\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.01153, lr:1.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:657.674, tt:5919.063\n",
      "Ep:9, loss:0.00026, loss_test:0.01150, lr:1.00e-02, fs:0.87912 (r=0.920,p=0.842),  time:658.202, tt:6582.018\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.01159, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:657.645, tt:7234.097\n",
      "Ep:11, loss:0.00021, loss_test:0.01171, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:656.670, tt:7880.036\n",
      "Ep:12, loss:0.00019, loss_test:0.01186, lr:1.00e-02, fs:0.80000 (r=0.736,p=0.877),  time:656.177, tt:8530.296\n",
      "Ep:13, loss:0.00018, loss_test:0.01204, lr:1.00e-02, fs:0.75000 (r=0.655,p=0.877),  time:655.726, tt:9180.165\n",
      "Ep:14, loss:0.00016, loss_test:0.01227, lr:1.00e-02, fs:0.75168 (r=0.644,p=0.903),  time:655.402, tt:9831.030\n",
      "Ep:15, loss:0.00015, loss_test:0.01259, lr:1.00e-02, fs:0.74830 (r=0.632,p=0.917),  time:655.385, tt:10486.158\n",
      "Ep:16, loss:0.00014, loss_test:0.01285, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:654.847, tt:11132.405\n",
      "Ep:17, loss:0.00012, loss_test:0.01315, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:654.587, tt:11782.565\n",
      "Ep:18, loss:0.00012, loss_test:0.01342, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:654.611, tt:12437.607\n",
      "Ep:19, loss:0.00011, loss_test:0.01369, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:654.317, tt:13086.348\n",
      "Ep:20, loss:0.00010, loss_test:0.01396, lr:1.00e-02, fs:0.74648 (r=0.609,p=0.964),  time:654.083, tt:13735.736\n",
      "Ep:21, loss:0.00009, loss_test:0.01424, lr:9.90e-03, fs:0.71942 (r=0.575,p=0.962),  time:654.100, tt:14390.190\n",
      "Ep:22, loss:0.00009, loss_test:0.01452, lr:9.80e-03, fs:0.70073 (r=0.552,p=0.960),  time:654.101, tt:15044.322\n",
      "Ep:23, loss:0.00008, loss_test:0.01479, lr:9.70e-03, fs:0.68148 (r=0.529,p=0.958),  time:654.440, tt:15706.552\n",
      "Ep:24, loss:0.00008, loss_test:0.01498, lr:9.61e-03, fs:0.67164 (r=0.517,p=0.957),  time:654.444, tt:16361.110\n",
      "Ep:25, loss:0.00007, loss_test:0.01528, lr:9.51e-03, fs:0.66165 (r=0.506,p=0.957),  time:654.996, tt:17029.896\n",
      "Ep:26, loss:0.00007, loss_test:0.01559, lr:9.41e-03, fs:0.66667 (r=0.506,p=0.978),  time:653.740, tt:17650.970\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00079, loss_test:0.01824, lr:1.00e-02, fs:0.69869 (r=0.920,p=0.563),  time:607.539, tt:607.539\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01559, lr:1.00e-02, fs:0.75701 (r=0.931,p=0.638),  time:604.948, tt:1209.897\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.01378, lr:1.00e-02, fs:0.80000 (r=0.920,p=0.708),  time:612.933, tt:1838.799\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.01273, lr:1.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:620.069, tt:2480.277\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01207, lr:1.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:625.422, tt:3127.112\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00035, loss_test:0.01161, lr:1.00e-02, fs:0.86911 (r=0.954,p=0.798),  time:627.632, tt:3765.791\n",
      "Ep:6, loss:0.00032, loss_test:0.01137, lr:1.00e-02, fs:0.88770 (r=0.954,p=0.830),  time:630.594, tt:4414.161\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00028, loss_test:0.01126, lr:1.00e-02, fs:0.89730 (r=0.954,p=0.847),  time:631.309, tt:5050.468\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.01109, lr:1.00e-02, fs:0.90110 (r=0.943,p=0.863),  time:632.591, tt:5693.319\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.01119, lr:1.00e-02, fs:0.88636 (r=0.897,p=0.876),  time:632.196, tt:6321.956\n",
      "Ep:10, loss:0.00021, loss_test:0.01124, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:632.464, tt:6957.100\n",
      "Ep:11, loss:0.00019, loss_test:0.01125, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:632.988, tt:7595.855\n",
      "Ep:12, loss:0.00017, loss_test:0.01132, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:632.733, tt:8225.527\n",
      "Ep:13, loss:0.00016, loss_test:0.01142, lr:1.00e-02, fs:0.80000 (r=0.736,p=0.877),  time:632.692, tt:8857.690\n",
      "Ep:14, loss:0.00015, loss_test:0.01150, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:632.805, tt:9492.069\n",
      "Ep:15, loss:0.00014, loss_test:0.01163, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:632.674, tt:10122.783\n",
      "Ep:16, loss:0.00013, loss_test:0.01174, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:633.467, tt:10768.931\n",
      "Ep:17, loss:0.00012, loss_test:0.01191, lr:1.00e-02, fs:0.79221 (r=0.701,p=0.910),  time:633.769, tt:11407.841\n",
      "Ep:18, loss:0.00011, loss_test:0.01215, lr:1.00e-02, fs:0.75676 (r=0.644,p=0.918),  time:633.840, tt:12042.956\n",
      "Ep:19, loss:0.00010, loss_test:0.01227, lr:1.00e-02, fs:0.73973 (r=0.621,p=0.915),  time:634.053, tt:12681.063\n",
      "Ep:20, loss:0.00010, loss_test:0.01236, lr:9.90e-03, fs:0.72727 (r=0.598,p=0.929),  time:633.903, tt:13311.957\n",
      "Ep:21, loss:0.00009, loss_test:0.01256, lr:9.80e-03, fs:0.71831 (r=0.586,p=0.927),  time:633.630, tt:13939.863\n",
      "Ep:22, loss:0.00008, loss_test:0.01275, lr:9.70e-03, fs:0.71429 (r=0.575,p=0.943),  time:633.581, tt:14572.366\n",
      "Ep:23, loss:0.00008, loss_test:0.01288, lr:9.61e-03, fs:0.71429 (r=0.575,p=0.943),  time:633.265, tt:15198.354\n",
      "Ep:24, loss:0.00008, loss_test:0.01301, lr:9.51e-03, fs:0.71429 (r=0.575,p=0.943),  time:633.241, tt:15831.032\n",
      "Ep:25, loss:0.00007, loss_test:0.01309, lr:9.41e-03, fs:0.71429 (r=0.575,p=0.943),  time:633.175, tt:16462.558\n",
      "Ep:26, loss:0.00007, loss_test:0.01326, lr:9.32e-03, fs:0.71942 (r=0.575,p=0.962),  time:633.230, tt:17097.217\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00076, loss_test:0.01839, lr:1.00e-02, fs:0.68050 (r=0.943,p=0.532),  time:698.248, tt:698.248\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01660, lr:1.00e-02, fs:0.72727 (r=0.874,p=0.623),  time:700.761, tt:1401.521\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01562, lr:1.00e-02, fs:0.75862 (r=0.885,p=0.664),  time:692.800, tt:2078.399\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.01495, lr:1.00e-02, fs:0.77778 (r=0.885,p=0.694),  time:685.853, tt:2743.414\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.01436, lr:1.00e-02, fs:0.78756 (r=0.874,p=0.717),  time:684.884, tt:3424.422\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.01394, lr:1.00e-02, fs:0.81720 (r=0.874,p=0.768),  time:682.272, tt:4093.635\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00043, loss_test:0.01363, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:682.555, tt:4777.888\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.01336, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:682.365, tt:5458.922\n",
      "Ep:8, loss:0.00038, loss_test:0.01308, lr:1.00e-02, fs:0.80925 (r=0.805,p=0.814),  time:680.599, tt:6125.387\n",
      "Ep:9, loss:0.00036, loss_test:0.01288, lr:1.00e-02, fs:0.80925 (r=0.805,p=0.814),  time:679.883, tt:6798.828\n",
      "Ep:10, loss:0.00034, loss_test:0.01270, lr:1.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:679.899, tt:7478.886\n",
      "Ep:11, loss:0.00032, loss_test:0.01254, lr:1.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:678.860, tt:8146.324\n",
      "Ep:12, loss:0.00030, loss_test:0.01247, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:678.630, tt:8822.191\n",
      "Ep:13, loss:0.00029, loss_test:0.01242, lr:1.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:677.576, tt:9486.070\n",
      "Ep:14, loss:0.00027, loss_test:0.01231, lr:1.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:676.518, tt:10147.773\n",
      "Ep:15, loss:0.00026, loss_test:0.01221, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:676.427, tt:10822.824\n",
      "Ep:16, loss:0.00024, loss_test:0.01219, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:676.051, tt:11492.873\n",
      "Ep:17, loss:0.00023, loss_test:0.01214, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:675.614, tt:12161.060\n",
      "Ep:18, loss:0.00022, loss_test:0.01216, lr:9.90e-03, fs:0.81707 (r=0.770,p=0.870),  time:675.835, tt:12840.863\n",
      "Ep:19, loss:0.00021, loss_test:0.01208, lr:9.80e-03, fs:0.81707 (r=0.770,p=0.870),  time:675.819, tt:13516.373\n",
      "Ep:20, loss:0.00020, loss_test:0.01220, lr:9.70e-03, fs:0.80982 (r=0.759,p=0.868),  time:675.858, tt:14193.023\n",
      "Ep:21, loss:0.00019, loss_test:0.01215, lr:9.61e-03, fs:0.81707 (r=0.770,p=0.870),  time:676.018, tt:14872.406\n",
      "Ep:22, loss:0.00018, loss_test:0.01225, lr:9.51e-03, fs:0.81707 (r=0.770,p=0.870),  time:676.052, tt:15549.195\n",
      "Ep:23, loss:0.00017, loss_test:0.01231, lr:9.41e-03, fs:0.82209 (r=0.770,p=0.882),  time:675.807, tt:16219.374\n",
      "Ep:24, loss:0.00016, loss_test:0.01236, lr:9.32e-03, fs:0.82209 (r=0.770,p=0.882),  time:675.778, tt:16894.441\n",
      "Ep:25, loss:0.00016, loss_test:0.01243, lr:9.23e-03, fs:0.83230 (r=0.770,p=0.905),  time:675.956, tt:17574.853\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.01245, lr:9.23e-03, fs:0.83750 (r=0.770,p=0.918),  time:675.941, tt:18250.404\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00078, loss_test:0.01865, lr:1.00e-02, fs:0.68016 (r=0.966,p=0.525),  time:667.597, tt:667.597\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01697, lr:1.00e-02, fs:0.71560 (r=0.897,p=0.595),  time:669.427, tt:1338.854\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00059, loss_test:0.01624, lr:1.00e-02, fs:0.73733 (r=0.920,p=0.615),  time:664.983, tt:1994.949\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00056, loss_test:0.01567, lr:1.00e-02, fs:0.74766 (r=0.920,p=0.630),  time:665.009, tt:2660.035\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00054, loss_test:0.01520, lr:1.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:664.229, tt:3321.146\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00052, loss_test:0.01478, lr:1.00e-02, fs:0.80402 (r=0.920,p=0.714),  time:666.829, tt:4000.973\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00050, loss_test:0.01439, lr:1.00e-02, fs:0.81407 (r=0.931,p=0.723),  time:668.035, tt:4676.246\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00048, loss_test:0.01404, lr:1.00e-02, fs:0.82234 (r=0.931,p=0.736),  time:668.728, tt:5349.828\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00046, loss_test:0.01375, lr:1.00e-02, fs:0.83077 (r=0.931,p=0.750),  time:670.320, tt:6032.880\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.01349, lr:1.00e-02, fs:0.85263 (r=0.931,p=0.786),  time:670.881, tt:6708.809\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.01327, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:676.068, tt:7436.750\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.01305, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:676.555, tt:8118.656\n",
      "Ep:12, loss:0.00039, loss_test:0.01289, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:676.840, tt:8798.916\n",
      "Ep:13, loss:0.00038, loss_test:0.01272, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:676.940, tt:9477.158\n",
      "Ep:14, loss:0.00036, loss_test:0.01260, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:677.377, tt:10160.661\n",
      "Ep:15, loss:0.00035, loss_test:0.01247, lr:1.00e-02, fs:0.84916 (r=0.874,p=0.826),  time:678.303, tt:10852.855\n",
      "Ep:16, loss:0.00034, loss_test:0.01239, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:678.648, tt:11537.008\n",
      "Ep:17, loss:0.00033, loss_test:0.01232, lr:1.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:678.960, tt:12221.275\n",
      "Ep:18, loss:0.00032, loss_test:0.01223, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:679.576, tt:12911.952\n",
      "Ep:19, loss:0.00031, loss_test:0.01221, lr:1.00e-02, fs:0.81395 (r=0.805,p=0.824),  time:679.725, tt:13594.500\n",
      "Ep:20, loss:0.00030, loss_test:0.01214, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:679.377, tt:14266.927\n",
      "Ep:21, loss:0.00029, loss_test:0.01210, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:679.368, tt:14946.090\n",
      "Ep:22, loss:0.00028, loss_test:0.01206, lr:9.90e-03, fs:0.80702 (r=0.793,p=0.821),  time:679.562, tt:15629.933\n",
      "Ep:23, loss:0.00027, loss_test:0.01205, lr:9.80e-03, fs:0.80702 (r=0.793,p=0.821),  time:679.643, tt:16311.420\n",
      "Ep:24, loss:0.00026, loss_test:0.01210, lr:9.70e-03, fs:0.80473 (r=0.782,p=0.829),  time:679.518, tt:16987.952\n",
      "Ep:25, loss:0.00025, loss_test:0.01208, lr:9.61e-03, fs:0.81176 (r=0.793,p=0.831),  time:679.803, tt:17674.868\n",
      "Ep:26, loss:0.00024, loss_test:0.01210, lr:9.51e-03, fs:0.81176 (r=0.793,p=0.831),  time:679.949, tt:18358.611\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.01799, lr:1.00e-02, fs:0.69076 (r=0.989,p=0.531),  time:547.708, tt:547.708\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01596, lr:1.00e-02, fs:0.73362 (r=0.966,p=0.592),  time:546.179, tt:1092.359\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00057, loss_test:0.01472, lr:1.00e-02, fs:0.80000 (r=0.966,p=0.683),  time:545.786, tt:1637.359\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.01399, lr:1.00e-02, fs:0.81951 (r=0.966,p=0.712),  time:547.887, tt:2191.548\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01343, lr:1.00e-02, fs:0.83744 (r=0.977,p=0.733),  time:548.710, tt:2743.552\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.01302, lr:1.00e-02, fs:0.86294 (r=0.977,p=0.773),  time:549.286, tt:3295.714\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.01267, lr:1.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:550.333, tt:3852.331\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.01238, lr:1.00e-02, fs:0.87500 (r=0.966,p=0.800),  time:554.848, tt:4438.780\n",
      "Ep:8, loss:0.00039, loss_test:0.01214, lr:1.00e-02, fs:0.89583 (r=0.989,p=0.819),  time:556.409, tt:5007.684\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.01199, lr:1.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:557.852, tt:5578.518\n",
      "Ep:10, loss:0.00035, loss_test:0.01179, lr:1.00e-02, fs:0.88889 (r=0.966,p=0.824),  time:558.477, tt:6143.249\n",
      "Ep:11, loss:0.00033, loss_test:0.01164, lr:1.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:559.367, tt:6712.408\n",
      "Ep:12, loss:0.00031, loss_test:0.01150, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:560.477, tt:7286.206\n",
      "Ep:13, loss:0.00030, loss_test:0.01140, lr:1.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:560.814, tt:7851.396\n",
      "Ep:14, loss:0.00028, loss_test:0.01128, lr:1.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:561.418, tt:8421.275\n",
      "Ep:15, loss:0.00027, loss_test:0.01121, lr:1.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:561.928, tt:8990.852\n",
      "Ep:16, loss:0.00026, loss_test:0.01111, lr:1.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:562.211, tt:9557.593\n",
      "Ep:17, loss:0.00025, loss_test:0.01109, lr:1.00e-02, fs:0.87778 (r=0.908,p=0.849),  time:563.093, tt:10135.670\n",
      "Ep:18, loss:0.00023, loss_test:0.01100, lr:1.00e-02, fs:0.87778 (r=0.908,p=0.849),  time:563.428, tt:10705.136\n",
      "Ep:19, loss:0.00022, loss_test:0.01103, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:564.067, tt:11281.338\n",
      "Ep:20, loss:0.00021, loss_test:0.01104, lr:9.90e-03, fs:0.88764 (r=0.908,p=0.868),  time:564.421, tt:11852.848\n",
      "Ep:21, loss:0.00020, loss_test:0.01102, lr:9.80e-03, fs:0.89773 (r=0.908,p=0.888),  time:564.866, tt:12427.055\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.01104, lr:9.80e-03, fs:0.89143 (r=0.897,p=0.886),  time:565.087, tt:12996.991\n",
      "Ep:23, loss:0.00019, loss_test:0.01100, lr:9.80e-03, fs:0.89655 (r=0.897,p=0.897),  time:564.785, tt:13554.835\n",
      "Ep:24, loss:0.00018, loss_test:0.01103, lr:9.80e-03, fs:0.90173 (r=0.897,p=0.907),  time:565.189, tt:14129.731\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.01113, lr:9.80e-03, fs:0.90173 (r=0.897,p=0.907),  time:565.032, tt:14690.828\n",
      "Ep:26, loss:0.00017, loss_test:0.01113, lr:9.80e-03, fs:0.89535 (r=0.885,p=0.906),  time:565.169, tt:15259.574\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.02017, lr:1.00e-02, fs:0.66953 (r=0.897,p=0.534),  time:636.574, tt:636.574\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00068, loss_test:0.01559, lr:1.00e-02, fs:0.74208 (r=0.943,p=0.612),  time:635.166, tt:1270.332\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01330, lr:1.00e-02, fs:0.80392 (r=0.943,p=0.701),  time:637.459, tt:1912.376\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00048, loss_test:0.01246, lr:1.00e-02, fs:0.81053 (r=0.885,p=0.748),  time:623.537, tt:2494.150\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01219, lr:1.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:612.361, tt:3061.802\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00033, loss_test:0.01255, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:605.368, tt:3632.207\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00028, loss_test:0.01315, lr:1.00e-02, fs:0.81657 (r=0.793,p=0.841),  time:600.186, tt:4201.301\n",
      "Ep:7, loss:0.00023, loss_test:0.01367, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:596.422, tt:4771.377\n",
      "Ep:8, loss:0.00020, loss_test:0.01423, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:595.013, tt:5355.115\n",
      "Ep:9, loss:0.00017, loss_test:0.01474, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:593.549, tt:5935.487\n",
      "Ep:10, loss:0.00015, loss_test:0.01557, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:591.663, tt:6508.288\n",
      "Ep:11, loss:0.00013, loss_test:0.01605, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:590.450, tt:7085.401\n",
      "Ep:12, loss:0.00011, loss_test:0.01659, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:589.278, tt:7660.619\n",
      "Ep:13, loss:0.00010, loss_test:0.01789, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:588.603, tt:8240.445\n",
      "Ep:14, loss:0.00009, loss_test:0.01870, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:587.638, tt:8814.572\n",
      "Ep:15, loss:0.00008, loss_test:0.02003, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:586.981, tt:9391.700\n",
      "Ep:16, loss:0.00007, loss_test:0.02120, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:586.162, tt:9964.753\n",
      "Ep:17, loss:0.00007, loss_test:0.02179, lr:9.90e-03, fs:0.83750 (r=0.770,p=0.918),  time:585.552, tt:10539.942\n",
      "Ep:18, loss:0.00006, loss_test:0.02275, lr:9.80e-03, fs:0.80769 (r=0.724,p=0.913),  time:584.667, tt:11108.670\n",
      "Ep:19, loss:0.00005, loss_test:0.02364, lr:9.70e-03, fs:0.82803 (r=0.747,p=0.929),  time:584.246, tt:11684.920\n",
      "Ep:20, loss:0.00005, loss_test:0.02493, lr:9.61e-03, fs:0.82581 (r=0.736,p=0.941),  time:583.866, tt:12261.180\n",
      "Ep:21, loss:0.00005, loss_test:0.02546, lr:9.51e-03, fs:0.79470 (r=0.690,p=0.938),  time:583.268, tt:12831.890\n",
      "Ep:22, loss:0.00004, loss_test:0.02640, lr:9.41e-03, fs:0.76190 (r=0.644,p=0.933),  time:583.207, tt:13413.762\n",
      "Ep:23, loss:0.00004, loss_test:0.02710, lr:9.32e-03, fs:0.76712 (r=0.644,p=0.949),  time:582.863, tt:13988.723\n",
      "Ep:24, loss:0.00004, loss_test:0.02798, lr:9.23e-03, fs:0.76712 (r=0.644,p=0.949),  time:582.530, tt:14563.239\n",
      "Ep:25, loss:0.00004, loss_test:0.02842, lr:9.14e-03, fs:0.76712 (r=0.644,p=0.949),  time:581.894, tt:15129.251\n",
      "Ep:26, loss:0.00003, loss_test:0.02939, lr:9.04e-03, fs:0.76712 (r=0.644,p=0.949),  time:581.465, tt:15699.567\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00076, loss_test:0.01644, lr:1.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:669.970, tt:669.970\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00057, loss_test:0.01438, lr:1.00e-02, fs:0.80000 (r=0.966,p=0.683),  time:645.137, tt:1290.274\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.01338, lr:1.00e-02, fs:0.83838 (r=0.954,p=0.748),  time:636.176, tt:1908.527\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.01266, lr:1.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:634.857, tt:2539.428\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.01223, lr:1.00e-02, fs:0.87958 (r=0.966,p=0.808),  time:634.602, tt:3173.008\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.01187, lr:1.00e-02, fs:0.87831 (r=0.954,p=0.814),  time:632.744, tt:3796.466\n",
      "Ep:6, loss:0.00034, loss_test:0.01168, lr:1.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:631.059, tt:4417.410\n",
      "Ep:7, loss:0.00031, loss_test:0.01149, lr:1.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:630.181, tt:5041.447\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.01144, lr:1.00e-02, fs:0.90286 (r=0.908,p=0.898),  time:629.857, tt:5668.711\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.01141, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:629.455, tt:6294.554\n",
      "Ep:10, loss:0.00024, loss_test:0.01131, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:635.366, tt:6989.025\n",
      "Ep:11, loss:0.00022, loss_test:0.01132, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:641.667, tt:7700.000\n",
      "Ep:12, loss:0.00020, loss_test:0.01133, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:645.824, tt:8395.709\n",
      "Ep:13, loss:0.00019, loss_test:0.01141, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:649.996, tt:9099.945\n",
      "Ep:14, loss:0.00017, loss_test:0.01139, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:653.943, tt:9809.139\n",
      "Ep:15, loss:0.00016, loss_test:0.01153, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:657.036, tt:10512.573\n",
      "Ep:16, loss:0.00015, loss_test:0.01165, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:659.812, tt:11216.807\n",
      "Ep:17, loss:0.00014, loss_test:0.01185, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:662.110, tt:11917.974\n",
      "Ep:18, loss:0.00013, loss_test:0.01206, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:664.730, tt:12629.875\n",
      "Ep:19, loss:0.00012, loss_test:0.01217, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:666.690, tt:13333.807\n",
      "Ep:20, loss:0.00011, loss_test:0.01227, lr:9.90e-03, fs:0.84810 (r=0.770,p=0.944),  time:668.263, tt:14033.517\n",
      "Ep:21, loss:0.00011, loss_test:0.01242, lr:9.80e-03, fs:0.84810 (r=0.770,p=0.944),  time:670.127, tt:14742.790\n",
      "Ep:22, loss:0.00010, loss_test:0.01273, lr:9.70e-03, fs:0.84810 (r=0.770,p=0.944),  time:671.719, tt:15449.529\n",
      "Ep:23, loss:0.00009, loss_test:0.01292, lr:9.61e-03, fs:0.84810 (r=0.770,p=0.944),  time:673.289, tt:16158.946\n",
      "Ep:24, loss:0.00009, loss_test:0.01298, lr:9.51e-03, fs:0.84810 (r=0.770,p=0.944),  time:674.776, tt:16869.400\n",
      "Ep:25, loss:0.00008, loss_test:0.01322, lr:9.41e-03, fs:0.85350 (r=0.770,p=0.957),  time:676.048, tt:17577.255\n",
      "Ep:26, loss:0.00008, loss_test:0.01332, lr:9.32e-03, fs:0.85350 (r=0.770,p=0.957),  time:677.005, tt:18279.142\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14041, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.960, tt:44.960\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.13871, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.162, tt:88.324\n",
      "Ep:2, loss:0.00001, loss_test:0.13559, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:42.684, tt:128.051\n",
      "Ep:3, loss:0.00001, loss_test:0.13003, lr:1.00e-02, fs:0.66932 (r=0.966,p=0.512),  time:40.659, tt:162.634\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.12167, lr:1.00e-02, fs:0.67511 (r=0.920,p=0.533),  time:40.292, tt:201.462\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.11326, lr:1.00e-02, fs:0.69565 (r=0.828,p=0.600),  time:40.633, tt:243.797\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.10857, lr:1.00e-02, fs:0.69231 (r=0.724,p=0.663),  time:41.180, tt:288.262\n",
      "Ep:7, loss:0.00001, loss_test:0.10401, lr:1.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:41.563, tt:332.501\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.10309, lr:1.00e-02, fs:0.74146 (r=0.874,p=0.644),  time:42.005, tt:378.044\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.09776, lr:1.00e-02, fs:0.74747 (r=0.851,p=0.667),  time:42.178, tt:421.776\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.09391, lr:1.00e-02, fs:0.75676 (r=0.805,p=0.714),  time:42.551, tt:468.064\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00001, loss_test:0.09071, lr:1.00e-02, fs:0.76757 (r=0.816,p=0.724),  time:42.994, tt:515.924\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00001, loss_test:0.08847, lr:1.00e-02, fs:0.77083 (r=0.851,p=0.705),  time:43.227, tt:561.951\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.08533, lr:1.00e-02, fs:0.81395 (r=0.805,p=0.824),  time:43.370, tt:607.184\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.08321, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:43.585, tt:653.770\n",
      "Ep:15, loss:0.00001, loss_test:0.08141, lr:1.00e-02, fs:0.84444 (r=0.874,p=0.817),  time:43.768, tt:700.282\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.07980, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:43.875, tt:745.873\n",
      "Ep:17, loss:0.00001, loss_test:0.07760, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:43.881, tt:789.865\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.07583, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:43.997, tt:835.951\n",
      "Ep:19, loss:0.00001, loss_test:0.07444, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:44.159, tt:883.170\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.07390, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:44.509, tt:934.685\n",
      "Ep:21, loss:0.00001, loss_test:0.07210, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:44.549, tt:980.075\n",
      "Ep:22, loss:0.00001, loss_test:0.07100, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:44.546, tt:1024.548\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.06964, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:44.622, tt:1070.917\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00001, loss_test:0.06885, lr:1.00e-02, fs:0.87006 (r=0.885,p=0.856),  time:44.716, tt:1117.893\n",
      "Ep:25, loss:0.00001, loss_test:0.06729, lr:1.00e-02, fs:0.88268 (r=0.908,p=0.859),  time:44.823, tt:1165.396\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.06773, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:44.839, tt:1210.647\n",
      "Ep:27, loss:0.00001, loss_test:0.06509, lr:1.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:44.907, tt:1257.402\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.06586, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:44.974, tt:1304.258\n",
      "Ep:29, loss:0.00001, loss_test:0.06454, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:45.025, tt:1350.749\n",
      "Ep:30, loss:0.00000, loss_test:0.06342, lr:1.00e-02, fs:0.86207 (r=0.862,p=0.862),  time:45.026, tt:1395.820\n",
      "Ep:31, loss:0.00000, loss_test:0.06447, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:45.070, tt:1442.247\n",
      "Ep:32, loss:0.00000, loss_test:0.06267, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:45.065, tt:1487.134\n",
      "Ep:33, loss:0.00000, loss_test:0.06265, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:45.067, tt:1532.289\n",
      "Ep:34, loss:0.00000, loss_test:0.06243, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:45.052, tt:1576.815\n",
      "Ep:35, loss:0.00000, loss_test:0.06156, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:45.027, tt:1620.984\n",
      "Ep:36, loss:0.00000, loss_test:0.06257, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:45.019, tt:1665.711\n",
      "Ep:37, loss:0.00000, loss_test:0.06269, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:45.035, tt:1711.332\n",
      "Ep:38, loss:0.00000, loss_test:0.06056, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:45.020, tt:1755.783\n",
      "Ep:39, loss:0.00000, loss_test:0.06459, lr:9.90e-03, fs:0.83019 (r=0.759,p=0.917),  time:45.049, tt:1801.943\n",
      "Ep:40, loss:0.00000, loss_test:0.06072, lr:9.80e-03, fs:0.87273 (r=0.828,p=0.923),  time:45.028, tt:1846.142\n",
      "Ep:41, loss:0.00000, loss_test:0.06028, lr:9.70e-03, fs:0.84524 (r=0.816,p=0.877),  time:45.165, tt:1896.941\n",
      "Ep:42, loss:0.00000, loss_test:0.06184, lr:9.61e-03, fs:0.84277 (r=0.770,p=0.931),  time:45.188, tt:1943.100\n",
      "Ep:43, loss:0.00000, loss_test:0.06274, lr:9.51e-03, fs:0.82051 (r=0.736,p=0.928),  time:45.248, tt:1990.922\n",
      "Ep:44, loss:0.00000, loss_test:0.06036, lr:9.41e-03, fs:0.85000 (r=0.782,p=0.932),  time:45.283, tt:2037.729\n",
      "Ep:45, loss:0.00000, loss_test:0.06218, lr:9.32e-03, fs:0.81818 (r=0.724,p=0.940),  time:45.289, tt:2083.280\n",
      "Ep:46, loss:0.00000, loss_test:0.06042, lr:9.23e-03, fs:0.84277 (r=0.770,p=0.931),  time:45.319, tt:2129.999\n",
      "Ep:47, loss:0.00000, loss_test:0.05970, lr:9.14e-03, fs:0.85535 (r=0.782,p=0.944),  time:45.305, tt:2174.628\n",
      "Ep:48, loss:0.00000, loss_test:0.06158, lr:9.04e-03, fs:0.81579 (r=0.713,p=0.954),  time:45.341, tt:2221.731\n",
      "Ep:49, loss:0.00000, loss_test:0.06032, lr:8.95e-03, fs:0.83333 (r=0.747,p=0.942),  time:45.331, tt:2266.543\n",
      "Ep:50, loss:0.00000, loss_test:0.05988, lr:8.86e-03, fs:0.81818 (r=0.724,p=0.940),  time:45.347, tt:2312.719\n",
      "Ep:51, loss:0.00000, loss_test:0.06022, lr:8.78e-03, fs:0.82353 (r=0.724,p=0.955),  time:45.381, tt:2359.788\n",
      "Ep:52, loss:0.00000, loss_test:0.05943, lr:8.69e-03, fs:0.82353 (r=0.724,p=0.955),  time:45.375, tt:2404.867\n",
      "Ep:53, loss:0.00000, loss_test:0.05929, lr:8.60e-03, fs:0.82353 (r=0.724,p=0.955),  time:45.336, tt:2448.129\n",
      "Ep:54, loss:0.00000, loss_test:0.05972, lr:8.51e-03, fs:0.81579 (r=0.713,p=0.954),  time:45.343, tt:2493.851\n",
      "Ep:55, loss:0.00000, loss_test:0.05986, lr:8.43e-03, fs:0.81579 (r=0.713,p=0.954),  time:45.370, tt:2540.722\n",
      "Ep:56, loss:0.00000, loss_test:0.05745, lr:8.35e-03, fs:0.83871 (r=0.747,p=0.956),  time:45.370, tt:2586.086\n",
      "Ep:57, loss:0.00000, loss_test:0.06017, lr:8.26e-03, fs:0.80795 (r=0.701,p=0.953),  time:45.386, tt:2632.390\n",
      "Ep:58, loss:0.00000, loss_test:0.05871, lr:8.18e-03, fs:0.80795 (r=0.701,p=0.953),  time:45.391, tt:2678.092\n",
      "Ep:59, loss:0.00000, loss_test:0.05818, lr:8.10e-03, fs:0.81579 (r=0.713,p=0.954),  time:45.412, tt:2724.724\n",
      "Ep:60, loss:0.00000, loss_test:0.06036, lr:8.02e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.420, tt:2770.603\n",
      "Ep:61, loss:0.00000, loss_test:0.05956, lr:7.94e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.444, tt:2817.534\n",
      "Ep:62, loss:0.00000, loss_test:0.05901, lr:7.86e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.427, tt:2861.905\n",
      "Ep:63, loss:0.00000, loss_test:0.05907, lr:7.78e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.425, tt:2907.174\n",
      "Ep:64, loss:0.00000, loss_test:0.06054, lr:7.70e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.431, tt:2953.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00000, loss_test:0.05865, lr:7.62e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.449, tt:2999.602\n",
      "Ep:66, loss:0.00000, loss_test:0.06036, lr:7.55e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.449, tt:3045.090\n",
      "Ep:67, loss:0.00000, loss_test:0.06047, lr:7.47e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.476, tt:3092.385\n",
      "Ep:68, loss:0.00000, loss_test:0.05905, lr:7.40e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.460, tt:3136.721\n",
      "Ep:69, loss:0.00000, loss_test:0.06025, lr:7.32e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.428, tt:3179.932\n",
      "Ep:70, loss:0.00000, loss_test:0.05970, lr:7.25e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.425, tt:3225.156\n",
      "Ep:71, loss:0.00000, loss_test:0.06111, lr:7.18e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.415, tt:3269.846\n",
      "Ep:72, loss:0.00000, loss_test:0.05967, lr:7.11e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.433, tt:3316.625\n",
      "Ep:73, loss:0.00000, loss_test:0.06142, lr:7.03e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.427, tt:3361.593\n",
      "Ep:74, loss:0.00000, loss_test:0.06219, lr:6.96e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.460, tt:3409.504\n",
      "Ep:75, loss:0.00000, loss_test:0.05998, lr:6.89e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.477, tt:3456.275\n",
      "Ep:76, loss:0.00000, loss_test:0.06199, lr:6.83e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.483, tt:3502.153\n",
      "Ep:77, loss:0.00000, loss_test:0.06211, lr:6.76e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.455, tt:3545.480\n",
      "Ep:78, loss:0.00000, loss_test:0.06212, lr:6.69e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.435, tt:3589.346\n",
      "Ep:79, loss:0.00000, loss_test:0.06102, lr:6.62e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.430, tt:3634.408\n",
      "Ep:80, loss:0.00000, loss_test:0.06276, lr:6.56e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.432, tt:3679.991\n",
      "Ep:81, loss:0.00000, loss_test:0.06188, lr:6.49e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.426, tt:3724.905\n",
      "Ep:82, loss:0.00000, loss_test:0.06242, lr:6.43e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.413, tt:3769.265\n",
      "Ep:83, loss:0.00000, loss_test:0.06327, lr:6.36e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.422, tt:3815.480\n",
      "Ep:84, loss:0.00000, loss_test:0.06239, lr:6.30e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.437, tt:3862.148\n",
      "Ep:85, loss:0.00000, loss_test:0.06359, lr:6.24e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.424, tt:3906.439\n",
      "Ep:86, loss:0.00000, loss_test:0.06310, lr:6.17e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.431, tt:3952.534\n",
      "Ep:87, loss:0.00000, loss_test:0.06366, lr:6.11e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.414, tt:3996.395\n",
      "Ep:88, loss:0.00000, loss_test:0.06409, lr:6.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:45.414, tt:4041.811\n",
      "Ep:89, loss:0.00000, loss_test:0.06397, lr:5.99e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.427, tt:4088.472\n",
      "Ep:90, loss:0.00000, loss_test:0.06520, lr:5.93e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.449, tt:4135.848\n",
      "Ep:91, loss:0.00000, loss_test:0.06446, lr:5.87e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.448, tt:4181.203\n",
      "Ep:92, loss:0.00000, loss_test:0.06558, lr:5.81e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.441, tt:4226.060\n",
      "Ep:93, loss:0.00000, loss_test:0.06449, lr:5.75e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.467, tt:4273.923\n",
      "Ep:94, loss:0.00000, loss_test:0.06584, lr:5.70e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.450, tt:4317.707\n",
      "Ep:95, loss:0.00000, loss_test:0.06532, lr:5.64e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.431, tt:4361.343\n",
      "Ep:96, loss:0.00000, loss_test:0.06606, lr:5.58e-03, fs:0.81633 (r=0.690,p=1.000),  time:45.428, tt:4406.511\n",
      "Ep:97, loss:0.00000, loss_test:0.06599, lr:5.53e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.448, tt:4453.938\n",
      "Ep:98, loss:0.00000, loss_test:0.06601, lr:5.47e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.442, tt:4498.753\n",
      "Ep:99, loss:0.00000, loss_test:0.06597, lr:5.42e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.483, tt:4548.259\n",
      "Ep:100, loss:0.00000, loss_test:0.06668, lr:5.36e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.499, tt:4595.383\n",
      "Ep:101, loss:0.00000, loss_test:0.06655, lr:5.31e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.513, tt:4642.363\n",
      "Ep:102, loss:0.00000, loss_test:0.06668, lr:5.26e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.510, tt:4687.558\n",
      "Ep:103, loss:0.00000, loss_test:0.06650, lr:5.20e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.504, tt:4732.396\n",
      "Ep:104, loss:0.00000, loss_test:0.06636, lr:5.15e-03, fs:0.80822 (r=0.678,p=1.000),  time:45.508, tt:4778.313\n",
      "Ep:105, loss:0.00000, loss_test:0.06724, lr:5.10e-03, fs:0.80000 (r=0.667,p=1.000),  time:45.492, tt:4822.132\n",
      "Ep:106, loss:0.00000, loss_test:0.06665, lr:5.05e-03, fs:0.79167 (r=0.655,p=1.000),  time:45.492, tt:4867.675\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14327, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.919, tt:44.919\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14197, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.939, tt:91.878\n",
      "Ep:2, loss:0.00001, loss_test:0.13961, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.472, tt:136.416\n",
      "Ep:3, loss:0.00001, loss_test:0.13539, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:45.339, tt:181.355\n",
      "Ep:4, loss:0.00001, loss_test:0.12748, lr:1.00e-02, fs:0.67490 (r=0.943,p=0.526),  time:45.605, tt:228.023\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.11756, lr:1.00e-02, fs:0.71233 (r=0.897,p=0.591),  time:45.745, tt:274.467\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.11138, lr:1.00e-02, fs:0.69613 (r=0.724,p=0.670),  time:45.333, tt:317.329\n",
      "Ep:7, loss:0.00001, loss_test:0.10777, lr:1.00e-02, fs:0.70391 (r=0.724,p=0.685),  time:46.140, tt:369.124\n",
      "Ep:8, loss:0.00001, loss_test:0.10361, lr:1.00e-02, fs:0.75897 (r=0.851,p=0.685),  time:46.221, tt:415.991\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.09962, lr:1.00e-02, fs:0.76289 (r=0.851,p=0.692),  time:46.215, tt:462.155\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.09781, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:46.248, tt:508.731\n",
      "Ep:11, loss:0.00001, loss_test:0.09551, lr:1.00e-02, fs:0.73684 (r=0.724,p=0.750),  time:46.193, tt:554.311\n",
      "Ep:12, loss:0.00001, loss_test:0.09140, lr:1.00e-02, fs:0.77528 (r=0.793,p=0.758),  time:46.174, tt:600.265\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.08720, lr:1.00e-02, fs:0.79545 (r=0.805,p=0.787),  time:46.088, tt:645.236\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.08522, lr:1.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:45.946, tt:689.192\n",
      "Ep:15, loss:0.00001, loss_test:0.08334, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:46.054, tt:736.870\n",
      "Ep:16, loss:0.00001, loss_test:0.08208, lr:1.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:46.044, tt:782.743\n",
      "Ep:17, loss:0.00001, loss_test:0.08036, lr:1.00e-02, fs:0.76364 (r=0.724,p=0.808),  time:46.071, tt:829.282\n",
      "Ep:18, loss:0.00001, loss_test:0.07832, lr:1.00e-02, fs:0.77108 (r=0.736,p=0.810),  time:46.192, tt:877.653\n",
      "Ep:19, loss:0.00001, loss_test:0.07940, lr:1.00e-02, fs:0.77301 (r=0.724,p=0.829),  time:46.079, tt:921.580\n",
      "Ep:20, loss:0.00001, loss_test:0.07822, lr:1.00e-02, fs:0.76543 (r=0.713,p=0.827),  time:46.146, tt:969.068\n",
      "Ep:21, loss:0.00001, loss_test:0.07808, lr:1.00e-02, fs:0.77019 (r=0.713,p=0.838),  time:46.296, tt:1018.507\n",
      "Ep:22, loss:0.00001, loss_test:0.07742, lr:1.00e-02, fs:0.75472 (r=0.690,p=0.833),  time:46.325, tt:1065.482\n",
      "Ep:23, loss:0.00001, loss_test:0.07675, lr:1.00e-02, fs:0.76250 (r=0.701,p=0.836),  time:46.302, tt:1111.238\n",
      "Ep:24, loss:0.00001, loss_test:0.07653, lr:1.00e-02, fs:0.75949 (r=0.690,p=0.845),  time:46.284, tt:1157.093\n",
      "Ep:25, loss:0.00001, loss_test:0.07610, lr:9.90e-03, fs:0.75949 (r=0.690,p=0.845),  time:46.206, tt:1201.349\n",
      "Ep:26, loss:0.00001, loss_test:0.07545, lr:9.80e-03, fs:0.75949 (r=0.690,p=0.845),  time:46.219, tt:1247.925\n",
      "Ep:27, loss:0.00001, loss_test:0.07584, lr:9.70e-03, fs:0.75949 (r=0.690,p=0.845),  time:46.224, tt:1294.273\n",
      "Ep:28, loss:0.00000, loss_test:0.07465, lr:9.61e-03, fs:0.76730 (r=0.701,p=0.847),  time:46.198, tt:1339.735\n",
      "Ep:29, loss:0.00000, loss_test:0.07643, lr:9.51e-03, fs:0.76730 (r=0.701,p=0.847),  time:46.144, tt:1384.319\n",
      "Ep:30, loss:0.00000, loss_test:0.07413, lr:9.41e-03, fs:0.76730 (r=0.701,p=0.847),  time:46.061, tt:1427.893\n",
      "Ep:31, loss:0.00000, loss_test:0.07724, lr:9.32e-03, fs:0.77215 (r=0.701,p=0.859),  time:46.011, tt:1472.353\n",
      "Ep:32, loss:0.00000, loss_test:0.07365, lr:9.23e-03, fs:0.77215 (r=0.701,p=0.859),  time:46.022, tt:1518.724\n",
      "Ep:33, loss:0.00000, loss_test:0.07734, lr:9.14e-03, fs:0.76923 (r=0.690,p=0.870),  time:46.004, tt:1564.146\n",
      "Ep:34, loss:0.00000, loss_test:0.07574, lr:9.04e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.896, tt:1606.354\n",
      "Ep:35, loss:0.00000, loss_test:0.07604, lr:8.95e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.857, tt:1650.865\n",
      "Ep:36, loss:0.00000, loss_test:0.07617, lr:8.86e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.881, tt:1697.585\n",
      "Ep:37, loss:0.00000, loss_test:0.07610, lr:8.78e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.871, tt:1743.108\n",
      "Ep:38, loss:0.00000, loss_test:0.07725, lr:8.69e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.836, tt:1787.619\n",
      "Ep:39, loss:0.00000, loss_test:0.07685, lr:8.60e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.785, tt:1831.418\n",
      "Ep:40, loss:0.00000, loss_test:0.07874, lr:8.51e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.779, tt:1876.957\n",
      "Ep:41, loss:0.00000, loss_test:0.07663, lr:8.43e-03, fs:0.77922 (r=0.690,p=0.896),  time:45.739, tt:1921.049\n",
      "Ep:42, loss:0.00000, loss_test:0.07642, lr:8.35e-03, fs:0.77419 (r=0.690,p=0.882),  time:45.703, tt:1965.239\n",
      "Ep:43, loss:0.00000, loss_test:0.07824, lr:8.26e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.680, tt:2009.910\n",
      "Ep:44, loss:0.00000, loss_test:0.07682, lr:8.18e-03, fs:0.77922 (r=0.690,p=0.896),  time:45.701, tt:2056.529\n",
      "Ep:45, loss:0.00000, loss_test:0.07873, lr:8.10e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.687, tt:2101.583\n",
      "Ep:46, loss:0.00000, loss_test:0.07719, lr:8.02e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.549, tt:2140.819\n",
      "Ep:47, loss:0.00000, loss_test:0.07801, lr:7.94e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.537, tt:2185.762\n",
      "Ep:48, loss:0.00000, loss_test:0.08013, lr:7.86e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.436, tt:2226.354\n",
      "Ep:49, loss:0.00000, loss_test:0.07857, lr:7.78e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.331, tt:2266.547\n",
      "Ep:50, loss:0.00000, loss_test:0.08081, lr:7.70e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.238, tt:2307.150\n",
      "Ep:51, loss:0.00000, loss_test:0.08100, lr:7.62e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.177, tt:2349.192\n",
      "Ep:52, loss:0.00000, loss_test:0.08127, lr:7.55e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.143, tt:2392.572\n",
      "Ep:53, loss:0.00000, loss_test:0.08237, lr:7.47e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.176, tt:2439.492\n",
      "Ep:54, loss:0.00000, loss_test:0.08225, lr:7.40e-03, fs:0.78947 (r=0.690,p=0.923),  time:45.140, tt:2482.709\n",
      "Ep:55, loss:0.00000, loss_test:0.08270, lr:7.32e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.133, tt:2527.440\n",
      "Ep:56, loss:0.00000, loss_test:0.08455, lr:7.25e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.128, tt:2572.315\n",
      "Ep:57, loss:0.00000, loss_test:0.08314, lr:7.18e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.151, tt:2618.738\n",
      "Ep:58, loss:0.00000, loss_test:0.08475, lr:7.11e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.148, tt:2663.756\n",
      "Ep:59, loss:0.00000, loss_test:0.08452, lr:7.03e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.155, tt:2709.295\n",
      "Ep:60, loss:0.00000, loss_test:0.08554, lr:6.96e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.154, tt:2754.400\n",
      "Ep:61, loss:0.00000, loss_test:0.08570, lr:6.89e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.145, tt:2799.020\n",
      "Ep:62, loss:0.00000, loss_test:0.08657, lr:6.83e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.163, tt:2845.263\n",
      "Ep:63, loss:0.00000, loss_test:0.08575, lr:6.76e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.155, tt:2889.941\n",
      "Ep:64, loss:0.00000, loss_test:0.08649, lr:6.69e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.154, tt:2934.981\n",
      "Ep:65, loss:0.00000, loss_test:0.08621, lr:6.62e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.173, tt:2981.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00000, loss_test:0.08637, lr:6.56e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.181, tt:3027.159\n",
      "Ep:67, loss:0.00000, loss_test:0.08682, lr:6.49e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.192, tt:3073.059\n",
      "Ep:68, loss:0.00000, loss_test:0.08677, lr:6.43e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.216, tt:3119.870\n",
      "Ep:69, loss:0.00000, loss_test:0.08703, lr:6.36e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.202, tt:3164.164\n",
      "Ep:70, loss:0.00000, loss_test:0.08696, lr:6.30e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.213, tt:3210.149\n",
      "Ep:71, loss:0.00000, loss_test:0.08768, lr:6.24e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.190, tt:3253.683\n",
      "Ep:72, loss:0.00000, loss_test:0.08693, lr:6.17e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.197, tt:3299.374\n",
      "Ep:73, loss:0.00000, loss_test:0.08789, lr:6.11e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.212, tt:3345.697\n",
      "Ep:74, loss:0.00000, loss_test:0.08696, lr:6.05e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.211, tt:3390.812\n",
      "Ep:75, loss:0.00000, loss_test:0.08719, lr:5.99e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.201, tt:3435.312\n",
      "Ep:76, loss:0.00000, loss_test:0.08749, lr:5.93e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.217, tt:3481.692\n",
      "Ep:77, loss:0.00000, loss_test:0.08725, lr:5.87e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.209, tt:3526.290\n",
      "Ep:78, loss:0.00000, loss_test:0.08702, lr:5.81e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.211, tt:3571.662\n",
      "Ep:79, loss:0.00000, loss_test:0.08713, lr:5.75e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.201, tt:3616.081\n",
      "Ep:80, loss:0.00000, loss_test:0.08690, lr:5.70e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.206, tt:3661.700\n",
      "Ep:81, loss:0.00000, loss_test:0.08742, lr:5.64e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.172, tt:3704.096\n",
      "Ep:82, loss:0.00000, loss_test:0.08700, lr:5.58e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.175, tt:3749.507\n",
      "Ep:83, loss:0.00000, loss_test:0.08783, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.180, tt:3795.138\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00000, loss_test:0.08705, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.174, tt:3839.821\n",
      "Ep:85, loss:0.00000, loss_test:0.08777, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.225, tt:3889.339\n",
      "Ep:86, loss:0.00000, loss_test:0.08770, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.226, tt:3934.628\n",
      "Ep:87, loss:0.00000, loss_test:0.08770, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.213, tt:3978.739\n",
      "Ep:88, loss:0.00000, loss_test:0.08844, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.207, tt:4023.387\n",
      "Ep:89, loss:0.00000, loss_test:0.08793, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.214, tt:4069.254\n",
      "Ep:90, loss:0.00000, loss_test:0.08878, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.236, tt:4116.505\n",
      "Ep:91, loss:0.00000, loss_test:0.08807, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.250, tt:4163.005\n",
      "Ep:92, loss:0.00000, loss_test:0.08926, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.245, tt:4207.800\n",
      "Ep:93, loss:0.00000, loss_test:0.08877, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.243, tt:4252.847\n",
      "Ep:94, loss:0.00000, loss_test:0.08915, lr:5.53e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.242, tt:4297.958\n",
      "Ep:95, loss:0.00000, loss_test:0.08920, lr:5.47e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.214, tt:4340.502\n",
      "Ep:96, loss:0.00000, loss_test:0.08971, lr:5.42e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.201, tt:4384.516\n",
      "Ep:97, loss:0.00000, loss_test:0.08989, lr:5.36e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.209, tt:4430.439\n",
      "Ep:98, loss:0.00000, loss_test:0.08957, lr:5.31e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.234, tt:4478.130\n",
      "Ep:99, loss:0.00000, loss_test:0.09044, lr:5.26e-03, fs:0.80000 (r=0.690,p=0.952),  time:45.264, tt:4526.417\n",
      "Ep:100, loss:0.00000, loss_test:0.08965, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.256, tt:4570.872\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00000, loss_test:0.09047, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.288, tt:4619.411\n",
      "Ep:102, loss:0.00000, loss_test:0.08930, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.284, tt:4664.263\n",
      "Ep:103, loss:0.00000, loss_test:0.09014, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.273, tt:4708.365\n",
      "Ep:104, loss:0.00000, loss_test:0.09033, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.282, tt:4754.585\n",
      "Ep:105, loss:0.00000, loss_test:0.08965, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.269, tt:4798.516\n",
      "Ep:106, loss:0.00000, loss_test:0.09032, lr:5.20e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.278, tt:4844.743\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00351, loss_test:0.11615, lr:4.00e-03, fs:0.66986 (r=0.707,p=0.636),  time:577.551, tt:577.551\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00254, loss_test:0.09598, lr:4.00e-03, fs:0.77720 (r=0.758,p=0.798),  time:579.779, tt:1159.558\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00184, loss_test:0.09151, lr:4.00e-03, fs:0.75676 (r=0.707,p=0.814),  time:579.406, tt:1738.219\n",
      "Ep:3, loss:0.00132, loss_test:0.09034, lr:4.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:579.817, tt:2319.268\n",
      "Ep:4, loss:0.00093, loss_test:0.09171, lr:4.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:580.355, tt:2901.773\n",
      "Ep:5, loss:0.00062, loss_test:0.09178, lr:4.00e-03, fs:0.78613 (r=0.687,p=0.919),  time:581.386, tt:3488.315\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00041, loss_test:0.09746, lr:4.00e-03, fs:0.80473 (r=0.687,p=0.971),  time:583.073, tt:4081.511\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00027, loss_test:0.09888, lr:4.00e-03, fs:0.80240 (r=0.677,p=0.985),  time:584.317, tt:4674.539\n",
      "Ep:8, loss:0.00017, loss_test:0.09891, lr:4.00e-03, fs:0.80240 (r=0.677,p=0.985),  time:584.466, tt:5260.197\n",
      "Ep:9, loss:0.00011, loss_test:0.09977, lr:4.00e-03, fs:0.80240 (r=0.677,p=0.985),  time:584.403, tt:5844.033\n",
      "Ep:10, loss:0.00008, loss_test:0.09941, lr:4.00e-03, fs:0.80240 (r=0.677,p=0.985),  time:580.736, tt:6388.096\n",
      "Ep:11, loss:0.00006, loss_test:0.10191, lr:4.00e-03, fs:0.80723 (r=0.677,p=1.000),  time:576.007, tt:6912.088\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.10456, lr:4.00e-03, fs:0.80723 (r=0.677,p=1.000),  time:572.491, tt:7442.389\n",
      "Ep:13, loss:0.00004, loss_test:0.10080, lr:4.00e-03, fs:0.80723 (r=0.677,p=1.000),  time:569.334, tt:7970.675\n",
      "Ep:14, loss:0.00003, loss_test:0.10223, lr:4.00e-03, fs:0.80723 (r=0.677,p=1.000),  time:566.742, tt:8501.130\n",
      "Ep:15, loss:0.00003, loss_test:0.10284, lr:4.00e-03, fs:0.80723 (r=0.677,p=1.000),  time:564.417, tt:9030.666\n",
      "Ep:16, loss:0.00002, loss_test:0.10115, lr:4.00e-03, fs:0.80723 (r=0.677,p=1.000),  time:558.367, tt:9492.243\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14354, lr:4.00e-03, fs:0.66892 (r=1.000,p=0.503),  time:76.316, tt:76.316\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.14169, lr:4.00e-03, fs:0.66892 (r=1.000,p=0.503),  time:79.024, tt:158.048\n",
      "Ep:2, loss:0.00052, loss_test:0.13793, lr:4.00e-03, fs:0.67596 (r=0.980,p=0.516),  time:80.442, tt:241.327\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00049, loss_test:0.13155, lr:4.00e-03, fs:0.60833 (r=0.737,p=0.518),  time:80.593, tt:322.371\n",
      "Ep:4, loss:0.00045, loss_test:0.13179, lr:4.00e-03, fs:0.52222 (r=0.475,p=0.580),  time:81.061, tt:405.306\n",
      "Ep:5, loss:0.00044, loss_test:0.13001, lr:4.00e-03, fs:0.58586 (r=0.586,p=0.586),  time:80.935, tt:485.612\n",
      "Ep:6, loss:0.00042, loss_test:0.12961, lr:4.00e-03, fs:0.58291 (r=0.586,p=0.580),  time:81.152, tt:568.062\n",
      "Ep:7, loss:0.00040, loss_test:0.13053, lr:4.00e-03, fs:0.56216 (r=0.525,p=0.605),  time:81.176, tt:649.404\n",
      "Ep:8, loss:0.00039, loss_test:0.12811, lr:4.00e-03, fs:0.58065 (r=0.545,p=0.621),  time:81.738, tt:735.643\n",
      "Ep:9, loss:0.00037, loss_test:0.12464, lr:4.00e-03, fs:0.59686 (r=0.576,p=0.620),  time:81.764, tt:817.638\n",
      "Ep:10, loss:0.00035, loss_test:0.12662, lr:4.00e-03, fs:0.58101 (r=0.525,p=0.650),  time:82.079, tt:902.873\n",
      "Ep:11, loss:0.00034, loss_test:0.12531, lr:4.00e-03, fs:0.58889 (r=0.535,p=0.654),  time:82.110, tt:985.321\n",
      "Ep:12, loss:0.00032, loss_test:0.12556, lr:4.00e-03, fs:0.59770 (r=0.525,p=0.693),  time:82.050, tt:1066.645\n",
      "Ep:13, loss:0.00031, loss_test:0.12307, lr:4.00e-03, fs:0.59429 (r=0.525,p=0.684),  time:82.147, tt:1150.054\n",
      "Ep:14, loss:0.00030, loss_test:0.12279, lr:3.96e-03, fs:0.60465 (r=0.525,p=0.712),  time:82.361, tt:1235.420\n",
      "Ep:15, loss:0.00028, loss_test:0.12175, lr:3.92e-03, fs:0.60819 (r=0.525,p=0.722),  time:82.351, tt:1317.620\n",
      "Ep:16, loss:0.00027, loss_test:0.12021, lr:3.88e-03, fs:0.61988 (r=0.535,p=0.736),  time:82.402, tt:1400.826\n",
      "Ep:17, loss:0.00026, loss_test:0.11960, lr:3.84e-03, fs:0.60355 (r=0.515,p=0.729),  time:82.093, tt:1477.674\n",
      "Ep:18, loss:0.00025, loss_test:0.11791, lr:3.80e-03, fs:0.62353 (r=0.535,p=0.746),  time:81.768, tt:1553.597\n",
      "Ep:19, loss:0.00024, loss_test:0.11837, lr:3.77e-03, fs:0.60714 (r=0.515,p=0.739),  time:81.842, tt:1636.844\n",
      "Ep:20, loss:0.00023, loss_test:0.11585, lr:3.73e-03, fs:0.62722 (r=0.535,p=0.757),  time:82.153, tt:1725.211\n",
      "Ep:21, loss:0.00022, loss_test:0.11511, lr:3.69e-03, fs:0.61905 (r=0.525,p=0.754),  time:82.248, tt:1809.462\n",
      "Ep:22, loss:0.00021, loss_test:0.11662, lr:3.65e-03, fs:0.60606 (r=0.505,p=0.758),  time:82.378, tt:1894.704\n",
      "Ep:23, loss:0.00020, loss_test:0.11287, lr:3.62e-03, fs:0.62275 (r=0.525,p=0.765),  time:82.529, tt:1980.699\n",
      "Ep:24, loss:0.00020, loss_test:0.11708, lr:3.58e-03, fs:0.60606 (r=0.505,p=0.758),  time:82.501, tt:2062.526\n",
      "Ep:25, loss:0.00019, loss_test:0.11708, lr:3.55e-03, fs:0.59259 (r=0.485,p=0.762),  time:82.602, tt:2147.645\n",
      "Ep:26, loss:0.00018, loss_test:0.11494, lr:3.51e-03, fs:0.60123 (r=0.495,p=0.766),  time:82.536, tt:2228.482\n",
      "Ep:27, loss:0.00017, loss_test:0.11320, lr:3.47e-03, fs:0.61818 (r=0.515,p=0.773),  time:82.354, tt:2305.917\n",
      "Ep:28, loss:0.00016, loss_test:0.11618, lr:3.44e-03, fs:0.60494 (r=0.495,p=0.778),  time:82.451, tt:2391.083\n",
      "Ep:29, loss:0.00016, loss_test:0.11052, lr:3.41e-03, fs:0.60123 (r=0.495,p=0.766),  time:82.472, tt:2474.162\n",
      "Ep:30, loss:0.00015, loss_test:0.11377, lr:3.37e-03, fs:0.60494 (r=0.495,p=0.778),  time:82.592, tt:2560.342\n",
      "Ep:31, loss:0.00014, loss_test:0.11525, lr:3.34e-03, fs:0.60494 (r=0.495,p=0.778),  time:82.551, tt:2641.621\n",
      "Ep:32, loss:0.00014, loss_test:0.11295, lr:3.30e-03, fs:0.60494 (r=0.495,p=0.778),  time:82.601, tt:2725.824\n",
      "Ep:33, loss:0.00013, loss_test:0.11601, lr:3.27e-03, fs:0.60870 (r=0.495,p=0.790),  time:82.654, tt:2810.248\n",
      "Ep:34, loss:0.00012, loss_test:0.11180, lr:3.24e-03, fs:0.60494 (r=0.495,p=0.778),  time:82.707, tt:2894.742\n",
      "Ep:35, loss:0.00012, loss_test:0.10984, lr:3.21e-03, fs:0.61350 (r=0.505,p=0.781),  time:82.693, tt:2976.951\n",
      "Ep:36, loss:0.00011, loss_test:0.11924, lr:3.17e-03, fs:0.62112 (r=0.505,p=0.806),  time:82.705, tt:3060.086\n",
      "Ep:37, loss:0.00011, loss_test:0.11208, lr:3.14e-03, fs:0.62112 (r=0.505,p=0.806),  time:82.767, tt:3145.149\n",
      "Ep:38, loss:0.00010, loss_test:0.10959, lr:3.11e-03, fs:0.62500 (r=0.505,p=0.820),  time:82.692, tt:3225.005\n",
      "Ep:39, loss:0.00010, loss_test:0.11323, lr:3.08e-03, fs:0.62893 (r=0.505,p=0.833),  time:82.833, tt:3313.312\n",
      "Ep:40, loss:0.00009, loss_test:0.11801, lr:3.05e-03, fs:0.64103 (r=0.505,p=0.877),  time:82.896, tt:3398.751\n",
      "Ep:41, loss:0.00009, loss_test:0.11416, lr:3.02e-03, fs:0.63694 (r=0.505,p=0.862),  time:82.919, tt:3482.607\n",
      "Ep:42, loss:0.00008, loss_test:0.11136, lr:2.99e-03, fs:0.63694 (r=0.505,p=0.862),  time:82.933, tt:3566.130\n",
      "Ep:43, loss:0.00008, loss_test:0.11539, lr:2.96e-03, fs:0.64516 (r=0.505,p=0.893),  time:82.953, tt:3649.922\n",
      "Ep:44, loss:0.00007, loss_test:0.11485, lr:2.93e-03, fs:0.65359 (r=0.505,p=0.926),  time:83.019, tt:3735.858\n",
      "Ep:45, loss:0.00007, loss_test:0.12212, lr:2.90e-03, fs:0.66667 (r=0.505,p=0.980),  time:83.028, tt:3819.282\n",
      "Ep:46, loss:0.00007, loss_test:0.11144, lr:2.87e-03, fs:0.64935 (r=0.505,p=0.909),  time:83.024, tt:3902.112\n",
      "Ep:47, loss:0.00006, loss_test:0.11790, lr:2.84e-03, fs:0.65789 (r=0.505,p=0.943),  time:83.082, tt:3987.931\n",
      "Ep:48, loss:0.00006, loss_test:0.11749, lr:2.81e-03, fs:0.65789 (r=0.505,p=0.943),  time:83.119, tt:4072.820\n",
      "Ep:49, loss:0.00006, loss_test:0.11751, lr:2.79e-03, fs:0.66225 (r=0.505,p=0.962),  time:83.154, tt:4157.677\n",
      "Ep:50, loss:0.00005, loss_test:0.11569, lr:2.76e-03, fs:0.66225 (r=0.505,p=0.962),  time:83.166, tt:4241.452\n",
      "Ep:51, loss:0.00005, loss_test:0.11490, lr:2.73e-03, fs:0.65789 (r=0.505,p=0.943),  time:83.206, tt:4326.688\n",
      "Ep:52, loss:0.00005, loss_test:0.11777, lr:2.70e-03, fs:0.66667 (r=0.505,p=0.980),  time:83.195, tt:4409.314\n",
      "Ep:53, loss:0.00005, loss_test:0.11708, lr:2.68e-03, fs:0.66225 (r=0.505,p=0.962),  time:83.197, tt:4492.658\n",
      "Ep:54, loss:0.00004, loss_test:0.11633, lr:2.65e-03, fs:0.66225 (r=0.505,p=0.962),  time:83.050, tt:4567.741\n",
      "Ep:55, loss:0.00004, loss_test:0.11527, lr:2.62e-03, fs:0.65789 (r=0.505,p=0.943),  time:82.836, tt:4638.821\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"8-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00408, loss_test:0.09529, lr:4.00e-03, fs:0.72727 (r=0.687,p=0.773),  time:749.428, tt:749.428\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00277, loss_test:0.08720, lr:4.00e-03, fs:0.75269 (r=0.707,p=0.805),  time:754.375, tt:1508.749\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00207, loss_test:0.07792, lr:4.00e-03, fs:0.79381 (r=0.778,p=0.811),  time:755.510, tt:2266.529\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00152, loss_test:0.07136, lr:4.00e-03, fs:0.83060 (r=0.768,p=0.905),  time:754.858, tt:3019.431\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00109, loss_test:0.06690, lr:4.00e-03, fs:0.83978 (r=0.768,p=0.927),  time:755.379, tt:3776.897\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00077, loss_test:0.06304, lr:4.00e-03, fs:0.85393 (r=0.768,p=0.962),  time:754.849, tt:4529.095\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00055, loss_test:0.06900, lr:4.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:752.740, tt:5269.183\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.07403, lr:4.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:751.234, tt:6009.874\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.06919, lr:4.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:749.156, tt:6742.406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3e454223b95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"8-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00402, loss_test:0.08934, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:746.420, tt:746.420\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00217, loss_test:0.07468, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:752.316, tt:1504.632\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00108, loss_test:0.06311, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:751.973, tt:2255.919\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.06801, lr:1.00e-02, fs:0.86364 (r=0.768,p=0.987),  time:751.881, tt:3007.524\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.07148, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:750.992, tt:3754.962\n",
      "Ep:5, loss:0.00011, loss_test:0.07738, lr:1.00e-02, fs:0.80723 (r=0.677,p=1.000),  time:750.653, tt:4503.921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d361f6211f5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"8-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00402, loss_test:0.08991, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:737.415, tt:737.415\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00219, loss_test:0.07071, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:748.825, tt:1497.650\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00109, loss_test:0.07687, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:751.729, tt:2255.186\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.07338, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:751.918, tt:3007.671\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.07990, lr:1.00e-02, fs:0.86857 (r=0.768,p=1.000),  time:756.212, tt:3781.061\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00010, loss_test:0.08371, lr:1.00e-02, fs:0.86207 (r=0.758,p=1.000),  time:757.086, tt:4542.515\n",
      "Ep:6, loss:0.00005, loss_test:0.08163, lr:1.00e-02, fs:0.86857 (r=0.768,p=1.000),  time:756.028, tt:5292.194\n",
      "Ep:7, loss:0.00003, loss_test:0.08255, lr:1.00e-02, fs:0.86857 (r=0.768,p=1.000),  time:754.777, tt:6038.212\n",
      "Ep:8, loss:0.00003, loss_test:0.08183, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:752.131, tt:6769.181\n",
      "Ep:9, loss:0.00002, loss_test:0.08027, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:750.902, tt:7509.017\n",
      "Ep:10, loss:0.00002, loss_test:0.08285, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:749.264, tt:8241.905\n",
      "Ep:11, loss:0.00002, loss_test:0.08093, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:750.325, tt:9003.904\n",
      "Ep:12, loss:0.00001, loss_test:0.08189, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:751.328, tt:9767.260\n",
      "Ep:13, loss:0.00001, loss_test:0.08190, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:751.293, tt:10518.101\n",
      "Ep:14, loss:0.00001, loss_test:0.08224, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:752.327, tt:11284.908\n",
      "Ep:15, loss:0.00001, loss_test:0.08108, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:752.553, tt:12040.847\n",
      "Ep:16, loss:0.00001, loss_test:0.08161, lr:9.90e-03, fs:0.83529 (r=0.717,p=1.000),  time:752.434, tt:12791.376\n",
      "Ep:17, loss:0.00001, loss_test:0.08121, lr:9.80e-03, fs:0.83529 (r=0.717,p=1.000),  time:752.997, tt:13553.943\n",
      "Ep:18, loss:0.00001, loss_test:0.08114, lr:9.70e-03, fs:0.83529 (r=0.717,p=1.000),  time:753.700, tt:14320.297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14395, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.105, tt:19.105\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14355, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.381, tt:38.762\n",
      "Ep:2, loss:0.00004, loss_test:0.14291, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:19.694, tt:59.081\n",
      "Ep:3, loss:0.00004, loss_test:0.14199, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:19.260, tt:77.040\n",
      "Ep:4, loss:0.00004, loss_test:0.14074, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:19.255, tt:96.275\n",
      "Ep:5, loss:0.00004, loss_test:0.13906, lr:1.00e-02, fs:0.64789 (r=0.929,p=0.497),  time:19.549, tt:117.293\n",
      "Ep:6, loss:0.00004, loss_test:0.13714, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:19.577, tt:137.041\n",
      "Ep:7, loss:0.00004, loss_test:0.13504, lr:1.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:19.641, tt:157.125\n",
      "Ep:8, loss:0.00003, loss_test:0.13236, lr:1.00e-02, fs:0.65560 (r=0.798,p=0.556),  time:19.602, tt:176.420\n",
      "Ep:9, loss:0.00003, loss_test:0.13060, lr:1.00e-02, fs:0.63594 (r=0.697,p=0.585),  time:19.608, tt:196.079\n",
      "Ep:10, loss:0.00003, loss_test:0.12988, lr:1.00e-02, fs:0.62069 (r=0.636,p=0.606),  time:19.870, tt:218.570\n",
      "Ep:11, loss:0.00003, loss_test:0.13135, lr:1.00e-02, fs:0.62887 (r=0.616,p=0.642),  time:19.966, tt:239.590\n",
      "Ep:12, loss:0.00003, loss_test:0.13115, lr:9.90e-03, fs:0.63590 (r=0.626,p=0.646),  time:19.920, tt:258.959\n",
      "Ep:13, loss:0.00003, loss_test:0.12850, lr:9.80e-03, fs:0.63959 (r=0.636,p=0.643),  time:19.870, tt:278.183\n",
      "Ep:14, loss:0.00003, loss_test:0.12527, lr:9.70e-03, fs:0.64677 (r=0.657,p=0.637),  time:19.814, tt:297.212\n",
      "Ep:15, loss:0.00003, loss_test:0.12341, lr:9.61e-03, fs:0.65714 (r=0.697,p=0.622),  time:19.780, tt:316.482\n",
      "Ep:16, loss:0.00003, loss_test:0.12263, lr:9.51e-03, fs:0.65438 (r=0.717,p=0.602),  time:19.730, tt:335.409\n",
      "Ep:17, loss:0.00003, loss_test:0.12163, lr:9.41e-03, fs:0.66351 (r=0.707,p=0.625),  time:19.734, tt:355.212\n",
      "Ep:18, loss:0.00003, loss_test:0.12059, lr:9.32e-03, fs:0.64356 (r=0.657,p=0.631),  time:19.716, tt:374.596\n",
      "Ep:19, loss:0.00003, loss_test:0.12016, lr:9.23e-03, fs:0.64286 (r=0.636,p=0.649),  time:19.762, tt:395.235\n",
      "Ep:20, loss:0.00003, loss_test:0.11998, lr:9.14e-03, fs:0.62766 (r=0.596,p=0.663),  time:19.743, tt:414.606\n",
      "Ep:21, loss:0.00003, loss_test:0.11877, lr:9.04e-03, fs:0.63441 (r=0.596,p=0.678),  time:19.725, tt:433.951\n",
      "Ep:22, loss:0.00003, loss_test:0.11666, lr:8.95e-03, fs:0.63158 (r=0.606,p=0.659),  time:19.665, tt:452.286\n",
      "Ep:23, loss:0.00003, loss_test:0.11466, lr:8.86e-03, fs:0.63542 (r=0.616,p=0.656),  time:19.717, tt:473.219\n",
      "Ep:24, loss:0.00003, loss_test:0.11313, lr:8.78e-03, fs:0.64975 (r=0.646,p=0.653),  time:19.733, tt:493.313\n",
      "Ep:25, loss:0.00002, loss_test:0.11207, lr:8.69e-03, fs:0.65657 (r=0.657,p=0.657),  time:19.711, tt:512.482\n",
      "Ep:26, loss:0.00002, loss_test:0.11139, lr:8.60e-03, fs:0.65979 (r=0.646,p=0.674),  time:19.610, tt:529.475\n",
      "Ep:27, loss:0.00002, loss_test:0.11088, lr:8.51e-03, fs:0.65263 (r=0.626,p=0.681),  time:19.575, tt:548.102\n",
      "Ep:28, loss:0.00002, loss_test:0.11019, lr:8.43e-03, fs:0.65608 (r=0.626,p=0.689),  time:19.591, tt:568.135\n",
      "Ep:29, loss:0.00002, loss_test:0.10909, lr:8.35e-03, fs:0.66316 (r=0.636,p=0.692),  time:19.540, tt:586.186\n",
      "Ep:30, loss:0.00002, loss_test:0.10783, lr:8.26e-03, fs:0.67708 (r=0.657,p=0.699),  time:19.566, tt:606.542\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.10676, lr:8.26e-03, fs:0.71287 (r=0.727,p=0.699),  time:19.586, tt:626.766\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.10601, lr:8.26e-03, fs:0.72906 (r=0.747,p=0.712),  time:19.599, tt:646.784\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10540, lr:8.26e-03, fs:0.72821 (r=0.717,p=0.740),  time:19.607, tt:666.632\n",
      "Ep:34, loss:0.00002, loss_test:0.10487, lr:8.26e-03, fs:0.72251 (r=0.697,p=0.750),  time:19.585, tt:685.462\n",
      "Ep:35, loss:0.00002, loss_test:0.10411, lr:8.26e-03, fs:0.72917 (r=0.707,p=0.753),  time:19.612, tt:706.041\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.10348, lr:8.26e-03, fs:0.74112 (r=0.737,p=0.745),  time:19.593, tt:724.945\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.10283, lr:8.26e-03, fs:0.73096 (r=0.727,p=0.735),  time:19.590, tt:744.409\n",
      "Ep:38, loss:0.00002, loss_test:0.10215, lr:8.26e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.592, tt:764.089\n",
      "Ep:39, loss:0.00002, loss_test:0.10158, lr:8.26e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.610, tt:784.405\n",
      "Ep:40, loss:0.00002, loss_test:0.10104, lr:8.26e-03, fs:0.72449 (r=0.717,p=0.732),  time:19.601, tt:803.639\n",
      "Ep:41, loss:0.00002, loss_test:0.10070, lr:8.26e-03, fs:0.73000 (r=0.737,p=0.723),  time:19.583, tt:822.501\n",
      "Ep:42, loss:0.00002, loss_test:0.10017, lr:8.26e-03, fs:0.71795 (r=0.707,p=0.729),  time:19.559, tt:841.037\n",
      "Ep:43, loss:0.00002, loss_test:0.09977, lr:8.26e-03, fs:0.73684 (r=0.707,p=0.769),  time:19.550, tt:860.180\n",
      "Ep:44, loss:0.00002, loss_test:0.09939, lr:8.26e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.535, tt:879.078\n",
      "Ep:45, loss:0.00002, loss_test:0.09903, lr:8.26e-03, fs:0.71429 (r=0.707,p=0.722),  time:19.529, tt:898.355\n",
      "Ep:46, loss:0.00002, loss_test:0.09877, lr:8.26e-03, fs:0.71717 (r=0.717,p=0.717),  time:19.552, tt:918.962\n",
      "Ep:47, loss:0.00002, loss_test:0.09852, lr:8.26e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.546, tt:938.200\n",
      "Ep:48, loss:0.00002, loss_test:0.09823, lr:8.18e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.574, tt:959.131\n",
      "Ep:49, loss:0.00002, loss_test:0.09794, lr:8.10e-03, fs:0.72821 (r=0.717,p=0.740),  time:19.556, tt:977.789\n",
      "Ep:50, loss:0.00002, loss_test:0.09758, lr:8.02e-03, fs:0.73469 (r=0.727,p=0.742),  time:19.593, tt:999.249\n",
      "Ep:51, loss:0.00002, loss_test:0.09716, lr:7.94e-03, fs:0.73846 (r=0.727,p=0.750),  time:19.572, tt:1017.749\n",
      "Ep:52, loss:0.00002, loss_test:0.09679, lr:7.86e-03, fs:0.73846 (r=0.727,p=0.750),  time:19.562, tt:1036.780\n",
      "Ep:53, loss:0.00002, loss_test:0.09655, lr:7.78e-03, fs:0.74112 (r=0.737,p=0.745),  time:19.525, tt:1054.327\n",
      "Ep:54, loss:0.00001, loss_test:0.09634, lr:7.70e-03, fs:0.74227 (r=0.727,p=0.758),  time:19.520, tt:1073.618\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.09613, lr:7.70e-03, fs:0.75127 (r=0.747,p=0.755),  time:19.523, tt:1093.286\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.09580, lr:7.70e-03, fs:0.76382 (r=0.768,p=0.760),  time:19.553, tt:1114.507\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.09572, lr:7.70e-03, fs:0.76142 (r=0.758,p=0.765),  time:19.525, tt:1132.430\n",
      "Ep:58, loss:0.00001, loss_test:0.09561, lr:7.70e-03, fs:0.78000 (r=0.788,p=0.772),  time:19.519, tt:1151.614\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.09552, lr:7.70e-03, fs:0.77612 (r=0.788,p=0.765),  time:19.510, tt:1170.595\n",
      "Ep:60, loss:0.00001, loss_test:0.09557, lr:7.70e-03, fs:0.77157 (r=0.768,p=0.776),  time:19.521, tt:1190.782\n",
      "Ep:61, loss:0.00001, loss_test:0.09536, lr:7.70e-03, fs:0.77778 (r=0.778,p=0.778),  time:19.515, tt:1209.944\n",
      "Ep:62, loss:0.00001, loss_test:0.09537, lr:7.70e-03, fs:0.77228 (r=0.788,p=0.757),  time:19.511, tt:1229.199\n",
      "Ep:63, loss:0.00001, loss_test:0.09557, lr:7.70e-03, fs:0.77387 (r=0.778,p=0.770),  time:19.516, tt:1249.030\n",
      "Ep:64, loss:0.00001, loss_test:0.09556, lr:7.70e-03, fs:0.77778 (r=0.778,p=0.778),  time:19.529, tt:1269.398\n",
      "Ep:65, loss:0.00001, loss_test:0.09512, lr:7.70e-03, fs:0.77612 (r=0.788,p=0.765),  time:19.555, tt:1290.601\n",
      "Ep:66, loss:0.00001, loss_test:0.09494, lr:7.70e-03, fs:0.77612 (r=0.788,p=0.765),  time:19.544, tt:1309.431\n",
      "Ep:67, loss:0.00001, loss_test:0.09527, lr:7.70e-03, fs:0.78173 (r=0.778,p=0.786),  time:19.557, tt:1329.904\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.09515, lr:7.70e-03, fs:0.78607 (r=0.798,p=0.775),  time:19.539, tt:1348.212\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09499, lr:7.70e-03, fs:0.77451 (r=0.798,p=0.752),  time:19.593, tt:1371.510\n",
      "Ep:70, loss:0.00001, loss_test:0.09508, lr:7.70e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.582, tt:1390.306\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.09472, lr:7.70e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.584, tt:1410.063\n",
      "Ep:72, loss:0.00001, loss_test:0.09425, lr:7.70e-03, fs:0.77451 (r=0.798,p=0.752),  time:19.591, tt:1430.178\n",
      "Ep:73, loss:0.00001, loss_test:0.09434, lr:7.70e-03, fs:0.79397 (r=0.798,p=0.790),  time:19.606, tt:1450.828\n",
      "Ep:74, loss:0.00001, loss_test:0.09460, lr:7.70e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.624, tt:1471.791\n",
      "Ep:75, loss:0.00001, loss_test:0.09393, lr:7.70e-03, fs:0.78607 (r=0.798,p=0.775),  time:19.632, tt:1492.018\n",
      "Ep:76, loss:0.00001, loss_test:0.09357, lr:7.70e-03, fs:0.77833 (r=0.798,p=0.760),  time:19.620, tt:1510.762\n",
      "Ep:77, loss:0.00001, loss_test:0.09385, lr:7.70e-03, fs:0.80412 (r=0.788,p=0.821),  time:19.647, tt:1532.459\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.09357, lr:7.70e-03, fs:0.80203 (r=0.798,p=0.806),  time:19.642, tt:1551.696\n",
      "Ep:79, loss:0.00001, loss_test:0.09350, lr:7.70e-03, fs:0.79024 (r=0.818,p=0.764),  time:19.656, tt:1572.459\n",
      "Ep:80, loss:0.00001, loss_test:0.09372, lr:7.70e-03, fs:0.80000 (r=0.788,p=0.812),  time:19.674, tt:1593.554\n",
      "Ep:81, loss:0.00001, loss_test:0.09336, lr:7.70e-03, fs:0.80203 (r=0.798,p=0.806),  time:19.676, tt:1613.410\n",
      "Ep:82, loss:0.00001, loss_test:0.09276, lr:7.70e-03, fs:0.79024 (r=0.818,p=0.764),  time:19.683, tt:1633.709\n",
      "Ep:83, loss:0.00001, loss_test:0.09294, lr:7.70e-03, fs:0.80203 (r=0.798,p=0.806),  time:19.699, tt:1654.723\n",
      "Ep:84, loss:0.00001, loss_test:0.09316, lr:7.70e-03, fs:0.80203 (r=0.798,p=0.806),  time:19.715, tt:1675.775\n",
      "Ep:85, loss:0.00001, loss_test:0.09316, lr:7.70e-03, fs:0.79803 (r=0.818,p=0.779),  time:19.721, tt:1696.041\n",
      "Ep:86, loss:0.00001, loss_test:0.09362, lr:7.70e-03, fs:0.79798 (r=0.798,p=0.798),  time:19.719, tt:1715.560\n",
      "Ep:87, loss:0.00001, loss_test:0.09381, lr:7.70e-03, fs:0.81026 (r=0.798,p=0.823),  time:19.742, tt:1737.272\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.09348, lr:7.70e-03, fs:0.80198 (r=0.818,p=0.786),  time:19.752, tt:1757.936\n",
      "Ep:89, loss:0.00001, loss_test:0.09395, lr:7.70e-03, fs:0.81443 (r=0.798,p=0.832),  time:19.792, tt:1781.270\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.09349, lr:7.70e-03, fs:0.81818 (r=0.818,p=0.818),  time:19.808, tt:1802.560\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.09315, lr:7.70e-03, fs:0.80198 (r=0.818,p=0.786),  time:19.825, tt:1823.916\n",
      "Ep:92, loss:0.00001, loss_test:0.09393, lr:7.70e-03, fs:0.81250 (r=0.788,p=0.839),  time:19.841, tt:1845.173\n",
      "Ep:93, loss:0.00001, loss_test:0.09335, lr:7.70e-03, fs:0.81407 (r=0.818,p=0.810),  time:19.859, tt:1866.768\n",
      "Ep:94, loss:0.00001, loss_test:0.09293, lr:7.70e-03, fs:0.81188 (r=0.828,p=0.796),  time:19.864, tt:1887.047\n",
      "Ep:95, loss:0.00001, loss_test:0.09338, lr:7.70e-03, fs:0.81865 (r=0.798,p=0.840),  time:19.874, tt:1907.866\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.09261, lr:7.70e-03, fs:0.81818 (r=0.818,p=0.818),  time:19.884, tt:1928.727\n",
      "Ep:97, loss:0.00001, loss_test:0.09193, lr:7.70e-03, fs:0.81553 (r=0.848,p=0.785),  time:19.891, tt:1949.342\n",
      "Ep:98, loss:0.00001, loss_test:0.09431, lr:7.70e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.903, tt:1970.369\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.09387, lr:7.70e-03, fs:0.84211 (r=0.808,p=0.879),  time:19.904, tt:1990.386\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.09167, lr:7.70e-03, fs:0.81553 (r=0.848,p=0.785),  time:19.904, tt:2010.257\n",
      "Ep:101, loss:0.00001, loss_test:0.09152, lr:7.70e-03, fs:0.82000 (r=0.828,p=0.812),  time:19.903, tt:2030.064\n",
      "Ep:102, loss:0.00001, loss_test:0.09205, lr:7.70e-03, fs:0.83770 (r=0.808,p=0.870),  time:19.895, tt:2049.171\n",
      "Ep:103, loss:0.00001, loss_test:0.09109, lr:7.70e-03, fs:0.83168 (r=0.848,p=0.816),  time:19.901, tt:2069.701\n",
      "Ep:104, loss:0.00001, loss_test:0.09093, lr:7.70e-03, fs:0.81951 (r=0.848,p=0.792),  time:19.887, tt:2088.121\n",
      "Ep:105, loss:0.00001, loss_test:0.09169, lr:7.70e-03, fs:0.83938 (r=0.818,p=0.862),  time:19.888, tt:2108.133\n",
      "Ep:106, loss:0.00001, loss_test:0.09113, lr:7.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:19.883, tt:2127.439\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.08961, lr:7.70e-03, fs:0.82759 (r=0.848,p=0.808),  time:19.881, tt:2147.109\n",
      "Ep:108, loss:0.00001, loss_test:0.09003, lr:7.70e-03, fs:0.84000 (r=0.848,p=0.832),  time:19.873, tt:2166.132\n",
      "Ep:109, loss:0.00001, loss_test:0.09110, lr:7.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:19.879, tt:2186.636\n",
      "Ep:110, loss:0.00001, loss_test:0.09016, lr:7.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.867, tt:2205.214\n",
      "Ep:111, loss:0.00001, loss_test:0.08876, lr:7.70e-03, fs:0.83168 (r=0.848,p=0.816),  time:19.867, tt:2225.155\n",
      "Ep:112, loss:0.00001, loss_test:0.08960, lr:7.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:19.870, tt:2245.258\n",
      "Ep:113, loss:0.00001, loss_test:0.08943, lr:7.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:19.870, tt:2265.218\n",
      "Ep:114, loss:0.00001, loss_test:0.08829, lr:7.70e-03, fs:0.84000 (r=0.848,p=0.832),  time:19.870, tt:2284.993\n",
      "Ep:115, loss:0.00001, loss_test:0.08828, lr:7.70e-03, fs:0.84422 (r=0.848,p=0.840),  time:19.932, tt:2312.099\n",
      "Ep:116, loss:0.00001, loss_test:0.08841, lr:7.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.928, tt:2331.570\n",
      "Ep:117, loss:0.00001, loss_test:0.08812, lr:7.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.926, tt:2351.250\n",
      "Ep:118, loss:0.00001, loss_test:0.08775, lr:7.62e-03, fs:0.84422 (r=0.848,p=0.840),  time:19.925, tt:2371.133\n",
      "Ep:119, loss:0.00001, loss_test:0.08832, lr:7.55e-03, fs:0.84264 (r=0.838,p=0.847),  time:19.926, tt:2391.084\n",
      "Ep:120, loss:0.00001, loss_test:0.08813, lr:7.47e-03, fs:0.84264 (r=0.838,p=0.847),  time:19.924, tt:2410.780\n",
      "Ep:121, loss:0.00001, loss_test:0.08720, lr:7.40e-03, fs:0.84422 (r=0.848,p=0.840),  time:19.927, tt:2431.048\n",
      "Ep:122, loss:0.00001, loss_test:0.08731, lr:7.32e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.925, tt:2450.835\n",
      "Ep:123, loss:0.00001, loss_test:0.08740, lr:7.25e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.932, tt:2471.510\n",
      "Ep:124, loss:0.00000, loss_test:0.08678, lr:7.18e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.936, tt:2492.060\n",
      "Ep:125, loss:0.00000, loss_test:0.08643, lr:7.11e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.939, tt:2512.364\n",
      "Ep:126, loss:0.00000, loss_test:0.08640, lr:7.03e-03, fs:0.84264 (r=0.838,p=0.847),  time:19.936, tt:2531.903\n",
      "Ep:127, loss:0.00000, loss_test:0.08598, lr:6.96e-03, fs:0.84264 (r=0.838,p=0.847),  time:19.951, tt:2553.698\n",
      "Ep:128, loss:0.00000, loss_test:0.08581, lr:6.89e-03, fs:0.84264 (r=0.838,p=0.847),  time:19.947, tt:2573.148\n",
      "Ep:129, loss:0.00000, loss_test:0.08636, lr:6.83e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.946, tt:2592.996\n",
      "Ep:130, loss:0.00000, loss_test:0.08576, lr:6.76e-03, fs:0.84264 (r=0.838,p=0.847),  time:19.944, tt:2612.632\n",
      "Ep:131, loss:0.00000, loss_test:0.08506, lr:6.69e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.943, tt:2632.502\n",
      "Ep:132, loss:0.00000, loss_test:0.08601, lr:6.62e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.950, tt:2653.316\n",
      "Ep:133, loss:0.00000, loss_test:0.08592, lr:6.56e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.949, tt:2673.140\n",
      "Ep:134, loss:0.00000, loss_test:0.08510, lr:6.49e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.953, tt:2693.683\n",
      "Ep:135, loss:0.00000, loss_test:0.08507, lr:6.43e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.950, tt:2713.223\n",
      "Ep:136, loss:0.00000, loss_test:0.08552, lr:6.36e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.944, tt:2732.301\n",
      "Ep:137, loss:0.00000, loss_test:0.08543, lr:6.30e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.949, tt:2752.984\n",
      "Ep:138, loss:0.00000, loss_test:0.08470, lr:6.24e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.945, tt:2772.370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.08462, lr:6.17e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.947, tt:2792.626\n",
      "Ep:140, loss:0.00000, loss_test:0.08412, lr:6.11e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.940, tt:2811.609\n",
      "Ep:141, loss:0.00000, loss_test:0.08371, lr:6.05e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.941, tt:2831.578\n",
      "Ep:142, loss:0.00000, loss_test:0.08461, lr:5.99e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.934, tt:2850.548\n",
      "Ep:143, loss:0.00000, loss_test:0.08479, lr:5.93e-03, fs:0.84536 (r=0.828,p=0.863),  time:19.934, tt:2870.560\n",
      "Ep:144, loss:0.00000, loss_test:0.08381, lr:5.87e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.934, tt:2890.459\n",
      "Ep:145, loss:0.00000, loss_test:0.08337, lr:5.81e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.929, tt:2909.674\n",
      "Ep:146, loss:0.00000, loss_test:0.08429, lr:5.75e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.931, tt:2929.826\n",
      "Ep:147, loss:0.00000, loss_test:0.08423, lr:5.70e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.931, tt:2949.716\n",
      "Ep:148, loss:0.00000, loss_test:0.08354, lr:5.64e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.937, tt:2970.677\n",
      "Ep:149, loss:0.00000, loss_test:0.08347, lr:5.58e-03, fs:0.84375 (r=0.818,p=0.871),  time:19.927, tt:2989.124\n",
      "Ep:150, loss:0.00000, loss_test:0.08364, lr:5.53e-03, fs:0.84375 (r=0.818,p=0.871),  time:19.931, tt:3009.567\n",
      "Ep:151, loss:0.00000, loss_test:0.08351, lr:5.47e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.928, tt:3029.071\n",
      "Ep:152, loss:0.00000, loss_test:0.08344, lr:5.42e-03, fs:0.83673 (r=0.828,p=0.845),  time:19.927, tt:3048.754\n",
      "Ep:153, loss:0.00000, loss_test:0.08337, lr:5.36e-03, fs:0.83333 (r=0.808,p=0.860),  time:19.928, tt:3068.877\n",
      "Ep:154, loss:0.00000, loss_test:0.08275, lr:5.31e-03, fs:0.83938 (r=0.818,p=0.862),  time:19.924, tt:3088.263\n",
      "Ep:155, loss:0.00000, loss_test:0.08248, lr:5.26e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.921, tt:3107.637\n",
      "Ep:156, loss:0.00000, loss_test:0.08336, lr:5.20e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.918, tt:3127.107\n",
      "Ep:157, loss:0.00000, loss_test:0.08396, lr:5.15e-03, fs:0.83333 (r=0.808,p=0.860),  time:19.919, tt:3147.130\n",
      "Ep:158, loss:0.00000, loss_test:0.08336, lr:5.10e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.917, tt:3166.873\n",
      "Ep:159, loss:0.00000, loss_test:0.08259, lr:5.05e-03, fs:0.84694 (r=0.838,p=0.856),  time:19.915, tt:3186.323\n",
      "Ep:160, loss:0.00000, loss_test:0.08319, lr:5.00e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.895, tt:3203.131\n",
      "Ep:161, loss:0.00000, loss_test:0.08328, lr:4.95e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.900, tt:3223.808\n",
      "Ep:162, loss:0.00000, loss_test:0.08276, lr:4.90e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.899, tt:3243.507\n",
      "Ep:163, loss:0.00000, loss_test:0.08265, lr:4.85e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.900, tt:3263.653\n",
      "Ep:164, loss:0.00000, loss_test:0.08278, lr:4.80e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.903, tt:3283.953\n",
      "Ep:165, loss:0.00000, loss_test:0.08293, lr:4.75e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.899, tt:3303.216\n",
      "Ep:166, loss:0.00000, loss_test:0.08311, lr:4.71e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.900, tt:3323.339\n",
      "Ep:167, loss:0.00000, loss_test:0.08280, lr:4.66e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.889, tt:3341.318\n",
      "Ep:168, loss:0.00000, loss_test:0.08196, lr:4.61e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.894, tt:3362.106\n",
      "Ep:169, loss:0.00000, loss_test:0.08233, lr:4.57e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.892, tt:3381.653\n",
      "Ep:170, loss:0.00000, loss_test:0.08294, lr:4.52e-03, fs:0.83333 (r=0.808,p=0.860),  time:19.891, tt:3401.348\n",
      "Ep:171, loss:0.00000, loss_test:0.08299, lr:4.48e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.897, tt:3422.211\n",
      "Ep:172, loss:0.00000, loss_test:0.08247, lr:4.43e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.888, tt:3440.709\n",
      "Ep:173, loss:0.00000, loss_test:0.08244, lr:4.39e-03, fs:0.83333 (r=0.808,p=0.860),  time:19.894, tt:3461.528\n",
      "Ep:174, loss:0.00000, loss_test:0.08217, lr:4.34e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.894, tt:3481.497\n",
      "Ep:175, loss:0.00000, loss_test:0.08230, lr:4.30e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.890, tt:3500.584\n",
      "Ep:176, loss:0.00000, loss_test:0.08272, lr:4.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.896, tt:3521.599\n",
      "Ep:177, loss:0.00000, loss_test:0.08256, lr:4.21e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.901, tt:3542.310\n",
      "Ep:178, loss:0.00000, loss_test:0.08180, lr:4.17e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.903, tt:3562.693\n",
      "Ep:179, loss:0.00000, loss_test:0.08231, lr:4.13e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.908, tt:3583.412\n",
      "Ep:180, loss:0.00000, loss_test:0.08247, lr:4.09e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.909, tt:3603.571\n",
      "Ep:181, loss:0.00000, loss_test:0.08216, lr:4.05e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.904, tt:3622.591\n",
      "Ep:182, loss:0.00000, loss_test:0.08211, lr:4.01e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.905, tt:3642.579\n",
      "Ep:183, loss:0.00000, loss_test:0.08217, lr:3.97e-03, fs:0.83333 (r=0.808,p=0.860),  time:19.904, tt:3662.400\n",
      "Ep:184, loss:0.00000, loss_test:0.08210, lr:3.93e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.896, tt:3680.716\n",
      "Ep:185, loss:0.00000, loss_test:0.08223, lr:3.89e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.884, tt:3698.372\n",
      "Ep:186, loss:0.00000, loss_test:0.08191, lr:3.85e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.887, tt:3718.923\n",
      "Ep:187, loss:0.00000, loss_test:0.08176, lr:3.81e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.887, tt:3738.825\n",
      "Ep:188, loss:0.00000, loss_test:0.08211, lr:3.77e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.888, tt:3758.881\n",
      "Ep:189, loss:0.00000, loss_test:0.08206, lr:3.73e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.891, tt:3779.292\n",
      "Ep:190, loss:0.00000, loss_test:0.08173, lr:3.70e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.889, tt:3798.831\n",
      "Ep:191, loss:0.00000, loss_test:0.08190, lr:3.66e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.881, tt:3817.082\n",
      "Ep:192, loss:0.00000, loss_test:0.08194, lr:3.62e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.885, tt:3837.890\n",
      "Ep:193, loss:0.00000, loss_test:0.08161, lr:3.59e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.881, tt:3856.879\n",
      "Ep:194, loss:0.00000, loss_test:0.08181, lr:3.55e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.882, tt:3876.956\n",
      "Ep:195, loss:0.00000, loss_test:0.08171, lr:3.52e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.880, tt:3896.554\n",
      "Ep:196, loss:0.00000, loss_test:0.08155, lr:3.48e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.880, tt:3916.334\n",
      "Ep:197, loss:0.00000, loss_test:0.08197, lr:3.45e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.886, tt:3937.491\n",
      "Ep:198, loss:0.00000, loss_test:0.08202, lr:3.41e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.890, tt:3958.127\n",
      "Ep:199, loss:0.00000, loss_test:0.08168, lr:3.38e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.888, tt:3977.569\n",
      "Ep:200, loss:0.00000, loss_test:0.08145, lr:3.34e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.888, tt:3997.551\n",
      "Ep:201, loss:0.00000, loss_test:0.08180, lr:3.31e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.883, tt:4016.327\n",
      "Ep:202, loss:0.00000, loss_test:0.08179, lr:3.28e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.884, tt:4036.503\n",
      "Ep:203, loss:0.00000, loss_test:0.08151, lr:3.24e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.887, tt:4056.921\n",
      "Ep:204, loss:0.00000, loss_test:0.08152, lr:3.21e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.884, tt:4076.296\n",
      "Ep:205, loss:0.00000, loss_test:0.08148, lr:3.18e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.887, tt:4096.795\n",
      "Ep:206, loss:0.00000, loss_test:0.08164, lr:3.15e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.883, tt:4115.742\n",
      "Ep:207, loss:0.00000, loss_test:0.08189, lr:3.12e-03, fs:0.82292 (r=0.798,p=0.849),  time:19.885, tt:4136.178\n",
      "Ep:208, loss:0.00000, loss_test:0.08193, lr:3.09e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.886, tt:4156.248\n",
      "Ep:209, loss:0.00000, loss_test:0.08146, lr:3.05e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.880, tt:4174.808\n",
      "Ep:210, loss:0.00000, loss_test:0.08105, lr:3.02e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.874, tt:4193.396\n",
      "Ep:211, loss:0.00000, loss_test:0.08155, lr:2.99e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.871, tt:4212.677\n",
      "Ep:212, loss:0.00000, loss_test:0.08210, lr:2.96e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.864, tt:4231.112\n",
      "Ep:213, loss:0.00000, loss_test:0.08206, lr:2.93e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.868, tt:4251.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:214, loss:0.00000, loss_test:0.08150, lr:2.90e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.865, tt:4270.952\n",
      "Ep:215, loss:0.00000, loss_test:0.08115, lr:2.88e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.857, tt:4289.046\n",
      "Ep:216, loss:0.00000, loss_test:0.08149, lr:2.85e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.852, tt:4307.952\n",
      "Ep:217, loss:0.00000, loss_test:0.08156, lr:2.82e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.845, tt:4326.184\n",
      "Ep:218, loss:0.00000, loss_test:0.08132, lr:2.79e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.836, tt:4344.087\n",
      "Ep:219, loss:0.00000, loss_test:0.08134, lr:2.76e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.832, tt:4362.935\n",
      "Ep:220, loss:0.00000, loss_test:0.08130, lr:2.73e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.830, tt:4382.401\n",
      "Ep:221, loss:0.00000, loss_test:0.08121, lr:2.71e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.826, tt:4401.281\n",
      "Ep:222, loss:0.00000, loss_test:0.08147, lr:2.68e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.823, tt:4420.627\n",
      "Ep:223, loss:0.00000, loss_test:0.08172, lr:2.65e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.821, tt:4439.957\n",
      "Ep:224, loss:0.00000, loss_test:0.08153, lr:2.63e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.812, tt:4457.699\n",
      "Ep:225, loss:0.00000, loss_test:0.08116, lr:2.60e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.813, tt:4477.779\n",
      "Ep:226, loss:0.00000, loss_test:0.08150, lr:2.57e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.813, tt:4497.598\n",
      "Ep:227, loss:0.00000, loss_test:0.08158, lr:2.55e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.811, tt:4516.892\n",
      "Ep:228, loss:0.00000, loss_test:0.08130, lr:2.52e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.814, tt:4537.371\n",
      "Ep:229, loss:0.00000, loss_test:0.08124, lr:2.50e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.813, tt:4557.035\n",
      "Ep:230, loss:0.00000, loss_test:0.08188, lr:2.47e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.812, tt:4576.493\n",
      "Ep:231, loss:0.00000, loss_test:0.08215, lr:2.45e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.812, tt:4596.310\n",
      "Ep:232, loss:0.00000, loss_test:0.08189, lr:2.42e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.810, tt:4615.744\n",
      "Ep:233, loss:0.00000, loss_test:0.08132, lr:2.40e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.809, tt:4635.311\n",
      "Ep:234, loss:0.00000, loss_test:0.08096, lr:2.38e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.806, tt:4654.385\n",
      "Ep:235, loss:0.00000, loss_test:0.08158, lr:2.35e-03, fs:0.82540 (r=0.788,p=0.867),  time:19.805, tt:4673.864\n",
      "Ep:236, loss:0.00000, loss_test:0.08193, lr:2.33e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.802, tt:4692.962\n",
      "Ep:237, loss:0.00000, loss_test:0.08180, lr:2.31e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.794, tt:4711.021\n",
      "Ep:238, loss:0.00000, loss_test:0.08128, lr:2.28e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.792, tt:4730.176\n",
      "Ep:239, loss:0.00000, loss_test:0.08082, lr:2.26e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.779, tt:4746.936\n",
      "Ep:240, loss:0.00000, loss_test:0.08117, lr:2.24e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.777, tt:4766.163\n",
      "Ep:241, loss:0.00000, loss_test:0.08163, lr:2.21e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.773, tt:4784.997\n",
      "Ep:242, loss:0.00000, loss_test:0.08169, lr:2.19e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.772, tt:4804.672\n",
      "Ep:243, loss:0.00000, loss_test:0.08134, lr:2.17e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.770, tt:4823.927\n",
      "Ep:244, loss:0.00000, loss_test:0.08092, lr:2.15e-03, fs:0.82723 (r=0.798,p=0.859),  time:19.765, tt:4842.431\n",
      "Ep:245, loss:0.00000, loss_test:0.08117, lr:2.13e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.759, tt:4860.596\n",
      "Ep:246, loss:0.00000, loss_test:0.08143, lr:2.11e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.752, tt:4878.726\n",
      "Ep:247, loss:0.00000, loss_test:0.08140, lr:2.08e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.746, tt:4897.033\n",
      "Ep:248, loss:0.00000, loss_test:0.08112, lr:2.06e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.744, tt:4916.369\n",
      "Ep:249, loss:0.00000, loss_test:0.08113, lr:2.04e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.738, tt:4934.513\n",
      "Ep:250, loss:0.00000, loss_test:0.08133, lr:2.02e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.731, tt:4952.581\n",
      "Ep:251, loss:0.00000, loss_test:0.08127, lr:2.00e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.730, tt:4971.916\n",
      "Ep:252, loss:0.00000, loss_test:0.08101, lr:1.98e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.753, tt:4997.391\n",
      "Ep:253, loss:0.00000, loss_test:0.08099, lr:1.96e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.744, tt:5015.014\n",
      "Ep:254, loss:0.00000, loss_test:0.08130, lr:1.94e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.741, tt:5034.019\n",
      "Ep:255, loss:0.00000, loss_test:0.08132, lr:1.92e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.740, tt:5053.459\n",
      "Ep:256, loss:0.00000, loss_test:0.08105, lr:1.90e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.731, tt:5070.954\n",
      "Ep:257, loss:0.00000, loss_test:0.08087, lr:1.89e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.734, tt:5091.476\n",
      "Ep:258, loss:0.00000, loss_test:0.08118, lr:1.87e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.726, tt:5108.921\n",
      "Ep:259, loss:0.00000, loss_test:0.08124, lr:1.85e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.721, tt:5127.556\n",
      "Ep:260, loss:0.00000, loss_test:0.08105, lr:1.83e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.717, tt:5146.196\n",
      "Ep:261, loss:0.00000, loss_test:0.08082, lr:1.81e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.715, tt:5165.448\n",
      "Ep:262, loss:0.00000, loss_test:0.08114, lr:1.79e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.708, tt:5183.173\n",
      "Ep:263, loss:0.00000, loss_test:0.08121, lr:1.78e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.703, tt:5201.625\n",
      "Ep:264, loss:0.00000, loss_test:0.08102, lr:1.76e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.700, tt:5220.579\n",
      "Ep:265, loss:0.00000, loss_test:0.08073, lr:1.74e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.700, tt:5240.255\n",
      "Ep:266, loss:0.00000, loss_test:0.08090, lr:1.72e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.691, tt:5257.626\n",
      "Ep:267, loss:0.00000, loss_test:0.08129, lr:1.71e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.687, tt:5276.087\n",
      "Ep:268, loss:0.00000, loss_test:0.08140, lr:1.69e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.681, tt:5294.293\n",
      "Ep:269, loss:0.00000, loss_test:0.08122, lr:1.67e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.680, tt:5313.671\n",
      "Ep:270, loss:0.00000, loss_test:0.08088, lr:1.65e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.676, tt:5332.305\n",
      "Ep:271, loss:0.00000, loss_test:0.08092, lr:1.64e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.672, tt:5350.773\n",
      "Ep:272, loss:0.00000, loss_test:0.08099, lr:1.62e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.667, tt:5369.082\n",
      "Ep:273, loss:0.00000, loss_test:0.08092, lr:1.61e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.664, tt:5387.841\n",
      "Ep:274, loss:0.00000, loss_test:0.08081, lr:1.59e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.655, tt:5405.115\n",
      "Ep:275, loss:0.00000, loss_test:0.08078, lr:1.57e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.655, tt:5424.765\n",
      "Ep:276, loss:0.00000, loss_test:0.08078, lr:1.56e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.651, tt:5443.233\n",
      "Ep:277, loss:0.00000, loss_test:0.08079, lr:1.54e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.644, tt:5460.904\n",
      "Ep:278, loss:0.00000, loss_test:0.08083, lr:1.53e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.643, tt:5480.482\n",
      "Ep:279, loss:0.00000, loss_test:0.08074, lr:1.51e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.636, tt:5497.975\n",
      "Ep:280, loss:0.00000, loss_test:0.08077, lr:1.50e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.632, tt:5516.646\n",
      "Ep:281, loss:0.00000, loss_test:0.08070, lr:1.48e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.631, tt:5535.923\n",
      "Ep:282, loss:0.00000, loss_test:0.08076, lr:1.47e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.629, tt:5554.967\n",
      "Ep:283, loss:0.00000, loss_test:0.08085, lr:1.45e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.626, tt:5573.800\n",
      "Ep:284, loss:0.00000, loss_test:0.08077, lr:1.44e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.625, tt:5593.193\n",
      "Ep:285, loss:0.00000, loss_test:0.08101, lr:1.42e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.622, tt:5611.827\n",
      "Ep:286, loss:0.00000, loss_test:0.08101, lr:1.41e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.616, tt:5629.915\n",
      "Ep:287, loss:0.00000, loss_test:0.08080, lr:1.39e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.614, tt:5648.727\n",
      "Ep:288, loss:0.00000, loss_test:0.08060, lr:1.38e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.610, tt:5667.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:289, loss:0.00000, loss_test:0.08085, lr:1.37e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.608, tt:5686.384\n",
      "Ep:290, loss:0.00000, loss_test:0.08094, lr:1.35e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.608, tt:5705.948\n",
      "Ep:291, loss:0.00000, loss_test:0.08083, lr:1.34e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.607, tt:5725.139\n",
      "Ep:292, loss:0.00000, loss_test:0.08063, lr:1.33e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.601, tt:5742.997\n",
      "Ep:293, loss:0.00000, loss_test:0.08062, lr:1.31e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.602, tt:5763.015\n",
      "Ep:294, loss:0.00000, loss_test:0.08078, lr:1.30e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.597, tt:5781.152\n",
      "Ep:295, loss:0.00000, loss_test:0.08082, lr:1.29e-03, fs:0.82353 (r=0.778,p=0.875),  time:19.567, tt:5791.686\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14219, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:18.245, tt:18.245\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14161, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:18.294, tt:36.587\n",
      "Ep:2, loss:0.00004, loss_test:0.14075, lr:1.00e-02, fs:0.64336 (r=0.929,p=0.492),  time:18.557, tt:55.670\n",
      "Ep:3, loss:0.00004, loss_test:0.13968, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:18.318, tt:73.272\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.13865, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:18.280, tt:91.401\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.13748, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:18.310, tt:109.862\n",
      "Ep:6, loss:0.00004, loss_test:0.13651, lr:1.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:18.393, tt:128.751\n",
      "Ep:7, loss:0.00003, loss_test:0.13631, lr:1.00e-02, fs:0.63115 (r=0.778,p=0.531),  time:18.506, tt:148.046\n",
      "Ep:8, loss:0.00003, loss_test:0.13629, lr:1.00e-02, fs:0.63025 (r=0.758,p=0.540),  time:18.633, tt:167.698\n",
      "Ep:9, loss:0.00003, loss_test:0.13606, lr:1.00e-02, fs:0.61472 (r=0.717,p=0.538),  time:18.601, tt:186.005\n",
      "Ep:10, loss:0.00003, loss_test:0.13553, lr:1.00e-02, fs:0.62555 (r=0.717,p=0.555),  time:18.628, tt:204.911\n",
      "Ep:11, loss:0.00003, loss_test:0.13459, lr:1.00e-02, fs:0.62780 (r=0.707,p=0.565),  time:18.651, tt:223.813\n",
      "Ep:12, loss:0.00003, loss_test:0.13273, lr:1.00e-02, fs:0.62780 (r=0.707,p=0.565),  time:18.552, tt:241.176\n",
      "Ep:13, loss:0.00003, loss_test:0.13093, lr:1.00e-02, fs:0.64035 (r=0.737,p=0.566),  time:18.526, tt:259.364\n",
      "Ep:14, loss:0.00003, loss_test:0.12927, lr:1.00e-02, fs:0.64912 (r=0.747,p=0.574),  time:18.491, tt:277.364\n",
      "Ep:15, loss:0.00003, loss_test:0.12785, lr:1.00e-02, fs:0.65789 (r=0.758,p=0.581),  time:18.424, tt:294.780\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.12673, lr:1.00e-02, fs:0.65198 (r=0.747,p=0.578),  time:18.431, tt:313.320\n",
      "Ep:17, loss:0.00003, loss_test:0.12604, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:18.399, tt:331.188\n",
      "Ep:18, loss:0.00003, loss_test:0.12558, lr:1.00e-02, fs:0.66063 (r=0.737,p=0.598),  time:18.341, tt:348.475\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.12503, lr:1.00e-02, fs:0.66055 (r=0.727,p=0.605),  time:18.331, tt:366.620\n",
      "Ep:20, loss:0.00003, loss_test:0.12426, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:18.323, tt:384.789\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.12329, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:18.325, tt:403.149\n",
      "Ep:22, loss:0.00003, loss_test:0.12246, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:18.286, tt:420.584\n",
      "Ep:23, loss:0.00003, loss_test:0.12152, lr:1.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:18.288, tt:438.924\n",
      "Ep:24, loss:0.00003, loss_test:0.12060, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:18.265, tt:456.613\n",
      "Ep:25, loss:0.00003, loss_test:0.11972, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:18.258, tt:474.704\n",
      "Ep:26, loss:0.00003, loss_test:0.11901, lr:1.00e-02, fs:0.67265 (r=0.758,p=0.605),  time:18.238, tt:492.427\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.11837, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:18.272, tt:511.613\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.11791, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:18.279, tt:530.101\n",
      "Ep:29, loss:0.00003, loss_test:0.11756, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:18.304, tt:549.120\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.11733, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:18.284, tt:566.817\n",
      "Ep:31, loss:0.00002, loss_test:0.11676, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:18.258, tt:584.264\n",
      "Ep:32, loss:0.00002, loss_test:0.11584, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:18.271, tt:602.929\n",
      "Ep:33, loss:0.00002, loss_test:0.11493, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:18.282, tt:621.601\n",
      "Ep:34, loss:0.00002, loss_test:0.11386, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:18.263, tt:639.221\n",
      "Ep:35, loss:0.00002, loss_test:0.11283, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:18.289, tt:658.418\n",
      "Ep:36, loss:0.00002, loss_test:0.11187, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:18.285, tt:676.530\n",
      "Ep:37, loss:0.00002, loss_test:0.11085, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:18.266, tt:694.114\n",
      "Ep:38, loss:0.00002, loss_test:0.10982, lr:1.00e-02, fs:0.66990 (r=0.697,p=0.645),  time:18.272, tt:712.624\n",
      "Ep:39, loss:0.00002, loss_test:0.10903, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:18.284, tt:731.365\n",
      "Ep:40, loss:0.00002, loss_test:0.10842, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:18.277, tt:749.343\n",
      "Ep:41, loss:0.00002, loss_test:0.10735, lr:9.90e-03, fs:0.67943 (r=0.717,p=0.645),  time:18.299, tt:768.557\n",
      "Ep:42, loss:0.00002, loss_test:0.10625, lr:9.80e-03, fs:0.67943 (r=0.717,p=0.645),  time:18.288, tt:786.364\n",
      "Ep:43, loss:0.00002, loss_test:0.10534, lr:9.70e-03, fs:0.67943 (r=0.717,p=0.645),  time:18.294, tt:804.954\n",
      "Ep:44, loss:0.00002, loss_test:0.10464, lr:9.61e-03, fs:0.68599 (r=0.717,p=0.657),  time:18.307, tt:823.818\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.10378, lr:9.61e-03, fs:0.68932 (r=0.717,p=0.664),  time:18.316, tt:842.533\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.10284, lr:9.61e-03, fs:0.69565 (r=0.727,p=0.667),  time:18.330, tt:861.505\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.10191, lr:9.61e-03, fs:0.70813 (r=0.747,p=0.673),  time:18.344, tt:880.529\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.10133, lr:9.61e-03, fs:0.72038 (r=0.768,p=0.679),  time:18.362, tt:899.737\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.10101, lr:9.61e-03, fs:0.72986 (r=0.778,p=0.688),  time:18.371, tt:918.549\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.10018, lr:9.61e-03, fs:0.75349 (r=0.818,p=0.698),  time:18.355, tt:936.120\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.09907, lr:9.61e-03, fs:0.76995 (r=0.828,p=0.719),  time:18.357, tt:954.574\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.09844, lr:9.61e-03, fs:0.76056 (r=0.818,p=0.711),  time:18.367, tt:973.427\n",
      "Ep:53, loss:0.00002, loss_test:0.09816, lr:9.61e-03, fs:0.76056 (r=0.818,p=0.711),  time:18.373, tt:992.141\n",
      "Ep:54, loss:0.00002, loss_test:0.09745, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.376, tt:1010.696\n",
      "Ep:55, loss:0.00002, loss_test:0.09659, lr:9.61e-03, fs:0.76555 (r=0.808,p=0.727),  time:18.371, tt:1028.795\n",
      "Ep:56, loss:0.00002, loss_test:0.09599, lr:9.61e-03, fs:0.76190 (r=0.808,p=0.721),  time:18.357, tt:1046.364\n",
      "Ep:57, loss:0.00002, loss_test:0.09554, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.330, tt:1063.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00002, loss_test:0.09521, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.316, tt:1080.656\n",
      "Ep:59, loss:0.00002, loss_test:0.09462, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.301, tt:1098.039\n",
      "Ep:60, loss:0.00002, loss_test:0.09419, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.316, tt:1117.288\n",
      "Ep:61, loss:0.00001, loss_test:0.09397, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.308, tt:1135.099\n",
      "Ep:62, loss:0.00001, loss_test:0.09366, lr:9.61e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.272, tt:1151.105\n",
      "Ep:63, loss:0.00001, loss_test:0.09333, lr:9.51e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.252, tt:1168.097\n",
      "Ep:64, loss:0.00001, loss_test:0.09313, lr:9.41e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.225, tt:1184.647\n",
      "Ep:65, loss:0.00001, loss_test:0.09270, lr:9.32e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.212, tt:1201.979\n",
      "Ep:66, loss:0.00001, loss_test:0.09228, lr:9.23e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.198, tt:1219.298\n",
      "Ep:67, loss:0.00001, loss_test:0.09246, lr:9.14e-03, fs:0.77512 (r=0.818,p=0.736),  time:18.189, tt:1236.853\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.09153, lr:9.14e-03, fs:0.78469 (r=0.828,p=0.745),  time:18.169, tt:1253.669\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09122, lr:9.14e-03, fs:0.78095 (r=0.828,p=0.739),  time:18.155, tt:1270.867\n",
      "Ep:70, loss:0.00001, loss_test:0.09116, lr:9.14e-03, fs:0.78095 (r=0.828,p=0.739),  time:18.137, tt:1287.698\n",
      "Ep:71, loss:0.00001, loss_test:0.08996, lr:9.14e-03, fs:0.78846 (r=0.828,p=0.752),  time:18.129, tt:1305.312\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.09110, lr:9.14e-03, fs:0.78469 (r=0.828,p=0.745),  time:18.126, tt:1323.171\n",
      "Ep:73, loss:0.00001, loss_test:0.08983, lr:9.14e-03, fs:0.78469 (r=0.828,p=0.745),  time:18.117, tt:1340.633\n",
      "Ep:74, loss:0.00001, loss_test:0.08943, lr:9.14e-03, fs:0.78095 (r=0.828,p=0.739),  time:18.105, tt:1357.909\n",
      "Ep:75, loss:0.00001, loss_test:0.09187, lr:9.14e-03, fs:0.78469 (r=0.828,p=0.745),  time:18.102, tt:1375.756\n",
      "Ep:76, loss:0.00001, loss_test:0.08854, lr:9.14e-03, fs:0.79612 (r=0.828,p=0.766),  time:18.092, tt:1393.098\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.08980, lr:9.14e-03, fs:0.79227 (r=0.828,p=0.759),  time:18.086, tt:1410.736\n",
      "Ep:78, loss:0.00001, loss_test:0.09104, lr:9.14e-03, fs:0.78469 (r=0.828,p=0.745),  time:18.068, tt:1427.379\n",
      "Ep:79, loss:0.00001, loss_test:0.08831, lr:9.14e-03, fs:0.78846 (r=0.828,p=0.752),  time:18.056, tt:1444.480\n",
      "Ep:80, loss:0.00001, loss_test:0.08878, lr:9.14e-03, fs:0.79412 (r=0.818,p=0.771),  time:18.035, tt:1460.832\n",
      "Ep:81, loss:0.00001, loss_test:0.09044, lr:9.14e-03, fs:0.79412 (r=0.818,p=0.771),  time:18.030, tt:1478.444\n",
      "Ep:82, loss:0.00001, loss_test:0.08848, lr:9.14e-03, fs:0.78846 (r=0.828,p=0.752),  time:18.013, tt:1495.042\n",
      "Ep:83, loss:0.00001, loss_test:0.08873, lr:9.14e-03, fs:0.79412 (r=0.818,p=0.771),  time:18.004, tt:1512.318\n",
      "Ep:84, loss:0.00001, loss_test:0.08989, lr:9.14e-03, fs:0.79024 (r=0.818,p=0.764),  time:18.006, tt:1530.549\n",
      "Ep:85, loss:0.00001, loss_test:0.08772, lr:9.14e-03, fs:0.79227 (r=0.828,p=0.759),  time:17.991, tt:1547.221\n",
      "Ep:86, loss:0.00001, loss_test:0.08830, lr:9.14e-03, fs:0.79024 (r=0.818,p=0.764),  time:17.969, tt:1563.305\n",
      "Ep:87, loss:0.00001, loss_test:0.08936, lr:9.14e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.957, tt:1580.219\n",
      "Ep:88, loss:0.00001, loss_test:0.08812, lr:9.04e-03, fs:0.79612 (r=0.828,p=0.766),  time:17.942, tt:1596.795\n",
      "Ep:89, loss:0.00001, loss_test:0.08938, lr:8.95e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.926, tt:1613.300\n",
      "Ep:90, loss:0.00001, loss_test:0.08856, lr:8.86e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.930, tt:1631.588\n",
      "Ep:91, loss:0.00001, loss_test:0.08818, lr:8.78e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.916, tt:1648.315\n",
      "Ep:92, loss:0.00001, loss_test:0.08922, lr:8.69e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.910, tt:1665.643\n",
      "Ep:93, loss:0.00001, loss_test:0.08747, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.902, tt:1682.799\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.09006, lr:8.60e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.894, tt:1699.953\n",
      "Ep:95, loss:0.00001, loss_test:0.08985, lr:8.60e-03, fs:0.79412 (r=0.818,p=0.771),  time:17.881, tt:1716.542\n",
      "Ep:96, loss:0.00001, loss_test:0.08750, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.877, tt:1734.100\n",
      "Ep:97, loss:0.00001, loss_test:0.09055, lr:8.60e-03, fs:0.78218 (r=0.798,p=0.767),  time:17.884, tt:1752.587\n",
      "Ep:98, loss:0.00001, loss_test:0.08996, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.883, tt:1770.443\n",
      "Ep:99, loss:0.00001, loss_test:0.08854, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.879, tt:1787.881\n",
      "Ep:100, loss:0.00001, loss_test:0.09112, lr:8.60e-03, fs:0.78218 (r=0.798,p=0.767),  time:17.887, tt:1806.548\n",
      "Ep:101, loss:0.00001, loss_test:0.08835, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.893, tt:1825.071\n",
      "Ep:102, loss:0.00001, loss_test:0.09087, lr:8.60e-03, fs:0.79000 (r=0.798,p=0.782),  time:17.898, tt:1843.483\n",
      "Ep:103, loss:0.00001, loss_test:0.09116, lr:8.60e-03, fs:0.78607 (r=0.798,p=0.775),  time:17.897, tt:1861.259\n",
      "Ep:104, loss:0.00001, loss_test:0.08970, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.894, tt:1878.839\n",
      "Ep:105, loss:0.00001, loss_test:0.08959, lr:8.51e-03, fs:0.78607 (r=0.798,p=0.775),  time:17.897, tt:1897.070\n",
      "Ep:106, loss:0.00001, loss_test:0.09291, lr:8.43e-03, fs:0.79000 (r=0.798,p=0.782),  time:17.893, tt:1914.554\n",
      "Ep:107, loss:0.00001, loss_test:0.09076, lr:8.35e-03, fs:0.79000 (r=0.798,p=0.782),  time:17.893, tt:1932.437\n",
      "Ep:108, loss:0.00001, loss_test:0.09121, lr:8.26e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.889, tt:1949.909\n",
      "Ep:109, loss:0.00001, loss_test:0.09241, lr:8.18e-03, fs:0.78607 (r=0.798,p=0.775),  time:17.880, tt:1966.747\n",
      "Ep:110, loss:0.00001, loss_test:0.08828, lr:8.10e-03, fs:0.81818 (r=0.818,p=0.818),  time:17.869, tt:1983.468\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.09306, lr:8.10e-03, fs:0.78571 (r=0.778,p=0.794),  time:17.864, tt:2000.776\n",
      "Ep:112, loss:0.00001, loss_test:0.09673, lr:8.10e-03, fs:0.77387 (r=0.778,p=0.770),  time:17.867, tt:2018.920\n",
      "Ep:113, loss:0.00001, loss_test:0.08886, lr:8.10e-03, fs:0.82234 (r=0.818,p=0.827),  time:17.863, tt:2036.412\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00001, loss_test:0.09097, lr:8.10e-03, fs:0.78173 (r=0.778,p=0.786),  time:17.870, tt:2055.013\n",
      "Ep:115, loss:0.00001, loss_test:0.09863, lr:8.10e-03, fs:0.75862 (r=0.778,p=0.740),  time:17.867, tt:2072.589\n",
      "Ep:116, loss:0.00001, loss_test:0.09110, lr:8.10e-03, fs:0.81865 (r=0.798,p=0.840),  time:17.866, tt:2090.352\n",
      "Ep:117, loss:0.00001, loss_test:0.09113, lr:8.10e-03, fs:0.81443 (r=0.798,p=0.832),  time:17.871, tt:2108.728\n",
      "Ep:118, loss:0.00001, loss_test:0.09716, lr:8.10e-03, fs:0.77387 (r=0.778,p=0.770),  time:17.867, tt:2126.208\n",
      "Ep:119, loss:0.00001, loss_test:0.09231, lr:8.10e-03, fs:0.78173 (r=0.778,p=0.786),  time:17.864, tt:2143.654\n",
      "Ep:120, loss:0.00001, loss_test:0.09035, lr:8.10e-03, fs:0.81443 (r=0.798,p=0.832),  time:17.860, tt:2161.041\n",
      "Ep:121, loss:0.00001, loss_test:0.09570, lr:8.10e-03, fs:0.77157 (r=0.768,p=0.776),  time:17.863, tt:2179.268\n",
      "Ep:122, loss:0.00001, loss_test:0.09439, lr:8.10e-03, fs:0.79602 (r=0.808,p=0.784),  time:17.875, tt:2198.611\n",
      "Ep:123, loss:0.00001, loss_test:0.09378, lr:8.10e-03, fs:0.80628 (r=0.778,p=0.837),  time:17.885, tt:2217.736\n",
      "Ep:124, loss:0.00001, loss_test:0.09623, lr:8.10e-03, fs:0.79167 (r=0.768,p=0.817),  time:17.885, tt:2235.591\n",
      "Ep:125, loss:0.00001, loss_test:0.09434, lr:8.02e-03, fs:0.79602 (r=0.808,p=0.784),  time:17.891, tt:2254.248\n",
      "Ep:126, loss:0.00001, loss_test:0.09281, lr:7.94e-03, fs:0.79798 (r=0.798,p=0.798),  time:17.903, tt:2273.680\n",
      "Ep:127, loss:0.00001, loss_test:0.09790, lr:7.86e-03, fs:0.77895 (r=0.747,p=0.813),  time:17.910, tt:2292.534\n",
      "Ep:128, loss:0.00001, loss_test:0.09611, lr:7.78e-03, fs:0.79381 (r=0.778,p=0.811),  time:17.910, tt:2310.449\n",
      "Ep:129, loss:0.00001, loss_test:0.09378, lr:7.70e-03, fs:0.78173 (r=0.778,p=0.786),  time:17.914, tt:2328.781\n",
      "Ep:130, loss:0.00001, loss_test:0.09536, lr:7.62e-03, fs:0.77778 (r=0.778,p=0.778),  time:17.920, tt:2347.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.09489, lr:7.55e-03, fs:0.78173 (r=0.778,p=0.786),  time:17.924, tt:2365.942\n",
      "Ep:132, loss:0.00001, loss_test:0.09578, lr:7.47e-03, fs:0.78571 (r=0.778,p=0.794),  time:17.935, tt:2385.298\n",
      "Ep:133, loss:0.00001, loss_test:0.09715, lr:7.40e-03, fs:0.77157 (r=0.768,p=0.776),  time:17.947, tt:2404.941\n",
      "Ep:134, loss:0.00001, loss_test:0.09380, lr:7.32e-03, fs:0.78571 (r=0.778,p=0.794),  time:17.970, tt:2425.909\n",
      "Ep:135, loss:0.00001, loss_test:0.09830, lr:7.25e-03, fs:0.78173 (r=0.778,p=0.786),  time:17.980, tt:2445.309\n",
      "Ep:136, loss:0.00001, loss_test:0.09539, lr:7.18e-03, fs:0.80628 (r=0.778,p=0.837),  time:17.987, tt:2464.205\n",
      "Ep:137, loss:0.00001, loss_test:0.09612, lr:7.11e-03, fs:0.79381 (r=0.778,p=0.811),  time:17.997, tt:2483.603\n",
      "Ep:138, loss:0.00001, loss_test:0.09867, lr:7.03e-03, fs:0.77778 (r=0.778,p=0.778),  time:18.008, tt:2503.149\n",
      "Ep:139, loss:0.00001, loss_test:0.09334, lr:6.96e-03, fs:0.80628 (r=0.778,p=0.837),  time:18.019, tt:2522.680\n",
      "Ep:140, loss:0.00001, loss_test:0.09665, lr:6.89e-03, fs:0.80208 (r=0.778,p=0.828),  time:18.032, tt:2542.507\n",
      "Ep:141, loss:0.00001, loss_test:0.10117, lr:6.83e-03, fs:0.73298 (r=0.707,p=0.761),  time:18.041, tt:2561.810\n",
      "Ep:142, loss:0.00001, loss_test:0.09470, lr:6.76e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.053, tt:2581.596\n",
      "Ep:143, loss:0.00001, loss_test:0.09525, lr:6.69e-03, fs:0.78974 (r=0.778,p=0.802),  time:18.063, tt:2601.100\n",
      "Ep:144, loss:0.00001, loss_test:0.10066, lr:6.62e-03, fs:0.75393 (r=0.727,p=0.783),  time:18.075, tt:2620.822\n",
      "Ep:145, loss:0.00001, loss_test:0.09485, lr:6.56e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.081, tt:2639.893\n",
      "Ep:146, loss:0.00001, loss_test:0.09506, lr:6.49e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.100, tt:2660.712\n",
      "Ep:147, loss:0.00001, loss_test:0.10002, lr:6.43e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.106, tt:2679.664\n",
      "Ep:148, loss:0.00001, loss_test:0.09824, lr:6.36e-03, fs:0.77949 (r=0.768,p=0.792),  time:18.117, tt:2699.432\n",
      "Ep:149, loss:0.00000, loss_test:0.09338, lr:6.30e-03, fs:0.79365 (r=0.758,p=0.833),  time:18.129, tt:2719.335\n",
      "Ep:150, loss:0.00000, loss_test:0.09668, lr:6.24e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.130, tt:2737.698\n",
      "Ep:151, loss:0.00000, loss_test:0.10187, lr:6.17e-03, fs:0.74468 (r=0.707,p=0.787),  time:18.141, tt:2757.396\n",
      "Ep:152, loss:0.00000, loss_test:0.09740, lr:6.11e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.148, tt:2776.708\n",
      "Ep:153, loss:0.00000, loss_test:0.09444, lr:6.05e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.159, tt:2796.543\n",
      "Ep:154, loss:0.00000, loss_test:0.09949, lr:5.99e-03, fs:0.77320 (r=0.758,p=0.789),  time:18.165, tt:2815.546\n",
      "Ep:155, loss:0.00000, loss_test:0.09978, lr:5.93e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.174, tt:2835.181\n",
      "Ep:156, loss:0.00000, loss_test:0.09686, lr:5.87e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.183, tt:2854.717\n",
      "Ep:157, loss:0.00000, loss_test:0.09663, lr:5.81e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.195, tt:2874.831\n",
      "Ep:158, loss:0.00000, loss_test:0.09952, lr:5.75e-03, fs:0.77320 (r=0.758,p=0.789),  time:18.206, tt:2894.737\n",
      "Ep:159, loss:0.00000, loss_test:0.09794, lr:5.70e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.217, tt:2914.673\n",
      "Ep:160, loss:0.00000, loss_test:0.09514, lr:5.64e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.223, tt:2933.972\n",
      "Ep:161, loss:0.00000, loss_test:0.09830, lr:5.58e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.232, tt:2953.531\n",
      "Ep:162, loss:0.00000, loss_test:0.10113, lr:5.53e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.239, tt:2972.967\n",
      "Ep:163, loss:0.00000, loss_test:0.09836, lr:5.47e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.245, tt:2992.133\n",
      "Ep:164, loss:0.00000, loss_test:0.09524, lr:5.42e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.242, tt:3009.971\n",
      "Ep:165, loss:0.00000, loss_test:0.09802, lr:5.36e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.251, tt:3029.629\n",
      "Ep:166, loss:0.00000, loss_test:0.10034, lr:5.31e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.258, tt:3049.060\n",
      "Ep:167, loss:0.00000, loss_test:0.09876, lr:5.26e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.262, tt:3068.035\n",
      "Ep:168, loss:0.00000, loss_test:0.09737, lr:5.20e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.268, tt:3087.273\n",
      "Ep:169, loss:0.00000, loss_test:0.09843, lr:5.15e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.274, tt:3106.545\n",
      "Ep:170, loss:0.00000, loss_test:0.09894, lr:5.10e-03, fs:0.77949 (r=0.768,p=0.792),  time:18.279, tt:3125.683\n",
      "Ep:171, loss:0.00000, loss_test:0.09652, lr:5.05e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.283, tt:3144.626\n",
      "Ep:172, loss:0.00000, loss_test:0.09758, lr:5.00e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.283, tt:3163.035\n",
      "Ep:173, loss:0.00000, loss_test:0.09947, lr:4.95e-03, fs:0.78125 (r=0.758,p=0.806),  time:18.288, tt:3182.070\n",
      "Ep:174, loss:0.00000, loss_test:0.09863, lr:4.90e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.291, tt:3200.878\n",
      "Ep:175, loss:0.00000, loss_test:0.09730, lr:4.85e-03, fs:0.79167 (r=0.768,p=0.817),  time:18.298, tt:3220.426\n",
      "Ep:176, loss:0.00000, loss_test:0.09752, lr:4.80e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.299, tt:3238.945\n",
      "Ep:177, loss:0.00000, loss_test:0.09817, lr:4.75e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.301, tt:3257.624\n",
      "Ep:178, loss:0.00000, loss_test:0.09849, lr:4.71e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.303, tt:3276.159\n",
      "Ep:179, loss:0.00000, loss_test:0.09841, lr:4.66e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.303, tt:3294.528\n",
      "Ep:180, loss:0.00000, loss_test:0.09781, lr:4.61e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.300, tt:3312.375\n",
      "Ep:181, loss:0.00000, loss_test:0.09766, lr:4.57e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.299, tt:3330.454\n",
      "Ep:182, loss:0.00000, loss_test:0.09930, lr:4.52e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.301, tt:3349.146\n",
      "Ep:183, loss:0.00000, loss_test:0.09803, lr:4.48e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.299, tt:3367.089\n",
      "Ep:184, loss:0.00000, loss_test:0.09733, lr:4.43e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.308, tt:3386.928\n",
      "Ep:185, loss:0.00000, loss_test:0.09888, lr:4.39e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.309, tt:3405.480\n",
      "Ep:186, loss:0.00000, loss_test:0.09918, lr:4.34e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.311, tt:3424.141\n",
      "Ep:187, loss:0.00000, loss_test:0.09689, lr:4.30e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.312, tt:3442.631\n",
      "Ep:188, loss:0.00000, loss_test:0.09838, lr:4.26e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.311, tt:3460.723\n",
      "Ep:189, loss:0.00000, loss_test:0.10023, lr:4.21e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.317, tt:3480.231\n",
      "Ep:190, loss:0.00000, loss_test:0.09874, lr:4.17e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.315, tt:3498.254\n",
      "Ep:191, loss:0.00000, loss_test:0.09733, lr:4.13e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.318, tt:3517.073\n",
      "Ep:192, loss:0.00000, loss_test:0.09824, lr:4.09e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.329, tt:3537.589\n",
      "Ep:193, loss:0.00000, loss_test:0.09845, lr:4.05e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.332, tt:3556.384\n",
      "Ep:194, loss:0.00000, loss_test:0.09837, lr:4.01e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.331, tt:3574.481\n",
      "Ep:195, loss:0.00000, loss_test:0.09847, lr:3.97e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.331, tt:3592.920\n",
      "Ep:196, loss:0.00000, loss_test:0.09850, lr:3.93e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.333, tt:3611.547\n",
      "Ep:197, loss:0.00000, loss_test:0.09819, lr:3.89e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.331, tt:3629.562\n",
      "Ep:198, loss:0.00000, loss_test:0.09816, lr:3.85e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.335, tt:3648.691\n",
      "Ep:199, loss:0.00000, loss_test:0.09835, lr:3.81e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.336, tt:3667.187\n",
      "Ep:200, loss:0.00000, loss_test:0.09808, lr:3.77e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.338, tt:3685.853\n",
      "Ep:201, loss:0.00000, loss_test:0.09861, lr:3.73e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.329, tt:3702.485\n",
      "Ep:202, loss:0.00000, loss_test:0.09919, lr:3.70e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.322, tt:3719.379\n",
      "Ep:203, loss:0.00000, loss_test:0.09838, lr:3.66e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.311, tt:3735.521\n",
      "Ep:204, loss:0.00000, loss_test:0.09783, lr:3.62e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.314, tt:3754.388\n",
      "Ep:205, loss:0.00000, loss_test:0.09896, lr:3.59e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.311, tt:3772.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.09934, lr:3.55e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.307, tt:3789.601\n",
      "Ep:207, loss:0.00000, loss_test:0.09971, lr:3.52e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.305, tt:3807.412\n",
      "Ep:208, loss:0.00000, loss_test:0.09959, lr:3.48e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.304, tt:3825.472\n",
      "Ep:209, loss:0.00000, loss_test:0.09865, lr:3.45e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.304, tt:3843.923\n",
      "Ep:210, loss:0.00000, loss_test:0.09850, lr:3.41e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.305, tt:3862.378\n",
      "Ep:211, loss:0.00000, loss_test:0.09867, lr:3.38e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.300, tt:3879.520\n",
      "Ep:212, loss:0.00000, loss_test:0.09893, lr:3.34e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.298, tt:3897.547\n",
      "Ep:213, loss:0.00000, loss_test:0.09938, lr:3.31e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.295, tt:3915.177\n",
      "Ep:214, loss:0.00000, loss_test:0.09931, lr:3.28e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.293, tt:3932.905\n",
      "Ep:215, loss:0.00000, loss_test:0.09790, lr:3.24e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.290, tt:3950.560\n",
      "Ep:216, loss:0.00000, loss_test:0.09866, lr:3.21e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.288, tt:3968.526\n",
      "Ep:217, loss:0.00000, loss_test:0.09963, lr:3.18e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.282, tt:3985.492\n",
      "Ep:218, loss:0.00000, loss_test:0.09898, lr:3.15e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.278, tt:4002.880\n",
      "Ep:219, loss:0.00000, loss_test:0.09934, lr:3.12e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.275, tt:4020.560\n",
      "Ep:220, loss:0.00000, loss_test:0.09986, lr:3.09e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.278, tt:4039.539\n",
      "Ep:221, loss:0.00000, loss_test:0.09880, lr:3.05e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.275, tt:4057.009\n",
      "Ep:222, loss:0.00000, loss_test:0.09789, lr:3.02e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.271, tt:4074.511\n",
      "Ep:223, loss:0.00000, loss_test:0.09905, lr:2.99e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.263, tt:4090.890\n",
      "Ep:224, loss:0.00000, loss_test:0.09910, lr:2.96e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.261, tt:4108.835\n",
      "Ep:225, loss:0.00000, loss_test:0.09949, lr:2.93e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.252, tt:4124.947\n",
      "Ep:226, loss:0.00000, loss_test:0.09976, lr:2.90e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.257, tt:4144.257\n",
      "Ep:227, loss:0.00000, loss_test:0.09938, lr:2.88e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.259, tt:4163.147\n",
      "Ep:228, loss:0.00000, loss_test:0.09818, lr:2.85e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.260, tt:4181.653\n",
      "Ep:229, loss:0.00000, loss_test:0.09887, lr:2.82e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.261, tt:4199.989\n",
      "Ep:230, loss:0.00000, loss_test:0.09971, lr:2.79e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.269, tt:4220.030\n",
      "Ep:231, loss:0.00000, loss_test:0.09995, lr:2.76e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.269, tt:4238.373\n",
      "Ep:232, loss:0.00000, loss_test:0.09932, lr:2.73e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.270, tt:4256.962\n",
      "Ep:233, loss:0.00000, loss_test:0.09887, lr:2.71e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.268, tt:4274.767\n",
      "Ep:234, loss:0.00000, loss_test:0.09892, lr:2.68e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.270, tt:4293.368\n",
      "Ep:235, loss:0.00000, loss_test:0.09937, lr:2.65e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.272, tt:4312.186\n",
      "Ep:236, loss:0.00000, loss_test:0.09926, lr:2.63e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.269, tt:4329.789\n",
      "Ep:237, loss:0.00000, loss_test:0.09986, lr:2.60e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.274, tt:4349.192\n",
      "Ep:238, loss:0.00000, loss_test:0.09983, lr:2.57e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.278, tt:4368.413\n",
      "Ep:239, loss:0.00000, loss_test:0.09932, lr:2.55e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.279, tt:4386.992\n",
      "Ep:240, loss:0.00000, loss_test:0.09863, lr:2.52e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.278, tt:4404.923\n",
      "Ep:241, loss:0.00000, loss_test:0.09888, lr:2.50e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.275, tt:4422.638\n",
      "Ep:242, loss:0.00000, loss_test:0.10010, lr:2.47e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.277, tt:4441.257\n",
      "Ep:243, loss:0.00000, loss_test:0.10015, lr:2.45e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.278, tt:4459.788\n",
      "Ep:244, loss:0.00000, loss_test:0.09904, lr:2.42e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.270, tt:4476.186\n",
      "Ep:245, loss:0.00000, loss_test:0.09870, lr:2.40e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.271, tt:4494.622\n",
      "Ep:246, loss:0.00000, loss_test:0.09947, lr:2.38e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.269, tt:4512.361\n",
      "Ep:247, loss:0.00000, loss_test:0.09903, lr:2.35e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.273, tt:4531.627\n",
      "Ep:248, loss:0.00000, loss_test:0.09886, lr:2.33e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.269, tt:4549.010\n",
      "Ep:249, loss:0.00000, loss_test:0.09939, lr:2.31e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.269, tt:4567.178\n",
      "Ep:250, loss:0.00000, loss_test:0.09955, lr:2.28e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.268, tt:4585.214\n",
      "Ep:251, loss:0.00000, loss_test:0.09910, lr:2.26e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.264, tt:4602.619\n",
      "Ep:252, loss:0.00000, loss_test:0.09924, lr:2.24e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.266, tt:4621.270\n",
      "Ep:253, loss:0.00000, loss_test:0.09941, lr:2.21e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.272, tt:4641.041\n",
      "Ep:254, loss:0.00000, loss_test:0.09881, lr:2.19e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.272, tt:4659.430\n",
      "Ep:255, loss:0.00000, loss_test:0.09901, lr:2.17e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.274, tt:4678.244\n",
      "Ep:256, loss:0.00000, loss_test:0.09978, lr:2.15e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.274, tt:4696.379\n",
      "Ep:257, loss:0.00000, loss_test:0.10016, lr:2.13e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.274, tt:4714.718\n",
      "Ep:258, loss:0.00000, loss_test:0.09910, lr:2.11e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.275, tt:4733.296\n",
      "Ep:259, loss:0.00000, loss_test:0.09890, lr:2.08e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.273, tt:4750.920\n",
      "Ep:260, loss:0.00000, loss_test:0.09948, lr:2.06e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.273, tt:4769.199\n",
      "Ep:261, loss:0.00000, loss_test:0.09992, lr:2.04e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.275, tt:4788.131\n",
      "Ep:262, loss:0.00000, loss_test:0.09934, lr:2.02e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.275, tt:4806.267\n",
      "Ep:263, loss:0.00000, loss_test:0.09902, lr:2.00e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.275, tt:4824.717\n",
      "Ep:264, loss:0.00000, loss_test:0.09953, lr:1.98e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.270, tt:4841.542\n",
      "Ep:265, loss:0.00000, loss_test:0.09990, lr:1.96e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.268, tt:4859.420\n",
      "Ep:266, loss:0.00000, loss_test:0.09911, lr:1.94e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.263, tt:4876.235\n",
      "Ep:267, loss:0.00000, loss_test:0.09900, lr:1.92e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.255, tt:4892.458\n",
      "Ep:268, loss:0.00000, loss_test:0.09955, lr:1.90e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.253, tt:4909.977\n",
      "Ep:269, loss:0.00000, loss_test:0.09994, lr:1.89e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.246, tt:4926.296\n",
      "Ep:270, loss:0.00000, loss_test:0.09922, lr:1.87e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.241, tt:4943.207\n",
      "Ep:271, loss:0.00000, loss_test:0.09897, lr:1.85e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.234, tt:4959.558\n",
      "Ep:272, loss:0.00000, loss_test:0.09947, lr:1.83e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.225, tt:4975.539\n",
      "Ep:273, loss:0.00000, loss_test:0.09988, lr:1.81e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.225, tt:4993.595\n",
      "Ep:274, loss:0.00000, loss_test:0.09928, lr:1.79e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.222, tt:5011.134\n",
      "Ep:275, loss:0.00000, loss_test:0.09902, lr:1.78e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.217, tt:5027.809\n",
      "Ep:276, loss:0.00000, loss_test:0.09954, lr:1.76e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.208, tt:5043.572\n",
      "Ep:277, loss:0.00000, loss_test:0.10003, lr:1.74e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.202, tt:5060.285\n",
      "Ep:278, loss:0.00000, loss_test:0.09949, lr:1.72e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.197, tt:5077.079\n",
      "Ep:279, loss:0.00000, loss_test:0.09910, lr:1.71e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.194, tt:5094.211\n",
      "Ep:280, loss:0.00000, loss_test:0.09948, lr:1.69e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.186, tt:5110.228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:281, loss:0.00000, loss_test:0.10000, lr:1.67e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.179, tt:5126.455\n",
      "Ep:282, loss:0.00000, loss_test:0.09971, lr:1.65e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.172, tt:5142.557\n",
      "Ep:283, loss:0.00000, loss_test:0.09912, lr:1.64e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.166, tt:5159.158\n",
      "Ep:284, loss:0.00000, loss_test:0.09936, lr:1.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.162, tt:5176.093\n",
      "Ep:285, loss:0.00000, loss_test:0.09977, lr:1.61e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.156, tt:5192.648\n",
      "Ep:286, loss:0.00000, loss_test:0.09981, lr:1.59e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.151, tt:5209.358\n",
      "Ep:287, loss:0.00000, loss_test:0.09938, lr:1.57e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.144, tt:5225.370\n",
      "Ep:288, loss:0.00000, loss_test:0.09922, lr:1.56e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.132, tt:5240.237\n",
      "Ep:289, loss:0.00000, loss_test:0.09962, lr:1.54e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.119, tt:5254.425\n",
      "Ep:290, loss:0.00000, loss_test:0.09978, lr:1.53e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.113, tt:5270.848\n",
      "Ep:291, loss:0.00000, loss_test:0.09926, lr:1.51e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.105, tt:5286.647\n",
      "Ep:292, loss:0.00000, loss_test:0.09925, lr:1.50e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.096, tt:5302.146\n",
      "Ep:293, loss:0.00000, loss_test:0.09955, lr:1.48e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.091, tt:5318.666\n",
      "Ep:294, loss:0.00000, loss_test:0.09960, lr:1.47e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.081, tt:5333.846\n",
      "Ep:295, loss:0.00000, loss_test:0.09937, lr:1.45e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.072, tt:5349.310\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14651, lr:1.00e-02, fs:0.62500 (r=0.859,p=0.491),  time:13.191, tt:13.191\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14638, lr:1.00e-02, fs:0.61993 (r=0.848,p=0.488),  time:15.536, tt:31.071\n",
      "Ep:2, loss:0.00004, loss_test:0.14616, lr:1.00e-02, fs:0.62687 (r=0.848,p=0.497),  time:16.511, tt:49.533\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.14583, lr:1.00e-02, fs:0.63602 (r=0.838,p=0.512),  time:16.772, tt:67.090\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.14540, lr:1.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:17.046, tt:85.229\n",
      "Ep:5, loss:0.00004, loss_test:0.14492, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:17.138, tt:102.826\n",
      "Ep:6, loss:0.00004, loss_test:0.14442, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:17.193, tt:120.350\n",
      "Ep:7, loss:0.00004, loss_test:0.14390, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:17.192, tt:137.538\n",
      "Ep:8, loss:0.00004, loss_test:0.14336, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:17.319, tt:155.875\n",
      "Ep:9, loss:0.00004, loss_test:0.14280, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:17.380, tt:173.796\n",
      "Ep:10, loss:0.00004, loss_test:0.14220, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:17.505, tt:192.557\n",
      "Ep:11, loss:0.00004, loss_test:0.14161, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:17.614, tt:211.367\n",
      "Ep:12, loss:0.00004, loss_test:0.14105, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:17.718, tt:230.335\n",
      "Ep:13, loss:0.00004, loss_test:0.14062, lr:1.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:17.794, tt:249.112\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.14031, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:17.768, tt:266.524\n",
      "Ep:15, loss:0.00004, loss_test:0.14002, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:17.776, tt:284.420\n",
      "Ep:16, loss:0.00004, loss_test:0.13974, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:17.863, tt:303.669\n",
      "Ep:17, loss:0.00004, loss_test:0.13946, lr:1.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:17.896, tt:322.132\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.13918, lr:1.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:17.924, tt:340.549\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.13878, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:17.941, tt:358.817\n",
      "Ep:20, loss:0.00003, loss_test:0.13825, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:17.955, tt:377.053\n",
      "Ep:21, loss:0.00003, loss_test:0.13766, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:17.980, tt:395.558\n",
      "Ep:22, loss:0.00003, loss_test:0.13699, lr:1.00e-02, fs:0.62903 (r=0.788,p=0.523),  time:17.987, tt:413.710\n",
      "Ep:23, loss:0.00003, loss_test:0.13634, lr:1.00e-02, fs:0.63415 (r=0.788,p=0.531),  time:18.010, tt:432.246\n",
      "Ep:24, loss:0.00003, loss_test:0.13571, lr:1.00e-02, fs:0.63415 (r=0.788,p=0.531),  time:18.049, tt:451.231\n",
      "Ep:25, loss:0.00003, loss_test:0.13516, lr:1.00e-02, fs:0.63115 (r=0.778,p=0.531),  time:18.064, tt:469.669\n",
      "Ep:26, loss:0.00003, loss_test:0.13463, lr:1.00e-02, fs:0.63115 (r=0.778,p=0.531),  time:18.111, tt:489.003\n",
      "Ep:27, loss:0.00003, loss_test:0.13406, lr:1.00e-02, fs:0.62810 (r=0.768,p=0.531),  time:18.140, tt:507.907\n",
      "Ep:28, loss:0.00003, loss_test:0.13344, lr:1.00e-02, fs:0.62762 (r=0.758,p=0.536),  time:18.166, tt:526.807\n",
      "Ep:29, loss:0.00003, loss_test:0.13278, lr:1.00e-02, fs:0.63025 (r=0.758,p=0.540),  time:18.212, tt:546.374\n",
      "Ep:30, loss:0.00003, loss_test:0.13194, lr:9.90e-03, fs:0.63291 (r=0.758,p=0.543),  time:18.232, tt:565.177\n",
      "Ep:31, loss:0.00003, loss_test:0.13091, lr:9.80e-03, fs:0.63830 (r=0.758,p=0.551),  time:18.226, tt:583.220\n",
      "Ep:32, loss:0.00003, loss_test:0.12983, lr:9.70e-03, fs:0.64103 (r=0.758,p=0.556),  time:18.201, tt:600.618\n",
      "Ep:33, loss:0.00003, loss_test:0.12873, lr:9.61e-03, fs:0.64655 (r=0.758,p=0.564),  time:18.216, tt:619.345\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.12754, lr:9.61e-03, fs:0.64348 (r=0.747,p=0.565),  time:18.227, tt:637.951\n",
      "Ep:35, loss:0.00003, loss_test:0.12656, lr:9.61e-03, fs:0.64348 (r=0.747,p=0.565),  time:18.237, tt:656.515\n",
      "Ep:36, loss:0.00003, loss_test:0.12564, lr:9.61e-03, fs:0.65179 (r=0.737,p=0.584),  time:18.236, tt:674.726\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.12459, lr:9.61e-03, fs:0.66364 (r=0.737,p=0.603),  time:18.252, tt:693.577\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.12346, lr:9.61e-03, fs:0.65438 (r=0.717,p=0.602),  time:18.234, tt:711.117\n",
      "Ep:39, loss:0.00003, loss_test:0.12241, lr:9.61e-03, fs:0.65728 (r=0.707,p=0.614),  time:18.274, tt:730.957\n",
      "Ep:40, loss:0.00003, loss_test:0.12169, lr:9.61e-03, fs:0.66355 (r=0.717,p=0.617),  time:18.292, tt:749.953\n",
      "Ep:41, loss:0.00003, loss_test:0.12113, lr:9.61e-03, fs:0.66977 (r=0.727,p=0.621),  time:18.313, tt:769.154\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.12078, lr:9.61e-03, fs:0.67606 (r=0.727,p=0.632),  time:18.327, tt:788.055\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.12073, lr:9.61e-03, fs:0.67619 (r=0.717,p=0.640),  time:18.351, tt:807.442\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.12100, lr:9.61e-03, fs:0.66351 (r=0.707,p=0.625),  time:18.375, tt:826.892\n",
      "Ep:45, loss:0.00003, loss_test:0.12139, lr:9.61e-03, fs:0.66986 (r=0.707,p=0.636),  time:18.401, tt:846.442\n",
      "Ep:46, loss:0.00003, loss_test:0.12168, lr:9.61e-03, fs:0.67633 (r=0.707,p=0.648),  time:18.406, tt:865.086\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.12208, lr:9.61e-03, fs:0.67943 (r=0.717,p=0.645),  time:18.439, tt:885.054\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.12259, lr:9.61e-03, fs:0.67633 (r=0.707,p=0.648),  time:18.469, tt:905.002\n",
      "Ep:49, loss:0.00002, loss_test:0.12305, lr:9.61e-03, fs:0.66019 (r=0.687,p=0.636),  time:18.495, tt:924.749\n",
      "Ep:50, loss:0.00002, loss_test:0.12342, lr:9.61e-03, fs:0.63636 (r=0.636,p=0.636),  time:18.503, tt:943.667\n",
      "Ep:51, loss:0.00002, loss_test:0.12366, lr:9.61e-03, fs:0.64322 (r=0.646,p=0.640),  time:18.509, tt:962.448\n",
      "Ep:52, loss:0.00002, loss_test:0.12387, lr:9.61e-03, fs:0.62944 (r=0.626,p=0.633),  time:18.542, tt:982.705\n",
      "Ep:53, loss:0.00002, loss_test:0.12389, lr:9.61e-03, fs:0.61929 (r=0.616,p=0.622),  time:18.610, tt:1004.944\n",
      "Ep:54, loss:0.00002, loss_test:0.12393, lr:9.61e-03, fs:0.62245 (r=0.616,p=0.629),  time:18.622, tt:1024.238\n",
      "Ep:55, loss:0.00002, loss_test:0.12385, lr:9.61e-03, fs:0.62245 (r=0.616,p=0.629),  time:18.669, tt:1045.468\n",
      "Ep:56, loss:0.00002, loss_test:0.12390, lr:9.61e-03, fs:0.62312 (r=0.626,p=0.620),  time:18.684, tt:1064.975\n",
      "Ep:57, loss:0.00002, loss_test:0.12452, lr:9.61e-03, fs:0.62944 (r=0.626,p=0.633),  time:18.689, tt:1083.979\n",
      "Ep:58, loss:0.00002, loss_test:0.12509, lr:9.61e-03, fs:0.62245 (r=0.616,p=0.629),  time:18.702, tt:1103.439\n",
      "Ep:59, loss:0.00002, loss_test:0.12538, lr:9.51e-03, fs:0.62176 (r=0.606,p=0.638),  time:18.713, tt:1122.783\n",
      "Ep:60, loss:0.00002, loss_test:0.12551, lr:9.41e-03, fs:0.61856 (r=0.606,p=0.632),  time:18.723, tt:1142.105\n",
      "Ep:61, loss:0.00002, loss_test:0.12567, lr:9.32e-03, fs:0.62564 (r=0.616,p=0.635),  time:18.734, tt:1161.496\n",
      "Ep:62, loss:0.00002, loss_test:0.12599, lr:9.23e-03, fs:0.62564 (r=0.616,p=0.635),  time:18.749, tt:1181.199\n",
      "Ep:63, loss:0.00002, loss_test:0.12649, lr:9.14e-03, fs:0.62176 (r=0.606,p=0.638),  time:18.759, tt:1200.564\n",
      "Ep:64, loss:0.00002, loss_test:0.12726, lr:9.04e-03, fs:0.62176 (r=0.606,p=0.638),  time:18.756, tt:1219.121\n",
      "Ep:65, loss:0.00002, loss_test:0.12835, lr:8.95e-03, fs:0.63542 (r=0.616,p=0.656),  time:18.771, tt:1238.891\n",
      "Ep:66, loss:0.00002, loss_test:0.12866, lr:8.86e-03, fs:0.63212 (r=0.616,p=0.649),  time:18.788, tt:1258.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00002, loss_test:0.12911, lr:8.78e-03, fs:0.63212 (r=0.616,p=0.649),  time:18.775, tt:1276.669\n",
      "Ep:68, loss:0.00002, loss_test:0.12974, lr:8.69e-03, fs:0.63542 (r=0.616,p=0.656),  time:18.791, tt:1296.560\n",
      "Ep:69, loss:0.00002, loss_test:0.12941, lr:8.60e-03, fs:0.63542 (r=0.616,p=0.656),  time:18.807, tt:1316.483\n",
      "Ep:70, loss:0.00002, loss_test:0.12943, lr:8.51e-03, fs:0.64211 (r=0.616,p=0.670),  time:18.805, tt:1335.169\n",
      "Ep:71, loss:0.00002, loss_test:0.13025, lr:8.43e-03, fs:0.65625 (r=0.636,p=0.677),  time:18.816, tt:1354.753\n",
      "Ep:72, loss:0.00002, loss_test:0.13065, lr:8.35e-03, fs:0.65969 (r=0.636,p=0.685),  time:18.809, tt:1373.058\n",
      "Ep:73, loss:0.00002, loss_test:0.13025, lr:8.26e-03, fs:0.67016 (r=0.646,p=0.696),  time:18.806, tt:1391.626\n",
      "Ep:74, loss:0.00002, loss_test:0.13027, lr:8.18e-03, fs:0.67016 (r=0.646,p=0.696),  time:18.803, tt:1410.262\n",
      "Ep:75, loss:0.00001, loss_test:0.13086, lr:8.10e-03, fs:0.67368 (r=0.646,p=0.703),  time:18.785, tt:1427.655\n",
      "Ep:76, loss:0.00001, loss_test:0.13068, lr:8.02e-03, fs:0.68085 (r=0.646,p=0.719),  time:18.776, tt:1445.770\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.13212, lr:8.02e-03, fs:0.67725 (r=0.646,p=0.711),  time:18.780, tt:1464.857\n",
      "Ep:78, loss:0.00001, loss_test:0.13172, lr:8.02e-03, fs:0.67742 (r=0.636,p=0.724),  time:18.785, tt:1483.989\n",
      "Ep:79, loss:0.00001, loss_test:0.13205, lr:8.02e-03, fs:0.67742 (r=0.636,p=0.724),  time:18.782, tt:1502.532\n",
      "Ep:80, loss:0.00001, loss_test:0.13291, lr:8.02e-03, fs:0.68085 (r=0.646,p=0.719),  time:18.785, tt:1521.623\n",
      "Ep:81, loss:0.00001, loss_test:0.13250, lr:8.02e-03, fs:0.67742 (r=0.636,p=0.724),  time:18.794, tt:1541.075\n",
      "Ep:82, loss:0.00001, loss_test:0.13333, lr:8.02e-03, fs:0.67380 (r=0.636,p=0.716),  time:18.778, tt:1558.555\n",
      "Ep:83, loss:0.00001, loss_test:0.13347, lr:8.02e-03, fs:0.67742 (r=0.636,p=0.724),  time:18.818, tt:1580.704\n",
      "Ep:84, loss:0.00001, loss_test:0.13290, lr:8.02e-03, fs:0.66304 (r=0.616,p=0.718),  time:18.814, tt:1599.221\n",
      "Ep:85, loss:0.00001, loss_test:0.13282, lr:8.02e-03, fs:0.66304 (r=0.616,p=0.718),  time:18.807, tt:1617.407\n",
      "Ep:86, loss:0.00001, loss_test:0.13208, lr:8.02e-03, fs:0.65934 (r=0.606,p=0.723),  time:18.795, tt:1635.161\n",
      "Ep:87, loss:0.00001, loss_test:0.13464, lr:8.02e-03, fs:0.67380 (r=0.636,p=0.716),  time:18.790, tt:1653.529\n",
      "Ep:88, loss:0.00001, loss_test:0.12766, lr:7.94e-03, fs:0.65556 (r=0.596,p=0.728),  time:18.793, tt:1672.558\n",
      "Ep:89, loss:0.00001, loss_test:0.13691, lr:7.86e-03, fs:0.64894 (r=0.616,p=0.685),  time:18.788, tt:1690.929\n",
      "Ep:90, loss:0.00001, loss_test:0.12077, lr:7.78e-03, fs:0.73239 (r=0.788,p=0.684),  time:18.781, tt:1709.112\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.13266, lr:7.78e-03, fs:0.64286 (r=0.636,p=0.649),  time:18.786, tt:1728.289\n",
      "Ep:92, loss:0.00001, loss_test:0.11778, lr:7.78e-03, fs:0.65922 (r=0.596,p=0.738),  time:18.781, tt:1746.635\n",
      "Ep:93, loss:0.00001, loss_test:0.11981, lr:7.78e-03, fs:0.65574 (r=0.606,p=0.714),  time:18.784, tt:1765.661\n",
      "Ep:94, loss:0.00001, loss_test:0.13081, lr:7.78e-03, fs:0.67033 (r=0.616,p=0.735),  time:18.777, tt:1783.793\n",
      "Ep:95, loss:0.00001, loss_test:0.12497, lr:7.78e-03, fs:0.68132 (r=0.626,p=0.747),  time:18.775, tt:1802.431\n",
      "Ep:96, loss:0.00001, loss_test:0.11284, lr:7.78e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.769, tt:1820.624\n",
      "Ep:97, loss:0.00001, loss_test:0.12257, lr:7.78e-03, fs:0.68132 (r=0.626,p=0.747),  time:18.778, tt:1840.275\n",
      "Ep:98, loss:0.00001, loss_test:0.12512, lr:7.78e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.782, tt:1859.369\n",
      "Ep:99, loss:0.00001, loss_test:0.12174, lr:7.78e-03, fs:0.67045 (r=0.596,p=0.766),  time:18.780, tt:1877.994\n",
      "Ep:100, loss:0.00001, loss_test:0.11737, lr:7.78e-03, fs:0.67039 (r=0.606,p=0.750),  time:18.785, tt:1897.296\n",
      "Ep:101, loss:0.00001, loss_test:0.12489, lr:7.78e-03, fs:0.67797 (r=0.606,p=0.769),  time:18.799, tt:1917.536\n",
      "Ep:102, loss:0.00001, loss_test:0.12340, lr:7.70e-03, fs:0.68449 (r=0.646,p=0.727),  time:18.800, tt:1936.380\n",
      "Ep:103, loss:0.00001, loss_test:0.11750, lr:7.62e-03, fs:0.66667 (r=0.596,p=0.756),  time:18.796, tt:1954.774\n",
      "Ep:104, loss:0.00001, loss_test:0.11448, lr:7.55e-03, fs:0.68182 (r=0.606,p=0.779),  time:18.792, tt:1973.128\n",
      "Ep:105, loss:0.00001, loss_test:0.12726, lr:7.47e-03, fs:0.67742 (r=0.636,p=0.724),  time:18.785, tt:1991.215\n",
      "Ep:106, loss:0.00001, loss_test:0.12710, lr:7.40e-03, fs:0.68132 (r=0.626,p=0.747),  time:18.794, tt:2010.967\n",
      "Ep:107, loss:0.00001, loss_test:0.11608, lr:7.32e-03, fs:0.67429 (r=0.596,p=0.776),  time:18.782, tt:2028.468\n",
      "Ep:108, loss:0.00001, loss_test:0.12286, lr:7.25e-03, fs:0.67429 (r=0.596,p=0.776),  time:18.777, tt:2046.646\n",
      "Ep:109, loss:0.00001, loss_test:0.12578, lr:7.18e-03, fs:0.68817 (r=0.646,p=0.736),  time:18.789, tt:2066.816\n",
      "Ep:110, loss:0.00001, loss_test:0.12026, lr:7.11e-03, fs:0.67045 (r=0.596,p=0.766),  time:18.791, tt:2085.769\n",
      "Ep:111, loss:0.00001, loss_test:0.11814, lr:7.03e-03, fs:0.67429 (r=0.596,p=0.776),  time:18.792, tt:2104.703\n",
      "Ep:112, loss:0.00001, loss_test:0.12834, lr:6.96e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.788, tt:2123.061\n",
      "Ep:113, loss:0.00001, loss_test:0.12664, lr:6.89e-03, fs:0.70000 (r=0.636,p=0.778),  time:18.798, tt:2142.974\n",
      "Ep:114, loss:0.00001, loss_test:0.11991, lr:6.83e-03, fs:0.68605 (r=0.596,p=0.808),  time:18.795, tt:2161.417\n",
      "Ep:115, loss:0.00001, loss_test:0.12041, lr:6.76e-03, fs:0.69714 (r=0.616,p=0.803),  time:18.800, tt:2180.849\n",
      "Ep:116, loss:0.00001, loss_test:0.12152, lr:6.69e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.803, tt:2199.922\n",
      "Ep:117, loss:0.00001, loss_test:0.12464, lr:6.62e-03, fs:0.71591 (r=0.636,p=0.818),  time:18.810, tt:2219.543\n",
      "Ep:118, loss:0.00001, loss_test:0.12193, lr:6.56e-03, fs:0.68605 (r=0.596,p=0.808),  time:18.800, tt:2237.179\n",
      "Ep:119, loss:0.00001, loss_test:0.12479, lr:6.49e-03, fs:0.71591 (r=0.636,p=0.818),  time:18.808, tt:2256.990\n",
      "Ep:120, loss:0.00001, loss_test:0.12799, lr:6.43e-03, fs:0.71186 (r=0.636,p=0.808),  time:18.814, tt:2276.486\n",
      "Ep:121, loss:0.00001, loss_test:0.12199, lr:6.36e-03, fs:0.70455 (r=0.626,p=0.805),  time:18.814, tt:2295.363\n",
      "Ep:122, loss:0.00001, loss_test:0.11913, lr:6.30e-03, fs:0.68208 (r=0.596,p=0.797),  time:18.801, tt:2312.552\n",
      "Ep:123, loss:0.00001, loss_test:0.12715, lr:6.24e-03, fs:0.70857 (r=0.626,p=0.816),  time:18.791, tt:2330.085\n",
      "Ep:124, loss:0.00001, loss_test:0.12758, lr:6.17e-03, fs:0.71264 (r=0.626,p=0.827),  time:18.795, tt:2349.427\n",
      "Ep:125, loss:0.00001, loss_test:0.12226, lr:6.11e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.798, tt:2368.575\n",
      "Ep:126, loss:0.00001, loss_test:0.12398, lr:6.05e-03, fs:0.70520 (r=0.616,p=0.824),  time:18.801, tt:2387.746\n",
      "Ep:127, loss:0.00001, loss_test:0.12473, lr:5.99e-03, fs:0.71264 (r=0.626,p=0.827),  time:18.807, tt:2407.316\n",
      "Ep:128, loss:0.00001, loss_test:0.12028, lr:5.93e-03, fs:0.71765 (r=0.616,p=0.859),  time:18.806, tt:2425.929\n",
      "Ep:129, loss:0.00001, loss_test:0.12265, lr:5.87e-03, fs:0.70588 (r=0.606,p=0.845),  time:18.805, tt:2444.594\n",
      "Ep:130, loss:0.00001, loss_test:0.12602, lr:5.81e-03, fs:0.70520 (r=0.616,p=0.824),  time:18.810, tt:2464.140\n",
      "Ep:131, loss:0.00001, loss_test:0.12291, lr:5.75e-03, fs:0.71006 (r=0.606,p=0.857),  time:18.814, tt:2483.388\n",
      "Ep:132, loss:0.00001, loss_test:0.12322, lr:5.70e-03, fs:0.70588 (r=0.606,p=0.845),  time:18.816, tt:2502.564\n",
      "Ep:133, loss:0.00001, loss_test:0.12594, lr:5.64e-03, fs:0.71264 (r=0.626,p=0.827),  time:18.812, tt:2520.841\n",
      "Ep:134, loss:0.00001, loss_test:0.12311, lr:5.58e-03, fs:0.72189 (r=0.616,p=0.871),  time:18.810, tt:2539.338\n",
      "Ep:135, loss:0.00001, loss_test:0.12431, lr:5.53e-03, fs:0.71006 (r=0.606,p=0.857),  time:18.812, tt:2558.370\n",
      "Ep:136, loss:0.00001, loss_test:0.12586, lr:5.47e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.798, tt:2575.316\n",
      "Ep:137, loss:0.00001, loss_test:0.12359, lr:5.42e-03, fs:0.72941 (r=0.626,p=0.873),  time:18.795, tt:2593.730\n",
      "Ep:138, loss:0.00001, loss_test:0.12407, lr:5.36e-03, fs:0.71006 (r=0.606,p=0.857),  time:18.793, tt:2612.170\n",
      "Ep:139, loss:0.00001, loss_test:0.12693, lr:5.31e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.798, tt:2631.666\n",
      "Ep:140, loss:0.00001, loss_test:0.12453, lr:5.26e-03, fs:0.72941 (r=0.626,p=0.873),  time:18.804, tt:2651.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.12346, lr:5.20e-03, fs:0.71006 (r=0.606,p=0.857),  time:18.804, tt:2670.171\n",
      "Ep:142, loss:0.00001, loss_test:0.12535, lr:5.15e-03, fs:0.69091 (r=0.576,p=0.864),  time:18.808, tt:2689.496\n",
      "Ep:143, loss:0.00001, loss_test:0.12363, lr:5.10e-03, fs:0.72941 (r=0.626,p=0.873),  time:18.809, tt:2708.442\n",
      "Ep:144, loss:0.00001, loss_test:0.12377, lr:5.05e-03, fs:0.71429 (r=0.606,p=0.870),  time:18.806, tt:2726.925\n",
      "Ep:145, loss:0.00001, loss_test:0.12657, lr:5.00e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.807, tt:2745.782\n",
      "Ep:146, loss:0.00001, loss_test:0.12551, lr:4.95e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.804, tt:2764.206\n",
      "Ep:147, loss:0.00001, loss_test:0.12217, lr:4.90e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.801, tt:2782.517\n",
      "Ep:148, loss:0.00001, loss_test:0.12538, lr:4.85e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.802, tt:2801.464\n",
      "Ep:149, loss:0.00001, loss_test:0.12621, lr:4.80e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.800, tt:2820.015\n",
      "Ep:150, loss:0.00001, loss_test:0.12245, lr:4.75e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.796, tt:2838.171\n",
      "Ep:151, loss:0.00001, loss_test:0.12620, lr:4.71e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.792, tt:2856.311\n",
      "Ep:152, loss:0.00001, loss_test:0.12568, lr:4.66e-03, fs:0.69091 (r=0.576,p=0.864),  time:18.788, tt:2874.516\n",
      "Ep:153, loss:0.00000, loss_test:0.12133, lr:4.61e-03, fs:0.68675 (r=0.576,p=0.851),  time:18.785, tt:2892.815\n",
      "Ep:154, loss:0.00000, loss_test:0.12498, lr:4.57e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.775, tt:2910.175\n",
      "Ep:155, loss:0.00000, loss_test:0.12663, lr:4.52e-03, fs:0.69091 (r=0.576,p=0.864),  time:18.771, tt:2928.311\n",
      "Ep:156, loss:0.00000, loss_test:0.12250, lr:4.48e-03, fs:0.66667 (r=0.545,p=0.857),  time:18.775, tt:2947.652\n",
      "Ep:157, loss:0.00000, loss_test:0.12499, lr:4.43e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.774, tt:2966.332\n",
      "Ep:158, loss:0.00000, loss_test:0.12629, lr:4.39e-03, fs:0.69091 (r=0.576,p=0.864),  time:18.790, tt:2987.552\n",
      "Ep:159, loss:0.00000, loss_test:0.12312, lr:4.34e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.794, tt:3007.023\n",
      "Ep:160, loss:0.00000, loss_test:0.12445, lr:4.30e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.798, tt:3026.556\n",
      "Ep:161, loss:0.00000, loss_test:0.12634, lr:4.26e-03, fs:0.69091 (r=0.576,p=0.864),  time:18.799, tt:3045.383\n",
      "Ep:162, loss:0.00000, loss_test:0.12355, lr:4.21e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.804, tt:3064.976\n",
      "Ep:163, loss:0.00000, loss_test:0.12347, lr:4.17e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.808, tt:3084.431\n",
      "Ep:164, loss:0.00000, loss_test:0.12560, lr:4.13e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.807, tt:3103.231\n",
      "Ep:165, loss:0.00000, loss_test:0.12410, lr:4.09e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.807, tt:3122.001\n",
      "Ep:166, loss:0.00000, loss_test:0.12366, lr:4.05e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.815, tt:3142.049\n",
      "Ep:167, loss:0.00000, loss_test:0.12520, lr:4.01e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.814, tt:3160.701\n",
      "Ep:168, loss:0.00000, loss_test:0.12518, lr:3.97e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.822, tt:3180.929\n",
      "Ep:169, loss:0.00000, loss_test:0.12329, lr:3.93e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.822, tt:3199.724\n",
      "Ep:170, loss:0.00000, loss_test:0.12420, lr:3.89e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.829, tt:3219.727\n",
      "Ep:171, loss:0.00000, loss_test:0.12586, lr:3.85e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.823, tt:3237.477\n",
      "Ep:172, loss:0.00000, loss_test:0.12484, lr:3.81e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.820, tt:3255.866\n",
      "Ep:173, loss:0.00000, loss_test:0.12364, lr:3.77e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.820, tt:3274.671\n",
      "Ep:174, loss:0.00000, loss_test:0.12487, lr:3.73e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.818, tt:3293.234\n",
      "Ep:175, loss:0.00000, loss_test:0.12554, lr:3.70e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.820, tt:3312.235\n",
      "Ep:176, loss:0.00000, loss_test:0.12472, lr:3.66e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.822, tt:3331.497\n",
      "Ep:177, loss:0.00000, loss_test:0.12398, lr:3.62e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.811, tt:3348.272\n",
      "Ep:178, loss:0.00000, loss_test:0.12476, lr:3.59e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.809, tt:3366.784\n",
      "Ep:179, loss:0.00000, loss_test:0.12570, lr:3.55e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.809, tt:3385.597\n",
      "Ep:180, loss:0.00000, loss_test:0.12484, lr:3.52e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.801, tt:3403.033\n",
      "Ep:181, loss:0.00000, loss_test:0.12437, lr:3.48e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.795, tt:3420.686\n",
      "Ep:182, loss:0.00000, loss_test:0.12533, lr:3.45e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.789, tt:3438.453\n",
      "Ep:183, loss:0.00000, loss_test:0.12564, lr:3.41e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.784, tt:3456.333\n",
      "Ep:184, loss:0.00000, loss_test:0.12483, lr:3.38e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.778, tt:3473.898\n",
      "Ep:185, loss:0.00000, loss_test:0.12560, lr:3.34e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.782, tt:3493.411\n",
      "Ep:186, loss:0.00000, loss_test:0.12601, lr:3.31e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.781, tt:3512.091\n",
      "Ep:187, loss:0.00000, loss_test:0.12490, lr:3.28e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.787, tt:3531.903\n",
      "Ep:188, loss:0.00000, loss_test:0.12537, lr:3.24e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.781, tt:3549.552\n",
      "Ep:189, loss:0.00000, loss_test:0.12683, lr:3.21e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.771, tt:3566.464\n",
      "Ep:190, loss:0.00000, loss_test:0.12540, lr:3.18e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.766, tt:3584.324\n",
      "Ep:191, loss:0.00000, loss_test:0.12519, lr:3.15e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.765, tt:3602.958\n",
      "Ep:192, loss:0.00000, loss_test:0.12670, lr:3.12e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.768, tt:3622.247\n",
      "Ep:193, loss:0.00000, loss_test:0.12626, lr:3.09e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.768, tt:3640.912\n",
      "Ep:194, loss:0.00000, loss_test:0.12534, lr:3.05e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.765, tt:3659.101\n",
      "Ep:195, loss:0.00000, loss_test:0.12677, lr:3.02e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.789, tt:3682.615\n",
      "Ep:196, loss:0.00000, loss_test:0.12700, lr:2.99e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.793, tt:3702.201\n",
      "Ep:197, loss:0.00000, loss_test:0.12594, lr:2.96e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.791, tt:3720.636\n",
      "Ep:198, loss:0.00000, loss_test:0.12704, lr:2.93e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.794, tt:3739.996\n",
      "Ep:199, loss:0.00000, loss_test:0.12767, lr:2.90e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.798, tt:3759.553\n",
      "Ep:200, loss:0.00000, loss_test:0.12705, lr:2.88e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.800, tt:3778.780\n",
      "Ep:201, loss:0.00000, loss_test:0.12780, lr:2.85e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.799, tt:3797.308\n",
      "Ep:202, loss:0.00000, loss_test:0.12780, lr:2.82e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.803, tt:3817.000\n",
      "Ep:203, loss:0.00000, loss_test:0.12714, lr:2.79e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.802, tt:3835.679\n",
      "Ep:204, loss:0.00000, loss_test:0.12793, lr:2.76e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.804, tt:3854.835\n",
      "Ep:205, loss:0.00000, loss_test:0.12865, lr:2.73e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.809, tt:3874.587\n",
      "Ep:206, loss:0.00000, loss_test:0.12823, lr:2.71e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.813, tt:3894.231\n",
      "Ep:207, loss:0.00000, loss_test:0.12737, lr:2.68e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.818, tt:3914.142\n",
      "Ep:208, loss:0.00000, loss_test:0.12930, lr:2.65e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.817, tt:3932.678\n",
      "Ep:209, loss:0.00000, loss_test:0.12935, lr:2.63e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.814, tt:3950.987\n",
      "Ep:210, loss:0.00000, loss_test:0.12759, lr:2.60e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.814, tt:3969.755\n",
      "Ep:211, loss:0.00000, loss_test:0.12834, lr:2.57e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.817, tt:3989.252\n",
      "Ep:212, loss:0.00000, loss_test:0.12916, lr:2.55e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.824, tt:4009.573\n",
      "Ep:213, loss:0.00000, loss_test:0.12844, lr:2.52e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.829, tt:4029.392\n",
      "Ep:214, loss:0.00000, loss_test:0.12832, lr:2.50e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.830, tt:4048.456\n",
      "Ep:215, loss:0.00000, loss_test:0.12997, lr:2.47e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.835, tt:4068.419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:216, loss:0.00000, loss_test:0.12964, lr:2.45e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.837, tt:4087.670\n",
      "Ep:217, loss:0.00000, loss_test:0.12826, lr:2.42e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.842, tt:4107.650\n",
      "Ep:218, loss:0.00000, loss_test:0.12960, lr:2.40e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.845, tt:4127.030\n",
      "Ep:219, loss:0.00000, loss_test:0.13038, lr:2.38e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.853, tt:4147.574\n",
      "Ep:220, loss:0.00000, loss_test:0.12922, lr:2.35e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.862, tt:4168.527\n",
      "Ep:221, loss:0.00000, loss_test:0.12883, lr:2.33e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.870, tt:4189.030\n",
      "Ep:222, loss:0.00000, loss_test:0.13080, lr:2.31e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.871, tt:4208.336\n",
      "Ep:223, loss:0.00000, loss_test:0.13014, lr:2.28e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.876, tt:4228.265\n",
      "Ep:224, loss:0.00000, loss_test:0.12848, lr:2.26e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.882, tt:4248.349\n",
      "Ep:225, loss:0.00000, loss_test:0.13013, lr:2.24e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.888, tt:4268.636\n",
      "Ep:226, loss:0.00000, loss_test:0.13090, lr:2.21e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.887, tt:4287.316\n",
      "Ep:227, loss:0.00000, loss_test:0.13011, lr:2.19e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.892, tt:4307.372\n",
      "Ep:228, loss:0.00000, loss_test:0.12952, lr:2.17e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.895, tt:4327.040\n",
      "Ep:229, loss:0.00000, loss_test:0.13056, lr:2.15e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.898, tt:4346.472\n",
      "Ep:230, loss:0.00000, loss_test:0.13094, lr:2.13e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.902, tt:4366.310\n",
      "Ep:231, loss:0.00000, loss_test:0.13004, lr:2.11e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.911, tt:4387.411\n",
      "Ep:232, loss:0.00000, loss_test:0.12965, lr:2.08e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.912, tt:4406.432\n",
      "Ep:233, loss:0.00000, loss_test:0.13116, lr:2.06e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.911, tt:4425.079\n",
      "Ep:234, loss:0.00000, loss_test:0.13034, lr:2.04e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.905, tt:4442.680\n",
      "Ep:235, loss:0.00000, loss_test:0.12955, lr:2.02e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.907, tt:4462.047\n",
      "Ep:236, loss:0.00000, loss_test:0.13122, lr:2.00e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.907, tt:4480.867\n",
      "Ep:237, loss:0.00000, loss_test:0.13126, lr:1.98e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.902, tt:4498.656\n",
      "Ep:238, loss:0.00000, loss_test:0.13049, lr:1.96e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.902, tt:4517.692\n",
      "Ep:239, loss:0.00000, loss_test:0.13019, lr:1.94e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.896, tt:4535.006\n",
      "Ep:240, loss:0.00000, loss_test:0.13097, lr:1.92e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.895, tt:4553.678\n",
      "Ep:241, loss:0.00000, loss_test:0.13146, lr:1.90e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.894, tt:4572.287\n",
      "Ep:242, loss:0.00000, loss_test:0.13045, lr:1.89e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.895, tt:4591.517\n",
      "Ep:243, loss:0.00000, loss_test:0.13076, lr:1.87e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.898, tt:4611.056\n",
      "Ep:244, loss:0.00000, loss_test:0.13219, lr:1.85e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.900, tt:4630.440\n",
      "Ep:245, loss:0.00000, loss_test:0.13135, lr:1.83e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.905, tt:4650.525\n",
      "Ep:246, loss:0.00000, loss_test:0.13048, lr:1.81e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.904, tt:4669.347\n",
      "Ep:247, loss:0.00000, loss_test:0.13140, lr:1.79e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.907, tt:4688.948\n",
      "Ep:248, loss:0.00000, loss_test:0.13236, lr:1.78e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.910, tt:4708.710\n",
      "Ep:249, loss:0.00000, loss_test:0.13174, lr:1.76e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.911, tt:4727.639\n",
      "Ep:250, loss:0.00000, loss_test:0.13093, lr:1.74e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.909, tt:4746.231\n",
      "Ep:251, loss:0.00000, loss_test:0.13174, lr:1.72e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.913, tt:4765.992\n",
      "Ep:252, loss:0.00000, loss_test:0.13235, lr:1.71e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.912, tt:4784.758\n",
      "Ep:253, loss:0.00000, loss_test:0.13170, lr:1.69e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.910, tt:4803.158\n",
      "Ep:254, loss:0.00000, loss_test:0.13113, lr:1.67e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.904, tt:4820.486\n",
      "Ep:255, loss:0.00000, loss_test:0.13191, lr:1.65e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.897, tt:4837.602\n",
      "Ep:256, loss:0.00000, loss_test:0.13215, lr:1.64e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.893, tt:4855.558\n",
      "Ep:257, loss:0.00000, loss_test:0.13181, lr:1.62e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.885, tt:4872.327\n",
      "Ep:258, loss:0.00000, loss_test:0.13188, lr:1.61e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.884, tt:4890.849\n",
      "Ep:259, loss:0.00000, loss_test:0.13219, lr:1.59e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.877, tt:4908.148\n",
      "Ep:260, loss:0.00000, loss_test:0.13251, lr:1.57e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.873, tt:4925.874\n",
      "Ep:261, loss:0.00000, loss_test:0.13176, lr:1.56e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.867, tt:4943.141\n",
      "Ep:262, loss:0.00000, loss_test:0.13172, lr:1.54e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.859, tt:4960.036\n",
      "Ep:263, loss:0.00000, loss_test:0.13241, lr:1.53e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.852, tt:4976.876\n",
      "Ep:264, loss:0.00000, loss_test:0.13227, lr:1.51e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.843, tt:4993.284\n",
      "Ep:265, loss:0.00000, loss_test:0.13187, lr:1.50e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.838, tt:5010.874\n",
      "Ep:266, loss:0.00000, loss_test:0.13226, lr:1.48e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.827, tt:5026.867\n",
      "Ep:267, loss:0.00000, loss_test:0.13241, lr:1.47e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.819, tt:5043.562\n",
      "Ep:268, loss:0.00000, loss_test:0.13210, lr:1.45e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.817, tt:5061.681\n",
      "Ep:269, loss:0.00000, loss_test:0.13227, lr:1.44e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.806, tt:5077.537\n",
      "Ep:270, loss:0.00000, loss_test:0.13234, lr:1.42e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.800, tt:5094.783\n",
      "Ep:271, loss:0.00000, loss_test:0.13240, lr:1.41e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.789, tt:5110.578\n",
      "Ep:272, loss:0.00000, loss_test:0.13225, lr:1.39e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.782, tt:5127.616\n",
      "Ep:273, loss:0.00000, loss_test:0.13240, lr:1.38e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.776, tt:5144.636\n",
      "Ep:274, loss:0.00000, loss_test:0.13258, lr:1.37e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.769, tt:5161.488\n",
      "Ep:275, loss:0.00000, loss_test:0.13253, lr:1.35e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.766, tt:5179.419\n",
      "Ep:276, loss:0.00000, loss_test:0.13252, lr:1.34e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.761, tt:5196.739\n",
      "Ep:277, loss:0.00000, loss_test:0.13267, lr:1.33e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.753, tt:5213.276\n",
      "Ep:278, loss:0.00000, loss_test:0.13271, lr:1.31e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.746, tt:5229.999\n",
      "Ep:279, loss:0.00000, loss_test:0.13265, lr:1.30e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.737, tt:5246.324\n",
      "Ep:280, loss:0.00000, loss_test:0.13288, lr:1.29e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.727, tt:5262.280\n",
      "Ep:281, loss:0.00000, loss_test:0.13293, lr:1.27e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.721, tt:5279.265\n",
      "Ep:282, loss:0.00000, loss_test:0.13270, lr:1.26e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.714, tt:5296.057\n",
      "Ep:283, loss:0.00000, loss_test:0.13281, lr:1.25e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.703, tt:5311.665\n",
      "Ep:284, loss:0.00000, loss_test:0.13337, lr:1.24e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.699, tt:5329.327\n",
      "Ep:285, loss:0.00000, loss_test:0.13283, lr:1.22e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.692, tt:5345.946\n",
      "Ep:286, loss:0.00000, loss_test:0.13272, lr:1.21e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.683, tt:5362.023\n",
      "Ep:287, loss:0.00000, loss_test:0.13338, lr:1.20e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.678, tt:5379.239\n",
      "Ep:288, loss:0.00000, loss_test:0.13322, lr:1.19e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.672, tt:5396.324\n",
      "Ep:289, loss:0.00000, loss_test:0.13290, lr:1.18e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.665, tt:5412.882\n",
      "Ep:290, loss:0.00000, loss_test:0.13309, lr:1.16e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.660, tt:5430.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:291, loss:0.00000, loss_test:0.13337, lr:1.15e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.649, tt:5445.619\n",
      "Ep:292, loss:0.00000, loss_test:0.13322, lr:1.14e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.645, tt:5463.064\n",
      "Ep:293, loss:0.00000, loss_test:0.13305, lr:1.13e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.636, tt:5479.030\n",
      "Ep:294, loss:0.00000, loss_test:0.13322, lr:1.12e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.613, tt:5490.965\n",
      "Ep:295, loss:0.00000, loss_test:0.13356, lr:1.11e-03, fs:0.67073 (r=0.556,p=0.846),  time:18.588, tt:5502.008\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14720, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.848, tt:12.848\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14707, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.896, tt:27.792\n",
      "Ep:2, loss:0.00004, loss_test:0.14686, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.903, tt:41.708\n",
      "Ep:3, loss:0.00004, loss_test:0.14658, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.219, tt:56.876\n",
      "Ep:4, loss:0.00004, loss_test:0.14621, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.337, tt:71.687\n",
      "Ep:5, loss:0.00004, loss_test:0.14574, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.486, tt:86.918\n",
      "Ep:6, loss:0.00004, loss_test:0.14519, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.619, tt:102.330\n",
      "Ep:7, loss:0.00004, loss_test:0.14454, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.779, tt:118.233\n",
      "Ep:8, loss:0.00004, loss_test:0.14374, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.833, tt:133.496\n",
      "Ep:9, loss:0.00004, loss_test:0.14273, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:14.893, tt:148.927\n",
      "Ep:10, loss:0.00004, loss_test:0.14146, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:14.874, tt:163.611\n",
      "Ep:11, loss:0.00004, loss_test:0.13982, lr:1.00e-02, fs:0.64286 (r=0.909,p=0.497),  time:14.842, tt:178.100\n",
      "Ep:12, loss:0.00004, loss_test:0.13786, lr:9.90e-03, fs:0.64260 (r=0.899,p=0.500),  time:14.824, tt:192.715\n",
      "Ep:13, loss:0.00003, loss_test:0.13577, lr:9.80e-03, fs:0.64591 (r=0.838,p=0.525),  time:14.773, tt:206.818\n",
      "Ep:14, loss:0.00003, loss_test:0.13371, lr:9.70e-03, fs:0.62661 (r=0.737,p=0.545),  time:14.812, tt:222.185\n",
      "Ep:15, loss:0.00003, loss_test:0.13199, lr:9.61e-03, fs:0.63927 (r=0.707,p=0.583),  time:14.825, tt:237.192\n",
      "Ep:16, loss:0.00003, loss_test:0.13115, lr:9.51e-03, fs:0.61692 (r=0.626,p=0.608),  time:14.839, tt:252.255\n",
      "Ep:17, loss:0.00003, loss_test:0.13079, lr:9.41e-03, fs:0.56684 (r=0.535,p=0.602),  time:14.859, tt:267.471\n",
      "Ep:18, loss:0.00003, loss_test:0.13032, lr:9.32e-03, fs:0.58065 (r=0.545,p=0.621),  time:14.942, tt:283.898\n",
      "Ep:19, loss:0.00003, loss_test:0.12963, lr:9.23e-03, fs:0.59375 (r=0.576,p=0.613),  time:14.904, tt:298.073\n",
      "Ep:20, loss:0.00003, loss_test:0.12902, lr:9.14e-03, fs:0.60204 (r=0.596,p=0.608),  time:14.826, tt:311.356\n",
      "Ep:21, loss:0.00003, loss_test:0.12863, lr:9.04e-03, fs:0.61000 (r=0.616,p=0.604),  time:14.859, tt:326.897\n",
      "Ep:22, loss:0.00003, loss_test:0.12805, lr:8.95e-03, fs:0.60204 (r=0.596,p=0.608),  time:14.887, tt:342.392\n",
      "Ep:23, loss:0.00003, loss_test:0.12755, lr:8.86e-03, fs:0.60000 (r=0.576,p=0.626),  time:14.835, tt:356.031\n",
      "Ep:24, loss:0.00003, loss_test:0.12738, lr:8.78e-03, fs:0.60000 (r=0.545,p=0.667),  time:14.757, tt:368.935\n",
      "Ep:25, loss:0.00003, loss_test:0.12723, lr:8.69e-03, fs:0.59091 (r=0.525,p=0.675),  time:14.767, tt:383.933\n",
      "Ep:26, loss:0.00003, loss_test:0.12652, lr:8.60e-03, fs:0.60335 (r=0.545,p=0.675),  time:14.771, tt:398.818\n",
      "Ep:27, loss:0.00003, loss_test:0.12587, lr:8.51e-03, fs:0.60773 (r=0.556,p=0.671),  time:14.811, tt:414.717\n",
      "Ep:28, loss:0.00003, loss_test:0.12556, lr:8.43e-03, fs:0.58639 (r=0.566,p=0.609),  time:14.824, tt:429.905\n",
      "Ep:29, loss:0.00003, loss_test:0.12523, lr:8.35e-03, fs:0.58639 (r=0.566,p=0.609),  time:14.862, tt:445.856\n",
      "Ep:30, loss:0.00003, loss_test:0.12498, lr:8.26e-03, fs:0.58242 (r=0.535,p=0.639),  time:14.867, tt:460.863\n",
      "Ep:31, loss:0.00003, loss_test:0.12501, lr:8.18e-03, fs:0.60674 (r=0.545,p=0.684),  time:14.862, tt:475.599\n",
      "Ep:32, loss:0.00002, loss_test:0.12498, lr:8.10e-03, fs:0.58427 (r=0.525,p=0.658),  time:14.838, tt:489.666\n",
      "Ep:33, loss:0.00002, loss_test:0.12460, lr:8.02e-03, fs:0.58427 (r=0.525,p=0.658),  time:14.825, tt:504.049\n",
      "Ep:34, loss:0.00002, loss_test:0.12395, lr:7.94e-03, fs:0.58564 (r=0.535,p=0.646),  time:14.843, tt:519.515\n",
      "Ep:35, loss:0.00002, loss_test:0.12338, lr:7.86e-03, fs:0.59016 (r=0.545,p=0.643),  time:14.846, tt:534.470\n",
      "Ep:36, loss:0.00002, loss_test:0.12291, lr:7.78e-03, fs:0.60541 (r=0.566,p=0.651),  time:14.841, tt:549.113\n",
      "Ep:37, loss:0.00002, loss_test:0.12257, lr:7.70e-03, fs:0.60541 (r=0.566,p=0.651),  time:14.851, tt:564.328\n",
      "Ep:38, loss:0.00002, loss_test:0.12261, lr:7.62e-03, fs:0.59016 (r=0.545,p=0.643),  time:14.830, tt:578.363\n",
      "Ep:39, loss:0.00002, loss_test:0.12288, lr:7.55e-03, fs:0.59218 (r=0.535,p=0.662),  time:14.832, tt:593.282\n",
      "Ep:40, loss:0.00002, loss_test:0.12304, lr:7.47e-03, fs:0.59551 (r=0.535,p=0.671),  time:14.839, tt:608.388\n",
      "Ep:41, loss:0.00002, loss_test:0.12288, lr:7.40e-03, fs:0.59218 (r=0.535,p=0.662),  time:14.843, tt:623.402\n",
      "Ep:42, loss:0.00002, loss_test:0.12250, lr:7.32e-03, fs:0.59341 (r=0.545,p=0.651),  time:14.916, tt:641.390\n",
      "Ep:43, loss:0.00002, loss_test:0.12209, lr:7.25e-03, fs:0.61290 (r=0.576,p=0.655),  time:14.923, tt:656.606\n",
      "Ep:44, loss:0.00002, loss_test:0.12181, lr:7.18e-03, fs:0.60963 (r=0.576,p=0.648),  time:14.965, tt:673.425\n",
      "Ep:45, loss:0.00002, loss_test:0.12169, lr:7.11e-03, fs:0.60541 (r=0.566,p=0.651),  time:14.972, tt:688.692\n",
      "Ep:46, loss:0.00002, loss_test:0.12167, lr:7.03e-03, fs:0.61202 (r=0.566,p=0.667),  time:14.994, tt:704.727\n",
      "Ep:47, loss:0.00002, loss_test:0.12167, lr:6.96e-03, fs:0.59551 (r=0.535,p=0.671),  time:15.004, tt:720.198\n",
      "Ep:48, loss:0.00002, loss_test:0.12160, lr:6.89e-03, fs:0.57955 (r=0.515,p=0.662),  time:15.041, tt:737.026\n",
      "Ep:49, loss:0.00002, loss_test:0.12146, lr:6.83e-03, fs:0.58757 (r=0.525,p=0.667),  time:15.077, tt:753.869\n",
      "Ep:50, loss:0.00002, loss_test:0.12127, lr:6.76e-03, fs:0.59551 (r=0.535,p=0.671),  time:15.090, tt:769.596\n",
      "Ep:51, loss:0.00002, loss_test:0.12099, lr:6.69e-03, fs:0.59218 (r=0.535,p=0.662),  time:15.105, tt:785.446\n",
      "Ep:52, loss:0.00002, loss_test:0.12067, lr:6.62e-03, fs:0.60000 (r=0.545,p=0.667),  time:15.115, tt:801.092\n",
      "Ep:53, loss:0.00002, loss_test:0.12033, lr:6.56e-03, fs:0.59551 (r=0.535,p=0.671),  time:15.137, tt:817.407\n",
      "Ep:54, loss:0.00002, loss_test:0.12002, lr:6.49e-03, fs:0.58286 (r=0.515,p=0.671),  time:15.141, tt:832.766\n",
      "Ep:55, loss:0.00002, loss_test:0.11973, lr:6.43e-03, fs:0.58960 (r=0.515,p=0.689),  time:15.144, tt:848.053\n",
      "Ep:56, loss:0.00002, loss_test:0.11939, lr:6.36e-03, fs:0.58960 (r=0.515,p=0.689),  time:15.146, tt:863.316\n",
      "Ep:57, loss:0.00002, loss_test:0.11910, lr:6.30e-03, fs:0.60571 (r=0.535,p=0.697),  time:15.164, tt:879.522\n",
      "Ep:58, loss:0.00002, loss_test:0.11889, lr:6.24e-03, fs:0.60227 (r=0.535,p=0.688),  time:15.180, tt:895.625\n",
      "Ep:59, loss:0.00002, loss_test:0.11878, lr:6.17e-03, fs:0.60227 (r=0.535,p=0.688),  time:15.178, tt:910.660\n",
      "Ep:60, loss:0.00002, loss_test:0.11868, lr:6.11e-03, fs:0.60227 (r=0.535,p=0.688),  time:15.165, tt:925.075\n",
      "Ep:61, loss:0.00002, loss_test:0.11858, lr:6.05e-03, fs:0.61017 (r=0.545,p=0.692),  time:15.183, tt:941.352\n",
      "Ep:62, loss:0.00002, loss_test:0.11845, lr:5.99e-03, fs:0.60674 (r=0.545,p=0.684),  time:15.203, tt:957.759\n",
      "Ep:63, loss:0.00002, loss_test:0.11830, lr:5.93e-03, fs:0.60674 (r=0.545,p=0.684),  time:15.215, tt:973.782\n",
      "Ep:64, loss:0.00002, loss_test:0.11815, lr:5.87e-03, fs:0.61364 (r=0.545,p=0.701),  time:15.221, tt:989.393\n",
      "Ep:65, loss:0.00002, loss_test:0.11801, lr:5.81e-03, fs:0.61714 (r=0.545,p=0.711),  time:15.244, tt:1006.114\n",
      "Ep:66, loss:0.00002, loss_test:0.11791, lr:5.75e-03, fs:0.61714 (r=0.545,p=0.711),  time:15.264, tt:1022.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00002, loss_test:0.11784, lr:5.70e-03, fs:0.60920 (r=0.535,p=0.707),  time:15.267, tt:1038.153\n",
      "Ep:68, loss:0.00002, loss_test:0.11777, lr:5.64e-03, fs:0.60116 (r=0.525,p=0.703),  time:15.279, tt:1054.272\n",
      "Ep:69, loss:0.00002, loss_test:0.11766, lr:5.58e-03, fs:0.60920 (r=0.535,p=0.707),  time:15.282, tt:1069.757\n",
      "Ep:70, loss:0.00002, loss_test:0.11754, lr:5.53e-03, fs:0.60920 (r=0.535,p=0.707),  time:15.281, tt:1084.931\n",
      "Ep:71, loss:0.00002, loss_test:0.11742, lr:5.47e-03, fs:0.60920 (r=0.535,p=0.707),  time:15.290, tt:1100.883\n",
      "Ep:72, loss:0.00002, loss_test:0.11733, lr:5.42e-03, fs:0.60920 (r=0.535,p=0.707),  time:15.290, tt:1116.158\n",
      "Ep:73, loss:0.00002, loss_test:0.11727, lr:5.36e-03, fs:0.61272 (r=0.535,p=0.716),  time:15.289, tt:1131.413\n",
      "Ep:74, loss:0.00002, loss_test:0.11722, lr:5.31e-03, fs:0.61272 (r=0.535,p=0.716),  time:15.288, tt:1146.593\n",
      "Ep:75, loss:0.00002, loss_test:0.11719, lr:5.26e-03, fs:0.61272 (r=0.535,p=0.716),  time:15.286, tt:1161.723\n",
      "Ep:76, loss:0.00002, loss_test:0.11719, lr:5.20e-03, fs:0.60819 (r=0.525,p=0.722),  time:15.288, tt:1177.150\n",
      "Ep:77, loss:0.00002, loss_test:0.11718, lr:5.15e-03, fs:0.60000 (r=0.515,p=0.718),  time:15.287, tt:1192.361\n",
      "Ep:78, loss:0.00002, loss_test:0.11715, lr:5.10e-03, fs:0.60000 (r=0.515,p=0.718),  time:15.300, tt:1208.684\n",
      "Ep:79, loss:0.00002, loss_test:0.11706, lr:5.05e-03, fs:0.59172 (r=0.505,p=0.714),  time:15.306, tt:1224.511\n",
      "Ep:80, loss:0.00002, loss_test:0.11693, lr:5.00e-03, fs:0.60000 (r=0.515,p=0.718),  time:15.320, tt:1240.923\n",
      "Ep:81, loss:0.00002, loss_test:0.11680, lr:4.95e-03, fs:0.60000 (r=0.515,p=0.718),  time:15.321, tt:1256.326\n",
      "Ep:82, loss:0.00002, loss_test:0.11665, lr:4.90e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.323, tt:1271.789\n",
      "Ep:83, loss:0.00002, loss_test:0.11654, lr:4.85e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.335, tt:1288.176\n",
      "Ep:84, loss:0.00002, loss_test:0.11641, lr:4.80e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.345, tt:1304.359\n",
      "Ep:85, loss:0.00002, loss_test:0.11628, lr:4.75e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.361, tt:1321.078\n",
      "Ep:86, loss:0.00002, loss_test:0.11617, lr:4.71e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.379, tt:1337.970\n",
      "Ep:87, loss:0.00002, loss_test:0.11606, lr:4.66e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.378, tt:1353.263\n",
      "Ep:88, loss:0.00002, loss_test:0.11595, lr:4.61e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.388, tt:1369.534\n",
      "Ep:89, loss:0.00002, loss_test:0.11584, lr:4.57e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.393, tt:1385.397\n",
      "Ep:90, loss:0.00002, loss_test:0.11574, lr:4.52e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.406, tt:1401.904\n",
      "Ep:91, loss:0.00002, loss_test:0.11564, lr:4.48e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.412, tt:1417.935\n",
      "Ep:92, loss:0.00002, loss_test:0.11555, lr:4.43e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.404, tt:1432.546\n",
      "Ep:93, loss:0.00002, loss_test:0.11549, lr:4.39e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.403, tt:1447.875\n",
      "Ep:94, loss:0.00002, loss_test:0.11544, lr:4.34e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.406, tt:1463.582\n",
      "Ep:95, loss:0.00002, loss_test:0.11542, lr:4.30e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.411, tt:1479.489\n",
      "Ep:96, loss:0.00002, loss_test:0.11538, lr:4.26e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.413, tt:1495.029\n",
      "Ep:97, loss:0.00002, loss_test:0.11531, lr:4.21e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.407, tt:1509.884\n",
      "Ep:98, loss:0.00002, loss_test:0.11523, lr:4.17e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.415, tt:1526.060\n",
      "Ep:99, loss:0.00002, loss_test:0.11515, lr:4.13e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.405, tt:1540.475\n",
      "Ep:100, loss:0.00001, loss_test:0.11508, lr:4.09e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.414, tt:1556.833\n",
      "Ep:101, loss:0.00001, loss_test:0.11503, lr:4.05e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.426, tt:1573.495\n",
      "Ep:102, loss:0.00001, loss_test:0.11503, lr:4.01e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.432, tt:1589.494\n",
      "Ep:103, loss:0.00001, loss_test:0.11506, lr:3.97e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.436, tt:1605.385\n",
      "Ep:104, loss:0.00001, loss_test:0.11507, lr:3.93e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.439, tt:1621.094\n",
      "Ep:105, loss:0.00001, loss_test:0.11502, lr:3.89e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.449, tt:1637.575\n",
      "Ep:106, loss:0.00001, loss_test:0.11491, lr:3.85e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.448, tt:1652.910\n",
      "Ep:107, loss:0.00001, loss_test:0.11480, lr:3.81e-03, fs:0.61176 (r=0.525,p=0.732),  time:15.451, tt:1668.713\n",
      "Ep:108, loss:0.00001, loss_test:0.11472, lr:3.77e-03, fs:0.61176 (r=0.525,p=0.732),  time:15.464, tt:1685.577\n",
      "Ep:109, loss:0.00001, loss_test:0.11469, lr:3.73e-03, fs:0.61176 (r=0.525,p=0.732),  time:15.468, tt:1701.503\n",
      "Ep:110, loss:0.00001, loss_test:0.11465, lr:3.70e-03, fs:0.61176 (r=0.525,p=0.732),  time:15.478, tt:1718.030\n",
      "Ep:111, loss:0.00001, loss_test:0.11462, lr:3.66e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.483, tt:1734.128\n",
      "Ep:112, loss:0.00001, loss_test:0.11455, lr:3.62e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.485, tt:1749.854\n",
      "Ep:113, loss:0.00001, loss_test:0.11448, lr:3.59e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.491, tt:1765.958\n",
      "Ep:114, loss:0.00001, loss_test:0.11441, lr:3.55e-03, fs:0.60355 (r=0.515,p=0.729),  time:15.495, tt:1781.942\n",
      "Ep:115, loss:0.00001, loss_test:0.11438, lr:3.52e-03, fs:0.60714 (r=0.515,p=0.739),  time:15.502, tt:1798.181\n",
      "Ep:116, loss:0.00001, loss_test:0.11436, lr:3.48e-03, fs:0.60714 (r=0.515,p=0.739),  time:15.506, tt:1814.193\n",
      "Ep:117, loss:0.00001, loss_test:0.11432, lr:3.45e-03, fs:0.60714 (r=0.515,p=0.739),  time:15.496, tt:1828.559\n",
      "Ep:118, loss:0.00001, loss_test:0.11426, lr:3.41e-03, fs:0.60714 (r=0.515,p=0.739),  time:15.502, tt:1844.713\n",
      "Ep:119, loss:0.00001, loss_test:0.11418, lr:3.38e-03, fs:0.61078 (r=0.515,p=0.750),  time:15.510, tt:1861.196\n",
      "Ep:120, loss:0.00001, loss_test:0.11406, lr:3.34e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.507, tt:1876.400\n",
      "Ep:121, loss:0.00001, loss_test:0.11395, lr:3.31e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.501, tt:1891.088\n",
      "Ep:122, loss:0.00001, loss_test:0.11385, lr:3.28e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.501, tt:1906.573\n",
      "Ep:123, loss:0.00001, loss_test:0.11376, lr:3.24e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.500, tt:1922.000\n",
      "Ep:124, loss:0.00001, loss_test:0.11370, lr:3.21e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.491, tt:1936.367\n",
      "Ep:125, loss:0.00001, loss_test:0.11364, lr:3.18e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.487, tt:1951.410\n",
      "Ep:126, loss:0.00001, loss_test:0.11358, lr:3.15e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.492, tt:1967.450\n",
      "Ep:127, loss:0.00001, loss_test:0.11352, lr:3.12e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.487, tt:1982.357\n",
      "Ep:128, loss:0.00001, loss_test:0.11347, lr:3.09e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.486, tt:1997.737\n",
      "Ep:129, loss:0.00001, loss_test:0.11343, lr:3.05e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.489, tt:2013.629\n",
      "Ep:130, loss:0.00001, loss_test:0.11340, lr:3.02e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.487, tt:2028.809\n",
      "Ep:131, loss:0.00001, loss_test:0.11338, lr:2.99e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.498, tt:2045.700\n",
      "Ep:132, loss:0.00001, loss_test:0.11336, lr:2.96e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.497, tt:2061.050\n",
      "Ep:133, loss:0.00001, loss_test:0.11333, lr:2.93e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.501, tt:2077.133\n",
      "Ep:134, loss:0.00001, loss_test:0.11328, lr:2.90e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.498, tt:2092.267\n",
      "Ep:135, loss:0.00001, loss_test:0.11322, lr:2.88e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.505, tt:2108.726\n",
      "Ep:136, loss:0.00001, loss_test:0.11315, lr:2.85e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.513, tt:2125.277\n",
      "Ep:137, loss:0.00001, loss_test:0.11308, lr:2.82e-03, fs:0.60606 (r=0.505,p=0.758),  time:15.514, tt:2140.924\n",
      "Ep:138, loss:0.00001, loss_test:0.11298, lr:2.79e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.518, tt:2156.983\n",
      "Ep:139, loss:0.00001, loss_test:0.11289, lr:2.76e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.522, tt:2173.107\n",
      "Ep:140, loss:0.00001, loss_test:0.11283, lr:2.73e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.526, tt:2189.134\n",
      "Ep:141, loss:0.00001, loss_test:0.11278, lr:2.71e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.524, tt:2204.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.11273, lr:2.68e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.523, tt:2219.752\n",
      "Ep:143, loss:0.00001, loss_test:0.11270, lr:2.65e-03, fs:0.61446 (r=0.515,p=0.761),  time:15.526, tt:2235.775\n",
      "Ep:144, loss:0.00001, loss_test:0.11267, lr:2.63e-03, fs:0.61818 (r=0.515,p=0.773),  time:15.522, tt:2250.697\n",
      "Ep:145, loss:0.00001, loss_test:0.11261, lr:2.60e-03, fs:0.61818 (r=0.515,p=0.773),  time:15.521, tt:2266.025\n",
      "Ep:146, loss:0.00001, loss_test:0.11253, lr:2.57e-03, fs:0.61818 (r=0.515,p=0.773),  time:15.528, tt:2282.593\n",
      "Ep:147, loss:0.00001, loss_test:0.11250, lr:2.55e-03, fs:0.61818 (r=0.515,p=0.773),  time:15.534, tt:2298.980\n",
      "Ep:148, loss:0.00001, loss_test:0.11250, lr:2.52e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.529, tt:2313.855\n",
      "Ep:149, loss:0.00001, loss_test:0.11250, lr:2.50e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.534, tt:2330.140\n",
      "Ep:150, loss:0.00001, loss_test:0.11248, lr:2.47e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.541, tt:2346.699\n",
      "Ep:151, loss:0.00001, loss_test:0.11244, lr:2.45e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.543, tt:2362.463\n",
      "Ep:152, loss:0.00001, loss_test:0.11240, lr:2.42e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.537, tt:2377.153\n",
      "Ep:153, loss:0.00001, loss_test:0.11237, lr:2.40e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.535, tt:2392.410\n",
      "Ep:154, loss:0.00001, loss_test:0.11234, lr:2.38e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.539, tt:2408.609\n",
      "Ep:155, loss:0.00001, loss_test:0.11231, lr:2.35e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.550, tt:2425.808\n",
      "Ep:156, loss:0.00001, loss_test:0.11227, lr:2.33e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.555, tt:2442.207\n",
      "Ep:157, loss:0.00001, loss_test:0.11222, lr:2.31e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.560, tt:2458.402\n",
      "Ep:158, loss:0.00001, loss_test:0.11218, lr:2.28e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.566, tt:2475.050\n",
      "Ep:159, loss:0.00001, loss_test:0.11215, lr:2.26e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.569, tt:2491.053\n",
      "Ep:160, loss:0.00001, loss_test:0.11211, lr:2.24e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.570, tt:2506.696\n",
      "Ep:161, loss:0.00001, loss_test:0.11206, lr:2.21e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.572, tt:2522.727\n",
      "Ep:162, loss:0.00001, loss_test:0.11201, lr:2.19e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.572, tt:2538.178\n",
      "Ep:163, loss:0.00001, loss_test:0.11198, lr:2.17e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.566, tt:2552.858\n",
      "Ep:164, loss:0.00001, loss_test:0.11196, lr:2.15e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.574, tt:2569.704\n",
      "Ep:165, loss:0.00001, loss_test:0.11194, lr:2.13e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.576, tt:2585.650\n",
      "Ep:166, loss:0.00001, loss_test:0.11191, lr:2.11e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.577, tt:2601.315\n",
      "Ep:167, loss:0.00001, loss_test:0.11189, lr:2.08e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.575, tt:2616.558\n",
      "Ep:168, loss:0.00001, loss_test:0.11185, lr:2.06e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.573, tt:2631.787\n",
      "Ep:169, loss:0.00001, loss_test:0.11181, lr:2.04e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.580, tt:2648.612\n",
      "Ep:170, loss:0.00001, loss_test:0.11175, lr:2.02e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.584, tt:2664.842\n",
      "Ep:171, loss:0.00001, loss_test:0.11171, lr:2.00e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.586, tt:2680.789\n",
      "Ep:172, loss:0.00001, loss_test:0.11168, lr:1.98e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.583, tt:2695.841\n",
      "Ep:173, loss:0.00001, loss_test:0.11166, lr:1.96e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.588, tt:2712.372\n",
      "Ep:174, loss:0.00001, loss_test:0.11163, lr:1.94e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.592, tt:2728.643\n",
      "Ep:175, loss:0.00001, loss_test:0.11159, lr:1.92e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.591, tt:2743.941\n",
      "Ep:176, loss:0.00001, loss_test:0.11154, lr:1.90e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.589, tt:2759.263\n",
      "Ep:177, loss:0.00001, loss_test:0.11149, lr:1.89e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.588, tt:2774.739\n",
      "Ep:178, loss:0.00001, loss_test:0.11144, lr:1.87e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.588, tt:2790.334\n",
      "Ep:179, loss:0.00001, loss_test:0.11139, lr:1.85e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.588, tt:2805.776\n",
      "Ep:180, loss:0.00001, loss_test:0.11136, lr:1.83e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.590, tt:2821.856\n",
      "Ep:181, loss:0.00001, loss_test:0.11132, lr:1.81e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.589, tt:2837.276\n",
      "Ep:182, loss:0.00001, loss_test:0.11129, lr:1.79e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.593, tt:2853.491\n",
      "Ep:183, loss:0.00001, loss_test:0.11125, lr:1.78e-03, fs:0.62195 (r=0.515,p=0.785),  time:15.591, tt:2868.666\n",
      "Ep:184, loss:0.00001, loss_test:0.11121, lr:1.76e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.592, tt:2884.606\n",
      "Ep:185, loss:0.00001, loss_test:0.11116, lr:1.74e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.595, tt:2900.626\n",
      "Ep:186, loss:0.00001, loss_test:0.11111, lr:1.72e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.599, tt:2917.045\n",
      "Ep:187, loss:0.00001, loss_test:0.11107, lr:1.71e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.600, tt:2932.757\n",
      "Ep:188, loss:0.00001, loss_test:0.11104, lr:1.69e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.602, tt:2948.856\n",
      "Ep:189, loss:0.00001, loss_test:0.11100, lr:1.67e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.604, tt:2964.731\n",
      "Ep:190, loss:0.00001, loss_test:0.11096, lr:1.65e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.602, tt:2979.934\n",
      "Ep:191, loss:0.00001, loss_test:0.11093, lr:1.64e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.603, tt:2995.785\n",
      "Ep:192, loss:0.00001, loss_test:0.11089, lr:1.62e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.608, tt:3012.441\n",
      "Ep:193, loss:0.00001, loss_test:0.11085, lr:1.61e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.609, tt:3028.107\n",
      "Ep:194, loss:0.00001, loss_test:0.11083, lr:1.59e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.608, tt:3043.658\n",
      "Ep:195, loss:0.00001, loss_test:0.11080, lr:1.57e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.611, tt:3059.682\n",
      "Ep:196, loss:0.00001, loss_test:0.11076, lr:1.56e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.613, tt:3075.725\n",
      "Ep:197, loss:0.00001, loss_test:0.11074, lr:1.54e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.608, tt:3090.375\n",
      "Ep:198, loss:0.00001, loss_test:0.11072, lr:1.53e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.606, tt:3105.622\n",
      "Ep:199, loss:0.00001, loss_test:0.11069, lr:1.51e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.601, tt:3120.142\n",
      "Ep:200, loss:0.00001, loss_test:0.11065, lr:1.50e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.604, tt:3136.457\n",
      "Ep:201, loss:0.00001, loss_test:0.11063, lr:1.48e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.607, tt:3152.676\n",
      "Ep:202, loss:0.00001, loss_test:0.11063, lr:1.47e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.605, tt:3167.791\n",
      "Ep:203, loss:0.00001, loss_test:0.11063, lr:1.45e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.601, tt:3182.658\n",
      "Ep:204, loss:0.00001, loss_test:0.11061, lr:1.44e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.600, tt:3197.981\n",
      "Ep:205, loss:0.00001, loss_test:0.11058, lr:1.42e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.603, tt:3214.276\n",
      "Ep:206, loss:0.00001, loss_test:0.11056, lr:1.41e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.610, tt:3231.297\n",
      "Ep:207, loss:0.00001, loss_test:0.11055, lr:1.39e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.612, tt:3247.300\n",
      "Ep:208, loss:0.00001, loss_test:0.11053, lr:1.38e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.609, tt:3262.359\n",
      "Ep:209, loss:0.00001, loss_test:0.11050, lr:1.37e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.616, tt:3279.306\n",
      "Ep:210, loss:0.00001, loss_test:0.11048, lr:1.35e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.612, tt:3294.053\n",
      "Ep:211, loss:0.00001, loss_test:0.11046, lr:1.34e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.615, tt:3310.334\n",
      "Ep:212, loss:0.00001, loss_test:0.11043, lr:1.33e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.613, tt:3325.541\n",
      "Ep:213, loss:0.00001, loss_test:0.11041, lr:1.31e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.615, tt:3341.663\n",
      "Ep:214, loss:0.00001, loss_test:0.11039, lr:1.30e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.616, tt:3357.358\n",
      "Ep:215, loss:0.00001, loss_test:0.11037, lr:1.29e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.618, tt:3373.574\n",
      "Ep:216, loss:0.00001, loss_test:0.11036, lr:1.27e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.621, tt:3389.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:217, loss:0.00001, loss_test:0.11034, lr:1.26e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.619, tt:3405.020\n",
      "Ep:218, loss:0.00001, loss_test:0.11031, lr:1.25e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.621, tt:3421.103\n",
      "Ep:219, loss:0.00001, loss_test:0.11028, lr:1.24e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.621, tt:3436.602\n",
      "Ep:220, loss:0.00001, loss_test:0.11024, lr:1.22e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.623, tt:3452.682\n",
      "Ep:221, loss:0.00001, loss_test:0.11021, lr:1.21e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.625, tt:3468.669\n",
      "Ep:222, loss:0.00001, loss_test:0.11019, lr:1.20e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.626, tt:3484.512\n",
      "Ep:223, loss:0.00001, loss_test:0.11016, lr:1.19e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.625, tt:3499.899\n",
      "Ep:224, loss:0.00001, loss_test:0.11014, lr:1.18e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.621, tt:3514.679\n",
      "Ep:225, loss:0.00001, loss_test:0.11012, lr:1.16e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.620, tt:3530.154\n",
      "Ep:226, loss:0.00001, loss_test:0.11009, lr:1.15e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.620, tt:3545.813\n",
      "Ep:227, loss:0.00001, loss_test:0.11008, lr:1.14e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.620, tt:3561.448\n",
      "Ep:228, loss:0.00001, loss_test:0.11008, lr:1.13e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.624, tt:3577.827\n",
      "Ep:229, loss:0.00001, loss_test:0.11007, lr:1.12e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.618, tt:3592.042\n",
      "Ep:230, loss:0.00001, loss_test:0.11005, lr:1.11e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.613, tt:3606.609\n",
      "Ep:231, loss:0.00001, loss_test:0.11002, lr:1.10e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.608, tt:3621.134\n",
      "Ep:232, loss:0.00001, loss_test:0.10999, lr:1.08e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.610, tt:3637.066\n",
      "Ep:233, loss:0.00001, loss_test:0.10998, lr:1.07e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.614, tt:3653.582\n",
      "Ep:234, loss:0.00001, loss_test:0.10997, lr:1.06e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.617, tt:3669.880\n",
      "Ep:235, loss:0.00001, loss_test:0.10995, lr:1.05e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.613, tt:3684.680\n",
      "Ep:236, loss:0.00001, loss_test:0.10993, lr:1.04e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.610, tt:3699.461\n",
      "Ep:237, loss:0.00001, loss_test:0.10990, lr:1.03e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.607, tt:3714.461\n",
      "Ep:238, loss:0.00001, loss_test:0.10988, lr:1.02e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.600, tt:3728.459\n",
      "Ep:239, loss:0.00001, loss_test:0.10986, lr:1.01e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.600, tt:3744.009\n",
      "Ep:240, loss:0.00001, loss_test:0.10983, lr:1.00e-03, fs:0.63030 (r=0.525,p=0.788),  time:15.598, tt:3759.136\n",
      "Ep:241, loss:0.00001, loss_test:0.10981, lr:9.91e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.598, tt:3774.739\n",
      "Ep:242, loss:0.00001, loss_test:0.10978, lr:9.81e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.596, tt:3789.733\n",
      "Ep:243, loss:0.00001, loss_test:0.10976, lr:9.71e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.596, tt:3805.376\n",
      "Ep:244, loss:0.00001, loss_test:0.10974, lr:9.62e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.592, tt:3820.086\n",
      "Ep:245, loss:0.00001, loss_test:0.10973, lr:9.52e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.595, tt:3836.261\n",
      "Ep:246, loss:0.00001, loss_test:0.10971, lr:9.42e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.594, tt:3851.732\n",
      "Ep:247, loss:0.00001, loss_test:0.10971, lr:9.33e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.592, tt:3866.709\n",
      "Ep:248, loss:0.00001, loss_test:0.10970, lr:9.24e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.591, tt:3882.104\n",
      "Ep:249, loss:0.00001, loss_test:0.10969, lr:9.14e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.591, tt:3897.755\n",
      "Ep:250, loss:0.00001, loss_test:0.10969, lr:9.05e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.594, tt:3914.053\n",
      "Ep:251, loss:0.00001, loss_test:0.10968, lr:8.96e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.590, tt:3928.616\n",
      "Ep:252, loss:0.00001, loss_test:0.10967, lr:8.87e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.592, tt:3944.746\n",
      "Ep:253, loss:0.00001, loss_test:0.10966, lr:8.78e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.589, tt:3959.734\n",
      "Ep:254, loss:0.00001, loss_test:0.10964, lr:8.70e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.587, tt:3974.785\n",
      "Ep:255, loss:0.00001, loss_test:0.10963, lr:8.61e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.589, tt:3990.743\n",
      "Ep:256, loss:0.00001, loss_test:0.10962, lr:8.52e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.587, tt:4005.791\n",
      "Ep:257, loss:0.00001, loss_test:0.10963, lr:8.44e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.585, tt:4020.894\n",
      "Ep:258, loss:0.00001, loss_test:0.10962, lr:8.35e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.586, tt:4036.788\n",
      "Ep:259, loss:0.00001, loss_test:0.10962, lr:8.27e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.588, tt:4053.002\n",
      "Ep:260, loss:0.00001, loss_test:0.10962, lr:8.19e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.590, tt:4069.119\n",
      "Ep:261, loss:0.00001, loss_test:0.10961, lr:8.11e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.587, tt:4083.714\n",
      "Ep:262, loss:0.00001, loss_test:0.10959, lr:8.02e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.584, tt:4098.662\n",
      "Ep:263, loss:0.00001, loss_test:0.10958, lr:7.94e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.584, tt:4114.273\n",
      "Ep:264, loss:0.00001, loss_test:0.10958, lr:7.87e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.585, tt:4130.031\n",
      "Ep:265, loss:0.00001, loss_test:0.10957, lr:7.79e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.591, tt:4147.117\n",
      "Ep:266, loss:0.00001, loss_test:0.10956, lr:7.71e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.595, tt:4163.829\n",
      "Ep:267, loss:0.00001, loss_test:0.10956, lr:7.63e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.596, tt:4179.616\n",
      "Ep:268, loss:0.00001, loss_test:0.10955, lr:7.56e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.595, tt:4194.988\n",
      "Ep:269, loss:0.00001, loss_test:0.10954, lr:7.48e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.594, tt:4210.263\n",
      "Ep:270, loss:0.00001, loss_test:0.10953, lr:7.40e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.596, tt:4226.396\n",
      "Ep:271, loss:0.00001, loss_test:0.10953, lr:7.33e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.596, tt:4242.207\n",
      "Ep:272, loss:0.00001, loss_test:0.10953, lr:7.26e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.600, tt:4258.891\n",
      "Ep:273, loss:0.00001, loss_test:0.10953, lr:7.18e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.605, tt:4275.826\n",
      "Ep:274, loss:0.00001, loss_test:0.10952, lr:7.11e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.611, tt:4292.948\n",
      "Ep:275, loss:0.00001, loss_test:0.10951, lr:7.04e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.613, tt:4309.191\n",
      "Ep:276, loss:0.00001, loss_test:0.10951, lr:6.97e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.621, tt:4327.006\n",
      "Ep:277, loss:0.00001, loss_test:0.10950, lr:6.90e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.618, tt:4341.733\n",
      "Ep:278, loss:0.00001, loss_test:0.10950, lr:6.83e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.619, tt:4357.741\n",
      "Ep:279, loss:0.00001, loss_test:0.10950, lr:6.76e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.618, tt:4372.908\n",
      "Ep:280, loss:0.00001, loss_test:0.10950, lr:6.70e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.618, tt:4388.778\n",
      "Ep:281, loss:0.00001, loss_test:0.10949, lr:6.63e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.623, tt:4405.641\n",
      "Ep:282, loss:0.00001, loss_test:0.10950, lr:6.56e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.624, tt:4421.647\n",
      "Ep:283, loss:0.00001, loss_test:0.10950, lr:6.50e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.625, tt:4437.494\n",
      "Ep:284, loss:0.00001, loss_test:0.10948, lr:6.43e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.627, tt:4453.836\n",
      "Ep:285, loss:0.00001, loss_test:0.10947, lr:6.37e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.630, tt:4470.289\n",
      "Ep:286, loss:0.00001, loss_test:0.10947, lr:6.30e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.634, tt:4487.092\n",
      "Ep:287, loss:0.00001, loss_test:0.10948, lr:6.24e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.638, tt:4503.878\n",
      "Ep:288, loss:0.00001, loss_test:0.10948, lr:6.18e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.642, tt:4520.546\n",
      "Ep:289, loss:0.00001, loss_test:0.10948, lr:6.12e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.647, tt:4537.714\n",
      "Ep:290, loss:0.00001, loss_test:0.10947, lr:6.06e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.649, tt:4553.936\n",
      "Ep:291, loss:0.00001, loss_test:0.10947, lr:6.00e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.653, tt:4570.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:292, loss:0.00001, loss_test:0.10946, lr:5.94e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.650, tt:4585.354\n",
      "Ep:293, loss:0.00001, loss_test:0.10945, lr:5.88e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.646, tt:4600.003\n",
      "Ep:294, loss:0.00001, loss_test:0.10945, lr:5.82e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.643, tt:4614.794\n",
      "Ep:295, loss:0.00001, loss_test:0.10945, lr:5.76e-04, fs:0.63030 (r=0.525,p=0.788),  time:15.621, tt:4623.701\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14850, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.708, tt:20.708\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14838, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.006, tt:42.012\n",
      "Ep:2, loss:0.00004, loss_test:0.14820, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.036, tt:63.108\n",
      "Ep:3, loss:0.00004, loss_test:0.14793, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.643, tt:82.574\n",
      "Ep:4, loss:0.00004, loss_test:0.14756, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:20.757, tt:103.786\n",
      "Ep:5, loss:0.00004, loss_test:0.14703, lr:1.00e-02, fs:0.65306 (r=0.970,p=0.492),  time:20.735, tt:124.409\n",
      "Ep:6, loss:0.00004, loss_test:0.14634, lr:1.00e-02, fs:0.64138 (r=0.939,p=0.487),  time:20.654, tt:144.576\n",
      "Ep:7, loss:0.00004, loss_test:0.14545, lr:1.00e-02, fs:0.63889 (r=0.929,p=0.487),  time:20.824, tt:166.595\n",
      "Ep:8, loss:0.00004, loss_test:0.14425, lr:1.00e-02, fs:0.63604 (r=0.909,p=0.489),  time:20.994, tt:188.947\n",
      "Ep:9, loss:0.00004, loss_test:0.14249, lr:1.00e-02, fs:0.63309 (r=0.889,p=0.492),  time:20.903, tt:209.026\n",
      "Ep:10, loss:0.00004, loss_test:0.14017, lr:1.00e-02, fs:0.62921 (r=0.848,p=0.500),  time:20.878, tt:229.653\n",
      "Ep:11, loss:0.00003, loss_test:0.13775, lr:1.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:20.938, tt:251.256\n",
      "Ep:12, loss:0.00003, loss_test:0.13646, lr:9.90e-03, fs:0.62617 (r=0.677,p=0.583),  time:20.921, tt:271.975\n",
      "Ep:13, loss:0.00003, loss_test:0.13737, lr:9.80e-03, fs:0.60606 (r=0.606,p=0.606),  time:20.951, tt:293.315\n",
      "Ep:14, loss:0.00003, loss_test:0.13848, lr:9.70e-03, fs:0.60733 (r=0.586,p=0.630),  time:20.949, tt:314.235\n",
      "Ep:15, loss:0.00003, loss_test:0.13786, lr:9.61e-03, fs:0.61458 (r=0.596,p=0.634),  time:21.026, tt:336.423\n",
      "Ep:16, loss:0.00003, loss_test:0.13636, lr:9.51e-03, fs:0.63415 (r=0.657,p=0.613),  time:20.973, tt:356.534\n",
      "Ep:17, loss:0.00003, loss_test:0.13436, lr:9.41e-03, fs:0.63507 (r=0.677,p=0.598),  time:20.946, tt:377.034\n",
      "Ep:18, loss:0.00003, loss_test:0.13209, lr:9.32e-03, fs:0.63889 (r=0.697,p=0.590),  time:20.963, tt:398.302\n",
      "Ep:19, loss:0.00003, loss_test:0.12976, lr:9.23e-03, fs:0.62857 (r=0.667,p=0.595),  time:20.919, tt:418.378\n",
      "Ep:20, loss:0.00003, loss_test:0.12804, lr:9.14e-03, fs:0.64356 (r=0.657,p=0.631),  time:20.885, tt:438.586\n",
      "Ep:21, loss:0.00003, loss_test:0.12697, lr:9.04e-03, fs:0.64948 (r=0.636,p=0.663),  time:20.909, tt:460.006\n",
      "Ep:22, loss:0.00003, loss_test:0.12626, lr:8.95e-03, fs:0.65285 (r=0.636,p=0.670),  time:20.870, tt:480.001\n",
      "Ep:23, loss:0.00003, loss_test:0.12570, lr:8.86e-03, fs:0.64249 (r=0.626,p=0.660),  time:20.885, tt:501.248\n",
      "Ep:24, loss:0.00003, loss_test:0.12533, lr:8.78e-03, fs:0.67347 (r=0.667,p=0.680),  time:20.881, tt:522.034\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.12505, lr:8.78e-03, fs:0.67005 (r=0.667,p=0.673),  time:20.889, tt:543.115\n",
      "Ep:26, loss:0.00003, loss_test:0.12463, lr:8.78e-03, fs:0.66321 (r=0.646,p=0.681),  time:20.904, tt:564.411\n",
      "Ep:27, loss:0.00002, loss_test:0.12421, lr:8.78e-03, fs:0.64516 (r=0.606,p=0.690),  time:20.871, tt:584.384\n",
      "Ep:28, loss:0.00002, loss_test:0.12382, lr:8.78e-03, fs:0.62570 (r=0.566,p=0.700),  time:20.825, tt:603.914\n",
      "Ep:29, loss:0.00002, loss_test:0.12314, lr:8.78e-03, fs:0.62637 (r=0.576,p=0.687),  time:20.767, tt:622.999\n",
      "Ep:30, loss:0.00002, loss_test:0.12229, lr:8.78e-03, fs:0.63388 (r=0.586,p=0.690),  time:20.759, tt:643.526\n",
      "Ep:31, loss:0.00002, loss_test:0.12172, lr:8.78e-03, fs:0.64516 (r=0.606,p=0.690),  time:20.762, tt:664.394\n",
      "Ep:32, loss:0.00002, loss_test:0.12151, lr:8.78e-03, fs:0.64894 (r=0.616,p=0.685),  time:20.772, tt:685.473\n",
      "Ep:33, loss:0.00002, loss_test:0.12153, lr:8.78e-03, fs:0.64171 (r=0.606,p=0.682),  time:20.776, tt:706.395\n",
      "Ep:34, loss:0.00002, loss_test:0.12171, lr:8.78e-03, fs:0.63388 (r=0.586,p=0.690),  time:20.784, tt:727.439\n",
      "Ep:35, loss:0.00002, loss_test:0.12160, lr:8.78e-03, fs:0.63736 (r=0.586,p=0.699),  time:20.788, tt:748.376\n",
      "Ep:36, loss:0.00002, loss_test:0.12108, lr:8.69e-03, fs:0.63388 (r=0.586,p=0.690),  time:20.790, tt:769.216\n",
      "Ep:37, loss:0.00002, loss_test:0.12061, lr:8.60e-03, fs:0.63388 (r=0.586,p=0.690),  time:20.797, tt:790.303\n",
      "Ep:38, loss:0.00002, loss_test:0.12049, lr:8.51e-03, fs:0.63784 (r=0.596,p=0.686),  time:20.798, tt:811.119\n",
      "Ep:39, loss:0.00002, loss_test:0.12085, lr:8.43e-03, fs:0.62222 (r=0.566,p=0.691),  time:20.822, tt:832.893\n",
      "Ep:40, loss:0.00002, loss_test:0.12113, lr:8.35e-03, fs:0.62222 (r=0.566,p=0.691),  time:20.810, tt:853.214\n",
      "Ep:41, loss:0.00002, loss_test:0.12100, lr:8.26e-03, fs:0.62983 (r=0.576,p=0.695),  time:20.857, tt:875.997\n",
      "Ep:42, loss:0.00002, loss_test:0.12053, lr:8.18e-03, fs:0.62637 (r=0.576,p=0.687),  time:20.852, tt:896.638\n",
      "Ep:43, loss:0.00002, loss_test:0.12024, lr:8.10e-03, fs:0.62637 (r=0.576,p=0.687),  time:20.894, tt:919.316\n",
      "Ep:44, loss:0.00002, loss_test:0.12015, lr:8.02e-03, fs:0.62637 (r=0.576,p=0.687),  time:20.883, tt:939.715\n",
      "Ep:45, loss:0.00002, loss_test:0.12019, lr:7.94e-03, fs:0.62983 (r=0.576,p=0.695),  time:20.903, tt:961.549\n",
      "Ep:46, loss:0.00002, loss_test:0.11998, lr:7.86e-03, fs:0.62983 (r=0.576,p=0.695),  time:20.913, tt:982.905\n",
      "Ep:47, loss:0.00002, loss_test:0.11932, lr:7.78e-03, fs:0.63736 (r=0.586,p=0.699),  time:20.918, tt:1004.052\n",
      "Ep:48, loss:0.00002, loss_test:0.11850, lr:7.70e-03, fs:0.62637 (r=0.576,p=0.687),  time:20.915, tt:1024.824\n",
      "Ep:49, loss:0.00002, loss_test:0.11791, lr:7.62e-03, fs:0.62983 (r=0.576,p=0.695),  time:20.881, tt:1044.028\n",
      "Ep:50, loss:0.00002, loss_test:0.11789, lr:7.55e-03, fs:0.62983 (r=0.576,p=0.695),  time:20.885, tt:1065.155\n",
      "Ep:51, loss:0.00002, loss_test:0.11799, lr:7.47e-03, fs:0.62983 (r=0.576,p=0.695),  time:20.883, tt:1085.911\n",
      "Ep:52, loss:0.00002, loss_test:0.11798, lr:7.40e-03, fs:0.62222 (r=0.566,p=0.691),  time:20.884, tt:1106.854\n",
      "Ep:53, loss:0.00002, loss_test:0.11768, lr:7.32e-03, fs:0.61453 (r=0.556,p=0.688),  time:20.858, tt:1126.330\n",
      "Ep:54, loss:0.00002, loss_test:0.11746, lr:7.25e-03, fs:0.61798 (r=0.556,p=0.696),  time:20.833, tt:1145.825\n",
      "Ep:55, loss:0.00002, loss_test:0.11743, lr:7.18e-03, fs:0.61798 (r=0.556,p=0.696),  time:20.819, tt:1165.870\n",
      "Ep:56, loss:0.00001, loss_test:0.11754, lr:7.11e-03, fs:0.62147 (r=0.556,p=0.705),  time:20.788, tt:1184.909\n",
      "Ep:57, loss:0.00001, loss_test:0.11743, lr:7.03e-03, fs:0.62500 (r=0.556,p=0.714),  time:20.784, tt:1205.483\n",
      "Ep:58, loss:0.00001, loss_test:0.11710, lr:6.96e-03, fs:0.62500 (r=0.556,p=0.714),  time:20.767, tt:1225.274\n",
      "Ep:59, loss:0.00001, loss_test:0.11698, lr:6.89e-03, fs:0.62857 (r=0.556,p=0.724),  time:20.771, tt:1246.237\n",
      "Ep:60, loss:0.00001, loss_test:0.11706, lr:6.83e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.771, tt:1267.017\n",
      "Ep:61, loss:0.00001, loss_test:0.11733, lr:6.76e-03, fs:0.63953 (r=0.556,p=0.753),  time:20.763, tt:1287.309\n",
      "Ep:62, loss:0.00001, loss_test:0.11728, lr:6.69e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.773, tt:1308.713\n",
      "Ep:63, loss:0.00001, loss_test:0.11694, lr:6.62e-03, fs:0.63218 (r=0.556,p=0.733),  time:20.768, tt:1329.124\n",
      "Ep:64, loss:0.00001, loss_test:0.11664, lr:6.56e-03, fs:0.63218 (r=0.556,p=0.733),  time:20.753, tt:1348.963\n",
      "Ep:65, loss:0.00001, loss_test:0.11649, lr:6.49e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.732, tt:1368.344\n",
      "Ep:66, loss:0.00001, loss_test:0.11638, lr:6.43e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.733, tt:1389.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.11614, lr:6.36e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.709, tt:1408.191\n",
      "Ep:68, loss:0.00001, loss_test:0.11581, lr:6.30e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.696, tt:1428.031\n",
      "Ep:69, loss:0.00001, loss_test:0.11534, lr:6.24e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.668, tt:1446.736\n",
      "Ep:70, loss:0.00001, loss_test:0.11490, lr:6.17e-03, fs:0.63584 (r=0.556,p=0.743),  time:20.650, tt:1466.173\n",
      "Ep:71, loss:0.00001, loss_test:0.11472, lr:6.11e-03, fs:0.64368 (r=0.566,p=0.747),  time:20.640, tt:1486.103\n",
      "Ep:72, loss:0.00001, loss_test:0.11466, lr:6.05e-03, fs:0.64368 (r=0.566,p=0.747),  time:20.650, tt:1507.476\n",
      "Ep:73, loss:0.00001, loss_test:0.11460, lr:5.99e-03, fs:0.63953 (r=0.556,p=0.753),  time:20.651, tt:1528.185\n",
      "Ep:74, loss:0.00001, loss_test:0.11459, lr:5.93e-03, fs:0.63953 (r=0.556,p=0.753),  time:20.642, tt:1548.149\n",
      "Ep:75, loss:0.00001, loss_test:0.11468, lr:5.87e-03, fs:0.63158 (r=0.545,p=0.750),  time:20.611, tt:1566.428\n",
      "Ep:76, loss:0.00001, loss_test:0.11480, lr:5.81e-03, fs:0.63158 (r=0.545,p=0.750),  time:20.612, tt:1587.128\n",
      "Ep:77, loss:0.00001, loss_test:0.11505, lr:5.75e-03, fs:0.63158 (r=0.545,p=0.750),  time:20.607, tt:1607.351\n",
      "Ep:78, loss:0.00001, loss_test:0.11508, lr:5.70e-03, fs:0.63158 (r=0.545,p=0.750),  time:20.610, tt:1628.164\n",
      "Ep:79, loss:0.00001, loss_test:0.11499, lr:5.64e-03, fs:0.63905 (r=0.545,p=0.771),  time:20.594, tt:1647.496\n",
      "Ep:80, loss:0.00001, loss_test:0.11471, lr:5.58e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.571, tt:1666.211\n",
      "Ep:81, loss:0.00001, loss_test:0.11458, lr:5.53e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.569, tt:1686.647\n",
      "Ep:82, loss:0.00001, loss_test:0.11477, lr:5.47e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.557, tt:1706.269\n",
      "Ep:83, loss:0.00001, loss_test:0.11500, lr:5.42e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.559, tt:1726.976\n",
      "Ep:84, loss:0.00001, loss_test:0.11500, lr:5.36e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.565, tt:1748.047\n",
      "Ep:85, loss:0.00001, loss_test:0.11487, lr:5.31e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.563, tt:1768.395\n",
      "Ep:86, loss:0.00001, loss_test:0.11489, lr:5.26e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.563, tt:1789.013\n",
      "Ep:87, loss:0.00001, loss_test:0.11488, lr:5.20e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.562, tt:1809.488\n",
      "Ep:88, loss:0.00001, loss_test:0.11468, lr:5.15e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.567, tt:1830.455\n",
      "Ep:89, loss:0.00001, loss_test:0.11460, lr:5.10e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.570, tt:1851.343\n",
      "Ep:90, loss:0.00001, loss_test:0.11456, lr:5.05e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.579, tt:1872.674\n",
      "Ep:91, loss:0.00001, loss_test:0.11457, lr:5.00e-03, fs:0.63095 (r=0.535,p=0.768),  time:20.580, tt:1893.361\n",
      "Ep:92, loss:0.00001, loss_test:0.11445, lr:4.95e-03, fs:0.63473 (r=0.535,p=0.779),  time:20.579, tt:1913.821\n",
      "Ep:93, loss:0.00001, loss_test:0.11420, lr:4.90e-03, fs:0.63855 (r=0.535,p=0.791),  time:20.580, tt:1934.548\n",
      "Ep:94, loss:0.00001, loss_test:0.11408, lr:4.85e-03, fs:0.64242 (r=0.535,p=0.803),  time:20.575, tt:1954.639\n",
      "Ep:95, loss:0.00001, loss_test:0.11425, lr:4.80e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.586, tt:1976.255\n",
      "Ep:96, loss:0.00001, loss_test:0.11428, lr:4.75e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.577, tt:1995.962\n",
      "Ep:97, loss:0.00001, loss_test:0.11414, lr:4.71e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.574, tt:2016.285\n",
      "Ep:98, loss:0.00001, loss_test:0.11413, lr:4.66e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.567, tt:2036.135\n",
      "Ep:99, loss:0.00001, loss_test:0.11421, lr:4.61e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.558, tt:2055.838\n",
      "Ep:100, loss:0.00001, loss_test:0.11431, lr:4.57e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.553, tt:2075.861\n",
      "Ep:101, loss:0.00001, loss_test:0.11430, lr:4.52e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.556, tt:2096.716\n",
      "Ep:102, loss:0.00001, loss_test:0.11427, lr:4.48e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.544, tt:2116.071\n",
      "Ep:103, loss:0.00001, loss_test:0.11434, lr:4.43e-03, fs:0.65432 (r=0.535,p=0.841),  time:20.528, tt:2134.953\n",
      "Ep:104, loss:0.00001, loss_test:0.11465, lr:4.39e-03, fs:0.64596 (r=0.525,p=0.839),  time:20.511, tt:2153.635\n",
      "Ep:105, loss:0.00001, loss_test:0.11502, lr:4.34e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.515, tt:2174.550\n",
      "Ep:106, loss:0.00001, loss_test:0.11511, lr:4.30e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.507, tt:2194.221\n",
      "Ep:107, loss:0.00001, loss_test:0.11491, lr:4.26e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.500, tt:2214.047\n",
      "Ep:108, loss:0.00001, loss_test:0.11495, lr:4.21e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.490, tt:2233.358\n",
      "Ep:109, loss:0.00001, loss_test:0.11508, lr:4.17e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.491, tt:2254.056\n",
      "Ep:110, loss:0.00001, loss_test:0.11509, lr:4.13e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.473, tt:2272.491\n",
      "Ep:111, loss:0.00001, loss_test:0.11494, lr:4.09e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.459, tt:2291.365\n",
      "Ep:112, loss:0.00001, loss_test:0.11494, lr:4.05e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.442, tt:2309.956\n",
      "Ep:113, loss:0.00001, loss_test:0.11522, lr:4.01e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.427, tt:2328.686\n",
      "Ep:114, loss:0.00001, loss_test:0.11534, lr:3.97e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.426, tt:2349.001\n",
      "Ep:115, loss:0.00001, loss_test:0.11515, lr:3.93e-03, fs:0.64557 (r=0.515,p=0.864),  time:20.410, tt:2367.608\n",
      "Ep:116, loss:0.00001, loss_test:0.11520, lr:3.89e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.392, tt:2385.906\n",
      "Ep:117, loss:0.00001, loss_test:0.11546, lr:3.85e-03, fs:0.67081 (r=0.545,p=0.871),  time:20.372, tt:2403.920\n",
      "Ep:118, loss:0.00001, loss_test:0.11540, lr:3.81e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.359, tt:2422.704\n",
      "Ep:119, loss:0.00001, loss_test:0.11513, lr:3.77e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.346, tt:2441.543\n",
      "Ep:120, loss:0.00001, loss_test:0.11508, lr:3.73e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.351, tt:2462.479\n",
      "Ep:121, loss:0.00001, loss_test:0.11519, lr:3.70e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.351, tt:2482.810\n",
      "Ep:122, loss:0.00001, loss_test:0.11513, lr:3.66e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.360, tt:2504.312\n",
      "Ep:123, loss:0.00001, loss_test:0.11502, lr:3.62e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.363, tt:2525.002\n",
      "Ep:124, loss:0.00001, loss_test:0.11504, lr:3.59e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.359, tt:2544.852\n",
      "Ep:125, loss:0.00001, loss_test:0.11518, lr:3.55e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.368, tt:2566.316\n",
      "Ep:126, loss:0.00001, loss_test:0.11509, lr:3.52e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.367, tt:2586.615\n",
      "Ep:127, loss:0.00001, loss_test:0.11500, lr:3.48e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.360, tt:2606.065\n",
      "Ep:128, loss:0.00001, loss_test:0.11491, lr:3.45e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.354, tt:2625.609\n",
      "Ep:129, loss:0.00001, loss_test:0.11490, lr:3.41e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.341, tt:2644.354\n",
      "Ep:130, loss:0.00001, loss_test:0.11486, lr:3.38e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.336, tt:2663.988\n",
      "Ep:131, loss:0.00001, loss_test:0.11489, lr:3.34e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.338, tt:2684.552\n",
      "Ep:132, loss:0.00001, loss_test:0.11497, lr:3.31e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.340, tt:2705.190\n",
      "Ep:133, loss:0.00001, loss_test:0.11504, lr:3.28e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.336, tt:2724.989\n",
      "Ep:134, loss:0.00001, loss_test:0.11499, lr:3.24e-03, fs:0.66667 (r=0.535,p=0.883),  time:20.339, tt:2745.775\n",
      "Ep:135, loss:0.00001, loss_test:0.11498, lr:3.21e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.333, tt:2765.335\n",
      "Ep:136, loss:0.00001, loss_test:0.11525, lr:3.18e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.330, tt:2785.253\n",
      "Ep:137, loss:0.00001, loss_test:0.11522, lr:3.15e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.328, tt:2805.233\n",
      "Ep:138, loss:0.00001, loss_test:0.11504, lr:3.12e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.345, tt:2827.904\n",
      "Ep:139, loss:0.00001, loss_test:0.11503, lr:3.09e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.341, tt:2847.731\n",
      "Ep:140, loss:0.00001, loss_test:0.11510, lr:3.05e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.338, tt:2867.642\n",
      "Ep:141, loss:0.00001, loss_test:0.11505, lr:3.02e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.341, tt:2888.433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.11514, lr:2.99e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.338, tt:2908.392\n",
      "Ep:143, loss:0.00001, loss_test:0.11518, lr:2.96e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.341, tt:2929.034\n",
      "Ep:144, loss:0.00001, loss_test:0.11515, lr:2.93e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.332, tt:2948.185\n",
      "Ep:145, loss:0.00001, loss_test:0.11511, lr:2.90e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.326, tt:2967.588\n",
      "Ep:146, loss:0.00001, loss_test:0.11496, lr:2.88e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.325, tt:2987.708\n",
      "Ep:147, loss:0.00001, loss_test:0.11480, lr:2.85e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.320, tt:3007.355\n",
      "Ep:148, loss:0.00001, loss_test:0.11469, lr:2.82e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.312, tt:3026.544\n",
      "Ep:149, loss:0.00001, loss_test:0.11476, lr:2.79e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.311, tt:3046.681\n",
      "Ep:150, loss:0.00001, loss_test:0.11453, lr:2.76e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.314, tt:3067.340\n",
      "Ep:151, loss:0.00001, loss_test:0.11456, lr:2.73e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.313, tt:3087.587\n",
      "Ep:152, loss:0.00001, loss_test:0.11470, lr:2.71e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.312, tt:3107.685\n",
      "Ep:153, loss:0.00001, loss_test:0.11456, lr:2.68e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.315, tt:3128.572\n",
      "Ep:154, loss:0.00001, loss_test:0.11441, lr:2.65e-03, fs:0.65823 (r=0.525,p=0.881),  time:20.312, tt:3148.419\n",
      "Ep:155, loss:0.00001, loss_test:0.11439, lr:2.63e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.309, tt:3168.282\n",
      "Ep:156, loss:0.00001, loss_test:0.11431, lr:2.60e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.312, tt:3189.056\n",
      "Ep:157, loss:0.00001, loss_test:0.11440, lr:2.57e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.305, tt:3208.203\n",
      "Ep:158, loss:0.00001, loss_test:0.11445, lr:2.55e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.305, tt:3228.498\n",
      "Ep:159, loss:0.00001, loss_test:0.11423, lr:2.52e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.308, tt:3249.232\n",
      "Ep:160, loss:0.00001, loss_test:0.11424, lr:2.50e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.307, tt:3269.379\n",
      "Ep:161, loss:0.00001, loss_test:0.11443, lr:2.47e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.303, tt:3289.123\n",
      "Ep:162, loss:0.00001, loss_test:0.11441, lr:2.45e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.308, tt:3310.197\n",
      "Ep:163, loss:0.00001, loss_test:0.11429, lr:2.42e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.313, tt:3331.376\n",
      "Ep:164, loss:0.00001, loss_test:0.11435, lr:2.40e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.326, tt:3353.872\n",
      "Ep:165, loss:0.00001, loss_test:0.11444, lr:2.38e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.334, tt:3375.475\n",
      "Ep:166, loss:0.00001, loss_test:0.11437, lr:2.35e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.332, tt:3395.403\n",
      "Ep:167, loss:0.00001, loss_test:0.11447, lr:2.33e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.332, tt:3415.825\n",
      "Ep:168, loss:0.00001, loss_test:0.11440, lr:2.31e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.330, tt:3435.694\n",
      "Ep:169, loss:0.00001, loss_test:0.11432, lr:2.28e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.332, tt:3456.369\n",
      "Ep:170, loss:0.00001, loss_test:0.11454, lr:2.26e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.334, tt:3477.075\n",
      "Ep:171, loss:0.00001, loss_test:0.11454, lr:2.24e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.340, tt:3498.475\n",
      "Ep:172, loss:0.00001, loss_test:0.11439, lr:2.21e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.342, tt:3519.150\n",
      "Ep:173, loss:0.00001, loss_test:0.11453, lr:2.19e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.343, tt:3539.629\n",
      "Ep:174, loss:0.00001, loss_test:0.11463, lr:2.17e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.344, tt:3560.164\n",
      "Ep:175, loss:0.00001, loss_test:0.11450, lr:2.15e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.343, tt:3580.379\n",
      "Ep:176, loss:0.00001, loss_test:0.11435, lr:2.13e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.346, tt:3601.213\n",
      "Ep:177, loss:0.00001, loss_test:0.11448, lr:2.11e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.347, tt:3621.832\n",
      "Ep:178, loss:0.00001, loss_test:0.11457, lr:2.08e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.348, tt:3642.220\n",
      "Ep:179, loss:0.00001, loss_test:0.11449, lr:2.06e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.344, tt:3661.852\n",
      "Ep:180, loss:0.00001, loss_test:0.11448, lr:2.04e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.344, tt:3682.307\n",
      "Ep:181, loss:0.00001, loss_test:0.11457, lr:2.02e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.338, tt:3701.507\n",
      "Ep:182, loss:0.00001, loss_test:0.11468, lr:2.00e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.339, tt:3722.093\n",
      "Ep:183, loss:0.00001, loss_test:0.11464, lr:1.98e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.341, tt:3742.669\n",
      "Ep:184, loss:0.00001, loss_test:0.11467, lr:1.96e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.343, tt:3763.501\n",
      "Ep:185, loss:0.00001, loss_test:0.11477, lr:1.94e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.337, tt:3782.743\n",
      "Ep:186, loss:0.00001, loss_test:0.11478, lr:1.92e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.340, tt:3803.579\n",
      "Ep:187, loss:0.00001, loss_test:0.11472, lr:1.90e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.347, tt:3825.310\n",
      "Ep:188, loss:0.00001, loss_test:0.11483, lr:1.89e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.346, tt:3845.428\n",
      "Ep:189, loss:0.00001, loss_test:0.11468, lr:1.87e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.337, tt:3864.007\n",
      "Ep:190, loss:0.00001, loss_test:0.11475, lr:1.85e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.337, tt:3884.278\n",
      "Ep:191, loss:0.00001, loss_test:0.11489, lr:1.83e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.332, tt:3903.773\n",
      "Ep:192, loss:0.00001, loss_test:0.11478, lr:1.81e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.334, tt:3924.468\n",
      "Ep:193, loss:0.00001, loss_test:0.11476, lr:1.79e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.332, tt:3944.316\n",
      "Ep:194, loss:0.00001, loss_test:0.11489, lr:1.78e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.326, tt:3963.596\n",
      "Ep:195, loss:0.00001, loss_test:0.11481, lr:1.76e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.325, tt:3983.671\n",
      "Ep:196, loss:0.00001, loss_test:0.11482, lr:1.74e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.318, tt:4002.612\n",
      "Ep:197, loss:0.00001, loss_test:0.11491, lr:1.72e-03, fs:0.65385 (r=0.515,p=0.895),  time:20.314, tt:4022.096\n",
      "Ep:198, loss:0.00001, loss_test:0.11482, lr:1.71e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.306, tt:4040.979\n",
      "Ep:199, loss:0.00001, loss_test:0.11494, lr:1.69e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.312, tt:4062.357\n",
      "Ep:200, loss:0.00001, loss_test:0.11500, lr:1.67e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.315, tt:4083.344\n",
      "Ep:201, loss:0.00001, loss_test:0.11505, lr:1.65e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.317, tt:4103.967\n",
      "Ep:202, loss:0.00001, loss_test:0.11511, lr:1.64e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.314, tt:4123.746\n",
      "Ep:203, loss:0.00001, loss_test:0.11516, lr:1.62e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.316, tt:4144.439\n",
      "Ep:204, loss:0.00001, loss_test:0.11510, lr:1.61e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.313, tt:4164.263\n",
      "Ep:205, loss:0.00001, loss_test:0.11517, lr:1.59e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.314, tt:4184.774\n",
      "Ep:206, loss:0.00001, loss_test:0.11527, lr:1.57e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.312, tt:4204.527\n",
      "Ep:207, loss:0.00001, loss_test:0.11521, lr:1.56e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.313, tt:4225.061\n",
      "Ep:208, loss:0.00001, loss_test:0.11519, lr:1.54e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.312, tt:4245.249\n",
      "Ep:209, loss:0.00001, loss_test:0.11529, lr:1.53e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.307, tt:4264.542\n",
      "Ep:210, loss:0.00001, loss_test:0.11523, lr:1.51e-03, fs:0.66242 (r=0.525,p=0.897),  time:20.306, tt:4284.542\n",
      "Ep:211, loss:0.00001, loss_test:0.11516, lr:1.50e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.305, tt:4304.693\n",
      "Ep:212, loss:0.00001, loss_test:0.11535, lr:1.48e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.306, tt:4325.225\n",
      "Ep:213, loss:0.00001, loss_test:0.11532, lr:1.47e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.307, tt:4345.609\n",
      "Ep:214, loss:0.00001, loss_test:0.11517, lr:1.45e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.307, tt:4365.907\n",
      "Ep:215, loss:0.00001, loss_test:0.11523, lr:1.44e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.308, tt:4386.491\n",
      "Ep:216, loss:0.00001, loss_test:0.11533, lr:1.42e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.321, tt:4409.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:217, loss:0.00001, loss_test:0.11520, lr:1.41e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.319, tt:4429.444\n",
      "Ep:218, loss:0.00001, loss_test:0.11508, lr:1.39e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.317, tt:4449.471\n",
      "Ep:219, loss:0.00000, loss_test:0.11515, lr:1.38e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.317, tt:4469.778\n",
      "Ep:220, loss:0.00000, loss_test:0.11527, lr:1.37e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.317, tt:4489.998\n",
      "Ep:221, loss:0.00000, loss_test:0.11512, lr:1.35e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.313, tt:4509.389\n",
      "Ep:222, loss:0.00000, loss_test:0.11502, lr:1.34e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.305, tt:4528.020\n",
      "Ep:223, loss:0.00000, loss_test:0.11508, lr:1.33e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.306, tt:4548.604\n",
      "Ep:224, loss:0.00000, loss_test:0.11515, lr:1.31e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.308, tt:4569.248\n",
      "Ep:225, loss:0.00000, loss_test:0.11503, lr:1.30e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.302, tt:4588.158\n",
      "Ep:226, loss:0.00000, loss_test:0.11496, lr:1.29e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.302, tt:4608.549\n",
      "Ep:227, loss:0.00000, loss_test:0.11513, lr:1.27e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.298, tt:4627.946\n",
      "Ep:228, loss:0.00000, loss_test:0.11508, lr:1.26e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.294, tt:4647.401\n",
      "Ep:229, loss:0.00000, loss_test:0.11487, lr:1.25e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.285, tt:4665.564\n",
      "Ep:230, loss:0.00000, loss_test:0.11495, lr:1.24e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.282, tt:4685.231\n",
      "Ep:231, loss:0.00000, loss_test:0.11514, lr:1.22e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.278, tt:4704.419\n",
      "Ep:232, loss:0.00000, loss_test:0.11504, lr:1.21e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.276, tt:4724.250\n",
      "Ep:233, loss:0.00000, loss_test:0.11487, lr:1.20e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.272, tt:4743.653\n",
      "Ep:234, loss:0.00000, loss_test:0.11490, lr:1.19e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.270, tt:4763.500\n",
      "Ep:235, loss:0.00000, loss_test:0.11504, lr:1.18e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.268, tt:4783.303\n",
      "Ep:236, loss:0.00000, loss_test:0.11505, lr:1.16e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.267, tt:4803.301\n",
      "Ep:237, loss:0.00000, loss_test:0.11486, lr:1.15e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.268, tt:4823.793\n",
      "Ep:238, loss:0.00000, loss_test:0.11480, lr:1.14e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.266, tt:4843.624\n",
      "Ep:239, loss:0.00000, loss_test:0.11495, lr:1.13e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.263, tt:4863.091\n",
      "Ep:240, loss:0.00000, loss_test:0.11497, lr:1.12e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.265, tt:4883.944\n",
      "Ep:241, loss:0.00000, loss_test:0.11481, lr:1.11e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.261, tt:4903.048\n",
      "Ep:242, loss:0.00000, loss_test:0.11481, lr:1.10e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.261, tt:4923.357\n",
      "Ep:243, loss:0.00000, loss_test:0.11491, lr:1.08e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.256, tt:4942.361\n",
      "Ep:244, loss:0.00000, loss_test:0.11484, lr:1.07e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.253, tt:4961.895\n",
      "Ep:245, loss:0.00000, loss_test:0.11475, lr:1.06e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.243, tt:4979.886\n",
      "Ep:246, loss:0.00000, loss_test:0.11483, lr:1.05e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.238, tt:4998.776\n",
      "Ep:247, loss:0.00000, loss_test:0.11485, lr:1.04e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.236, tt:5018.631\n",
      "Ep:248, loss:0.00000, loss_test:0.11474, lr:1.03e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.251, tt:5042.379\n",
      "Ep:249, loss:0.00000, loss_test:0.11476, lr:1.02e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.245, tt:5061.162\n",
      "Ep:250, loss:0.00000, loss_test:0.11482, lr:1.01e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.242, tt:5080.738\n",
      "Ep:251, loss:0.00000, loss_test:0.11474, lr:1.00e-03, fs:0.66667 (r=0.525,p=0.912),  time:20.242, tt:5101.057\n",
      "Ep:252, loss:0.00000, loss_test:0.11471, lr:9.91e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.236, tt:5119.799\n",
      "Ep:253, loss:0.00000, loss_test:0.11480, lr:9.81e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.234, tt:5139.342\n",
      "Ep:254, loss:0.00000, loss_test:0.11475, lr:9.71e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.235, tt:5159.988\n",
      "Ep:255, loss:0.00000, loss_test:0.11462, lr:9.62e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.233, tt:5179.623\n",
      "Ep:256, loss:0.00000, loss_test:0.11473, lr:9.52e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.232, tt:5199.730\n",
      "Ep:257, loss:0.00000, loss_test:0.11476, lr:9.42e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.234, tt:5220.249\n",
      "Ep:258, loss:0.00000, loss_test:0.11465, lr:9.33e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.232, tt:5240.153\n",
      "Ep:259, loss:0.00000, loss_test:0.11464, lr:9.24e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.232, tt:5260.244\n",
      "Ep:260, loss:0.00000, loss_test:0.11469, lr:9.14e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.231, tt:5280.372\n",
      "Ep:261, loss:0.00000, loss_test:0.11468, lr:9.05e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.224, tt:5298.759\n",
      "Ep:262, loss:0.00000, loss_test:0.11460, lr:8.96e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.225, tt:5319.187\n",
      "Ep:263, loss:0.00000, loss_test:0.11463, lr:8.87e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.227, tt:5339.870\n",
      "Ep:264, loss:0.00000, loss_test:0.11463, lr:8.78e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.229, tt:5360.564\n",
      "Ep:265, loss:0.00000, loss_test:0.11459, lr:8.70e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.225, tt:5379.947\n",
      "Ep:266, loss:0.00000, loss_test:0.11455, lr:8.61e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.226, tt:5400.275\n",
      "Ep:267, loss:0.00000, loss_test:0.11464, lr:8.52e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.225, tt:5420.423\n",
      "Ep:268, loss:0.00000, loss_test:0.11461, lr:8.44e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.227, tt:5440.934\n",
      "Ep:269, loss:0.00000, loss_test:0.11453, lr:8.35e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.229, tt:5461.925\n",
      "Ep:270, loss:0.00000, loss_test:0.11457, lr:8.27e-04, fs:0.66667 (r=0.525,p=0.912),  time:20.227, tt:5481.575\n",
      "Ep:271, loss:0.00000, loss_test:0.11461, lr:8.19e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.226, tt:5501.606\n",
      "Ep:272, loss:0.00000, loss_test:0.11457, lr:8.11e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.227, tt:5522.097\n",
      "Ep:273, loss:0.00000, loss_test:0.11454, lr:8.02e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.224, tt:5541.362\n",
      "Ep:274, loss:0.00000, loss_test:0.11459, lr:7.94e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.219, tt:5560.145\n",
      "Ep:275, loss:0.00000, loss_test:0.11458, lr:7.87e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.220, tt:5580.588\n",
      "Ep:276, loss:0.00000, loss_test:0.11453, lr:7.79e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.221, tt:5601.087\n",
      "Ep:277, loss:0.00000, loss_test:0.11458, lr:7.71e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.221, tt:5621.301\n",
      "Ep:278, loss:0.00000, loss_test:0.11457, lr:7.63e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.218, tt:5640.708\n",
      "Ep:279, loss:0.00000, loss_test:0.11451, lr:7.56e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.217, tt:5660.829\n",
      "Ep:280, loss:0.00000, loss_test:0.11452, lr:7.48e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.232, tt:5685.141\n",
      "Ep:281, loss:0.00000, loss_test:0.11453, lr:7.40e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.235, tt:5706.405\n",
      "Ep:282, loss:0.00000, loss_test:0.11451, lr:7.33e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.232, tt:5725.709\n",
      "Ep:283, loss:0.00000, loss_test:0.11453, lr:7.26e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.225, tt:5743.804\n",
      "Ep:284, loss:0.00000, loss_test:0.11449, lr:7.18e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.222, tt:5763.204\n",
      "Ep:285, loss:0.00000, loss_test:0.11448, lr:7.11e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.223, tt:5783.737\n",
      "Ep:286, loss:0.00000, loss_test:0.11448, lr:7.04e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.220, tt:5803.126\n",
      "Ep:287, loss:0.00000, loss_test:0.11446, lr:6.97e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.220, tt:5823.266\n",
      "Ep:288, loss:0.00000, loss_test:0.11443, lr:6.90e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.221, tt:5843.738\n",
      "Ep:289, loss:0.00000, loss_test:0.11446, lr:6.83e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.219, tt:5863.493\n",
      "Ep:290, loss:0.00000, loss_test:0.11440, lr:6.76e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.218, tt:5883.541\n",
      "Ep:291, loss:0.00000, loss_test:0.11442, lr:6.70e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.217, tt:5903.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:292, loss:0.00000, loss_test:0.11438, lr:6.63e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.210, tt:5921.468\n",
      "Ep:293, loss:0.00000, loss_test:0.11442, lr:6.56e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.206, tt:5940.443\n",
      "Ep:294, loss:0.00000, loss_test:0.11438, lr:6.50e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.199, tt:5958.573\n",
      "Ep:295, loss:0.00000, loss_test:0.11435, lr:6.43e-04, fs:0.67097 (r=0.525,p=0.929),  time:20.184, tt:5974.351\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14775, lr:1.00e-02, fs:0.63830 (r=0.909,p=0.492),  time:17.936, tt:17.936\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14735, lr:1.00e-02, fs:0.63082 (r=0.889,p=0.489),  time:18.141, tt:36.283\n",
      "Ep:2, loss:0.00004, loss_test:0.14680, lr:1.00e-02, fs:0.63309 (r=0.889,p=0.492),  time:18.082, tt:54.246\n",
      "Ep:3, loss:0.00004, loss_test:0.14615, lr:1.00e-02, fs:0.61538 (r=0.848,p=0.483),  time:18.199, tt:72.797\n",
      "Ep:4, loss:0.00004, loss_test:0.14521, lr:1.00e-02, fs:0.61765 (r=0.848,p=0.486),  time:18.297, tt:91.487\n",
      "Ep:5, loss:0.00004, loss_test:0.14415, lr:1.00e-02, fs:0.63359 (r=0.838,p=0.509),  time:18.295, tt:109.770\n",
      "Ep:6, loss:0.00004, loss_test:0.14297, lr:1.00e-02, fs:0.62451 (r=0.798,p=0.513),  time:18.446, tt:129.122\n",
      "Ep:7, loss:0.00004, loss_test:0.14143, lr:1.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:18.407, tt:147.254\n",
      "Ep:8, loss:0.00003, loss_test:0.14012, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:18.406, tt:165.657\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.13930, lr:1.00e-02, fs:0.63636 (r=0.778,p=0.538),  time:18.445, tt:184.449\n",
      "Ep:10, loss:0.00003, loss_test:0.13873, lr:1.00e-02, fs:0.63900 (r=0.778,p=0.542),  time:18.444, tt:202.881\n",
      "Ep:11, loss:0.00003, loss_test:0.13848, lr:1.00e-02, fs:0.63636 (r=0.778,p=0.538),  time:18.520, tt:222.237\n",
      "Ep:12, loss:0.00003, loss_test:0.13819, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:18.489, tt:240.357\n",
      "Ep:13, loss:0.00003, loss_test:0.13758, lr:1.00e-02, fs:0.63598 (r=0.768,p=0.543),  time:18.473, tt:258.621\n",
      "Ep:14, loss:0.00003, loss_test:0.13656, lr:1.00e-02, fs:0.62447 (r=0.747,p=0.536),  time:18.573, tt:278.589\n",
      "Ep:15, loss:0.00003, loss_test:0.13538, lr:1.00e-02, fs:0.62931 (r=0.737,p=0.549),  time:18.576, tt:297.216\n",
      "Ep:16, loss:0.00003, loss_test:0.13438, lr:1.00e-02, fs:0.62609 (r=0.727,p=0.550),  time:18.686, tt:317.668\n",
      "Ep:17, loss:0.00003, loss_test:0.13362, lr:1.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:18.712, tt:336.812\n",
      "Ep:18, loss:0.00003, loss_test:0.13304, lr:1.00e-02, fs:0.60633 (r=0.677,p=0.549),  time:18.738, tt:356.028\n",
      "Ep:19, loss:0.00003, loss_test:0.13257, lr:1.00e-02, fs:0.62162 (r=0.697,p=0.561),  time:18.737, tt:374.742\n",
      "Ep:20, loss:0.00003, loss_test:0.13200, lr:9.90e-03, fs:0.63636 (r=0.707,p=0.579),  time:18.810, tt:395.020\n",
      "Ep:21, loss:0.00003, loss_test:0.13104, lr:9.80e-03, fs:0.64486 (r=0.697,p=0.600),  time:18.842, tt:414.533\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.12967, lr:9.80e-03, fs:0.64151 (r=0.687,p=0.602),  time:18.885, tt:434.346\n",
      "Ep:23, loss:0.00003, loss_test:0.12840, lr:9.80e-03, fs:0.63768 (r=0.667,p=0.611),  time:18.884, tt:453.220\n",
      "Ep:24, loss:0.00003, loss_test:0.12730, lr:9.80e-03, fs:0.63725 (r=0.657,p=0.619),  time:18.888, tt:472.199\n",
      "Ep:25, loss:0.00003, loss_test:0.12636, lr:9.80e-03, fs:0.64039 (r=0.657,p=0.625),  time:18.906, tt:491.563\n",
      "Ep:26, loss:0.00003, loss_test:0.12544, lr:9.80e-03, fs:0.65657 (r=0.657,p=0.657),  time:18.939, tt:511.362\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.12443, lr:9.80e-03, fs:0.65657 (r=0.657,p=0.657),  time:18.950, tt:530.591\n",
      "Ep:28, loss:0.00003, loss_test:0.12363, lr:9.80e-03, fs:0.66327 (r=0.657,p=0.670),  time:18.959, tt:549.811\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.12305, lr:9.80e-03, fs:0.64615 (r=0.636,p=0.656),  time:18.973, tt:569.199\n",
      "Ep:30, loss:0.00002, loss_test:0.12289, lr:9.80e-03, fs:0.64249 (r=0.626,p=0.660),  time:18.994, tt:588.822\n",
      "Ep:31, loss:0.00002, loss_test:0.12281, lr:9.80e-03, fs:0.63542 (r=0.616,p=0.656),  time:19.020, tt:608.625\n",
      "Ep:32, loss:0.00002, loss_test:0.12226, lr:9.80e-03, fs:0.62887 (r=0.616,p=0.642),  time:19.020, tt:627.660\n",
      "Ep:33, loss:0.00002, loss_test:0.12160, lr:9.80e-03, fs:0.61780 (r=0.596,p=0.641),  time:19.018, tt:646.624\n",
      "Ep:34, loss:0.00002, loss_test:0.12121, lr:9.80e-03, fs:0.61376 (r=0.586,p=0.644),  time:19.042, tt:666.455\n",
      "Ep:35, loss:0.00002, loss_test:0.12117, lr:9.80e-03, fs:0.61458 (r=0.596,p=0.634),  time:19.055, tt:685.982\n",
      "Ep:36, loss:0.00002, loss_test:0.12106, lr:9.80e-03, fs:0.62500 (r=0.606,p=0.645),  time:19.076, tt:705.829\n",
      "Ep:37, loss:0.00002, loss_test:0.12094, lr:9.80e-03, fs:0.62500 (r=0.606,p=0.645),  time:19.078, tt:724.960\n",
      "Ep:38, loss:0.00002, loss_test:0.12095, lr:9.80e-03, fs:0.62500 (r=0.606,p=0.645),  time:19.077, tt:744.004\n",
      "Ep:39, loss:0.00002, loss_test:0.12109, lr:9.80e-03, fs:0.63542 (r=0.616,p=0.656),  time:19.073, tt:762.900\n",
      "Ep:40, loss:0.00002, loss_test:0.12135, lr:9.70e-03, fs:0.63212 (r=0.616,p=0.649),  time:19.070, tt:781.876\n",
      "Ep:41, loss:0.00002, loss_test:0.12151, lr:9.61e-03, fs:0.62827 (r=0.606,p=0.652),  time:19.075, tt:801.154\n",
      "Ep:42, loss:0.00002, loss_test:0.12136, lr:9.51e-03, fs:0.62434 (r=0.596,p=0.656),  time:19.060, tt:819.565\n",
      "Ep:43, loss:0.00002, loss_test:0.12100, lr:9.41e-03, fs:0.62766 (r=0.596,p=0.663),  time:19.057, tt:838.504\n",
      "Ep:44, loss:0.00002, loss_test:0.12062, lr:9.32e-03, fs:0.62434 (r=0.596,p=0.656),  time:19.053, tt:857.387\n",
      "Ep:45, loss:0.00002, loss_test:0.12018, lr:9.23e-03, fs:0.64583 (r=0.626,p=0.667),  time:19.065, tt:876.998\n",
      "Ep:46, loss:0.00002, loss_test:0.11964, lr:9.14e-03, fs:0.64171 (r=0.606,p=0.682),  time:19.065, tt:896.038\n",
      "Ep:47, loss:0.00002, loss_test:0.11947, lr:9.04e-03, fs:0.64171 (r=0.606,p=0.682),  time:19.062, tt:914.968\n",
      "Ep:48, loss:0.00002, loss_test:0.11966, lr:8.95e-03, fs:0.65969 (r=0.636,p=0.685),  time:19.072, tt:934.505\n",
      "Ep:49, loss:0.00002, loss_test:0.11953, lr:8.86e-03, fs:0.65625 (r=0.636,p=0.677),  time:19.081, tt:954.044\n",
      "Ep:50, loss:0.00002, loss_test:0.11908, lr:8.78e-03, fs:0.66316 (r=0.636,p=0.692),  time:19.083, tt:973.232\n",
      "Ep:51, loss:0.00002, loss_test:0.11876, lr:8.69e-03, fs:0.65957 (r=0.626,p=0.697),  time:19.078, tt:992.032\n",
      "Ep:52, loss:0.00002, loss_test:0.11842, lr:8.60e-03, fs:0.66310 (r=0.626,p=0.705),  time:19.092, tt:1011.898\n",
      "Ep:53, loss:0.00002, loss_test:0.11812, lr:8.51e-03, fs:0.66310 (r=0.626,p=0.705),  time:19.096, tt:1031.198\n",
      "Ep:54, loss:0.00002, loss_test:0.11778, lr:8.43e-03, fs:0.66310 (r=0.626,p=0.705),  time:19.098, tt:1050.393\n",
      "Ep:55, loss:0.00002, loss_test:0.11746, lr:8.35e-03, fs:0.67027 (r=0.626,p=0.721),  time:19.087, tt:1068.888\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.11710, lr:8.35e-03, fs:0.67027 (r=0.626,p=0.721),  time:19.093, tt:1088.309\n",
      "Ep:57, loss:0.00002, loss_test:0.11674, lr:8.35e-03, fs:0.66304 (r=0.616,p=0.718),  time:19.075, tt:1106.356\n",
      "Ep:58, loss:0.00002, loss_test:0.11654, lr:8.35e-03, fs:0.66304 (r=0.616,p=0.718),  time:19.073, tt:1125.299\n",
      "Ep:59, loss:0.00002, loss_test:0.11643, lr:8.35e-03, fs:0.66304 (r=0.616,p=0.718),  time:19.046, tt:1142.766\n",
      "Ep:60, loss:0.00002, loss_test:0.11637, lr:8.35e-03, fs:0.65946 (r=0.616,p=0.709),  time:19.030, tt:1160.820\n",
      "Ep:61, loss:0.00002, loss_test:0.11609, lr:8.35e-03, fs:0.66667 (r=0.616,p=0.726),  time:19.018, tt:1179.119\n",
      "Ep:62, loss:0.00002, loss_test:0.11585, lr:8.35e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.995, tt:1196.679\n",
      "Ep:63, loss:0.00001, loss_test:0.11579, lr:8.35e-03, fs:0.65193 (r=0.596,p=0.720),  time:18.974, tt:1214.334\n",
      "Ep:64, loss:0.00001, loss_test:0.11602, lr:8.35e-03, fs:0.65193 (r=0.596,p=0.720),  time:18.973, tt:1233.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.11631, lr:8.35e-03, fs:0.65934 (r=0.606,p=0.723),  time:18.961, tt:1251.447\n",
      "Ep:66, loss:0.00001, loss_test:0.11618, lr:8.35e-03, fs:0.65193 (r=0.596,p=0.720),  time:18.946, tt:1269.372\n",
      "Ep:67, loss:0.00001, loss_test:0.11548, lr:8.26e-03, fs:0.65193 (r=0.596,p=0.720),  time:18.938, tt:1287.777\n",
      "Ep:68, loss:0.00001, loss_test:0.11480, lr:8.18e-03, fs:0.65934 (r=0.606,p=0.723),  time:18.933, tt:1306.396\n",
      "Ep:69, loss:0.00001, loss_test:0.11477, lr:8.10e-03, fs:0.65934 (r=0.606,p=0.723),  time:18.931, tt:1325.146\n",
      "Ep:70, loss:0.00001, loss_test:0.11455, lr:8.02e-03, fs:0.66298 (r=0.606,p=0.732),  time:18.916, tt:1343.047\n",
      "Ep:71, loss:0.00001, loss_test:0.11409, lr:7.94e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.907, tt:1361.281\n",
      "Ep:72, loss:0.00001, loss_test:0.11384, lr:7.86e-03, fs:0.65556 (r=0.596,p=0.728),  time:18.906, tt:1380.172\n",
      "Ep:73, loss:0.00001, loss_test:0.11368, lr:7.78e-03, fs:0.65556 (r=0.596,p=0.728),  time:18.892, tt:1398.006\n",
      "Ep:74, loss:0.00001, loss_test:0.11351, lr:7.70e-03, fs:0.65169 (r=0.586,p=0.734),  time:18.890, tt:1416.762\n",
      "Ep:75, loss:0.00001, loss_test:0.11303, lr:7.62e-03, fs:0.65556 (r=0.596,p=0.728),  time:18.897, tt:1436.207\n",
      "Ep:76, loss:0.00001, loss_test:0.11268, lr:7.55e-03, fs:0.65556 (r=0.596,p=0.728),  time:18.897, tt:1455.051\n",
      "Ep:77, loss:0.00001, loss_test:0.11240, lr:7.47e-03, fs:0.65556 (r=0.596,p=0.728),  time:18.897, tt:1473.962\n",
      "Ep:78, loss:0.00001, loss_test:0.11208, lr:7.40e-03, fs:0.66292 (r=0.596,p=0.747),  time:18.900, tt:1493.133\n",
      "Ep:79, loss:0.00001, loss_test:0.11190, lr:7.32e-03, fs:0.65909 (r=0.586,p=0.753),  time:18.920, tt:1513.629\n",
      "Ep:80, loss:0.00001, loss_test:0.11169, lr:7.25e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.933, tt:1533.597\n",
      "Ep:81, loss:0.00001, loss_test:0.11132, lr:7.18e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.923, tt:1551.699\n",
      "Ep:82, loss:0.00001, loss_test:0.11110, lr:7.11e-03, fs:0.65537 (r=0.586,p=0.744),  time:18.933, tt:1571.419\n",
      "Ep:83, loss:0.00001, loss_test:0.11108, lr:7.03e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.935, tt:1590.550\n",
      "Ep:84, loss:0.00001, loss_test:0.11092, lr:6.96e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.938, tt:1609.724\n",
      "Ep:85, loss:0.00001, loss_test:0.11062, lr:6.89e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.948, tt:1629.532\n",
      "Ep:86, loss:0.00001, loss_test:0.11043, lr:6.83e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.941, tt:1647.835\n",
      "Ep:87, loss:0.00001, loss_test:0.11043, lr:6.76e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.938, tt:1666.523\n",
      "Ep:88, loss:0.00001, loss_test:0.11027, lr:6.69e-03, fs:0.65116 (r=0.566,p=0.767),  time:18.952, tt:1686.759\n",
      "Ep:89, loss:0.00001, loss_test:0.10987, lr:6.62e-03, fs:0.65116 (r=0.566,p=0.767),  time:18.950, tt:1705.505\n",
      "Ep:90, loss:0.00001, loss_test:0.10943, lr:6.56e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.948, tt:1724.312\n",
      "Ep:91, loss:0.00001, loss_test:0.10959, lr:6.49e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.960, tt:1744.348\n",
      "Ep:92, loss:0.00001, loss_test:0.10950, lr:6.43e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.956, tt:1762.875\n",
      "Ep:93, loss:0.00001, loss_test:0.10914, lr:6.36e-03, fs:0.67052 (r=0.586,p=0.784),  time:18.952, tt:1781.533\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.10903, lr:6.36e-03, fs:0.67052 (r=0.586,p=0.784),  time:18.955, tt:1800.756\n",
      "Ep:95, loss:0.00001, loss_test:0.10894, lr:6.36e-03, fs:0.67052 (r=0.586,p=0.784),  time:18.959, tt:1820.057\n",
      "Ep:96, loss:0.00001, loss_test:0.10863, lr:6.36e-03, fs:0.67052 (r=0.586,p=0.784),  time:18.964, tt:1839.532\n",
      "Ep:97, loss:0.00001, loss_test:0.10862, lr:6.36e-03, fs:0.67052 (r=0.586,p=0.784),  time:18.967, tt:1858.728\n",
      "Ep:98, loss:0.00001, loss_test:0.10844, lr:6.36e-03, fs:0.67816 (r=0.596,p=0.787),  time:18.965, tt:1877.499\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.10840, lr:6.36e-03, fs:0.67442 (r=0.586,p=0.795),  time:18.958, tt:1895.776\n",
      "Ep:100, loss:0.00001, loss_test:0.10816, lr:6.36e-03, fs:0.67442 (r=0.586,p=0.795),  time:18.961, tt:1915.015\n",
      "Ep:101, loss:0.00001, loss_test:0.10799, lr:6.36e-03, fs:0.67442 (r=0.586,p=0.795),  time:18.953, tt:1933.236\n",
      "Ep:102, loss:0.00001, loss_test:0.10798, lr:6.36e-03, fs:0.68966 (r=0.606,p=0.800),  time:18.953, tt:1952.141\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.10751, lr:6.36e-03, fs:0.69364 (r=0.606,p=0.811),  time:18.949, tt:1970.683\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.10761, lr:6.36e-03, fs:0.69364 (r=0.606,p=0.811),  time:18.959, tt:1990.711\n",
      "Ep:105, loss:0.00001, loss_test:0.10761, lr:6.36e-03, fs:0.70455 (r=0.626,p=0.805),  time:18.952, tt:2008.919\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.10739, lr:6.36e-03, fs:0.69767 (r=0.606,p=0.822),  time:18.947, tt:2027.356\n",
      "Ep:107, loss:0.00001, loss_test:0.10742, lr:6.36e-03, fs:0.69767 (r=0.606,p=0.822),  time:18.936, tt:2045.079\n",
      "Ep:108, loss:0.00001, loss_test:0.10719, lr:6.36e-03, fs:0.71264 (r=0.626,p=0.827),  time:18.931, tt:2063.515\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00001, loss_test:0.10720, lr:6.36e-03, fs:0.71264 (r=0.626,p=0.827),  time:18.935, tt:2082.852\n",
      "Ep:110, loss:0.00001, loss_test:0.10736, lr:6.36e-03, fs:0.69767 (r=0.606,p=0.822),  time:18.937, tt:2101.999\n",
      "Ep:111, loss:0.00001, loss_test:0.10729, lr:6.36e-03, fs:0.71264 (r=0.626,p=0.827),  time:18.937, tt:2120.996\n",
      "Ep:112, loss:0.00001, loss_test:0.10702, lr:6.36e-03, fs:0.70520 (r=0.616,p=0.824),  time:18.937, tt:2139.855\n",
      "Ep:113, loss:0.00001, loss_test:0.10709, lr:6.36e-03, fs:0.70520 (r=0.616,p=0.824),  time:18.932, tt:2158.302\n",
      "Ep:114, loss:0.00001, loss_test:0.10704, lr:6.36e-03, fs:0.71676 (r=0.626,p=0.838),  time:18.924, tt:2176.296\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.10662, lr:6.36e-03, fs:0.71676 (r=0.626,p=0.838),  time:18.919, tt:2194.617\n",
      "Ep:116, loss:0.00001, loss_test:0.10711, lr:6.36e-03, fs:0.70930 (r=0.616,p=0.836),  time:18.915, tt:2213.032\n",
      "Ep:117, loss:0.00001, loss_test:0.10655, lr:6.36e-03, fs:0.71676 (r=0.626,p=0.838),  time:18.922, tt:2232.791\n",
      "Ep:118, loss:0.00001, loss_test:0.10661, lr:6.36e-03, fs:0.71676 (r=0.626,p=0.838),  time:18.925, tt:2252.022\n",
      "Ep:119, loss:0.00001, loss_test:0.10714, lr:6.36e-03, fs:0.71676 (r=0.626,p=0.838),  time:18.921, tt:2270.575\n",
      "Ep:120, loss:0.00001, loss_test:0.10658, lr:6.36e-03, fs:0.73864 (r=0.657,p=0.844),  time:18.917, tt:2288.918\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.10631, lr:6.36e-03, fs:0.74576 (r=0.667,p=0.846),  time:18.913, tt:2307.380\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00001, loss_test:0.10675, lr:6.36e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.903, tt:2325.055\n",
      "Ep:123, loss:0.00001, loss_test:0.10647, lr:6.36e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.903, tt:2343.937\n",
      "Ep:124, loss:0.00001, loss_test:0.10598, lr:6.36e-03, fs:0.73864 (r=0.657,p=0.844),  time:18.901, tt:2362.572\n",
      "Ep:125, loss:0.00001, loss_test:0.10644, lr:6.36e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.901, tt:2381.474\n",
      "Ep:126, loss:0.00001, loss_test:0.10659, lr:6.36e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.895, tt:2399.622\n",
      "Ep:127, loss:0.00001, loss_test:0.10607, lr:6.36e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.895, tt:2418.552\n",
      "Ep:128, loss:0.00001, loss_test:0.10617, lr:6.36e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.886, tt:2436.331\n",
      "Ep:129, loss:0.00001, loss_test:0.10586, lr:6.36e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.875, tt:2453.705\n",
      "Ep:130, loss:0.00001, loss_test:0.10556, lr:6.36e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.868, tt:2471.660\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.10600, lr:6.36e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.861, tt:2489.590\n",
      "Ep:132, loss:0.00001, loss_test:0.10544, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.849, tt:2506.905\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00001, loss_test:0.10550, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.840, tt:2524.610\n",
      "Ep:134, loss:0.00001, loss_test:0.10552, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.836, tt:2542.817\n",
      "Ep:135, loss:0.00001, loss_test:0.10485, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.829, tt:2560.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00001, loss_test:0.10546, lr:6.36e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.821, tt:2578.448\n",
      "Ep:137, loss:0.00001, loss_test:0.10501, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.820, tt:2597.095\n",
      "Ep:138, loss:0.00001, loss_test:0.10481, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.807, tt:2614.114\n",
      "Ep:139, loss:0.00001, loss_test:0.10533, lr:6.36e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.803, tt:2632.374\n",
      "Ep:140, loss:0.00001, loss_test:0.10461, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.804, tt:2651.385\n",
      "Ep:141, loss:0.00001, loss_test:0.10460, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.805, tt:2670.263\n",
      "Ep:142, loss:0.00001, loss_test:0.10492, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.801, tt:2688.521\n",
      "Ep:143, loss:0.00001, loss_test:0.10439, lr:6.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.803, tt:2707.584\n",
      "Ep:144, loss:0.00001, loss_test:0.10518, lr:6.30e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.805, tt:2726.676\n",
      "Ep:145, loss:0.00001, loss_test:0.10470, lr:6.24e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.809, tt:2746.135\n",
      "Ep:146, loss:0.00001, loss_test:0.10464, lr:6.17e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.813, tt:2765.479\n",
      "Ep:147, loss:0.00001, loss_test:0.10485, lr:6.11e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.814, tt:2784.498\n",
      "Ep:148, loss:0.00001, loss_test:0.10441, lr:6.05e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.824, tt:2804.805\n",
      "Ep:149, loss:0.00001, loss_test:0.10499, lr:5.99e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.821, tt:2823.172\n",
      "Ep:150, loss:0.00001, loss_test:0.10472, lr:5.93e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.825, tt:2842.640\n",
      "Ep:151, loss:0.00001, loss_test:0.10439, lr:5.87e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.824, tt:2861.195\n",
      "Ep:152, loss:0.00001, loss_test:0.10485, lr:5.81e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.826, tt:2880.310\n",
      "Ep:153, loss:0.00001, loss_test:0.10459, lr:5.75e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.833, tt:2900.352\n",
      "Ep:154, loss:0.00001, loss_test:0.10419, lr:5.70e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.836, tt:2919.532\n",
      "Ep:155, loss:0.00001, loss_test:0.10447, lr:5.64e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.842, tt:2939.283\n",
      "Ep:156, loss:0.00001, loss_test:0.10448, lr:5.58e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.846, tt:2958.870\n",
      "Ep:157, loss:0.00001, loss_test:0.10441, lr:5.53e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.855, tt:2979.063\n",
      "Ep:158, loss:0.00001, loss_test:0.10437, lr:5.47e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.857, tt:2998.300\n",
      "Ep:159, loss:0.00001, loss_test:0.10433, lr:5.42e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.867, tt:3018.659\n",
      "Ep:160, loss:0.00001, loss_test:0.10456, lr:5.36e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.872, tt:3038.410\n",
      "Ep:161, loss:0.00001, loss_test:0.10401, lr:5.31e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.875, tt:3057.785\n",
      "Ep:162, loss:0.00001, loss_test:0.10433, lr:5.26e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.879, tt:3077.265\n",
      "Ep:163, loss:0.00001, loss_test:0.10469, lr:5.20e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.885, tt:3097.097\n",
      "Ep:164, loss:0.00001, loss_test:0.10408, lr:5.15e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.888, tt:3116.539\n",
      "Ep:165, loss:0.00001, loss_test:0.10429, lr:5.10e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.893, tt:3136.179\n",
      "Ep:166, loss:0.00001, loss_test:0.10443, lr:5.05e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.892, tt:3154.975\n",
      "Ep:167, loss:0.00001, loss_test:0.10420, lr:5.00e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.896, tt:3174.451\n",
      "Ep:168, loss:0.00001, loss_test:0.10419, lr:4.95e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.899, tt:3193.953\n",
      "Ep:169, loss:0.00001, loss_test:0.10423, lr:4.90e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.901, tt:3213.152\n",
      "Ep:170, loss:0.00001, loss_test:0.10433, lr:4.85e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.905, tt:3232.811\n",
      "Ep:171, loss:0.00000, loss_test:0.10419, lr:4.80e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.901, tt:3250.974\n",
      "Ep:172, loss:0.00000, loss_test:0.10409, lr:4.75e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.902, tt:3270.066\n",
      "Ep:173, loss:0.00000, loss_test:0.10463, lr:4.71e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.901, tt:3288.821\n",
      "Ep:174, loss:0.00000, loss_test:0.10447, lr:4.66e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.906, tt:3308.513\n",
      "Ep:175, loss:0.00000, loss_test:0.10391, lr:4.61e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.905, tt:3327.253\n",
      "Ep:176, loss:0.00000, loss_test:0.10445, lr:4.57e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.906, tt:3346.345\n",
      "Ep:177, loss:0.00000, loss_test:0.10471, lr:4.52e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.904, tt:3364.957\n",
      "Ep:178, loss:0.00000, loss_test:0.10386, lr:4.48e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.902, tt:3383.403\n",
      "Ep:179, loss:0.00000, loss_test:0.10404, lr:4.43e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.901, tt:3402.258\n",
      "Ep:180, loss:0.00000, loss_test:0.10481, lr:4.39e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.899, tt:3420.787\n",
      "Ep:181, loss:0.00000, loss_test:0.10407, lr:4.34e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.898, tt:3439.470\n",
      "Ep:182, loss:0.00000, loss_test:0.10375, lr:4.30e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.902, tt:3459.125\n",
      "Ep:183, loss:0.00000, loss_test:0.10449, lr:4.26e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.914, tt:3480.248\n",
      "Ep:184, loss:0.00000, loss_test:0.10438, lr:4.21e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.915, tt:3499.201\n",
      "Ep:185, loss:0.00000, loss_test:0.10384, lr:4.17e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.917, tt:3518.636\n",
      "Ep:186, loss:0.00000, loss_test:0.10412, lr:4.13e-03, fs:0.73864 (r=0.657,p=0.844),  time:18.904, tt:3535.113\n",
      "Ep:187, loss:0.00000, loss_test:0.10412, lr:4.09e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.907, tt:3554.460\n",
      "Ep:188, loss:0.00000, loss_test:0.10380, lr:4.05e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.905, tt:3572.990\n",
      "Ep:189, loss:0.00000, loss_test:0.10401, lr:4.01e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.905, tt:3591.981\n",
      "Ep:190, loss:0.00000, loss_test:0.10399, lr:3.97e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.904, tt:3610.657\n",
      "Ep:191, loss:0.00000, loss_test:0.10372, lr:3.93e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.902, tt:3629.274\n",
      "Ep:192, loss:0.00000, loss_test:0.10395, lr:3.89e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.903, tt:3648.229\n",
      "Ep:193, loss:0.00000, loss_test:0.10410, lr:3.85e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.904, tt:3667.369\n",
      "Ep:194, loss:0.00000, loss_test:0.10383, lr:3.81e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.909, tt:3687.293\n",
      "Ep:195, loss:0.00000, loss_test:0.10383, lr:3.77e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.915, tt:3707.411\n",
      "Ep:196, loss:0.00000, loss_test:0.10392, lr:3.73e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.914, tt:3725.978\n",
      "Ep:197, loss:0.00000, loss_test:0.10390, lr:3.70e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.913, tt:3744.698\n",
      "Ep:198, loss:0.00000, loss_test:0.10366, lr:3.66e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.911, tt:3763.356\n",
      "Ep:199, loss:0.00000, loss_test:0.10365, lr:3.62e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.910, tt:3781.906\n",
      "Ep:200, loss:0.00000, loss_test:0.10383, lr:3.59e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.908, tt:3800.546\n",
      "Ep:201, loss:0.00000, loss_test:0.10363, lr:3.55e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.911, tt:3820.063\n",
      "Ep:202, loss:0.00000, loss_test:0.10358, lr:3.52e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.908, tt:3838.350\n",
      "Ep:203, loss:0.00000, loss_test:0.10371, lr:3.48e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.909, tt:3857.375\n",
      "Ep:204, loss:0.00000, loss_test:0.10357, lr:3.45e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.911, tt:3876.724\n",
      "Ep:205, loss:0.00000, loss_test:0.10374, lr:3.41e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.917, tt:3896.875\n",
      "Ep:206, loss:0.00000, loss_test:0.10381, lr:3.38e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.920, tt:3916.490\n",
      "Ep:207, loss:0.00000, loss_test:0.10347, lr:3.34e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.915, tt:3934.393\n",
      "Ep:208, loss:0.00000, loss_test:0.10368, lr:3.31e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.911, tt:3952.472\n",
      "Ep:209, loss:0.00000, loss_test:0.10371, lr:3.28e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.909, tt:3970.843\n",
      "Ep:210, loss:0.00000, loss_test:0.10344, lr:3.24e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.906, tt:3989.261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:211, loss:0.00000, loss_test:0.10361, lr:3.21e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.903, tt:4007.420\n",
      "Ep:212, loss:0.00000, loss_test:0.10371, lr:3.18e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.918, tt:4029.595\n",
      "Ep:213, loss:0.00000, loss_test:0.10337, lr:3.15e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.923, tt:4049.482\n",
      "Ep:214, loss:0.00000, loss_test:0.10349, lr:3.12e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.921, tt:4068.040\n",
      "Ep:215, loss:0.00000, loss_test:0.10370, lr:3.09e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.925, tt:4087.847\n",
      "Ep:216, loss:0.00000, loss_test:0.10337, lr:3.05e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.921, tt:4105.758\n",
      "Ep:217, loss:0.00000, loss_test:0.10342, lr:3.02e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.921, tt:4124.685\n",
      "Ep:218, loss:0.00000, loss_test:0.10365, lr:2.99e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.919, tt:4143.332\n",
      "Ep:219, loss:0.00000, loss_test:0.10339, lr:2.96e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.919, tt:4162.134\n",
      "Ep:220, loss:0.00000, loss_test:0.10336, lr:2.93e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.915, tt:4180.241\n",
      "Ep:221, loss:0.00000, loss_test:0.10361, lr:2.90e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.913, tt:4198.704\n",
      "Ep:222, loss:0.00000, loss_test:0.10347, lr:2.88e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.908, tt:4216.498\n",
      "Ep:223, loss:0.00000, loss_test:0.10326, lr:2.85e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.904, tt:4234.477\n",
      "Ep:224, loss:0.00000, loss_test:0.10347, lr:2.82e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.904, tt:4253.461\n",
      "Ep:225, loss:0.00000, loss_test:0.10346, lr:2.79e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.899, tt:4271.155\n",
      "Ep:226, loss:0.00000, loss_test:0.10330, lr:2.76e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.898, tt:4289.746\n",
      "Ep:227, loss:0.00000, loss_test:0.10346, lr:2.73e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.899, tt:4308.946\n",
      "Ep:228, loss:0.00000, loss_test:0.10333, lr:2.71e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.906, tt:4329.430\n",
      "Ep:229, loss:0.00000, loss_test:0.10339, lr:2.68e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.903, tt:4347.653\n",
      "Ep:230, loss:0.00000, loss_test:0.10342, lr:2.65e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.904, tt:4366.836\n",
      "Ep:231, loss:0.00000, loss_test:0.10326, lr:2.63e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.908, tt:4386.680\n",
      "Ep:232, loss:0.00000, loss_test:0.10349, lr:2.60e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.908, tt:4405.475\n",
      "Ep:233, loss:0.00000, loss_test:0.10345, lr:2.57e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.913, tt:4425.638\n",
      "Ep:234, loss:0.00000, loss_test:0.10317, lr:2.55e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.916, tt:4445.364\n",
      "Ep:235, loss:0.00000, loss_test:0.10341, lr:2.52e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.924, tt:4466.029\n",
      "Ep:236, loss:0.00000, loss_test:0.10353, lr:2.50e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.930, tt:4486.461\n",
      "Ep:237, loss:0.00000, loss_test:0.10321, lr:2.47e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.936, tt:4506.663\n",
      "Ep:238, loss:0.00000, loss_test:0.10322, lr:2.45e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.942, tt:4527.028\n",
      "Ep:239, loss:0.00000, loss_test:0.10343, lr:2.42e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.945, tt:4546.791\n",
      "Ep:240, loss:0.00000, loss_test:0.10339, lr:2.40e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.950, tt:4567.065\n",
      "Ep:241, loss:0.00000, loss_test:0.10316, lr:2.38e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.964, tt:4589.182\n",
      "Ep:242, loss:0.00000, loss_test:0.10322, lr:2.35e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.969, tt:4609.545\n",
      "Ep:243, loss:0.00000, loss_test:0.10345, lr:2.33e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.972, tt:4629.192\n",
      "Ep:244, loss:0.00000, loss_test:0.10336, lr:2.31e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.974, tt:4648.622\n",
      "Ep:245, loss:0.00000, loss_test:0.10316, lr:2.28e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.974, tt:4667.561\n",
      "Ep:246, loss:0.00000, loss_test:0.10323, lr:2.26e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.972, tt:4686.195\n",
      "Ep:247, loss:0.00000, loss_test:0.10337, lr:2.24e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.970, tt:4704.589\n",
      "Ep:248, loss:0.00000, loss_test:0.10329, lr:2.21e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.971, tt:4723.656\n",
      "Ep:249, loss:0.00000, loss_test:0.10319, lr:2.19e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.971, tt:4742.756\n",
      "Ep:250, loss:0.00000, loss_test:0.10320, lr:2.17e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.970, tt:4761.488\n",
      "Ep:251, loss:0.00000, loss_test:0.10327, lr:2.15e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.972, tt:4780.943\n",
      "Ep:252, loss:0.00000, loss_test:0.10323, lr:2.13e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.972, tt:4799.801\n",
      "Ep:253, loss:0.00000, loss_test:0.10306, lr:2.11e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.970, tt:4818.472\n",
      "Ep:254, loss:0.00000, loss_test:0.10306, lr:2.08e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.967, tt:4836.603\n",
      "Ep:255, loss:0.00000, loss_test:0.10319, lr:2.06e-03, fs:0.73563 (r=0.646,p=0.853),  time:18.962, tt:4854.334\n",
      "Ep:256, loss:0.00000, loss_test:0.10315, lr:2.04e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.958, tt:4872.196\n",
      "Ep:257, loss:0.00000, loss_test:0.10300, lr:2.02e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.957, tt:4890.944\n",
      "Ep:258, loss:0.00000, loss_test:0.10303, lr:2.00e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.953, tt:4908.773\n",
      "Ep:259, loss:0.00000, loss_test:0.10315, lr:1.98e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.950, tt:4927.115\n",
      "Ep:260, loss:0.00000, loss_test:0.10311, lr:1.96e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.945, tt:4944.721\n",
      "Ep:261, loss:0.00000, loss_test:0.10304, lr:1.94e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.937, tt:4961.389\n",
      "Ep:262, loss:0.00000, loss_test:0.10298, lr:1.92e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.935, tt:4979.950\n",
      "Ep:263, loss:0.00000, loss_test:0.10308, lr:1.90e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.931, tt:4997.903\n",
      "Ep:264, loss:0.00000, loss_test:0.10310, lr:1.89e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.930, tt:5016.523\n",
      "Ep:265, loss:0.00000, loss_test:0.10290, lr:1.87e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.929, tt:5035.146\n",
      "Ep:266, loss:0.00000, loss_test:0.10302, lr:1.85e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.931, tt:5054.705\n",
      "Ep:267, loss:0.00000, loss_test:0.10313, lr:1.83e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.931, tt:5073.620\n",
      "Ep:268, loss:0.00000, loss_test:0.10299, lr:1.81e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.938, tt:5094.303\n",
      "Ep:269, loss:0.00000, loss_test:0.10296, lr:1.79e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.936, tt:5112.654\n",
      "Ep:270, loss:0.00000, loss_test:0.10312, lr:1.78e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.937, tt:5131.991\n",
      "Ep:271, loss:0.00000, loss_test:0.10303, lr:1.76e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.933, tt:5149.770\n",
      "Ep:272, loss:0.00000, loss_test:0.10286, lr:1.74e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.934, tt:5168.892\n",
      "Ep:273, loss:0.00000, loss_test:0.10298, lr:1.72e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.934, tt:5188.015\n",
      "Ep:274, loss:0.00000, loss_test:0.10305, lr:1.71e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.934, tt:5206.767\n",
      "Ep:275, loss:0.00000, loss_test:0.10292, lr:1.69e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.930, tt:5224.750\n",
      "Ep:276, loss:0.00000, loss_test:0.10293, lr:1.67e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.932, tt:5244.068\n",
      "Ep:277, loss:0.00000, loss_test:0.10299, lr:1.65e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.931, tt:5262.768\n",
      "Ep:278, loss:0.00000, loss_test:0.10298, lr:1.64e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.930, tt:5281.384\n",
      "Ep:279, loss:0.00000, loss_test:0.10301, lr:1.62e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.928, tt:5299.779\n",
      "Ep:280, loss:0.00000, loss_test:0.10301, lr:1.61e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.927, tt:5318.539\n",
      "Ep:281, loss:0.00000, loss_test:0.10293, lr:1.59e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.925, tt:5336.919\n",
      "Ep:282, loss:0.00000, loss_test:0.10296, lr:1.57e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.923, tt:5355.188\n",
      "Ep:283, loss:0.00000, loss_test:0.10305, lr:1.56e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.923, tt:5374.183\n",
      "Ep:284, loss:0.00000, loss_test:0.10294, lr:1.54e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.915, tt:5390.884\n",
      "Ep:285, loss:0.00000, loss_test:0.10281, lr:1.53e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.913, tt:5409.150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:286, loss:0.00000, loss_test:0.10291, lr:1.51e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.913, tt:5428.045\n",
      "Ep:287, loss:0.00000, loss_test:0.10307, lr:1.50e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.912, tt:5446.548\n",
      "Ep:288, loss:0.00000, loss_test:0.10298, lr:1.48e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.908, tt:5464.471\n",
      "Ep:289, loss:0.00000, loss_test:0.10285, lr:1.47e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.908, tt:5483.204\n",
      "Ep:290, loss:0.00000, loss_test:0.10293, lr:1.45e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.905, tt:5501.433\n",
      "Ep:291, loss:0.00000, loss_test:0.10309, lr:1.44e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.903, tt:5519.788\n",
      "Ep:292, loss:0.00000, loss_test:0.10302, lr:1.42e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.901, tt:5537.856\n",
      "Ep:293, loss:0.00000, loss_test:0.10290, lr:1.41e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.897, tt:5555.783\n",
      "Ep:294, loss:0.00000, loss_test:0.10293, lr:1.39e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.897, tt:5574.593\n",
      "Ep:295, loss:0.00000, loss_test:0.10310, lr:1.38e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.874, tt:5586.725\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14168, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.334, tt:58.334\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13666, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:62.358, tt:124.716\n",
      "Ep:2, loss:0.00051, loss_test:0.12578, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:63.536, tt:190.608\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.12301, lr:1.00e-02, fs:0.66667 (r=0.677,p=0.657),  time:64.080, tt:256.321\n",
      "Ep:4, loss:0.00044, loss_test:0.11762, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:64.477, tt:322.385\n",
      "Ep:5, loss:0.00042, loss_test:0.11429, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:64.903, tt:389.416\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00039, loss_test:0.11297, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:65.496, tt:458.474\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00037, loss_test:0.11001, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:65.401, tt:523.207\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00035, loss_test:0.10698, lr:1.00e-02, fs:0.65957 (r=0.626,p=0.697),  time:65.513, tt:589.618\n",
      "Ep:9, loss:0.00033, loss_test:0.10338, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:65.390, tt:653.902\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.10196, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:65.342, tt:718.761\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00030, loss_test:0.09935, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:65.401, tt:784.806\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00029, loss_test:0.09936, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:65.481, tt:851.252\n",
      "Ep:13, loss:0.00027, loss_test:0.09647, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:65.598, tt:918.375\n",
      "Ep:14, loss:0.00026, loss_test:0.09518, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:65.586, tt:983.790\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.09526, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:65.560, tt:1048.964\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.09326, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:65.608, tt:1115.334\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.09392, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:65.665, tt:1181.962\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.09688, lr:1.00e-02, fs:0.71823 (r=0.657,p=0.793),  time:65.685, tt:1248.018\n",
      "Ep:19, loss:0.00021, loss_test:0.09260, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:65.686, tt:1313.728\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09214, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:65.638, tt:1378.390\n",
      "Ep:21, loss:0.00019, loss_test:0.09377, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:65.731, tt:1446.073\n",
      "Ep:22, loss:0.00018, loss_test:0.09420, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:65.788, tt:1513.132\n",
      "Ep:23, loss:0.00017, loss_test:0.09223, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:65.828, tt:1579.871\n",
      "Ep:24, loss:0.00017, loss_test:0.09200, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:66.043, tt:1651.066\n",
      "Ep:25, loss:0.00016, loss_test:0.09432, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:66.058, tt:1717.501\n",
      "Ep:26, loss:0.00015, loss_test:0.09181, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:66.140, tt:1785.781\n",
      "Ep:27, loss:0.00015, loss_test:0.09258, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:66.110, tt:1851.076\n",
      "Ep:28, loss:0.00014, loss_test:0.09285, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:66.168, tt:1918.862\n",
      "Ep:29, loss:0.00014, loss_test:0.09581, lr:1.00e-02, fs:0.72832 (r=0.636,p=0.851),  time:66.203, tt:1986.085\n",
      "Ep:30, loss:0.00013, loss_test:0.09269, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:66.203, tt:2052.292\n",
      "Ep:31, loss:0.00013, loss_test:0.09284, lr:9.90e-03, fs:0.75706 (r=0.677,p=0.859),  time:66.200, tt:2118.404\n",
      "Ep:32, loss:0.00012, loss_test:0.09369, lr:9.80e-03, fs:0.73563 (r=0.646,p=0.853),  time:66.287, tt:2187.479\n",
      "Ep:33, loss:0.00012, loss_test:0.09283, lr:9.70e-03, fs:0.75706 (r=0.677,p=0.859),  time:66.311, tt:2254.575\n",
      "Ep:34, loss:0.00011, loss_test:0.09281, lr:9.61e-03, fs:0.75145 (r=0.657,p=0.878),  time:66.360, tt:2322.586\n",
      "Ep:35, loss:0.00011, loss_test:0.09260, lr:9.51e-03, fs:0.76136 (r=0.677,p=0.870),  time:66.406, tt:2390.605\n",
      "Ep:36, loss:0.00010, loss_test:0.09346, lr:9.41e-03, fs:0.75706 (r=0.677,p=0.859),  time:66.412, tt:2457.232\n",
      "Ep:37, loss:0.00010, loss_test:0.09594, lr:9.32e-03, fs:0.73810 (r=0.626,p=0.899),  time:66.425, tt:2524.148\n",
      "Ep:38, loss:0.00010, loss_test:0.09483, lr:9.23e-03, fs:0.73810 (r=0.626,p=0.899),  time:66.382, tt:2588.911\n",
      "Ep:39, loss:0.00009, loss_test:0.09330, lr:9.14e-03, fs:0.74118 (r=0.636,p=0.887),  time:66.356, tt:2654.239\n",
      "Ep:40, loss:0.00009, loss_test:0.09544, lr:9.04e-03, fs:0.73810 (r=0.626,p=0.899),  time:66.366, tt:2720.990\n",
      "Ep:41, loss:0.00009, loss_test:0.09101, lr:8.95e-03, fs:0.77011 (r=0.677,p=0.893),  time:66.375, tt:2787.762\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.10058, lr:8.95e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.355, tt:2853.285\n",
      "Ep:43, loss:0.00009, loss_test:0.09667, lr:8.95e-03, fs:0.74118 (r=0.636,p=0.887),  time:66.393, tt:2921.292\n",
      "Ep:44, loss:0.00008, loss_test:0.09524, lr:8.95e-03, fs:0.74118 (r=0.636,p=0.887),  time:66.402, tt:2988.088\n",
      "Ep:45, loss:0.00008, loss_test:0.09358, lr:8.95e-03, fs:0.76023 (r=0.657,p=0.903),  time:66.450, tt:3056.703\n",
      "Ep:46, loss:0.00007, loss_test:0.09740, lr:8.95e-03, fs:0.71951 (r=0.596,p=0.908),  time:66.473, tt:3124.218\n",
      "Ep:47, loss:0.00007, loss_test:0.09571, lr:8.95e-03, fs:0.73054 (r=0.616,p=0.897),  time:66.417, tt:3188.022\n",
      "Ep:48, loss:0.00007, loss_test:0.09656, lr:8.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:66.410, tt:3254.088\n",
      "Ep:49, loss:0.00007, loss_test:0.09703, lr:8.95e-03, fs:0.70370 (r=0.576,p=0.905),  time:66.419, tt:3320.971\n",
      "Ep:50, loss:0.00007, loss_test:0.09575, lr:8.95e-03, fs:0.72727 (r=0.606,p=0.909),  time:66.431, tt:3387.958\n",
      "Ep:51, loss:0.00006, loss_test:0.09737, lr:8.95e-03, fs:0.70370 (r=0.576,p=0.905),  time:66.393, tt:3452.436\n",
      "Ep:52, loss:0.00006, loss_test:0.09794, lr:8.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:66.395, tt:3518.927\n",
      "Ep:53, loss:0.00006, loss_test:0.09690, lr:8.86e-03, fs:0.71166 (r=0.586,p=0.906),  time:66.405, tt:3585.870\n",
      "Ep:54, loss:0.00006, loss_test:0.09836, lr:8.78e-03, fs:0.69565 (r=0.566,p=0.903),  time:66.398, tt:3651.864\n",
      "Ep:55, loss:0.00006, loss_test:0.09987, lr:8.69e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.425, tt:3719.814\n",
      "Ep:56, loss:0.00005, loss_test:0.09834, lr:8.60e-03, fs:0.70370 (r=0.576,p=0.905),  time:66.422, tt:3786.066\n",
      "Ep:57, loss:0.00005, loss_test:0.09842, lr:8.51e-03, fs:0.70370 (r=0.576,p=0.905),  time:66.403, tt:3851.368\n",
      "Ep:58, loss:0.00005, loss_test:0.09642, lr:8.43e-03, fs:0.71166 (r=0.586,p=0.906),  time:66.369, tt:3915.759\n",
      "Ep:59, loss:0.00005, loss_test:0.10002, lr:8.35e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.370, tt:3982.170\n",
      "Ep:60, loss:0.00005, loss_test:0.09909, lr:8.26e-03, fs:0.71166 (r=0.586,p=0.906),  time:66.369, tt:4048.537\n",
      "Ep:61, loss:0.00005, loss_test:0.09933, lr:8.18e-03, fs:0.69565 (r=0.566,p=0.903),  time:66.385, tt:4115.885\n",
      "Ep:62, loss:0.00005, loss_test:0.09886, lr:8.10e-03, fs:0.70370 (r=0.576,p=0.905),  time:66.379, tt:4181.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00004, loss_test:0.10226, lr:8.02e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.381, tt:4248.380\n",
      "Ep:64, loss:0.00004, loss_test:0.10106, lr:7.94e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.374, tt:4314.308\n",
      "Ep:65, loss:0.00004, loss_test:0.10150, lr:7.86e-03, fs:0.70370 (r=0.576,p=0.905),  time:66.420, tt:4383.722\n",
      "Ep:66, loss:0.00004, loss_test:0.10129, lr:7.78e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.438, tt:4451.368\n",
      "Ep:67, loss:0.00004, loss_test:0.10060, lr:7.70e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.457, tt:4519.067\n",
      "Ep:68, loss:0.00004, loss_test:0.09937, lr:7.62e-03, fs:0.71166 (r=0.586,p=0.906),  time:66.425, tt:4583.322\n",
      "Ep:69, loss:0.00004, loss_test:0.10361, lr:7.55e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.422, tt:4649.517\n",
      "Ep:70, loss:0.00004, loss_test:0.10048, lr:7.47e-03, fs:0.69565 (r=0.566,p=0.903),  time:66.410, tt:4715.134\n",
      "Ep:71, loss:0.00004, loss_test:0.10191, lr:7.40e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.392, tt:4780.230\n",
      "Ep:72, loss:0.00003, loss_test:0.10229, lr:7.32e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.401, tt:4847.296\n",
      "Ep:73, loss:0.00003, loss_test:0.10115, lr:7.25e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.394, tt:4913.127\n",
      "Ep:74, loss:0.00003, loss_test:0.10143, lr:7.18e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.372, tt:4977.884\n",
      "Ep:75, loss:0.00003, loss_test:0.10246, lr:7.11e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.375, tt:5044.471\n",
      "Ep:76, loss:0.00003, loss_test:0.10309, lr:7.03e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.333, tt:5107.646\n",
      "Ep:77, loss:0.00003, loss_test:0.10414, lr:6.96e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.345, tt:5174.929\n",
      "Ep:78, loss:0.00003, loss_test:0.10205, lr:6.89e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.336, tt:5240.514\n",
      "Ep:79, loss:0.00003, loss_test:0.10253, lr:6.83e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.337, tt:5306.934\n",
      "Ep:80, loss:0.00003, loss_test:0.10337, lr:6.76e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.310, tt:5371.130\n",
      "Ep:81, loss:0.00003, loss_test:0.10177, lr:6.69e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.344, tt:5440.173\n",
      "Ep:82, loss:0.00003, loss_test:0.10464, lr:6.62e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.339, tt:5506.176\n",
      "Ep:83, loss:0.00003, loss_test:0.10187, lr:6.56e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.335, tt:5572.162\n",
      "Ep:84, loss:0.00003, loss_test:0.10535, lr:6.49e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.341, tt:5638.980\n",
      "Ep:85, loss:0.00003, loss_test:0.10324, lr:6.43e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.335, tt:5704.819\n",
      "Ep:86, loss:0.00003, loss_test:0.10442, lr:6.36e-03, fs:0.70000 (r=0.566,p=0.918),  time:66.353, tt:5772.742\n",
      "Ep:87, loss:0.00003, loss_test:0.10414, lr:6.30e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.358, tt:5839.533\n",
      "Ep:88, loss:0.00003, loss_test:0.10366, lr:6.24e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.351, tt:5905.196\n",
      "Ep:89, loss:0.00003, loss_test:0.10452, lr:6.17e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.383, tt:5974.514\n",
      "Ep:90, loss:0.00002, loss_test:0.10504, lr:6.11e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.386, tt:6041.120\n",
      "Ep:91, loss:0.00002, loss_test:0.10327, lr:6.05e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.372, tt:6106.243\n",
      "Ep:92, loss:0.00002, loss_test:0.10517, lr:5.99e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.368, tt:6172.186\n",
      "Ep:93, loss:0.00002, loss_test:0.10424, lr:5.93e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.381, tt:6239.817\n",
      "Ep:94, loss:0.00002, loss_test:0.10491, lr:5.87e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.385, tt:6306.584\n",
      "Ep:95, loss:0.00002, loss_test:0.10529, lr:5.81e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.412, tt:6375.581\n",
      "Ep:96, loss:0.00002, loss_test:0.10374, lr:5.75e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.405, tt:6441.314\n",
      "Ep:97, loss:0.00002, loss_test:0.10658, lr:5.70e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.405, tt:6507.688\n",
      "Ep:98, loss:0.00002, loss_test:0.10363, lr:5.64e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.413, tt:6574.923\n",
      "Ep:99, loss:0.00002, loss_test:0.10579, lr:5.58e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.448, tt:6644.758\n",
      "Ep:100, loss:0.00002, loss_test:0.10416, lr:5.53e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.441, tt:6710.562\n",
      "Ep:101, loss:0.00002, loss_test:0.10520, lr:5.47e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.447, tt:6777.642\n",
      "Ep:102, loss:0.00002, loss_test:0.10583, lr:5.42e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.405, tt:6839.674\n",
      "Ep:103, loss:0.00002, loss_test:0.10459, lr:5.36e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.331, tt:6898.432\n",
      "Ep:104, loss:0.00002, loss_test:0.10455, lr:5.31e-03, fs:0.70440 (r=0.566,p=0.933),  time:66.285, tt:6959.967\n",
      "Ep:105, loss:0.00002, loss_test:0.10575, lr:5.26e-03, fs:0.70886 (r=0.566,p=0.949),  time:66.254, tt:7022.929\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14336, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:78.564, tt:78.564\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13923, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:79.523, tt:159.046\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.12881, lr:1.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:79.497, tt:238.490\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.11982, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:80.845, tt:323.380\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.11760, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:80.804, tt:404.021\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00041, loss_test:0.11237, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:81.249, tt:487.492\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00038, loss_test:0.10779, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:81.591, tt:571.136\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00035, loss_test:0.10306, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:81.730, tt:653.837\n",
      "Ep:8, loss:0.00032, loss_test:0.10054, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:81.832, tt:736.484\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.09854, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:82.117, tt:821.169\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.09733, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:82.319, tt:905.514\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.09464, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:82.414, tt:988.969\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.09225, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:82.523, tt:1072.799\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.09236, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:82.582, tt:1156.147\n",
      "Ep:14, loss:0.00020, loss_test:0.09211, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:82.609, tt:1239.134\n",
      "Ep:15, loss:0.00018, loss_test:0.09333, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:82.679, tt:1322.863\n",
      "Ep:16, loss:0.00017, loss_test:0.09522, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:82.644, tt:1404.950\n",
      "Ep:17, loss:0.00016, loss_test:0.08892, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:82.683, tt:1488.293\n",
      "Ep:18, loss:0.00014, loss_test:0.08577, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:82.830, tt:1573.764\n",
      "Ep:19, loss:0.00013, loss_test:0.08569, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:82.853, tt:1657.062\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.08744, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:82.777, tt:1738.319\n",
      "Ep:21, loss:0.00011, loss_test:0.08845, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:82.858, tt:1822.865\n",
      "Ep:22, loss:0.00010, loss_test:0.08739, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:83.066, tt:1910.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00009, loss_test:0.08675, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:83.069, tt:1993.650\n",
      "Ep:24, loss:0.00008, loss_test:0.09639, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:83.159, tt:2078.978\n",
      "Ep:25, loss:0.00008, loss_test:0.10097, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:83.192, tt:2162.997\n",
      "Ep:26, loss:0.00007, loss_test:0.09601, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:83.216, tt:2246.845\n",
      "Ep:27, loss:0.00007, loss_test:0.08703, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:83.224, tt:2330.281\n",
      "Ep:28, loss:0.00006, loss_test:0.08954, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:83.284, tt:2415.237\n",
      "Ep:29, loss:0.00005, loss_test:0.09549, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:83.292, tt:2498.770\n",
      "Ep:30, loss:0.00005, loss_test:0.09520, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:83.335, tt:2583.390\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.09102, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:83.241, tt:2663.708\n",
      "Ep:32, loss:0.00004, loss_test:0.09426, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:83.197, tt:2745.488\n",
      "Ep:33, loss:0.00003, loss_test:0.09286, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:83.209, tt:2829.100\n",
      "Ep:34, loss:0.00003, loss_test:0.09333, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:83.231, tt:2913.087\n",
      "Ep:35, loss:0.00003, loss_test:0.09673, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:83.288, tt:2998.362\n",
      "Ep:36, loss:0.00003, loss_test:0.10295, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:83.337, tt:3083.462\n",
      "Ep:37, loss:0.00002, loss_test:0.09867, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:83.362, tt:3167.760\n",
      "Ep:38, loss:0.00002, loss_test:0.09874, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:83.420, tt:3253.376\n",
      "Ep:39, loss:0.00002, loss_test:0.10113, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:83.461, tt:3338.430\n",
      "Ep:40, loss:0.00002, loss_test:0.09904, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:83.442, tt:3421.122\n",
      "Ep:41, loss:0.00002, loss_test:0.10196, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:83.534, tt:3508.440\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10329, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:83.541, tt:3592.272\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.10621, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:83.511, tt:3674.505\n",
      "Ep:44, loss:0.00001, loss_test:0.10821, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:83.509, tt:3757.892\n",
      "Ep:45, loss:0.00001, loss_test:0.10598, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:83.513, tt:3841.608\n",
      "Ep:46, loss:0.00001, loss_test:0.10771, lr:1.00e-02, fs:0.69620 (r=0.556,p=0.932),  time:83.525, tt:3925.687\n",
      "Ep:47, loss:0.00001, loss_test:0.10874, lr:1.00e-02, fs:0.72956 (r=0.586,p=0.967),  time:83.545, tt:4010.178\n",
      "Ep:48, loss:0.00001, loss_test:0.11236, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:83.535, tt:4093.200\n",
      "Ep:49, loss:0.00001, loss_test:0.10854, lr:1.00e-02, fs:0.66667 (r=0.515,p=0.944),  time:83.566, tt:4178.314\n",
      "Ep:50, loss:0.00001, loss_test:0.11010, lr:1.00e-02, fs:0.66667 (r=0.515,p=0.944),  time:83.567, tt:4261.918\n",
      "Ep:51, loss:0.00001, loss_test:0.11330, lr:1.00e-02, fs:0.64430 (r=0.485,p=0.960),  time:83.578, tt:4346.081\n",
      "Ep:52, loss:0.00001, loss_test:0.11125, lr:1.00e-02, fs:0.63514 (r=0.475,p=0.959),  time:83.556, tt:4428.452\n",
      "Ep:53, loss:0.00001, loss_test:0.11367, lr:1.00e-02, fs:0.66225 (r=0.505,p=0.962),  time:83.585, tt:4513.566\n",
      "Ep:54, loss:0.00001, loss_test:0.11052, lr:9.90e-03, fs:0.64901 (r=0.495,p=0.942),  time:83.593, tt:4597.601\n",
      "Ep:55, loss:0.00000, loss_test:0.11386, lr:9.80e-03, fs:0.63514 (r=0.475,p=0.959),  time:83.569, tt:4679.865\n",
      "Ep:56, loss:0.00000, loss_test:0.11038, lr:9.70e-03, fs:0.63514 (r=0.475,p=0.959),  time:83.549, tt:4762.308\n",
      "Ep:57, loss:0.00000, loss_test:0.11192, lr:9.61e-03, fs:0.64901 (r=0.495,p=0.942),  time:83.524, tt:4844.406\n",
      "Ep:58, loss:0.00000, loss_test:0.11066, lr:9.51e-03, fs:0.65333 (r=0.495,p=0.961),  time:83.517, tt:4927.499\n",
      "Ep:59, loss:0.00000, loss_test:0.11019, lr:9.41e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.506, tt:5010.341\n",
      "Ep:60, loss:0.00000, loss_test:0.11180, lr:9.32e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.492, tt:5093.034\n",
      "Ep:61, loss:0.00000, loss_test:0.11333, lr:9.23e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.453, tt:5174.097\n",
      "Ep:62, loss:0.00000, loss_test:0.11210, lr:9.14e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.428, tt:5255.988\n",
      "Ep:63, loss:0.00000, loss_test:0.11206, lr:9.04e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.414, tt:5338.519\n",
      "Ep:64, loss:0.00000, loss_test:0.11035, lr:8.95e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.391, tt:5420.433\n",
      "Ep:65, loss:0.00000, loss_test:0.11332, lr:8.86e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.379, tt:5503.001\n",
      "Ep:66, loss:0.00000, loss_test:0.11144, lr:8.78e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.393, tt:5587.312\n",
      "Ep:67, loss:0.00000, loss_test:0.11244, lr:8.69e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.432, tt:5673.392\n",
      "Ep:68, loss:0.00000, loss_test:0.10983, lr:8.60e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.428, tt:5756.498\n",
      "Ep:69, loss:0.00000, loss_test:0.11107, lr:8.51e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.429, tt:5840.025\n",
      "Ep:70, loss:0.00000, loss_test:0.11297, lr:8.43e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.444, tt:5924.510\n",
      "Ep:71, loss:0.00000, loss_test:0.11019, lr:8.35e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.448, tt:6008.261\n",
      "Ep:72, loss:0.00000, loss_test:0.11255, lr:8.26e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.430, tt:6090.376\n",
      "Ep:73, loss:0.00000, loss_test:0.11022, lr:8.18e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.462, tt:6176.186\n",
      "Ep:74, loss:0.00000, loss_test:0.11317, lr:8.10e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.473, tt:6260.506\n",
      "Ep:75, loss:0.00000, loss_test:0.10994, lr:8.02e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.469, tt:6343.636\n",
      "Ep:76, loss:0.00000, loss_test:0.11109, lr:7.94e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.477, tt:6427.760\n",
      "Ep:77, loss:0.00000, loss_test:0.10942, lr:7.86e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.514, tt:6514.107\n",
      "Ep:78, loss:0.00000, loss_test:0.11272, lr:7.78e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.465, tt:6593.737\n",
      "Ep:79, loss:0.00000, loss_test:0.10947, lr:7.70e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.475, tt:6677.999\n",
      "Ep:80, loss:0.00000, loss_test:0.11025, lr:7.62e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.467, tt:6760.810\n",
      "Ep:81, loss:0.00000, loss_test:0.11064, lr:7.55e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.466, tt:6844.221\n",
      "Ep:82, loss:0.00000, loss_test:0.11205, lr:7.47e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.478, tt:6928.637\n",
      "Ep:83, loss:0.00000, loss_test:0.11114, lr:7.40e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.462, tt:7010.829\n",
      "Ep:84, loss:0.00000, loss_test:0.11001, lr:7.32e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.477, tt:7095.508\n",
      "Ep:85, loss:0.00000, loss_test:0.10933, lr:7.25e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.479, tt:7179.220\n",
      "Ep:86, loss:0.00000, loss_test:0.11028, lr:7.18e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.533, tt:7267.380\n",
      "Ep:87, loss:0.00000, loss_test:0.11022, lr:7.11e-03, fs:0.63087 (r=0.475,p=0.940),  time:83.540, tt:7351.511\n",
      "Ep:88, loss:0.00000, loss_test:0.11052, lr:7.03e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.525, tt:7433.690\n",
      "Ep:89, loss:0.00000, loss_test:0.10983, lr:6.96e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.521, tt:7516.901\n",
      "Ep:90, loss:0.00000, loss_test:0.10855, lr:6.89e-03, fs:0.68387 (r=0.535,p=0.946),  time:83.500, tt:7598.544\n",
      "Ep:91, loss:0.00000, loss_test:0.11011, lr:6.83e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.504, tt:7682.374\n",
      "Ep:92, loss:0.00000, loss_test:0.10953, lr:6.76e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.498, tt:7765.359\n",
      "Ep:93, loss:0.00000, loss_test:0.11045, lr:6.69e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.497, tt:7848.742\n",
      "Ep:94, loss:0.00000, loss_test:0.10875, lr:6.62e-03, fs:0.68387 (r=0.535,p=0.946),  time:83.499, tt:7932.376\n",
      "Ep:95, loss:0.00000, loss_test:0.10982, lr:6.56e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.490, tt:8015.008\n",
      "Ep:96, loss:0.00000, loss_test:0.11092, lr:6.49e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.464, tt:8096.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00000, loss_test:0.10976, lr:6.43e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.446, tt:8177.714\n",
      "Ep:98, loss:0.00000, loss_test:0.11088, lr:6.36e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.472, tt:8263.730\n",
      "Ep:99, loss:0.00000, loss_test:0.10885, lr:6.30e-03, fs:0.62162 (r=0.465,p=0.939),  time:83.471, tt:8347.111\n",
      "Ep:100, loss:0.00000, loss_test:0.10936, lr:6.24e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.470, tt:8430.440\n",
      "Ep:101, loss:0.00000, loss_test:0.10856, lr:6.17e-03, fs:0.69231 (r=0.545,p=0.947),  time:83.422, tt:8509.095\n",
      "Ep:102, loss:0.00000, loss_test:0.10991, lr:6.11e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.419, tt:8592.117\n",
      "Ep:103, loss:0.00000, loss_test:0.10874, lr:6.05e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.370, tt:8670.513\n",
      "Ep:104, loss:0.00000, loss_test:0.11006, lr:5.99e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.291, tt:8745.527\n",
      "Ep:105, loss:0.00000, loss_test:0.11260, lr:5.93e-03, fs:0.62585 (r=0.465,p=0.958),  time:83.252, tt:8824.691\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00053, loss_test:0.13196, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:73.715, tt:73.715\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00050, loss_test:0.12249, lr:1.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:73.591, tt:147.182\n",
      "Ep:2, loss:0.00048, loss_test:0.11988, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:74.563, tt:223.688\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.11417, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:74.324, tt:297.297\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00043, loss_test:0.10996, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:74.261, tt:371.306\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00041, loss_test:0.10814, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:74.563, tt:447.377\n",
      "Ep:6, loss:0.00039, loss_test:0.10380, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:74.732, tt:523.121\n",
      "Ep:7, loss:0.00037, loss_test:0.10097, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:74.773, tt:598.187\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00035, loss_test:0.09699, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:74.621, tt:671.593\n",
      "Ep:9, loss:0.00034, loss_test:0.09622, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:74.869, tt:748.688\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.09204, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:74.815, tt:822.960\n",
      "Ep:11, loss:0.00030, loss_test:0.09100, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:75.046, tt:900.555\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00028, loss_test:0.08889, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:75.212, tt:977.755\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00027, loss_test:0.08700, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:75.244, tt:1053.418\n",
      "Ep:14, loss:0.00025, loss_test:0.08418, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:75.279, tt:1129.182\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.08392, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:75.326, tt:1205.212\n",
      "Ep:16, loss:0.00022, loss_test:0.08258, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:75.287, tt:1279.887\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.08223, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:75.148, tt:1352.667\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.07963, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:75.029, tt:1425.558\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.07974, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:74.948, tt:1498.958\n",
      "Ep:20, loss:0.00016, loss_test:0.07819, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:74.987, tt:1574.717\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.07861, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:74.920, tt:1648.242\n",
      "Ep:22, loss:0.00015, loss_test:0.07741, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:74.863, tt:1721.841\n",
      "Ep:23, loss:0.00014, loss_test:0.07564, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:74.828, tt:1795.865\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.07865, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:74.796, tt:1869.895\n",
      "Ep:25, loss:0.00013, loss_test:0.08292, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:74.798, tt:1944.743\n",
      "Ep:26, loss:0.00012, loss_test:0.08018, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:74.714, tt:2017.267\n",
      "Ep:27, loss:0.00012, loss_test:0.07797, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:74.664, tt:2090.594\n",
      "Ep:28, loss:0.00011, loss_test:0.07594, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:74.665, tt:2165.281\n",
      "Ep:29, loss:0.00010, loss_test:0.07782, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:74.663, tt:2239.889\n",
      "Ep:30, loss:0.00010, loss_test:0.08186, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:74.638, tt:2313.783\n",
      "Ep:31, loss:0.00009, loss_test:0.07927, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:74.602, tt:2387.252\n",
      "Ep:32, loss:0.00009, loss_test:0.07420, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:74.566, tt:2460.683\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.07517, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:74.599, tt:2536.370\n",
      "Ep:34, loss:0.00008, loss_test:0.08419, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:74.561, tt:2609.635\n",
      "Ep:35, loss:0.00007, loss_test:0.08071, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:74.577, tt:2684.770\n",
      "Ep:36, loss:0.00007, loss_test:0.07796, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:74.591, tt:2759.853\n",
      "Ep:37, loss:0.00006, loss_test:0.07736, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:74.633, tt:2836.051\n",
      "Ep:38, loss:0.00006, loss_test:0.08201, lr:1.00e-02, fs:0.72832 (r=0.636,p=0.851),  time:74.635, tt:2910.763\n",
      "Ep:39, loss:0.00006, loss_test:0.08444, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:74.636, tt:2985.460\n",
      "Ep:40, loss:0.00006, loss_test:0.08141, lr:1.00e-02, fs:0.72619 (r=0.616,p=0.884),  time:74.633, tt:3059.967\n",
      "Ep:41, loss:0.00006, loss_test:0.08554, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:74.640, tt:3134.882\n",
      "Ep:42, loss:0.00006, loss_test:0.07994, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:74.640, tt:3209.537\n",
      "Ep:43, loss:0.00005, loss_test:0.08422, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:74.638, tt:3284.075\n",
      "Ep:44, loss:0.00005, loss_test:0.08836, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.719, tt:3362.358\n",
      "Ep:45, loss:0.00005, loss_test:0.08379, lr:9.80e-03, fs:0.73054 (r=0.616,p=0.897),  time:74.764, tt:3439.137\n",
      "Ep:46, loss:0.00004, loss_test:0.08068, lr:9.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:74.793, tt:3515.248\n",
      "Ep:47, loss:0.00004, loss_test:0.09051, lr:9.61e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.772, tt:3589.059\n",
      "Ep:48, loss:0.00004, loss_test:0.08926, lr:9.51e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.774, tt:3663.924\n",
      "Ep:49, loss:0.00004, loss_test:0.08408, lr:9.41e-03, fs:0.73054 (r=0.616,p=0.897),  time:74.790, tt:3739.477\n",
      "Ep:50, loss:0.00004, loss_test:0.09036, lr:9.32e-03, fs:0.73939 (r=0.616,p=0.924),  time:74.807, tt:3815.180\n",
      "Ep:51, loss:0.00004, loss_test:0.09117, lr:9.23e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.818, tt:3890.559\n",
      "Ep:52, loss:0.00004, loss_test:0.09446, lr:9.14e-03, fs:0.74699 (r=0.626,p=0.925),  time:74.877, tt:3968.503\n",
      "Ep:53, loss:0.00003, loss_test:0.08912, lr:9.04e-03, fs:0.74556 (r=0.636,p=0.900),  time:74.911, tt:4045.182\n",
      "Ep:54, loss:0.00003, loss_test:0.08693, lr:8.95e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.939, tt:4121.645\n",
      "Ep:55, loss:0.00003, loss_test:0.09427, lr:8.86e-03, fs:0.73939 (r=0.616,p=0.924),  time:74.898, tt:4194.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00003, loss_test:0.09246, lr:8.78e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.909, tt:4269.794\n",
      "Ep:57, loss:0.00003, loss_test:0.09215, lr:8.69e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.894, tt:4343.829\n",
      "Ep:58, loss:0.00003, loss_test:0.08948, lr:8.60e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.898, tt:4418.985\n",
      "Ep:59, loss:0.00003, loss_test:0.09049, lr:8.51e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.905, tt:4494.289\n",
      "Ep:60, loss:0.00002, loss_test:0.09367, lr:8.43e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.903, tt:4569.113\n",
      "Ep:61, loss:0.00002, loss_test:0.09003, lr:8.35e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.949, tt:4646.844\n",
      "Ep:62, loss:0.00002, loss_test:0.09522, lr:8.26e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.944, tt:4721.500\n",
      "Ep:63, loss:0.00002, loss_test:0.09356, lr:8.18e-03, fs:0.72727 (r=0.606,p=0.909),  time:74.978, tt:4798.572\n",
      "Ep:64, loss:0.00002, loss_test:0.09085, lr:8.10e-03, fs:0.73054 (r=0.616,p=0.897),  time:75.005, tt:4875.347\n",
      "Ep:65, loss:0.00002, loss_test:0.09395, lr:8.02e-03, fs:0.71515 (r=0.596,p=0.894),  time:75.033, tt:4952.190\n",
      "Ep:66, loss:0.00002, loss_test:0.09212, lr:7.94e-03, fs:0.73494 (r=0.616,p=0.910),  time:75.037, tt:5027.507\n",
      "Ep:67, loss:0.00002, loss_test:0.09557, lr:7.86e-03, fs:0.73494 (r=0.616,p=0.910),  time:75.041, tt:5102.756\n",
      "Ep:68, loss:0.00002, loss_test:0.09348, lr:7.78e-03, fs:0.73494 (r=0.616,p=0.910),  time:75.066, tt:5179.559\n",
      "Ep:69, loss:0.00002, loss_test:0.09153, lr:7.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:75.057, tt:5254.017\n",
      "Ep:70, loss:0.00002, loss_test:0.09564, lr:7.62e-03, fs:0.73494 (r=0.616,p=0.910),  time:75.058, tt:5329.108\n",
      "Ep:71, loss:0.00002, loss_test:0.09150, lr:7.55e-03, fs:0.75740 (r=0.646,p=0.914),  time:75.027, tt:5401.955\n",
      "Ep:72, loss:0.00002, loss_test:0.09408, lr:7.47e-03, fs:0.74556 (r=0.636,p=0.900),  time:75.019, tt:5476.394\n",
      "Ep:73, loss:0.00002, loss_test:0.09408, lr:7.40e-03, fs:0.72289 (r=0.606,p=0.896),  time:75.017, tt:5551.266\n",
      "Ep:74, loss:0.00002, loss_test:0.09326, lr:7.32e-03, fs:0.72727 (r=0.606,p=0.909),  time:74.990, tt:5624.265\n",
      "Ep:75, loss:0.00002, loss_test:0.09307, lr:7.25e-03, fs:0.74251 (r=0.626,p=0.912),  time:74.991, tt:5699.300\n",
      "Ep:76, loss:0.00002, loss_test:0.09278, lr:7.18e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.991, tt:5774.305\n",
      "Ep:77, loss:0.00002, loss_test:0.09609, lr:7.11e-03, fs:0.73494 (r=0.616,p=0.910),  time:74.991, tt:5849.284\n",
      "Ep:78, loss:0.00001, loss_test:0.09467, lr:7.03e-03, fs:0.74556 (r=0.636,p=0.900),  time:74.975, tt:5922.999\n",
      "Ep:79, loss:0.00001, loss_test:0.09525, lr:6.96e-03, fs:0.72727 (r=0.606,p=0.909),  time:74.931, tt:5994.495\n",
      "Ep:80, loss:0.00001, loss_test:0.09556, lr:6.89e-03, fs:0.72727 (r=0.606,p=0.909),  time:74.937, tt:6069.886\n",
      "Ep:81, loss:0.00001, loss_test:0.09603, lr:6.83e-03, fs:0.72393 (r=0.596,p=0.922),  time:74.932, tt:6144.397\n",
      "Ep:82, loss:0.00001, loss_test:0.09507, lr:6.76e-03, fs:0.74251 (r=0.626,p=0.912),  time:74.933, tt:6219.465\n",
      "Ep:83, loss:0.00001, loss_test:0.09308, lr:6.69e-03, fs:0.75449 (r=0.636,p=0.926),  time:74.944, tt:6295.317\n",
      "Ep:84, loss:0.00001, loss_test:0.09479, lr:6.62e-03, fs:0.71166 (r=0.586,p=0.906),  time:74.937, tt:6369.672\n",
      "Ep:85, loss:0.00001, loss_test:0.09577, lr:6.56e-03, fs:0.74699 (r=0.626,p=0.925),  time:74.940, tt:6444.806\n",
      "Ep:86, loss:0.00001, loss_test:0.09500, lr:6.49e-03, fs:0.75449 (r=0.636,p=0.926),  time:75.006, tt:6525.549\n",
      "Ep:87, loss:0.00001, loss_test:0.09569, lr:6.43e-03, fs:0.75000 (r=0.636,p=0.913),  time:75.001, tt:6600.120\n",
      "Ep:88, loss:0.00001, loss_test:0.09755, lr:6.36e-03, fs:0.75449 (r=0.636,p=0.926),  time:75.004, tt:6675.332\n",
      "Ep:89, loss:0.00001, loss_test:0.09748, lr:6.30e-03, fs:0.75152 (r=0.626,p=0.939),  time:75.018, tt:6751.662\n",
      "Ep:90, loss:0.00001, loss_test:0.09517, lr:6.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:75.021, tt:6826.901\n",
      "Ep:91, loss:0.00001, loss_test:0.09552, lr:6.17e-03, fs:0.73750 (r=0.596,p=0.967),  time:75.024, tt:6902.233\n",
      "Ep:92, loss:0.00001, loss_test:0.09577, lr:6.11e-03, fs:0.73750 (r=0.596,p=0.967),  time:75.020, tt:6976.839\n",
      "Ep:93, loss:0.00001, loss_test:0.09634, lr:6.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:75.014, tt:7051.357\n",
      "Ep:94, loss:0.00001, loss_test:0.09637, lr:5.99e-03, fs:0.76364 (r=0.636,p=0.955),  time:75.033, tt:7128.137\n",
      "Ep:95, loss:0.00001, loss_test:0.09539, lr:5.93e-03, fs:0.75904 (r=0.636,p=0.940),  time:75.046, tt:7204.435\n",
      "Ep:96, loss:0.00001, loss_test:0.09742, lr:5.87e-03, fs:0.76364 (r=0.636,p=0.955),  time:75.044, tt:7279.306\n",
      "Ep:97, loss:0.00001, loss_test:0.09506, lr:5.81e-03, fs:0.76543 (r=0.626,p=0.984),  time:75.055, tt:7355.370\n",
      "Ep:98, loss:0.00001, loss_test:0.09619, lr:5.75e-03, fs:0.75776 (r=0.616,p=0.984),  time:75.044, tt:7429.377\n",
      "Ep:99, loss:0.00001, loss_test:0.09565, lr:5.70e-03, fs:0.77301 (r=0.636,p=0.984),  time:75.029, tt:7502.924\n",
      "Ep:100, loss:0.00001, loss_test:0.09600, lr:5.64e-03, fs:0.75776 (r=0.616,p=0.984),  time:75.025, tt:7577.567\n",
      "Ep:101, loss:0.00001, loss_test:0.09721, lr:5.58e-03, fs:0.76543 (r=0.626,p=0.984),  time:74.948, tt:7644.731\n",
      "Ep:102, loss:0.00001, loss_test:0.09677, lr:5.53e-03, fs:0.77301 (r=0.636,p=0.984),  time:74.776, tt:7701.882\n",
      "Ep:103, loss:0.00001, loss_test:0.09788, lr:5.47e-03, fs:0.76364 (r=0.636,p=0.955),  time:74.368, tt:7734.261\n",
      "Ep:104, loss:0.00001, loss_test:0.09851, lr:5.42e-03, fs:0.76364 (r=0.636,p=0.955),  time:73.886, tt:7758.072\n",
      "Ep:105, loss:0.00001, loss_test:0.09675, lr:5.36e-03, fs:0.77301 (r=0.636,p=0.984),  time:73.391, tt:7779.496\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"8-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.03063, lr:6.00e-02, fs:0.62009 (r=0.717,p=0.546),  time:29.822, tt:29.822\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02679, lr:6.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:31.844, tt:63.687\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02878, lr:6.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:32.517, tt:97.552\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02933, lr:6.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:33.019, tt:132.078\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02921, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:33.147, tt:165.735\n",
      "Ep:5, loss:0.00005, loss_test:0.02909, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:33.094, tt:198.563\n",
      "Ep:6, loss:0.00005, loss_test:0.02911, lr:6.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:33.297, tt:233.078\n",
      "Ep:7, loss:0.00005, loss_test:0.02964, lr:6.00e-02, fs:0.63602 (r=0.838,p=0.512),  time:33.568, tt:268.547\n",
      "Ep:8, loss:0.00005, loss_test:0.03072, lr:6.00e-02, fs:0.61660 (r=0.788,p=0.506),  time:33.651, tt:302.861\n",
      "Ep:9, loss:0.00005, loss_test:0.03148, lr:6.00e-02, fs:0.62857 (r=0.778,p=0.527),  time:33.748, tt:337.484\n",
      "Ep:10, loss:0.00005, loss_test:0.03085, lr:6.00e-02, fs:0.62602 (r=0.778,p=0.524),  time:33.739, tt:371.132\n",
      "Ep:11, loss:0.00005, loss_test:0.02953, lr:6.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:33.781, tt:405.374\n",
      "Ep:12, loss:0.00005, loss_test:0.02846, lr:6.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:33.808, tt:439.506\n",
      "Ep:13, loss:0.00005, loss_test:0.02780, lr:6.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:33.832, tt:473.654\n",
      "Ep:14, loss:0.00005, loss_test:0.02735, lr:6.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:33.909, tt:508.638\n",
      "Ep:15, loss:0.00005, loss_test:0.02711, lr:5.94e-02, fs:0.64032 (r=0.818,p=0.526),  time:33.999, tt:543.982\n",
      "Ep:16, loss:0.00005, loss_test:0.02709, lr:5.88e-02, fs:0.62097 (r=0.778,p=0.517),  time:34.004, tt:578.075\n",
      "Ep:17, loss:0.00004, loss_test:0.02693, lr:5.82e-02, fs:0.62241 (r=0.758,p=0.528),  time:34.036, tt:612.642\n",
      "Ep:18, loss:0.00004, loss_test:0.02636, lr:5.76e-02, fs:0.60759 (r=0.727,p=0.522),  time:34.015, tt:646.289\n",
      "Ep:19, loss:0.00004, loss_test:0.02576, lr:5.71e-02, fs:0.60684 (r=0.717,p=0.526),  time:33.996, tt:679.925\n",
      "Ep:20, loss:0.00004, loss_test:0.02544, lr:5.65e-02, fs:0.61207 (r=0.717,p=0.534),  time:33.969, tt:713.345\n",
      "Ep:21, loss:0.00004, loss_test:0.02536, lr:5.59e-02, fs:0.62009 (r=0.717,p=0.546),  time:34.059, tt:749.304\n",
      "Ep:22, loss:0.00004, loss_test:0.02541, lr:5.54e-02, fs:0.62780 (r=0.707,p=0.565),  time:34.106, tt:784.439\n",
      "Ep:23, loss:0.00004, loss_test:0.02538, lr:5.48e-02, fs:0.63063 (r=0.707,p=0.569),  time:34.102, tt:818.440\n",
      "Ep:24, loss:0.00004, loss_test:0.02515, lr:5.43e-02, fs:0.63348 (r=0.707,p=0.574),  time:34.144, tt:853.589\n",
      "Ep:25, loss:0.00004, loss_test:0.02482, lr:5.37e-02, fs:0.63677 (r=0.717,p=0.573),  time:34.148, tt:887.852\n",
      "Ep:26, loss:0.00004, loss_test:0.02448, lr:5.32e-02, fs:0.63677 (r=0.717,p=0.573),  time:34.175, tt:922.722\n",
      "Ep:27, loss:0.00004, loss_test:0.02413, lr:5.27e-02, fs:0.63677 (r=0.717,p=0.573),  time:34.209, tt:957.858\n",
      "Ep:28, loss:0.00004, loss_test:0.02388, lr:5.21e-02, fs:0.63677 (r=0.717,p=0.573),  time:34.245, tt:993.102\n",
      "Ep:29, loss:0.00004, loss_test:0.02360, lr:5.16e-02, fs:0.63393 (r=0.717,p=0.568),  time:34.274, tt:1028.232\n",
      "Ep:30, loss:0.00004, loss_test:0.02350, lr:5.11e-02, fs:0.63393 (r=0.717,p=0.568),  time:34.284, tt:1062.796\n",
      "Ep:31, loss:0.00004, loss_test:0.02338, lr:5.06e-02, fs:0.63063 (r=0.707,p=0.569),  time:34.298, tt:1097.547\n",
      "Ep:32, loss:0.00004, loss_test:0.02320, lr:5.01e-02, fs:0.63063 (r=0.707,p=0.569),  time:34.289, tt:1131.550\n",
      "Ep:33, loss:0.00004, loss_test:0.02291, lr:4.96e-02, fs:0.63063 (r=0.707,p=0.569),  time:34.294, tt:1166.004\n",
      "Ep:34, loss:0.00004, loss_test:0.02250, lr:4.91e-02, fs:0.63677 (r=0.717,p=0.573),  time:34.323, tt:1201.289\n",
      "Ep:35, loss:0.00003, loss_test:0.02225, lr:4.86e-02, fs:0.64253 (r=0.717,p=0.582),  time:34.335, tt:1236.066\n",
      "Ep:36, loss:0.00003, loss_test:0.02201, lr:4.81e-02, fs:0.64253 (r=0.717,p=0.582),  time:34.330, tt:1270.218\n",
      "Ep:37, loss:0.00003, loss_test:0.02181, lr:4.76e-02, fs:0.64253 (r=0.717,p=0.582),  time:34.295, tt:1303.196\n",
      "Ep:38, loss:0.00003, loss_test:0.02166, lr:4.71e-02, fs:0.63927 (r=0.707,p=0.583),  time:34.273, tt:1336.664\n",
      "Ep:39, loss:0.00003, loss_test:0.02146, lr:4.67e-02, fs:0.64220 (r=0.707,p=0.588),  time:34.230, tt:1369.220\n",
      "Ep:40, loss:0.00003, loss_test:0.02116, lr:4.62e-02, fs:0.65753 (r=0.727,p=0.600),  time:34.188, tt:1401.704\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.02086, lr:4.62e-02, fs:0.66063 (r=0.737,p=0.598),  time:34.124, tt:1433.192\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.02065, lr:4.62e-02, fs:0.66364 (r=0.737,p=0.603),  time:34.077, tt:1465.308\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.02039, lr:4.62e-02, fs:0.66063 (r=0.737,p=0.598),  time:34.079, tt:1499.457\n",
      "Ep:44, loss:0.00003, loss_test:0.02020, lr:4.62e-02, fs:0.66667 (r=0.747,p=0.602),  time:34.063, tt:1532.854\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01995, lr:4.62e-02, fs:0.67265 (r=0.758,p=0.605),  time:34.088, tt:1568.068\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01971, lr:4.62e-02, fs:0.69604 (r=0.798,p=0.617),  time:34.071, tt:1601.336\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01954, lr:4.62e-02, fs:0.71111 (r=0.808,p=0.635),  time:34.051, tt:1634.456\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01942, lr:4.62e-02, fs:0.70536 (r=0.798,p=0.632),  time:34.031, tt:1667.518\n",
      "Ep:49, loss:0.00003, loss_test:0.01931, lr:4.62e-02, fs:0.71171 (r=0.798,p=0.642),  time:34.021, tt:1701.050\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01900, lr:4.62e-02, fs:0.71429 (r=0.808,p=0.640),  time:33.999, tt:1733.974\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00003, loss_test:0.01887, lr:4.62e-02, fs:0.72566 (r=0.828,p=0.646),  time:33.973, tt:1766.590\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.01884, lr:4.62e-02, fs:0.72973 (r=0.818,p=0.659),  time:33.976, tt:1800.753\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01872, lr:4.62e-02, fs:0.73543 (r=0.828,p=0.661),  time:33.948, tt:1833.216\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.01864, lr:4.62e-02, fs:0.73214 (r=0.828,p=0.656),  time:33.931, tt:1866.202\n",
      "Ep:55, loss:0.00003, loss_test:0.01857, lr:4.62e-02, fs:0.74439 (r=0.838,p=0.669),  time:33.905, tt:1898.661\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01846, lr:4.62e-02, fs:0.73636 (r=0.818,p=0.669),  time:33.925, tt:1933.734\n",
      "Ep:57, loss:0.00002, loss_test:0.01835, lr:4.62e-02, fs:0.70698 (r=0.768,p=0.655),  time:33.899, tt:1966.115\n",
      "Ep:58, loss:0.00002, loss_test:0.01816, lr:4.62e-02, fs:0.69767 (r=0.758,p=0.647),  time:33.873, tt:1998.489\n",
      "Ep:59, loss:0.00002, loss_test:0.01806, lr:4.62e-02, fs:0.70093 (r=0.758,p=0.652),  time:33.860, tt:2031.577\n",
      "Ep:60, loss:0.00002, loss_test:0.01808, lr:4.62e-02, fs:0.69194 (r=0.737,p=0.652),  time:33.826, tt:2063.404\n",
      "Ep:61, loss:0.00002, loss_test:0.01797, lr:4.62e-02, fs:0.70142 (r=0.747,p=0.661),  time:33.833, tt:2097.626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00002, loss_test:0.01804, lr:4.62e-02, fs:0.69856 (r=0.737,p=0.664),  time:33.830, tt:2131.271\n",
      "Ep:63, loss:0.00002, loss_test:0.01812, lr:4.62e-02, fs:0.70244 (r=0.727,p=0.679),  time:33.814, tt:2164.100\n",
      "Ep:64, loss:0.00002, loss_test:0.01803, lr:4.62e-02, fs:0.71220 (r=0.737,p=0.689),  time:33.805, tt:2197.338\n",
      "Ep:65, loss:0.00002, loss_test:0.01810, lr:4.62e-02, fs:0.70588 (r=0.727,p=0.686),  time:33.801, tt:2230.869\n",
      "Ep:66, loss:0.00002, loss_test:0.01808, lr:4.62e-02, fs:0.70936 (r=0.727,p=0.692),  time:33.791, tt:2263.973\n",
      "Ep:67, loss:0.00002, loss_test:0.01794, lr:4.57e-02, fs:0.70936 (r=0.727,p=0.692),  time:33.771, tt:2296.439\n",
      "Ep:68, loss:0.00002, loss_test:0.01816, lr:4.53e-02, fs:0.71642 (r=0.727,p=0.706),  time:33.782, tt:2330.963\n",
      "Ep:69, loss:0.00002, loss_test:0.01821, lr:4.48e-02, fs:0.71357 (r=0.717,p=0.710),  time:33.785, tt:2364.919\n",
      "Ep:70, loss:0.00002, loss_test:0.01791, lr:4.44e-02, fs:0.71642 (r=0.727,p=0.706),  time:33.781, tt:2398.427\n",
      "Ep:71, loss:0.00002, loss_test:0.01819, lr:4.39e-02, fs:0.72081 (r=0.717,p=0.724),  time:33.813, tt:2434.504\n",
      "Ep:72, loss:0.00002, loss_test:0.01842, lr:4.35e-02, fs:0.72449 (r=0.717,p=0.732),  time:33.814, tt:2468.388\n",
      "Ep:73, loss:0.00002, loss_test:0.01823, lr:4.31e-02, fs:0.72081 (r=0.717,p=0.724),  time:33.796, tt:2500.905\n",
      "Ep:74, loss:0.00002, loss_test:0.01837, lr:4.26e-02, fs:0.72449 (r=0.717,p=0.732),  time:33.801, tt:2535.061\n",
      "Ep:75, loss:0.00002, loss_test:0.01894, lr:4.22e-02, fs:0.70103 (r=0.687,p=0.716),  time:33.813, tt:2569.787\n",
      "Ep:76, loss:0.00002, loss_test:0.01810, lr:4.18e-02, fs:0.72727 (r=0.727,p=0.727),  time:33.803, tt:2602.837\n",
      "Ep:77, loss:0.00001, loss_test:0.01879, lr:4.14e-02, fs:0.71134 (r=0.697,p=0.726),  time:33.816, tt:2637.646\n",
      "Ep:78, loss:0.00001, loss_test:0.01823, lr:4.10e-02, fs:0.72449 (r=0.717,p=0.732),  time:33.826, tt:2672.226\n",
      "Ep:79, loss:0.00001, loss_test:0.01919, lr:4.05e-02, fs:0.70833 (r=0.687,p=0.731),  time:33.852, tt:2708.150\n",
      "Ep:80, loss:0.00001, loss_test:0.01854, lr:4.01e-02, fs:0.71795 (r=0.707,p=0.729),  time:33.849, tt:2741.748\n",
      "Ep:81, loss:0.00001, loss_test:0.01926, lr:3.97e-02, fs:0.71503 (r=0.697,p=0.734),  time:33.872, tt:2777.520\n",
      "Ep:82, loss:0.00001, loss_test:0.01881, lr:3.93e-02, fs:0.72251 (r=0.697,p=0.750),  time:33.883, tt:2812.282\n",
      "Ep:83, loss:0.00001, loss_test:0.01911, lr:3.89e-02, fs:0.72632 (r=0.697,p=0.758),  time:33.917, tt:2849.058\n",
      "Ep:84, loss:0.00001, loss_test:0.01917, lr:3.86e-02, fs:0.72727 (r=0.687,p=0.773),  time:33.936, tt:2884.546\n",
      "Ep:85, loss:0.00001, loss_test:0.01928, lr:3.82e-02, fs:0.72727 (r=0.687,p=0.773),  time:33.940, tt:2918.799\n",
      "Ep:86, loss:0.00001, loss_test:0.01989, lr:3.78e-02, fs:0.73118 (r=0.687,p=0.782),  time:33.952, tt:2953.828\n",
      "Ep:87, loss:0.00001, loss_test:0.01931, lr:3.74e-02, fs:0.72340 (r=0.687,p=0.764),  time:33.949, tt:2987.519\n",
      "Ep:88, loss:0.00001, loss_test:0.02083, lr:3.70e-02, fs:0.72131 (r=0.667,p=0.786),  time:33.956, tt:3022.044\n",
      "Ep:89, loss:0.00001, loss_test:0.01949, lr:3.67e-02, fs:0.72727 (r=0.687,p=0.773),  time:33.961, tt:3056.500\n",
      "Ep:90, loss:0.00001, loss_test:0.02023, lr:3.63e-02, fs:0.73118 (r=0.687,p=0.782),  time:33.971, tt:3091.348\n",
      "Ep:91, loss:0.00001, loss_test:0.02020, lr:3.59e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.001, tt:3128.118\n",
      "Ep:92, loss:0.00001, loss_test:0.01976, lr:3.56e-02, fs:0.73797 (r=0.697,p=0.784),  time:34.025, tt:3164.304\n",
      "Ep:93, loss:0.00001, loss_test:0.02086, lr:3.52e-02, fs:0.73913 (r=0.687,p=0.800),  time:34.032, tt:3198.979\n",
      "Ep:94, loss:0.00001, loss_test:0.01996, lr:3.49e-02, fs:0.73797 (r=0.697,p=0.784),  time:34.048, tt:3234.569\n",
      "Ep:95, loss:0.00001, loss_test:0.02110, lr:3.45e-02, fs:0.73913 (r=0.687,p=0.800),  time:34.049, tt:3268.674\n",
      "Ep:96, loss:0.00001, loss_test:0.02058, lr:3.42e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.051, tt:3302.902\n",
      "Ep:97, loss:0.00001, loss_test:0.02066, lr:3.38e-02, fs:0.73797 (r=0.697,p=0.784),  time:34.051, tt:3336.955\n",
      "Ep:98, loss:0.00001, loss_test:0.02128, lr:3.35e-02, fs:0.74725 (r=0.687,p=0.819),  time:34.066, tt:3372.496\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.02103, lr:3.35e-02, fs:0.73514 (r=0.687,p=0.791),  time:34.080, tt:3407.969\n",
      "Ep:100, loss:0.00001, loss_test:0.02158, lr:3.35e-02, fs:0.73913 (r=0.687,p=0.800),  time:34.095, tt:3443.588\n",
      "Ep:101, loss:0.00001, loss_test:0.02206, lr:3.35e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.111, tt:3479.313\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.02137, lr:3.35e-02, fs:0.74595 (r=0.697,p=0.802),  time:34.145, tt:3516.983\n",
      "Ep:103, loss:0.00001, loss_test:0.02230, lr:3.35e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.158, tt:3552.414\n",
      "Ep:104, loss:0.00001, loss_test:0.02196, lr:3.35e-02, fs:0.74317 (r=0.687,p=0.810),  time:34.163, tt:3587.165\n",
      "Ep:105, loss:0.00001, loss_test:0.02184, lr:3.35e-02, fs:0.74317 (r=0.687,p=0.810),  time:34.178, tt:3622.817\n",
      "Ep:106, loss:0.00001, loss_test:0.02456, lr:3.35e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.182, tt:3657.493\n",
      "Ep:107, loss:0.00001, loss_test:0.02128, lr:3.35e-02, fs:0.74595 (r=0.697,p=0.802),  time:34.194, tt:3692.936\n",
      "Ep:108, loss:0.00001, loss_test:0.02210, lr:3.35e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.204, tt:3728.257\n",
      "Ep:109, loss:0.00001, loss_test:0.02328, lr:3.35e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.201, tt:3762.106\n",
      "Ep:110, loss:0.00001, loss_test:0.02121, lr:3.35e-02, fs:0.75000 (r=0.697,p=0.812),  time:34.201, tt:3796.343\n",
      "Ep:111, loss:0.00001, loss_test:0.02407, lr:3.35e-02, fs:0.71429 (r=0.657,p=0.783),  time:34.199, tt:3830.236\n",
      "Ep:112, loss:0.00001, loss_test:0.02166, lr:3.35e-02, fs:0.74595 (r=0.697,p=0.802),  time:34.204, tt:3865.055\n",
      "Ep:113, loss:0.00001, loss_test:0.02218, lr:3.32e-02, fs:0.75000 (r=0.697,p=0.812),  time:34.206, tt:3899.430\n",
      "Ep:114, loss:0.00001, loss_test:0.02507, lr:3.28e-02, fs:0.71429 (r=0.657,p=0.783),  time:34.208, tt:3933.934\n",
      "Ep:115, loss:0.00001, loss_test:0.02104, lr:3.25e-02, fs:0.74317 (r=0.687,p=0.810),  time:34.215, tt:3968.967\n",
      "Ep:116, loss:0.00001, loss_test:0.02450, lr:3.22e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.220, tt:4003.796\n",
      "Ep:117, loss:0.00001, loss_test:0.02184, lr:3.19e-02, fs:0.73913 (r=0.687,p=0.800),  time:34.225, tt:4038.532\n",
      "Ep:118, loss:0.00001, loss_test:0.02367, lr:3.15e-02, fs:0.74725 (r=0.687,p=0.819),  time:34.222, tt:4072.373\n",
      "Ep:119, loss:0.00001, loss_test:0.02282, lr:3.12e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.225, tt:4106.945\n",
      "Ep:120, loss:0.00001, loss_test:0.02367, lr:3.09e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.223, tt:4140.969\n",
      "Ep:121, loss:0.00001, loss_test:0.02355, lr:3.06e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.230, tt:4176.021\n",
      "Ep:122, loss:0.00001, loss_test:0.02374, lr:3.03e-02, fs:0.74444 (r=0.677,p=0.827),  time:34.237, tt:4211.136\n",
      "Ep:123, loss:0.00001, loss_test:0.02463, lr:3.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:34.244, tt:4246.210\n",
      "Ep:124, loss:0.00001, loss_test:0.02401, lr:2.97e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.255, tt:4281.867\n",
      "Ep:125, loss:0.00001, loss_test:0.02493, lr:2.94e-02, fs:0.74444 (r=0.677,p=0.827),  time:34.256, tt:4316.229\n",
      "Ep:126, loss:0.00001, loss_test:0.02450, lr:2.91e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.246, tt:4349.184\n",
      "Ep:127, loss:0.00001, loss_test:0.02472, lr:2.88e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.254, tt:4384.529\n",
      "Ep:128, loss:0.00001, loss_test:0.02650, lr:2.85e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.249, tt:4418.170\n",
      "Ep:129, loss:0.00001, loss_test:0.02439, lr:2.82e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.251, tt:4452.629\n",
      "Ep:130, loss:0.00001, loss_test:0.02465, lr:2.80e-02, fs:0.73743 (r=0.667,p=0.825),  time:34.280, tt:4490.680\n",
      "Ep:131, loss:0.00001, loss_test:0.02597, lr:2.77e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.286, tt:4525.772\n",
      "Ep:132, loss:0.00001, loss_test:0.02411, lr:2.74e-02, fs:0.73743 (r=0.667,p=0.825),  time:34.291, tt:4560.682\n",
      "Ep:133, loss:0.00001, loss_test:0.02608, lr:2.71e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.291, tt:4595.002\n",
      "Ep:134, loss:0.00001, loss_test:0.02522, lr:2.69e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.286, tt:4628.568\n",
      "Ep:135, loss:0.00001, loss_test:0.02400, lr:2.66e-02, fs:0.73333 (r=0.667,p=0.815),  time:34.295, tt:4664.156\n",
      "Ep:136, loss:0.00001, loss_test:0.02810, lr:2.63e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.298, tt:4698.810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.02380, lr:2.61e-02, fs:0.73743 (r=0.667,p=0.825),  time:34.297, tt:4732.940\n",
      "Ep:138, loss:0.00001, loss_test:0.02660, lr:2.58e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.310, tt:4769.149\n",
      "Ep:139, loss:0.00001, loss_test:0.02551, lr:2.55e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.297, tt:4801.555\n",
      "Ep:140, loss:0.00000, loss_test:0.02562, lr:2.53e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.282, tt:4833.778\n",
      "Ep:141, loss:0.00000, loss_test:0.02645, lr:2.50e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.279, tt:4867.616\n",
      "Ep:142, loss:0.00000, loss_test:0.02498, lr:2.48e-02, fs:0.72626 (r=0.657,p=0.812),  time:34.275, tt:4901.332\n",
      "Ep:143, loss:0.00000, loss_test:0.02656, lr:2.45e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.266, tt:4934.319\n",
      "Ep:144, loss:0.00000, loss_test:0.02602, lr:2.43e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.265, tt:4968.355\n",
      "Ep:145, loss:0.00000, loss_test:0.02614, lr:2.40e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.263, tt:5002.433\n",
      "Ep:146, loss:0.00000, loss_test:0.02692, lr:2.38e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.259, tt:5036.133\n",
      "Ep:147, loss:0.00000, loss_test:0.02613, lr:2.36e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.250, tt:5069.011\n",
      "Ep:148, loss:0.00000, loss_test:0.02815, lr:2.33e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.255, tt:5104.065\n",
      "Ep:149, loss:0.00000, loss_test:0.02616, lr:2.31e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.247, tt:5137.057\n",
      "Ep:150, loss:0.00000, loss_test:0.02803, lr:2.29e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.254, tt:5172.304\n",
      "Ep:151, loss:0.00000, loss_test:0.02725, lr:2.26e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.253, tt:5206.407\n",
      "Ep:152, loss:0.00000, loss_test:0.02668, lr:2.24e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.250, tt:5240.310\n",
      "Ep:153, loss:0.00000, loss_test:0.02869, lr:2.22e-02, fs:0.69006 (r=0.596,p=0.819),  time:34.254, tt:5275.042\n",
      "Ep:154, loss:0.00000, loss_test:0.02677, lr:2.20e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.264, tt:5310.868\n",
      "Ep:155, loss:0.00000, loss_test:0.02821, lr:2.17e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.266, tt:5345.540\n",
      "Ep:156, loss:0.00000, loss_test:0.02706, lr:2.15e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.274, tt:5381.023\n",
      "Ep:157, loss:0.00000, loss_test:0.02848, lr:2.13e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.271, tt:5414.859\n",
      "Ep:158, loss:0.00000, loss_test:0.02806, lr:2.11e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.266, tt:5448.371\n",
      "Ep:159, loss:0.00000, loss_test:0.02750, lr:2.09e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.264, tt:5482.309\n",
      "Ep:160, loss:0.00000, loss_test:0.02864, lr:2.07e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.270, tt:5517.414\n",
      "Ep:161, loss:0.00000, loss_test:0.02764, lr:2.05e-02, fs:0.71676 (r=0.626,p=0.838),  time:34.271, tt:5551.890\n",
      "Ep:162, loss:0.00000, loss_test:0.02878, lr:2.03e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.278, tt:5587.268\n",
      "Ep:163, loss:0.00000, loss_test:0.02837, lr:2.01e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.276, tt:5621.285\n",
      "Ep:164, loss:0.00000, loss_test:0.02874, lr:1.99e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.277, tt:5655.676\n",
      "Ep:165, loss:0.00000, loss_test:0.02891, lr:1.97e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.280, tt:5690.463\n",
      "Ep:166, loss:0.00000, loss_test:0.02858, lr:1.95e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.274, tt:5723.808\n",
      "Ep:167, loss:0.00000, loss_test:0.02896, lr:1.93e-02, fs:0.69412 (r=0.596,p=0.831),  time:34.279, tt:5758.868\n",
      "Ep:168, loss:0.00000, loss_test:0.02915, lr:1.91e-02, fs:0.69412 (r=0.596,p=0.831),  time:34.277, tt:5792.895\n",
      "Ep:169, loss:0.00000, loss_test:0.02955, lr:1.89e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.294, tt:5830.027\n",
      "Ep:170, loss:0.00000, loss_test:0.02865, lr:1.87e-02, fs:0.69822 (r=0.596,p=0.843),  time:34.292, tt:5863.957\n",
      "Ep:171, loss:0.00000, loss_test:0.02956, lr:1.85e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.290, tt:5897.916\n",
      "Ep:172, loss:0.00000, loss_test:0.02949, lr:1.83e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.287, tt:5931.708\n",
      "Ep:173, loss:0.00000, loss_test:0.02962, lr:1.81e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.286, tt:5965.818\n",
      "Ep:174, loss:0.00000, loss_test:0.02970, lr:1.80e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.285, tt:5999.875\n",
      "Ep:175, loss:0.00000, loss_test:0.02947, lr:1.78e-02, fs:0.69822 (r=0.596,p=0.843),  time:34.299, tt:6036.603\n",
      "Ep:176, loss:0.00000, loss_test:0.02954, lr:1.76e-02, fs:0.69822 (r=0.596,p=0.843),  time:34.293, tt:6069.813\n",
      "Ep:177, loss:0.00000, loss_test:0.03009, lr:1.74e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.292, tt:6104.037\n",
      "Ep:178, loss:0.00000, loss_test:0.02981, lr:1.73e-02, fs:0.69822 (r=0.596,p=0.843),  time:34.292, tt:6138.234\n",
      "Ep:179, loss:0.00000, loss_test:0.02998, lr:1.71e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.287, tt:6171.590\n",
      "Ep:180, loss:0.00000, loss_test:0.03038, lr:1.69e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.282, tt:6204.994\n",
      "Ep:181, loss:0.00000, loss_test:0.02991, lr:1.67e-02, fs:0.69822 (r=0.596,p=0.843),  time:34.268, tt:6236.745\n",
      "Ep:182, loss:0.00000, loss_test:0.03022, lr:1.66e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.261, tt:6269.797\n",
      "Ep:183, loss:0.00000, loss_test:0.03085, lr:1.64e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.255, tt:6302.993\n",
      "Ep:184, loss:0.00000, loss_test:0.03018, lr:1.62e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.250, tt:6336.305\n",
      "Ep:185, loss:0.00000, loss_test:0.03062, lr:1.61e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.240, tt:6368.671\n",
      "Ep:186, loss:0.00000, loss_test:0.03052, lr:1.59e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.233, tt:6401.551\n",
      "Ep:187, loss:0.00000, loss_test:0.03040, lr:1.58e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.223, tt:6433.957\n",
      "Ep:188, loss:0.00000, loss_test:0.03107, lr:1.56e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.222, tt:6467.913\n",
      "Ep:189, loss:0.00000, loss_test:0.03033, lr:1.54e-02, fs:0.69822 (r=0.596,p=0.843),  time:34.215, tt:6500.841\n",
      "Ep:190, loss:0.00000, loss_test:0.03140, lr:1.53e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.211, tt:6534.235\n",
      "Ep:191, loss:0.00000, loss_test:0.03058, lr:1.51e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.203, tt:6567.004\n",
      "Ep:192, loss:0.00000, loss_test:0.03108, lr:1.50e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.196, tt:6599.750\n",
      "Ep:193, loss:0.00000, loss_test:0.03175, lr:1.48e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.177, tt:6630.271\n",
      "Ep:194, loss:0.00000, loss_test:0.03024, lr:1.47e-02, fs:0.69412 (r=0.596,p=0.831),  time:34.156, tt:6660.414\n",
      "Ep:195, loss:0.00000, loss_test:0.03207, lr:1.45e-02, fs:0.67456 (r=0.576,p=0.814),  time:34.116, tt:6686.815\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02447, lr:6.00e-02, fs:0.60606 (r=0.707,p=0.530),  time:27.208, tt:27.208\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02274, lr:6.00e-02, fs:0.64286 (r=0.909,p=0.497),  time:27.163, tt:54.326\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02417, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.456, tt:79.368\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02455, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.461, tt:105.846\n",
      "Ep:4, loss:0.00005, loss_test:0.02420, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.246, tt:136.229\n",
      "Ep:5, loss:0.00004, loss_test:0.02344, lr:6.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:27.602, tt:165.612\n",
      "Ep:6, loss:0.00004, loss_test:0.02263, lr:6.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:27.751, tt:194.255\n",
      "Ep:7, loss:0.00004, loss_test:0.02226, lr:6.00e-02, fs:0.64122 (r=0.848,p=0.515),  time:28.000, tt:223.999\n",
      "Ep:8, loss:0.00004, loss_test:0.02276, lr:6.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:28.119, tt:253.071\n",
      "Ep:9, loss:0.00003, loss_test:0.02390, lr:6.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:28.273, tt:282.727\n",
      "Ep:10, loss:0.00003, loss_test:0.02452, lr:6.00e-02, fs:0.63208 (r=0.677,p=0.593),  time:28.366, tt:312.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00003, loss_test:0.02380, lr:6.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:28.488, tt:341.851\n",
      "Ep:12, loss:0.00003, loss_test:0.02235, lr:6.00e-02, fs:0.64516 (r=0.707,p=0.593),  time:28.626, tt:372.138\n",
      "Ep:13, loss:0.00003, loss_test:0.02120, lr:6.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:28.637, tt:400.921\n",
      "Ep:14, loss:0.00003, loss_test:0.02060, lr:5.94e-02, fs:0.64655 (r=0.758,p=0.564),  time:28.654, tt:429.810\n",
      "Ep:15, loss:0.00003, loss_test:0.02033, lr:5.88e-02, fs:0.64655 (r=0.758,p=0.564),  time:28.781, tt:460.500\n",
      "Ep:16, loss:0.00003, loss_test:0.02028, lr:5.82e-02, fs:0.64655 (r=0.758,p=0.564),  time:28.798, tt:489.568\n",
      "Ep:17, loss:0.00003, loss_test:0.02037, lr:5.76e-02, fs:0.65502 (r=0.758,p=0.577),  time:28.870, tt:519.655\n",
      "Ep:18, loss:0.00003, loss_test:0.02050, lr:5.71e-02, fs:0.66079 (r=0.758,p=0.586),  time:28.879, tt:548.695\n",
      "Ep:19, loss:0.00003, loss_test:0.02053, lr:5.65e-02, fs:0.65158 (r=0.727,p=0.590),  time:28.839, tt:576.785\n",
      "Ep:20, loss:0.00003, loss_test:0.02035, lr:5.59e-02, fs:0.62673 (r=0.687,p=0.576),  time:28.833, tt:605.490\n",
      "Ep:21, loss:0.00003, loss_test:0.02001, lr:5.54e-02, fs:0.63348 (r=0.707,p=0.574),  time:28.805, tt:633.704\n",
      "Ep:22, loss:0.00003, loss_test:0.01959, lr:5.48e-02, fs:0.65778 (r=0.747,p=0.587),  time:28.835, tt:663.210\n",
      "Ep:23, loss:0.00003, loss_test:0.01921, lr:5.43e-02, fs:0.68421 (r=0.788,p=0.605),  time:28.836, tt:692.059\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01894, lr:5.43e-02, fs:0.68696 (r=0.798,p=0.603),  time:28.792, tt:719.802\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01877, lr:5.43e-02, fs:0.68996 (r=0.798,p=0.608),  time:28.769, tt:747.986\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01869, lr:5.43e-02, fs:0.69604 (r=0.798,p=0.617),  time:28.725, tt:775.579\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01870, lr:5.43e-02, fs:0.70222 (r=0.798,p=0.627),  time:28.721, tt:804.181\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01874, lr:5.43e-02, fs:0.69955 (r=0.788,p=0.629),  time:28.749, tt:833.733\n",
      "Ep:29, loss:0.00002, loss_test:0.01869, lr:5.43e-02, fs:0.70588 (r=0.788,p=0.639),  time:28.769, tt:863.061\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01866, lr:5.43e-02, fs:0.71749 (r=0.808,p=0.645),  time:28.781, tt:892.226\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01860, lr:5.43e-02, fs:0.72889 (r=0.828,p=0.651),  time:28.823, tt:922.342\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01861, lr:5.43e-02, fs:0.72889 (r=0.828,p=0.651),  time:28.851, tt:952.068\n",
      "Ep:33, loss:0.00002, loss_test:0.01864, lr:5.43e-02, fs:0.73214 (r=0.828,p=0.656),  time:28.892, tt:982.334\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01868, lr:5.43e-02, fs:0.73214 (r=0.828,p=0.656),  time:28.939, tt:1012.855\n",
      "Ep:35, loss:0.00002, loss_test:0.01870, lr:5.43e-02, fs:0.73214 (r=0.828,p=0.656),  time:28.928, tt:1041.395\n",
      "Ep:36, loss:0.00002, loss_test:0.01866, lr:5.43e-02, fs:0.73543 (r=0.828,p=0.661),  time:28.969, tt:1071.861\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01861, lr:5.43e-02, fs:0.73543 (r=0.828,p=0.661),  time:29.057, tt:1104.178\n",
      "Ep:38, loss:0.00002, loss_test:0.01859, lr:5.43e-02, fs:0.73874 (r=0.828,p=0.667),  time:29.040, tt:1132.545\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01857, lr:5.43e-02, fs:0.73874 (r=0.828,p=0.667),  time:29.077, tt:1163.063\n",
      "Ep:40, loss:0.00002, loss_test:0.01856, lr:5.43e-02, fs:0.73874 (r=0.828,p=0.667),  time:29.096, tt:1192.930\n",
      "Ep:41, loss:0.00002, loss_test:0.01859, lr:5.43e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.088, tt:1221.717\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01862, lr:5.43e-02, fs:0.74775 (r=0.838,p=0.675),  time:29.143, tt:1253.168\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01863, lr:5.43e-02, fs:0.75336 (r=0.848,p=0.677),  time:29.180, tt:1283.940\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01863, lr:5.43e-02, fs:0.75893 (r=0.859,p=0.680),  time:29.208, tt:1314.359\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01858, lr:5.43e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.245, tt:1345.262\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01854, lr:5.43e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.291, tt:1376.663\n",
      "Ep:47, loss:0.00002, loss_test:0.01855, lr:5.43e-02, fs:0.76786 (r=0.869,p=0.688),  time:29.295, tt:1406.178\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01855, lr:5.43e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.299, tt:1435.653\n",
      "Ep:49, loss:0.00002, loss_test:0.01857, lr:5.43e-02, fs:0.76786 (r=0.869,p=0.688),  time:29.324, tt:1466.177\n",
      "Ep:50, loss:0.00002, loss_test:0.01858, lr:5.43e-02, fs:0.77828 (r=0.869,p=0.705),  time:29.346, tt:1496.668\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01859, lr:5.43e-02, fs:0.78182 (r=0.869,p=0.711),  time:29.374, tt:1527.444\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01858, lr:5.43e-02, fs:0.77828 (r=0.869,p=0.705),  time:29.404, tt:1558.387\n",
      "Ep:53, loss:0.00002, loss_test:0.01856, lr:5.43e-02, fs:0.77828 (r=0.869,p=0.705),  time:29.448, tt:1590.209\n",
      "Ep:54, loss:0.00002, loss_test:0.01852, lr:5.43e-02, fs:0.77477 (r=0.869,p=0.699),  time:29.449, tt:1619.696\n",
      "Ep:55, loss:0.00002, loss_test:0.01851, lr:5.43e-02, fs:0.78378 (r=0.879,p=0.707),  time:29.453, tt:1649.348\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01850, lr:5.43e-02, fs:0.78924 (r=0.889,p=0.710),  time:29.442, tt:1678.176\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01848, lr:5.43e-02, fs:0.79464 (r=0.899,p=0.712),  time:29.456, tt:1708.457\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01849, lr:5.43e-02, fs:0.79464 (r=0.899,p=0.712),  time:29.467, tt:1738.559\n",
      "Ep:59, loss:0.00001, loss_test:0.01847, lr:5.43e-02, fs:0.79464 (r=0.899,p=0.712),  time:29.530, tt:1771.802\n",
      "Ep:60, loss:0.00001, loss_test:0.01848, lr:5.43e-02, fs:0.79464 (r=0.899,p=0.712),  time:29.548, tt:1802.421\n",
      "Ep:61, loss:0.00001, loss_test:0.01850, lr:5.43e-02, fs:0.79464 (r=0.899,p=0.712),  time:29.576, tt:1833.717\n",
      "Ep:62, loss:0.00001, loss_test:0.01845, lr:5.43e-02, fs:0.79464 (r=0.899,p=0.712),  time:29.593, tt:1864.336\n",
      "Ep:63, loss:0.00001, loss_test:0.01845, lr:5.43e-02, fs:0.79821 (r=0.899,p=0.718),  time:29.587, tt:1893.580\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01838, lr:5.43e-02, fs:0.79821 (r=0.899,p=0.718),  time:29.587, tt:1923.134\n",
      "Ep:65, loss:0.00001, loss_test:0.01839, lr:5.43e-02, fs:0.79821 (r=0.899,p=0.718),  time:29.575, tt:1951.961\n",
      "Ep:66, loss:0.00001, loss_test:0.01838, lr:5.43e-02, fs:0.79821 (r=0.899,p=0.718),  time:29.568, tt:1981.033\n",
      "Ep:67, loss:0.00001, loss_test:0.01838, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.581, tt:2011.485\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01835, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.580, tt:2041.036\n",
      "Ep:69, loss:0.00001, loss_test:0.01832, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.605, tt:2072.359\n",
      "Ep:70, loss:0.00001, loss_test:0.01835, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.626, tt:2103.422\n",
      "Ep:71, loss:0.00001, loss_test:0.01834, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.661, tt:2135.558\n",
      "Ep:72, loss:0.00001, loss_test:0.01833, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.677, tt:2166.417\n",
      "Ep:73, loss:0.00001, loss_test:0.01836, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.695, tt:2197.407\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01838, lr:5.43e-02, fs:0.80543 (r=0.899,p=0.730),  time:29.694, tt:2227.071\n",
      "Ep:75, loss:0.00001, loss_test:0.01835, lr:5.43e-02, fs:0.81081 (r=0.909,p=0.732),  time:29.704, tt:2257.538\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00001, loss_test:0.01834, lr:5.43e-02, fs:0.81448 (r=0.909,p=0.738),  time:29.723, tt:2288.706\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01839, lr:5.43e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.743, tt:2319.938\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01844, lr:5.43e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.756, tt:2350.734\n",
      "Ep:79, loss:0.00001, loss_test:0.01838, lr:5.43e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.770, tt:2381.578\n",
      "Ep:80, loss:0.00001, loss_test:0.01837, lr:5.43e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.771, tt:2411.478\n",
      "Ep:81, loss:0.00001, loss_test:0.01843, lr:5.43e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.797, tt:2443.386\n",
      "Ep:82, loss:0.00001, loss_test:0.01845, lr:5.43e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.789, tt:2472.522\n",
      "Ep:83, loss:0.00001, loss_test:0.01843, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.786, tt:2501.992\n",
      "Ep:84, loss:0.00001, loss_test:0.01839, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.801, tt:2533.075\n",
      "Ep:85, loss:0.00001, loss_test:0.01843, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.812, tt:2563.854\n",
      "Ep:86, loss:0.00001, loss_test:0.01840, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.837, tt:2595.812\n",
      "Ep:87, loss:0.00001, loss_test:0.01839, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.830, tt:2625.054\n",
      "Ep:88, loss:0.00001, loss_test:0.01844, lr:5.43e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.824, tt:2654.377\n",
      "Ep:89, loss:0.00001, loss_test:0.01836, lr:5.37e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.821, tt:2683.883\n",
      "Ep:90, loss:0.00001, loss_test:0.01831, lr:5.32e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.827, tt:2714.253\n",
      "Ep:91, loss:0.00001, loss_test:0.01837, lr:5.27e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.830, tt:2744.396\n",
      "Ep:92, loss:0.00001, loss_test:0.01851, lr:5.21e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.823, tt:2773.584\n",
      "Ep:93, loss:0.00001, loss_test:0.01861, lr:5.16e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.834, tt:2804.399\n",
      "Ep:94, loss:0.00001, loss_test:0.01850, lr:5.11e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.832, tt:2834.005\n",
      "Ep:95, loss:0.00001, loss_test:0.01841, lr:5.06e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.841, tt:2864.728\n",
      "Ep:96, loss:0.00001, loss_test:0.01843, lr:5.01e-02, fs:0.81448 (r=0.909,p=0.738),  time:29.824, tt:2892.916\n",
      "Ep:97, loss:0.00001, loss_test:0.01850, lr:4.96e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.822, tt:2922.575\n",
      "Ep:98, loss:0.00001, loss_test:0.01855, lr:4.91e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.827, tt:2952.862\n",
      "Ep:99, loss:0.00001, loss_test:0.01855, lr:4.86e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.829, tt:2982.945\n",
      "Ep:100, loss:0.00001, loss_test:0.01863, lr:4.81e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.828, tt:3012.672\n",
      "Ep:101, loss:0.00001, loss_test:0.01861, lr:4.76e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.833, tt:3042.995\n",
      "Ep:102, loss:0.00001, loss_test:0.01860, lr:4.71e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.820, tt:3071.454\n",
      "Ep:103, loss:0.00001, loss_test:0.01862, lr:4.67e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.809, tt:3100.169\n",
      "Ep:104, loss:0.00001, loss_test:0.01862, lr:4.62e-02, fs:0.81818 (r=0.909,p=0.744),  time:29.839, tt:3133.144\n",
      "Ep:105, loss:0.00001, loss_test:0.01850, lr:4.57e-02, fs:0.82353 (r=0.919,p=0.746),  time:29.834, tt:3162.386\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.01856, lr:4.57e-02, fs:0.82192 (r=0.909,p=0.750),  time:29.830, tt:3191.776\n",
      "Ep:107, loss:0.00001, loss_test:0.01868, lr:4.57e-02, fs:0.82569 (r=0.909,p=0.756),  time:29.849, tt:3223.673\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01877, lr:4.57e-02, fs:0.81481 (r=0.889,p=0.752),  time:29.853, tt:3253.998\n",
      "Ep:109, loss:0.00001, loss_test:0.01875, lr:4.57e-02, fs:0.82192 (r=0.909,p=0.750),  time:29.850, tt:3283.518\n",
      "Ep:110, loss:0.00001, loss_test:0.01870, lr:4.57e-02, fs:0.82192 (r=0.909,p=0.750),  time:29.855, tt:3313.853\n",
      "Ep:111, loss:0.00001, loss_test:0.01867, lr:4.57e-02, fs:0.82192 (r=0.909,p=0.750),  time:29.872, tt:3345.702\n",
      "Ep:112, loss:0.00001, loss_test:0.01871, lr:4.57e-02, fs:0.82192 (r=0.909,p=0.750),  time:29.865, tt:3374.758\n",
      "Ep:113, loss:0.00001, loss_test:0.01879, lr:4.57e-02, fs:0.81481 (r=0.889,p=0.752),  time:29.868, tt:3405.004\n",
      "Ep:114, loss:0.00001, loss_test:0.01877, lr:4.57e-02, fs:0.81481 (r=0.889,p=0.752),  time:29.872, tt:3435.334\n",
      "Ep:115, loss:0.00001, loss_test:0.01879, lr:4.57e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.872, tt:3465.157\n",
      "Ep:116, loss:0.00001, loss_test:0.01881, lr:4.57e-02, fs:0.81690 (r=0.879,p=0.763),  time:29.871, tt:3494.904\n",
      "Ep:117, loss:0.00001, loss_test:0.01882, lr:4.57e-02, fs:0.82075 (r=0.879,p=0.770),  time:29.870, tt:3524.614\n",
      "Ep:118, loss:0.00001, loss_test:0.01883, lr:4.57e-02, fs:0.82075 (r=0.879,p=0.770),  time:29.866, tt:3554.098\n",
      "Ep:119, loss:0.00001, loss_test:0.01885, lr:4.53e-02, fs:0.82075 (r=0.879,p=0.770),  time:29.866, tt:3583.969\n",
      "Ep:120, loss:0.00001, loss_test:0.01884, lr:4.48e-02, fs:0.81690 (r=0.879,p=0.763),  time:29.872, tt:3614.512\n",
      "Ep:121, loss:0.00001, loss_test:0.01892, lr:4.44e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.870, tt:3644.130\n",
      "Ep:122, loss:0.00001, loss_test:0.01896, lr:4.39e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.882, tt:3675.448\n",
      "Ep:123, loss:0.00001, loss_test:0.01892, lr:4.35e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.881, tt:3705.187\n",
      "Ep:124, loss:0.00001, loss_test:0.01893, lr:4.31e-02, fs:0.81340 (r=0.859,p=0.773),  time:29.885, tt:3735.591\n",
      "Ep:125, loss:0.00001, loss_test:0.01892, lr:4.26e-02, fs:0.81340 (r=0.859,p=0.773),  time:29.916, tt:3769.471\n",
      "Ep:126, loss:0.00001, loss_test:0.01903, lr:4.22e-02, fs:0.80193 (r=0.838,p=0.769),  time:29.918, tt:3799.611\n",
      "Ep:127, loss:0.00001, loss_test:0.01908, lr:4.18e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.922, tt:3830.045\n",
      "Ep:128, loss:0.00001, loss_test:0.01906, lr:4.14e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.932, tt:3861.247\n",
      "Ep:129, loss:0.00001, loss_test:0.01905, lr:4.10e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.928, tt:3890.670\n",
      "Ep:130, loss:0.00001, loss_test:0.01899, lr:4.05e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.932, tt:3921.064\n",
      "Ep:131, loss:0.00001, loss_test:0.01903, lr:4.01e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.932, tt:3951.087\n",
      "Ep:132, loss:0.00001, loss_test:0.01910, lr:3.97e-02, fs:0.80000 (r=0.828,p=0.774),  time:29.937, tt:3981.575\n",
      "Ep:133, loss:0.00001, loss_test:0.01913, lr:3.93e-02, fs:0.80000 (r=0.828,p=0.774),  time:29.930, tt:4010.662\n",
      "Ep:134, loss:0.00001, loss_test:0.01915, lr:3.89e-02, fs:0.80000 (r=0.828,p=0.774),  time:29.936, tt:4041.370\n",
      "Ep:135, loss:0.00001, loss_test:0.01917, lr:3.86e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.938, tt:4071.561\n",
      "Ep:136, loss:0.00001, loss_test:0.01917, lr:3.82e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.926, tt:4099.835\n",
      "Ep:137, loss:0.00001, loss_test:0.01922, lr:3.78e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.928, tt:4130.109\n",
      "Ep:138, loss:0.00001, loss_test:0.01923, lr:3.74e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.929, tt:4160.100\n",
      "Ep:139, loss:0.00001, loss_test:0.01926, lr:3.70e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.932, tt:4190.483\n",
      "Ep:140, loss:0.00001, loss_test:0.01929, lr:3.67e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.939, tt:4221.350\n",
      "Ep:141, loss:0.00001, loss_test:0.01931, lr:3.63e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.941, tt:4251.605\n",
      "Ep:142, loss:0.00001, loss_test:0.01930, lr:3.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.943, tt:4281.847\n",
      "Ep:143, loss:0.00001, loss_test:0.01931, lr:3.56e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.945, tt:4312.022\n",
      "Ep:144, loss:0.00001, loss_test:0.01934, lr:3.52e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.943, tt:4341.745\n",
      "Ep:145, loss:0.00001, loss_test:0.01937, lr:3.49e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.938, tt:4370.948\n",
      "Ep:146, loss:0.00001, loss_test:0.01942, lr:3.45e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.933, tt:4400.211\n",
      "Ep:147, loss:0.00001, loss_test:0.01941, lr:3.42e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.938, tt:4430.783\n",
      "Ep:148, loss:0.00001, loss_test:0.01943, lr:3.38e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.945, tt:4461.828\n",
      "Ep:149, loss:0.00001, loss_test:0.01949, lr:3.35e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.950, tt:4492.450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00001, loss_test:0.01948, lr:3.32e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.949, tt:4522.358\n",
      "Ep:151, loss:0.00001, loss_test:0.01951, lr:3.28e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.953, tt:4552.833\n",
      "Ep:152, loss:0.00001, loss_test:0.01952, lr:3.25e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.965, tt:4584.637\n",
      "Ep:153, loss:0.00001, loss_test:0.01952, lr:3.22e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.964, tt:4614.481\n",
      "Ep:154, loss:0.00001, loss_test:0.01958, lr:3.19e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.963, tt:4644.273\n",
      "Ep:155, loss:0.00001, loss_test:0.01957, lr:3.15e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.968, tt:4674.978\n",
      "Ep:156, loss:0.00001, loss_test:0.01961, lr:3.12e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.960, tt:4703.709\n",
      "Ep:157, loss:0.00001, loss_test:0.01961, lr:3.09e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.958, tt:4733.398\n",
      "Ep:158, loss:0.00001, loss_test:0.01962, lr:3.06e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.959, tt:4763.546\n",
      "Ep:159, loss:0.00001, loss_test:0.01968, lr:3.03e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.948, tt:4791.714\n",
      "Ep:160, loss:0.00001, loss_test:0.01971, lr:3.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.946, tt:4821.272\n",
      "Ep:161, loss:0.00001, loss_test:0.01968, lr:2.97e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.945, tt:4851.119\n",
      "Ep:162, loss:0.00001, loss_test:0.01967, lr:2.94e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.953, tt:4882.394\n",
      "Ep:163, loss:0.00001, loss_test:0.01971, lr:2.91e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.963, tt:4913.878\n",
      "Ep:164, loss:0.00001, loss_test:0.01972, lr:2.88e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.959, tt:4943.165\n",
      "Ep:165, loss:0.00001, loss_test:0.01975, lr:2.85e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.959, tt:4973.124\n",
      "Ep:166, loss:0.00001, loss_test:0.01977, lr:2.82e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.971, tt:5005.182\n",
      "Ep:167, loss:0.00001, loss_test:0.01980, lr:2.80e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.977, tt:5036.099\n",
      "Ep:168, loss:0.00001, loss_test:0.01979, lr:2.77e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.979, tt:5066.458\n",
      "Ep:169, loss:0.00001, loss_test:0.01981, lr:2.74e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.982, tt:5096.965\n",
      "Ep:170, loss:0.00001, loss_test:0.01982, lr:2.71e-02, fs:0.80597 (r=0.818,p=0.794),  time:29.978, tt:5126.284\n",
      "Ep:171, loss:0.00001, loss_test:0.01988, lr:2.69e-02, fs:0.80000 (r=0.808,p=0.792),  time:29.979, tt:5156.415\n",
      "Ep:172, loss:0.00001, loss_test:0.01987, lr:2.66e-02, fs:0.80000 (r=0.808,p=0.792),  time:29.984, tt:5187.234\n",
      "Ep:173, loss:0.00001, loss_test:0.01988, lr:2.63e-02, fs:0.80000 (r=0.808,p=0.792),  time:29.989, tt:5218.125\n",
      "Ep:174, loss:0.00001, loss_test:0.01986, lr:2.61e-02, fs:0.80000 (r=0.808,p=0.792),  time:29.996, tt:5249.224\n",
      "Ep:175, loss:0.00001, loss_test:0.01992, lr:2.58e-02, fs:0.80000 (r=0.808,p=0.792),  time:30.005, tt:5280.868\n",
      "Ep:176, loss:0.00001, loss_test:0.01996, lr:2.55e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.014, tt:5312.491\n",
      "Ep:177, loss:0.00001, loss_test:0.01996, lr:2.53e-02, fs:0.80000 (r=0.808,p=0.792),  time:30.012, tt:5342.221\n",
      "Ep:178, loss:0.00001, loss_test:0.01996, lr:2.50e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.007, tt:5371.188\n",
      "Ep:179, loss:0.00001, loss_test:0.01997, lr:2.48e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.004, tt:5400.759\n",
      "Ep:180, loss:0.00001, loss_test:0.01999, lr:2.45e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.014, tt:5432.471\n",
      "Ep:181, loss:0.00001, loss_test:0.02002, lr:2.43e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.022, tt:5463.921\n",
      "Ep:182, loss:0.00001, loss_test:0.02006, lr:2.40e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.025, tt:5494.530\n",
      "Ep:183, loss:0.00001, loss_test:0.02005, lr:2.38e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.028, tt:5525.117\n",
      "Ep:184, loss:0.00001, loss_test:0.02005, lr:2.36e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.037, tt:5556.828\n",
      "Ep:185, loss:0.00001, loss_test:0.02009, lr:2.33e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.037, tt:5586.924\n",
      "Ep:186, loss:0.00001, loss_test:0.02011, lr:2.31e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.041, tt:5617.699\n",
      "Ep:187, loss:0.00000, loss_test:0.02014, lr:2.29e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.045, tt:5648.386\n",
      "Ep:188, loss:0.00000, loss_test:0.02014, lr:2.26e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.049, tt:5679.218\n",
      "Ep:189, loss:0.00000, loss_test:0.02012, lr:2.24e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.054, tt:5710.221\n",
      "Ep:190, loss:0.00000, loss_test:0.02013, lr:2.22e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.056, tt:5740.612\n",
      "Ep:191, loss:0.00000, loss_test:0.02014, lr:2.20e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.059, tt:5771.423\n",
      "Ep:192, loss:0.00000, loss_test:0.02017, lr:2.17e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.058, tt:5801.178\n",
      "Ep:193, loss:0.00000, loss_test:0.02017, lr:2.15e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.055, tt:5830.714\n",
      "Ep:194, loss:0.00000, loss_test:0.02019, lr:2.13e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.054, tt:5860.474\n",
      "Ep:195, loss:0.00000, loss_test:0.02023, lr:2.11e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.060, tt:5891.760\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02284, lr:6.00e-02, fs:0.62879 (r=0.838,p=0.503),  time:29.029, tt:29.029\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02401, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.710, tt:65.421\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.675, tt:101.026\n",
      "Ep:3, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.083, tt:136.333\n",
      "Ep:4, loss:0.00005, loss_test:0.02333, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:34.949, tt:174.745\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:35.497, tt:212.985\n",
      "Ep:6, loss:0.00004, loss_test:0.02273, lr:6.00e-02, fs:0.63636 (r=0.778,p=0.538),  time:35.736, tt:250.151\n",
      "Ep:7, loss:0.00004, loss_test:0.02436, lr:6.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:36.131, tt:289.050\n",
      "Ep:8, loss:0.00004, loss_test:0.02472, lr:6.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:36.323, tt:326.906\n",
      "Ep:9, loss:0.00004, loss_test:0.02293, lr:6.00e-02, fs:0.63014 (r=0.697,p=0.575),  time:36.509, tt:365.093\n",
      "Ep:10, loss:0.00003, loss_test:0.02122, lr:6.00e-02, fs:0.63436 (r=0.727,p=0.562),  time:36.671, tt:403.376\n",
      "Ep:11, loss:0.00003, loss_test:0.02032, lr:6.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:37.007, tt:444.084\n",
      "Ep:12, loss:0.00003, loss_test:0.01994, lr:6.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:37.169, tt:483.203\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01983, lr:6.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:37.310, tt:522.340\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01992, lr:6.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:37.425, tt:561.373\n",
      "Ep:15, loss:0.00003, loss_test:0.02002, lr:6.00e-02, fs:0.69298 (r=0.798,p=0.612),  time:37.368, tt:597.892\n",
      "Ep:16, loss:0.00003, loss_test:0.01982, lr:6.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:37.343, tt:634.823\n",
      "Ep:17, loss:0.00003, loss_test:0.01939, lr:6.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:37.363, tt:672.529\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01894, lr:6.00e-02, fs:0.67265 (r=0.758,p=0.605),  time:37.326, tt:709.190\n",
      "Ep:19, loss:0.00003, loss_test:0.01862, lr:6.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:37.389, tt:747.781\n",
      "Ep:20, loss:0.00003, loss_test:0.01846, lr:6.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:37.396, tt:785.308\n",
      "Ep:21, loss:0.00002, loss_test:0.01840, lr:6.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:37.407, tt:822.946\n",
      "Ep:22, loss:0.00002, loss_test:0.01842, lr:6.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:37.428, tt:860.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00002, loss_test:0.01836, lr:6.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:37.437, tt:898.484\n",
      "Ep:24, loss:0.00002, loss_test:0.01821, lr:6.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:37.519, tt:937.976\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01814, lr:6.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:37.577, tt:976.991\n",
      "Ep:26, loss:0.00002, loss_test:0.01814, lr:6.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:37.759, tt:1019.489\n",
      "Ep:27, loss:0.00002, loss_test:0.01814, lr:6.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:37.812, tt:1058.733\n",
      "Ep:28, loss:0.00002, loss_test:0.01822, lr:6.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:37.794, tt:1096.040\n",
      "Ep:29, loss:0.00002, loss_test:0.01820, lr:6.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:37.790, tt:1133.695\n",
      "Ep:30, loss:0.00002, loss_test:0.01815, lr:6.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:37.756, tt:1170.439\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01810, lr:6.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:37.796, tt:1209.461\n",
      "Ep:32, loss:0.00002, loss_test:0.01805, lr:6.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:37.807, tt:1247.617\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01797, lr:6.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:37.832, tt:1286.288\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:37.809, tt:1323.316\n",
      "Ep:35, loss:0.00002, loss_test:0.01787, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:37.844, tt:1362.371\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01791, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:37.869, tt:1401.167\n",
      "Ep:37, loss:0.00002, loss_test:0.01787, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:37.905, tt:1440.387\n",
      "Ep:38, loss:0.00002, loss_test:0.01791, lr:6.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:37.878, tt:1477.257\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01792, lr:6.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:37.863, tt:1514.535\n",
      "Ep:40, loss:0.00002, loss_test:0.01794, lr:6.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:37.830, tt:1551.026\n",
      "Ep:41, loss:0.00001, loss_test:0.01794, lr:6.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:37.806, tt:1587.841\n",
      "Ep:42, loss:0.00001, loss_test:0.01786, lr:6.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:37.781, tt:1624.576\n",
      "Ep:43, loss:0.00001, loss_test:0.01785, lr:6.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:37.825, tt:1664.295\n",
      "Ep:44, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:37.833, tt:1702.470\n",
      "Ep:45, loss:0.00001, loss_test:0.01773, lr:6.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:37.778, tt:1737.783\n",
      "Ep:46, loss:0.00001, loss_test:0.01773, lr:6.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:37.806, tt:1776.862\n",
      "Ep:47, loss:0.00001, loss_test:0.01793, lr:6.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:37.791, tt:1813.951\n",
      "Ep:48, loss:0.00001, loss_test:0.01790, lr:6.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:37.777, tt:1851.069\n",
      "Ep:49, loss:0.00001, loss_test:0.01778, lr:6.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:37.782, tt:1889.116\n",
      "Ep:50, loss:0.00001, loss_test:0.01775, lr:5.94e-02, fs:0.72381 (r=0.768,p=0.685),  time:37.794, tt:1927.490\n",
      "Ep:51, loss:0.00001, loss_test:0.01786, lr:5.88e-02, fs:0.71154 (r=0.747,p=0.679),  time:37.796, tt:1965.381\n",
      "Ep:52, loss:0.00001, loss_test:0.01784, lr:5.82e-02, fs:0.71770 (r=0.758,p=0.682),  time:37.794, tt:2003.084\n",
      "Ep:53, loss:0.00001, loss_test:0.01780, lr:5.76e-02, fs:0.72464 (r=0.758,p=0.694),  time:37.817, tt:2042.119\n",
      "Ep:54, loss:0.00001, loss_test:0.01780, lr:5.71e-02, fs:0.72816 (r=0.758,p=0.701),  time:37.785, tt:2078.159\n",
      "Ep:55, loss:0.00001, loss_test:0.01782, lr:5.65e-02, fs:0.71569 (r=0.737,p=0.695),  time:37.790, tt:2116.240\n",
      "Ep:56, loss:0.00001, loss_test:0.01775, lr:5.59e-02, fs:0.72195 (r=0.747,p=0.698),  time:37.842, tt:2157.014\n",
      "Ep:57, loss:0.00001, loss_test:0.01780, lr:5.54e-02, fs:0.71287 (r=0.727,p=0.699),  time:37.825, tt:2193.850\n",
      "Ep:58, loss:0.00001, loss_test:0.01783, lr:5.48e-02, fs:0.71642 (r=0.727,p=0.706),  time:37.849, tt:2233.072\n",
      "Ep:59, loss:0.00001, loss_test:0.01782, lr:5.43e-02, fs:0.72000 (r=0.727,p=0.713),  time:37.843, tt:2270.550\n",
      "Ep:60, loss:0.00001, loss_test:0.01773, lr:5.37e-02, fs:0.72277 (r=0.737,p=0.709),  time:37.846, tt:2308.628\n",
      "Ep:61, loss:0.00001, loss_test:0.01774, lr:5.32e-02, fs:0.72277 (r=0.737,p=0.709),  time:37.849, tt:2346.627\n",
      "Ep:62, loss:0.00001, loss_test:0.01778, lr:5.27e-02, fs:0.72637 (r=0.737,p=0.716),  time:37.865, tt:2385.476\n",
      "Ep:63, loss:0.00001, loss_test:0.01775, lr:5.21e-02, fs:0.72637 (r=0.737,p=0.716),  time:37.847, tt:2422.208\n",
      "Ep:64, loss:0.00001, loss_test:0.01771, lr:5.16e-02, fs:0.73000 (r=0.737,p=0.723),  time:37.816, tt:2458.044\n",
      "Ep:65, loss:0.00001, loss_test:0.01768, lr:5.11e-02, fs:0.73000 (r=0.737,p=0.723),  time:37.810, tt:2495.448\n",
      "Ep:66, loss:0.00001, loss_test:0.01769, lr:5.06e-02, fs:0.73000 (r=0.737,p=0.723),  time:37.813, tt:2533.494\n",
      "Ep:67, loss:0.00001, loss_test:0.01778, lr:5.01e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.853, tt:2574.021\n",
      "Ep:68, loss:0.00001, loss_test:0.01780, lr:4.96e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.851, tt:2611.716\n",
      "Ep:69, loss:0.00001, loss_test:0.01774, lr:4.91e-02, fs:0.73367 (r=0.737,p=0.730),  time:37.856, tt:2649.903\n",
      "Ep:70, loss:0.00001, loss_test:0.01779, lr:4.86e-02, fs:0.72727 (r=0.727,p=0.727),  time:37.838, tt:2686.466\n",
      "Ep:71, loss:0.00001, loss_test:0.01781, lr:4.81e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.805, tt:2721.933\n",
      "Ep:72, loss:0.00001, loss_test:0.01784, lr:4.76e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.798, tt:2759.248\n",
      "Ep:73, loss:0.00001, loss_test:0.01786, lr:4.71e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.792, tt:2796.575\n",
      "Ep:74, loss:0.00001, loss_test:0.01794, lr:4.67e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.834, tt:2837.583\n",
      "Ep:75, loss:0.00001, loss_test:0.01789, lr:4.62e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.822, tt:2874.507\n",
      "Ep:76, loss:0.00001, loss_test:0.01792, lr:4.57e-02, fs:0.72449 (r=0.717,p=0.732),  time:37.844, tt:2913.966\n",
      "Ep:77, loss:0.00001, loss_test:0.01798, lr:4.53e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.831, tt:2950.788\n",
      "Ep:78, loss:0.00001, loss_test:0.01804, lr:4.48e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.850, tt:2990.128\n",
      "Ep:79, loss:0.00001, loss_test:0.01802, lr:4.44e-02, fs:0.72449 (r=0.717,p=0.732),  time:37.829, tt:3026.300\n",
      "Ep:80, loss:0.00001, loss_test:0.01799, lr:4.39e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.790, tt:3060.971\n",
      "Ep:81, loss:0.00001, loss_test:0.01804, lr:4.35e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.779, tt:3097.838\n",
      "Ep:82, loss:0.00001, loss_test:0.01813, lr:4.31e-02, fs:0.72449 (r=0.717,p=0.732),  time:37.778, tt:3135.582\n",
      "Ep:83, loss:0.00001, loss_test:0.01813, lr:4.26e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.751, tt:3171.118\n",
      "Ep:84, loss:0.00001, loss_test:0.01817, lr:4.22e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.760, tt:3209.605\n",
      "Ep:85, loss:0.00001, loss_test:0.01816, lr:4.18e-02, fs:0.72449 (r=0.717,p=0.732),  time:37.737, tt:3245.413\n",
      "Ep:86, loss:0.00001, loss_test:0.01821, lr:4.14e-02, fs:0.73096 (r=0.727,p=0.735),  time:37.756, tt:3284.740\n",
      "Ep:87, loss:0.00001, loss_test:0.01824, lr:4.10e-02, fs:0.73469 (r=0.727,p=0.742),  time:37.760, tt:3322.907\n",
      "Ep:88, loss:0.00001, loss_test:0.01827, lr:4.05e-02, fs:0.72821 (r=0.717,p=0.740),  time:37.739, tt:3358.810\n",
      "Ep:89, loss:0.00001, loss_test:0.01830, lr:4.01e-02, fs:0.72821 (r=0.717,p=0.740),  time:37.735, tt:3396.185\n",
      "Ep:90, loss:0.00001, loss_test:0.01829, lr:3.97e-02, fs:0.72539 (r=0.707,p=0.745),  time:37.744, tt:3434.687\n",
      "Ep:91, loss:0.00001, loss_test:0.01836, lr:3.93e-02, fs:0.72539 (r=0.707,p=0.745),  time:37.741, tt:3472.199\n",
      "Ep:92, loss:0.00001, loss_test:0.01835, lr:3.89e-02, fs:0.72917 (r=0.707,p=0.753),  time:37.754, tt:3511.159\n",
      "Ep:93, loss:0.00001, loss_test:0.01844, lr:3.86e-02, fs:0.72917 (r=0.707,p=0.753),  time:37.753, tt:3548.762\n",
      "Ep:94, loss:0.00001, loss_test:0.01851, lr:3.82e-02, fs:0.72917 (r=0.707,p=0.753),  time:37.752, tt:3586.464\n",
      "Ep:95, loss:0.00001, loss_test:0.01852, lr:3.78e-02, fs:0.73298 (r=0.707,p=0.761),  time:37.764, tt:3625.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00001, loss_test:0.01852, lr:3.74e-02, fs:0.73298 (r=0.707,p=0.761),  time:37.774, tt:3664.066\n",
      "Ep:97, loss:0.00001, loss_test:0.01861, lr:3.70e-02, fs:0.73684 (r=0.707,p=0.769),  time:37.767, tt:3701.171\n",
      "Ep:98, loss:0.00001, loss_test:0.01865, lr:3.67e-02, fs:0.73684 (r=0.707,p=0.769),  time:37.759, tt:3738.098\n",
      "Ep:99, loss:0.00001, loss_test:0.01867, lr:3.63e-02, fs:0.73684 (r=0.707,p=0.769),  time:37.752, tt:3775.217\n",
      "Ep:100, loss:0.00001, loss_test:0.01869, lr:3.59e-02, fs:0.74468 (r=0.707,p=0.787),  time:37.750, tt:3812.740\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01876, lr:3.59e-02, fs:0.74468 (r=0.707,p=0.787),  time:37.763, tt:3851.866\n",
      "Ep:102, loss:0.00001, loss_test:0.01880, lr:3.59e-02, fs:0.74866 (r=0.707,p=0.795),  time:37.777, tt:3891.045\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.01885, lr:3.59e-02, fs:0.75269 (r=0.707,p=0.805),  time:37.780, tt:3929.158\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.01885, lr:3.59e-02, fs:0.75269 (r=0.707,p=0.805),  time:37.800, tt:3969.002\n",
      "Ep:105, loss:0.00001, loss_test:0.01889, lr:3.59e-02, fs:0.75269 (r=0.707,p=0.805),  time:37.811, tt:4007.953\n",
      "Ep:106, loss:0.00001, loss_test:0.01894, lr:3.59e-02, fs:0.75269 (r=0.707,p=0.805),  time:37.818, tt:4046.477\n",
      "Ep:107, loss:0.00001, loss_test:0.01898, lr:3.59e-02, fs:0.75676 (r=0.707,p=0.814),  time:37.822, tt:4084.796\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01902, lr:3.59e-02, fs:0.75676 (r=0.707,p=0.814),  time:37.841, tt:4124.644\n",
      "Ep:109, loss:0.00001, loss_test:0.01902, lr:3.59e-02, fs:0.75269 (r=0.707,p=0.805),  time:37.841, tt:4162.504\n",
      "Ep:110, loss:0.00001, loss_test:0.01910, lr:3.59e-02, fs:0.75676 (r=0.707,p=0.814),  time:37.833, tt:4199.494\n",
      "Ep:111, loss:0.00001, loss_test:0.01912, lr:3.59e-02, fs:0.75676 (r=0.707,p=0.814),  time:37.856, tt:4239.818\n",
      "Ep:112, loss:0.00001, loss_test:0.01917, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.854, tt:4277.508\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00001, loss_test:0.01923, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.869, tt:4317.086\n",
      "Ep:114, loss:0.00001, loss_test:0.01925, lr:3.59e-02, fs:0.75676 (r=0.707,p=0.814),  time:37.872, tt:4355.251\n",
      "Ep:115, loss:0.00001, loss_test:0.01927, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.889, tt:4395.111\n",
      "Ep:116, loss:0.00001, loss_test:0.01934, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.874, tt:4431.314\n",
      "Ep:117, loss:0.00001, loss_test:0.01941, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.895, tt:4471.561\n",
      "Ep:118, loss:0.00001, loss_test:0.01942, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.893, tt:4509.249\n",
      "Ep:119, loss:0.00001, loss_test:0.01947, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.907, tt:4548.835\n",
      "Ep:120, loss:0.00001, loss_test:0.01956, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.931, tt:4589.698\n",
      "Ep:121, loss:0.00001, loss_test:0.01959, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.947, tt:4629.593\n",
      "Ep:122, loss:0.00001, loss_test:0.01963, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.958, tt:4668.819\n",
      "Ep:123, loss:0.00000, loss_test:0.01965, lr:3.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.963, tt:4707.383\n",
      "Ep:124, loss:0.00000, loss_test:0.01973, lr:3.56e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.969, tt:4746.176\n",
      "Ep:125, loss:0.00000, loss_test:0.01979, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:37.979, tt:4785.416\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.01983, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:37.980, tt:4823.472\n",
      "Ep:127, loss:0.00000, loss_test:0.01981, lr:3.52e-02, fs:0.76087 (r=0.707,p=0.824),  time:37.981, tt:4861.558\n",
      "Ep:128, loss:0.00000, loss_test:0.01992, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:37.987, tt:4900.337\n",
      "Ep:129, loss:0.00000, loss_test:0.01999, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:37.976, tt:4936.846\n",
      "Ep:130, loss:0.00000, loss_test:0.01993, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:37.992, tt:4976.997\n",
      "Ep:131, loss:0.00000, loss_test:0.02001, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:38.007, tt:5016.877\n",
      "Ep:132, loss:0.00000, loss_test:0.02009, lr:3.52e-02, fs:0.76503 (r=0.707,p=0.833),  time:38.013, tt:5055.684\n",
      "Ep:133, loss:0.00000, loss_test:0.02015, lr:3.52e-02, fs:0.76243 (r=0.697,p=0.841),  time:38.004, tt:5092.575\n",
      "Ep:134, loss:0.00000, loss_test:0.02015, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.002, tt:5130.222\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00000, loss_test:0.02020, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.005, tt:5168.744\n",
      "Ep:136, loss:0.00000, loss_test:0.02028, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.004, tt:5206.488\n",
      "Ep:137, loss:0.00000, loss_test:0.02033, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.015, tt:5246.023\n",
      "Ep:138, loss:0.00000, loss_test:0.02036, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.022, tt:5285.037\n",
      "Ep:139, loss:0.00000, loss_test:0.02041, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.032, tt:5324.476\n",
      "Ep:140, loss:0.00000, loss_test:0.02044, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.037, tt:5363.156\n",
      "Ep:141, loss:0.00000, loss_test:0.02053, lr:3.52e-02, fs:0.76667 (r=0.697,p=0.852),  time:38.040, tt:5401.664\n",
      "Ep:142, loss:0.00000, loss_test:0.02051, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.035, tt:5439.034\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00000, loss_test:0.02059, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.026, tt:5475.808\n",
      "Ep:144, loss:0.00000, loss_test:0.02066, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.019, tt:5512.699\n",
      "Ep:145, loss:0.00000, loss_test:0.02070, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.030, tt:5552.351\n",
      "Ep:146, loss:0.00000, loss_test:0.02070, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.038, tt:5591.535\n",
      "Ep:147, loss:0.00000, loss_test:0.02084, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.059, tt:5632.773\n",
      "Ep:148, loss:0.00000, loss_test:0.02086, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.062, tt:5671.188\n",
      "Ep:149, loss:0.00000, loss_test:0.02083, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.050, tt:5707.497\n",
      "Ep:150, loss:0.00000, loss_test:0.02089, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.039, tt:5743.825\n",
      "Ep:151, loss:0.00000, loss_test:0.02093, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.037, tt:5781.579\n",
      "Ep:152, loss:0.00000, loss_test:0.02098, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.044, tt:5820.778\n",
      "Ep:153, loss:0.00000, loss_test:0.02102, lr:3.52e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.046, tt:5859.017\n",
      "Ep:154, loss:0.00000, loss_test:0.02106, lr:3.49e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.056, tt:5898.672\n",
      "Ep:155, loss:0.00000, loss_test:0.02109, lr:3.45e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.053, tt:5936.191\n",
      "Ep:156, loss:0.00000, loss_test:0.02116, lr:3.42e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.056, tt:5974.771\n",
      "Ep:157, loss:0.00000, loss_test:0.02125, lr:3.38e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.061, tt:6013.655\n",
      "Ep:158, loss:0.00000, loss_test:0.02123, lr:3.35e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.054, tt:6050.518\n",
      "Ep:159, loss:0.00000, loss_test:0.02134, lr:3.32e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.058, tt:6089.326\n",
      "Ep:160, loss:0.00000, loss_test:0.02135, lr:3.28e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.072, tt:6129.542\n",
      "Ep:161, loss:0.00000, loss_test:0.02135, lr:3.25e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.078, tt:6168.691\n",
      "Ep:162, loss:0.00000, loss_test:0.02150, lr:3.22e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.089, tt:6208.532\n",
      "Ep:163, loss:0.00000, loss_test:0.02154, lr:3.19e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.095, tt:6247.632\n",
      "Ep:164, loss:0.00000, loss_test:0.02148, lr:3.15e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.102, tt:6286.903\n",
      "Ep:165, loss:0.00000, loss_test:0.02152, lr:3.12e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.101, tt:6324.735\n",
      "Ep:166, loss:0.00000, loss_test:0.02166, lr:3.09e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.093, tt:6361.594\n",
      "Ep:167, loss:0.00000, loss_test:0.02165, lr:3.06e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.100, tt:6400.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00000, loss_test:0.02165, lr:3.03e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.106, tt:6439.993\n",
      "Ep:169, loss:0.00000, loss_test:0.02177, lr:3.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.103, tt:6477.469\n",
      "Ep:170, loss:0.00000, loss_test:0.02174, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.117, tt:6517.953\n",
      "##########Best model found so far##########\n",
      "Ep:171, loss:0.00000, loss_test:0.02180, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.127, tt:6557.874\n",
      "Ep:172, loss:0.00000, loss_test:0.02188, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.124, tt:6595.525\n",
      "Ep:173, loss:0.00000, loss_test:0.02188, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.124, tt:6633.569\n",
      "Ep:174, loss:0.00000, loss_test:0.02194, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.136, tt:6673.749\n",
      "Ep:175, loss:0.00000, loss_test:0.02202, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.144, tt:6713.304\n",
      "Ep:176, loss:0.00000, loss_test:0.02203, lr:2.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:38.160, tt:6754.316\n",
      "Ep:177, loss:0.00000, loss_test:0.02204, lr:2.97e-02, fs:0.77966 (r=0.697,p=0.885),  time:38.155, tt:6791.636\n",
      "##########Best model found so far##########\n",
      "Ep:178, loss:0.00000, loss_test:0.02216, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:38.158, tt:6830.236\n",
      "Ep:179, loss:0.00000, loss_test:0.02217, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:38.165, tt:6869.622\n",
      "Ep:180, loss:0.00000, loss_test:0.02221, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:38.164, tt:6907.685\n",
      "Ep:181, loss:0.00000, loss_test:0.02226, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:38.155, tt:6944.232\n",
      "Ep:182, loss:0.00000, loss_test:0.02231, lr:2.97e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.164, tt:6984.004\n",
      "Ep:183, loss:0.00000, loss_test:0.02225, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:38.166, tt:7022.473\n",
      "Ep:184, loss:0.00000, loss_test:0.02235, lr:2.97e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.170, tt:7061.471\n",
      "Ep:185, loss:0.00000, loss_test:0.02241, lr:2.97e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.174, tt:7100.370\n",
      "Ep:186, loss:0.00000, loss_test:0.02239, lr:2.97e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.165, tt:7136.925\n",
      "Ep:187, loss:0.00000, loss_test:0.02243, lr:2.97e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.166, tt:7175.172\n",
      "Ep:188, loss:0.00000, loss_test:0.02251, lr:2.97e-02, fs:0.75862 (r=0.667,p=0.880),  time:38.160, tt:7212.324\n",
      "Ep:189, loss:0.00000, loss_test:0.02255, lr:2.94e-02, fs:0.75862 (r=0.667,p=0.880),  time:38.161, tt:7250.518\n",
      "Ep:190, loss:0.00000, loss_test:0.02256, lr:2.91e-02, fs:0.75862 (r=0.667,p=0.880),  time:38.155, tt:7287.569\n",
      "Ep:191, loss:0.00000, loss_test:0.02267, lr:2.88e-02, fs:0.75145 (r=0.657,p=0.878),  time:38.148, tt:7324.445\n",
      "Ep:192, loss:0.00000, loss_test:0.02270, lr:2.85e-02, fs:0.75862 (r=0.667,p=0.880),  time:38.144, tt:7361.802\n",
      "Ep:193, loss:0.00000, loss_test:0.02272, lr:2.82e-02, fs:0.75862 (r=0.667,p=0.880),  time:38.148, tt:7400.765\n",
      "Ep:194, loss:0.00000, loss_test:0.02278, lr:2.80e-02, fs:0.75145 (r=0.657,p=0.878),  time:38.134, tt:7436.225\n",
      "Ep:195, loss:0.00000, loss_test:0.02275, lr:2.77e-02, fs:0.75145 (r=0.657,p=0.878),  time:38.133, tt:7473.989\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02693, lr:6.00e-02, fs:0.63492 (r=0.808,p=0.523),  time:24.874, tt:24.874\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02674, lr:6.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:29.393, tt:58.787\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02837, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.026, tt:93.079\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02881, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.925, tt:127.699\n",
      "Ep:4, loss:0.00005, loss_test:0.02819, lr:6.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:32.880, tt:164.401\n",
      "Ep:5, loss:0.00005, loss_test:0.02704, lr:6.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:33.076, tt:198.456\n",
      "Ep:6, loss:0.00005, loss_test:0.02595, lr:6.00e-02, fs:0.64945 (r=0.889,p=0.512),  time:33.379, tt:233.651\n",
      "Ep:7, loss:0.00005, loss_test:0.02556, lr:6.00e-02, fs:0.62879 (r=0.838,p=0.503),  time:33.677, tt:269.414\n",
      "Ep:8, loss:0.00004, loss_test:0.02598, lr:6.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:33.841, tt:304.573\n",
      "Ep:9, loss:0.00004, loss_test:0.02652, lr:6.00e-02, fs:0.62069 (r=0.727,p=0.541),  time:34.073, tt:340.727\n",
      "Ep:10, loss:0.00004, loss_test:0.02607, lr:6.00e-02, fs:0.59459 (r=0.667,p=0.537),  time:34.177, tt:375.945\n",
      "Ep:11, loss:0.00004, loss_test:0.02467, lr:6.00e-02, fs:0.60526 (r=0.697,p=0.535),  time:34.166, tt:409.994\n",
      "Ep:12, loss:0.00004, loss_test:0.02342, lr:6.00e-02, fs:0.61674 (r=0.707,p=0.547),  time:34.238, tt:445.097\n",
      "Ep:13, loss:0.00004, loss_test:0.02269, lr:6.00e-02, fs:0.63203 (r=0.737,p=0.553),  time:34.344, tt:480.816\n",
      "Ep:14, loss:0.00004, loss_test:0.02238, lr:5.94e-02, fs:0.62009 (r=0.717,p=0.546),  time:34.446, tt:516.683\n",
      "Ep:15, loss:0.00003, loss_test:0.02220, lr:5.88e-02, fs:0.61607 (r=0.697,p=0.552),  time:34.545, tt:552.727\n",
      "Ep:16, loss:0.00003, loss_test:0.02195, lr:5.82e-02, fs:0.62727 (r=0.697,p=0.570),  time:34.513, tt:586.726\n",
      "Ep:17, loss:0.00003, loss_test:0.02149, lr:5.76e-02, fs:0.63927 (r=0.707,p=0.583),  time:34.523, tt:621.417\n",
      "Ep:18, loss:0.00003, loss_test:0.02092, lr:5.71e-02, fs:0.63927 (r=0.707,p=0.583),  time:34.450, tt:654.544\n",
      "Ep:19, loss:0.00003, loss_test:0.02033, lr:5.65e-02, fs:0.65158 (r=0.727,p=0.590),  time:34.490, tt:689.791\n",
      "Ep:20, loss:0.00003, loss_test:0.01988, lr:5.59e-02, fs:0.65766 (r=0.737,p=0.593),  time:34.539, tt:725.309\n",
      "Ep:21, loss:0.00003, loss_test:0.01952, lr:5.54e-02, fs:0.66964 (r=0.758,p=0.600),  time:34.542, tt:759.914\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01928, lr:5.54e-02, fs:0.67265 (r=0.758,p=0.605),  time:34.477, tt:792.982\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01909, lr:5.54e-02, fs:0.70270 (r=0.788,p=0.634),  time:34.561, tt:829.467\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01886, lr:5.54e-02, fs:0.71233 (r=0.788,p=0.650),  time:34.568, tt:864.207\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01860, lr:5.54e-02, fs:0.68545 (r=0.737,p=0.640),  time:34.591, tt:899.362\n",
      "Ep:26, loss:0.00003, loss_test:0.01836, lr:5.54e-02, fs:0.68224 (r=0.737,p=0.635),  time:34.628, tt:934.966\n",
      "Ep:27, loss:0.00003, loss_test:0.01824, lr:5.54e-02, fs:0.70093 (r=0.758,p=0.652),  time:34.609, tt:969.062\n",
      "Ep:28, loss:0.00002, loss_test:0.01816, lr:5.54e-02, fs:0.70093 (r=0.758,p=0.652),  time:34.600, tt:1003.414\n",
      "Ep:29, loss:0.00002, loss_test:0.01816, lr:5.54e-02, fs:0.69159 (r=0.747,p=0.643),  time:34.592, tt:1037.770\n",
      "Ep:30, loss:0.00002, loss_test:0.01819, lr:5.54e-02, fs:0.69159 (r=0.747,p=0.643),  time:34.610, tt:1072.925\n",
      "Ep:31, loss:0.00002, loss_test:0.01827, lr:5.54e-02, fs:0.69767 (r=0.758,p=0.647),  time:34.644, tt:1108.616\n",
      "Ep:32, loss:0.00002, loss_test:0.01836, lr:5.54e-02, fs:0.69767 (r=0.758,p=0.647),  time:34.637, tt:1143.009\n",
      "Ep:33, loss:0.00002, loss_test:0.01838, lr:5.54e-02, fs:0.70093 (r=0.758,p=0.652),  time:34.593, tt:1176.173\n",
      "Ep:34, loss:0.00002, loss_test:0.01853, lr:5.54e-02, fs:0.70423 (r=0.758,p=0.658),  time:34.613, tt:1211.471\n",
      "Ep:35, loss:0.00002, loss_test:0.01864, lr:5.54e-02, fs:0.70423 (r=0.758,p=0.658),  time:34.587, tt:1245.122\n",
      "Ep:36, loss:0.00002, loss_test:0.01862, lr:5.48e-02, fs:0.71090 (r=0.758,p=0.670),  time:34.554, tt:1278.506\n",
      "Ep:37, loss:0.00002, loss_test:0.01867, lr:5.43e-02, fs:0.73934 (r=0.788,p=0.696),  time:34.519, tt:1311.722\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01865, lr:5.43e-02, fs:0.73684 (r=0.778,p=0.700),  time:34.521, tt:1346.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00002, loss_test:0.01863, lr:5.43e-02, fs:0.73684 (r=0.778,p=0.700),  time:34.533, tt:1381.312\n",
      "Ep:40, loss:0.00002, loss_test:0.01866, lr:5.43e-02, fs:0.74038 (r=0.778,p=0.706),  time:34.555, tt:1416.740\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01877, lr:5.43e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.606, tt:1453.464\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01871, lr:5.43e-02, fs:0.74396 (r=0.778,p=0.713),  time:34.613, tt:1488.352\n",
      "Ep:43, loss:0.00002, loss_test:0.01891, lr:5.43e-02, fs:0.74877 (r=0.768,p=0.731),  time:34.639, tt:1524.127\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01892, lr:5.43e-02, fs:0.74877 (r=0.768,p=0.731),  time:34.647, tt:1559.100\n",
      "Ep:45, loss:0.00001, loss_test:0.01910, lr:5.43e-02, fs:0.74877 (r=0.768,p=0.731),  time:34.651, tt:1593.931\n",
      "Ep:46, loss:0.00001, loss_test:0.01926, lr:5.43e-02, fs:0.75248 (r=0.768,p=0.738),  time:34.664, tt:1629.220\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01930, lr:5.43e-02, fs:0.76000 (r=0.768,p=0.752),  time:34.715, tt:1666.344\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01941, lr:5.43e-02, fs:0.76000 (r=0.768,p=0.752),  time:34.729, tt:1701.704\n",
      "Ep:49, loss:0.00001, loss_test:0.01947, lr:5.43e-02, fs:0.76382 (r=0.768,p=0.760),  time:34.747, tt:1737.333\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01921, lr:5.43e-02, fs:0.77612 (r=0.788,p=0.765),  time:34.766, tt:1773.067\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01941, lr:5.43e-02, fs:0.76617 (r=0.778,p=0.755),  time:34.786, tt:1808.862\n",
      "Ep:52, loss:0.00001, loss_test:0.01926, lr:5.43e-02, fs:0.77612 (r=0.788,p=0.765),  time:34.814, tt:1845.122\n",
      "Ep:53, loss:0.00001, loss_test:0.01927, lr:5.43e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.830, tt:1880.818\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01941, lr:5.43e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.838, tt:1916.106\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01942, lr:5.43e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.849, tt:1951.524\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01955, lr:5.43e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.857, tt:1986.872\n",
      "Ep:57, loss:0.00001, loss_test:0.01941, lr:5.43e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.866, tt:2022.203\n",
      "Ep:58, loss:0.00001, loss_test:0.01981, lr:5.43e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.883, tt:2058.117\n",
      "Ep:59, loss:0.00001, loss_test:0.01960, lr:5.43e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.870, tt:2092.212\n",
      "Ep:60, loss:0.00001, loss_test:0.01974, lr:5.43e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.859, tt:2126.389\n",
      "Ep:61, loss:0.00001, loss_test:0.01974, lr:5.43e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.872, tt:2162.080\n",
      "Ep:62, loss:0.00001, loss_test:0.01977, lr:5.43e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.882, tt:2197.546\n",
      "Ep:63, loss:0.00001, loss_test:0.02005, lr:5.43e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.891, tt:2233.018\n",
      "Ep:64, loss:0.00001, loss_test:0.01964, lr:5.43e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.912, tt:2269.307\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.02021, lr:5.43e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.908, tt:2303.955\n",
      "Ep:66, loss:0.00001, loss_test:0.01972, lr:5.43e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.924, tt:2339.923\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.02005, lr:5.43e-02, fs:0.79592 (r=0.788,p=0.804),  time:34.935, tt:2375.586\n",
      "Ep:68, loss:0.00001, loss_test:0.01991, lr:5.43e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.946, tt:2411.304\n",
      "Ep:69, loss:0.00001, loss_test:0.02022, lr:5.43e-02, fs:0.80000 (r=0.788,p=0.812),  time:34.957, tt:2447.011\n",
      "Ep:70, loss:0.00001, loss_test:0.02009, lr:5.43e-02, fs:0.80000 (r=0.788,p=0.812),  time:34.953, tt:2481.627\n",
      "Ep:71, loss:0.00001, loss_test:0.02050, lr:5.43e-02, fs:0.79381 (r=0.778,p=0.811),  time:34.964, tt:2517.438\n",
      "Ep:72, loss:0.00001, loss_test:0.02037, lr:5.43e-02, fs:0.80000 (r=0.788,p=0.812),  time:34.961, tt:2552.160\n",
      "Ep:73, loss:0.00001, loss_test:0.02045, lr:5.43e-02, fs:0.79381 (r=0.778,p=0.811),  time:34.963, tt:2587.231\n",
      "Ep:74, loss:0.00001, loss_test:0.02047, lr:5.43e-02, fs:0.79793 (r=0.778,p=0.819),  time:34.965, tt:2622.355\n",
      "Ep:75, loss:0.00001, loss_test:0.02040, lr:5.43e-02, fs:0.79793 (r=0.778,p=0.819),  time:34.951, tt:2656.302\n",
      "Ep:76, loss:0.00001, loss_test:0.02034, lr:5.43e-02, fs:0.79793 (r=0.778,p=0.819),  time:34.962, tt:2692.097\n",
      "Ep:77, loss:0.00001, loss_test:0.02078, lr:5.43e-02, fs:0.77249 (r=0.737,p=0.811),  time:34.989, tt:2729.171\n",
      "Ep:78, loss:0.00001, loss_test:0.02042, lr:5.37e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.017, tt:2766.354\n",
      "Ep:79, loss:0.00001, loss_test:0.02101, lr:5.32e-02, fs:0.77249 (r=0.737,p=0.811),  time:35.011, tt:2800.915\n",
      "Ep:80, loss:0.00001, loss_test:0.02068, lr:5.27e-02, fs:0.78534 (r=0.758,p=0.815),  time:35.017, tt:2836.382\n",
      "Ep:81, loss:0.00001, loss_test:0.02119, lr:5.21e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.042, tt:2873.433\n",
      "Ep:82, loss:0.00001, loss_test:0.02071, lr:5.16e-02, fs:0.78534 (r=0.758,p=0.815),  time:35.052, tt:2909.326\n",
      "Ep:83, loss:0.00001, loss_test:0.02131, lr:5.11e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.060, tt:2945.061\n",
      "Ep:84, loss:0.00001, loss_test:0.02094, lr:5.06e-02, fs:0.78307 (r=0.747,p=0.822),  time:35.080, tt:2981.812\n",
      "Ep:85, loss:0.00001, loss_test:0.02120, lr:5.01e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.082, tt:3017.028\n",
      "Ep:86, loss:0.00001, loss_test:0.02115, lr:4.96e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.098, tt:3053.567\n",
      "Ep:87, loss:0.00001, loss_test:0.02166, lr:4.91e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.088, tt:3087.731\n",
      "Ep:88, loss:0.00001, loss_test:0.02120, lr:4.86e-02, fs:0.78075 (r=0.737,p=0.830),  time:35.085, tt:3122.586\n",
      "Ep:89, loss:0.00001, loss_test:0.02174, lr:4.81e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.085, tt:3157.643\n",
      "Ep:90, loss:0.00001, loss_test:0.02136, lr:4.76e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.079, tt:3192.175\n",
      "Ep:91, loss:0.00001, loss_test:0.02186, lr:4.71e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.084, tt:3227.742\n",
      "Ep:92, loss:0.00001, loss_test:0.02173, lr:4.67e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.087, tt:3263.105\n",
      "Ep:93, loss:0.00001, loss_test:0.02198, lr:4.62e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.080, tt:3297.493\n",
      "Ep:94, loss:0.00001, loss_test:0.02208, lr:4.57e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.075, tt:3332.149\n",
      "Ep:95, loss:0.00001, loss_test:0.02187, lr:4.53e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.074, tt:3367.080\n",
      "Ep:96, loss:0.00001, loss_test:0.02231, lr:4.48e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.087, tt:3403.391\n",
      "Ep:97, loss:0.00001, loss_test:0.02173, lr:4.44e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.088, tt:3438.659\n",
      "Ep:98, loss:0.00001, loss_test:0.02274, lr:4.39e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.092, tt:3474.117\n",
      "Ep:99, loss:0.00001, loss_test:0.02180, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.103, tt:3510.300\n",
      "Ep:100, loss:0.00001, loss_test:0.02286, lr:4.31e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.092, tt:3544.337\n",
      "Ep:101, loss:0.00001, loss_test:0.02202, lr:4.26e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.096, tt:3579.840\n",
      "Ep:102, loss:0.00000, loss_test:0.02276, lr:4.22e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.107, tt:3615.970\n",
      "Ep:103, loss:0.00000, loss_test:0.02228, lr:4.18e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.108, tt:3651.253\n",
      "Ep:104, loss:0.00000, loss_test:0.02269, lr:4.14e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.113, tt:3686.889\n",
      "Ep:105, loss:0.00000, loss_test:0.02250, lr:4.10e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.107, tt:3721.336\n",
      "Ep:106, loss:0.00000, loss_test:0.02295, lr:4.05e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.125, tt:3758.343\n",
      "Ep:107, loss:0.00000, loss_test:0.02296, lr:4.01e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.120, tt:3792.925\n",
      "Ep:108, loss:0.00000, loss_test:0.02314, lr:3.97e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.113, tt:3827.293\n",
      "Ep:109, loss:0.00000, loss_test:0.02328, lr:3.93e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.116, tt:3862.707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:110, loss:0.00000, loss_test:0.02323, lr:3.89e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.134, tt:3899.902\n",
      "Ep:111, loss:0.00000, loss_test:0.02358, lr:3.86e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.148, tt:3936.542\n",
      "Ep:112, loss:0.00000, loss_test:0.02337, lr:3.82e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.153, tt:3972.345\n",
      "Ep:113, loss:0.00000, loss_test:0.02374, lr:3.78e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.151, tt:4007.266\n",
      "Ep:114, loss:0.00000, loss_test:0.02370, lr:3.74e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.161, tt:4043.510\n",
      "Ep:115, loss:0.00000, loss_test:0.02375, lr:3.70e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.184, tt:4081.329\n",
      "Ep:116, loss:0.00000, loss_test:0.02396, lr:3.67e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.189, tt:4117.148\n",
      "Ep:117, loss:0.00000, loss_test:0.02409, lr:3.63e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.193, tt:4152.763\n",
      "Ep:118, loss:0.00000, loss_test:0.02396, lr:3.59e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.204, tt:4189.279\n",
      "Ep:119, loss:0.00000, loss_test:0.02424, lr:3.56e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.218, tt:4226.150\n",
      "Ep:120, loss:0.00000, loss_test:0.02403, lr:3.52e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.222, tt:4261.834\n",
      "Ep:121, loss:0.00000, loss_test:0.02443, lr:3.49e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.234, tt:4298.581\n",
      "Ep:122, loss:0.00000, loss_test:0.02415, lr:3.45e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.244, tt:4335.020\n",
      "Ep:123, loss:0.00000, loss_test:0.02460, lr:3.42e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.253, tt:4371.392\n",
      "Ep:124, loss:0.00000, loss_test:0.02426, lr:3.38e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.264, tt:4408.059\n",
      "Ep:125, loss:0.00000, loss_test:0.02480, lr:3.35e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.264, tt:4443.286\n",
      "Ep:126, loss:0.00000, loss_test:0.02458, lr:3.32e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.264, tt:4478.498\n",
      "Ep:127, loss:0.00000, loss_test:0.02475, lr:3.28e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.273, tt:4514.884\n",
      "Ep:128, loss:0.00000, loss_test:0.02482, lr:3.25e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.268, tt:4549.558\n",
      "Ep:129, loss:0.00000, loss_test:0.02496, lr:3.22e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.256, tt:4583.246\n",
      "Ep:130, loss:0.00000, loss_test:0.02479, lr:3.19e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.253, tt:4618.080\n",
      "Ep:131, loss:0.00000, loss_test:0.02511, lr:3.15e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.252, tt:4653.317\n",
      "Ep:132, loss:0.00000, loss_test:0.02519, lr:3.12e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.254, tt:4688.818\n",
      "Ep:133, loss:0.00000, loss_test:0.02502, lr:3.09e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.263, tt:4725.262\n",
      "Ep:134, loss:0.00000, loss_test:0.02533, lr:3.06e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.264, tt:4760.705\n",
      "Ep:135, loss:0.00000, loss_test:0.02533, lr:3.03e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.267, tt:4796.302\n",
      "Ep:136, loss:0.00000, loss_test:0.02545, lr:3.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.270, tt:4832.058\n",
      "Ep:137, loss:0.00000, loss_test:0.02539, lr:2.97e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.267, tt:4866.856\n",
      "Ep:138, loss:0.00000, loss_test:0.02542, lr:2.94e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.273, tt:4902.937\n",
      "Ep:139, loss:0.00000, loss_test:0.02564, lr:2.91e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.282, tt:4939.473\n",
      "Ep:140, loss:0.00000, loss_test:0.02562, lr:2.88e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.284, tt:4975.040\n",
      "Ep:141, loss:0.00000, loss_test:0.02571, lr:2.85e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.275, tt:5009.110\n",
      "Ep:142, loss:0.00000, loss_test:0.02563, lr:2.82e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.278, tt:5044.765\n",
      "Ep:143, loss:0.00000, loss_test:0.02589, lr:2.80e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.277, tt:5079.848\n",
      "Ep:144, loss:0.00000, loss_test:0.02563, lr:2.77e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.262, tt:5112.992\n",
      "Ep:145, loss:0.00000, loss_test:0.02618, lr:2.74e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.257, tt:5147.503\n",
      "Ep:146, loss:0.00000, loss_test:0.02571, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.249, tt:5181.623\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00000, loss_test:0.02609, lr:2.71e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.236, tt:5214.950\n",
      "Ep:148, loss:0.00000, loss_test:0.02629, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.230, tt:5249.261\n",
      "Ep:149, loss:0.00000, loss_test:0.02598, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.237, tt:5285.624\n",
      "Ep:150, loss:0.00000, loss_test:0.02621, lr:2.71e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.245, tt:5322.011\n",
      "Ep:151, loss:0.00000, loss_test:0.02616, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.230, tt:5354.934\n",
      "Ep:152, loss:0.00000, loss_test:0.02639, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.211, tt:5387.257\n",
      "Ep:153, loss:0.00000, loss_test:0.02627, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.200, tt:5420.731\n",
      "Ep:154, loss:0.00000, loss_test:0.02646, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.194, tt:5455.083\n",
      "Ep:155, loss:0.00000, loss_test:0.02639, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.180, tt:5488.146\n",
      "Ep:156, loss:0.00000, loss_test:0.02664, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.165, tt:5520.886\n",
      "Ep:157, loss:0.00000, loss_test:0.02667, lr:2.71e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.162, tt:5555.670\n",
      "Ep:158, loss:0.00000, loss_test:0.02661, lr:2.69e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.162, tt:5590.778\n",
      "Ep:159, loss:0.00000, loss_test:0.02674, lr:2.66e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.156, tt:5624.955\n",
      "Ep:160, loss:0.00000, loss_test:0.02690, lr:2.63e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.148, tt:5658.805\n",
      "Ep:161, loss:0.00000, loss_test:0.02679, lr:2.61e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.130, tt:5691.069\n",
      "Ep:162, loss:0.00000, loss_test:0.02696, lr:2.58e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.127, tt:5725.744\n",
      "Ep:163, loss:0.00000, loss_test:0.02689, lr:2.55e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.132, tt:5761.615\n",
      "Ep:164, loss:0.00000, loss_test:0.02702, lr:2.53e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.126, tt:5795.774\n",
      "Ep:165, loss:0.00000, loss_test:0.02702, lr:2.50e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.118, tt:5829.525\n",
      "Ep:166, loss:0.00000, loss_test:0.02716, lr:2.48e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.107, tt:5862.898\n",
      "Ep:167, loss:0.00000, loss_test:0.02709, lr:2.45e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.103, tt:5897.381\n",
      "Ep:168, loss:0.00000, loss_test:0.02736, lr:2.43e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.093, tt:5930.716\n",
      "Ep:169, loss:0.00000, loss_test:0.02714, lr:2.40e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.076, tt:5962.879\n",
      "Ep:170, loss:0.00000, loss_test:0.02746, lr:2.38e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.068, tt:5996.559\n",
      "Ep:171, loss:0.00000, loss_test:0.02724, lr:2.36e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.062, tt:6030.658\n",
      "Ep:172, loss:0.00000, loss_test:0.02743, lr:2.33e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.060, tt:6065.431\n",
      "Ep:173, loss:0.00000, loss_test:0.02752, lr:2.31e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.050, tt:6098.706\n",
      "Ep:174, loss:0.00000, loss_test:0.02750, lr:2.29e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.045, tt:6132.877\n",
      "Ep:175, loss:0.00000, loss_test:0.02767, lr:2.26e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.031, tt:6165.379\n",
      "Ep:176, loss:0.00000, loss_test:0.02754, lr:2.24e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.020, tt:6198.606\n",
      "Ep:177, loss:0.00000, loss_test:0.02771, lr:2.22e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.003, tt:6230.518\n",
      "Ep:178, loss:0.00000, loss_test:0.02775, lr:2.20e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.990, tt:6263.261\n",
      "Ep:179, loss:0.00000, loss_test:0.02779, lr:2.17e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.980, tt:6296.489\n",
      "Ep:180, loss:0.00000, loss_test:0.02791, lr:2.15e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.969, tt:6329.368\n",
      "Ep:181, loss:0.00000, loss_test:0.02780, lr:2.13e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.963, tt:6363.290\n",
      "Ep:182, loss:0.00000, loss_test:0.02791, lr:2.11e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.957, tt:6397.087\n",
      "Ep:183, loss:0.00000, loss_test:0.02809, lr:2.09e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.951, tt:6431.002\n",
      "Ep:184, loss:0.00000, loss_test:0.02795, lr:2.07e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.933, tt:6462.642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:185, loss:0.00000, loss_test:0.02815, lr:2.05e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.926, tt:6496.201\n",
      "Ep:186, loss:0.00000, loss_test:0.02821, lr:2.03e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.918, tt:6529.620\n",
      "Ep:187, loss:0.00000, loss_test:0.02809, lr:2.01e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.908, tt:6562.755\n",
      "Ep:188, loss:0.00000, loss_test:0.02817, lr:1.99e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.927, tt:6601.271\n",
      "Ep:189, loss:0.00000, loss_test:0.02828, lr:1.97e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.921, tt:6635.032\n",
      "Ep:190, loss:0.00000, loss_test:0.02841, lr:1.95e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.913, tt:6668.432\n",
      "Ep:191, loss:0.00000, loss_test:0.02849, lr:1.93e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.912, tt:6703.075\n",
      "Ep:192, loss:0.00000, loss_test:0.02830, lr:1.91e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.898, tt:6735.377\n",
      "Ep:193, loss:0.00000, loss_test:0.02856, lr:1.89e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.897, tt:6770.056\n",
      "Ep:194, loss:0.00000, loss_test:0.02843, lr:1.87e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.891, tt:6803.833\n",
      "Ep:195, loss:0.00000, loss_test:0.02863, lr:1.85e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.853, tt:6831.257\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"8-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14613, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.081, tt:42.081\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14555, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.374, tt:86.747\n",
      "Ep:2, loss:0.00028, loss_test:0.14450, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.160, tt:138.479\n",
      "Ep:3, loss:0.00028, loss_test:0.14281, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.472, tt:189.889\n",
      "Ep:4, loss:0.00027, loss_test:0.13996, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.260, tt:241.300\n",
      "Ep:5, loss:0.00026, loss_test:0.13471, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:48.544, tt:291.266\n",
      "Ep:6, loss:0.00024, loss_test:0.12465, lr:1.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:48.869, tt:342.086\n",
      "Ep:7, loss:0.00022, loss_test:0.12047, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:49.473, tt:395.780\n",
      "Ep:8, loss:0.00021, loss_test:0.11596, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:49.812, tt:448.308\n",
      "Ep:9, loss:0.00020, loss_test:0.11449, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:50.206, tt:502.056\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11378, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:50.644, tt:557.080\n",
      "Ep:11, loss:0.00019, loss_test:0.11366, lr:1.00e-02, fs:0.63810 (r=0.677,p=0.604),  time:51.059, tt:612.706\n",
      "Ep:12, loss:0.00019, loss_test:0.10990, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:51.062, tt:663.802\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10924, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:51.117, tt:715.642\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10931, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:51.154, tt:767.304\n",
      "Ep:15, loss:0.00017, loss_test:0.10845, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:51.261, tt:820.180\n",
      "Ep:16, loss:0.00016, loss_test:0.10550, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:51.332, tt:872.636\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.10466, lr:1.00e-02, fs:0.68868 (r=0.737,p=0.646),  time:51.450, tt:926.097\n",
      "Ep:18, loss:0.00016, loss_test:0.10503, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:51.549, tt:979.437\n",
      "Ep:19, loss:0.00015, loss_test:0.10162, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:51.441, tt:1028.829\n",
      "Ep:20, loss:0.00015, loss_test:0.10200, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:51.484, tt:1081.173\n",
      "Ep:21, loss:0.00014, loss_test:0.10070, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:51.513, tt:1133.275\n",
      "Ep:22, loss:0.00014, loss_test:0.09866, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:51.539, tt:1185.391\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09858, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:51.476, tt:1235.420\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.09725, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:51.463, tt:1286.565\n",
      "Ep:25, loss:0.00013, loss_test:0.09519, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:51.515, tt:1339.399\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.09512, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:51.491, tt:1390.266\n",
      "Ep:27, loss:0.00012, loss_test:0.09255, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:51.468, tt:1441.117\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.09498, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:51.447, tt:1491.960\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.09030, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:51.444, tt:1543.329\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.09181, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:51.571, tt:1598.690\n",
      "Ep:31, loss:0.00010, loss_test:0.09339, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:51.645, tt:1652.653\n",
      "Ep:32, loss:0.00010, loss_test:0.08928, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:51.652, tt:1704.510\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.09188, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:51.617, tt:1754.981\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.09171, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:51.592, tt:1805.717\n",
      "Ep:35, loss:0.00009, loss_test:0.08679, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:51.580, tt:1856.880\n",
      "Ep:36, loss:0.00009, loss_test:0.08792, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:51.589, tt:1908.801\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.08991, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:51.590, tt:1960.424\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.08585, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:51.571, tt:2011.263\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.09671, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:51.587, tt:2063.495\n",
      "Ep:40, loss:0.00008, loss_test:0.08715, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:51.592, tt:2115.284\n",
      "Ep:41, loss:0.00007, loss_test:0.08684, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:51.577, tt:2166.246\n",
      "Ep:42, loss:0.00007, loss_test:0.09381, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:51.629, tt:2220.026\n",
      "Ep:43, loss:0.00007, loss_test:0.08379, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:51.608, tt:2270.765\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.08932, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:51.603, tt:2322.124\n",
      "Ep:45, loss:0.00006, loss_test:0.09488, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:51.644, tt:2375.627\n",
      "Ep:46, loss:0.00006, loss_test:0.09455, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:51.640, tt:2427.066\n",
      "Ep:47, loss:0.00006, loss_test:0.08259, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:51.621, tt:2477.824\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.09308, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:51.618, tt:2529.291\n",
      "Ep:49, loss:0.00006, loss_test:0.09657, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:51.585, tt:2579.240\n",
      "Ep:50, loss:0.00005, loss_test:0.08744, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:51.584, tt:2630.800\n",
      "Ep:51, loss:0.00005, loss_test:0.08855, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:51.581, tt:2682.213\n",
      "Ep:52, loss:0.00005, loss_test:0.09282, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:51.587, tt:2734.102\n",
      "Ep:53, loss:0.00004, loss_test:0.08334, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:51.606, tt:2786.751\n",
      "Ep:54, loss:0.00005, loss_test:0.09071, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:51.571, tt:2836.426\n",
      "Ep:55, loss:0.00004, loss_test:0.09542, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:51.595, tt:2889.341\n",
      "Ep:56, loss:0.00004, loss_test:0.08828, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:51.574, tt:2939.713\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.08384, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:51.588, tt:2992.110\n",
      "Ep:58, loss:0.00004, loss_test:0.08997, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:51.619, tt:3045.507\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00004, loss_test:0.08681, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:51.606, tt:3096.366\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.08834, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:51.610, tt:3148.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.08297, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:51.623, tt:3200.629\n",
      "Ep:62, loss:0.00003, loss_test:0.09044, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:51.634, tt:3252.944\n",
      "Ep:63, loss:0.00003, loss_test:0.10204, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:51.655, tt:3305.900\n",
      "Ep:64, loss:0.00003, loss_test:0.08231, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:51.652, tt:3357.352\n",
      "Ep:65, loss:0.00003, loss_test:0.10054, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:51.628, tt:3407.460\n",
      "Ep:66, loss:0.00003, loss_test:0.09303, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:51.632, tt:3459.323\n",
      "Ep:67, loss:0.00003, loss_test:0.08886, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:51.640, tt:3511.487\n",
      "Ep:68, loss:0.00003, loss_test:0.09656, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:51.643, tt:3563.395\n",
      "Ep:69, loss:0.00003, loss_test:0.08538, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:51.668, tt:3616.730\n",
      "Ep:70, loss:0.00003, loss_test:0.09333, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:51.661, tt:3667.954\n",
      "Ep:71, loss:0.00003, loss_test:0.09491, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:51.697, tt:3722.161\n",
      "Ep:72, loss:0.00002, loss_test:0.08728, lr:9.80e-03, fs:0.81564 (r=0.737,p=0.912),  time:51.689, tt:3773.290\n",
      "Ep:73, loss:0.00002, loss_test:0.09402, lr:9.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:51.699, tt:3825.730\n",
      "Ep:74, loss:0.00002, loss_test:0.08641, lr:9.61e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.699, tt:3877.454\n",
      "Ep:75, loss:0.00002, loss_test:0.09212, lr:9.51e-03, fs:0.72956 (r=0.586,p=0.967),  time:51.724, tt:3930.992\n",
      "Ep:76, loss:0.00002, loss_test:0.09261, lr:9.41e-03, fs:0.79310 (r=0.697,p=0.920),  time:51.738, tt:3983.819\n",
      "Ep:77, loss:0.00002, loss_test:0.09297, lr:9.32e-03, fs:0.79290 (r=0.677,p=0.957),  time:51.730, tt:4034.971\n",
      "Ep:78, loss:0.00002, loss_test:0.08569, lr:9.23e-03, fs:0.82022 (r=0.737,p=0.924),  time:51.722, tt:4086.058\n",
      "Ep:79, loss:0.00002, loss_test:0.10101, lr:9.14e-03, fs:0.72050 (r=0.586,p=0.935),  time:51.727, tt:4138.141\n",
      "Ep:80, loss:0.00002, loss_test:0.08581, lr:9.04e-03, fs:0.82955 (r=0.737,p=0.948),  time:51.746, tt:4191.404\n",
      "Ep:81, loss:0.00002, loss_test:0.09822, lr:8.95e-03, fs:0.75904 (r=0.636,p=0.940),  time:51.756, tt:4243.966\n",
      "Ep:82, loss:0.00002, loss_test:0.08755, lr:8.86e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.758, tt:4295.931\n",
      "Ep:83, loss:0.00002, loss_test:0.09148, lr:8.78e-03, fs:0.74074 (r=0.606,p=0.952),  time:51.754, tt:4347.368\n",
      "Ep:84, loss:0.00001, loss_test:0.08810, lr:8.69e-03, fs:0.81564 (r=0.737,p=0.912),  time:51.760, tt:4399.607\n",
      "Ep:85, loss:0.00001, loss_test:0.09542, lr:8.60e-03, fs:0.73292 (r=0.596,p=0.952),  time:51.759, tt:4451.255\n",
      "Ep:86, loss:0.00001, loss_test:0.08856, lr:8.51e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.761, tt:4503.201\n",
      "Ep:87, loss:0.00001, loss_test:0.08910, lr:8.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.745, tt:4553.590\n",
      "Ep:88, loss:0.00001, loss_test:0.09193, lr:8.35e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.763, tt:4606.948\n",
      "Ep:89, loss:0.00001, loss_test:0.08257, lr:8.26e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.771, tt:4659.420\n",
      "Ep:90, loss:0.00001, loss_test:0.08998, lr:8.18e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.761, tt:4710.244\n",
      "Ep:91, loss:0.00001, loss_test:0.08428, lr:8.10e-03, fs:0.82955 (r=0.737,p=0.948),  time:51.767, tt:4762.582\n",
      "Ep:92, loss:0.00001, loss_test:0.08879, lr:8.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.776, tt:4815.187\n",
      "Ep:93, loss:0.00001, loss_test:0.08670, lr:7.94e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.781, tt:4867.374\n",
      "Ep:94, loss:0.00001, loss_test:0.08735, lr:7.86e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.772, tt:4918.376\n",
      "Ep:95, loss:0.00001, loss_test:0.08593, lr:7.78e-03, fs:0.82081 (r=0.717,p=0.959),  time:51.786, tt:4971.444\n",
      "Ep:96, loss:0.00001, loss_test:0.09202, lr:7.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.775, tt:5022.219\n",
      "Ep:97, loss:0.00001, loss_test:0.08742, lr:7.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.797, tt:5076.077\n",
      "Ep:98, loss:0.00001, loss_test:0.09126, lr:7.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:51.806, tt:5128.766\n",
      "Ep:99, loss:0.00001, loss_test:0.08786, lr:7.47e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.800, tt:5180.026\n",
      "Ep:100, loss:0.00001, loss_test:0.08857, lr:7.40e-03, fs:0.80233 (r=0.697,p=0.945),  time:51.791, tt:5230.873\n",
      "Ep:101, loss:0.00001, loss_test:0.08624, lr:7.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.792, tt:5282.817\n",
      "Ep:102, loss:0.00001, loss_test:0.09218, lr:7.25e-03, fs:0.81176 (r=0.697,p=0.972),  time:51.803, tt:5335.670\n",
      "Ep:103, loss:0.00001, loss_test:0.08853, lr:7.18e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.837, tt:5391.043\n",
      "Ep:104, loss:0.00001, loss_test:0.08732, lr:7.11e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.837, tt:5442.875\n",
      "Ep:105, loss:0.00000, loss_test:0.09049, lr:7.03e-03, fs:0.81176 (r=0.697,p=0.972),  time:51.828, tt:5493.810\n",
      "Ep:106, loss:0.00000, loss_test:0.08696, lr:6.96e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.833, tt:5546.162\n",
      "Ep:107, loss:0.00000, loss_test:0.09120, lr:6.89e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.842, tt:5598.901\n",
      "Ep:108, loss:0.00000, loss_test:0.08732, lr:6.83e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.868, tt:5653.634\n",
      "Ep:109, loss:0.00000, loss_test:0.08960, lr:6.76e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.865, tt:5705.158\n",
      "Ep:110, loss:0.00000, loss_test:0.08956, lr:6.69e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.870, tt:5757.540\n",
      "Ep:111, loss:0.00000, loss_test:0.08760, lr:6.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.880, tt:5810.554\n",
      "Ep:112, loss:0.00000, loss_test:0.08955, lr:6.56e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.877, tt:5862.105\n",
      "Ep:113, loss:0.00000, loss_test:0.08897, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.865, tt:5912.606\n",
      "Ep:114, loss:0.00000, loss_test:0.08857, lr:6.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.868, tt:5964.860\n",
      "Ep:115, loss:0.00000, loss_test:0.09007, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.870, tt:6016.872\n",
      "Ep:116, loss:0.00000, loss_test:0.08899, lr:6.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.881, tt:6070.107\n",
      "Ep:117, loss:0.00000, loss_test:0.08788, lr:6.24e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.875, tt:6121.286\n",
      "Ep:118, loss:0.00000, loss_test:0.08751, lr:6.17e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.875, tt:6173.069\n",
      "Ep:119, loss:0.00000, loss_test:0.08850, lr:6.11e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.877, tt:6225.243\n",
      "Ep:120, loss:0.00000, loss_test:0.08843, lr:6.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.876, tt:6276.991\n",
      "Ep:121, loss:0.00000, loss_test:0.08876, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.895, tt:6331.247\n",
      "Ep:122, loss:0.00000, loss_test:0.09066, lr:5.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.882, tt:6381.516\n",
      "Ep:123, loss:0.00000, loss_test:0.08989, lr:5.87e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.875, tt:6432.454\n",
      "Ep:124, loss:0.00000, loss_test:0.08627, lr:5.81e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.874, tt:6484.277\n",
      "Ep:125, loss:0.00000, loss_test:0.08769, lr:5.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.860, tt:6534.334\n",
      "Ep:126, loss:0.00000, loss_test:0.08842, lr:5.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.851, tt:6585.047\n",
      "Ep:127, loss:0.00000, loss_test:0.08791, lr:5.64e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.860, tt:6638.028\n",
      "Ep:128, loss:0.00000, loss_test:0.08867, lr:5.58e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.860, tt:6689.885\n",
      "Ep:129, loss:0.00000, loss_test:0.08647, lr:5.53e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.897, tt:6746.633\n",
      "Ep:130, loss:0.00000, loss_test:0.08808, lr:5.47e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.923, tt:6801.970\n",
      "Ep:131, loss:0.00000, loss_test:0.08709, lr:5.42e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.953, tt:6857.781\n",
      "Ep:132, loss:0.00000, loss_test:0.08800, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.973, tt:6912.379\n",
      "Ep:133, loss:0.00000, loss_test:0.08921, lr:5.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.978, tt:6965.070\n",
      "Ep:134, loss:0.00000, loss_test:0.09020, lr:5.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.003, tt:7020.350\n",
      "Ep:135, loss:0.00000, loss_test:0.08762, lr:5.20e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.014, tt:7073.837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.08932, lr:5.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.032, tt:7128.427\n",
      "Ep:137, loss:0.00000, loss_test:0.08821, lr:5.10e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.051, tt:7183.078\n",
      "Ep:138, loss:0.00000, loss_test:0.09023, lr:5.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.071, tt:7237.905\n",
      "Ep:139, loss:0.00000, loss_test:0.08932, lr:5.00e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.075, tt:7290.432\n",
      "Ep:140, loss:0.00000, loss_test:0.08836, lr:4.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.097, tt:7345.629\n",
      "Ep:141, loss:0.00000, loss_test:0.08949, lr:4.90e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.096, tt:7397.686\n",
      "Ep:142, loss:0.00000, loss_test:0.08754, lr:4.85e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.100, tt:7450.362\n",
      "Ep:143, loss:0.00000, loss_test:0.09066, lr:4.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.123, tt:7505.778\n",
      "Ep:144, loss:0.00000, loss_test:0.09052, lr:4.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.129, tt:7558.699\n",
      "Ep:145, loss:0.00000, loss_test:0.08747, lr:4.71e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.141, tt:7612.594\n",
      "Ep:146, loss:0.00000, loss_test:0.08956, lr:4.66e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.144, tt:7665.113\n",
      "Ep:147, loss:0.00000, loss_test:0.08983, lr:4.61e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.140, tt:7716.664\n",
      "Ep:148, loss:0.00000, loss_test:0.08846, lr:4.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.136, tt:7768.271\n",
      "Ep:149, loss:0.00000, loss_test:0.08818, lr:4.52e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.143, tt:7821.507\n",
      "Ep:150, loss:0.00000, loss_test:0.08518, lr:4.48e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.138, tt:7872.898\n",
      "Ep:151, loss:0.00000, loss_test:0.08804, lr:4.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.144, tt:7925.850\n",
      "Ep:152, loss:0.00000, loss_test:0.08887, lr:4.39e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.147, tt:7978.529\n",
      "Ep:153, loss:0.00000, loss_test:0.08711, lr:4.34e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.165, tt:8033.458\n",
      "Ep:154, loss:0.00000, loss_test:0.08847, lr:4.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.166, tt:8085.798\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14341, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.785, tt:49.785\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14236, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.360, tt:92.720\n",
      "Ep:2, loss:0.00028, loss_test:0.14054, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.817, tt:143.452\n",
      "Ep:3, loss:0.00028, loss_test:0.13762, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.944, tt:195.777\n",
      "Ep:4, loss:0.00027, loss_test:0.13250, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:50.036, tt:250.180\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12285, lr:1.00e-02, fs:0.68531 (r=0.990,p=0.524),  time:50.626, tt:303.759\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10794, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:50.932, tt:356.522\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10344, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:51.087, tt:408.698\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10181, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:51.286, tt:461.576\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10107, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:51.729, tt:517.293\n",
      "Ep:10, loss:0.00020, loss_test:0.09686, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:51.994, tt:571.936\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09484, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:52.010, tt:624.125\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09513, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:52.060, tt:676.778\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09167, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:52.234, tt:731.280\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08945, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:52.332, tt:784.983\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09095, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:52.470, tt:839.514\n",
      "Ep:16, loss:0.00016, loss_test:0.08831, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:52.511, tt:892.681\n",
      "Ep:17, loss:0.00016, loss_test:0.08749, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:52.543, tt:945.776\n",
      "Ep:18, loss:0.00015, loss_test:0.08775, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:52.699, tt:1001.288\n",
      "Ep:19, loss:0.00015, loss_test:0.08556, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:52.718, tt:1054.356\n",
      "Ep:20, loss:0.00015, loss_test:0.08488, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:52.738, tt:1107.499\n",
      "Ep:21, loss:0.00014, loss_test:0.08479, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:52.541, tt:1155.903\n",
      "Ep:22, loss:0.00014, loss_test:0.08463, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:52.613, tt:1210.098\n",
      "Ep:23, loss:0.00013, loss_test:0.08478, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:52.449, tt:1258.785\n",
      "Ep:24, loss:0.00013, loss_test:0.08342, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:52.446, tt:1311.158\n",
      "Ep:25, loss:0.00013, loss_test:0.08223, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:52.414, tt:1362.772\n",
      "Ep:26, loss:0.00012, loss_test:0.08107, lr:9.90e-03, fs:0.80788 (r=0.828,p=0.788),  time:52.443, tt:1415.963\n",
      "Ep:27, loss:0.00012, loss_test:0.08171, lr:9.80e-03, fs:0.80000 (r=0.788,p=0.812),  time:52.527, tt:1470.761\n",
      "Ep:28, loss:0.00011, loss_test:0.08067, lr:9.70e-03, fs:0.80597 (r=0.818,p=0.794),  time:52.537, tt:1523.586\n",
      "Ep:29, loss:0.00011, loss_test:0.08133, lr:9.61e-03, fs:0.81026 (r=0.798,p=0.823),  time:52.504, tt:1575.134\n",
      "Ep:30, loss:0.00011, loss_test:0.08131, lr:9.51e-03, fs:0.81633 (r=0.808,p=0.825),  time:52.520, tt:1628.132\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.07932, lr:9.51e-03, fs:0.81026 (r=0.798,p=0.823),  time:52.503, tt:1680.108\n",
      "Ep:32, loss:0.00010, loss_test:0.08432, lr:9.51e-03, fs:0.80214 (r=0.758,p=0.852),  time:52.523, tt:1733.256\n",
      "Ep:33, loss:0.00010, loss_test:0.07867, lr:9.51e-03, fs:0.81905 (r=0.869,p=0.775),  time:52.678, tt:1791.043\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.08420, lr:9.51e-03, fs:0.80214 (r=0.758,p=0.852),  time:52.795, tt:1847.815\n",
      "Ep:35, loss:0.00009, loss_test:0.08045, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:52.820, tt:1901.502\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07923, lr:9.51e-03, fs:0.81188 (r=0.828,p=0.796),  time:52.833, tt:1954.806\n",
      "Ep:37, loss:0.00009, loss_test:0.08224, lr:9.51e-03, fs:0.82353 (r=0.848,p=0.800),  time:52.831, tt:2007.582\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07679, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:52.831, tt:2060.418\n",
      "Ep:39, loss:0.00008, loss_test:0.09263, lr:9.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:52.920, tt:2116.809\n",
      "Ep:40, loss:0.00008, loss_test:0.07878, lr:9.51e-03, fs:0.80751 (r=0.869,p=0.754),  time:52.979, tt:2172.122\n",
      "Ep:41, loss:0.00008, loss_test:0.08587, lr:9.51e-03, fs:0.82353 (r=0.778,p=0.875),  time:53.079, tt:2229.328\n",
      "Ep:42, loss:0.00007, loss_test:0.07769, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:53.167, tt:2286.171\n",
      "Ep:43, loss:0.00007, loss_test:0.08753, lr:9.51e-03, fs:0.78756 (r=0.768,p=0.809),  time:53.173, tt:2339.623\n",
      "Ep:44, loss:0.00007, loss_test:0.07712, lr:9.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:53.170, tt:2392.641\n",
      "Ep:45, loss:0.00007, loss_test:0.08504, lr:9.51e-03, fs:0.83243 (r=0.778,p=0.895),  time:53.123, tt:2443.640\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00006, loss_test:0.07955, lr:9.51e-03, fs:0.80612 (r=0.798,p=0.814),  time:53.125, tt:2496.852\n",
      "Ep:47, loss:0.00006, loss_test:0.08430, lr:9.51e-03, fs:0.81283 (r=0.768,p=0.864),  time:53.133, tt:2550.395\n",
      "Ep:48, loss:0.00006, loss_test:0.08469, lr:9.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:53.103, tt:2602.063\n",
      "Ep:49, loss:0.00005, loss_test:0.08175, lr:9.51e-03, fs:0.80214 (r=0.758,p=0.852),  time:53.120, tt:2656.015\n",
      "Ep:50, loss:0.00005, loss_test:0.09181, lr:9.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:53.123, tt:2709.274\n",
      "Ep:51, loss:0.00005, loss_test:0.07900, lr:9.51e-03, fs:0.78392 (r=0.788,p=0.780),  time:53.156, tt:2764.098\n",
      "Ep:52, loss:0.00006, loss_test:0.09170, lr:9.51e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.201, tt:2819.677\n",
      "Ep:53, loss:0.00005, loss_test:0.08137, lr:9.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:53.202, tt:2872.895\n",
      "Ep:54, loss:0.00005, loss_test:0.09601, lr:9.51e-03, fs:0.82222 (r=0.747,p=0.914),  time:53.205, tt:2926.271\n",
      "Ep:55, loss:0.00004, loss_test:0.08274, lr:9.51e-03, fs:0.80423 (r=0.768,p=0.844),  time:53.184, tt:2978.303\n",
      "Ep:56, loss:0.00004, loss_test:0.09290, lr:9.51e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.158, tt:3029.988\n",
      "Ep:57, loss:0.00004, loss_test:0.08369, lr:9.41e-03, fs:0.80423 (r=0.768,p=0.844),  time:53.166, tt:3083.624\n",
      "Ep:58, loss:0.00004, loss_test:0.09319, lr:9.32e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.178, tt:3137.500\n",
      "Ep:59, loss:0.00004, loss_test:0.08395, lr:9.23e-03, fs:0.80645 (r=0.758,p=0.862),  time:53.200, tt:3191.996\n",
      "Ep:60, loss:0.00004, loss_test:0.09171, lr:9.14e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.181, tt:3244.067\n",
      "Ep:61, loss:0.00004, loss_test:0.08707, lr:9.04e-03, fs:0.79787 (r=0.758,p=0.843),  time:53.175, tt:3296.830\n",
      "Ep:62, loss:0.00003, loss_test:0.09288, lr:8.95e-03, fs:0.81768 (r=0.747,p=0.902),  time:53.173, tt:3349.881\n",
      "Ep:63, loss:0.00003, loss_test:0.08581, lr:8.86e-03, fs:0.80645 (r=0.758,p=0.862),  time:53.184, tt:3403.800\n",
      "Ep:64, loss:0.00003, loss_test:0.09268, lr:8.78e-03, fs:0.80435 (r=0.747,p=0.871),  time:53.206, tt:3458.408\n",
      "Ep:65, loss:0.00003, loss_test:0.09021, lr:8.69e-03, fs:0.81522 (r=0.758,p=0.882),  time:53.193, tt:3510.723\n",
      "Ep:66, loss:0.00003, loss_test:0.09308, lr:8.60e-03, fs:0.80874 (r=0.747,p=0.881),  time:53.190, tt:3563.737\n",
      "Ep:67, loss:0.00003, loss_test:0.09073, lr:8.51e-03, fs:0.82418 (r=0.758,p=0.904),  time:53.197, tt:3617.397\n",
      "Ep:68, loss:0.00003, loss_test:0.09436, lr:8.43e-03, fs:0.82222 (r=0.747,p=0.914),  time:53.187, tt:3669.888\n",
      "Ep:69, loss:0.00003, loss_test:0.09176, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:53.139, tt:3719.707\n",
      "Ep:70, loss:0.00002, loss_test:0.09823, lr:8.26e-03, fs:0.82486 (r=0.737,p=0.936),  time:53.110, tt:3770.799\n",
      "Ep:71, loss:0.00003, loss_test:0.09006, lr:8.18e-03, fs:0.80645 (r=0.758,p=0.862),  time:53.090, tt:3822.470\n",
      "Ep:72, loss:0.00003, loss_test:0.09962, lr:8.10e-03, fs:0.84091 (r=0.747,p=0.961),  time:53.100, tt:3876.306\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.09344, lr:8.10e-03, fs:0.82873 (r=0.758,p=0.915),  time:53.098, tt:3929.277\n",
      "Ep:74, loss:0.00002, loss_test:0.09509, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.107, tt:3983.009\n",
      "Ep:75, loss:0.00002, loss_test:0.09440, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:53.133, tt:4038.070\n",
      "Ep:76, loss:0.00002, loss_test:0.09277, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.090, tt:4087.915\n",
      "Ep:77, loss:0.00002, loss_test:0.09421, lr:8.10e-03, fs:0.81564 (r=0.737,p=0.912),  time:53.106, tt:4142.250\n",
      "Ep:78, loss:0.00002, loss_test:0.09637, lr:8.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.097, tt:4194.641\n",
      "Ep:79, loss:0.00002, loss_test:0.09609, lr:8.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.106, tt:4248.461\n",
      "Ep:80, loss:0.00002, loss_test:0.09104, lr:8.10e-03, fs:0.82609 (r=0.768,p=0.894),  time:53.111, tt:4301.972\n",
      "Ep:81, loss:0.00002, loss_test:0.10282, lr:8.10e-03, fs:0.82682 (r=0.747,p=0.925),  time:53.087, tt:4353.125\n",
      "Ep:82, loss:0.00002, loss_test:0.09514, lr:8.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.026, tt:4401.158\n",
      "Ep:83, loss:0.00002, loss_test:0.09674, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:52.954, tt:4448.172\n",
      "Ep:84, loss:0.00002, loss_test:0.10139, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.876, tt:4494.475\n",
      "Ep:85, loss:0.00002, loss_test:0.09731, lr:7.94e-03, fs:0.81768 (r=0.747,p=0.902),  time:52.814, tt:4542.023\n",
      "Ep:86, loss:0.00002, loss_test:0.09365, lr:7.86e-03, fs:0.81768 (r=0.747,p=0.902),  time:52.791, tt:4592.859\n",
      "Ep:87, loss:0.00001, loss_test:0.09759, lr:7.78e-03, fs:0.82022 (r=0.737,p=0.924),  time:52.783, tt:4644.894\n",
      "Ep:88, loss:0.00001, loss_test:0.09638, lr:7.70e-03, fs:0.80447 (r=0.727,p=0.900),  time:52.803, tt:4699.494\n",
      "Ep:89, loss:0.00001, loss_test:0.09676, lr:7.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:52.806, tt:4752.534\n",
      "Ep:90, loss:0.00001, loss_test:0.09303, lr:7.55e-03, fs:0.80447 (r=0.727,p=0.900),  time:52.791, tt:4803.953\n",
      "Ep:91, loss:0.00001, loss_test:0.10187, lr:7.47e-03, fs:0.82022 (r=0.737,p=0.924),  time:52.814, tt:4858.865\n",
      "Ep:92, loss:0.00001, loss_test:0.09307, lr:7.40e-03, fs:0.81111 (r=0.737,p=0.901),  time:52.810, tt:4911.315\n",
      "Ep:93, loss:0.00001, loss_test:0.10044, lr:7.32e-03, fs:0.83616 (r=0.747,p=0.949),  time:52.797, tt:4962.891\n",
      "Ep:94, loss:0.00001, loss_test:0.09815, lr:7.25e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.781, tt:5014.198\n",
      "Ep:95, loss:0.00001, loss_test:0.09377, lr:7.18e-03, fs:0.81111 (r=0.737,p=0.901),  time:52.779, tt:5066.751\n",
      "Ep:96, loss:0.00001, loss_test:0.09844, lr:7.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.758, tt:5117.572\n",
      "Ep:97, loss:0.00001, loss_test:0.09650, lr:7.03e-03, fs:0.80899 (r=0.727,p=0.911),  time:52.749, tt:5169.436\n",
      "Ep:98, loss:0.00001, loss_test:0.09886, lr:6.96e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.746, tt:5221.816\n",
      "Ep:99, loss:0.00001, loss_test:0.09596, lr:6.89e-03, fs:0.80460 (r=0.707,p=0.933),  time:52.749, tt:5274.912\n",
      "Ep:100, loss:0.00001, loss_test:0.09683, lr:6.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.729, tt:5325.624\n",
      "Ep:101, loss:0.00001, loss_test:0.09591, lr:6.76e-03, fs:0.79775 (r=0.717,p=0.899),  time:52.719, tt:5377.356\n",
      "Ep:102, loss:0.00001, loss_test:0.09894, lr:6.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.709, tt:5429.047\n",
      "Ep:103, loss:0.00001, loss_test:0.09611, lr:6.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.709, tt:5481.727\n",
      "Ep:104, loss:0.00001, loss_test:0.09806, lr:6.56e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.705, tt:5534.033\n",
      "Ep:105, loss:0.00001, loss_test:0.09712, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.689, tt:5585.045\n",
      "Ep:106, loss:0.00001, loss_test:0.09577, lr:6.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.692, tt:5638.074\n",
      "Ep:107, loss:0.00001, loss_test:0.09971, lr:6.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.680, tt:5689.479\n",
      "Ep:108, loss:0.00001, loss_test:0.09415, lr:6.30e-03, fs:0.81143 (r=0.717,p=0.934),  time:52.693, tt:5743.560\n",
      "Ep:109, loss:0.00001, loss_test:0.10263, lr:6.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.677, tt:5794.502\n",
      "Ep:110, loss:0.00001, loss_test:0.09638, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.685, tt:5848.070\n",
      "Ep:111, loss:0.00001, loss_test:0.09816, lr:6.11e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.682, tt:5900.409\n",
      "Ep:112, loss:0.00001, loss_test:0.09790, lr:6.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.680, tt:5952.862\n",
      "Ep:113, loss:0.00001, loss_test:0.09679, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.665, tt:6003.790\n",
      "Ep:114, loss:0.00001, loss_test:0.09686, lr:5.93e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.657, tt:6055.590\n",
      "Ep:115, loss:0.00001, loss_test:0.09697, lr:5.87e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.640, tt:6106.287\n",
      "Ep:116, loss:0.00001, loss_test:0.09744, lr:5.81e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.635, tt:6158.293\n",
      "Ep:117, loss:0.00001, loss_test:0.09781, lr:5.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.631, tt:6210.463\n",
      "Ep:118, loss:0.00001, loss_test:0.10012, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.614, tt:6261.113\n",
      "Ep:119, loss:0.00001, loss_test:0.09739, lr:5.64e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.619, tt:6314.333\n",
      "Ep:120, loss:0.00001, loss_test:0.09761, lr:5.58e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.623, tt:6367.425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.09895, lr:5.53e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.624, tt:6420.104\n",
      "Ep:122, loss:0.00001, loss_test:0.09571, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.638, tt:6474.528\n",
      "Ep:123, loss:0.00001, loss_test:0.10063, lr:5.42e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.641, tt:6527.490\n",
      "Ep:124, loss:0.00001, loss_test:0.09738, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.628, tt:6578.528\n",
      "Ep:125, loss:0.00000, loss_test:0.09701, lr:5.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.616, tt:6629.655\n",
      "Ep:126, loss:0.00000, loss_test:0.09881, lr:5.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.613, tt:6681.813\n",
      "Ep:127, loss:0.00000, loss_test:0.09557, lr:5.20e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.605, tt:6733.502\n",
      "Ep:128, loss:0.00000, loss_test:0.09826, lr:5.15e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.606, tt:6786.225\n",
      "Ep:129, loss:0.00000, loss_test:0.09863, lr:5.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.601, tt:6838.170\n",
      "Ep:130, loss:0.00000, loss_test:0.09594, lr:5.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.605, tt:6891.290\n",
      "Ep:131, loss:0.00000, loss_test:0.09753, lr:5.00e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.615, tt:6945.233\n",
      "Ep:132, loss:0.00000, loss_test:0.09716, lr:4.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.612, tt:6997.452\n",
      "Ep:133, loss:0.00000, loss_test:0.09767, lr:4.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.610, tt:7049.722\n",
      "Ep:134, loss:0.00000, loss_test:0.09813, lr:4.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.616, tt:7103.141\n",
      "Ep:135, loss:0.00000, loss_test:0.09617, lr:4.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.629, tt:7157.532\n",
      "Ep:136, loss:0.00000, loss_test:0.09706, lr:4.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.624, tt:7209.440\n",
      "Ep:137, loss:0.00000, loss_test:0.09709, lr:4.71e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.613, tt:7260.607\n",
      "Ep:138, loss:0.00000, loss_test:0.09706, lr:4.66e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.610, tt:7312.826\n",
      "Ep:139, loss:0.00000, loss_test:0.09803, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.606, tt:7364.793\n",
      "Ep:140, loss:0.00000, loss_test:0.09642, lr:4.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.628, tt:7420.488\n",
      "Ep:141, loss:0.00000, loss_test:0.09794, lr:4.52e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.655, tt:7476.977\n",
      "Ep:142, loss:0.00000, loss_test:0.09725, lr:4.48e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.649, tt:7528.801\n",
      "Ep:143, loss:0.00000, loss_test:0.09549, lr:4.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.634, tt:7579.236\n",
      "Ep:144, loss:0.00000, loss_test:0.09730, lr:4.39e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.637, tt:7632.311\n",
      "Ep:145, loss:0.00000, loss_test:0.09661, lr:4.34e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.638, tt:7685.218\n",
      "Ep:146, loss:0.00000, loss_test:0.09689, lr:4.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.629, tt:7736.486\n",
      "Ep:147, loss:0.00000, loss_test:0.09848, lr:4.26e-03, fs:0.81657 (r=0.697,p=0.986),  time:52.632, tt:7789.600\n",
      "Ep:148, loss:0.00000, loss_test:0.09636, lr:4.21e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.639, tt:7843.283\n",
      "Ep:149, loss:0.00000, loss_test:0.09700, lr:4.17e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.644, tt:7896.568\n",
      "Ep:150, loss:0.00000, loss_test:0.09742, lr:4.13e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.650, tt:7950.215\n",
      "Ep:151, loss:0.00000, loss_test:0.09629, lr:4.09e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.661, tt:8004.411\n",
      "Ep:152, loss:0.00000, loss_test:0.09700, lr:4.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.658, tt:8056.621\n",
      "Ep:153, loss:0.00000, loss_test:0.09823, lr:4.01e-03, fs:0.81657 (r=0.697,p=0.986),  time:52.666, tt:8110.496\n",
      "Ep:154, loss:0.00000, loss_test:0.09618, lr:3.97e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.674, tt:8164.400\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14101, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.152, tt:21.152\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13954, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:19.110, tt:38.219\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13681, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:18.397, tt:55.190\n",
      "Ep:3, loss:0.00027, loss_test:0.13252, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:18.443, tt:73.773\n",
      "Ep:4, loss:0.00026, loss_test:0.12571, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:19.093, tt:95.465\n",
      "Ep:5, loss:0.00025, loss_test:0.11806, lr:1.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:19.360, tt:116.160\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11462, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:19.792, tt:138.546\n",
      "Ep:7, loss:0.00023, loss_test:0.11297, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:20.218, tt:161.746\n",
      "Ep:8, loss:0.00022, loss_test:0.11062, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:20.426, tt:183.834\n",
      "Ep:9, loss:0.00021, loss_test:0.10661, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:20.657, tt:206.571\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10347, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:20.779, tt:228.572\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10063, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:20.660, tt:247.919\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09794, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:20.618, tt:268.040\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09609, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:20.594, tt:288.312\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09389, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:20.492, tt:307.375\n",
      "Ep:15, loss:0.00016, loss_test:0.09201, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:20.573, tt:329.166\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09015, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:20.544, tt:349.253\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08728, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:20.495, tt:368.917\n",
      "Ep:18, loss:0.00014, loss_test:0.08582, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:20.512, tt:389.737\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.08262, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:20.507, tt:410.136\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08166, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:20.604, tt:432.676\n",
      "Ep:21, loss:0.00012, loss_test:0.08038, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:20.663, tt:454.588\n",
      "Ep:22, loss:0.00012, loss_test:0.07800, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:20.715, tt:476.455\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.07697, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:20.738, tt:497.721\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07535, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:20.721, tt:518.025\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.07380, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:20.730, tt:538.978\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07430, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:20.775, tt:560.917\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07179, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:20.790, tt:582.118\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:28, loss:0.00009, loss_test:0.07061, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:20.798, tt:603.141\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.07113, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:20.805, tt:624.135\n",
      "Ep:30, loss:0.00008, loss_test:0.06969, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:20.747, tt:643.151\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06910, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:20.763, tt:664.419\n",
      "Ep:32, loss:0.00008, loss_test:0.06973, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:20.803, tt:686.515\n",
      "Ep:33, loss:0.00007, loss_test:0.06656, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:20.790, tt:706.865\n",
      "Ep:34, loss:0.00007, loss_test:0.06777, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:20.792, tt:727.730\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06562, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:20.866, tt:751.170\n",
      "Ep:36, loss:0.00007, loss_test:0.06654, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:20.831, tt:770.746\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.06705, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:20.800, tt:790.385\n",
      "Ep:38, loss:0.00006, loss_test:0.06504, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:20.766, tt:809.873\n",
      "Ep:39, loss:0.00006, loss_test:0.06493, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:20.788, tt:831.521\n",
      "Ep:40, loss:0.00006, loss_test:0.06655, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:20.793, tt:852.524\n",
      "Ep:41, loss:0.00006, loss_test:0.06514, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:20.816, tt:874.270\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06553, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:20.776, tt:893.378\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.06429, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:20.757, tt:913.320\n",
      "Ep:44, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:20.725, tt:932.631\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.06478, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:20.681, tt:951.322\n",
      "Ep:46, loss:0.00005, loss_test:0.06564, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:20.707, tt:973.247\n",
      "Ep:47, loss:0.00004, loss_test:0.06461, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:20.711, tt:994.130\n",
      "Ep:48, loss:0.00004, loss_test:0.06810, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:20.804, tt:1019.406\n",
      "Ep:49, loss:0.00004, loss_test:0.06488, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:20.816, tt:1040.822\n",
      "Ep:50, loss:0.00004, loss_test:0.06881, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:20.823, tt:1061.991\n",
      "Ep:51, loss:0.00004, loss_test:0.06361, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:20.860, tt:1084.738\n",
      "Ep:52, loss:0.00004, loss_test:0.06747, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:20.892, tt:1107.274\n",
      "Ep:53, loss:0.00004, loss_test:0.06459, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:20.913, tt:1129.323\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00004, loss_test:0.06576, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:20.939, tt:1151.640\n",
      "Ep:55, loss:0.00003, loss_test:0.06418, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:20.944, tt:1172.863\n",
      "Ep:56, loss:0.00003, loss_test:0.06577, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:20.975, tt:1195.569\n",
      "Ep:57, loss:0.00003, loss_test:0.06516, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:20.975, tt:1216.551\n",
      "Ep:58, loss:0.00003, loss_test:0.06521, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:20.968, tt:1237.111\n",
      "Ep:59, loss:0.00003, loss_test:0.06529, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:20.964, tt:1257.827\n",
      "Ep:60, loss:0.00003, loss_test:0.06548, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:20.945, tt:1277.631\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.06614, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:20.930, tt:1297.672\n",
      "Ep:62, loss:0.00003, loss_test:0.06452, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:20.928, tt:1318.495\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.06457, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:20.956, tt:1341.159\n",
      "Ep:64, loss:0.00002, loss_test:0.06460, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.032, tt:1367.068\n",
      "Ep:65, loss:0.00002, loss_test:0.06411, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:21.042, tt:1388.779\n",
      "Ep:66, loss:0.00002, loss_test:0.06501, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.059, tt:1410.949\n",
      "Ep:67, loss:0.00002, loss_test:0.06592, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:21.084, tt:1433.701\n",
      "Ep:68, loss:0.00002, loss_test:0.06251, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.094, tt:1455.491\n",
      "Ep:69, loss:0.00002, loss_test:0.06624, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:21.116, tt:1478.126\n",
      "Ep:70, loss:0.00002, loss_test:0.06255, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:21.101, tt:1498.181\n",
      "Ep:71, loss:0.00002, loss_test:0.06721, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.096, tt:1518.905\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.06460, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:21.074, tt:1538.422\n",
      "Ep:73, loss:0.00002, loss_test:0.06323, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.070, tt:1559.172\n",
      "Ep:74, loss:0.00002, loss_test:0.06751, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:21.083, tt:1581.195\n",
      "Ep:75, loss:0.00002, loss_test:0.06214, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.092, tt:1602.959\n",
      "Ep:76, loss:0.00002, loss_test:0.06463, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:21.105, tt:1625.094\n",
      "Ep:77, loss:0.00002, loss_test:0.06439, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:21.110, tt:1646.583\n",
      "Ep:78, loss:0.00002, loss_test:0.06146, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.135, tt:1669.640\n",
      "Ep:79, loss:0.00002, loss_test:0.06567, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:21.150, tt:1692.004\n",
      "Ep:80, loss:0.00002, loss_test:0.06122, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.123, tt:1710.956\n",
      "Ep:81, loss:0.00002, loss_test:0.06692, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:21.106, tt:1730.716\n",
      "Ep:82, loss:0.00002, loss_test:0.06461, lr:1.00e-02, fs:0.86667 (r=0.788,p=0.963),  time:21.101, tt:1751.391\n",
      "Ep:83, loss:0.00001, loss_test:0.06058, lr:9.90e-03, fs:0.89247 (r=0.838,p=0.954),  time:21.100, tt:1772.403\n",
      "Ep:84, loss:0.00001, loss_test:0.06669, lr:9.80e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.094, tt:1792.979\n",
      "Ep:85, loss:0.00001, loss_test:0.06331, lr:9.70e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.097, tt:1814.363\n",
      "Ep:86, loss:0.00001, loss_test:0.06179, lr:9.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.080, tt:1833.942\n",
      "Ep:87, loss:0.00001, loss_test:0.06443, lr:9.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.063, tt:1853.578\n",
      "Ep:88, loss:0.00001, loss_test:0.06137, lr:9.41e-03, fs:0.89247 (r=0.838,p=0.954),  time:21.058, tt:1874.169\n",
      "Ep:89, loss:0.00001, loss_test:0.06407, lr:9.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:21.072, tt:1896.465\n",
      "Ep:90, loss:0.00001, loss_test:0.06319, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.085, tt:1918.717\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.06060, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.070, tt:1938.466\n",
      "Ep:92, loss:0.00001, loss_test:0.06585, lr:9.23e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.063, tt:1958.861\n",
      "Ep:93, loss:0.00001, loss_test:0.06258, lr:9.23e-03, fs:0.87151 (r=0.788,p=0.975),  time:21.056, tt:1979.225\n",
      "Ep:94, loss:0.00001, loss_test:0.06144, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.047, tt:1999.434\n",
      "Ep:95, loss:0.00001, loss_test:0.06508, lr:9.23e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.029, tt:2018.830\n",
      "Ep:96, loss:0.00001, loss_test:0.06201, lr:9.23e-03, fs:0.88398 (r=0.808,p=0.976),  time:21.025, tt:2039.473\n",
      "Ep:97, loss:0.00001, loss_test:0.06338, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.020, tt:2059.984\n",
      "Ep:98, loss:0.00001, loss_test:0.06367, lr:9.23e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.020, tt:2081.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:99, loss:0.00001, loss_test:0.06228, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.018, tt:2101.826\n",
      "Ep:100, loss:0.00001, loss_test:0.06389, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.013, tt:2122.277\n",
      "Ep:101, loss:0.00001, loss_test:0.06358, lr:9.23e-03, fs:0.89617 (r=0.828,p=0.976),  time:20.997, tt:2141.729\n",
      "Ep:102, loss:0.00001, loss_test:0.06232, lr:9.14e-03, fs:0.90811 (r=0.848,p=0.977),  time:20.998, tt:2162.772\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.06329, lr:9.14e-03, fs:0.86517 (r=0.778,p=0.975),  time:20.984, tt:2182.367\n",
      "Ep:104, loss:0.00001, loss_test:0.06382, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.999, tt:2204.847\n",
      "Ep:105, loss:0.00001, loss_test:0.06268, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.998, tt:2225.795\n",
      "Ep:106, loss:0.00001, loss_test:0.06306, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.990, tt:2245.878\n",
      "Ep:107, loss:0.00001, loss_test:0.06370, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.984, tt:2266.225\n",
      "Ep:108, loss:0.00001, loss_test:0.06288, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.974, tt:2286.172\n",
      "Ep:109, loss:0.00001, loss_test:0.06400, lr:9.14e-03, fs:0.89011 (r=0.818,p=0.976),  time:20.964, tt:2306.023\n",
      "Ep:110, loss:0.00001, loss_test:0.06220, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.975, tt:2328.251\n",
      "Ep:111, loss:0.00001, loss_test:0.06386, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.966, tt:2348.202\n",
      "Ep:112, loss:0.00001, loss_test:0.06289, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.953, tt:2367.657\n",
      "Ep:113, loss:0.00001, loss_test:0.06344, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.957, tt:2389.137\n",
      "Ep:114, loss:0.00001, loss_test:0.06303, lr:9.04e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.965, tt:2410.973\n",
      "Ep:115, loss:0.00001, loss_test:0.06406, lr:8.95e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.991, tt:2434.921\n",
      "Ep:116, loss:0.00001, loss_test:0.06304, lr:8.86e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.992, tt:2456.102\n",
      "Ep:117, loss:0.00000, loss_test:0.06424, lr:8.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.997, tt:2477.623\n",
      "Ep:118, loss:0.00000, loss_test:0.06322, lr:8.69e-03, fs:0.87151 (r=0.788,p=0.975),  time:20.990, tt:2497.787\n",
      "Ep:119, loss:0.00000, loss_test:0.06473, lr:8.60e-03, fs:0.90811 (r=0.848,p=0.977),  time:20.989, tt:2518.699\n",
      "Ep:120, loss:0.00000, loss_test:0.06424, lr:8.51e-03, fs:0.86517 (r=0.778,p=0.975),  time:21.009, tt:2542.149\n",
      "Ep:121, loss:0.00000, loss_test:0.06519, lr:8.43e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.014, tt:2563.766\n",
      "Ep:122, loss:0.00000, loss_test:0.06476, lr:8.35e-03, fs:0.86517 (r=0.778,p=0.975),  time:21.007, tt:2583.893\n",
      "Ep:123, loss:0.00000, loss_test:0.06482, lr:8.26e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.012, tt:2605.488\n",
      "Ep:124, loss:0.00000, loss_test:0.06564, lr:8.18e-03, fs:0.87151 (r=0.788,p=0.975),  time:21.013, tt:2626.683\n",
      "Ep:125, loss:0.00000, loss_test:0.06442, lr:8.10e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.027, tt:2649.371\n",
      "Ep:126, loss:0.00000, loss_test:0.06485, lr:8.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.034, tt:2671.334\n",
      "Ep:127, loss:0.00000, loss_test:0.06581, lr:7.94e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.050, tt:2694.414\n",
      "Ep:128, loss:0.00000, loss_test:0.06365, lr:7.86e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.048, tt:2715.145\n",
      "Ep:129, loss:0.00000, loss_test:0.06576, lr:7.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.057, tt:2737.392\n",
      "Ep:130, loss:0.00000, loss_test:0.06443, lr:7.70e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.064, tt:2759.333\n",
      "Ep:131, loss:0.00000, loss_test:0.06551, lr:7.62e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.058, tt:2779.660\n",
      "Ep:132, loss:0.00000, loss_test:0.06442, lr:7.55e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.050, tt:2799.610\n",
      "Ep:133, loss:0.00000, loss_test:0.06454, lr:7.47e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.062, tt:2822.343\n",
      "Ep:134, loss:0.00000, loss_test:0.06424, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.051, tt:2841.844\n",
      "Ep:135, loss:0.00000, loss_test:0.06548, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.038, tt:2861.171\n",
      "Ep:136, loss:0.00000, loss_test:0.06458, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.015, tt:2879.106\n",
      "Ep:137, loss:0.00000, loss_test:0.06450, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:21.006, tt:2898.785\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00000, loss_test:0.06496, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.991, tt:2917.746\n",
      "Ep:139, loss:0.00000, loss_test:0.06408, lr:7.18e-03, fs:0.90811 (r=0.848,p=0.977),  time:20.997, tt:2939.561\n",
      "Ep:140, loss:0.00000, loss_test:0.06493, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.994, tt:2960.083\n",
      "Ep:141, loss:0.00000, loss_test:0.06431, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.970, tt:2977.691\n",
      "Ep:142, loss:0.00000, loss_test:0.06521, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.962, tt:2997.515\n",
      "Ep:143, loss:0.00000, loss_test:0.06510, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.954, tt:3017.347\n",
      "Ep:144, loss:0.00000, loss_test:0.06425, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.966, tt:3040.030\n",
      "Ep:145, loss:0.00000, loss_test:0.06520, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.968, tt:3061.280\n",
      "Ep:146, loss:0.00000, loss_test:0.06430, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.963, tt:3081.538\n",
      "Ep:147, loss:0.00000, loss_test:0.06519, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.959, tt:3101.861\n",
      "Ep:148, loss:0.00000, loss_test:0.06446, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.956, tt:3122.512\n",
      "Ep:149, loss:0.00000, loss_test:0.06528, lr:7.11e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.957, tt:3143.481\n",
      "Ep:150, loss:0.00000, loss_test:0.06521, lr:7.03e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.953, tt:3163.891\n",
      "Ep:151, loss:0.00000, loss_test:0.06452, lr:6.96e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.966, tt:3186.862\n",
      "Ep:152, loss:0.00000, loss_test:0.06505, lr:6.89e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.964, tt:3207.453\n",
      "Ep:153, loss:0.00000, loss_test:0.06470, lr:6.83e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.973, tt:3229.849\n",
      "Ep:154, loss:0.00000, loss_test:0.06490, lr:6.76e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.968, tt:3250.001\n",
      "Ep:155, loss:0.00000, loss_test:0.06537, lr:6.69e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.969, tt:3271.164\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13982, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.452, tt:20.452\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13799, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.274, tt:40.548\n",
      "Ep:2, loss:0.00028, loss_test:0.13471, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:19.222, tt:57.667\n",
      "Ep:3, loss:0.00027, loss_test:0.12939, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:18.834, tt:75.335\n",
      "Ep:4, loss:0.00026, loss_test:0.12111, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:19.280, tt:96.398\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11207, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:19.425, tt:116.548\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10338, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:19.937, tt:139.557\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.09932, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:19.920, tt:159.357\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.09762, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:20.191, tt:181.717\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09697, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:20.171, tt:201.708\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00020, loss_test:0.09363, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:20.258, tt:222.843\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09158, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:20.337, tt:244.039\n",
      "Ep:12, loss:0.00019, loss_test:0.08989, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:20.353, tt:264.586\n",
      "Ep:13, loss:0.00018, loss_test:0.08876, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:20.497, tt:286.962\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08689, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:20.418, tt:306.268\n",
      "Ep:15, loss:0.00017, loss_test:0.08449, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:20.553, tt:328.856\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08280, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:20.614, tt:350.436\n",
      "Ep:17, loss:0.00015, loss_test:0.08163, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:20.727, tt:373.085\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07908, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:20.710, tt:393.485\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.07750, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:20.764, tt:415.271\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07601, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:20.791, tt:436.612\n",
      "Ep:21, loss:0.00013, loss_test:0.07417, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:20.779, tt:457.147\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.07310, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:20.778, tt:477.888\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07218, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:20.757, tt:498.165\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07065, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:20.805, tt:520.122\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07010, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:20.941, tt:544.467\n",
      "Ep:26, loss:0.00011, loss_test:0.06807, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:20.886, tt:563.932\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.06768, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:20.914, tt:585.605\n",
      "Ep:28, loss:0.00010, loss_test:0.06705, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:20.945, tt:607.392\n",
      "Ep:29, loss:0.00009, loss_test:0.06619, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:20.893, tt:626.789\n",
      "Ep:30, loss:0.00009, loss_test:0.06592, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:20.926, tt:648.715\n",
      "Ep:31, loss:0.00008, loss_test:0.06348, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.987, tt:671.581\n",
      "Ep:32, loss:0.00008, loss_test:0.06270, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:20.972, tt:692.087\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.06222, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:21.004, tt:714.125\n",
      "Ep:34, loss:0.00007, loss_test:0.06239, lr:1.00e-02, fs:0.91489 (r=0.869,p=0.966),  time:21.034, tt:736.190\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06116, lr:1.00e-02, fs:0.91489 (r=0.869,p=0.966),  time:21.039, tt:757.413\n",
      "Ep:36, loss:0.00007, loss_test:0.06029, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:21.042, tt:778.536\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.06019, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.064, tt:800.438\n",
      "Ep:38, loss:0.00006, loss_test:0.05965, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:21.065, tt:821.533\n",
      "Ep:39, loss:0.00006, loss_test:0.05980, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:21.073, tt:842.911\n",
      "Ep:40, loss:0.00006, loss_test:0.05897, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:21.045, tt:862.843\n",
      "Ep:41, loss:0.00005, loss_test:0.05784, lr:1.00e-02, fs:0.92063 (r=0.879,p=0.967),  time:21.037, tt:883.542\n",
      "Ep:42, loss:0.00005, loss_test:0.05744, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:21.042, tt:904.792\n",
      "Ep:43, loss:0.00005, loss_test:0.05923, lr:1.00e-02, fs:0.90909 (r=0.859,p=0.966),  time:21.036, tt:925.577\n",
      "Ep:44, loss:0.00005, loss_test:0.05686, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:21.028, tt:946.278\n",
      "Ep:45, loss:0.00005, loss_test:0.05797, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:21.049, tt:968.235\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.05637, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:21.050, tt:989.337\n",
      "Ep:47, loss:0.00004, loss_test:0.05861, lr:1.00e-02, fs:0.91979 (r=0.869,p=0.977),  time:21.067, tt:1011.194\n",
      "Ep:48, loss:0.00004, loss_test:0.05649, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:21.060, tt:1031.942\n",
      "Ep:49, loss:0.00004, loss_test:0.05847, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:21.055, tt:1052.734\n",
      "Ep:50, loss:0.00004, loss_test:0.05581, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:21.040, tt:1073.034\n",
      "Ep:51, loss:0.00004, loss_test:0.05776, lr:1.00e-02, fs:0.92473 (r=0.869,p=0.989),  time:21.043, tt:1094.217\n",
      "Ep:52, loss:0.00004, loss_test:0.05511, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:21.048, tt:1115.528\n",
      "Ep:53, loss:0.00003, loss_test:0.05865, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:21.015, tt:1134.831\n",
      "Ep:54, loss:0.00003, loss_test:0.05603, lr:1.00e-02, fs:0.93194 (r=0.899,p=0.967),  time:21.000, tt:1154.997\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.05584, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:20.974, tt:1174.529\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.05630, lr:1.00e-02, fs:0.92063 (r=0.879,p=0.967),  time:20.965, tt:1194.988\n",
      "Ep:57, loss:0.00003, loss_test:0.05611, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:20.985, tt:1217.136\n",
      "Ep:58, loss:0.00003, loss_test:0.05630, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:20.988, tt:1238.266\n",
      "Ep:59, loss:0.00002, loss_test:0.05457, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.024, tt:1261.463\n",
      "Ep:60, loss:0.00002, loss_test:0.05687, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:21.022, tt:1282.354\n",
      "Ep:61, loss:0.00002, loss_test:0.05406, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.019, tt:1303.198\n",
      "Ep:62, loss:0.00002, loss_test:0.05448, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.027, tt:1324.697\n",
      "Ep:63, loss:0.00002, loss_test:0.05719, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:21.018, tt:1345.156\n",
      "Ep:64, loss:0.00002, loss_test:0.05369, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.032, tt:1367.075\n",
      "Ep:65, loss:0.00002, loss_test:0.05596, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:21.037, tt:1388.455\n",
      "Ep:66, loss:0.00002, loss_test:0.05330, lr:1.00e-02, fs:0.92632 (r=0.889,p=0.967),  time:21.032, tt:1409.131\n",
      "Ep:67, loss:0.00002, loss_test:0.05764, lr:9.90e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.046, tt:1431.159\n",
      "Ep:68, loss:0.00002, loss_test:0.05297, lr:9.80e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.059, tt:1453.075\n",
      "Ep:69, loss:0.00002, loss_test:0.05823, lr:9.70e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.069, tt:1474.848\n",
      "Ep:70, loss:0.00002, loss_test:0.05506, lr:9.61e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.070, tt:1495.960\n",
      "Ep:71, loss:0.00002, loss_test:0.05741, lr:9.51e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.068, tt:1516.921\n",
      "Ep:72, loss:0.00002, loss_test:0.05517, lr:9.41e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.060, tt:1537.377\n",
      "Ep:73, loss:0.00001, loss_test:0.05438, lr:9.32e-03, fs:0.92063 (r=0.879,p=0.967),  time:21.077, tt:1559.728\n",
      "Ep:74, loss:0.00001, loss_test:0.05669, lr:9.23e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.077, tt:1580.779\n",
      "Ep:75, loss:0.00001, loss_test:0.05392, lr:9.14e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.079, tt:1602.022\n",
      "Ep:76, loss:0.00001, loss_test:0.05460, lr:9.04e-03, fs:0.92632 (r=0.889,p=0.967),  time:21.075, tt:1622.757\n",
      "Ep:77, loss:0.00001, loss_test:0.05966, lr:8.95e-03, fs:0.91304 (r=0.848,p=0.988),  time:21.071, tt:1643.560\n",
      "Ep:78, loss:0.00001, loss_test:0.05519, lr:8.86e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.073, tt:1664.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00001, loss_test:0.05751, lr:8.78e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.071, tt:1685.672\n",
      "Ep:80, loss:0.00001, loss_test:0.05455, lr:8.69e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.068, tt:1706.546\n",
      "Ep:81, loss:0.00001, loss_test:0.05794, lr:8.60e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.054, tt:1726.457\n",
      "Ep:82, loss:0.00001, loss_test:0.05500, lr:8.51e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.072, tt:1748.989\n",
      "Ep:83, loss:0.00001, loss_test:0.05684, lr:8.43e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.075, tt:1770.274\n",
      "Ep:84, loss:0.00001, loss_test:0.05481, lr:8.35e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.080, tt:1791.827\n",
      "Ep:85, loss:0.00001, loss_test:0.05652, lr:8.26e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.086, tt:1813.427\n",
      "Ep:86, loss:0.00001, loss_test:0.05581, lr:8.18e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.080, tt:1833.982\n",
      "Ep:87, loss:0.00001, loss_test:0.05670, lr:8.10e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.083, tt:1855.335\n",
      "Ep:88, loss:0.00001, loss_test:0.05517, lr:8.02e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.112, tt:1878.993\n",
      "Ep:89, loss:0.00001, loss_test:0.05719, lr:7.94e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.100, tt:1899.029\n",
      "Ep:90, loss:0.00001, loss_test:0.05794, lr:7.86e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.109, tt:1920.893\n",
      "Ep:91, loss:0.00001, loss_test:0.05602, lr:7.78e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.098, tt:1941.012\n",
      "Ep:92, loss:0.00001, loss_test:0.05813, lr:7.70e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.093, tt:1961.624\n",
      "Ep:93, loss:0.00001, loss_test:0.05534, lr:7.62e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.085, tt:1981.977\n",
      "Ep:94, loss:0.00001, loss_test:0.05740, lr:7.55e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.100, tt:2004.477\n",
      "Ep:95, loss:0.00001, loss_test:0.05567, lr:7.47e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.093, tt:2024.928\n",
      "Ep:96, loss:0.00001, loss_test:0.05747, lr:7.40e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.091, tt:2045.871\n",
      "Ep:97, loss:0.00001, loss_test:0.05594, lr:7.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.099, tt:2067.658\n",
      "Ep:98, loss:0.00001, loss_test:0.05783, lr:7.25e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.093, tt:2088.223\n",
      "Ep:99, loss:0.00001, loss_test:0.05709, lr:7.18e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.104, tt:2110.396\n",
      "Ep:100, loss:0.00001, loss_test:0.05850, lr:7.11e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.122, tt:2133.337\n",
      "Ep:101, loss:0.00001, loss_test:0.05757, lr:7.03e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.133, tt:2155.548\n",
      "Ep:102, loss:0.00001, loss_test:0.05761, lr:6.96e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.129, tt:2176.271\n",
      "Ep:103, loss:0.00001, loss_test:0.05772, lr:6.89e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.132, tt:2197.766\n",
      "Ep:104, loss:0.00001, loss_test:0.05714, lr:6.83e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.132, tt:2218.892\n",
      "Ep:105, loss:0.00000, loss_test:0.05802, lr:6.76e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.153, tt:2242.192\n",
      "Ep:106, loss:0.00000, loss_test:0.05750, lr:6.69e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.156, tt:2263.738\n",
      "Ep:107, loss:0.00000, loss_test:0.05763, lr:6.62e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.139, tt:2283.045\n",
      "Ep:108, loss:0.00000, loss_test:0.05782, lr:6.56e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.113, tt:2301.284\n",
      "Ep:109, loss:0.00000, loss_test:0.05818, lr:6.49e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.083, tt:2319.099\n",
      "Ep:110, loss:0.00000, loss_test:0.05789, lr:6.43e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.092, tt:2341.195\n",
      "Ep:111, loss:0.00000, loss_test:0.05801, lr:6.36e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.090, tt:2362.058\n",
      "Ep:112, loss:0.00000, loss_test:0.05803, lr:6.30e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.084, tt:2382.461\n",
      "Ep:113, loss:0.00000, loss_test:0.05926, lr:6.24e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.055, tt:2400.297\n",
      "Ep:114, loss:0.00000, loss_test:0.05862, lr:6.17e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.033, tt:2418.757\n",
      "Ep:115, loss:0.00000, loss_test:0.05907, lr:6.11e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.035, tt:2440.083\n",
      "Ep:116, loss:0.00000, loss_test:0.05988, lr:6.05e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.055, tt:2463.474\n",
      "Ep:117, loss:0.00000, loss_test:0.05830, lr:5.99e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.053, tt:2484.234\n",
      "Ep:118, loss:0.00000, loss_test:0.05955, lr:5.93e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.061, tt:2506.249\n",
      "Ep:119, loss:0.00000, loss_test:0.05887, lr:5.87e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.051, tt:2526.136\n",
      "Ep:120, loss:0.00000, loss_test:0.06052, lr:5.81e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.044, tt:2546.327\n",
      "Ep:121, loss:0.00000, loss_test:0.05800, lr:5.75e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.036, tt:2566.435\n",
      "Ep:122, loss:0.00000, loss_test:0.05993, lr:5.70e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.035, tt:2587.346\n",
      "Ep:123, loss:0.00000, loss_test:0.05943, lr:5.64e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.032, tt:2607.981\n",
      "Ep:124, loss:0.00000, loss_test:0.05844, lr:5.58e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.022, tt:2627.745\n",
      "Ep:125, loss:0.00000, loss_test:0.06011, lr:5.53e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.018, tt:2648.268\n",
      "Ep:126, loss:0.00000, loss_test:0.05826, lr:5.47e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.017, tt:2669.163\n",
      "Ep:127, loss:0.00000, loss_test:0.06038, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.013, tt:2689.726\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.05955, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.010, tt:2710.310\n",
      "Ep:129, loss:0.00000, loss_test:0.05921, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.003, tt:2730.416\n",
      "Ep:130, loss:0.00000, loss_test:0.06023, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.996, tt:2750.501\n",
      "Ep:131, loss:0.00000, loss_test:0.05978, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.009, tt:2773.140\n",
      "Ep:132, loss:0.00000, loss_test:0.06023, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.007, tt:2793.966\n",
      "Ep:133, loss:0.00000, loss_test:0.05981, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.014, tt:2815.892\n",
      "Ep:134, loss:0.00000, loss_test:0.05969, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.020, tt:2837.736\n",
      "Ep:135, loss:0.00000, loss_test:0.06092, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.013, tt:2857.796\n",
      "Ep:136, loss:0.00000, loss_test:0.05922, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.009, tt:2878.248\n",
      "Ep:137, loss:0.00000, loss_test:0.06054, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.003, tt:2898.483\n",
      "Ep:138, loss:0.00000, loss_test:0.06044, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.997, tt:2918.534\n",
      "Ep:139, loss:0.00000, loss_test:0.06032, lr:5.36e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.992, tt:2938.938\n",
      "Ep:140, loss:0.00000, loss_test:0.05986, lr:5.31e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.990, tt:2959.593\n",
      "Ep:141, loss:0.00000, loss_test:0.06044, lr:5.26e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.981, tt:2979.309\n",
      "Ep:142, loss:0.00000, loss_test:0.06051, lr:5.20e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.994, tt:3002.072\n",
      "Ep:143, loss:0.00000, loss_test:0.06011, lr:5.15e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.995, tt:3023.333\n",
      "Ep:144, loss:0.00000, loss_test:0.06029, lr:5.10e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.985, tt:3042.777\n",
      "Ep:145, loss:0.00000, loss_test:0.06028, lr:5.05e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.989, tt:3064.456\n",
      "Ep:146, loss:0.00000, loss_test:0.06059, lr:5.00e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.997, tt:3086.503\n",
      "Ep:147, loss:0.00000, loss_test:0.06036, lr:4.95e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.990, tt:3106.483\n",
      "Ep:148, loss:0.00000, loss_test:0.06065, lr:4.90e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.998, tt:3128.730\n",
      "Ep:149, loss:0.00000, loss_test:0.06064, lr:4.85e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.994, tt:3149.054\n",
      "Ep:150, loss:0.00000, loss_test:0.06033, lr:4.80e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.006, tt:3171.973\n",
      "Ep:151, loss:0.00000, loss_test:0.06078, lr:4.75e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.002, tt:3192.228\n",
      "Ep:152, loss:0.00000, loss_test:0.06047, lr:4.71e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.997, tt:3212.590\n",
      "Ep:153, loss:0.00000, loss_test:0.06082, lr:4.66e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.989, tt:3232.258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00000, loss_test:0.06033, lr:4.61e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.991, tt:3253.561\n",
      "Ep:155, loss:0.00000, loss_test:0.06072, lr:4.57e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.984, tt:3273.565\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14045, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:23.171, tt:23.171\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13748, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:21.687, tt:43.373\n",
      "Ep:2, loss:0.00026, loss_test:0.13166, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:20.931, tt:62.792\n",
      "Ep:3, loss:0.00025, loss_test:0.12578, lr:1.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:22.221, tt:88.884\n",
      "Ep:4, loss:0.00024, loss_test:0.12577, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:22.839, tt:114.194\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12403, lr:1.00e-02, fs:0.64602 (r=0.737,p=0.575),  time:23.216, tt:139.294\n",
      "Ep:6, loss:0.00023, loss_test:0.12260, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:23.497, tt:164.478\n",
      "Ep:7, loss:0.00022, loss_test:0.12059, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:23.666, tt:189.326\n",
      "Ep:8, loss:0.00021, loss_test:0.11990, lr:1.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:23.998, tt:215.978\n",
      "Ep:9, loss:0.00020, loss_test:0.11655, lr:1.00e-02, fs:0.65753 (r=0.727,p=0.600),  time:24.106, tt:241.056\n",
      "Ep:10, loss:0.00020, loss_test:0.11443, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:24.065, tt:264.712\n",
      "Ep:11, loss:0.00019, loss_test:0.11319, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:24.208, tt:290.499\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.11108, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:24.194, tt:314.525\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.10876, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:24.238, tt:339.328\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10651, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:24.254, tt:363.816\n",
      "Ep:15, loss:0.00016, loss_test:0.10498, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:24.198, tt:387.166\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.10354, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:24.340, tt:413.778\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10106, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:24.372, tt:438.692\n",
      "Ep:18, loss:0.00014, loss_test:0.10038, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:24.331, tt:462.288\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.09775, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:24.372, tt:487.430\n",
      "Ep:20, loss:0.00013, loss_test:0.09759, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:24.352, tt:511.402\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.09550, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:24.421, tt:537.258\n",
      "Ep:22, loss:0.00012, loss_test:0.09582, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:24.467, tt:562.745\n",
      "Ep:23, loss:0.00011, loss_test:0.09510, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:24.468, tt:587.229\n",
      "Ep:24, loss:0.00011, loss_test:0.09378, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:24.444, tt:611.093\n",
      "Ep:25, loss:0.00010, loss_test:0.09354, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.439, tt:635.409\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.09161, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.488, tt:661.186\n",
      "Ep:27, loss:0.00009, loss_test:0.09083, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.634, tt:689.743\n",
      "Ep:28, loss:0.00009, loss_test:0.08948, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:24.621, tt:713.995\n",
      "Ep:29, loss:0.00009, loss_test:0.09091, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:24.637, tt:739.100\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.08917, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:24.670, tt:764.774\n",
      "Ep:31, loss:0.00008, loss_test:0.08946, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:24.674, tt:789.561\n",
      "Ep:32, loss:0.00008, loss_test:0.09038, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:24.678, tt:814.385\n",
      "Ep:33, loss:0.00007, loss_test:0.08877, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:24.665, tt:838.606\n",
      "Ep:34, loss:0.00007, loss_test:0.08939, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:24.678, tt:863.715\n",
      "Ep:35, loss:0.00007, loss_test:0.08967, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:24.688, tt:888.755\n",
      "Ep:36, loss:0.00006, loss_test:0.08841, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:24.756, tt:915.975\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.08864, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:24.733, tt:939.873\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00006, loss_test:0.08765, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:24.763, tt:965.767\n",
      "Ep:39, loss:0.00006, loss_test:0.09152, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:24.808, tt:992.308\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.08457, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:24.801, tt:1016.828\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.08630, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:24.771, tt:1040.382\n",
      "Ep:42, loss:0.00005, loss_test:0.09050, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:24.769, tt:1065.049\n",
      "Ep:43, loss:0.00005, loss_test:0.08370, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.807, tt:1091.508\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.09578, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:24.816, tt:1116.723\n",
      "Ep:45, loss:0.00004, loss_test:0.08188, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.801, tt:1140.847\n",
      "Ep:46, loss:0.00004, loss_test:0.09838, lr:1.00e-02, fs:0.72289 (r=0.606,p=0.896),  time:24.771, tt:1164.244\n",
      "Ep:47, loss:0.00004, loss_test:0.08408, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.759, tt:1188.435\n",
      "Ep:48, loss:0.00004, loss_test:0.09152, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.781, tt:1214.260\n",
      "Ep:49, loss:0.00004, loss_test:0.09015, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:24.861, tt:1243.051\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.08378, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:24.858, tt:1267.772\n",
      "Ep:51, loss:0.00003, loss_test:0.09460, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:24.858, tt:1292.593\n",
      "Ep:52, loss:0.00003, loss_test:0.08387, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:24.894, tt:1319.408\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.08728, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:24.951, tt:1347.369\n",
      "Ep:54, loss:0.00003, loss_test:0.09143, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:24.937, tt:1371.509\n",
      "Ep:55, loss:0.00003, loss_test:0.08474, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:24.969, tt:1398.248\n",
      "Ep:56, loss:0.00003, loss_test:0.08869, lr:1.00e-02, fs:0.75449 (r=0.636,p=0.926),  time:24.990, tt:1424.412\n",
      "Ep:57, loss:0.00003, loss_test:0.08729, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:24.991, tt:1449.488\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.08628, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:25.005, tt:1475.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00002, loss_test:0.08946, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:25.014, tt:1500.846\n",
      "Ep:60, loss:0.00002, loss_test:0.08649, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:25.011, tt:1525.665\n",
      "Ep:61, loss:0.00002, loss_test:0.08583, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.006, tt:1550.357\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.08672, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.019, tt:1576.213\n",
      "Ep:63, loss:0.00002, loss_test:0.08337, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.020, tt:1601.296\n",
      "Ep:64, loss:0.00002, loss_test:0.08775, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.001, tt:1625.089\n",
      "Ep:65, loss:0.00002, loss_test:0.08311, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.004, tt:1650.232\n",
      "Ep:66, loss:0.00002, loss_test:0.08784, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:25.001, tt:1675.088\n",
      "Ep:67, loss:0.00002, loss_test:0.08531, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:25.004, tt:1700.278\n",
      "Ep:68, loss:0.00002, loss_test:0.08446, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:24.997, tt:1724.773\n",
      "Ep:69, loss:0.00001, loss_test:0.08717, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:25.004, tt:1750.248\n",
      "Ep:70, loss:0.00001, loss_test:0.08427, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.004, tt:1775.289\n",
      "Ep:71, loss:0.00001, loss_test:0.08651, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:25.001, tt:1800.075\n",
      "Ep:72, loss:0.00001, loss_test:0.08508, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:24.997, tt:1824.755\n",
      "Ep:73, loss:0.00001, loss_test:0.08406, lr:9.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.979, tt:1848.420\n",
      "Ep:74, loss:0.00001, loss_test:0.08553, lr:9.80e-03, fs:0.77381 (r=0.657,p=0.942),  time:25.029, tt:1877.151\n",
      "Ep:75, loss:0.00001, loss_test:0.08249, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.051, tt:1903.856\n",
      "Ep:76, loss:0.00001, loss_test:0.09076, lr:9.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:25.036, tt:1927.787\n",
      "Ep:77, loss:0.00001, loss_test:0.08231, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.026, tt:1951.996\n",
      "Ep:78, loss:0.00001, loss_test:0.08881, lr:9.41e-03, fs:0.75152 (r=0.626,p=0.939),  time:25.018, tt:1976.440\n",
      "Ep:79, loss:0.00001, loss_test:0.08387, lr:9.32e-03, fs:0.78824 (r=0.677,p=0.944),  time:25.017, tt:2001.383\n",
      "Ep:80, loss:0.00001, loss_test:0.08601, lr:9.23e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.001, tt:2025.116\n",
      "Ep:81, loss:0.00001, loss_test:0.08905, lr:9.14e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.996, tt:2049.648\n",
      "Ep:82, loss:0.00001, loss_test:0.08293, lr:9.04e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.997, tt:2074.731\n",
      "Ep:83, loss:0.00001, loss_test:0.08829, lr:8.95e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.998, tt:2099.808\n",
      "Ep:84, loss:0.00001, loss_test:0.08833, lr:8.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:25.010, tt:2125.815\n",
      "Ep:85, loss:0.00001, loss_test:0.08232, lr:8.78e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.013, tt:2151.119\n",
      "Ep:86, loss:0.00001, loss_test:0.08685, lr:8.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.005, tt:2175.464\n",
      "Ep:87, loss:0.00001, loss_test:0.08752, lr:8.60e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.984, tt:2198.588\n",
      "Ep:88, loss:0.00001, loss_test:0.08256, lr:8.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.950, tt:2220.505\n",
      "Ep:89, loss:0.00001, loss_test:0.08535, lr:8.43e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.906, tt:2241.515\n",
      "Ep:90, loss:0.00001, loss_test:0.08561, lr:8.35e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.865, tt:2262.724\n",
      "Ep:91, loss:0.00001, loss_test:0.08302, lr:8.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.816, tt:2283.093\n",
      "Ep:92, loss:0.00001, loss_test:0.08728, lr:8.18e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.785, tt:2304.985\n",
      "Ep:93, loss:0.00001, loss_test:0.08495, lr:8.10e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.762, tt:2327.632\n",
      "Ep:94, loss:0.00001, loss_test:0.08406, lr:8.02e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.716, tt:2348.045\n",
      "Ep:95, loss:0.00001, loss_test:0.08562, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.701, tt:2371.248\n",
      "Ep:96, loss:0.00001, loss_test:0.08404, lr:7.86e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.704, tt:2396.335\n",
      "Ep:97, loss:0.00001, loss_test:0.08565, lr:7.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.713, tt:2421.850\n",
      "Ep:98, loss:0.00001, loss_test:0.08676, lr:7.70e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.708, tt:2446.085\n",
      "Ep:99, loss:0.00001, loss_test:0.08375, lr:7.62e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.706, tt:2470.565\n",
      "Ep:100, loss:0.00001, loss_test:0.08441, lr:7.55e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.703, tt:2495.048\n",
      "Ep:101, loss:0.00001, loss_test:0.08501, lr:7.47e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.726, tt:2522.002\n",
      "Ep:102, loss:0.00001, loss_test:0.08298, lr:7.40e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.709, tt:2544.985\n",
      "Ep:103, loss:0.00001, loss_test:0.08575, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.715, tt:2570.334\n",
      "Ep:104, loss:0.00001, loss_test:0.08663, lr:7.25e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.710, tt:2594.596\n",
      "Ep:105, loss:0.00001, loss_test:0.08448, lr:7.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.718, tt:2620.092\n",
      "Ep:106, loss:0.00001, loss_test:0.08377, lr:7.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.715, tt:2644.534\n",
      "Ep:107, loss:0.00001, loss_test:0.08505, lr:7.03e-03, fs:0.79532 (r=0.687,p=0.944),  time:24.713, tt:2669.008\n",
      "Ep:108, loss:0.00001, loss_test:0.08589, lr:6.96e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.725, tt:2695.035\n",
      "Ep:109, loss:0.00001, loss_test:0.08299, lr:6.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.757, tt:2723.271\n",
      "Ep:110, loss:0.00000, loss_test:0.08652, lr:6.83e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.771, tt:2749.594\n",
      "Ep:111, loss:0.00000, loss_test:0.08490, lr:6.76e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.765, tt:2773.703\n",
      "Ep:112, loss:0.00000, loss_test:0.08454, lr:6.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.779, tt:2800.041\n",
      "Ep:113, loss:0.00000, loss_test:0.08375, lr:6.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.786, tt:2825.584\n",
      "Ep:114, loss:0.00000, loss_test:0.08399, lr:6.56e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.801, tt:2852.075\n",
      "Ep:115, loss:0.00000, loss_test:0.08432, lr:6.49e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.800, tt:2876.752\n",
      "Ep:116, loss:0.00000, loss_test:0.08341, lr:6.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.802, tt:2901.775\n",
      "Ep:117, loss:0.00000, loss_test:0.08420, lr:6.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.793, tt:2925.593\n",
      "Ep:118, loss:0.00000, loss_test:0.08474, lr:6.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.798, tt:2951.003\n",
      "Ep:119, loss:0.00000, loss_test:0.08373, lr:6.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.803, tt:2976.379\n",
      "Ep:120, loss:0.00000, loss_test:0.08469, lr:6.17e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.799, tt:3000.674\n",
      "Ep:121, loss:0.00000, loss_test:0.08505, lr:6.11e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.808, tt:3026.547\n",
      "Ep:122, loss:0.00000, loss_test:0.08380, lr:6.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.803, tt:3050.826\n",
      "Ep:123, loss:0.00000, loss_test:0.08458, lr:5.99e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.795, tt:3074.541\n",
      "Ep:124, loss:0.00000, loss_test:0.08504, lr:5.93e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.791, tt:3098.902\n",
      "Ep:125, loss:0.00000, loss_test:0.08339, lr:5.87e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.806, tt:3125.550\n",
      "Ep:126, loss:0.00000, loss_test:0.08390, lr:5.81e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.800, tt:3149.644\n",
      "Ep:127, loss:0.00000, loss_test:0.08385, lr:5.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.803, tt:3174.811\n",
      "Ep:128, loss:0.00000, loss_test:0.08424, lr:5.70e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.798, tt:3198.910\n",
      "Ep:129, loss:0.00000, loss_test:0.08456, lr:5.64e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.807, tt:3224.912\n",
      "Ep:130, loss:0.00000, loss_test:0.08333, lr:5.58e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.811, tt:3250.302\n",
      "Ep:131, loss:0.00000, loss_test:0.08455, lr:5.53e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.797, tt:3273.194\n",
      "Ep:132, loss:0.00000, loss_test:0.08475, lr:5.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:24.779, tt:3295.655\n",
      "Ep:133, loss:0.00000, loss_test:0.08394, lr:5.42e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.768, tt:3318.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.08410, lr:5.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.760, tt:3342.659\n",
      "Ep:135, loss:0.00000, loss_test:0.08361, lr:5.31e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.759, tt:3367.245\n",
      "Ep:136, loss:0.00000, loss_test:0.08372, lr:5.26e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.750, tt:3390.756\n",
      "Ep:137, loss:0.00000, loss_test:0.08439, lr:5.20e-03, fs:0.78824 (r=0.677,p=0.944),  time:24.743, tt:3414.509\n",
      "Ep:138, loss:0.00000, loss_test:0.08391, lr:5.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.743, tt:3439.329\n",
      "Ep:139, loss:0.00000, loss_test:0.08413, lr:5.10e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.741, tt:3463.692\n",
      "Ep:140, loss:0.00000, loss_test:0.08423, lr:5.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.741, tt:3488.492\n",
      "Ep:141, loss:0.00000, loss_test:0.08376, lr:5.00e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.735, tt:3512.379\n",
      "Ep:142, loss:0.00000, loss_test:0.08355, lr:4.95e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.741, tt:3538.027\n",
      "Ep:143, loss:0.00000, loss_test:0.08369, lr:4.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.743, tt:3562.970\n",
      "Ep:144, loss:0.00000, loss_test:0.08388, lr:4.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.751, tt:3588.873\n",
      "Ep:145, loss:0.00000, loss_test:0.08378, lr:4.80e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.744, tt:3612.569\n",
      "Ep:146, loss:0.00000, loss_test:0.08474, lr:4.75e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.733, tt:3635.781\n",
      "Ep:147, loss:0.00000, loss_test:0.08524, lr:4.71e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.743, tt:3661.987\n",
      "Ep:148, loss:0.00000, loss_test:0.08400, lr:4.66e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.734, tt:3685.415\n",
      "Ep:149, loss:0.00000, loss_test:0.08366, lr:4.61e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.737, tt:3710.524\n",
      "Ep:150, loss:0.00000, loss_test:0.08444, lr:4.57e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.735, tt:3735.036\n",
      "Ep:151, loss:0.00000, loss_test:0.08423, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.731, tt:3759.178\n",
      "Ep:152, loss:0.00000, loss_test:0.08438, lr:4.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:24.726, tt:3783.081\n",
      "Ep:153, loss:0.00000, loss_test:0.08426, lr:4.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:24.728, tt:3808.145\n",
      "Ep:154, loss:0.00000, loss_test:0.08345, lr:4.39e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.719, tt:3831.441\n",
      "Ep:155, loss:0.00000, loss_test:0.08419, lr:4.34e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.715, tt:3855.617\n",
      "Ep:156, loss:0.00000, loss_test:0.08378, lr:4.30e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.714, tt:3880.082\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13554, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:21.839, tt:21.839\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13120, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:22.220, tt:44.440\n",
      "Ep:2, loss:0.00027, loss_test:0.12300, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:21.708, tt:65.123\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11262, lr:1.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:22.312, tt:89.247\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.10769, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:22.847, tt:114.237\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10442, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:22.948, tt:137.686\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10108, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:23.479, tt:164.354\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.09901, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:23.302, tt:186.415\n",
      "Ep:8, loss:0.00022, loss_test:0.09441, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:23.564, tt:212.076\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09334, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:23.474, tt:234.743\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09324, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:23.527, tt:258.795\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09122, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:23.626, tt:283.508\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.08877, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:23.589, tt:306.658\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.08753, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:23.563, tt:329.887\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08677, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:23.538, tt:353.074\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08547, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:23.592, tt:377.475\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08302, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:23.533, tt:400.060\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08201, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:23.819, tt:428.739\n",
      "Ep:18, loss:0.00014, loss_test:0.08227, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:23.796, tt:452.119\n",
      "Ep:19, loss:0.00013, loss_test:0.07906, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:23.862, tt:477.242\n",
      "Ep:20, loss:0.00013, loss_test:0.07726, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:23.814, tt:500.091\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07745, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:23.767, tt:522.873\n",
      "Ep:22, loss:0.00012, loss_test:0.07493, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:23.826, tt:548.002\n",
      "Ep:23, loss:0.00011, loss_test:0.07326, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:23.864, tt:572.743\n",
      "Ep:24, loss:0.00011, loss_test:0.07373, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:23.921, tt:598.034\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.07135, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:23.935, tt:622.313\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07067, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:23.956, tt:646.820\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.06949, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:23.988, tt:671.650\n",
      "Ep:28, loss:0.00009, loss_test:0.06904, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:24.071, tt:698.058\n",
      "Ep:29, loss:0.00008, loss_test:0.06738, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:24.089, tt:722.682\n",
      "Ep:30, loss:0.00008, loss_test:0.06734, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:24.122, tt:747.780\n",
      "Ep:31, loss:0.00008, loss_test:0.06505, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:24.062, tt:769.998\n",
      "Ep:32, loss:0.00007, loss_test:0.06596, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:24.029, tt:792.950\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.06553, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:24.033, tt:817.114\n",
      "Ep:34, loss:0.00007, loss_test:0.06379, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:24.039, tt:841.378\n",
      "Ep:35, loss:0.00007, loss_test:0.06692, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:24.048, tt:865.714\n",
      "Ep:36, loss:0.00006, loss_test:0.06370, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:24.001, tt:888.046\n",
      "Ep:37, loss:0.00006, loss_test:0.06524, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:24.074, tt:914.797\n",
      "Ep:38, loss:0.00006, loss_test:0.06303, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:24.071, tt:938.765\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.06461, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:24.098, tt:963.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00005, loss_test:0.06294, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:24.099, tt:988.039\n",
      "Ep:41, loss:0.00005, loss_test:0.06308, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.140, tt:1013.891\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06254, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.143, tt:1038.155\n",
      "Ep:43, loss:0.00005, loss_test:0.06112, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:24.158, tt:1062.935\n",
      "Ep:44, loss:0.00005, loss_test:0.06191, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:24.114, tt:1085.123\n",
      "Ep:45, loss:0.00004, loss_test:0.06073, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.070, tt:1107.215\n",
      "Ep:46, loss:0.00004, loss_test:0.06118, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.063, tt:1130.951\n",
      "Ep:47, loss:0.00004, loss_test:0.06041, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.093, tt:1156.455\n",
      "Ep:48, loss:0.00004, loss_test:0.05936, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:24.113, tt:1181.532\n",
      "Ep:49, loss:0.00004, loss_test:0.06187, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:24.090, tt:1204.493\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.05897, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.085, tt:1228.345\n",
      "Ep:51, loss:0.00004, loss_test:0.06071, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.085, tt:1252.401\n",
      "Ep:52, loss:0.00004, loss_test:0.06102, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.098, tt:1277.202\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.05813, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:24.109, tt:1301.875\n",
      "Ep:54, loss:0.00003, loss_test:0.06156, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.147, tt:1328.112\n",
      "Ep:55, loss:0.00003, loss_test:0.06037, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.151, tt:1352.463\n",
      "Ep:56, loss:0.00003, loss_test:0.05874, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:24.144, tt:1376.189\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.06199, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.201, tt:1403.636\n",
      "Ep:58, loss:0.00003, loss_test:0.05749, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:24.174, tt:1426.262\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.05966, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:24.198, tt:1451.904\n",
      "Ep:60, loss:0.00003, loss_test:0.05799, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.213, tt:1476.967\n",
      "Ep:61, loss:0.00002, loss_test:0.05911, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.223, tt:1501.819\n",
      "Ep:62, loss:0.00002, loss_test:0.05795, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:24.210, tt:1525.246\n",
      "Ep:63, loss:0.00002, loss_test:0.05534, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:24.206, tt:1549.174\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.05903, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.185, tt:1572.030\n",
      "Ep:65, loss:0.00002, loss_test:0.05769, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:24.213, tt:1598.031\n",
      "Ep:66, loss:0.00002, loss_test:0.05687, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.208, tt:1621.913\n",
      "Ep:67, loss:0.00002, loss_test:0.05817, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:24.227, tt:1647.417\n",
      "Ep:68, loss:0.00002, loss_test:0.05705, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:24.235, tt:1672.197\n",
      "Ep:69, loss:0.00002, loss_test:0.05940, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.267, tt:1698.724\n",
      "Ep:70, loss:0.00002, loss_test:0.05598, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:24.266, tt:1722.874\n",
      "Ep:71, loss:0.00002, loss_test:0.05703, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.279, tt:1748.089\n",
      "Ep:72, loss:0.00002, loss_test:0.05611, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.294, tt:1773.498\n",
      "Ep:73, loss:0.00002, loss_test:0.05459, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.310, tt:1798.962\n",
      "Ep:74, loss:0.00002, loss_test:0.05684, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.305, tt:1822.911\n",
      "Ep:75, loss:0.00001, loss_test:0.05579, lr:9.90e-03, fs:0.89130 (r=0.828,p=0.965),  time:24.282, tt:1845.410\n",
      "Ep:76, loss:0.00001, loss_test:0.05439, lr:9.80e-03, fs:0.89130 (r=0.828,p=0.965),  time:24.282, tt:1869.743\n",
      "Ep:77, loss:0.00002, loss_test:0.05896, lr:9.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.317, tt:1896.704\n",
      "Ep:78, loss:0.00002, loss_test:0.05579, lr:9.61e-03, fs:0.89617 (r=0.828,p=0.976),  time:24.325, tt:1921.707\n",
      "Ep:79, loss:0.00002, loss_test:0.05480, lr:9.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:24.319, tt:1945.531\n",
      "Ep:80, loss:0.00002, loss_test:0.06070, lr:9.41e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.327, tt:1970.465\n",
      "Ep:81, loss:0.00001, loss_test:0.05363, lr:9.32e-03, fs:0.90323 (r=0.848,p=0.966),  time:24.315, tt:1993.813\n",
      "Ep:82, loss:0.00001, loss_test:0.05787, lr:9.23e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.311, tt:2017.846\n",
      "Ep:83, loss:0.00001, loss_test:0.05490, lr:9.14e-03, fs:0.89730 (r=0.838,p=0.965),  time:24.326, tt:2043.383\n",
      "Ep:84, loss:0.00001, loss_test:0.05512, lr:9.04e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.319, tt:2067.090\n",
      "Ep:85, loss:0.00001, loss_test:0.05604, lr:8.95e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.315, tt:2091.116\n",
      "Ep:86, loss:0.00001, loss_test:0.05560, lr:8.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.311, tt:2115.088\n",
      "Ep:87, loss:0.00001, loss_test:0.05450, lr:8.78e-03, fs:0.89617 (r=0.828,p=0.976),  time:24.335, tt:2141.499\n",
      "Ep:88, loss:0.00001, loss_test:0.05602, lr:8.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.358, tt:2167.879\n",
      "Ep:89, loss:0.00001, loss_test:0.05635, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.351, tt:2191.619\n",
      "Ep:90, loss:0.00001, loss_test:0.05386, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.371, tt:2217.783\n",
      "Ep:91, loss:0.00001, loss_test:0.05514, lr:8.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.393, tt:2244.202\n",
      "Ep:92, loss:0.00001, loss_test:0.05463, lr:8.35e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.395, tt:2268.702\n",
      "Ep:93, loss:0.00001, loss_test:0.05516, lr:8.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.406, tt:2294.145\n",
      "Ep:94, loss:0.00001, loss_test:0.05444, lr:8.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.410, tt:2318.963\n",
      "Ep:95, loss:0.00001, loss_test:0.05577, lr:8.10e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.445, tt:2346.706\n",
      "Ep:96, loss:0.00001, loss_test:0.05433, lr:8.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.453, tt:2371.914\n",
      "Ep:97, loss:0.00001, loss_test:0.05573, lr:7.94e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.458, tt:2396.873\n",
      "Ep:98, loss:0.00001, loss_test:0.05558, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.444, tt:2419.981\n",
      "Ep:99, loss:0.00001, loss_test:0.05537, lr:7.78e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.439, tt:2443.875\n",
      "Ep:100, loss:0.00001, loss_test:0.05642, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.428, tt:2467.193\n",
      "Ep:101, loss:0.00001, loss_test:0.05462, lr:7.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.419, tt:2490.760\n",
      "Ep:102, loss:0.00001, loss_test:0.05616, lr:7.55e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.419, tt:2515.200\n",
      "Ep:103, loss:0.00001, loss_test:0.05481, lr:7.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.429, tt:2540.619\n",
      "Ep:104, loss:0.00001, loss_test:0.05564, lr:7.40e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.447, tt:2566.947\n",
      "Ep:105, loss:0.00001, loss_test:0.05468, lr:7.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.442, tt:2590.839\n",
      "Ep:106, loss:0.00001, loss_test:0.05619, lr:7.25e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.443, tt:2615.439\n",
      "Ep:107, loss:0.00001, loss_test:0.05768, lr:7.18e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.419, tt:2637.199\n",
      "Ep:108, loss:0.00001, loss_test:0.05557, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.422, tt:2662.029\n",
      "Ep:109, loss:0.00001, loss_test:0.05550, lr:7.03e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.406, tt:2684.713\n",
      "Ep:110, loss:0.00001, loss_test:0.05631, lr:6.96e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.409, tt:2709.416\n",
      "Ep:111, loss:0.00001, loss_test:0.05539, lr:6.89e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.395, tt:2732.284\n",
      "Ep:112, loss:0.00001, loss_test:0.05524, lr:6.83e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.395, tt:2756.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00001, loss_test:0.05608, lr:6.76e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.391, tt:2780.613\n",
      "Ep:114, loss:0.00001, loss_test:0.05584, lr:6.69e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.406, tt:2806.634\n",
      "Ep:115, loss:0.00001, loss_test:0.05560, lr:6.62e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.405, tt:2830.934\n",
      "Ep:116, loss:0.00000, loss_test:0.05680, lr:6.56e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.400, tt:2854.792\n",
      "Ep:117, loss:0.00000, loss_test:0.05671, lr:6.49e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.411, tt:2880.540\n",
      "Ep:118, loss:0.00000, loss_test:0.05561, lr:6.43e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.413, tt:2905.163\n",
      "Ep:119, loss:0.00000, loss_test:0.05682, lr:6.36e-03, fs:0.88268 (r=0.798,p=0.988),  time:24.424, tt:2930.907\n",
      "Ep:120, loss:0.00000, loss_test:0.05604, lr:6.30e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.414, tt:2954.106\n",
      "Ep:121, loss:0.00000, loss_test:0.05691, lr:6.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.413, tt:2978.404\n",
      "Ep:122, loss:0.00000, loss_test:0.05670, lr:6.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.415, tt:3003.009\n",
      "Ep:123, loss:0.00000, loss_test:0.05662, lr:6.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.403, tt:3025.941\n",
      "Ep:124, loss:0.00000, loss_test:0.05663, lr:6.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.408, tt:3051.018\n",
      "Ep:125, loss:0.00000, loss_test:0.05633, lr:5.99e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.409, tt:3075.503\n",
      "Ep:126, loss:0.00000, loss_test:0.05692, lr:5.93e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.414, tt:3100.628\n",
      "Ep:127, loss:0.00000, loss_test:0.05654, lr:5.87e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.402, tt:3123.480\n",
      "Ep:128, loss:0.00000, loss_test:0.05708, lr:5.81e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.403, tt:3147.971\n",
      "Ep:129, loss:0.00000, loss_test:0.05725, lr:5.75e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.409, tt:3173.168\n",
      "Ep:130, loss:0.00000, loss_test:0.05633, lr:5.70e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.412, tt:3197.940\n",
      "Ep:131, loss:0.00000, loss_test:0.05737, lr:5.64e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.397, tt:3220.439\n",
      "Ep:132, loss:0.00000, loss_test:0.05750, lr:5.58e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.387, tt:3243.508\n",
      "Ep:133, loss:0.00000, loss_test:0.05741, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.384, tt:3267.463\n",
      "Ep:134, loss:0.00000, loss_test:0.05663, lr:5.47e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.379, tt:3291.223\n",
      "Ep:135, loss:0.00000, loss_test:0.05716, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.389, tt:3316.907\n",
      "Ep:136, loss:0.00000, loss_test:0.05759, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.377, tt:3339.698\n",
      "Ep:137, loss:0.00000, loss_test:0.05706, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.373, tt:3363.439\n",
      "Ep:138, loss:0.00000, loss_test:0.05701, lr:5.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.363, tt:3386.487\n",
      "Ep:139, loss:0.00000, loss_test:0.05716, lr:5.20e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.372, tt:3412.030\n",
      "Ep:140, loss:0.00000, loss_test:0.05739, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.368, tt:3435.899\n",
      "Ep:141, loss:0.00000, loss_test:0.05730, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.374, tt:3461.161\n",
      "Ep:142, loss:0.00000, loss_test:0.05691, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.378, tt:3486.083\n",
      "Ep:143, loss:0.00000, loss_test:0.05790, lr:5.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.400, tt:3513.581\n",
      "Ep:144, loss:0.00000, loss_test:0.05751, lr:4.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.413, tt:3539.855\n",
      "Ep:145, loss:0.00000, loss_test:0.05688, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.417, tt:3564.919\n",
      "Ep:146, loss:0.00000, loss_test:0.05757, lr:4.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.419, tt:3589.545\n",
      "Ep:147, loss:0.00000, loss_test:0.05742, lr:4.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.421, tt:3614.312\n",
      "Ep:148, loss:0.00000, loss_test:0.05736, lr:4.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.422, tt:3638.843\n",
      "Ep:149, loss:0.00000, loss_test:0.05721, lr:4.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.412, tt:3661.827\n",
      "Ep:150, loss:0.00000, loss_test:0.05726, lr:4.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.408, tt:3685.576\n",
      "Ep:151, loss:0.00000, loss_test:0.05744, lr:4.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.397, tt:3708.369\n",
      "Ep:152, loss:0.00000, loss_test:0.05735, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.392, tt:3731.971\n",
      "Ep:153, loss:0.00000, loss_test:0.05724, lr:4.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.388, tt:3755.810\n",
      "Ep:154, loss:0.00000, loss_test:0.05741, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.388, tt:3780.163\n",
      "Ep:155, loss:0.00000, loss_test:0.05724, lr:4.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.392, tt:3805.122\n",
      "Ep:156, loss:0.00000, loss_test:0.05718, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.409, tt:3832.219\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14167, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:33.078, tt:33.078\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13937, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:33.492, tt:66.984\n",
      "Ep:2, loss:0.00027, loss_test:0.13524, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:36.685, tt:110.055\n",
      "Ep:3, loss:0.00025, loss_test:0.12865, lr:1.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:37.919, tt:151.678\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.12221, lr:1.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:39.089, tt:195.443\n",
      "Ep:5, loss:0.00022, loss_test:0.11953, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:39.852, tt:239.111\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00021, loss_test:0.11750, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:39.965, tt:279.752\n",
      "Ep:7, loss:0.00021, loss_test:0.11484, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:40.539, tt:324.308\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00020, loss_test:0.11335, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:41.068, tt:369.609\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.11213, lr:1.00e-02, fs:0.68868 (r=0.737,p=0.646),  time:41.334, tt:413.344\n",
      "Ep:10, loss:0.00019, loss_test:0.11001, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:41.518, tt:456.695\n",
      "Ep:11, loss:0.00018, loss_test:0.11000, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:41.610, tt:499.318\n",
      "Ep:12, loss:0.00018, loss_test:0.10908, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:41.519, tt:539.750\n",
      "Ep:13, loss:0.00017, loss_test:0.10774, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:41.580, tt:582.121\n",
      "Ep:14, loss:0.00017, loss_test:0.10804, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:41.602, tt:624.033\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.10856, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:41.743, tt:667.896\n",
      "Ep:16, loss:0.00016, loss_test:0.10724, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:42.010, tt:714.171\n",
      "Ep:17, loss:0.00016, loss_test:0.10688, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:42.062, tt:757.108\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10665, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:42.104, tt:799.975\n",
      "Ep:19, loss:0.00015, loss_test:0.10714, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:42.053, tt:841.051\n",
      "Ep:20, loss:0.00015, loss_test:0.10684, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:42.082, tt:883.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00014, loss_test:0.10588, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:42.157, tt:927.449\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.10624, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:42.188, tt:970.321\n",
      "Ep:23, loss:0.00014, loss_test:0.10595, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.165, tt:1011.952\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.10437, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:42.163, tt:1054.083\n",
      "Ep:25, loss:0.00013, loss_test:0.10484, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.221, tt:1097.735\n",
      "Ep:26, loss:0.00013, loss_test:0.10568, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.228, tt:1140.155\n",
      "Ep:27, loss:0.00013, loss_test:0.10257, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:42.194, tt:1181.425\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.10413, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.161, tt:1222.658\n",
      "Ep:29, loss:0.00012, loss_test:0.10314, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:42.131, tt:1263.935\n",
      "Ep:30, loss:0.00012, loss_test:0.10236, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:42.047, tt:1303.472\n",
      "Ep:31, loss:0.00012, loss_test:0.10370, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:42.042, tt:1345.360\n",
      "Ep:32, loss:0.00012, loss_test:0.10134, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.064, tt:1388.102\n",
      "Ep:33, loss:0.00011, loss_test:0.10278, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.075, tt:1430.546\n",
      "Ep:34, loss:0.00011, loss_test:0.10266, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.047, tt:1471.646\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.10014, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:42.080, tt:1514.867\n",
      "Ep:36, loss:0.00011, loss_test:0.10268, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.122, tt:1558.503\n",
      "Ep:37, loss:0.00011, loss_test:0.10054, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:42.090, tt:1599.420\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.10320, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.111, tt:1642.325\n",
      "Ep:39, loss:0.00010, loss_test:0.10026, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:42.157, tt:1686.277\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.10230, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:42.167, tt:1728.866\n",
      "Ep:41, loss:0.00010, loss_test:0.10040, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:42.186, tt:1771.798\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.10010, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:42.188, tt:1814.086\n",
      "Ep:43, loss:0.00009, loss_test:0.10091, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:42.190, tt:1856.353\n",
      "Ep:44, loss:0.00009, loss_test:0.10037, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:42.200, tt:1898.978\n",
      "Ep:45, loss:0.00009, loss_test:0.10099, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:42.182, tt:1940.366\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.09950, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:42.194, tt:1983.096\n",
      "Ep:47, loss:0.00009, loss_test:0.10001, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:42.226, tt:2026.848\n",
      "Ep:48, loss:0.00009, loss_test:0.09958, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:42.253, tt:2070.410\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.10006, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:42.285, tt:2114.273\n",
      "Ep:50, loss:0.00008, loss_test:0.09893, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:42.276, tt:2156.090\n",
      "Ep:51, loss:0.00008, loss_test:0.09815, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:42.305, tt:2199.877\n",
      "Ep:52, loss:0.00008, loss_test:0.09945, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:42.333, tt:2243.669\n",
      "Ep:53, loss:0.00008, loss_test:0.09758, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:42.359, tt:2287.405\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.09796, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:42.342, tt:2328.837\n",
      "Ep:55, loss:0.00007, loss_test:0.09790, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:42.318, tt:2369.804\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.09614, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:42.337, tt:2413.226\n",
      "Ep:57, loss:0.00007, loss_test:0.09799, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:42.341, tt:2455.793\n",
      "Ep:58, loss:0.00007, loss_test:0.09766, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:42.344, tt:2498.289\n",
      "Ep:59, loss:0.00007, loss_test:0.09684, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:42.361, tt:2541.680\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00007, loss_test:0.09604, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:42.378, tt:2585.080\n",
      "Ep:61, loss:0.00006, loss_test:0.09585, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:42.388, tt:2628.056\n",
      "Ep:62, loss:0.00006, loss_test:0.09598, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:42.350, tt:2668.041\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.09698, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:42.318, tt:2708.381\n",
      "Ep:64, loss:0.00008, loss_test:0.09977, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:42.286, tt:2748.623\n",
      "Ep:65, loss:0.00006, loss_test:0.09755, lr:1.00e-02, fs:0.70238 (r=0.596,p=0.855),  time:42.288, tt:2791.037\n",
      "Ep:66, loss:0.00007, loss_test:0.09914, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:42.319, tt:2835.373\n",
      "Ep:67, loss:0.00008, loss_test:0.09855, lr:1.00e-02, fs:0.71084 (r=0.596,p=0.881),  time:42.309, tt:2877.024\n",
      "Ep:68, loss:0.00009, loss_test:0.09254, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.321, tt:2920.131\n",
      "Ep:69, loss:0.00007, loss_test:0.09896, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:42.365, tt:2965.571\n",
      "Ep:70, loss:0.00007, loss_test:0.09127, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:42.358, tt:3007.442\n",
      "Ep:71, loss:0.00006, loss_test:0.09072, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:42.370, tt:3050.609\n",
      "Ep:72, loss:0.00006, loss_test:0.09560, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:42.383, tt:3093.964\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00006, loss_test:0.08993, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.384, tt:3136.431\n",
      "Ep:74, loss:0.00006, loss_test:0.09290, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:42.408, tt:3180.574\n",
      "Ep:75, loss:0.00005, loss_test:0.09053, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:42.380, tt:3220.914\n",
      "Ep:76, loss:0.00005, loss_test:0.09168, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:42.364, tt:3262.065\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.09163, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:42.367, tt:3304.665\n",
      "Ep:78, loss:0.00005, loss_test:0.09125, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:42.363, tt:3346.683\n",
      "Ep:79, loss:0.00005, loss_test:0.09120, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:42.356, tt:3388.502\n",
      "Ep:80, loss:0.00005, loss_test:0.09087, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:42.345, tt:3429.962\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.08914, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:42.362, tt:3473.647\n",
      "Ep:82, loss:0.00005, loss_test:0.08862, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:42.351, tt:3515.170\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00005, loss_test:0.09351, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:42.346, tt:3557.058\n",
      "Ep:84, loss:0.00004, loss_test:0.08949, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:42.363, tt:3600.887\n",
      "Ep:85, loss:0.00004, loss_test:0.09116, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:42.377, tt:3644.415\n",
      "Ep:86, loss:0.00004, loss_test:0.09271, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:42.374, tt:3686.539\n",
      "Ep:87, loss:0.00004, loss_test:0.08830, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:42.395, tt:3730.790\n",
      "Ep:88, loss:0.00004, loss_test:0.09021, lr:1.00e-02, fs:0.70659 (r=0.596,p=0.868),  time:42.414, tt:3774.889\n",
      "Ep:89, loss:0.00004, loss_test:0.09070, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:42.437, tt:3819.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00004, loss_test:0.08657, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:42.429, tt:3861.060\n",
      "Ep:91, loss:0.00004, loss_test:0.09543, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.436, tt:3904.067\n",
      "Ep:92, loss:0.00004, loss_test:0.08627, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:42.422, tt:3945.202\n",
      "Ep:93, loss:0.00004, loss_test:0.09425, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:42.419, tt:3987.402\n",
      "Ep:94, loss:0.00004, loss_test:0.09301, lr:9.90e-03, fs:0.71429 (r=0.606,p=0.870),  time:42.416, tt:4029.493\n",
      "Ep:95, loss:0.00004, loss_test:0.09061, lr:9.80e-03, fs:0.79558 (r=0.727,p=0.878),  time:42.402, tt:4070.552\n",
      "Ep:96, loss:0.00004, loss_test:0.09020, lr:9.70e-03, fs:0.74713 (r=0.657,p=0.867),  time:42.408, tt:4113.531\n",
      "Ep:97, loss:0.00004, loss_test:0.09166, lr:9.61e-03, fs:0.75581 (r=0.657,p=0.890),  time:42.396, tt:4154.817\n",
      "Ep:98, loss:0.00003, loss_test:0.09153, lr:9.51e-03, fs:0.71006 (r=0.606,p=0.857),  time:42.408, tt:4198.409\n",
      "Ep:99, loss:0.00003, loss_test:0.09228, lr:9.41e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.417, tt:4241.654\n",
      "Ep:100, loss:0.00003, loss_test:0.09284, lr:9.32e-03, fs:0.72289 (r=0.606,p=0.896),  time:42.404, tt:4282.776\n",
      "Ep:101, loss:0.00003, loss_test:0.09421, lr:9.23e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.413, tt:4326.136\n",
      "Ep:102, loss:0.00003, loss_test:0.08987, lr:9.14e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.424, tt:4369.700\n",
      "Ep:103, loss:0.00003, loss_test:0.09653, lr:9.04e-03, fs:0.70732 (r=0.586,p=0.892),  time:42.422, tt:4411.927\n",
      "Ep:104, loss:0.00003, loss_test:0.09132, lr:8.95e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.411, tt:4453.174\n",
      "Ep:105, loss:0.00003, loss_test:0.09136, lr:8.86e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.414, tt:4495.839\n",
      "Ep:106, loss:0.00003, loss_test:0.09469, lr:8.78e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.411, tt:4538.025\n",
      "Ep:107, loss:0.00003, loss_test:0.09248, lr:8.69e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.411, tt:4580.350\n",
      "Ep:108, loss:0.00003, loss_test:0.09142, lr:8.60e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.414, tt:4623.160\n",
      "Ep:109, loss:0.00003, loss_test:0.09768, lr:8.51e-03, fs:0.71166 (r=0.586,p=0.906),  time:42.411, tt:4665.228\n",
      "Ep:110, loss:0.00003, loss_test:0.09014, lr:8.43e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.419, tt:4708.511\n",
      "Ep:111, loss:0.00003, loss_test:0.09578, lr:8.35e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.440, tt:4753.235\n",
      "Ep:112, loss:0.00003, loss_test:0.09114, lr:8.26e-03, fs:0.72727 (r=0.606,p=0.909),  time:42.444, tt:4796.143\n",
      "Ep:113, loss:0.00003, loss_test:0.09366, lr:8.18e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.445, tt:4838.733\n",
      "Ep:114, loss:0.00003, loss_test:0.09501, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.465, tt:4883.485\n",
      "Ep:115, loss:0.00003, loss_test:0.09159, lr:8.02e-03, fs:0.81111 (r=0.737,p=0.901),  time:42.458, tt:4925.172\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00003, loss_test:0.09664, lr:8.02e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.449, tt:4966.503\n",
      "Ep:117, loss:0.00003, loss_test:0.09498, lr:8.02e-03, fs:0.71856 (r=0.606,p=0.882),  time:42.456, tt:5009.810\n",
      "Ep:118, loss:0.00003, loss_test:0.09387, lr:8.02e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.470, tt:5053.944\n",
      "Ep:119, loss:0.00003, loss_test:0.09501, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.457, tt:5094.828\n",
      "Ep:120, loss:0.00003, loss_test:0.09528, lr:8.02e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.481, tt:5140.259\n",
      "Ep:121, loss:0.00003, loss_test:0.09401, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.481, tt:5182.625\n",
      "Ep:122, loss:0.00003, loss_test:0.09470, lr:8.02e-03, fs:0.71856 (r=0.606,p=0.882),  time:42.480, tt:5225.040\n",
      "Ep:123, loss:0.00003, loss_test:0.09464, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.473, tt:5266.700\n",
      "Ep:124, loss:0.00003, loss_test:0.09461, lr:8.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.485, tt:5310.617\n",
      "Ep:125, loss:0.00002, loss_test:0.09216, lr:8.02e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.496, tt:5354.485\n",
      "Ep:126, loss:0.00002, loss_test:0.09688, lr:8.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.490, tt:5396.260\n",
      "Ep:127, loss:0.00002, loss_test:0.09109, lr:7.94e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.487, tt:5438.360\n",
      "Ep:128, loss:0.00002, loss_test:0.09939, lr:7.86e-03, fs:0.71250 (r=0.576,p=0.934),  time:42.482, tt:5480.215\n",
      "Ep:129, loss:0.00003, loss_test:0.09208, lr:7.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.495, tt:5524.402\n",
      "Ep:130, loss:0.00002, loss_test:0.09620, lr:7.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.492, tt:5566.438\n",
      "Ep:131, loss:0.00002, loss_test:0.09492, lr:7.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.491, tt:5608.846\n",
      "Ep:132, loss:0.00002, loss_test:0.09471, lr:7.55e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.505, tt:5653.146\n",
      "Ep:133, loss:0.00002, loss_test:0.09440, lr:7.47e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.502, tt:5695.320\n",
      "Ep:134, loss:0.00002, loss_test:0.09600, lr:7.40e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.509, tt:5738.715\n",
      "Ep:135, loss:0.00002, loss_test:0.09229, lr:7.32e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.488, tt:5778.427\n",
      "Ep:136, loss:0.00002, loss_test:0.09625, lr:7.25e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.453, tt:5816.118\n",
      "Ep:137, loss:0.00002, loss_test:0.09280, lr:7.18e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.446, tt:5857.482\n",
      "Ep:138, loss:0.00002, loss_test:0.09744, lr:7.11e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.432, tt:5898.118\n",
      "Ep:139, loss:0.00002, loss_test:0.09318, lr:7.03e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.430, tt:5940.221\n",
      "Ep:140, loss:0.00002, loss_test:0.09414, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.465, tt:5987.568\n",
      "Ep:141, loss:0.00002, loss_test:0.09315, lr:6.89e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.475, tt:6031.499\n",
      "Ep:142, loss:0.00002, loss_test:0.09671, lr:6.83e-03, fs:0.71250 (r=0.576,p=0.934),  time:42.480, tt:6074.590\n",
      "Ep:143, loss:0.00002, loss_test:0.09345, lr:6.76e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.492, tt:6118.837\n",
      "Ep:144, loss:0.00002, loss_test:0.09561, lr:6.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:42.494, tt:6161.582\n",
      "Ep:145, loss:0.00002, loss_test:0.09279, lr:6.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.499, tt:6204.886\n",
      "Ep:146, loss:0.00002, loss_test:0.09563, lr:6.56e-03, fs:0.72393 (r=0.596,p=0.922),  time:42.498, tt:6247.260\n",
      "Ep:147, loss:0.00002, loss_test:0.09442, lr:6.49e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.516, tt:6292.422\n",
      "Ep:148, loss:0.00002, loss_test:0.09407, lr:6.43e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.510, tt:6333.995\n",
      "Ep:149, loss:0.00002, loss_test:0.09408, lr:6.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.514, tt:6377.040\n",
      "Ep:150, loss:0.00002, loss_test:0.09661, lr:6.30e-03, fs:0.72393 (r=0.596,p=0.922),  time:42.511, tt:6419.131\n",
      "Ep:151, loss:0.00002, loss_test:0.09547, lr:6.24e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.510, tt:6461.504\n",
      "Ep:152, loss:0.00002, loss_test:0.09414, lr:6.17e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.530, tt:6507.164\n",
      "Ep:153, loss:0.00002, loss_test:0.09572, lr:6.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.529, tt:6549.456\n",
      "Ep:154, loss:0.00002, loss_test:0.09515, lr:6.05e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.533, tt:6592.651\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13537, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.815, tt:34.815\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13151, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:34.618, tt:69.236\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12491, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:37.360, tt:112.080\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11417, lr:1.00e-02, fs:0.70896 (r=0.960,p=0.562),  time:39.054, tt:156.217\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00024, loss_test:0.10399, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:39.318, tt:196.592\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.09702, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:39.702, tt:238.212\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.09338, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.218, tt:281.528\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00021, loss_test:0.09394, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:40.504, tt:324.034\n",
      "Ep:8, loss:0.00021, loss_test:0.09161, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:40.709, tt:366.378\n",
      "Ep:9, loss:0.00020, loss_test:0.08896, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:40.996, tt:409.962\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.08929, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:41.179, tt:452.966\n",
      "Ep:11, loss:0.00019, loss_test:0.08757, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:41.263, tt:495.157\n",
      "Ep:12, loss:0.00018, loss_test:0.08444, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:41.442, tt:538.750\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.08286, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:41.763, tt:584.688\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08462, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:41.858, tt:627.863\n",
      "Ep:15, loss:0.00017, loss_test:0.08333, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:42.052, tt:672.834\n",
      "Ep:16, loss:0.00017, loss_test:0.08211, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:42.024, tt:714.403\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08318, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:42.038, tt:756.689\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.08277, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:42.143, tt:800.721\n",
      "Ep:19, loss:0.00015, loss_test:0.08118, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:42.226, tt:844.518\n",
      "Ep:20, loss:0.00015, loss_test:0.07976, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:42.326, tt:888.836\n",
      "Ep:21, loss:0.00015, loss_test:0.07969, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:42.377, tt:932.303\n",
      "Ep:22, loss:0.00014, loss_test:0.07928, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:42.411, tt:975.456\n",
      "Ep:23, loss:0.00014, loss_test:0.07866, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:42.480, tt:1019.528\n",
      "Ep:24, loss:0.00014, loss_test:0.07863, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:42.529, tt:1063.222\n",
      "Ep:25, loss:0.00013, loss_test:0.07890, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:42.622, tt:1108.181\n",
      "Ep:26, loss:0.00013, loss_test:0.07853, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:42.694, tt:1152.735\n",
      "Ep:27, loss:0.00013, loss_test:0.07704, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:42.720, tt:1196.163\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07828, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.685, tt:1237.873\n",
      "Ep:29, loss:0.00012, loss_test:0.07661, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:42.765, tt:1282.945\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07955, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:42.747, tt:1325.155\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07706, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:42.754, tt:1368.128\n",
      "Ep:32, loss:0.00012, loss_test:0.07803, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:42.774, tt:1411.542\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07770, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:42.842, tt:1456.633\n",
      "Ep:34, loss:0.00011, loss_test:0.07816, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:42.848, tt:1499.677\n",
      "Ep:35, loss:0.00011, loss_test:0.07974, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:42.857, tt:1542.868\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07539, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:42.845, tt:1585.258\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08078, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:42.896, tt:1630.042\n",
      "Ep:38, loss:0.00010, loss_test:0.07454, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:42.875, tt:1672.144\n",
      "Ep:39, loss:0.00010, loss_test:0.07959, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.865, tt:1714.581\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07472, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:42.927, tt:1760.012\n",
      "Ep:41, loss:0.00010, loss_test:0.08008, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:42.919, tt:1802.608\n",
      "Ep:42, loss:0.00009, loss_test:0.07479, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:42.902, tt:1844.800\n",
      "Ep:43, loss:0.00009, loss_test:0.07796, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:42.885, tt:1886.938\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.07542, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.895, tt:1930.275\n",
      "Ep:45, loss:0.00009, loss_test:0.07934, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:42.903, tt:1973.535\n",
      "Ep:46, loss:0.00008, loss_test:0.07649, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:42.934, tt:2017.880\n",
      "Ep:47, loss:0.00008, loss_test:0.07821, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.988, tt:2063.436\n",
      "Ep:48, loss:0.00008, loss_test:0.07789, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:43.040, tt:2108.951\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.07955, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:43.051, tt:2152.550\n",
      "Ep:50, loss:0.00008, loss_test:0.07841, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:43.079, tt:2197.014\n",
      "Ep:51, loss:0.00008, loss_test:0.08136, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:43.119, tt:2242.198\n",
      "Ep:52, loss:0.00007, loss_test:0.07595, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:43.141, tt:2286.454\n",
      "Ep:53, loss:0.00007, loss_test:0.08419, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:43.148, tt:2330.018\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07678, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:43.158, tt:2373.684\n",
      "Ep:55, loss:0.00007, loss_test:0.08073, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:43.167, tt:2417.336\n",
      "Ep:56, loss:0.00007, loss_test:0.07974, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:43.196, tt:2462.184\n",
      "Ep:57, loss:0.00007, loss_test:0.07980, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:43.184, tt:2504.660\n",
      "Ep:58, loss:0.00006, loss_test:0.08022, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:43.148, tt:2545.707\n",
      "Ep:59, loss:0.00006, loss_test:0.07891, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:43.150, tt:2589.027\n",
      "Ep:60, loss:0.00006, loss_test:0.08772, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:43.141, tt:2631.576\n",
      "Ep:61, loss:0.00006, loss_test:0.07616, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:43.129, tt:2673.997\n",
      "Ep:62, loss:0.00006, loss_test:0.08568, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:43.090, tt:2714.667\n",
      "Ep:63, loss:0.00006, loss_test:0.07997, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:43.059, tt:2755.798\n",
      "Ep:64, loss:0.00006, loss_test:0.08304, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:43.036, tt:2797.371\n",
      "Ep:65, loss:0.00006, loss_test:0.08518, lr:9.90e-03, fs:0.82979 (r=0.788,p=0.876),  time:43.031, tt:2840.014\n",
      "Ep:66, loss:0.00006, loss_test:0.08246, lr:9.80e-03, fs:0.84817 (r=0.818,p=0.880),  time:43.030, tt:2883.040\n",
      "Ep:67, loss:0.00005, loss_test:0.07792, lr:9.70e-03, fs:0.84264 (r=0.838,p=0.847),  time:43.050, tt:2927.392\n",
      "Ep:68, loss:0.00005, loss_test:0.08643, lr:9.61e-03, fs:0.83422 (r=0.788,p=0.886),  time:43.013, tt:2967.906\n",
      "Ep:69, loss:0.00005, loss_test:0.08109, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.920, tt:3004.365\n",
      "Ep:70, loss:0.00005, loss_test:0.08144, lr:9.41e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.811, tt:3039.613\n",
      "Ep:71, loss:0.00005, loss_test:0.08181, lr:9.32e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.803, tt:3081.836\n",
      "Ep:72, loss:0.00005, loss_test:0.08180, lr:9.23e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.791, tt:3123.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00005, loss_test:0.08330, lr:9.14e-03, fs:0.82979 (r=0.788,p=0.876),  time:42.754, tt:3163.819\n",
      "Ep:74, loss:0.00005, loss_test:0.08323, lr:9.04e-03, fs:0.85128 (r=0.838,p=0.865),  time:42.777, tt:3208.262\n",
      "Ep:75, loss:0.00005, loss_test:0.08323, lr:8.95e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.806, tt:3253.283\n",
      "Ep:76, loss:0.00004, loss_test:0.08303, lr:8.86e-03, fs:0.85864 (r=0.828,p=0.891),  time:42.827, tt:3297.654\n",
      "Ep:77, loss:0.00004, loss_test:0.08328, lr:8.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.839, tt:3341.461\n",
      "Ep:78, loss:0.00004, loss_test:0.08325, lr:8.69e-03, fs:0.86458 (r=0.838,p=0.892),  time:42.835, tt:3383.969\n",
      "Ep:79, loss:0.00004, loss_test:0.08299, lr:8.60e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.889, tt:3431.157\n",
      "Ep:80, loss:0.00004, loss_test:0.08630, lr:8.51e-03, fs:0.82353 (r=0.778,p=0.875),  time:42.882, tt:3473.480\n",
      "Ep:81, loss:0.00004, loss_test:0.08254, lr:8.43e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.886, tt:3516.692\n",
      "Ep:82, loss:0.00004, loss_test:0.08506, lr:8.35e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.896, tt:3560.330\n",
      "Ep:83, loss:0.00004, loss_test:0.08242, lr:8.26e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.884, tt:3602.220\n",
      "Ep:84, loss:0.00004, loss_test:0.08703, lr:8.18e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.876, tt:3644.420\n",
      "Ep:85, loss:0.00004, loss_test:0.08257, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.878, tt:3687.536\n",
      "Ep:86, loss:0.00004, loss_test:0.08458, lr:8.02e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.866, tt:3729.311\n",
      "Ep:87, loss:0.00004, loss_test:0.08644, lr:7.94e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.842, tt:3770.086\n",
      "Ep:88, loss:0.00004, loss_test:0.08316, lr:7.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.839, tt:3812.653\n",
      "Ep:89, loss:0.00004, loss_test:0.08430, lr:7.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.840, tt:3855.619\n",
      "Ep:90, loss:0.00003, loss_test:0.08707, lr:7.70e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.827, tt:3897.256\n",
      "Ep:91, loss:0.00003, loss_test:0.08382, lr:7.62e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.831, tt:3940.482\n",
      "Ep:92, loss:0.00003, loss_test:0.08561, lr:7.55e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.827, tt:3982.907\n",
      "Ep:93, loss:0.00003, loss_test:0.08788, lr:7.47e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.818, tt:4024.935\n",
      "Ep:94, loss:0.00003, loss_test:0.08474, lr:7.40e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.797, tt:4065.701\n",
      "Ep:95, loss:0.00003, loss_test:0.08831, lr:7.32e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.787, tt:4107.549\n",
      "Ep:96, loss:0.00003, loss_test:0.08476, lr:7.25e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.778, tt:4149.486\n",
      "Ep:97, loss:0.00003, loss_test:0.08712, lr:7.18e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.765, tt:4190.944\n",
      "Ep:98, loss:0.00003, loss_test:0.08519, lr:7.11e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.775, tt:4234.748\n",
      "Ep:99, loss:0.00003, loss_test:0.08365, lr:7.03e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.771, tt:4277.112\n",
      "Ep:100, loss:0.00003, loss_test:0.08853, lr:6.96e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.789, tt:4321.664\n",
      "Ep:101, loss:0.00003, loss_test:0.08354, lr:6.89e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.766, tt:4362.171\n",
      "Ep:102, loss:0.00003, loss_test:0.08633, lr:6.83e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.760, tt:4404.266\n",
      "Ep:103, loss:0.00003, loss_test:0.08766, lr:6.76e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.762, tt:4447.244\n",
      "Ep:104, loss:0.00003, loss_test:0.08553, lr:6.69e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.760, tt:4489.831\n",
      "Ep:105, loss:0.00003, loss_test:0.08779, lr:6.62e-03, fs:0.84492 (r=0.798,p=0.898),  time:42.778, tt:4534.510\n",
      "Ep:106, loss:0.00003, loss_test:0.08724, lr:6.56e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.779, tt:4577.353\n",
      "Ep:107, loss:0.00003, loss_test:0.08636, lr:6.49e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.800, tt:4622.368\n",
      "Ep:108, loss:0.00003, loss_test:0.08973, lr:6.43e-03, fs:0.80874 (r=0.747,p=0.881),  time:42.791, tt:4664.196\n",
      "Ep:109, loss:0.00003, loss_test:0.08435, lr:6.36e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.776, tt:4705.383\n",
      "Ep:110, loss:0.00003, loss_test:0.08934, lr:6.30e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.766, tt:4746.997\n",
      "Ep:111, loss:0.00003, loss_test:0.08630, lr:6.24e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.783, tt:4791.696\n",
      "Ep:112, loss:0.00003, loss_test:0.08728, lr:6.17e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.798, tt:4836.131\n",
      "Ep:113, loss:0.00003, loss_test:0.08967, lr:6.11e-03, fs:0.84492 (r=0.798,p=0.898),  time:42.774, tt:4876.288\n",
      "Ep:114, loss:0.00003, loss_test:0.08653, lr:6.05e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.752, tt:4916.531\n",
      "Ep:115, loss:0.00003, loss_test:0.09015, lr:5.99e-03, fs:0.82162 (r=0.768,p=0.884),  time:42.742, tt:4958.118\n",
      "Ep:116, loss:0.00002, loss_test:0.08662, lr:5.93e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.738, tt:5000.302\n",
      "Ep:117, loss:0.00003, loss_test:0.09008, lr:5.87e-03, fs:0.81522 (r=0.758,p=0.882),  time:42.740, tt:5043.312\n",
      "Ep:118, loss:0.00003, loss_test:0.08709, lr:5.81e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.736, tt:5085.635\n",
      "Ep:119, loss:0.00003, loss_test:0.08772, lr:5.75e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.738, tt:5128.534\n",
      "Ep:120, loss:0.00002, loss_test:0.09209, lr:5.70e-03, fs:0.80000 (r=0.727,p=0.889),  time:42.733, tt:5170.645\n",
      "Ep:121, loss:0.00003, loss_test:0.08618, lr:5.64e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.743, tt:5214.700\n",
      "Ep:122, loss:0.00003, loss_test:0.09138, lr:5.58e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.745, tt:5257.619\n",
      "Ep:123, loss:0.00002, loss_test:0.08772, lr:5.53e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.752, tt:5301.203\n",
      "Ep:124, loss:0.00002, loss_test:0.08929, lr:5.47e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.761, tt:5345.091\n",
      "Ep:125, loss:0.00002, loss_test:0.08876, lr:5.42e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.754, tt:5386.984\n",
      "Ep:126, loss:0.00002, loss_test:0.08960, lr:5.36e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.760, tt:5430.473\n",
      "Ep:127, loss:0.00002, loss_test:0.08885, lr:5.31e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.779, tt:5475.705\n",
      "Ep:128, loss:0.00002, loss_test:0.08872, lr:5.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.783, tt:5519.065\n",
      "Ep:129, loss:0.00002, loss_test:0.08999, lr:5.20e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.769, tt:5559.960\n",
      "Ep:130, loss:0.00002, loss_test:0.08973, lr:5.15e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.765, tt:5602.217\n",
      "Ep:131, loss:0.00002, loss_test:0.08898, lr:5.10e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.771, tt:5645.794\n",
      "Ep:132, loss:0.00002, loss_test:0.08880, lr:5.05e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.764, tt:5687.555\n",
      "Ep:133, loss:0.00002, loss_test:0.08979, lr:5.00e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.770, tt:5731.178\n",
      "Ep:134, loss:0.00002, loss_test:0.08957, lr:4.95e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.771, tt:5774.035\n",
      "Ep:135, loss:0.00002, loss_test:0.08846, lr:4.90e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.777, tt:5817.658\n",
      "Ep:136, loss:0.00002, loss_test:0.09068, lr:4.85e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.773, tt:5859.926\n",
      "Ep:137, loss:0.00002, loss_test:0.08924, lr:4.80e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.773, tt:5902.672\n",
      "Ep:138, loss:0.00002, loss_test:0.08930, lr:4.75e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.765, tt:5944.316\n",
      "Ep:139, loss:0.00002, loss_test:0.09051, lr:4.71e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.775, tt:5988.444\n",
      "Ep:140, loss:0.00002, loss_test:0.09090, lr:4.66e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.783, tt:6032.395\n",
      "Ep:141, loss:0.00002, loss_test:0.08965, lr:4.61e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.792, tt:6076.446\n",
      "Ep:142, loss:0.00002, loss_test:0.08982, lr:4.57e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.792, tt:6119.265\n",
      "Ep:143, loss:0.00002, loss_test:0.09000, lr:4.52e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.806, tt:6164.008\n",
      "Ep:144, loss:0.00002, loss_test:0.09105, lr:4.48e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.804, tt:6206.562\n",
      "Ep:145, loss:0.00002, loss_test:0.08924, lr:4.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.798, tt:6248.517\n",
      "Ep:146, loss:0.00002, loss_test:0.09068, lr:4.39e-03, fs:0.82609 (r=0.768,p=0.894),  time:42.806, tt:6292.528\n",
      "Ep:147, loss:0.00002, loss_test:0.09014, lr:4.34e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.822, tt:6337.727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00002, loss_test:0.09164, lr:4.30e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.831, tt:6381.881\n",
      "Ep:149, loss:0.00002, loss_test:0.08883, lr:4.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.844, tt:6426.584\n",
      "Ep:150, loss:0.00002, loss_test:0.09193, lr:4.21e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.847, tt:6469.872\n",
      "Ep:151, loss:0.00002, loss_test:0.09133, lr:4.17e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.841, tt:6511.904\n",
      "Ep:152, loss:0.00002, loss_test:0.08991, lr:4.13e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.831, tt:6553.167\n",
      "Ep:153, loss:0.00002, loss_test:0.09185, lr:4.09e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.825, tt:6595.098\n",
      "Ep:154, loss:0.00002, loss_test:0.09121, lr:4.05e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.824, tt:6637.666\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13751, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:14.679, tt:14.679\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13483, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:15.068, tt:30.137\n",
      "Ep:2, loss:0.00027, loss_test:0.13092, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:15.053, tt:45.159\n",
      "Ep:3, loss:0.00026, loss_test:0.12739, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:14.797, tt:59.189\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12507, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:14.708, tt:73.542\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12480, lr:1.00e-02, fs:0.66942 (r=0.818,p=0.566),  time:14.555, tt:87.331\n",
      "Ep:6, loss:0.00025, loss_test:0.12428, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:14.836, tt:103.853\n",
      "Ep:7, loss:0.00024, loss_test:0.12348, lr:1.00e-02, fs:0.66667 (r=0.818,p=0.562),  time:14.901, tt:119.211\n",
      "Ep:8, loss:0.00024, loss_test:0.12272, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:15.265, tt:137.383\n",
      "Ep:9, loss:0.00023, loss_test:0.12190, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:15.830, tt:158.299\n",
      "Ep:10, loss:0.00023, loss_test:0.12133, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:15.815, tt:173.963\n",
      "Ep:11, loss:0.00022, loss_test:0.12051, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:16.005, tt:192.062\n",
      "Ep:12, loss:0.00021, loss_test:0.11990, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:16.028, tt:208.362\n",
      "Ep:13, loss:0.00021, loss_test:0.11887, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:16.225, tt:227.153\n",
      "Ep:14, loss:0.00020, loss_test:0.11727, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:16.500, tt:247.494\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11560, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:16.487, tt:263.791\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.11369, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:16.628, tt:282.684\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.11171, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:16.604, tt:298.871\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10997, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:16.742, tt:318.106\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10797, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:16.766, tt:335.317\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10659, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.746, tt:351.666\n",
      "Ep:21, loss:0.00016, loss_test:0.10495, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.787, tt:369.318\n",
      "Ep:22, loss:0.00015, loss_test:0.10378, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:16.859, tt:387.764\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.10287, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:16.961, tt:407.065\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.10151, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:17.081, tt:427.035\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09945, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:17.099, tt:444.578\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09845, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:17.148, tt:463.008\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09682, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:17.137, tt:479.839\n",
      "Ep:28, loss:0.00012, loss_test:0.09698, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:17.151, tt:497.366\n",
      "Ep:29, loss:0.00012, loss_test:0.09561, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:17.173, tt:515.178\n",
      "Ep:30, loss:0.00012, loss_test:0.09613, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:17.201, tt:533.225\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.09313, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:17.303, tt:553.705\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.09575, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:17.273, tt:570.003\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.09181, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:17.304, tt:588.352\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.09317, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:17.343, tt:607.008\n",
      "Ep:35, loss:0.00010, loss_test:0.09038, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:17.320, tt:623.520\n",
      "Ep:36, loss:0.00010, loss_test:0.09204, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:17.386, tt:643.277\n",
      "Ep:37, loss:0.00009, loss_test:0.08840, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:17.376, tt:660.301\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08735, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:17.392, tt:678.282\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.09177, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:17.417, tt:696.665\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.08529, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:17.367, tt:712.027\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08917, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:17.399, tt:730.747\n",
      "Ep:42, loss:0.00008, loss_test:0.08662, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:17.399, tt:748.166\n",
      "Ep:43, loss:0.00008, loss_test:0.08491, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:17.417, tt:766.330\n",
      "Ep:44, loss:0.00007, loss_test:0.08736, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:17.439, tt:784.754\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.08148, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:17.447, tt:802.551\n",
      "Ep:46, loss:0.00007, loss_test:0.08781, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:17.489, tt:822.002\n",
      "Ep:47, loss:0.00007, loss_test:0.08261, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:17.466, tt:838.349\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.08350, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:17.496, tt:857.312\n",
      "Ep:49, loss:0.00007, loss_test:0.08916, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:17.535, tt:876.736\n",
      "Ep:50, loss:0.00006, loss_test:0.08206, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:17.513, tt:893.139\n",
      "Ep:51, loss:0.00006, loss_test:0.08193, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:17.520, tt:911.059\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00006, loss_test:0.08581, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:17.497, tt:927.318\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.07884, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:17.531, tt:946.663\n",
      "Ep:54, loss:0.00006, loss_test:0.08420, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:17.530, tt:964.165\n",
      "Ep:55, loss:0.00006, loss_test:0.08295, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:17.534, tt:981.896\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.08255, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:17.581, tt:1002.131\n",
      "Ep:57, loss:0.00005, loss_test:0.08312, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:17.646, tt:1023.476\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.08204, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:17.723, tt:1045.666\n",
      "Ep:59, loss:0.00005, loss_test:0.08256, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:17.785, tt:1067.105\n",
      "Ep:60, loss:0.00005, loss_test:0.08059, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:17.828, tt:1087.525\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.08558, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:17.875, tt:1108.252\n",
      "Ep:62, loss:0.00005, loss_test:0.08088, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:17.865, tt:1125.512\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.08005, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:17.884, tt:1144.604\n",
      "Ep:64, loss:0.00004, loss_test:0.08118, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:17.880, tt:1162.199\n",
      "Ep:65, loss:0.00004, loss_test:0.08361, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:17.889, tt:1180.696\n",
      "Ep:66, loss:0.00004, loss_test:0.07929, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.897, tt:1199.132\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.08138, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:17.875, tt:1215.471\n",
      "Ep:68, loss:0.00004, loss_test:0.08293, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.882, tt:1233.859\n",
      "Ep:69, loss:0.00004, loss_test:0.08057, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.867, tt:1250.683\n",
      "Ep:70, loss:0.00004, loss_test:0.08068, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.867, tt:1268.526\n",
      "Ep:71, loss:0.00004, loss_test:0.07810, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.862, tt:1286.093\n",
      "Ep:72, loss:0.00004, loss_test:0.07906, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.825, tt:1301.207\n",
      "Ep:73, loss:0.00004, loss_test:0.08285, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.835, tt:1319.772\n",
      "Ep:74, loss:0.00004, loss_test:0.08133, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.806, tt:1335.458\n",
      "Ep:75, loss:0.00003, loss_test:0.07571, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.831, tt:1355.131\n",
      "Ep:76, loss:0.00003, loss_test:0.08003, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.853, tt:1374.714\n",
      "Ep:77, loss:0.00003, loss_test:0.08100, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.833, tt:1390.970\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.07683, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.837, tt:1409.085\n",
      "Ep:79, loss:0.00003, loss_test:0.07871, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.828, tt:1426.212\n",
      "Ep:80, loss:0.00003, loss_test:0.07956, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.838, tt:1444.913\n",
      "Ep:81, loss:0.00003, loss_test:0.07906, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.839, tt:1462.799\n",
      "Ep:82, loss:0.00003, loss_test:0.07837, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.827, tt:1479.609\n",
      "Ep:83, loss:0.00003, loss_test:0.07780, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.850, tt:1499.405\n",
      "Ep:84, loss:0.00003, loss_test:0.07733, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.837, tt:1516.120\n",
      "Ep:85, loss:0.00003, loss_test:0.07835, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.825, tt:1532.909\n",
      "Ep:86, loss:0.00003, loss_test:0.08204, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.816, tt:1550.026\n",
      "Ep:87, loss:0.00003, loss_test:0.07561, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.805, tt:1566.822\n",
      "Ep:88, loss:0.00003, loss_test:0.07808, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.817, tt:1585.737\n",
      "Ep:89, loss:0.00002, loss_test:0.08130, lr:9.90e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.835, tt:1605.123\n",
      "Ep:90, loss:0.00003, loss_test:0.07409, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.820, tt:1621.638\n",
      "Ep:91, loss:0.00003, loss_test:0.08078, lr:9.70e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.811, tt:1638.642\n",
      "Ep:92, loss:0.00003, loss_test:0.07911, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.784, tt:1653.893\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.07846, lr:9.61e-03, fs:0.84615 (r=0.778,p=0.928),  time:17.768, tt:1670.172\n",
      "Ep:94, loss:0.00002, loss_test:0.07922, lr:9.61e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.777, tt:1688.815\n",
      "Ep:95, loss:0.00002, loss_test:0.07687, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.756, tt:1704.543\n",
      "Ep:96, loss:0.00002, loss_test:0.07928, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.758, tt:1722.497\n",
      "Ep:97, loss:0.00002, loss_test:0.07630, lr:9.61e-03, fs:0.86772 (r=0.828,p=0.911),  time:17.753, tt:1739.760\n",
      "Ep:98, loss:0.00002, loss_test:0.07888, lr:9.61e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.750, tt:1757.239\n",
      "Ep:99, loss:0.00002, loss_test:0.07587, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.755, tt:1775.483\n",
      "Ep:100, loss:0.00002, loss_test:0.07891, lr:9.61e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.741, tt:1791.807\n",
      "Ep:101, loss:0.00002, loss_test:0.07579, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.740, tt:1809.438\n",
      "Ep:102, loss:0.00002, loss_test:0.07923, lr:9.61e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.745, tt:1827.735\n",
      "Ep:103, loss:0.00002, loss_test:0.07436, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.753, tt:1846.346\n",
      "Ep:104, loss:0.00002, loss_test:0.07969, lr:9.51e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.769, tt:1865.761\n",
      "Ep:105, loss:0.00002, loss_test:0.07601, lr:9.41e-03, fs:0.83871 (r=0.788,p=0.897),  time:17.745, tt:1880.951\n",
      "Ep:106, loss:0.00002, loss_test:0.07896, lr:9.32e-03, fs:0.87958 (r=0.848,p=0.913),  time:17.731, tt:1897.255\n",
      "Ep:107, loss:0.00002, loss_test:0.07800, lr:9.23e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.726, tt:1914.390\n",
      "Ep:108, loss:0.00002, loss_test:0.07735, lr:9.14e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.710, tt:1930.371\n",
      "Ep:109, loss:0.00002, loss_test:0.07774, lr:9.04e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.710, tt:1948.076\n",
      "Ep:110, loss:0.00002, loss_test:0.07919, lr:8.95e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.699, tt:1964.624\n",
      "Ep:111, loss:0.00002, loss_test:0.07650, lr:8.86e-03, fs:0.84324 (r=0.788,p=0.907),  time:17.705, tt:1982.955\n",
      "Ep:112, loss:0.00002, loss_test:0.07812, lr:8.78e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.759, tt:2006.749\n",
      "Ep:113, loss:0.00001, loss_test:0.07701, lr:8.69e-03, fs:0.84324 (r=0.788,p=0.907),  time:17.756, tt:2024.235\n",
      "Ep:114, loss:0.00001, loss_test:0.07913, lr:8.60e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.768, tt:2043.280\n",
      "Ep:115, loss:0.00001, loss_test:0.07551, lr:8.51e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.784, tt:2062.976\n",
      "Ep:116, loss:0.00001, loss_test:0.07993, lr:8.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.805, tt:2083.197\n",
      "Ep:117, loss:0.00001, loss_test:0.07612, lr:8.35e-03, fs:0.84946 (r=0.798,p=0.908),  time:17.821, tt:2102.919\n",
      "Ep:118, loss:0.00001, loss_test:0.07900, lr:8.26e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.838, tt:2122.700\n",
      "Ep:119, loss:0.00001, loss_test:0.07764, lr:8.18e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.843, tt:2141.184\n",
      "Ep:120, loss:0.00001, loss_test:0.07860, lr:8.10e-03, fs:0.84043 (r=0.798,p=0.888),  time:17.839, tt:2158.571\n",
      "Ep:121, loss:0.00001, loss_test:0.07837, lr:8.02e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.857, tt:2178.515\n",
      "Ep:122, loss:0.00001, loss_test:0.07925, lr:7.94e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.869, tt:2197.931\n",
      "Ep:123, loss:0.00001, loss_test:0.07696, lr:7.86e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.875, tt:2216.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00001, loss_test:0.07908, lr:7.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.887, tt:2235.835\n",
      "Ep:125, loss:0.00001, loss_test:0.07582, lr:7.70e-03, fs:0.84946 (r=0.798,p=0.908),  time:17.874, tt:2252.083\n",
      "Ep:126, loss:0.00001, loss_test:0.07984, lr:7.62e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.885, tt:2271.359\n",
      "Ep:127, loss:0.00001, loss_test:0.07596, lr:7.55e-03, fs:0.84324 (r=0.788,p=0.907),  time:17.892, tt:2290.127\n",
      "Ep:128, loss:0.00001, loss_test:0.07807, lr:7.47e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.890, tt:2307.786\n",
      "Ep:129, loss:0.00001, loss_test:0.07847, lr:7.40e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.909, tt:2328.118\n",
      "Ep:130, loss:0.00001, loss_test:0.07789, lr:7.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:17.890, tt:2343.569\n",
      "Ep:131, loss:0.00001, loss_test:0.07932, lr:7.25e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.888, tt:2361.245\n",
      "Ep:132, loss:0.00001, loss_test:0.07711, lr:7.18e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.892, tt:2379.684\n",
      "Ep:133, loss:0.00001, loss_test:0.07904, lr:7.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.883, tt:2396.359\n",
      "Ep:134, loss:0.00001, loss_test:0.07765, lr:7.03e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.873, tt:2412.868\n",
      "Ep:135, loss:0.00001, loss_test:0.07872, lr:6.96e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.862, tt:2429.272\n",
      "Ep:136, loss:0.00001, loss_test:0.07737, lr:6.89e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.879, tt:2449.423\n",
      "Ep:137, loss:0.00001, loss_test:0.07926, lr:6.83e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.883, tt:2467.827\n",
      "Ep:138, loss:0.00001, loss_test:0.07741, lr:6.76e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.872, tt:2484.273\n",
      "Ep:139, loss:0.00001, loss_test:0.07908, lr:6.69e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.876, tt:2502.686\n",
      "Ep:140, loss:0.00001, loss_test:0.07873, lr:6.62e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.861, tt:2518.361\n",
      "Ep:141, loss:0.00001, loss_test:0.07733, lr:6.56e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.862, tt:2536.461\n",
      "Ep:142, loss:0.00001, loss_test:0.07909, lr:6.49e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.867, tt:2555.025\n",
      "Ep:143, loss:0.00001, loss_test:0.07872, lr:6.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.861, tt:2572.004\n",
      "Ep:144, loss:0.00001, loss_test:0.07813, lr:6.36e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.868, tt:2590.895\n",
      "Ep:145, loss:0.00001, loss_test:0.07859, lr:6.30e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.872, tt:2609.342\n",
      "Ep:146, loss:0.00001, loss_test:0.07883, lr:6.24e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.869, tt:2626.705\n",
      "Ep:147, loss:0.00001, loss_test:0.07821, lr:6.17e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.863, tt:2643.691\n",
      "Ep:148, loss:0.00001, loss_test:0.07885, lr:6.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.853, tt:2660.075\n",
      "Ep:149, loss:0.00001, loss_test:0.07793, lr:6.05e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.857, tt:2678.582\n",
      "Ep:150, loss:0.00001, loss_test:0.07837, lr:5.99e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.849, tt:2695.150\n",
      "Ep:151, loss:0.00001, loss_test:0.07807, lr:5.93e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.842, tt:2711.922\n",
      "Ep:152, loss:0.00001, loss_test:0.07839, lr:5.87e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.848, tt:2730.717\n",
      "Ep:153, loss:0.00001, loss_test:0.07830, lr:5.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.833, tt:2746.217\n",
      "Ep:154, loss:0.00001, loss_test:0.07944, lr:5.75e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.837, tt:2764.744\n",
      "Ep:155, loss:0.00001, loss_test:0.07794, lr:5.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.829, tt:2781.251\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13233, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:18.163, tt:18.163\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12835, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:16.941, tt:33.882\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12273, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:17.422, tt:52.265\n",
      "Ep:3, loss:0.00026, loss_test:0.11772, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:16.316, tt:65.265\n",
      "Ep:4, loss:0.00026, loss_test:0.11335, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:16.222, tt:81.109\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.10974, lr:1.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:16.828, tt:100.966\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.10756, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:16.783, tt:117.480\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10574, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:17.048, tt:136.382\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.10256, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:17.086, tt:153.776\n",
      "Ep:9, loss:0.00023, loss_test:0.09813, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:17.148, tt:171.476\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.09447, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:17.032, tt:187.351\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.09231, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:17.040, tt:204.482\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.09099, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:17.032, tt:221.412\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.08994, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:16.985, tt:237.796\n",
      "Ep:14, loss:0.00021, loss_test:0.08912, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:17.129, tt:256.935\n",
      "Ep:15, loss:0.00020, loss_test:0.08799, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:17.244, tt:275.911\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.08608, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:17.149, tt:291.533\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.08539, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:17.009, tt:306.161\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08522, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:16.848, tt:320.106\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.08454, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:16.735, tt:334.707\n",
      "Ep:20, loss:0.00017, loss_test:0.08452, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:16.726, tt:351.243\n",
      "Ep:21, loss:0.00017, loss_test:0.08384, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:16.865, tt:371.023\n",
      "Ep:22, loss:0.00016, loss_test:0.08430, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:17.099, tt:393.270\n",
      "Ep:23, loss:0.00016, loss_test:0.08397, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:17.156, tt:411.749\n",
      "Ep:24, loss:0.00015, loss_test:0.08318, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:17.220, tt:430.492\n",
      "Ep:25, loss:0.00015, loss_test:0.08332, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:17.241, tt:448.272\n",
      "Ep:26, loss:0.00014, loss_test:0.08257, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:17.334, tt:468.017\n",
      "Ep:27, loss:0.00014, loss_test:0.08134, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:17.379, tt:486.600\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08058, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:17.506, tt:507.678\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08108, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:17.648, tt:529.455\n",
      "Ep:30, loss:0.00013, loss_test:0.07879, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:17.677, tt:547.994\n",
      "Ep:31, loss:0.00012, loss_test:0.07987, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:17.690, tt:566.080\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07707, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:17.746, tt:585.629\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00011, loss_test:0.07792, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:17.779, tt:604.476\n",
      "Ep:34, loss:0.00011, loss_test:0.07879, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:17.805, tt:623.167\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07503, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:17.844, tt:642.392\n",
      "Ep:36, loss:0.00010, loss_test:0.07741, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:17.917, tt:662.916\n",
      "Ep:37, loss:0.00010, loss_test:0.07414, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:17.902, tt:680.269\n",
      "Ep:38, loss:0.00010, loss_test:0.07611, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:17.940, tt:699.661\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07291, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:18.017, tt:720.697\n",
      "Ep:40, loss:0.00009, loss_test:0.07369, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:18.026, tt:739.075\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07251, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:18.026, tt:757.084\n",
      "Ep:42, loss:0.00009, loss_test:0.06978, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:18.012, tt:774.529\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.07134, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:18.093, tt:796.114\n",
      "Ep:44, loss:0.00008, loss_test:0.07037, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:18.168, tt:817.579\n",
      "Ep:45, loss:0.00008, loss_test:0.06821, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:18.221, tt:838.155\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.06982, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:18.231, tt:856.879\n",
      "Ep:47, loss:0.00007, loss_test:0.06904, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:18.244, tt:875.716\n",
      "Ep:48, loss:0.00007, loss_test:0.06847, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:18.259, tt:894.702\n",
      "Ep:49, loss:0.00007, loss_test:0.06833, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:18.268, tt:913.411\n",
      "Ep:50, loss:0.00007, loss_test:0.06788, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:18.253, tt:930.918\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06850, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:18.259, tt:949.494\n",
      "Ep:52, loss:0.00007, loss_test:0.06791, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:18.240, tt:966.721\n",
      "Ep:53, loss:0.00006, loss_test:0.06660, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:18.241, tt:985.014\n",
      "Ep:54, loss:0.00006, loss_test:0.06530, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:18.227, tt:1002.488\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.06823, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:18.280, tt:1023.677\n",
      "Ep:56, loss:0.00006, loss_test:0.06465, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:18.314, tt:1043.922\n",
      "Ep:57, loss:0.00006, loss_test:0.06683, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:18.345, tt:1063.999\n",
      "Ep:58, loss:0.00006, loss_test:0.06749, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:18.349, tt:1082.575\n",
      "Ep:59, loss:0.00006, loss_test:0.06518, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:18.350, tt:1100.973\n",
      "Ep:60, loss:0.00005, loss_test:0.06700, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.365, tt:1120.241\n",
      "Ep:61, loss:0.00005, loss_test:0.06537, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.394, tt:1140.401\n",
      "Ep:62, loss:0.00005, loss_test:0.06518, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:18.447, tt:1162.130\n",
      "Ep:63, loss:0.00005, loss_test:0.06339, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.471, tt:1182.117\n",
      "Ep:64, loss:0.00005, loss_test:0.06605, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:18.526, tt:1204.212\n",
      "Ep:65, loss:0.00005, loss_test:0.06540, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:18.556, tt:1224.698\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:18.569, tt:1244.131\n",
      "Ep:67, loss:0.00005, loss_test:0.06458, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:18.564, tt:1262.371\n",
      "Ep:68, loss:0.00004, loss_test:0.06639, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:18.543, tt:1279.443\n",
      "Ep:69, loss:0.00004, loss_test:0.06433, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:18.544, tt:1298.075\n",
      "Ep:70, loss:0.00004, loss_test:0.06549, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:18.552, tt:1317.203\n",
      "Ep:71, loss:0.00004, loss_test:0.06486, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.553, tt:1335.851\n",
      "Ep:72, loss:0.00004, loss_test:0.06343, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:18.547, tt:1353.925\n",
      "Ep:73, loss:0.00004, loss_test:0.06600, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.529, tt:1371.162\n",
      "Ep:74, loss:0.00004, loss_test:0.06229, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:18.547, tt:1391.003\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.06785, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:18.544, tt:1409.323\n",
      "Ep:76, loss:0.00004, loss_test:0.06188, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:18.531, tt:1426.894\n",
      "Ep:77, loss:0.00004, loss_test:0.06476, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:18.512, tt:1443.919\n",
      "Ep:78, loss:0.00004, loss_test:0.06493, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:18.533, tt:1464.145\n",
      "Ep:79, loss:0.00003, loss_test:0.06259, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:18.558, tt:1484.652\n",
      "Ep:80, loss:0.00003, loss_test:0.06407, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:18.552, tt:1502.688\n",
      "Ep:81, loss:0.00003, loss_test:0.06160, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:18.550, tt:1521.106\n",
      "Ep:82, loss:0.00003, loss_test:0.06399, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:18.546, tt:1539.279\n",
      "Ep:83, loss:0.00003, loss_test:0.06193, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:18.559, tt:1558.980\n",
      "Ep:84, loss:0.00003, loss_test:0.06275, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:18.569, tt:1578.398\n",
      "Ep:85, loss:0.00003, loss_test:0.06216, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:18.564, tt:1596.487\n",
      "Ep:86, loss:0.00003, loss_test:0.06308, lr:9.90e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.555, tt:1614.253\n",
      "Ep:87, loss:0.00003, loss_test:0.06336, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.547, tt:1632.111\n",
      "Ep:88, loss:0.00003, loss_test:0.06323, lr:9.70e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.581, tt:1653.697\n",
      "Ep:89, loss:0.00003, loss_test:0.06326, lr:9.61e-03, fs:0.87179 (r=0.859,p=0.885),  time:18.561, tt:1670.462\n",
      "Ep:90, loss:0.00003, loss_test:0.06144, lr:9.51e-03, fs:0.90323 (r=0.848,p=0.966),  time:18.560, tt:1688.940\n",
      "Ep:91, loss:0.00003, loss_test:0.06324, lr:9.41e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.561, tt:1707.651\n",
      "Ep:92, loss:0.00003, loss_test:0.06179, lr:9.32e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.544, tt:1724.578\n",
      "Ep:93, loss:0.00003, loss_test:0.06207, lr:9.23e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.547, tt:1743.427\n",
      "Ep:94, loss:0.00003, loss_test:0.06087, lr:9.14e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.541, tt:1761.406\n",
      "Ep:95, loss:0.00003, loss_test:0.06201, lr:9.04e-03, fs:0.87568 (r=0.818,p=0.942),  time:18.533, tt:1779.186\n",
      "Ep:96, loss:0.00002, loss_test:0.06130, lr:8.95e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.534, tt:1797.776\n",
      "Ep:97, loss:0.00002, loss_test:0.06299, lr:8.86e-03, fs:0.84270 (r=0.758,p=0.949),  time:18.546, tt:1817.476\n",
      "Ep:98, loss:0.00002, loss_test:0.06108, lr:8.78e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.543, tt:1835.731\n",
      "Ep:99, loss:0.00002, loss_test:0.06272, lr:8.69e-03, fs:0.87701 (r=0.828,p=0.932),  time:18.532, tt:1853.245\n",
      "Ep:100, loss:0.00002, loss_test:0.06081, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.546, tt:1873.111\n",
      "Ep:101, loss:0.00002, loss_test:0.06138, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:18.540, tt:1891.050\n",
      "Ep:102, loss:0.00002, loss_test:0.06065, lr:8.43e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.520, tt:1907.535\n",
      "Ep:103, loss:0.00002, loss_test:0.06179, lr:8.35e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.543, tt:1928.475\n",
      "Ep:104, loss:0.00002, loss_test:0.06098, lr:8.26e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.560, tt:1948.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00002, loss_test:0.06144, lr:8.18e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.541, tt:1965.392\n",
      "Ep:106, loss:0.00002, loss_test:0.06089, lr:8.10e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.527, tt:1982.355\n",
      "Ep:107, loss:0.00002, loss_test:0.06185, lr:8.02e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.513, tt:1999.403\n",
      "Ep:108, loss:0.00002, loss_test:0.06053, lr:7.94e-03, fs:0.89362 (r=0.848,p=0.944),  time:18.511, tt:2017.646\n",
      "Ep:109, loss:0.00002, loss_test:0.06165, lr:7.86e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.541, tt:2039.486\n",
      "Ep:110, loss:0.00002, loss_test:0.06034, lr:7.78e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.536, tt:2057.515\n",
      "Ep:111, loss:0.00002, loss_test:0.06214, lr:7.70e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.529, tt:2075.271\n",
      "Ep:112, loss:0.00002, loss_test:0.06083, lr:7.62e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.525, tt:2093.362\n",
      "Ep:113, loss:0.00002, loss_test:0.06177, lr:7.55e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.525, tt:2111.816\n",
      "Ep:114, loss:0.00002, loss_test:0.06232, lr:7.47e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.523, tt:2130.111\n",
      "Ep:115, loss:0.00002, loss_test:0.06088, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:18.533, tt:2149.817\n",
      "Ep:116, loss:0.00002, loss_test:0.06247, lr:7.32e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.530, tt:2168.014\n",
      "Ep:117, loss:0.00002, loss_test:0.06160, lr:7.25e-03, fs:0.88172 (r=0.828,p=0.943),  time:18.525, tt:2185.965\n",
      "Ep:118, loss:0.00002, loss_test:0.06115, lr:7.18e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.522, tt:2204.075\n",
      "Ep:119, loss:0.00002, loss_test:0.06181, lr:7.11e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.532, tt:2223.805\n",
      "Ep:120, loss:0.00002, loss_test:0.06091, lr:7.03e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.521, tt:2241.045\n",
      "Ep:121, loss:0.00002, loss_test:0.06251, lr:6.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:18.531, tt:2260.770\n",
      "Ep:122, loss:0.00002, loss_test:0.06146, lr:6.89e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.538, tt:2280.210\n",
      "Ep:123, loss:0.00002, loss_test:0.06210, lr:6.83e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.543, tt:2299.312\n",
      "Ep:124, loss:0.00002, loss_test:0.06271, lr:6.76e-03, fs:0.85405 (r=0.798,p=0.919),  time:18.536, tt:2317.016\n",
      "Ep:125, loss:0.00002, loss_test:0.06162, lr:6.69e-03, fs:0.87234 (r=0.828,p=0.921),  time:18.527, tt:2334.363\n",
      "Ep:126, loss:0.00002, loss_test:0.06177, lr:6.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:18.523, tt:2352.470\n",
      "Ep:127, loss:0.00002, loss_test:0.06141, lr:6.56e-03, fs:0.88421 (r=0.848,p=0.923),  time:18.530, tt:2371.837\n",
      "Ep:128, loss:0.00002, loss_test:0.06231, lr:6.49e-03, fs:0.82486 (r=0.737,p=0.936),  time:18.554, tt:2393.428\n",
      "Ep:129, loss:0.00002, loss_test:0.06184, lr:6.43e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.574, tt:2414.580\n",
      "Ep:130, loss:0.00002, loss_test:0.06271, lr:6.36e-03, fs:0.83616 (r=0.747,p=0.949),  time:18.584, tt:2434.515\n",
      "Ep:131, loss:0.00002, loss_test:0.06171, lr:6.30e-03, fs:0.86022 (r=0.808,p=0.920),  time:18.594, tt:2454.356\n",
      "Ep:132, loss:0.00002, loss_test:0.06272, lr:6.24e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.607, tt:2474.706\n",
      "Ep:133, loss:0.00002, loss_test:0.06226, lr:6.17e-03, fs:0.87831 (r=0.838,p=0.922),  time:18.603, tt:2492.813\n",
      "Ep:134, loss:0.00001, loss_test:0.06178, lr:6.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.617, tt:2513.321\n",
      "Ep:135, loss:0.00002, loss_test:0.06256, lr:6.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:18.600, tt:2529.577\n",
      "Ep:136, loss:0.00001, loss_test:0.06141, lr:5.99e-03, fs:0.89362 (r=0.848,p=0.944),  time:18.603, tt:2548.593\n",
      "Ep:137, loss:0.00001, loss_test:0.06267, lr:5.93e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.595, tt:2566.077\n",
      "Ep:138, loss:0.00001, loss_test:0.06110, lr:5.87e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.597, tt:2585.032\n",
      "Ep:139, loss:0.00001, loss_test:0.06246, lr:5.81e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.599, tt:2603.859\n",
      "Ep:140, loss:0.00001, loss_test:0.06247, lr:5.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:18.586, tt:2620.563\n",
      "Ep:141, loss:0.00001, loss_test:0.06116, lr:5.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.576, tt:2637.755\n",
      "Ep:142, loss:0.00001, loss_test:0.06371, lr:5.64e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.581, tt:2657.034\n",
      "Ep:143, loss:0.00001, loss_test:0.06080, lr:5.58e-03, fs:0.87568 (r=0.818,p=0.942),  time:18.568, tt:2673.845\n",
      "Ep:144, loss:0.00001, loss_test:0.06274, lr:5.53e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.563, tt:2691.609\n",
      "Ep:145, loss:0.00001, loss_test:0.06171, lr:5.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:18.558, tt:2709.399\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"2-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
