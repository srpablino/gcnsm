{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number = \"81-90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24381, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.155, tt:32.155\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24159, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.865, tt:63.729\n",
      "Ep:2, loss:0.00059, loss_test:0.23672, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.819, tt:95.456\n",
      "Ep:3, loss:0.00056, loss_test:0.22648, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.230, tt:128.919\n",
      "Ep:4, loss:0.00049, loss_test:0.20969, lr:9.22e-03, fs:0.66894 (r=0.990,p=0.505),  time:32.458, tt:162.290\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00041, loss_test:0.19694, lr:9.04e-03, fs:0.65399 (r=0.869,p=0.524),  time:32.866, tt:197.196\n",
      "Ep:6, loss:0.00033, loss_test:0.19884, lr:8.86e-03, fs:0.66102 (r=0.788,p=0.569),  time:33.164, tt:232.150\n",
      "Ep:7, loss:0.00032, loss_test:0.20023, lr:8.68e-03, fs:0.66071 (r=0.747,p=0.592),  time:33.072, tt:264.573\n",
      "Ep:8, loss:0.00031, loss_test:0.20121, lr:8.51e-03, fs:0.67299 (r=0.717,p=0.634),  time:33.250, tt:299.253\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00029, loss_test:0.19807, lr:8.34e-03, fs:0.66986 (r=0.707,p=0.636),  time:33.052, tt:330.519\n",
      "Ep:10, loss:0.00028, loss_test:0.19322, lr:8.17e-03, fs:0.70370 (r=0.768,p=0.650),  time:32.874, tt:361.616\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.18790, lr:8.01e-03, fs:0.70000 (r=0.778,p=0.636),  time:32.822, tt:393.870\n",
      "Ep:12, loss:0.00027, loss_test:0.18905, lr:7.85e-03, fs:0.69856 (r=0.737,p=0.664),  time:32.880, tt:427.434\n",
      "Ep:13, loss:0.00027, loss_test:0.18493, lr:7.69e-03, fs:0.70755 (r=0.758,p=0.664),  time:32.817, tt:459.436\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00026, loss_test:0.18077, lr:7.54e-03, fs:0.70093 (r=0.758,p=0.652),  time:32.861, tt:492.921\n",
      "Ep:15, loss:0.00025, loss_test:0.18069, lr:7.39e-03, fs:0.71154 (r=0.747,p=0.679),  time:32.820, tt:525.116\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.17476, lr:7.24e-03, fs:0.74074 (r=0.808,p=0.684),  time:32.913, tt:559.513\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.17633, lr:7.09e-03, fs:0.72986 (r=0.778,p=0.688),  time:32.831, tt:590.950\n",
      "Ep:18, loss:0.00023, loss_test:0.17447, lr:6.95e-03, fs:0.74882 (r=0.798,p=0.705),  time:32.914, tt:625.362\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.16960, lr:6.81e-03, fs:0.74419 (r=0.808,p=0.690),  time:32.914, tt:658.282\n",
      "Ep:20, loss:0.00023, loss_test:0.17079, lr:6.68e-03, fs:0.74396 (r=0.778,p=0.713),  time:32.983, tt:692.633\n",
      "Ep:21, loss:0.00022, loss_test:0.16751, lr:6.54e-03, fs:0.75472 (r=0.808,p=0.708),  time:33.002, tt:726.048\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.16230, lr:6.41e-03, fs:0.77064 (r=0.848,p=0.706),  time:32.973, tt:758.374\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.16385, lr:6.28e-03, fs:0.77419 (r=0.848,p=0.712),  time:33.075, tt:793.804\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.16459, lr:6.16e-03, fs:0.76555 (r=0.808,p=0.727),  time:33.080, tt:826.997\n",
      "Ep:25, loss:0.00021, loss_test:0.16083, lr:6.03e-03, fs:0.77570 (r=0.838,p=0.722),  time:33.167, tt:862.338\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00020, loss_test:0.15519, lr:5.91e-03, fs:0.78924 (r=0.889,p=0.710),  time:33.095, tt:893.559\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.15889, lr:5.80e-03, fs:0.79048 (r=0.838,p=0.748),  time:33.142, tt:927.964\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.15473, lr:5.68e-03, fs:0.79279 (r=0.889,p=0.715),  time:33.115, tt:960.325\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00018, loss_test:0.15629, lr:5.57e-03, fs:0.81517 (r=0.869,p=0.768),  time:33.110, tt:993.295\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.16419, lr:5.45e-03, fs:0.79803 (r=0.818,p=0.779),  time:33.084, tt:1025.593\n",
      "Ep:31, loss:0.00018, loss_test:0.15399, lr:5.35e-03, fs:0.82243 (r=0.889,p=0.765),  time:33.088, tt:1058.808\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00017, loss_test:0.15214, lr:5.24e-03, fs:0.81690 (r=0.879,p=0.763),  time:33.071, tt:1091.329\n",
      "Ep:33, loss:0.00017, loss_test:0.15900, lr:5.13e-03, fs:0.80198 (r=0.818,p=0.786),  time:33.138, tt:1126.692\n",
      "Ep:34, loss:0.00017, loss_test:0.15019, lr:5.03e-03, fs:0.81481 (r=0.889,p=0.752),  time:33.174, tt:1161.090\n",
      "Ep:35, loss:0.00016, loss_test:0.14742, lr:4.93e-03, fs:0.83486 (r=0.919,p=0.765),  time:33.197, tt:1195.078\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00015, loss_test:0.15348, lr:4.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:33.236, tt:1229.735\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00015, loss_test:0.15159, lr:4.74e-03, fs:0.84211 (r=0.889,p=0.800),  time:33.221, tt:1262.404\n",
      "Ep:38, loss:0.00014, loss_test:0.14888, lr:4.64e-03, fs:0.84507 (r=0.909,p=0.789),  time:33.220, tt:1295.596\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00015, loss_test:0.15214, lr:4.55e-03, fs:0.84058 (r=0.879,p=0.806),  time:33.215, tt:1328.588\n",
      "Ep:40, loss:0.00014, loss_test:0.14926, lr:4.46e-03, fs:0.85577 (r=0.899,p=0.817),  time:33.194, tt:1360.963\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00014, loss_test:0.15050, lr:4.37e-03, fs:0.84360 (r=0.899,p=0.795),  time:33.178, tt:1393.458\n",
      "Ep:42, loss:0.00013, loss_test:0.15086, lr:4.28e-03, fs:0.85577 (r=0.899,p=0.817),  time:33.194, tt:1427.334\n",
      "Ep:43, loss:0.00013, loss_test:0.14502, lr:4.19e-03, fs:0.85308 (r=0.909,p=0.804),  time:33.214, tt:1461.408\n",
      "Ep:44, loss:0.00013, loss_test:0.15025, lr:4.11e-03, fs:0.84466 (r=0.879,p=0.813),  time:33.228, tt:1495.243\n",
      "Ep:45, loss:0.00013, loss_test:0.14822, lr:4.03e-03, fs:0.85024 (r=0.889,p=0.815),  time:33.229, tt:1528.527\n",
      "Ep:46, loss:0.00012, loss_test:0.14843, lr:3.95e-03, fs:0.84466 (r=0.879,p=0.813),  time:33.265, tt:1563.438\n",
      "Ep:47, loss:0.00012, loss_test:0.15102, lr:3.87e-03, fs:0.84577 (r=0.859,p=0.833),  time:33.282, tt:1597.521\n",
      "Ep:48, loss:0.00012, loss_test:0.14789, lr:3.79e-03, fs:0.85024 (r=0.889,p=0.815),  time:33.298, tt:1631.612\n",
      "Ep:49, loss:0.00012, loss_test:0.14809, lr:3.72e-03, fs:0.85854 (r=0.889,p=0.830),  time:33.339, tt:1666.939\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00012, loss_test:0.15076, lr:3.64e-03, fs:0.85024 (r=0.889,p=0.815),  time:33.324, tt:1699.542\n",
      "Ep:51, loss:0.00012, loss_test:0.14575, lr:3.57e-03, fs:0.85714 (r=0.909,p=0.811),  time:33.386, tt:1736.062\n",
      "Ep:52, loss:0.00011, loss_test:0.14561, lr:3.50e-03, fs:0.83654 (r=0.879,p=0.798),  time:33.413, tt:1770.913\n",
      "Ep:53, loss:0.00011, loss_test:0.14625, lr:3.43e-03, fs:0.84422 (r=0.848,p=0.840),  time:33.467, tt:1807.237\n",
      "Ep:54, loss:0.00011, loss_test:0.14790, lr:3.36e-03, fs:0.84000 (r=0.848,p=0.832),  time:33.461, tt:1840.332\n",
      "Ep:55, loss:0.00010, loss_test:0.15211, lr:3.29e-03, fs:0.84577 (r=0.859,p=0.833),  time:33.476, tt:1874.658\n",
      "Ep:56, loss:0.00011, loss_test:0.15202, lr:3.23e-03, fs:0.82759 (r=0.848,p=0.808),  time:33.467, tt:1907.610\n",
      "Ep:57, loss:0.00010, loss_test:0.14912, lr:3.16e-03, fs:0.83249 (r=0.828,p=0.837),  time:33.484, tt:1942.081\n",
      "Ep:58, loss:0.00010, loss_test:0.15087, lr:3.10e-03, fs:0.83249 (r=0.828,p=0.837),  time:33.490, tt:1975.900\n",
      "Ep:59, loss:0.00009, loss_test:0.15023, lr:3.04e-03, fs:0.83249 (r=0.828,p=0.837),  time:33.499, tt:2009.950\n",
      "Ep:60, loss:0.00009, loss_test:0.14703, lr:2.98e-03, fs:0.84158 (r=0.859,p=0.825),  time:33.511, tt:2044.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00009, loss_test:0.15404, lr:2.92e-03, fs:0.84694 (r=0.838,p=0.856),  time:33.555, tt:2080.413\n",
      "Ep:62, loss:0.00009, loss_test:0.15057, lr:2.86e-03, fs:0.85567 (r=0.838,p=0.874),  time:33.576, tt:2115.280\n",
      "Ep:63, loss:0.00009, loss_test:0.14542, lr:2.80e-03, fs:0.82828 (r=0.828,p=0.828),  time:33.625, tt:2151.971\n",
      "Ep:64, loss:0.00009, loss_test:0.14744, lr:2.74e-03, fs:0.84103 (r=0.828,p=0.854),  time:33.630, tt:2185.931\n",
      "Ep:65, loss:0.00008, loss_test:0.14763, lr:2.69e-03, fs:0.85859 (r=0.859,p=0.859),  time:33.650, tt:2220.915\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00008, loss_test:0.14459, lr:2.64e-03, fs:0.85000 (r=0.859,p=0.842),  time:33.690, tt:2257.200\n",
      "Ep:67, loss:0.00008, loss_test:0.15028, lr:2.58e-03, fs:0.84103 (r=0.828,p=0.854),  time:33.711, tt:2292.376\n",
      "Ep:68, loss:0.00008, loss_test:0.15095, lr:2.53e-03, fs:0.84974 (r=0.828,p=0.872),  time:33.759, tt:2329.351\n",
      "Ep:69, loss:0.00008, loss_test:0.14965, lr:2.48e-03, fs:0.83838 (r=0.838,p=0.838),  time:33.772, tt:2364.018\n",
      "Ep:70, loss:0.00008, loss_test:0.15322, lr:2.43e-03, fs:0.83158 (r=0.798,p=0.868),  time:33.761, tt:2397.057\n",
      "Ep:71, loss:0.00008, loss_test:0.15049, lr:2.38e-03, fs:0.83158 (r=0.798,p=0.868),  time:33.765, tt:2431.114\n",
      "Ep:72, loss:0.00008, loss_test:0.14801, lr:2.33e-03, fs:0.81443 (r=0.798,p=0.832),  time:33.769, tt:2465.170\n",
      "Ep:73, loss:0.00008, loss_test:0.15379, lr:2.29e-03, fs:0.83158 (r=0.798,p=0.868),  time:33.763, tt:2498.467\n",
      "Ep:74, loss:0.00007, loss_test:0.15477, lr:2.24e-03, fs:0.81675 (r=0.788,p=0.848),  time:33.773, tt:2532.985\n",
      "Ep:75, loss:0.00007, loss_test:0.15401, lr:2.20e-03, fs:0.81915 (r=0.778,p=0.865),  time:33.779, tt:2567.236\n",
      "Ep:76, loss:0.00007, loss_test:0.15397, lr:2.15e-03, fs:0.77596 (r=0.717,p=0.845),  time:33.772, tt:2600.431\n",
      "Ep:77, loss:0.00007, loss_test:0.15489, lr:2.11e-03, fs:0.80874 (r=0.747,p=0.881),  time:33.788, tt:2635.502\n",
      "Ep:78, loss:0.00007, loss_test:0.15333, lr:2.07e-03, fs:0.82796 (r=0.778,p=0.885),  time:33.791, tt:2669.482\n",
      "Ep:79, loss:0.00007, loss_test:0.15209, lr:2.03e-03, fs:0.82979 (r=0.788,p=0.876),  time:33.798, tt:2703.811\n",
      "Ep:80, loss:0.00007, loss_test:0.15553, lr:1.99e-03, fs:0.82162 (r=0.768,p=0.884),  time:33.793, tt:2737.238\n",
      "Ep:81, loss:0.00006, loss_test:0.15629, lr:1.95e-03, fs:0.78212 (r=0.707,p=0.875),  time:33.794, tt:2771.127\n",
      "Ep:82, loss:0.00006, loss_test:0.15481, lr:1.91e-03, fs:0.77348 (r=0.707,p=0.854),  time:33.785, tt:2804.117\n",
      "Ep:83, loss:0.00006, loss_test:0.15475, lr:1.87e-03, fs:0.76503 (r=0.707,p=0.833),  time:33.775, tt:2837.115\n",
      "Ep:84, loss:0.00006, loss_test:0.15548, lr:1.83e-03, fs:0.78453 (r=0.717,p=0.866),  time:33.769, tt:2870.387\n",
      "Ep:85, loss:0.00006, loss_test:0.15515, lr:1.80e-03, fs:0.77778 (r=0.707,p=0.864),  time:33.777, tt:2904.830\n",
      "Ep:86, loss:0.00006, loss_test:0.15658, lr:1.76e-03, fs:0.75978 (r=0.687,p=0.850),  time:33.783, tt:2939.109\n",
      "Ep:87, loss:0.00006, loss_test:0.15907, lr:1.72e-03, fs:0.76404 (r=0.687,p=0.861),  time:33.760, tt:2970.865\n",
      "Ep:88, loss:0.00006, loss_test:0.15813, lr:1.69e-03, fs:0.76243 (r=0.697,p=0.841),  time:33.741, tt:3002.918\n",
      "Ep:89, loss:0.00006, loss_test:0.15604, lr:1.66e-03, fs:0.75978 (r=0.687,p=0.850),  time:33.756, tt:3038.065\n",
      "Ep:90, loss:0.00005, loss_test:0.15504, lr:1.62e-03, fs:0.76404 (r=0.687,p=0.861),  time:33.747, tt:3070.957\n",
      "Ep:91, loss:0.00006, loss_test:0.15404, lr:1.59e-03, fs:0.78652 (r=0.707,p=0.886),  time:33.756, tt:3105.544\n",
      "Ep:92, loss:0.00006, loss_test:0.15424, lr:1.56e-03, fs:0.77778 (r=0.707,p=0.864),  time:33.759, tt:3139.607\n",
      "Ep:93, loss:0.00005, loss_test:0.15454, lr:1.53e-03, fs:0.75824 (r=0.697,p=0.831),  time:33.757, tt:3173.182\n",
      "Ep:94, loss:0.00005, loss_test:0.15804, lr:1.50e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.751, tt:3206.346\n",
      "Ep:95, loss:0.00005, loss_test:0.15928, lr:1.47e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.750, tt:3239.953\n",
      "Ep:96, loss:0.00005, loss_test:0.15982, lr:1.44e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.764, tt:3275.087\n",
      "Ep:97, loss:0.00005, loss_test:0.16215, lr:1.41e-03, fs:0.77273 (r=0.687,p=0.883),  time:33.785, tt:3310.918\n",
      "Ep:98, loss:0.00005, loss_test:0.16382, lr:1.38e-03, fs:0.76404 (r=0.687,p=0.861),  time:33.801, tt:3346.266\n",
      "Ep:99, loss:0.00005, loss_test:0.16306, lr:1.35e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.805, tt:3380.462\n",
      "Ep:100, loss:0.00005, loss_test:0.16112, lr:1.33e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.824, tt:3416.200\n",
      "Ep:101, loss:0.00005, loss_test:0.16170, lr:1.30e-03, fs:0.76571 (r=0.677,p=0.882),  time:33.823, tt:3449.927\n",
      "Ep:102, loss:0.00005, loss_test:0.16141, lr:1.27e-03, fs:0.77273 (r=0.687,p=0.883),  time:33.847, tt:3486.191\n",
      "Ep:103, loss:0.00005, loss_test:0.16032, lr:1.25e-03, fs:0.76571 (r=0.677,p=0.882),  time:33.868, tt:3522.262\n",
      "Ep:104, loss:0.00005, loss_test:0.16073, lr:1.22e-03, fs:0.77011 (r=0.677,p=0.893),  time:33.881, tt:3557.529\n",
      "Ep:105, loss:0.00005, loss_test:0.16191, lr:1.20e-03, fs:0.77714 (r=0.687,p=0.895),  time:33.896, tt:3592.981\n",
      "Ep:106, loss:0.00005, loss_test:0.16179, lr:1.17e-03, fs:0.76571 (r=0.677,p=0.882),  time:33.910, tt:3628.365\n",
      "Ep:107, loss:0.00004, loss_test:0.16003, lr:1.15e-03, fs:0.76571 (r=0.677,p=0.882),  time:33.913, tt:3662.603\n",
      "Ep:108, loss:0.00004, loss_test:0.15970, lr:1.13e-03, fs:0.76136 (r=0.677,p=0.870),  time:33.937, tt:3699.102\n",
      "Ep:109, loss:0.00004, loss_test:0.16111, lr:1.11e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.962, tt:3735.776\n",
      "Ep:110, loss:0.00004, loss_test:0.16344, lr:1.08e-03, fs:0.76836 (r=0.687,p=0.872),  time:33.971, tt:3770.771\n",
      "Ep:111, loss:0.00004, loss_test:0.16619, lr:1.06e-03, fs:0.77273 (r=0.687,p=0.883),  time:33.988, tt:3806.658\n",
      "Ep:112, loss:0.00004, loss_test:0.16641, lr:1.04e-03, fs:0.77011 (r=0.677,p=0.893),  time:33.988, tt:3840.656\n",
      "Ep:113, loss:0.00004, loss_test:0.16680, lr:1.02e-03, fs:0.77011 (r=0.677,p=0.893),  time:34.002, tt:3876.255\n",
      "Ep:114, loss:0.00004, loss_test:0.16733, lr:9.99e-04, fs:0.77907 (r=0.677,p=0.918),  time:33.994, tt:3909.362\n",
      "Ep:115, loss:0.00004, loss_test:0.16538, lr:9.79e-04, fs:0.77457 (r=0.677,p=0.905),  time:33.994, tt:3943.353\n",
      "Ep:116, loss:0.00004, loss_test:0.16272, lr:9.60e-04, fs:0.76571 (r=0.677,p=0.882),  time:34.005, tt:3978.612\n",
      "Ep:117, loss:0.00004, loss_test:0.16310, lr:9.41e-04, fs:0.75556 (r=0.687,p=0.840),  time:33.995, tt:4011.359\n",
      "Ep:118, loss:0.00004, loss_test:0.16503, lr:9.22e-04, fs:0.76836 (r=0.687,p=0.872),  time:34.007, tt:4046.866\n",
      "Ep:119, loss:0.00004, loss_test:0.16596, lr:9.03e-04, fs:0.76136 (r=0.677,p=0.870),  time:33.972, tt:4076.587\n",
      "Ep:120, loss:0.00004, loss_test:0.16581, lr:8.85e-04, fs:0.77011 (r=0.677,p=0.893),  time:33.958, tt:4108.872\n",
      "Ep:121, loss:0.00004, loss_test:0.16574, lr:8.68e-04, fs:0.77457 (r=0.677,p=0.905),  time:33.944, tt:4141.223\n",
      "Ep:122, loss:0.00004, loss_test:0.16716, lr:8.50e-04, fs:0.77457 (r=0.677,p=0.905),  time:33.912, tt:4171.218\n",
      "Ep:123, loss:0.00004, loss_test:0.16773, lr:8.33e-04, fs:0.77457 (r=0.677,p=0.905),  time:33.914, tt:4205.361\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00062, loss_test:0.24291, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.861, tt:33.861\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24010, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:33.808, tt:67.615\n",
      "Ep:2, loss:0.00059, loss_test:0.23407, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:33.919, tt:101.757\n",
      "Ep:3, loss:0.00056, loss_test:0.22160, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:34.503, tt:138.012\n",
      "Ep:4, loss:0.00049, loss_test:0.19896, lr:9.22e-03, fs:0.66667 (r=0.990,p=0.503),  time:34.545, tt:172.724\n",
      "Ep:5, loss:0.00040, loss_test:0.18292, lr:9.04e-03, fs:0.68441 (r=0.909,p=0.549),  time:34.562, tt:207.371\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.17721, lr:8.86e-03, fs:0.69748 (r=0.838,p=0.597),  time:34.621, tt:242.349\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00032, loss_test:0.17837, lr:8.68e-03, fs:0.72174 (r=0.838,p=0.634),  time:34.621, tt:276.970\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00031, loss_test:0.17727, lr:8.51e-03, fs:0.72807 (r=0.838,p=0.643),  time:34.874, tt:313.869\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.17423, lr:8.34e-03, fs:0.73059 (r=0.808,p=0.667),  time:34.849, tt:348.486\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00029, loss_test:0.16827, lr:8.17e-03, fs:0.72566 (r=0.828,p=0.646),  time:34.882, tt:383.703\n",
      "Ep:11, loss:0.00028, loss_test:0.16752, lr:8.01e-03, fs:0.75229 (r=0.828,p=0.689),  time:34.897, tt:418.770\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00028, loss_test:0.16558, lr:7.85e-03, fs:0.77778 (r=0.848,p=0.718),  time:34.808, tt:452.500\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00027, loss_test:0.16573, lr:7.69e-03, fs:0.72477 (r=0.798,p=0.664),  time:34.822, tt:487.514\n",
      "Ep:14, loss:0.00026, loss_test:0.16046, lr:7.54e-03, fs:0.76279 (r=0.828,p=0.707),  time:34.827, tt:522.405\n",
      "Ep:15, loss:0.00026, loss_test:0.16130, lr:7.39e-03, fs:0.77885 (r=0.818,p=0.743),  time:34.776, tt:556.417\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.16066, lr:7.24e-03, fs:0.76699 (r=0.798,p=0.738),  time:34.729, tt:590.400\n",
      "Ep:17, loss:0.00025, loss_test:0.15734, lr:7.09e-03, fs:0.75962 (r=0.798,p=0.725),  time:34.736, tt:625.251\n",
      "Ep:18, loss:0.00024, loss_test:0.15396, lr:6.95e-03, fs:0.78261 (r=0.818,p=0.750),  time:34.757, tt:660.374\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.15656, lr:6.81e-03, fs:0.77833 (r=0.798,p=0.760),  time:34.745, tt:694.892\n",
      "Ep:20, loss:0.00023, loss_test:0.15112, lr:6.68e-03, fs:0.79245 (r=0.848,p=0.743),  time:34.757, tt:729.891\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.15393, lr:6.54e-03, fs:0.78818 (r=0.808,p=0.769),  time:34.788, tt:765.329\n",
      "Ep:22, loss:0.00022, loss_test:0.15023, lr:6.41e-03, fs:0.77885 (r=0.818,p=0.743),  time:34.848, tt:801.500\n",
      "Ep:23, loss:0.00021, loss_test:0.14887, lr:6.28e-03, fs:0.80000 (r=0.828,p=0.774),  time:34.881, tt:837.155\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.14567, lr:6.16e-03, fs:0.80569 (r=0.859,p=0.759),  time:34.932, tt:873.291\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.14646, lr:6.03e-03, fs:0.80198 (r=0.818,p=0.786),  time:35.001, tt:910.033\n",
      "Ep:26, loss:0.00020, loss_test:0.14071, lr:5.91e-03, fs:0.80976 (r=0.838,p=0.783),  time:34.989, tt:944.706\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.13796, lr:5.80e-03, fs:0.80717 (r=0.909,p=0.726),  time:34.953, tt:978.680\n",
      "Ep:28, loss:0.00019, loss_test:0.14198, lr:5.68e-03, fs:0.83744 (r=0.859,p=0.817),  time:34.994, tt:1014.823\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00019, loss_test:0.13748, lr:5.57e-03, fs:0.82692 (r=0.869,p=0.789),  time:34.934, tt:1048.019\n",
      "Ep:30, loss:0.00018, loss_test:0.13112, lr:5.45e-03, fs:0.79825 (r=0.919,p=0.705),  time:34.986, tt:1084.574\n",
      "Ep:31, loss:0.00018, loss_test:0.13679, lr:5.35e-03, fs:0.85572 (r=0.869,p=0.843),  time:34.949, tt:1118.372\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00018, loss_test:0.12913, lr:5.24e-03, fs:0.81982 (r=0.919,p=0.740),  time:34.938, tt:1152.969\n",
      "Ep:33, loss:0.00017, loss_test:0.12866, lr:5.13e-03, fs:0.82629 (r=0.889,p=0.772),  time:35.013, tt:1190.436\n",
      "Ep:34, loss:0.00017, loss_test:0.13465, lr:5.03e-03, fs:0.84577 (r=0.859,p=0.833),  time:35.065, tt:1227.261\n",
      "Ep:35, loss:0.00016, loss_test:0.13029, lr:4.93e-03, fs:0.81651 (r=0.899,p=0.748),  time:35.069, tt:1262.477\n",
      "Ep:36, loss:0.00016, loss_test:0.12052, lr:4.83e-03, fs:0.84507 (r=0.909,p=0.789),  time:35.059, tt:1297.196\n",
      "Ep:37, loss:0.00016, loss_test:0.12467, lr:4.74e-03, fs:0.84112 (r=0.909,p=0.783),  time:35.079, tt:1332.991\n",
      "Ep:38, loss:0.00016, loss_test:0.12559, lr:4.64e-03, fs:0.84878 (r=0.879,p=0.821),  time:35.092, tt:1368.602\n",
      "Ep:39, loss:0.00015, loss_test:0.12281, lr:4.55e-03, fs:0.86275 (r=0.889,p=0.838),  time:35.060, tt:1402.414\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00015, loss_test:0.11998, lr:4.46e-03, fs:0.84507 (r=0.909,p=0.789),  time:35.099, tt:1439.040\n",
      "Ep:41, loss:0.00014, loss_test:0.12562, lr:4.37e-03, fs:0.82791 (r=0.899,p=0.767),  time:35.115, tt:1474.825\n",
      "Ep:42, loss:0.00014, loss_test:0.11952, lr:4.28e-03, fs:0.84360 (r=0.899,p=0.795),  time:35.099, tt:1509.240\n",
      "Ep:43, loss:0.00014, loss_test:0.11434, lr:4.19e-03, fs:0.85185 (r=0.929,p=0.786),  time:35.111, tt:1544.891\n",
      "Ep:44, loss:0.00014, loss_test:0.12528, lr:4.11e-03, fs:0.87129 (r=0.889,p=0.854),  time:35.068, tt:1578.071\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00013, loss_test:0.11997, lr:4.03e-03, fs:0.86408 (r=0.899,p=0.832),  time:35.094, tt:1614.303\n",
      "Ep:46, loss:0.00013, loss_test:0.11789, lr:3.95e-03, fs:0.86538 (r=0.909,p=0.826),  time:35.114, tt:1650.370\n",
      "Ep:47, loss:0.00012, loss_test:0.12025, lr:3.87e-03, fs:0.86408 (r=0.899,p=0.832),  time:35.124, tt:1685.934\n",
      "Ep:48, loss:0.00012, loss_test:0.12016, lr:3.79e-03, fs:0.87129 (r=0.889,p=0.854),  time:35.082, tt:1718.994\n",
      "Ep:49, loss:0.00012, loss_test:0.11223, lr:3.72e-03, fs:0.86957 (r=0.909,p=0.833),  time:35.089, tt:1754.461\n",
      "Ep:50, loss:0.00012, loss_test:0.11238, lr:3.64e-03, fs:0.86124 (r=0.909,p=0.818),  time:35.084, tt:1789.305\n",
      "Ep:51, loss:0.00012, loss_test:0.12367, lr:3.57e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.052, tt:1822.692\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00011, loss_test:0.11253, lr:3.50e-03, fs:0.88670 (r=0.909,p=0.865),  time:35.019, tt:1856.028\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00011, loss_test:0.10740, lr:3.43e-03, fs:0.87500 (r=0.919,p=0.835),  time:35.012, tt:1890.651\n",
      "Ep:54, loss:0.00010, loss_test:0.11569, lr:3.36e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.995, tt:1924.751\n",
      "Ep:55, loss:0.00010, loss_test:0.11339, lr:3.29e-03, fs:0.86829 (r=0.899,p=0.840),  time:34.969, tt:1958.243\n",
      "Ep:56, loss:0.00011, loss_test:0.10936, lr:3.23e-03, fs:0.87379 (r=0.909,p=0.841),  time:34.953, tt:1992.301\n",
      "Ep:57, loss:0.00010, loss_test:0.11346, lr:3.16e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.964, tt:2027.904\n",
      "Ep:58, loss:0.00010, loss_test:0.11393, lr:3.10e-03, fs:0.88000 (r=0.889,p=0.871),  time:34.957, tt:2062.456\n",
      "Ep:59, loss:0.00010, loss_test:0.10829, lr:3.04e-03, fs:0.87685 (r=0.899,p=0.856),  time:34.954, tt:2097.251\n",
      "Ep:60, loss:0.00010, loss_test:0.11255, lr:2.98e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.943, tt:2131.504\n",
      "Ep:61, loss:0.00009, loss_test:0.11486, lr:2.92e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.930, tt:2165.673\n",
      "Ep:62, loss:0.00009, loss_test:0.11139, lr:2.86e-03, fs:0.88119 (r=0.899,p=0.864),  time:34.877, tt:2197.252\n",
      "Ep:63, loss:0.00009, loss_test:0.11236, lr:2.80e-03, fs:0.88557 (r=0.899,p=0.873),  time:34.881, tt:2232.363\n",
      "Ep:64, loss:0.00009, loss_test:0.11509, lr:2.74e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.860, tt:2265.883\n",
      "Ep:65, loss:0.00008, loss_test:0.10712, lr:2.69e-03, fs:0.88670 (r=0.909,p=0.865),  time:34.843, tt:2299.670\n",
      "Ep:66, loss:0.00008, loss_test:0.10858, lr:2.64e-03, fs:0.89000 (r=0.899,p=0.881),  time:34.835, tt:2333.970\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00008, loss_test:0.11338, lr:2.58e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.821, tt:2367.811\n",
      "Ep:68, loss:0.00008, loss_test:0.11134, lr:2.53e-03, fs:0.89447 (r=0.899,p=0.890),  time:34.804, tt:2401.466\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00008, loss_test:0.11020, lr:2.48e-03, fs:0.89000 (r=0.899,p=0.881),  time:34.748, tt:2432.339\n",
      "Ep:70, loss:0.00008, loss_test:0.11008, lr:2.43e-03, fs:0.87685 (r=0.899,p=0.856),  time:34.726, tt:2465.526\n",
      "Ep:71, loss:0.00007, loss_test:0.11043, lr:2.38e-03, fs:0.87255 (r=0.899,p=0.848),  time:34.664, tt:2495.818\n",
      "Ep:72, loss:0.00007, loss_test:0.10877, lr:2.33e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.664, tt:2530.481\n",
      "Ep:73, loss:0.00007, loss_test:0.10910, lr:2.29e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.649, tt:2564.008\n",
      "Ep:74, loss:0.00007, loss_test:0.10922, lr:2.24e-03, fs:0.87255 (r=0.899,p=0.848),  time:34.619, tt:2596.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00007, loss_test:0.10983, lr:2.20e-03, fs:0.87255 (r=0.899,p=0.848),  time:34.599, tt:2629.508\n",
      "Ep:76, loss:0.00007, loss_test:0.11171, lr:2.15e-03, fs:0.88119 (r=0.899,p=0.864),  time:34.570, tt:2661.897\n",
      "Ep:77, loss:0.00006, loss_test:0.11099, lr:2.11e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.564, tt:2696.017\n",
      "Ep:78, loss:0.00006, loss_test:0.10590, lr:2.07e-03, fs:0.88557 (r=0.899,p=0.873),  time:34.543, tt:2728.860\n",
      "Ep:79, loss:0.00006, loss_test:0.10508, lr:2.03e-03, fs:0.87685 (r=0.899,p=0.856),  time:34.558, tt:2764.655\n",
      "Ep:80, loss:0.00006, loss_test:0.11064, lr:1.99e-03, fs:0.87562 (r=0.889,p=0.863),  time:34.551, tt:2798.630\n",
      "Ep:81, loss:0.00006, loss_test:0.11227, lr:1.95e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.527, tt:2831.251\n",
      "Ep:82, loss:0.00006, loss_test:0.11005, lr:1.91e-03, fs:0.89447 (r=0.899,p=0.890),  time:34.500, tt:2863.466\n",
      "Ep:83, loss:0.00006, loss_test:0.10940, lr:1.87e-03, fs:0.88119 (r=0.899,p=0.864),  time:34.484, tt:2896.686\n",
      "Ep:84, loss:0.00006, loss_test:0.11264, lr:1.83e-03, fs:0.88000 (r=0.889,p=0.871),  time:34.452, tt:2928.421\n",
      "Ep:85, loss:0.00006, loss_test:0.11180, lr:1.80e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.436, tt:2961.465\n",
      "Ep:86, loss:0.00005, loss_test:0.10940, lr:1.76e-03, fs:0.88557 (r=0.899,p=0.873),  time:34.409, tt:2993.561\n",
      "Ep:87, loss:0.00005, loss_test:0.10837, lr:1.72e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.393, tt:3026.552\n",
      "Ep:88, loss:0.00005, loss_test:0.11144, lr:1.69e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.362, tt:3058.237\n",
      "Ep:89, loss:0.00005, loss_test:0.11194, lr:1.66e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.374, tt:3093.668\n",
      "Ep:90, loss:0.00005, loss_test:0.11025, lr:1.62e-03, fs:0.88000 (r=0.889,p=0.871),  time:34.372, tt:3127.867\n",
      "Ep:91, loss:0.00005, loss_test:0.11044, lr:1.59e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.352, tt:3160.351\n",
      "Ep:92, loss:0.00005, loss_test:0.11306, lr:1.56e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.364, tt:3195.846\n",
      "Ep:93, loss:0.00005, loss_test:0.11158, lr:1.53e-03, fs:0.88119 (r=0.899,p=0.864),  time:34.357, tt:3229.517\n",
      "Ep:94, loss:0.00005, loss_test:0.11015, lr:1.50e-03, fs:0.88119 (r=0.899,p=0.864),  time:34.353, tt:3263.530\n",
      "Ep:95, loss:0.00005, loss_test:0.11216, lr:1.47e-03, fs:0.89796 (r=0.889,p=0.907),  time:34.352, tt:3297.793\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00005, loss_test:0.11302, lr:1.44e-03, fs:0.89796 (r=0.889,p=0.907),  time:34.351, tt:3332.070\n",
      "Ep:97, loss:0.00005, loss_test:0.11188, lr:1.41e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.353, tt:3366.593\n",
      "Ep:98, loss:0.00004, loss_test:0.11172, lr:1.38e-03, fs:0.88000 (r=0.889,p=0.871),  time:34.345, tt:3400.148\n",
      "Ep:99, loss:0.00005, loss_test:0.11397, lr:1.35e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.342, tt:3434.163\n",
      "Ep:100, loss:0.00004, loss_test:0.11261, lr:1.33e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.346, tt:3468.956\n",
      "Ep:101, loss:0.00004, loss_test:0.10966, lr:1.30e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.341, tt:3502.828\n",
      "Ep:102, loss:0.00005, loss_test:0.11255, lr:1.27e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.342, tt:3537.236\n",
      "Ep:103, loss:0.00005, loss_test:0.11410, lr:1.25e-03, fs:0.90256 (r=0.889,p=0.917),  time:34.338, tt:3571.107\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00004, loss_test:0.11213, lr:1.22e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.342, tt:3605.873\n",
      "Ep:105, loss:0.00004, loss_test:0.11393, lr:1.20e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.336, tt:3639.661\n",
      "Ep:106, loss:0.00004, loss_test:0.11462, lr:1.17e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.348, tt:3675.272\n",
      "Ep:107, loss:0.00004, loss_test:0.11189, lr:1.15e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.352, tt:3710.024\n",
      "Ep:108, loss:0.00004, loss_test:0.10999, lr:1.13e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.345, tt:3743.591\n",
      "Ep:109, loss:0.00004, loss_test:0.11004, lr:1.11e-03, fs:0.89340 (r=0.889,p=0.898),  time:34.335, tt:3776.866\n",
      "Ep:110, loss:0.00004, loss_test:0.11253, lr:1.08e-03, fs:0.89796 (r=0.889,p=0.907),  time:34.349, tt:3812.698\n",
      "Ep:111, loss:0.00004, loss_test:0.11274, lr:1.06e-03, fs:0.90256 (r=0.889,p=0.917),  time:34.349, tt:3847.106\n",
      "Ep:112, loss:0.00004, loss_test:0.11107, lr:1.04e-03, fs:0.88889 (r=0.889,p=0.889),  time:34.375, tt:3884.349\n",
      "Ep:113, loss:0.00004, loss_test:0.10998, lr:1.02e-03, fs:0.88442 (r=0.889,p=0.880),  time:34.389, tt:3920.316\n",
      "Ep:114, loss:0.00004, loss_test:0.11237, lr:9.99e-04, fs:0.89796 (r=0.889,p=0.907),  time:34.371, tt:3952.723\n",
      "Ep:115, loss:0.00004, loss_test:0.11381, lr:9.79e-04, fs:0.90722 (r=0.889,p=0.926),  time:34.364, tt:3986.190\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00004, loss_test:0.11224, lr:9.60e-04, fs:0.89796 (r=0.889,p=0.907),  time:34.341, tt:4017.907\n",
      "Ep:117, loss:0.00004, loss_test:0.11085, lr:9.41e-04, fs:0.88889 (r=0.889,p=0.889),  time:34.343, tt:4052.502\n",
      "Ep:118, loss:0.00004, loss_test:0.11049, lr:9.22e-04, fs:0.89447 (r=0.899,p=0.890),  time:34.275, tt:4078.693\n",
      "Ep:119, loss:0.00004, loss_test:0.11127, lr:9.03e-04, fs:0.90256 (r=0.889,p=0.917),  time:34.262, tt:4111.487\n",
      "Ep:120, loss:0.00004, loss_test:0.11311, lr:8.85e-04, fs:0.90256 (r=0.889,p=0.917),  time:34.241, tt:4143.150\n",
      "Ep:121, loss:0.00004, loss_test:0.11422, lr:8.68e-04, fs:0.90256 (r=0.889,p=0.917),  time:34.205, tt:4173.024\n",
      "Ep:122, loss:0.00004, loss_test:0.11375, lr:8.50e-04, fs:0.89796 (r=0.889,p=0.907),  time:34.205, tt:4207.167\n",
      "Ep:123, loss:0.00004, loss_test:0.11298, lr:8.33e-04, fs:0.89796 (r=0.889,p=0.907),  time:34.193, tt:4239.906\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 82\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24622, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.825, tt:32.825\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24462, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:33.056, tt:66.112\n",
      "Ep:2, loss:0.00059, loss_test:0.24128, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.861, tt:98.583\n",
      "Ep:3, loss:0.00055, loss_test:0.23451, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:33.476, tt:133.906\n",
      "Ep:4, loss:0.00048, loss_test:0.22455, lr:9.22e-03, fs:0.67577 (r=1.000,p=0.510),  time:33.529, tt:167.646\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00039, loss_test:0.22104, lr:9.04e-03, fs:0.64885 (r=0.859,p=0.521),  time:33.993, tt:203.956\n",
      "Ep:6, loss:0.00033, loss_test:0.22547, lr:8.86e-03, fs:0.66667 (r=0.788,p=0.578),  time:33.917, tt:237.419\n",
      "Ep:7, loss:0.00030, loss_test:0.22803, lr:8.68e-03, fs:0.64220 (r=0.707,p=0.588),  time:33.708, tt:269.666\n",
      "Ep:8, loss:0.00030, loss_test:0.23115, lr:8.51e-03, fs:0.63415 (r=0.657,p=0.613),  time:33.604, tt:302.433\n",
      "Ep:9, loss:0.00028, loss_test:0.23027, lr:8.34e-03, fs:0.62069 (r=0.636,p=0.606),  time:33.774, tt:337.736\n",
      "Ep:10, loss:0.00027, loss_test:0.22010, lr:8.17e-03, fs:0.67890 (r=0.747,p=0.622),  time:33.646, tt:370.108\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.22446, lr:8.01e-03, fs:0.65366 (r=0.677,p=0.632),  time:33.705, tt:404.465\n",
      "Ep:12, loss:0.00027, loss_test:0.22975, lr:7.85e-03, fs:0.62245 (r=0.616,p=0.629),  time:33.619, tt:437.052\n",
      "Ep:13, loss:0.00026, loss_test:0.23024, lr:7.69e-03, fs:0.59375 (r=0.576,p=0.613),  time:33.773, tt:472.823\n",
      "Ep:14, loss:0.00025, loss_test:0.22478, lr:7.54e-03, fs:0.59296 (r=0.596,p=0.590),  time:33.891, tt:508.367\n",
      "Ep:15, loss:0.00024, loss_test:0.22869, lr:7.39e-03, fs:0.57592 (r=0.556,p=0.598),  time:33.769, tt:540.306\n",
      "Ep:16, loss:0.00023, loss_test:0.23307, lr:7.24e-03, fs:0.53846 (r=0.495,p=0.590),  time:33.701, tt:572.918\n",
      "Ep:17, loss:0.00023, loss_test:0.23036, lr:7.09e-03, fs:0.60204 (r=0.596,p=0.608),  time:33.718, tt:606.922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-072c7752a036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,124,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24368, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.263, tt:36.263\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24130, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.948, tt:75.897\n",
      "Ep:2, loss:0.00059, loss_test:0.23619, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.767, tt:116.300\n",
      "Ep:3, loss:0.00055, loss_test:0.22489, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.960, tt:155.840\n",
      "Ep:4, loss:0.00047, loss_test:0.20281, lr:9.61e-03, fs:0.66438 (r=0.980,p=0.503),  time:38.837, tt:194.187\n",
      "Ep:5, loss:0.00037, loss_test:0.18962, lr:9.51e-03, fs:0.71595 (r=0.929,p=0.582),  time:39.318, tt:235.906\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.19093, lr:9.41e-03, fs:0.67826 (r=0.788,p=0.595),  time:40.008, tt:280.055\n",
      "Ep:7, loss:0.00030, loss_test:0.19128, lr:9.32e-03, fs:0.65158 (r=0.727,p=0.590),  time:40.750, tt:326.002\n",
      "Ep:8, loss:0.00029, loss_test:0.18954, lr:9.23e-03, fs:0.67857 (r=0.768,p=0.608),  time:41.196, tt:370.761\n",
      "Ep:9, loss:0.00029, loss_test:0.18912, lr:9.14e-03, fs:0.66981 (r=0.717,p=0.628),  time:41.069, tt:410.686\n",
      "Ep:10, loss:0.00028, loss_test:0.18626, lr:9.04e-03, fs:0.66038 (r=0.707,p=0.619),  time:41.119, tt:452.312\n",
      "Ep:11, loss:0.00026, loss_test:0.18615, lr:8.95e-03, fs:0.69767 (r=0.758,p=0.647),  time:41.010, tt:492.124\n",
      "Ep:12, loss:0.00026, loss_test:0.18531, lr:8.86e-03, fs:0.68571 (r=0.727,p=0.649),  time:41.069, tt:533.892\n",
      "Ep:13, loss:0.00025, loss_test:0.18024, lr:8.78e-03, fs:0.70142 (r=0.747,p=0.661),  time:41.113, tt:575.583\n",
      "Ep:14, loss:0.00024, loss_test:0.17464, lr:8.69e-03, fs:0.75229 (r=0.828,p=0.689),  time:41.137, tt:617.050\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.17213, lr:8.60e-03, fs:0.74312 (r=0.818,p=0.681),  time:41.258, tt:660.131\n",
      "Ep:16, loss:0.00023, loss_test:0.16829, lr:8.51e-03, fs:0.74886 (r=0.828,p=0.683),  time:41.339, tt:702.771\n",
      "Ep:17, loss:0.00022, loss_test:0.16504, lr:8.43e-03, fs:0.77333 (r=0.879,p=0.690),  time:41.553, tt:747.960\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.16509, lr:8.35e-03, fs:0.74208 (r=0.828,p=0.672),  time:41.727, tt:792.812\n",
      "Ep:19, loss:0.00022, loss_test:0.16386, lr:8.26e-03, fs:0.77570 (r=0.838,p=0.722),  time:41.560, tt:831.199\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.16388, lr:8.18e-03, fs:0.76991 (r=0.879,p=0.685),  time:41.443, tt:870.299\n",
      "Ep:21, loss:0.00020, loss_test:0.15912, lr:8.10e-03, fs:0.78571 (r=0.889,p=0.704),  time:41.405, tt:910.915\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.16230, lr:8.02e-03, fs:0.77934 (r=0.838,p=0.728),  time:41.348, tt:950.996\n",
      "Ep:23, loss:0.00019, loss_test:0.15673, lr:7.94e-03, fs:0.78571 (r=0.889,p=0.704),  time:41.290, tt:990.951\n",
      "Ep:24, loss:0.00019, loss_test:0.15550, lr:7.86e-03, fs:0.80180 (r=0.899,p=0.724),  time:41.238, tt:1030.946\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.16132, lr:7.78e-03, fs:0.78140 (r=0.848,p=0.724),  time:41.378, tt:1075.827\n",
      "Ep:26, loss:0.00018, loss_test:0.15455, lr:7.70e-03, fs:0.80870 (r=0.939,p=0.710),  time:41.473, tt:1119.768\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.15295, lr:7.62e-03, fs:0.79646 (r=0.909,p=0.709),  time:41.550, tt:1163.405\n",
      "Ep:28, loss:0.00017, loss_test:0.15785, lr:7.55e-03, fs:0.82143 (r=0.929,p=0.736),  time:41.593, tt:1206.188\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.14858, lr:7.47e-03, fs:0.82192 (r=0.909,p=0.750),  time:41.499, tt:1244.961\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.14915, lr:7.40e-03, fs:0.82353 (r=0.919,p=0.746),  time:41.453, tt:1285.052\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.14774, lr:7.32e-03, fs:0.83262 (r=0.980,p=0.724),  time:41.459, tt:1326.685\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.14776, lr:7.25e-03, fs:0.84163 (r=0.939,p=0.762),  time:41.427, tt:1367.092\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.15561, lr:7.18e-03, fs:0.80952 (r=0.859,p=0.766),  time:41.437, tt:1408.854\n",
      "Ep:34, loss:0.00014, loss_test:0.14688, lr:7.11e-03, fs:0.83556 (r=0.949,p=0.746),  time:41.419, tt:1449.666\n",
      "Ep:35, loss:0.00014, loss_test:0.15138, lr:7.03e-03, fs:0.83186 (r=0.949,p=0.740),  time:41.499, tt:1493.981\n",
      "Ep:36, loss:0.00014, loss_test:0.14873, lr:6.96e-03, fs:0.81279 (r=0.899,p=0.742),  time:41.586, tt:1538.696\n",
      "Ep:37, loss:0.00013, loss_test:0.14342, lr:6.89e-03, fs:0.84651 (r=0.919,p=0.784),  time:41.618, tt:1581.492\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.15228, lr:6.83e-03, fs:0.82857 (r=0.879,p=0.784),  time:41.644, tt:1624.120\n",
      "Ep:39, loss:0.00012, loss_test:0.14411, lr:6.76e-03, fs:0.86364 (r=0.960,p=0.785),  time:41.676, tt:1667.056\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.14661, lr:6.69e-03, fs:0.81982 (r=0.919,p=0.740),  time:41.704, tt:1709.849\n",
      "Ep:41, loss:0.00011, loss_test:0.14857, lr:6.62e-03, fs:0.83092 (r=0.869,p=0.796),  time:41.707, tt:1751.693\n",
      "Ep:42, loss:0.00011, loss_test:0.14157, lr:6.56e-03, fs:0.84651 (r=0.919,p=0.784),  time:41.693, tt:1792.801\n",
      "Ep:43, loss:0.00010, loss_test:0.14843, lr:6.49e-03, fs:0.81132 (r=0.869,p=0.761),  time:41.700, tt:1834.799\n",
      "Ep:44, loss:0.00010, loss_test:0.14419, lr:6.43e-03, fs:0.81731 (r=0.859,p=0.780),  time:41.708, tt:1876.879\n",
      "Ep:45, loss:0.00010, loss_test:0.14692, lr:6.36e-03, fs:0.80976 (r=0.838,p=0.783),  time:41.802, tt:1922.897\n",
      "Ep:46, loss:0.00010, loss_test:0.13956, lr:6.30e-03, fs:0.83092 (r=0.869,p=0.796),  time:41.887, tt:1968.712\n",
      "Ep:47, loss:0.00009, loss_test:0.14264, lr:6.24e-03, fs:0.81905 (r=0.869,p=0.775),  time:41.944, tt:2013.291\n",
      "Ep:48, loss:0.00009, loss_test:0.14140, lr:6.17e-03, fs:0.82126 (r=0.859,p=0.787),  time:41.997, tt:2057.858\n",
      "Ep:49, loss:0.00009, loss_test:0.14556, lr:6.11e-03, fs:0.84314 (r=0.869,p=0.819),  time:41.989, tt:2099.450\n",
      "Ep:50, loss:0.00008, loss_test:0.14180, lr:6.05e-03, fs:0.84314 (r=0.869,p=0.819),  time:41.973, tt:2140.604\n",
      "Ep:51, loss:0.00008, loss_test:0.14197, lr:5.93e-03, fs:0.82075 (r=0.879,p=0.770),  time:41.982, tt:2183.040\n",
      "Ep:52, loss:0.00008, loss_test:0.14290, lr:5.81e-03, fs:0.83673 (r=0.828,p=0.845),  time:41.962, tt:2223.971\n",
      "Ep:53, loss:0.00007, loss_test:0.14488, lr:5.70e-03, fs:0.81951 (r=0.848,p=0.792),  time:41.963, tt:2266.011\n",
      "Ep:54, loss:0.00007, loss_test:0.13642, lr:5.58e-03, fs:0.83254 (r=0.879,p=0.791),  time:42.010, tt:2310.557\n",
      "Ep:55, loss:0.00007, loss_test:0.14316, lr:5.47e-03, fs:0.83168 (r=0.848,p=0.816),  time:42.067, tt:2355.761\n",
      "Ep:56, loss:0.00007, loss_test:0.14134, lr:5.36e-03, fs:0.86000 (r=0.869,p=0.851),  time:42.093, tt:2399.304\n",
      "Ep:57, loss:0.00007, loss_test:0.14563, lr:5.26e-03, fs:0.84878 (r=0.879,p=0.821),  time:42.141, tt:2444.170\n",
      "Ep:58, loss:0.00007, loss_test:0.15032, lr:5.15e-03, fs:0.84656 (r=0.808,p=0.889),  time:42.177, tt:2488.462\n",
      "Ep:59, loss:0.00006, loss_test:0.15199, lr:5.05e-03, fs:0.81633 (r=0.808,p=0.825),  time:42.168, tt:2530.095\n",
      "Ep:60, loss:0.00006, loss_test:0.14767, lr:4.95e-03, fs:0.82653 (r=0.818,p=0.835),  time:42.150, tt:2571.134\n",
      "Ep:61, loss:0.00006, loss_test:0.14330, lr:4.85e-03, fs:0.85714 (r=0.848,p=0.866),  time:42.113, tt:2611.020\n",
      "Ep:62, loss:0.00006, loss_test:0.15139, lr:4.75e-03, fs:0.79144 (r=0.747,p=0.841),  time:42.071, tt:2650.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.15340, lr:4.66e-03, fs:0.78307 (r=0.747,p=0.822),  time:42.064, tt:2692.074\n",
      "Ep:64, loss:0.00005, loss_test:0.15222, lr:4.57e-03, fs:0.80214 (r=0.758,p=0.852),  time:42.088, tt:2735.745\n",
      "Ep:65, loss:0.00005, loss_test:0.15209, lr:4.48e-03, fs:0.80000 (r=0.747,p=0.860),  time:42.114, tt:2779.516\n",
      "Ep:66, loss:0.00004, loss_test:0.15147, lr:4.39e-03, fs:0.80645 (r=0.758,p=0.862),  time:42.127, tt:2822.508\n",
      "Ep:67, loss:0.00005, loss_test:0.14638, lr:4.30e-03, fs:0.80628 (r=0.778,p=0.837),  time:42.152, tt:2866.333\n",
      "Ep:68, loss:0.00004, loss_test:0.14606, lr:4.21e-03, fs:0.81915 (r=0.778,p=0.865),  time:42.148, tt:2908.200\n",
      "Ep:69, loss:0.00004, loss_test:0.14762, lr:4.13e-03, fs:0.83333 (r=0.808,p=0.860),  time:42.126, tt:2948.791\n",
      "Ep:70, loss:0.00004, loss_test:0.15210, lr:4.05e-03, fs:0.79558 (r=0.727,p=0.878),  time:42.098, tt:2988.929\n",
      "Ep:71, loss:0.00004, loss_test:0.15829, lr:3.97e-03, fs:0.78261 (r=0.727,p=0.847),  time:42.058, tt:3028.164\n",
      "Ep:72, loss:0.00004, loss_test:0.15433, lr:3.89e-03, fs:0.79781 (r=0.737,p=0.869),  time:42.028, tt:3068.055\n",
      "Ep:73, loss:0.00004, loss_test:0.15420, lr:3.81e-03, fs:0.79144 (r=0.747,p=0.841),  time:42.029, tt:3110.131\n",
      "Ep:74, loss:0.00004, loss_test:0.15641, lr:3.73e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.052, tt:3153.911\n",
      "Ep:75, loss:0.00004, loss_test:0.15429, lr:3.66e-03, fs:0.80435 (r=0.747,p=0.871),  time:42.080, tt:3198.072\n",
      "Ep:76, loss:0.00003, loss_test:0.15626, lr:3.59e-03, fs:0.80874 (r=0.747,p=0.881),  time:42.135, tt:3244.423\n",
      "Ep:77, loss:0.00004, loss_test:0.16761, lr:3.52e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.179, tt:3289.961\n",
      "Ep:78, loss:0.00003, loss_test:0.16222, lr:3.45e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.192, tt:3333.178\n",
      "Ep:79, loss:0.00004, loss_test:0.14824, lr:3.38e-03, fs:0.80435 (r=0.747,p=0.871),  time:42.141, tt:3371.262\n",
      "Ep:80, loss:0.00003, loss_test:0.15377, lr:3.31e-03, fs:0.75706 (r=0.677,p=0.859),  time:42.144, tt:3413.632\n",
      "Ep:81, loss:0.00003, loss_test:0.15702, lr:3.24e-03, fs:0.74419 (r=0.646,p=0.877),  time:42.125, tt:3454.219\n",
      "Ep:82, loss:0.00003, loss_test:0.16120, lr:3.18e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.129, tt:3496.746\n",
      "Ep:83, loss:0.00003, loss_test:0.15898, lr:3.12e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.137, tt:3539.531\n",
      "Ep:84, loss:0.00003, loss_test:0.16272, lr:3.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:42.165, tt:3584.036\n",
      "Ep:85, loss:0.00003, loss_test:0.15955, lr:2.99e-03, fs:0.75145 (r=0.657,p=0.878),  time:42.152, tt:3625.031\n",
      "Ep:86, loss:0.00003, loss_test:0.15836, lr:2.93e-03, fs:0.77011 (r=0.677,p=0.893),  time:42.196, tt:3671.087\n",
      "Ep:87, loss:0.00003, loss_test:0.15358, lr:2.88e-03, fs:0.79545 (r=0.707,p=0.909),  time:42.226, tt:3715.850\n",
      "Ep:88, loss:0.00003, loss_test:0.15465, lr:2.82e-03, fs:0.76404 (r=0.687,p=0.861),  time:42.216, tt:3757.229\n",
      "Ep:89, loss:0.00003, loss_test:0.15590, lr:2.76e-03, fs:0.74713 (r=0.657,p=0.867),  time:42.226, tt:3800.309\n",
      "Ep:90, loss:0.00002, loss_test:0.15758, lr:2.71e-03, fs:0.77457 (r=0.677,p=0.905),  time:42.223, tt:3842.264\n",
      "Ep:91, loss:0.00003, loss_test:0.15883, lr:2.65e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.222, tt:3884.435\n",
      "Ep:92, loss:0.00002, loss_test:0.15722, lr:2.60e-03, fs:0.75000 (r=0.667,p=0.857),  time:42.198, tt:3924.415\n",
      "Ep:93, loss:0.00002, loss_test:0.15470, lr:2.55e-03, fs:0.73988 (r=0.646,p=0.865),  time:42.211, tt:3967.861\n",
      "Ep:94, loss:0.00002, loss_test:0.16007, lr:2.50e-03, fs:0.76301 (r=0.667,p=0.892),  time:42.249, tt:4013.692\n",
      "Ep:95, loss:0.00002, loss_test:0.16069, lr:2.45e-03, fs:0.76301 (r=0.667,p=0.892),  time:42.289, tt:4059.788\n",
      "Ep:96, loss:0.00002, loss_test:0.15718, lr:2.40e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.322, tt:4105.272\n",
      "Ep:97, loss:0.00002, loss_test:0.16258, lr:2.35e-03, fs:0.73373 (r=0.626,p=0.886),  time:42.325, tt:4147.894\n",
      "Ep:98, loss:0.00002, loss_test:0.16235, lr:2.31e-03, fs:0.73373 (r=0.626,p=0.886),  time:42.307, tt:4188.378\n",
      "Ep:99, loss:0.00002, loss_test:0.16288, lr:2.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:42.292, tt:4229.198\n",
      "Ep:100, loss:0.00002, loss_test:0.16072, lr:2.21e-03, fs:0.75294 (r=0.646,p=0.901),  time:42.253, tt:4267.584\n",
      "Ep:101, loss:0.00002, loss_test:0.15992, lr:2.17e-03, fs:0.73373 (r=0.626,p=0.886),  time:42.236, tt:4308.068\n",
      "Ep:102, loss:0.00002, loss_test:0.16243, lr:2.13e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.216, tt:4348.230\n",
      "Ep:103, loss:0.00002, loss_test:0.16328, lr:2.08e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.212, tt:4390.010\n",
      "Ep:104, loss:0.00002, loss_test:0.15865, lr:2.04e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.255, tt:4436.825\n",
      "Ep:105, loss:0.00002, loss_test:0.15565, lr:2.00e-03, fs:0.75581 (r=0.657,p=0.890),  time:42.281, tt:4481.792\n",
      "Ep:106, loss:0.00002, loss_test:0.16390, lr:1.96e-03, fs:0.73810 (r=0.626,p=0.899),  time:42.313, tt:4527.463\n",
      "Ep:107, loss:0.00002, loss_test:0.16679, lr:1.92e-03, fs:0.70370 (r=0.576,p=0.905),  time:42.302, tt:4568.582\n",
      "Ep:108, loss:0.00002, loss_test:0.16140, lr:1.89e-03, fs:0.71084 (r=0.596,p=0.881),  time:42.282, tt:4608.749\n",
      "Ep:109, loss:0.00002, loss_test:0.16213, lr:1.85e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.252, tt:4647.733\n",
      "Ep:110, loss:0.00002, loss_test:0.16748, lr:1.81e-03, fs:0.74699 (r=0.626,p=0.925),  time:42.240, tt:4688.664\n",
      "Ep:111, loss:0.00002, loss_test:0.16683, lr:1.78e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.219, tt:4728.524\n",
      "Ep:112, loss:0.00002, loss_test:0.16475, lr:1.74e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.216, tt:4770.435\n",
      "Ep:113, loss:0.00002, loss_test:0.16395, lr:1.71e-03, fs:0.72727 (r=0.606,p=0.909),  time:42.224, tt:4813.578\n",
      "Ep:114, loss:0.00002, loss_test:0.16502, lr:1.67e-03, fs:0.73810 (r=0.626,p=0.899),  time:42.241, tt:4857.673\n",
      "Ep:115, loss:0.00002, loss_test:0.16585, lr:1.64e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.247, tt:4900.629\n",
      "Ep:116, loss:0.00001, loss_test:0.16014, lr:1.61e-03, fs:0.75294 (r=0.646,p=0.901),  time:42.251, tt:4943.397\n",
      "Ep:117, loss:0.00001, loss_test:0.15806, lr:1.57e-03, fs:0.74854 (r=0.646,p=0.889),  time:42.188, tt:4978.233\n",
      "Ep:118, loss:0.00002, loss_test:0.16088, lr:1.54e-03, fs:0.71429 (r=0.606,p=0.870),  time:42.188, tt:5020.401\n",
      "Ep:119, loss:0.00002, loss_test:0.16442, lr:1.51e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.164, tt:5059.728\n",
      "Ep:120, loss:0.00001, loss_test:0.16290, lr:1.48e-03, fs:0.73810 (r=0.626,p=0.899),  time:42.157, tt:5101.011\n",
      "Ep:121, loss:0.00002, loss_test:0.16355, lr:1.45e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.123, tt:5138.985\n",
      "Ep:122, loss:0.00002, loss_test:0.16708, lr:1.42e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.055, tt:5172.713\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24207, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.103, tt:40.103\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23911, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:42.432, tt:84.865\n",
      "Ep:2, loss:0.00059, loss_test:0.23282, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:43.240, tt:129.720\n",
      "Ep:3, loss:0.00055, loss_test:0.21983, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:42.331, tt:169.324\n",
      "Ep:4, loss:0.00048, loss_test:0.19394, lr:9.61e-03, fs:0.67586 (r=0.990,p=0.513),  time:41.911, tt:209.554\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00039, loss_test:0.17250, lr:9.51e-03, fs:0.70992 (r=0.939,p=0.571),  time:41.759, tt:250.554\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.16957, lr:9.41e-03, fs:0.70588 (r=0.848,p=0.604),  time:41.628, tt:291.395\n",
      "Ep:7, loss:0.00031, loss_test:0.17024, lr:9.32e-03, fs:0.72000 (r=0.818,p=0.643),  time:41.430, tt:331.442\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.16988, lr:9.23e-03, fs:0.70742 (r=0.818,p=0.623),  time:41.200, tt:370.800\n",
      "Ep:9, loss:0.00029, loss_test:0.16381, lr:9.14e-03, fs:0.74208 (r=0.828,p=0.672),  time:41.469, tt:414.691\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00028, loss_test:0.16892, lr:9.04e-03, fs:0.75248 (r=0.768,p=0.738),  time:41.792, tt:459.709\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.16526, lr:8.95e-03, fs:0.73832 (r=0.798,p=0.687),  time:41.904, tt:502.851\n",
      "Ep:12, loss:0.00026, loss_test:0.15547, lr:8.86e-03, fs:0.75576 (r=0.828,p=0.695),  time:42.084, tt:547.088\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.15419, lr:8.78e-03, fs:0.77570 (r=0.838,p=0.722),  time:42.040, tt:588.554\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.15774, lr:8.69e-03, fs:0.78641 (r=0.818,p=0.757),  time:42.009, tt:630.131\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.14975, lr:8.60e-03, fs:0.78673 (r=0.838,p=0.741),  time:42.018, tt:672.292\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.14906, lr:8.51e-03, fs:0.78378 (r=0.879,p=0.707),  time:42.139, tt:716.365\n",
      "Ep:17, loss:0.00023, loss_test:0.14862, lr:8.43e-03, fs:0.78140 (r=0.848,p=0.724),  time:42.184, tt:759.311\n",
      "Ep:18, loss:0.00022, loss_test:0.14403, lr:8.35e-03, fs:0.78704 (r=0.859,p=0.726),  time:42.265, tt:803.043\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.14276, lr:8.26e-03, fs:0.78027 (r=0.879,p=0.702),  time:42.431, tt:848.625\n",
      "Ep:20, loss:0.00022, loss_test:0.15066, lr:8.18e-03, fs:0.78641 (r=0.818,p=0.757),  time:42.600, tt:894.604\n",
      "Ep:21, loss:0.00020, loss_test:0.14099, lr:8.10e-03, fs:0.78070 (r=0.899,p=0.690),  time:42.674, tt:938.831\n",
      "Ep:22, loss:0.00021, loss_test:0.14444, lr:8.02e-03, fs:0.80189 (r=0.859,p=0.752),  time:42.645, tt:980.830\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.14026, lr:7.94e-03, fs:0.80000 (r=0.869,p=0.741),  time:42.619, tt:1022.864\n",
      "Ep:24, loss:0.00020, loss_test:0.14096, lr:7.86e-03, fs:0.80717 (r=0.909,p=0.726),  time:42.526, tt:1063.163\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.14087, lr:7.78e-03, fs:0.81407 (r=0.818,p=0.810),  time:42.515, tt:1105.383\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.13484, lr:7.70e-03, fs:0.78924 (r=0.889,p=0.710),  time:42.527, tt:1148.240\n",
      "Ep:27, loss:0.00018, loss_test:0.13944, lr:7.62e-03, fs:0.81731 (r=0.859,p=0.780),  time:42.392, tt:1186.984\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.13768, lr:7.55e-03, fs:0.83654 (r=0.879,p=0.798),  time:42.490, tt:1232.209\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.13135, lr:7.47e-03, fs:0.82569 (r=0.909,p=0.756),  time:42.583, tt:1277.497\n",
      "Ep:30, loss:0.00016, loss_test:0.13533, lr:7.40e-03, fs:0.83092 (r=0.869,p=0.796),  time:42.653, tt:1322.235\n",
      "Ep:31, loss:0.00016, loss_test:0.13610, lr:7.32e-03, fs:0.82126 (r=0.859,p=0.787),  time:42.726, tt:1367.244\n",
      "Ep:32, loss:0.00016, loss_test:0.12671, lr:7.25e-03, fs:0.81279 (r=0.899,p=0.742),  time:42.701, tt:1409.137\n",
      "Ep:33, loss:0.00015, loss_test:0.12763, lr:7.18e-03, fs:0.85167 (r=0.899,p=0.809),  time:42.680, tt:1451.128\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.12669, lr:7.11e-03, fs:0.83721 (r=0.909,p=0.776),  time:42.716, tt:1495.060\n",
      "Ep:35, loss:0.00014, loss_test:0.12232, lr:7.03e-03, fs:0.82629 (r=0.889,p=0.772),  time:42.737, tt:1538.515\n",
      "Ep:36, loss:0.00014, loss_test:0.12618, lr:6.96e-03, fs:0.84615 (r=0.889,p=0.807),  time:42.722, tt:1580.730\n",
      "Ep:37, loss:0.00013, loss_test:0.12361, lr:6.89e-03, fs:0.82857 (r=0.879,p=0.784),  time:42.730, tt:1623.744\n",
      "Ep:38, loss:0.00013, loss_test:0.12325, lr:6.83e-03, fs:0.84211 (r=0.889,p=0.800),  time:42.815, tt:1669.800\n",
      "Ep:39, loss:0.00012, loss_test:0.12034, lr:6.76e-03, fs:0.85714 (r=0.909,p=0.811),  time:42.893, tt:1715.739\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00012, loss_test:0.11557, lr:6.69e-03, fs:0.85714 (r=0.909,p=0.811),  time:42.951, tt:1761.000\n",
      "Ep:41, loss:0.00012, loss_test:0.11538, lr:6.62e-03, fs:0.85714 (r=0.909,p=0.811),  time:42.990, tt:1805.590\n",
      "Ep:42, loss:0.00011, loss_test:0.11822, lr:6.56e-03, fs:0.85714 (r=0.909,p=0.811),  time:42.996, tt:1848.817\n",
      "Ep:43, loss:0.00011, loss_test:0.11435, lr:6.49e-03, fs:0.85854 (r=0.889,p=0.830),  time:42.969, tt:1890.624\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.11231, lr:6.43e-03, fs:0.86408 (r=0.899,p=0.832),  time:42.985, tt:1934.310\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.10843, lr:6.36e-03, fs:0.85577 (r=0.899,p=0.817),  time:42.985, tt:1977.321\n",
      "Ep:46, loss:0.00010, loss_test:0.11065, lr:6.30e-03, fs:0.85308 (r=0.909,p=0.804),  time:42.987, tt:2020.388\n",
      "Ep:47, loss:0.00009, loss_test:0.11220, lr:6.24e-03, fs:0.86700 (r=0.889,p=0.846),  time:42.969, tt:2062.506\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.10714, lr:6.17e-03, fs:0.86124 (r=0.909,p=0.818),  time:43.042, tt:2109.066\n",
      "Ep:49, loss:0.00009, loss_test:0.10518, lr:6.11e-03, fs:0.87129 (r=0.889,p=0.854),  time:43.082, tt:2154.090\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00009, loss_test:0.10707, lr:6.05e-03, fs:0.85981 (r=0.929,p=0.800),  time:43.160, tt:2201.162\n",
      "Ep:51, loss:0.00008, loss_test:0.10529, lr:5.99e-03, fs:0.86667 (r=0.919,p=0.820),  time:43.130, tt:2242.778\n",
      "Ep:52, loss:0.00008, loss_test:0.10024, lr:5.93e-03, fs:0.84906 (r=0.909,p=0.796),  time:43.101, tt:2284.344\n",
      "Ep:53, loss:0.00008, loss_test:0.11106, lr:5.87e-03, fs:0.88038 (r=0.929,p=0.836),  time:43.100, tt:2327.403\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.09696, lr:5.81e-03, fs:0.83871 (r=0.919,p=0.771),  time:43.067, tt:2368.712\n",
      "Ep:55, loss:0.00007, loss_test:0.10205, lr:5.75e-03, fs:0.88038 (r=0.929,p=0.836),  time:43.071, tt:2411.963\n",
      "Ep:56, loss:0.00007, loss_test:0.10423, lr:5.70e-03, fs:0.89320 (r=0.929,p=0.860),  time:43.029, tt:2452.674\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.09903, lr:5.64e-03, fs:0.87923 (r=0.919,p=0.843),  time:43.020, tt:2495.134\n",
      "Ep:58, loss:0.00007, loss_test:0.09717, lr:5.58e-03, fs:0.88780 (r=0.919,p=0.858),  time:43.054, tt:2540.167\n",
      "Ep:59, loss:0.00006, loss_test:0.09974, lr:5.53e-03, fs:0.85167 (r=0.899,p=0.809),  time:43.089, tt:2585.322\n",
      "Ep:60, loss:0.00006, loss_test:0.09903, lr:5.47e-03, fs:0.88038 (r=0.929,p=0.836),  time:43.115, tt:2630.018\n",
      "Ep:61, loss:0.00006, loss_test:0.09722, lr:5.42e-03, fs:0.88325 (r=0.879,p=0.888),  time:43.120, tt:2673.464\n",
      "Ep:62, loss:0.00006, loss_test:0.09785, lr:5.36e-03, fs:0.89216 (r=0.919,p=0.867),  time:43.083, tt:2714.221\n",
      "Ep:63, loss:0.00005, loss_test:0.10471, lr:5.31e-03, fs:0.89756 (r=0.929,p=0.868),  time:43.048, tt:2755.104\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.10043, lr:5.26e-03, fs:0.89756 (r=0.929,p=0.868),  time:43.017, tt:2796.087\n",
      "Ep:65, loss:0.00005, loss_test:0.09269, lr:5.20e-03, fs:0.89320 (r=0.929,p=0.860),  time:42.970, tt:2836.001\n",
      "Ep:66, loss:0.00005, loss_test:0.10166, lr:5.15e-03, fs:0.89320 (r=0.929,p=0.860),  time:42.965, tt:2878.652\n",
      "Ep:67, loss:0.00004, loss_test:0.09657, lr:5.10e-03, fs:0.89756 (r=0.929,p=0.868),  time:42.967, tt:2921.723\n",
      "Ep:68, loss:0.00004, loss_test:0.09747, lr:5.05e-03, fs:0.88442 (r=0.889,p=0.880),  time:42.997, tt:2966.771\n",
      "Ep:69, loss:0.00004, loss_test:0.09592, lr:5.00e-03, fs:0.89756 (r=0.929,p=0.868),  time:43.021, tt:3011.495\n",
      "Ep:70, loss:0.00004, loss_test:0.09452, lr:4.95e-03, fs:0.91457 (r=0.919,p=0.910),  time:43.007, tt:3053.482\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.09088, lr:4.90e-03, fs:0.89216 (r=0.919,p=0.867),  time:42.976, tt:3094.299\n",
      "Ep:72, loss:0.00004, loss_test:0.09787, lr:4.85e-03, fs:0.90196 (r=0.929,p=0.876),  time:42.969, tt:3136.706\n",
      "Ep:73, loss:0.00004, loss_test:0.09177, lr:4.80e-03, fs:0.88557 (r=0.899,p=0.873),  time:42.946, tt:3178.015\n",
      "Ep:74, loss:0.00004, loss_test:0.10049, lr:4.75e-03, fs:0.89447 (r=0.899,p=0.890),  time:42.927, tt:3219.504\n",
      "Ep:75, loss:0.00004, loss_test:0.10413, lr:4.71e-03, fs:0.89655 (r=0.919,p=0.875),  time:42.913, tt:3261.387\n",
      "Ep:76, loss:0.00003, loss_test:0.09521, lr:4.66e-03, fs:0.91667 (r=0.889,p=0.946),  time:42.904, tt:3303.635\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00004, loss_test:0.09375, lr:4.61e-03, fs:0.89320 (r=0.929,p=0.860),  time:42.910, tt:3347.010\n",
      "Ep:78, loss:0.00003, loss_test:0.10008, lr:4.57e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.947, tt:3392.786\n",
      "Ep:79, loss:0.00003, loss_test:0.10013, lr:4.52e-03, fs:0.88000 (r=0.889,p=0.871),  time:42.962, tt:3436.966\n",
      "Ep:80, loss:0.00003, loss_test:0.09384, lr:4.48e-03, fs:0.89756 (r=0.929,p=0.868),  time:42.980, tt:3481.414\n",
      "Ep:81, loss:0.00003, loss_test:0.09590, lr:4.43e-03, fs:0.89340 (r=0.889,p=0.898),  time:42.945, tt:3521.485\n",
      "Ep:82, loss:0.00003, loss_test:0.10088, lr:4.39e-03, fs:0.90196 (r=0.929,p=0.876),  time:42.916, tt:3562.008\n",
      "Ep:83, loss:0.00003, loss_test:0.09820, lr:4.34e-03, fs:0.90256 (r=0.889,p=0.917),  time:42.875, tt:3601.499\n",
      "Ep:84, loss:0.00003, loss_test:0.09586, lr:4.30e-03, fs:0.90256 (r=0.889,p=0.917),  time:42.820, tt:3639.680\n",
      "Ep:85, loss:0.00003, loss_test:0.09451, lr:4.26e-03, fs:0.90640 (r=0.929,p=0.885),  time:42.759, tt:3677.235\n",
      "Ep:86, loss:0.00002, loss_test:0.09811, lr:4.21e-03, fs:0.90256 (r=0.889,p=0.917),  time:42.714, tt:3716.118\n",
      "Ep:87, loss:0.00002, loss_test:0.09419, lr:4.17e-03, fs:0.89796 (r=0.889,p=0.907),  time:42.690, tt:3756.697\n",
      "Ep:88, loss:0.00002, loss_test:0.09621, lr:4.09e-03, fs:0.90640 (r=0.929,p=0.885),  time:42.652, tt:3796.069\n",
      "Ep:89, loss:0.00002, loss_test:0.09834, lr:4.01e-03, fs:0.90256 (r=0.889,p=0.917),  time:42.623, tt:3836.112\n",
      "Ep:90, loss:0.00002, loss_test:0.09304, lr:3.93e-03, fs:0.90909 (r=0.909,p=0.909),  time:42.596, tt:3876.260\n",
      "Ep:91, loss:0.00002, loss_test:0.09295, lr:3.85e-03, fs:0.89899 (r=0.899,p=0.899),  time:42.585, tt:3917.783\n",
      "Ep:92, loss:0.00002, loss_test:0.09931, lr:3.77e-03, fs:0.89796 (r=0.889,p=0.907),  time:42.546, tt:3956.778\n",
      "Ep:93, loss:0.00002, loss_test:0.09615, lr:3.70e-03, fs:0.91089 (r=0.929,p=0.893),  time:42.527, tt:3997.507\n",
      "Ep:94, loss:0.00002, loss_test:0.09544, lr:3.62e-03, fs:0.89899 (r=0.899,p=0.899),  time:42.509, tt:4038.337\n",
      "Ep:95, loss:0.00002, loss_test:0.09871, lr:3.55e-03, fs:0.89796 (r=0.889,p=0.907),  time:42.495, tt:4079.472\n",
      "Ep:96, loss:0.00002, loss_test:0.10160, lr:3.48e-03, fs:0.90355 (r=0.899,p=0.908),  time:42.467, tt:4119.299\n",
      "Ep:97, loss:0.00002, loss_test:0.09673, lr:3.41e-03, fs:0.89796 (r=0.889,p=0.907),  time:42.457, tt:4160.758\n",
      "Ep:98, loss:0.00002, loss_test:0.09752, lr:3.34e-03, fs:0.92462 (r=0.929,p=0.920),  time:42.431, tt:4200.668\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00002, loss_test:0.09982, lr:3.31e-03, fs:0.92462 (r=0.929,p=0.920),  time:42.394, tt:4239.408\n",
      "Ep:100, loss:0.00001, loss_test:0.10072, lr:3.28e-03, fs:0.90256 (r=0.889,p=0.917),  time:42.364, tt:4278.768\n",
      "Ep:101, loss:0.00001, loss_test:0.10084, lr:3.24e-03, fs:0.90256 (r=0.889,p=0.917),  time:42.342, tt:4318.849\n",
      "Ep:102, loss:0.00001, loss_test:0.10055, lr:3.21e-03, fs:0.91919 (r=0.919,p=0.919),  time:42.318, tt:4358.740\n",
      "Ep:103, loss:0.00001, loss_test:0.10121, lr:3.18e-03, fs:0.90816 (r=0.899,p=0.918),  time:42.297, tt:4398.851\n",
      "Ep:104, loss:0.00001, loss_test:0.09920, lr:3.15e-03, fs:0.93401 (r=0.929,p=0.939),  time:42.287, tt:4440.087\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.10260, lr:3.12e-03, fs:0.91667 (r=0.889,p=0.946),  time:42.254, tt:4478.880\n",
      "Ep:106, loss:0.00001, loss_test:0.10459, lr:3.09e-03, fs:0.91667 (r=0.889,p=0.946),  time:42.246, tt:4520.315\n",
      "Ep:107, loss:0.00001, loss_test:0.09902, lr:3.05e-03, fs:0.91753 (r=0.899,p=0.937),  time:42.225, tt:4560.343\n",
      "Ep:108, loss:0.00001, loss_test:0.10152, lr:3.02e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.202, tt:4599.983\n",
      "Ep:109, loss:0.00001, loss_test:0.10301, lr:2.99e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.171, tt:4638.778\n",
      "Ep:110, loss:0.00001, loss_test:0.09929, lr:2.96e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.148, tt:4678.440\n",
      "Ep:111, loss:0.00001, loss_test:0.09931, lr:2.93e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.125, tt:4717.979\n",
      "Ep:112, loss:0.00001, loss_test:0.10204, lr:2.90e-03, fs:0.91667 (r=0.889,p=0.946),  time:42.116, tt:4759.075\n",
      "Ep:113, loss:0.00001, loss_test:0.10242, lr:2.88e-03, fs:0.91837 (r=0.909,p=0.928),  time:42.090, tt:4798.313\n",
      "Ep:114, loss:0.00001, loss_test:0.09915, lr:2.85e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.060, tt:4836.857\n",
      "Ep:115, loss:0.00001, loss_test:0.10143, lr:2.82e-03, fs:0.91192 (r=0.889,p=0.936),  time:42.019, tt:4874.204\n",
      "Ep:116, loss:0.00001, loss_test:0.10278, lr:2.76e-03, fs:0.90722 (r=0.889,p=0.926),  time:41.948, tt:4907.899\n",
      "Ep:117, loss:0.00001, loss_test:0.10311, lr:2.71e-03, fs:0.90722 (r=0.889,p=0.926),  time:41.939, tt:4948.830\n",
      "Ep:118, loss:0.00001, loss_test:0.10335, lr:2.65e-03, fs:0.91192 (r=0.889,p=0.936),  time:41.902, tt:4986.353\n",
      "Ep:119, loss:0.00001, loss_test:0.10561, lr:2.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:41.880, tt:5025.596\n",
      "Ep:120, loss:0.00001, loss_test:0.10438, lr:2.55e-03, fs:0.90722 (r=0.889,p=0.926),  time:41.837, tt:5062.322\n",
      "Ep:121, loss:0.00001, loss_test:0.10391, lr:2.50e-03, fs:0.90722 (r=0.889,p=0.926),  time:41.786, tt:5097.897\n",
      "Ep:122, loss:0.00001, loss_test:0.10096, lr:2.45e-03, fs:0.91192 (r=0.889,p=0.936),  time:41.758, tt:5136.204\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 82\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24543, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.592, tt:35.592\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24356, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.257, tt:74.514\n",
      "Ep:2, loss:0.00058, loss_test:0.23993, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.223, tt:114.669\n",
      "Ep:3, loss:0.00054, loss_test:0.23053, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.468, tt:153.872\n",
      "Ep:4, loss:0.00046, loss_test:0.21285, lr:9.61e-03, fs:0.67354 (r=0.990,p=0.510),  time:38.613, tt:193.067\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.21902, lr:9.51e-03, fs:0.67742 (r=0.848,p=0.564),  time:38.665, tt:231.989\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.21906, lr:9.41e-03, fs:0.68161 (r=0.768,p=0.613),  time:39.189, tt:274.322\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.22743, lr:9.32e-03, fs:0.64815 (r=0.707,p=0.598),  time:39.131, tt:313.048\n",
      "Ep:8, loss:0.00029, loss_test:0.21906, lr:9.23e-03, fs:0.67281 (r=0.737,p=0.619),  time:39.104, tt:351.939\n",
      "Ep:9, loss:0.00027, loss_test:0.22086, lr:9.14e-03, fs:0.67619 (r=0.717,p=0.640),  time:39.215, tt:392.150\n",
      "Ep:10, loss:0.00026, loss_test:0.22554, lr:9.04e-03, fs:0.64734 (r=0.677,p=0.620),  time:39.371, tt:433.077\n",
      "Ep:11, loss:0.00025, loss_test:0.22658, lr:8.95e-03, fs:0.65327 (r=0.657,p=0.650),  time:39.385, tt:472.620\n",
      "Ep:12, loss:0.00024, loss_test:0.22003, lr:8.86e-03, fs:0.67000 (r=0.677,p=0.663),  time:39.535, tt:513.949\n",
      "Ep:13, loss:0.00024, loss_test:0.21990, lr:8.78e-03, fs:0.66667 (r=0.687,p=0.648),  time:39.401, tt:551.617\n",
      "Ep:14, loss:0.00023, loss_test:0.23044, lr:8.69e-03, fs:0.65327 (r=0.657,p=0.650),  time:39.360, tt:590.396\n",
      "Ep:15, loss:0.00022, loss_test:0.22982, lr:8.60e-03, fs:0.65327 (r=0.657,p=0.650),  time:39.327, tt:629.227\n",
      "Ep:16, loss:0.00022, loss_test:0.22877, lr:8.51e-03, fs:0.68657 (r=0.697,p=0.676),  time:39.324, tt:668.503\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.23647, lr:8.43e-03, fs:0.61702 (r=0.586,p=0.652),  time:39.406, tt:709.305\n",
      "Ep:18, loss:0.00020, loss_test:0.22876, lr:8.35e-03, fs:0.65969 (r=0.636,p=0.685),  time:39.346, tt:747.579\n",
      "Ep:19, loss:0.00020, loss_test:0.22756, lr:8.26e-03, fs:0.68041 (r=0.667,p=0.695),  time:39.282, tt:785.631\n",
      "Ep:20, loss:0.00019, loss_test:0.23572, lr:8.18e-03, fs:0.61290 (r=0.576,p=0.655),  time:39.283, tt:824.945\n",
      "Ep:21, loss:0.00018, loss_test:0.22858, lr:8.10e-03, fs:0.68020 (r=0.677,p=0.684),  time:39.283, tt:864.225\n",
      "Ep:22, loss:0.00018, loss_test:0.23549, lr:8.02e-03, fs:0.59016 (r=0.545,p=0.643),  time:39.316, tt:904.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00017, loss_test:0.23257, lr:7.94e-03, fs:0.68394 (r=0.667,p=0.702),  time:39.297, tt:943.119\n",
      "Ep:24, loss:0.00017, loss_test:0.22873, lr:7.86e-03, fs:0.66667 (r=0.657,p=0.677),  time:39.188, tt:979.698\n",
      "Ep:25, loss:0.00017, loss_test:0.23628, lr:7.78e-03, fs:0.62703 (r=0.586,p=0.674),  time:39.208, tt:1019.396\n",
      "Ep:26, loss:0.00016, loss_test:0.23747, lr:7.70e-03, fs:0.56667 (r=0.515,p=0.630),  time:39.138, tt:1056.735\n",
      "Ep:27, loss:0.00016, loss_test:0.23488, lr:7.62e-03, fs:0.65946 (r=0.616,p=0.709),  time:39.137, tt:1095.846\n",
      "Ep:28, loss:0.00016, loss_test:0.23009, lr:7.47e-03, fs:0.68063 (r=0.657,p=0.707),  time:39.156, tt:1135.512\n",
      "Ep:29, loss:0.00015, loss_test:0.23384, lr:7.32e-03, fs:0.56667 (r=0.515,p=0.630),  time:39.162, tt:1174.858\n",
      "Ep:30, loss:0.00015, loss_test:0.23484, lr:7.18e-03, fs:0.61111 (r=0.556,p=0.679),  time:39.143, tt:1213.448\n",
      "Ep:31, loss:0.00014, loss_test:0.22968, lr:7.03e-03, fs:0.61622 (r=0.576,p=0.663),  time:39.086, tt:1250.740\n",
      "Ep:32, loss:0.00014, loss_test:0.22568, lr:6.89e-03, fs:0.67708 (r=0.657,p=0.699),  time:39.068, tt:1289.252\n",
      "Ep:33, loss:0.00013, loss_test:0.22423, lr:6.76e-03, fs:0.64615 (r=0.636,p=0.656),  time:39.052, tt:1327.768\n",
      "Ep:34, loss:0.00013, loss_test:0.22832, lr:6.62e-03, fs:0.68063 (r=0.657,p=0.707),  time:39.017, tt:1365.600\n",
      "Ep:35, loss:0.00013, loss_test:0.22525, lr:6.49e-03, fs:0.67347 (r=0.667,p=0.680),  time:38.986, tt:1403.488\n",
      "Ep:36, loss:0.00013, loss_test:0.23172, lr:6.36e-03, fs:0.65217 (r=0.606,p=0.706),  time:38.923, tt:1440.134\n",
      "Ep:37, loss:0.00012, loss_test:0.22912, lr:6.24e-03, fs:0.67368 (r=0.646,p=0.703),  time:38.918, tt:1478.881\n",
      "Ep:38, loss:0.00012, loss_test:0.22477, lr:6.11e-03, fs:0.68041 (r=0.667,p=0.695),  time:38.883, tt:1516.456\n",
      "Ep:39, loss:0.00011, loss_test:0.22064, lr:5.99e-03, fs:0.67358 (r=0.657,p=0.691),  time:38.862, tt:1554.475\n",
      "Ep:40, loss:0.00012, loss_test:0.23378, lr:5.87e-03, fs:0.57143 (r=0.505,p=0.658),  time:38.813, tt:1591.350\n",
      "Ep:41, loss:0.00011, loss_test:0.22801, lr:5.75e-03, fs:0.67725 (r=0.646,p=0.711),  time:38.778, tt:1628.696\n",
      "Ep:42, loss:0.00011, loss_test:0.22454, lr:5.64e-03, fs:0.68449 (r=0.646,p=0.727),  time:38.744, tt:1666.011\n",
      "Ep:43, loss:0.00011, loss_test:0.23066, lr:5.53e-03, fs:0.63736 (r=0.586,p=0.699),  time:38.741, tt:1704.583\n",
      "Ep:44, loss:0.00010, loss_test:0.22841, lr:5.42e-03, fs:0.66667 (r=0.626,p=0.713),  time:38.701, tt:1741.537\n",
      "Ep:45, loss:0.00010, loss_test:0.22638, lr:5.31e-03, fs:0.67742 (r=0.636,p=0.724),  time:38.701, tt:1780.233\n",
      "Ep:46, loss:0.00010, loss_test:0.22461, lr:5.20e-03, fs:0.59887 (r=0.535,p=0.679),  time:38.679, tt:1817.931\n",
      "Ep:47, loss:0.00010, loss_test:0.22272, lr:5.10e-03, fs:0.68108 (r=0.636,p=0.733),  time:38.662, tt:1855.754\n",
      "Ep:48, loss:0.00010, loss_test:0.22934, lr:5.00e-03, fs:0.67742 (r=0.636,p=0.724),  time:38.641, tt:1893.417\n",
      "Ep:49, loss:0.00009, loss_test:0.22367, lr:4.90e-03, fs:0.67358 (r=0.657,p=0.691),  time:38.630, tt:1931.476\n",
      "Ep:50, loss:0.00010, loss_test:0.22361, lr:4.80e-03, fs:0.70270 (r=0.657,p=0.756),  time:38.607, tt:1968.979\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.22971, lr:4.75e-03, fs:0.67033 (r=0.616,p=0.735),  time:38.609, tt:2007.651\n",
      "Ep:52, loss:0.00008, loss_test:0.22821, lr:4.71e-03, fs:0.53179 (r=0.465,p=0.622),  time:38.540, tt:2042.646\n",
      "Ep:53, loss:0.00009, loss_test:0.22276, lr:4.66e-03, fs:0.68817 (r=0.646,p=0.736),  time:38.506, tt:2079.341\n",
      "Ep:54, loss:0.00008, loss_test:0.23083, lr:4.61e-03, fs:0.60920 (r=0.535,p=0.707),  time:38.501, tt:2117.541\n",
      "Ep:55, loss:0.00009, loss_test:0.23295, lr:4.57e-03, fs:0.54118 (r=0.465,p=0.648),  time:38.489, tt:2155.400\n",
      "Ep:56, loss:0.00008, loss_test:0.23417, lr:4.52e-03, fs:0.68156 (r=0.616,p=0.762),  time:38.471, tt:2192.844\n",
      "Ep:57, loss:0.00008, loss_test:0.23238, lr:4.48e-03, fs:0.62570 (r=0.566,p=0.700),  time:38.483, tt:2232.027\n",
      "Ep:58, loss:0.00008, loss_test:0.22520, lr:4.43e-03, fs:0.64088 (r=0.586,p=0.707),  time:38.458, tt:2269.039\n",
      "Ep:59, loss:0.00007, loss_test:0.22713, lr:4.39e-03, fs:0.68132 (r=0.626,p=0.747),  time:38.441, tt:2306.459\n",
      "Ep:60, loss:0.00007, loss_test:0.23419, lr:4.34e-03, fs:0.65909 (r=0.586,p=0.753),  time:38.448, tt:2345.354\n",
      "Ep:61, loss:0.00006, loss_test:0.22890, lr:4.30e-03, fs:0.57317 (r=0.475,p=0.723),  time:38.425, tt:2382.376\n",
      "Ep:62, loss:0.00007, loss_test:0.22527, lr:4.21e-03, fs:0.63687 (r=0.576,p=0.713),  time:38.412, tt:2419.938\n",
      "Ep:63, loss:0.00007, loss_test:0.22605, lr:4.13e-03, fs:0.70270 (r=0.657,p=0.756),  time:38.402, tt:2457.697\n",
      "Ep:64, loss:0.00007, loss_test:0.22735, lr:4.05e-03, fs:0.55422 (r=0.465,p=0.687),  time:38.378, tt:2494.539\n",
      "Ep:65, loss:0.00007, loss_test:0.22633, lr:3.97e-03, fs:0.55758 (r=0.465,p=0.697),  time:38.373, tt:2532.602\n",
      "Ep:66, loss:0.00007, loss_test:0.22968, lr:3.89e-03, fs:0.68966 (r=0.606,p=0.800),  time:38.358, tt:2569.956\n",
      "Ep:67, loss:0.00006, loss_test:0.22621, lr:3.81e-03, fs:0.67039 (r=0.606,p=0.750),  time:38.329, tt:2606.383\n",
      "Ep:68, loss:0.00006, loss_test:0.22324, lr:3.73e-03, fs:0.62353 (r=0.535,p=0.746),  time:38.303, tt:2642.929\n",
      "Ep:69, loss:0.00006, loss_test:0.22768, lr:3.66e-03, fs:0.71508 (r=0.646,p=0.800),  time:38.289, tt:2680.261\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.23419, lr:3.62e-03, fs:0.61538 (r=0.525,p=0.743),  time:38.306, tt:2719.723\n",
      "Ep:71, loss:0.00005, loss_test:0.23227, lr:3.59e-03, fs:0.55556 (r=0.455,p=0.714),  time:38.305, tt:2757.926\n",
      "Ep:72, loss:0.00006, loss_test:0.22560, lr:3.55e-03, fs:0.65116 (r=0.566,p=0.767),  time:38.309, tt:2796.534\n",
      "Ep:73, loss:0.00005, loss_test:0.22541, lr:3.52e-03, fs:0.68927 (r=0.616,p=0.782),  time:38.305, tt:2834.586\n",
      "Ep:74, loss:0.00005, loss_test:0.23105, lr:3.48e-03, fs:0.66286 (r=0.586,p=0.763),  time:38.301, tt:2872.573\n",
      "Ep:75, loss:0.00005, loss_test:0.23316, lr:3.45e-03, fs:0.67816 (r=0.596,p=0.787),  time:38.316, tt:2912.009\n",
      "Ep:76, loss:0.00005, loss_test:0.23078, lr:3.41e-03, fs:0.68966 (r=0.606,p=0.800),  time:38.281, tt:2947.648\n",
      "Ep:77, loss:0.00005, loss_test:0.22371, lr:3.38e-03, fs:0.66667 (r=0.586,p=0.773),  time:38.274, tt:2985.406\n",
      "Ep:78, loss:0.00005, loss_test:0.22354, lr:3.34e-03, fs:0.66667 (r=0.596,p=0.756),  time:38.279, tt:3024.081\n",
      "Ep:79, loss:0.00005, loss_test:0.22885, lr:3.31e-03, fs:0.70455 (r=0.626,p=0.805),  time:38.251, tt:3060.111\n",
      "Ep:80, loss:0.00005, loss_test:0.22988, lr:3.28e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.247, tt:3097.998\n",
      "Ep:81, loss:0.00005, loss_test:0.22681, lr:3.21e-03, fs:0.67429 (r=0.596,p=0.776),  time:38.258, tt:3137.193\n",
      "Ep:82, loss:0.00004, loss_test:0.22613, lr:3.15e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.247, tt:3174.536\n",
      "Ep:83, loss:0.00005, loss_test:0.22694, lr:3.09e-03, fs:0.71910 (r=0.646,p=0.810),  time:38.272, tt:3214.832\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00004, loss_test:0.22386, lr:3.05e-03, fs:0.70000 (r=0.636,p=0.778),  time:38.270, tt:3252.983\n",
      "Ep:85, loss:0.00004, loss_test:0.22772, lr:3.02e-03, fs:0.69318 (r=0.616,p=0.792),  time:38.229, tt:3287.701\n",
      "Ep:86, loss:0.00004, loss_test:0.23109, lr:2.99e-03, fs:0.68571 (r=0.606,p=0.789),  time:38.213, tt:3324.549\n",
      "Ep:87, loss:0.00005, loss_test:0.22668, lr:2.96e-03, fs:0.68539 (r=0.616,p=0.772),  time:38.215, tt:3362.912\n",
      "Ep:88, loss:0.00004, loss_test:0.22466, lr:2.93e-03, fs:0.71111 (r=0.646,p=0.790),  time:38.196, tt:3399.453\n",
      "Ep:89, loss:0.00004, loss_test:0.22774, lr:2.90e-03, fs:0.68571 (r=0.606,p=0.789),  time:38.188, tt:3436.917\n",
      "Ep:90, loss:0.00004, loss_test:0.22853, lr:2.88e-03, fs:0.68182 (r=0.606,p=0.779),  time:38.197, tt:3475.912\n",
      "Ep:91, loss:0.00004, loss_test:0.22623, lr:2.85e-03, fs:0.67797 (r=0.606,p=0.769),  time:38.208, tt:3515.161\n",
      "Ep:92, loss:0.00004, loss_test:0.22414, lr:2.82e-03, fs:0.68889 (r=0.626,p=0.765),  time:38.189, tt:3551.537\n",
      "Ep:93, loss:0.00004, loss_test:0.22971, lr:2.79e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.196, tt:3590.425\n",
      "Ep:94, loss:0.00004, loss_test:0.23159, lr:2.76e-03, fs:0.69364 (r=0.606,p=0.811),  time:38.201, tt:3629.100\n",
      "Ep:95, loss:0.00004, loss_test:0.22718, lr:2.71e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.201, tt:3667.263\n",
      "Ep:96, loss:0.00004, loss_test:0.22672, lr:2.65e-03, fs:0.70787 (r=0.636,p=0.797),  time:38.220, tt:3707.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00004, loss_test:0.23015, lr:2.60e-03, fs:0.69318 (r=0.616,p=0.792),  time:38.217, tt:3745.233\n",
      "Ep:98, loss:0.00003, loss_test:0.22961, lr:2.55e-03, fs:0.69318 (r=0.616,p=0.792),  time:38.218, tt:3783.576\n",
      "Ep:99, loss:0.00004, loss_test:0.22653, lr:2.50e-03, fs:0.69663 (r=0.626,p=0.785),  time:38.208, tt:3820.775\n",
      "Ep:100, loss:0.00003, loss_test:0.22470, lr:2.45e-03, fs:0.70455 (r=0.626,p=0.805),  time:38.205, tt:3858.670\n",
      "Ep:101, loss:0.00004, loss_test:0.22580, lr:2.40e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.200, tt:3896.440\n",
      "Ep:102, loss:0.00003, loss_test:0.23063, lr:2.35e-03, fs:0.68966 (r=0.606,p=0.800),  time:38.208, tt:3935.382\n",
      "Ep:103, loss:0.00003, loss_test:0.23444, lr:2.31e-03, fs:0.69364 (r=0.606,p=0.811),  time:38.193, tt:3972.058\n",
      "Ep:104, loss:0.00003, loss_test:0.22997, lr:2.26e-03, fs:0.67816 (r=0.596,p=0.787),  time:38.185, tt:4009.401\n",
      "Ep:105, loss:0.00003, loss_test:0.22439, lr:2.21e-03, fs:0.68927 (r=0.616,p=0.782),  time:38.189, tt:4048.075\n",
      "Ep:106, loss:0.00003, loss_test:0.22478, lr:2.17e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.174, tt:4084.610\n",
      "Ep:107, loss:0.00003, loss_test:0.22684, lr:2.13e-03, fs:0.72316 (r=0.646,p=0.821),  time:38.160, tt:4121.229\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00003, loss_test:0.22786, lr:2.11e-03, fs:0.69663 (r=0.626,p=0.785),  time:38.152, tt:4158.604\n",
      "Ep:109, loss:0.00003, loss_test:0.22611, lr:2.08e-03, fs:0.69663 (r=0.626,p=0.785),  time:38.150, tt:4196.531\n",
      "Ep:110, loss:0.00003, loss_test:0.22442, lr:2.06e-03, fs:0.69663 (r=0.626,p=0.785),  time:38.131, tt:4232.543\n",
      "Ep:111, loss:0.00003, loss_test:0.22402, lr:2.04e-03, fs:0.69663 (r=0.626,p=0.785),  time:38.146, tt:4272.407\n",
      "Ep:112, loss:0.00003, loss_test:0.22556, lr:2.02e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.154, tt:4311.358\n",
      "Ep:113, loss:0.00003, loss_test:0.22501, lr:2.00e-03, fs:0.69663 (r=0.626,p=0.785),  time:38.148, tt:4348.879\n",
      "Ep:114, loss:0.00003, loss_test:0.22597, lr:1.98e-03, fs:0.70455 (r=0.626,p=0.805),  time:38.152, tt:4387.458\n",
      "Ep:115, loss:0.00003, loss_test:0.22611, lr:1.96e-03, fs:0.70857 (r=0.626,p=0.816),  time:38.153, tt:4425.776\n",
      "Ep:116, loss:0.00003, loss_test:0.22754, lr:1.94e-03, fs:0.70115 (r=0.616,p=0.813),  time:38.115, tt:4459.492\n",
      "Ep:117, loss:0.00003, loss_test:0.22697, lr:1.92e-03, fs:0.70115 (r=0.616,p=0.813),  time:38.129, tt:4499.242\n",
      "Ep:118, loss:0.00003, loss_test:0.22541, lr:1.90e-03, fs:0.70056 (r=0.626,p=0.795),  time:38.154, tt:4540.341\n",
      "Ep:119, loss:0.00003, loss_test:0.22430, lr:1.87e-03, fs:0.70455 (r=0.626,p=0.805),  time:38.171, tt:4580.549\n",
      "Ep:120, loss:0.00003, loss_test:0.22457, lr:1.83e-03, fs:0.68966 (r=0.606,p=0.800),  time:38.183, tt:4620.108\n",
      "Ep:121, loss:0.00003, loss_test:0.22521, lr:1.79e-03, fs:0.68966 (r=0.606,p=0.800),  time:38.189, tt:4659.031\n",
      "Ep:122, loss:0.00003, loss_test:0.22599, lr:1.76e-03, fs:0.68571 (r=0.606,p=0.789),  time:38.187, tt:4696.946\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 83\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24097, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.430, tt:36.430\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23787, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:36.214, tt:72.428\n",
      "Ep:2, loss:0.00059, loss_test:0.23137, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.322, tt:111.967\n",
      "Ep:3, loss:0.00055, loss_test:0.21779, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.331, tt:153.326\n",
      "Ep:4, loss:0.00047, loss_test:0.19437, lr:9.61e-03, fs:0.67133 (r=0.970,p=0.513),  time:38.316, tt:191.580\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00037, loss_test:0.17901, lr:9.51e-03, fs:0.69020 (r=0.889,p=0.564),  time:38.731, tt:232.388\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.17642, lr:9.41e-03, fs:0.68619 (r=0.828,p=0.586),  time:38.959, tt:272.710\n",
      "Ep:7, loss:0.00030, loss_test:0.17509, lr:9.32e-03, fs:0.68936 (r=0.818,p=0.596),  time:39.071, tt:312.569\n",
      "Ep:8, loss:0.00029, loss_test:0.17532, lr:9.23e-03, fs:0.69955 (r=0.788,p=0.629),  time:39.238, tt:353.140\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.16909, lr:9.14e-03, fs:0.70996 (r=0.828,p=0.621),  time:39.449, tt:394.486\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.16717, lr:9.04e-03, fs:0.70968 (r=0.778,p=0.653),  time:39.460, tt:434.062\n",
      "Ep:11, loss:0.00026, loss_test:0.16468, lr:8.95e-03, fs:0.71171 (r=0.798,p=0.642),  time:39.471, tt:473.649\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.15989, lr:8.86e-03, fs:0.72321 (r=0.818,p=0.648),  time:39.454, tt:512.907\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.15634, lr:8.78e-03, fs:0.72889 (r=0.828,p=0.651),  time:39.404, tt:551.660\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.15815, lr:8.69e-03, fs:0.73148 (r=0.798,p=0.675),  time:39.360, tt:590.395\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.15546, lr:8.60e-03, fs:0.75362 (r=0.788,p=0.722),  time:39.383, tt:630.124\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.15185, lr:8.51e-03, fs:0.74654 (r=0.818,p=0.686),  time:39.389, tt:669.609\n",
      "Ep:17, loss:0.00023, loss_test:0.15637, lr:8.43e-03, fs:0.75117 (r=0.808,p=0.702),  time:39.402, tt:709.244\n",
      "Ep:18, loss:0.00022, loss_test:0.15246, lr:8.35e-03, fs:0.76555 (r=0.808,p=0.727),  time:39.441, tt:749.387\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.14929, lr:8.26e-03, fs:0.72807 (r=0.838,p=0.643),  time:39.484, tt:789.677\n",
      "Ep:20, loss:0.00021, loss_test:0.15156, lr:8.18e-03, fs:0.76847 (r=0.788,p=0.750),  time:39.566, tt:830.886\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.14907, lr:8.10e-03, fs:0.77451 (r=0.798,p=0.752),  time:39.634, tt:871.944\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.14624, lr:8.02e-03, fs:0.75455 (r=0.838,p=0.686),  time:39.668, tt:912.372\n",
      "Ep:23, loss:0.00020, loss_test:0.14965, lr:7.94e-03, fs:0.78469 (r=0.828,p=0.745),  time:39.662, tt:951.879\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.14573, lr:7.86e-03, fs:0.77419 (r=0.848,p=0.712),  time:39.596, tt:989.897\n",
      "Ep:25, loss:0.00018, loss_test:0.14843, lr:7.78e-03, fs:0.76233 (r=0.859,p=0.685),  time:39.587, tt:1029.268\n",
      "Ep:26, loss:0.00018, loss_test:0.14882, lr:7.70e-03, fs:0.79602 (r=0.808,p=0.784),  time:39.494, tt:1066.326\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.14842, lr:7.62e-03, fs:0.77570 (r=0.838,p=0.722),  time:39.474, tt:1105.260\n",
      "Ep:28, loss:0.00017, loss_test:0.13929, lr:7.55e-03, fs:0.78302 (r=0.838,p=0.735),  time:39.514, tt:1145.898\n",
      "Ep:29, loss:0.00017, loss_test:0.14064, lr:7.47e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.525, tt:1185.753\n",
      "Ep:30, loss:0.00016, loss_test:0.14194, lr:7.40e-03, fs:0.79024 (r=0.818,p=0.764),  time:39.544, tt:1225.852\n",
      "Ep:31, loss:0.00015, loss_test:0.14335, lr:7.32e-03, fs:0.80583 (r=0.838,p=0.776),  time:39.545, tt:1265.439\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.13635, lr:7.25e-03, fs:0.78539 (r=0.869,p=0.717),  time:39.534, tt:1304.611\n",
      "Ep:33, loss:0.00015, loss_test:0.13974, lr:7.18e-03, fs:0.80976 (r=0.838,p=0.783),  time:39.511, tt:1343.366\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.13966, lr:7.11e-03, fs:0.78095 (r=0.828,p=0.739),  time:39.518, tt:1383.121\n",
      "Ep:35, loss:0.00014, loss_test:0.13650, lr:7.03e-03, fs:0.80769 (r=0.848,p=0.771),  time:39.475, tt:1421.099\n",
      "Ep:36, loss:0.00014, loss_test:0.13940, lr:6.96e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.395, tt:1457.618\n",
      "Ep:37, loss:0.00012, loss_test:0.13391, lr:6.89e-03, fs:0.81340 (r=0.859,p=0.773),  time:39.332, tt:1494.606\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00013, loss_test:0.14053, lr:6.83e-03, fs:0.83417 (r=0.838,p=0.830),  time:39.381, tt:1535.877\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.13583, lr:6.76e-03, fs:0.79439 (r=0.859,p=0.739),  time:39.363, tt:1574.530\n",
      "Ep:40, loss:0.00011, loss_test:0.13824, lr:6.69e-03, fs:0.83000 (r=0.838,p=0.822),  time:39.371, tt:1614.213\n",
      "Ep:41, loss:0.00011, loss_test:0.13896, lr:6.62e-03, fs:0.81592 (r=0.828,p=0.804),  time:39.329, tt:1651.804\n",
      "Ep:42, loss:0.00011, loss_test:0.13338, lr:6.56e-03, fs:0.81905 (r=0.869,p=0.775),  time:39.301, tt:1689.935\n",
      "Ep:43, loss:0.00011, loss_test:0.13810, lr:6.49e-03, fs:0.82126 (r=0.859,p=0.787),  time:39.307, tt:1729.510\n",
      "Ep:44, loss:0.00011, loss_test:0.13597, lr:6.43e-03, fs:0.82587 (r=0.838,p=0.814),  time:39.291, tt:1768.076\n",
      "Ep:45, loss:0.00010, loss_test:0.13955, lr:6.36e-03, fs:0.86567 (r=0.879,p=0.853),  time:39.255, tt:1805.751\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.14248, lr:6.30e-03, fs:0.82828 (r=0.828,p=0.828),  time:39.239, tt:1844.240\n",
      "Ep:47, loss:0.00009, loss_test:0.13252, lr:6.24e-03, fs:0.81553 (r=0.848,p=0.785),  time:39.159, tt:1879.638\n",
      "Ep:48, loss:0.00009, loss_test:0.13236, lr:6.17e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.089, tt:1915.367\n",
      "Ep:49, loss:0.00009, loss_test:0.13443, lr:6.11e-03, fs:0.85567 (r=0.838,p=0.874),  time:38.989, tt:1949.435\n",
      "Ep:50, loss:0.00008, loss_test:0.13472, lr:6.05e-03, fs:0.83582 (r=0.848,p=0.824),  time:38.894, tt:1983.578\n",
      "Ep:51, loss:0.00008, loss_test:0.14048, lr:5.99e-03, fs:0.85714 (r=0.818,p=0.900),  time:38.781, tt:2016.627\n",
      "Ep:52, loss:0.00007, loss_test:0.13327, lr:5.93e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.674, tt:2049.700\n",
      "Ep:53, loss:0.00007, loss_test:0.14199, lr:5.87e-03, fs:0.84375 (r=0.818,p=0.871),  time:38.581, tt:2083.378\n",
      "Ep:54, loss:0.00007, loss_test:0.13313, lr:5.81e-03, fs:0.86154 (r=0.848,p=0.875),  time:38.492, tt:2117.053\n",
      "Ep:55, loss:0.00006, loss_test:0.13402, lr:5.75e-03, fs:0.86598 (r=0.848,p=0.884),  time:38.424, tt:2151.730\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.13234, lr:5.70e-03, fs:0.86735 (r=0.859,p=0.876),  time:38.351, tt:2185.981\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.12781, lr:5.64e-03, fs:0.86154 (r=0.848,p=0.875),  time:38.269, tt:2219.607\n",
      "Ep:58, loss:0.00006, loss_test:0.13014, lr:5.58e-03, fs:0.86010 (r=0.838,p=0.883),  time:38.176, tt:2252.407\n",
      "Ep:59, loss:0.00005, loss_test:0.13190, lr:5.53e-03, fs:0.86010 (r=0.838,p=0.883),  time:38.103, tt:2286.210\n",
      "Ep:60, loss:0.00005, loss_test:0.12894, lr:5.47e-03, fs:0.87047 (r=0.848,p=0.894),  time:38.045, tt:2320.758\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.13419, lr:5.42e-03, fs:0.84492 (r=0.798,p=0.898),  time:37.956, tt:2353.300\n",
      "Ep:62, loss:0.00005, loss_test:0.13257, lr:5.36e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.881, tt:2386.525\n",
      "Ep:63, loss:0.00004, loss_test:0.12884, lr:5.31e-03, fs:0.87047 (r=0.848,p=0.894),  time:37.821, tt:2420.572\n",
      "Ep:64, loss:0.00004, loss_test:0.13321, lr:5.26e-03, fs:0.86911 (r=0.838,p=0.902),  time:37.759, tt:2454.366\n",
      "Ep:65, loss:0.00004, loss_test:0.12959, lr:5.20e-03, fs:0.86598 (r=0.848,p=0.884),  time:37.692, tt:2487.657\n",
      "Ep:66, loss:0.00004, loss_test:0.13155, lr:5.15e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.620, tt:2520.544\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.13089, lr:5.10e-03, fs:0.87368 (r=0.838,p=0.912),  time:37.579, tt:2555.347\n",
      "Ep:68, loss:0.00004, loss_test:0.12623, lr:5.05e-03, fs:0.86911 (r=0.838,p=0.902),  time:37.536, tt:2589.961\n",
      "Ep:69, loss:0.00004, loss_test:0.13127, lr:5.00e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.450, tt:2621.512\n",
      "Ep:70, loss:0.00003, loss_test:0.12699, lr:4.95e-03, fs:0.88205 (r=0.869,p=0.896),  time:37.423, tt:2657.013\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.12570, lr:4.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.382, tt:2691.500\n",
      "Ep:72, loss:0.00004, loss_test:0.12641, lr:4.85e-03, fs:0.87368 (r=0.838,p=0.912),  time:37.349, tt:2726.455\n",
      "Ep:73, loss:0.00003, loss_test:0.12865, lr:4.80e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.304, tt:2760.520\n",
      "Ep:74, loss:0.00003, loss_test:0.12974, lr:4.75e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.255, tt:2794.111\n",
      "Ep:75, loss:0.00003, loss_test:0.13198, lr:4.71e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.214, tt:2828.262\n",
      "Ep:76, loss:0.00003, loss_test:0.13721, lr:4.66e-03, fs:0.84946 (r=0.798,p=0.908),  time:37.156, tt:2861.033\n",
      "Ep:77, loss:0.00003, loss_test:0.13375, lr:4.61e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.130, tt:2896.116\n",
      "Ep:78, loss:0.00003, loss_test:0.12962, lr:4.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.082, tt:2929.506\n",
      "Ep:79, loss:0.00003, loss_test:0.13529, lr:4.52e-03, fs:0.87097 (r=0.818,p=0.931),  time:37.067, tt:2965.341\n",
      "Ep:80, loss:0.00003, loss_test:0.13674, lr:4.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.066, tt:3002.329\n",
      "Ep:81, loss:0.00002, loss_test:0.12748, lr:4.43e-03, fs:0.89947 (r=0.859,p=0.944),  time:37.074, tt:3040.028\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.13486, lr:4.39e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.132, tt:3081.937\n",
      "Ep:83, loss:0.00003, loss_test:0.13432, lr:4.34e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.178, tt:3122.913\n",
      "Ep:84, loss:0.00002, loss_test:0.13143, lr:4.30e-03, fs:0.89474 (r=0.859,p=0.934),  time:37.225, tt:3164.091\n",
      "Ep:85, loss:0.00002, loss_test:0.14028, lr:4.26e-03, fs:0.82486 (r=0.737,p=0.936),  time:37.257, tt:3204.066\n",
      "Ep:86, loss:0.00002, loss_test:0.13741, lr:4.21e-03, fs:0.79545 (r=0.707,p=0.909),  time:37.294, tt:3244.620\n",
      "Ep:87, loss:0.00002, loss_test:0.13568, lr:4.17e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.345, tt:3286.319\n",
      "Ep:88, loss:0.00002, loss_test:0.14563, lr:4.13e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.393, tt:3327.953\n",
      "Ep:89, loss:0.00002, loss_test:0.13925, lr:4.09e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.432, tt:3368.880\n",
      "Ep:90, loss:0.00002, loss_test:0.13444, lr:4.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.436, tt:3406.716\n",
      "Ep:91, loss:0.00002, loss_test:0.13309, lr:4.01e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.463, tt:3446.555\n",
      "Ep:92, loss:0.00002, loss_test:0.13718, lr:3.97e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.497, tt:3487.240\n",
      "Ep:93, loss:0.00002, loss_test:0.13756, lr:3.89e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.536, tt:3528.339\n",
      "Ep:94, loss:0.00002, loss_test:0.14005, lr:3.81e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.589, tt:3570.915\n",
      "Ep:95, loss:0.00002, loss_test:0.13883, lr:3.73e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.629, tt:3612.402\n",
      "Ep:96, loss:0.00002, loss_test:0.13811, lr:3.66e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.665, tt:3653.517\n",
      "Ep:97, loss:0.00002, loss_test:0.13712, lr:3.59e-03, fs:0.86957 (r=0.808,p=0.941),  time:37.696, tt:3694.252\n",
      "Ep:98, loss:0.00002, loss_test:0.13884, lr:3.52e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.737, tt:3735.940\n",
      "Ep:99, loss:0.00001, loss_test:0.14051, lr:3.45e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.765, tt:3776.471\n",
      "Ep:100, loss:0.00001, loss_test:0.14250, lr:3.38e-03, fs:0.84270 (r=0.758,p=0.949),  time:37.796, tt:3817.378\n",
      "Ep:101, loss:0.00001, loss_test:0.13609, lr:3.31e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.829, tt:3858.568\n",
      "Ep:102, loss:0.00001, loss_test:0.13601, lr:3.24e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.872, tt:3900.830\n",
      "Ep:103, loss:0.00001, loss_test:0.14423, lr:3.18e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.913, tt:3942.905\n",
      "Ep:104, loss:0.00001, loss_test:0.14399, lr:3.12e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.944, tt:3984.076\n",
      "Ep:105, loss:0.00001, loss_test:0.14137, lr:3.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.982, tt:4026.046\n",
      "Ep:106, loss:0.00001, loss_test:0.13901, lr:2.99e-03, fs:0.85556 (r=0.778,p=0.951),  time:38.014, tt:4067.509\n",
      "Ep:107, loss:0.00001, loss_test:0.14075, lr:2.93e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.058, tt:4110.211\n",
      "Ep:108, loss:0.00001, loss_test:0.14350, lr:2.88e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.080, tt:4150.695\n",
      "Ep:109, loss:0.00001, loss_test:0.14211, lr:2.82e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.107, tt:4191.727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:110, loss:0.00001, loss_test:0.14021, lr:2.76e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.140, tt:4233.582\n",
      "Ep:111, loss:0.00001, loss_test:0.13972, lr:2.71e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.155, tt:4273.357\n",
      "Ep:112, loss:0.00001, loss_test:0.14190, lr:2.65e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.164, tt:4312.580\n",
      "Ep:113, loss:0.00001, loss_test:0.14187, lr:2.60e-03, fs:0.84444 (r=0.768,p=0.938),  time:38.196, tt:4354.335\n",
      "Ep:114, loss:0.00001, loss_test:0.14397, lr:2.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.216, tt:4394.890\n",
      "Ep:115, loss:0.00001, loss_test:0.14244, lr:2.50e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.223, tt:4433.919\n",
      "Ep:116, loss:0.00001, loss_test:0.14163, lr:2.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.215, tt:4471.146\n",
      "Ep:117, loss:0.00001, loss_test:0.14918, lr:2.40e-03, fs:0.80233 (r=0.697,p=0.945),  time:38.256, tt:4514.257\n",
      "Ep:118, loss:0.00001, loss_test:0.14955, lr:2.35e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.250, tt:4551.727\n",
      "Ep:119, loss:0.00001, loss_test:0.13836, lr:2.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.231, tt:4587.682\n",
      "Ep:120, loss:0.00001, loss_test:0.13424, lr:2.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.204, tt:4622.678\n",
      "Ep:121, loss:0.00001, loss_test:0.13881, lr:2.21e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.131, tt:4652.012\n",
      "Ep:122, loss:0.00001, loss_test:0.14399, lr:2.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:38.060, tt:4681.343\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 84\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1230bd3a7753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Meta-feature graph from datasets loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mfrom_networkx\u001b[0;34m(self, nx_graph, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \"\"\"\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# Relabel nodes using consecutive integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m         \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_node_labels_to_integers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sorted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m         \u001b[0;31m# With to_directed we will get a directed version of the original networkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m         \u001b[0;31m# graph, with the original nodes, edges and their attributes preserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/relabel.py\u001b[0m in \u001b[0;36mconvert_node_labels_to_integers\u001b[0;34m(G, first_label, ordering, label_attribute)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mordering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sorted\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mnlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mordering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"increasing degree\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,123,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24286, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:36.339, tt:36.339\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24068, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:35.887, tt:71.773\n",
      "Ep:2, loss:0.00059, loss_test:0.23588, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:36.124, tt:108.373\n",
      "Ep:3, loss:0.00056, loss_test:0.22611, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:36.268, tt:145.072\n",
      "Ep:4, loss:0.00049, loss_test:0.21047, lr:8.00e-03, fs:0.66436 (r=0.970,p=0.505),  time:37.029, tt:185.146\n",
      "Ep:5, loss:0.00040, loss_test:0.20321, lr:8.00e-03, fs:0.66939 (r=0.828,p=0.562),  time:37.582, tt:225.492\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.20264, lr:8.00e-03, fs:0.68750 (r=0.778,p=0.616),  time:38.232, tt:267.625\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.19770, lr:8.00e-03, fs:0.65455 (r=0.727,p=0.595),  time:38.684, tt:309.471\n",
      "Ep:8, loss:0.00031, loss_test:0.20133, lr:8.00e-03, fs:0.64039 (r=0.657,p=0.625),  time:38.438, tt:345.943\n",
      "Ep:9, loss:0.00029, loss_test:0.19538, lr:8.00e-03, fs:0.67308 (r=0.707,p=0.642),  time:38.329, tt:383.289\n",
      "Ep:10, loss:0.00028, loss_test:0.18842, lr:8.00e-03, fs:0.69091 (r=0.768,p=0.628),  time:38.166, tt:419.825\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.18178, lr:8.00e-03, fs:0.71493 (r=0.798,p=0.648),  time:38.081, tt:456.978\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00028, loss_test:0.18392, lr:8.00e-03, fs:0.71921 (r=0.737,p=0.702),  time:37.908, tt:492.805\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.18113, lr:8.00e-03, fs:0.71429 (r=0.758,p=0.676),  time:37.852, tt:529.927\n",
      "Ep:14, loss:0.00025, loss_test:0.17404, lr:8.00e-03, fs:0.74886 (r=0.828,p=0.683),  time:37.942, tt:569.126\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.17832, lr:8.00e-03, fs:0.74627 (r=0.758,p=0.735),  time:38.044, tt:608.699\n",
      "Ep:16, loss:0.00024, loss_test:0.17234, lr:8.00e-03, fs:0.75728 (r=0.788,p=0.729),  time:38.145, tt:648.458\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.16647, lr:8.00e-03, fs:0.78539 (r=0.869,p=0.717),  time:38.220, tt:687.959\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.16451, lr:8.00e-03, fs:0.78261 (r=0.818,p=0.750),  time:38.177, tt:725.367\n",
      "Ep:19, loss:0.00022, loss_test:0.16237, lr:8.00e-03, fs:0.80193 (r=0.838,p=0.769),  time:38.002, tt:760.035\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.17035, lr:8.00e-03, fs:0.79803 (r=0.818,p=0.779),  time:37.969, tt:797.353\n",
      "Ep:21, loss:0.00021, loss_test:0.16706, lr:8.00e-03, fs:0.80583 (r=0.838,p=0.776),  time:37.806, tt:831.732\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.16051, lr:8.00e-03, fs:0.80000 (r=0.848,p=0.757),  time:37.715, tt:867.457\n",
      "Ep:23, loss:0.00021, loss_test:0.15757, lr:8.00e-03, fs:0.84615 (r=0.889,p=0.807),  time:37.736, tt:905.672\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.15891, lr:8.00e-03, fs:0.85149 (r=0.869,p=0.835),  time:37.838, tt:945.952\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.15082, lr:8.00e-03, fs:0.82028 (r=0.899,p=0.754),  time:37.867, tt:984.532\n",
      "Ep:26, loss:0.00018, loss_test:0.15529, lr:8.00e-03, fs:0.85167 (r=0.899,p=0.809),  time:37.928, tt:1024.059\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.15732, lr:8.00e-03, fs:0.83654 (r=0.879,p=0.798),  time:37.890, tt:1060.928\n",
      "Ep:28, loss:0.00018, loss_test:0.14969, lr:8.00e-03, fs:0.85581 (r=0.929,p=0.793),  time:37.879, tt:1098.503\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.15244, lr:8.00e-03, fs:0.86957 (r=0.909,p=0.833),  time:37.836, tt:1135.076\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.14888, lr:8.00e-03, fs:0.87558 (r=0.960,p=0.805),  time:37.772, tt:1170.933\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.15544, lr:8.00e-03, fs:0.87562 (r=0.889,p=0.863),  time:37.724, tt:1207.170\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.13964, lr:8.00e-03, fs:0.89302 (r=0.970,p=0.828),  time:37.687, tt:1243.655\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.15421, lr:8.00e-03, fs:0.89447 (r=0.899,p=0.890),  time:37.703, tt:1281.915\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.14039, lr:8.00e-03, fs:0.90909 (r=0.960,p=0.864),  time:37.809, tt:1323.300\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.13951, lr:8.00e-03, fs:0.90476 (r=0.960,p=0.856),  time:37.861, tt:1362.994\n",
      "Ep:36, loss:0.00012, loss_test:0.14316, lr:8.00e-03, fs:0.91346 (r=0.960,p=0.872),  time:37.928, tt:1403.331\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.14263, lr:8.00e-03, fs:0.88571 (r=0.939,p=0.838),  time:37.920, tt:1440.946\n",
      "Ep:38, loss:0.00011, loss_test:0.13014, lr:8.00e-03, fs:0.93839 (r=1.000,p=0.884),  time:37.886, tt:1477.546\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.14270, lr:8.00e-03, fs:0.87437 (r=0.879,p=0.870),  time:37.918, tt:1516.710\n",
      "Ep:40, loss:0.00011, loss_test:0.12788, lr:8.00e-03, fs:0.90654 (r=0.980,p=0.843),  time:37.967, tt:1556.628\n",
      "Ep:41, loss:0.00010, loss_test:0.13630, lr:8.00e-03, fs:0.91542 (r=0.929,p=0.902),  time:38.006, tt:1596.232\n",
      "Ep:42, loss:0.00009, loss_test:0.14311, lr:8.00e-03, fs:0.89000 (r=0.899,p=0.881),  time:38.050, tt:1636.151\n",
      "Ep:43, loss:0.00009, loss_test:0.14411, lr:8.00e-03, fs:0.86432 (r=0.869,p=0.860),  time:38.149, tt:1678.540\n",
      "Ep:44, loss:0.00009, loss_test:0.12193, lr:8.00e-03, fs:0.89720 (r=0.970,p=0.835),  time:38.291, tt:1723.082\n",
      "Ep:45, loss:0.00009, loss_test:0.12873, lr:8.00e-03, fs:0.85849 (r=0.919,p=0.805),  time:38.394, tt:1766.125\n",
      "Ep:46, loss:0.00009, loss_test:0.11561, lr:8.00e-03, fs:0.89908 (r=0.990,p=0.824),  time:38.511, tt:1810.000\n",
      "Ep:47, loss:0.00009, loss_test:0.11895, lr:8.00e-03, fs:0.88182 (r=0.980,p=0.802),  time:38.519, tt:1848.929\n",
      "Ep:48, loss:0.00008, loss_test:0.15059, lr:8.00e-03, fs:0.82234 (r=0.818,p=0.827),  time:38.551, tt:1889.007\n",
      "Ep:49, loss:0.00008, loss_test:0.14047, lr:8.00e-03, fs:0.90256 (r=0.889,p=0.917),  time:38.581, tt:1929.075\n",
      "Ep:50, loss:0.00008, loss_test:0.12242, lr:8.00e-03, fs:0.86996 (r=0.980,p=0.782),  time:38.595, tt:1968.326\n",
      "Ep:51, loss:0.00009, loss_test:0.11617, lr:8.00e-03, fs:0.82906 (r=0.980,p=0.719),  time:38.651, tt:2009.833\n",
      "Ep:52, loss:0.00010, loss_test:0.14216, lr:8.00e-03, fs:0.84615 (r=0.889,p=0.807),  time:38.675, tt:2049.764\n",
      "Ep:53, loss:0.00014, loss_test:0.15705, lr:8.00e-03, fs:0.77922 (r=0.909,p=0.682),  time:38.763, tt:2093.215\n",
      "Ep:54, loss:0.00017, loss_test:0.15750, lr:8.00e-03, fs:0.86538 (r=0.909,p=0.826),  time:38.846, tt:2136.550\n",
      "Ep:55, loss:0.00014, loss_test:0.14241, lr:8.00e-03, fs:0.78788 (r=0.919,p=0.689),  time:38.941, tt:2180.697\n",
      "Ep:56, loss:0.00014, loss_test:0.13874, lr:8.00e-03, fs:0.88670 (r=0.909,p=0.865),  time:38.989, tt:2222.383\n",
      "Ep:57, loss:0.00014, loss_test:0.17798, lr:8.00e-03, fs:0.79121 (r=0.727,p=0.867),  time:38.999, tt:2261.967\n",
      "Ep:58, loss:0.00013, loss_test:0.14523, lr:7.92e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.979, tt:2299.753\n",
      "Ep:59, loss:0.00011, loss_test:0.13323, lr:7.84e-03, fs:0.82609 (r=0.960,p=0.725),  time:38.986, tt:2339.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00011, loss_test:0.12139, lr:7.76e-03, fs:0.86364 (r=0.960,p=0.785),  time:38.997, tt:2378.803\n",
      "Ep:61, loss:0.00010, loss_test:0.13910, lr:7.68e-03, fs:0.85106 (r=0.808,p=0.899),  time:39.055, tt:2421.385\n",
      "Ep:62, loss:0.00008, loss_test:0.12133, lr:7.61e-03, fs:0.88288 (r=0.990,p=0.797),  time:39.078, tt:2461.913\n",
      "Ep:63, loss:0.00008, loss_test:0.14011, lr:7.53e-03, fs:0.84112 (r=0.909,p=0.783),  time:39.145, tt:2505.280\n",
      "Ep:64, loss:0.00008, loss_test:0.13471, lr:7.46e-03, fs:0.88325 (r=0.879,p=0.888),  time:39.221, tt:2549.352\n",
      "Ep:65, loss:0.00010, loss_test:0.12724, lr:7.38e-03, fs:0.85149 (r=0.869,p=0.835),  time:39.294, tt:2593.382\n",
      "Ep:66, loss:0.00007, loss_test:0.13722, lr:7.31e-03, fs:0.87437 (r=0.879,p=0.870),  time:39.336, tt:2635.521\n",
      "Ep:67, loss:0.00008, loss_test:0.12258, lr:7.24e-03, fs:0.88182 (r=0.980,p=0.802),  time:39.338, tt:2674.980\n",
      "Ep:68, loss:0.00009, loss_test:0.15677, lr:7.16e-03, fs:0.81818 (r=0.818,p=0.818),  time:39.368, tt:2716.387\n",
      "Ep:69, loss:0.00008, loss_test:0.13248, lr:7.09e-03, fs:0.82511 (r=0.929,p=0.742),  time:39.383, tt:2756.829\n",
      "Ep:70, loss:0.00010, loss_test:0.14842, lr:7.02e-03, fs:0.80000 (r=0.788,p=0.812),  time:39.410, tt:2798.076\n",
      "Ep:71, loss:0.00008, loss_test:0.13058, lr:6.95e-03, fs:0.83417 (r=0.838,p=0.830),  time:39.413, tt:2837.748\n",
      "Ep:72, loss:0.00010, loss_test:0.14463, lr:6.88e-03, fs:0.78947 (r=0.909,p=0.698),  time:39.427, tt:2878.151\n",
      "Ep:73, loss:0.00015, loss_test:0.17446, lr:6.81e-03, fs:0.70111 (r=0.960,p=0.552),  time:39.463, tt:2920.254\n",
      "Ep:74, loss:0.00025, loss_test:0.15691, lr:6.74e-03, fs:0.75676 (r=0.848,p=0.683),  time:39.495, tt:2962.134\n",
      "Ep:75, loss:0.00019, loss_test:0.16377, lr:6.68e-03, fs:0.77670 (r=0.808,p=0.748),  time:39.544, tt:3005.370\n",
      "Ep:76, loss:0.00018, loss_test:0.15540, lr:6.61e-03, fs:0.76364 (r=0.848,p=0.694),  time:39.559, tt:3046.015\n",
      "Ep:77, loss:0.00015, loss_test:0.14444, lr:6.54e-03, fs:0.76329 (r=0.798,p=0.731),  time:39.529, tt:3083.282\n",
      "Ep:78, loss:0.00015, loss_test:0.15428, lr:6.48e-03, fs:0.77295 (r=0.808,p=0.741),  time:39.540, tt:3123.664\n",
      "Ep:79, loss:0.00012, loss_test:0.14346, lr:6.41e-03, fs:0.82883 (r=0.929,p=0.748),  time:39.560, tt:3164.796\n",
      "Ep:80, loss:0.00013, loss_test:0.19737, lr:6.35e-03, fs:0.66923 (r=0.879,p=0.540),  time:39.552, tt:3203.735\n",
      "Ep:81, loss:0.00020, loss_test:0.15333, lr:6.29e-03, fs:0.71304 (r=0.828,p=0.626),  time:39.571, tt:3244.794\n",
      "Ep:82, loss:0.00017, loss_test:0.13785, lr:6.22e-03, fs:0.78947 (r=0.909,p=0.698),  time:39.575, tt:3284.742\n",
      "Ep:83, loss:0.00017, loss_test:0.15633, lr:6.16e-03, fs:0.75983 (r=0.879,p=0.669),  time:39.633, tt:3329.137\n",
      "Ep:84, loss:0.00014, loss_test:0.14260, lr:6.10e-03, fs:0.78704 (r=0.859,p=0.726),  time:39.666, tt:3371.604\n",
      "Ep:85, loss:0.00013, loss_test:0.13258, lr:6.04e-03, fs:0.83333 (r=0.909,p=0.769),  time:39.695, tt:3413.800\n",
      "Ep:86, loss:0.00013, loss_test:0.14240, lr:5.98e-03, fs:0.84466 (r=0.879,p=0.813),  time:39.728, tt:3456.347\n",
      "Ep:87, loss:0.00012, loss_test:0.12679, lr:5.92e-03, fs:0.76316 (r=0.879,p=0.674),  time:39.729, tt:3496.190\n",
      "Ep:88, loss:0.00012, loss_test:0.11166, lr:5.86e-03, fs:0.90411 (r=1.000,p=0.825),  time:39.729, tt:3535.866\n",
      "Ep:89, loss:0.00010, loss_test:0.13691, lr:5.86e-03, fs:0.78222 (r=0.889,p=0.698),  time:39.720, tt:3574.838\n",
      "Ep:90, loss:0.00010, loss_test:0.13758, lr:5.86e-03, fs:0.80569 (r=0.859,p=0.759),  time:39.725, tt:3614.953\n",
      "Ep:91, loss:0.00009, loss_test:0.11636, lr:5.86e-03, fs:0.81553 (r=0.848,p=0.785),  time:39.733, tt:3655.395\n",
      "Ep:92, loss:0.00008, loss_test:0.08681, lr:5.86e-03, fs:0.89908 (r=0.990,p=0.824),  time:39.755, tt:3697.184\n",
      "Ep:93, loss:0.00008, loss_test:0.12322, lr:5.86e-03, fs:0.81159 (r=0.848,p=0.778),  time:39.774, tt:3738.779\n",
      "Ep:94, loss:0.00008, loss_test:0.14892, lr:5.86e-03, fs:0.75728 (r=0.788,p=0.729),  time:39.841, tt:3784.912\n",
      "Ep:95, loss:0.00012, loss_test:0.13048, lr:5.86e-03, fs:0.79812 (r=0.859,p=0.746),  time:39.885, tt:3828.946\n",
      "Ep:96, loss:0.00008, loss_test:0.07482, lr:5.86e-03, fs:0.89720 (r=0.970,p=0.835),  time:39.915, tt:3871.746\n",
      "Ep:97, loss:0.00008, loss_test:0.07835, lr:5.86e-03, fs:0.90411 (r=1.000,p=0.825),  time:39.922, tt:3912.317\n",
      "Ep:98, loss:0.00006, loss_test:0.12178, lr:5.86e-03, fs:0.80000 (r=0.828,p=0.774),  time:39.938, tt:3953.865\n",
      "Ep:99, loss:0.00006, loss_test:0.12319, lr:5.86e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.964, tt:3996.381\n",
      "Ep:100, loss:0.00006, loss_test:0.15777, lr:5.86e-03, fs:0.71000 (r=0.717,p=0.703),  time:39.987, tt:4038.717\n",
      "Ep:101, loss:0.00006, loss_test:0.15136, lr:5.86e-03, fs:0.78392 (r=0.788,p=0.780),  time:40.008, tt:4080.868\n",
      "Ep:102, loss:0.00006, loss_test:0.11717, lr:5.86e-03, fs:0.88670 (r=0.909,p=0.865),  time:40.060, tt:4126.218\n",
      "Ep:103, loss:0.00006, loss_test:0.15249, lr:5.86e-03, fs:0.76142 (r=0.758,p=0.765),  time:40.111, tt:4171.525\n",
      "Ep:104, loss:0.00005, loss_test:0.12304, lr:5.86e-03, fs:0.81250 (r=0.788,p=0.839),  time:40.164, tt:4217.248\n",
      "Ep:105, loss:0.00005, loss_test:0.14909, lr:5.86e-03, fs:0.78723 (r=0.747,p=0.831),  time:40.202, tt:4261.431\n",
      "Ep:106, loss:0.00004, loss_test:0.16892, lr:5.86e-03, fs:0.74317 (r=0.687,p=0.810),  time:40.216, tt:4303.092\n",
      "Ep:107, loss:0.00004, loss_test:0.15042, lr:5.86e-03, fs:0.74872 (r=0.737,p=0.760),  time:40.221, tt:4343.911\n",
      "Ep:108, loss:0.00005, loss_test:0.08649, lr:5.80e-03, fs:0.90566 (r=0.970,p=0.850),  time:40.220, tt:4384.027\n",
      "Ep:109, loss:0.00004, loss_test:0.10779, lr:5.74e-03, fs:0.83333 (r=0.808,p=0.860),  time:40.241, tt:4426.555\n",
      "Ep:110, loss:0.00004, loss_test:0.15342, lr:5.68e-03, fs:0.74725 (r=0.687,p=0.819),  time:40.243, tt:4467.025\n",
      "Ep:111, loss:0.00004, loss_test:0.11730, lr:5.63e-03, fs:0.80412 (r=0.788,p=0.821),  time:40.247, tt:4507.618\n",
      "Ep:112, loss:0.00004, loss_test:0.13160, lr:5.57e-03, fs:0.77083 (r=0.747,p=0.796),  time:40.271, tt:4550.637\n",
      "Ep:113, loss:0.00004, loss_test:0.15406, lr:5.52e-03, fs:0.74317 (r=0.687,p=0.810),  time:40.280, tt:4591.904\n",
      "Ep:114, loss:0.00004, loss_test:0.11616, lr:5.46e-03, fs:0.87923 (r=0.919,p=0.843),  time:40.315, tt:4636.270\n",
      "Ep:115, loss:0.00004, loss_test:0.15750, lr:5.41e-03, fs:0.73913 (r=0.687,p=0.800),  time:40.344, tt:4679.874\n",
      "Ep:116, loss:0.00004, loss_test:0.14835, lr:5.35e-03, fs:0.77083 (r=0.747,p=0.796),  time:40.287, tt:4713.601\n",
      "Ep:117, loss:0.00003, loss_test:0.14860, lr:5.30e-03, fs:0.71579 (r=0.687,p=0.747),  time:40.218, tt:4745.729\n",
      "Ep:118, loss:0.00003, loss_test:0.14066, lr:5.25e-03, fs:0.76344 (r=0.717,p=0.816),  time:40.120, tt:4774.304\n",
      "Ep:119, loss:0.00003, loss_test:0.15636, lr:5.19e-03, fs:0.74317 (r=0.687,p=0.810),  time:39.969, tt:4796.308\n",
      "Ep:120, loss:0.00002, loss_test:0.13661, lr:5.14e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.795, tt:4815.145\n",
      "Ep:121, loss:0.00003, loss_test:0.13062, lr:5.09e-03, fs:0.76243 (r=0.697,p=0.841),  time:39.585, tt:4829.327\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-355502d63c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Meta-feature graph from datasets loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mfrom_networkx\u001b[0;34m(self, nx_graph, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m         \u001b[0;31m# original edges (v, u).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36mto_directed\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m         G.add_edges_from((u, v, deepcopy(data))\n\u001b[1;32m   1569\u001b[0m                          \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_nodes_from\u001b[0;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_for_adding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0;31m# keep all this inside try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# CPython throws TypeError on n not in self._succ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m         G.add_edges_from((u, v, deepcopy(data))\n\u001b[1;32m   1569\u001b[0m                          \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqscheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_tensor_affine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,122,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09386, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:72.186, tt:72.186\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09156, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:72.116, tt:144.232\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08834, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:72.542, tt:217.626\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08610, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:72.943, tt:291.773\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08492, lr:1.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:73.135, tt:365.673\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.08218, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:73.947, tt:443.683\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.07973, lr:1.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:74.798, tt:523.589\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.07719, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:75.512, tt:604.095\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07440, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:75.729, tt:681.560\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00026, loss_test:0.07227, lr:1.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:76.021, tt:760.206\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07118, lr:1.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:76.548, tt:842.030\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06865, lr:1.00e-02, fs:0.74104 (r=0.939,p=0.612),  time:76.522, tt:918.268\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.06735, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:76.111, tt:989.445\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06633, lr:1.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:75.922, tt:1062.901\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.06515, lr:1.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:75.779, tt:1136.683\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06408, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:76.036, tt:1216.568\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06325, lr:1.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:76.242, tt:1296.114\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.06269, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:76.567, tt:1378.203\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06201, lr:1.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:76.908, tt:1461.258\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.06071, lr:1.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:77.103, tt:1542.057\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06169, lr:1.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:77.323, tt:1623.789\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05989, lr:1.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:77.234, tt:1699.153\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06067, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:77.101, tt:1773.323\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.06005, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:76.886, tt:1845.266\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.06033, lr:1.00e-02, fs:0.80000 (r=0.970,p=0.681),  time:76.781, tt:1919.525\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.05999, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:76.844, tt:1997.941\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.05811, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:76.949, tt:2077.618\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.06003, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:77.070, tt:2157.965\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.05906, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:77.155, tt:2237.509\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.05943, lr:1.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:77.248, tt:2317.438\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.05742, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:77.206, tt:2393.385\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.06085, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:77.107, tt:2467.420\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.05808, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:76.943, tt:2539.135\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.05963, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:76.831, tt:2612.253\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.06036, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:76.873, tt:2690.550\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.05894, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:77.055, tt:2773.984\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.05673, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:77.185, tt:2855.843\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.06457, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:77.291, tt:2937.070\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.05622, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:77.339, tt:3016.229\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.05957, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:77.405, tt:3096.212\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.05685, lr:1.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:77.281, tt:3168.519\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.05792, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:77.141, tt:3239.919\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05749, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:77.028, tt:3312.189\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.05876, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:77.012, tt:3388.547\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.05723, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:77.105, tt:3469.723\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.05666, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:77.158, tt:3549.290\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.05923, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:77.181, tt:3627.512\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.05544, lr:9.90e-03, fs:0.81651 (r=0.899,p=0.748),  time:77.196, tt:3705.416\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.05680, lr:9.80e-03, fs:0.81340 (r=0.859,p=0.773),  time:77.258, tt:3785.618\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.05944, lr:9.70e-03, fs:0.79612 (r=0.828,p=0.766),  time:77.217, tt:3860.841\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.05940, lr:9.61e-03, fs:0.78607 (r=0.798,p=0.775),  time:77.153, tt:3934.796\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.05681, lr:9.51e-03, fs:0.81731 (r=0.859,p=0.780),  time:77.115, tt:4009.967\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.05695, lr:9.41e-03, fs:0.77612 (r=0.788,p=0.765),  time:77.090, tt:4085.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.05761, lr:9.32e-03, fs:0.79798 (r=0.798,p=0.798),  time:77.167, tt:4167.012\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.05600, lr:9.23e-03, fs:0.78218 (r=0.798,p=0.767),  time:77.196, tt:4245.755\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.05708, lr:9.14e-03, fs:0.78173 (r=0.778,p=0.786),  time:77.225, tt:4324.605\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.05981, lr:9.04e-03, fs:0.78351 (r=0.768,p=0.800),  time:77.253, tt:4403.432\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.05918, lr:8.95e-03, fs:0.77720 (r=0.758,p=0.798),  time:77.305, tt:4483.710\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.05587, lr:8.86e-03, fs:0.77833 (r=0.798,p=0.760),  time:77.381, tt:4565.505\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.05782, lr:8.78e-03, fs:0.77551 (r=0.768,p=0.784),  time:77.336, tt:4640.136\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.06100, lr:8.69e-03, fs:0.78307 (r=0.747,p=0.822),  time:77.276, tt:4713.811\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.05681, lr:8.60e-03, fs:0.77157 (r=0.768,p=0.776),  time:77.204, tt:4786.661\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.05802, lr:8.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:77.211, tt:4864.296\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.05881, lr:8.43e-03, fs:0.77487 (r=0.747,p=0.804),  time:77.197, tt:4940.616\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.05895, lr:8.35e-03, fs:0.77487 (r=0.747,p=0.804),  time:77.211, tt:5018.731\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.05685, lr:8.26e-03, fs:0.76531 (r=0.758,p=0.773),  time:77.233, tt:5097.391\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.05954, lr:8.18e-03, fs:0.78947 (r=0.758,p=0.824),  time:77.231, tt:5174.464\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.05745, lr:8.10e-03, fs:0.77320 (r=0.758,p=0.789),  time:77.246, tt:5252.746\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.05773, lr:8.02e-03, fs:0.78125 (r=0.758,p=0.806),  time:77.192, tt:5326.240\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00005, loss_test:0.05915, lr:7.94e-03, fs:0.77895 (r=0.747,p=0.813),  time:77.129, tt:5399.019\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00005, loss_test:0.05926, lr:7.86e-03, fs:0.78307 (r=0.747,p=0.822),  time:77.066, tt:5471.713\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.05815, lr:7.78e-03, fs:0.78947 (r=0.758,p=0.824),  time:77.003, tt:5544.196\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.05908, lr:7.70e-03, fs:0.78723 (r=0.747,p=0.831),  time:77.025, tt:5622.799\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.05862, lr:7.62e-03, fs:0.78307 (r=0.747,p=0.822),  time:77.026, tt:5699.903\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.05740, lr:7.55e-03, fs:0.78125 (r=0.758,p=0.806),  time:77.057, tt:5779.242\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.06092, lr:7.47e-03, fs:0.79570 (r=0.747,p=0.851),  time:77.052, tt:5855.984\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.05952, lr:7.40e-03, fs:0.80000 (r=0.747,p=0.860),  time:77.106, tt:5937.139\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.05782, lr:7.32e-03, fs:0.78307 (r=0.747,p=0.822),  time:77.111, tt:6014.666\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.06205, lr:7.25e-03, fs:0.78919 (r=0.737,p=0.849),  time:77.041, tt:6086.270\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.05963, lr:7.18e-03, fs:0.79144 (r=0.747,p=0.841),  time:76.992, tt:6159.322\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.05847, lr:7.11e-03, fs:0.79144 (r=0.747,p=0.841),  time:76.970, tt:6234.538\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.06158, lr:7.03e-03, fs:0.80435 (r=0.747,p=0.871),  time:76.958, tt:6310.593\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.05774, lr:6.96e-03, fs:0.79144 (r=0.747,p=0.841),  time:76.976, tt:6388.989\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00004, loss_test:0.05954, lr:6.89e-03, fs:0.80000 (r=0.747,p=0.860),  time:77.026, tt:6470.189\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00004, loss_test:0.06189, lr:6.83e-03, fs:0.80220 (r=0.737,p=0.880),  time:77.052, tt:6549.420\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00004, loss_test:0.05819, lr:6.76e-03, fs:0.79570 (r=0.747,p=0.851),  time:77.078, tt:6628.715\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.06244, lr:6.69e-03, fs:0.79348 (r=0.737,p=0.859),  time:77.115, tt:6708.999\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.05862, lr:6.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:77.100, tt:6784.802\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.06307, lr:6.56e-03, fs:0.80000 (r=0.727,p=0.889),  time:77.050, tt:6857.446\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.05991, lr:6.49e-03, fs:0.80874 (r=0.747,p=0.881),  time:77.004, tt:6930.356\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.06076, lr:6.43e-03, fs:0.80874 (r=0.747,p=0.881),  time:76.939, tt:7001.462\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.06124, lr:6.36e-03, fs:0.81319 (r=0.747,p=0.892),  time:76.978, tt:7081.932\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.05971, lr:6.30e-03, fs:0.80874 (r=0.747,p=0.881),  time:77.019, tt:7162.788\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.06036, lr:6.24e-03, fs:0.80874 (r=0.747,p=0.881),  time:77.060, tt:7243.630\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.06222, lr:6.17e-03, fs:0.80663 (r=0.737,p=0.890),  time:77.113, tt:7325.704\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.06099, lr:6.11e-03, fs:0.80663 (r=0.737,p=0.890),  time:77.123, tt:7403.855\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.06224, lr:6.05e-03, fs:0.80663 (r=0.737,p=0.890),  time:77.154, tt:7483.986\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.06176, lr:5.99e-03, fs:0.81319 (r=0.747,p=0.892),  time:77.107, tt:7556.473\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.06283, lr:5.93e-03, fs:0.81111 (r=0.737,p=0.901),  time:77.051, tt:7628.076\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.06029, lr:5.87e-03, fs:0.81319 (r=0.747,p=0.892),  time:77.013, tt:7701.349\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.06375, lr:5.81e-03, fs:0.79330 (r=0.717,p=0.887),  time:76.969, tt:7773.910\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00003, loss_test:0.06002, lr:5.75e-03, fs:0.81319 (r=0.747,p=0.892),  time:76.972, tt:7851.194\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00003, loss_test:0.06464, lr:5.70e-03, fs:0.78652 (r=0.707,p=0.886),  time:77.005, tt:7931.502\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00003, loss_test:0.06058, lr:5.64e-03, fs:0.81319 (r=0.747,p=0.892),  time:77.024, tt:8010.537\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00003, loss_test:0.06361, lr:5.58e-03, fs:0.80447 (r=0.727,p=0.900),  time:77.050, tt:8090.265\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00003, loss_test:0.06055, lr:5.53e-03, fs:0.80874 (r=0.747,p=0.881),  time:77.076, tt:8170.100\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00003, loss_test:0.06398, lr:5.47e-03, fs:0.79330 (r=0.717,p=0.887),  time:77.084, tt:8247.951\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00003, loss_test:0.06015, lr:5.42e-03, fs:0.81967 (r=0.758,p=0.893),  time:77.029, tt:8319.147\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00003, loss_test:0.06341, lr:5.36e-03, fs:0.80000 (r=0.727,p=0.889),  time:77.003, tt:8393.335\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00003, loss_test:0.06287, lr:5.31e-03, fs:0.80663 (r=0.737,p=0.890),  time:76.959, tt:8465.451\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00003, loss_test:0.06345, lr:5.26e-03, fs:0.80663 (r=0.737,p=0.890),  time:76.989, tt:8545.754\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.06283, lr:5.20e-03, fs:0.80663 (r=0.737,p=0.890),  time:77.010, tt:8625.137\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.06292, lr:5.15e-03, fs:0.81111 (r=0.737,p=0.901),  time:77.009, tt:8701.984\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.06335, lr:5.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:77.016, tt:8779.778\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.06263, lr:5.05e-03, fs:0.81319 (r=0.747,p=0.892),  time:77.022, tt:8857.581\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.06413, lr:5.00e-03, fs:0.81111 (r=0.737,p=0.901),  time:77.035, tt:8936.116\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.06362, lr:4.95e-03, fs:0.81111 (r=0.737,p=0.901),  time:76.976, tt:9006.183\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.06411, lr:4.90e-03, fs:0.81111 (r=0.737,p=0.901),  time:76.938, tt:9078.726\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.06258, lr:4.85e-03, fs:0.81111 (r=0.737,p=0.901),  time:76.884, tt:9149.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.06505, lr:4.80e-03, fs:0.79775 (r=0.717,p=0.899),  time:76.839, tt:9220.708\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.06316, lr:4.75e-03, fs:0.81111 (r=0.737,p=0.901),  time:76.634, tt:9272.699\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09198, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:80.039, tt:80.039\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.08861, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:80.822, tt:161.645\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00035, loss_test:0.08244, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:81.075, tt:243.226\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00033, loss_test:0.07621, lr:1.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:80.953, tt:323.813\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07282, lr:1.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:79.007, tt:395.035\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00031, loss_test:0.07057, lr:1.00e-02, fs:0.69630 (r=0.949,p=0.550),  time:77.856, tt:467.133\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.06771, lr:1.00e-02, fs:0.70677 (r=0.949,p=0.563),  time:77.107, tt:539.751\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.06540, lr:1.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:76.763, tt:614.105\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00027, loss_test:0.06382, lr:1.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:76.959, tt:692.634\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00026, loss_test:0.06154, lr:1.00e-02, fs:0.73563 (r=0.970,p=0.593),  time:76.912, tt:769.125\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00025, loss_test:0.06039, lr:1.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:76.953, tt:846.482\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00024, loss_test:0.05946, lr:1.00e-02, fs:0.74131 (r=0.970,p=0.600),  time:77.295, tt:927.540\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.05857, lr:1.00e-02, fs:0.75486 (r=0.980,p=0.614),  time:77.595, tt:1008.738\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.05811, lr:1.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:77.562, tt:1085.867\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.05681, lr:1.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:77.358, tt:1160.371\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.05581, lr:1.00e-02, fs:0.76680 (r=0.980,p=0.630),  time:77.136, tt:1234.184\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00021, loss_test:0.05501, lr:1.00e-02, fs:0.76863 (r=0.990,p=0.628),  time:76.853, tt:1306.507\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.05415, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:76.929, tt:1384.729\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.05341, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:77.172, tt:1466.271\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.05277, lr:1.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:77.323, tt:1546.466\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.05190, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:77.443, tt:1626.308\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.05090, lr:1.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:77.632, tt:1707.907\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00018, loss_test:0.05073, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:77.797, tt:1789.324\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.05082, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:77.698, tt:1864.759\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.05040, lr:1.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:77.429, tt:1935.714\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.04968, lr:1.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:77.201, tt:2007.217\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.04965, lr:1.00e-02, fs:0.82759 (r=0.970,p=0.722),  time:77.208, tt:2084.615\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.04940, lr:1.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:77.217, tt:2162.090\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.04863, lr:1.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:77.325, tt:2242.436\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.04856, lr:1.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:77.276, tt:2318.276\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.04799, lr:1.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:77.273, tt:2395.478\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.04865, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:77.324, tt:2474.365\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.04778, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:77.283, tt:2550.336\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.04759, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:77.165, tt:2623.611\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.04648, lr:1.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:77.106, tt:2698.699\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.04780, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:76.974, tt:2771.078\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.04585, lr:1.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:76.967, tt:2847.786\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.04690, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:77.041, tt:2927.550\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.04584, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:77.110, tt:3007.296\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.04626, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:77.129, tt:3085.142\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.04638, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:77.234, tt:3166.601\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.04546, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:77.271, tt:3245.378\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.04591, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:77.204, tt:3319.786\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.04561, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:77.081, tt:3391.573\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.04558, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:77.010, tt:3465.443\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.04447, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:76.902, tt:3537.471\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.04623, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:76.944, tt:3616.345\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.04432, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:76.981, tt:3695.068\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.04458, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:77.051, tt:3775.479\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.04500, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:77.091, tt:3854.562\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.04396, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:77.135, tt:3933.899\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.04406, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:77.157, tt:4012.178\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.04445, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:77.072, tt:4084.838\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.04440, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:76.955, tt:4155.585\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.04543, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:76.900, tt:4229.495\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.04427, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:76.870, tt:4304.710\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.04476, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:76.926, tt:4384.802\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.04413, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:76.946, tt:4462.850\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.04404, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:76.969, tt:4541.159\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.04443, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:76.980, tt:4618.770\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.04414, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:76.970, tt:4695.173\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.04396, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:76.983, tt:4772.926\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00006, loss_test:0.04449, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:76.932, tt:4846.709\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.04370, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:76.853, tt:4918.605\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.04431, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:76.767, tt:4989.835\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.04434, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.810, tt:5069.487\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.04374, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:76.848, tt:5148.839\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.04356, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:76.897, tt:5228.982\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.04383, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:76.903, tt:5306.277\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00005, loss_test:0.04352, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.916, tt:5384.151\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.04230, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:76.974, tt:5465.150\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.04287, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:76.918, tt:5538.090\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.04320, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.863, tt:5610.981\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.04297, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.785, tt:5682.122\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.04285, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:76.759, tt:5756.897\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.04251, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:76.824, tt:5838.641\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.04296, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:76.824, tt:5915.444\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.04216, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:76.838, tt:5993.348\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.04353, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.847, tt:6070.903\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.04234, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:76.871, tt:6149.698\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.04284, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:76.869, tt:6226.381\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.04303, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.804, tt:6297.966\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.04266, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:76.758, tt:6370.925\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00004, loss_test:0.04256, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:76.723, tt:6444.766\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00004, loss_test:0.04354, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:76.722, tt:6521.385\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.04163, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:76.763, tt:6601.617\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.04275, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:76.777, tt:6679.626\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.04227, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:76.810, tt:6759.237\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.04217, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:76.845, tt:6839.173\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.04204, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:76.882, tt:6919.392\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.04237, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:76.843, tt:6992.672\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.04275, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:76.775, tt:7063.319\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.04256, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:76.729, tt:7135.770\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.04296, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:76.676, tt:7207.509\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.04178, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:76.712, tt:7287.592\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.04273, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:76.737, tt:7366.763\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.04276, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:76.757, tt:7445.410\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.04243, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:76.781, tt:7524.513\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.04134, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.775, tt:7600.723\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.04284, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:76.785, tt:7678.479\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.04250, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:76.733, tt:7750.043\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.04207, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:76.653, tt:7818.622\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.04212, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:76.619, tt:7891.753\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.04237, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:76.634, tt:7969.966\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.04207, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:76.680, tt:8051.452\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.04193, lr:9.90e-03, fs:0.88000 (r=0.889,p=0.871),  time:76.712, tt:8131.511\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.04265, lr:9.80e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.757, tt:8212.994\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.04235, lr:9.70e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.804, tt:8294.809\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.04262, lr:9.61e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.824, tt:8373.845\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.04263, lr:9.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.795, tt:8447.488\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.04215, lr:9.41e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.756, tt:8519.904\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.04229, lr:9.32e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.720, tt:8592.614\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.04303, lr:9.23e-03, fs:0.89796 (r=0.889,p=0.907),  time:76.716, tt:8668.894\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.04236, lr:9.14e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.755, tt:8750.120\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.04297, lr:9.04e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.793, tt:8831.170\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.04192, lr:8.95e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.818, tt:8910.914\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.04179, lr:8.86e-03, fs:0.88889 (r=0.889,p=0.889),  time:76.831, tt:8989.212\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.04214, lr:8.78e-03, fs:0.89340 (r=0.889,p=0.898),  time:76.857, tt:9069.116\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.04234, lr:8.69e-03, fs:0.89340 (r=0.889,p=0.898),  time:76.862, tt:9146.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.04199, lr:8.60e-03, fs:0.88442 (r=0.889,p=0.880),  time:76.816, tt:9217.900\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.04200, lr:8.51e-03, fs:0.89340 (r=0.889,p=0.898),  time:76.552, tt:9262.770\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 82\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09482, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:76.348, tt:76.348\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.09192, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:79.482, tt:158.963\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08672, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:79.670, tt:239.010\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08729, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:80.145, tt:320.580\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08592, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:80.548, tt:402.738\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.08340, lr:1.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:81.110, tt:486.662\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.08325, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:80.490, tt:563.432\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00026, loss_test:0.08478, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:79.828, tt:638.627\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00025, loss_test:0.08409, lr:1.00e-02, fs:0.68595 (r=0.838,p=0.580),  time:79.189, tt:712.698\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00024, loss_test:0.08557, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:78.678, tt:786.782\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00023, loss_test:0.08650, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:79.008, tt:869.085\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.08557, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:79.018, tt:948.221\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.08715, lr:1.00e-02, fs:0.66667 (r=0.768,p=0.589),  time:79.289, tt:1030.763\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00021, loss_test:0.08717, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:79.452, tt:1112.327\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00020, loss_test:0.08627, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:79.553, tt:1193.290\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.08731, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:79.617, tt:1273.865\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.08855, lr:9.90e-03, fs:0.65766 (r=0.737,p=0.593),  time:79.444, tt:1350.552\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.08885, lr:9.80e-03, fs:0.66364 (r=0.737,p=0.603),  time:79.247, tt:1426.452\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.08803, lr:9.70e-03, fs:0.66063 (r=0.737,p=0.598),  time:79.153, tt:1503.911\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00017, loss_test:0.08935, lr:9.61e-03, fs:0.65753 (r=0.727,p=0.600),  time:79.073, tt:1581.458\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.08954, lr:9.51e-03, fs:0.64789 (r=0.697,p=0.605),  time:79.312, tt:1665.545\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.08919, lr:9.41e-03, fs:0.65116 (r=0.707,p=0.603),  time:79.534, tt:1749.758\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.08926, lr:9.32e-03, fs:0.65116 (r=0.707,p=0.603),  time:79.603, tt:1830.869\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.09103, lr:9.23e-03, fs:0.64789 (r=0.697,p=0.605),  time:79.771, tt:1914.499\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.08986, lr:9.14e-03, fs:0.64486 (r=0.697,p=0.600),  time:79.812, tt:1995.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.09191, lr:9.04e-03, fs:0.65403 (r=0.697,p=0.616),  time:79.663, tt:2071.246\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.09197, lr:8.95e-03, fs:0.65094 (r=0.697,p=0.611),  time:79.477, tt:2145.872\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.09208, lr:8.86e-03, fs:0.65094 (r=0.697,p=0.611),  time:79.247, tt:2218.912\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.09228, lr:8.78e-03, fs:0.65094 (r=0.697,p=0.611),  time:79.084, tt:2293.427\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.09301, lr:8.69e-03, fs:0.66038 (r=0.707,p=0.619),  time:79.074, tt:2372.207\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.09108, lr:8.60e-03, fs:0.66047 (r=0.717,p=0.612),  time:79.127, tt:2452.923\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.09518, lr:8.51e-03, fs:0.67308 (r=0.707,p=0.642),  time:79.197, tt:2534.302\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.09376, lr:8.43e-03, fs:0.66667 (r=0.707,p=0.631),  time:79.208, tt:2613.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00013, loss_test:0.09227, lr:8.35e-03, fs:0.66986 (r=0.707,p=0.636),  time:79.207, tt:2693.036\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.09487, lr:8.26e-03, fs:0.66990 (r=0.697,p=0.645),  time:79.232, tt:2773.135\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.09491, lr:8.18e-03, fs:0.67633 (r=0.707,p=0.648),  time:79.131, tt:2848.730\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.09346, lr:8.10e-03, fs:0.66346 (r=0.697,p=0.633),  time:78.961, tt:2921.548\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.09593, lr:8.02e-03, fs:0.67317 (r=0.697,p=0.651),  time:78.867, tt:2996.956\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.09496, lr:7.94e-03, fs:0.67647 (r=0.697,p=0.657),  time:78.833, tt:3074.491\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00011, loss_test:0.09798, lr:7.86e-03, fs:0.67662 (r=0.687,p=0.667),  time:78.820, tt:3152.781\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00011, loss_test:0.09432, lr:7.78e-03, fs:0.67647 (r=0.697,p=0.657),  time:78.773, tt:3229.696\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.09562, lr:7.70e-03, fs:0.67647 (r=0.697,p=0.657),  time:78.814, tt:3310.184\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00010, loss_test:0.09552, lr:7.62e-03, fs:0.67980 (r=0.697,p=0.663),  time:78.813, tt:3388.954\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00010, loss_test:0.09763, lr:7.55e-03, fs:0.66667 (r=0.667,p=0.667),  time:78.853, tt:3469.529\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00010, loss_test:0.09551, lr:7.47e-03, fs:0.68657 (r=0.697,p=0.676),  time:78.847, tt:3548.112\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00010, loss_test:0.09743, lr:7.40e-03, fs:0.66667 (r=0.667,p=0.667),  time:78.766, tt:3623.227\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00009, loss_test:0.09772, lr:7.32e-03, fs:0.68020 (r=0.677,p=0.684),  time:78.661, tt:3697.086\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00009, loss_test:0.09689, lr:7.25e-03, fs:0.67677 (r=0.677,p=0.677),  time:78.587, tt:3772.166\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00009, loss_test:0.09753, lr:7.18e-03, fs:0.68020 (r=0.677,p=0.684),  time:78.650, tt:3853.829\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00009, loss_test:0.09788, lr:7.11e-03, fs:0.67692 (r=0.667,p=0.688),  time:78.659, tt:3932.948\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00009, loss_test:0.09746, lr:7.03e-03, fs:0.68020 (r=0.677,p=0.684),  time:78.689, tt:4013.123\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00009, loss_test:0.09914, lr:6.96e-03, fs:0.69792 (r=0.677,p=0.720),  time:78.718, tt:4093.337\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00008, loss_test:0.09856, lr:6.89e-03, fs:0.68367 (r=0.677,p=0.691),  time:78.736, tt:4173.008\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00008, loss_test:0.09840, lr:6.83e-03, fs:0.68718 (r=0.677,p=0.698),  time:78.727, tt:4251.263\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00008, loss_test:0.09951, lr:6.76e-03, fs:0.69474 (r=0.667,p=0.725),  time:78.618, tt:4323.994\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00008, loss_test:0.09872, lr:6.69e-03, fs:0.69430 (r=0.677,p=0.713),  time:78.523, tt:4397.289\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00007, loss_test:0.09839, lr:6.62e-03, fs:0.68020 (r=0.677,p=0.684),  time:78.417, tt:4469.768\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00007, loss_test:0.09955, lr:6.56e-03, fs:0.69430 (r=0.677,p=0.713),  time:78.347, tt:4544.155\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00007, loss_test:0.09976, lr:6.49e-03, fs:0.69430 (r=0.677,p=0.713),  time:78.369, tt:4623.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00007, loss_test:0.10080, lr:6.43e-03, fs:0.70157 (r=0.677,p=0.728),  time:78.415, tt:4704.929\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00007, loss_test:0.10072, lr:6.36e-03, fs:0.70899 (r=0.677,p=0.744),  time:78.424, tt:4783.888\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00007, loss_test:0.10084, lr:6.36e-03, fs:0.70157 (r=0.677,p=0.728),  time:78.460, tt:4864.513\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00007, loss_test:0.10093, lr:6.36e-03, fs:0.70157 (r=0.677,p=0.728),  time:78.450, tt:4942.350\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00007, loss_test:0.10264, lr:6.36e-03, fs:0.70588 (r=0.667,p=0.750),  time:78.429, tt:5019.434\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00007, loss_test:0.10141, lr:6.36e-03, fs:0.69474 (r=0.667,p=0.725),  time:78.325, tt:5091.133\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00007, loss_test:0.10173, lr:6.36e-03, fs:0.70526 (r=0.677,p=0.736),  time:78.253, tt:5164.705\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00006, loss_test:0.10148, lr:6.36e-03, fs:0.70899 (r=0.677,p=0.744),  time:78.178, tt:5237.915\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00006, loss_test:0.10280, lr:6.36e-03, fs:0.70588 (r=0.667,p=0.750),  time:78.184, tt:5316.539\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00006, loss_test:0.10388, lr:6.36e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.208, tt:5396.366\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00006, loss_test:0.10262, lr:6.36e-03, fs:0.70526 (r=0.677,p=0.736),  time:78.241, tt:5476.902\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00006, loss_test:0.10401, lr:6.36e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.238, tt:5554.898\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00006, loss_test:0.10225, lr:6.36e-03, fs:0.70157 (r=0.677,p=0.728),  time:78.269, tt:5635.377\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00006, loss_test:0.10428, lr:6.36e-03, fs:0.71351 (r=0.667,p=0.767),  time:78.311, tt:5716.703\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00006, loss_test:0.10326, lr:6.36e-03, fs:0.71277 (r=0.677,p=0.753),  time:78.235, tt:5789.411\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00006, loss_test:0.10390, lr:6.36e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.194, tt:5864.534\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00005, loss_test:0.10305, lr:6.36e-03, fs:0.70899 (r=0.677,p=0.744),  time:78.125, tt:5937.474\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00005, loss_test:0.10478, lr:6.36e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.097, tt:6013.506\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00005, loss_test:0.10290, lr:6.36e-03, fs:0.70899 (r=0.677,p=0.744),  time:78.111, tt:6092.630\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00005, loss_test:0.10352, lr:6.36e-03, fs:0.70526 (r=0.677,p=0.736),  time:78.105, tt:6170.321\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00005, loss_test:0.10491, lr:6.36e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.127, tt:6250.164\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00005, loss_test:0.10218, lr:6.30e-03, fs:0.69792 (r=0.677,p=0.720),  time:78.134, tt:6328.875\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00005, loss_test:0.10563, lr:6.24e-03, fs:0.72826 (r=0.677,p=0.788),  time:78.160, tt:6409.122\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00005, loss_test:0.10474, lr:6.24e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.121, tt:6484.080\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00005, loss_test:0.10698, lr:6.24e-03, fs:0.72131 (r=0.667,p=0.786),  time:78.064, tt:6557.394\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00005, loss_test:0.10421, lr:6.24e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.038, tt:6633.245\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00005, loss_test:0.10691, lr:6.24e-03, fs:0.70718 (r=0.646,p=0.780),  time:78.005, tt:6708.415\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00005, loss_test:0.10436, lr:6.24e-03, fs:0.72043 (r=0.677,p=0.770),  time:78.002, tt:6786.207\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00005, loss_test:0.10433, lr:6.24e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.034, tt:6867.022\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00005, loss_test:0.10570, lr:6.24e-03, fs:0.71658 (r=0.677,p=0.761),  time:78.061, tt:6947.393\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00005, loss_test:0.10626, lr:6.24e-03, fs:0.71739 (r=0.667,p=0.776),  time:78.085, tt:7027.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00004, loss_test:0.10678, lr:6.24e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.102, tt:7107.313\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00004, loss_test:0.10591, lr:6.24e-03, fs:0.72432 (r=0.677,p=0.779),  time:78.143, tt:7189.187\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00004, loss_test:0.10622, lr:6.24e-03, fs:0.72131 (r=0.667,p=0.786),  time:78.123, tt:7265.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00004, loss_test:0.10616, lr:6.17e-03, fs:0.71739 (r=0.667,p=0.776),  time:78.075, tt:7339.036\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00004, loss_test:0.10685, lr:6.11e-03, fs:0.71823 (r=0.657,p=0.793),  time:78.032, tt:7413.051\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00004, loss_test:0.10548, lr:6.05e-03, fs:0.72131 (r=0.667,p=0.786),  time:77.997, tt:7487.690\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00004, loss_test:0.10831, lr:5.99e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.019, tt:7567.817\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00004, loss_test:0.10508, lr:5.93e-03, fs:0.71277 (r=0.677,p=0.753),  time:78.015, tt:7645.516\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00004, loss_test:0.10604, lr:5.87e-03, fs:0.71739 (r=0.667,p=0.776),  time:78.027, tt:7724.667\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00004, loss_test:0.10698, lr:5.81e-03, fs:0.70652 (r=0.657,p=0.765),  time:78.046, tt:7804.646\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00004, loss_test:0.10722, lr:5.75e-03, fs:0.70718 (r=0.646,p=0.780),  time:78.058, tt:7883.873\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00004, loss_test:0.10642, lr:5.70e-03, fs:0.71429 (r=0.657,p=0.783),  time:78.075, tt:7963.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00004, loss_test:0.10852, lr:5.64e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.039, tt:8038.032\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00004, loss_test:0.10684, lr:5.58e-03, fs:0.71429 (r=0.657,p=0.783),  time:77.986, tt:8110.584\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00004, loss_test:0.10758, lr:5.53e-03, fs:0.71111 (r=0.646,p=0.790),  time:77.948, tt:8184.574\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00004, loss_test:0.10813, lr:5.47e-03, fs:0.71111 (r=0.646,p=0.790),  time:77.959, tt:8263.655\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00004, loss_test:0.10748, lr:5.42e-03, fs:0.71111 (r=0.646,p=0.790),  time:77.975, tt:8343.333\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00003, loss_test:0.10819, lr:5.36e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.004, tt:8424.472\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00004, loss_test:0.10942, lr:5.31e-03, fs:0.71508 (r=0.646,p=0.800),  time:78.039, tt:8506.223\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00003, loss_test:0.10839, lr:5.26e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.070, tt:8587.665\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00004, loss_test:0.10820, lr:5.20e-03, fs:0.71508 (r=0.646,p=0.800),  time:78.106, tt:8669.760\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00003, loss_test:0.10723, lr:5.15e-03, fs:0.70718 (r=0.646,p=0.780),  time:78.073, tt:8744.132\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00003, loss_test:0.10765, lr:5.10e-03, fs:0.70718 (r=0.646,p=0.780),  time:78.034, tt:8817.887\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00003, loss_test:0.10798, lr:5.05e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.013, tt:8893.459\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00003, loss_test:0.10693, lr:5.00e-03, fs:0.70718 (r=0.646,p=0.780),  time:77.987, tt:8968.514\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00003, loss_test:0.10783, lr:4.95e-03, fs:0.71508 (r=0.646,p=0.800),  time:78.002, tt:9048.277\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00003, loss_test:0.10754, lr:4.90e-03, fs:0.71429 (r=0.657,p=0.783),  time:78.020, tt:9128.322\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00003, loss_test:0.10938, lr:4.85e-03, fs:0.70787 (r=0.636,p=0.797),  time:78.026, tt:9207.033\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00003, loss_test:0.10760, lr:4.80e-03, fs:0.71111 (r=0.646,p=0.790),  time:78.048, tt:9287.660\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00003, loss_test:0.10795, lr:4.75e-03, fs:0.70000 (r=0.636,p=0.778),  time:78.049, tt:9365.919\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00003, loss_test:0.10910, lr:4.71e-03, fs:0.71111 (r=0.646,p=0.790),  time:77.819, tt:9416.062\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 83\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09006, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:73.244, tt:73.244\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.08657, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:73.924, tt:147.848\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00035, loss_test:0.08176, lr:1.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:75.604, tt:226.811\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00033, loss_test:0.07720, lr:1.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:76.193, tt:304.773\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07558, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:77.057, tt:385.284\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00031, loss_test:0.07422, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:77.602, tt:465.611\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.07255, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:77.989, tt:545.926\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.07047, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:78.125, tt:625.000\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00027, loss_test:0.06884, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:77.912, tt:701.204\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.06781, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:77.209, tt:772.086\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00025, loss_test:0.06646, lr:1.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:76.656, tt:843.217\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00024, loss_test:0.06533, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:76.233, tt:914.795\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.06431, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:76.483, tt:994.273\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06412, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:76.659, tt:1073.220\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.06326, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:76.882, tt:1153.234\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06197, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:77.157, tt:1234.506\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00021, loss_test:0.06246, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:77.299, tt:1314.085\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.06159, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:77.393, tt:1393.067\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.06138, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:77.194, tt:1466.687\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.06064, lr:1.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:77.043, tt:1540.866\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.06014, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:76.835, tt:1613.536\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.06005, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:76.799, tt:1689.572\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.05912, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:76.874, tt:1768.100\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.05976, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:77.008, tt:1848.191\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.05916, lr:1.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:77.088, tt:1927.196\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.05982, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:77.118, tt:2005.060\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00016, loss_test:0.05902, lr:1.00e-02, fs:0.75862 (r=0.889,p=0.662),  time:77.202, tt:2084.458\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.05932, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:77.184, tt:2161.139\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.05759, lr:1.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:76.941, tt:2231.303\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.05822, lr:1.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:76.706, tt:2301.170\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.05802, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:76.552, tt:2373.121\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00014, loss_test:0.05836, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:76.582, tt:2450.637\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.05664, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:76.634, tt:2528.912\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00013, loss_test:0.06047, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:76.649, tt:2606.082\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.05671, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:76.722, tt:2685.265\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.06086, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:76.796, tt:2764.655\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.05802, lr:1.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:76.860, tt:2843.819\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.06095, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:76.740, tt:2916.110\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.05838, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:76.652, tt:2989.447\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.06040, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:76.506, tt:3060.254\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.05845, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:76.400, tt:3132.404\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.06062, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:76.518, tt:3213.759\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05854, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:76.600, tt:3293.802\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.05911, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:76.636, tt:3371.966\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.06013, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:76.650, tt:3449.248\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00009, loss_test:0.06044, lr:9.90e-03, fs:0.76712 (r=0.848,p=0.700),  time:76.733, tt:3529.700\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00009, loss_test:0.06008, lr:9.80e-03, fs:0.79227 (r=0.828,p=0.759),  time:76.756, tt:3607.536\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.05987, lr:9.70e-03, fs:0.78095 (r=0.828,p=0.739),  time:76.666, tt:3679.951\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.06141, lr:9.61e-03, fs:0.78873 (r=0.848,p=0.737),  time:76.564, tt:3751.626\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.06044, lr:9.51e-03, fs:0.78218 (r=0.798,p=0.767),  time:76.493, tt:3824.626\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00008, loss_test:0.05987, lr:9.41e-03, fs:0.78846 (r=0.828,p=0.752),  time:76.538, tt:3903.437\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.06232, lr:9.32e-03, fs:0.76471 (r=0.788,p=0.743),  time:76.600, tt:3983.184\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.05816, lr:9.23e-03, fs:0.77358 (r=0.828,p=0.726),  time:76.659, tt:4062.903\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.06178, lr:9.14e-03, fs:0.77778 (r=0.778,p=0.778),  time:76.692, tt:4141.387\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.06022, lr:9.04e-03, fs:0.77451 (r=0.798,p=0.752),  time:76.758, tt:4221.678\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.06206, lr:8.95e-03, fs:0.78571 (r=0.778,p=0.794),  time:76.865, tt:4304.461\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00007, loss_test:0.06040, lr:8.86e-03, fs:0.77778 (r=0.778,p=0.778),  time:76.783, tt:4376.617\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.06108, lr:8.78e-03, fs:0.78788 (r=0.788,p=0.788),  time:76.704, tt:4448.860\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.06150, lr:8.69e-03, fs:0.78571 (r=0.778,p=0.794),  time:76.621, tt:4520.658\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.06071, lr:8.60e-03, fs:0.79000 (r=0.798,p=0.782),  time:76.539, tt:4592.358\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.06348, lr:8.51e-03, fs:0.78571 (r=0.778,p=0.794),  time:76.603, tt:4672.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.06024, lr:8.43e-03, fs:0.78788 (r=0.788,p=0.788),  time:76.669, tt:4753.464\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00006, loss_test:0.06201, lr:8.35e-03, fs:0.78218 (r=0.798,p=0.767),  time:76.766, tt:4836.228\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00006, loss_test:0.06059, lr:8.26e-03, fs:0.79188 (r=0.788,p=0.796),  time:76.835, tt:4917.418\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00006, loss_test:0.06179, lr:8.18e-03, fs:0.78571 (r=0.778,p=0.794),  time:76.896, tt:4998.241\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.06211, lr:8.10e-03, fs:0.78607 (r=0.798,p=0.775),  time:76.954, tt:5078.955\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.06283, lr:8.02e-03, fs:0.79381 (r=0.778,p=0.811),  time:76.931, tt:5154.346\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.06130, lr:8.02e-03, fs:0.78392 (r=0.788,p=0.780),  time:76.857, tt:5226.249\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.06350, lr:8.02e-03, fs:0.80000 (r=0.788,p=0.812),  time:76.826, tt:5300.970\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00005, loss_test:0.06294, lr:8.02e-03, fs:0.79381 (r=0.778,p=0.811),  time:76.857, tt:5380.022\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00005, loss_test:0.06223, lr:8.02e-03, fs:0.79592 (r=0.788,p=0.804),  time:76.934, tt:5462.293\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00005, loss_test:0.06199, lr:8.02e-03, fs:0.78788 (r=0.788,p=0.788),  time:76.951, tt:5540.468\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00005, loss_test:0.06316, lr:8.02e-03, fs:0.79793 (r=0.778,p=0.819),  time:76.964, tt:5618.404\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00005, loss_test:0.06352, lr:8.02e-03, fs:0.79793 (r=0.778,p=0.819),  time:76.989, tt:5697.159\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00005, loss_test:0.06322, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.995, tt:5774.602\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.06267, lr:8.02e-03, fs:0.79592 (r=0.788,p=0.804),  time:76.965, tt:5849.310\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.06248, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.946, tt:5924.853\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.06377, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.902, tt:5998.337\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.06424, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.849, tt:6071.091\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.06298, lr:8.02e-03, fs:0.80000 (r=0.788,p=0.812),  time:76.904, tt:6152.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.06407, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.936, tt:6231.786\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.06379, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.950, tt:6309.906\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.06397, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.992, tt:6390.361\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00004, loss_test:0.06363, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:77.014, tt:6469.193\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00004, loss_test:0.06381, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:77.029, tt:6547.453\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00004, loss_test:0.06426, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:76.998, tt:6621.797\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00004, loss_test:0.06470, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:76.942, tt:6693.956\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.06430, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:76.903, tt:6767.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00004, loss_test:0.06522, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.928, tt:6846.558\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.06489, lr:8.02e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.961, tt:6926.516\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.06548, lr:8.02e-03, fs:0.80412 (r=0.788,p=0.821),  time:76.957, tt:7003.111\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.06469, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:76.987, tt:7082.821\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.06560, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:76.983, tt:7159.460\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.06561, lr:8.02e-03, fs:0.80208 (r=0.778,p=0.828),  time:76.988, tt:7236.871\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.06518, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:76.945, tt:7309.743\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.06624, lr:8.02e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.875, tt:7379.978\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.06662, lr:8.02e-03, fs:0.80208 (r=0.778,p=0.828),  time:76.838, tt:7453.253\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.06651, lr:8.02e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.810, tt:7527.384\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.06725, lr:8.02e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.823, tt:7605.465\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.06632, lr:8.02e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.854, tt:7685.416\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.06736, lr:8.02e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.883, tt:7765.215\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00003, loss_test:0.06651, lr:8.02e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.906, tt:7844.461\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00003, loss_test:0.06682, lr:8.02e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.899, tt:7920.644\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00003, loss_test:0.06703, lr:8.02e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.924, tt:8000.147\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00003, loss_test:0.06743, lr:8.02e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.892, tt:8073.641\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00003, loss_test:0.06788, lr:8.02e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.844, tt:8145.444\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00003, loss_test:0.06676, lr:8.02e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.787, tt:8216.194\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00003, loss_test:0.06972, lr:8.02e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.788, tt:8293.125\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.06778, lr:8.02e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.782, tt:8369.253\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00003, loss_test:0.06825, lr:7.94e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.795, tt:8447.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00003, loss_test:0.06821, lr:7.86e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.805, tt:8525.411\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00003, loss_test:0.06788, lr:7.78e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.805, tt:8602.197\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.06779, lr:7.70e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.820, tt:8680.651\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.06888, lr:7.62e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.828, tt:8758.374\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.06893, lr:7.55e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.790, tt:8830.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.06872, lr:7.47e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.748, tt:8902.821\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.06868, lr:7.40e-03, fs:0.81481 (r=0.778,p=0.856),  time:76.696, tt:8973.417\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.06954, lr:7.32e-03, fs:0.80851 (r=0.768,p=0.854),  time:76.699, tt:9050.432\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.06884, lr:7.25e-03, fs:0.81481 (r=0.778,p=0.856),  time:76.725, tt:9130.280\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.07008, lr:7.18e-03, fs:0.80851 (r=0.768,p=0.854),  time:76.686, tt:9202.343\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.06841, lr:7.11e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.537, tt:9260.954\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 84\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09670, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:76.115, tt:76.115\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09535, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:73.429, tt:146.858\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.09405, lr:1.00e-02, fs:0.64561 (r=0.929,p=0.495),  time:72.002, tt:216.005\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.09341, lr:1.00e-02, fs:0.61364 (r=0.818,p=0.491),  time:71.642, tt:286.568\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.09164, lr:1.00e-02, fs:0.62879 (r=0.838,p=0.503),  time:71.424, tt:357.119\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.08865, lr:1.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:71.126, tt:426.754\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.08669, lr:1.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:70.989, tt:496.922\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.08520, lr:1.00e-02, fs:0.62992 (r=0.808,p=0.516),  time:71.080, tt:568.638\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.08234, lr:1.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:71.133, tt:640.199\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07955, lr:1.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:70.865, tt:708.647\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07693, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:70.774, tt:778.514\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.07661, lr:1.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:70.819, tt:849.824\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.07536, lr:1.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:70.724, tt:919.417\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.07450, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:70.779, tt:990.910\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.07488, lr:1.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:70.668, tt:1060.015\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.07332, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:70.636, tt:1130.182\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00019, loss_test:0.07275, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:70.671, tt:1201.415\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.07319, lr:1.00e-02, fs:0.69298 (r=0.798,p=0.612),  time:70.703, tt:1272.652\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.07230, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:70.629, tt:1341.954\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.07293, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:70.714, tt:1414.286\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.07133, lr:1.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:70.583, tt:1482.250\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.07122, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:70.487, tt:1550.720\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.07127, lr:1.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:70.543, tt:1622.495\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.07250, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:70.557, tt:1693.362\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.07040, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:70.555, tt:1763.876\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.07091, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:70.496, tt:1832.894\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.06968, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:70.490, tt:1903.217\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.07069, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:70.420, tt:1971.748\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.07025, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:70.447, tt:2042.957\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.07123, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:70.366, tt:2110.988\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.07003, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:70.414, tt:2182.824\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.07008, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:70.377, tt:2252.054\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.06973, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:70.396, tt:2323.057\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.06964, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:70.394, tt:2393.406\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.07020, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:70.506, tt:2467.695\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.06969, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:70.496, tt:2537.864\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.06983, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:70.508, tt:2608.780\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.07087, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:70.503, tt:2679.099\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.06929, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:70.561, tt:2751.867\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.06919, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:70.555, tt:2822.220\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.07052, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:70.553, tt:2892.677\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.07018, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:70.587, tt:2964.650\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00010, loss_test:0.07103, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:70.580, tt:3034.934\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.06881, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:70.570, tt:3105.064\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.06992, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:70.592, tt:3176.651\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00009, loss_test:0.06899, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:70.617, tt:3248.374\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.07059, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:70.606, tt:3318.497\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.06947, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:70.622, tt:3389.845\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.06906, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:70.633, tt:3461.023\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.07074, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:70.603, tt:3530.138\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00008, loss_test:0.06966, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:70.594, tt:3600.317\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.07045, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:70.543, tt:3668.252\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.07026, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:70.539, tt:3738.588\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.07275, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:70.534, tt:3808.835\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.07047, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:70.530, tt:3879.130\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.07283, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:70.565, tt:3951.647\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00007, loss_test:0.07048, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:70.579, tt:4023.030\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.07228, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:70.569, tt:4092.989\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.07043, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:70.554, tt:4162.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.07225, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:70.588, tt:4235.303\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.07285, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:70.573, tt:4304.944\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.07175, lr:9.90e-03, fs:0.78469 (r=0.828,p=0.745),  time:70.585, tt:4376.242\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.07187, lr:9.80e-03, fs:0.78261 (r=0.818,p=0.750),  time:70.603, tt:4447.977\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.07307, lr:9.70e-03, fs:0.78469 (r=0.828,p=0.745),  time:70.606, tt:4518.802\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.07344, lr:9.61e-03, fs:0.79024 (r=0.818,p=0.764),  time:70.596, tt:4588.753\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.07327, lr:9.51e-03, fs:0.78261 (r=0.818,p=0.750),  time:70.553, tt:4656.528\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.07210, lr:9.41e-03, fs:0.78469 (r=0.828,p=0.745),  time:70.552, tt:4726.991\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.07337, lr:9.32e-03, fs:0.76617 (r=0.778,p=0.755),  time:70.529, tt:4795.949\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0307a213a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,121,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 91\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:0, loss:0.00051, loss_test:0.14701, lr:1.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:51.934, tt:51.934\n",
      "##########Best model found so far##########\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:1, loss:0.00047, loss_test:0.14366, lr:1.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:53.708, tt:107.416\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:2, loss:0.00036, loss_test:0.15951, lr:1.00e-02, fs:0.48750 (r=0.394,p=0.639),  time:54.613, tt:163.839\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:3, loss:0.00029, loss_test:0.15672, lr:1.00e-02, fs:0.48148 (r=0.394,p=0.619),  time:54.913, tt:219.653\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:4, loss:0.00028, loss_test:0.15010, lr:1.00e-02, fs:0.49383 (r=0.404,p=0.635),  time:55.247, tt:276.236\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:5, loss:0.00028, loss_test:0.15768, lr:1.00e-02, fs:0.41727 (r=0.293,p=0.725),  time:54.915, tt:329.487\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:6, loss:0.00025, loss_test:0.14694, lr:1.00e-02, fs:0.47059 (r=0.364,p=0.667),  time:54.529, tt:381.702\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:7, loss:0.00025, loss_test:0.14792, lr:1.00e-02, fs:0.44138 (r=0.323,p=0.696),  time:53.955, tt:431.641\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:8, loss:0.00023, loss_test:0.13955, lr:1.00e-02, fs:0.55484 (r=0.434,p=0.768),  time:53.624, tt:482.615\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:9, loss:0.00023, loss_test:0.14114, lr:1.00e-02, fs:0.51034 (r=0.374,p=0.804),  time:53.026, tt:530.258\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:10, loss:0.00022, loss_test:0.13759, lr:1.00e-02, fs:0.53333 (r=0.404,p=0.784),  time:53.163, tt:584.797\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:11, loss:0.00021, loss_test:0.13865, lr:1.00e-02, fs:0.53061 (r=0.394,p=0.812),  time:53.415, tt:640.978\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:12, loss:0.00020, loss_test:0.13682, lr:9.90e-03, fs:0.54054 (r=0.404,p=0.816),  time:53.628, tt:697.165\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:13, loss:0.00020, loss_test:0.13544, lr:9.80e-03, fs:0.53425 (r=0.394,p=0.830),  time:53.522, tt:749.305\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:14, loss:0.00019, loss_test:0.13970, lr:9.70e-03, fs:0.53061 (r=0.394,p=0.812),  time:52.480, tt:787.207\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:15, loss:0.00018, loss_test:0.13321, lr:9.61e-03, fs:0.50350 (r=0.364,p=0.818),  time:51.277, tt:820.431\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:16, loss:0.00018, loss_test:0.13609, lr:9.51e-03, fs:0.59740 (r=0.465,p=0.836),  time:50.054, tt:850.923\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:17, loss:0.00017, loss_test:0.13546, lr:9.41e-03, fs:0.53793 (r=0.394,p=0.848),  time:48.978, tt:881.596\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:18, loss:0.00017, loss_test:0.13556, lr:9.32e-03, fs:0.62420 (r=0.495,p=0.845),  time:48.143, tt:914.711\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:19, loss:0.00016, loss_test:0.13641, lr:9.23e-03, fs:0.52778 (r=0.384,p=0.844),  time:47.308, tt:946.152\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:20, loss:0.00015, loss_test:0.12895, lr:9.14e-03, fs:0.63694 (r=0.505,p=0.862),  time:46.626, tt:979.153\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:21, loss:0.00014, loss_test:0.13582, lr:9.04e-03, fs:0.57718 (r=0.434,p=0.860),  time:46.226, tt:1016.976\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:22, loss:0.00014, loss_test:0.13116, lr:8.95e-03, fs:0.61538 (r=0.485,p=0.842),  time:45.863, tt:1054.840\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:23, loss:0.00013, loss_test:0.13678, lr:8.86e-03, fs:0.58278 (r=0.444,p=0.846),  time:45.605, tt:1094.515\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:24, loss:0.00012, loss_test:0.13460, lr:8.78e-03, fs:0.61039 (r=0.475,p=0.855),  time:45.319, tt:1132.974\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:25, loss:0.00012, loss_test:0.13627, lr:8.69e-03, fs:0.62821 (r=0.495,p=0.860),  time:44.766, tt:1163.909\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:26, loss:0.00012, loss_test:0.12717, lr:8.60e-03, fs:0.62821 (r=0.495,p=0.860),  time:44.261, tt:1195.042\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:27, loss:0.00011, loss_test:0.14786, lr:8.51e-03, fs:0.59060 (r=0.444,p=0.880),  time:43.768, tt:1225.513\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:28, loss:0.00012, loss_test:0.11729, lr:8.43e-03, fs:0.73684 (r=0.636,p=0.875),  time:43.301, tt:1255.744\n",
      "##########Best model found so far##########\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:29, loss:0.00012, loss_test:0.15376, lr:8.43e-03, fs:0.58108 (r=0.434,p=0.878),  time:42.870, tt:1286.088\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:30, loss:0.00013, loss_test:0.11652, lr:8.43e-03, fs:0.75429 (r=0.667,p=0.868),  time:42.618, tt:1321.163\n",
      "##########Best model found so far##########\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:31, loss:0.00012, loss_test:0.14871, lr:8.43e-03, fs:0.61438 (r=0.475,p=0.870),  time:42.349, tt:1355.161\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:32, loss:0.00011, loss_test:0.12103, lr:8.43e-03, fs:0.63694 (r=0.505,p=0.862),  time:42.151, tt:1390.992\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:33, loss:0.00010, loss_test:0.13311, lr:8.43e-03, fs:0.63226 (r=0.495,p=0.875),  time:41.979, tt:1427.286\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:34, loss:0.00009, loss_test:0.12477, lr:8.43e-03, fs:0.64516 (r=0.505,p=0.893),  time:41.789, tt:1462.601\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:35, loss:0.00009, loss_test:0.14204, lr:8.43e-03, fs:0.61333 (r=0.465,p=0.902),  time:41.495, tt:1493.836\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:36, loss:0.00008, loss_test:0.11923, lr:8.43e-03, fs:0.69136 (r=0.566,p=0.889),  time:41.172, tt:1523.351\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:37, loss:0.00008, loss_test:0.13382, lr:8.43e-03, fs:0.61745 (r=0.465,p=0.920),  time:40.887, tt:1553.714\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:38, loss:0.00007, loss_test:0.12809, lr:8.43e-03, fs:0.65806 (r=0.515,p=0.911),  time:40.630, tt:1584.578\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:39, loss:0.00007, loss_test:0.12128, lr:8.43e-03, fs:0.63636 (r=0.495,p=0.891),  time:40.413, tt:1616.534\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:40, loss:0.00007, loss_test:0.14006, lr:8.43e-03, fs:0.64052 (r=0.495,p=0.907),  time:40.257, tt:1650.534\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:41, loss:0.00007, loss_test:0.11438, lr:8.43e-03, fs:0.67901 (r=0.556,p=0.873),  time:40.159, tt:1686.679\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:42, loss:0.00006, loss_test:0.13984, lr:8.35e-03, fs:0.62252 (r=0.475,p=0.904),  time:40.109, tt:1724.686\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:43, loss:0.00006, loss_test:0.11172, lr:8.26e-03, fs:0.66667 (r=0.545,p=0.857),  time:40.036, tt:1761.605\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:44, loss:0.00006, loss_test:0.14019, lr:8.18e-03, fs:0.62667 (r=0.475,p=0.922),  time:39.935, tt:1797.096\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:45, loss:0.00005, loss_test:0.12020, lr:8.10e-03, fs:0.64052 (r=0.495,p=0.907),  time:39.698, tt:1826.123\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:46, loss:0.00005, loss_test:0.12938, lr:8.02e-03, fs:0.64000 (r=0.485,p=0.941),  time:39.463, tt:1854.766\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:47, loss:0.00005, loss_test:0.12356, lr:7.94e-03, fs:0.64935 (r=0.505,p=0.909),  time:39.283, tt:1885.601\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:48, loss:0.00004, loss_test:0.13249, lr:7.86e-03, fs:0.62667 (r=0.475,p=0.922),  time:39.102, tt:1915.984\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:49, loss:0.00004, loss_test:0.12175, lr:7.78e-03, fs:0.64516 (r=0.505,p=0.893),  time:39.019, tt:1950.962\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:50, loss:0.00004, loss_test:0.13104, lr:7.70e-03, fs:0.64000 (r=0.485,p=0.941),  time:38.986, tt:1988.266\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:51, loss:0.00004, loss_test:0.13514, lr:7.62e-03, fs:0.63087 (r=0.475,p=0.940),  time:38.924, tt:2024.033\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:52, loss:0.00004, loss_test:0.13265, lr:7.55e-03, fs:0.62162 (r=0.465,p=0.939),  time:38.719, tt:2052.091\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:53, loss:0.00003, loss_test:0.13509, lr:7.47e-03, fs:0.63087 (r=0.475,p=0.940),  time:38.412, tt:2074.223\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:54, loss:0.00003, loss_test:0.12662, lr:7.40e-03, fs:0.63087 (r=0.475,p=0.940),  time:38.068, tt:2093.726\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:55, loss:0.00003, loss_test:0.13682, lr:7.32e-03, fs:0.63087 (r=0.475,p=0.940),  time:37.736, tt:2113.203\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:56, loss:0.00003, loss_test:0.12581, lr:7.25e-03, fs:0.64516 (r=0.505,p=0.893),  time:37.417, tt:2132.788\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:57, loss:0.00003, loss_test:0.13141, lr:7.18e-03, fs:0.62162 (r=0.465,p=0.939),  time:37.097, tt:2151.640\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:58, loss:0.00003, loss_test:0.13236, lr:7.11e-03, fs:0.62667 (r=0.475,p=0.922),  time:36.809, tt:2171.705\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:59, loss:0.00003, loss_test:0.13500, lr:7.03e-03, fs:0.61745 (r=0.465,p=0.920),  time:36.553, tt:2193.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:60, loss:0.00003, loss_test:0.13718, lr:6.96e-03, fs:0.62252 (r=0.475,p=0.904),  time:36.304, tt:2214.547\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:61, loss:0.00002, loss_test:0.12906, lr:6.89e-03, fs:0.62667 (r=0.475,p=0.922),  time:36.070, tt:2236.334\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:62, loss:0.00002, loss_test:0.14510, lr:6.83e-03, fs:0.62162 (r=0.465,p=0.939),  time:35.894, tt:2261.296\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:63, loss:0.00002, loss_test:0.13115, lr:6.76e-03, fs:0.62162 (r=0.465,p=0.939),  time:35.716, tt:2285.832\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:64, loss:0.00002, loss_test:0.13502, lr:6.69e-03, fs:0.62162 (r=0.465,p=0.939),  time:35.646, tt:2317.020\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:65, loss:0.00002, loss_test:0.13613, lr:6.62e-03, fs:0.62162 (r=0.465,p=0.939),  time:35.573, tt:2347.820\n",
      "1047\n",
      "1029\n",
      "588\n",
      "Ep:66, loss:0.00002, loss_test:0.13632, lr:6.56e-03, fs:0.62585 (r=0.465,p=0.958),  time:35.611, tt:2385.910\n",
      "1047\n",
      "1029\n",
      "588\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b4e5dd35b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"92-92\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,\"92-92\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:0, loss:0.00054, loss_test:0.08888, lr:1.00e-02, fs:0.62921 (r=0.848,p=0.500),  time:94.639, tt:94.639\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:1, loss:0.00029, loss_test:0.09865, lr:1.00e-02, fs:0.60606 (r=0.606,p=0.606),  time:92.932, tt:185.864\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:2, loss:0.00023, loss_test:0.09733, lr:1.00e-02, fs:0.61458 (r=0.596,p=0.634),  time:92.756, tt:278.267\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:3, loss:0.00022, loss_test:0.09576, lr:1.00e-02, fs:0.61290 (r=0.576,p=0.655),  time:92.069, tt:368.278\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:4, loss:0.00020, loss_test:0.09236, lr:1.00e-02, fs:0.63492 (r=0.606,p=0.667),  time:92.989, tt:464.943\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:5, loss:0.00019, loss_test:0.09071, lr:1.00e-02, fs:0.65169 (r=0.586,p=0.734),  time:93.791, tt:562.744\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:6, loss:0.00018, loss_test:0.08835, lr:1.00e-02, fs:0.65537 (r=0.586,p=0.744),  time:94.316, tt:660.209\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:7, loss:0.00017, loss_test:0.07946, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:94.205, tt:753.643\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:8, loss:0.00017, loss_test:0.08562, lr:1.00e-02, fs:0.70000 (r=0.636,p=0.778),  time:93.679, tt:843.108\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:9, loss:0.00016, loss_test:0.08182, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:93.105, tt:931.048\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:10, loss:0.00015, loss_test:0.07707, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:93.128, tt:1024.406\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:11, loss:0.00015, loss_test:0.07967, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:93.384, tt:1120.602\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:12, loss:0.00014, loss_test:0.07704, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:93.352, tt:1213.570\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:13, loss:0.00014, loss_test:0.07350, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:93.560, tt:1309.835\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:14, loss:0.00013, loss_test:0.07417, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:93.461, tt:1401.917\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:15, loss:0.00012, loss_test:0.07552, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:93.295, tt:1492.714\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:16, loss:0.00012, loss_test:0.07175, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:93.066, tt:1582.120\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:17, loss:0.00012, loss_test:0.06995, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:93.182, tt:1677.278\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:18, loss:0.00011, loss_test:0.07098, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:93.267, tt:1772.078\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:19, loss:0.00010, loss_test:0.07124, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:93.604, tt:1872.084\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:20, loss:0.00010, loss_test:0.07193, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:93.888, tt:1971.651\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:21, loss:0.00010, loss_test:0.07089, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:93.787, tt:2063.318\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:22, loss:0.00010, loss_test:0.06523, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:93.625, tt:2153.385\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:23, loss:0.00009, loss_test:0.06973, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:93.440, tt:2242.553\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:24, loss:0.00009, loss_test:0.07374, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:93.484, tt:2337.102\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:25, loss:0.00009, loss_test:0.06320, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:93.711, tt:2436.491\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:26, loss:0.00009, loss_test:0.06940, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:93.869, tt:2534.467\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:27, loss:0.00008, loss_test:0.07363, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:93.978, tt:2631.384\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:28, loss:0.00008, loss_test:0.06401, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:93.861, tt:2721.968\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:29, loss:0.00007, loss_test:0.06541, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:93.796, tt:2813.874\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:30, loss:0.00007, loss_test:0.06751, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:93.764, tt:2906.685\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:31, loss:0.00007, loss_test:0.06520, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:93.788, tt:3001.216\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:32, loss:0.00007, loss_test:0.06204, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:94.019, tt:3102.640\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:33, loss:0.00007, loss_test:0.06831, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:94.150, tt:3201.110\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:34, loss:0.00006, loss_test:0.06505, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:94.228, tt:3297.977\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:35, loss:0.00006, loss_test:0.05949, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:94.146, tt:3389.244\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:36, loss:0.00006, loss_test:0.06422, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:94.025, tt:3478.910\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:37, loss:0.00006, loss_test:0.06789, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:94.007, tt:3572.260\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:38, loss:0.00006, loss_test:0.06129, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:94.118, tt:3670.589\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:39, loss:0.00005, loss_test:0.06434, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:94.185, tt:3767.417\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:40, loss:0.00005, loss_test:0.06403, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:94.218, tt:3862.956\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:41, loss:0.00005, loss_test:0.06264, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:94.240, tt:3958.072\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:42, loss:0.00005, loss_test:0.06156, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:94.107, tt:4046.603\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:43, loss:0.00005, loss_test:0.06121, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:94.037, tt:4137.627\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:44, loss:0.00005, loss_test:0.05930, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:94.009, tt:4230.421\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:45, loss:0.00005, loss_test:0.06512, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:94.091, tt:4328.191\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:46, loss:0.00005, loss_test:0.05878, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:94.229, tt:4428.750\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:47, loss:0.00005, loss_test:0.06492, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:94.358, tt:4529.204\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:48, loss:0.00005, loss_test:0.06261, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:94.285, tt:4619.955\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:49, loss:0.00004, loss_test:0.06280, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:94.234, tt:4711.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:50, loss:0.00004, loss_test:0.06361, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:94.109, tt:4799.558\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:51, loss:0.00004, loss_test:0.06111, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:94.106, tt:4893.534\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:52, loss:0.00004, loss_test:0.06143, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:94.190, tt:4992.081\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:53, loss:0.00004, loss_test:0.05873, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:94.258, tt:5089.916\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:54, loss:0.00003, loss_test:0.06171, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:94.371, tt:5190.391\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:55, loss:0.00003, loss_test:0.05875, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:94.316, tt:5281.671\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:56, loss:0.00003, loss_test:0.05828, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:94.289, tt:5374.470\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:57, loss:0.00003, loss_test:0.06190, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:94.165, tt:5461.545\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:58, loss:0.00003, loss_test:0.05875, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:94.026, tt:5547.560\n",
      "1060\n",
      "1055\n",
      "1040\n",
      "1050\n",
      "235\n",
      "Ep:59, loss:0.00003, loss_test:0.05893, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:93.805, tt:5628.299\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:0, loss:0.00054, loss_test:0.08232, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:96.315, tt:96.315\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:1, loss:0.00029, loss_test:0.08447, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:94.406, tt:188.812\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:2, loss:0.00023, loss_test:0.08494, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:92.154, tt:276.461\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:3, loss:0.00021, loss_test:0.07896, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:91.333, tt:365.331\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:4, loss:0.00020, loss_test:0.08340, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:91.467, tt:457.336\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:5, loss:0.00019, loss_test:0.07687, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:92.632, tt:555.793\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:6, loss:0.00018, loss_test:0.07797, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:93.066, tt:651.464\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:7, loss:0.00017, loss_test:0.07707, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:93.841, tt:750.732\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:8, loss:0.00017, loss_test:0.07518, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:93.654, tt:842.887\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:9, loss:0.00016, loss_test:0.07267, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:93.328, tt:933.281\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:10, loss:0.00015, loss_test:0.07234, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:93.177, tt:1024.952\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:11, loss:0.00015, loss_test:0.07379, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:93.342, tt:1120.105\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:12, loss:0.00014, loss_test:0.06990, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:93.881, tt:1220.452\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:13, loss:0.00014, loss_test:0.07065, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:94.139, tt:1317.947\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:14, loss:0.00013, loss_test:0.06705, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:94.354, tt:1415.316\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:15, loss:0.00013, loss_test:0.06910, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:94.238, tt:1507.814\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:16, loss:0.00012, loss_test:0.06682, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:94.000, tt:1598.006\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:17, loss:0.00012, loss_test:0.06553, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:93.814, tt:1688.648\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:18, loss:0.00012, loss_test:0.06559, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:93.979, tt:1785.608\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:19, loss:0.00011, loss_test:0.06484, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:94.224, tt:1884.489\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:20, loss:0.00011, loss_test:0.06524, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:94.506, tt:1984.620\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:21, loss:0.00010, loss_test:0.06190, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:94.548, tt:2080.060\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:22, loss:0.00010, loss_test:0.06013, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:94.362, tt:2170.320\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:23, loss:0.00010, loss_test:0.06563, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:94.137, tt:2259.284\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:24, loss:0.00010, loss_test:0.06367, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:94.017, tt:2350.433\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:25, loss:0.00009, loss_test:0.05705, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:94.127, tt:2447.310\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:26, loss:0.00009, loss_test:0.06125, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:94.292, tt:2545.890\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:27, loss:0.00009, loss_test:0.06567, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:94.519, tt:2646.534\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:28, loss:0.00009, loss_test:0.05930, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:94.587, tt:2743.037\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:29, loss:0.00008, loss_test:0.05651, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:94.464, tt:2833.924\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:30, loss:0.00008, loss_test:0.05897, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:94.318, tt:2923.843\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:31, loss:0.00008, loss_test:0.05992, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:94.170, tt:3013.444\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:32, loss:0.00007, loss_test:0.05909, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:94.516, tt:3119.035\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:33, loss:0.00007, loss_test:0.05496, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:94.701, tt:3219.847\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:34, loss:0.00007, loss_test:0.05547, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:94.805, tt:3318.166\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:35, loss:0.00007, loss_test:0.05832, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:94.850, tt:3414.605\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:36, loss:0.00007, loss_test:0.05730, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:94.801, tt:3507.649\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:37, loss:0.00006, loss_test:0.05159, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:94.721, tt:3599.388\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:38, loss:0.00006, loss_test:0.05810, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:94.687, tt:3692.786\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:39, loss:0.00006, loss_test:0.05577, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:94.717, tt:3788.665\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:40, loss:0.00006, loss_test:0.05196, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:94.799, tt:3886.758\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:41, loss:0.00006, loss_test:0.05487, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:94.873, tt:3984.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:42, loss:0.00005, loss_test:0.05431, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:94.823, tt:4077.410\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:43, loss:0.00005, loss_test:0.05237, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:94.730, tt:4168.130\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:44, loss:0.00005, loss_test:0.05367, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:94.638, tt:4258.702\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:45, loss:0.00005, loss_test:0.05325, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:94.586, tt:4350.944\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:46, loss:0.00005, loss_test:0.05268, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:94.664, tt:4449.207\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:47, loss:0.00005, loss_test:0.04880, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:94.686, tt:4544.951\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:48, loss:0.00005, loss_test:0.05668, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:94.780, tt:4644.228\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:49, loss:0.00005, loss_test:0.04989, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:94.666, tt:4733.283\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:50, loss:0.00004, loss_test:0.05227, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:94.532, tt:4821.114\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:51, loss:0.00004, loss_test:0.04951, lr:9.90e-03, fs:0.89000 (r=0.899,p=0.881),  time:94.449, tt:4911.359\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:52, loss:0.00004, loss_test:0.05343, lr:9.80e-03, fs:0.91667 (r=0.889,p=0.946),  time:94.494, tt:5008.170\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:53, loss:0.00004, loss_test:0.05044, lr:9.70e-03, fs:0.91282 (r=0.899,p=0.927),  time:94.594, tt:5108.057\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:54, loss:0.00004, loss_test:0.04892, lr:9.61e-03, fs:0.89216 (r=0.919,p=0.867),  time:94.705, tt:5208.800\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:55, loss:0.00004, loss_test:0.05183, lr:9.51e-03, fs:0.91753 (r=0.899,p=0.937),  time:94.705, tt:5303.494\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:56, loss:0.00004, loss_test:0.04903, lr:9.51e-03, fs:0.91457 (r=0.919,p=0.910),  time:94.583, tt:5391.203\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:57, loss:0.00004, loss_test:0.04809, lr:9.51e-03, fs:0.90000 (r=0.909,p=0.891),  time:94.538, tt:5483.216\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:58, loss:0.00004, loss_test:0.04951, lr:9.51e-03, fs:0.91000 (r=0.919,p=0.901),  time:94.270, tt:5561.926\n",
      "1040\n",
      "1025\n",
      "1065\n",
      "1025\n",
      "285\n",
      "Ep:59, loss:0.00004, loss_test:0.04929, lr:9.51e-03, fs:0.91753 (r=0.899,p=0.937),  time:94.056, tt:5643.349\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 82\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1040\n",
      "1060\n",
      "1025\n",
      "1050\n",
      "265\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e897897f90e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_ran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"isolation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for CV out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:0, loss:0.00032, loss_test:0.09251, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:57.012, tt:57.012\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:1, loss:0.00029, loss_test:0.08646, lr:1.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:59.339, tt:118.677\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:2, loss:0.00023, loss_test:0.08886, lr:1.00e-02, fs:0.61818 (r=0.687,p=0.562),  time:58.805, tt:176.414\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:3, loss:0.00021, loss_test:0.08957, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:59.038, tt:236.150\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:4, loss:0.00020, loss_test:0.08431, lr:1.00e-02, fs:0.62009 (r=0.717,p=0.546),  time:58.787, tt:293.933\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:5, loss:0.00020, loss_test:0.08616, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:58.386, tt:350.316\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:6, loss:0.00019, loss_test:0.08550, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:58.488, tt:409.415\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:7, loss:0.00018, loss_test:0.08081, lr:1.00e-02, fs:0.64220 (r=0.707,p=0.588),  time:58.534, tt:468.275\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:8, loss:0.00017, loss_test:0.07891, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:58.699, tt:528.289\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:9, loss:0.00017, loss_test:0.07724, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:58.755, tt:587.548\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:10, loss:0.00016, loss_test:0.07496, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:58.330, tt:641.632\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:11, loss:0.00016, loss_test:0.07476, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:57.961, tt:695.526\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:12, loss:0.00015, loss_test:0.07225, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:57.696, tt:750.052\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:13, loss:0.00015, loss_test:0.07107, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:57.302, tt:802.225\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:14, loss:0.00014, loss_test:0.06977, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:57.151, tt:857.265\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:15, loss:0.00014, loss_test:0.06805, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:57.118, tt:913.891\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:16, loss:0.00014, loss_test:0.06724, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:57.017, tt:969.282\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:17, loss:0.00014, loss_test:0.06686, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:56.840, tt:1023.112\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:18, loss:0.00013, loss_test:0.06588, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:56.639, tt:1076.134\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:19, loss:0.00013, loss_test:0.06464, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:56.374, tt:1127.489\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:20, loss:0.00013, loss_test:0.06395, lr:1.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:56.280, tt:1181.889\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:21, loss:0.00012, loss_test:0.06285, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:56.120, tt:1234.630\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:22, loss:0.00012, loss_test:0.06310, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:56.155, tt:1291.568\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:23, loss:0.00012, loss_test:0.06274, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:56.126, tt:1347.013\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:24, loss:0.00011, loss_test:0.06089, lr:1.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:56.103, tt:1402.566\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:25, loss:0.00011, loss_test:0.06115, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:56.052, tt:1457.355\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:26, loss:0.00011, loss_test:0.05971, lr:1.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:55.964, tt:1511.034\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:27, loss:0.00011, loss_test:0.06111, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:55.884, tt:1564.758\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:28, loss:0.00010, loss_test:0.05895, lr:1.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:55.854, tt:1619.779\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:29, loss:0.00010, loss_test:0.05957, lr:1.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:55.817, tt:1674.521\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:30, loss:0.00010, loss_test:0.05897, lr:1.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:55.728, tt:1727.577\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:31, loss:0.00010, loss_test:0.05973, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:55.613, tt:1779.608\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:32, loss:0.00009, loss_test:0.05844, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:55.554, tt:1833.281\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:33, loss:0.00009, loss_test:0.05739, lr:1.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:55.533, tt:1888.120\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:34, loss:0.00009, loss_test:0.06009, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:55.448, tt:1940.695\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:35, loss:0.00009, loss_test:0.05745, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:55.389, tt:1993.990\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:36, loss:0.00009, loss_test:0.05960, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:55.357, tt:2048.223\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:37, loss:0.00008, loss_test:0.05687, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:55.336, tt:2102.750\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:38, loss:0.00008, loss_test:0.05874, lr:1.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:55.373, tt:2159.549\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:39, loss:0.00008, loss_test:0.05652, lr:1.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:55.382, tt:2215.296\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:40, loss:0.00008, loss_test:0.06015, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:55.328, tt:2268.451\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:41, loss:0.00007, loss_test:0.05679, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:55.305, tt:2322.810\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:42, loss:0.00008, loss_test:0.05847, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:55.313, tt:2378.476\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:43, loss:0.00007, loss_test:0.05674, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:55.312, tt:2433.749\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:44, loss:0.00007, loss_test:0.05968, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:55.283, tt:2487.725\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:45, loss:0.00007, loss_test:0.05737, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:55.253, tt:2541.624\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:46, loss:0.00007, loss_test:0.05943, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:55.213, tt:2594.991\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:47, loss:0.00007, loss_test:0.05852, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:55.184, tt:2648.826\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:48, loss:0.00007, loss_test:0.05774, lr:9.90e-03, fs:0.84615 (r=0.889,p=0.807),  time:55.161, tt:2702.881\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:49, loss:0.00007, loss_test:0.06045, lr:9.80e-03, fs:0.85149 (r=0.869,p=0.835),  time:55.123, tt:2756.164\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:50, loss:0.00006, loss_test:0.05692, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:55.103, tt:2810.235\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:51, loss:0.00006, loss_test:0.05976, lr:9.61e-03, fs:0.86700 (r=0.889,p=0.846),  time:55.057, tt:2862.957\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:52, loss:0.00006, loss_test:0.05717, lr:9.51e-03, fs:0.83019 (r=0.889,p=0.779),  time:55.043, tt:2917.278\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:53, loss:0.00006, loss_test:0.05912, lr:9.41e-03, fs:0.85572 (r=0.869,p=0.843),  time:55.022, tt:2971.171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:54, loss:0.00006, loss_test:0.05687, lr:9.32e-03, fs:0.84615 (r=0.889,p=0.807),  time:54.990, tt:3024.455\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:55, loss:0.00006, loss_test:0.05870, lr:9.23e-03, fs:0.85024 (r=0.889,p=0.815),  time:54.982, tt:3078.982\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:56, loss:0.00006, loss_test:0.05903, lr:9.14e-03, fs:0.85437 (r=0.889,p=0.822),  time:54.995, tt:3134.694\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:57, loss:0.00005, loss_test:0.05678, lr:9.04e-03, fs:0.83962 (r=0.899,p=0.788),  time:54.971, tt:3188.322\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:58, loss:0.00005, loss_test:0.05959, lr:8.95e-03, fs:0.85854 (r=0.889,p=0.830),  time:54.984, tt:3244.060\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:59, loss:0.00005, loss_test:0.05707, lr:8.86e-03, fs:0.84615 (r=0.889,p=0.807),  time:54.944, tt:3296.625\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:60, loss:0.00005, loss_test:0.05893, lr:8.78e-03, fs:0.85024 (r=0.889,p=0.815),  time:54.952, tt:3352.045\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:61, loss:0.00005, loss_test:0.05854, lr:8.69e-03, fs:0.84729 (r=0.869,p=0.827),  time:54.979, tt:3408.684\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:62, loss:0.00005, loss_test:0.05693, lr:8.60e-03, fs:0.84211 (r=0.889,p=0.800),  time:55.017, tt:3466.083\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:63, loss:0.00005, loss_test:0.05778, lr:8.51e-03, fs:0.84729 (r=0.869,p=0.827),  time:55.010, tt:3520.615\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:64, loss:0.00005, loss_test:0.05745, lr:8.43e-03, fs:0.83654 (r=0.879,p=0.798),  time:54.988, tt:3574.250\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:65, loss:0.00005, loss_test:0.05883, lr:8.35e-03, fs:0.82234 (r=0.818,p=0.827),  time:54.981, tt:3628.777\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:66, loss:0.00005, loss_test:0.05729, lr:8.26e-03, fs:0.83902 (r=0.869,p=0.811),  time:54.945, tt:3681.333\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:67, loss:0.00005, loss_test:0.05825, lr:8.18e-03, fs:0.84729 (r=0.869,p=0.827),  time:54.945, tt:3736.284\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:68, loss:0.00004, loss_test:0.05718, lr:8.10e-03, fs:0.84058 (r=0.879,p=0.806),  time:54.912, tt:3788.921\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:69, loss:0.00004, loss_test:0.05804, lr:8.02e-03, fs:0.83333 (r=0.859,p=0.810),  time:54.902, tt:3843.128\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:70, loss:0.00004, loss_test:0.05885, lr:7.94e-03, fs:0.85000 (r=0.859,p=0.842),  time:54.890, tt:3897.208\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:71, loss:0.00004, loss_test:0.05714, lr:7.86e-03, fs:0.83495 (r=0.869,p=0.804),  time:54.868, tt:3950.510\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:72, loss:0.00004, loss_test:0.05905, lr:7.78e-03, fs:0.83838 (r=0.838,p=0.838),  time:54.852, tt:4004.181\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:73, loss:0.00004, loss_test:0.05848, lr:7.70e-03, fs:0.84158 (r=0.859,p=0.825),  time:54.839, tt:4058.120\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:74, loss:0.00004, loss_test:0.05699, lr:7.62e-03, fs:0.84058 (r=0.879,p=0.806),  time:54.824, tt:4111.819\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:75, loss:0.00004, loss_test:0.05999, lr:7.55e-03, fs:0.83417 (r=0.838,p=0.830),  time:54.824, tt:4166.642\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:76, loss:0.00004, loss_test:0.05751, lr:7.47e-03, fs:0.83333 (r=0.859,p=0.810),  time:54.787, tt:4218.574\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:77, loss:0.00004, loss_test:0.05710, lr:7.40e-03, fs:0.84314 (r=0.869,p=0.819),  time:54.743, tt:4269.966\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:78, loss:0.00004, loss_test:0.05959, lr:7.32e-03, fs:0.84577 (r=0.859,p=0.833),  time:54.710, tt:4322.075\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:79, loss:0.00004, loss_test:0.05747, lr:7.25e-03, fs:0.83902 (r=0.869,p=0.811),  time:54.697, tt:4375.723\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:80, loss:0.00004, loss_test:0.05820, lr:7.18e-03, fs:0.84729 (r=0.869,p=0.827),  time:54.704, tt:4431.025\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:81, loss:0.00004, loss_test:0.05998, lr:7.11e-03, fs:0.83417 (r=0.838,p=0.830),  time:54.680, tt:4483.743\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:82, loss:0.00004, loss_test:0.05746, lr:7.03e-03, fs:0.83333 (r=0.859,p=0.810),  time:54.672, tt:4537.747\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:83, loss:0.00004, loss_test:0.05777, lr:6.96e-03, fs:0.83902 (r=0.869,p=0.811),  time:54.660, tt:4591.430\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:84, loss:0.00004, loss_test:0.05871, lr:6.89e-03, fs:0.83744 (r=0.859,p=0.817),  time:54.653, tt:4645.497\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:85, loss:0.00004, loss_test:0.05912, lr:6.83e-03, fs:0.84158 (r=0.859,p=0.825),  time:54.631, tt:4698.292\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:86, loss:0.00004, loss_test:0.05904, lr:6.76e-03, fs:0.83000 (r=0.838,p=0.822),  time:54.629, tt:4752.699\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:87, loss:0.00003, loss_test:0.05786, lr:6.69e-03, fs:0.83902 (r=0.869,p=0.811),  time:54.619, tt:4806.462\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:88, loss:0.00003, loss_test:0.05879, lr:6.62e-03, fs:0.83333 (r=0.859,p=0.810),  time:54.599, tt:4859.305\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:89, loss:0.00003, loss_test:0.05883, lr:6.56e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.586, tt:4912.751\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:90, loss:0.00003, loss_test:0.05858, lr:6.49e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.577, tt:4966.527\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:91, loss:0.00003, loss_test:0.05886, lr:6.43e-03, fs:0.84158 (r=0.859,p=0.825),  time:54.564, tt:5019.907\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:92, loss:0.00003, loss_test:0.05826, lr:6.36e-03, fs:0.83744 (r=0.859,p=0.817),  time:54.539, tt:5072.141\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:93, loss:0.00003, loss_test:0.05871, lr:6.30e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.547, tt:5127.406\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:94, loss:0.00003, loss_test:0.05827, lr:6.24e-03, fs:0.84314 (r=0.869,p=0.819),  time:54.535, tt:5180.872\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:95, loss:0.00003, loss_test:0.05839, lr:6.17e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.531, tt:5234.984\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:96, loss:0.00003, loss_test:0.05878, lr:6.11e-03, fs:0.84000 (r=0.848,p=0.832),  time:54.508, tt:5287.296\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:97, loss:0.00003, loss_test:0.05855, lr:6.05e-03, fs:0.84729 (r=0.869,p=0.827),  time:54.500, tt:5340.963\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:98, loss:0.00003, loss_test:0.05836, lr:5.99e-03, fs:0.83168 (r=0.848,p=0.816),  time:54.493, tt:5394.842\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:99, loss:0.00003, loss_test:0.05866, lr:5.93e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.483, tt:5448.292\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:100, loss:0.00003, loss_test:0.05863, lr:5.87e-03, fs:0.82000 (r=0.828,p=0.812),  time:54.485, tt:5502.975\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:101, loss:0.00003, loss_test:0.05863, lr:5.81e-03, fs:0.82412 (r=0.828,p=0.820),  time:54.487, tt:5557.695\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:102, loss:0.00003, loss_test:0.05829, lr:5.75e-03, fs:0.83168 (r=0.848,p=0.816),  time:54.486, tt:5612.047\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:103, loss:0.00003, loss_test:0.05878, lr:5.70e-03, fs:0.82412 (r=0.828,p=0.820),  time:54.479, tt:5665.838\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:104, loss:0.00003, loss_test:0.05860, lr:5.64e-03, fs:0.81218 (r=0.808,p=0.816),  time:54.484, tt:5720.769\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:105, loss:0.00003, loss_test:0.05785, lr:5.58e-03, fs:0.83168 (r=0.848,p=0.816),  time:54.472, tt:5774.012\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:106, loss:0.00003, loss_test:0.05772, lr:5.53e-03, fs:0.84158 (r=0.859,p=0.825),  time:54.475, tt:5828.835\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:107, loss:0.00003, loss_test:0.05917, lr:5.47e-03, fs:0.82412 (r=0.828,p=0.820),  time:54.481, tt:5883.958\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:108, loss:0.00003, loss_test:0.05863, lr:5.42e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.486, tt:5939.026\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:109, loss:0.00003, loss_test:0.05866, lr:5.36e-03, fs:0.81818 (r=0.818,p=0.818),  time:54.477, tt:5992.521\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:110, loss:0.00003, loss_test:0.05860, lr:5.31e-03, fs:0.82412 (r=0.828,p=0.820),  time:54.472, tt:6046.401\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:111, loss:0.00003, loss_test:0.05785, lr:5.26e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.455, tt:6098.956\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:112, loss:0.00003, loss_test:0.05843, lr:5.20e-03, fs:0.82828 (r=0.828,p=0.828),  time:54.449, tt:6152.743\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:113, loss:0.00003, loss_test:0.05890, lr:5.15e-03, fs:0.82234 (r=0.818,p=0.827),  time:54.439, tt:6206.051\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:114, loss:0.00003, loss_test:0.05839, lr:5.10e-03, fs:0.82412 (r=0.828,p=0.820),  time:54.426, tt:6258.968\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:115, loss:0.00003, loss_test:0.05784, lr:5.05e-03, fs:0.83000 (r=0.838,p=0.822),  time:54.429, tt:6313.759\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:116, loss:0.00003, loss_test:0.05839, lr:5.00e-03, fs:0.82412 (r=0.828,p=0.820),  time:54.434, tt:6368.726\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:117, loss:0.00003, loss_test:0.05862, lr:4.95e-03, fs:0.82234 (r=0.818,p=0.827),  time:54.421, tt:6421.730\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:118, loss:0.00003, loss_test:0.05753, lr:4.90e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.305, tt:6462.337\n",
      "1026\n",
      "1026\n",
      "612\n",
      "Ep:119, loss:0.00003, loss_test:0.05771, lr:4.85e-03, fs:0.83582 (r=0.848,p=0.824),  time:54.283, tt:6514.012\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:0, loss:0.00032, loss_test:0.08967, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.019, tt:48.019\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:1, loss:0.00029, loss_test:0.08099, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:50.940, tt:101.880\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:2, loss:0.00023, loss_test:0.08070, lr:1.00e-02, fs:0.65789 (r=0.758,p=0.581),  time:51.598, tt:154.794\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:3, loss:0.00021, loss_test:0.08180, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:52.032, tt:208.128\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:4, loss:0.00020, loss_test:0.07692, lr:1.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:52.417, tt:262.083\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:5, loss:0.00020, loss_test:0.07702, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:52.783, tt:316.698\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:6, loss:0.00019, loss_test:0.07610, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:53.223, tt:372.560\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:7, loss:0.00018, loss_test:0.07144, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:53.426, tt:427.406\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:8, loss:0.00018, loss_test:0.07088, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:53.393, tt:480.534\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:9, loss:0.00017, loss_test:0.07004, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:53.423, tt:534.229\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:10, loss:0.00017, loss_test:0.06737, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:53.674, tt:590.417\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:11, loss:0.00016, loss_test:0.06694, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:54.038, tt:648.451\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:12, loss:0.00015, loss_test:0.06526, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:54.081, tt:703.057\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:13, loss:0.00015, loss_test:0.06513, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:54.026, tt:756.365\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:14, loss:0.00015, loss_test:0.06502, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:53.913, tt:808.690\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:15, loss:0.00014, loss_test:0.06282, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:53.845, tt:861.527\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:16, loss:0.00014, loss_test:0.06180, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:53.877, tt:915.918\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:17, loss:0.00014, loss_test:0.06233, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:53.908, tt:970.352\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:18, loss:0.00013, loss_test:0.05941, lr:1.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:53.970, tt:1025.429\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:19, loss:0.00013, loss_test:0.06089, lr:1.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:54.107, tt:1082.140\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:20, loss:0.00013, loss_test:0.05843, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:54.380, tt:1141.979\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:21, loss:0.00012, loss_test:0.05843, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:54.628, tt:1201.810\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:22, loss:0.00012, loss_test:0.05926, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:54.864, tt:1261.863\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:23, loss:0.00012, loss_test:0.05658, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:55.021, tt:1320.504\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:24, loss:0.00011, loss_test:0.05659, lr:1.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:55.227, tt:1380.683\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:25, loss:0.00011, loss_test:0.05667, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:55.177, tt:1434.600\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:26, loss:0.00011, loss_test:0.05583, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:55.198, tt:1490.357\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:27, loss:0.00011, loss_test:0.05513, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:55.181, tt:1545.072\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:28, loss:0.00011, loss_test:0.05409, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:55.127, tt:1598.672\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:29, loss:0.00010, loss_test:0.05420, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:55.141, tt:1654.241\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:30, loss:0.00010, loss_test:0.05309, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:55.281, tt:1713.718\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:31, loss:0.00010, loss_test:0.05465, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:55.422, tt:1773.509\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:32, loss:0.00009, loss_test:0.05253, lr:1.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:55.551, tt:1833.185\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:33, loss:0.00009, loss_test:0.05423, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:55.716, tt:1894.342\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:34, loss:0.00009, loss_test:0.05190, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:55.831, tt:1954.081\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:35, loss:0.00009, loss_test:0.05199, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:55.799, tt:2008.772\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:36, loss:0.00009, loss_test:0.05099, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:55.779, tt:2063.832\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:37, loss:0.00009, loss_test:0.05098, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:55.811, tt:2120.818\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:38, loss:0.00008, loss_test:0.05026, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:55.797, tt:2176.066\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:39, loss:0.00008, loss_test:0.05052, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:55.858, tt:2234.314\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:40, loss:0.00008, loss_test:0.04936, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:55.976, tt:2295.012\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:41, loss:0.00008, loss_test:0.04933, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:56.086, tt:2355.592\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:42, loss:0.00007, loss_test:0.04815, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:56.128, tt:2413.499\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:43, loss:0.00007, loss_test:0.05111, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:56.214, tt:2473.430\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:44, loss:0.00007, loss_test:0.04753, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:56.328, tt:2534.763\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:45, loss:0.00007, loss_test:0.05137, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:56.349, tt:2592.069\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:46, loss:0.00007, loss_test:0.04672, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:56.363, tt:2649.056\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:47, loss:0.00007, loss_test:0.04949, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:56.332, tt:2703.914\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:48, loss:0.00007, loss_test:0.04674, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:56.331, tt:2760.242\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:49, loss:0.00007, loss_test:0.04845, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:56.325, tt:2816.256\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:50, loss:0.00006, loss_test:0.04726, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:56.399, tt:2876.327\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:51, loss:0.00006, loss_test:0.04773, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:56.439, tt:2934.850\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:52, loss:0.00006, loss_test:0.04634, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:56.533, tt:2996.254\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:53, loss:0.00006, loss_test:0.04735, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:56.632, tt:3058.129\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:54, loss:0.00006, loss_test:0.04611, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:56.750, tt:3121.257\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:55, loss:0.00006, loss_test:0.04607, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:56.739, tt:3177.378\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:56, loss:0.00006, loss_test:0.04749, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:56.730, tt:3233.597\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:57, loss:0.00005, loss_test:0.04620, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:56.710, tt:3289.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:58, loss:0.00005, loss_test:0.04648, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:56.726, tt:3346.845\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:59, loss:0.00005, loss_test:0.04614, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:56.781, tt:3406.835\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:60, loss:0.00005, loss_test:0.04609, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:56.842, tt:3467.341\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:61, loss:0.00005, loss_test:0.04553, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:56.898, tt:3527.702\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:62, loss:0.00005, loss_test:0.04619, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:56.953, tt:3588.025\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:63, loss:0.00005, loss_test:0.04400, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:56.982, tt:3646.841\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:64, loss:0.00005, loss_test:0.04513, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:57.012, tt:3705.785\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:65, loss:0.00005, loss_test:0.04398, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:56.972, tt:3760.132\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:66, loss:0.00005, loss_test:0.04544, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:56.914, tt:3813.259\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:67, loss:0.00004, loss_test:0.04405, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:56.876, tt:3867.542\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:68, loss:0.00004, loss_test:0.04427, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:56.838, tt:3921.850\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:69, loss:0.00004, loss_test:0.04407, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:56.857, tt:3980.023\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:70, loss:0.00004, loss_test:0.04440, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:56.902, tt:4040.042\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:71, loss:0.00004, loss_test:0.04409, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:56.922, tt:4098.417\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:72, loss:0.00004, loss_test:0.04371, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:56.931, tt:4155.960\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:73, loss:0.00004, loss_test:0.04340, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:56.942, tt:4213.739\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:74, loss:0.00004, loss_test:0.04428, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:56.973, tt:4272.947\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:75, loss:0.00004, loss_test:0.04300, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:56.922, tt:4326.102\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:76, loss:0.00004, loss_test:0.04317, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:56.872, tt:4379.173\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:77, loss:0.00004, loss_test:0.04423, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:56.846, tt:4433.977\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:78, loss:0.00004, loss_test:0.04324, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:56.832, tt:4489.759\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:79, loss:0.00004, loss_test:0.04238, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:56.848, tt:4547.867\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:80, loss:0.00004, loss_test:0.04413, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:56.866, tt:4606.135\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:81, loss:0.00003, loss_test:0.04206, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:56.919, tt:4667.346\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:82, loss:0.00003, loss_test:0.04245, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:56.971, tt:4728.617\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:83, loss:0.00003, loss_test:0.04310, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:57.005, tt:4788.446\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:84, loss:0.00003, loss_test:0.04200, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:57.024, tt:4847.042\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:85, loss:0.00003, loss_test:0.04263, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:56.997, tt:4901.757\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:86, loss:0.00003, loss_test:0.04213, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:56.961, tt:4955.584\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:87, loss:0.00003, loss_test:0.04227, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:56.940, tt:5010.728\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:88, loss:0.00003, loss_test:0.04299, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:56.911, tt:5065.051\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:89, loss:0.00003, loss_test:0.04157, lr:9.90e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.926, tt:5123.338\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:90, loss:0.00003, loss_test:0.04188, lr:9.80e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.963, tt:5183.677\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:91, loss:0.00003, loss_test:0.04169, lr:9.70e-03, fs:0.89756 (r=0.929,p=0.868),  time:57.010, tt:5244.899\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:92, loss:0.00003, loss_test:0.04179, lr:9.61e-03, fs:0.90196 (r=0.929,p=0.876),  time:57.068, tt:5307.366\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:93, loss:0.00003, loss_test:0.04209, lr:9.51e-03, fs:0.90196 (r=0.929,p=0.876),  time:57.072, tt:5364.797\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:94, loss:0.00003, loss_test:0.04189, lr:9.41e-03, fs:0.89320 (r=0.929,p=0.860),  time:57.072, tt:5421.878\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:95, loss:0.00003, loss_test:0.04167, lr:9.32e-03, fs:0.89320 (r=0.929,p=0.860),  time:57.052, tt:5476.981\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:96, loss:0.00003, loss_test:0.04138, lr:9.23e-03, fs:0.88889 (r=0.929,p=0.852),  time:57.048, tt:5533.684\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:97, loss:0.00003, loss_test:0.04175, lr:9.14e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.999, tt:5585.864\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:99, loss:0.00003, loss_test:0.04164, lr:8.95e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.995, tt:5699.517\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:100, loss:0.00003, loss_test:0.04165, lr:8.86e-03, fs:0.90196 (r=0.929,p=0.876),  time:57.014, tt:5758.425\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:101, loss:0.00002, loss_test:0.04156, lr:8.78e-03, fs:0.89756 (r=0.929,p=0.868),  time:57.046, tt:5818.681\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:102, loss:0.00002, loss_test:0.04120, lr:8.69e-03, fs:0.89320 (r=0.929,p=0.860),  time:57.070, tt:5878.217\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:103, loss:0.00003, loss_test:0.04092, lr:8.60e-03, fs:0.88889 (r=0.929,p=0.852),  time:57.085, tt:5936.867\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:104, loss:0.00002, loss_test:0.04136, lr:8.51e-03, fs:0.89320 (r=0.929,p=0.860),  time:57.033, tt:5988.459\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:105, loss:0.00002, loss_test:0.04086, lr:8.43e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.996, tt:6041.562\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:106, loss:0.00002, loss_test:0.04096, lr:8.35e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.949, tt:6093.517\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:107, loss:0.00002, loss_test:0.04098, lr:8.26e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.921, tt:6147.436\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:108, loss:0.00002, loss_test:0.04097, lr:8.18e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.885, tt:6200.518\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:109, loss:0.00002, loss_test:0.04083, lr:8.10e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.904, tt:6259.406\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:110, loss:0.00002, loss_test:0.04075, lr:8.02e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.901, tt:6316.017\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:111, loss:0.00002, loss_test:0.04062, lr:7.94e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.916, tt:6374.550\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:112, loss:0.00002, loss_test:0.04050, lr:7.86e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.925, tt:6432.468\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:113, loss:0.00002, loss_test:0.04074, lr:7.78e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.944, tt:6491.583\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:114, loss:0.00002, loss_test:0.04008, lr:7.70e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.936, tt:6547.629\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:115, loss:0.00002, loss_test:0.04088, lr:7.62e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.921, tt:6602.804\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:116, loss:0.00002, loss_test:0.04022, lr:7.55e-03, fs:0.88889 (r=0.929,p=0.852),  time:56.896, tt:6656.879\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:117, loss:0.00002, loss_test:0.04102, lr:7.47e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.844, tt:6707.646\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:118, loss:0.00002, loss_test:0.04127, lr:7.40e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.731, tt:6750.941\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1041\n",
      "567\n",
      "Ep:119, loss:0.00002, loss_test:0.03989, lr:7.40e-03, fs:0.88889 (r=0.929,p=0.852),  time:56.746, tt:6809.461\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 82\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:0, loss:0.00032, loss_test:0.09576, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:55.213, tt:55.213\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:1, loss:0.00028, loss_test:0.09172, lr:1.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:57.932, tt:115.864\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:2, loss:0.00022, loss_test:0.10250, lr:1.00e-02, fs:0.57277 (r=0.616,p=0.535),  time:58.813, tt:176.438\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:3, loss:0.00020, loss_test:0.10634, lr:1.00e-02, fs:0.52041 (r=0.515,p=0.526),  time:52.664, tt:210.655\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:4, loss:0.00020, loss_test:0.09989, lr:1.00e-02, fs:0.58447 (r=0.646,p=0.533),  time:45.410, tt:227.051\n",
      "1038\n",
      "1047\n",
      "579\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 80\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14556, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.158, tt:59.158\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14346, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.846, tt:119.692\n",
      "Ep:2, loss:0.00054, loss_test:0.13881, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:59.810, tt:179.431\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.13105, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:59.380, tt:237.521\n",
      "Ep:4, loss:0.00046, loss_test:0.12766, lr:1.00e-02, fs:0.52850 (r=0.515,p=0.543),  time:59.339, tt:296.696\n",
      "Ep:5, loss:0.00044, loss_test:0.12511, lr:1.00e-02, fs:0.57009 (r=0.616,p=0.530),  time:59.064, tt:354.384\n",
      "Ep:6, loss:0.00042, loss_test:0.12221, lr:1.00e-02, fs:0.60094 (r=0.646,p=0.561),  time:59.277, tt:414.939\n",
      "Ep:7, loss:0.00040, loss_test:0.12259, lr:1.00e-02, fs:0.62000 (r=0.626,p=0.614),  time:59.370, tt:474.957\n",
      "Ep:8, loss:0.00037, loss_test:0.11763, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:59.518, tt:535.661\n",
      "Ep:9, loss:0.00035, loss_test:0.11787, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:59.569, tt:595.694\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.11732, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:59.623, tt:655.848\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.11680, lr:1.00e-02, fs:0.68718 (r=0.677,p=0.698),  time:59.680, tt:716.161\n",
      "Ep:12, loss:0.00031, loss_test:0.11622, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:59.781, tt:777.153\n",
      "Ep:13, loss:0.00029, loss_test:0.11605, lr:1.00e-02, fs:0.69110 (r=0.667,p=0.717),  time:59.892, tt:838.492\n",
      "Ep:14, loss:0.00028, loss_test:0.11320, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:60.084, tt:901.255\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.11415, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:60.131, tt:962.092\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.11175, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:60.217, tt:1023.694\n",
      "Ep:17, loss:0.00025, loss_test:0.11206, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:60.262, tt:1084.716\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.11150, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:60.345, tt:1146.559\n",
      "Ep:19, loss:0.00024, loss_test:0.11065, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:60.360, tt:1207.206\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.11077, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:60.219, tt:1264.594\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.10920, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:60.182, tt:1324.008\n",
      "Ep:22, loss:0.00022, loss_test:0.10815, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:60.126, tt:1382.903\n",
      "Ep:23, loss:0.00021, loss_test:0.10919, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:60.126, tt:1443.018\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.10816, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:60.139, tt:1503.472\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.10888, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:60.290, tt:1567.542\n",
      "Ep:26, loss:0.00019, loss_test:0.10853, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:60.305, tt:1628.241\n",
      "Ep:27, loss:0.00018, loss_test:0.10756, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:60.337, tt:1689.440\n",
      "Ep:28, loss:0.00017, loss_test:0.10781, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:60.321, tt:1749.323\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.10627, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:60.410, tt:1812.285\n",
      "Ep:30, loss:0.00016, loss_test:0.10715, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:60.470, tt:1874.555\n",
      "Ep:31, loss:0.00016, loss_test:0.10856, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:60.514, tt:1936.437\n",
      "Ep:32, loss:0.00015, loss_test:0.10858, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:60.611, tt:2000.173\n",
      "Ep:33, loss:0.00014, loss_test:0.10560, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:60.655, tt:2062.258\n",
      "Ep:34, loss:0.00014, loss_test:0.10764, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:60.660, tt:2123.116\n",
      "Ep:35, loss:0.00013, loss_test:0.10648, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:60.654, tt:2183.547\n",
      "Ep:36, loss:0.00013, loss_test:0.10955, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:60.645, tt:2243.850\n",
      "Ep:37, loss:0.00012, loss_test:0.10687, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:60.788, tt:2309.962\n",
      "Ep:38, loss:0.00012, loss_test:0.10846, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:60.969, tt:2377.777\n",
      "Ep:39, loss:0.00012, loss_test:0.10845, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:60.852, tt:2434.084\n",
      "Ep:40, loss:0.00011, loss_test:0.10763, lr:9.90e-03, fs:0.74854 (r=0.646,p=0.889),  time:60.783, tt:2492.099\n",
      "Ep:41, loss:0.00011, loss_test:0.10892, lr:9.80e-03, fs:0.75294 (r=0.646,p=0.901),  time:60.748, tt:2551.419\n",
      "Ep:42, loss:0.00010, loss_test:0.10785, lr:9.70e-03, fs:0.74854 (r=0.646,p=0.889),  time:60.718, tt:2610.888\n",
      "Ep:43, loss:0.00010, loss_test:0.11035, lr:9.61e-03, fs:0.75740 (r=0.646,p=0.914),  time:60.649, tt:2668.541\n",
      "Ep:44, loss:0.00010, loss_test:0.10800, lr:9.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:60.606, tt:2727.252\n",
      "Ep:45, loss:0.00009, loss_test:0.11120, lr:9.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:60.561, tt:2785.820\n",
      "Ep:46, loss:0.00009, loss_test:0.11050, lr:9.32e-03, fs:0.75294 (r=0.646,p=0.901),  time:60.510, tt:2843.951\n",
      "Ep:47, loss:0.00009, loss_test:0.11205, lr:9.23e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.453, tt:2901.730\n",
      "Ep:48, loss:0.00009, loss_test:0.11028, lr:9.14e-03, fs:0.75740 (r=0.646,p=0.914),  time:60.346, tt:2956.949\n",
      "Ep:49, loss:0.00008, loss_test:0.11025, lr:9.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:60.309, tt:3015.460\n",
      "Ep:50, loss:0.00008, loss_test:0.10943, lr:8.95e-03, fs:0.74854 (r=0.646,p=0.889),  time:60.371, tt:3078.917\n",
      "Ep:51, loss:0.00008, loss_test:0.11202, lr:8.86e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.338, tt:3137.573\n",
      "Ep:52, loss:0.00008, loss_test:0.11376, lr:8.78e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.355, tt:3198.841\n",
      "Ep:53, loss:0.00007, loss_test:0.11442, lr:8.69e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.355, tt:3259.160\n",
      "Ep:54, loss:0.00007, loss_test:0.11218, lr:8.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.431, tt:3323.731\n",
      "Ep:55, loss:0.00007, loss_test:0.10994, lr:8.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:60.441, tt:3384.689\n",
      "Ep:56, loss:0.00007, loss_test:0.11176, lr:8.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.461, tt:3446.281\n",
      "Ep:57, loss:0.00006, loss_test:0.11231, lr:8.35e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.516, tt:3509.928\n",
      "Ep:58, loss:0.00006, loss_test:0.11068, lr:8.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.609, tt:3575.931\n",
      "Ep:59, loss:0.00006, loss_test:0.11027, lr:8.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.620, tt:3637.182\n",
      "Ep:60, loss:0.00006, loss_test:0.11125, lr:8.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.682, tt:3701.621\n",
      "Ep:61, loss:0.00005, loss_test:0.11232, lr:8.02e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.732, tt:3765.369\n",
      "Ep:62, loss:0.00005, loss_test:0.11212, lr:7.94e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.744, tt:3826.868\n",
      "Ep:63, loss:0.00005, loss_test:0.11084, lr:7.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.743, tt:3887.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00005, loss_test:0.11038, lr:7.78e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.720, tt:3946.815\n",
      "Ep:65, loss:0.00005, loss_test:0.11126, lr:7.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.714, tt:4007.127\n",
      "Ep:66, loss:0.00005, loss_test:0.11170, lr:7.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.687, tt:4066.047\n",
      "Ep:67, loss:0.00005, loss_test:0.10965, lr:7.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.682, tt:4126.398\n",
      "Ep:68, loss:0.00005, loss_test:0.11344, lr:7.47e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.717, tt:4189.477\n",
      "Ep:69, loss:0.00004, loss_test:0.11163, lr:7.40e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.713, tt:4249.909\n",
      "Ep:70, loss:0.00004, loss_test:0.11173, lr:7.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.760, tt:4313.936\n",
      "Ep:71, loss:0.00004, loss_test:0.11187, lr:7.25e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.762, tt:4374.868\n",
      "Ep:72, loss:0.00004, loss_test:0.11177, lr:7.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.777, tt:4436.708\n",
      "Ep:73, loss:0.00004, loss_test:0.11103, lr:7.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.775, tt:4497.328\n",
      "Ep:74, loss:0.00004, loss_test:0.11141, lr:7.03e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.769, tt:4557.682\n",
      "Ep:75, loss:0.00004, loss_test:0.11249, lr:6.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.768, tt:4618.381\n",
      "Ep:76, loss:0.00004, loss_test:0.11234, lr:6.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.735, tt:4676.612\n",
      "Ep:77, loss:0.00004, loss_test:0.11189, lr:6.83e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.732, tt:4737.064\n",
      "Ep:78, loss:0.00004, loss_test:0.11308, lr:6.76e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.731, tt:4797.751\n",
      "Ep:79, loss:0.00004, loss_test:0.11091, lr:6.69e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.717, tt:4857.354\n",
      "Ep:80, loss:0.00004, loss_test:0.11106, lr:6.62e-03, fs:0.75740 (r=0.646,p=0.914),  time:60.746, tt:4920.434\n",
      "Ep:81, loss:0.00004, loss_test:0.11184, lr:6.56e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.742, tt:4980.817\n",
      "Ep:82, loss:0.00003, loss_test:0.11336, lr:6.49e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.728, tt:5040.432\n",
      "Ep:83, loss:0.00003, loss_test:0.11269, lr:6.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.726, tt:5101.023\n",
      "Ep:84, loss:0.00003, loss_test:0.11258, lr:6.36e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.743, tt:5163.114\n",
      "Ep:85, loss:0.00003, loss_test:0.11256, lr:6.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.722, tt:5222.125\n",
      "Ep:86, loss:0.00003, loss_test:0.11320, lr:6.24e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.726, tt:5283.165\n",
      "Ep:87, loss:0.00003, loss_test:0.11191, lr:6.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.716, tt:5343.005\n",
      "Ep:88, loss:0.00003, loss_test:0.11143, lr:6.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.703, tt:5402.597\n",
      "Ep:89, loss:0.00003, loss_test:0.11270, lr:6.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.727, tt:5465.396\n",
      "Ep:90, loss:0.00003, loss_test:0.11323, lr:5.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.710, tt:5524.651\n",
      "Ep:91, loss:0.00003, loss_test:0.11286, lr:5.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.746, tt:5588.675\n",
      "Ep:92, loss:0.00003, loss_test:0.11231, lr:5.87e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.733, tt:5648.183\n",
      "Ep:93, loss:0.00003, loss_test:0.11279, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.726, tt:5708.286\n",
      "Ep:94, loss:0.00003, loss_test:0.11205, lr:5.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.757, tt:5771.901\n",
      "Ep:95, loss:0.00003, loss_test:0.11255, lr:5.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.756, tt:5832.556\n",
      "Ep:96, loss:0.00003, loss_test:0.11207, lr:5.64e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.753, tt:5893.062\n",
      "Ep:97, loss:0.00003, loss_test:0.11295, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.749, tt:5953.405\n",
      "Ep:98, loss:0.00003, loss_test:0.11215, lr:5.53e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.742, tt:6013.409\n",
      "Ep:99, loss:0.00003, loss_test:0.11335, lr:5.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.742, tt:6074.231\n",
      "Ep:100, loss:0.00003, loss_test:0.11330, lr:5.42e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.736, tt:6134.366\n",
      "Ep:101, loss:0.00003, loss_test:0.11320, lr:5.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.745, tt:6195.958\n",
      "Ep:102, loss:0.00003, loss_test:0.11271, lr:5.31e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.721, tt:6254.301\n",
      "Ep:103, loss:0.00003, loss_test:0.11279, lr:5.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.731, tt:6316.068\n",
      "Ep:104, loss:0.00002, loss_test:0.11239, lr:5.20e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.715, tt:6375.090\n",
      "Ep:105, loss:0.00002, loss_test:0.11301, lr:5.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.702, tt:6434.462\n",
      "Ep:106, loss:0.00002, loss_test:0.11299, lr:5.10e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.701, tt:6495.017\n",
      "Ep:107, loss:0.00002, loss_test:0.11341, lr:5.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.697, tt:6555.265\n",
      "Ep:108, loss:0.00002, loss_test:0.11345, lr:5.00e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.694, tt:6615.692\n",
      "Ep:109, loss:0.00002, loss_test:0.11360, lr:4.95e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.675, tt:6674.232\n",
      "Ep:110, loss:0.00002, loss_test:0.11303, lr:4.90e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.664, tt:6733.658\n",
      "Ep:111, loss:0.00002, loss_test:0.11335, lr:4.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.661, tt:6794.078\n",
      "Ep:112, loss:0.00002, loss_test:0.11357, lr:4.80e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.665, tt:6855.130\n",
      "Ep:113, loss:0.00002, loss_test:0.11366, lr:4.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.661, tt:6915.300\n",
      "Ep:114, loss:0.00002, loss_test:0.11365, lr:4.71e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.660, tt:6975.955\n",
      "Ep:115, loss:0.00002, loss_test:0.11336, lr:4.66e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.655, tt:7035.933\n",
      "Ep:116, loss:0.00002, loss_test:0.11339, lr:4.61e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.672, tt:7098.644\n",
      "Ep:117, loss:0.00002, loss_test:0.11343, lr:4.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.668, tt:7158.788\n",
      "Ep:118, loss:0.00002, loss_test:0.11357, lr:4.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.671, tt:7219.891\n",
      "Ep:119, loss:0.00002, loss_test:0.11322, lr:4.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.664, tt:7279.737\n",
      "Ep:120, loss:0.00002, loss_test:0.11360, lr:4.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.654, tt:7339.109\n",
      "Ep:121, loss:0.00002, loss_test:0.11326, lr:4.39e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.667, tt:7401.344\n",
      "Ep:122, loss:0.00002, loss_test:0.11365, lr:4.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.653, tt:7460.363\n",
      "Ep:123, loss:0.00002, loss_test:0.11403, lr:4.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.643, tt:7519.685\n",
      "Ep:124, loss:0.00002, loss_test:0.11466, lr:4.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.644, tt:7580.498\n",
      "Ep:125, loss:0.00002, loss_test:0.11369, lr:4.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.638, tt:7640.382\n",
      "Ep:126, loss:0.00002, loss_test:0.11408, lr:4.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.626, tt:7699.461\n",
      "Ep:127, loss:0.00002, loss_test:0.11411, lr:4.13e-03, fs:0.76190 (r=0.646,p=0.928),  time:60.623, tt:7759.724\n",
      "Ep:128, loss:0.00002, loss_test:0.11372, lr:4.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.624, tt:7820.442\n",
      "Ep:129, loss:0.00002, loss_test:0.11349, lr:4.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.615, tt:7880.001\n",
      "Ep:130, loss:0.00002, loss_test:0.11392, lr:4.01e-03, fs:0.77108 (r=0.646,p=0.955),  time:60.631, tt:7942.680\n",
      "Ep:131, loss:0.00002, loss_test:0.11438, lr:3.97e-03, fs:0.77108 (r=0.646,p=0.955),  time:60.660, tt:8007.128\n",
      "Ep:132, loss:0.00002, loss_test:0.11378, lr:3.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.684, tt:8070.907\n",
      "Ep:133, loss:0.00002, loss_test:0.11433, lr:3.89e-03, fs:0.77108 (r=0.646,p=0.955),  time:60.684, tt:8131.650\n",
      "Ep:134, loss:0.00002, loss_test:0.11443, lr:3.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.684, tt:8192.353\n",
      "Ep:135, loss:0.00002, loss_test:0.11408, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.683, tt:8252.872\n",
      "Ep:136, loss:0.00002, loss_test:0.11421, lr:3.77e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.662, tt:8310.635\n",
      "Ep:137, loss:0.00002, loss_test:0.11380, lr:3.73e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.653, tt:8370.151\n",
      "Ep:138, loss:0.00002, loss_test:0.11477, lr:3.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.654, tt:8430.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00002, loss_test:0.11417, lr:3.66e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.662, tt:8492.700\n",
      "Ep:140, loss:0.00002, loss_test:0.11412, lr:3.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.674, tt:8555.012\n",
      "Ep:141, loss:0.00002, loss_test:0.11518, lr:3.59e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.695, tt:8618.687\n",
      "Ep:142, loss:0.00002, loss_test:0.11452, lr:3.55e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.703, tt:8680.534\n",
      "Ep:143, loss:0.00002, loss_test:0.11425, lr:3.52e-03, fs:0.77108 (r=0.646,p=0.955),  time:60.714, tt:8742.817\n",
      "Ep:144, loss:0.00002, loss_test:0.11429, lr:3.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.714, tt:8803.532\n",
      "Ep:145, loss:0.00002, loss_test:0.11527, lr:3.45e-03, fs:0.77108 (r=0.646,p=0.955),  time:60.730, tt:8866.556\n",
      "Ep:146, loss:0.00002, loss_test:0.11471, lr:3.41e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.757, tt:8931.243\n",
      "Ep:147, loss:0.00002, loss_test:0.11445, lr:3.38e-03, fs:0.77108 (r=0.646,p=0.955),  time:60.717, tt:8986.130\n",
      "Ep:148, loss:0.00002, loss_test:0.11457, lr:3.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.670, tt:9039.778\n",
      "Ep:149, loss:0.00002, loss_test:0.11450, lr:3.31e-03, fs:0.76647 (r=0.646,p=0.941),  time:60.675, tt:9101.263\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 81\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.13848, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.280, tt:59.280\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.13507, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:60.987, tt:121.974\n",
      "Ep:2, loss:0.00055, loss_test:0.12807, lr:1.00e-02, fs:0.68512 (r=1.000,p=0.521),  time:62.274, tt:186.821\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.11505, lr:1.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:62.910, tt:251.641\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.10563, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:62.760, tt:313.800\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.10286, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:63.003, tt:378.017\n",
      "Ep:6, loss:0.00044, loss_test:0.09923, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:63.085, tt:441.593\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.09508, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:63.199, tt:505.591\n",
      "Ep:8, loss:0.00040, loss_test:0.09197, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:63.145, tt:568.307\n",
      "Ep:9, loss:0.00038, loss_test:0.08844, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:63.041, tt:630.413\n",
      "Ep:10, loss:0.00036, loss_test:0.08703, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:63.087, tt:693.960\n",
      "Ep:11, loss:0.00035, loss_test:0.08487, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:63.080, tt:756.958\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00033, loss_test:0.08379, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:63.393, tt:824.113\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.08117, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:63.272, tt:885.802\n",
      "Ep:14, loss:0.00031, loss_test:0.08047, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:63.290, tt:949.355\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.07862, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:63.361, tt:1013.773\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00029, loss_test:0.07692, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:63.511, tt:1079.688\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00028, loss_test:0.07655, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:63.585, tt:1144.533\n",
      "Ep:18, loss:0.00027, loss_test:0.07450, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:63.746, tt:1211.178\n",
      "Ep:19, loss:0.00026, loss_test:0.07467, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:63.718, tt:1274.369\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00025, loss_test:0.07240, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:63.761, tt:1338.983\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00024, loss_test:0.07141, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:63.820, tt:1404.047\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.07146, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:63.974, tt:1471.408\n",
      "Ep:23, loss:0.00022, loss_test:0.06977, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:64.106, tt:1538.535\n",
      "Ep:24, loss:0.00021, loss_test:0.06905, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:64.097, tt:1602.422\n",
      "Ep:25, loss:0.00020, loss_test:0.06954, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:64.218, tt:1669.661\n",
      "Ep:26, loss:0.00019, loss_test:0.06766, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:64.284, tt:1735.663\n",
      "Ep:27, loss:0.00018, loss_test:0.06834, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:64.171, tt:1796.782\n",
      "Ep:28, loss:0.00018, loss_test:0.06848, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:64.168, tt:1860.885\n",
      "Ep:29, loss:0.00017, loss_test:0.06768, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:64.202, tt:1926.060\n",
      "Ep:30, loss:0.00016, loss_test:0.06628, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:64.257, tt:1991.958\n",
      "Ep:31, loss:0.00015, loss_test:0.06999, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:64.213, tt:2054.822\n",
      "Ep:32, loss:0.00015, loss_test:0.06696, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:64.188, tt:2118.205\n",
      "Ep:33, loss:0.00014, loss_test:0.06725, lr:9.90e-03, fs:0.84153 (r=0.778,p=0.917),  time:64.160, tt:2181.440\n",
      "Ep:34, loss:0.00013, loss_test:0.06752, lr:9.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:64.165, tt:2245.759\n",
      "Ep:35, loss:0.00013, loss_test:0.06769, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:64.143, tt:2309.158\n",
      "Ep:36, loss:0.00012, loss_test:0.06674, lr:9.61e-03, fs:0.83978 (r=0.768,p=0.927),  time:64.171, tt:2374.342\n",
      "Ep:37, loss:0.00011, loss_test:0.06784, lr:9.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:64.151, tt:2437.756\n",
      "Ep:38, loss:0.00011, loss_test:0.06935, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:64.116, tt:2500.527\n",
      "Ep:39, loss:0.00010, loss_test:0.06595, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:64.110, tt:2564.395\n",
      "Ep:40, loss:0.00010, loss_test:0.06870, lr:9.23e-03, fs:0.82873 (r=0.758,p=0.915),  time:64.126, tt:2629.183\n",
      "Ep:41, loss:0.00010, loss_test:0.06750, lr:9.14e-03, fs:0.83333 (r=0.758,p=0.926),  time:64.103, tt:2692.318\n",
      "Ep:42, loss:0.00009, loss_test:0.06528, lr:9.04e-03, fs:0.82873 (r=0.758,p=0.915),  time:64.064, tt:2754.768\n",
      "Ep:43, loss:0.00009, loss_test:0.06667, lr:8.95e-03, fs:0.83146 (r=0.747,p=0.937),  time:64.061, tt:2818.695\n",
      "Ep:44, loss:0.00008, loss_test:0.06745, lr:8.86e-03, fs:0.82682 (r=0.747,p=0.925),  time:64.050, tt:2882.242\n",
      "Ep:45, loss:0.00008, loss_test:0.06434, lr:8.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:64.068, tt:2947.113\n",
      "Ep:46, loss:0.00008, loss_test:0.06641, lr:8.69e-03, fs:0.82682 (r=0.747,p=0.925),  time:64.105, tt:3012.956\n",
      "Ep:47, loss:0.00007, loss_test:0.06853, lr:8.60e-03, fs:0.81609 (r=0.717,p=0.947),  time:64.111, tt:3077.325\n",
      "Ep:48, loss:0.00007, loss_test:0.06591, lr:8.51e-03, fs:0.82682 (r=0.747,p=0.925),  time:64.103, tt:3141.061\n",
      "Ep:49, loss:0.00007, loss_test:0.06546, lr:8.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:64.070, tt:3203.480\n",
      "Ep:50, loss:0.00007, loss_test:0.06669, lr:8.35e-03, fs:0.83616 (r=0.747,p=0.949),  time:64.096, tt:3268.912\n",
      "Ep:51, loss:0.00006, loss_test:0.06517, lr:8.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:64.097, tt:3333.044\n",
      "Ep:52, loss:0.00006, loss_test:0.06571, lr:8.18e-03, fs:0.84270 (r=0.758,p=0.949),  time:64.097, tt:3397.119\n",
      "Ep:53, loss:0.00006, loss_test:0.06568, lr:8.10e-03, fs:0.83146 (r=0.747,p=0.937),  time:64.102, tt:3461.506\n",
      "Ep:54, loss:0.00006, loss_test:0.06487, lr:8.02e-03, fs:0.83616 (r=0.747,p=0.949),  time:64.116, tt:3526.372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00006, loss_test:0.06569, lr:7.94e-03, fs:0.83616 (r=0.747,p=0.949),  time:64.143, tt:3592.035\n",
      "Ep:56, loss:0.00005, loss_test:0.06542, lr:7.86e-03, fs:0.83616 (r=0.747,p=0.949),  time:64.136, tt:3655.758\n",
      "Ep:57, loss:0.00005, loss_test:0.06568, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:64.131, tt:3719.626\n",
      "Ep:58, loss:0.00005, loss_test:0.06445, lr:7.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:64.135, tt:3783.957\n",
      "Ep:59, loss:0.00005, loss_test:0.06553, lr:7.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:64.158, tt:3849.476\n",
      "Ep:60, loss:0.00005, loss_test:0.06499, lr:7.55e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.144, tt:3912.762\n",
      "Ep:61, loss:0.00005, loss_test:0.06481, lr:7.47e-03, fs:0.83616 (r=0.747,p=0.949),  time:64.146, tt:3977.054\n",
      "Ep:62, loss:0.00005, loss_test:0.06454, lr:7.40e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.146, tt:4041.172\n",
      "Ep:63, loss:0.00004, loss_test:0.06506, lr:7.32e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.154, tt:4105.855\n",
      "Ep:64, loss:0.00004, loss_test:0.06511, lr:7.25e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.186, tt:4172.102\n",
      "Ep:65, loss:0.00004, loss_test:0.06548, lr:7.18e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.184, tt:4236.116\n",
      "Ep:66, loss:0.00004, loss_test:0.06551, lr:7.11e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.193, tt:4300.939\n",
      "Ep:67, loss:0.00004, loss_test:0.06506, lr:7.03e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.204, tt:4365.857\n",
      "Ep:68, loss:0.00004, loss_test:0.06571, lr:6.96e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.185, tt:4428.764\n",
      "Ep:69, loss:0.00004, loss_test:0.06595, lr:6.89e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.185, tt:4492.935\n",
      "Ep:70, loss:0.00004, loss_test:0.06569, lr:6.83e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.203, tt:4558.381\n",
      "Ep:71, loss:0.00004, loss_test:0.06718, lr:6.76e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.203, tt:4622.629\n",
      "Ep:72, loss:0.00004, loss_test:0.06606, lr:6.69e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.176, tt:4684.868\n",
      "Ep:73, loss:0.00004, loss_test:0.06767, lr:6.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:64.227, tt:4752.783\n",
      "Ep:74, loss:0.00003, loss_test:0.06670, lr:6.56e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.206, tt:4815.480\n",
      "Ep:75, loss:0.00003, loss_test:0.06555, lr:6.49e-03, fs:0.82022 (r=0.737,p=0.924),  time:64.214, tt:4880.235\n",
      "Ep:76, loss:0.00003, loss_test:0.06916, lr:6.43e-03, fs:0.81871 (r=0.707,p=0.972),  time:64.177, tt:4941.654\n",
      "Ep:77, loss:0.00003, loss_test:0.06746, lr:6.36e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.170, tt:5005.288\n",
      "Ep:78, loss:0.00003, loss_test:0.06712, lr:6.30e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.179, tt:5070.119\n",
      "Ep:79, loss:0.00003, loss_test:0.06968, lr:6.24e-03, fs:0.81871 (r=0.707,p=0.972),  time:64.182, tt:5134.534\n",
      "Ep:80, loss:0.00003, loss_test:0.06567, lr:6.17e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.163, tt:5197.197\n",
      "Ep:81, loss:0.00003, loss_test:0.06912, lr:6.11e-03, fs:0.82353 (r=0.707,p=0.986),  time:64.175, tt:5262.361\n",
      "Ep:82, loss:0.00003, loss_test:0.07023, lr:6.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:64.157, tt:5325.064\n",
      "Ep:83, loss:0.00003, loss_test:0.06630, lr:5.99e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.138, tt:5387.559\n",
      "Ep:84, loss:0.00003, loss_test:0.07055, lr:5.93e-03, fs:0.81176 (r=0.697,p=0.972),  time:64.154, tt:5453.058\n",
      "Ep:85, loss:0.00003, loss_test:0.06737, lr:5.87e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.129, tt:5515.105\n",
      "Ep:86, loss:0.00003, loss_test:0.06815, lr:5.81e-03, fs:0.83237 (r=0.727,p=0.973),  time:64.140, tt:5580.208\n",
      "Ep:87, loss:0.00003, loss_test:0.06872, lr:5.75e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.138, tt:5644.127\n",
      "Ep:88, loss:0.00003, loss_test:0.06777, lr:5.70e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.135, tt:5708.054\n",
      "Ep:89, loss:0.00003, loss_test:0.06866, lr:5.64e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.114, tt:5770.249\n",
      "Ep:90, loss:0.00002, loss_test:0.06935, lr:5.58e-03, fs:0.81176 (r=0.697,p=0.972),  time:64.106, tt:5833.665\n",
      "Ep:91, loss:0.00002, loss_test:0.06769, lr:5.53e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.088, tt:5896.100\n",
      "Ep:92, loss:0.00002, loss_test:0.06885, lr:5.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:64.063, tt:5957.836\n",
      "Ep:93, loss:0.00002, loss_test:0.06897, lr:5.42e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.056, tt:6021.271\n",
      "Ep:94, loss:0.00002, loss_test:0.06846, lr:5.36e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.037, tt:6083.546\n",
      "Ep:95, loss:0.00002, loss_test:0.06883, lr:5.31e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.044, tt:6148.224\n",
      "Ep:96, loss:0.00002, loss_test:0.06808, lr:5.26e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.049, tt:6212.787\n",
      "Ep:97, loss:0.00002, loss_test:0.06923, lr:5.20e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.006, tt:6272.574\n",
      "Ep:98, loss:0.00002, loss_test:0.06875, lr:5.15e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.009, tt:6336.912\n",
      "Ep:99, loss:0.00002, loss_test:0.06822, lr:5.10e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.985, tt:6398.516\n",
      "Ep:100, loss:0.00002, loss_test:0.06934, lr:5.05e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.984, tt:6462.419\n",
      "Ep:101, loss:0.00002, loss_test:0.06851, lr:5.00e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.980, tt:6525.990\n",
      "Ep:102, loss:0.00002, loss_test:0.06963, lr:4.95e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.985, tt:6590.417\n",
      "Ep:103, loss:0.00002, loss_test:0.06814, lr:4.90e-03, fs:0.83908 (r=0.737,p=0.973),  time:63.974, tt:6653.312\n",
      "Ep:104, loss:0.00002, loss_test:0.07040, lr:4.85e-03, fs:0.82353 (r=0.707,p=0.986),  time:63.957, tt:6715.460\n",
      "Ep:105, loss:0.00002, loss_test:0.06960, lr:4.80e-03, fs:0.82558 (r=0.717,p=0.973),  time:63.956, tt:6779.387\n",
      "Ep:106, loss:0.00002, loss_test:0.06916, lr:4.75e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.947, tt:6842.375\n",
      "Ep:107, loss:0.00002, loss_test:0.07138, lr:4.71e-03, fs:0.82840 (r=0.707,p=1.000),  time:63.938, tt:6905.297\n",
      "Ep:108, loss:0.00002, loss_test:0.06843, lr:4.66e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.923, tt:6967.573\n",
      "Ep:109, loss:0.00002, loss_test:0.07108, lr:4.61e-03, fs:0.82353 (r=0.707,p=0.986),  time:63.915, tt:7030.600\n",
      "Ep:110, loss:0.00002, loss_test:0.06878, lr:4.57e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.907, tt:7093.643\n",
      "Ep:111, loss:0.00002, loss_test:0.07129, lr:4.52e-03, fs:0.82353 (r=0.707,p=0.986),  time:63.888, tt:7155.414\n",
      "Ep:112, loss:0.00002, loss_test:0.06943, lr:4.48e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.862, tt:7216.421\n",
      "Ep:113, loss:0.00002, loss_test:0.07019, lr:4.43e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.846, tt:7278.455\n",
      "Ep:114, loss:0.00002, loss_test:0.06967, lr:4.39e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.838, tt:7341.390\n",
      "Ep:115, loss:0.00002, loss_test:0.07022, lr:4.34e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.810, tt:7401.930\n",
      "Ep:116, loss:0.00002, loss_test:0.06949, lr:4.30e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.802, tt:7464.888\n",
      "Ep:117, loss:0.00002, loss_test:0.07017, lr:4.26e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.787, tt:7526.918\n",
      "Ep:118, loss:0.00002, loss_test:0.07031, lr:4.21e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.773, tt:7588.957\n",
      "Ep:119, loss:0.00002, loss_test:0.06978, lr:4.17e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.762, tt:7651.412\n",
      "Ep:120, loss:0.00002, loss_test:0.07097, lr:4.13e-03, fs:0.81871 (r=0.707,p=0.972),  time:63.750, tt:7713.727\n",
      "Ep:121, loss:0.00002, loss_test:0.06975, lr:4.09e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.741, tt:7776.394\n",
      "Ep:122, loss:0.00002, loss_test:0.07037, lr:4.05e-03, fs:0.82353 (r=0.707,p=0.986),  time:63.720, tt:7837.561\n",
      "Ep:123, loss:0.00002, loss_test:0.06958, lr:4.01e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.700, tt:7898.752\n",
      "Ep:124, loss:0.00002, loss_test:0.07061, lr:3.97e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.684, tt:7960.543\n",
      "Ep:125, loss:0.00002, loss_test:0.07016, lr:3.93e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.658, tt:8020.922\n",
      "Ep:126, loss:0.00002, loss_test:0.07064, lr:3.89e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.662, tt:8085.102\n",
      "Ep:127, loss:0.00002, loss_test:0.06952, lr:3.85e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.647, tt:8146.856\n",
      "Ep:128, loss:0.00002, loss_test:0.07119, lr:3.81e-03, fs:0.82353 (r=0.707,p=0.986),  time:63.636, tt:8209.052\n",
      "Ep:129, loss:0.00002, loss_test:0.06957, lr:3.77e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.638, tt:8272.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.07107, lr:3.73e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.620, tt:8334.203\n",
      "Ep:131, loss:0.00002, loss_test:0.06999, lr:3.70e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.594, tt:8394.387\n",
      "Ep:132, loss:0.00001, loss_test:0.07128, lr:3.66e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.597, tt:8458.459\n",
      "Ep:133, loss:0.00001, loss_test:0.06984, lr:3.62e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.586, tt:8520.485\n",
      "Ep:134, loss:0.00001, loss_test:0.07093, lr:3.59e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.569, tt:8581.784\n",
      "Ep:135, loss:0.00001, loss_test:0.06991, lr:3.55e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.555, tt:8643.434\n",
      "Ep:136, loss:0.00001, loss_test:0.07068, lr:3.52e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.544, tt:8705.497\n",
      "Ep:137, loss:0.00001, loss_test:0.07009, lr:3.48e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.513, tt:8764.804\n",
      "Ep:138, loss:0.00001, loss_test:0.07091, lr:3.45e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.492, tt:8825.429\n",
      "Ep:139, loss:0.00001, loss_test:0.07001, lr:3.41e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.484, tt:8887.694\n",
      "Ep:140, loss:0.00001, loss_test:0.07102, lr:3.38e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.448, tt:8946.134\n",
      "Ep:141, loss:0.00001, loss_test:0.07018, lr:3.34e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.414, tt:9004.805\n",
      "Ep:142, loss:0.00001, loss_test:0.07129, lr:3.31e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.388, tt:9064.503\n",
      "Ep:143, loss:0.00001, loss_test:0.07048, lr:3.28e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.378, tt:9126.458\n",
      "Ep:144, loss:0.00001, loss_test:0.07051, lr:3.24e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.366, tt:9188.096\n",
      "Ep:145, loss:0.00001, loss_test:0.07048, lr:3.21e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.353, tt:9249.503\n",
      "Ep:146, loss:0.00001, loss_test:0.07091, lr:3.18e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.325, tt:9308.750\n",
      "Ep:147, loss:0.00001, loss_test:0.07048, lr:3.15e-03, fs:0.84393 (r=0.737,p=0.986),  time:63.322, tt:9371.688\n",
      "Ep:148, loss:0.00001, loss_test:0.07078, lr:3.12e-03, fs:0.83721 (r=0.727,p=0.986),  time:63.259, tt:9425.617\n",
      "Ep:149, loss:0.00001, loss_test:0.07138, lr:3.09e-03, fs:0.82353 (r=0.707,p=0.986),  time:63.231, tt:9484.632\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 82\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14359, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.704, tt:52.704\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14121, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:55.931, tt:111.862\n",
      "Ep:2, loss:0.00055, loss_test:0.13624, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:58.281, tt:174.842\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.12459, lr:1.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:59.616, tt:238.465\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.11653, lr:1.00e-02, fs:0.65421 (r=0.707,p=0.609),  time:60.442, tt:302.209\n",
      "Ep:5, loss:0.00046, loss_test:0.11599, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:60.578, tt:363.467\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.11220, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:60.906, tt:426.340\n",
      "Ep:7, loss:0.00041, loss_test:0.10879, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:61.124, tt:488.990\n",
      "Ep:8, loss:0.00039, loss_test:0.10568, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:61.351, tt:552.157\n",
      "Ep:9, loss:0.00037, loss_test:0.10354, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:61.382, tt:613.825\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.10155, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:61.371, tt:675.083\n",
      "Ep:11, loss:0.00034, loss_test:0.10024, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:61.610, tt:739.317\n",
      "Ep:12, loss:0.00033, loss_test:0.09917, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:62.016, tt:806.209\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.09811, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:62.140, tt:869.954\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.09801, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:62.289, tt:934.339\n",
      "Ep:15, loss:0.00029, loss_test:0.09724, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:62.350, tt:997.604\n",
      "Ep:16, loss:0.00028, loss_test:0.09533, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:62.785, tt:1067.342\n",
      "Ep:17, loss:0.00027, loss_test:0.09557, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:62.862, tt:1131.512\n",
      "Ep:18, loss:0.00026, loss_test:0.09511, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:62.985, tt:1196.719\n",
      "Ep:19, loss:0.00025, loss_test:0.09354, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:63.010, tt:1260.205\n",
      "Ep:20, loss:0.00024, loss_test:0.09322, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:63.034, tt:1323.716\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.09293, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:63.128, tt:1388.814\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.09320, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:63.082, tt:1450.888\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00022, loss_test:0.09160, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:63.066, tt:1513.574\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.09100, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:63.079, tt:1576.975\n",
      "Ep:25, loss:0.00020, loss_test:0.08884, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:63.078, tt:1640.030\n",
      "Ep:26, loss:0.00019, loss_test:0.09238, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:63.038, tt:1702.033\n",
      "Ep:27, loss:0.00018, loss_test:0.08817, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:62.983, tt:1763.537\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.09206, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:63.024, tt:1827.708\n",
      "Ep:29, loss:0.00017, loss_test:0.08963, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:62.996, tt:1889.890\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.08967, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:63.008, tt:1953.259\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.08827, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:62.976, tt:2015.236\n",
      "Ep:32, loss:0.00015, loss_test:0.08542, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:63.043, tt:2080.435\n",
      "Ep:33, loss:0.00014, loss_test:0.08647, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:63.047, tt:2143.614\n",
      "Ep:34, loss:0.00014, loss_test:0.08470, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:63.112, tt:2208.937\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.08550, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:63.185, tt:2274.654\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.08431, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:63.230, tt:2339.527\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.08566, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:63.277, tt:2404.519\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.08365, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:63.313, tt:2469.204\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08532, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:63.333, tt:2533.328\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08514, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:63.361, tt:2597.809\n",
      "Ep:41, loss:0.00010, loss_test:0.08353, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.357, tt:2660.991\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.08090, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.327, tt:2723.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:43, loss:0.00009, loss_test:0.07939, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.311, tt:2785.703\n",
      "Ep:44, loss:0.00009, loss_test:0.08195, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:63.351, tt:2850.815\n",
      "Ep:45, loss:0.00008, loss_test:0.07873, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:63.353, tt:2914.246\n",
      "Ep:46, loss:0.00008, loss_test:0.07862, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.366, tt:2978.194\n",
      "Ep:47, loss:0.00008, loss_test:0.07929, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.330, tt:3039.833\n",
      "Ep:48, loss:0.00007, loss_test:0.07674, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:63.319, tt:3102.624\n",
      "Ep:49, loss:0.00007, loss_test:0.08166, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:63.329, tt:3166.435\n",
      "Ep:50, loss:0.00007, loss_test:0.07849, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:63.370, tt:3231.849\n",
      "Ep:51, loss:0.00006, loss_test:0.07642, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.347, tt:3294.023\n",
      "Ep:52, loss:0.00006, loss_test:0.07714, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:63.309, tt:3355.383\n",
      "Ep:53, loss:0.00006, loss_test:0.07527, lr:9.90e-03, fs:0.80000 (r=0.727,p=0.889),  time:63.240, tt:3414.948\n",
      "Ep:54, loss:0.00006, loss_test:0.07460, lr:9.80e-03, fs:0.80000 (r=0.727,p=0.889),  time:63.157, tt:3473.635\n",
      "Ep:55, loss:0.00005, loss_test:0.07613, lr:9.70e-03, fs:0.79558 (r=0.727,p=0.878),  time:63.093, tt:3533.227\n",
      "Ep:56, loss:0.00005, loss_test:0.07456, lr:9.61e-03, fs:0.80000 (r=0.727,p=0.889),  time:63.057, tt:3594.238\n",
      "Ep:57, loss:0.00005, loss_test:0.07518, lr:9.51e-03, fs:0.79558 (r=0.727,p=0.878),  time:63.046, tt:3656.649\n",
      "Ep:58, loss:0.00005, loss_test:0.07607, lr:9.41e-03, fs:0.79558 (r=0.727,p=0.878),  time:63.017, tt:3717.996\n",
      "Ep:59, loss:0.00005, loss_test:0.07554, lr:9.32e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.989, tt:3779.331\n",
      "Ep:60, loss:0.00005, loss_test:0.07496, lr:9.23e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.961, tt:3840.626\n",
      "Ep:61, loss:0.00005, loss_test:0.07756, lr:9.14e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.953, tt:3903.065\n",
      "Ep:62, loss:0.00004, loss_test:0.07625, lr:9.04e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.941, tt:3965.281\n",
      "Ep:63, loss:0.00004, loss_test:0.07746, lr:8.95e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.924, tt:4027.144\n",
      "Ep:64, loss:0.00004, loss_test:0.07774, lr:8.86e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.860, tt:4085.912\n",
      "Ep:65, loss:0.00004, loss_test:0.07758, lr:8.78e-03, fs:0.76136 (r=0.677,p=0.870),  time:62.813, tt:4145.674\n",
      "Ep:66, loss:0.00004, loss_test:0.07458, lr:8.69e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.800, tt:4207.569\n",
      "Ep:67, loss:0.00004, loss_test:0.07438, lr:8.60e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.802, tt:4270.564\n",
      "Ep:68, loss:0.00004, loss_test:0.07340, lr:8.51e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.804, tt:4333.499\n",
      "Ep:69, loss:0.00004, loss_test:0.07407, lr:8.43e-03, fs:0.80000 (r=0.727,p=0.889),  time:62.796, tt:4395.747\n",
      "Ep:70, loss:0.00004, loss_test:0.07482, lr:8.35e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.769, tt:4456.615\n",
      "Ep:71, loss:0.00004, loss_test:0.07761, lr:8.26e-03, fs:0.78212 (r=0.707,p=0.875),  time:62.769, tt:4519.385\n",
      "Ep:72, loss:0.00004, loss_test:0.08009, lr:8.18e-03, fs:0.74419 (r=0.646,p=0.877),  time:62.756, tt:4581.160\n",
      "Ep:73, loss:0.00003, loss_test:0.08089, lr:8.10e-03, fs:0.75862 (r=0.667,p=0.880),  time:62.742, tt:4642.927\n",
      "Ep:74, loss:0.00003, loss_test:0.07986, lr:8.02e-03, fs:0.74419 (r=0.646,p=0.877),  time:62.755, tt:4706.634\n",
      "Ep:75, loss:0.00003, loss_test:0.07896, lr:7.94e-03, fs:0.76301 (r=0.667,p=0.892),  time:62.767, tt:4770.329\n",
      "Ep:76, loss:0.00003, loss_test:0.07562, lr:7.86e-03, fs:0.80000 (r=0.727,p=0.889),  time:62.748, tt:4831.564\n",
      "Ep:77, loss:0.00003, loss_test:0.07623, lr:7.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:62.758, tt:4895.108\n",
      "Ep:78, loss:0.00003, loss_test:0.07699, lr:7.70e-03, fs:0.75145 (r=0.657,p=0.878),  time:62.759, tt:4957.968\n",
      "Ep:79, loss:0.00003, loss_test:0.07702, lr:7.62e-03, fs:0.79558 (r=0.727,p=0.878),  time:62.767, tt:5021.370\n",
      "Ep:80, loss:0.00003, loss_test:0.07589, lr:7.55e-03, fs:0.76571 (r=0.677,p=0.882),  time:62.748, tt:5082.557\n",
      "Ep:81, loss:0.00003, loss_test:0.07470, lr:7.47e-03, fs:0.80000 (r=0.727,p=0.889),  time:62.727, tt:5143.624\n",
      "Ep:82, loss:0.00003, loss_test:0.07778, lr:7.40e-03, fs:0.76301 (r=0.667,p=0.892),  time:62.728, tt:5206.443\n",
      "Ep:83, loss:0.00003, loss_test:0.07790, lr:7.32e-03, fs:0.75581 (r=0.657,p=0.890),  time:62.723, tt:5268.738\n",
      "Ep:84, loss:0.00003, loss_test:0.07782, lr:7.25e-03, fs:0.76301 (r=0.667,p=0.892),  time:62.699, tt:5329.422\n",
      "Ep:85, loss:0.00003, loss_test:0.07864, lr:7.18e-03, fs:0.75581 (r=0.657,p=0.890),  time:62.680, tt:5390.510\n",
      "Ep:86, loss:0.00003, loss_test:0.07725, lr:7.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.688, tt:5453.841\n",
      "Ep:87, loss:0.00003, loss_test:0.07781, lr:7.03e-03, fs:0.75581 (r=0.657,p=0.890),  time:62.669, tt:5514.872\n",
      "Ep:88, loss:0.00002, loss_test:0.07706, lr:6.96e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.672, tt:5577.774\n",
      "Ep:89, loss:0.00002, loss_test:0.07843, lr:6.89e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.681, tt:5641.294\n",
      "Ep:90, loss:0.00002, loss_test:0.08105, lr:6.83e-03, fs:0.74854 (r=0.646,p=0.889),  time:62.706, tt:5706.221\n",
      "Ep:91, loss:0.00002, loss_test:0.07903, lr:6.76e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.713, tt:5769.613\n",
      "Ep:92, loss:0.00002, loss_test:0.07697, lr:6.69e-03, fs:0.77647 (r=0.667,p=0.930),  time:62.712, tt:5832.248\n",
      "Ep:93, loss:0.00002, loss_test:0.07754, lr:6.62e-03, fs:0.77647 (r=0.667,p=0.930),  time:62.714, tt:5895.119\n",
      "Ep:94, loss:0.00002, loss_test:0.08048, lr:6.56e-03, fs:0.74854 (r=0.646,p=0.889),  time:62.721, tt:5958.494\n",
      "Ep:95, loss:0.00002, loss_test:0.08219, lr:6.49e-03, fs:0.74854 (r=0.646,p=0.889),  time:62.721, tt:6021.225\n",
      "Ep:96, loss:0.00002, loss_test:0.07910, lr:6.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.709, tt:6082.815\n",
      "Ep:97, loss:0.00002, loss_test:0.07863, lr:6.36e-03, fs:0.77647 (r=0.667,p=0.930),  time:62.721, tt:6146.655\n",
      "Ep:98, loss:0.00002, loss_test:0.08081, lr:6.30e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.698, tt:6207.118\n",
      "Ep:99, loss:0.00002, loss_test:0.08116, lr:6.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.690, tt:6269.026\n",
      "Ep:100, loss:0.00002, loss_test:0.07794, lr:6.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.705, tt:6333.199\n",
      "Ep:101, loss:0.00002, loss_test:0.08020, lr:6.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.709, tt:6396.368\n",
      "Ep:102, loss:0.00002, loss_test:0.08057, lr:6.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.687, tt:6456.796\n",
      "Ep:103, loss:0.00002, loss_test:0.08005, lr:5.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.673, tt:6518.040\n",
      "Ep:104, loss:0.00002, loss_test:0.07916, lr:5.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.687, tt:6582.182\n",
      "Ep:105, loss:0.00002, loss_test:0.08190, lr:5.87e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.668, tt:6642.781\n",
      "Ep:106, loss:0.00002, loss_test:0.08096, lr:5.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.652, tt:6703.760\n",
      "Ep:107, loss:0.00002, loss_test:0.08013, lr:5.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.654, tt:6766.615\n",
      "Ep:108, loss:0.00002, loss_test:0.08175, lr:5.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.644, tt:6828.222\n",
      "Ep:109, loss:0.00002, loss_test:0.08015, lr:5.64e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.643, tt:6890.700\n",
      "Ep:110, loss:0.00002, loss_test:0.08122, lr:5.58e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.659, tt:6955.103\n",
      "Ep:111, loss:0.00002, loss_test:0.08101, lr:5.53e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.661, tt:7018.006\n",
      "Ep:112, loss:0.00002, loss_test:0.08146, lr:5.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.656, tt:7080.121\n",
      "Ep:113, loss:0.00002, loss_test:0.08146, lr:5.42e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.673, tt:7144.765\n",
      "Ep:114, loss:0.00002, loss_test:0.08129, lr:5.36e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.674, tt:7207.558\n",
      "Ep:115, loss:0.00002, loss_test:0.08257, lr:5.31e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.666, tt:7269.298\n",
      "Ep:116, loss:0.00002, loss_test:0.08122, lr:5.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.676, tt:7333.120\n",
      "Ep:117, loss:0.00002, loss_test:0.08215, lr:5.20e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.695, tt:7397.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:118, loss:0.00002, loss_test:0.08187, lr:5.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.710, tt:7462.519\n",
      "Ep:119, loss:0.00002, loss_test:0.08156, lr:5.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.705, tt:7524.611\n",
      "Ep:120, loss:0.00002, loss_test:0.08188, lr:5.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:62.716, tt:7588.637\n",
      "Ep:121, loss:0.00002, loss_test:0.08305, lr:5.00e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.726, tt:7652.572\n",
      "Ep:122, loss:0.00002, loss_test:0.08173, lr:4.95e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.749, tt:7718.071\n",
      "Ep:123, loss:0.00001, loss_test:0.08251, lr:4.90e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.754, tt:7781.438\n",
      "Ep:124, loss:0.00001, loss_test:0.08245, lr:4.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.747, tt:7843.429\n",
      "Ep:125, loss:0.00001, loss_test:0.08203, lr:4.80e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.747, tt:7906.081\n",
      "Ep:126, loss:0.00001, loss_test:0.08304, lr:4.75e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.739, tt:7967.880\n",
      "Ep:127, loss:0.00001, loss_test:0.08366, lr:4.71e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.744, tt:8031.290\n",
      "Ep:128, loss:0.00001, loss_test:0.08283, lr:4.66e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.737, tt:8093.013\n",
      "Ep:129, loss:0.00001, loss_test:0.08253, lr:4.61e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.724, tt:8154.140\n",
      "Ep:130, loss:0.00001, loss_test:0.08241, lr:4.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.742, tt:8219.263\n",
      "Ep:131, loss:0.00001, loss_test:0.08280, lr:4.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.746, tt:8282.455\n",
      "Ep:132, loss:0.00001, loss_test:0.08301, lr:4.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.743, tt:8344.881\n",
      "Ep:133, loss:0.00001, loss_test:0.08347, lr:4.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.763, tt:8410.232\n",
      "Ep:134, loss:0.00001, loss_test:0.08336, lr:4.39e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.740, tt:8469.847\n",
      "Ep:135, loss:0.00001, loss_test:0.08280, lr:4.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.730, tt:8531.311\n",
      "Ep:136, loss:0.00001, loss_test:0.08409, lr:4.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.744, tt:8595.969\n",
      "Ep:137, loss:0.00001, loss_test:0.08326, lr:4.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.779, tt:8663.461\n",
      "Ep:138, loss:0.00001, loss_test:0.08366, lr:4.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.817, tt:8731.529\n",
      "Ep:139, loss:0.00001, loss_test:0.08434, lr:4.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.843, tt:8798.068\n",
      "Ep:140, loss:0.00001, loss_test:0.08421, lr:4.13e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.858, tt:8862.918\n",
      "Ep:141, loss:0.00001, loss_test:0.08294, lr:4.09e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.868, tt:8927.270\n",
      "Ep:142, loss:0.00001, loss_test:0.08421, lr:4.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.886, tt:8992.629\n",
      "Ep:143, loss:0.00001, loss_test:0.08369, lr:4.01e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.905, tt:9058.313\n",
      "Ep:144, loss:0.00001, loss_test:0.08272, lr:3.97e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.939, tt:9126.204\n",
      "Ep:145, loss:0.00001, loss_test:0.08527, lr:3.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.958, tt:9191.893\n",
      "Ep:146, loss:0.00001, loss_test:0.08272, lr:3.89e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.944, tt:9252.796\n",
      "Ep:147, loss:0.00001, loss_test:0.08324, lr:3.85e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.966, tt:9318.995\n",
      "Ep:148, loss:0.00001, loss_test:0.08504, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:62.964, tt:9381.626\n",
      "Ep:149, loss:0.00001, loss_test:0.08250, lr:3.77e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.918, tt:9437.737\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 83\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14294, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:60.596, tt:60.596\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14067, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.515, tt:117.030\n",
      "Ep:2, loss:0.00055, loss_test:0.13604, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:60.737, tt:182.210\n",
      "Ep:3, loss:0.00053, loss_test:0.12636, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:62.191, tt:248.766\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.11253, lr:1.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:62.524, tt:312.619\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.10832, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:63.031, tt:378.189\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.10484, lr:1.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:63.908, tt:447.358\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.10103, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:64.310, tt:514.480\n",
      "Ep:8, loss:0.00040, loss_test:0.09886, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:64.279, tt:578.511\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00038, loss_test:0.09684, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:64.411, tt:644.113\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00037, loss_test:0.09521, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:64.258, tt:706.838\n",
      "Ep:11, loss:0.00035, loss_test:0.09350, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:64.142, tt:769.710\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.09133, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:63.727, tt:828.449\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.08992, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:63.723, tt:892.126\n",
      "Ep:14, loss:0.00031, loss_test:0.08769, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:63.510, tt:952.649\n",
      "Ep:15, loss:0.00030, loss_test:0.08812, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:63.353, tt:1013.652\n",
      "Ep:16, loss:0.00029, loss_test:0.08604, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:63.267, tt:1075.546\n",
      "Ep:17, loss:0.00028, loss_test:0.08444, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:63.286, tt:1139.146\n",
      "Ep:18, loss:0.00026, loss_test:0.08644, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:63.327, tt:1203.209\n",
      "Ep:19, loss:0.00025, loss_test:0.08388, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:63.198, tt:1263.968\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.08377, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:63.271, tt:1328.688\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.08153, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:63.354, tt:1393.790\n",
      "Ep:22, loss:0.00023, loss_test:0.08329, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:63.404, tt:1458.281\n",
      "Ep:23, loss:0.00022, loss_test:0.08177, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:63.437, tt:1522.489\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.07958, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:63.444, tt:1586.094\n",
      "Ep:25, loss:0.00020, loss_test:0.08273, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:63.545, tt:1652.183\n",
      "Ep:26, loss:0.00019, loss_test:0.08116, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:63.536, tt:1715.473\n",
      "Ep:27, loss:0.00019, loss_test:0.07945, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:63.597, tt:1780.722\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.08027, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:63.692, tt:1847.063\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.08081, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:63.731, tt:1911.932\n",
      "Ep:30, loss:0.00016, loss_test:0.07963, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:63.731, tt:1975.659\n",
      "Ep:31, loss:0.00016, loss_test:0.08181, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:63.742, tt:2039.733\n",
      "Ep:32, loss:0.00015, loss_test:0.07712, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:63.758, tt:2104.009\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00014, loss_test:0.07815, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:63.766, tt:2168.056\n",
      "Ep:34, loss:0.00014, loss_test:0.07834, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:63.813, tt:2233.439\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.07908, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:63.827, tt:2297.755\n",
      "Ep:36, loss:0.00013, loss_test:0.07837, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:63.808, tt:2360.882\n",
      "Ep:37, loss:0.00012, loss_test:0.08081, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:63.837, tt:2425.817\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.07658, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:63.822, tt:2489.056\n",
      "Ep:39, loss:0.00011, loss_test:0.07322, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:63.839, tt:2553.564\n",
      "Ep:40, loss:0.00010, loss_test:0.07879, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:63.846, tt:2617.704\n",
      "Ep:41, loss:0.00010, loss_test:0.07672, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:63.848, tt:2681.636\n",
      "Ep:42, loss:0.00009, loss_test:0.07633, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:63.865, tt:2746.197\n",
      "Ep:43, loss:0.00009, loss_test:0.07535, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:63.882, tt:2810.828\n",
      "Ep:44, loss:0.00009, loss_test:0.07862, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:63.945, tt:2877.532\n",
      "Ep:45, loss:0.00008, loss_test:0.07770, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:63.931, tt:2940.842\n",
      "Ep:46, loss:0.00008, loss_test:0.07202, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:63.959, tt:3006.073\n",
      "Ep:47, loss:0.00008, loss_test:0.07138, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:64.023, tt:3073.100\n",
      "Ep:48, loss:0.00007, loss_test:0.07286, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:64.033, tt:3137.611\n",
      "Ep:49, loss:0.00007, loss_test:0.07482, lr:9.90e-03, fs:0.86170 (r=0.818,p=0.910),  time:64.044, tt:3202.223\n",
      "Ep:50, loss:0.00007, loss_test:0.07378, lr:9.80e-03, fs:0.85561 (r=0.808,p=0.909),  time:64.104, tt:3269.321\n",
      "Ep:51, loss:0.00006, loss_test:0.07550, lr:9.70e-03, fs:0.86170 (r=0.818,p=0.910),  time:64.129, tt:3334.704\n",
      "Ep:52, loss:0.00006, loss_test:0.07374, lr:9.61e-03, fs:0.86486 (r=0.808,p=0.930),  time:64.167, tt:3400.871\n",
      "Ep:53, loss:0.00006, loss_test:0.07069, lr:9.51e-03, fs:0.86022 (r=0.808,p=0.920),  time:64.212, tt:3467.465\n",
      "Ep:54, loss:0.00006, loss_test:0.07330, lr:9.41e-03, fs:0.86486 (r=0.808,p=0.930),  time:64.259, tt:3534.240\n",
      "Ep:55, loss:0.00006, loss_test:0.07421, lr:9.32e-03, fs:0.86957 (r=0.808,p=0.941),  time:64.292, tt:3600.351\n",
      "Ep:56, loss:0.00005, loss_test:0.07389, lr:9.23e-03, fs:0.86022 (r=0.808,p=0.920),  time:64.317, tt:3666.094\n",
      "Ep:57, loss:0.00005, loss_test:0.07243, lr:9.14e-03, fs:0.86486 (r=0.808,p=0.930),  time:64.327, tt:3730.941\n",
      "Ep:58, loss:0.00005, loss_test:0.07218, lr:9.04e-03, fs:0.87234 (r=0.828,p=0.921),  time:64.355, tt:3796.924\n",
      "Ep:59, loss:0.00005, loss_test:0.07450, lr:8.95e-03, fs:0.86631 (r=0.818,p=0.920),  time:64.402, tt:3864.143\n",
      "Ep:60, loss:0.00005, loss_test:0.07386, lr:8.86e-03, fs:0.87293 (r=0.798,p=0.963),  time:64.451, tt:3931.510\n",
      "Ep:61, loss:0.00005, loss_test:0.06864, lr:8.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:64.472, tt:3997.282\n",
      "Ep:62, loss:0.00005, loss_test:0.07279, lr:8.69e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.488, tt:4062.741\n",
      "Ep:63, loss:0.00004, loss_test:0.07085, lr:8.60e-03, fs:0.86957 (r=0.808,p=0.941),  time:64.524, tt:4129.540\n",
      "Ep:64, loss:0.00004, loss_test:0.07103, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:64.537, tt:4194.931\n",
      "Ep:65, loss:0.00004, loss_test:0.07085, lr:8.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.558, tt:4260.835\n",
      "Ep:66, loss:0.00004, loss_test:0.07212, lr:8.35e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.598, tt:4328.062\n",
      "Ep:67, loss:0.00004, loss_test:0.07237, lr:8.26e-03, fs:0.86022 (r=0.808,p=0.920),  time:64.570, tt:4390.794\n",
      "Ep:68, loss:0.00004, loss_test:0.07204, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.608, tt:4457.941\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.07167, lr:8.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.639, tt:4524.713\n",
      "Ep:70, loss:0.00004, loss_test:0.07181, lr:8.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.698, tt:4593.548\n",
      "Ep:71, loss:0.00003, loss_test:0.07460, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.712, tt:4659.251\n",
      "Ep:72, loss:0.00003, loss_test:0.07353, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.703, tt:4723.290\n",
      "Ep:73, loss:0.00003, loss_test:0.07431, lr:8.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.726, tt:4789.746\n",
      "Ep:74, loss:0.00003, loss_test:0.07399, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.738, tt:4855.329\n",
      "Ep:75, loss:0.00003, loss_test:0.07255, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.757, tt:4921.548\n",
      "Ep:76, loss:0.00003, loss_test:0.07262, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.771, tt:4987.342\n",
      "Ep:77, loss:0.00003, loss_test:0.07358, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.777, tt:5052.642\n",
      "Ep:78, loss:0.00003, loss_test:0.07444, lr:8.18e-03, fs:0.87293 (r=0.798,p=0.963),  time:64.790, tt:5118.429\n",
      "Ep:79, loss:0.00003, loss_test:0.07517, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.780, tt:5182.423\n",
      "Ep:80, loss:0.00003, loss_test:0.07330, lr:8.10e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.774, tt:5246.700\n",
      "Ep:81, loss:0.00003, loss_test:0.07497, lr:8.02e-03, fs:0.86034 (r=0.778,p=0.963),  time:64.762, tt:5310.471\n",
      "Ep:82, loss:0.00003, loss_test:0.07553, lr:7.94e-03, fs:0.86517 (r=0.778,p=0.975),  time:64.770, tt:5375.927\n",
      "Ep:83, loss:0.00002, loss_test:0.07374, lr:7.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.803, tt:5443.433\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.07462, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:64.810, tt:5508.856\n",
      "Ep:85, loss:0.00002, loss_test:0.07339, lr:7.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.843, tt:5576.467\n",
      "Ep:86, loss:0.00002, loss_test:0.07428, lr:7.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.852, tt:5642.158\n",
      "Ep:87, loss:0.00002, loss_test:0.07376, lr:7.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.860, tt:5707.681\n",
      "Ep:88, loss:0.00002, loss_test:0.07817, lr:7.86e-03, fs:0.81176 (r=0.697,p=0.972),  time:64.895, tt:5775.637\n",
      "Ep:89, loss:0.00002, loss_test:0.07301, lr:7.86e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.873, tt:5838.611\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.07496, lr:7.86e-03, fs:0.87006 (r=0.778,p=0.987),  time:64.873, tt:5903.413\n",
      "Ep:91, loss:0.00002, loss_test:0.07359, lr:7.86e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.877, tt:5968.660\n",
      "Ep:92, loss:0.00002, loss_test:0.07540, lr:7.86e-03, fs:0.86517 (r=0.778,p=0.975),  time:64.878, tt:6033.619\n",
      "Ep:93, loss:0.00002, loss_test:0.07598, lr:7.86e-03, fs:0.87006 (r=0.778,p=0.987),  time:64.857, tt:6096.544\n",
      "Ep:94, loss:0.00002, loss_test:0.07296, lr:7.86e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.860, tt:6161.674\n",
      "Ep:95, loss:0.00002, loss_test:0.07415, lr:7.86e-03, fs:0.88268 (r=0.798,p=0.988),  time:64.866, tt:6227.110\n",
      "Ep:96, loss:0.00002, loss_test:0.07511, lr:7.86e-03, fs:0.86207 (r=0.758,p=1.000),  time:64.871, tt:6292.451\n",
      "Ep:97, loss:0.00002, loss_test:0.07484, lr:7.86e-03, fs:0.85714 (r=0.758,p=0.987),  time:64.885, tt:6358.758\n",
      "Ep:98, loss:0.00002, loss_test:0.07252, lr:7.86e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.872, tt:6422.353\n",
      "Ep:99, loss:0.00002, loss_test:0.07606, lr:7.86e-03, fs:0.83041 (r=0.717,p=0.986),  time:64.875, tt:6487.488\n",
      "Ep:100, loss:0.00002, loss_test:0.07649, lr:7.86e-03, fs:0.85714 (r=0.758,p=0.987),  time:64.879, tt:6552.775\n",
      "Ep:101, loss:0.00002, loss_test:0.07381, lr:7.78e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.849, tt:6614.578\n",
      "Ep:102, loss:0.00002, loss_test:0.07363, lr:7.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.856, tt:6680.145\n",
      "Ep:103, loss:0.00002, loss_test:0.07452, lr:7.62e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.848, tt:6744.176\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.07314, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.853, tt:6809.551\n",
      "Ep:105, loss:0.00002, loss_test:0.07265, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.839, tt:6872.959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00002, loss_test:0.07498, lr:7.62e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.823, tt:6936.070\n",
      "Ep:107, loss:0.00001, loss_test:0.07438, lr:7.62e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.847, tt:7003.434\n",
      "Ep:108, loss:0.00001, loss_test:0.07425, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.844, tt:7067.977\n",
      "Ep:109, loss:0.00001, loss_test:0.07492, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.874, tt:7136.180\n",
      "Ep:110, loss:0.00001, loss_test:0.07295, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.843, tt:7197.571\n",
      "Ep:111, loss:0.00001, loss_test:0.07446, lr:7.62e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.847, tt:7262.878\n",
      "Ep:112, loss:0.00001, loss_test:0.07406, lr:7.62e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.868, tt:7330.089\n",
      "Ep:113, loss:0.00001, loss_test:0.07407, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.852, tt:7393.184\n",
      "Ep:114, loss:0.00001, loss_test:0.07433, lr:7.62e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.862, tt:7459.088\n",
      "Ep:115, loss:0.00001, loss_test:0.07475, lr:7.55e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.886, tt:7526.759\n",
      "Ep:116, loss:0.00001, loss_test:0.07550, lr:7.47e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.897, tt:7592.977\n",
      "Ep:117, loss:0.00001, loss_test:0.07391, lr:7.40e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.879, tt:7655.670\n",
      "Ep:118, loss:0.00001, loss_test:0.07475, lr:7.32e-03, fs:0.88136 (r=0.788,p=1.000),  time:64.886, tt:7721.480\n",
      "Ep:119, loss:0.00001, loss_test:0.07308, lr:7.25e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.885, tt:7786.166\n",
      "Ep:120, loss:0.00001, loss_test:0.07421, lr:7.18e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.900, tt:7852.941\n",
      "Ep:121, loss:0.00001, loss_test:0.07513, lr:7.11e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.915, tt:7919.606\n",
      "Ep:122, loss:0.00001, loss_test:0.07324, lr:7.03e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.912, tt:7984.200\n",
      "Ep:123, loss:0.00001, loss_test:0.07473, lr:6.96e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.910, tt:8048.874\n",
      "Ep:124, loss:0.00001, loss_test:0.07277, lr:6.89e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.908, tt:8113.504\n",
      "Ep:125, loss:0.00001, loss_test:0.07421, lr:6.83e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.917, tt:8179.598\n",
      "Ep:126, loss:0.00001, loss_test:0.07500, lr:6.76e-03, fs:0.88889 (r=0.808,p=0.988),  time:64.905, tt:8242.951\n",
      "Ep:127, loss:0.00001, loss_test:0.07531, lr:6.69e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.904, tt:8307.653\n",
      "Ep:128, loss:0.00001, loss_test:0.07364, lr:6.62e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.901, tt:8372.252\n",
      "Ep:129, loss:0.00001, loss_test:0.07409, lr:6.56e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.886, tt:8435.192\n",
      "Ep:130, loss:0.00001, loss_test:0.07265, lr:6.49e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.886, tt:8500.103\n",
      "Ep:131, loss:0.00001, loss_test:0.07513, lr:6.43e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.877, tt:8563.770\n",
      "Ep:132, loss:0.00001, loss_test:0.07425, lr:6.36e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.861, tt:8626.465\n",
      "Ep:133, loss:0.00001, loss_test:0.07364, lr:6.30e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.839, tt:8688.400\n",
      "Ep:135, loss:0.00001, loss_test:0.07267, lr:6.17e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.825, tt:8816.182\n",
      "Ep:136, loss:0.00001, loss_test:0.07431, lr:6.11e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.807, tt:8878.588\n",
      "Ep:137, loss:0.00001, loss_test:0.07439, lr:6.05e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.791, tt:8941.099\n",
      "Ep:138, loss:0.00001, loss_test:0.07377, lr:5.99e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.771, tt:9003.238\n",
      "Ep:139, loss:0.00001, loss_test:0.07445, lr:5.93e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.760, tt:9066.333\n",
      "Ep:140, loss:0.00001, loss_test:0.07354, lr:5.87e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.742, tt:9128.624\n",
      "Ep:141, loss:0.00001, loss_test:0.07377, lr:5.81e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.740, tt:9193.010\n",
      "Ep:142, loss:0.00001, loss_test:0.07449, lr:5.75e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.723, tt:9255.433\n",
      "Ep:143, loss:0.00001, loss_test:0.07462, lr:5.70e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.721, tt:9319.816\n",
      "Ep:144, loss:0.00001, loss_test:0.07436, lr:5.64e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.704, tt:9382.105\n",
      "Ep:145, loss:0.00001, loss_test:0.07396, lr:5.58e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.681, tt:9443.460\n",
      "Ep:147, loss:0.00001, loss_test:0.07380, lr:5.47e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.635, tt:9565.995\n",
      "Ep:148, loss:0.00001, loss_test:0.07444, lr:5.42e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.602, tt:9625.639\n",
      "Ep:149, loss:0.00001, loss_test:0.07373, lr:5.36e-03, fs:0.89385 (r=0.808,p=1.000),  time:64.527, tt:9679.045\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 84\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14375, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.188, tt:62.188\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14180, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.767, tt:117.534\n",
      "Ep:2, loss:0.00055, loss_test:0.13787, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:60.226, tt:180.677\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.13046, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:60.838, tt:243.352\n",
      "Ep:4, loss:0.00049, loss_test:0.12075, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:61.895, tt:309.476\n",
      "Ep:5, loss:0.00046, loss_test:0.11892, lr:1.00e-02, fs:0.63000 (r=0.636,p=0.624),  time:62.659, tt:375.955\n",
      "Ep:6, loss:0.00044, loss_test:0.11531, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:62.609, tt:438.265\n",
      "Ep:7, loss:0.00041, loss_test:0.11402, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:62.759, tt:502.072\n",
      "Ep:8, loss:0.00039, loss_test:0.11112, lr:1.00e-02, fs:0.67005 (r=0.667,p=0.673),  time:62.651, tt:563.862\n",
      "Ep:9, loss:0.00037, loss_test:0.11011, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:62.668, tt:626.677\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00036, loss_test:0.10973, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:62.830, tt:691.130\n",
      "Ep:11, loss:0.00034, loss_test:0.10750, lr:1.00e-02, fs:0.70466 (r=0.687,p=0.723),  time:62.634, tt:751.605\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00033, loss_test:0.10766, lr:1.00e-02, fs:0.67391 (r=0.626,p=0.729),  time:62.491, tt:812.389\n",
      "Ep:13, loss:0.00032, loss_test:0.10561, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:62.528, tt:875.396\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.10725, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:62.717, tt:940.748\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.10566, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:62.763, tt:1004.200\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.10575, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:62.796, tt:1067.538\n",
      "Ep:17, loss:0.00027, loss_test:0.10475, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:62.925, tt:1132.642\n",
      "Ep:18, loss:0.00026, loss_test:0.10607, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:62.893, tt:1194.975\n",
      "Ep:19, loss:0.00025, loss_test:0.10349, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:62.893, tt:1257.867\n",
      "Ep:20, loss:0.00024, loss_test:0.10478, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:62.824, tt:1319.309\n",
      "Ep:21, loss:0.00023, loss_test:0.10322, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:62.881, tt:1383.375\n",
      "Ep:22, loss:0.00022, loss_test:0.10410, lr:1.00e-02, fs:0.69274 (r=0.626,p=0.775),  time:62.888, tt:1446.435\n",
      "Ep:23, loss:0.00022, loss_test:0.10333, lr:1.00e-02, fs:0.69318 (r=0.616,p=0.792),  time:62.826, tt:1507.822\n",
      "Ep:24, loss:0.00021, loss_test:0.10475, lr:1.00e-02, fs:0.67836 (r=0.586,p=0.806),  time:62.775, tt:1569.386\n",
      "Ep:25, loss:0.00020, loss_test:0.10505, lr:1.00e-02, fs:0.71508 (r=0.646,p=0.800),  time:62.789, tt:1632.510\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00019, loss_test:0.10567, lr:1.00e-02, fs:0.67059 (r=0.576,p=0.803),  time:62.856, tt:1697.124\n",
      "Ep:27, loss:0.00018, loss_test:0.10694, lr:1.00e-02, fs:0.68235 (r=0.586,p=0.817),  time:62.888, tt:1760.854\n",
      "Ep:28, loss:0.00017, loss_test:0.10592, lr:1.00e-02, fs:0.68263 (r=0.576,p=0.838),  time:62.793, tt:1821.009\n",
      "Ep:29, loss:0.00016, loss_test:0.10871, lr:1.00e-02, fs:0.66667 (r=0.556,p=0.833),  time:62.751, tt:1882.538\n",
      "Ep:30, loss:0.00016, loss_test:0.10707, lr:1.00e-02, fs:0.66265 (r=0.556,p=0.821),  time:62.787, tt:1946.406\n",
      "Ep:31, loss:0.00015, loss_test:0.10814, lr:1.00e-02, fs:0.67485 (r=0.556,p=0.859),  time:62.811, tt:2009.946\n",
      "Ep:32, loss:0.00014, loss_test:0.10795, lr:1.00e-02, fs:0.67485 (r=0.556,p=0.859),  time:62.875, tt:2074.873\n",
      "Ep:33, loss:0.00013, loss_test:0.10954, lr:1.00e-02, fs:0.66667 (r=0.556,p=0.833),  time:62.862, tt:2137.301\n",
      "Ep:34, loss:0.00013, loss_test:0.11005, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:62.880, tt:2200.787\n",
      "Ep:35, loss:0.00012, loss_test:0.10856, lr:1.00e-02, fs:0.69048 (r=0.586,p=0.841),  time:62.951, tt:2266.230\n",
      "Ep:36, loss:0.00012, loss_test:0.11086, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:63.009, tt:2331.349\n",
      "Ep:37, loss:0.00011, loss_test:0.10962, lr:9.90e-03, fs:0.69091 (r=0.576,p=0.864),  time:63.046, tt:2395.760\n",
      "Ep:38, loss:0.00011, loss_test:0.10850, lr:9.80e-03, fs:0.69880 (r=0.586,p=0.866),  time:63.036, tt:2458.424\n",
      "Ep:39, loss:0.00010, loss_test:0.11120, lr:9.70e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.064, tt:2522.567\n",
      "Ep:40, loss:0.00010, loss_test:0.11279, lr:9.61e-03, fs:0.71166 (r=0.586,p=0.906),  time:63.108, tt:2587.432\n",
      "Ep:41, loss:0.00009, loss_test:0.10665, lr:9.51e-03, fs:0.70175 (r=0.606,p=0.833),  time:63.082, tt:2649.427\n",
      "Ep:42, loss:0.00009, loss_test:0.10977, lr:9.41e-03, fs:0.71084 (r=0.596,p=0.881),  time:63.075, tt:2712.238\n",
      "Ep:43, loss:0.00009, loss_test:0.11141, lr:9.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:63.100, tt:2776.417\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.10844, lr:9.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:63.111, tt:2839.985\n",
      "Ep:45, loss:0.00008, loss_test:0.10810, lr:9.32e-03, fs:0.70238 (r=0.596,p=0.855),  time:63.104, tt:2902.784\n",
      "Ep:46, loss:0.00008, loss_test:0.10810, lr:9.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:63.116, tt:2966.465\n",
      "Ep:47, loss:0.00007, loss_test:0.10891, lr:9.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.112, tt:3029.387\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.10991, lr:9.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.137, tt:3093.716\n",
      "Ep:49, loss:0.00007, loss_test:0.10853, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.137, tt:3156.827\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.10781, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.141, tt:3220.200\n",
      "Ep:51, loss:0.00006, loss_test:0.10725, lr:9.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.136, tt:3283.058\n",
      "Ep:52, loss:0.00006, loss_test:0.10794, lr:9.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.099, tt:3344.274\n",
      "Ep:53, loss:0.00006, loss_test:0.10922, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.104, tt:3407.613\n",
      "Ep:54, loss:0.00006, loss_test:0.10896, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.099, tt:3470.441\n",
      "Ep:55, loss:0.00005, loss_test:0.10725, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.126, tt:3535.074\n",
      "Ep:56, loss:0.00005, loss_test:0.10799, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.119, tt:3597.757\n",
      "Ep:57, loss:0.00005, loss_test:0.10750, lr:9.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.119, tt:3660.920\n",
      "Ep:58, loss:0.00005, loss_test:0.10645, lr:9.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.127, tt:3724.491\n",
      "Ep:59, loss:0.00005, loss_test:0.10852, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.115, tt:3786.879\n",
      "Ep:60, loss:0.00005, loss_test:0.10809, lr:9.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.164, tt:3852.974\n",
      "Ep:61, loss:0.00005, loss_test:0.10706, lr:9.23e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.185, tt:3917.460\n",
      "Ep:62, loss:0.00004, loss_test:0.10839, lr:9.14e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.200, tt:3981.632\n",
      "Ep:63, loss:0.00004, loss_test:0.10873, lr:9.04e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.217, tt:4045.901\n",
      "Ep:64, loss:0.00004, loss_test:0.10863, lr:8.95e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.214, tt:4108.904\n",
      "Ep:65, loss:0.00004, loss_test:0.10895, lr:8.86e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.209, tt:4171.800\n",
      "Ep:66, loss:0.00004, loss_test:0.10860, lr:8.78e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.160, tt:4231.733\n",
      "Ep:67, loss:0.00004, loss_test:0.10868, lr:8.69e-03, fs:0.73171 (r=0.606,p=0.923),  time:63.135, tt:4293.175\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.11057, lr:8.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.192, tt:4360.263\n",
      "Ep:69, loss:0.00004, loss_test:0.10947, lr:8.69e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.237, tt:4426.565\n",
      "Ep:70, loss:0.00004, loss_test:0.10825, lr:8.69e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.253, tt:4490.934\n",
      "Ep:71, loss:0.00004, loss_test:0.10848, lr:8.69e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.333, tt:4559.945\n",
      "Ep:72, loss:0.00003, loss_test:0.10888, lr:8.69e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.364, tt:4625.548\n",
      "Ep:73, loss:0.00003, loss_test:0.10999, lr:8.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.427, tt:4693.597\n",
      "Ep:74, loss:0.00003, loss_test:0.10974, lr:8.69e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.479, tt:4760.901\n",
      "Ep:75, loss:0.00003, loss_test:0.11034, lr:8.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.539, tt:4828.992\n",
      "Ep:76, loss:0.00003, loss_test:0.11154, lr:8.69e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.580, tt:4895.661\n",
      "Ep:77, loss:0.00003, loss_test:0.11099, lr:8.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.609, tt:4961.493\n",
      "Ep:78, loss:0.00003, loss_test:0.11162, lr:8.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.660, tt:5029.105\n",
      "Ep:79, loss:0.00003, loss_test:0.11050, lr:8.60e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.723, tt:5097.834\n",
      "Ep:80, loss:0.00003, loss_test:0.11139, lr:8.51e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.776, tt:5165.842\n",
      "Ep:81, loss:0.00003, loss_test:0.11092, lr:8.43e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.839, tt:5234.797\n",
      "Ep:82, loss:0.00003, loss_test:0.11232, lr:8.35e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.869, tt:5301.097\n",
      "Ep:83, loss:0.00003, loss_test:0.11169, lr:8.26e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.921, tt:5369.385\n",
      "Ep:84, loss:0.00003, loss_test:0.11109, lr:8.18e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.961, tt:5436.667\n",
      "Ep:85, loss:0.00002, loss_test:0.11154, lr:8.10e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.991, tt:5503.221\n",
      "Ep:86, loss:0.00002, loss_test:0.11085, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:64.025, tt:5570.180\n",
      "Ep:87, loss:0.00002, loss_test:0.11162, lr:7.94e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.080, tt:5639.071\n",
      "Ep:88, loss:0.00002, loss_test:0.11228, lr:7.86e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.110, tt:5705.786\n",
      "Ep:89, loss:0.00002, loss_test:0.11100, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.137, tt:5772.361\n",
      "Ep:90, loss:0.00002, loss_test:0.11151, lr:7.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.178, tt:5840.207\n",
      "Ep:91, loss:0.00002, loss_test:0.11232, lr:7.62e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.162, tt:5902.891\n",
      "Ep:92, loss:0.00002, loss_test:0.11303, lr:7.55e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.236, tt:5973.945\n",
      "Ep:93, loss:0.00002, loss_test:0.11217, lr:7.47e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.298, tt:6043.991\n",
      "Ep:94, loss:0.00002, loss_test:0.11154, lr:7.40e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.351, tt:6113.353\n",
      "Ep:95, loss:0.00002, loss_test:0.11170, lr:7.32e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.385, tt:6180.913\n",
      "Ep:96, loss:0.00002, loss_test:0.11262, lr:7.25e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.442, tt:6250.876\n",
      "Ep:97, loss:0.00002, loss_test:0.11284, lr:7.18e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.504, tt:6321.367\n",
      "Ep:98, loss:0.00002, loss_test:0.11263, lr:7.11e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.554, tt:6390.894\n",
      "Ep:99, loss:0.00002, loss_test:0.11294, lr:7.03e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.613, tt:6461.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00002, loss_test:0.11339, lr:6.96e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.643, tt:6528.908\n",
      "Ep:101, loss:0.00002, loss_test:0.11287, lr:6.89e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.687, tt:6598.099\n",
      "Ep:102, loss:0.00002, loss_test:0.11237, lr:6.83e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.714, tt:6665.534\n",
      "Ep:103, loss:0.00002, loss_test:0.11368, lr:6.76e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.741, tt:6733.057\n",
      "Ep:104, loss:0.00002, loss_test:0.11285, lr:6.69e-03, fs:0.71605 (r=0.586,p=0.921),  time:64.753, tt:6799.096\n",
      "Ep:105, loss:0.00002, loss_test:0.11403, lr:6.62e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.783, tt:6867.038\n",
      "Ep:106, loss:0.00002, loss_test:0.11335, lr:6.56e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.817, tt:6935.423\n",
      "Ep:107, loss:0.00002, loss_test:0.11390, lr:6.49e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.871, tt:7006.074\n",
      "Ep:108, loss:0.00002, loss_test:0.11417, lr:6.43e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.917, tt:7075.954\n",
      "Ep:109, loss:0.00002, loss_test:0.11437, lr:6.36e-03, fs:0.72500 (r=0.586,p=0.951),  time:64.933, tt:7142.662\n",
      "Ep:110, loss:0.00002, loss_test:0.11377, lr:6.30e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.969, tt:7211.609\n",
      "Ep:111, loss:0.00002, loss_test:0.11456, lr:6.24e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.001, tt:7280.148\n",
      "Ep:112, loss:0.00002, loss_test:0.11350, lr:6.17e-03, fs:0.72050 (r=0.586,p=0.935),  time:65.036, tt:7349.102\n",
      "Ep:113, loss:0.00002, loss_test:0.11453, lr:6.11e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.066, tt:7417.557\n",
      "Ep:114, loss:0.00002, loss_test:0.11530, lr:6.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:65.089, tt:7485.260\n",
      "Ep:115, loss:0.00002, loss_test:0.11445, lr:5.99e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.131, tt:7555.155\n",
      "Ep:116, loss:0.00002, loss_test:0.11497, lr:5.93e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.149, tt:7622.398\n",
      "Ep:117, loss:0.00002, loss_test:0.11478, lr:5.87e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.174, tt:7690.578\n",
      "Ep:118, loss:0.00001, loss_test:0.11475, lr:5.81e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.201, tt:7758.909\n",
      "Ep:119, loss:0.00001, loss_test:0.11526, lr:5.75e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.231, tt:7827.701\n",
      "Ep:120, loss:0.00001, loss_test:0.11490, lr:5.70e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.256, tt:7895.924\n",
      "Ep:121, loss:0.00001, loss_test:0.11544, lr:5.64e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.269, tt:7962.844\n",
      "Ep:122, loss:0.00001, loss_test:0.11536, lr:5.58e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.294, tt:8031.111\n",
      "Ep:123, loss:0.00001, loss_test:0.11532, lr:5.53e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.332, tt:8101.127\n",
      "Ep:124, loss:0.00001, loss_test:0.11559, lr:5.47e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.365, tt:8170.586\n",
      "Ep:125, loss:0.00001, loss_test:0.11597, lr:5.42e-03, fs:0.72956 (r=0.586,p=0.967),  time:65.394, tt:8239.622\n",
      "Ep:126, loss:0.00001, loss_test:0.11584, lr:5.36e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.444, tt:8311.441\n",
      "Ep:127, loss:0.00001, loss_test:0.11569, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.473, tt:8380.545\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.11591, lr:5.31e-03, fs:0.72500 (r=0.586,p=0.951),  time:65.510, tt:8450.728\n",
      "Ep:129, loss:0.00001, loss_test:0.11652, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.531, tt:8518.999\n",
      "Ep:130, loss:0.00001, loss_test:0.11564, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.592, tt:8592.590\n",
      "Ep:131, loss:0.00001, loss_test:0.11719, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.608, tt:8660.297\n",
      "Ep:132, loss:0.00001, loss_test:0.11674, lr:5.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:65.675, tt:8734.797\n",
      "Ep:133, loss:0.00001, loss_test:0.11656, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.719, tt:8806.377\n",
      "Ep:134, loss:0.00001, loss_test:0.11713, lr:5.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:65.754, tt:8876.788\n",
      "Ep:135, loss:0.00001, loss_test:0.11752, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.786, tt:8946.929\n",
      "Ep:137, loss:0.00001, loss_test:0.11713, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.868, tt:9089.764\n",
      "Ep:138, loss:0.00001, loss_test:0.11799, lr:5.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:65.900, tt:9160.152\n",
      "Ep:139, loss:0.00001, loss_test:0.11770, lr:5.26e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.929, tt:9230.107\n",
      "Ep:140, loss:0.00001, loss_test:0.11704, lr:5.20e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.960, tt:9300.330\n",
      "Ep:141, loss:0.00001, loss_test:0.11803, lr:5.15e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.981, tt:9369.337\n",
      "Ep:142, loss:0.00001, loss_test:0.11800, lr:5.10e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.995, tt:9437.311\n",
      "Ep:143, loss:0.00001, loss_test:0.11744, lr:5.05e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.049, tt:9511.034\n",
      "Ep:144, loss:0.00001, loss_test:0.11800, lr:5.00e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.086, tt:9582.506\n",
      "Ep:145, loss:0.00001, loss_test:0.11739, lr:4.95e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.085, tt:9648.376\n",
      "Ep:146, loss:0.00001, loss_test:0.11854, lr:4.90e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.101, tt:9716.894\n",
      "Ep:147, loss:0.00001, loss_test:0.11802, lr:4.85e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.122, tt:9786.063\n",
      "Ep:148, loss:0.00001, loss_test:0.11811, lr:4.80e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.108, tt:9850.031\n",
      "Ep:149, loss:0.00001, loss_test:0.11820, lr:4.75e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.031, tt:9904.610\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 85\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14505, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:63.064, tt:63.064\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14311, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:57.431, tt:114.862\n",
      "Ep:2, loss:0.00054, loss_test:0.13890, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:58.258, tt:174.773\n",
      "Ep:3, loss:0.00051, loss_test:0.13035, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:59.707, tt:238.829\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.12173, lr:1.00e-02, fs:0.64151 (r=0.687,p=0.602),  time:60.517, tt:302.587\n",
      "Ep:5, loss:0.00044, loss_test:0.11791, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:61.280, tt:367.683\n",
      "Ep:6, loss:0.00042, loss_test:0.11489, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:61.745, tt:432.217\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.11313, lr:1.00e-02, fs:0.65000 (r=0.657,p=0.644),  time:61.723, tt:493.783\n",
      "Ep:8, loss:0.00037, loss_test:0.11059, lr:1.00e-02, fs:0.65686 (r=0.677,p=0.638),  time:62.001, tt:558.006\n",
      "Ep:9, loss:0.00036, loss_test:0.11069, lr:1.00e-02, fs:0.63959 (r=0.636,p=0.643),  time:61.777, tt:617.766\n",
      "Ep:10, loss:0.00034, loss_test:0.10868, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:62.040, tt:682.438\n",
      "Ep:11, loss:0.00033, loss_test:0.10757, lr:1.00e-02, fs:0.65306 (r=0.646,p=0.660),  time:62.034, tt:744.409\n",
      "Ep:12, loss:0.00031, loss_test:0.10604, lr:1.00e-02, fs:0.67317 (r=0.697,p=0.651),  time:61.926, tt:805.040\n",
      "Ep:13, loss:0.00030, loss_test:0.10542, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:61.961, tt:867.459\n",
      "Ep:14, loss:0.00029, loss_test:0.10399, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:62.150, tt:932.246\n",
      "Ep:15, loss:0.00028, loss_test:0.10436, lr:1.00e-02, fs:0.67016 (r=0.646,p=0.696),  time:62.201, tt:995.219\n",
      "Ep:16, loss:0.00027, loss_test:0.10231, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:62.358, tt:1060.082\n",
      "Ep:17, loss:0.00026, loss_test:0.10279, lr:1.00e-02, fs:0.66304 (r=0.616,p=0.718),  time:62.308, tt:1121.542\n",
      "Ep:18, loss:0.00025, loss_test:0.10099, lr:9.90e-03, fs:0.69072 (r=0.677,p=0.705),  time:62.642, tt:1190.196\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.10302, lr:9.90e-03, fs:0.67778 (r=0.616,p=0.753),  time:62.922, tt:1258.430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00024, loss_test:0.09858, lr:9.90e-03, fs:0.69149 (r=0.657,p=0.730),  time:62.852, tt:1319.886\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.10100, lr:9.90e-03, fs:0.69663 (r=0.626,p=0.785),  time:62.785, tt:1381.275\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.10013, lr:9.90e-03, fs:0.69663 (r=0.626,p=0.785),  time:62.790, tt:1444.172\n",
      "Ep:23, loss:0.00021, loss_test:0.09821, lr:9.90e-03, fs:0.69892 (r=0.657,p=0.747),  time:62.932, tt:1510.379\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.09994, lr:9.90e-03, fs:0.68571 (r=0.606,p=0.789),  time:62.619, tt:1565.466\n",
      "Ep:25, loss:0.00019, loss_test:0.09687, lr:9.90e-03, fs:0.73404 (r=0.697,p=0.775),  time:62.245, tt:1618.377\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00019, loss_test:0.09666, lr:9.90e-03, fs:0.70056 (r=0.626,p=0.795),  time:61.858, tt:1670.156\n",
      "Ep:27, loss:0.00018, loss_test:0.10144, lr:9.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:61.582, tt:1724.288\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.09557, lr:9.90e-03, fs:0.71508 (r=0.646,p=0.800),  time:61.271, tt:1776.861\n",
      "Ep:29, loss:0.00016, loss_test:0.09932, lr:9.90e-03, fs:0.73864 (r=0.657,p=0.844),  time:61.108, tt:1833.228\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.10026, lr:9.90e-03, fs:0.74576 (r=0.667,p=0.846),  time:60.950, tt:1889.440\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.09675, lr:9.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:60.911, tt:1949.157\n",
      "Ep:32, loss:0.00014, loss_test:0.09949, lr:9.90e-03, fs:0.73988 (r=0.646,p=0.865),  time:60.856, tt:2008.244\n",
      "Ep:33, loss:0.00013, loss_test:0.09799, lr:9.90e-03, fs:0.74713 (r=0.657,p=0.867),  time:60.813, tt:2067.641\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.10206, lr:9.90e-03, fs:0.74419 (r=0.646,p=0.877),  time:60.767, tt:2126.846\n",
      "Ep:35, loss:0.00012, loss_test:0.09678, lr:9.90e-03, fs:0.74713 (r=0.657,p=0.867),  time:60.694, tt:2184.967\n",
      "Ep:36, loss:0.00012, loss_test:0.09581, lr:9.90e-03, fs:0.74286 (r=0.657,p=0.855),  time:60.692, tt:2245.607\n",
      "Ep:37, loss:0.00011, loss_test:0.09655, lr:9.90e-03, fs:0.75581 (r=0.657,p=0.890),  time:60.615, tt:2303.385\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.09953, lr:9.90e-03, fs:0.75581 (r=0.657,p=0.890),  time:60.576, tt:2362.470\n",
      "Ep:39, loss:0.00010, loss_test:0.09585, lr:9.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:60.483, tt:2419.301\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.09392, lr:9.90e-03, fs:0.77714 (r=0.687,p=0.895),  time:60.460, tt:2478.854\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.09698, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:60.445, tt:2538.695\n",
      "Ep:42, loss:0.00009, loss_test:0.09752, lr:9.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:60.282, tt:2592.110\n",
      "Ep:43, loss:0.00009, loss_test:0.09338, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:60.250, tt:2651.003\n",
      "Ep:44, loss:0.00008, loss_test:0.09504, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:60.192, tt:2708.654\n",
      "Ep:45, loss:0.00008, loss_test:0.09463, lr:9.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:60.169, tt:2767.777\n",
      "Ep:46, loss:0.00008, loss_test:0.09744, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:60.133, tt:2826.236\n",
      "Ep:47, loss:0.00007, loss_test:0.09708, lr:9.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:60.042, tt:2882.019\n",
      "Ep:48, loss:0.00007, loss_test:0.09426, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:60.056, tt:2942.767\n",
      "Ep:49, loss:0.00007, loss_test:0.09415, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:60.020, tt:3001.006\n",
      "Ep:50, loss:0.00006, loss_test:0.09751, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:59.974, tt:3058.690\n",
      "Ep:51, loss:0.00006, loss_test:0.09733, lr:9.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:59.923, tt:3116.013\n",
      "Ep:52, loss:0.00006, loss_test:0.09541, lr:9.80e-03, fs:0.76744 (r=0.667,p=0.904),  time:59.842, tt:3171.601\n",
      "Ep:53, loss:0.00006, loss_test:0.09291, lr:9.70e-03, fs:0.76301 (r=0.667,p=0.892),  time:59.839, tt:3231.303\n",
      "Ep:54, loss:0.00006, loss_test:0.09916, lr:9.61e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.850, tt:3291.734\n",
      "Ep:55, loss:0.00005, loss_test:0.09978, lr:9.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.823, tt:3350.110\n",
      "Ep:56, loss:0.00005, loss_test:0.09342, lr:9.41e-03, fs:0.76301 (r=0.667,p=0.892),  time:59.813, tt:3409.361\n",
      "Ep:57, loss:0.00005, loss_test:0.09599, lr:9.32e-03, fs:0.76023 (r=0.657,p=0.903),  time:59.846, tt:3471.064\n",
      "Ep:58, loss:0.00005, loss_test:0.09951, lr:9.23e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.824, tt:3529.640\n",
      "Ep:59, loss:0.00005, loss_test:0.09536, lr:9.14e-03, fs:0.76744 (r=0.667,p=0.904),  time:59.760, tt:3585.591\n",
      "Ep:60, loss:0.00005, loss_test:0.09374, lr:9.04e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.774, tt:3646.218\n",
      "Ep:61, loss:0.00004, loss_test:0.09755, lr:8.95e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.804, tt:3707.817\n",
      "Ep:62, loss:0.00004, loss_test:0.09509, lr:8.86e-03, fs:0.76744 (r=0.667,p=0.904),  time:59.769, tt:3765.464\n",
      "Ep:63, loss:0.00004, loss_test:0.09788, lr:8.78e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.730, tt:3822.703\n",
      "Ep:64, loss:0.00004, loss_test:0.09654, lr:8.69e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.692, tt:3879.975\n",
      "Ep:65, loss:0.00004, loss_test:0.09791, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:59.709, tt:3940.814\n",
      "Ep:66, loss:0.00004, loss_test:0.09819, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.715, tt:4000.897\n",
      "Ep:67, loss:0.00004, loss_test:0.09610, lr:8.43e-03, fs:0.76023 (r=0.657,p=0.903),  time:59.712, tt:4060.449\n",
      "Ep:68, loss:0.00004, loss_test:0.09692, lr:8.35e-03, fs:0.76023 (r=0.657,p=0.903),  time:59.665, tt:4116.896\n",
      "Ep:69, loss:0.00003, loss_test:0.09862, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.644, tt:4175.055\n",
      "Ep:70, loss:0.00003, loss_test:0.09950, lr:8.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.624, tt:4233.333\n",
      "Ep:71, loss:0.00003, loss_test:0.09587, lr:8.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.617, tt:4292.388\n",
      "Ep:72, loss:0.00003, loss_test:0.09700, lr:8.02e-03, fs:0.76023 (r=0.657,p=0.903),  time:59.582, tt:4349.480\n",
      "Ep:73, loss:0.00003, loss_test:0.10303, lr:7.94e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.566, tt:4407.875\n",
      "Ep:74, loss:0.00003, loss_test:0.10046, lr:7.86e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.533, tt:4464.954\n",
      "Ep:75, loss:0.00003, loss_test:0.09572, lr:7.78e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.541, tt:4525.146\n",
      "Ep:76, loss:0.00003, loss_test:0.09869, lr:7.70e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.552, tt:4585.484\n",
      "Ep:77, loss:0.00003, loss_test:0.10045, lr:7.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.544, tt:4644.416\n",
      "Ep:78, loss:0.00003, loss_test:0.09749, lr:7.55e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.496, tt:4700.222\n",
      "Ep:79, loss:0.00003, loss_test:0.10019, lr:7.47e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.500, tt:4759.972\n",
      "Ep:80, loss:0.00003, loss_test:0.10064, lr:7.40e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.526, tt:4821.627\n",
      "Ep:81, loss:0.00003, loss_test:0.09996, lr:7.32e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.528, tt:4881.281\n",
      "Ep:82, loss:0.00003, loss_test:0.09757, lr:7.25e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.524, tt:4940.497\n",
      "Ep:83, loss:0.00003, loss_test:0.09969, lr:7.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.556, tt:5002.664\n",
      "Ep:84, loss:0.00003, loss_test:0.09906, lr:7.11e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.548, tt:5061.620\n",
      "Ep:85, loss:0.00002, loss_test:0.09887, lr:7.03e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.547, tt:5120.999\n",
      "Ep:86, loss:0.00002, loss_test:0.10139, lr:6.96e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.517, tt:5178.022\n",
      "Ep:87, loss:0.00002, loss_test:0.09965, lr:6.89e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.523, tt:5238.026\n",
      "Ep:88, loss:0.00002, loss_test:0.09938, lr:6.83e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.531, tt:5298.274\n",
      "Ep:89, loss:0.00002, loss_test:0.09942, lr:6.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.518, tt:5356.637\n",
      "Ep:90, loss:0.00002, loss_test:0.10170, lr:6.69e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.486, tt:5413.200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:91, loss:0.00002, loss_test:0.09811, lr:6.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.451, tt:5469.519\n",
      "Ep:92, loss:0.00002, loss_test:0.09928, lr:6.56e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.422, tt:5526.266\n",
      "Ep:93, loss:0.00002, loss_test:0.10099, lr:6.49e-03, fs:0.76923 (r=0.657,p=0.929),  time:59.403, tt:5583.900\n",
      "Ep:94, loss:0.00002, loss_test:0.09938, lr:6.43e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.420, tt:5644.868\n",
      "Ep:95, loss:0.00002, loss_test:0.09995, lr:6.36e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.422, tt:5704.511\n",
      "Ep:96, loss:0.00002, loss_test:0.10089, lr:6.30e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.402, tt:5762.018\n",
      "Ep:97, loss:0.00002, loss_test:0.10120, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.405, tt:5821.665\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00002, loss_test:0.09962, lr:6.24e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.405, tt:5881.143\n",
      "Ep:99, loss:0.00002, loss_test:0.10054, lr:6.24e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.406, tt:5940.638\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.09959, lr:6.24e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.404, tt:5999.755\n",
      "Ep:101, loss:0.00002, loss_test:0.10003, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.392, tt:6057.942\n",
      "Ep:102, loss:0.00002, loss_test:0.10122, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.347, tt:6112.793\n",
      "Ep:103, loss:0.00002, loss_test:0.10185, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.313, tt:6168.592\n",
      "Ep:104, loss:0.00002, loss_test:0.10117, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.290, tt:6225.448\n",
      "Ep:105, loss:0.00002, loss_test:0.10191, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.275, tt:6283.178\n",
      "Ep:106, loss:0.00002, loss_test:0.10123, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.250, tt:6339.773\n",
      "Ep:107, loss:0.00002, loss_test:0.10004, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.239, tt:6397.815\n",
      "Ep:108, loss:0.00002, loss_test:0.10088, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.227, tt:6455.790\n",
      "Ep:109, loss:0.00002, loss_test:0.10150, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.213, tt:6513.394\n",
      "Ep:110, loss:0.00002, loss_test:0.10088, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.218, tt:6573.254\n",
      "Ep:111, loss:0.00002, loss_test:0.10134, lr:6.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.234, tt:6634.224\n",
      "Ep:112, loss:0.00002, loss_test:0.10347, lr:6.11e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.232, tt:6693.263\n",
      "Ep:113, loss:0.00002, loss_test:0.10173, lr:6.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.218, tt:6750.797\n",
      "Ep:114, loss:0.00002, loss_test:0.10143, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.207, tt:6808.809\n",
      "Ep:115, loss:0.00001, loss_test:0.10170, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.176, tt:6864.444\n",
      "Ep:116, loss:0.00001, loss_test:0.10210, lr:5.87e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.179, tt:6923.911\n",
      "Ep:117, loss:0.00001, loss_test:0.10065, lr:5.81e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.165, tt:6981.429\n",
      "Ep:118, loss:0.00001, loss_test:0.10440, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.154, tt:7039.334\n",
      "Ep:119, loss:0.00001, loss_test:0.10327, lr:5.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.163, tt:7099.598\n",
      "Ep:120, loss:0.00001, loss_test:0.10152, lr:5.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.173, tt:7159.925\n",
      "Ep:121, loss:0.00001, loss_test:0.10096, lr:5.58e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.161, tt:7217.585\n",
      "Ep:122, loss:0.00001, loss_test:0.10319, lr:5.53e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.157, tt:7276.364\n",
      "Ep:123, loss:0.00001, loss_test:0.10202, lr:5.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.152, tt:7334.899\n",
      "Ep:124, loss:0.00001, loss_test:0.10239, lr:5.42e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.134, tt:7391.710\n",
      "Ep:125, loss:0.00001, loss_test:0.10114, lr:5.36e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.138, tt:7451.338\n",
      "Ep:126, loss:0.00001, loss_test:0.10287, lr:5.31e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.144, tt:7511.266\n",
      "Ep:127, loss:0.00001, loss_test:0.10292, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.135, tt:7569.341\n",
      "Ep:128, loss:0.00001, loss_test:0.10354, lr:5.20e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.125, tt:7627.145\n",
      "Ep:129, loss:0.00001, loss_test:0.10355, lr:5.15e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.134, tt:7687.469\n",
      "Ep:130, loss:0.00001, loss_test:0.10225, lr:5.10e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.110, tt:7743.357\n",
      "Ep:131, loss:0.00001, loss_test:0.10407, lr:5.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.096, tt:7800.680\n",
      "Ep:132, loss:0.00001, loss_test:0.10400, lr:5.00e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.089, tt:7858.811\n",
      "Ep:133, loss:0.00001, loss_test:0.10169, lr:4.95e-03, fs:0.75309 (r=0.616,p=0.968),  time:59.078, tt:7916.434\n",
      "Ep:134, loss:0.00001, loss_test:0.10478, lr:4.90e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.082, tt:7976.005\n",
      "Ep:135, loss:0.00001, loss_test:0.10268, lr:4.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.061, tt:8032.254\n",
      "Ep:136, loss:0.00001, loss_test:0.10232, lr:4.80e-03, fs:0.75309 (r=0.616,p=0.968),  time:59.051, tt:8089.982\n",
      "Ep:137, loss:0.00001, loss_test:0.10343, lr:4.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.045, tt:8148.217\n",
      "Ep:138, loss:0.00001, loss_test:0.10383, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.037, tt:8206.132\n",
      "Ep:139, loss:0.00001, loss_test:0.10265, lr:4.66e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.023, tt:8263.208\n",
      "Ep:140, loss:0.00001, loss_test:0.10310, lr:4.61e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.013, tt:8320.843\n",
      "Ep:141, loss:0.00001, loss_test:0.10371, lr:4.57e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.012, tt:8379.754\n",
      "Ep:142, loss:0.00001, loss_test:0.10454, lr:4.52e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.018, tt:8439.537\n",
      "Ep:143, loss:0.00001, loss_test:0.10278, lr:4.48e-03, fs:0.75309 (r=0.616,p=0.968),  time:59.022, tt:8499.141\n",
      "Ep:144, loss:0.00001, loss_test:0.10307, lr:4.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.001, tt:8555.106\n",
      "Ep:145, loss:0.00001, loss_test:0.10419, lr:4.39e-03, fs:0.78313 (r=0.657,p=0.970),  time:58.979, tt:8610.992\n",
      "Ep:146, loss:0.00001, loss_test:0.10207, lr:4.34e-03, fs:0.75309 (r=0.616,p=0.968),  time:58.976, tt:8669.442\n",
      "Ep:147, loss:0.00001, loss_test:0.10406, lr:4.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:58.951, tt:8724.677\n",
      "Ep:148, loss:0.00001, loss_test:0.10309, lr:4.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:58.940, tt:8781.988\n",
      "Ep:149, loss:0.00001, loss_test:0.10245, lr:4.21e-03, fs:0.75309 (r=0.616,p=0.968),  time:58.870, tt:8830.542\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 86\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14748, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.578, tt:57.578\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14645, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:55.492, tt:110.984\n",
      "Ep:2, loss:0.00054, loss_test:0.14415, lr:1.00e-02, fs:0.62857 (r=0.889,p=0.486),  time:54.909, tt:164.727\n",
      "Ep:3, loss:0.00050, loss_test:0.14065, lr:1.00e-02, fs:0.62602 (r=0.778,p=0.524),  time:55.151, tt:220.603\n",
      "Ep:4, loss:0.00047, loss_test:0.13778, lr:1.00e-02, fs:0.60909 (r=0.677,p=0.554),  time:55.920, tt:279.602\n",
      "Ep:5, loss:0.00045, loss_test:0.13138, lr:1.00e-02, fs:0.62069 (r=0.727,p=0.541),  time:56.065, tt:336.389\n",
      "Ep:6, loss:0.00043, loss_test:0.12882, lr:1.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:56.525, tt:395.676\n",
      "Ep:7, loss:0.00041, loss_test:0.12685, lr:1.00e-02, fs:0.63348 (r=0.707,p=0.574),  time:57.103, tt:456.824\n",
      "Ep:8, loss:0.00039, loss_test:0.12191, lr:1.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:57.270, tt:515.430\n",
      "Ep:9, loss:0.00038, loss_test:0.11696, lr:1.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:57.302, tt:573.022\n",
      "Ep:10, loss:0.00036, loss_test:0.11310, lr:1.00e-02, fs:0.65741 (r=0.717,p=0.607),  time:57.422, tt:631.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00035, loss_test:0.10983, lr:1.00e-02, fs:0.66047 (r=0.717,p=0.612),  time:57.571, tt:690.852\n",
      "Ep:12, loss:0.00034, loss_test:0.10624, lr:9.90e-03, fs:0.66977 (r=0.727,p=0.621),  time:57.651, tt:749.463\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00033, loss_test:0.10382, lr:9.90e-03, fs:0.69406 (r=0.768,p=0.633),  time:57.616, tt:806.628\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00031, loss_test:0.10109, lr:9.90e-03, fs:0.69725 (r=0.768,p=0.639),  time:57.748, tt:866.218\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.09995, lr:9.90e-03, fs:0.70423 (r=0.758,p=0.658),  time:57.733, tt:923.731\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00029, loss_test:0.09800, lr:9.90e-03, fs:0.72222 (r=0.788,p=0.667),  time:57.758, tt:981.888\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00028, loss_test:0.09625, lr:9.90e-03, fs:0.72986 (r=0.778,p=0.688),  time:57.896, tt:1042.129\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00028, loss_test:0.09428, lr:9.90e-03, fs:0.73832 (r=0.798,p=0.687),  time:57.993, tt:1101.867\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00027, loss_test:0.09226, lr:9.90e-03, fs:0.74178 (r=0.798,p=0.693),  time:58.040, tt:1160.807\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00026, loss_test:0.09164, lr:9.90e-03, fs:0.74396 (r=0.778,p=0.713),  time:58.057, tt:1219.194\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00025, loss_test:0.08844, lr:9.90e-03, fs:0.75829 (r=0.808,p=0.714),  time:58.026, tt:1276.583\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00024, loss_test:0.08762, lr:9.90e-03, fs:0.77512 (r=0.818,p=0.736),  time:57.961, tt:1333.114\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00023, loss_test:0.08521, lr:9.90e-03, fs:0.78261 (r=0.818,p=0.750),  time:57.894, tt:1389.464\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00022, loss_test:0.08493, lr:9.90e-03, fs:0.79621 (r=0.848,p=0.750),  time:57.992, tt:1449.796\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.08244, lr:9.90e-03, fs:0.79426 (r=0.838,p=0.755),  time:57.940, tt:1506.427\n",
      "Ep:26, loss:0.00020, loss_test:0.08180, lr:9.90e-03, fs:0.81553 (r=0.848,p=0.785),  time:57.972, tt:1565.243\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.08081, lr:9.90e-03, fs:0.80769 (r=0.848,p=0.771),  time:57.794, tt:1618.228\n",
      "Ep:28, loss:0.00018, loss_test:0.07833, lr:9.90e-03, fs:0.80000 (r=0.848,p=0.757),  time:57.765, tt:1675.198\n",
      "Ep:29, loss:0.00018, loss_test:0.07884, lr:9.90e-03, fs:0.81159 (r=0.848,p=0.778),  time:57.754, tt:1732.626\n",
      "Ep:30, loss:0.00017, loss_test:0.07675, lr:9.90e-03, fs:0.80976 (r=0.838,p=0.783),  time:57.751, tt:1790.283\n",
      "Ep:31, loss:0.00016, loss_test:0.07765, lr:9.90e-03, fs:0.83417 (r=0.838,p=0.830),  time:57.703, tt:1846.503\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.07538, lr:9.90e-03, fs:0.82353 (r=0.848,p=0.800),  time:57.767, tt:1906.296\n",
      "Ep:33, loss:0.00014, loss_test:0.07372, lr:9.90e-03, fs:0.83168 (r=0.848,p=0.816),  time:57.760, tt:1963.848\n",
      "Ep:34, loss:0.00014, loss_test:0.07368, lr:9.90e-03, fs:0.83168 (r=0.848,p=0.816),  time:57.720, tt:2020.205\n",
      "Ep:35, loss:0.00013, loss_test:0.07378, lr:9.90e-03, fs:0.84264 (r=0.838,p=0.847),  time:57.752, tt:2079.084\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.07233, lr:9.90e-03, fs:0.84422 (r=0.848,p=0.840),  time:57.773, tt:2137.605\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.06914, lr:9.90e-03, fs:0.84264 (r=0.838,p=0.847),  time:57.852, tt:2198.377\n",
      "Ep:38, loss:0.00012, loss_test:0.07232, lr:9.90e-03, fs:0.86010 (r=0.838,p=0.883),  time:57.889, tt:2257.656\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.06986, lr:9.90e-03, fs:0.85567 (r=0.838,p=0.874),  time:57.927, tt:2317.085\n",
      "Ep:40, loss:0.00011, loss_test:0.06754, lr:9.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:57.952, tt:2376.013\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.06909, lr:9.90e-03, fs:0.85714 (r=0.848,p=0.866),  time:57.973, tt:2434.866\n",
      "Ep:42, loss:0.00010, loss_test:0.06813, lr:9.90e-03, fs:0.84000 (r=0.848,p=0.832),  time:57.962, tt:2492.373\n",
      "Ep:43, loss:0.00010, loss_test:0.06751, lr:9.90e-03, fs:0.85567 (r=0.838,p=0.874),  time:58.025, tt:2553.112\n",
      "Ep:44, loss:0.00009, loss_test:0.06521, lr:9.90e-03, fs:0.86911 (r=0.838,p=0.902),  time:58.038, tt:2611.730\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.07110, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:58.037, tt:2669.690\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.06563, lr:9.90e-03, fs:0.86911 (r=0.838,p=0.902),  time:58.043, tt:2728.031\n",
      "Ep:47, loss:0.00008, loss_test:0.06562, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:58.018, tt:2784.882\n",
      "Ep:48, loss:0.00007, loss_test:0.06725, lr:9.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:58.014, tt:2842.682\n",
      "Ep:49, loss:0.00007, loss_test:0.06670, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:57.984, tt:2899.202\n",
      "Ep:50, loss:0.00007, loss_test:0.06436, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:57.947, tt:2955.305\n",
      "Ep:51, loss:0.00007, loss_test:0.06740, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:57.961, tt:3013.947\n",
      "Ep:52, loss:0.00006, loss_test:0.06652, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:58.013, tt:3074.666\n",
      "Ep:53, loss:0.00006, loss_test:0.06491, lr:9.90e-03, fs:0.87831 (r=0.838,p=0.922),  time:58.025, tt:3133.373\n",
      "Ep:54, loss:0.00006, loss_test:0.06449, lr:9.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:58.020, tt:3191.121\n",
      "Ep:55, loss:0.00006, loss_test:0.06755, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:58.011, tt:3248.596\n",
      "Ep:56, loss:0.00006, loss_test:0.06506, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:58.009, tt:3306.516\n",
      "Ep:57, loss:0.00005, loss_test:0.06146, lr:9.80e-03, fs:0.88083 (r=0.859,p=0.904),  time:58.016, tt:3364.944\n",
      "Ep:58, loss:0.00005, loss_test:0.06627, lr:9.70e-03, fs:0.87368 (r=0.838,p=0.912),  time:58.011, tt:3422.674\n",
      "Ep:59, loss:0.00005, loss_test:0.06511, lr:9.61e-03, fs:0.88298 (r=0.838,p=0.933),  time:57.989, tt:3479.310\n",
      "Ep:60, loss:0.00005, loss_test:0.06387, lr:9.51e-03, fs:0.88083 (r=0.859,p=0.904),  time:57.980, tt:3536.765\n",
      "Ep:61, loss:0.00005, loss_test:0.06360, lr:9.41e-03, fs:0.87831 (r=0.838,p=0.922),  time:57.998, tt:3595.884\n",
      "Ep:62, loss:0.00005, loss_test:0.06414, lr:9.32e-03, fs:0.86911 (r=0.838,p=0.902),  time:57.988, tt:3653.262\n",
      "Ep:63, loss:0.00004, loss_test:0.06294, lr:9.23e-03, fs:0.87368 (r=0.838,p=0.912),  time:57.997, tt:3711.833\n",
      "Ep:64, loss:0.00004, loss_test:0.06382, lr:9.14e-03, fs:0.88083 (r=0.859,p=0.904),  time:58.028, tt:3771.841\n",
      "Ep:65, loss:0.00004, loss_test:0.06320, lr:9.04e-03, fs:0.86911 (r=0.838,p=0.902),  time:58.052, tt:3831.455\n",
      "Ep:66, loss:0.00004, loss_test:0.06519, lr:8.95e-03, fs:0.87368 (r=0.838,p=0.912),  time:58.023, tt:3887.558\n",
      "Ep:67, loss:0.00004, loss_test:0.06257, lr:8.86e-03, fs:0.86911 (r=0.838,p=0.902),  time:58.056, tt:3947.820\n",
      "Ep:68, loss:0.00004, loss_test:0.06306, lr:8.78e-03, fs:0.88298 (r=0.838,p=0.933),  time:58.101, tt:4008.999\n",
      "Ep:69, loss:0.00004, loss_test:0.06432, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.095, tt:4066.619\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00004, loss_test:0.06351, lr:8.69e-03, fs:0.88298 (r=0.838,p=0.933),  time:58.099, tt:4125.026\n",
      "Ep:71, loss:0.00003, loss_test:0.06208, lr:8.69e-03, fs:0.87831 (r=0.838,p=0.922),  time:58.100, tt:4183.217\n",
      "Ep:72, loss:0.00003, loss_test:0.06264, lr:8.69e-03, fs:0.87958 (r=0.848,p=0.913),  time:58.090, tt:4240.593\n",
      "Ep:73, loss:0.00003, loss_test:0.06313, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.137, tt:4302.144\n",
      "Ep:74, loss:0.00003, loss_test:0.06249, lr:8.69e-03, fs:0.87831 (r=0.838,p=0.922),  time:58.149, tt:4361.159\n",
      "Ep:75, loss:0.00003, loss_test:0.06280, lr:8.69e-03, fs:0.87831 (r=0.838,p=0.922),  time:58.159, tt:4420.098\n",
      "Ep:76, loss:0.00003, loss_test:0.06289, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.192, tt:4480.773\n",
      "Ep:77, loss:0.00003, loss_test:0.06330, lr:8.69e-03, fs:0.88298 (r=0.838,p=0.933),  time:58.172, tt:4537.431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00003, loss_test:0.06322, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.146, tt:4593.526\n",
      "Ep:79, loss:0.00003, loss_test:0.06320, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.139, tt:4651.129\n",
      "Ep:80, loss:0.00003, loss_test:0.06281, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.136, tt:4709.056\n",
      "Ep:81, loss:0.00003, loss_test:0.06172, lr:8.60e-03, fs:0.89474 (r=0.859,p=0.934),  time:58.132, tt:4766.815\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00003, loss_test:0.06368, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.111, tt:4823.220\n",
      "Ep:83, loss:0.00003, loss_test:0.06348, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.098, tt:4880.252\n",
      "Ep:84, loss:0.00002, loss_test:0.06252, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.126, tt:4940.750\n",
      "Ep:85, loss:0.00002, loss_test:0.06274, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.119, tt:4998.209\n",
      "Ep:86, loss:0.00002, loss_test:0.06285, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.161, tt:5059.980\n",
      "Ep:87, loss:0.00002, loss_test:0.06262, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.185, tt:5120.268\n",
      "Ep:88, loss:0.00002, loss_test:0.06215, lr:8.60e-03, fs:0.89947 (r=0.859,p=0.944),  time:58.186, tt:5178.593\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00002, loss_test:0.06282, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.164, tt:5234.794\n",
      "Ep:90, loss:0.00002, loss_test:0.06397, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.183, tt:5294.687\n",
      "Ep:91, loss:0.00002, loss_test:0.06248, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.211, tt:5355.449\n",
      "Ep:92, loss:0.00002, loss_test:0.06220, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.202, tt:5412.809\n",
      "Ep:93, loss:0.00002, loss_test:0.06329, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.197, tt:5470.535\n",
      "Ep:94, loss:0.00002, loss_test:0.06267, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.206, tt:5529.587\n",
      "Ep:95, loss:0.00002, loss_test:0.06435, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.175, tt:5584.763\n",
      "Ep:96, loss:0.00002, loss_test:0.06271, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.152, tt:5640.699\n",
      "Ep:97, loss:0.00002, loss_test:0.06335, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.138, tt:5697.558\n",
      "Ep:98, loss:0.00002, loss_test:0.06422, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.128, tt:5754.625\n",
      "Ep:99, loss:0.00002, loss_test:0.06464, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.112, tt:5811.205\n",
      "Ep:100, loss:0.00002, loss_test:0.06246, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.117, tt:5869.804\n",
      "Ep:101, loss:0.00002, loss_test:0.06476, lr:8.43e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.132, tt:5929.503\n",
      "Ep:102, loss:0.00002, loss_test:0.06504, lr:8.35e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.139, tt:5988.287\n",
      "Ep:103, loss:0.00002, loss_test:0.06293, lr:8.26e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.142, tt:6046.783\n",
      "Ep:104, loss:0.00002, loss_test:0.06391, lr:8.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.140, tt:6104.682\n",
      "Ep:105, loss:0.00002, loss_test:0.06332, lr:8.10e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.121, tt:6160.791\n",
      "Ep:106, loss:0.00002, loss_test:0.06350, lr:8.02e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.137, tt:6220.706\n",
      "Ep:107, loss:0.00002, loss_test:0.06254, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.105, tt:6275.308\n",
      "Ep:108, loss:0.00002, loss_test:0.06365, lr:7.86e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.104, tt:6333.307\n",
      "Ep:109, loss:0.00001, loss_test:0.06442, lr:7.78e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.080, tt:6388.806\n",
      "Ep:110, loss:0.00001, loss_test:0.06268, lr:7.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.077, tt:6446.521\n",
      "Ep:111, loss:0.00001, loss_test:0.06409, lr:7.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.064, tt:6503.120\n",
      "Ep:112, loss:0.00001, loss_test:0.06381, lr:7.55e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.076, tt:6562.560\n",
      "Ep:113, loss:0.00001, loss_test:0.06322, lr:7.47e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.072, tt:6620.230\n",
      "Ep:114, loss:0.00001, loss_test:0.06407, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.088, tt:6680.125\n",
      "Ep:115, loss:0.00001, loss_test:0.06346, lr:7.32e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.091, tt:6738.604\n",
      "Ep:116, loss:0.00001, loss_test:0.06408, lr:7.25e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.075, tt:6794.719\n",
      "Ep:117, loss:0.00001, loss_test:0.06588, lr:7.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.074, tt:6852.785\n",
      "Ep:118, loss:0.00001, loss_test:0.06431, lr:7.11e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.064, tt:6909.596\n",
      "Ep:119, loss:0.00001, loss_test:0.06376, lr:7.03e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.067, tt:6968.082\n",
      "Ep:120, loss:0.00001, loss_test:0.06460, lr:6.96e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.053, tt:7024.358\n",
      "Ep:121, loss:0.00001, loss_test:0.06438, lr:6.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.061, tt:7083.501\n",
      "Ep:122, loss:0.00001, loss_test:0.06436, lr:6.83e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.046, tt:7139.673\n",
      "Ep:123, loss:0.00001, loss_test:0.06430, lr:6.76e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.034, tt:7196.231\n",
      "Ep:124, loss:0.00001, loss_test:0.06386, lr:6.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.026, tt:7253.202\n",
      "Ep:125, loss:0.00001, loss_test:0.06503, lr:6.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.014, tt:7309.713\n",
      "Ep:126, loss:0.00001, loss_test:0.06407, lr:6.56e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.003, tt:7366.416\n",
      "Ep:127, loss:0.00001, loss_test:0.06496, lr:6.49e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.011, tt:7425.414\n",
      "Ep:128, loss:0.00001, loss_test:0.06442, lr:6.43e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.018, tt:7484.322\n",
      "Ep:129, loss:0.00001, loss_test:0.06401, lr:6.36e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.024, tt:7543.061\n",
      "Ep:130, loss:0.00001, loss_test:0.06507, lr:6.30e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.029, tt:7601.747\n",
      "Ep:131, loss:0.00001, loss_test:0.06360, lr:6.24e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.038, tt:7661.066\n",
      "Ep:132, loss:0.00001, loss_test:0.06500, lr:6.17e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.033, tt:7718.435\n",
      "Ep:133, loss:0.00001, loss_test:0.06533, lr:6.11e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.026, tt:7775.445\n",
      "Ep:134, loss:0.00001, loss_test:0.06451, lr:6.05e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.025, tt:7833.313\n",
      "Ep:135, loss:0.00001, loss_test:0.06577, lr:5.99e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.005, tt:7888.672\n",
      "Ep:136, loss:0.00001, loss_test:0.06431, lr:5.93e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.003, tt:7946.415\n",
      "Ep:137, loss:0.00001, loss_test:0.06568, lr:5.87e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.008, tt:8005.105\n",
      "Ep:138, loss:0.00001, loss_test:0.06435, lr:5.81e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.015, tt:8064.141\n",
      "Ep:139, loss:0.00001, loss_test:0.06530, lr:5.75e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.029, tt:8124.080\n",
      "Ep:140, loss:0.00001, loss_test:0.06464, lr:5.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.032, tt:8182.546\n",
      "Ep:141, loss:0.00001, loss_test:0.06477, lr:5.64e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.033, tt:8240.637\n",
      "Ep:142, loss:0.00001, loss_test:0.06506, lr:5.58e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.044, tt:8300.220\n",
      "Ep:143, loss:0.00001, loss_test:0.06511, lr:5.53e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.008, tt:8353.091\n",
      "Ep:144, loss:0.00001, loss_test:0.06557, lr:5.47e-03, fs:0.88770 (r=0.838,p=0.943),  time:57.998, tt:8409.747\n",
      "Ep:145, loss:0.00001, loss_test:0.06457, lr:5.42e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.000, tt:8468.008\n",
      "Ep:146, loss:0.00001, loss_test:0.06599, lr:5.36e-03, fs:0.88770 (r=0.838,p=0.943),  time:58.004, tt:8526.543\n",
      "Ep:147, loss:0.00001, loss_test:0.06471, lr:5.31e-03, fs:0.88770 (r=0.838,p=0.943),  time:57.996, tt:8583.349\n",
      "Ep:148, loss:0.00001, loss_test:0.06553, lr:5.26e-03, fs:0.88770 (r=0.838,p=0.943),  time:57.963, tt:8636.432\n",
      "Ep:149, loss:0.00001, loss_test:0.06509, lr:5.20e-03, fs:0.88770 (r=0.838,p=0.943),  time:57.934, tt:8690.175\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 87\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14630, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.776, tt:58.776\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14476, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:55.329, tt:110.659\n",
      "Ep:2, loss:0.00055, loss_test:0.14196, lr:1.00e-02, fs:0.64138 (r=0.939,p=0.487),  time:54.658, tt:163.975\n",
      "Ep:3, loss:0.00052, loss_test:0.13552, lr:1.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:55.508, tt:222.033\n",
      "Ep:4, loss:0.00048, loss_test:0.13189, lr:1.00e-02, fs:0.60377 (r=0.646,p=0.566),  time:56.478, tt:282.388\n",
      "Ep:5, loss:0.00045, loss_test:0.13190, lr:1.00e-02, fs:0.61187 (r=0.677,p=0.558),  time:56.976, tt:341.859\n",
      "Ep:6, loss:0.00043, loss_test:0.12629, lr:1.00e-02, fs:0.62882 (r=0.727,p=0.554),  time:57.371, tt:401.598\n",
      "Ep:7, loss:0.00041, loss_test:0.12241, lr:1.00e-02, fs:0.63636 (r=0.707,p=0.579),  time:57.192, tt:457.533\n",
      "Ep:8, loss:0.00039, loss_test:0.11876, lr:1.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:57.641, tt:518.767\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00038, loss_test:0.11489, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:57.686, tt:576.861\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00036, loss_test:0.10987, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:57.971, tt:637.686\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00035, loss_test:0.10696, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:58.165, tt:697.974\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.10372, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:58.260, tt:757.376\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.10217, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:58.340, tt:816.764\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00031, loss_test:0.09917, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:58.323, tt:874.842\n",
      "Ep:15, loss:0.00030, loss_test:0.09845, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:58.266, tt:932.253\n",
      "Ep:16, loss:0.00029, loss_test:0.09433, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:58.253, tt:990.307\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00028, loss_test:0.09583, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:58.234, tt:1048.216\n",
      "Ep:18, loss:0.00027, loss_test:0.09357, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:58.123, tt:1104.342\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00026, loss_test:0.09079, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:58.126, tt:1162.522\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00025, loss_test:0.09145, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:58.242, tt:1223.085\n",
      "Ep:21, loss:0.00024, loss_test:0.08834, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:58.392, tt:1284.623\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.08935, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:58.355, tt:1342.169\n",
      "Ep:23, loss:0.00022, loss_test:0.08832, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:58.251, tt:1398.032\n",
      "Ep:24, loss:0.00021, loss_test:0.08627, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:58.195, tt:1454.867\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.08623, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:58.197, tt:1513.120\n",
      "Ep:26, loss:0.00020, loss_test:0.08310, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:58.066, tt:1567.785\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.08586, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:57.910, tt:1621.486\n",
      "Ep:28, loss:0.00018, loss_test:0.08599, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:57.848, tt:1677.599\n",
      "Ep:29, loss:0.00017, loss_test:0.08453, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:57.824, tt:1734.730\n",
      "Ep:30, loss:0.00017, loss_test:0.08797, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:57.692, tt:1788.445\n",
      "Ep:31, loss:0.00016, loss_test:0.08310, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:57.616, tt:1843.696\n",
      "Ep:32, loss:0.00015, loss_test:0.08256, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:57.600, tt:1900.788\n",
      "Ep:33, loss:0.00015, loss_test:0.08201, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:57.523, tt:1955.771\n",
      "Ep:34, loss:0.00014, loss_test:0.08163, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:57.430, tt:2010.042\n",
      "Ep:35, loss:0.00013, loss_test:0.08089, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:57.418, tt:2067.033\n",
      "Ep:36, loss:0.00012, loss_test:0.08428, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:57.421, tt:2124.576\n",
      "Ep:37, loss:0.00012, loss_test:0.08238, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:57.394, tt:2180.983\n",
      "Ep:38, loss:0.00011, loss_test:0.07888, lr:9.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:57.283, tt:2234.026\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.07768, lr:9.90e-03, fs:0.86339 (r=0.798,p=0.940),  time:57.282, tt:2291.291\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07986, lr:9.90e-03, fs:0.84091 (r=0.747,p=0.961),  time:57.237, tt:2346.719\n",
      "Ep:41, loss:0.00010, loss_test:0.08163, lr:9.90e-03, fs:0.79290 (r=0.677,p=0.957),  time:57.246, tt:2404.346\n",
      "Ep:42, loss:0.00009, loss_test:0.08044, lr:9.90e-03, fs:0.79762 (r=0.677,p=0.971),  time:57.155, tt:2457.682\n",
      "Ep:43, loss:0.00009, loss_test:0.08414, lr:9.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:57.162, tt:2515.121\n",
      "Ep:44, loss:0.00009, loss_test:0.08271, lr:9.90e-03, fs:0.76074 (r=0.626,p=0.969),  time:57.128, tt:2570.752\n",
      "Ep:45, loss:0.00008, loss_test:0.07852, lr:9.90e-03, fs:0.84091 (r=0.747,p=0.961),  time:57.087, tt:2626.002\n",
      "Ep:46, loss:0.00008, loss_test:0.07756, lr:9.90e-03, fs:0.86667 (r=0.788,p=0.963),  time:57.139, tt:2685.545\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07667, lr:9.90e-03, fs:0.86034 (r=0.778,p=0.963),  time:57.134, tt:2742.430\n",
      "Ep:48, loss:0.00007, loss_test:0.07805, lr:9.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.115, tt:2798.653\n",
      "Ep:49, loss:0.00007, loss_test:0.07771, lr:9.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.127, tt:2856.352\n",
      "Ep:50, loss:0.00007, loss_test:0.08244, lr:9.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.122, tt:2913.215\n",
      "Ep:51, loss:0.00007, loss_test:0.08099, lr:9.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.166, tt:2972.622\n",
      "Ep:52, loss:0.00006, loss_test:0.07912, lr:9.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.087, tt:3025.586\n",
      "Ep:53, loss:0.00006, loss_test:0.07811, lr:9.90e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.064, tt:3081.458\n",
      "Ep:54, loss:0.00006, loss_test:0.07768, lr:9.90e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.070, tt:3138.860\n",
      "Ep:55, loss:0.00006, loss_test:0.07769, lr:9.90e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.056, tt:3195.162\n",
      "Ep:56, loss:0.00005, loss_test:0.08040, lr:9.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.044, tt:3251.514\n",
      "Ep:57, loss:0.00005, loss_test:0.08151, lr:9.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:57.044, tt:3308.545\n",
      "Ep:58, loss:0.00005, loss_test:0.08201, lr:9.80e-03, fs:0.75610 (r=0.626,p=0.954),  time:57.068, tt:3366.983\n",
      "Ep:59, loss:0.00005, loss_test:0.08281, lr:9.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:57.089, tt:3425.318\n",
      "Ep:60, loss:0.00005, loss_test:0.07987, lr:9.61e-03, fs:0.80000 (r=0.687,p=0.958),  time:57.082, tt:3481.986\n",
      "Ep:61, loss:0.00004, loss_test:0.07809, lr:9.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.066, tt:3538.111\n",
      "Ep:62, loss:0.00004, loss_test:0.07719, lr:9.41e-03, fs:0.87293 (r=0.798,p=0.963),  time:57.035, tt:3593.178\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.07922, lr:9.41e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.065, tt:3652.150\n",
      "Ep:64, loss:0.00004, loss_test:0.07836, lr:9.41e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.097, tt:3711.301\n",
      "Ep:65, loss:0.00004, loss_test:0.07705, lr:9.41e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.098, tt:3768.436\n",
      "Ep:66, loss:0.00004, loss_test:0.07899, lr:9.41e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.112, tt:3826.507\n",
      "Ep:67, loss:0.00003, loss_test:0.07574, lr:9.41e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.108, tt:3883.373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00003, loss_test:0.07869, lr:9.41e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.108, tt:3940.484\n",
      "Ep:69, loss:0.00003, loss_test:0.07983, lr:9.41e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.100, tt:3996.976\n",
      "Ep:70, loss:0.00003, loss_test:0.08262, lr:9.41e-03, fs:0.78571 (r=0.667,p=0.957),  time:57.111, tt:4054.899\n",
      "Ep:71, loss:0.00003, loss_test:0.08221, lr:9.41e-03, fs:0.79762 (r=0.677,p=0.971),  time:57.117, tt:4112.438\n",
      "Ep:72, loss:0.00003, loss_test:0.08212, lr:9.41e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.086, tt:4167.309\n",
      "Ep:73, loss:0.00003, loss_test:0.08220, lr:9.41e-03, fs:0.76074 (r=0.626,p=0.969),  time:57.074, tt:4223.481\n",
      "Ep:74, loss:0.00003, loss_test:0.08038, lr:9.32e-03, fs:0.80723 (r=0.677,p=1.000),  time:57.074, tt:4280.545\n",
      "Ep:75, loss:0.00003, loss_test:0.07979, lr:9.23e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.093, tt:4339.100\n",
      "Ep:76, loss:0.00003, loss_test:0.07741, lr:9.14e-03, fs:0.84091 (r=0.747,p=0.961),  time:57.099, tt:4396.592\n",
      "Ep:77, loss:0.00003, loss_test:0.07751, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.070, tt:4451.443\n",
      "Ep:78, loss:0.00002, loss_test:0.07944, lr:8.95e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.064, tt:4508.091\n",
      "Ep:79, loss:0.00002, loss_test:0.08221, lr:8.86e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.041, tt:4563.266\n",
      "Ep:80, loss:0.00002, loss_test:0.08119, lr:8.78e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.037, tt:4619.996\n",
      "Ep:81, loss:0.00002, loss_test:0.08000, lr:8.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.039, tt:4677.219\n",
      "Ep:82, loss:0.00002, loss_test:0.07868, lr:8.60e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.045, tt:4734.762\n",
      "Ep:83, loss:0.00002, loss_test:0.07712, lr:8.51e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.066, tt:4793.524\n",
      "Ep:84, loss:0.00002, loss_test:0.08065, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.057, tt:4849.831\n",
      "Ep:85, loss:0.00002, loss_test:0.08212, lr:8.35e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.995, tt:4901.545\n",
      "Ep:86, loss:0.00002, loss_test:0.08132, lr:8.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.002, tt:4959.200\n",
      "Ep:87, loss:0.00002, loss_test:0.08128, lr:8.18e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.043, tt:5019.824\n",
      "Ep:88, loss:0.00002, loss_test:0.07872, lr:8.10e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.021, tt:5074.886\n",
      "Ep:89, loss:0.00002, loss_test:0.07665, lr:8.02e-03, fs:0.84091 (r=0.747,p=0.961),  time:57.034, tt:5133.074\n",
      "Ep:90, loss:0.00002, loss_test:0.07974, lr:7.94e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.023, tt:5189.049\n",
      "Ep:91, loss:0.00002, loss_test:0.08231, lr:7.86e-03, fs:0.80702 (r=0.697,p=0.958),  time:57.003, tt:5244.256\n",
      "Ep:92, loss:0.00002, loss_test:0.08084, lr:7.78e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.993, tt:5300.317\n",
      "Ep:93, loss:0.00002, loss_test:0.07904, lr:7.70e-03, fs:0.83429 (r=0.737,p=0.961),  time:56.965, tt:5354.705\n",
      "Ep:94, loss:0.00002, loss_test:0.07928, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.950, tt:5410.241\n",
      "Ep:95, loss:0.00001, loss_test:0.08160, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.964, tt:5468.555\n",
      "Ep:96, loss:0.00001, loss_test:0.08147, lr:7.47e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.962, tt:5525.307\n",
      "Ep:97, loss:0.00002, loss_test:0.08059, lr:7.40e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.947, tt:5580.802\n",
      "Ep:98, loss:0.00001, loss_test:0.07895, lr:7.32e-03, fs:0.83429 (r=0.737,p=0.961),  time:56.912, tt:5634.276\n",
      "Ep:99, loss:0.00001, loss_test:0.07936, lr:7.25e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.901, tt:5690.135\n",
      "Ep:100, loss:0.00001, loss_test:0.07906, lr:7.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.890, tt:5745.918\n",
      "Ep:101, loss:0.00001, loss_test:0.07846, lr:7.11e-03, fs:0.83429 (r=0.737,p=0.961),  time:56.879, tt:5801.693\n",
      "Ep:102, loss:0.00001, loss_test:0.08016, lr:7.03e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.862, tt:5856.768\n",
      "Ep:103, loss:0.00001, loss_test:0.08110, lr:6.96e-03, fs:0.81395 (r=0.707,p=0.959),  time:56.856, tt:5913.012\n",
      "Ep:104, loss:0.00001, loss_test:0.08022, lr:6.89e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.859, tt:5970.175\n",
      "Ep:105, loss:0.00001, loss_test:0.07845, lr:6.83e-03, fs:0.80702 (r=0.697,p=0.958),  time:56.845, tt:6025.592\n",
      "Ep:106, loss:0.00001, loss_test:0.07931, lr:6.76e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.827, tt:6080.464\n",
      "Ep:107, loss:0.00001, loss_test:0.08131, lr:6.69e-03, fs:0.80000 (r=0.687,p=0.958),  time:56.841, tt:6138.785\n",
      "Ep:108, loss:0.00001, loss_test:0.07794, lr:6.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.834, tt:6194.929\n",
      "Ep:109, loss:0.00001, loss_test:0.07874, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.820, tt:6250.160\n",
      "Ep:110, loss:0.00001, loss_test:0.07980, lr:6.49e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.817, tt:6306.679\n",
      "Ep:111, loss:0.00001, loss_test:0.07976, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.818, tt:6363.560\n",
      "Ep:112, loss:0.00001, loss_test:0.07808, lr:6.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.836, tt:6422.443\n",
      "Ep:113, loss:0.00001, loss_test:0.07919, lr:6.30e-03, fs:0.82081 (r=0.717,p=0.959),  time:56.835, tt:6479.179\n",
      "Ep:114, loss:0.00001, loss_test:0.07861, lr:6.24e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.815, tt:6533.771\n",
      "Ep:115, loss:0.00001, loss_test:0.07995, lr:6.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.819, tt:6591.022\n",
      "Ep:116, loss:0.00001, loss_test:0.07852, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.831, tt:6649.258\n",
      "Ep:117, loss:0.00001, loss_test:0.07867, lr:6.05e-03, fs:0.82081 (r=0.717,p=0.959),  time:56.839, tt:6707.026\n",
      "Ep:118, loss:0.00001, loss_test:0.07916, lr:5.99e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.855, tt:6765.795\n",
      "Ep:119, loss:0.00001, loss_test:0.07874, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.859, tt:6823.030\n",
      "Ep:120, loss:0.00001, loss_test:0.07827, lr:5.87e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.853, tt:6879.273\n",
      "Ep:121, loss:0.00001, loss_test:0.07840, lr:5.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.870, tt:6938.128\n",
      "Ep:122, loss:0.00001, loss_test:0.07821, lr:5.75e-03, fs:0.82081 (r=0.717,p=0.959),  time:56.858, tt:6993.559\n",
      "Ep:123, loss:0.00001, loss_test:0.07847, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.878, tt:7052.881\n",
      "Ep:124, loss:0.00001, loss_test:0.07906, lr:5.64e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.898, tt:7112.295\n",
      "Ep:125, loss:0.00001, loss_test:0.07802, lr:5.58e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.899, tt:7169.310\n",
      "Ep:126, loss:0.00001, loss_test:0.07925, lr:5.53e-03, fs:0.82081 (r=0.717,p=0.959),  time:56.911, tt:7227.758\n",
      "Ep:127, loss:0.00001, loss_test:0.07759, lr:5.47e-03, fs:0.83429 (r=0.737,p=0.961),  time:56.902, tt:7283.518\n",
      "Ep:128, loss:0.00001, loss_test:0.07979, lr:5.42e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.922, tt:7342.962\n",
      "Ep:129, loss:0.00001, loss_test:0.07928, lr:5.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.929, tt:7400.780\n",
      "Ep:130, loss:0.00001, loss_test:0.07712, lr:5.31e-03, fs:0.83429 (r=0.737,p=0.961),  time:56.963, tt:7462.176\n",
      "Ep:131, loss:0.00001, loss_test:0.08008, lr:5.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:56.985, tt:7521.999\n",
      "Ep:132, loss:0.00001, loss_test:0.07825, lr:5.20e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.002, tt:7581.225\n",
      "Ep:133, loss:0.00001, loss_test:0.07803, lr:5.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:56.999, tt:7637.832\n",
      "Ep:134, loss:0.00001, loss_test:0.07919, lr:5.10e-03, fs:0.82081 (r=0.717,p=0.959),  time:56.997, tt:7694.537\n",
      "Ep:135, loss:0.00001, loss_test:0.07772, lr:5.05e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.018, tt:7754.454\n",
      "Ep:136, loss:0.00001, loss_test:0.07899, lr:5.00e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.031, tt:7813.304\n",
      "Ep:137, loss:0.00001, loss_test:0.07877, lr:4.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:57.065, tt:7874.991\n",
      "Ep:138, loss:0.00001, loss_test:0.07783, lr:4.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.082, tt:7934.434\n",
      "Ep:139, loss:0.00001, loss_test:0.07772, lr:4.85e-03, fs:0.81395 (r=0.707,p=0.959),  time:57.095, tt:7993.360\n",
      "Ep:140, loss:0.00001, loss_test:0.07863, lr:4.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.114, tt:8053.135\n",
      "Ep:141, loss:0.00001, loss_test:0.07760, lr:4.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.126, tt:8111.928\n",
      "Ep:142, loss:0.00001, loss_test:0.07762, lr:4.71e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.165, tt:8174.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.07831, lr:4.66e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.121, tt:8225.403\n",
      "Ep:144, loss:0.00001, loss_test:0.07762, lr:4.61e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.141, tt:8285.459\n",
      "Ep:145, loss:0.00001, loss_test:0.07794, lr:4.57e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.176, tt:8347.725\n",
      "Ep:146, loss:0.00001, loss_test:0.07811, lr:4.52e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.183, tt:8405.845\n",
      "Ep:147, loss:0.00001, loss_test:0.07715, lr:4.48e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.143, tt:8457.167\n",
      "Ep:148, loss:0.00001, loss_test:0.07780, lr:4.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.149, tt:8515.229\n",
      "Ep:149, loss:0.00001, loss_test:0.07759, lr:4.39e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.066, tt:8559.908\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 88\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14385, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.358, tt:57.358\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14153, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:55.732, tt:111.465\n",
      "Ep:2, loss:0.00054, loss_test:0.13617, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:53.368, tt:160.104\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.12577, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:54.491, tt:217.966\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.12255, lr:1.00e-02, fs:0.55135 (r=0.515,p=0.593),  time:55.330, tt:276.651\n",
      "Ep:5, loss:0.00045, loss_test:0.12049, lr:1.00e-02, fs:0.58462 (r=0.576,p=0.594),  time:56.817, tt:340.902\n",
      "Ep:6, loss:0.00042, loss_test:0.11860, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:57.365, tt:401.554\n",
      "Ep:7, loss:0.00040, loss_test:0.11771, lr:1.00e-02, fs:0.62032 (r=0.586,p=0.659),  time:57.234, tt:457.873\n",
      "Ep:8, loss:0.00038, loss_test:0.11416, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:57.485, tt:517.364\n",
      "Ep:9, loss:0.00036, loss_test:0.11470, lr:1.00e-02, fs:0.63102 (r=0.596,p=0.670),  time:57.559, tt:575.588\n",
      "Ep:10, loss:0.00034, loss_test:0.11453, lr:1.00e-02, fs:0.67016 (r=0.646,p=0.696),  time:57.557, tt:633.127\n",
      "Ep:11, loss:0.00033, loss_test:0.11354, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:57.726, tt:692.706\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.11389, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:57.978, tt:753.713\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.11143, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:57.974, tt:811.629\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.11216, lr:1.00e-02, fs:0.69892 (r=0.657,p=0.747),  time:58.012, tt:870.175\n",
      "Ep:15, loss:0.00028, loss_test:0.11212, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:58.098, tt:929.573\n",
      "Ep:16, loss:0.00027, loss_test:0.11185, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:58.207, tt:989.515\n",
      "Ep:17, loss:0.00026, loss_test:0.11078, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:58.208, tt:1047.748\n",
      "Ep:18, loss:0.00025, loss_test:0.11194, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:58.197, tt:1105.751\n",
      "Ep:19, loss:0.00024, loss_test:0.11037, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:58.270, tt:1165.404\n",
      "Ep:20, loss:0.00023, loss_test:0.11153, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:58.179, tt:1221.755\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.11171, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:58.281, tt:1282.193\n",
      "Ep:22, loss:0.00022, loss_test:0.11141, lr:1.00e-02, fs:0.68132 (r=0.626,p=0.747),  time:58.352, tt:1342.102\n",
      "Ep:23, loss:0.00021, loss_test:0.11089, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:58.394, tt:1401.461\n",
      "Ep:24, loss:0.00020, loss_test:0.11588, lr:1.00e-02, fs:0.65537 (r=0.586,p=0.744),  time:58.425, tt:1460.621\n",
      "Ep:25, loss:0.00019, loss_test:0.11077, lr:1.00e-02, fs:0.67416 (r=0.606,p=0.759),  time:58.285, tt:1515.420\n",
      "Ep:26, loss:0.00019, loss_test:0.11498, lr:1.00e-02, fs:0.67778 (r=0.616,p=0.753),  time:58.343, tt:1575.268\n",
      "Ep:27, loss:0.00018, loss_test:0.11659, lr:1.00e-02, fs:0.66286 (r=0.586,p=0.763),  time:58.420, tt:1635.759\n",
      "Ep:28, loss:0.00017, loss_test:0.11624, lr:1.00e-02, fs:0.66667 (r=0.586,p=0.773),  time:58.440, tt:1694.774\n",
      "Ep:29, loss:0.00017, loss_test:0.11677, lr:1.00e-02, fs:0.67052 (r=0.586,p=0.784),  time:58.397, tt:1751.917\n",
      "Ep:30, loss:0.00016, loss_test:0.11867, lr:1.00e-02, fs:0.65896 (r=0.576,p=0.770),  time:58.426, tt:1811.216\n",
      "Ep:31, loss:0.00015, loss_test:0.11732, lr:1.00e-02, fs:0.66667 (r=0.576,p=0.792),  time:58.406, tt:1868.987\n",
      "Ep:32, loss:0.00015, loss_test:0.11237, lr:9.90e-03, fs:0.67442 (r=0.586,p=0.795),  time:58.450, tt:1928.844\n",
      "Ep:33, loss:0.00014, loss_test:0.12073, lr:9.80e-03, fs:0.65882 (r=0.566,p=0.789),  time:58.458, tt:1987.586\n",
      "Ep:34, loss:0.00013, loss_test:0.11805, lr:9.70e-03, fs:0.65882 (r=0.566,p=0.789),  time:58.484, tt:2046.957\n",
      "Ep:35, loss:0.00013, loss_test:0.11800, lr:9.61e-03, fs:0.66272 (r=0.566,p=0.800),  time:58.462, tt:2104.647\n",
      "Ep:36, loss:0.00012, loss_test:0.12273, lr:9.51e-03, fs:0.65882 (r=0.566,p=0.789),  time:58.509, tt:2164.834\n",
      "Ep:37, loss:0.00012, loss_test:0.12078, lr:9.41e-03, fs:0.66272 (r=0.566,p=0.800),  time:58.590, tt:2226.409\n",
      "Ep:38, loss:0.00011, loss_test:0.11948, lr:9.32e-03, fs:0.66667 (r=0.566,p=0.812),  time:58.591, tt:2285.030\n",
      "Ep:39, loss:0.00011, loss_test:0.11950, lr:9.23e-03, fs:0.67066 (r=0.566,p=0.824),  time:58.590, tt:2343.597\n",
      "Ep:40, loss:0.00011, loss_test:0.12123, lr:9.14e-03, fs:0.67066 (r=0.566,p=0.824),  time:58.651, tt:2404.676\n",
      "Ep:41, loss:0.00010, loss_test:0.12502, lr:9.04e-03, fs:0.67879 (r=0.566,p=0.848),  time:58.649, tt:2463.275\n",
      "Ep:42, loss:0.00010, loss_test:0.12183, lr:8.95e-03, fs:0.69048 (r=0.586,p=0.841),  time:58.692, tt:2523.767\n",
      "Ep:43, loss:0.00009, loss_test:0.12185, lr:8.86e-03, fs:0.68712 (r=0.566,p=0.875),  time:58.830, tt:2588.539\n",
      "Ep:44, loss:0.00009, loss_test:0.12361, lr:8.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:58.897, tt:2650.385\n",
      "Ep:45, loss:0.00009, loss_test:0.12026, lr:8.69e-03, fs:0.70303 (r=0.586,p=0.879),  time:58.902, tt:2709.470\n",
      "Ep:46, loss:0.00008, loss_test:0.12266, lr:8.60e-03, fs:0.69461 (r=0.586,p=0.853),  time:58.885, tt:2767.574\n",
      "Ep:47, loss:0.00008, loss_test:0.12281, lr:8.51e-03, fs:0.70303 (r=0.586,p=0.879),  time:58.867, tt:2825.627\n",
      "Ep:48, loss:0.00008, loss_test:0.12309, lr:8.43e-03, fs:0.70303 (r=0.586,p=0.879),  time:58.854, tt:2883.847\n",
      "Ep:49, loss:0.00007, loss_test:0.11926, lr:8.35e-03, fs:0.69461 (r=0.586,p=0.853),  time:58.874, tt:2943.716\n",
      "Ep:50, loss:0.00007, loss_test:0.11989, lr:8.26e-03, fs:0.70732 (r=0.586,p=0.892),  time:58.847, tt:3001.195\n",
      "Ep:51, loss:0.00007, loss_test:0.12497, lr:8.18e-03, fs:0.70732 (r=0.586,p=0.892),  time:58.880, tt:3061.778\n",
      "Ep:52, loss:0.00007, loss_test:0.12162, lr:8.10e-03, fs:0.70588 (r=0.606,p=0.845),  time:58.861, tt:3119.649\n",
      "Ep:53, loss:0.00006, loss_test:0.12257, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:58.852, tt:3177.995\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.12029, lr:8.02e-03, fs:0.70303 (r=0.586,p=0.879),  time:58.890, tt:3238.964\n",
      "Ep:55, loss:0.00006, loss_test:0.12281, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:58.988, tt:3303.303\n",
      "Ep:56, loss:0.00006, loss_test:0.11887, lr:8.02e-03, fs:0.71515 (r=0.596,p=0.894),  time:59.042, tt:3365.421\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.12002, lr:8.02e-03, fs:0.70732 (r=0.586,p=0.892),  time:59.046, tt:3424.675\n",
      "Ep:58, loss:0.00006, loss_test:0.11959, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:59.068, tt:3485.024\n",
      "Ep:59, loss:0.00005, loss_test:0.12180, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.091, tt:3545.432\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.11909, lr:8.02e-03, fs:0.70732 (r=0.586,p=0.892),  time:59.095, tt:3604.804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00005, loss_test:0.12043, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.132, tt:3666.207\n",
      "Ep:62, loss:0.00005, loss_test:0.12145, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.142, tt:3725.975\n",
      "Ep:63, loss:0.00005, loss_test:0.11874, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:59.150, tt:3785.593\n",
      "Ep:64, loss:0.00005, loss_test:0.12118, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:59.174, tt:3846.332\n",
      "Ep:65, loss:0.00005, loss_test:0.12036, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:59.161, tt:3904.627\n",
      "Ep:66, loss:0.00004, loss_test:0.11985, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.161, tt:3963.773\n",
      "Ep:67, loss:0.00004, loss_test:0.11963, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:59.221, tt:4027.024\n",
      "Ep:68, loss:0.00004, loss_test:0.12049, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.257, tt:4088.759\n",
      "Ep:69, loss:0.00004, loss_test:0.12075, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.318, tt:4152.274\n",
      "Ep:70, loss:0.00004, loss_test:0.11915, lr:8.02e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.350, tt:4213.828\n",
      "Ep:71, loss:0.00004, loss_test:0.11974, lr:7.94e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.357, tt:4273.692\n",
      "Ep:72, loss:0.00004, loss_test:0.11991, lr:7.86e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.364, tt:4333.551\n",
      "Ep:73, loss:0.00004, loss_test:0.12087, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.365, tt:4393.013\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.11808, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.383, tt:4453.728\n",
      "Ep:75, loss:0.00004, loss_test:0.11988, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.427, tt:4516.476\n",
      "Ep:76, loss:0.00003, loss_test:0.11981, lr:7.78e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.496, tt:4581.163\n",
      "Ep:77, loss:0.00003, loss_test:0.11925, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.507, tt:4641.575\n",
      "Ep:78, loss:0.00003, loss_test:0.12011, lr:7.78e-03, fs:0.71605 (r=0.586,p=0.921),  time:59.458, tt:4697.197\n",
      "Ep:79, loss:0.00003, loss_test:0.11935, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.449, tt:4755.885\n",
      "Ep:80, loss:0.00003, loss_test:0.11974, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.452, tt:4815.587\n",
      "Ep:81, loss:0.00003, loss_test:0.11867, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.437, tt:4873.817\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00003, loss_test:0.11922, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.428, tt:4932.551\n",
      "Ep:83, loss:0.00003, loss_test:0.12019, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.394, tt:4989.118\n",
      "Ep:84, loss:0.00003, loss_test:0.12166, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:59.392, tt:5048.329\n",
      "Ep:85, loss:0.00003, loss_test:0.11958, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.394, tt:5107.869\n",
      "Ep:86, loss:0.00003, loss_test:0.12015, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.406, tt:5168.284\n",
      "Ep:87, loss:0.00003, loss_test:0.12058, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.422, tt:5229.129\n",
      "Ep:88, loss:0.00003, loss_test:0.11891, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.434, tt:5289.620\n",
      "Ep:89, loss:0.00003, loss_test:0.11968, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.410, tt:5346.927\n",
      "Ep:90, loss:0.00003, loss_test:0.11918, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.396, tt:5405.045\n",
      "Ep:91, loss:0.00002, loss_test:0.12027, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.400, tt:5464.760\n",
      "Ep:92, loss:0.00002, loss_test:0.11974, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.432, tt:5527.167\n",
      "Ep:93, loss:0.00002, loss_test:0.11984, lr:7.70e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.423, tt:5585.806\n",
      "Ep:94, loss:0.00002, loss_test:0.12041, lr:7.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.440, tt:5646.822\n",
      "Ep:95, loss:0.00002, loss_test:0.11917, lr:7.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:59.437, tt:5705.918\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.11993, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.414, tt:5763.162\n",
      "Ep:97, loss:0.00002, loss_test:0.11928, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.392, tt:5820.369\n",
      "Ep:98, loss:0.00002, loss_test:0.12177, lr:7.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:59.388, tt:5879.400\n",
      "Ep:99, loss:0.00002, loss_test:0.12083, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.361, tt:5936.079\n",
      "Ep:100, loss:0.00002, loss_test:0.12101, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.353, tt:5994.606\n",
      "Ep:101, loss:0.00002, loss_test:0.12041, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.355, tt:6054.250\n",
      "Ep:102, loss:0.00002, loss_test:0.12115, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.345, tt:6112.554\n",
      "Ep:103, loss:0.00002, loss_test:0.11940, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.327, tt:6170.001\n",
      "Ep:104, loss:0.00002, loss_test:0.12087, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:59.320, tt:6228.643\n",
      "Ep:105, loss:0.00002, loss_test:0.12117, lr:7.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:59.327, tt:6288.658\n",
      "Ep:106, loss:0.00002, loss_test:0.12166, lr:7.55e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.293, tt:6344.357\n",
      "Ep:107, loss:0.00002, loss_test:0.12243, lr:7.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.310, tt:6405.502\n",
      "Ep:108, loss:0.00002, loss_test:0.12339, lr:7.40e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.364, tt:6470.730\n",
      "Ep:109, loss:0.00002, loss_test:0.12127, lr:7.32e-03, fs:0.71698 (r=0.576,p=0.950),  time:59.371, tt:6530.841\n",
      "Ep:110, loss:0.00002, loss_test:0.12185, lr:7.25e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.382, tt:6591.356\n",
      "Ep:111, loss:0.00002, loss_test:0.12145, lr:7.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.410, tt:6653.869\n",
      "Ep:112, loss:0.00002, loss_test:0.12158, lr:7.11e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.449, tt:6717.693\n",
      "Ep:113, loss:0.00002, loss_test:0.12106, lr:7.03e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.443, tt:6776.513\n",
      "Ep:114, loss:0.00001, loss_test:0.12272, lr:6.96e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.462, tt:6838.132\n",
      "Ep:115, loss:0.00001, loss_test:0.12195, lr:6.89e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.508, tt:6902.936\n",
      "Ep:116, loss:0.00001, loss_test:0.12120, lr:6.83e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.564, tt:6969.035\n",
      "Ep:117, loss:0.00001, loss_test:0.12286, lr:6.76e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.622, tt:7035.362\n",
      "Ep:118, loss:0.00001, loss_test:0.12257, lr:6.69e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.668, tt:7100.535\n",
      "Ep:119, loss:0.00001, loss_test:0.12240, lr:6.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.696, tt:7163.526\n",
      "Ep:120, loss:0.00001, loss_test:0.12318, lr:6.56e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.728, tt:7227.049\n",
      "Ep:121, loss:0.00001, loss_test:0.12259, lr:6.49e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.771, tt:7292.068\n",
      "Ep:122, loss:0.00001, loss_test:0.12268, lr:6.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.803, tt:7355.736\n",
      "Ep:123, loss:0.00001, loss_test:0.12243, lr:6.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.833, tt:7419.343\n",
      "Ep:124, loss:0.00001, loss_test:0.12360, lr:6.30e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.869, tt:7483.578\n",
      "Ep:125, loss:0.00001, loss_test:0.12307, lr:6.24e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.901, tt:7547.481\n",
      "Ep:126, loss:0.00001, loss_test:0.12247, lr:6.17e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.881, tt:7604.895\n",
      "Ep:127, loss:0.00001, loss_test:0.12294, lr:6.11e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.906, tt:7667.942\n",
      "Ep:128, loss:0.00001, loss_test:0.12317, lr:6.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.955, tt:7734.221\n",
      "Ep:129, loss:0.00001, loss_test:0.12379, lr:5.99e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.997, tt:7799.640\n",
      "Ep:130, loss:0.00001, loss_test:0.12259, lr:5.93e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.026, tt:7863.470\n",
      "Ep:131, loss:0.00001, loss_test:0.12260, lr:5.87e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.048, tt:7926.377\n",
      "Ep:132, loss:0.00001, loss_test:0.12344, lr:5.81e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.085, tt:7991.247\n",
      "Ep:133, loss:0.00001, loss_test:0.12380, lr:5.75e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.122, tt:8056.370\n",
      "Ep:134, loss:0.00001, loss_test:0.12290, lr:5.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.170, tt:8122.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.12318, lr:5.64e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.191, tt:8185.963\n",
      "Ep:136, loss:0.00001, loss_test:0.12320, lr:5.58e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.241, tt:8252.986\n",
      "Ep:137, loss:0.00001, loss_test:0.12257, lr:5.53e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.267, tt:8316.824\n",
      "Ep:138, loss:0.00001, loss_test:0.12310, lr:5.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.298, tt:8381.439\n",
      "Ep:139, loss:0.00001, loss_test:0.12332, lr:5.42e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.324, tt:8445.374\n",
      "Ep:140, loss:0.00001, loss_test:0.12326, lr:5.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.363, tt:8511.165\n",
      "Ep:141, loss:0.00001, loss_test:0.12293, lr:5.31e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.388, tt:8575.115\n",
      "Ep:142, loss:0.00001, loss_test:0.12345, lr:5.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.429, tt:8641.387\n",
      "Ep:143, loss:0.00001, loss_test:0.12337, lr:5.20e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.448, tt:8704.547\n",
      "Ep:144, loss:0.00001, loss_test:0.12371, lr:5.15e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.483, tt:8770.091\n",
      "Ep:145, loss:0.00001, loss_test:0.12283, lr:5.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.515, tt:8835.259\n",
      "Ep:146, loss:0.00001, loss_test:0.12407, lr:5.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.551, tt:8900.978\n",
      "Ep:147, loss:0.00001, loss_test:0.12353, lr:5.00e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.567, tt:8963.857\n",
      "Ep:148, loss:0.00001, loss_test:0.12311, lr:4.95e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.595, tt:9028.596\n",
      "Ep:149, loss:0.00001, loss_test:0.12309, lr:4.90e-03, fs:0.72152 (r=0.576,p=0.966),  time:60.581, tt:9087.168\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 89\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14305, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.416, tt:62.416\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14053, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:61.569, tt:123.138\n",
      "Ep:2, loss:0.00055, loss_test:0.13536, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:63.131, tt:189.393\n",
      "Ep:3, loss:0.00053, loss_test:0.12524, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:61.487, tt:245.948\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.11639, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:62.596, tt:312.980\n",
      "Ep:5, loss:0.00046, loss_test:0.11553, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:63.093, tt:378.560\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00043, loss_test:0.11355, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:63.504, tt:444.530\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.11070, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:63.720, tt:509.764\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.10862, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:63.536, tt:571.828\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.10638, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:64.002, tt:640.018\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00036, loss_test:0.10556, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:64.078, tt:704.859\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.10541, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:64.308, tt:771.697\n",
      "Ep:12, loss:0.00033, loss_test:0.10379, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:64.299, tt:835.884\n",
      "Ep:13, loss:0.00032, loss_test:0.10276, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:64.388, tt:901.427\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.10195, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:64.518, tt:967.768\n",
      "Ep:15, loss:0.00029, loss_test:0.10102, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:64.562, tt:1032.985\n",
      "Ep:16, loss:0.00028, loss_test:0.10072, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:64.589, tt:1098.008\n",
      "Ep:17, loss:0.00027, loss_test:0.10097, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:64.659, tt:1163.858\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.09917, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:64.602, tt:1227.432\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.09882, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:64.650, tt:1292.996\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.09801, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:64.672, tt:1358.117\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00024, loss_test:0.09770, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:64.686, tt:1423.082\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.09791, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:64.849, tt:1491.519\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00022, loss_test:0.09670, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:64.796, tt:1555.092\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.09516, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:64.782, tt:1619.549\n",
      "Ep:25, loss:0.00020, loss_test:0.09637, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:64.845, tt:1685.960\n",
      "Ep:26, loss:0.00019, loss_test:0.09628, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:64.909, tt:1752.554\n",
      "Ep:27, loss:0.00018, loss_test:0.09634, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:64.954, tt:1818.725\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.09689, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:64.998, tt:1884.947\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.09553, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:64.947, tt:1948.412\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.09464, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:65.004, tt:2015.109\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.09245, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:65.108, tt:2083.446\n",
      "Ep:32, loss:0.00014, loss_test:0.09326, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:65.134, tt:2149.421\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.09295, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:65.233, tt:2217.929\n",
      "Ep:34, loss:0.00013, loss_test:0.09377, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:65.253, tt:2283.852\n",
      "Ep:35, loss:0.00013, loss_test:0.09254, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:65.240, tt:2348.632\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.09159, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:65.195, tt:2412.233\n",
      "Ep:37, loss:0.00012, loss_test:0.09283, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:65.182, tt:2476.924\n",
      "Ep:38, loss:0.00011, loss_test:0.09175, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:65.131, tt:2540.100\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08991, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:65.093, tt:2603.729\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08988, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:65.082, tt:2668.342\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.08665, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:65.135, tt:2735.689\n",
      "Ep:42, loss:0.00009, loss_test:0.08949, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:65.163, tt:2801.988\n",
      "Ep:43, loss:0.00009, loss_test:0.08553, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:65.086, tt:2863.803\n",
      "Ep:44, loss:0.00008, loss_test:0.08621, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:65.095, tt:2929.254\n",
      "Ep:45, loss:0.00008, loss_test:0.08697, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:65.121, tt:2995.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00008, loss_test:0.08556, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:65.103, tt:3059.838\n",
      "Ep:47, loss:0.00007, loss_test:0.08853, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:65.111, tt:3125.341\n",
      "Ep:48, loss:0.00007, loss_test:0.08531, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:65.084, tt:3189.127\n",
      "Ep:49, loss:0.00007, loss_test:0.08380, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:65.120, tt:3255.979\n",
      "Ep:50, loss:0.00006, loss_test:0.08549, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:65.105, tt:3320.355\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.08423, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:65.091, tt:3384.719\n",
      "Ep:52, loss:0.00006, loss_test:0.08508, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:65.096, tt:3450.066\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.08498, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:65.102, tt:3515.486\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.08257, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:65.102, tt:3580.585\n",
      "Ep:55, loss:0.00005, loss_test:0.08408, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:65.149, tt:3648.333\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.08410, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:65.141, tt:3713.050\n",
      "Ep:57, loss:0.00005, loss_test:0.08524, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:65.140, tt:3778.136\n",
      "Ep:58, loss:0.00005, loss_test:0.08346, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.159, tt:3844.400\n",
      "Ep:59, loss:0.00005, loss_test:0.08095, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:65.199, tt:3911.952\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.08099, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:65.223, tt:3978.596\n",
      "Ep:61, loss:0.00005, loss_test:0.08439, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:65.225, tt:4043.966\n",
      "Ep:62, loss:0.00004, loss_test:0.08217, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:65.220, tt:4108.877\n",
      "Ep:63, loss:0.00004, loss_test:0.08204, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.225, tt:4174.420\n",
      "Ep:64, loss:0.00004, loss_test:0.08308, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.228, tt:4239.840\n",
      "Ep:65, loss:0.00004, loss_test:0.07959, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.210, tt:4303.883\n",
      "Ep:66, loss:0.00004, loss_test:0.08061, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.221, tt:4369.826\n",
      "Ep:67, loss:0.00004, loss_test:0.08101, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:65.209, tt:4434.217\n",
      "Ep:68, loss:0.00004, loss_test:0.08187, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.218, tt:4500.048\n",
      "Ep:69, loss:0.00004, loss_test:0.08248, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:65.182, tt:4562.716\n",
      "Ep:70, loss:0.00003, loss_test:0.08087, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:65.212, tt:4630.075\n",
      "Ep:71, loss:0.00003, loss_test:0.07971, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.221, tt:4695.890\n",
      "Ep:72, loss:0.00003, loss_test:0.07909, lr:9.80e-03, fs:0.86957 (r=0.808,p=0.941),  time:65.244, tt:4762.821\n",
      "Ep:73, loss:0.00003, loss_test:0.07851, lr:9.70e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.248, tt:4828.325\n",
      "Ep:74, loss:0.00003, loss_test:0.08112, lr:9.61e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.266, tt:4894.960\n",
      "Ep:75, loss:0.00003, loss_test:0.08025, lr:9.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:65.269, tt:4960.416\n",
      "Ep:76, loss:0.00003, loss_test:0.08019, lr:9.41e-03, fs:0.87912 (r=0.808,p=0.964),  time:65.276, tt:5026.250\n",
      "Ep:77, loss:0.00003, loss_test:0.07997, lr:9.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.283, tt:5092.073\n",
      "Ep:78, loss:0.00003, loss_test:0.08195, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.285, tt:5157.489\n",
      "Ep:79, loss:0.00003, loss_test:0.08010, lr:9.14e-03, fs:0.86957 (r=0.808,p=0.941),  time:65.261, tt:5220.895\n",
      "Ep:80, loss:0.00003, loss_test:0.07864, lr:9.04e-03, fs:0.87912 (r=0.808,p=0.964),  time:65.176, tt:5279.247\n",
      "Ep:81, loss:0.00002, loss_test:0.07893, lr:8.95e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.112, tt:5339.166\n",
      "Ep:82, loss:0.00002, loss_test:0.07950, lr:8.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.029, tt:5397.442\n",
      "Ep:83, loss:0.00002, loss_test:0.08053, lr:8.78e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.952, tt:5456.002\n",
      "Ep:84, loss:0.00002, loss_test:0.07950, lr:8.69e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.904, tt:5516.877\n",
      "Ep:85, loss:0.00002, loss_test:0.08092, lr:8.60e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.827, tt:5575.148\n",
      "Ep:86, loss:0.00002, loss_test:0.08008, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.745, tt:5632.791\n",
      "Ep:87, loss:0.00002, loss_test:0.07877, lr:8.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.680, tt:5691.839\n",
      "Ep:88, loss:0.00002, loss_test:0.07897, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.624, tt:5751.580\n",
      "Ep:89, loss:0.00002, loss_test:0.07953, lr:8.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.546, tt:5809.119\n",
      "Ep:90, loss:0.00002, loss_test:0.08067, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.495, tt:5869.046\n",
      "Ep:91, loss:0.00002, loss_test:0.07902, lr:8.10e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.428, tt:5927.400\n",
      "Ep:92, loss:0.00002, loss_test:0.07925, lr:8.02e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.375, tt:5986.891\n",
      "Ep:93, loss:0.00002, loss_test:0.07761, lr:7.94e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.335, tt:6047.450\n",
      "Ep:94, loss:0.00002, loss_test:0.07677, lr:7.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.287, tt:6107.277\n",
      "Ep:95, loss:0.00002, loss_test:0.07875, lr:7.78e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.233, tt:6166.360\n",
      "Ep:96, loss:0.00002, loss_test:0.08184, lr:7.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.189, tt:6226.296\n",
      "Ep:97, loss:0.00002, loss_test:0.08125, lr:7.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.159, tt:6287.619\n",
      "Ep:98, loss:0.00002, loss_test:0.07765, lr:7.55e-03, fs:0.87912 (r=0.808,p=0.964),  time:64.093, tt:6345.243\n",
      "Ep:99, loss:0.00002, loss_test:0.07746, lr:7.47e-03, fs:0.88398 (r=0.808,p=0.976),  time:64.026, tt:6402.573\n",
      "Ep:100, loss:0.00002, loss_test:0.08059, lr:7.40e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.969, tt:6460.909\n",
      "Ep:101, loss:0.00002, loss_test:0.07942, lr:7.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.932, tt:6521.081\n",
      "Ep:102, loss:0.00001, loss_test:0.07808, lr:7.25e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.898, tt:6581.470\n",
      "Ep:103, loss:0.00001, loss_test:0.07901, lr:7.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:63.856, tt:6641.005\n",
      "Ep:104, loss:0.00001, loss_test:0.07821, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.816, tt:6700.640\n",
      "Ep:105, loss:0.00001, loss_test:0.08047, lr:7.03e-03, fs:0.85876 (r=0.768,p=0.974),  time:63.783, tt:6761.039\n",
      "Ep:106, loss:0.00001, loss_test:0.08085, lr:6.96e-03, fs:0.87912 (r=0.808,p=0.964),  time:63.749, tt:6821.134\n",
      "Ep:107, loss:0.00001, loss_test:0.07895, lr:6.89e-03, fs:0.87912 (r=0.808,p=0.964),  time:63.697, tt:6879.261\n",
      "Ep:108, loss:0.00001, loss_test:0.08016, lr:6.83e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.647, tt:6937.479\n",
      "Ep:109, loss:0.00001, loss_test:0.07986, lr:6.76e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.588, tt:6994.666\n",
      "Ep:110, loss:0.00001, loss_test:0.07925, lr:6.69e-03, fs:0.87778 (r=0.798,p=0.975),  time:63.548, tt:7053.857\n",
      "Ep:111, loss:0.00001, loss_test:0.07941, lr:6.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:63.506, tt:7112.682\n",
      "Ep:112, loss:0.00001, loss_test:0.08028, lr:6.56e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.463, tt:7171.270\n",
      "Ep:113, loss:0.00001, loss_test:0.08026, lr:6.49e-03, fs:0.87151 (r=0.788,p=0.975),  time:63.431, tt:7231.141\n",
      "Ep:114, loss:0.00001, loss_test:0.07945, lr:6.43e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.379, tt:7288.572\n",
      "Ep:115, loss:0.00001, loss_test:0.07855, lr:6.36e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.331, tt:7346.355\n",
      "Ep:116, loss:0.00001, loss_test:0.07996, lr:6.30e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.294, tt:7405.366\n",
      "Ep:117, loss:0.00001, loss_test:0.08036, lr:6.24e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.248, tt:7463.229\n",
      "Ep:118, loss:0.00001, loss_test:0.07842, lr:6.17e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.194, tt:7520.128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00001, loss_test:0.08045, lr:6.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.158, tt:7578.932\n",
      "Ep:120, loss:0.00001, loss_test:0.08138, lr:6.05e-03, fs:0.85227 (r=0.758,p=0.974),  time:63.120, tt:7637.476\n",
      "Ep:121, loss:0.00001, loss_test:0.07856, lr:5.99e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.091, tt:7697.091\n",
      "Ep:122, loss:0.00001, loss_test:0.07953, lr:5.93e-03, fs:0.88398 (r=0.808,p=0.976),  time:63.057, tt:7756.070\n",
      "Ep:123, loss:0.00001, loss_test:0.08048, lr:5.87e-03, fs:0.84571 (r=0.747,p=0.974),  time:63.008, tt:7813.022\n",
      "Ep:124, loss:0.00001, loss_test:0.07927, lr:5.81e-03, fs:0.87293 (r=0.798,p=0.963),  time:62.978, tt:7872.251\n",
      "Ep:125, loss:0.00001, loss_test:0.08077, lr:5.75e-03, fs:0.84571 (r=0.747,p=0.974),  time:62.964, tt:7933.429\n",
      "Ep:126, loss:0.00001, loss_test:0.08117, lr:5.70e-03, fs:0.88398 (r=0.808,p=0.976),  time:62.919, tt:7990.681\n",
      "Ep:127, loss:0.00001, loss_test:0.07831, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:62.913, tt:8052.901\n",
      "Ep:128, loss:0.00001, loss_test:0.08081, lr:5.58e-03, fs:0.85227 (r=0.758,p=0.974),  time:62.863, tt:8109.288\n",
      "Ep:129, loss:0.00001, loss_test:0.08046, lr:5.53e-03, fs:0.86034 (r=0.778,p=0.963),  time:62.838, tt:8168.878\n",
      "Ep:130, loss:0.00001, loss_test:0.07948, lr:5.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:62.821, tt:8229.545\n",
      "Ep:131, loss:0.00001, loss_test:0.07982, lr:5.42e-03, fs:0.84571 (r=0.747,p=0.974),  time:62.783, tt:8287.312\n",
      "Ep:132, loss:0.00001, loss_test:0.08051, lr:5.36e-03, fs:0.85227 (r=0.758,p=0.974),  time:62.751, tt:8345.880\n",
      "Ep:133, loss:0.00001, loss_test:0.07982, lr:5.31e-03, fs:0.88398 (r=0.808,p=0.976),  time:62.721, tt:8404.666\n",
      "Ep:134, loss:0.00001, loss_test:0.07923, lr:5.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:62.701, tt:8464.673\n",
      "Ep:135, loss:0.00001, loss_test:0.07953, lr:5.20e-03, fs:0.88398 (r=0.808,p=0.976),  time:62.650, tt:8520.336\n",
      "Ep:136, loss:0.00001, loss_test:0.08065, lr:5.15e-03, fs:0.81871 (r=0.707,p=0.972),  time:62.618, tt:8578.647\n",
      "Ep:137, loss:0.00001, loss_test:0.08037, lr:5.10e-03, fs:0.83908 (r=0.737,p=0.973),  time:62.565, tt:8634.038\n",
      "Ep:138, loss:0.00001, loss_test:0.07930, lr:5.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:62.535, tt:8692.341\n",
      "Ep:139, loss:0.00001, loss_test:0.08033, lr:5.00e-03, fs:0.81871 (r=0.707,p=0.972),  time:62.487, tt:8748.203\n",
      "Ep:140, loss:0.00001, loss_test:0.08020, lr:4.95e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.451, tt:8805.605\n",
      "Ep:141, loss:0.00001, loss_test:0.08023, lr:4.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.419, tt:8863.484\n",
      "Ep:142, loss:0.00001, loss_test:0.08009, lr:4.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:62.365, tt:8918.266\n",
      "Ep:143, loss:0.00001, loss_test:0.07945, lr:4.80e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.291, tt:8969.861\n",
      "Ep:144, loss:0.00001, loss_test:0.08039, lr:4.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.219, tt:9021.824\n",
      "Ep:145, loss:0.00001, loss_test:0.08075, lr:4.71e-03, fs:0.80473 (r=0.687,p=0.971),  time:62.132, tt:9071.331\n",
      "Ep:146, loss:0.00001, loss_test:0.08009, lr:4.66e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.057, tt:9122.336\n",
      "Ep:147, loss:0.00001, loss_test:0.08015, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:61.954, tt:9169.194\n",
      "Ep:148, loss:0.00001, loss_test:0.08019, lr:4.57e-03, fs:0.80473 (r=0.687,p=0.971),  time:61.824, tt:9211.789\n",
      "Ep:149, loss:0.00001, loss_test:0.07984, lr:4.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:61.660, tt:9248.929\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00007, loss_test:0.14464, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.148, tt:14.148\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.14442, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.275, tt:28.551\n",
      "Ep:2, loss:0.00007, loss_test:0.14409, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.286, tt:42.858\n",
      "Ep:3, loss:0.00007, loss_test:0.14363, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.178, tt:56.713\n",
      "Ep:4, loss:0.00007, loss_test:0.14301, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.186, tt:70.932\n",
      "Ep:5, loss:0.00007, loss_test:0.14219, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.325, tt:85.951\n",
      "Ep:6, loss:0.00007, loss_test:0.14117, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.329, tt:100.302\n",
      "Ep:7, loss:0.00007, loss_test:0.13993, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:14.487, tt:115.893\n",
      "Ep:8, loss:0.00007, loss_test:0.13838, lr:1.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:14.407, tt:129.664\n",
      "Ep:9, loss:0.00006, loss_test:0.13648, lr:1.00e-02, fs:0.64029 (r=0.899,p=0.497),  time:14.428, tt:144.283\n",
      "Ep:10, loss:0.00006, loss_test:0.13422, lr:1.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:14.424, tt:158.663\n",
      "Ep:11, loss:0.00006, loss_test:0.13205, lr:1.00e-02, fs:0.62500 (r=0.808,p=0.510),  time:14.388, tt:172.653\n",
      "Ep:12, loss:0.00006, loss_test:0.12992, lr:9.90e-03, fs:0.61925 (r=0.747,p=0.529),  time:14.440, tt:187.720\n",
      "Ep:13, loss:0.00006, loss_test:0.12757, lr:9.80e-03, fs:0.63636 (r=0.707,p=0.579),  time:14.446, tt:202.247\n",
      "Ep:14, loss:0.00006, loss_test:0.12564, lr:9.70e-03, fs:0.64356 (r=0.657,p=0.631),  time:14.407, tt:216.098\n",
      "Ep:15, loss:0.00006, loss_test:0.12445, lr:9.61e-03, fs:0.64677 (r=0.657,p=0.637),  time:14.389, tt:230.226\n",
      "Ep:16, loss:0.00006, loss_test:0.12369, lr:9.51e-03, fs:0.64322 (r=0.646,p=0.640),  time:14.422, tt:245.173\n",
      "Ep:17, loss:0.00005, loss_test:0.12267, lr:9.41e-03, fs:0.65686 (r=0.677,p=0.638),  time:14.446, tt:260.020\n",
      "Ep:18, loss:0.00005, loss_test:0.12169, lr:9.32e-03, fs:0.65116 (r=0.707,p=0.603),  time:14.477, tt:275.070\n",
      "Ep:19, loss:0.00005, loss_test:0.12099, lr:9.23e-03, fs:0.63636 (r=0.707,p=0.579),  time:14.443, tt:288.854\n",
      "Ep:20, loss:0.00005, loss_test:0.12023, lr:9.14e-03, fs:0.63063 (r=0.707,p=0.569),  time:14.417, tt:302.758\n",
      "Ep:21, loss:0.00005, loss_test:0.11897, lr:9.04e-03, fs:0.63964 (r=0.717,p=0.577),  time:14.418, tt:317.197\n",
      "Ep:22, loss:0.00005, loss_test:0.11727, lr:8.95e-03, fs:0.66355 (r=0.717,p=0.617),  time:14.389, tt:330.948\n",
      "Ep:23, loss:0.00005, loss_test:0.11579, lr:8.86e-03, fs:0.66986 (r=0.707,p=0.636),  time:14.390, tt:345.358\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00005, loss_test:0.11488, lr:8.86e-03, fs:0.68627 (r=0.707,p=0.667),  time:14.387, tt:359.672\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00005, loss_test:0.11429, lr:8.86e-03, fs:0.67000 (r=0.677,p=0.663),  time:14.397, tt:374.326\n",
      "Ep:26, loss:0.00005, loss_test:0.11366, lr:8.86e-03, fs:0.66332 (r=0.667,p=0.660),  time:14.348, tt:387.401\n",
      "Ep:27, loss:0.00005, loss_test:0.11298, lr:8.86e-03, fs:0.67000 (r=0.677,p=0.663),  time:14.387, tt:402.833\n",
      "Ep:28, loss:0.00005, loss_test:0.11223, lr:8.86e-03, fs:0.66995 (r=0.687,p=0.654),  time:14.441, tt:418.796\n",
      "Ep:29, loss:0.00005, loss_test:0.11133, lr:8.86e-03, fs:0.69856 (r=0.737,p=0.664),  time:14.467, tt:434.004\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00005, loss_test:0.11030, lr:8.86e-03, fs:0.69524 (r=0.737,p=0.658),  time:14.480, tt:448.870\n",
      "Ep:31, loss:0.00005, loss_test:0.10929, lr:8.86e-03, fs:0.68571 (r=0.727,p=0.649),  time:14.521, tt:464.661\n",
      "Ep:32, loss:0.00005, loss_test:0.10815, lr:8.86e-03, fs:0.69231 (r=0.727,p=0.661),  time:14.499, tt:478.460\n",
      "Ep:33, loss:0.00005, loss_test:0.10705, lr:8.86e-03, fs:0.69565 (r=0.727,p=0.667),  time:14.472, tt:492.060\n",
      "Ep:34, loss:0.00004, loss_test:0.10611, lr:8.86e-03, fs:0.70244 (r=0.727,p=0.679),  time:14.465, tt:506.283\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00004, loss_test:0.10520, lr:8.86e-03, fs:0.70588 (r=0.727,p=0.686),  time:14.465, tt:520.757\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00004, loss_test:0.10444, lr:8.86e-03, fs:0.70936 (r=0.727,p=0.692),  time:14.442, tt:534.347\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00004, loss_test:0.10373, lr:8.86e-03, fs:0.70936 (r=0.727,p=0.692),  time:14.448, tt:549.005\n",
      "Ep:38, loss:0.00004, loss_test:0.10303, lr:8.86e-03, fs:0.71287 (r=0.727,p=0.699),  time:14.434, tt:562.909\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00004, loss_test:0.10229, lr:8.86e-03, fs:0.71921 (r=0.737,p=0.702),  time:14.437, tt:577.494\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00004, loss_test:0.10151, lr:8.86e-03, fs:0.73171 (r=0.758,p=0.708),  time:14.428, tt:591.559\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00004, loss_test:0.10072, lr:8.86e-03, fs:0.73529 (r=0.758,p=0.714),  time:14.451, tt:606.926\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00004, loss_test:0.09992, lr:8.86e-03, fs:0.74510 (r=0.768,p=0.724),  time:14.452, tt:621.436\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00004, loss_test:0.09923, lr:8.86e-03, fs:0.74877 (r=0.768,p=0.731),  time:14.444, tt:635.537\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.09855, lr:8.86e-03, fs:0.74877 (r=0.768,p=0.731),  time:14.444, tt:649.962\n",
      "Ep:45, loss:0.00004, loss_test:0.09790, lr:8.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:14.397, tt:662.250\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.09724, lr:8.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:14.387, tt:676.171\n",
      "Ep:47, loss:0.00004, loss_test:0.09660, lr:8.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:14.397, tt:691.039\n",
      "Ep:48, loss:0.00004, loss_test:0.09599, lr:8.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:14.402, tt:705.714\n",
      "Ep:49, loss:0.00004, loss_test:0.09540, lr:8.86e-03, fs:0.75862 (r=0.778,p=0.740),  time:14.400, tt:719.984\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.09485, lr:8.86e-03, fs:0.75862 (r=0.778,p=0.740),  time:14.393, tt:734.050\n",
      "Ep:51, loss:0.00004, loss_test:0.09436, lr:8.86e-03, fs:0.75248 (r=0.768,p=0.738),  time:14.396, tt:748.589\n",
      "Ep:52, loss:0.00004, loss_test:0.09395, lr:8.86e-03, fs:0.75248 (r=0.768,p=0.738),  time:14.377, tt:761.976\n",
      "Ep:53, loss:0.00004, loss_test:0.09363, lr:8.86e-03, fs:0.75248 (r=0.768,p=0.738),  time:14.369, tt:775.911\n",
      "Ep:54, loss:0.00004, loss_test:0.09333, lr:8.86e-03, fs:0.75248 (r=0.768,p=0.738),  time:14.360, tt:789.814\n",
      "Ep:55, loss:0.00004, loss_test:0.09304, lr:8.86e-03, fs:0.75000 (r=0.758,p=0.743),  time:14.349, tt:803.522\n",
      "Ep:56, loss:0.00004, loss_test:0.09282, lr:8.86e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.340, tt:817.377\n",
      "Ep:57, loss:0.00004, loss_test:0.09260, lr:8.86e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.336, tt:831.468\n",
      "Ep:58, loss:0.00004, loss_test:0.09235, lr:8.86e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.339, tt:846.020\n",
      "Ep:59, loss:0.00004, loss_test:0.09209, lr:8.86e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.353, tt:861.164\n",
      "Ep:60, loss:0.00004, loss_test:0.09182, lr:8.86e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.363, tt:876.136\n",
      "Ep:61, loss:0.00004, loss_test:0.09153, lr:8.78e-03, fs:0.74112 (r=0.737,p=0.745),  time:14.351, tt:889.764\n",
      "Ep:62, loss:0.00004, loss_test:0.09126, lr:8.69e-03, fs:0.75510 (r=0.747,p=0.763),  time:14.366, tt:905.042\n",
      "Ep:63, loss:0.00004, loss_test:0.09103, lr:8.60e-03, fs:0.74872 (r=0.737,p=0.760),  time:14.372, tt:919.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00004, loss_test:0.09081, lr:8.51e-03, fs:0.74227 (r=0.727,p=0.758),  time:14.394, tt:935.612\n",
      "Ep:65, loss:0.00003, loss_test:0.09064, lr:8.43e-03, fs:0.74227 (r=0.727,p=0.758),  time:14.399, tt:950.337\n",
      "Ep:66, loss:0.00003, loss_test:0.09046, lr:8.35e-03, fs:0.74227 (r=0.727,p=0.758),  time:14.391, tt:964.181\n",
      "Ep:67, loss:0.00003, loss_test:0.09023, lr:8.26e-03, fs:0.73684 (r=0.707,p=0.769),  time:14.380, tt:977.812\n",
      "Ep:68, loss:0.00003, loss_test:0.09000, lr:8.18e-03, fs:0.74074 (r=0.707,p=0.778),  time:14.386, tt:992.619\n",
      "Ep:69, loss:0.00003, loss_test:0.08978, lr:8.10e-03, fs:0.73797 (r=0.697,p=0.784),  time:14.388, tt:1007.187\n",
      "Ep:70, loss:0.00003, loss_test:0.08958, lr:8.02e-03, fs:0.73797 (r=0.697,p=0.784),  time:14.377, tt:1020.755\n",
      "Ep:71, loss:0.00003, loss_test:0.08936, lr:7.94e-03, fs:0.73797 (r=0.697,p=0.784),  time:14.365, tt:1034.292\n",
      "Ep:72, loss:0.00003, loss_test:0.08907, lr:7.86e-03, fs:0.73797 (r=0.697,p=0.784),  time:14.361, tt:1048.351\n",
      "Ep:73, loss:0.00003, loss_test:0.08879, lr:7.78e-03, fs:0.74194 (r=0.697,p=0.793),  time:14.340, tt:1061.192\n",
      "Ep:74, loss:0.00003, loss_test:0.08863, lr:7.70e-03, fs:0.73514 (r=0.687,p=0.791),  time:14.338, tt:1075.351\n",
      "Ep:75, loss:0.00003, loss_test:0.08859, lr:7.62e-03, fs:0.73514 (r=0.687,p=0.791),  time:14.344, tt:1090.158\n",
      "Ep:76, loss:0.00003, loss_test:0.08854, lr:7.55e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.357, tt:1105.454\n",
      "Ep:77, loss:0.00003, loss_test:0.08844, lr:7.47e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.367, tt:1120.649\n",
      "Ep:78, loss:0.00003, loss_test:0.08835, lr:7.40e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.347, tt:1133.396\n",
      "Ep:79, loss:0.00003, loss_test:0.08828, lr:7.32e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.358, tt:1148.625\n",
      "Ep:80, loss:0.00003, loss_test:0.08824, lr:7.25e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.351, tt:1162.427\n",
      "Ep:81, loss:0.00003, loss_test:0.08820, lr:7.18e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.368, tt:1178.162\n",
      "Ep:82, loss:0.00003, loss_test:0.08817, lr:7.11e-03, fs:0.72826 (r=0.677,p=0.788),  time:14.378, tt:1193.361\n",
      "Ep:83, loss:0.00003, loss_test:0.08812, lr:7.03e-03, fs:0.73224 (r=0.677,p=0.798),  time:14.380, tt:1207.925\n",
      "Ep:84, loss:0.00003, loss_test:0.08805, lr:6.96e-03, fs:0.73224 (r=0.677,p=0.798),  time:14.373, tt:1221.687\n",
      "Ep:85, loss:0.00003, loss_test:0.08801, lr:6.89e-03, fs:0.73626 (r=0.677,p=0.807),  time:14.366, tt:1235.503\n",
      "Ep:86, loss:0.00003, loss_test:0.08793, lr:6.83e-03, fs:0.73626 (r=0.677,p=0.807),  time:14.380, tt:1251.017\n",
      "Ep:87, loss:0.00003, loss_test:0.08785, lr:6.76e-03, fs:0.73626 (r=0.677,p=0.807),  time:14.374, tt:1264.909\n",
      "Ep:88, loss:0.00003, loss_test:0.08773, lr:6.69e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.394, tt:1281.102\n",
      "Ep:89, loss:0.00003, loss_test:0.08760, lr:6.62e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.398, tt:1295.857\n",
      "Ep:90, loss:0.00003, loss_test:0.08754, lr:6.56e-03, fs:0.73626 (r=0.677,p=0.807),  time:14.411, tt:1311.412\n",
      "Ep:91, loss:0.00003, loss_test:0.08757, lr:6.49e-03, fs:0.73626 (r=0.677,p=0.807),  time:14.406, tt:1325.363\n",
      "Ep:92, loss:0.00003, loss_test:0.08763, lr:6.43e-03, fs:0.73626 (r=0.677,p=0.807),  time:14.429, tt:1341.919\n",
      "Ep:93, loss:0.00003, loss_test:0.08769, lr:6.36e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.424, tt:1355.811\n",
      "Ep:94, loss:0.00003, loss_test:0.08760, lr:6.30e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.437, tt:1371.554\n",
      "Ep:95, loss:0.00003, loss_test:0.08746, lr:6.24e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.444, tt:1386.594\n",
      "Ep:96, loss:0.00003, loss_test:0.08744, lr:6.17e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.445, tt:1401.198\n",
      "Ep:97, loss:0.00003, loss_test:0.08749, lr:6.11e-03, fs:0.74317 (r=0.687,p=0.810),  time:14.458, tt:1416.889\n",
      "Ep:98, loss:0.00003, loss_test:0.08752, lr:6.05e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.458, tt:1431.324\n",
      "Ep:99, loss:0.00003, loss_test:0.08745, lr:5.99e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.474, tt:1447.418\n",
      "Ep:100, loss:0.00003, loss_test:0.08730, lr:5.93e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.468, tt:1461.312\n",
      "Ep:101, loss:0.00003, loss_test:0.08701, lr:5.87e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.473, tt:1476.288\n",
      "Ep:102, loss:0.00003, loss_test:0.08678, lr:5.81e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.469, tt:1490.261\n",
      "Ep:103, loss:0.00003, loss_test:0.08670, lr:5.75e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.478, tt:1505.734\n",
      "Ep:104, loss:0.00003, loss_test:0.08667, lr:5.70e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.478, tt:1520.208\n",
      "Ep:105, loss:0.00003, loss_test:0.08660, lr:5.64e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.479, tt:1534.742\n",
      "Ep:106, loss:0.00003, loss_test:0.08640, lr:5.58e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.479, tt:1549.271\n",
      "Ep:107, loss:0.00003, loss_test:0.08614, lr:5.53e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.485, tt:1564.355\n",
      "Ep:108, loss:0.00002, loss_test:0.08596, lr:5.47e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.495, tt:1579.927\n",
      "Ep:109, loss:0.00002, loss_test:0.08582, lr:5.42e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.492, tt:1594.174\n",
      "Ep:110, loss:0.00002, loss_test:0.08578, lr:5.36e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.498, tt:1609.325\n",
      "Ep:111, loss:0.00002, loss_test:0.08573, lr:5.31e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.495, tt:1623.431\n",
      "Ep:112, loss:0.00002, loss_test:0.08565, lr:5.26e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.501, tt:1638.567\n",
      "Ep:113, loss:0.00002, loss_test:0.08551, lr:5.20e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.492, tt:1652.078\n",
      "Ep:114, loss:0.00002, loss_test:0.08544, lr:5.15e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.497, tt:1667.109\n",
      "Ep:115, loss:0.00002, loss_test:0.08537, lr:5.10e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.487, tt:1680.447\n",
      "Ep:116, loss:0.00002, loss_test:0.08526, lr:5.05e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.495, tt:1695.951\n",
      "Ep:117, loss:0.00002, loss_test:0.08511, lr:5.00e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.493, tt:1710.131\n",
      "Ep:118, loss:0.00002, loss_test:0.08498, lr:4.95e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.495, tt:1724.874\n",
      "Ep:119, loss:0.00002, loss_test:0.08496, lr:4.90e-03, fs:0.74725 (r=0.687,p=0.819),  time:14.495, tt:1739.409\n",
      "Ep:120, loss:0.00002, loss_test:0.08497, lr:4.85e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.496, tt:1754.073\n",
      "Ep:121, loss:0.00002, loss_test:0.08494, lr:4.80e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.495, tt:1768.412\n",
      "Ep:122, loss:0.00002, loss_test:0.08471, lr:4.75e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.496, tt:1782.988\n",
      "Ep:123, loss:0.00002, loss_test:0.08447, lr:4.71e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.505, tt:1798.563\n",
      "Ep:124, loss:0.00002, loss_test:0.08434, lr:4.66e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.487, tt:1810.841\n",
      "Ep:125, loss:0.00002, loss_test:0.08434, lr:4.61e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.496, tt:1826.486\n",
      "Ep:126, loss:0.00002, loss_test:0.08434, lr:4.57e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.486, tt:1839.782\n",
      "Ep:127, loss:0.00002, loss_test:0.08426, lr:4.52e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.484, tt:1854.014\n",
      "Ep:128, loss:0.00002, loss_test:0.08411, lr:4.48e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.483, tt:1868.292\n",
      "Ep:129, loss:0.00002, loss_test:0.08394, lr:4.43e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.488, tt:1883.411\n",
      "Ep:130, loss:0.00002, loss_test:0.08383, lr:4.39e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.486, tt:1897.626\n",
      "Ep:131, loss:0.00002, loss_test:0.08384, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.498, tt:1913.722\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00002, loss_test:0.08388, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.487, tt:1926.759\n",
      "Ep:133, loss:0.00002, loss_test:0.08386, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.485, tt:1941.055\n",
      "Ep:134, loss:0.00002, loss_test:0.08379, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.489, tt:1955.994\n",
      "Ep:135, loss:0.00002, loss_test:0.08371, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.490, tt:1970.625\n",
      "Ep:136, loss:0.00002, loss_test:0.08367, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.488, tt:1984.872\n",
      "Ep:137, loss:0.00002, loss_test:0.08369, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.497, tt:2000.547\n",
      "Ep:138, loss:0.00002, loss_test:0.08370, lr:4.34e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.497, tt:2015.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00002, loss_test:0.08372, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.495, tt:2029.354\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00002, loss_test:0.08373, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.515, tt:2046.678\n",
      "Ep:141, loss:0.00002, loss_test:0.08370, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.507, tt:2059.933\n",
      "Ep:142, loss:0.00002, loss_test:0.08364, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.515, tt:2075.651\n",
      "Ep:143, loss:0.00002, loss_test:0.08360, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.509, tt:2089.255\n",
      "Ep:144, loss:0.00002, loss_test:0.08354, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.515, tt:2104.621\n",
      "Ep:145, loss:0.00002, loss_test:0.08350, lr:4.34e-03, fs:0.76404 (r=0.687,p=0.861),  time:14.502, tt:2117.273\n",
      "Ep:146, loss:0.00002, loss_test:0.08345, lr:4.34e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.508, tt:2132.672\n",
      "Ep:147, loss:0.00002, loss_test:0.08346, lr:4.34e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.503, tt:2146.375\n",
      "Ep:148, loss:0.00002, loss_test:0.08336, lr:4.34e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.505, tt:2161.190\n",
      "Ep:149, loss:0.00002, loss_test:0.08333, lr:4.34e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.499, tt:2174.896\n",
      "Ep:150, loss:0.00002, loss_test:0.08339, lr:4.34e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.494, tt:2188.567\n",
      "Ep:151, loss:0.00002, loss_test:0.08331, lr:4.30e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.485, tt:2201.659\n",
      "Ep:152, loss:0.00002, loss_test:0.08320, lr:4.26e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.482, tt:2215.750\n",
      "Ep:153, loss:0.00002, loss_test:0.08315, lr:4.21e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.484, tt:2230.560\n",
      "Ep:154, loss:0.00002, loss_test:0.08320, lr:4.17e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.496, tt:2246.903\n",
      "Ep:155, loss:0.00002, loss_test:0.08317, lr:4.13e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.497, tt:2261.482\n",
      "Ep:156, loss:0.00002, loss_test:0.08304, lr:4.09e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.488, tt:2274.674\n",
      "Ep:157, loss:0.00002, loss_test:0.08297, lr:4.05e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.501, tt:2291.177\n",
      "Ep:158, loss:0.00002, loss_test:0.08292, lr:4.01e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.499, tt:2305.373\n",
      "Ep:159, loss:0.00002, loss_test:0.08290, lr:3.97e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.500, tt:2320.014\n",
      "Ep:160, loss:0.00002, loss_test:0.08291, lr:3.93e-03, fs:0.75429 (r=0.667,p=0.868),  time:14.499, tt:2334.365\n",
      "Ep:161, loss:0.00002, loss_test:0.08292, lr:3.89e-03, fs:0.75000 (r=0.667,p=0.857),  time:14.500, tt:2349.052\n",
      "Ep:162, loss:0.00002, loss_test:0.08291, lr:3.85e-03, fs:0.75000 (r=0.667,p=0.857),  time:14.496, tt:2362.907\n",
      "Ep:163, loss:0.00002, loss_test:0.08291, lr:3.81e-03, fs:0.75000 (r=0.667,p=0.857),  time:14.511, tt:2379.801\n",
      "Ep:164, loss:0.00002, loss_test:0.08292, lr:3.77e-03, fs:0.75000 (r=0.667,p=0.857),  time:14.510, tt:2394.151\n",
      "Ep:165, loss:0.00002, loss_test:0.08290, lr:3.73e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.520, tt:2410.339\n",
      "Ep:166, loss:0.00002, loss_test:0.08284, lr:3.70e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.518, tt:2424.506\n",
      "Ep:167, loss:0.00002, loss_test:0.08287, lr:3.66e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.523, tt:2439.870\n",
      "Ep:168, loss:0.00002, loss_test:0.08278, lr:3.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.519, tt:2453.745\n",
      "Ep:169, loss:0.00002, loss_test:0.08269, lr:3.59e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.523, tt:2468.951\n",
      "Ep:170, loss:0.00002, loss_test:0.08268, lr:3.55e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.524, tt:2483.658\n",
      "Ep:171, loss:0.00002, loss_test:0.08264, lr:3.52e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.535, tt:2500.082\n",
      "Ep:172, loss:0.00002, loss_test:0.08258, lr:3.48e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.538, tt:2515.100\n",
      "Ep:173, loss:0.00002, loss_test:0.08261, lr:3.45e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.543, tt:2530.499\n",
      "Ep:174, loss:0.00002, loss_test:0.08255, lr:3.41e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.555, tt:2547.055\n",
      "Ep:175, loss:0.00002, loss_test:0.08257, lr:3.38e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.562, tt:2562.827\n",
      "Ep:176, loss:0.00002, loss_test:0.08255, lr:3.34e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.567, tt:2578.378\n",
      "Ep:177, loss:0.00002, loss_test:0.08255, lr:3.31e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.566, tt:2592.697\n",
      "Ep:178, loss:0.00002, loss_test:0.08246, lr:3.28e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.575, tt:2608.940\n",
      "Ep:179, loss:0.00002, loss_test:0.08243, lr:3.24e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.571, tt:2622.784\n",
      "Ep:180, loss:0.00002, loss_test:0.08250, lr:3.21e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.574, tt:2637.939\n",
      "Ep:181, loss:0.00002, loss_test:0.08252, lr:3.18e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.572, tt:2652.102\n",
      "Ep:182, loss:0.00002, loss_test:0.08243, lr:3.15e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.576, tt:2667.409\n",
      "Ep:183, loss:0.00002, loss_test:0.08234, lr:3.12e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.576, tt:2681.908\n",
      "Ep:184, loss:0.00002, loss_test:0.08232, lr:3.09e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.583, tt:2697.920\n",
      "Ep:185, loss:0.00002, loss_test:0.08230, lr:3.05e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.590, tt:2713.781\n",
      "Ep:186, loss:0.00002, loss_test:0.08220, lr:3.02e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.597, tt:2729.614\n",
      "Ep:187, loss:0.00002, loss_test:0.08215, lr:2.99e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.605, tt:2745.736\n",
      "Ep:188, loss:0.00002, loss_test:0.08210, lr:2.96e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.599, tt:2759.175\n",
      "Ep:189, loss:0.00002, loss_test:0.08205, lr:2.93e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.604, tt:2774.827\n",
      "Ep:190, loss:0.00002, loss_test:0.08200, lr:2.90e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.608, tt:2790.150\n",
      "Ep:191, loss:0.00002, loss_test:0.08199, lr:2.88e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.607, tt:2804.626\n",
      "Ep:192, loss:0.00002, loss_test:0.08200, lr:2.85e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.609, tt:2819.468\n",
      "Ep:193, loss:0.00002, loss_test:0.08197, lr:2.82e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.605, tt:2833.459\n",
      "Ep:194, loss:0.00002, loss_test:0.08197, lr:2.79e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.602, tt:2847.430\n",
      "Ep:195, loss:0.00002, loss_test:0.08191, lr:2.76e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.604, tt:2862.285\n",
      "Ep:196, loss:0.00002, loss_test:0.08189, lr:2.73e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.603, tt:2876.760\n",
      "Ep:197, loss:0.00002, loss_test:0.08183, lr:2.71e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.612, tt:2893.098\n",
      "Ep:198, loss:0.00002, loss_test:0.08191, lr:2.68e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.613, tt:2907.977\n",
      "Ep:199, loss:0.00002, loss_test:0.08187, lr:2.65e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.618, tt:2923.625\n",
      "Ep:200, loss:0.00002, loss_test:0.08179, lr:2.63e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.620, tt:2938.660\n",
      "Ep:201, loss:0.00002, loss_test:0.08181, lr:2.60e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.628, tt:2954.859\n",
      "Ep:202, loss:0.00002, loss_test:0.08178, lr:2.57e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.634, tt:2970.743\n",
      "Ep:203, loss:0.00002, loss_test:0.08172, lr:2.55e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.633, tt:2985.033\n",
      "Ep:204, loss:0.00002, loss_test:0.08165, lr:2.52e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.638, tt:3000.798\n",
      "Ep:205, loss:0.00002, loss_test:0.08171, lr:2.50e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.630, tt:3013.765\n",
      "Ep:206, loss:0.00002, loss_test:0.08168, lr:2.47e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.627, tt:3027.765\n",
      "Ep:207, loss:0.00002, loss_test:0.08158, lr:2.45e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.622, tt:3041.404\n",
      "Ep:208, loss:0.00002, loss_test:0.08156, lr:2.42e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.633, tt:3058.313\n",
      "Ep:209, loss:0.00002, loss_test:0.08161, lr:2.40e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.630, tt:3072.300\n",
      "Ep:210, loss:0.00002, loss_test:0.08162, lr:2.38e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.636, tt:3088.204\n",
      "Ep:211, loss:0.00002, loss_test:0.08156, lr:2.35e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.636, tt:3102.872\n",
      "Ep:212, loss:0.00002, loss_test:0.08151, lr:2.33e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.638, tt:3117.827\n",
      "Ep:213, loss:0.00002, loss_test:0.08153, lr:2.31e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.641, tt:3133.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:214, loss:0.00002, loss_test:0.08160, lr:2.28e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.646, tt:3148.913\n",
      "Ep:215, loss:0.00002, loss_test:0.08157, lr:2.26e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.646, tt:3163.596\n",
      "Ep:216, loss:0.00002, loss_test:0.08147, lr:2.24e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.645, tt:3177.985\n",
      "Ep:217, loss:0.00001, loss_test:0.08147, lr:2.21e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.646, tt:3192.756\n",
      "Ep:218, loss:0.00001, loss_test:0.08155, lr:2.19e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.648, tt:3207.807\n",
      "Ep:219, loss:0.00001, loss_test:0.08154, lr:2.17e-03, fs:0.76136 (r=0.677,p=0.870),  time:14.652, tt:3223.467\n",
      "Ep:220, loss:0.00001, loss_test:0.08143, lr:2.15e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.655, tt:3238.687\n",
      "Ep:221, loss:0.00001, loss_test:0.08138, lr:2.13e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.658, tt:3254.134\n",
      "Ep:222, loss:0.00001, loss_test:0.08140, lr:2.11e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.657, tt:3268.413\n",
      "Ep:223, loss:0.00001, loss_test:0.08145, lr:2.08e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.659, tt:3283.634\n",
      "Ep:224, loss:0.00001, loss_test:0.08145, lr:2.06e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.657, tt:3297.729\n",
      "Ep:225, loss:0.00001, loss_test:0.08142, lr:2.04e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.664, tt:3314.077\n",
      "Ep:226, loss:0.00001, loss_test:0.08139, lr:2.02e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.665, tt:3329.048\n",
      "Ep:227, loss:0.00001, loss_test:0.08141, lr:2.00e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.662, tt:3342.975\n",
      "Ep:228, loss:0.00001, loss_test:0.08143, lr:1.98e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.665, tt:3358.298\n",
      "Ep:229, loss:0.00001, loss_test:0.08142, lr:1.96e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.668, tt:3373.620\n",
      "Ep:230, loss:0.00001, loss_test:0.08138, lr:1.94e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.670, tt:3388.816\n",
      "Ep:231, loss:0.00001, loss_test:0.08134, lr:1.92e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.663, tt:3401.843\n",
      "Ep:232, loss:0.00001, loss_test:0.08135, lr:1.90e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.669, tt:3417.938\n",
      "Ep:233, loss:0.00001, loss_test:0.08139, lr:1.89e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.662, tt:3430.986\n",
      "Ep:234, loss:0.00001, loss_test:0.08141, lr:1.87e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.663, tt:3445.805\n",
      "Ep:235, loss:0.00001, loss_test:0.08138, lr:1.85e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.658, tt:3459.213\n",
      "Ep:236, loss:0.00001, loss_test:0.08136, lr:1.83e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.655, tt:3473.308\n",
      "Ep:237, loss:0.00001, loss_test:0.08137, lr:1.81e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.642, tt:3484.771\n",
      "Ep:238, loss:0.00001, loss_test:0.08140, lr:1.79e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.618, tt:3493.643\n",
      "Ep:239, loss:0.00001, loss_test:0.08140, lr:1.78e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.591, tt:3501.782\n",
      "Ep:240, loss:0.00001, loss_test:0.08138, lr:1.76e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.565, tt:3510.051\n",
      "Ep:241, loss:0.00001, loss_test:0.08137, lr:1.74e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.536, tt:3517.818\n",
      "Ep:242, loss:0.00001, loss_test:0.08134, lr:1.72e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.506, tt:3525.033\n",
      "Ep:243, loss:0.00001, loss_test:0.08134, lr:1.71e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.481, tt:3533.429\n",
      "Ep:244, loss:0.00001, loss_test:0.08136, lr:1.69e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.450, tt:3540.133\n",
      "Ep:245, loss:0.00001, loss_test:0.08134, lr:1.67e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.426, tt:3548.836\n",
      "Ep:246, loss:0.00001, loss_test:0.08132, lr:1.65e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.397, tt:3555.956\n",
      "Ep:247, loss:0.00001, loss_test:0.08133, lr:1.64e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.372, tt:3564.234\n",
      "Ep:248, loss:0.00001, loss_test:0.08132, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.344, tt:3571.574\n",
      "Ep:249, loss:0.00001, loss_test:0.08128, lr:1.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.320, tt:3580.018\n",
      "Ep:250, loss:0.00001, loss_test:0.08128, lr:1.59e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.294, tt:3587.786\n",
      "Ep:251, loss:0.00001, loss_test:0.08129, lr:1.57e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.270, tt:3596.029\n",
      "Ep:252, loss:0.00001, loss_test:0.08125, lr:1.56e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.243, tt:3603.498\n",
      "Ep:253, loss:0.00001, loss_test:0.08123, lr:1.54e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.215, tt:3610.554\n",
      "Ep:254, loss:0.00001, loss_test:0.08125, lr:1.53e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.196, tt:3620.009\n",
      "Ep:255, loss:0.00001, loss_test:0.08125, lr:1.51e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.170, tt:3627.583\n",
      "Ep:256, loss:0.00001, loss_test:0.08123, lr:1.50e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.147, tt:3635.655\n",
      "Ep:257, loss:0.00001, loss_test:0.08120, lr:1.48e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.118, tt:3642.450\n",
      "Ep:258, loss:0.00001, loss_test:0.08121, lr:1.47e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.093, tt:3650.171\n",
      "Ep:259, loss:0.00001, loss_test:0.08120, lr:1.45e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.074, tt:3659.117\n",
      "Ep:260, loss:0.00001, loss_test:0.08118, lr:1.44e-03, fs:0.75281 (r=0.677,p=0.848),  time:14.051, tt:3667.440\n",
      "Ep:261, loss:0.00001, loss_test:0.08120, lr:1.42e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.026, tt:3674.939\n",
      "Ep:262, loss:0.00001, loss_test:0.08118, lr:1.41e-03, fs:0.75706 (r=0.677,p=0.859),  time:14.001, tt:3682.278\n",
      "Ep:263, loss:0.00001, loss_test:0.08115, lr:1.39e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.978, tt:3690.106\n",
      "Ep:264, loss:0.00001, loss_test:0.08117, lr:1.38e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.954, tt:3697.826\n",
      "Ep:265, loss:0.00001, loss_test:0.08115, lr:1.37e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.933, tt:3706.131\n",
      "Ep:266, loss:0.00001, loss_test:0.08112, lr:1.35e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.906, tt:3712.983\n",
      "Ep:267, loss:0.00001, loss_test:0.08113, lr:1.34e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.883, tt:3720.641\n",
      "Ep:268, loss:0.00001, loss_test:0.08115, lr:1.33e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.858, tt:3727.749\n",
      "Ep:269, loss:0.00001, loss_test:0.08113, lr:1.31e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.839, tt:3736.523\n",
      "Ep:270, loss:0.00001, loss_test:0.08109, lr:1.30e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.815, tt:3743.900\n",
      "Ep:271, loss:0.00001, loss_test:0.08110, lr:1.29e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.793, tt:3751.723\n",
      "Ep:272, loss:0.00001, loss_test:0.08109, lr:1.27e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.772, tt:3759.858\n",
      "Ep:273, loss:0.00001, loss_test:0.08108, lr:1.26e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.752, tt:3768.014\n",
      "Ep:274, loss:0.00001, loss_test:0.08108, lr:1.25e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.731, tt:3775.937\n",
      "Ep:275, loss:0.00001, loss_test:0.08110, lr:1.24e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.708, tt:3783.367\n",
      "Ep:276, loss:0.00001, loss_test:0.08108, lr:1.22e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.691, tt:3792.374\n",
      "Ep:277, loss:0.00001, loss_test:0.08105, lr:1.21e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.673, tt:3801.002\n",
      "Ep:278, loss:0.00001, loss_test:0.08109, lr:1.20e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.653, tt:3809.257\n",
      "Ep:279, loss:0.00001, loss_test:0.08109, lr:1.19e-03, fs:0.75706 (r=0.677,p=0.859),  time:13.633, tt:3817.144\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00007, loss_test:0.14978, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.295, tt:8.295\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00007, loss_test:0.14975, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.578, tt:15.156\n",
      "Ep:2, loss:0.00007, loss_test:0.14971, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.603, tt:22.808\n",
      "Ep:3, loss:0.00007, loss_test:0.14965, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.889, tt:31.556\n",
      "Ep:4, loss:0.00007, loss_test:0.14960, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.803, tt:39.016\n",
      "Ep:5, loss:0.00007, loss_test:0.14956, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.920, tt:47.519\n",
      "Ep:6, loss:0.00007, loss_test:0.14953, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.807, tt:54.650\n",
      "Ep:7, loss:0.00007, loss_test:0.14947, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:7.837, tt:62.694\n",
      "Ep:8, loss:0.00007, loss_test:0.14936, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:7.735, tt:69.618\n",
      "Ep:9, loss:0.00007, loss_test:0.14915, lr:1.00e-02, fs:0.63636 (r=0.919,p=0.487),  time:7.701, tt:77.013\n",
      "Ep:10, loss:0.00007, loss_test:0.14889, lr:1.00e-02, fs:0.63571 (r=0.899,p=0.492),  time:7.641, tt:84.056\n",
      "Ep:11, loss:0.00006, loss_test:0.14889, lr:1.00e-02, fs:0.61029 (r=0.838,p=0.480),  time:7.618, tt:91.419\n",
      "Ep:12, loss:0.00006, loss_test:0.14897, lr:9.90e-03, fs:0.58915 (r=0.768,p=0.478),  time:7.593, tt:98.703\n",
      "Ep:13, loss:0.00006, loss_test:0.14949, lr:9.80e-03, fs:0.58436 (r=0.717,p=0.493),  time:7.565, tt:105.912\n",
      "Ep:14, loss:0.00006, loss_test:0.15020, lr:9.70e-03, fs:0.54626 (r=0.626,p=0.484),  time:7.537, tt:113.055\n",
      "Ep:15, loss:0.00006, loss_test:0.15156, lr:9.61e-03, fs:0.53953 (r=0.586,p=0.500),  time:7.590, tt:121.435\n",
      "Ep:16, loss:0.00006, loss_test:0.15360, lr:9.51e-03, fs:0.51707 (r=0.535,p=0.500),  time:7.636, tt:129.809\n",
      "Ep:17, loss:0.00005, loss_test:0.15488, lr:9.41e-03, fs:0.50251 (r=0.505,p=0.500),  time:7.616, tt:137.089\n",
      "Ep:18, loss:0.00005, loss_test:0.15526, lr:9.32e-03, fs:0.50256 (r=0.495,p=0.510),  time:7.620, tt:144.781\n",
      "Ep:19, loss:0.00005, loss_test:0.15436, lr:9.23e-03, fs:0.50761 (r=0.505,p=0.510),  time:7.628, tt:152.565\n",
      "Ep:20, loss:0.00005, loss_test:0.15253, lr:9.14e-03, fs:0.51256 (r=0.515,p=0.510),  time:7.681, tt:161.293\n",
      "Ep:21, loss:0.00005, loss_test:0.15061, lr:9.04e-03, fs:0.51707 (r=0.535,p=0.500),  time:7.719, tt:169.818\n",
      "Ep:22, loss:0.00005, loss_test:0.14938, lr:8.95e-03, fs:0.52174 (r=0.545,p=0.500),  time:7.740, tt:178.012\n",
      "Ep:23, loss:0.00005, loss_test:0.14854, lr:8.86e-03, fs:0.55660 (r=0.596,p=0.522),  time:7.724, tt:185.367\n",
      "Ep:24, loss:0.00005, loss_test:0.14814, lr:8.78e-03, fs:0.55924 (r=0.596,p=0.527),  time:7.718, tt:192.950\n",
      "Ep:25, loss:0.00005, loss_test:0.14810, lr:8.69e-03, fs:0.55769 (r=0.586,p=0.532),  time:7.718, tt:200.674\n",
      "Ep:26, loss:0.00005, loss_test:0.14828, lr:8.60e-03, fs:0.55072 (r=0.576,p=0.528),  time:7.717, tt:208.366\n",
      "Ep:27, loss:0.00005, loss_test:0.14824, lr:8.51e-03, fs:0.56436 (r=0.576,p=0.553),  time:7.754, tt:217.105\n",
      "Ep:28, loss:0.00005, loss_test:0.14785, lr:8.43e-03, fs:0.56716 (r=0.576,p=0.559),  time:7.769, tt:225.297\n",
      "Ep:29, loss:0.00005, loss_test:0.14714, lr:8.35e-03, fs:0.56436 (r=0.576,p=0.553),  time:7.825, tt:234.740\n",
      "Ep:30, loss:0.00005, loss_test:0.14617, lr:8.26e-03, fs:0.56436 (r=0.576,p=0.553),  time:7.820, tt:242.413\n",
      "Ep:31, loss:0.00004, loss_test:0.14517, lr:8.18e-03, fs:0.56311 (r=0.586,p=0.542),  time:7.821, tt:250.280\n",
      "Ep:32, loss:0.00004, loss_test:0.14421, lr:8.10e-03, fs:0.55769 (r=0.586,p=0.532),  time:7.820, tt:258.065\n",
      "Ep:33, loss:0.00004, loss_test:0.14342, lr:8.02e-03, fs:0.55238 (r=0.586,p=0.523),  time:7.819, tt:265.848\n",
      "Ep:34, loss:0.00004, loss_test:0.14279, lr:7.94e-03, fs:0.55502 (r=0.586,p=0.527),  time:7.816, tt:273.573\n",
      "Ep:35, loss:0.00004, loss_test:0.14228, lr:7.86e-03, fs:0.55610 (r=0.576,p=0.538),  time:7.827, tt:281.769\n",
      "Ep:36, loss:0.00004, loss_test:0.14182, lr:7.78e-03, fs:0.55610 (r=0.576,p=0.538),  time:7.822, tt:289.405\n",
      "Ep:37, loss:0.00004, loss_test:0.14140, lr:7.70e-03, fs:0.55610 (r=0.576,p=0.538),  time:7.828, tt:297.452\n",
      "Ep:38, loss:0.00004, loss_test:0.14105, lr:7.62e-03, fs:0.55610 (r=0.576,p=0.538),  time:7.790, tt:303.825\n",
      "Ep:39, loss:0.00004, loss_test:0.14068, lr:7.55e-03, fs:0.55340 (r=0.576,p=0.533),  time:7.719, tt:308.765\n",
      "Ep:40, loss:0.00004, loss_test:0.14018, lr:7.47e-03, fs:0.55610 (r=0.576,p=0.538),  time:7.638, tt:313.165\n",
      "Ep:41, loss:0.00004, loss_test:0.13961, lr:7.40e-03, fs:0.55340 (r=0.576,p=0.533),  time:7.561, tt:317.567\n",
      "Ep:42, loss:0.00004, loss_test:0.13899, lr:7.32e-03, fs:0.55882 (r=0.576,p=0.543),  time:7.485, tt:321.875\n",
      "Ep:43, loss:0.00004, loss_test:0.13838, lr:7.25e-03, fs:0.56158 (r=0.576,p=0.548),  time:7.417, tt:326.327\n",
      "Ep:44, loss:0.00004, loss_test:0.13768, lr:7.18e-03, fs:0.56436 (r=0.576,p=0.553),  time:7.347, tt:330.633\n",
      "Ep:45, loss:0.00004, loss_test:0.13708, lr:7.11e-03, fs:0.56436 (r=0.576,p=0.553),  time:7.284, tt:335.061\n",
      "Ep:46, loss:0.00004, loss_test:0.13663, lr:7.03e-03, fs:0.57843 (r=0.596,p=0.562),  time:7.222, tt:339.425\n",
      "Ep:47, loss:0.00004, loss_test:0.13624, lr:6.96e-03, fs:0.58128 (r=0.596,p=0.567),  time:7.163, tt:343.813\n",
      "Ep:48, loss:0.00004, loss_test:0.13588, lr:6.89e-03, fs:0.57843 (r=0.596,p=0.562),  time:7.104, tt:348.086\n",
      "Ep:49, loss:0.00004, loss_test:0.13546, lr:6.83e-03, fs:0.58537 (r=0.606,p=0.566),  time:7.048, tt:352.390\n",
      "Ep:50, loss:0.00004, loss_test:0.13498, lr:6.76e-03, fs:0.58537 (r=0.606,p=0.566),  time:6.996, tt:356.786\n",
      "Ep:51, loss:0.00004, loss_test:0.13442, lr:6.69e-03, fs:0.59223 (r=0.616,p=0.570),  time:6.947, tt:361.251\n",
      "Ep:52, loss:0.00004, loss_test:0.13377, lr:6.62e-03, fs:0.59804 (r=0.616,p=0.581),  time:6.898, tt:365.571\n",
      "Ep:53, loss:0.00004, loss_test:0.13315, lr:6.56e-03, fs:0.60099 (r=0.616,p=0.587),  time:6.853, tt:370.051\n",
      "Ep:54, loss:0.00004, loss_test:0.13263, lr:6.49e-03, fs:0.60396 (r=0.616,p=0.592),  time:6.808, tt:374.463\n",
      "Ep:55, loss:0.00004, loss_test:0.13220, lr:6.43e-03, fs:0.60302 (r=0.606,p=0.600),  time:6.767, tt:378.927\n",
      "Ep:56, loss:0.00004, loss_test:0.13188, lr:6.36e-03, fs:0.61000 (r=0.616,p=0.604),  time:6.723, tt:383.230\n",
      "Ep:57, loss:0.00004, loss_test:0.13160, lr:6.30e-03, fs:0.60697 (r=0.616,p=0.598),  time:6.683, tt:387.607\n",
      "Ep:58, loss:0.00004, loss_test:0.13135, lr:6.24e-03, fs:0.61000 (r=0.616,p=0.604),  time:6.645, tt:392.051\n",
      "Ep:59, loss:0.00003, loss_test:0.13111, lr:6.17e-03, fs:0.61307 (r=0.616,p=0.610),  time:6.606, tt:396.367\n",
      "Ep:60, loss:0.00003, loss_test:0.13086, lr:6.11e-03, fs:0.60606 (r=0.606,p=0.606),  time:6.569, tt:400.688\n",
      "Ep:61, loss:0.00003, loss_test:0.13061, lr:6.05e-03, fs:0.60606 (r=0.606,p=0.606),  time:6.532, tt:404.991\n",
      "Ep:62, loss:0.00003, loss_test:0.13034, lr:5.99e-03, fs:0.60914 (r=0.606,p=0.612),  time:6.497, tt:409.315\n",
      "Ep:63, loss:0.00003, loss_test:0.13007, lr:5.93e-03, fs:0.61224 (r=0.606,p=0.619),  time:6.465, tt:413.774\n",
      "Ep:64, loss:0.00003, loss_test:0.12979, lr:5.87e-03, fs:0.61224 (r=0.606,p=0.619),  time:6.431, tt:418.042\n",
      "Ep:65, loss:0.00003, loss_test:0.12949, lr:5.81e-03, fs:0.64000 (r=0.646,p=0.634),  time:6.400, tt:422.425\n",
      "Ep:66, loss:0.00003, loss_test:0.12914, lr:5.75e-03, fs:0.65000 (r=0.657,p=0.644),  time:6.370, tt:426.815\n",
      "Ep:67, loss:0.00003, loss_test:0.12880, lr:5.70e-03, fs:0.66000 (r=0.667,p=0.653),  time:6.342, tt:431.263\n",
      "Ep:68, loss:0.00003, loss_test:0.12847, lr:5.64e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.314, tt:435.651\n",
      "Ep:69, loss:0.00003, loss_test:0.12816, lr:5.58e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.286, tt:440.013\n",
      "Ep:70, loss:0.00003, loss_test:0.12788, lr:5.53e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.259, tt:444.381\n",
      "Ep:71, loss:0.00003, loss_test:0.12765, lr:5.47e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.232, tt:448.685\n",
      "Ep:72, loss:0.00003, loss_test:0.12745, lr:5.42e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.207, tt:453.081\n",
      "Ep:73, loss:0.00003, loss_test:0.12724, lr:5.36e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.182, tt:457.457\n",
      "Ep:74, loss:0.00003, loss_test:0.12704, lr:5.31e-03, fs:0.66332 (r=0.667,p=0.660),  time:6.158, tt:461.884\n",
      "Ep:75, loss:0.00003, loss_test:0.12685, lr:5.26e-03, fs:0.66327 (r=0.657,p=0.670),  time:6.135, tt:466.276\n",
      "Ep:76, loss:0.00003, loss_test:0.12663, lr:5.20e-03, fs:0.66667 (r=0.657,p=0.677),  time:6.113, tt:470.703\n",
      "Ep:77, loss:0.00003, loss_test:0.12634, lr:5.15e-03, fs:0.67692 (r=0.667,p=0.688),  time:6.091, tt:475.127\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00003, loss_test:0.12601, lr:5.15e-03, fs:0.67347 (r=0.667,p=0.680),  time:6.071, tt:479.576\n",
      "Ep:79, loss:0.00003, loss_test:0.12566, lr:5.15e-03, fs:0.67347 (r=0.667,p=0.680),  time:6.047, tt:483.796\n",
      "Ep:80, loss:0.00003, loss_test:0.12535, lr:5.15e-03, fs:0.66667 (r=0.657,p=0.677),  time:6.027, tt:488.178\n",
      "Ep:81, loss:0.00003, loss_test:0.12505, lr:5.15e-03, fs:0.66667 (r=0.657,p=0.677),  time:6.008, tt:492.621\n",
      "Ep:82, loss:0.00003, loss_test:0.12479, lr:5.15e-03, fs:0.67358 (r=0.657,p=0.691),  time:5.988, tt:497.021\n",
      "Ep:83, loss:0.00003, loss_test:0.12451, lr:5.15e-03, fs:0.68063 (r=0.657,p=0.707),  time:5.970, tt:501.506\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00003, loss_test:0.12423, lr:5.15e-03, fs:0.68063 (r=0.657,p=0.707),  time:5.952, tt:505.891\n",
      "Ep:85, loss:0.00003, loss_test:0.12395, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.933, tt:510.240\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00003, loss_test:0.12363, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.914, tt:514.553\n",
      "Ep:87, loss:0.00003, loss_test:0.12329, lr:5.15e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.897, tt:518.915\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.12296, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.880, tt:523.301\n",
      "Ep:89, loss:0.00003, loss_test:0.12267, lr:5.15e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.863, tt:527.689\n",
      "Ep:90, loss:0.00003, loss_test:0.12243, lr:5.15e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.846, tt:532.007\n",
      "Ep:91, loss:0.00003, loss_test:0.12222, lr:5.15e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.830, tt:536.391\n",
      "Ep:92, loss:0.00003, loss_test:0.12207, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.815, tt:540.836\n",
      "Ep:93, loss:0.00003, loss_test:0.12189, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.799, tt:545.145\n",
      "Ep:94, loss:0.00003, loss_test:0.12165, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.784, tt:549.525\n",
      "Ep:95, loss:0.00003, loss_test:0.12141, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.769, tt:553.853\n",
      "Ep:96, loss:0.00003, loss_test:0.12121, lr:5.15e-03, fs:0.68421 (r=0.657,p=0.714),  time:5.755, tt:558.191\n",
      "Ep:97, loss:0.00003, loss_test:0.12106, lr:5.15e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.740, tt:562.545\n",
      "Ep:98, loss:0.00003, loss_test:0.12091, lr:5.15e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.726, tt:566.886\n",
      "Ep:99, loss:0.00003, loss_test:0.12069, lr:5.10e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.713, tt:571.253\n",
      "Ep:100, loss:0.00003, loss_test:0.12047, lr:5.05e-03, fs:0.69149 (r=0.657,p=0.730),  time:5.702, tt:575.909\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00003, loss_test:0.12030, lr:5.05e-03, fs:0.69149 (r=0.657,p=0.730),  time:5.691, tt:580.432\n",
      "Ep:102, loss:0.00003, loss_test:0.12017, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.679, tt:584.908\n",
      "Ep:103, loss:0.00003, loss_test:0.12002, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.666, tt:589.272\n",
      "Ep:104, loss:0.00003, loss_test:0.11981, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.654, tt:593.685\n",
      "Ep:105, loss:0.00003, loss_test:0.11956, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.642, tt:598.090\n",
      "Ep:106, loss:0.00003, loss_test:0.11937, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.631, tt:602.508\n",
      "Ep:107, loss:0.00003, loss_test:0.11929, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.621, tt:607.016\n",
      "Ep:108, loss:0.00003, loss_test:0.11924, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.609, tt:611.400\n",
      "Ep:109, loss:0.00003, loss_test:0.11914, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.598, tt:615.808\n",
      "Ep:110, loss:0.00003, loss_test:0.11895, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.587, tt:620.204\n",
      "Ep:111, loss:0.00003, loss_test:0.11877, lr:5.05e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.576, tt:624.492\n",
      "Ep:112, loss:0.00003, loss_test:0.11861, lr:5.00e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.565, tt:628.850\n",
      "Ep:113, loss:0.00002, loss_test:0.11851, lr:4.95e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.556, tt:633.337\n",
      "Ep:114, loss:0.00002, loss_test:0.11843, lr:4.90e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.545, tt:637.690\n",
      "Ep:115, loss:0.00002, loss_test:0.11828, lr:4.85e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.534, tt:641.979\n",
      "Ep:116, loss:0.00002, loss_test:0.11806, lr:4.80e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.525, tt:646.419\n",
      "Ep:117, loss:0.00002, loss_test:0.11788, lr:4.75e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.515, tt:650.759\n",
      "Ep:118, loss:0.00002, loss_test:0.11779, lr:4.71e-03, fs:0.68783 (r=0.657,p=0.722),  time:5.505, tt:655.092\n",
      "Ep:119, loss:0.00002, loss_test:0.11771, lr:4.66e-03, fs:0.68085 (r=0.646,p=0.719),  time:5.495, tt:659.428\n",
      "Ep:120, loss:0.00002, loss_test:0.11760, lr:4.61e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.486, tt:663.784\n",
      "Ep:121, loss:0.00002, loss_test:0.11747, lr:4.57e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.477, tt:668.208\n",
      "Ep:122, loss:0.00002, loss_test:0.11742, lr:4.52e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.468, tt:672.607\n",
      "Ep:123, loss:0.00002, loss_test:0.11742, lr:4.48e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.460, tt:677.054\n",
      "Ep:124, loss:0.00002, loss_test:0.11734, lr:4.43e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.451, tt:681.342\n",
      "Ep:125, loss:0.00002, loss_test:0.11721, lr:4.39e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.442, tt:685.742\n",
      "Ep:126, loss:0.00002, loss_test:0.11716, lr:4.34e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.434, tt:690.109\n",
      "Ep:127, loss:0.00002, loss_test:0.11709, lr:4.30e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.425, tt:694.441\n",
      "Ep:128, loss:0.00002, loss_test:0.11694, lr:4.26e-03, fs:0.68085 (r=0.646,p=0.719),  time:5.417, tt:698.804\n",
      "Ep:129, loss:0.00002, loss_test:0.11681, lr:4.21e-03, fs:0.68085 (r=0.646,p=0.719),  time:5.408, tt:703.039\n",
      "Ep:130, loss:0.00002, loss_test:0.11678, lr:4.17e-03, fs:0.68085 (r=0.646,p=0.719),  time:5.400, tt:707.458\n",
      "Ep:131, loss:0.00002, loss_test:0.11675, lr:4.13e-03, fs:0.68085 (r=0.646,p=0.719),  time:5.393, tt:711.856\n",
      "Ep:132, loss:0.00002, loss_test:0.11665, lr:4.09e-03, fs:0.68085 (r=0.646,p=0.719),  time:5.385, tt:716.251\n",
      "Ep:133, loss:0.00002, loss_test:0.11655, lr:4.05e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.379, tt:720.751\n",
      "Ep:134, loss:0.00002, loss_test:0.11649, lr:4.01e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.370, tt:725.016\n",
      "Ep:135, loss:0.00002, loss_test:0.11637, lr:3.97e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.363, tt:729.365\n",
      "Ep:136, loss:0.00002, loss_test:0.11623, lr:3.93e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.356, tt:733.749\n",
      "Ep:137, loss:0.00002, loss_test:0.11612, lr:3.89e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.348, tt:738.029\n",
      "Ep:138, loss:0.00002, loss_test:0.11601, lr:3.85e-03, fs:0.66310 (r=0.626,p=0.705),  time:5.342, tt:742.482\n",
      "Ep:139, loss:0.00002, loss_test:0.11585, lr:3.81e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.335, tt:746.843\n",
      "Ep:140, loss:0.00002, loss_test:0.11568, lr:3.77e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.328, tt:751.255\n",
      "Ep:141, loss:0.00002, loss_test:0.11554, lr:3.73e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.321, tt:755.594\n",
      "Ep:142, loss:0.00002, loss_test:0.11545, lr:3.70e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.313, tt:759.826\n",
      "Ep:143, loss:0.00002, loss_test:0.11538, lr:3.66e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.307, tt:764.262\n",
      "Ep:144, loss:0.00002, loss_test:0.11529, lr:3.62e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.301, tt:768.634\n",
      "Ep:145, loss:0.00002, loss_test:0.11522, lr:3.59e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.295, tt:773.083\n",
      "Ep:146, loss:0.00002, loss_test:0.11511, lr:3.55e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.288, tt:777.362\n",
      "Ep:147, loss:0.00002, loss_test:0.11504, lr:3.52e-03, fs:0.67021 (r=0.636,p=0.708),  time:5.282, tt:781.766\n",
      "Ep:148, loss:0.00002, loss_test:0.11497, lr:3.48e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.277, tt:786.206\n",
      "Ep:149, loss:0.00002, loss_test:0.11491, lr:3.45e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.270, tt:790.523\n",
      "Ep:150, loss:0.00002, loss_test:0.11484, lr:3.41e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.264, tt:794.862\n",
      "Ep:151, loss:0.00002, loss_test:0.11474, lr:3.38e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.259, tt:799.329\n",
      "Ep:152, loss:0.00002, loss_test:0.11464, lr:3.34e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.253, tt:803.661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00002, loss_test:0.11457, lr:3.31e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.247, tt:808.097\n",
      "Ep:154, loss:0.00002, loss_test:0.11455, lr:3.28e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.241, tt:812.359\n",
      "Ep:155, loss:0.00002, loss_test:0.11449, lr:3.24e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.235, tt:816.715\n",
      "Ep:156, loss:0.00002, loss_test:0.11438, lr:3.21e-03, fs:0.66667 (r=0.626,p=0.713),  time:5.230, tt:821.091\n",
      "Ep:157, loss:0.00002, loss_test:0.11429, lr:3.18e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.225, tt:825.504\n",
      "Ep:158, loss:0.00002, loss_test:0.11424, lr:3.15e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.220, tt:829.920\n",
      "Ep:159, loss:0.00002, loss_test:0.11420, lr:3.12e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.214, tt:834.288\n",
      "Ep:160, loss:0.00002, loss_test:0.11409, lr:3.09e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.210, tt:838.740\n",
      "Ep:161, loss:0.00002, loss_test:0.11398, lr:3.05e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.205, tt:843.176\n",
      "Ep:162, loss:0.00002, loss_test:0.11396, lr:3.02e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.199, tt:847.500\n",
      "Ep:163, loss:0.00002, loss_test:0.11395, lr:2.99e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.195, tt:852.000\n",
      "Ep:164, loss:0.00002, loss_test:0.11389, lr:2.96e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.190, tt:856.352\n",
      "Ep:165, loss:0.00002, loss_test:0.11380, lr:2.93e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.185, tt:860.781\n",
      "Ep:166, loss:0.00002, loss_test:0.11369, lr:2.90e-03, fs:0.67380 (r=0.636,p=0.716),  time:5.181, tt:865.212\n",
      "Ep:167, loss:0.00002, loss_test:0.11366, lr:2.88e-03, fs:0.67742 (r=0.636,p=0.724),  time:5.176, tt:869.625\n",
      "Ep:168, loss:0.00002, loss_test:0.11365, lr:2.85e-03, fs:0.67027 (r=0.626,p=0.721),  time:5.172, tt:874.011\n",
      "Ep:169, loss:0.00002, loss_test:0.11357, lr:2.82e-03, fs:0.67027 (r=0.626,p=0.721),  time:5.168, tt:878.527\n",
      "Ep:170, loss:0.00002, loss_test:0.11341, lr:2.79e-03, fs:0.67027 (r=0.626,p=0.721),  time:5.163, tt:882.917\n",
      "Ep:171, loss:0.00002, loss_test:0.11335, lr:2.76e-03, fs:0.67027 (r=0.626,p=0.721),  time:5.158, tt:887.161\n",
      "Ep:172, loss:0.00002, loss_test:0.11336, lr:2.73e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.153, tt:891.540\n",
      "Ep:173, loss:0.00002, loss_test:0.11337, lr:2.71e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.149, tt:895.953\n",
      "Ep:174, loss:0.00002, loss_test:0.11330, lr:2.68e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.144, tt:900.261\n",
      "Ep:175, loss:0.00002, loss_test:0.11322, lr:2.65e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.139, tt:904.524\n",
      "Ep:176, loss:0.00002, loss_test:0.11322, lr:2.63e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.135, tt:908.892\n",
      "Ep:177, loss:0.00002, loss_test:0.11331, lr:2.60e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.131, tt:913.266\n",
      "Ep:178, loss:0.00002, loss_test:0.11340, lr:2.57e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.127, tt:917.692\n",
      "Ep:179, loss:0.00002, loss_test:0.11342, lr:2.55e-03, fs:0.67391 (r=0.626,p=0.729),  time:5.124, tt:922.240\n",
      "Ep:180, loss:0.00002, loss_test:0.11337, lr:2.52e-03, fs:0.67760 (r=0.626,p=0.738),  time:5.119, tt:926.603\n",
      "Ep:181, loss:0.00002, loss_test:0.11333, lr:2.50e-03, fs:0.67760 (r=0.626,p=0.738),  time:5.115, tt:930.891\n",
      "Ep:182, loss:0.00002, loss_test:0.11338, lr:2.47e-03, fs:0.67760 (r=0.626,p=0.738),  time:5.111, tt:935.301\n",
      "Ep:183, loss:0.00002, loss_test:0.11346, lr:2.45e-03, fs:0.67760 (r=0.626,p=0.738),  time:5.107, tt:939.687\n",
      "Ep:184, loss:0.00002, loss_test:0.11353, lr:2.42e-03, fs:0.67760 (r=0.626,p=0.738),  time:5.104, tt:944.198\n",
      "Ep:185, loss:0.00002, loss_test:0.11352, lr:2.40e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.100, tt:948.569\n",
      "Ep:186, loss:0.00002, loss_test:0.11346, lr:2.38e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.096, tt:952.925\n",
      "Ep:187, loss:0.00002, loss_test:0.11342, lr:2.35e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.092, tt:957.281\n",
      "Ep:188, loss:0.00002, loss_test:0.11348, lr:2.33e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.088, tt:961.647\n",
      "Ep:189, loss:0.00002, loss_test:0.11353, lr:2.31e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.084, tt:965.943\n",
      "Ep:190, loss:0.00002, loss_test:0.11349, lr:2.28e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.080, tt:970.350\n",
      "Ep:191, loss:0.00002, loss_test:0.11346, lr:2.26e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.077, tt:974.742\n",
      "Ep:192, loss:0.00002, loss_test:0.11346, lr:2.24e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.073, tt:979.058\n",
      "Ep:193, loss:0.00002, loss_test:0.11346, lr:2.21e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.069, tt:983.416\n",
      "Ep:194, loss:0.00002, loss_test:0.11338, lr:2.19e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.066, tt:987.889\n",
      "Ep:195, loss:0.00002, loss_test:0.11334, lr:2.17e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.063, tt:992.354\n",
      "Ep:196, loss:0.00002, loss_test:0.11329, lr:2.15e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.059, tt:996.661\n",
      "Ep:197, loss:0.00002, loss_test:0.11324, lr:2.13e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.056, tt:1000.989\n",
      "Ep:198, loss:0.00002, loss_test:0.11321, lr:2.11e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.052, tt:1005.367\n",
      "Ep:199, loss:0.00002, loss_test:0.11317, lr:2.08e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.049, tt:1009.716\n",
      "Ep:200, loss:0.00002, loss_test:0.11311, lr:2.06e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.045, tt:1014.066\n",
      "Ep:201, loss:0.00002, loss_test:0.11306, lr:2.04e-03, fs:0.68132 (r=0.626,p=0.747),  time:5.042, tt:1018.426\n",
      "Ep:202, loss:0.00002, loss_test:0.11305, lr:2.02e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.038, tt:1022.774\n",
      "Ep:203, loss:0.00002, loss_test:0.11301, lr:2.00e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.035, tt:1027.188\n",
      "Ep:204, loss:0.00002, loss_test:0.11292, lr:1.98e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.031, tt:1031.395\n",
      "Ep:205, loss:0.00002, loss_test:0.11290, lr:1.96e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.028, tt:1035.848\n",
      "Ep:206, loss:0.00002, loss_test:0.11287, lr:1.94e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.025, tt:1040.263\n",
      "Ep:207, loss:0.00002, loss_test:0.11282, lr:1.92e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.023, tt:1044.746\n",
      "Ep:208, loss:0.00002, loss_test:0.11283, lr:1.90e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.020, tt:1049.099\n",
      "Ep:209, loss:0.00002, loss_test:0.11280, lr:1.89e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.017, tt:1053.553\n",
      "Ep:210, loss:0.00002, loss_test:0.11276, lr:1.87e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.014, tt:1057.979\n",
      "Ep:211, loss:0.00002, loss_test:0.11272, lr:1.85e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.011, tt:1062.399\n",
      "Ep:212, loss:0.00002, loss_test:0.11265, lr:1.83e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.008, tt:1066.741\n",
      "Ep:213, loss:0.00002, loss_test:0.11264, lr:1.81e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.006, tt:1071.209\n",
      "Ep:214, loss:0.00002, loss_test:0.11258, lr:1.79e-03, fs:0.68508 (r=0.626,p=0.756),  time:5.002, tt:1075.471\n",
      "Ep:215, loss:0.00002, loss_test:0.11253, lr:1.78e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.999, tt:1079.755\n",
      "Ep:216, loss:0.00002, loss_test:0.11251, lr:1.76e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.996, tt:1084.095\n",
      "Ep:217, loss:0.00002, loss_test:0.11249, lr:1.74e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.993, tt:1088.434\n",
      "Ep:218, loss:0.00002, loss_test:0.11247, lr:1.72e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.990, tt:1092.813\n",
      "Ep:219, loss:0.00002, loss_test:0.11245, lr:1.71e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.988, tt:1097.376\n",
      "Ep:220, loss:0.00002, loss_test:0.11245, lr:1.69e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.985, tt:1101.736\n",
      "Ep:221, loss:0.00002, loss_test:0.11245, lr:1.67e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.983, tt:1106.140\n",
      "Ep:222, loss:0.00002, loss_test:0.11242, lr:1.65e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.980, tt:1110.551\n",
      "Ep:223, loss:0.00002, loss_test:0.11238, lr:1.64e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.978, tt:1115.021\n",
      "Ep:224, loss:0.00002, loss_test:0.11239, lr:1.62e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.975, tt:1119.475\n",
      "Ep:225, loss:0.00002, loss_test:0.11235, lr:1.61e-03, fs:0.68889 (r=0.626,p=0.765),  time:4.972, tt:1123.748\n",
      "Ep:226, loss:0.00002, loss_test:0.11232, lr:1.59e-03, fs:0.69274 (r=0.626,p=0.775),  time:4.969, tt:1128.014\n",
      "##########Best model found so far##########\n",
      "Ep:227, loss:0.00002, loss_test:0.11231, lr:1.59e-03, fs:0.69274 (r=0.626,p=0.775),  time:4.967, tt:1132.391\n",
      "Ep:228, loss:0.00002, loss_test:0.11232, lr:1.59e-03, fs:0.69274 (r=0.626,p=0.775),  time:4.964, tt:1136.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:229, loss:0.00002, loss_test:0.11228, lr:1.59e-03, fs:0.69274 (r=0.626,p=0.775),  time:4.961, tt:1141.051\n",
      "Ep:230, loss:0.00002, loss_test:0.11227, lr:1.59e-03, fs:0.69274 (r=0.626,p=0.775),  time:4.959, tt:1145.490\n",
      "Ep:231, loss:0.00002, loss_test:0.11226, lr:1.59e-03, fs:0.68927 (r=0.616,p=0.782),  time:4.958, tt:1150.190\n",
      "Ep:232, loss:0.00002, loss_test:0.11223, lr:1.59e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.957, tt:1154.874\n",
      "Ep:233, loss:0.00002, loss_test:0.11221, lr:1.59e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.956, tt:1159.590\n",
      "Ep:234, loss:0.00002, loss_test:0.11221, lr:1.59e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.954, tt:1164.216\n",
      "Ep:235, loss:0.00002, loss_test:0.11220, lr:1.59e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.953, tt:1168.805\n",
      "Ep:236, loss:0.00002, loss_test:0.11220, lr:1.59e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.951, tt:1173.496\n",
      "Ep:237, loss:0.00002, loss_test:0.11219, lr:1.59e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.950, tt:1178.107\n",
      "Ep:238, loss:0.00002, loss_test:0.11216, lr:1.57e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.948, tt:1182.543\n",
      "Ep:239, loss:0.00002, loss_test:0.11219, lr:1.56e-03, fs:0.68182 (r=0.606,p=0.779),  time:4.946, tt:1187.035\n",
      "Ep:240, loss:0.00002, loss_test:0.11222, lr:1.54e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.944, tt:1191.543\n",
      "Ep:241, loss:0.00002, loss_test:0.11220, lr:1.53e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.943, tt:1196.138\n",
      "Ep:242, loss:0.00002, loss_test:0.11221, lr:1.51e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.941, tt:1200.754\n",
      "Ep:243, loss:0.00002, loss_test:0.11224, lr:1.50e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.939, tt:1205.202\n",
      "Ep:244, loss:0.00002, loss_test:0.11221, lr:1.48e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.937, tt:1209.543\n",
      "Ep:245, loss:0.00002, loss_test:0.11219, lr:1.47e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.935, tt:1213.995\n",
      "Ep:246, loss:0.00002, loss_test:0.11222, lr:1.45e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.933, tt:1218.465\n",
      "Ep:247, loss:0.00002, loss_test:0.11222, lr:1.44e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.931, tt:1222.906\n",
      "Ep:248, loss:0.00002, loss_test:0.11218, lr:1.42e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.929, tt:1227.367\n",
      "Ep:249, loss:0.00002, loss_test:0.11219, lr:1.41e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.927, tt:1231.678\n",
      "Ep:250, loss:0.00002, loss_test:0.11223, lr:1.39e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.925, tt:1236.132\n",
      "Ep:251, loss:0.00002, loss_test:0.11221, lr:1.38e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.923, tt:1240.509\n",
      "Ep:252, loss:0.00002, loss_test:0.11216, lr:1.37e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.921, tt:1244.927\n",
      "Ep:253, loss:0.00002, loss_test:0.11215, lr:1.35e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.918, tt:1249.263\n",
      "Ep:254, loss:0.00002, loss_test:0.11213, lr:1.34e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.916, tt:1253.700\n",
      "Ep:255, loss:0.00002, loss_test:0.11210, lr:1.33e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.914, tt:1258.109\n",
      "Ep:256, loss:0.00002, loss_test:0.11209, lr:1.31e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.912, tt:1262.512\n",
      "Ep:257, loss:0.00002, loss_test:0.11210, lr:1.30e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.911, tt:1266.975\n",
      "Ep:258, loss:0.00002, loss_test:0.11212, lr:1.29e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.909, tt:1271.463\n",
      "Ep:259, loss:0.00002, loss_test:0.11213, lr:1.27e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.907, tt:1275.810\n",
      "Ep:260, loss:0.00002, loss_test:0.11214, lr:1.26e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.905, tt:1280.166\n",
      "Ep:261, loss:0.00002, loss_test:0.11216, lr:1.25e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.903, tt:1284.573\n",
      "Ep:262, loss:0.00002, loss_test:0.11214, lr:1.24e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.901, tt:1288.933\n",
      "Ep:263, loss:0.00002, loss_test:0.11212, lr:1.22e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.899, tt:1293.332\n",
      "Ep:264, loss:0.00002, loss_test:0.11215, lr:1.21e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.897, tt:1297.692\n",
      "Ep:265, loss:0.00002, loss_test:0.11215, lr:1.20e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.895, tt:1302.160\n",
      "Ep:266, loss:0.00002, loss_test:0.11213, lr:1.19e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.894, tt:1306.758\n",
      "Ep:267, loss:0.00002, loss_test:0.11215, lr:1.18e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.892, tt:1311.186\n",
      "Ep:268, loss:0.00002, loss_test:0.11219, lr:1.16e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.891, tt:1315.702\n",
      "Ep:269, loss:0.00002, loss_test:0.11220, lr:1.15e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.889, tt:1320.158\n",
      "Ep:270, loss:0.00002, loss_test:0.11217, lr:1.14e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.888, tt:1324.551\n",
      "Ep:271, loss:0.00002, loss_test:0.11217, lr:1.13e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.886, tt:1328.955\n",
      "Ep:272, loss:0.00002, loss_test:0.11220, lr:1.12e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.884, tt:1333.343\n",
      "Ep:273, loss:0.00002, loss_test:0.11219, lr:1.11e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.882, tt:1337.792\n",
      "Ep:274, loss:0.00002, loss_test:0.11216, lr:1.10e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.881, tt:1342.280\n",
      "Ep:275, loss:0.00002, loss_test:0.11214, lr:1.08e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.880, tt:1346.800\n",
      "Ep:276, loss:0.00002, loss_test:0.11216, lr:1.07e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.878, tt:1351.108\n",
      "Ep:277, loss:0.00002, loss_test:0.11220, lr:1.06e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.876, tt:1355.495\n",
      "Ep:278, loss:0.00002, loss_test:0.11222, lr:1.05e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.874, tt:1359.982\n",
      "Ep:279, loss:0.00002, loss_test:0.11220, lr:1.04e-03, fs:0.67429 (r=0.596,p=0.776),  time:4.873, tt:1364.388\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,280,cv_number,2,False)\n",
    "\n",
    "cv_number = \"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,280,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14024, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.723, tt:28.723\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13874, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:29.809, tt:59.618\n",
      "Ep:2, loss:0.00027, loss_test:0.13609, lr:1.00e-02, fs:0.63860 (r=0.919,p=0.489),  time:30.089, tt:90.268\n",
      "Ep:3, loss:0.00027, loss_test:0.13165, lr:1.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:30.540, tt:122.160\n",
      "Ep:4, loss:0.00026, loss_test:0.12610, lr:1.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:30.499, tt:152.495\n",
      "Ep:5, loss:0.00025, loss_test:0.12137, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:30.502, tt:183.013\n",
      "Ep:6, loss:0.00024, loss_test:0.11905, lr:1.00e-02, fs:0.64734 (r=0.677,p=0.620),  time:30.670, tt:214.689\n",
      "Ep:7, loss:0.00024, loss_test:0.11672, lr:1.00e-02, fs:0.65657 (r=0.657,p=0.657),  time:30.601, tt:244.805\n",
      "Ep:8, loss:0.00023, loss_test:0.11385, lr:1.00e-02, fs:0.65327 (r=0.657,p=0.650),  time:30.532, tt:274.784\n",
      "Ep:9, loss:0.00023, loss_test:0.11099, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:30.694, tt:306.936\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10804, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:30.771, tt:338.481\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10465, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:30.856, tt:370.275\n",
      "Ep:12, loss:0.00021, loss_test:0.10345, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:30.933, tt:402.127\n",
      "Ep:13, loss:0.00020, loss_test:0.10172, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:30.930, tt:433.014\n",
      "Ep:14, loss:0.00020, loss_test:0.09930, lr:1.00e-02, fs:0.68718 (r=0.677,p=0.698),  time:30.930, tt:463.957\n",
      "Ep:15, loss:0.00019, loss_test:0.09712, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:31.000, tt:495.993\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09628, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:30.912, tt:525.509\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09563, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:30.893, tt:556.076\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09505, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:30.833, tt:585.829\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09417, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:30.827, tt:616.542\n",
      "Ep:20, loss:0.00017, loss_test:0.09277, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:30.770, tt:646.166\n",
      "Ep:21, loss:0.00017, loss_test:0.09133, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:30.816, tt:677.953\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.09042, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:30.844, tt:709.402\n",
      "Ep:23, loss:0.00016, loss_test:0.08944, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.891, tt:741.388\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.08817, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:30.969, tt:774.234\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08693, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:30.989, tt:805.707\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08580, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:31.026, tt:837.708\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.08481, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:31.064, tt:869.802\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08355, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:31.092, tt:901.680\n",
      "Ep:29, loss:0.00014, loss_test:0.08214, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.072, tt:932.155\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.08141, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:31.077, tt:963.401\n",
      "Ep:31, loss:0.00013, loss_test:0.08076, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.102, tt:995.270\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.07925, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.109, tt:1026.587\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07937, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.088, tt:1056.997\n",
      "Ep:34, loss:0.00012, loss_test:0.07912, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:31.083, tt:1087.900\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.07672, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.084, tt:1119.037\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.07725, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:31.130, tt:1151.803\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07680, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:31.123, tt:1182.672\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.07469, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:31.126, tt:1213.913\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.07588, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.120, tt:1244.798\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.07515, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.146, tt:1277.005\n",
      "Ep:41, loss:0.00010, loss_test:0.07341, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.186, tt:1309.808\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.07405, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:31.191, tt:1341.213\n",
      "Ep:43, loss:0.00010, loss_test:0.07224, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:31.203, tt:1372.924\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.07404, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.200, tt:1403.993\n",
      "Ep:45, loss:0.00009, loss_test:0.07081, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.220, tt:1436.097\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.07284, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.217, tt:1467.178\n",
      "Ep:47, loss:0.00009, loss_test:0.07089, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.223, tt:1498.685\n",
      "Ep:48, loss:0.00008, loss_test:0.07076, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:31.226, tt:1530.061\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.06975, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:31.238, tt:1561.886\n",
      "Ep:50, loss:0.00008, loss_test:0.06904, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:31.258, tt:1594.153\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.06780, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:31.284, tt:1626.747\n",
      "Ep:52, loss:0.00007, loss_test:0.06888, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.300, tt:1658.906\n",
      "Ep:53, loss:0.00007, loss_test:0.06819, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:31.303, tt:1690.369\n",
      "Ep:54, loss:0.00007, loss_test:0.06714, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:31.320, tt:1722.580\n",
      "Ep:55, loss:0.00007, loss_test:0.06650, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.343, tt:1755.211\n",
      "Ep:56, loss:0.00006, loss_test:0.06710, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:31.374, tt:1788.291\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.06578, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.373, tt:1819.630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00006, loss_test:0.06585, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.389, tt:1851.970\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.06356, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.393, tt:1883.588\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.06785, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.392, tt:1914.908\n",
      "Ep:61, loss:0.00006, loss_test:0.06657, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.388, tt:1946.052\n",
      "Ep:62, loss:0.00006, loss_test:0.06575, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.382, tt:1977.087\n",
      "Ep:63, loss:0.00005, loss_test:0.06279, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.373, tt:2007.857\n",
      "Ep:64, loss:0.00005, loss_test:0.06520, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.379, tt:2039.617\n",
      "Ep:65, loss:0.00005, loss_test:0.06224, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:31.391, tt:2071.793\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.06536, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:31.393, tt:2103.354\n",
      "Ep:67, loss:0.00005, loss_test:0.06174, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.412, tt:2136.005\n",
      "Ep:68, loss:0.00004, loss_test:0.06481, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.402, tt:2166.728\n",
      "Ep:69, loss:0.00004, loss_test:0.06367, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.398, tt:2197.891\n",
      "Ep:70, loss:0.00004, loss_test:0.06166, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.414, tt:2230.406\n",
      "Ep:71, loss:0.00004, loss_test:0.06287, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.423, tt:2262.484\n",
      "Ep:72, loss:0.00004, loss_test:0.06021, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.423, tt:2293.843\n",
      "Ep:73, loss:0.00004, loss_test:0.06198, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.407, tt:2324.100\n",
      "Ep:74, loss:0.00004, loss_test:0.06188, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.412, tt:2355.907\n",
      "Ep:75, loss:0.00003, loss_test:0.05880, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:31.412, tt:2387.326\n",
      "Ep:76, loss:0.00003, loss_test:0.06165, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.399, tt:2417.736\n",
      "Ep:77, loss:0.00003, loss_test:0.06297, lr:9.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.403, tt:2449.399\n",
      "Ep:78, loss:0.00003, loss_test:0.05899, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.397, tt:2480.366\n",
      "Ep:79, loss:0.00003, loss_test:0.06447, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.402, tt:2512.141\n",
      "Ep:80, loss:0.00003, loss_test:0.05916, lr:9.61e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.405, tt:2543.809\n",
      "Ep:81, loss:0.00003, loss_test:0.06212, lr:9.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.410, tt:2575.655\n",
      "Ep:82, loss:0.00003, loss_test:0.06017, lr:9.41e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.374, tt:2604.010\n",
      "Ep:83, loss:0.00003, loss_test:0.06072, lr:9.32e-03, fs:0.88542 (r=0.859,p=0.914),  time:31.373, tt:2635.358\n",
      "Ep:84, loss:0.00003, loss_test:0.06153, lr:9.23e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.383, tt:2667.525\n",
      "Ep:85, loss:0.00003, loss_test:0.06335, lr:9.14e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.357, tt:2696.740\n",
      "Ep:86, loss:0.00003, loss_test:0.05887, lr:9.04e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.344, tt:2726.947\n",
      "Ep:87, loss:0.00003, loss_test:0.06338, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.333, tt:2757.266\n",
      "Ep:88, loss:0.00003, loss_test:0.05788, lr:8.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.326, tt:2788.042\n",
      "Ep:89, loss:0.00003, loss_test:0.06333, lr:8.78e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.321, tt:2818.889\n",
      "Ep:90, loss:0.00003, loss_test:0.05958, lr:8.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.320, tt:2850.154\n",
      "Ep:91, loss:0.00002, loss_test:0.06274, lr:8.60e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.315, tt:2880.941\n",
      "Ep:92, loss:0.00002, loss_test:0.05977, lr:8.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.317, tt:2912.440\n",
      "Ep:93, loss:0.00002, loss_test:0.06228, lr:8.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.305, tt:2942.688\n",
      "Ep:94, loss:0.00002, loss_test:0.05908, lr:8.35e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.297, tt:2973.195\n",
      "Ep:95, loss:0.00002, loss_test:0.06404, lr:8.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.298, tt:3004.618\n",
      "Ep:96, loss:0.00002, loss_test:0.05915, lr:8.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.293, tt:3035.382\n",
      "Ep:97, loss:0.00002, loss_test:0.06202, lr:8.10e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.288, tt:3066.213\n",
      "Ep:98, loss:0.00002, loss_test:0.06050, lr:8.02e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.290, tt:3097.680\n",
      "Ep:99, loss:0.00002, loss_test:0.06155, lr:7.94e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.290, tt:3129.024\n",
      "Ep:100, loss:0.00002, loss_test:0.05988, lr:7.86e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.285, tt:3159.744\n",
      "Ep:101, loss:0.00002, loss_test:0.06204, lr:7.78e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.285, tt:3191.103\n",
      "Ep:102, loss:0.00002, loss_test:0.05989, lr:7.70e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.282, tt:3222.070\n",
      "Ep:103, loss:0.00002, loss_test:0.06188, lr:7.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.285, tt:3253.609\n",
      "Ep:104, loss:0.00002, loss_test:0.06180, lr:7.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.288, tt:3285.271\n",
      "Ep:105, loss:0.00002, loss_test:0.06198, lr:7.47e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.310, tt:3318.894\n",
      "Ep:106, loss:0.00002, loss_test:0.06049, lr:7.40e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.329, tt:3352.164\n",
      "Ep:107, loss:0.00002, loss_test:0.06296, lr:7.32e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.338, tt:3384.511\n",
      "Ep:108, loss:0.00002, loss_test:0.05930, lr:7.25e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.347, tt:3416.838\n",
      "Ep:109, loss:0.00002, loss_test:0.06241, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.353, tt:3448.834\n",
      "Ep:110, loss:0.00002, loss_test:0.06117, lr:7.11e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.343, tt:3479.113\n",
      "Ep:111, loss:0.00002, loss_test:0.06122, lr:7.03e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.352, tt:3511.457\n",
      "Ep:112, loss:0.00002, loss_test:0.06098, lr:6.96e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.368, tt:3544.616\n",
      "Ep:113, loss:0.00002, loss_test:0.06382, lr:6.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.386, tt:3577.989\n",
      "Ep:114, loss:0.00002, loss_test:0.05967, lr:6.83e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.388, tt:3609.590\n",
      "Ep:115, loss:0.00002, loss_test:0.06253, lr:6.76e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.388, tt:3641.003\n",
      "Ep:116, loss:0.00002, loss_test:0.06027, lr:6.69e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.394, tt:3673.116\n",
      "Ep:117, loss:0.00002, loss_test:0.06146, lr:6.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.400, tt:3705.224\n",
      "Ep:118, loss:0.00002, loss_test:0.06116, lr:6.56e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.403, tt:3736.983\n",
      "Ep:119, loss:0.00002, loss_test:0.06257, lr:6.49e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.406, tt:3768.743\n",
      "Ep:120, loss:0.00002, loss_test:0.06058, lr:6.43e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.411, tt:3800.738\n",
      "Ep:121, loss:0.00001, loss_test:0.06329, lr:6.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.404, tt:3831.301\n",
      "Ep:122, loss:0.00001, loss_test:0.06116, lr:6.30e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.397, tt:3861.872\n",
      "Ep:123, loss:0.00001, loss_test:0.06159, lr:6.24e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.392, tt:3892.567\n",
      "Ep:124, loss:0.00001, loss_test:0.06221, lr:6.17e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.395, tt:3924.374\n",
      "Ep:125, loss:0.00001, loss_test:0.06119, lr:6.11e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.398, tt:3956.209\n",
      "Ep:126, loss:0.00001, loss_test:0.06208, lr:6.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.400, tt:3987.836\n",
      "Ep:127, loss:0.00001, loss_test:0.06214, lr:5.99e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.401, tt:4019.368\n",
      "Ep:128, loss:0.00001, loss_test:0.06281, lr:5.93e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.409, tt:4051.708\n",
      "Ep:129, loss:0.00001, loss_test:0.06265, lr:5.87e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.401, tt:4082.150\n",
      "Ep:130, loss:0.00001, loss_test:0.06138, lr:5.81e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.414, tt:4115.261\n",
      "Ep:131, loss:0.00001, loss_test:0.06262, lr:5.75e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.409, tt:4145.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.06154, lr:5.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.413, tt:4177.943\n",
      "Ep:133, loss:0.00001, loss_test:0.06317, lr:5.64e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.414, tt:4209.423\n",
      "Ep:134, loss:0.00001, loss_test:0.06233, lr:5.58e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.419, tt:4241.554\n",
      "Ep:135, loss:0.00001, loss_test:0.06159, lr:5.53e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.420, tt:4273.109\n",
      "Ep:136, loss:0.00001, loss_test:0.06298, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.424, tt:4305.153\n",
      "Ep:137, loss:0.00001, loss_test:0.06257, lr:5.42e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.435, tt:4338.060\n",
      "Ep:138, loss:0.00001, loss_test:0.06278, lr:5.36e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.433, tt:4369.228\n",
      "Ep:139, loss:0.00001, loss_test:0.06289, lr:5.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.441, tt:4401.762\n",
      "Ep:140, loss:0.00001, loss_test:0.06236, lr:5.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.446, tt:4433.951\n",
      "Ep:141, loss:0.00001, loss_test:0.06275, lr:5.20e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.448, tt:4465.640\n",
      "Ep:142, loss:0.00001, loss_test:0.06339, lr:5.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.455, tt:4498.059\n",
      "Ep:143, loss:0.00001, loss_test:0.06258, lr:5.10e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.465, tt:4530.975\n",
      "Ep:144, loss:0.00001, loss_test:0.06302, lr:5.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.475, tt:4563.932\n",
      "Ep:145, loss:0.00001, loss_test:0.06253, lr:5.00e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.484, tt:4596.647\n",
      "Ep:146, loss:0.00001, loss_test:0.06272, lr:4.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.496, tt:4629.910\n",
      "Ep:147, loss:0.00001, loss_test:0.06302, lr:4.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.500, tt:4662.027\n",
      "Ep:148, loss:0.00001, loss_test:0.06260, lr:4.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.510, tt:4695.043\n",
      "Ep:149, loss:0.00001, loss_test:0.06264, lr:4.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.515, tt:4727.287\n",
      "Ep:150, loss:0.00001, loss_test:0.06296, lr:4.75e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.521, tt:4759.689\n",
      "Ep:151, loss:0.00001, loss_test:0.06239, lr:4.71e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.519, tt:4790.901\n",
      "Ep:152, loss:0.00001, loss_test:0.06312, lr:4.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.524, tt:4823.098\n",
      "Ep:153, loss:0.00001, loss_test:0.06209, lr:4.61e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.519, tt:4853.990\n",
      "Ep:154, loss:0.00001, loss_test:0.06371, lr:4.57e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.513, tt:4884.588\n",
      "Ep:155, loss:0.00001, loss_test:0.06349, lr:4.52e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.518, tt:4916.820\n",
      "Ep:156, loss:0.00001, loss_test:0.06329, lr:4.48e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.519, tt:4948.419\n",
      "Ep:157, loss:0.00001, loss_test:0.06313, lr:4.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.502, tt:4977.347\n",
      "Ep:158, loss:0.00001, loss_test:0.06296, lr:4.39e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.499, tt:5008.274\n",
      "Ep:159, loss:0.00001, loss_test:0.06347, lr:4.34e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.498, tt:5039.661\n",
      "Ep:160, loss:0.00001, loss_test:0.06287, lr:4.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.501, tt:5071.625\n",
      "Ep:161, loss:0.00001, loss_test:0.06345, lr:4.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.501, tt:5103.190\n",
      "Ep:162, loss:0.00001, loss_test:0.06343, lr:4.21e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.499, tt:5134.320\n",
      "Ep:163, loss:0.00001, loss_test:0.06295, lr:4.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.494, tt:5164.959\n",
      "Ep:164, loss:0.00001, loss_test:0.06430, lr:4.13e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.492, tt:5196.141\n",
      "Ep:165, loss:0.00001, loss_test:0.06342, lr:4.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.493, tt:5227.765\n",
      "Ep:166, loss:0.00001, loss_test:0.06338, lr:4.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.490, tt:5258.784\n",
      "Ep:167, loss:0.00001, loss_test:0.06349, lr:4.01e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.479, tt:5288.503\n",
      "Ep:168, loss:0.00001, loss_test:0.06413, lr:3.97e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.476, tt:5319.428\n",
      "Ep:169, loss:0.00001, loss_test:0.06355, lr:3.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.475, tt:5350.755\n",
      "Ep:170, loss:0.00001, loss_test:0.06320, lr:3.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.477, tt:5382.539\n",
      "Ep:171, loss:0.00001, loss_test:0.06410, lr:3.85e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.476, tt:5413.882\n",
      "Ep:172, loss:0.00001, loss_test:0.06327, lr:3.81e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.469, tt:5444.177\n",
      "Ep:173, loss:0.00001, loss_test:0.06336, lr:3.77e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.464, tt:5474.769\n",
      "Ep:174, loss:0.00001, loss_test:0.06392, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.458, tt:5505.201\n",
      "Ep:175, loss:0.00001, loss_test:0.06345, lr:3.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.459, tt:5536.845\n",
      "Ep:176, loss:0.00001, loss_test:0.06363, lr:3.66e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.421, tt:5561.496\n",
      "Ep:177, loss:0.00001, loss_test:0.06391, lr:3.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.402, tt:5589.631\n",
      "Ep:178, loss:0.00001, loss_test:0.06347, lr:3.59e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.382, tt:5617.350\n",
      "Ep:179, loss:0.00001, loss_test:0.06406, lr:3.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.329, tt:5639.234\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14464, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.863, tt:31.863\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14375, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.842, tt:63.685\n",
      "Ep:2, loss:0.00027, loss_test:0.14226, lr:1.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:31.663, tt:94.988\n",
      "Ep:3, loss:0.00027, loss_test:0.13957, lr:1.00e-02, fs:0.64789 (r=0.929,p=0.497),  time:31.507, tt:126.027\n",
      "Ep:4, loss:0.00026, loss_test:0.13573, lr:1.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:31.598, tt:157.990\n",
      "Ep:5, loss:0.00024, loss_test:0.13321, lr:1.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:31.510, tt:189.057\n",
      "Ep:6, loss:0.00024, loss_test:0.13367, lr:1.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:31.305, tt:219.137\n",
      "Ep:7, loss:0.00023, loss_test:0.13289, lr:1.00e-02, fs:0.60577 (r=0.636,p=0.578),  time:31.440, tt:251.517\n",
      "Ep:8, loss:0.00022, loss_test:0.12913, lr:1.00e-02, fs:0.62559 (r=0.667,p=0.589),  time:31.328, tt:281.953\n",
      "Ep:9, loss:0.00021, loss_test:0.12602, lr:1.00e-02, fs:0.63889 (r=0.697,p=0.590),  time:31.214, tt:312.140\n",
      "Ep:10, loss:0.00021, loss_test:0.12364, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:31.106, tt:342.167\n",
      "Ep:11, loss:0.00020, loss_test:0.12208, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:31.226, tt:374.707\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.12047, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:31.338, tt:407.394\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.11835, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:31.441, tt:440.173\n",
      "Ep:14, loss:0.00018, loss_test:0.11673, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:31.326, tt:469.896\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.11612, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:31.276, tt:500.418\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.11634, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:31.320, tt:532.443\n",
      "Ep:17, loss:0.00017, loss_test:0.11551, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:31.337, tt:564.061\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.11441, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:31.345, tt:595.551\n",
      "Ep:19, loss:0.00016, loss_test:0.11376, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:31.302, tt:626.034\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00016, loss_test:0.11267, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:31.316, tt:657.628\n",
      "Ep:21, loss:0.00015, loss_test:0.11149, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.306, tt:688.741\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.11036, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.328, tt:720.552\n",
      "Ep:23, loss:0.00015, loss_test:0.10974, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.278, tt:750.683\n",
      "Ep:24, loss:0.00014, loss_test:0.10918, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:31.308, tt:782.703\n",
      "Ep:25, loss:0.00014, loss_test:0.10839, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.325, tt:814.438\n",
      "Ep:26, loss:0.00014, loss_test:0.10686, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.321, tt:845.673\n",
      "Ep:27, loss:0.00013, loss_test:0.10695, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.315, tt:876.827\n",
      "Ep:28, loss:0.00013, loss_test:0.10743, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.317, tt:908.193\n",
      "Ep:29, loss:0.00013, loss_test:0.10690, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.324, tt:939.708\n",
      "Ep:30, loss:0.00012, loss_test:0.10690, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.328, tt:971.176\n",
      "Ep:31, loss:0.00012, loss_test:0.10773, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:31.310, tt:1001.915\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.10714, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:31.319, tt:1033.521\n",
      "Ep:33, loss:0.00012, loss_test:0.10726, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:31.368, tt:1066.512\n",
      "Ep:34, loss:0.00011, loss_test:0.10731, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:31.381, tt:1098.352\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.10766, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:31.364, tt:1129.088\n",
      "Ep:36, loss:0.00011, loss_test:0.10899, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:31.364, tt:1160.483\n",
      "Ep:37, loss:0.00011, loss_test:0.10704, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:31.347, tt:1191.202\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.10863, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:31.310, tt:1221.092\n",
      "Ep:39, loss:0.00010, loss_test:0.10744, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:31.350, tt:1253.991\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.10789, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:31.395, tt:1287.192\n",
      "Ep:41, loss:0.00010, loss_test:0.10765, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:31.424, tt:1319.797\n",
      "Ep:42, loss:0.00009, loss_test:0.10720, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:31.427, tt:1351.372\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.10958, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:31.416, tt:1382.318\n",
      "Ep:44, loss:0.00009, loss_test:0.10691, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:31.413, tt:1413.587\n",
      "Ep:45, loss:0.00009, loss_test:0.11149, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:31.430, tt:1445.763\n",
      "Ep:46, loss:0.00009, loss_test:0.10638, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:31.396, tt:1475.614\n",
      "Ep:47, loss:0.00008, loss_test:0.10933, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:31.392, tt:1506.813\n",
      "Ep:48, loss:0.00008, loss_test:0.10817, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:31.364, tt:1536.858\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.10573, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:31.364, tt:1568.211\n",
      "Ep:50, loss:0.00008, loss_test:0.11016, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:31.350, tt:1598.826\n",
      "Ep:51, loss:0.00007, loss_test:0.10813, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:31.360, tt:1630.717\n",
      "Ep:52, loss:0.00007, loss_test:0.10974, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:31.350, tt:1661.542\n",
      "Ep:53, loss:0.00007, loss_test:0.10832, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.337, tt:1692.209\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.10854, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:31.327, tt:1723.010\n",
      "Ep:55, loss:0.00007, loss_test:0.10924, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.351, tt:1755.629\n",
      "Ep:56, loss:0.00006, loss_test:0.10992, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:31.371, tt:1788.137\n",
      "Ep:57, loss:0.00006, loss_test:0.10810, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.399, tt:1821.163\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.11155, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:31.388, tt:1851.869\n",
      "Ep:59, loss:0.00006, loss_test:0.10866, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.383, tt:1882.976\n",
      "Ep:60, loss:0.00006, loss_test:0.11106, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:31.365, tt:1913.288\n",
      "Ep:61, loss:0.00005, loss_test:0.11073, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.375, tt:1945.255\n",
      "Ep:62, loss:0.00005, loss_test:0.11077, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:31.381, tt:1977.014\n",
      "Ep:63, loss:0.00005, loss_test:0.11115, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:31.402, tt:2009.713\n",
      "Ep:64, loss:0.00005, loss_test:0.10947, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:31.414, tt:2041.916\n",
      "Ep:65, loss:0.00005, loss_test:0.11219, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:31.419, tt:2073.648\n",
      "Ep:66, loss:0.00005, loss_test:0.11027, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:31.422, tt:2105.263\n",
      "Ep:67, loss:0.00005, loss_test:0.11329, lr:1.00e-02, fs:0.73494 (r=0.616,p=0.910),  time:31.433, tt:2137.410\n",
      "Ep:68, loss:0.00004, loss_test:0.11201, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.434, tt:2168.942\n",
      "Ep:69, loss:0.00004, loss_test:0.11283, lr:9.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.453, tt:2201.721\n",
      "Ep:70, loss:0.00004, loss_test:0.11240, lr:9.80e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.467, tt:2234.153\n",
      "Ep:71, loss:0.00004, loss_test:0.11333, lr:9.70e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.444, tt:2263.969\n",
      "Ep:72, loss:0.00004, loss_test:0.11177, lr:9.61e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.429, tt:2294.290\n",
      "Ep:73, loss:0.00004, loss_test:0.11255, lr:9.51e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.414, tt:2324.632\n",
      "Ep:74, loss:0.00004, loss_test:0.11228, lr:9.41e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.406, tt:2355.451\n",
      "Ep:75, loss:0.00004, loss_test:0.10939, lr:9.32e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.407, tt:2386.968\n",
      "Ep:76, loss:0.00004, loss_test:0.11344, lr:9.23e-03, fs:0.70370 (r=0.576,p=0.905),  time:31.406, tt:2418.252\n",
      "Ep:77, loss:0.00004, loss_test:0.11231, lr:9.14e-03, fs:0.70807 (r=0.576,p=0.919),  time:31.415, tt:2450.357\n",
      "Ep:78, loss:0.00004, loss_test:0.11296, lr:9.04e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.408, tt:2481.258\n",
      "Ep:79, loss:0.00003, loss_test:0.11561, lr:8.95e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.400, tt:2511.998\n",
      "Ep:80, loss:0.00003, loss_test:0.11279, lr:8.86e-03, fs:0.70807 (r=0.576,p=0.919),  time:31.390, tt:2542.550\n",
      "Ep:81, loss:0.00003, loss_test:0.11471, lr:8.78e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.385, tt:2573.558\n",
      "Ep:82, loss:0.00003, loss_test:0.11370, lr:8.69e-03, fs:0.70000 (r=0.566,p=0.918),  time:31.413, tt:2607.271\n",
      "Ep:83, loss:0.00003, loss_test:0.11423, lr:8.60e-03, fs:0.68354 (r=0.545,p=0.915),  time:31.418, tt:2639.074\n",
      "Ep:84, loss:0.00003, loss_test:0.11464, lr:8.51e-03, fs:0.70000 (r=0.566,p=0.918),  time:31.418, tt:2670.501\n",
      "Ep:85, loss:0.00003, loss_test:0.11444, lr:8.43e-03, fs:0.67949 (r=0.535,p=0.930),  time:31.430, tt:2703.008\n",
      "Ep:86, loss:0.00003, loss_test:0.11482, lr:8.35e-03, fs:0.67516 (r=0.535,p=0.914),  time:31.440, tt:2735.296\n",
      "Ep:87, loss:0.00003, loss_test:0.11713, lr:8.26e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.443, tt:2766.943\n",
      "Ep:88, loss:0.00003, loss_test:0.11519, lr:8.18e-03, fs:0.67949 (r=0.535,p=0.930),  time:31.425, tt:2796.866\n",
      "Ep:89, loss:0.00003, loss_test:0.11451, lr:8.10e-03, fs:0.69182 (r=0.556,p=0.917),  time:31.431, tt:2828.765\n",
      "Ep:90, loss:0.00003, loss_test:0.11542, lr:8.02e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.430, tt:2860.116\n",
      "Ep:91, loss:0.00003, loss_test:0.11462, lr:7.94e-03, fs:0.70000 (r=0.566,p=0.918),  time:31.418, tt:2890.464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:92, loss:0.00003, loss_test:0.11751, lr:7.86e-03, fs:0.64474 (r=0.495,p=0.925),  time:31.431, tt:2923.123\n",
      "Ep:93, loss:0.00003, loss_test:0.11578, lr:7.78e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.424, tt:2953.866\n",
      "Ep:94, loss:0.00003, loss_test:0.11559, lr:7.70e-03, fs:0.67949 (r=0.535,p=0.930),  time:31.419, tt:2984.763\n",
      "Ep:95, loss:0.00003, loss_test:0.11552, lr:7.62e-03, fs:0.67949 (r=0.535,p=0.930),  time:31.421, tt:3016.433\n",
      "Ep:96, loss:0.00003, loss_test:0.11645, lr:7.55e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.422, tt:3047.900\n",
      "Ep:97, loss:0.00002, loss_test:0.11728, lr:7.47e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.413, tt:3078.451\n",
      "Ep:98, loss:0.00002, loss_test:0.11559, lr:7.40e-03, fs:0.67516 (r=0.535,p=0.914),  time:31.419, tt:3110.479\n",
      "Ep:99, loss:0.00002, loss_test:0.11755, lr:7.32e-03, fs:0.64474 (r=0.495,p=0.925),  time:31.416, tt:3141.602\n",
      "Ep:100, loss:0.00002, loss_test:0.11583, lr:7.25e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.414, tt:3172.829\n",
      "Ep:101, loss:0.00002, loss_test:0.11678, lr:7.18e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.416, tt:3204.401\n",
      "Ep:102, loss:0.00002, loss_test:0.11734, lr:7.11e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.420, tt:3236.264\n",
      "Ep:103, loss:0.00002, loss_test:0.11634, lr:7.03e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.408, tt:3266.452\n",
      "Ep:104, loss:0.00002, loss_test:0.11747, lr:6.96e-03, fs:0.66667 (r=0.525,p=0.912),  time:31.417, tt:3298.829\n",
      "Ep:105, loss:0.00002, loss_test:0.11912, lr:6.89e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.421, tt:3330.675\n",
      "Ep:106, loss:0.00002, loss_test:0.11624, lr:6.83e-03, fs:0.66667 (r=0.525,p=0.912),  time:31.413, tt:3361.162\n",
      "Ep:107, loss:0.00002, loss_test:0.11751, lr:6.76e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.420, tt:3393.362\n",
      "Ep:108, loss:0.00002, loss_test:0.11862, lr:6.69e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.418, tt:3424.601\n",
      "Ep:109, loss:0.00002, loss_test:0.11662, lr:6.62e-03, fs:0.66667 (r=0.525,p=0.912),  time:31.426, tt:3456.852\n",
      "Ep:110, loss:0.00002, loss_test:0.11864, lr:6.56e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.430, tt:3488.675\n",
      "Ep:111, loss:0.00002, loss_test:0.11825, lr:6.49e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.436, tt:3520.886\n",
      "Ep:112, loss:0.00002, loss_test:0.11825, lr:6.43e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.444, tt:3553.219\n",
      "Ep:113, loss:0.00002, loss_test:0.11848, lr:6.36e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.438, tt:3583.879\n",
      "Ep:114, loss:0.00002, loss_test:0.11763, lr:6.30e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.440, tt:3615.615\n",
      "Ep:115, loss:0.00002, loss_test:0.11800, lr:6.24e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.443, tt:3647.405\n",
      "Ep:116, loss:0.00002, loss_test:0.11897, lr:6.17e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.460, tt:3680.844\n",
      "Ep:117, loss:0.00002, loss_test:0.11747, lr:6.11e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.447, tt:3710.783\n",
      "Ep:118, loss:0.00002, loss_test:0.11828, lr:6.05e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.445, tt:3741.964\n",
      "Ep:119, loss:0.00002, loss_test:0.11858, lr:5.99e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.431, tt:3771.683\n",
      "Ep:120, loss:0.00002, loss_test:0.11818, lr:5.93e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.434, tt:3803.540\n",
      "Ep:121, loss:0.00002, loss_test:0.11969, lr:5.87e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.434, tt:3834.958\n",
      "Ep:122, loss:0.00002, loss_test:0.11868, lr:5.81e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.445, tt:3867.749\n",
      "Ep:123, loss:0.00002, loss_test:0.11832, lr:5.75e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.442, tt:3898.848\n",
      "Ep:124, loss:0.00002, loss_test:0.12048, lr:5.70e-03, fs:0.65789 (r=0.505,p=0.943),  time:31.439, tt:3929.831\n",
      "Ep:125, loss:0.00002, loss_test:0.11784, lr:5.64e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.434, tt:3960.654\n",
      "Ep:126, loss:0.00002, loss_test:0.11893, lr:5.58e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.431, tt:3991.762\n",
      "Ep:127, loss:0.00002, loss_test:0.12030, lr:5.53e-03, fs:0.65789 (r=0.505,p=0.943),  time:31.431, tt:4023.197\n",
      "Ep:128, loss:0.00002, loss_test:0.11912, lr:5.47e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.426, tt:4054.017\n",
      "Ep:129, loss:0.00002, loss_test:0.11953, lr:5.42e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.413, tt:4083.696\n",
      "Ep:130, loss:0.00002, loss_test:0.11819, lr:5.36e-03, fs:0.66667 (r=0.525,p=0.912),  time:31.417, tt:4115.619\n",
      "Ep:131, loss:0.00002, loss_test:0.12186, lr:5.31e-03, fs:0.64901 (r=0.495,p=0.942),  time:31.428, tt:4148.504\n",
      "Ep:132, loss:0.00002, loss_test:0.11916, lr:5.26e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.427, tt:4179.751\n",
      "Ep:133, loss:0.00002, loss_test:0.11968, lr:5.20e-03, fs:0.65789 (r=0.505,p=0.943),  time:31.416, tt:4209.738\n",
      "Ep:134, loss:0.00002, loss_test:0.12104, lr:5.15e-03, fs:0.64901 (r=0.495,p=0.942),  time:31.423, tt:4242.085\n",
      "Ep:135, loss:0.00002, loss_test:0.11931, lr:5.10e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.427, tt:4274.108\n",
      "Ep:136, loss:0.00002, loss_test:0.11937, lr:5.05e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.429, tt:4305.773\n",
      "Ep:137, loss:0.00002, loss_test:0.12043, lr:5.00e-03, fs:0.65789 (r=0.505,p=0.943),  time:31.430, tt:4337.292\n",
      "Ep:138, loss:0.00002, loss_test:0.11984, lr:4.95e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.436, tt:4369.585\n",
      "Ep:139, loss:0.00002, loss_test:0.11934, lr:4.90e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.434, tt:4400.808\n",
      "Ep:140, loss:0.00002, loss_test:0.12013, lr:4.85e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.437, tt:4432.667\n",
      "Ep:141, loss:0.00002, loss_test:0.12080, lr:4.80e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.434, tt:4463.582\n",
      "Ep:142, loss:0.00001, loss_test:0.11939, lr:4.75e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.423, tt:4493.457\n",
      "Ep:143, loss:0.00001, loss_test:0.11990, lr:4.71e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.423, tt:4524.917\n",
      "Ep:144, loss:0.00001, loss_test:0.12055, lr:4.66e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.432, tt:4557.660\n",
      "Ep:145, loss:0.00001, loss_test:0.11972, lr:4.61e-03, fs:0.66234 (r=0.515,p=0.927),  time:31.433, tt:4589.195\n",
      "Ep:146, loss:0.00001, loss_test:0.11979, lr:4.57e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.437, tt:4621.215\n",
      "Ep:147, loss:0.00001, loss_test:0.12068, lr:4.52e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.441, tt:4653.258\n",
      "Ep:148, loss:0.00001, loss_test:0.11893, lr:4.48e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.436, tt:4684.018\n",
      "Ep:149, loss:0.00001, loss_test:0.12037, lr:4.43e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.442, tt:4716.329\n",
      "Ep:150, loss:0.00001, loss_test:0.12222, lr:4.39e-03, fs:0.64901 (r=0.495,p=0.942),  time:31.454, tt:4749.580\n",
      "Ep:151, loss:0.00001, loss_test:0.11970, lr:4.34e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.465, tt:4782.656\n",
      "Ep:152, loss:0.00001, loss_test:0.11881, lr:4.30e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.462, tt:4813.719\n",
      "Ep:153, loss:0.00001, loss_test:0.12056, lr:4.26e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.456, tt:4844.243\n",
      "Ep:154, loss:0.00001, loss_test:0.12031, lr:4.21e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.457, tt:4875.771\n",
      "Ep:155, loss:0.00001, loss_test:0.11931, lr:4.17e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.455, tt:4906.903\n",
      "Ep:156, loss:0.00001, loss_test:0.12024, lr:4.13e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.460, tt:4939.251\n",
      "Ep:157, loss:0.00001, loss_test:0.12023, lr:4.09e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.463, tt:4971.203\n",
      "Ep:158, loss:0.00001, loss_test:0.11949, lr:4.05e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.460, tt:5002.157\n",
      "Ep:159, loss:0.00001, loss_test:0.11938, lr:4.01e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.454, tt:5032.681\n",
      "Ep:160, loss:0.00001, loss_test:0.12054, lr:3.97e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.453, tt:5063.960\n",
      "Ep:161, loss:0.00001, loss_test:0.12033, lr:3.93e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.453, tt:5095.308\n",
      "Ep:162, loss:0.00001, loss_test:0.12020, lr:3.89e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.446, tt:5125.656\n",
      "Ep:163, loss:0.00001, loss_test:0.12000, lr:3.85e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.441, tt:5156.343\n",
      "Ep:164, loss:0.00001, loss_test:0.12089, lr:3.81e-03, fs:0.64000 (r=0.485,p=0.941),  time:31.452, tt:5189.557\n",
      "Ep:165, loss:0.00001, loss_test:0.12093, lr:3.77e-03, fs:0.64901 (r=0.495,p=0.942),  time:31.452, tt:5220.985\n",
      "Ep:166, loss:0.00001, loss_test:0.11930, lr:3.73e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.449, tt:5251.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:167, loss:0.00001, loss_test:0.12124, lr:3.70e-03, fs:0.64000 (r=0.485,p=0.941),  time:31.440, tt:5281.979\n",
      "Ep:168, loss:0.00001, loss_test:0.12111, lr:3.66e-03, fs:0.64000 (r=0.485,p=0.941),  time:31.451, tt:5315.298\n",
      "Ep:169, loss:0.00001, loss_test:0.11953, lr:3.62e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.453, tt:5347.029\n",
      "Ep:170, loss:0.00001, loss_test:0.12121, lr:3.59e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.454, tt:5378.565\n",
      "Ep:171, loss:0.00001, loss_test:0.12064, lr:3.55e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.457, tt:5410.677\n",
      "Ep:172, loss:0.00001, loss_test:0.11953, lr:3.52e-03, fs:0.67097 (r=0.525,p=0.929),  time:31.460, tt:5442.656\n",
      "Ep:173, loss:0.00001, loss_test:0.12022, lr:3.48e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.444, tt:5471.168\n",
      "Ep:174, loss:0.00001, loss_test:0.12031, lr:3.45e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.445, tt:5502.897\n",
      "Ep:175, loss:0.00001, loss_test:0.11947, lr:3.41e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.444, tt:5534.173\n",
      "Ep:176, loss:0.00001, loss_test:0.12031, lr:3.38e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.402, tt:5558.236\n",
      "Ep:177, loss:0.00001, loss_test:0.12057, lr:3.34e-03, fs:0.64901 (r=0.495,p=0.942),  time:31.377, tt:5585.060\n",
      "Ep:178, loss:0.00001, loss_test:0.11959, lr:3.31e-03, fs:0.67532 (r=0.525,p=0.945),  time:31.350, tt:5611.615\n",
      "Ep:179, loss:0.00001, loss_test:0.12012, lr:3.28e-03, fs:0.66667 (r=0.515,p=0.944),  time:31.322, tt:5637.910\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00054, loss_test:0.14722, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:64.028, tt:64.028\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00051, loss_test:0.14558, lr:1.00e-02, fs:0.58824 (r=0.758,p=0.481),  time:64.361, tt:128.722\n",
      "Ep:2, loss:0.00046, loss_test:0.14790, lr:1.00e-02, fs:0.47059 (r=0.444,p=0.500),  time:64.710, tt:194.129\n",
      "Ep:3, loss:0.00043, loss_test:0.14549, lr:1.00e-02, fs:0.51813 (r=0.505,p=0.532),  time:65.219, tt:260.877\n",
      "Ep:4, loss:0.00041, loss_test:0.14127, lr:1.00e-02, fs:0.53535 (r=0.535,p=0.535),  time:65.248, tt:326.240\n",
      "Ep:5, loss:0.00039, loss_test:0.14173, lr:1.00e-02, fs:0.54082 (r=0.535,p=0.546),  time:64.864, tt:389.182\n",
      "Ep:6, loss:0.00037, loss_test:0.13905, lr:1.00e-02, fs:0.53535 (r=0.535,p=0.535),  time:64.870, tt:454.090\n",
      "Ep:7, loss:0.00035, loss_test:0.13734, lr:1.00e-02, fs:0.54271 (r=0.545,p=0.540),  time:64.795, tt:518.361\n",
      "Ep:8, loss:0.00034, loss_test:0.13630, lr:1.00e-02, fs:0.54822 (r=0.545,p=0.551),  time:64.889, tt:583.997\n",
      "Ep:9, loss:0.00032, loss_test:0.13368, lr:1.00e-02, fs:0.57000 (r=0.576,p=0.564),  time:64.786, tt:647.861\n",
      "Ep:10, loss:0.00031, loss_test:0.13197, lr:1.00e-02, fs:0.57576 (r=0.576,p=0.576),  time:64.647, tt:711.122\n",
      "Ep:11, loss:0.00030, loss_test:0.13001, lr:1.00e-02, fs:0.59296 (r=0.596,p=0.590),  time:64.669, tt:776.026\n",
      "Ep:12, loss:0.00029, loss_test:0.12935, lr:9.90e-03, fs:0.57592 (r=0.556,p=0.598),  time:64.699, tt:841.093\n",
      "Ep:13, loss:0.00028, loss_test:0.12607, lr:9.80e-03, fs:0.59067 (r=0.576,p=0.606),  time:64.692, tt:905.688\n",
      "Ep:14, loss:0.00027, loss_test:0.12615, lr:9.70e-03, fs:0.57297 (r=0.535,p=0.616),  time:64.597, tt:968.951\n",
      "Ep:15, loss:0.00026, loss_test:0.12349, lr:9.61e-03, fs:0.58065 (r=0.545,p=0.621),  time:64.614, tt:1033.818\n",
      "Ep:16, loss:0.00025, loss_test:0.12245, lr:9.51e-03, fs:0.59574 (r=0.566,p=0.629),  time:64.627, tt:1098.654\n",
      "Ep:17, loss:0.00025, loss_test:0.12199, lr:9.41e-03, fs:0.57459 (r=0.525,p=0.634),  time:64.491, tt:1160.845\n",
      "Ep:18, loss:0.00024, loss_test:0.12070, lr:9.32e-03, fs:0.59783 (r=0.556,p=0.647),  time:64.518, tt:1225.835\n",
      "Ep:19, loss:0.00023, loss_test:0.11837, lr:9.23e-03, fs:0.57923 (r=0.535,p=0.631),  time:64.538, tt:1290.759\n",
      "Ep:20, loss:0.00022, loss_test:0.11933, lr:9.14e-03, fs:0.58286 (r=0.515,p=0.671),  time:64.620, tt:1357.018\n",
      "Ep:21, loss:0.00021, loss_test:0.11531, lr:9.04e-03, fs:0.63388 (r=0.586,p=0.690),  time:64.566, tt:1420.457\n",
      "Ep:22, loss:0.00020, loss_test:0.11760, lr:8.95e-03, fs:0.56140 (r=0.485,p=0.667),  time:64.509, tt:1483.708\n",
      "Ep:23, loss:0.00020, loss_test:0.11560, lr:8.86e-03, fs:0.60819 (r=0.525,p=0.722),  time:64.507, tt:1548.171\n",
      "Ep:24, loss:0.00019, loss_test:0.11662, lr:8.78e-03, fs:0.57988 (r=0.495,p=0.700),  time:64.427, tt:1610.686\n",
      "Ep:25, loss:0.00018, loss_test:0.11304, lr:8.69e-03, fs:0.57310 (r=0.495,p=0.681),  time:64.371, tt:1673.641\n",
      "Ep:26, loss:0.00018, loss_test:0.11536, lr:8.60e-03, fs:0.58683 (r=0.495,p=0.721),  time:64.405, tt:1738.937\n",
      "Ep:27, loss:0.00017, loss_test:0.11310, lr:8.51e-03, fs:0.59394 (r=0.495,p=0.742),  time:64.402, tt:1803.264\n",
      "Ep:28, loss:0.00016, loss_test:0.11333, lr:8.43e-03, fs:0.59756 (r=0.495,p=0.754),  time:64.446, tt:1868.935\n",
      "Ep:29, loss:0.00015, loss_test:0.11215, lr:8.35e-03, fs:0.60123 (r=0.495,p=0.766),  time:64.430, tt:1932.906\n",
      "Ep:30, loss:0.00015, loss_test:0.11122, lr:8.26e-03, fs:0.61446 (r=0.515,p=0.761),  time:64.432, tt:1997.398\n",
      "Ep:31, loss:0.00014, loss_test:0.11121, lr:8.18e-03, fs:0.60241 (r=0.505,p=0.746),  time:64.419, tt:2061.405\n",
      "Ep:32, loss:0.00014, loss_test:0.10817, lr:8.10e-03, fs:0.60976 (r=0.505,p=0.769),  time:64.425, tt:2126.012\n",
      "Ep:33, loss:0.00013, loss_test:0.11213, lr:8.02e-03, fs:0.62025 (r=0.495,p=0.831),  time:64.400, tt:2189.595\n",
      "Ep:34, loss:0.00013, loss_test:0.11042, lr:7.94e-03, fs:0.61935 (r=0.485,p=0.857),  time:64.411, tt:2254.397\n",
      "Ep:35, loss:0.00013, loss_test:0.10790, lr:7.86e-03, fs:0.62577 (r=0.515,p=0.797),  time:64.380, tt:2317.668\n",
      "Ep:36, loss:0.00012, loss_test:0.11112, lr:7.78e-03, fs:0.64103 (r=0.505,p=0.877),  time:64.389, tt:2382.387\n",
      "Ep:37, loss:0.00012, loss_test:0.10492, lr:7.70e-03, fs:0.63415 (r=0.525,p=0.800),  time:64.351, tt:2445.346\n",
      "Ep:38, loss:0.00011, loss_test:0.11016, lr:7.62e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.331, tt:2508.918\n",
      "Ep:39, loss:0.00011, loss_test:0.10649, lr:7.55e-03, fs:0.64968 (r=0.515,p=0.879),  time:64.389, tt:2575.549\n",
      "Ep:40, loss:0.00010, loss_test:0.10650, lr:7.47e-03, fs:0.65000 (r=0.525,p=0.852),  time:64.445, tt:2642.238\n",
      "Ep:41, loss:0.00010, loss_test:0.11032, lr:7.40e-03, fs:0.66242 (r=0.525,p=0.897),  time:64.400, tt:2704.806\n",
      "Ep:42, loss:0.00010, loss_test:0.10426, lr:7.32e-03, fs:0.64634 (r=0.535,p=0.815),  time:64.470, tt:2772.217\n",
      "Ep:43, loss:0.00009, loss_test:0.11134, lr:7.25e-03, fs:0.66242 (r=0.525,p=0.897),  time:64.475, tt:2836.921\n",
      "Ep:44, loss:0.00009, loss_test:0.10393, lr:7.18e-03, fs:0.66667 (r=0.535,p=0.883),  time:64.505, tt:2902.720\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.10724, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.538, tt:2968.726\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.10823, lr:7.18e-03, fs:0.66250 (r=0.535,p=0.869),  time:64.507, tt:3031.831\n",
      "Ep:47, loss:0.00008, loss_test:0.10371, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.517, tt:3096.821\n",
      "Ep:48, loss:0.00008, loss_test:0.10993, lr:7.18e-03, fs:0.66242 (r=0.525,p=0.897),  time:64.496, tt:3160.316\n",
      "Ep:49, loss:0.00008, loss_test:0.10390, lr:7.18e-03, fs:0.66667 (r=0.535,p=0.883),  time:64.447, tt:3222.352\n",
      "Ep:50, loss:0.00008, loss_test:0.10674, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.424, tt:3285.603\n",
      "Ep:51, loss:0.00007, loss_test:0.10398, lr:7.18e-03, fs:0.66250 (r=0.535,p=0.869),  time:64.393, tt:3348.442\n",
      "Ep:52, loss:0.00007, loss_test:0.10605, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.419, tt:3414.202\n",
      "Ep:53, loss:0.00007, loss_test:0.10514, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.449, tt:3480.236\n",
      "Ep:54, loss:0.00007, loss_test:0.10291, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.443, tt:3544.379\n",
      "Ep:55, loss:0.00006, loss_test:0.10684, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.440, tt:3608.638\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.10342, lr:7.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:64.461, tt:3674.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00006, loss_test:0.10541, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.430, tt:3736.950\n",
      "Ep:58, loss:0.00006, loss_test:0.10377, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.416, tt:3800.520\n",
      "Ep:59, loss:0.00006, loss_test:0.10456, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.409, tt:3864.563\n",
      "Ep:60, loss:0.00006, loss_test:0.10327, lr:7.18e-03, fs:0.66250 (r=0.535,p=0.869),  time:64.386, tt:3927.534\n",
      "Ep:61, loss:0.00006, loss_test:0.10459, lr:7.18e-03, fs:0.66667 (r=0.535,p=0.883),  time:64.398, tt:3992.677\n",
      "Ep:62, loss:0.00005, loss_test:0.10228, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.408, tt:4057.710\n",
      "Ep:63, loss:0.00005, loss_test:0.10579, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.386, tt:4120.713\n",
      "Ep:64, loss:0.00005, loss_test:0.10298, lr:7.18e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.354, tt:4182.989\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.10370, lr:7.18e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.342, tt:4246.590\n",
      "Ep:66, loss:0.00005, loss_test:0.10313, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.356, tt:4311.826\n",
      "Ep:67, loss:0.00005, loss_test:0.10234, lr:7.18e-03, fs:0.66667 (r=0.535,p=0.883),  time:64.366, tt:4376.921\n",
      "Ep:68, loss:0.00005, loss_test:0.10268, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.362, tt:4440.968\n",
      "Ep:69, loss:0.00005, loss_test:0.10443, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.366, tt:4505.631\n",
      "Ep:70, loss:0.00004, loss_test:0.10398, lr:7.18e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.326, tt:4567.115\n",
      "Ep:71, loss:0.00004, loss_test:0.10450, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.296, tt:4629.302\n",
      "Ep:72, loss:0.00004, loss_test:0.10350, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.316, tt:4695.033\n",
      "Ep:73, loss:0.00004, loss_test:0.10285, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.329, tt:4760.326\n",
      "Ep:74, loss:0.00004, loss_test:0.10446, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.345, tt:4825.890\n",
      "Ep:75, loss:0.00004, loss_test:0.10286, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.322, tt:4888.505\n",
      "Ep:76, loss:0.00004, loss_test:0.10555, lr:7.11e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.321, tt:4952.727\n",
      "Ep:77, loss:0.00004, loss_test:0.10296, lr:7.03e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.317, tt:5016.754\n",
      "Ep:78, loss:0.00004, loss_test:0.10378, lr:6.96e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.319, tt:5081.186\n",
      "Ep:79, loss:0.00004, loss_test:0.10580, lr:6.89e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.297, tt:5143.757\n",
      "Ep:80, loss:0.00004, loss_test:0.10547, lr:6.83e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.287, tt:5207.264\n",
      "Ep:81, loss:0.00004, loss_test:0.10494, lr:6.76e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.305, tt:5273.011\n",
      "Ep:82, loss:0.00003, loss_test:0.10544, lr:6.69e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.321, tt:5338.615\n",
      "Ep:83, loss:0.00003, loss_test:0.10745, lr:6.62e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.299, tt:5401.151\n",
      "Ep:84, loss:0.00003, loss_test:0.10377, lr:6.56e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.323, tt:5467.457\n",
      "Ep:85, loss:0.00003, loss_test:0.10451, lr:6.49e-03, fs:0.67516 (r=0.535,p=0.914),  time:64.341, tt:5533.285\n",
      "Ep:86, loss:0.00003, loss_test:0.10541, lr:6.43e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.346, tt:5598.139\n",
      "Ep:87, loss:0.00003, loss_test:0.10621, lr:6.36e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.367, tt:5664.299\n",
      "Ep:88, loss:0.00003, loss_test:0.10525, lr:6.30e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.349, tt:5727.018\n",
      "Ep:89, loss:0.00003, loss_test:0.10595, lr:6.24e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.343, tt:5790.888\n",
      "Ep:90, loss:0.00003, loss_test:0.10471, lr:6.17e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.344, tt:5855.283\n",
      "Ep:91, loss:0.00003, loss_test:0.10612, lr:6.11e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.346, tt:5919.850\n",
      "Ep:92, loss:0.00003, loss_test:0.10360, lr:6.05e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.352, tt:5984.722\n",
      "Ep:93, loss:0.00003, loss_test:0.10711, lr:5.99e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.368, tt:6050.589\n",
      "Ep:94, loss:0.00003, loss_test:0.10735, lr:5.93e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.388, tt:6116.821\n",
      "Ep:95, loss:0.00003, loss_test:0.10390, lr:5.87e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.397, tt:6182.065\n",
      "Ep:96, loss:0.00003, loss_test:0.10745, lr:5.81e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.384, tt:6245.244\n",
      "Ep:97, loss:0.00003, loss_test:0.10452, lr:5.75e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.347, tt:6306.028\n",
      "Ep:98, loss:0.00003, loss_test:0.10554, lr:5.70e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.348, tt:6370.423\n",
      "Ep:99, loss:0.00002, loss_test:0.10467, lr:5.64e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.346, tt:6434.644\n",
      "Ep:100, loss:0.00002, loss_test:0.10586, lr:5.58e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.359, tt:6500.215\n",
      "Ep:101, loss:0.00002, loss_test:0.10502, lr:5.53e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.358, tt:6564.546\n",
      "Ep:102, loss:0.00002, loss_test:0.10529, lr:5.47e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.342, tt:6627.185\n",
      "Ep:103, loss:0.00002, loss_test:0.10611, lr:5.42e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.356, tt:6693.027\n",
      "Ep:104, loss:0.00002, loss_test:0.10721, lr:5.36e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.359, tt:6757.706\n",
      "Ep:105, loss:0.00002, loss_test:0.10611, lr:5.31e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.344, tt:6820.496\n",
      "Ep:106, loss:0.00002, loss_test:0.10471, lr:5.26e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.369, tt:6887.522\n",
      "Ep:107, loss:0.00002, loss_test:0.10799, lr:5.20e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.375, tt:6952.482\n",
      "Ep:108, loss:0.00002, loss_test:0.10530, lr:5.15e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.367, tt:7016.018\n",
      "Ep:109, loss:0.00002, loss_test:0.10520, lr:5.10e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.365, tt:7080.102\n",
      "Ep:110, loss:0.00002, loss_test:0.10616, lr:5.05e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.367, tt:7144.741\n",
      "Ep:111, loss:0.00002, loss_test:0.10620, lr:5.00e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.363, tt:7208.677\n",
      "Ep:112, loss:0.00002, loss_test:0.10485, lr:4.95e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.365, tt:7273.284\n",
      "Ep:113, loss:0.00002, loss_test:0.10611, lr:4.90e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.369, tt:7338.118\n",
      "Ep:114, loss:0.00002, loss_test:0.10478, lr:4.85e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.363, tt:7401.706\n",
      "Ep:115, loss:0.00002, loss_test:0.10674, lr:4.80e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.352, tt:7464.789\n",
      "Ep:116, loss:0.00002, loss_test:0.10514, lr:4.75e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.329, tt:7526.472\n",
      "Ep:117, loss:0.00002, loss_test:0.10596, lr:4.71e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.265, tt:7583.263\n",
      "Ep:118, loss:0.00002, loss_test:0.10500, lr:4.66e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.222, tt:7642.441\n",
      "Ep:119, loss:0.00002, loss_test:0.10613, lr:4.61e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.142, tt:7697.009\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.13678, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:63.404, tt:63.404\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.12659, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:64.501, tt:129.003\n",
      "Ep:2, loss:0.00049, loss_test:0.11042, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:64.777, tt:194.330\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.10709, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:64.665, tt:258.660\n",
      "Ep:4, loss:0.00043, loss_test:0.10380, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:64.786, tt:323.932\n",
      "Ep:5, loss:0.00041, loss_test:0.09866, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:64.926, tt:389.556\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00039, loss_test:0.09647, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:64.721, tt:453.046\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00037, loss_test:0.09435, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:64.657, tt:517.255\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00035, loss_test:0.09345, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:64.845, tt:583.604\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09222, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:64.947, tt:649.474\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.09074, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:64.733, tt:712.068\n",
      "Ep:11, loss:0.00031, loss_test:0.08921, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:64.735, tt:776.819\n",
      "Ep:12, loss:0.00029, loss_test:0.08896, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:64.851, tt:843.059\n",
      "Ep:13, loss:0.00028, loss_test:0.08767, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:64.939, tt:909.147\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.08709, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:64.973, tt:974.593\n",
      "Ep:15, loss:0.00026, loss_test:0.08623, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:64.993, tt:1039.896\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.08481, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:64.919, tt:1103.622\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.08355, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:64.844, tt:1167.200\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.08266, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:64.840, tt:1231.961\n",
      "Ep:19, loss:0.00022, loss_test:0.08180, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:64.899, tt:1297.981\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.08153, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:64.961, tt:1364.191\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.08044, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:64.942, tt:1428.728\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.08021, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:64.931, tt:1493.406\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.07778, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:64.985, tt:1559.638\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.07722, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:64.997, tt:1624.929\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.07806, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:65.031, tt:1690.795\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.07789, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:65.014, tt:1755.372\n",
      "Ep:27, loss:0.00014, loss_test:0.07505, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:65.019, tt:1820.533\n",
      "Ep:28, loss:0.00013, loss_test:0.07913, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:65.062, tt:1886.791\n",
      "Ep:29, loss:0.00013, loss_test:0.07676, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:65.054, tt:1951.610\n",
      "Ep:30, loss:0.00012, loss_test:0.07714, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:65.026, tt:2015.805\n",
      "Ep:31, loss:0.00011, loss_test:0.07757, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:65.026, tt:2080.821\n",
      "Ep:32, loss:0.00011, loss_test:0.08120, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:65.041, tt:2146.341\n",
      "Ep:33, loss:0.00010, loss_test:0.07816, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:65.049, tt:2211.660\n",
      "Ep:34, loss:0.00010, loss_test:0.07718, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:65.040, tt:2276.405\n",
      "Ep:35, loss:0.00009, loss_test:0.07884, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:65.030, tt:2341.080\n",
      "Ep:36, loss:0.00008, loss_test:0.08256, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:64.979, tt:2404.207\n",
      "Ep:37, loss:0.00008, loss_test:0.08242, lr:9.90e-03, fs:0.82609 (r=0.768,p=0.894),  time:64.987, tt:2469.498\n",
      "Ep:38, loss:0.00008, loss_test:0.07820, lr:9.80e-03, fs:0.82162 (r=0.768,p=0.884),  time:64.976, tt:2534.078\n",
      "Ep:39, loss:0.00008, loss_test:0.07759, lr:9.70e-03, fs:0.82353 (r=0.778,p=0.875),  time:65.021, tt:2600.833\n",
      "Ep:40, loss:0.00007, loss_test:0.08220, lr:9.61e-03, fs:0.79330 (r=0.717,p=0.887),  time:65.084, tt:2668.440\n",
      "Ep:41, loss:0.00007, loss_test:0.07845, lr:9.51e-03, fs:0.82353 (r=0.778,p=0.875),  time:65.062, tt:2732.591\n",
      "Ep:42, loss:0.00007, loss_test:0.07970, lr:9.41e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.082, tt:2798.535\n",
      "Ep:43, loss:0.00006, loss_test:0.08128, lr:9.32e-03, fs:0.79330 (r=0.717,p=0.887),  time:65.032, tt:2861.415\n",
      "Ep:44, loss:0.00006, loss_test:0.07861, lr:9.23e-03, fs:0.82353 (r=0.778,p=0.875),  time:64.973, tt:2923.770\n",
      "Ep:45, loss:0.00006, loss_test:0.08129, lr:9.14e-03, fs:0.81967 (r=0.758,p=0.893),  time:64.968, tt:2988.533\n",
      "Ep:46, loss:0.00006, loss_test:0.08200, lr:9.04e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.976, tt:3053.871\n",
      "Ep:47, loss:0.00005, loss_test:0.08134, lr:8.95e-03, fs:0.82609 (r=0.768,p=0.894),  time:64.973, tt:3118.705\n",
      "Ep:48, loss:0.00005, loss_test:0.08122, lr:8.86e-03, fs:0.82609 (r=0.768,p=0.894),  time:64.993, tt:3184.668\n",
      "Ep:49, loss:0.00005, loss_test:0.08180, lr:8.78e-03, fs:0.82609 (r=0.768,p=0.894),  time:65.042, tt:3252.116\n",
      "Ep:50, loss:0.00005, loss_test:0.08007, lr:8.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:65.058, tt:3317.971\n",
      "Ep:51, loss:0.00005, loss_test:0.08049, lr:8.60e-03, fs:0.78889 (r=0.717,p=0.877),  time:65.057, tt:3382.959\n",
      "Ep:52, loss:0.00005, loss_test:0.08183, lr:8.51e-03, fs:0.80663 (r=0.737,p=0.890),  time:65.057, tt:3448.030\n",
      "Ep:53, loss:0.00005, loss_test:0.08525, lr:8.43e-03, fs:0.80663 (r=0.737,p=0.890),  time:65.062, tt:3513.337\n",
      "Ep:54, loss:0.00005, loss_test:0.08334, lr:8.35e-03, fs:0.82609 (r=0.768,p=0.894),  time:65.061, tt:3578.377\n",
      "Ep:55, loss:0.00004, loss_test:0.07953, lr:8.26e-03, fs:0.80874 (r=0.747,p=0.881),  time:65.068, tt:3643.792\n",
      "Ep:56, loss:0.00004, loss_test:0.08365, lr:8.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.045, tt:3707.552\n",
      "Ep:57, loss:0.00004, loss_test:0.08356, lr:8.10e-03, fs:0.80663 (r=0.737,p=0.890),  time:65.100, tt:3775.799\n",
      "Ep:58, loss:0.00004, loss_test:0.08291, lr:8.02e-03, fs:0.77966 (r=0.697,p=0.885),  time:65.100, tt:3840.898\n",
      "Ep:59, loss:0.00004, loss_test:0.08205, lr:7.94e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.113, tt:3906.769\n",
      "Ep:60, loss:0.00004, loss_test:0.08096, lr:7.86e-03, fs:0.82609 (r=0.768,p=0.894),  time:65.134, tt:3973.165\n",
      "Ep:61, loss:0.00004, loss_test:0.08702, lr:7.78e-03, fs:0.74854 (r=0.646,p=0.889),  time:65.144, tt:4038.948\n",
      "Ep:62, loss:0.00004, loss_test:0.08049, lr:7.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:65.149, tt:4104.394\n",
      "Ep:63, loss:0.00003, loss_test:0.08375, lr:7.62e-03, fs:0.78652 (r=0.707,p=0.886),  time:65.121, tt:4167.765\n",
      "Ep:64, loss:0.00003, loss_test:0.08260, lr:7.55e-03, fs:0.78652 (r=0.707,p=0.886),  time:65.132, tt:4233.600\n",
      "Ep:65, loss:0.00003, loss_test:0.08221, lr:7.47e-03, fs:0.82609 (r=0.768,p=0.894),  time:65.117, tt:4297.736\n",
      "Ep:66, loss:0.00003, loss_test:0.08385, lr:7.40e-03, fs:0.81111 (r=0.737,p=0.901),  time:65.147, tt:4364.864\n",
      "Ep:67, loss:0.00003, loss_test:0.08377, lr:7.32e-03, fs:0.77714 (r=0.687,p=0.895),  time:65.133, tt:4429.038\n",
      "Ep:68, loss:0.00003, loss_test:0.08197, lr:7.25e-03, fs:0.82609 (r=0.768,p=0.894),  time:65.127, tt:4493.782\n",
      "Ep:69, loss:0.00003, loss_test:0.08284, lr:7.18e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.127, tt:4558.897\n",
      "Ep:70, loss:0.00003, loss_test:0.08469, lr:7.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:65.112, tt:4622.977\n",
      "Ep:71, loss:0.00003, loss_test:0.08184, lr:7.03e-03, fs:0.81319 (r=0.747,p=0.892),  time:65.091, tt:4686.528\n",
      "Ep:72, loss:0.00003, loss_test:0.08512, lr:6.96e-03, fs:0.77457 (r=0.677,p=0.905),  time:65.080, tt:4750.804\n",
      "Ep:73, loss:0.00003, loss_test:0.08362, lr:6.89e-03, fs:0.78161 (r=0.687,p=0.907),  time:65.070, tt:4815.179\n",
      "Ep:74, loss:0.00003, loss_test:0.08267, lr:6.83e-03, fs:0.81564 (r=0.737,p=0.912),  time:65.085, tt:4881.342\n",
      "Ep:75, loss:0.00003, loss_test:0.08503, lr:6.76e-03, fs:0.76744 (r=0.667,p=0.904),  time:65.067, tt:4945.057\n",
      "Ep:76, loss:0.00003, loss_test:0.08510, lr:6.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:65.049, tt:5008.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00002, loss_test:0.08347, lr:6.62e-03, fs:0.78161 (r=0.687,p=0.907),  time:65.037, tt:5072.923\n",
      "Ep:78, loss:0.00002, loss_test:0.08500, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:65.058, tt:5139.546\n",
      "Ep:79, loss:0.00002, loss_test:0.08495, lr:6.49e-03, fs:0.78161 (r=0.687,p=0.907),  time:65.052, tt:5204.197\n",
      "Ep:80, loss:0.00002, loss_test:0.08430, lr:6.43e-03, fs:0.76471 (r=0.657,p=0.915),  time:65.032, tt:5267.577\n",
      "Ep:81, loss:0.00002, loss_test:0.08523, lr:6.36e-03, fs:0.77907 (r=0.677,p=0.918),  time:65.015, tt:5331.195\n",
      "Ep:82, loss:0.00002, loss_test:0.08479, lr:6.30e-03, fs:0.76471 (r=0.657,p=0.915),  time:64.992, tt:5394.365\n",
      "Ep:83, loss:0.00002, loss_test:0.08474, lr:6.24e-03, fs:0.77907 (r=0.677,p=0.918),  time:64.983, tt:5458.580\n",
      "Ep:84, loss:0.00002, loss_test:0.08494, lr:6.17e-03, fs:0.78613 (r=0.687,p=0.919),  time:64.972, tt:5522.616\n",
      "Ep:85, loss:0.00002, loss_test:0.08488, lr:6.11e-03, fs:0.77193 (r=0.667,p=0.917),  time:64.987, tt:5588.863\n",
      "Ep:86, loss:0.00002, loss_test:0.08583, lr:6.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:64.984, tt:5653.582\n",
      "Ep:87, loss:0.00002, loss_test:0.08612, lr:5.99e-03, fs:0.75000 (r=0.636,p=0.913),  time:64.971, tt:5717.405\n",
      "Ep:88, loss:0.00002, loss_test:0.08676, lr:5.93e-03, fs:0.75000 (r=0.636,p=0.913),  time:64.977, tt:5782.988\n",
      "Ep:89, loss:0.00002, loss_test:0.08605, lr:5.87e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.966, tt:5846.965\n",
      "Ep:90, loss:0.00002, loss_test:0.08676, lr:5.81e-03, fs:0.76471 (r=0.657,p=0.915),  time:64.962, tt:5911.508\n",
      "Ep:91, loss:0.00002, loss_test:0.08704, lr:5.75e-03, fs:0.74251 (r=0.626,p=0.912),  time:64.996, tt:5979.647\n",
      "Ep:92, loss:0.00002, loss_test:0.08641, lr:5.70e-03, fs:0.75740 (r=0.646,p=0.914),  time:65.009, tt:6045.796\n",
      "Ep:93, loss:0.00002, loss_test:0.08890, lr:5.64e-03, fs:0.72393 (r=0.596,p=0.922),  time:65.010, tt:6110.936\n",
      "Ep:94, loss:0.00002, loss_test:0.08740, lr:5.58e-03, fs:0.74251 (r=0.626,p=0.912),  time:64.992, tt:6174.219\n",
      "Ep:95, loss:0.00002, loss_test:0.08820, lr:5.53e-03, fs:0.75904 (r=0.636,p=0.940),  time:65.013, tt:6241.286\n",
      "Ep:96, loss:0.00002, loss_test:0.08855, lr:5.47e-03, fs:0.73494 (r=0.616,p=0.910),  time:65.029, tt:6307.812\n",
      "Ep:97, loss:0.00002, loss_test:0.08845, lr:5.42e-03, fs:0.74390 (r=0.616,p=0.938),  time:65.034, tt:6373.370\n",
      "Ep:98, loss:0.00002, loss_test:0.08742, lr:5.36e-03, fs:0.74251 (r=0.626,p=0.912),  time:65.035, tt:6438.441\n",
      "Ep:99, loss:0.00002, loss_test:0.08880, lr:5.31e-03, fs:0.74390 (r=0.616,p=0.938),  time:65.038, tt:6503.777\n",
      "Ep:100, loss:0.00002, loss_test:0.08852, lr:5.26e-03, fs:0.74390 (r=0.616,p=0.938),  time:65.046, tt:6569.616\n",
      "Ep:101, loss:0.00001, loss_test:0.08901, lr:5.20e-03, fs:0.73620 (r=0.606,p=0.938),  time:65.032, tt:6633.251\n",
      "Ep:102, loss:0.00001, loss_test:0.08982, lr:5.15e-03, fs:0.72840 (r=0.596,p=0.937),  time:65.016, tt:6696.602\n",
      "Ep:103, loss:0.00001, loss_test:0.08845, lr:5.10e-03, fs:0.74390 (r=0.616,p=0.938),  time:65.023, tt:6762.389\n",
      "Ep:104, loss:0.00001, loss_test:0.09006, lr:5.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:65.002, tt:6825.213\n",
      "Ep:105, loss:0.00001, loss_test:0.08960, lr:5.00e-03, fs:0.72840 (r=0.596,p=0.937),  time:65.002, tt:6890.192\n",
      "Ep:106, loss:0.00001, loss_test:0.09070, lr:4.95e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.995, tt:6954.471\n",
      "Ep:107, loss:0.00001, loss_test:0.08899, lr:4.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:64.998, tt:7019.834\n",
      "Ep:108, loss:0.00001, loss_test:0.09131, lr:4.85e-03, fs:0.72840 (r=0.596,p=0.937),  time:65.001, tt:7085.089\n",
      "Ep:109, loss:0.00001, loss_test:0.08914, lr:4.80e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.993, tt:7149.280\n",
      "Ep:110, loss:0.00001, loss_test:0.09073, lr:4.75e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.981, tt:7212.874\n",
      "Ep:111, loss:0.00001, loss_test:0.09072, lr:4.71e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.991, tt:7278.981\n",
      "Ep:112, loss:0.00001, loss_test:0.09034, lr:4.66e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.981, tt:7342.824\n",
      "Ep:113, loss:0.00001, loss_test:0.09100, lr:4.61e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.989, tt:7408.750\n",
      "Ep:114, loss:0.00001, loss_test:0.09113, lr:4.57e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.936, tt:7467.678\n",
      "Ep:115, loss:0.00001, loss_test:0.09074, lr:4.52e-03, fs:0.70440 (r=0.566,p=0.933),  time:64.922, tt:7530.957\n",
      "Ep:116, loss:0.00001, loss_test:0.09034, lr:4.48e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.888, tt:7591.892\n",
      "Ep:117, loss:0.00001, loss_test:0.09111, lr:4.43e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.802, tt:7646.587\n",
      "Ep:118, loss:0.00001, loss_test:0.09055, lr:4.39e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.700, tt:7699.335\n",
      "Ep:119, loss:0.00001, loss_test:0.09176, lr:4.34e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.715, tt:7765.748\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00085, loss_test:0.14423, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:97.984, tt:97.984\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00083, loss_test:0.13797, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:98.601, tt:197.202\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00076, loss_test:0.11952, lr:1.00e-02, fs:0.63393 (r=0.717,p=0.568),  time:98.088, tt:294.264\n",
      "Ep:3, loss:0.00068, loss_test:0.11338, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:98.874, tt:395.495\n",
      "Ep:4, loss:0.00063, loss_test:0.10490, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:98.670, tt:493.351\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00059, loss_test:0.09981, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:98.964, tt:593.785\n",
      "Ep:6, loss:0.00055, loss_test:0.09551, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:98.723, tt:691.062\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00052, loss_test:0.09164, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:98.771, tt:790.168\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00049, loss_test:0.09007, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:98.867, tt:889.806\n",
      "Ep:9, loss:0.00046, loss_test:0.08603, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:98.845, tt:988.454\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00044, loss_test:0.08321, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:98.518, tt:1083.696\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.08126, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:98.631, tt:1183.570\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00039, loss_test:0.07933, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:98.622, tt:1282.080\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00036, loss_test:0.07841, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:98.822, tt:1383.509\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00034, loss_test:0.07703, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:98.569, tt:1478.535\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00032, loss_test:0.07537, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:98.665, tt:1578.640\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00030, loss_test:0.07490, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:98.724, tt:1678.314\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00028, loss_test:0.07403, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:98.752, tt:1777.542\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.07254, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:98.702, tt:1875.336\n",
      "Ep:19, loss:0.00024, loss_test:0.07209, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:98.585, tt:1971.695\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.07264, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:98.570, tt:2069.976\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.07133, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:98.561, tt:2168.338\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00019, loss_test:0.06962, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:98.513, tt:2265.800\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.07127, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:98.677, tt:2368.242\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.07049, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:98.649, tt:2466.230\n",
      "Ep:25, loss:0.00015, loss_test:0.06949, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:98.621, tt:2564.153\n",
      "Ep:26, loss:0.00015, loss_test:0.06979, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:98.557, tt:2661.028\n",
      "Ep:27, loss:0.00014, loss_test:0.06581, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:98.529, tt:2758.799\n",
      "Ep:28, loss:0.00013, loss_test:0.06544, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:98.513, tt:2856.877\n",
      "Ep:29, loss:0.00012, loss_test:0.06658, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:98.442, tt:2953.260\n",
      "Ep:30, loss:0.00011, loss_test:0.06530, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:98.491, tt:3053.231\n",
      "Ep:31, loss:0.00011, loss_test:0.06431, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:98.551, tt:3153.636\n",
      "Ep:32, loss:0.00010, loss_test:0.07084, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:98.496, tt:3250.383\n",
      "Ep:33, loss:0.00010, loss_test:0.07004, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:98.463, tt:3347.732\n",
      "Ep:34, loss:0.00009, loss_test:0.06684, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:98.383, tt:3443.407\n",
      "Ep:35, loss:0.00008, loss_test:0.06775, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.451, tt:3544.245\n",
      "Ep:36, loss:0.00008, loss_test:0.06986, lr:9.80e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.405, tt:3640.992\n",
      "Ep:37, loss:0.00008, loss_test:0.07094, lr:9.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.395, tt:3738.995\n",
      "Ep:38, loss:0.00007, loss_test:0.06798, lr:9.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:98.405, tt:3837.798\n",
      "Ep:39, loss:0.00007, loss_test:0.06761, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:98.420, tt:3936.798\n",
      "Ep:40, loss:0.00006, loss_test:0.06891, lr:9.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:98.431, tt:4035.673\n",
      "Ep:41, loss:0.00006, loss_test:0.07015, lr:9.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.485, tt:4136.351\n",
      "Ep:42, loss:0.00006, loss_test:0.06704, lr:9.23e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.498, tt:4235.430\n",
      "Ep:43, loss:0.00005, loss_test:0.06675, lr:9.14e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.485, tt:4333.334\n",
      "Ep:44, loss:0.00005, loss_test:0.06745, lr:9.04e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.543, tt:4434.453\n",
      "Ep:45, loss:0.00005, loss_test:0.06898, lr:8.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.552, tt:4533.376\n",
      "Ep:46, loss:0.00005, loss_test:0.06807, lr:8.86e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.499, tt:4629.468\n",
      "Ep:47, loss:0.00004, loss_test:0.06884, lr:8.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.494, tt:4727.698\n",
      "Ep:48, loss:0.00004, loss_test:0.06801, lr:8.69e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.522, tt:4827.601\n",
      "Ep:49, loss:0.00004, loss_test:0.06778, lr:8.60e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.513, tt:4925.640\n",
      "Ep:50, loss:0.00004, loss_test:0.06706, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.529, tt:5024.979\n",
      "Ep:51, loss:0.00003, loss_test:0.06645, lr:8.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.515, tt:5122.799\n",
      "Ep:52, loss:0.00003, loss_test:0.06695, lr:8.35e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.547, tt:5222.994\n",
      "Ep:53, loss:0.00003, loss_test:0.06749, lr:8.26e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.465, tt:5317.118\n",
      "Ep:54, loss:0.00003, loss_test:0.06805, lr:8.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.389, tt:5411.394\n",
      "Ep:55, loss:0.00003, loss_test:0.06859, lr:8.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.360, tt:5508.157\n",
      "Ep:56, loss:0.00003, loss_test:0.06866, lr:8.02e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.309, tt:5603.613\n",
      "Ep:57, loss:0.00003, loss_test:0.06668, lr:7.94e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.287, tt:5700.656\n",
      "Ep:58, loss:0.00002, loss_test:0.06526, lr:7.86e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.259, tt:5797.310\n",
      "Ep:59, loss:0.00002, loss_test:0.06491, lr:7.78e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.264, tt:5895.847\n",
      "Ep:60, loss:0.00002, loss_test:0.06657, lr:7.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.263, tt:5994.074\n",
      "Ep:61, loss:0.00002, loss_test:0.06681, lr:7.62e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.269, tt:6092.701\n",
      "Ep:62, loss:0.00002, loss_test:0.06683, lr:7.55e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.237, tt:6188.900\n",
      "Ep:63, loss:0.00002, loss_test:0.06683, lr:7.47e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.219, tt:6286.002\n",
      "Ep:64, loss:0.00002, loss_test:0.06844, lr:7.40e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.155, tt:6380.101\n",
      "Ep:65, loss:0.00002, loss_test:0.06784, lr:7.32e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.112, tt:6475.412\n",
      "Ep:66, loss:0.00002, loss_test:0.06836, lr:7.25e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.088, tt:6571.877\n",
      "Ep:67, loss:0.00002, loss_test:0.06750, lr:7.18e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.056, tt:6667.789\n",
      "Ep:68, loss:0.00002, loss_test:0.06651, lr:7.11e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.049, tt:6765.376\n",
      "Ep:69, loss:0.00002, loss_test:0.06721, lr:7.03e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.022, tt:6861.547\n",
      "Ep:70, loss:0.00002, loss_test:0.06749, lr:6.96e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.016, tt:6959.134\n",
      "Ep:71, loss:0.00002, loss_test:0.06760, lr:6.89e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.040, tt:7058.908\n",
      "Ep:72, loss:0.00002, loss_test:0.06758, lr:6.83e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.033, tt:7156.423\n",
      "Ep:73, loss:0.00001, loss_test:0.06685, lr:6.76e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.972, tt:7249.944\n",
      "Ep:74, loss:0.00001, loss_test:0.06655, lr:6.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.972, tt:7347.899\n",
      "Ep:75, loss:0.00001, loss_test:0.06674, lr:6.62e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.968, tt:7445.590\n",
      "Ep:76, loss:0.00001, loss_test:0.06634, lr:6.56e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.932, tt:7540.781\n",
      "Ep:77, loss:0.00001, loss_test:0.06655, lr:6.49e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.927, tt:7638.289\n",
      "Ep:78, loss:0.00001, loss_test:0.06628, lr:6.43e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.939, tt:7737.183\n",
      "Ep:79, loss:0.00001, loss_test:0.06626, lr:6.36e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.971, tt:7837.650\n",
      "Ep:80, loss:0.00001, loss_test:0.06682, lr:6.30e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.021, tt:7939.673\n",
      "Ep:81, loss:0.00001, loss_test:0.06646, lr:6.24e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.024, tt:8038.008\n",
      "Ep:82, loss:0.00001, loss_test:0.06661, lr:6.17e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.017, tt:8135.408\n",
      "Ep:83, loss:0.00001, loss_test:0.06689, lr:6.11e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.015, tt:8233.236\n",
      "Ep:84, loss:0.00001, loss_test:0.06735, lr:6.05e-03, fs:0.86857 (r=0.768,p=1.000),  time:98.005, tt:8330.402\n",
      "Ep:85, loss:0.00001, loss_test:0.06724, lr:5.99e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.995, tt:8427.584\n",
      "Ep:86, loss:0.00001, loss_test:0.06734, lr:5.93e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.979, tt:8524.170\n",
      "Ep:87, loss:0.00001, loss_test:0.06789, lr:5.87e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.982, tt:8622.423\n",
      "Ep:88, loss:0.00001, loss_test:0.06637, lr:5.81e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.936, tt:8716.310\n",
      "Ep:89, loss:0.00001, loss_test:0.06616, lr:5.75e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.926, tt:8813.358\n",
      "Ep:90, loss:0.00001, loss_test:0.06561, lr:5.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.903, tt:8909.214\n",
      "Ep:91, loss:0.00001, loss_test:0.06618, lr:5.64e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.871, tt:9004.170\n",
      "Ep:92, loss:0.00001, loss_test:0.06648, lr:5.58e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.875, tt:9102.357\n",
      "Ep:93, loss:0.00001, loss_test:0.06609, lr:5.53e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.889, tt:9201.525\n",
      "Ep:94, loss:0.00001, loss_test:0.06583, lr:5.47e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.885, tt:9299.116\n",
      "Ep:95, loss:0.00001, loss_test:0.06620, lr:5.42e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.892, tt:9397.643\n",
      "Ep:96, loss:0.00001, loss_test:0.06639, lr:5.36e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.824, tt:9488.882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00001, loss_test:0.06610, lr:5.31e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.810, tt:9585.413\n",
      "Ep:98, loss:0.00001, loss_test:0.06624, lr:5.26e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.795, tt:9681.658\n",
      "Ep:99, loss:0.00001, loss_test:0.06618, lr:5.20e-03, fs:0.86857 (r=0.768,p=1.000),  time:97.599, tt:9759.929\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00085, loss_test:0.14090, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:95.920, tt:95.920\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00082, loss_test:0.13427, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:96.731, tt:193.462\n",
      "Ep:2, loss:0.00075, loss_test:0.12712, lr:1.00e-02, fs:0.61165 (r=0.636,p=0.589),  time:97.149, tt:291.446\n",
      "Ep:3, loss:0.00067, loss_test:0.12575, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:97.555, tt:390.220\n",
      "Ep:4, loss:0.00062, loss_test:0.11975, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:97.673, tt:488.364\n",
      "Ep:5, loss:0.00058, loss_test:0.11115, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:97.053, tt:582.320\n",
      "Ep:6, loss:0.00054, loss_test:0.10633, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:96.983, tt:678.881\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00051, loss_test:0.10438, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:97.089, tt:776.715\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00048, loss_test:0.10119, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:97.052, tt:873.465\n",
      "Ep:9, loss:0.00045, loss_test:0.09796, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:97.127, tt:971.268\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.09740, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:97.218, tt:1069.402\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.09627, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:97.382, tt:1168.582\n",
      "Ep:12, loss:0.00037, loss_test:0.09512, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:97.402, tt:1266.221\n",
      "Ep:13, loss:0.00035, loss_test:0.09356, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:97.293, tt:1362.100\n",
      "Ep:14, loss:0.00032, loss_test:0.09330, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:97.359, tt:1460.388\n",
      "Ep:15, loss:0.00030, loss_test:0.09224, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:97.433, tt:1558.932\n",
      "Ep:16, loss:0.00028, loss_test:0.09079, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:97.366, tt:1655.220\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.09193, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:97.414, tt:1753.450\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.09017, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:97.230, tt:1847.360\n",
      "Ep:19, loss:0.00022, loss_test:0.08883, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:97.336, tt:1946.724\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.08775, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:97.372, tt:2044.812\n",
      "Ep:21, loss:0.00019, loss_test:0.08773, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:97.402, tt:2142.837\n",
      "Ep:22, loss:0.00018, loss_test:0.08776, lr:1.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:97.403, tt:2240.273\n",
      "Ep:23, loss:0.00017, loss_test:0.08781, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:97.329, tt:2335.901\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08712, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:97.305, tt:2432.619\n",
      "Ep:25, loss:0.00014, loss_test:0.08767, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:97.339, tt:2530.802\n",
      "Ep:26, loss:0.00013, loss_test:0.08725, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:97.291, tt:2626.861\n",
      "Ep:27, loss:0.00012, loss_test:0.08724, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:97.224, tt:2722.285\n",
      "Ep:28, loss:0.00012, loss_test:0.08799, lr:1.00e-02, fs:0.72289 (r=0.606,p=0.896),  time:97.222, tt:2819.432\n",
      "Ep:29, loss:0.00011, loss_test:0.08899, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:97.224, tt:2916.723\n",
      "Ep:30, loss:0.00010, loss_test:0.08981, lr:1.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:97.261, tt:3015.103\n",
      "Ep:31, loss:0.00010, loss_test:0.09073, lr:1.00e-02, fs:0.69136 (r=0.566,p=0.889),  time:97.231, tt:3111.382\n",
      "Ep:32, loss:0.00009, loss_test:0.09156, lr:1.00e-02, fs:0.69620 (r=0.556,p=0.932),  time:97.222, tt:3208.337\n",
      "Ep:33, loss:0.00009, loss_test:0.08953, lr:1.00e-02, fs:0.69620 (r=0.556,p=0.932),  time:97.239, tt:3306.136\n",
      "Ep:34, loss:0.00008, loss_test:0.08844, lr:1.00e-02, fs:0.69182 (r=0.556,p=0.917),  time:97.264, tt:3404.228\n",
      "Ep:35, loss:0.00008, loss_test:0.08898, lr:9.90e-03, fs:0.67097 (r=0.525,p=0.929),  time:97.275, tt:3501.908\n",
      "Ep:36, loss:0.00007, loss_test:0.09472, lr:9.80e-03, fs:0.67532 (r=0.525,p=0.945),  time:97.293, tt:3599.859\n",
      "Ep:37, loss:0.00007, loss_test:0.09327, lr:9.70e-03, fs:0.64901 (r=0.495,p=0.942),  time:97.375, tt:3700.234\n",
      "Ep:38, loss:0.00007, loss_test:0.09538, lr:9.61e-03, fs:0.64901 (r=0.495,p=0.942),  time:97.391, tt:3798.249\n",
      "Ep:39, loss:0.00006, loss_test:0.09415, lr:9.51e-03, fs:0.64901 (r=0.495,p=0.942),  time:97.473, tt:3898.924\n",
      "Ep:40, loss:0.00006, loss_test:0.09577, lr:9.41e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.509, tt:3997.872\n",
      "Ep:41, loss:0.00006, loss_test:0.09365, lr:9.32e-03, fs:0.65789 (r=0.505,p=0.943),  time:97.568, tt:4097.868\n",
      "Ep:42, loss:0.00005, loss_test:0.09558, lr:9.23e-03, fs:0.66225 (r=0.505,p=0.962),  time:97.599, tt:4196.763\n",
      "Ep:43, loss:0.00005, loss_test:0.09642, lr:9.14e-03, fs:0.64901 (r=0.495,p=0.942),  time:97.616, tt:4295.110\n",
      "Ep:44, loss:0.00005, loss_test:0.09874, lr:9.04e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.598, tt:4391.929\n",
      "Ep:45, loss:0.00005, loss_test:0.09661, lr:8.95e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.582, tt:4488.777\n",
      "Ep:46, loss:0.00004, loss_test:0.09565, lr:8.86e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.551, tt:4584.896\n",
      "Ep:47, loss:0.00004, loss_test:0.09466, lr:8.78e-03, fs:0.65789 (r=0.505,p=0.943),  time:97.550, tt:4682.404\n",
      "Ep:48, loss:0.00004, loss_test:0.09521, lr:8.69e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.486, tt:4776.806\n",
      "Ep:49, loss:0.00004, loss_test:0.09881, lr:8.60e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.470, tt:4873.502\n",
      "Ep:50, loss:0.00004, loss_test:0.09926, lr:8.51e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.431, tt:4968.980\n",
      "Ep:51, loss:0.00004, loss_test:0.09651, lr:8.43e-03, fs:0.66225 (r=0.505,p=0.962),  time:97.440, tt:5066.882\n",
      "Ep:52, loss:0.00004, loss_test:0.09759, lr:8.35e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.457, tt:5165.225\n",
      "Ep:53, loss:0.00004, loss_test:0.09781, lr:8.26e-03, fs:0.64430 (r=0.485,p=0.960),  time:97.460, tt:5262.832\n",
      "Ep:54, loss:0.00003, loss_test:0.09862, lr:8.18e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.475, tt:5361.147\n",
      "Ep:55, loss:0.00003, loss_test:0.09991, lr:8.10e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.458, tt:5457.630\n",
      "Ep:56, loss:0.00003, loss_test:0.10026, lr:8.02e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.432, tt:5553.617\n",
      "Ep:57, loss:0.00003, loss_test:0.09928, lr:7.94e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.423, tt:5650.549\n",
      "Ep:58, loss:0.00003, loss_test:0.09873, lr:7.86e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.404, tt:5746.820\n",
      "Ep:59, loss:0.00003, loss_test:0.10014, lr:7.78e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.329, tt:5839.720\n",
      "Ep:60, loss:0.00003, loss_test:0.10186, lr:7.70e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.331, tt:5937.215\n",
      "Ep:61, loss:0.00003, loss_test:0.09884, lr:7.62e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.329, tt:6034.422\n",
      "Ep:62, loss:0.00003, loss_test:0.09919, lr:7.55e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.342, tt:6132.533\n",
      "Ep:63, loss:0.00003, loss_test:0.10040, lr:7.47e-03, fs:0.65772 (r=0.495,p=0.980),  time:97.326, tt:6228.873\n",
      "Ep:64, loss:0.00003, loss_test:0.09988, lr:7.40e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.351, tt:6327.785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00002, loss_test:0.09988, lr:7.32e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.336, tt:6424.208\n",
      "Ep:66, loss:0.00002, loss_test:0.10120, lr:7.25e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.297, tt:6518.867\n",
      "Ep:67, loss:0.00002, loss_test:0.10014, lr:7.18e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.321, tt:6617.810\n",
      "Ep:68, loss:0.00002, loss_test:0.10069, lr:7.11e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.319, tt:6715.017\n",
      "Ep:69, loss:0.00002, loss_test:0.10094, lr:7.03e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.299, tt:6810.900\n",
      "Ep:70, loss:0.00002, loss_test:0.10107, lr:6.96e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.255, tt:6905.121\n",
      "Ep:71, loss:0.00002, loss_test:0.10101, lr:6.89e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.256, tt:7002.424\n",
      "Ep:72, loss:0.00002, loss_test:0.10291, lr:6.83e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.276, tt:7101.135\n",
      "Ep:73, loss:0.00002, loss_test:0.10190, lr:6.76e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.276, tt:7198.402\n",
      "Ep:74, loss:0.00002, loss_test:0.10092, lr:6.69e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.293, tt:7296.994\n",
      "Ep:75, loss:0.00002, loss_test:0.10139, lr:6.62e-03, fs:0.64865 (r=0.485,p=0.980),  time:97.299, tt:7394.717\n",
      "Ep:76, loss:0.00002, loss_test:0.10283, lr:6.56e-03, fs:0.63946 (r=0.475,p=0.979),  time:97.326, tt:7494.084\n",
      "Ep:77, loss:0.00002, loss_test:0.10284, lr:6.49e-03, fs:0.64384 (r=0.475,p=1.000),  time:97.317, tt:7590.692\n",
      "Ep:78, loss:0.00002, loss_test:0.10316, lr:6.43e-03, fs:0.63448 (r=0.465,p=1.000),  time:97.288, tt:7685.735\n",
      "Ep:79, loss:0.00002, loss_test:0.10345, lr:6.36e-03, fs:0.65306 (r=0.485,p=1.000),  time:97.276, tt:7782.074\n",
      "Ep:80, loss:0.00002, loss_test:0.10240, lr:6.30e-03, fs:0.63946 (r=0.475,p=0.979),  time:97.262, tt:7878.214\n",
      "Ep:81, loss:0.00002, loss_test:0.10221, lr:6.24e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.267, tt:7975.917\n",
      "Ep:82, loss:0.00002, loss_test:0.10284, lr:6.17e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.249, tt:8071.689\n",
      "Ep:83, loss:0.00002, loss_test:0.10427, lr:6.11e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.232, tt:8167.465\n",
      "Ep:84, loss:0.00002, loss_test:0.10324, lr:6.05e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.241, tt:8265.457\n",
      "Ep:85, loss:0.00002, loss_test:0.10301, lr:5.99e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.237, tt:8362.381\n",
      "Ep:86, loss:0.00002, loss_test:0.10467, lr:5.93e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.227, tt:8458.776\n",
      "Ep:87, loss:0.00002, loss_test:0.10453, lr:5.87e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.251, tt:8558.060\n",
      "Ep:88, loss:0.00001, loss_test:0.10334, lr:5.81e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.228, tt:8653.280\n",
      "Ep:89, loss:0.00001, loss_test:0.10244, lr:5.75e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.252, tt:8752.715\n",
      "Ep:90, loss:0.00001, loss_test:0.10361, lr:5.70e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.260, tt:8850.626\n",
      "Ep:91, loss:0.00001, loss_test:0.10438, lr:5.64e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.247, tt:8946.696\n",
      "Ep:92, loss:0.00001, loss_test:0.10432, lr:5.58e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.241, tt:9043.424\n",
      "Ep:93, loss:0.00001, loss_test:0.10375, lr:5.53e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.246, tt:9141.084\n",
      "Ep:94, loss:0.00001, loss_test:0.10394, lr:5.47e-03, fs:0.62500 (r=0.455,p=1.000),  time:97.254, tt:9239.084\n",
      "Ep:95, loss:0.00001, loss_test:0.10446, lr:5.42e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.248, tt:9335.808\n",
      "Ep:96, loss:0.00001, loss_test:0.10430, lr:5.36e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.239, tt:9432.144\n",
      "Ep:97, loss:0.00001, loss_test:0.10456, lr:5.31e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.243, tt:9529.831\n",
      "Ep:98, loss:0.00001, loss_test:0.10416, lr:5.26e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.212, tt:9624.000\n",
      "Ep:99, loss:0.00001, loss_test:0.10448, lr:5.20e-03, fs:0.61538 (r=0.444,p=1.000),  time:97.051, tt:9705.131\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.13960, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:106.655, tt:106.655\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00091, loss_test:0.12585, lr:1.00e-02, fs:0.66960 (r=0.768,p=0.594),  time:110.905, tt:221.810\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00080, loss_test:0.12235, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:112.231, tt:336.692\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00073, loss_test:0.12121, lr:1.00e-02, fs:0.60302 (r=0.606,p=0.600),  time:113.963, tt:455.854\n",
      "Ep:4, loss:0.00067, loss_test:0.11809, lr:1.00e-02, fs:0.63158 (r=0.606,p=0.659),  time:113.982, tt:569.909\n",
      "Ep:5, loss:0.00061, loss_test:0.11622, lr:1.00e-02, fs:0.63043 (r=0.586,p=0.682),  time:114.743, tt:688.460\n",
      "Ep:6, loss:0.00056, loss_test:0.11325, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:114.913, tt:804.391\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00052, loss_test:0.10979, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:114.950, tt:919.597\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00048, loss_test:0.11065, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:114.809, tt:1033.281\n",
      "Ep:9, loss:0.00045, loss_test:0.10869, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:114.565, tt:1145.652\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00041, loss_test:0.10925, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:114.505, tt:1259.551\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00038, loss_test:0.10558, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:114.530, tt:1374.365\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00035, loss_test:0.10371, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:114.476, tt:1488.182\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.10109, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:114.648, tt:1605.068\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.10122, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:114.566, tt:1718.497\n",
      "Ep:15, loss:0.00026, loss_test:0.10367, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:114.513, tt:1832.207\n",
      "Ep:16, loss:0.00025, loss_test:0.10031, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:114.462, tt:1945.851\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.09996, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:114.548, tt:2061.860\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00020, loss_test:0.09850, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:114.548, tt:2176.419\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09896, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:114.608, tt:2292.150\n",
      "Ep:20, loss:0.00017, loss_test:0.10187, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:114.567, tt:2405.913\n",
      "Ep:21, loss:0.00015, loss_test:0.09731, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:114.558, tt:2520.268\n",
      "Ep:22, loss:0.00014, loss_test:0.09784, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:114.528, tt:2634.148\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09863, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:114.510, tt:2748.249\n",
      "Ep:24, loss:0.00012, loss_test:0.09881, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:114.456, tt:2861.400\n",
      "Ep:25, loss:0.00011, loss_test:0.09668, lr:1.00e-02, fs:0.75449 (r=0.636,p=0.926),  time:114.402, tt:2974.460\n",
      "Ep:26, loss:0.00010, loss_test:0.10272, lr:1.00e-02, fs:0.72050 (r=0.586,p=0.935),  time:114.439, tt:3089.860\n",
      "Ep:27, loss:0.00010, loss_test:0.10098, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:114.466, tt:3205.059\n",
      "Ep:28, loss:0.00009, loss_test:0.09995, lr:1.00e-02, fs:0.73620 (r=0.606,p=0.938),  time:114.436, tt:3318.654\n",
      "Ep:29, loss:0.00008, loss_test:0.10286, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:114.445, tt:3433.362\n",
      "Ep:30, loss:0.00008, loss_test:0.10012, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:114.318, tt:3543.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00007, loss_test:0.09668, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:114.368, tt:3659.777\n",
      "Ep:32, loss:0.00007, loss_test:0.10086, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:114.362, tt:3773.949\n",
      "Ep:33, loss:0.00007, loss_test:0.10017, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:114.358, tt:3888.168\n",
      "Ep:34, loss:0.00006, loss_test:0.09753, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:114.297, tt:4000.391\n",
      "Ep:35, loss:0.00006, loss_test:0.09880, lr:9.80e-03, fs:0.78363 (r=0.677,p=0.931),  time:114.281, tt:4114.134\n",
      "Ep:36, loss:0.00006, loss_test:0.10230, lr:9.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:114.306, tt:4229.321\n",
      "Ep:37, loss:0.00005, loss_test:0.10539, lr:9.61e-03, fs:0.71605 (r=0.586,p=0.921),  time:114.332, tt:4344.619\n",
      "Ep:38, loss:0.00005, loss_test:0.10322, lr:9.51e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.320, tt:4458.473\n",
      "Ep:39, loss:0.00005, loss_test:0.10439, lr:9.41e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.335, tt:4573.420\n",
      "Ep:40, loss:0.00004, loss_test:0.10199, lr:9.32e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.306, tt:4686.559\n",
      "Ep:41, loss:0.00004, loss_test:0.10445, lr:9.23e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.334, tt:4802.026\n",
      "Ep:42, loss:0.00004, loss_test:0.10600, lr:9.14e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.344, tt:4916.810\n",
      "Ep:43, loss:0.00004, loss_test:0.10638, lr:9.04e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.442, tt:5035.464\n",
      "Ep:44, loss:0.00003, loss_test:0.10608, lr:8.95e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.446, tt:5150.063\n",
      "Ep:45, loss:0.00003, loss_test:0.10664, lr:8.86e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.434, tt:5263.974\n",
      "Ep:46, loss:0.00003, loss_test:0.10634, lr:8.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.527, tt:5382.748\n",
      "Ep:47, loss:0.00003, loss_test:0.10705, lr:8.69e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.553, tt:5498.539\n",
      "Ep:48, loss:0.00003, loss_test:0.10495, lr:8.60e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.570, tt:5613.942\n",
      "Ep:49, loss:0.00003, loss_test:0.10606, lr:8.51e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.598, tt:5729.893\n",
      "Ep:50, loss:0.00003, loss_test:0.10567, lr:8.43e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.591, tt:5844.134\n",
      "Ep:51, loss:0.00002, loss_test:0.10586, lr:8.35e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.611, tt:5959.787\n",
      "Ep:52, loss:0.00002, loss_test:0.10681, lr:8.26e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.652, tt:6076.542\n",
      "Ep:53, loss:0.00002, loss_test:0.10768, lr:8.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.675, tt:6192.461\n",
      "Ep:54, loss:0.00002, loss_test:0.10543, lr:8.10e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.725, tt:6309.877\n",
      "Ep:55, loss:0.00002, loss_test:0.10778, lr:8.02e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.703, tt:6423.369\n",
      "Ep:56, loss:0.00002, loss_test:0.10759, lr:7.94e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.692, tt:6537.453\n",
      "Ep:57, loss:0.00002, loss_test:0.10739, lr:7.86e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.715, tt:6653.449\n",
      "Ep:58, loss:0.00002, loss_test:0.10855, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.740, tt:6769.679\n",
      "Ep:59, loss:0.00002, loss_test:0.10699, lr:7.70e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.754, tt:6885.258\n",
      "Ep:60, loss:0.00002, loss_test:0.10736, lr:7.62e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.740, tt:6999.116\n",
      "Ep:61, loss:0.00002, loss_test:0.10820, lr:7.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.747, tt:7114.323\n",
      "Ep:62, loss:0.00002, loss_test:0.10879, lr:7.47e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.734, tt:7228.214\n",
      "Ep:63, loss:0.00002, loss_test:0.10612, lr:7.40e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.726, tt:7342.487\n",
      "Ep:64, loss:0.00001, loss_test:0.10755, lr:7.32e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.712, tt:7456.307\n",
      "Ep:65, loss:0.00001, loss_test:0.10897, lr:7.25e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.636, tt:7565.998\n",
      "Ep:66, loss:0.00001, loss_test:0.10755, lr:7.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.592, tt:7677.654\n",
      "Ep:67, loss:0.00001, loss_test:0.10815, lr:7.11e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.594, tt:7792.409\n",
      "Ep:68, loss:0.00001, loss_test:0.10678, lr:7.03e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.584, tt:7906.292\n",
      "Ep:69, loss:0.00001, loss_test:0.10626, lr:6.96e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.618, tt:8023.252\n",
      "Ep:70, loss:0.00001, loss_test:0.10721, lr:6.89e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.633, tt:8138.951\n",
      "Ep:71, loss:0.00001, loss_test:0.10766, lr:6.83e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.621, tt:8252.687\n",
      "Ep:72, loss:0.00001, loss_test:0.10803, lr:6.76e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.614, tt:8366.817\n",
      "Ep:73, loss:0.00001, loss_test:0.10673, lr:6.69e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.628, tt:8482.496\n",
      "Ep:74, loss:0.00001, loss_test:0.10657, lr:6.62e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.637, tt:8597.771\n",
      "Ep:75, loss:0.00001, loss_test:0.10658, lr:6.56e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.644, tt:8712.926\n",
      "Ep:76, loss:0.00001, loss_test:0.10710, lr:6.49e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.640, tt:8827.301\n",
      "Ep:77, loss:0.00001, loss_test:0.10651, lr:6.43e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.633, tt:8941.345\n",
      "Ep:78, loss:0.00001, loss_test:0.10629, lr:6.36e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.655, tt:9057.741\n",
      "Ep:79, loss:0.00001, loss_test:0.10659, lr:6.30e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.448, tt:9155.844\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14124, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:104.627, tt:104.627\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00092, loss_test:0.12383, lr:1.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:110.279, tt:220.557\n",
      "Ep:2, loss:0.00081, loss_test:0.11686, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:111.467, tt:334.402\n",
      "Ep:3, loss:0.00074, loss_test:0.11249, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:111.985, tt:447.941\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00067, loss_test:0.10883, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:112.656, tt:563.280\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00061, loss_test:0.10652, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:113.199, tt:679.194\n",
      "Ep:6, loss:0.00057, loss_test:0.10782, lr:1.00e-02, fs:0.67021 (r=0.636,p=0.708),  time:113.343, tt:793.402\n",
      "Ep:7, loss:0.00052, loss_test:0.10766, lr:1.00e-02, fs:0.67760 (r=0.626,p=0.738),  time:113.678, tt:909.424\n",
      "Ep:8, loss:0.00049, loss_test:0.10656, lr:1.00e-02, fs:0.67039 (r=0.606,p=0.750),  time:113.626, tt:1022.635\n",
      "Ep:9, loss:0.00045, loss_test:0.10565, lr:1.00e-02, fs:0.68132 (r=0.626,p=0.747),  time:114.109, tt:1141.085\n",
      "Ep:10, loss:0.00041, loss_test:0.10647, lr:1.00e-02, fs:0.67045 (r=0.596,p=0.766),  time:114.418, tt:1258.593\n",
      "Ep:11, loss:0.00038, loss_test:0.10427, lr:1.00e-02, fs:0.67442 (r=0.586,p=0.795),  time:114.515, tt:1374.174\n",
      "Ep:12, loss:0.00034, loss_test:0.10066, lr:1.00e-02, fs:0.70930 (r=0.616,p=0.836),  time:114.441, tt:1487.738\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.10272, lr:1.00e-02, fs:0.70238 (r=0.596,p=0.855),  time:114.532, tt:1603.444\n",
      "Ep:14, loss:0.00028, loss_test:0.09688, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:114.684, tt:1720.258\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.09973, lr:1.00e-02, fs:0.69461 (r=0.586,p=0.853),  time:114.653, tt:1834.453\n",
      "Ep:16, loss:0.00023, loss_test:0.09670, lr:1.00e-02, fs:0.73143 (r=0.646,p=0.842),  time:114.699, tt:1949.880\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.09931, lr:1.00e-02, fs:0.71765 (r=0.616,p=0.859),  time:114.773, tt:2065.920\n",
      "Ep:18, loss:0.00019, loss_test:0.09349, lr:1.00e-02, fs:0.73446 (r=0.657,p=0.833),  time:114.782, tt:2180.866\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00018, loss_test:0.10065, lr:1.00e-02, fs:0.68263 (r=0.576,p=0.838),  time:114.596, tt:2291.912\n",
      "Ep:20, loss:0.00016, loss_test:0.09893, lr:1.00e-02, fs:0.69091 (r=0.576,p=0.864),  time:114.772, tt:2410.202\n",
      "Ep:21, loss:0.00015, loss_test:0.09945, lr:1.00e-02, fs:0.68263 (r=0.576,p=0.838),  time:114.629, tt:2521.828\n",
      "Ep:22, loss:0.00013, loss_test:0.10165, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:114.573, tt:2635.186\n",
      "Ep:23, loss:0.00012, loss_test:0.10031, lr:1.00e-02, fs:0.68675 (r=0.576,p=0.851),  time:114.507, tt:2748.164\n",
      "Ep:24, loss:0.00011, loss_test:0.09892, lr:1.00e-02, fs:0.69091 (r=0.576,p=0.864),  time:114.610, tt:2865.255\n",
      "Ep:25, loss:0.00010, loss_test:0.10455, lr:1.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:114.587, tt:2979.259\n",
      "Ep:26, loss:0.00010, loss_test:0.09703, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:114.621, tt:3094.758\n",
      "Ep:27, loss:0.00009, loss_test:0.10114, lr:1.00e-02, fs:0.69512 (r=0.576,p=0.877),  time:114.604, tt:3208.913\n",
      "Ep:28, loss:0.00008, loss_test:0.09700, lr:1.00e-02, fs:0.70659 (r=0.596,p=0.868),  time:114.603, tt:3323.490\n",
      "Ep:29, loss:0.00008, loss_test:0.10479, lr:1.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:114.612, tt:3438.346\n",
      "Ep:30, loss:0.00007, loss_test:0.10480, lr:9.90e-03, fs:0.70807 (r=0.576,p=0.919),  time:114.671, tt:3554.800\n",
      "Ep:31, loss:0.00007, loss_test:0.10060, lr:9.80e-03, fs:0.69939 (r=0.576,p=0.891),  time:114.726, tt:3671.228\n",
      "Ep:32, loss:0.00007, loss_test:0.09971, lr:9.70e-03, fs:0.72393 (r=0.596,p=0.922),  time:114.692, tt:3784.851\n",
      "Ep:33, loss:0.00006, loss_test:0.10271, lr:9.61e-03, fs:0.69939 (r=0.576,p=0.891),  time:114.780, tt:3902.514\n",
      "Ep:34, loss:0.00006, loss_test:0.10978, lr:9.51e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.738, tt:4015.825\n",
      "Ep:35, loss:0.00005, loss_test:0.10831, lr:9.41e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.821, tt:4133.553\n",
      "Ep:36, loss:0.00005, loss_test:0.10819, lr:9.32e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.757, tt:4246.012\n",
      "Ep:37, loss:0.00005, loss_test:0.10985, lr:9.23e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.748, tt:4360.439\n",
      "Ep:38, loss:0.00004, loss_test:0.10365, lr:9.14e-03, fs:0.70370 (r=0.576,p=0.905),  time:114.775, tt:4476.210\n",
      "Ep:39, loss:0.00004, loss_test:0.10663, lr:9.04e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.755, tt:4590.181\n",
      "Ep:40, loss:0.00004, loss_test:0.11471, lr:8.95e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.747, tt:4704.609\n",
      "Ep:41, loss:0.00004, loss_test:0.10817, lr:8.86e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.772, tt:4820.428\n",
      "Ep:42, loss:0.00003, loss_test:0.10976, lr:8.78e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.789, tt:4935.935\n",
      "Ep:43, loss:0.00003, loss_test:0.11297, lr:8.69e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.758, tt:5049.363\n",
      "Ep:44, loss:0.00003, loss_test:0.11566, lr:8.60e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.761, tt:5164.227\n",
      "Ep:45, loss:0.00003, loss_test:0.11134, lr:8.51e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.723, tt:5277.278\n",
      "Ep:46, loss:0.00003, loss_test:0.10885, lr:8.43e-03, fs:0.70807 (r=0.576,p=0.919),  time:114.682, tt:5390.062\n",
      "Ep:47, loss:0.00003, loss_test:0.10999, lr:8.35e-03, fs:0.70807 (r=0.576,p=0.919),  time:114.696, tt:5505.417\n",
      "Ep:48, loss:0.00002, loss_test:0.11508, lr:8.26e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.753, tt:5622.908\n",
      "Ep:49, loss:0.00002, loss_test:0.11470, lr:8.18e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.787, tt:5739.367\n",
      "Ep:50, loss:0.00002, loss_test:0.11292, lr:8.10e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.816, tt:5855.594\n",
      "Ep:51, loss:0.00002, loss_test:0.11340, lr:8.02e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.789, tt:5969.021\n",
      "Ep:52, loss:0.00002, loss_test:0.11324, lr:7.94e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.828, tt:6085.860\n",
      "Ep:53, loss:0.00002, loss_test:0.11342, lr:7.86e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.804, tt:6199.411\n",
      "Ep:54, loss:0.00002, loss_test:0.11368, lr:7.78e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.801, tt:6314.050\n",
      "Ep:55, loss:0.00002, loss_test:0.11354, lr:7.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.782, tt:6427.818\n",
      "Ep:56, loss:0.00002, loss_test:0.11264, lr:7.62e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.793, tt:6543.196\n",
      "Ep:57, loss:0.00002, loss_test:0.11364, lr:7.55e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.769, tt:6656.600\n",
      "Ep:58, loss:0.00002, loss_test:0.11446, lr:7.47e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.794, tt:6772.831\n",
      "Ep:59, loss:0.00001, loss_test:0.11311, lr:7.40e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.785, tt:6887.084\n",
      "Ep:60, loss:0.00001, loss_test:0.11444, lr:7.32e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.824, tt:7004.234\n",
      "Ep:61, loss:0.00001, loss_test:0.11383, lr:7.25e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.844, tt:7120.345\n",
      "Ep:62, loss:0.00001, loss_test:0.11518, lr:7.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.922, tt:7240.056\n",
      "Ep:63, loss:0.00001, loss_test:0.11487, lr:7.11e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.938, tt:7356.008\n",
      "Ep:64, loss:0.00001, loss_test:0.11245, lr:7.03e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.958, tt:7472.247\n",
      "Ep:65, loss:0.00001, loss_test:0.11434, lr:6.96e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.964, tt:7587.626\n",
      "Ep:66, loss:0.00001, loss_test:0.11634, lr:6.89e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.968, tt:7702.837\n",
      "Ep:67, loss:0.00001, loss_test:0.11542, lr:6.83e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.935, tt:7815.563\n",
      "Ep:68, loss:0.00001, loss_test:0.11578, lr:6.76e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.942, tt:7931.018\n",
      "Ep:69, loss:0.00001, loss_test:0.11651, lr:6.69e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.969, tt:8047.822\n",
      "Ep:70, loss:0.00001, loss_test:0.11567, lr:6.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.946, tt:8161.157\n",
      "Ep:71, loss:0.00001, loss_test:0.11509, lr:6.56e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.956, tt:8276.824\n",
      "Ep:72, loss:0.00001, loss_test:0.11665, lr:6.49e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.952, tt:8391.531\n",
      "Ep:73, loss:0.00001, loss_test:0.11646, lr:6.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.990, tt:8509.247\n",
      "Ep:74, loss:0.00001, loss_test:0.11703, lr:6.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:115.015, tt:8626.114\n",
      "Ep:75, loss:0.00001, loss_test:0.11518, lr:6.30e-03, fs:0.72152 (r=0.576,p=0.966),  time:115.038, tt:8742.861\n",
      "Ep:76, loss:0.00001, loss_test:0.11550, lr:6.24e-03, fs:0.72152 (r=0.576,p=0.966),  time:115.083, tt:8861.416\n",
      "Ep:77, loss:0.00001, loss_test:0.11425, lr:6.17e-03, fs:0.72152 (r=0.576,p=0.966),  time:115.035, tt:8972.764\n",
      "Ep:78, loss:0.00001, loss_test:0.11322, lr:6.11e-03, fs:0.72152 (r=0.576,p=0.966),  time:115.048, tt:9088.805\n",
      "Ep:79, loss:0.00001, loss_test:0.11425, lr:6.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:114.864, tt:9189.140\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00123, loss_test:0.12973, lr:1.00e-02, fs:0.68794 (r=0.980,p=0.530),  time:139.644, tt:139.644\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00108, loss_test:0.11076, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:142.749, tt:285.497\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00096, loss_test:0.10463, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:144.813, tt:434.438\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00085, loss_test:0.10038, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:146.311, tt:585.245\n",
      "Ep:4, loss:0.00077, loss_test:0.09635, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:147.338, tt:736.688\n",
      "Ep:5, loss:0.00070, loss_test:0.09318, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:147.593, tt:885.559\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00064, loss_test:0.08986, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:147.716, tt:1034.013\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00058, loss_test:0.08553, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:148.031, tt:1184.247\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00053, loss_test:0.08262, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:148.218, tt:1333.965\n",
      "Ep:9, loss:0.00048, loss_test:0.08116, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:148.266, tt:1482.656\n",
      "Ep:10, loss:0.00043, loss_test:0.07697, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:148.082, tt:1628.899\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00038, loss_test:0.07385, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:147.964, tt:1775.573\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00035, loss_test:0.07281, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:147.958, tt:1923.448\n",
      "Ep:13, loss:0.00031, loss_test:0.07154, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:148.005, tt:2072.068\n",
      "Ep:14, loss:0.00028, loss_test:0.06925, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:147.997, tt:2219.959\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.07048, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:148.128, tt:2370.045\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.06844, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:148.212, tt:2519.603\n",
      "Ep:17, loss:0.00021, loss_test:0.06810, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:148.075, tt:2665.345\n",
      "Ep:18, loss:0.00019, loss_test:0.06526, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:147.747, tt:2807.193\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.06808, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:147.328, tt:2946.559\n",
      "Ep:20, loss:0.00015, loss_test:0.06792, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:147.134, tt:3089.818\n",
      "Ep:21, loss:0.00014, loss_test:0.06581, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:146.911, tt:3232.043\n",
      "Ep:22, loss:0.00013, loss_test:0.06765, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:146.842, tt:3377.355\n",
      "Ep:23, loss:0.00012, loss_test:0.06863, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:146.929, tt:3526.286\n",
      "Ep:24, loss:0.00011, loss_test:0.06468, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:146.850, tt:3671.243\n",
      "Ep:25, loss:0.00010, loss_test:0.06726, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:146.976, tt:3821.374\n",
      "Ep:26, loss:0.00009, loss_test:0.06900, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:147.016, tt:3969.441\n",
      "Ep:27, loss:0.00009, loss_test:0.06871, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:146.925, tt:4113.893\n",
      "Ep:28, loss:0.00008, loss_test:0.06846, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:147.027, tt:4263.772\n",
      "Ep:29, loss:0.00008, loss_test:0.06771, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:147.007, tt:4410.224\n",
      "Ep:30, loss:0.00007, loss_test:0.06929, lr:9.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.092, tt:4559.852\n",
      "Ep:31, loss:0.00007, loss_test:0.06935, lr:9.80e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.195, tt:4710.227\n",
      "Ep:32, loss:0.00006, loss_test:0.06906, lr:9.70e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.321, tt:4861.591\n",
      "Ep:33, loss:0.00006, loss_test:0.07071, lr:9.61e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.387, tt:5011.159\n",
      "Ep:34, loss:0.00006, loss_test:0.07171, lr:9.51e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.362, tt:5157.659\n",
      "Ep:35, loss:0.00005, loss_test:0.07047, lr:9.41e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.300, tt:5302.806\n",
      "Ep:36, loss:0.00005, loss_test:0.07176, lr:9.32e-03, fs:0.83146 (r=0.747,p=0.937),  time:147.247, tt:5448.157\n",
      "Ep:37, loss:0.00005, loss_test:0.07272, lr:9.23e-03, fs:0.84091 (r=0.747,p=0.961),  time:147.221, tt:5594.405\n",
      "Ep:38, loss:0.00004, loss_test:0.07436, lr:9.14e-03, fs:0.83616 (r=0.747,p=0.949),  time:147.231, tt:5742.015\n",
      "Ep:39, loss:0.00004, loss_test:0.07478, lr:9.04e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.225, tt:5888.995\n",
      "Ep:40, loss:0.00004, loss_test:0.07511, lr:8.95e-03, fs:0.84091 (r=0.747,p=0.961),  time:147.173, tt:6034.103\n",
      "Ep:41, loss:0.00003, loss_test:0.07535, lr:8.86e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.153, tt:6180.410\n",
      "Ep:42, loss:0.00003, loss_test:0.07627, lr:8.78e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.161, tt:6327.925\n",
      "Ep:43, loss:0.00003, loss_test:0.07711, lr:8.69e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.175, tt:6475.685\n",
      "Ep:44, loss:0.00003, loss_test:0.07675, lr:8.60e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.196, tt:6623.834\n",
      "Ep:45, loss:0.00003, loss_test:0.07671, lr:8.51e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.225, tt:6772.341\n",
      "Ep:46, loss:0.00003, loss_test:0.07736, lr:8.43e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.213, tt:6918.997\n",
      "Ep:47, loss:0.00002, loss_test:0.07857, lr:8.35e-03, fs:0.84571 (r=0.747,p=0.974),  time:147.203, tt:7065.748\n",
      "Ep:48, loss:0.00002, loss_test:0.07947, lr:8.26e-03, fs:0.84393 (r=0.737,p=0.986),  time:147.207, tt:7213.167\n",
      "Ep:49, loss:0.00002, loss_test:0.07888, lr:8.18e-03, fs:0.83237 (r=0.727,p=0.973),  time:147.239, tt:7361.930\n",
      "Ep:50, loss:0.00002, loss_test:0.07919, lr:8.10e-03, fs:0.85057 (r=0.747,p=0.987),  time:147.245, tt:7509.501\n",
      "Ep:51, loss:0.00002, loss_test:0.07965, lr:8.02e-03, fs:0.85057 (r=0.747,p=0.987),  time:147.221, tt:7655.517\n",
      "Ep:52, loss:0.00002, loss_test:0.07910, lr:7.94e-03, fs:0.85549 (r=0.747,p=1.000),  time:147.239, tt:7803.687\n",
      "Ep:53, loss:0.00002, loss_test:0.07820, lr:7.86e-03, fs:0.85549 (r=0.747,p=1.000),  time:147.231, tt:7950.471\n",
      "Ep:54, loss:0.00002, loss_test:0.07954, lr:7.78e-03, fs:0.84884 (r=0.737,p=1.000),  time:147.281, tt:8100.435\n",
      "Ep:55, loss:0.00002, loss_test:0.08213, lr:7.70e-03, fs:0.83041 (r=0.717,p=0.986),  time:147.307, tt:8249.198\n",
      "Ep:56, loss:0.00002, loss_test:0.07829, lr:7.62e-03, fs:0.85549 (r=0.747,p=1.000),  time:147.374, tt:8400.301\n",
      "Ep:57, loss:0.00002, loss_test:0.07918, lr:7.55e-03, fs:0.85549 (r=0.747,p=1.000),  time:147.383, tt:8548.205\n",
      "Ep:58, loss:0.00001, loss_test:0.08027, lr:7.47e-03, fs:0.83529 (r=0.717,p=1.000),  time:147.446, tt:8699.340\n",
      "Ep:59, loss:0.00001, loss_test:0.08002, lr:7.40e-03, fs:0.83529 (r=0.717,p=1.000),  time:147.204, tt:8832.263\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00122, loss_test:0.13630, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:138.833, tt:138.833\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00104, loss_test:0.12381, lr:1.00e-02, fs:0.64423 (r=0.677,p=0.615),  time:143.094, tt:286.188\n",
      "Ep:2, loss:0.00092, loss_test:0.11979, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:144.142, tt:432.427\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00082, loss_test:0.12228, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:144.770, tt:579.081\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00073, loss_test:0.12185, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:144.836, tt:724.179\n",
      "Ep:5, loss:0.00067, loss_test:0.12221, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:146.296, tt:877.774\n",
      "Ep:6, loss:0.00060, loss_test:0.12209, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:146.648, tt:1026.537\n",
      "Ep:7, loss:0.00055, loss_test:0.12161, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:147.085, tt:1176.676\n",
      "Ep:8, loss:0.00049, loss_test:0.12456, lr:1.00e-02, fs:0.67039 (r=0.606,p=0.750),  time:147.030, tt:1323.272\n",
      "Ep:9, loss:0.00045, loss_test:0.12505, lr:1.00e-02, fs:0.67045 (r=0.596,p=0.766),  time:147.026, tt:1470.259\n",
      "Ep:10, loss:0.00041, loss_test:0.12511, lr:1.00e-02, fs:0.65089 (r=0.556,p=0.786),  time:147.130, tt:1618.426\n",
      "Ep:11, loss:0.00037, loss_test:0.12273, lr:1.00e-02, fs:0.68539 (r=0.616,p=0.772),  time:147.268, tt:1767.217\n",
      "Ep:12, loss:0.00033, loss_test:0.12322, lr:1.00e-02, fs:0.66279 (r=0.576,p=0.781),  time:147.250, tt:1914.244\n",
      "Ep:13, loss:0.00030, loss_test:0.12089, lr:1.00e-02, fs:0.67816 (r=0.596,p=0.787),  time:147.262, tt:2061.663\n",
      "Ep:14, loss:0.00027, loss_test:0.12467, lr:1.00e-02, fs:0.67470 (r=0.566,p=0.836),  time:147.648, tt:2214.715\n",
      "Ep:15, loss:0.00024, loss_test:0.12543, lr:9.90e-03, fs:0.69048 (r=0.586,p=0.841),  time:147.618, tt:2361.883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00022, loss_test:0.12485, lr:9.80e-03, fs:0.66667 (r=0.556,p=0.833),  time:147.436, tt:2506.415\n",
      "Ep:17, loss:0.00020, loss_test:0.12459, lr:9.70e-03, fs:0.68263 (r=0.576,p=0.838),  time:147.487, tt:2654.762\n",
      "Ep:18, loss:0.00018, loss_test:0.12530, lr:9.61e-03, fs:0.66265 (r=0.556,p=0.821),  time:147.439, tt:2801.340\n",
      "Ep:19, loss:0.00017, loss_test:0.12560, lr:9.51e-03, fs:0.68263 (r=0.576,p=0.838),  time:147.505, tt:2950.092\n",
      "Ep:20, loss:0.00015, loss_test:0.13068, lr:9.41e-03, fs:0.63750 (r=0.515,p=0.836),  time:147.400, tt:3095.395\n",
      "Ep:21, loss:0.00014, loss_test:0.12842, lr:9.32e-03, fs:0.65432 (r=0.535,p=0.841),  time:147.434, tt:3243.550\n",
      "Ep:22, loss:0.00013, loss_test:0.12968, lr:9.23e-03, fs:0.63354 (r=0.515,p=0.823),  time:147.635, tt:3395.597\n",
      "Ep:23, loss:0.00012, loss_test:0.12800, lr:9.14e-03, fs:0.62500 (r=0.505,p=0.820),  time:147.722, tt:3545.319\n",
      "Ep:24, loss:0.00011, loss_test:0.12862, lr:9.04e-03, fs:0.61635 (r=0.495,p=0.817),  time:147.704, tt:3692.606\n",
      "Ep:25, loss:0.00010, loss_test:0.12868, lr:8.95e-03, fs:0.62025 (r=0.495,p=0.831),  time:147.792, tt:3842.597\n",
      "Ep:26, loss:0.00010, loss_test:0.13183, lr:8.86e-03, fs:0.60131 (r=0.465,p=0.852),  time:147.728, tt:3988.660\n",
      "Ep:27, loss:0.00009, loss_test:0.13023, lr:8.78e-03, fs:0.60131 (r=0.465,p=0.852),  time:147.732, tt:4136.507\n",
      "Ep:28, loss:0.00008, loss_test:0.13032, lr:8.69e-03, fs:0.60645 (r=0.475,p=0.839),  time:147.790, tt:4285.898\n",
      "Ep:29, loss:0.00008, loss_test:0.13077, lr:8.60e-03, fs:0.64557 (r=0.515,p=0.864),  time:147.690, tt:4430.707\n",
      "Ep:30, loss:0.00007, loss_test:0.13129, lr:8.51e-03, fs:0.58278 (r=0.444,p=0.846),  time:147.746, tt:4580.118\n",
      "Ep:31, loss:0.00007, loss_test:0.13317, lr:8.43e-03, fs:0.61039 (r=0.475,p=0.855),  time:147.772, tt:4728.709\n",
      "Ep:32, loss:0.00007, loss_test:0.13313, lr:8.35e-03, fs:0.58667 (r=0.444,p=0.863),  time:147.731, tt:4875.135\n",
      "Ep:33, loss:0.00006, loss_test:0.13281, lr:8.26e-03, fs:0.59603 (r=0.455,p=0.865),  time:147.805, tt:5025.373\n",
      "Ep:34, loss:0.00006, loss_test:0.13379, lr:8.18e-03, fs:0.58108 (r=0.434,p=0.878),  time:147.817, tt:5173.604\n",
      "Ep:35, loss:0.00006, loss_test:0.13375, lr:8.10e-03, fs:0.58503 (r=0.434,p=0.896),  time:147.901, tt:5324.430\n",
      "Ep:36, loss:0.00005, loss_test:0.13419, lr:8.02e-03, fs:0.58108 (r=0.434,p=0.878),  time:147.923, tt:5473.162\n",
      "Ep:37, loss:0.00005, loss_test:0.13683, lr:7.94e-03, fs:0.59310 (r=0.434,p=0.935),  time:147.993, tt:5623.753\n",
      "Ep:38, loss:0.00005, loss_test:0.13568, lr:7.86e-03, fs:0.57718 (r=0.434,p=0.860),  time:147.977, tt:5771.084\n",
      "Ep:39, loss:0.00005, loss_test:0.13603, lr:7.78e-03, fs:0.59310 (r=0.434,p=0.935),  time:147.928, tt:5917.123\n",
      "Ep:40, loss:0.00005, loss_test:0.13956, lr:7.70e-03, fs:0.59722 (r=0.434,p=0.956),  time:147.924, tt:6064.867\n",
      "Ep:41, loss:0.00004, loss_test:0.13567, lr:7.62e-03, fs:0.58503 (r=0.434,p=0.896),  time:148.037, tt:6217.534\n",
      "Ep:42, loss:0.00004, loss_test:0.13617, lr:7.55e-03, fs:0.59310 (r=0.434,p=0.935),  time:148.052, tt:6366.237\n",
      "Ep:43, loss:0.00004, loss_test:0.13810, lr:7.47e-03, fs:0.59310 (r=0.434,p=0.935),  time:148.068, tt:6514.984\n",
      "Ep:44, loss:0.00004, loss_test:0.14011, lr:7.40e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.062, tt:6662.779\n",
      "Ep:45, loss:0.00004, loss_test:0.13852, lr:7.32e-03, fs:0.59310 (r=0.434,p=0.935),  time:148.080, tt:6811.670\n",
      "Ep:46, loss:0.00003, loss_test:0.13956, lr:7.25e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.087, tt:6960.089\n",
      "Ep:47, loss:0.00003, loss_test:0.14073, lr:7.18e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.109, tt:7109.212\n",
      "Ep:48, loss:0.00003, loss_test:0.14068, lr:7.11e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.144, tt:7259.036\n",
      "Ep:49, loss:0.00003, loss_test:0.14044, lr:7.03e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.146, tt:7407.311\n",
      "Ep:50, loss:0.00003, loss_test:0.13948, lr:6.96e-03, fs:0.60140 (r=0.434,p=0.977),  time:148.132, tt:7554.748\n",
      "Ep:51, loss:0.00003, loss_test:0.14157, lr:6.89e-03, fs:0.60140 (r=0.434,p=0.977),  time:148.122, tt:7702.362\n",
      "Ep:52, loss:0.00003, loss_test:0.14241, lr:6.83e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.118, tt:7850.273\n",
      "Ep:53, loss:0.00003, loss_test:0.14113, lr:6.76e-03, fs:0.59722 (r=0.434,p=0.956),  time:148.065, tt:7995.536\n",
      "Ep:54, loss:0.00002, loss_test:0.14028, lr:6.69e-03, fs:0.60140 (r=0.434,p=0.977),  time:148.042, tt:8142.323\n",
      "Ep:55, loss:0.00002, loss_test:0.14215, lr:6.62e-03, fs:0.60140 (r=0.434,p=0.977),  time:148.060, tt:8291.384\n",
      "Ep:56, loss:0.00002, loss_test:0.14217, lr:6.56e-03, fs:0.59722 (r=0.434,p=0.956),  time:147.975, tt:8434.591\n",
      "Ep:57, loss:0.00002, loss_test:0.14202, lr:6.49e-03, fs:0.60140 (r=0.434,p=0.977),  time:147.950, tt:8581.125\n",
      "Ep:58, loss:0.00002, loss_test:0.14022, lr:6.43e-03, fs:0.59722 (r=0.434,p=0.956),  time:147.980, tt:8730.840\n",
      "Ep:59, loss:0.00002, loss_test:0.13962, lr:6.36e-03, fs:0.59722 (r=0.434,p=0.956),  time:147.650, tt:8859.004\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00402, loss_test:0.09352, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:554.404, tt:554.404\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00257, loss_test:0.08146, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:558.117, tt:1116.234\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00170, loss_test:0.08006, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:558.867, tt:1676.600\n",
      "Ep:3, loss:0.00109, loss_test:0.08265, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:559.100, tt:2236.402\n",
      "Ep:4, loss:0.00070, loss_test:0.08160, lr:1.00e-02, fs:0.80473 (r=0.687,p=0.971),  time:560.299, tt:2801.493\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.08362, lr:1.00e-02, fs:0.81437 (r=0.687,p=1.000),  time:559.939, tt:3359.636\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.08585, lr:1.00e-02, fs:0.81437 (r=0.687,p=1.000),  time:560.687, tt:3924.810\n",
      "Ep:7, loss:0.00020, loss_test:0.09817, lr:1.00e-02, fs:0.79268 (r=0.657,p=1.000),  time:561.233, tt:4489.865\n",
      "Ep:8, loss:0.00014, loss_test:0.09584, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:561.876, tt:5056.886\n",
      "Ep:9, loss:0.00010, loss_test:0.10208, lr:1.00e-02, fs:0.73885 (r=0.586,p=1.000),  time:561.563, tt:5615.630\n",
      "Ep:10, loss:0.00008, loss_test:0.09849, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:561.727, tt:6178.994\n",
      "Ep:11, loss:0.00006, loss_test:0.10200, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:561.976, tt:6743.713\n",
      "Ep:12, loss:0.00005, loss_test:0.10203, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:561.892, tt:7304.600\n",
      "Ep:13, loss:0.00004, loss_test:0.10498, lr:1.00e-02, fs:0.73885 (r=0.586,p=1.000),  time:561.993, tt:7867.906\n",
      "Ep:14, loss:0.00003, loss_test:0.10246, lr:1.00e-02, fs:0.81437 (r=0.687,p=1.000),  time:562.195, tt:8432.925\n",
      "Ep:15, loss:0.00003, loss_test:0.10445, lr:1.00e-02, fs:0.73885 (r=0.586,p=1.000),  time:561.538, tt:8984.612\n",
      "Ep:16, loss:0.00003, loss_test:0.10326, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:560.973, tt:9536.536\n",
      "Ep:17, loss:0.00002, loss_test:0.10424, lr:9.90e-03, fs:0.77778 (r=0.636,p=1.000),  time:560.563, tt:10090.135\n",
      "Ep:18, loss:0.00002, loss_test:0.10607, lr:9.80e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.894, tt:10637.994\n",
      "Ep:19, loss:0.00002, loss_test:0.10392, lr:9.70e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.088, tt:11181.769\n",
      "Ep:20, loss:0.00002, loss_test:0.10454, lr:9.61e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.879, tt:11736.460\n",
      "Ep:21, loss:0.00001, loss_test:0.10325, lr:9.51e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.941, tt:12296.696\n",
      "Ep:22, loss:0.00001, loss_test:0.10332, lr:9.41e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.785, tt:12852.066\n",
      "Ep:23, loss:0.00001, loss_test:0.10375, lr:9.32e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.887, tt:13413.297\n",
      "Ep:24, loss:0.00001, loss_test:0.10358, lr:9.23e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.994, tt:13974.861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00001, loss_test:0.10274, lr:9.14e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.731, tt:14527.000\n",
      "Ep:26, loss:0.00001, loss_test:0.10334, lr:9.04e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.664, tt:15083.927\n",
      "Ep:27, loss:0.00001, loss_test:0.10452, lr:8.95e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.178, tt:15628.986\n",
      "Ep:28, loss:0.00001, loss_test:0.10314, lr:8.86e-03, fs:0.73885 (r=0.586,p=1.000),  time:557.953, tt:16180.637\n",
      "Ep:29, loss:0.00001, loss_test:0.10236, lr:8.78e-03, fs:0.73885 (r=0.586,p=1.000),  time:556.975, tt:16709.253\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00403, loss_test:0.09244, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:534.109, tt:534.109\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00262, loss_test:0.07622, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:551.174, tt:1102.348\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00183, loss_test:0.06974, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:552.343, tt:1657.029\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00122, loss_test:0.06667, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:552.538, tt:2210.151\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00077, loss_test:0.06352, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:554.304, tt:2771.521\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00050, loss_test:0.06255, lr:1.00e-02, fs:0.90710 (r=0.838,p=0.988),  time:555.600, tt:3333.599\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.06002, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:556.008, tt:3892.053\n",
      "Ep:7, loss:0.00023, loss_test:0.06470, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:554.832, tt:4438.652\n",
      "Ep:8, loss:0.00016, loss_test:0.06416, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:554.351, tt:4989.155\n",
      "Ep:9, loss:0.00012, loss_test:0.06467, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:553.511, tt:5535.110\n",
      "Ep:10, loss:0.00009, loss_test:0.06829, lr:1.00e-02, fs:0.85057 (r=0.747,p=0.987),  time:552.699, tt:6079.685\n",
      "Ep:11, loss:0.00007, loss_test:0.06721, lr:1.00e-02, fs:0.85714 (r=0.758,p=0.987),  time:551.851, tt:6622.212\n",
      "Ep:12, loss:0.00006, loss_test:0.06614, lr:1.00e-02, fs:0.85057 (r=0.747,p=0.987),  time:551.644, tt:7171.374\n",
      "Ep:13, loss:0.00004, loss_test:0.06844, lr:1.00e-02, fs:0.85549 (r=0.747,p=1.000),  time:550.907, tt:7712.702\n",
      "Ep:14, loss:0.00004, loss_test:0.06947, lr:1.00e-02, fs:0.85549 (r=0.747,p=1.000),  time:551.004, tt:8265.066\n",
      "Ep:15, loss:0.00003, loss_test:0.06698, lr:1.00e-02, fs:0.85549 (r=0.747,p=1.000),  time:550.863, tt:8813.805\n",
      "Ep:16, loss:0.00003, loss_test:0.06791, lr:1.00e-02, fs:0.85549 (r=0.747,p=1.000),  time:550.788, tt:9363.405\n",
      "Ep:17, loss:0.00002, loss_test:0.06767, lr:9.90e-03, fs:0.85549 (r=0.747,p=1.000),  time:550.815, tt:9914.672\n",
      "Ep:18, loss:0.00002, loss_test:0.06941, lr:9.80e-03, fs:0.85549 (r=0.747,p=1.000),  time:550.633, tt:10462.027\n",
      "Ep:19, loss:0.00002, loss_test:0.06917, lr:9.70e-03, fs:0.85549 (r=0.747,p=1.000),  time:550.431, tt:11008.614\n",
      "Ep:20, loss:0.00002, loss_test:0.07037, lr:9.61e-03, fs:0.85549 (r=0.747,p=1.000),  time:550.191, tt:11554.004\n",
      "Ep:21, loss:0.00002, loss_test:0.06995, lr:9.51e-03, fs:0.85549 (r=0.747,p=1.000),  time:549.966, tt:12099.251\n",
      "Ep:22, loss:0.00002, loss_test:0.06951, lr:9.41e-03, fs:0.85057 (r=0.747,p=0.987),  time:549.341, tt:12634.853\n",
      "Ep:23, loss:0.00001, loss_test:0.07075, lr:9.32e-03, fs:0.85549 (r=0.747,p=1.000),  time:549.237, tt:13181.688\n",
      "Ep:24, loss:0.00001, loss_test:0.06982, lr:9.23e-03, fs:0.85549 (r=0.747,p=1.000),  time:549.049, tt:13726.234\n",
      "Ep:25, loss:0.00001, loss_test:0.06938, lr:9.14e-03, fs:0.85057 (r=0.747,p=0.987),  time:548.824, tt:14269.416\n",
      "Ep:26, loss:0.00001, loss_test:0.06968, lr:9.04e-03, fs:0.85057 (r=0.747,p=0.987),  time:548.737, tt:14815.889\n",
      "Ep:27, loss:0.00001, loss_test:0.06991, lr:8.95e-03, fs:0.85057 (r=0.747,p=0.987),  time:548.702, tt:15363.652\n",
      "Ep:28, loss:0.00001, loss_test:0.06894, lr:8.86e-03, fs:0.85057 (r=0.747,p=0.987),  time:548.711, tt:15912.624\n",
      "Ep:29, loss:0.00001, loss_test:0.06901, lr:8.78e-03, fs:0.85057 (r=0.747,p=0.987),  time:546.123, tt:16383.703\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,6,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,80,cv_number,8,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,10,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,0,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14023, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:24.395, tt:24.395\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13880, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:26.003, tt:52.006\n",
      "Ep:2, loss:0.00027, loss_test:0.13642, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:26.356, tt:79.068\n",
      "Ep:3, loss:0.00027, loss_test:0.13287, lr:1.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:26.481, tt:105.922\n",
      "Ep:4, loss:0.00026, loss_test:0.12831, lr:1.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:26.648, tt:133.242\n",
      "Ep:5, loss:0.00024, loss_test:0.12384, lr:1.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:26.777, tt:160.662\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.12269, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:26.757, tt:187.300\n",
      "Ep:7, loss:0.00023, loss_test:0.12176, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:26.767, tt:214.136\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11927, lr:1.00e-02, fs:0.66029 (r=0.697,p=0.627),  time:26.642, tt:239.779\n",
      "Ep:9, loss:0.00022, loss_test:0.11642, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:26.632, tt:266.318\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.11458, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:26.576, tt:292.336\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11404, lr:1.00e-02, fs:0.69159 (r=0.747,p=0.643),  time:26.642, tt:319.709\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.11353, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:26.584, tt:345.590\n",
      "Ep:13, loss:0.00020, loss_test:0.11137, lr:1.00e-02, fs:0.68293 (r=0.707,p=0.660),  time:26.602, tt:372.421\n",
      "Ep:14, loss:0.00019, loss_test:0.10901, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:26.522, tt:397.824\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10727, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:26.653, tt:426.446\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10553, lr:1.00e-02, fs:0.71204 (r=0.687,p=0.739),  time:26.792, tt:455.466\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10394, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:26.941, tt:484.945\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10228, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:27.074, tt:514.414\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10102, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:27.112, tt:542.249\n",
      "Ep:20, loss:0.00017, loss_test:0.10065, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:27.211, tt:571.429\n",
      "Ep:21, loss:0.00016, loss_test:0.09937, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:27.268, tt:599.897\n",
      "Ep:22, loss:0.00016, loss_test:0.09764, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:27.327, tt:628.532\n",
      "Ep:23, loss:0.00016, loss_test:0.09724, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:27.383, tt:657.191\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09676, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:27.412, tt:685.311\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09466, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:27.511, tt:715.283\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.09462, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:27.557, tt:744.031\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09455, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:27.587, tt:772.445\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.09292, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:27.639, tt:801.533\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09221, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:27.684, tt:830.514\n",
      "Ep:30, loss:0.00013, loss_test:0.09268, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:27.726, tt:859.497\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09073, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:27.721, tt:887.077\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.09115, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:27.731, tt:915.129\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.09077, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:27.756, tt:943.688\n",
      "Ep:34, loss:0.00012, loss_test:0.08969, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:27.773, tt:972.042\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08882, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:27.772, tt:999.774\n",
      "Ep:36, loss:0.00012, loss_test:0.08865, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:27.805, tt:1028.798\n",
      "Ep:37, loss:0.00011, loss_test:0.08879, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:27.819, tt:1057.114\n",
      "Ep:38, loss:0.00011, loss_test:0.08672, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:27.834, tt:1085.516\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08725, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:27.787, tt:1111.469\n",
      "Ep:40, loss:0.00011, loss_test:0.08674, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:27.789, tt:1139.341\n",
      "Ep:41, loss:0.00010, loss_test:0.08425, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:27.810, tt:1168.000\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.08539, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:27.842, tt:1197.213\n",
      "Ep:43, loss:0.00010, loss_test:0.08333, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:27.824, tt:1224.274\n",
      "Ep:44, loss:0.00010, loss_test:0.08519, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:27.841, tt:1252.832\n",
      "Ep:45, loss:0.00009, loss_test:0.08206, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.854, tt:1281.288\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.08291, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:27.844, tt:1308.665\n",
      "Ep:47, loss:0.00009, loss_test:0.08269, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.861, tt:1337.311\n",
      "Ep:48, loss:0.00009, loss_test:0.08164, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.866, tt:1365.438\n",
      "Ep:49, loss:0.00008, loss_test:0.07982, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.823, tt:1391.173\n",
      "Ep:50, loss:0.00008, loss_test:0.08166, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.797, tt:1417.633\n",
      "Ep:51, loss:0.00008, loss_test:0.08041, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.802, tt:1445.721\n",
      "Ep:52, loss:0.00008, loss_test:0.07871, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.798, tt:1473.276\n",
      "Ep:53, loss:0.00008, loss_test:0.08010, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:27.809, tt:1501.664\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07779, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.829, tt:1530.573\n",
      "Ep:55, loss:0.00007, loss_test:0.07896, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.827, tt:1558.320\n",
      "Ep:56, loss:0.00007, loss_test:0.07970, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:27.853, tt:1587.648\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.07793, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:27.864, tt:1616.104\n",
      "Ep:58, loss:0.00007, loss_test:0.07711, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:27.892, tt:1645.642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00007, loss_test:0.07784, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.892, tt:1673.493\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.07768, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:27.904, tt:1702.162\n",
      "Ep:61, loss:0.00006, loss_test:0.07658, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.901, tt:1729.885\n",
      "Ep:62, loss:0.00006, loss_test:0.07590, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.952, tt:1760.957\n",
      "Ep:63, loss:0.00006, loss_test:0.07850, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:27.966, tt:1789.816\n",
      "Ep:64, loss:0.00006, loss_test:0.07435, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.971, tt:1818.124\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.07857, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.977, tt:1846.476\n",
      "Ep:66, loss:0.00006, loss_test:0.07657, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.979, tt:1874.599\n",
      "Ep:67, loss:0.00005, loss_test:0.07418, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.995, tt:1903.667\n",
      "Ep:68, loss:0.00005, loss_test:0.07654, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.991, tt:1931.374\n",
      "Ep:69, loss:0.00005, loss_test:0.07427, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.997, tt:1959.797\n",
      "Ep:70, loss:0.00005, loss_test:0.07592, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:28.006, tt:1988.416\n",
      "Ep:71, loss:0.00005, loss_test:0.07745, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.989, tt:2015.207\n",
      "Ep:72, loss:0.00005, loss_test:0.07491, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.986, tt:2042.946\n",
      "Ep:73, loss:0.00005, loss_test:0.07916, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:28.006, tt:2072.473\n",
      "Ep:74, loss:0.00005, loss_test:0.07466, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.997, tt:2099.780\n",
      "Ep:75, loss:0.00005, loss_test:0.07785, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:28.013, tt:2129.011\n",
      "Ep:76, loss:0.00005, loss_test:0.07712, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.035, tt:2158.727\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.07410, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.044, tt:2187.434\n",
      "Ep:78, loss:0.00004, loss_test:0.08004, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.061, tt:2216.793\n",
      "Ep:79, loss:0.00004, loss_test:0.07173, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.036, tt:2242.872\n",
      "Ep:80, loss:0.00004, loss_test:0.07833, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.038, tt:2271.117\n",
      "Ep:81, loss:0.00004, loss_test:0.07299, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.028, tt:2298.332\n",
      "Ep:82, loss:0.00004, loss_test:0.07649, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.034, tt:2326.851\n",
      "Ep:83, loss:0.00004, loss_test:0.07769, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.050, tt:2356.210\n",
      "Ep:84, loss:0.00004, loss_test:0.07130, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.079, tt:2386.675\n",
      "Ep:85, loss:0.00004, loss_test:0.07895, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.078, tt:2414.677\n",
      "Ep:86, loss:0.00004, loss_test:0.07320, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.078, tt:2442.794\n",
      "Ep:87, loss:0.00003, loss_test:0.07379, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.097, tt:2472.559\n",
      "Ep:88, loss:0.00003, loss_test:0.07693, lr:9.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.105, tt:2501.363\n",
      "Ep:89, loss:0.00003, loss_test:0.07229, lr:9.70e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.098, tt:2528.798\n",
      "Ep:90, loss:0.00003, loss_test:0.07570, lr:9.61e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.112, tt:2558.234\n",
      "Ep:91, loss:0.00003, loss_test:0.07269, lr:9.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.098, tt:2585.057\n",
      "Ep:92, loss:0.00003, loss_test:0.07406, lr:9.41e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.098, tt:2613.124\n",
      "Ep:93, loss:0.00003, loss_test:0.07431, lr:9.32e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.113, tt:2642.644\n",
      "Ep:94, loss:0.00003, loss_test:0.07300, lr:9.23e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.124, tt:2671.827\n",
      "Ep:95, loss:0.00003, loss_test:0.07447, lr:9.14e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.127, tt:2700.152\n",
      "Ep:96, loss:0.00003, loss_test:0.07423, lr:9.04e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.123, tt:2727.966\n",
      "Ep:97, loss:0.00003, loss_test:0.07424, lr:8.95e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.124, tt:2756.106\n",
      "Ep:98, loss:0.00003, loss_test:0.07556, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.137, tt:2785.561\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00003, loss_test:0.07181, lr:8.86e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.125, tt:2812.504\n",
      "Ep:100, loss:0.00003, loss_test:0.07747, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.124, tt:2840.524\n",
      "Ep:101, loss:0.00003, loss_test:0.07261, lr:8.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.136, tt:2869.831\n",
      "Ep:102, loss:0.00003, loss_test:0.07380, lr:8.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.150, tt:2899.446\n",
      "Ep:103, loss:0.00003, loss_test:0.07610, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.145, tt:2927.089\n",
      "Ep:104, loss:0.00002, loss_test:0.07054, lr:8.86e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.150, tt:2955.724\n",
      "Ep:105, loss:0.00002, loss_test:0.07641, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.153, tt:2984.195\n",
      "Ep:106, loss:0.00002, loss_test:0.07417, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.164, tt:3013.558\n",
      "Ep:107, loss:0.00002, loss_test:0.07175, lr:8.86e-03, fs:0.86957 (r=0.808,p=0.941),  time:28.163, tt:3041.640\n",
      "Ep:108, loss:0.00002, loss_test:0.07675, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.155, tt:3068.869\n",
      "Ep:109, loss:0.00002, loss_test:0.07279, lr:8.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.173, tt:3099.048\n",
      "Ep:110, loss:0.00002, loss_test:0.07415, lr:8.78e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.186, tt:3128.691\n",
      "Ep:111, loss:0.00002, loss_test:0.07502, lr:8.69e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.204, tt:3158.895\n",
      "Ep:112, loss:0.00002, loss_test:0.07193, lr:8.60e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.219, tt:3188.799\n",
      "Ep:113, loss:0.00002, loss_test:0.07537, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.231, tt:3218.328\n",
      "Ep:114, loss:0.00002, loss_test:0.07358, lr:8.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.252, tt:3249.027\n",
      "Ep:115, loss:0.00002, loss_test:0.07422, lr:8.35e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.284, tt:3280.983\n",
      "Ep:116, loss:0.00002, loss_test:0.07394, lr:8.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.321, tt:3313.602\n",
      "Ep:117, loss:0.00002, loss_test:0.07362, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.339, tt:3343.976\n",
      "Ep:118, loss:0.00002, loss_test:0.07322, lr:8.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.356, tt:3374.373\n",
      "Ep:119, loss:0.00002, loss_test:0.07543, lr:8.02e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.382, tt:3405.824\n",
      "Ep:120, loss:0.00002, loss_test:0.07187, lr:7.94e-03, fs:0.87432 (r=0.808,p=0.952),  time:28.393, tt:3435.605\n",
      "Ep:121, loss:0.00002, loss_test:0.07600, lr:7.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.428, tt:3468.181\n",
      "Ep:122, loss:0.00002, loss_test:0.07306, lr:7.78e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.459, tt:3500.438\n",
      "Ep:123, loss:0.00002, loss_test:0.07348, lr:7.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.492, tt:3533.045\n",
      "Ep:124, loss:0.00002, loss_test:0.07447, lr:7.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.527, tt:3565.889\n",
      "Ep:125, loss:0.00002, loss_test:0.07377, lr:7.55e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.550, tt:3597.245\n",
      "Ep:126, loss:0.00002, loss_test:0.07330, lr:7.47e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.571, tt:3628.514\n",
      "Ep:127, loss:0.00002, loss_test:0.07469, lr:7.40e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.586, tt:3658.977\n",
      "Ep:128, loss:0.00002, loss_test:0.07297, lr:7.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.617, tt:3691.616\n",
      "Ep:129, loss:0.00002, loss_test:0.07460, lr:7.25e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.641, tt:3723.287\n",
      "Ep:130, loss:0.00002, loss_test:0.07328, lr:7.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:28.657, tt:3754.066\n",
      "Ep:131, loss:0.00002, loss_test:0.07404, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:28.678, tt:3785.466\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00002, loss_test:0.07384, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:28.688, tt:3815.509\n",
      "Ep:133, loss:0.00002, loss_test:0.07336, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:28.699, tt:3845.708\n",
      "Ep:134, loss:0.00002, loss_test:0.07349, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:28.717, tt:3876.835\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00002, loss_test:0.07388, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:28.702, tt:3903.512\n",
      "Ep:136, loss:0.00002, loss_test:0.07346, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:28.709, tt:3933.065\n",
      "Ep:137, loss:0.00002, loss_test:0.07428, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:28.720, tt:3963.416\n",
      "Ep:138, loss:0.00002, loss_test:0.07252, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:28.733, tt:3993.880\n",
      "Ep:139, loss:0.00002, loss_test:0.07496, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:28.726, tt:4021.674\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14333, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.523, tt:31.523\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14233, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.862, tt:63.725\n",
      "Ep:2, loss:0.00027, loss_test:0.14062, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:31.635, tt:94.905\n",
      "Ep:3, loss:0.00027, loss_test:0.13781, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:31.848, tt:127.392\n",
      "Ep:4, loss:0.00026, loss_test:0.13362, lr:1.00e-02, fs:0.64029 (r=0.899,p=0.497),  time:31.732, tt:158.659\n",
      "Ep:5, loss:0.00025, loss_test:0.12812, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:31.698, tt:190.187\n",
      "Ep:6, loss:0.00024, loss_test:0.12436, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:31.509, tt:220.566\n",
      "Ep:7, loss:0.00023, loss_test:0.12308, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:31.465, tt:251.721\n",
      "Ep:8, loss:0.00022, loss_test:0.12235, lr:1.00e-02, fs:0.63000 (r=0.636,p=0.624),  time:31.565, tt:284.088\n",
      "Ep:9, loss:0.00022, loss_test:0.12101, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:31.618, tt:316.183\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.11924, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:31.761, tt:349.372\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11706, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:31.857, tt:382.278\n",
      "Ep:12, loss:0.00020, loss_test:0.11421, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:31.884, tt:414.490\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.11167, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:31.876, tt:446.263\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10978, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:31.952, tt:479.284\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10839, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:31.878, tt:510.053\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10649, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:31.885, tt:542.042\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10401, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:31.863, tt:573.536\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10286, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:31.839, tt:604.938\n",
      "Ep:19, loss:0.00017, loss_test:0.10224, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:31.824, tt:636.477\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10148, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:31.803, tt:667.866\n",
      "Ep:21, loss:0.00016, loss_test:0.10042, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:31.794, tt:699.478\n",
      "Ep:22, loss:0.00015, loss_test:0.09987, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:31.785, tt:731.045\n",
      "Ep:23, loss:0.00015, loss_test:0.09923, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:31.774, tt:762.572\n",
      "Ep:24, loss:0.00015, loss_test:0.09838, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:31.788, tt:794.705\n",
      "Ep:25, loss:0.00014, loss_test:0.09769, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:31.789, tt:826.524\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09711, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:31.800, tt:858.597\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09612, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:31.756, tt:889.166\n",
      "Ep:28, loss:0.00013, loss_test:0.09524, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:31.714, tt:919.719\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09457, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:31.755, tt:952.649\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.09374, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:31.773, tt:984.978\n",
      "Ep:31, loss:0.00012, loss_test:0.09310, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:31.762, tt:1016.397\n",
      "Ep:32, loss:0.00012, loss_test:0.09259, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:31.796, tt:1049.280\n",
      "Ep:33, loss:0.00012, loss_test:0.09194, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:31.765, tt:1080.019\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.09104, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:31.707, tt:1109.753\n",
      "Ep:35, loss:0.00011, loss_test:0.09053, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:31.701, tt:1141.244\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.09003, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:31.719, tt:1173.589\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08956, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:31.729, tt:1205.697\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.08945, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:31.766, tt:1238.882\n",
      "Ep:39, loss:0.00010, loss_test:0.08913, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:31.777, tt:1271.077\n",
      "Ep:40, loss:0.00010, loss_test:0.08856, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:31.764, tt:1302.324\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.08828, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:31.798, tt:1335.501\n",
      "Ep:42, loss:0.00010, loss_test:0.08793, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:31.815, tt:1368.028\n",
      "Ep:43, loss:0.00010, loss_test:0.08723, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:31.819, tt:1400.055\n",
      "Ep:44, loss:0.00009, loss_test:0.08741, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.823, tt:1432.031\n",
      "Ep:45, loss:0.00009, loss_test:0.08610, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:31.810, tt:1463.250\n",
      "Ep:46, loss:0.00009, loss_test:0.08600, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:31.854, tt:1497.146\n",
      "Ep:47, loss:0.00009, loss_test:0.08567, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.830, tt:1527.821\n",
      "Ep:48, loss:0.00008, loss_test:0.08502, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:31.833, tt:1559.816\n",
      "Ep:49, loss:0.00008, loss_test:0.08510, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.832, tt:1591.607\n",
      "Ep:50, loss:0.00008, loss_test:0.08399, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.837, tt:1623.704\n",
      "Ep:51, loss:0.00008, loss_test:0.08386, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.814, tt:1654.335\n",
      "Ep:52, loss:0.00008, loss_test:0.08338, lr:9.90e-03, fs:0.80597 (r=0.818,p=0.794),  time:31.826, tt:1686.759\n",
      "Ep:53, loss:0.00008, loss_test:0.08286, lr:9.80e-03, fs:0.80198 (r=0.818,p=0.786),  time:31.807, tt:1717.598\n",
      "Ep:54, loss:0.00007, loss_test:0.08249, lr:9.70e-03, fs:0.80198 (r=0.818,p=0.786),  time:31.823, tt:1750.285\n",
      "Ep:55, loss:0.00007, loss_test:0.08216, lr:9.61e-03, fs:0.82234 (r=0.818,p=0.827),  time:31.795, tt:1780.504\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00007, loss_test:0.08075, lr:9.61e-03, fs:0.81373 (r=0.838,p=0.790),  time:31.777, tt:1811.297\n",
      "Ep:57, loss:0.00007, loss_test:0.08051, lr:9.61e-03, fs:0.82234 (r=0.818,p=0.827),  time:31.756, tt:1841.821\n",
      "Ep:58, loss:0.00007, loss_test:0.08032, lr:9.61e-03, fs:0.82234 (r=0.818,p=0.827),  time:31.767, tt:1874.260\n",
      "Ep:59, loss:0.00007, loss_test:0.07953, lr:9.61e-03, fs:0.81407 (r=0.818,p=0.810),  time:31.754, tt:1905.243\n",
      "Ep:60, loss:0.00007, loss_test:0.07958, lr:9.61e-03, fs:0.82234 (r=0.818,p=0.827),  time:31.727, tt:1935.323\n",
      "Ep:61, loss:0.00006, loss_test:0.07919, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:31.704, tt:1965.663\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.07847, lr:9.61e-03, fs:0.83582 (r=0.848,p=0.824),  time:31.669, tt:1995.178\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.07827, lr:9.61e-03, fs:0.82828 (r=0.828,p=0.828),  time:31.661, tt:2026.331\n",
      "Ep:64, loss:0.00006, loss_test:0.07824, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:31.643, tt:2056.812\n",
      "Ep:65, loss:0.00006, loss_test:0.07805, lr:9.61e-03, fs:0.82828 (r=0.828,p=0.828),  time:31.622, tt:2087.035\n",
      "Ep:66, loss:0.00006, loss_test:0.07800, lr:9.61e-03, fs:0.82828 (r=0.828,p=0.828),  time:31.596, tt:2116.955\n",
      "Ep:67, loss:0.00006, loss_test:0.07837, lr:9.61e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.567, tt:2146.547\n",
      "Ep:68, loss:0.00006, loss_test:0.07780, lr:9.61e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.518, tt:2174.746\n",
      "Ep:69, loss:0.00006, loss_test:0.07746, lr:9.61e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.509, tt:2205.610\n",
      "Ep:70, loss:0.00005, loss_test:0.07737, lr:9.61e-03, fs:0.82902 (r=0.808,p=0.851),  time:31.488, tt:2235.617\n",
      "Ep:71, loss:0.00005, loss_test:0.07673, lr:9.61e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.493, tt:2267.468\n",
      "Ep:72, loss:0.00005, loss_test:0.07720, lr:9.61e-03, fs:0.82902 (r=0.808,p=0.851),  time:31.496, tt:2299.179\n",
      "Ep:73, loss:0.00005, loss_test:0.07645, lr:9.61e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.499, tt:2330.918\n",
      "Ep:74, loss:0.00005, loss_test:0.07644, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.478, tt:2360.860\n",
      "Ep:75, loss:0.00005, loss_test:0.07614, lr:9.41e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.463, tt:2391.207\n",
      "Ep:76, loss:0.00005, loss_test:0.07617, lr:9.32e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.457, tt:2422.165\n",
      "Ep:77, loss:0.00005, loss_test:0.07555, lr:9.23e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.463, tt:2454.125\n",
      "Ep:78, loss:0.00005, loss_test:0.07569, lr:9.14e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.465, tt:2485.732\n",
      "Ep:79, loss:0.00004, loss_test:0.07575, lr:9.04e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.459, tt:2516.733\n",
      "Ep:80, loss:0.00004, loss_test:0.07486, lr:8.95e-03, fs:0.82051 (r=0.808,p=0.833),  time:31.437, tt:2546.404\n",
      "Ep:81, loss:0.00004, loss_test:0.07500, lr:8.86e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.437, tt:2577.811\n",
      "Ep:82, loss:0.00004, loss_test:0.07437, lr:8.78e-03, fs:0.82474 (r=0.808,p=0.842),  time:31.429, tt:2608.572\n",
      "Ep:83, loss:0.00004, loss_test:0.07425, lr:8.69e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.427, tt:2639.892\n",
      "Ep:84, loss:0.00004, loss_test:0.07439, lr:8.60e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.402, tt:2669.162\n",
      "Ep:85, loss:0.00004, loss_test:0.07356, lr:8.51e-03, fs:0.81443 (r=0.798,p=0.832),  time:31.398, tt:2700.191\n",
      "Ep:86, loss:0.00004, loss_test:0.07465, lr:8.43e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.377, tt:2729.814\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00004, loss_test:0.07332, lr:8.43e-03, fs:0.81443 (r=0.798,p=0.832),  time:31.366, tt:2760.250\n",
      "Ep:88, loss:0.00004, loss_test:0.07459, lr:8.43e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.362, tt:2791.214\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.07284, lr:8.43e-03, fs:0.81443 (r=0.798,p=0.832),  time:31.362, tt:2822.544\n",
      "Ep:90, loss:0.00004, loss_test:0.07384, lr:8.43e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.348, tt:2852.656\n",
      "Ep:91, loss:0.00004, loss_test:0.07245, lr:8.43e-03, fs:0.81443 (r=0.798,p=0.832),  time:31.338, tt:2883.102\n",
      "Ep:92, loss:0.00004, loss_test:0.07315, lr:8.43e-03, fs:0.86316 (r=0.828,p=0.901),  time:31.324, tt:2913.094\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00003, loss_test:0.07243, lr:8.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.323, tt:2944.396\n",
      "Ep:94, loss:0.00003, loss_test:0.07252, lr:8.43e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.317, tt:2975.091\n",
      "Ep:95, loss:0.00003, loss_test:0.07286, lr:8.43e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.300, tt:3004.763\n",
      "Ep:96, loss:0.00003, loss_test:0.07205, lr:8.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.287, tt:3034.870\n",
      "Ep:97, loss:0.00003, loss_test:0.07228, lr:8.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.273, tt:3064.705\n",
      "Ep:98, loss:0.00003, loss_test:0.07244, lr:8.43e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.258, tt:3094.563\n",
      "Ep:99, loss:0.00003, loss_test:0.07154, lr:8.43e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.261, tt:3126.115\n",
      "Ep:100, loss:0.00003, loss_test:0.07131, lr:8.43e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.249, tt:3156.182\n",
      "Ep:101, loss:0.00003, loss_test:0.07206, lr:8.43e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.237, tt:3186.224\n",
      "Ep:102, loss:0.00003, loss_test:0.07138, lr:8.43e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.231, tt:3216.827\n",
      "Ep:103, loss:0.00003, loss_test:0.07227, lr:8.43e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.238, tt:3248.746\n",
      "Ep:104, loss:0.00003, loss_test:0.07172, lr:8.35e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.230, tt:3279.174\n",
      "Ep:105, loss:0.00003, loss_test:0.07169, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.218, tt:3309.100\n",
      "Ep:106, loss:0.00003, loss_test:0.07197, lr:8.18e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.216, tt:3340.160\n",
      "Ep:107, loss:0.00003, loss_test:0.07086, lr:8.10e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.214, tt:3371.134\n",
      "Ep:108, loss:0.00003, loss_test:0.07194, lr:8.02e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.212, tt:3402.109\n",
      "Ep:109, loss:0.00003, loss_test:0.07146, lr:7.94e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.215, tt:3433.629\n",
      "Ep:110, loss:0.00003, loss_test:0.07150, lr:7.86e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.206, tt:3463.903\n",
      "Ep:111, loss:0.00003, loss_test:0.07115, lr:7.78e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.204, tt:3494.799\n",
      "Ep:112, loss:0.00003, loss_test:0.07081, lr:7.70e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.194, tt:3524.934\n",
      "Ep:113, loss:0.00002, loss_test:0.07159, lr:7.62e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.193, tt:3555.955\n",
      "Ep:114, loss:0.00002, loss_test:0.07116, lr:7.55e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.200, tt:3587.955\n",
      "Ep:115, loss:0.00002, loss_test:0.07037, lr:7.47e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.203, tt:3619.595\n",
      "Ep:116, loss:0.00002, loss_test:0.07164, lr:7.40e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.181, tt:3648.136\n",
      "Ep:117, loss:0.00002, loss_test:0.07079, lr:7.32e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.183, tt:3679.548\n",
      "Ep:118, loss:0.00002, loss_test:0.07209, lr:7.25e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.187, tt:3711.276\n",
      "Ep:119, loss:0.00002, loss_test:0.07174, lr:7.18e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.186, tt:3742.358\n",
      "Ep:120, loss:0.00002, loss_test:0.07076, lr:7.11e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.190, tt:3773.977\n",
      "Ep:121, loss:0.00002, loss_test:0.07170, lr:7.03e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.207, tt:3807.305\n",
      "Ep:122, loss:0.00002, loss_test:0.07079, lr:6.96e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.221, tt:3840.158\n",
      "Ep:123, loss:0.00002, loss_test:0.07141, lr:6.89e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.227, tt:3872.145\n",
      "Ep:124, loss:0.00002, loss_test:0.07128, lr:6.83e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.239, tt:3904.901\n",
      "Ep:125, loss:0.00002, loss_test:0.07068, lr:6.76e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.237, tt:3935.856\n",
      "Ep:126, loss:0.00002, loss_test:0.07144, lr:6.69e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.241, tt:3967.627\n",
      "Ep:127, loss:0.00002, loss_test:0.07118, lr:6.62e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.251, tt:4000.094\n",
      "Ep:128, loss:0.00002, loss_test:0.07120, lr:6.56e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.240, tt:4029.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00002, loss_test:0.07100, lr:6.49e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.230, tt:4059.925\n",
      "Ep:130, loss:0.00002, loss_test:0.07101, lr:6.43e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.219, tt:4089.673\n",
      "Ep:131, loss:0.00002, loss_test:0.07119, lr:6.36e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.221, tt:4121.165\n",
      "Ep:132, loss:0.00002, loss_test:0.07097, lr:6.30e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.199, tt:4149.440\n",
      "Ep:133, loss:0.00002, loss_test:0.07100, lr:6.24e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.162, tt:4175.682\n",
      "Ep:134, loss:0.00002, loss_test:0.07087, lr:6.17e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.124, tt:4201.782\n",
      "Ep:135, loss:0.00002, loss_test:0.07065, lr:6.11e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.045, tt:4222.130\n",
      "Ep:136, loss:0.00002, loss_test:0.07110, lr:6.05e-03, fs:0.84492 (r=0.798,p=0.898),  time:30.947, tt:4239.777\n",
      "Ep:137, loss:0.00002, loss_test:0.07045, lr:5.99e-03, fs:0.84043 (r=0.798,p=0.888),  time:30.850, tt:4257.321\n",
      "Ep:138, loss:0.00002, loss_test:0.07078, lr:5.93e-03, fs:0.84946 (r=0.798,p=0.908),  time:30.752, tt:4274.471\n",
      "Ep:139, loss:0.00002, loss_test:0.07101, lr:5.87e-03, fs:0.84492 (r=0.798,p=0.898),  time:30.608, tt:4285.059\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"17-18\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,140,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00183, loss_test:0.12112, lr:1.00e-02, fs:0.65403 (r=0.697,p=0.616),  time:225.395, tt:225.395\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00151, loss_test:0.10853, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:229.780, tt:459.560\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00130, loss_test:0.09659, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:232.533, tt:697.599\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00114, loss_test:0.08838, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:234.478, tt:937.912\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00101, loss_test:0.08118, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:234.512, tt:1172.561\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00088, loss_test:0.07702, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:235.372, tt:1412.231\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00077, loss_test:0.07407, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:235.618, tt:1649.324\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00066, loss_test:0.07380, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:235.591, tt:1884.729\n",
      "Ep:8, loss:0.00053, loss_test:0.06831, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:235.640, tt:2120.764\n",
      "Ep:9, loss:0.00044, loss_test:0.07078, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:235.193, tt:2351.927\n",
      "Ep:10, loss:0.00037, loss_test:0.07269, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:235.224, tt:2587.461\n",
      "Ep:11, loss:0.00031, loss_test:0.07059, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:235.167, tt:2822.004\n",
      "Ep:12, loss:0.00025, loss_test:0.06944, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:235.357, tt:3059.641\n",
      "Ep:13, loss:0.00023, loss_test:0.07570, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:235.435, tt:3296.089\n",
      "Ep:14, loss:0.00020, loss_test:0.07462, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:235.223, tt:3528.345\n",
      "Ep:15, loss:0.00017, loss_test:0.07267, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:235.202, tt:3763.236\n",
      "Ep:16, loss:0.00014, loss_test:0.07365, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:234.860, tt:3992.618\n",
      "Ep:17, loss:0.00013, loss_test:0.07590, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:234.756, tt:4225.600\n",
      "Ep:18, loss:0.00012, loss_test:0.07815, lr:9.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:234.488, tt:4455.276\n",
      "Ep:19, loss:0.00010, loss_test:0.07804, lr:9.80e-03, fs:0.77907 (r=0.677,p=0.918),  time:233.441, tt:4668.828\n",
      "Ep:20, loss:0.00009, loss_test:0.07960, lr:9.70e-03, fs:0.78363 (r=0.677,p=0.931),  time:232.418, tt:4880.787\n",
      "Ep:21, loss:0.00008, loss_test:0.08102, lr:9.61e-03, fs:0.78363 (r=0.677,p=0.931),  time:231.348, tt:5089.652\n",
      "Ep:22, loss:0.00007, loss_test:0.08564, lr:9.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:230.349, tt:5298.032\n",
      "Ep:23, loss:0.00007, loss_test:0.08240, lr:9.41e-03, fs:0.79290 (r=0.677,p=0.957),  time:229.637, tt:5511.297\n",
      "Ep:24, loss:0.00006, loss_test:0.08352, lr:9.32e-03, fs:0.79290 (r=0.677,p=0.957),  time:228.948, tt:5723.705\n",
      "Ep:25, loss:0.00006, loss_test:0.08548, lr:9.23e-03, fs:0.78571 (r=0.667,p=0.957),  time:228.274, tt:5935.124\n",
      "Ep:26, loss:0.00005, loss_test:0.08841, lr:9.14e-03, fs:0.77844 (r=0.657,p=0.956),  time:227.681, tt:6147.397\n",
      "Ep:27, loss:0.00005, loss_test:0.08993, lr:9.04e-03, fs:0.76829 (r=0.636,p=0.969),  time:227.092, tt:6358.563\n",
      "Ep:28, loss:0.00004, loss_test:0.09311, lr:8.95e-03, fs:0.76074 (r=0.626,p=0.969),  time:226.701, tt:6574.326\n",
      "Ep:29, loss:0.00004, loss_test:0.09371, lr:8.86e-03, fs:0.76074 (r=0.626,p=0.969),  time:225.923, tt:6777.689\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=16,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,16,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14184, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:115.340, tt:115.340\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00094, loss_test:0.13040, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:116.999, tt:233.998\n",
      "Ep:2, loss:0.00083, loss_test:0.11265, lr:1.00e-02, fs:0.64550 (r=0.616,p=0.678),  time:117.427, tt:352.282\n",
      "Ep:3, loss:0.00076, loss_test:0.10653, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:117.278, tt:469.113\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00070, loss_test:0.10038, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:117.070, tt:585.352\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00064, loss_test:0.09373, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:117.220, tt:703.321\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00058, loss_test:0.09045, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:117.674, tt:823.715\n",
      "Ep:7, loss:0.00054, loss_test:0.08624, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:117.890, tt:943.118\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00050, loss_test:0.08341, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:117.819, tt:1060.368\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00046, loss_test:0.08042, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:117.783, tt:1177.831\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00043, loss_test:0.07721, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:117.552, tt:1293.077\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.07630, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:117.482, tt:1409.787\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00036, loss_test:0.07951, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:117.453, tt:1526.884\n",
      "Ep:13, loss:0.00034, loss_test:0.07514, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:117.357, tt:1642.992\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00031, loss_test:0.07237, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:117.259, tt:1758.882\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.07106, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:117.290, tt:1876.648\n",
      "Ep:16, loss:0.00025, loss_test:0.07354, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:117.239, tt:1993.055\n",
      "Ep:17, loss:0.00023, loss_test:0.07433, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:117.267, tt:2110.798\n",
      "Ep:18, loss:0.00021, loss_test:0.07146, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:117.125, tt:2225.374\n",
      "Ep:19, loss:0.00019, loss_test:0.06877, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:117.164, tt:2343.281\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.07080, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:117.126, tt:2459.642\n",
      "Ep:21, loss:0.00016, loss_test:0.07134, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:117.138, tt:2577.046\n",
      "Ep:22, loss:0.00015, loss_test:0.06950, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:117.203, tt:2695.668\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07107, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:117.104, tt:2810.489\n",
      "Ep:24, loss:0.00013, loss_test:0.07431, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:117.052, tt:2926.289\n",
      "Ep:25, loss:0.00012, loss_test:0.07298, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:117.014, tt:3042.360\n",
      "Ep:26, loss:0.00011, loss_test:0.07365, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:117.036, tt:3159.963\n",
      "Ep:27, loss:0.00010, loss_test:0.07272, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:117.012, tt:3276.326\n",
      "Ep:28, loss:0.00010, loss_test:0.07640, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:117.027, tt:3393.773\n",
      "Ep:29, loss:0.00009, loss_test:0.07546, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:116.977, tt:3509.309\n",
      "Ep:30, loss:0.00009, loss_test:0.07598, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:116.871, tt:3622.988\n",
      "Ep:31, loss:0.00008, loss_test:0.07824, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:116.833, tt:3738.646\n",
      "Ep:32, loss:0.00007, loss_test:0.07665, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:116.822, tt:3855.116\n",
      "Ep:33, loss:0.00007, loss_test:0.07832, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:116.754, tt:3969.641\n",
      "Ep:34, loss:0.00007, loss_test:0.07875, lr:9.90e-03, fs:0.76471 (r=0.657,p=0.915),  time:116.762, tt:4086.656\n",
      "Ep:35, loss:0.00006, loss_test:0.07838, lr:9.80e-03, fs:0.76471 (r=0.657,p=0.915),  time:116.787, tt:4204.344\n",
      "Ep:36, loss:0.00006, loss_test:0.07882, lr:9.70e-03, fs:0.73494 (r=0.616,p=0.910),  time:116.751, tt:4319.784\n",
      "Ep:37, loss:0.00006, loss_test:0.07765, lr:9.61e-03, fs:0.76923 (r=0.657,p=0.929),  time:116.743, tt:4436.252\n",
      "Ep:38, loss:0.00005, loss_test:0.07836, lr:9.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:116.746, tt:4553.083\n",
      "Ep:39, loss:0.00005, loss_test:0.07869, lr:9.41e-03, fs:0.76923 (r=0.657,p=0.929),  time:116.684, tt:4667.342\n",
      "Ep:40, loss:0.00005, loss_test:0.07867, lr:9.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:116.668, tt:4783.390\n",
      "Ep:41, loss:0.00005, loss_test:0.08039, lr:9.23e-03, fs:0.75449 (r=0.636,p=0.926),  time:116.589, tt:4896.746\n",
      "Ep:42, loss:0.00004, loss_test:0.08064, lr:9.14e-03, fs:0.73939 (r=0.616,p=0.924),  time:116.585, tt:5013.173\n",
      "Ep:43, loss:0.00004, loss_test:0.08262, lr:9.04e-03, fs:0.73939 (r=0.616,p=0.924),  time:116.531, tt:5127.376\n",
      "Ep:44, loss:0.00004, loss_test:0.08022, lr:8.95e-03, fs:0.76923 (r=0.657,p=0.929),  time:116.545, tt:5244.533\n",
      "Ep:45, loss:0.00004, loss_test:0.08103, lr:8.86e-03, fs:0.73939 (r=0.616,p=0.924),  time:116.535, tt:5360.591\n",
      "Ep:46, loss:0.00004, loss_test:0.08383, lr:8.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:116.516, tt:5476.256\n",
      "Ep:47, loss:0.00004, loss_test:0.08357, lr:8.69e-03, fs:0.73939 (r=0.616,p=0.924),  time:116.531, tt:5593.471\n",
      "Ep:48, loss:0.00003, loss_test:0.08137, lr:8.60e-03, fs:0.73939 (r=0.616,p=0.924),  time:116.506, tt:5708.784\n",
      "Ep:49, loss:0.00003, loss_test:0.08196, lr:8.51e-03, fs:0.74390 (r=0.616,p=0.938),  time:115.441, tt:5772.049\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 4096: \n",
      "Ep:0, loss:0.00007, loss_test:0.14249, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.943, tt:29.943\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.14162, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.057, tt:62.114\n",
      "Ep:2, loss:0.00007, loss_test:0.14020, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.434, tt:94.302\n",
      "Ep:3, loss:0.00007, loss_test:0.13802, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:32.613, tt:130.452\n",
      "Ep:4, loss:0.00007, loss_test:0.13455, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:32.788, tt:163.942\n",
      "Ep:5, loss:0.00006, loss_test:0.12885, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:32.693, tt:196.158\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00006, loss_test:0.12044, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:32.487, tt:227.406\n",
      "Ep:7, loss:0.00006, loss_test:0.11316, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:32.416, tt:259.330\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00006, loss_test:0.11110, lr:1.00e-02, fs:0.63542 (r=0.616,p=0.656),  time:32.435, tt:291.916\n",
      "Ep:9, loss:0.00006, loss_test:0.10993, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:32.267, tt:322.670\n",
      "Ep:10, loss:0.00005, loss_test:0.11008, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:32.311, tt:355.421\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00005, loss_test:0.10814, lr:1.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:32.286, tt:387.427\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.10393, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:32.239, tt:419.107\n",
      "Ep:13, loss:0.00005, loss_test:0.10165, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:32.049, tt:448.681\n",
      "Ep:14, loss:0.00005, loss_test:0.09968, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:32.014, tt:480.208\n",
      "Ep:15, loss:0.00005, loss_test:0.09836, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:32.059, tt:512.939\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00005, loss_test:0.09742, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:32.018, tt:544.302\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00005, loss_test:0.09619, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:32.064, tt:577.147\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.09460, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:32.003, tt:608.053\n",
      "Ep:19, loss:0.00004, loss_test:0.09296, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:32.029, tt:640.587\n",
      "Ep:20, loss:0.00004, loss_test:0.09245, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:32.051, tt:673.069\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.09191, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:32.086, tt:705.894\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.09037, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:32.097, tt:738.220\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.08915, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:32.069, tt:769.647\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.08866, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:32.045, tt:801.137\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.08847, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:32.042, tt:833.099\n",
      "Ep:26, loss:0.00004, loss_test:0.08739, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:32.051, tt:865.372\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.08593, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:32.050, tt:897.403\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.08548, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:31.929, tt:925.953\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.08495, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:31.808, tt:954.228\n",
      "Ep:30, loss:0.00003, loss_test:0.08382, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:31.705, tt:982.853\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.08321, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:31.595, tt:1011.050\n",
      "Ep:32, loss:0.00003, loss_test:0.08272, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:31.491, tt:1039.195\n",
      "Ep:33, loss:0.00003, loss_test:0.08230, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.420, tt:1068.266\n",
      "Ep:34, loss:0.00003, loss_test:0.08170, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:31.348, tt:1097.189\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.08162, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:31.249, tt:1124.955\n",
      "Ep:36, loss:0.00003, loss_test:0.08125, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:31.179, tt:1153.614\n",
      "Ep:37, loss:0.00003, loss_test:0.08060, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:31.057, tt:1180.173\n",
      "Ep:38, loss:0.00003, loss_test:0.08016, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.956, tt:1207.268\n",
      "Ep:39, loss:0.00003, loss_test:0.08019, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.895, tt:1235.814\n",
      "Ep:40, loss:0.00003, loss_test:0.07966, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.831, tt:1264.079\n",
      "Ep:41, loss:0.00003, loss_test:0.07917, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:30.756, tt:1291.747\n",
      "Ep:42, loss:0.00003, loss_test:0.07917, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.692, tt:1319.743\n",
      "Ep:43, loss:0.00003, loss_test:0.07889, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.604, tt:1346.598\n",
      "Ep:44, loss:0.00003, loss_test:0.07826, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.530, tt:1373.853\n",
      "Ep:45, loss:0.00002, loss_test:0.07885, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:30.502, tt:1403.101\n",
      "Ep:46, loss:0.00002, loss_test:0.07794, lr:9.90e-03, fs:0.79144 (r=0.747,p=0.841),  time:30.406, tt:1429.092\n",
      "Ep:47, loss:0.00002, loss_test:0.07803, lr:9.80e-03, fs:0.78022 (r=0.717,p=0.855),  time:30.245, tt:1451.756\n",
      "Ep:48, loss:0.00002, loss_test:0.07834, lr:9.70e-03, fs:0.79348 (r=0.737,p=0.859),  time:29.903, tt:1465.257\n",
      "Ep:49, loss:0.00002, loss_test:0.07753, lr:9.61e-03, fs:0.78495 (r=0.737,p=0.839),  time:29.553, tt:1477.672\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=4096 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 6400 Test samples: 198\n",
      "Train positive samples: 3200 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.13844, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:114.019, tt:114.019\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00090, loss_test:0.12098, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:114.854, tt:229.709\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00079, loss_test:0.11882, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:114.886, tt:344.658\n",
      "Ep:3, loss:0.00073, loss_test:0.11032, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:114.645, tt:458.578\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00067, loss_test:0.10459, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:114.236, tt:571.181\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00062, loss_test:0.10133, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:114.879, tt:689.275\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00057, loss_test:0.09640, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:114.775, tt:803.424\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00053, loss_test:0.09305, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:114.819, tt:918.550\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00049, loss_test:0.09262, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:114.904, tt:1034.139\n",
      "Ep:9, loss:0.00046, loss_test:0.09050, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:114.889, tt:1148.885\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.09091, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:114.907, tt:1263.975\n",
      "Ep:11, loss:0.00039, loss_test:0.09258, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:115.145, tt:1381.742\n",
      "Ep:12, loss:0.00036, loss_test:0.09236, lr:1.00e-02, fs:0.71508 (r=0.646,p=0.800),  time:115.071, tt:1495.918\n",
      "Ep:13, loss:0.00033, loss_test:0.09145, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:114.981, tt:1609.737\n",
      "Ep:14, loss:0.00030, loss_test:0.08623, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:115.116, tt:1726.745\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.08965, lr:1.00e-02, fs:0.73256 (r=0.636,p=0.863),  time:115.056, tt:1840.899\n",
      "Ep:16, loss:0.00024, loss_test:0.08644, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:114.978, tt:1954.618\n",
      "Ep:17, loss:0.00022, loss_test:0.08919, lr:1.00e-02, fs:0.73256 (r=0.636,p=0.863),  time:115.033, tt:2070.589\n",
      "Ep:18, loss:0.00020, loss_test:0.09116, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:115.027, tt:2185.512\n",
      "Ep:19, loss:0.00018, loss_test:0.09107, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:114.990, tt:2299.790\n",
      "Ep:20, loss:0.00017, loss_test:0.09350, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:115.013, tt:2415.270\n",
      "Ep:21, loss:0.00015, loss_test:0.08828, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:115.033, tt:2530.725\n",
      "Ep:22, loss:0.00014, loss_test:0.09594, lr:1.00e-02, fs:0.72832 (r=0.636,p=0.851),  time:115.018, tt:2645.416\n",
      "Ep:23, loss:0.00013, loss_test:0.09738, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:115.094, tt:2762.267\n",
      "Ep:24, loss:0.00012, loss_test:0.09722, lr:1.00e-02, fs:0.64103 (r=0.505,p=0.877),  time:115.112, tt:2877.803\n",
      "Ep:25, loss:0.00012, loss_test:0.09807, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:115.117, tt:2993.034\n",
      "Ep:26, loss:0.00011, loss_test:0.09950, lr:9.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:115.040, tt:3106.093\n",
      "Ep:27, loss:0.00010, loss_test:0.09777, lr:9.80e-03, fs:0.65823 (r=0.525,p=0.881),  time:115.069, tt:3221.932\n",
      "Ep:28, loss:0.00009, loss_test:0.09635, lr:9.70e-03, fs:0.67857 (r=0.576,p=0.826),  time:115.140, tt:3339.055\n",
      "Ep:29, loss:0.00008, loss_test:0.10075, lr:9.61e-03, fs:0.64103 (r=0.505,p=0.877),  time:115.196, tt:3455.866\n",
      "Ep:30, loss:0.00008, loss_test:0.10533, lr:9.51e-03, fs:0.66667 (r=0.545,p=0.857),  time:115.142, tt:3569.417\n",
      "Ep:31, loss:0.00007, loss_test:0.10220, lr:9.41e-03, fs:0.65000 (r=0.525,p=0.852),  time:115.200, tt:3686.399\n",
      "Ep:32, loss:0.00007, loss_test:0.10434, lr:9.32e-03, fs:0.68675 (r=0.576,p=0.851),  time:115.316, tt:3805.443\n",
      "Ep:33, loss:0.00006, loss_test:0.10608, lr:9.23e-03, fs:0.63576 (r=0.485,p=0.923),  time:115.328, tt:3921.136\n",
      "Ep:34, loss:0.00006, loss_test:0.10825, lr:9.14e-03, fs:0.63158 (r=0.485,p=0.906),  time:115.368, tt:4037.864\n",
      "Ep:35, loss:0.00006, loss_test:0.10453, lr:9.04e-03, fs:0.64516 (r=0.505,p=0.893),  time:115.452, tt:4156.260\n",
      "Ep:36, loss:0.00005, loss_test:0.11166, lr:8.95e-03, fs:0.63158 (r=0.485,p=0.906),  time:115.395, tt:4269.608\n",
      "Ep:37, loss:0.00005, loss_test:0.10401, lr:8.86e-03, fs:0.64103 (r=0.505,p=0.877),  time:115.297, tt:4381.300\n",
      "Ep:38, loss:0.00005, loss_test:0.10614, lr:8.78e-03, fs:0.65839 (r=0.535,p=0.855),  time:115.362, tt:4499.128\n",
      "Ep:39, loss:0.00004, loss_test:0.10742, lr:8.69e-03, fs:0.62338 (r=0.485,p=0.873),  time:115.417, tt:4616.684\n",
      "Ep:40, loss:0.00004, loss_test:0.10623, lr:8.60e-03, fs:0.64516 (r=0.505,p=0.893),  time:115.419, tt:4732.183\n",
      "Ep:41, loss:0.00004, loss_test:0.10594, lr:8.51e-03, fs:0.64103 (r=0.505,p=0.877),  time:115.443, tt:4848.626\n",
      "Ep:42, loss:0.00004, loss_test:0.10679, lr:8.43e-03, fs:0.63158 (r=0.485,p=0.906),  time:115.457, tt:4964.641\n",
      "Ep:43, loss:0.00004, loss_test:0.10852, lr:8.35e-03, fs:0.63636 (r=0.495,p=0.891),  time:115.442, tt:5079.428\n",
      "Ep:44, loss:0.00003, loss_test:0.10785, lr:8.26e-03, fs:0.63636 (r=0.495,p=0.891),  time:115.382, tt:5192.174\n",
      "Ep:45, loss:0.00003, loss_test:0.10862, lr:8.18e-03, fs:0.62252 (r=0.475,p=0.904),  time:115.450, tt:5310.717\n",
      "Ep:46, loss:0.00003, loss_test:0.11048, lr:8.10e-03, fs:0.63158 (r=0.485,p=0.906),  time:115.443, tt:5425.840\n",
      "Ep:47, loss:0.00003, loss_test:0.10785, lr:8.02e-03, fs:0.62745 (r=0.485,p=0.889),  time:115.409, tt:5539.642\n",
      "Ep:48, loss:0.00003, loss_test:0.10830, lr:7.94e-03, fs:0.62338 (r=0.485,p=0.873),  time:115.014, tt:5635.702\n",
      "Ep:49, loss:0.00003, loss_test:0.11021, lr:7.86e-03, fs:0.62252 (r=0.475,p=0.904),  time:113.581, tt:5679.026\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14591, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.833, tt:31.833\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14533, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.775, tt:63.551\n",
      "Ep:2, loss:0.00014, loss_test:0.14444, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.558, tt:94.674\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00013, loss_test:0.14325, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.608, tt:126.431\n",
      "Ep:4, loss:0.00013, loss_test:0.14146, lr:1.00e-02, fs:0.63380 (r=0.909,p=0.486),  time:31.603, tt:158.016\n",
      "Ep:5, loss:0.00012, loss_test:0.13910, lr:1.00e-02, fs:0.62791 (r=0.818,p=0.509),  time:31.661, tt:189.968\n",
      "Ep:6, loss:0.00012, loss_test:0.13716, lr:1.00e-02, fs:0.61207 (r=0.717,p=0.534),  time:31.701, tt:221.906\n",
      "Ep:7, loss:0.00011, loss_test:0.13888, lr:1.00e-02, fs:0.56566 (r=0.566,p=0.566),  time:31.875, tt:255.002\n",
      "Ep:8, loss:0.00011, loss_test:0.13750, lr:1.00e-02, fs:0.56701 (r=0.556,p=0.579),  time:31.958, tt:287.623\n",
      "Ep:9, loss:0.00011, loss_test:0.13273, lr:1.00e-02, fs:0.60829 (r=0.667,p=0.559),  time:31.951, tt:319.510\n",
      "Ep:10, loss:0.00010, loss_test:0.12917, lr:1.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:31.972, tt:351.697\n",
      "Ep:11, loss:0.00010, loss_test:0.12746, lr:1.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:32.007, tt:384.085\n",
      "Ep:12, loss:0.00010, loss_test:0.12609, lr:1.00e-02, fs:0.57868 (r=0.576,p=0.582),  time:32.029, tt:416.372\n",
      "Ep:13, loss:0.00010, loss_test:0.12266, lr:1.00e-02, fs:0.62745 (r=0.646,p=0.610),  time:32.059, tt:448.823\n",
      "Ep:14, loss:0.00009, loss_test:0.11962, lr:9.90e-03, fs:0.64455 (r=0.687,p=0.607),  time:32.152, tt:482.273\n",
      "Ep:15, loss:0.00009, loss_test:0.11758, lr:9.80e-03, fs:0.66019 (r=0.687,p=0.636),  time:31.922, tt:510.744\n",
      "Ep:16, loss:0.00009, loss_test:0.11627, lr:9.70e-03, fs:0.65657 (r=0.657,p=0.657),  time:32.032, tt:544.539\n",
      "Ep:17, loss:0.00009, loss_test:0.11405, lr:9.61e-03, fs:0.67000 (r=0.677,p=0.663),  time:32.153, tt:578.758\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.11180, lr:9.61e-03, fs:0.69268 (r=0.717,p=0.670),  time:32.132, tt:610.509\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.11026, lr:9.61e-03, fs:0.69744 (r=0.687,p=0.708),  time:32.211, tt:644.211\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.10908, lr:9.61e-03, fs:0.72539 (r=0.707,p=0.745),  time:32.298, tt:678.252\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.10738, lr:9.61e-03, fs:0.72821 (r=0.717,p=0.740),  time:32.296, tt:710.516\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.10574, lr:9.61e-03, fs:0.74490 (r=0.737,p=0.753),  time:32.305, tt:743.017\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00008, loss_test:0.10405, lr:9.61e-03, fs:0.74872 (r=0.737,p=0.760),  time:32.290, tt:774.958\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00007, loss_test:0.10168, lr:9.61e-03, fs:0.76923 (r=0.758,p=0.781),  time:32.235, tt:805.871\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.10059, lr:9.61e-03, fs:0.77720 (r=0.758,p=0.798),  time:32.280, tt:839.269\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.10035, lr:9.61e-03, fs:0.76923 (r=0.758,p=0.781),  time:32.290, tt:871.821\n",
      "Ep:27, loss:0.00007, loss_test:0.09972, lr:9.61e-03, fs:0.77487 (r=0.747,p=0.804),  time:32.317, tt:904.875\n",
      "Ep:28, loss:0.00007, loss_test:0.09913, lr:9.61e-03, fs:0.77249 (r=0.737,p=0.811),  time:32.243, tt:935.039\n",
      "Ep:29, loss:0.00007, loss_test:0.09864, lr:9.61e-03, fs:0.76842 (r=0.737,p=0.802),  time:32.210, tt:966.297\n",
      "Ep:30, loss:0.00006, loss_test:0.09837, lr:9.61e-03, fs:0.76087 (r=0.707,p=0.824),  time:32.241, tt:999.457\n",
      "Ep:31, loss:0.00006, loss_test:0.09778, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:32.277, tt:1032.850\n",
      "Ep:32, loss:0.00006, loss_test:0.09675, lr:9.61e-03, fs:0.77005 (r=0.727,p=0.818),  time:32.263, tt:1064.680\n",
      "Ep:33, loss:0.00006, loss_test:0.09670, lr:9.61e-03, fs:0.74444 (r=0.677,p=0.827),  time:32.253, tt:1096.591\n",
      "Ep:34, loss:0.00006, loss_test:0.09595, lr:9.61e-03, fs:0.74860 (r=0.677,p=0.838),  time:32.266, tt:1129.311\n",
      "Ep:35, loss:0.00006, loss_test:0.09593, lr:9.61e-03, fs:0.75824 (r=0.697,p=0.831),  time:32.261, tt:1161.411\n",
      "Ep:36, loss:0.00006, loss_test:0.09711, lr:9.61e-03, fs:0.72727 (r=0.646,p=0.831),  time:32.282, tt:1194.438\n",
      "Ep:37, loss:0.00005, loss_test:0.09551, lr:9.51e-03, fs:0.74860 (r=0.677,p=0.838),  time:32.320, tt:1228.145\n",
      "Ep:38, loss:0.00005, loss_test:0.09562, lr:9.41e-03, fs:0.74157 (r=0.667,p=0.835),  time:32.313, tt:1260.191\n",
      "Ep:39, loss:0.00005, loss_test:0.09625, lr:9.32e-03, fs:0.73446 (r=0.657,p=0.833),  time:32.344, tt:1293.746\n",
      "Ep:40, loss:0.00005, loss_test:0.09546, lr:9.23e-03, fs:0.75556 (r=0.687,p=0.840),  time:32.326, tt:1325.357\n",
      "Ep:41, loss:0.00005, loss_test:0.09685, lr:9.14e-03, fs:0.70588 (r=0.606,p=0.845),  time:32.300, tt:1356.608\n",
      "Ep:42, loss:0.00005, loss_test:0.09562, lr:9.04e-03, fs:0.74725 (r=0.687,p=0.819),  time:32.322, tt:1389.839\n",
      "Ep:43, loss:0.00005, loss_test:0.09678, lr:8.95e-03, fs:0.71345 (r=0.616,p=0.847),  time:32.301, tt:1421.230\n",
      "Ep:44, loss:0.00005, loss_test:0.09504, lr:8.86e-03, fs:0.74576 (r=0.667,p=0.846),  time:32.265, tt:1451.904\n",
      "Ep:45, loss:0.00005, loss_test:0.09641, lr:8.78e-03, fs:0.72414 (r=0.636,p=0.840),  time:32.240, tt:1483.059\n",
      "Ep:46, loss:0.00004, loss_test:0.09577, lr:8.69e-03, fs:0.72414 (r=0.636,p=0.840),  time:32.217, tt:1514.190\n",
      "Ep:47, loss:0.00004, loss_test:0.09529, lr:8.60e-03, fs:0.72414 (r=0.636,p=0.840),  time:32.174, tt:1544.333\n",
      "Ep:48, loss:0.00004, loss_test:0.09624, lr:8.51e-03, fs:0.70175 (r=0.606,p=0.833),  time:32.173, tt:1576.460\n",
      "Ep:49, loss:0.00004, loss_test:0.09583, lr:8.43e-03, fs:0.70175 (r=0.606,p=0.833),  time:32.143, tt:1607.147\n",
      "Ep:50, loss:0.00004, loss_test:0.09676, lr:8.35e-03, fs:0.67066 (r=0.566,p=0.824),  time:32.165, tt:1640.437\n",
      "Ep:51, loss:0.00004, loss_test:0.09596, lr:8.26e-03, fs:0.70175 (r=0.606,p=0.833),  time:32.179, tt:1673.308\n",
      "Ep:52, loss:0.00004, loss_test:0.09517, lr:8.18e-03, fs:0.70930 (r=0.616,p=0.836),  time:32.173, tt:1705.195\n",
      "Ep:53, loss:0.00004, loss_test:0.09720, lr:8.10e-03, fs:0.64634 (r=0.535,p=0.815),  time:32.166, tt:1736.966\n",
      "Ep:54, loss:0.00004, loss_test:0.09572, lr:8.02e-03, fs:0.67857 (r=0.576,p=0.826),  time:32.170, tt:1769.361\n",
      "Ep:55, loss:0.00004, loss_test:0.09655, lr:7.94e-03, fs:0.64634 (r=0.535,p=0.815),  time:32.178, tt:1801.961\n",
      "Ep:56, loss:0.00004, loss_test:0.09642, lr:7.86e-03, fs:0.64634 (r=0.535,p=0.815),  time:32.205, tt:1835.685\n",
      "Ep:57, loss:0.00004, loss_test:0.09601, lr:7.78e-03, fs:0.66265 (r=0.556,p=0.821),  time:32.239, tt:1869.856\n",
      "Ep:58, loss:0.00004, loss_test:0.09693, lr:7.70e-03, fs:0.65031 (r=0.535,p=0.828),  time:32.237, tt:1901.967\n",
      "Ep:59, loss:0.00004, loss_test:0.09643, lr:7.62e-03, fs:0.64634 (r=0.535,p=0.815),  time:32.234, tt:1934.053\n",
      "Ep:60, loss:0.00003, loss_test:0.09861, lr:7.55e-03, fs:0.65031 (r=0.535,p=0.828),  time:32.212, tt:1964.946\n",
      "Ep:61, loss:0.00003, loss_test:0.09559, lr:7.47e-03, fs:0.65455 (r=0.545,p=0.818),  time:32.215, tt:1997.317\n",
      "Ep:62, loss:0.00003, loss_test:0.09755, lr:7.40e-03, fs:0.63804 (r=0.525,p=0.812),  time:32.185, tt:2027.668\n",
      "Ep:63, loss:0.00003, loss_test:0.09709, lr:7.32e-03, fs:0.64634 (r=0.535,p=0.815),  time:32.192, tt:2060.287\n",
      "Ep:64, loss:0.00003, loss_test:0.09734, lr:7.25e-03, fs:0.65031 (r=0.535,p=0.828),  time:32.193, tt:2092.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00003, loss_test:0.09846, lr:7.18e-03, fs:0.64198 (r=0.525,p=0.825),  time:32.178, tt:2123.721\n",
      "Ep:66, loss:0.00003, loss_test:0.09599, lr:7.11e-03, fs:0.65455 (r=0.545,p=0.818),  time:32.162, tt:2154.853\n",
      "Ep:67, loss:0.00003, loss_test:0.09873, lr:7.03e-03, fs:0.64198 (r=0.525,p=0.825),  time:32.165, tt:2187.200\n",
      "Ep:68, loss:0.00003, loss_test:0.09692, lr:6.96e-03, fs:0.63804 (r=0.525,p=0.812),  time:32.134, tt:2217.247\n",
      "Ep:69, loss:0.00003, loss_test:0.09835, lr:6.89e-03, fs:0.65000 (r=0.525,p=0.852),  time:32.141, tt:2249.860\n",
      "Ep:70, loss:0.00003, loss_test:0.09881, lr:6.83e-03, fs:0.65000 (r=0.525,p=0.852),  time:32.149, tt:2282.550\n",
      "Ep:71, loss:0.00003, loss_test:0.09832, lr:6.76e-03, fs:0.64596 (r=0.525,p=0.839),  time:32.159, tt:2315.474\n",
      "Ep:72, loss:0.00003, loss_test:0.09925, lr:6.69e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.168, tt:2348.294\n",
      "Ep:73, loss:0.00003, loss_test:0.09892, lr:6.62e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.195, tt:2382.421\n",
      "Ep:74, loss:0.00003, loss_test:0.09921, lr:6.56e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.209, tt:2415.656\n",
      "Ep:75, loss:0.00003, loss_test:0.10016, lr:6.49e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.181, tt:2445.738\n",
      "Ep:76, loss:0.00003, loss_test:0.09894, lr:6.43e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.168, tt:2476.914\n",
      "Ep:77, loss:0.00003, loss_test:0.10013, lr:6.36e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.177, tt:2509.780\n",
      "Ep:78, loss:0.00003, loss_test:0.10025, lr:6.30e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.172, tt:2541.552\n",
      "Ep:79, loss:0.00003, loss_test:0.10073, lr:6.24e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.157, tt:2572.530\n",
      "Ep:80, loss:0.00003, loss_test:0.10009, lr:6.17e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.144, tt:2603.690\n",
      "Ep:81, loss:0.00003, loss_test:0.10081, lr:6.11e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.126, tt:2634.297\n",
      "Ep:82, loss:0.00003, loss_test:0.10117, lr:6.05e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.106, tt:2664.765\n",
      "Ep:83, loss:0.00003, loss_test:0.10076, lr:5.99e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.103, tt:2696.686\n",
      "Ep:84, loss:0.00002, loss_test:0.10171, lr:5.93e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.094, tt:2727.953\n",
      "Ep:85, loss:0.00002, loss_test:0.10163, lr:5.87e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.098, tt:2760.415\n",
      "Ep:86, loss:0.00002, loss_test:0.10088, lr:5.81e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.093, tt:2792.103\n",
      "Ep:87, loss:0.00002, loss_test:0.10175, lr:5.75e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.086, tt:2823.542\n",
      "Ep:88, loss:0.00002, loss_test:0.10124, lr:5.70e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.069, tt:2854.137\n",
      "Ep:89, loss:0.00002, loss_test:0.10129, lr:5.64e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.063, tt:2885.632\n",
      "Ep:90, loss:0.00002, loss_test:0.10182, lr:5.58e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.056, tt:2917.099\n",
      "Ep:91, loss:0.00002, loss_test:0.10157, lr:5.53e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.030, tt:2946.772\n",
      "Ep:92, loss:0.00002, loss_test:0.10103, lr:5.47e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.034, tt:2979.150\n",
      "Ep:93, loss:0.00002, loss_test:0.10272, lr:5.42e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.016, tt:3009.482\n",
      "Ep:94, loss:0.00002, loss_test:0.10216, lr:5.36e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.020, tt:3041.937\n",
      "Ep:95, loss:0.00002, loss_test:0.10211, lr:5.31e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.016, tt:3073.568\n",
      "Ep:96, loss:0.00002, loss_test:0.10195, lr:5.26e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.018, tt:3105.735\n",
      "Ep:97, loss:0.00002, loss_test:0.10236, lr:5.20e-03, fs:0.64151 (r=0.515,p=0.850),  time:32.010, tt:3136.989\n",
      "Ep:98, loss:0.00002, loss_test:0.10252, lr:5.15e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.996, tt:3167.585\n",
      "Ep:99, loss:0.00002, loss_test:0.10246, lr:5.10e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.985, tt:3198.459\n",
      "Ep:100, loss:0.00002, loss_test:0.10292, lr:5.05e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.972, tt:3229.195\n",
      "Ep:101, loss:0.00002, loss_test:0.10319, lr:5.00e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.965, tt:3260.450\n",
      "Ep:102, loss:0.00002, loss_test:0.10242, lr:4.95e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.955, tt:3291.333\n",
      "Ep:103, loss:0.00002, loss_test:0.10343, lr:4.90e-03, fs:0.64557 (r=0.515,p=0.864),  time:31.947, tt:3322.483\n",
      "Ep:104, loss:0.00002, loss_test:0.10254, lr:4.85e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.925, tt:3352.157\n",
      "Ep:105, loss:0.00002, loss_test:0.10221, lr:4.80e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.918, tt:3383.292\n",
      "Ep:106, loss:0.00002, loss_test:0.10348, lr:4.75e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.908, tt:3414.196\n",
      "Ep:107, loss:0.00002, loss_test:0.10288, lr:4.71e-03, fs:0.64557 (r=0.515,p=0.864),  time:31.900, tt:3445.235\n",
      "Ep:108, loss:0.00002, loss_test:0.10290, lr:4.66e-03, fs:0.64557 (r=0.515,p=0.864),  time:31.896, tt:3476.623\n",
      "Ep:109, loss:0.00002, loss_test:0.10374, lr:4.61e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.883, tt:3507.170\n",
      "Ep:110, loss:0.00002, loss_test:0.10327, lr:4.57e-03, fs:0.64557 (r=0.515,p=0.864),  time:31.878, tt:3538.437\n",
      "Ep:111, loss:0.00002, loss_test:0.10447, lr:4.52e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.861, tt:3568.472\n",
      "Ep:112, loss:0.00002, loss_test:0.10356, lr:4.48e-03, fs:0.64557 (r=0.515,p=0.864),  time:31.854, tt:3599.504\n",
      "Ep:113, loss:0.00002, loss_test:0.10416, lr:4.43e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.844, tt:3630.271\n",
      "Ep:114, loss:0.00002, loss_test:0.10408, lr:4.39e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.835, tt:3661.034\n",
      "Ep:115, loss:0.00002, loss_test:0.10398, lr:4.34e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.838, tt:3693.175\n",
      "Ep:116, loss:0.00002, loss_test:0.10471, lr:4.30e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.844, tt:3725.805\n",
      "Ep:117, loss:0.00002, loss_test:0.10416, lr:4.26e-03, fs:0.63694 (r=0.505,p=0.862),  time:31.841, tt:3757.184\n",
      "Ep:118, loss:0.00002, loss_test:0.10484, lr:4.21e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.836, tt:3788.468\n",
      "Ep:119, loss:0.00002, loss_test:0.10530, lr:4.17e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.828, tt:3819.396\n",
      "Ep:120, loss:0.00002, loss_test:0.10400, lr:4.13e-03, fs:0.63694 (r=0.505,p=0.862),  time:31.818, tt:3849.985\n",
      "Ep:121, loss:0.00002, loss_test:0.10520, lr:4.09e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.812, tt:3881.112\n",
      "Ep:122, loss:0.00002, loss_test:0.10522, lr:4.05e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.790, tt:3910.171\n",
      "Ep:123, loss:0.00002, loss_test:0.10420, lr:4.01e-03, fs:0.63694 (r=0.505,p=0.862),  time:31.778, tt:3940.411\n",
      "Ep:124, loss:0.00002, loss_test:0.10568, lr:3.97e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.766, tt:3970.782\n",
      "Ep:125, loss:0.00002, loss_test:0.10542, lr:3.93e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.741, tt:3999.330\n",
      "Ep:126, loss:0.00002, loss_test:0.10505, lr:3.89e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.729, tt:4029.637\n",
      "Ep:127, loss:0.00002, loss_test:0.10615, lr:3.85e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.717, tt:4059.756\n",
      "Ep:128, loss:0.00002, loss_test:0.10569, lr:3.81e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.706, tt:4090.104\n",
      "Ep:129, loss:0.00002, loss_test:0.10524, lr:3.77e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.693, tt:4120.115\n",
      "Ep:130, loss:0.00002, loss_test:0.10556, lr:3.73e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.686, tt:4150.831\n",
      "Ep:131, loss:0.00002, loss_test:0.10543, lr:3.70e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.682, tt:4181.993\n",
      "Ep:132, loss:0.00002, loss_test:0.10617, lr:3.66e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.676, tt:4212.892\n",
      "Ep:133, loss:0.00002, loss_test:0.10569, lr:3.62e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.663, tt:4242.864\n",
      "Ep:134, loss:0.00002, loss_test:0.10548, lr:3.59e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.660, tt:4274.151\n",
      "Ep:135, loss:0.00002, loss_test:0.10590, lr:3.55e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.656, tt:4305.153\n",
      "Ep:136, loss:0.00002, loss_test:0.10630, lr:3.52e-03, fs:0.64935 (r=0.505,p=0.909),  time:31.637, tt:4334.240\n",
      "Ep:137, loss:0.00002, loss_test:0.10565, lr:3.48e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.636, tt:4365.707\n",
      "Ep:138, loss:0.00001, loss_test:0.10578, lr:3.45e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.631, tt:4396.704\n",
      "Ep:139, loss:0.00001, loss_test:0.10611, lr:3.41e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.630, tt:4428.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.10603, lr:3.38e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.614, tt:4457.570\n",
      "Ep:141, loss:0.00001, loss_test:0.10539, lr:3.34e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.605, tt:4487.856\n",
      "Ep:142, loss:0.00001, loss_test:0.10603, lr:3.31e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.595, tt:4518.057\n",
      "Ep:143, loss:0.00001, loss_test:0.10645, lr:3.28e-03, fs:0.64935 (r=0.505,p=0.909),  time:31.585, tt:4548.203\n",
      "Ep:144, loss:0.00001, loss_test:0.10565, lr:3.24e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.581, tt:4579.262\n",
      "Ep:145, loss:0.00001, loss_test:0.10610, lr:3.21e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.578, tt:4610.366\n",
      "Ep:146, loss:0.00001, loss_test:0.10674, lr:3.18e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.574, tt:4641.349\n",
      "Ep:147, loss:0.00001, loss_test:0.10565, lr:3.15e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.566, tt:4671.816\n",
      "Ep:148, loss:0.00001, loss_test:0.10629, lr:3.12e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.559, tt:4702.315\n",
      "Ep:149, loss:0.00001, loss_test:0.10659, lr:3.09e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.554, tt:4733.154\n",
      "Ep:150, loss:0.00001, loss_test:0.10653, lr:3.05e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.535, tt:4761.756\n",
      "Ep:151, loss:0.00001, loss_test:0.10670, lr:3.02e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.556, tt:4796.492\n",
      "Ep:152, loss:0.00001, loss_test:0.10690, lr:2.99e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.547, tt:4826.703\n",
      "Ep:153, loss:0.00001, loss_test:0.10620, lr:2.96e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.539, tt:4857.069\n",
      "Ep:154, loss:0.00001, loss_test:0.10706, lr:2.93e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.533, tt:4887.568\n",
      "Ep:155, loss:0.00001, loss_test:0.10723, lr:2.90e-03, fs:0.64935 (r=0.505,p=0.909),  time:31.533, tt:4919.179\n",
      "Ep:156, loss:0.00001, loss_test:0.10621, lr:2.88e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.528, tt:4949.953\n",
      "Ep:157, loss:0.00001, loss_test:0.10689, lr:2.85e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.516, tt:4979.546\n",
      "Ep:158, loss:0.00001, loss_test:0.10743, lr:2.82e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.515, tt:5010.806\n",
      "Ep:159, loss:0.00001, loss_test:0.10652, lr:2.79e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.508, tt:5041.278\n",
      "Ep:160, loss:0.00001, loss_test:0.10654, lr:2.76e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.495, tt:5070.714\n",
      "Ep:161, loss:0.00001, loss_test:0.10737, lr:2.73e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.483, tt:5100.276\n",
      "Ep:162, loss:0.00001, loss_test:0.10701, lr:2.71e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.475, tt:5130.503\n",
      "Ep:163, loss:0.00001, loss_test:0.10674, lr:2.68e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.476, tt:5162.091\n",
      "Ep:164, loss:0.00001, loss_test:0.10731, lr:2.65e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.469, tt:5192.378\n",
      "Ep:165, loss:0.00001, loss_test:0.10682, lr:2.63e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.460, tt:5222.409\n",
      "Ep:166, loss:0.00001, loss_test:0.10725, lr:2.60e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.468, tt:5255.188\n",
      "Ep:167, loss:0.00001, loss_test:0.10732, lr:2.57e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.464, tt:5285.896\n",
      "Ep:168, loss:0.00001, loss_test:0.10696, lr:2.55e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.466, tt:5317.680\n",
      "Ep:169, loss:0.00001, loss_test:0.10768, lr:2.52e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.461, tt:5348.439\n",
      "Ep:170, loss:0.00001, loss_test:0.10705, lr:2.50e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.464, tt:5380.289\n",
      "Ep:171, loss:0.00001, loss_test:0.10697, lr:2.47e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.459, tt:5410.933\n",
      "Ep:172, loss:0.00001, loss_test:0.10752, lr:2.45e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.459, tt:5442.388\n",
      "Ep:173, loss:0.00001, loss_test:0.10710, lr:2.42e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.448, tt:5471.960\n",
      "Ep:174, loss:0.00001, loss_test:0.10716, lr:2.40e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.450, tt:5503.699\n",
      "Ep:175, loss:0.00001, loss_test:0.10780, lr:2.38e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.444, tt:5534.118\n",
      "Ep:176, loss:0.00001, loss_test:0.10760, lr:2.35e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.442, tt:5565.246\n",
      "Ep:177, loss:0.00001, loss_test:0.10727, lr:2.33e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.439, tt:5596.181\n",
      "Ep:178, loss:0.00001, loss_test:0.10791, lr:2.31e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.439, tt:5627.564\n",
      "Ep:179, loss:0.00001, loss_test:0.10779, lr:2.28e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.430, tt:5657.448\n",
      "Ep:180, loss:0.00001, loss_test:0.10740, lr:2.26e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.430, tt:5688.767\n",
      "Ep:181, loss:0.00001, loss_test:0.10753, lr:2.24e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.433, tt:5720.727\n",
      "Ep:182, loss:0.00001, loss_test:0.10802, lr:2.21e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.431, tt:5751.794\n",
      "Ep:183, loss:0.00001, loss_test:0.10761, lr:2.19e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.432, tt:5783.444\n",
      "Ep:184, loss:0.00001, loss_test:0.10753, lr:2.17e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.441, tt:5816.643\n",
      "Ep:185, loss:0.00001, loss_test:0.10821, lr:2.15e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.442, tt:5848.137\n",
      "Ep:186, loss:0.00001, loss_test:0.10806, lr:2.13e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.429, tt:5877.149\n",
      "Ep:187, loss:0.00001, loss_test:0.10740, lr:2.11e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.431, tt:5909.099\n",
      "Ep:188, loss:0.00001, loss_test:0.10799, lr:2.08e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.427, tt:5939.626\n",
      "Ep:189, loss:0.00001, loss_test:0.10808, lr:2.06e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.432, tt:5972.138\n",
      "Ep:190, loss:0.00001, loss_test:0.10770, lr:2.04e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.432, tt:6003.517\n",
      "Ep:191, loss:0.00001, loss_test:0.10783, lr:2.02e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.418, tt:6032.261\n",
      "Ep:192, loss:0.00001, loss_test:0.10814, lr:2.00e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.423, tt:6064.709\n",
      "Ep:193, loss:0.00001, loss_test:0.10792, lr:1.98e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.426, tt:6096.716\n",
      "Ep:194, loss:0.00001, loss_test:0.10819, lr:1.96e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.433, tt:6129.434\n",
      "Ep:195, loss:0.00001, loss_test:0.10834, lr:1.94e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.420, tt:6158.409\n",
      "Ep:196, loss:0.00001, loss_test:0.10785, lr:1.92e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.427, tt:6191.049\n",
      "Ep:197, loss:0.00001, loss_test:0.10826, lr:1.90e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.438, tt:6224.694\n",
      "Ep:198, loss:0.00001, loss_test:0.10831, lr:1.89e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.439, tt:6256.301\n",
      "Ep:199, loss:0.00001, loss_test:0.10801, lr:1.87e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.432, tt:6286.396\n",
      "Ep:200, loss:0.00001, loss_test:0.10787, lr:1.85e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.423, tt:6316.015\n",
      "Ep:201, loss:0.00001, loss_test:0.10840, lr:1.83e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.403, tt:6343.470\n",
      "Ep:202, loss:0.00001, loss_test:0.10849, lr:1.81e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.388, tt:6371.689\n",
      "Ep:203, loss:0.00001, loss_test:0.10794, lr:1.79e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.364, tt:6398.177\n",
      "Ep:204, loss:0.00001, loss_test:0.10828, lr:1.78e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.338, tt:6424.209\n",
      "Ep:205, loss:0.00001, loss_test:0.10847, lr:1.76e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.291, tt:6445.938\n",
      "Ep:206, loss:0.00001, loss_test:0.10813, lr:1.74e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.212, tt:6460.930\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14593, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:29.907, tt:29.907\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14527, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.631, tt:63.262\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00014, loss_test:0.14419, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:31.577, tt:94.732\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00013, loss_test:0.14250, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:31.317, tt:125.269\n",
      "Ep:4, loss:0.00013, loss_test:0.14036, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:31.267, tt:156.337\n",
      "Ep:5, loss:0.00012, loss_test:0.13785, lr:1.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:31.557, tt:189.344\n",
      "Ep:6, loss:0.00012, loss_test:0.13615, lr:1.00e-02, fs:0.57143 (r=0.606,p=0.541),  time:31.579, tt:221.052\n",
      "Ep:7, loss:0.00011, loss_test:0.13775, lr:1.00e-02, fs:0.52273 (r=0.465,p=0.597),  time:31.466, tt:251.730\n",
      "Ep:8, loss:0.00011, loss_test:0.13513, lr:1.00e-02, fs:0.52874 (r=0.465,p=0.613),  time:31.570, tt:284.134\n",
      "Ep:9, loss:0.00011, loss_test:0.12911, lr:1.00e-02, fs:0.59067 (r=0.576,p=0.606),  time:31.686, tt:316.864\n",
      "Ep:10, loss:0.00010, loss_test:0.12583, lr:1.00e-02, fs:0.64000 (r=0.646,p=0.634),  time:31.759, tt:349.351\n",
      "Ep:11, loss:0.00010, loss_test:0.12522, lr:1.00e-02, fs:0.62637 (r=0.576,p=0.687),  time:31.769, tt:381.227\n",
      "Ep:12, loss:0.00010, loss_test:0.12479, lr:1.00e-02, fs:0.63636 (r=0.566,p=0.727),  time:31.820, tt:413.666\n",
      "Ep:13, loss:0.00010, loss_test:0.12191, lr:1.00e-02, fs:0.64407 (r=0.576,p=0.731),  time:31.841, tt:445.773\n",
      "Ep:14, loss:0.00009, loss_test:0.11955, lr:9.90e-03, fs:0.68478 (r=0.636,p=0.741),  time:31.835, tt:477.528\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00009, loss_test:0.11859, lr:9.90e-03, fs:0.68852 (r=0.636,p=0.750),  time:31.839, tt:509.421\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00009, loss_test:0.11776, lr:9.90e-03, fs:0.69613 (r=0.636,p=0.768),  time:31.807, tt:540.716\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.11582, lr:9.90e-03, fs:0.70330 (r=0.646,p=0.771),  time:31.823, tt:572.822\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00008, loss_test:0.11471, lr:9.90e-03, fs:0.70652 (r=0.657,p=0.765),  time:31.836, tt:604.883\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.11393, lr:9.90e-03, fs:0.72131 (r=0.667,p=0.786),  time:31.828, tt:636.569\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.11223, lr:9.90e-03, fs:0.72727 (r=0.687,p=0.773),  time:31.876, tt:669.398\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.10989, lr:9.90e-03, fs:0.74074 (r=0.707,p=0.778),  time:31.883, tt:701.426\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.10953, lr:9.90e-03, fs:0.73118 (r=0.687,p=0.782),  time:31.897, tt:733.624\n",
      "Ep:23, loss:0.00007, loss_test:0.10929, lr:9.90e-03, fs:0.73224 (r=0.677,p=0.798),  time:31.892, tt:765.411\n",
      "Ep:24, loss:0.00007, loss_test:0.10741, lr:9.90e-03, fs:0.73514 (r=0.687,p=0.791),  time:31.937, tt:798.414\n",
      "Ep:25, loss:0.00007, loss_test:0.10771, lr:9.90e-03, fs:0.75000 (r=0.697,p=0.812),  time:31.913, tt:829.735\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.10738, lr:9.90e-03, fs:0.74317 (r=0.687,p=0.810),  time:31.995, tt:863.874\n",
      "Ep:27, loss:0.00007, loss_test:0.10528, lr:9.90e-03, fs:0.75676 (r=0.707,p=0.814),  time:32.020, tt:896.565\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.10597, lr:9.90e-03, fs:0.74725 (r=0.687,p=0.819),  time:32.087, tt:930.514\n",
      "Ep:29, loss:0.00006, loss_test:0.10618, lr:9.90e-03, fs:0.75556 (r=0.687,p=0.840),  time:32.116, tt:963.485\n",
      "Ep:30, loss:0.00006, loss_test:0.10440, lr:9.90e-03, fs:0.76503 (r=0.707,p=0.833),  time:32.120, tt:995.717\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.10498, lr:9.90e-03, fs:0.76243 (r=0.697,p=0.841),  time:32.148, tt:1028.743\n",
      "Ep:32, loss:0.00006, loss_test:0.10411, lr:9.90e-03, fs:0.76667 (r=0.697,p=0.852),  time:32.164, tt:1061.427\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.10300, lr:9.90e-03, fs:0.76243 (r=0.697,p=0.841),  time:32.206, tt:1094.997\n",
      "Ep:34, loss:0.00006, loss_test:0.10332, lr:9.90e-03, fs:0.76404 (r=0.687,p=0.861),  time:32.219, tt:1127.662\n",
      "Ep:35, loss:0.00006, loss_test:0.10139, lr:9.90e-03, fs:0.77348 (r=0.707,p=0.854),  time:32.229, tt:1160.245\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00005, loss_test:0.10110, lr:9.90e-03, fs:0.77596 (r=0.717,p=0.845),  time:32.281, tt:1194.408\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.10260, lr:9.90e-03, fs:0.77273 (r=0.687,p=0.883),  time:32.312, tt:1227.857\n",
      "Ep:38, loss:0.00005, loss_test:0.10031, lr:9.90e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.334, tt:1261.028\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.10163, lr:9.90e-03, fs:0.77966 (r=0.697,p=0.885),  time:32.367, tt:1294.689\n",
      "Ep:40, loss:0.00005, loss_test:0.09950, lr:9.90e-03, fs:0.77528 (r=0.697,p=0.873),  time:32.344, tt:1326.095\n",
      "Ep:41, loss:0.00005, loss_test:0.10005, lr:9.90e-03, fs:0.78652 (r=0.707,p=0.886),  time:32.357, tt:1358.982\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.09926, lr:9.90e-03, fs:0.78409 (r=0.697,p=0.896),  time:32.354, tt:1391.217\n",
      "Ep:43, loss:0.00005, loss_test:0.09854, lr:9.90e-03, fs:0.78409 (r=0.697,p=0.896),  time:32.373, tt:1424.433\n",
      "Ep:44, loss:0.00004, loss_test:0.09979, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.407, tt:1458.335\n",
      "Ep:45, loss:0.00004, loss_test:0.09836, lr:9.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:32.456, tt:1492.983\n",
      "Ep:46, loss:0.00004, loss_test:0.10025, lr:9.90e-03, fs:0.73054 (r=0.616,p=0.897),  time:32.428, tt:1524.110\n",
      "Ep:47, loss:0.00004, loss_test:0.09767, lr:9.90e-03, fs:0.78161 (r=0.687,p=0.907),  time:32.445, tt:1557.345\n",
      "Ep:48, loss:0.00004, loss_test:0.10004, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:32.435, tt:1589.332\n",
      "Ep:49, loss:0.00004, loss_test:0.09875, lr:9.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:32.406, tt:1620.275\n",
      "Ep:50, loss:0.00004, loss_test:0.09929, lr:9.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.415, tt:1653.162\n",
      "Ep:51, loss:0.00004, loss_test:0.09962, lr:9.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.422, tt:1685.948\n",
      "Ep:52, loss:0.00004, loss_test:0.09974, lr:9.90e-03, fs:0.75000 (r=0.636,p=0.913),  time:32.450, tt:1719.836\n",
      "Ep:53, loss:0.00003, loss_test:0.10024, lr:9.80e-03, fs:0.72727 (r=0.606,p=0.909),  time:32.443, tt:1751.911\n",
      "Ep:54, loss:0.00003, loss_test:0.10043, lr:9.70e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.463, tt:1785.467\n",
      "Ep:55, loss:0.00003, loss_test:0.10174, lr:9.61e-03, fs:0.69939 (r=0.576,p=0.891),  time:32.457, tt:1817.578\n",
      "Ep:56, loss:0.00003, loss_test:0.10006, lr:9.51e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.450, tt:1849.622\n",
      "Ep:57, loss:0.00003, loss_test:0.10522, lr:9.41e-03, fs:0.63158 (r=0.485,p=0.906),  time:32.467, tt:1883.097\n",
      "Ep:58, loss:0.00003, loss_test:0.10149, lr:9.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:32.523, tt:1918.856\n",
      "Ep:59, loss:0.00003, loss_test:0.10276, lr:9.23e-03, fs:0.68354 (r=0.545,p=0.915),  time:32.537, tt:1952.215\n",
      "Ep:60, loss:0.00003, loss_test:0.10626, lr:9.14e-03, fs:0.60403 (r=0.455,p=0.900),  time:32.538, tt:1984.827\n",
      "Ep:61, loss:0.00003, loss_test:0.10142, lr:9.04e-03, fs:0.71515 (r=0.596,p=0.894),  time:32.546, tt:2017.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00003, loss_test:0.10746, lr:8.95e-03, fs:0.56944 (r=0.414,p=0.911),  time:32.548, tt:2050.553\n",
      "Ep:63, loss:0.00003, loss_test:0.10393, lr:8.86e-03, fs:0.64474 (r=0.495,p=0.925),  time:32.545, tt:2082.908\n",
      "Ep:64, loss:0.00003, loss_test:0.10667, lr:8.78e-03, fs:0.57931 (r=0.424,p=0.913),  time:32.549, tt:2115.715\n",
      "Ep:65, loss:0.00003, loss_test:0.10497, lr:8.69e-03, fs:0.62252 (r=0.475,p=0.904),  time:32.578, tt:2150.122\n",
      "Ep:66, loss:0.00002, loss_test:0.10799, lr:8.60e-03, fs:0.56944 (r=0.414,p=0.911),  time:32.569, tt:2182.143\n",
      "Ep:67, loss:0.00002, loss_test:0.10569, lr:8.51e-03, fs:0.62667 (r=0.475,p=0.922),  time:32.588, tt:2216.006\n",
      "Ep:68, loss:0.00002, loss_test:0.10920, lr:8.43e-03, fs:0.56944 (r=0.414,p=0.911),  time:32.609, tt:2250.025\n",
      "Ep:69, loss:0.00002, loss_test:0.10634, lr:8.35e-03, fs:0.58904 (r=0.434,p=0.915),  time:32.591, tt:2281.380\n",
      "Ep:70, loss:0.00002, loss_test:0.11049, lr:8.26e-03, fs:0.55944 (r=0.404,p=0.909),  time:32.605, tt:2314.939\n",
      "Ep:71, loss:0.00002, loss_test:0.10813, lr:8.18e-03, fs:0.55944 (r=0.404,p=0.909),  time:32.603, tt:2347.418\n",
      "Ep:72, loss:0.00002, loss_test:0.11096, lr:8.10e-03, fs:0.54930 (r=0.394,p=0.907),  time:32.625, tt:2381.608\n",
      "Ep:73, loss:0.00002, loss_test:0.11140, lr:8.02e-03, fs:0.54930 (r=0.394,p=0.907),  time:32.626, tt:2414.311\n",
      "Ep:74, loss:0.00002, loss_test:0.10971, lr:7.94e-03, fs:0.55944 (r=0.404,p=0.909),  time:32.632, tt:2447.421\n",
      "Ep:75, loss:0.00002, loss_test:0.11199, lr:7.86e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.638, tt:2480.453\n",
      "Ep:76, loss:0.00002, loss_test:0.11003, lr:7.78e-03, fs:0.55944 (r=0.404,p=0.909),  time:32.660, tt:2514.788\n",
      "Ep:77, loss:0.00002, loss_test:0.11256, lr:7.70e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.648, tt:2546.508\n",
      "Ep:78, loss:0.00002, loss_test:0.11099, lr:7.62e-03, fs:0.54930 (r=0.394,p=0.907),  time:32.640, tt:2578.527\n",
      "Ep:79, loss:0.00002, loss_test:0.11240, lr:7.55e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.649, tt:2611.910\n",
      "Ep:80, loss:0.00002, loss_test:0.11349, lr:7.47e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.650, tt:2644.661\n",
      "Ep:81, loss:0.00002, loss_test:0.11097, lr:7.40e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.641, tt:2676.596\n",
      "Ep:82, loss:0.00002, loss_test:0.11465, lr:7.32e-03, fs:0.53901 (r=0.384,p=0.905),  time:32.644, tt:2709.410\n",
      "Ep:83, loss:0.00002, loss_test:0.11283, lr:7.25e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.665, tt:2743.854\n",
      "Ep:84, loss:0.00002, loss_test:0.11506, lr:7.18e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.672, tt:2777.103\n",
      "Ep:85, loss:0.00002, loss_test:0.11374, lr:7.11e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.676, tt:2810.129\n",
      "Ep:86, loss:0.00002, loss_test:0.11763, lr:7.03e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.684, tt:2843.512\n",
      "Ep:87, loss:0.00002, loss_test:0.11378, lr:6.96e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.691, tt:2876.840\n",
      "Ep:88, loss:0.00002, loss_test:0.11573, lr:6.89e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.712, tt:2911.407\n",
      "Ep:89, loss:0.00002, loss_test:0.11845, lr:6.83e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.710, tt:2943.890\n",
      "Ep:90, loss:0.00001, loss_test:0.11414, lr:6.76e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.714, tt:2976.949\n",
      "Ep:91, loss:0.00001, loss_test:0.11841, lr:6.69e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.690, tt:3007.452\n",
      "Ep:92, loss:0.00001, loss_test:0.11603, lr:6.62e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.690, tt:3040.126\n",
      "Ep:93, loss:0.00001, loss_test:0.11690, lr:6.56e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.693, tt:3073.104\n",
      "Ep:94, loss:0.00001, loss_test:0.11766, lr:6.49e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.700, tt:3106.495\n",
      "Ep:95, loss:0.00001, loss_test:0.11707, lr:6.43e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.715, tt:3140.621\n",
      "Ep:96, loss:0.00001, loss_test:0.11675, lr:6.36e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.703, tt:3172.160\n",
      "Ep:97, loss:0.00001, loss_test:0.11747, lr:6.30e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.696, tt:3204.242\n",
      "Ep:98, loss:0.00001, loss_test:0.11766, lr:6.24e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.707, tt:3237.949\n",
      "Ep:99, loss:0.00001, loss_test:0.11762, lr:6.17e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.695, tt:3269.476\n",
      "Ep:100, loss:0.00001, loss_test:0.11858, lr:6.11e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.693, tt:3302.011\n",
      "Ep:101, loss:0.00001, loss_test:0.11780, lr:6.05e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.692, tt:3334.634\n",
      "Ep:102, loss:0.00001, loss_test:0.11871, lr:5.99e-03, fs:0.51799 (r=0.364,p=0.900),  time:32.697, tt:3367.752\n",
      "Ep:103, loss:0.00001, loss_test:0.11959, lr:5.93e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.707, tt:3401.551\n",
      "Ep:104, loss:0.00001, loss_test:0.11964, lr:5.87e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.707, tt:3434.207\n",
      "Ep:105, loss:0.00001, loss_test:0.11806, lr:5.81e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.703, tt:3466.570\n",
      "Ep:106, loss:0.00001, loss_test:0.12195, lr:5.75e-03, fs:0.51095 (r=0.354,p=0.921),  time:32.717, tt:3500.726\n",
      "Ep:107, loss:0.00001, loss_test:0.11804, lr:5.70e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.719, tt:3533.632\n",
      "Ep:108, loss:0.00001, loss_test:0.11970, lr:5.64e-03, fs:0.53237 (r=0.374,p=0.925),  time:32.716, tt:3566.004\n",
      "Ep:109, loss:0.00001, loss_test:0.12145, lr:5.58e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.733, tt:3600.586\n",
      "Ep:110, loss:0.00001, loss_test:0.11894, lr:5.53e-03, fs:0.51799 (r=0.364,p=0.900),  time:32.732, tt:3633.277\n",
      "Ep:111, loss:0.00001, loss_test:0.12143, lr:5.47e-03, fs:0.51799 (r=0.364,p=0.900),  time:32.736, tt:3666.413\n",
      "Ep:112, loss:0.00001, loss_test:0.12122, lr:5.42e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.723, tt:3697.721\n",
      "Ep:113, loss:0.00001, loss_test:0.11913, lr:5.36e-03, fs:0.52857 (r=0.374,p=0.902),  time:32.724, tt:3730.579\n",
      "Ep:114, loss:0.00001, loss_test:0.12156, lr:5.31e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.710, tt:3761.666\n",
      "Ep:115, loss:0.00001, loss_test:0.12162, lr:5.26e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.707, tt:3793.961\n",
      "Ep:116, loss:0.00001, loss_test:0.11989, lr:5.20e-03, fs:0.53237 (r=0.374,p=0.925),  time:32.707, tt:3826.687\n",
      "Ep:117, loss:0.00001, loss_test:0.12253, lr:5.15e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.703, tt:3858.955\n",
      "Ep:118, loss:0.00001, loss_test:0.12235, lr:5.10e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.688, tt:3889.905\n",
      "Ep:119, loss:0.00001, loss_test:0.12073, lr:5.05e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.689, tt:3922.656\n",
      "Ep:120, loss:0.00001, loss_test:0.12355, lr:5.00e-03, fs:0.48889 (r=0.333,p=0.917),  time:32.694, tt:3956.023\n",
      "Ep:121, loss:0.00001, loss_test:0.12207, lr:4.95e-03, fs:0.52174 (r=0.364,p=0.923),  time:32.689, tt:3988.078\n",
      "Ep:122, loss:0.00001, loss_test:0.12151, lr:4.90e-03, fs:0.52555 (r=0.364,p=0.947),  time:32.691, tt:4020.955\n",
      "Ep:123, loss:0.00001, loss_test:0.12291, lr:4.85e-03, fs:0.51471 (r=0.354,p=0.946),  time:32.689, tt:4053.411\n",
      "Ep:124, loss:0.00001, loss_test:0.12186, lr:4.80e-03, fs:0.52555 (r=0.364,p=0.947),  time:32.693, tt:4086.594\n",
      "Ep:125, loss:0.00001, loss_test:0.12349, lr:4.75e-03, fs:0.48889 (r=0.333,p=0.917),  time:32.699, tt:4120.081\n",
      "Ep:126, loss:0.00001, loss_test:0.12378, lr:4.71e-03, fs:0.52555 (r=0.364,p=0.947),  time:32.690, tt:4151.689\n",
      "Ep:127, loss:0.00001, loss_test:0.12310, lr:4.66e-03, fs:0.49254 (r=0.333,p=0.943),  time:32.701, tt:4185.689\n",
      "Ep:128, loss:0.00001, loss_test:0.12285, lr:4.61e-03, fs:0.52555 (r=0.364,p=0.947),  time:32.703, tt:4218.647\n",
      "Ep:129, loss:0.00001, loss_test:0.12413, lr:4.57e-03, fs:0.49624 (r=0.333,p=0.971),  time:32.720, tt:4253.615\n",
      "Ep:130, loss:0.00001, loss_test:0.12508, lr:4.52e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.725, tt:4286.935\n",
      "Ep:131, loss:0.00001, loss_test:0.12331, lr:4.48e-03, fs:0.52941 (r=0.364,p=0.973),  time:32.728, tt:4320.130\n",
      "Ep:132, loss:0.00001, loss_test:0.12391, lr:4.43e-03, fs:0.48120 (r=0.323,p=0.941),  time:32.720, tt:4351.813\n",
      "Ep:133, loss:0.00001, loss_test:0.12498, lr:4.39e-03, fs:0.49624 (r=0.333,p=0.971),  time:32.731, tt:4386.004\n",
      "Ep:134, loss:0.00001, loss_test:0.12471, lr:4.34e-03, fs:0.50746 (r=0.343,p=0.971),  time:32.731, tt:4418.747\n",
      "Ep:135, loss:0.00001, loss_test:0.12413, lr:4.30e-03, fs:0.49624 (r=0.333,p=0.971),  time:32.721, tt:4450.022\n",
      "Ep:136, loss:0.00001, loss_test:0.12499, lr:4.26e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.724, tt:4483.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.12540, lr:4.21e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.730, tt:4516.727\n",
      "Ep:138, loss:0.00001, loss_test:0.12458, lr:4.17e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.734, tt:4550.035\n",
      "Ep:139, loss:0.00001, loss_test:0.12563, lr:4.13e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.731, tt:4582.297\n",
      "Ep:140, loss:0.00001, loss_test:0.12550, lr:4.09e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.733, tt:4615.404\n",
      "Ep:141, loss:0.00001, loss_test:0.12539, lr:4.05e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.739, tt:4648.996\n",
      "Ep:142, loss:0.00001, loss_test:0.12607, lr:4.01e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.750, tt:4683.316\n",
      "Ep:143, loss:0.00001, loss_test:0.12657, lr:3.97e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.756, tt:4716.820\n",
      "Ep:144, loss:0.00001, loss_test:0.12579, lr:3.93e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.756, tt:4749.615\n",
      "Ep:145, loss:0.00001, loss_test:0.12650, lr:3.89e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.749, tt:4781.378\n",
      "Ep:146, loss:0.00001, loss_test:0.12599, lr:3.85e-03, fs:0.49624 (r=0.333,p=0.971),  time:32.752, tt:4814.589\n",
      "Ep:147, loss:0.00001, loss_test:0.12653, lr:3.81e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.756, tt:4847.829\n",
      "Ep:148, loss:0.00001, loss_test:0.12796, lr:3.77e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.762, tt:4881.564\n",
      "Ep:149, loss:0.00001, loss_test:0.12620, lr:3.73e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.763, tt:4914.465\n",
      "Ep:150, loss:0.00001, loss_test:0.12728, lr:3.70e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.783, tt:4950.264\n",
      "Ep:151, loss:0.00001, loss_test:0.12854, lr:3.66e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.776, tt:4982.028\n",
      "Ep:152, loss:0.00001, loss_test:0.12657, lr:3.62e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.778, tt:5015.047\n",
      "Ep:153, loss:0.00001, loss_test:0.12757, lr:3.59e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.784, tt:5048.766\n",
      "Ep:154, loss:0.00001, loss_test:0.12799, lr:3.55e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.784, tt:5081.580\n",
      "Ep:155, loss:0.00001, loss_test:0.12754, lr:3.52e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.783, tt:5114.083\n",
      "Ep:156, loss:0.00001, loss_test:0.12812, lr:3.48e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.787, tt:5147.599\n",
      "Ep:157, loss:0.00001, loss_test:0.12926, lr:3.45e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.792, tt:5181.139\n",
      "Ep:158, loss:0.00001, loss_test:0.12805, lr:3.41e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.795, tt:5214.417\n",
      "Ep:159, loss:0.00001, loss_test:0.12845, lr:3.38e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.798, tt:5247.707\n",
      "Ep:160, loss:0.00001, loss_test:0.12938, lr:3.34e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.803, tt:5281.202\n",
      "Ep:161, loss:0.00001, loss_test:0.12804, lr:3.31e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.801, tt:5313.689\n",
      "Ep:162, loss:0.00001, loss_test:0.12865, lr:3.28e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.802, tt:5346.711\n",
      "Ep:163, loss:0.00001, loss_test:0.12861, lr:3.24e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.797, tt:5378.766\n",
      "Ep:164, loss:0.00001, loss_test:0.12891, lr:3.21e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.796, tt:5411.276\n",
      "Ep:165, loss:0.00001, loss_test:0.12889, lr:3.18e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.796, tt:5444.056\n",
      "Ep:166, loss:0.00001, loss_test:0.12925, lr:3.15e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.789, tt:5475.691\n",
      "Ep:167, loss:0.00001, loss_test:0.12938, lr:3.12e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.784, tt:5507.795\n",
      "Ep:168, loss:0.00001, loss_test:0.12999, lr:3.09e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.785, tt:5540.709\n",
      "Ep:169, loss:0.00001, loss_test:0.12979, lr:3.05e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.777, tt:5572.016\n",
      "Ep:170, loss:0.00001, loss_test:0.13034, lr:3.02e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.770, tt:5603.642\n",
      "Ep:171, loss:0.00001, loss_test:0.12971, lr:2.99e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.773, tt:5636.947\n",
      "Ep:172, loss:0.00001, loss_test:0.12965, lr:2.96e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.772, tt:5669.587\n",
      "Ep:173, loss:0.00001, loss_test:0.13008, lr:2.93e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.778, tt:5703.290\n",
      "Ep:174, loss:0.00001, loss_test:0.13012, lr:2.90e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.770, tt:5734.836\n",
      "Ep:175, loss:0.00001, loss_test:0.12980, lr:2.88e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.759, tt:5765.643\n",
      "Ep:176, loss:0.00001, loss_test:0.13016, lr:2.85e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.762, tt:5798.793\n",
      "Ep:177, loss:0.00001, loss_test:0.13016, lr:2.82e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.760, tt:5831.250\n",
      "Ep:178, loss:0.00001, loss_test:0.13068, lr:2.79e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.755, tt:5863.097\n",
      "Ep:179, loss:0.00001, loss_test:0.13074, lr:2.76e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.745, tt:5894.048\n",
      "Ep:180, loss:0.00001, loss_test:0.13038, lr:2.73e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.739, tt:5925.806\n",
      "Ep:181, loss:0.00001, loss_test:0.13093, lr:2.71e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.737, tt:5958.197\n",
      "Ep:182, loss:0.00001, loss_test:0.13115, lr:2.68e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.734, tt:5990.272\n",
      "Ep:183, loss:0.00001, loss_test:0.13074, lr:2.65e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.733, tt:6022.780\n",
      "Ep:184, loss:0.00001, loss_test:0.13105, lr:2.63e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.731, tt:6055.251\n",
      "Ep:185, loss:0.00001, loss_test:0.13188, lr:2.60e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.721, tt:6086.062\n",
      "Ep:186, loss:0.00001, loss_test:0.13079, lr:2.57e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.711, tt:6116.995\n",
      "Ep:187, loss:0.00001, loss_test:0.13138, lr:2.55e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.715, tt:6150.418\n",
      "Ep:188, loss:0.00001, loss_test:0.13113, lr:2.52e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.714, tt:6182.869\n",
      "Ep:189, loss:0.00001, loss_test:0.13182, lr:2.50e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.706, tt:6214.152\n",
      "Ep:190, loss:0.00001, loss_test:0.13203, lr:2.47e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.701, tt:6245.847\n",
      "Ep:191, loss:0.00001, loss_test:0.13182, lr:2.45e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.721, tt:6282.370\n",
      "Ep:192, loss:0.00001, loss_test:0.13212, lr:2.42e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.718, tt:6314.659\n",
      "Ep:193, loss:0.00001, loss_test:0.13125, lr:2.40e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.713, tt:6346.402\n",
      "Ep:194, loss:0.00001, loss_test:0.13190, lr:2.38e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.708, tt:6378.132\n",
      "Ep:195, loss:0.00001, loss_test:0.13200, lr:2.35e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.704, tt:6409.899\n",
      "Ep:196, loss:0.00001, loss_test:0.13174, lr:2.33e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.699, tt:6441.685\n",
      "Ep:197, loss:0.00001, loss_test:0.13275, lr:2.31e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.691, tt:6472.789\n",
      "Ep:198, loss:0.00001, loss_test:0.13256, lr:2.28e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.681, tt:6503.522\n",
      "Ep:199, loss:0.00001, loss_test:0.13199, lr:2.26e-03, fs:0.48485 (r=0.323,p=0.970),  time:32.669, tt:6533.849\n",
      "Ep:200, loss:0.00001, loss_test:0.13261, lr:2.24e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.665, tt:6565.720\n",
      "Ep:201, loss:0.00001, loss_test:0.13238, lr:2.21e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.657, tt:6596.751\n",
      "Ep:202, loss:0.00001, loss_test:0.13245, lr:2.19e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.654, tt:6628.770\n",
      "Ep:203, loss:0.00001, loss_test:0.13303, lr:2.17e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.642, tt:6658.913\n",
      "Ep:204, loss:0.00001, loss_test:0.13252, lr:2.15e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.623, tt:6687.740\n",
      "Ep:205, loss:0.00001, loss_test:0.13257, lr:2.13e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.586, tt:6712.722\n",
      "Ep:206, loss:0.00001, loss_test:0.13278, lr:2.11e-03, fs:0.47328 (r=0.313,p=0.969),  time:32.496, tt:6726.570\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14602, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.768, tt:62.768\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14372, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:64.311, tt:128.622\n",
      "Ep:2, loss:0.00053, loss_test:0.13832, lr:1.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:64.532, tt:193.597\n",
      "Ep:3, loss:0.00048, loss_test:0.13514, lr:1.00e-02, fs:0.53608 (r=0.525,p=0.547),  time:64.903, tt:259.612\n",
      "Ep:4, loss:0.00045, loss_test:0.13326, lr:1.00e-02, fs:0.58586 (r=0.586,p=0.586),  time:65.002, tt:325.012\n",
      "Ep:5, loss:0.00043, loss_test:0.12591, lr:1.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:65.313, tt:391.880\n",
      "Ep:6, loss:0.00041, loss_test:0.12399, lr:1.00e-02, fs:0.60215 (r=0.566,p=0.644),  time:65.535, tt:458.748\n",
      "Ep:7, loss:0.00038, loss_test:0.11697, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:65.527, tt:524.220\n",
      "Ep:8, loss:0.00036, loss_test:0.11656, lr:1.00e-02, fs:0.66298 (r=0.606,p=0.732),  time:65.635, tt:590.715\n",
      "Ep:9, loss:0.00034, loss_test:0.11102, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:65.635, tt:656.346\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.11173, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:65.743, tt:723.167\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.10603, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:65.790, tt:789.477\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00029, loss_test:0.10871, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:65.670, tt:853.710\n",
      "Ep:13, loss:0.00028, loss_test:0.10442, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:65.700, tt:919.806\n",
      "Ep:14, loss:0.00026, loss_test:0.10238, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:65.695, tt:985.418\n",
      "Ep:15, loss:0.00025, loss_test:0.10428, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:65.824, tt:1053.181\n",
      "Ep:16, loss:0.00024, loss_test:0.09944, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:65.868, tt:1119.764\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.09941, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:65.954, tt:1187.174\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10345, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:65.835, tt:1250.864\n",
      "Ep:19, loss:0.00021, loss_test:0.09991, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:65.924, tt:1318.475\n",
      "Ep:20, loss:0.00020, loss_test:0.09560, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:65.925, tt:1384.428\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09970, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:65.956, tt:1451.026\n",
      "Ep:22, loss:0.00018, loss_test:0.10398, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:65.952, tt:1516.893\n",
      "Ep:23, loss:0.00018, loss_test:0.09380, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:65.991, tt:1583.776\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09688, lr:1.00e-02, fs:0.70175 (r=0.606,p=0.833),  time:65.893, tt:1647.334\n",
      "Ep:25, loss:0.00016, loss_test:0.10538, lr:1.00e-02, fs:0.66250 (r=0.535,p=0.869),  time:65.900, tt:1713.397\n",
      "Ep:26, loss:0.00015, loss_test:0.09946, lr:1.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:65.863, tt:1778.300\n",
      "Ep:27, loss:0.00014, loss_test:0.09482, lr:1.00e-02, fs:0.69822 (r=0.596,p=0.843),  time:65.928, tt:1845.972\n",
      "Ep:28, loss:0.00014, loss_test:0.09856, lr:1.00e-02, fs:0.66667 (r=0.545,p=0.857),  time:65.906, tt:1911.267\n",
      "Ep:29, loss:0.00013, loss_test:0.10124, lr:1.00e-02, fs:0.63291 (r=0.505,p=0.847),  time:65.867, tt:1976.002\n",
      "Ep:30, loss:0.00013, loss_test:0.09534, lr:1.00e-02, fs:0.69822 (r=0.596,p=0.843),  time:65.890, tt:2042.578\n",
      "Ep:31, loss:0.00012, loss_test:0.09605, lr:1.00e-02, fs:0.67073 (r=0.556,p=0.846),  time:65.909, tt:2109.088\n",
      "Ep:32, loss:0.00011, loss_test:0.09742, lr:1.00e-02, fs:0.63750 (r=0.515,p=0.836),  time:65.863, tt:2173.472\n",
      "Ep:33, loss:0.00011, loss_test:0.09827, lr:1.00e-02, fs:0.62745 (r=0.485,p=0.889),  time:65.821, tt:2237.915\n",
      "Ep:34, loss:0.00010, loss_test:0.09771, lr:1.00e-02, fs:0.63694 (r=0.505,p=0.862),  time:65.838, tt:2304.338\n",
      "Ep:35, loss:0.00010, loss_test:0.10053, lr:9.90e-03, fs:0.62667 (r=0.475,p=0.922),  time:65.770, tt:2367.714\n",
      "Ep:36, loss:0.00009, loss_test:0.10315, lr:9.80e-03, fs:0.62667 (r=0.475,p=0.922),  time:65.713, tt:2431.395\n",
      "Ep:37, loss:0.00009, loss_test:0.10230, lr:9.70e-03, fs:0.62667 (r=0.475,p=0.922),  time:65.691, tt:2496.265\n",
      "Ep:38, loss:0.00009, loss_test:0.09924, lr:9.61e-03, fs:0.65359 (r=0.505,p=0.926),  time:65.722, tt:2563.171\n",
      "Ep:39, loss:0.00008, loss_test:0.09479, lr:9.51e-03, fs:0.66667 (r=0.525,p=0.912),  time:65.674, tt:2626.959\n",
      "Ep:40, loss:0.00008, loss_test:0.09953, lr:9.41e-03, fs:0.63087 (r=0.475,p=0.940),  time:65.656, tt:2691.906\n",
      "Ep:41, loss:0.00008, loss_test:0.10179, lr:9.32e-03, fs:0.62162 (r=0.465,p=0.939),  time:65.648, tt:2757.230\n",
      "Ep:42, loss:0.00007, loss_test:0.10252, lr:9.23e-03, fs:0.63087 (r=0.475,p=0.940),  time:65.625, tt:2821.881\n",
      "Ep:43, loss:0.00007, loss_test:0.10697, lr:9.14e-03, fs:0.63087 (r=0.475,p=0.940),  time:65.619, tt:2887.232\n",
      "Ep:44, loss:0.00007, loss_test:0.10395, lr:9.04e-03, fs:0.65333 (r=0.495,p=0.961),  time:65.587, tt:2951.406\n",
      "Ep:45, loss:0.00007, loss_test:0.10352, lr:8.95e-03, fs:0.63087 (r=0.475,p=0.940),  time:65.549, tt:3015.264\n",
      "Ep:46, loss:0.00007, loss_test:0.10300, lr:8.86e-03, fs:0.64000 (r=0.485,p=0.941),  time:65.559, tt:3081.251\n",
      "Ep:47, loss:0.00006, loss_test:0.10000, lr:8.78e-03, fs:0.62162 (r=0.465,p=0.939),  time:65.538, tt:3145.830\n",
      "Ep:48, loss:0.00006, loss_test:0.09893, lr:8.69e-03, fs:0.62162 (r=0.465,p=0.939),  time:65.530, tt:3210.966\n",
      "Ep:49, loss:0.00006, loss_test:0.10532, lr:8.60e-03, fs:0.62162 (r=0.465,p=0.939),  time:65.522, tt:3276.081\n",
      "Ep:50, loss:0.00006, loss_test:0.10597, lr:8.51e-03, fs:0.62585 (r=0.465,p=0.958),  time:65.516, tt:3341.318\n",
      "Ep:51, loss:0.00006, loss_test:0.09864, lr:8.43e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.501, tt:3406.074\n",
      "Ep:52, loss:0.00005, loss_test:0.10986, lr:8.35e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.531, tt:3473.148\n",
      "Ep:53, loss:0.00005, loss_test:0.10319, lr:8.26e-03, fs:0.62585 (r=0.465,p=0.958),  time:65.536, tt:3538.919\n",
      "Ep:54, loss:0.00005, loss_test:0.10798, lr:8.18e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.514, tt:3603.279\n",
      "Ep:55, loss:0.00005, loss_test:0.10365, lr:8.10e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.497, tt:3667.854\n",
      "Ep:56, loss:0.00005, loss_test:0.10945, lr:8.02e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.491, tt:3732.967\n",
      "Ep:57, loss:0.00005, loss_test:0.10587, lr:7.94e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.521, tt:3800.226\n",
      "Ep:58, loss:0.00005, loss_test:0.10671, lr:7.86e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.526, tt:3866.031\n",
      "Ep:59, loss:0.00004, loss_test:0.10592, lr:7.78e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.501, tt:3930.089\n",
      "Ep:60, loss:0.00004, loss_test:0.11013, lr:7.70e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.472, tt:3993.805\n",
      "Ep:61, loss:0.00004, loss_test:0.11129, lr:7.62e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.468, tt:4059.004\n",
      "Ep:62, loss:0.00004, loss_test:0.10988, lr:7.55e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.473, tt:4124.819\n",
      "Ep:63, loss:0.00004, loss_test:0.10651, lr:7.47e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.461, tt:4189.527\n",
      "Ep:64, loss:0.00004, loss_test:0.11145, lr:7.40e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.474, tt:4255.802\n",
      "Ep:65, loss:0.00004, loss_test:0.11363, lr:7.32e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.508, tt:4323.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00004, loss_test:0.10920, lr:7.25e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.519, tt:4389.760\n",
      "Ep:67, loss:0.00004, loss_test:0.11186, lr:7.18e-03, fs:0.61111 (r=0.444,p=0.978),  time:65.545, tt:4457.067\n",
      "Ep:68, loss:0.00004, loss_test:0.10933, lr:7.11e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.543, tt:4522.454\n",
      "Ep:69, loss:0.00004, loss_test:0.11470, lr:7.03e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.523, tt:4586.610\n",
      "Ep:70, loss:0.00003, loss_test:0.10844, lr:6.96e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.546, tt:4653.772\n",
      "Ep:71, loss:0.00003, loss_test:0.11238, lr:6.89e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.560, tt:4720.338\n",
      "Ep:72, loss:0.00003, loss_test:0.11559, lr:6.83e-03, fs:0.62069 (r=0.455,p=0.978),  time:65.577, tt:4787.085\n",
      "Ep:73, loss:0.00003, loss_test:0.10882, lr:6.76e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.575, tt:4852.528\n",
      "Ep:74, loss:0.00003, loss_test:0.11663, lr:6.69e-03, fs:0.62069 (r=0.455,p=0.978),  time:65.575, tt:4918.159\n",
      "Ep:75, loss:0.00003, loss_test:0.11319, lr:6.62e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.584, tt:4984.408\n",
      "Ep:76, loss:0.00003, loss_test:0.11298, lr:6.56e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.587, tt:5050.199\n",
      "Ep:77, loss:0.00003, loss_test:0.11810, lr:6.49e-03, fs:0.59155 (r=0.424,p=0.977),  time:65.565, tt:5114.079\n",
      "Ep:78, loss:0.00003, loss_test:0.11072, lr:6.43e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.573, tt:5180.278\n",
      "Ep:79, loss:0.00003, loss_test:0.11704, lr:6.36e-03, fs:0.61111 (r=0.444,p=0.978),  time:65.555, tt:5244.371\n",
      "Ep:80, loss:0.00003, loss_test:0.11352, lr:6.30e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.577, tt:5311.758\n",
      "Ep:81, loss:0.00003, loss_test:0.11830, lr:6.24e-03, fs:0.59155 (r=0.424,p=0.977),  time:65.587, tt:5378.148\n",
      "Ep:82, loss:0.00003, loss_test:0.11407, lr:6.17e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.625, tt:5446.895\n",
      "Ep:83, loss:0.00003, loss_test:0.11521, lr:6.11e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.609, tt:5511.122\n",
      "Ep:84, loss:0.00003, loss_test:0.11652, lr:6.05e-03, fs:0.60140 (r=0.434,p=0.977),  time:65.598, tt:5575.852\n",
      "Ep:85, loss:0.00003, loss_test:0.11843, lr:5.99e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.601, tt:5641.684\n",
      "Ep:86, loss:0.00002, loss_test:0.11711, lr:5.93e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.598, tt:5707.027\n",
      "Ep:87, loss:0.00002, loss_test:0.11619, lr:5.87e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.589, tt:5771.818\n",
      "Ep:88, loss:0.00002, loss_test:0.11885, lr:5.81e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.610, tt:5839.277\n",
      "Ep:89, loss:0.00002, loss_test:0.12107, lr:5.75e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.615, tt:5905.388\n",
      "Ep:90, loss:0.00002, loss_test:0.11653, lr:5.70e-03, fs:0.63014 (r=0.465,p=0.979),  time:65.628, tt:5972.163\n",
      "Ep:91, loss:0.00002, loss_test:0.12275, lr:5.64e-03, fs:0.55072 (r=0.384,p=0.974),  time:65.635, tt:6038.415\n",
      "Ep:92, loss:0.00002, loss_test:0.12200, lr:5.58e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.647, tt:6105.218\n",
      "Ep:93, loss:0.00002, loss_test:0.12145, lr:5.53e-03, fs:0.57143 (r=0.404,p=0.976),  time:65.652, tt:6171.308\n",
      "Ep:94, loss:0.00002, loss_test:0.11969, lr:5.47e-03, fs:0.61111 (r=0.444,p=0.978),  time:65.656, tt:6237.324\n",
      "Ep:95, loss:0.00002, loss_test:0.12294, lr:5.42e-03, fs:0.56115 (r=0.394,p=0.975),  time:65.669, tt:6304.231\n",
      "Ep:96, loss:0.00002, loss_test:0.12215, lr:5.36e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.630, tt:6366.099\n",
      "Ep:97, loss:0.00002, loss_test:0.12227, lr:5.31e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.685, tt:6437.136\n",
      "Ep:98, loss:0.00002, loss_test:0.12337, lr:5.26e-03, fs:0.57143 (r=0.404,p=0.976),  time:65.681, tt:6502.463\n",
      "Ep:99, loss:0.00002, loss_test:0.12180, lr:5.20e-03, fs:0.61111 (r=0.444,p=0.978),  time:65.691, tt:6569.115\n",
      "Ep:100, loss:0.00002, loss_test:0.12319, lr:5.15e-03, fs:0.57143 (r=0.404,p=0.976),  time:65.710, tt:6636.760\n",
      "Ep:101, loss:0.00002, loss_test:0.12283, lr:5.10e-03, fs:0.57143 (r=0.404,p=0.976),  time:65.714, tt:6702.806\n",
      "Ep:102, loss:0.00002, loss_test:0.12601, lr:5.05e-03, fs:0.54015 (r=0.374,p=0.974),  time:65.734, tt:6770.622\n",
      "Ep:103, loss:0.00002, loss_test:0.12292, lr:5.00e-03, fs:0.58156 (r=0.414,p=0.976),  time:65.747, tt:6837.682\n",
      "Ep:104, loss:0.00002, loss_test:0.12365, lr:4.95e-03, fs:0.59155 (r=0.424,p=0.977),  time:65.733, tt:6901.933\n",
      "Ep:105, loss:0.00002, loss_test:0.12516, lr:4.90e-03, fs:0.57143 (r=0.404,p=0.976),  time:65.747, tt:6969.212\n",
      "Ep:106, loss:0.00002, loss_test:0.12440, lr:4.85e-03, fs:0.57143 (r=0.404,p=0.976),  time:65.483, tt:7006.695\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14160, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:13.925, tt:13.925\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14122, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.153, tt:28.306\n",
      "Ep:2, loss:0.00014, loss_test:0.14064, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.470, tt:43.409\n",
      "Ep:3, loss:0.00014, loss_test:0.13986, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.885, tt:59.540\n",
      "Ep:4, loss:0.00014, loss_test:0.13882, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.999, tt:74.996\n",
      "Ep:5, loss:0.00014, loss_test:0.13752, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:15.036, tt:90.215\n",
      "Ep:6, loss:0.00014, loss_test:0.13589, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:15.143, tt:106.003\n",
      "Ep:7, loss:0.00013, loss_test:0.13398, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:15.181, tt:121.446\n",
      "Ep:8, loss:0.00013, loss_test:0.13166, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:15.091, tt:135.823\n",
      "Ep:9, loss:0.00013, loss_test:0.12883, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:15.147, tt:151.466\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00013, loss_test:0.12542, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:15.221, tt:167.435\n",
      "Ep:11, loss:0.00013, loss_test:0.12133, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:15.456, tt:185.470\n",
      "Ep:12, loss:0.00012, loss_test:0.11714, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:15.419, tt:200.453\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00012, loss_test:0.11310, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:15.416, tt:215.819\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00012, loss_test:0.10967, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:15.491, tt:232.369\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00012, loss_test:0.10790, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:15.492, tt:247.874\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00011, loss_test:0.10688, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:15.497, tt:263.447\n",
      "Ep:17, loss:0.00011, loss_test:0.10614, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:15.424, tt:277.638\n",
      "Ep:18, loss:0.00011, loss_test:0.10521, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:15.393, tt:292.473\n",
      "Ep:19, loss:0.00011, loss_test:0.10438, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:15.378, tt:307.568\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.10366, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:15.347, tt:322.286\n",
      "Ep:21, loss:0.00011, loss_test:0.10287, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:15.355, tt:337.808\n",
      "Ep:22, loss:0.00010, loss_test:0.10183, lr:1.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:15.377, tt:353.672\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.10062, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:15.367, tt:368.805\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.09919, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:15.396, tt:384.901\n",
      "Ep:25, loss:0.00010, loss_test:0.09828, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:15.377, tt:399.792\n",
      "Ep:26, loss:0.00010, loss_test:0.09783, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:15.376, tt:415.159\n",
      "Ep:27, loss:0.00010, loss_test:0.09736, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:15.398, tt:431.146\n",
      "Ep:28, loss:0.00009, loss_test:0.09699, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:15.415, tt:447.042\n",
      "Ep:29, loss:0.00009, loss_test:0.09694, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:15.420, tt:462.609\n",
      "Ep:30, loss:0.00009, loss_test:0.09683, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:15.410, tt:477.705\n",
      "Ep:31, loss:0.00009, loss_test:0.09647, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:15.433, tt:493.868\n",
      "Ep:32, loss:0.00009, loss_test:0.09581, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:15.448, tt:509.791\n",
      "Ep:33, loss:0.00009, loss_test:0.09497, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:15.479, tt:526.298\n",
      "Ep:34, loss:0.00009, loss_test:0.09427, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:15.478, tt:541.713\n",
      "Ep:35, loss:0.00008, loss_test:0.09380, lr:9.90e-03, fs:0.73196 (r=0.717,p=0.747),  time:15.485, tt:557.447\n",
      "Ep:36, loss:0.00008, loss_test:0.09363, lr:9.80e-03, fs:0.74627 (r=0.758,p=0.735),  time:15.480, tt:572.748\n",
      "Ep:37, loss:0.00008, loss_test:0.09346, lr:9.70e-03, fs:0.75248 (r=0.768,p=0.738),  time:15.498, tt:588.920\n",
      "Ep:38, loss:0.00008, loss_test:0.09307, lr:9.61e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.534, tt:605.824\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.09259, lr:9.61e-03, fs:0.75758 (r=0.758,p=0.758),  time:15.520, tt:620.811\n",
      "Ep:40, loss:0.00008, loss_test:0.09216, lr:9.61e-03, fs:0.76382 (r=0.768,p=0.760),  time:15.516, tt:636.164\n",
      "Ep:41, loss:0.00008, loss_test:0.09186, lr:9.61e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.502, tt:651.063\n",
      "Ep:42, loss:0.00008, loss_test:0.09166, lr:9.61e-03, fs:0.76699 (r=0.798,p=0.738),  time:15.502, tt:666.606\n",
      "Ep:43, loss:0.00008, loss_test:0.09122, lr:9.61e-03, fs:0.77295 (r=0.808,p=0.741),  time:15.494, tt:681.733\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.09060, lr:9.61e-03, fs:0.78000 (r=0.788,p=0.772),  time:15.505, tt:697.742\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.09019, lr:9.61e-03, fs:0.78000 (r=0.788,p=0.772),  time:15.509, tt:713.422\n",
      "Ep:46, loss:0.00007, loss_test:0.08996, lr:9.61e-03, fs:0.78218 (r=0.798,p=0.767),  time:15.482, tt:727.674\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.08967, lr:9.61e-03, fs:0.78218 (r=0.798,p=0.767),  time:15.464, tt:742.266\n",
      "Ep:48, loss:0.00007, loss_test:0.08917, lr:9.61e-03, fs:0.79024 (r=0.818,p=0.764),  time:15.447, tt:756.899\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.08853, lr:9.61e-03, fs:0.79803 (r=0.818,p=0.779),  time:15.421, tt:771.039\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.08793, lr:9.61e-03, fs:0.80198 (r=0.818,p=0.786),  time:15.426, tt:786.712\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.08762, lr:9.61e-03, fs:0.80597 (r=0.818,p=0.794),  time:15.423, tt:801.980\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.08752, lr:9.61e-03, fs:0.80198 (r=0.818,p=0.786),  time:15.446, tt:818.661\n",
      "Ep:53, loss:0.00007, loss_test:0.08738, lr:9.61e-03, fs:0.80597 (r=0.818,p=0.794),  time:15.438, tt:833.625\n",
      "Ep:54, loss:0.00007, loss_test:0.08705, lr:9.61e-03, fs:0.79798 (r=0.798,p=0.798),  time:15.452, tt:849.876\n",
      "Ep:55, loss:0.00007, loss_test:0.08686, lr:9.61e-03, fs:0.79798 (r=0.798,p=0.798),  time:15.463, tt:865.943\n",
      "Ep:56, loss:0.00006, loss_test:0.08677, lr:9.61e-03, fs:0.79798 (r=0.798,p=0.798),  time:15.456, tt:880.990\n",
      "Ep:57, loss:0.00006, loss_test:0.08650, lr:9.61e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.460, tt:896.709\n",
      "Ep:58, loss:0.00006, loss_test:0.08604, lr:9.61e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.470, tt:912.724\n",
      "Ep:59, loss:0.00006, loss_test:0.08568, lr:9.61e-03, fs:0.81000 (r=0.818,p=0.802),  time:15.467, tt:928.011\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.08535, lr:9.61e-03, fs:0.81000 (r=0.818,p=0.802),  time:15.479, tt:944.241\n",
      "Ep:61, loss:0.00006, loss_test:0.08513, lr:9.61e-03, fs:0.81592 (r=0.828,p=0.804),  time:15.485, tt:960.065\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00006, loss_test:0.08479, lr:9.61e-03, fs:0.81592 (r=0.828,p=0.804),  time:15.496, tt:976.253\n",
      "Ep:63, loss:0.00006, loss_test:0.08433, lr:9.61e-03, fs:0.82000 (r=0.828,p=0.812),  time:15.496, tt:991.768\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.08399, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:15.512, tt:1008.291\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.08370, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:15.504, tt:1023.278\n",
      "Ep:66, loss:0.00006, loss_test:0.08328, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:15.500, tt:1038.486\n",
      "Ep:67, loss:0.00006, loss_test:0.08310, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:15.509, tt:1054.597\n",
      "Ep:68, loss:0.00006, loss_test:0.08303, lr:9.61e-03, fs:0.82412 (r=0.828,p=0.820),  time:15.508, tt:1070.083\n",
      "Ep:69, loss:0.00006, loss_test:0.08279, lr:9.61e-03, fs:0.82828 (r=0.828,p=0.828),  time:15.512, tt:1085.850\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.08243, lr:9.61e-03, fs:0.82828 (r=0.828,p=0.828),  time:15.506, tt:1100.960\n",
      "Ep:71, loss:0.00005, loss_test:0.08202, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.501, tt:1116.039\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.08152, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.505, tt:1131.854\n",
      "Ep:73, loss:0.00005, loss_test:0.08111, lr:9.61e-03, fs:0.82828 (r=0.828,p=0.828),  time:15.506, tt:1147.446\n",
      "Ep:74, loss:0.00005, loss_test:0.08082, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.501, tt:1162.609\n",
      "Ep:75, loss:0.00005, loss_test:0.08050, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.508, tt:1178.588\n",
      "Ep:76, loss:0.00005, loss_test:0.08013, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.523, tt:1195.260\n",
      "Ep:77, loss:0.00005, loss_test:0.07975, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.520, tt:1210.523\n",
      "Ep:78, loss:0.00005, loss_test:0.07941, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.522, tt:1226.202\n",
      "Ep:79, loss:0.00005, loss_test:0.07917, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.505, tt:1240.401\n",
      "Ep:80, loss:0.00005, loss_test:0.07898, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.516, tt:1256.756\n",
      "Ep:81, loss:0.00005, loss_test:0.07869, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.513, tt:1272.068\n",
      "Ep:82, loss:0.00005, loss_test:0.07839, lr:9.61e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.515, tt:1287.779\n",
      "Ep:83, loss:0.00005, loss_test:0.07810, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.516, tt:1303.350\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00005, loss_test:0.07797, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.528, tt:1319.892\n",
      "Ep:85, loss:0.00005, loss_test:0.07778, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.521, tt:1334.807\n",
      "Ep:86, loss:0.00005, loss_test:0.07755, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.520, tt:1350.234\n",
      "Ep:87, loss:0.00005, loss_test:0.07732, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.516, tt:1365.396\n",
      "Ep:88, loss:0.00004, loss_test:0.07704, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.520, tt:1381.295\n",
      "Ep:89, loss:0.00004, loss_test:0.07671, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.520, tt:1396.783\n",
      "Ep:90, loss:0.00004, loss_test:0.07647, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.523, tt:1412.575\n",
      "Ep:91, loss:0.00004, loss_test:0.07638, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.524, tt:1428.175\n",
      "Ep:92, loss:0.00004, loss_test:0.07635, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.530, tt:1444.294\n",
      "Ep:93, loss:0.00004, loss_test:0.07615, lr:9.51e-03, fs:0.83838 (r=0.838,p=0.838),  time:15.532, tt:1460.003\n",
      "Ep:94, loss:0.00004, loss_test:0.07579, lr:9.51e-03, fs:0.84422 (r=0.848,p=0.840),  time:15.538, tt:1476.113\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00004, loss_test:0.07558, lr:9.51e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.535, tt:1491.390\n",
      "Ep:96, loss:0.00004, loss_test:0.07544, lr:9.51e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.537, tt:1507.064\n",
      "Ep:97, loss:0.00004, loss_test:0.07514, lr:9.51e-03, fs:0.84848 (r=0.848,p=0.848),  time:15.544, tt:1523.299\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00004, loss_test:0.07549, lr:9.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.542, tt:1538.658\n",
      "Ep:99, loss:0.00004, loss_test:0.07505, lr:9.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.539, tt:1553.945\n",
      "Ep:100, loss:0.00004, loss_test:0.07449, lr:9.51e-03, fs:0.85279 (r=0.848,p=0.857),  time:15.539, tt:1569.416\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00004, loss_test:0.07469, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.546, tt:1585.659\n",
      "Ep:102, loss:0.00004, loss_test:0.07451, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.542, tt:1600.858\n",
      "Ep:103, loss:0.00004, loss_test:0.07430, lr:9.51e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.535, tt:1615.627\n",
      "Ep:104, loss:0.00004, loss_test:0.07444, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.542, tt:1631.870\n",
      "Ep:105, loss:0.00004, loss_test:0.07420, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.546, tt:1647.921\n",
      "Ep:106, loss:0.00004, loss_test:0.07349, lr:9.51e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.546, tt:1663.463\n",
      "Ep:107, loss:0.00004, loss_test:0.07339, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.549, tt:1679.339\n",
      "Ep:108, loss:0.00004, loss_test:0.07365, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.552, tt:1695.186\n",
      "Ep:109, loss:0.00003, loss_test:0.07344, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.559, tt:1711.456\n",
      "Ep:110, loss:0.00003, loss_test:0.07305, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.574, tt:1728.726\n",
      "Ep:111, loss:0.00003, loss_test:0.07327, lr:9.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.570, tt:1743.881\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00003, loss_test:0.07310, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.564, tt:1758.684\n",
      "Ep:113, loss:0.00003, loss_test:0.07304, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.572, tt:1775.177\n",
      "Ep:114, loss:0.00003, loss_test:0.07398, lr:9.51e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.572, tt:1790.795\n",
      "Ep:115, loss:0.00003, loss_test:0.07365, lr:9.51e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.574, tt:1806.638\n",
      "Ep:116, loss:0.00003, loss_test:0.07287, lr:9.51e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.575, tt:1822.253\n",
      "Ep:117, loss:0.00003, loss_test:0.07399, lr:9.51e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.573, tt:1837.566\n",
      "Ep:118, loss:0.00003, loss_test:0.07431, lr:9.51e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.585, tt:1854.585\n",
      "Ep:119, loss:0.00003, loss_test:0.07315, lr:9.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.593, tt:1871.149\n",
      "Ep:120, loss:0.00003, loss_test:0.07263, lr:9.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.600, tt:1887.625\n",
      "Ep:121, loss:0.00003, loss_test:0.07350, lr:9.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.603, tt:1903.511\n",
      "Ep:122, loss:0.00003, loss_test:0.07347, lr:9.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.609, tt:1919.895\n",
      "Ep:123, loss:0.00003, loss_test:0.07239, lr:9.41e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.603, tt:1934.823\n",
      "Ep:124, loss:0.00003, loss_test:0.07265, lr:9.32e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.603, tt:1950.314\n",
      "Ep:125, loss:0.00003, loss_test:0.07342, lr:9.23e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.606, tt:1966.361\n",
      "Ep:126, loss:0.00003, loss_test:0.07262, lr:9.14e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.612, tt:1982.717\n",
      "Ep:127, loss:0.00003, loss_test:0.07176, lr:9.04e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.615, tt:1998.764\n",
      "Ep:128, loss:0.00003, loss_test:0.07296, lr:8.95e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.615, tt:2014.347\n",
      "Ep:129, loss:0.00003, loss_test:0.07292, lr:8.86e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.612, tt:2029.572\n",
      "Ep:130, loss:0.00003, loss_test:0.07165, lr:8.78e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.618, tt:2045.964\n",
      "Ep:131, loss:0.00003, loss_test:0.07170, lr:8.69e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.620, tt:2061.787\n",
      "Ep:132, loss:0.00003, loss_test:0.07269, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.628, tt:2078.520\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00003, loss_test:0.07195, lr:8.60e-03, fs:0.85567 (r=0.838,p=0.874),  time:15.627, tt:2094.066\n",
      "Ep:134, loss:0.00003, loss_test:0.07099, lr:8.60e-03, fs:0.85128 (r=0.838,p=0.865),  time:15.632, tt:2110.376\n",
      "Ep:135, loss:0.00003, loss_test:0.07236, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.635, tt:2126.420\n",
      "Ep:136, loss:0.00003, loss_test:0.07182, lr:8.60e-03, fs:0.86010 (r=0.838,p=0.883),  time:15.642, tt:2142.958\n",
      "Ep:137, loss:0.00003, loss_test:0.07064, lr:8.60e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.647, tt:2159.297\n",
      "Ep:138, loss:0.00003, loss_test:0.07257, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.650, tt:2175.393\n",
      "Ep:139, loss:0.00003, loss_test:0.07215, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.653, tt:2191.372\n",
      "Ep:140, loss:0.00002, loss_test:0.07004, lr:8.60e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.650, tt:2206.586\n",
      "Ep:141, loss:0.00002, loss_test:0.07214, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.646, tt:2221.740\n",
      "Ep:142, loss:0.00002, loss_test:0.07240, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.641, tt:2236.679\n",
      "Ep:143, loss:0.00002, loss_test:0.07056, lr:8.60e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.676, tt:2257.291\n",
      "Ep:144, loss:0.00002, loss_test:0.07027, lr:8.51e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.681, tt:2273.802\n",
      "Ep:145, loss:0.00002, loss_test:0.07178, lr:8.43e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.675, tt:2288.557\n",
      "Ep:146, loss:0.00002, loss_test:0.07164, lr:8.35e-03, fs:0.86458 (r=0.838,p=0.892),  time:15.672, tt:2303.824\n",
      "Ep:147, loss:0.00002, loss_test:0.07046, lr:8.26e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.672, tt:2319.464\n",
      "Ep:148, loss:0.00002, loss_test:0.07096, lr:8.18e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.659, tt:2333.239\n",
      "Ep:149, loss:0.00002, loss_test:0.07134, lr:8.10e-03, fs:0.86458 (r=0.838,p=0.892),  time:15.646, tt:2346.921\n",
      "Ep:150, loss:0.00002, loss_test:0.07041, lr:8.02e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.633, tt:2360.649\n",
      "Ep:151, loss:0.00002, loss_test:0.07120, lr:7.94e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.622, tt:2374.545\n",
      "Ep:152, loss:0.00002, loss_test:0.07132, lr:7.86e-03, fs:0.86154 (r=0.848,p=0.875),  time:15.617, tt:2389.352\n",
      "Ep:153, loss:0.00002, loss_test:0.07056, lr:7.78e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.608, tt:2403.622\n",
      "Ep:154, loss:0.00002, loss_test:0.07191, lr:7.70e-03, fs:0.86458 (r=0.838,p=0.892),  time:15.596, tt:2417.343\n",
      "Ep:155, loss:0.00002, loss_test:0.07145, lr:7.62e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.592, tt:2432.329\n",
      "Ep:156, loss:0.00002, loss_test:0.07043, lr:7.55e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.580, tt:2445.996\n",
      "Ep:157, loss:0.00002, loss_test:0.07099, lr:7.47e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.568, tt:2459.762\n",
      "Ep:158, loss:0.00002, loss_test:0.07100, lr:7.40e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.557, tt:2473.557\n",
      "##########Best model found so far##########\n",
      "Ep:159, loss:0.00002, loss_test:0.07028, lr:7.40e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.554, tt:2488.568\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00002, loss_test:0.07194, lr:7.40e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.548, tt:2503.308\n",
      "Ep:161, loss:0.00002, loss_test:0.07154, lr:7.40e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.540, tt:2517.504\n",
      "Ep:162, loss:0.00002, loss_test:0.07005, lr:7.40e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.533, tt:2531.855\n",
      "Ep:163, loss:0.00002, loss_test:0.07317, lr:7.40e-03, fs:0.86316 (r=0.828,p=0.901),  time:15.524, tt:2545.966\n",
      "Ep:164, loss:0.00002, loss_test:0.07386, lr:7.40e-03, fs:0.86772 (r=0.828,p=0.911),  time:15.517, tt:2560.238\n",
      "Ep:165, loss:0.00002, loss_test:0.07183, lr:7.40e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.508, tt:2574.265\n",
      "Ep:166, loss:0.00002, loss_test:0.06983, lr:7.40e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.500, tt:2588.464\n",
      "Ep:167, loss:0.00002, loss_test:0.07341, lr:7.40e-03, fs:0.86316 (r=0.828,p=0.901),  time:15.489, tt:2602.167\n",
      "Ep:168, loss:0.00002, loss_test:0.07510, lr:7.40e-03, fs:0.86316 (r=0.828,p=0.901),  time:15.480, tt:2616.141\n",
      "Ep:169, loss:0.00002, loss_test:0.07355, lr:7.40e-03, fs:0.86316 (r=0.828,p=0.901),  time:15.472, tt:2630.188\n",
      "Ep:170, loss:0.00002, loss_test:0.07063, lr:7.40e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.461, tt:2643.840\n",
      "Ep:171, loss:0.00002, loss_test:0.07169, lr:7.32e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.452, tt:2657.730\n",
      "Ep:172, loss:0.00002, loss_test:0.07278, lr:7.25e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.445, tt:2672.022\n",
      "Ep:173, loss:0.00002, loss_test:0.07261, lr:7.18e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.437, tt:2686.001\n",
      "Ep:174, loss:0.00002, loss_test:0.07127, lr:7.11e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.432, tt:2700.547\n",
      "Ep:175, loss:0.00002, loss_test:0.07067, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.422, tt:2714.199\n",
      "Ep:176, loss:0.00002, loss_test:0.07401, lr:6.96e-03, fs:0.86911 (r=0.838,p=0.902),  time:15.412, tt:2727.998\n",
      "Ep:177, loss:0.00002, loss_test:0.07534, lr:6.89e-03, fs:0.86772 (r=0.828,p=0.911),  time:15.403, tt:2741.721\n",
      "Ep:178, loss:0.00002, loss_test:0.07382, lr:6.83e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.391, tt:2754.986\n",
      "##########Best model found so far##########\n",
      "Ep:179, loss:0.00002, loss_test:0.07110, lr:6.83e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.378, tt:2768.029\n",
      "Ep:180, loss:0.00002, loss_test:0.07130, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.369, tt:2781.727\n",
      "Ep:181, loss:0.00002, loss_test:0.07269, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.355, tt:2794.555\n",
      "Ep:182, loss:0.00002, loss_test:0.07323, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.335, tt:2806.391\n",
      "Ep:183, loss:0.00002, loss_test:0.07266, lr:6.83e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.322, tt:2819.186\n",
      "Ep:184, loss:0.00002, loss_test:0.07177, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.313, tt:2832.832\n",
      "Ep:185, loss:0.00002, loss_test:0.07155, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.305, tt:2846.791\n",
      "Ep:186, loss:0.00002, loss_test:0.07253, lr:6.83e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.293, tt:2859.834\n",
      "Ep:187, loss:0.00002, loss_test:0.07296, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.287, tt:2873.894\n",
      "Ep:188, loss:0.00002, loss_test:0.07237, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.280, tt:2887.969\n",
      "Ep:189, loss:0.00002, loss_test:0.07181, lr:6.83e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.274, tt:2902.032\n",
      "Ep:190, loss:0.00002, loss_test:0.07258, lr:6.76e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.268, tt:2916.267\n",
      "Ep:191, loss:0.00002, loss_test:0.07307, lr:6.69e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.260, tt:2929.883\n",
      "Ep:192, loss:0.00002, loss_test:0.07279, lr:6.62e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.248, tt:2942.778\n",
      "Ep:193, loss:0.00002, loss_test:0.07205, lr:6.56e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.238, tt:2956.246\n",
      "Ep:194, loss:0.00002, loss_test:0.07279, lr:6.49e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.229, tt:2969.733\n",
      "Ep:195, loss:0.00002, loss_test:0.07333, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.227, tt:2984.471\n",
      "##########Best model found so far##########\n",
      "Ep:196, loss:0.00002, loss_test:0.07331, lr:6.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.228, tt:2999.884\n",
      "Ep:197, loss:0.00002, loss_test:0.07270, lr:6.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.219, tt:3013.343\n",
      "Ep:198, loss:0.00002, loss_test:0.07356, lr:6.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.207, tt:3026.222\n",
      "Ep:199, loss:0.00002, loss_test:0.07377, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.202, tt:3040.497\n",
      "Ep:200, loss:0.00002, loss_test:0.07325, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.188, tt:3052.789\n",
      "Ep:201, loss:0.00002, loss_test:0.07272, lr:6.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.177, tt:3065.704\n",
      "Ep:202, loss:0.00002, loss_test:0.07314, lr:6.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.161, tt:3077.615\n",
      "Ep:203, loss:0.00002, loss_test:0.07346, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.145, tt:3089.525\n",
      "Ep:204, loss:0.00002, loss_test:0.07305, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.118, tt:3099.140\n",
      "Ep:205, loss:0.00001, loss_test:0.07363, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.085, tt:3107.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00001, loss_test:0.07397, lr:6.43e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.039, tt:3113.033\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14524, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.736, tt:30.736\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14481, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.577, tt:63.154\n",
      "Ep:2, loss:0.00028, loss_test:0.14411, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.984, tt:95.951\n",
      "Ep:3, loss:0.00028, loss_test:0.14313, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.265, tt:129.058\n",
      "Ep:4, loss:0.00028, loss_test:0.14176, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.327, tt:161.633\n",
      "Ep:5, loss:0.00027, loss_test:0.13983, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.292, tt:193.752\n",
      "Ep:6, loss:0.00027, loss_test:0.13711, lr:1.00e-02, fs:0.67500 (r=1.000,p=0.509),  time:32.482, tt:227.371\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.13307, lr:1.00e-02, fs:0.65359 (r=0.926,p=0.505),  time:32.493, tt:259.940\n",
      "Ep:8, loss:0.00025, loss_test:0.12751, lr:1.00e-02, fs:0.68056 (r=0.907,p=0.544),  time:32.469, tt:292.224\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.12246, lr:1.00e-02, fs:0.66142 (r=0.778,p=0.575),  time:32.463, tt:324.634\n",
      "Ep:10, loss:0.00023, loss_test:0.11918, lr:1.00e-02, fs:0.63063 (r=0.648,p=0.614),  time:32.379, tt:356.174\n",
      "Ep:11, loss:0.00022, loss_test:0.11671, lr:1.00e-02, fs:0.64815 (r=0.648,p=0.648),  time:32.182, tt:386.181\n",
      "Ep:12, loss:0.00022, loss_test:0.11382, lr:1.00e-02, fs:0.67241 (r=0.722,p=0.629),  time:32.219, tt:418.845\n",
      "Ep:13, loss:0.00021, loss_test:0.11230, lr:1.00e-02, fs:0.68908 (r=0.759,p=0.631),  time:31.947, tt:447.252\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.11040, lr:1.00e-02, fs:0.68966 (r=0.741,p=0.645),  time:32.030, tt:480.448\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10901, lr:1.00e-02, fs:0.69091 (r=0.704,p=0.679),  time:31.958, tt:511.330\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.10653, lr:1.00e-02, fs:0.67890 (r=0.685,p=0.673),  time:31.936, tt:542.917\n",
      "Ep:17, loss:0.00019, loss_test:0.10382, lr:1.00e-02, fs:0.70175 (r=0.741,p=0.667),  time:31.914, tt:574.455\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.10173, lr:1.00e-02, fs:0.73043 (r=0.778,p=0.689),  time:31.928, tt:606.637\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.10004, lr:1.00e-02, fs:0.69811 (r=0.685,p=0.712),  time:31.911, tt:638.226\n",
      "Ep:20, loss:0.00018, loss_test:0.09776, lr:1.00e-02, fs:0.72222 (r=0.722,p=0.722),  time:31.927, tt:670.474\n",
      "Ep:21, loss:0.00017, loss_test:0.09534, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:31.954, tt:702.992\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.09417, lr:1.00e-02, fs:0.74545 (r=0.759,p=0.732),  time:31.958, tt:735.045\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09291, lr:1.00e-02, fs:0.72222 (r=0.722,p=0.722),  time:31.904, tt:765.701\n",
      "Ep:24, loss:0.00016, loss_test:0.09114, lr:1.00e-02, fs:0.75000 (r=0.778,p=0.724),  time:31.857, tt:796.428\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.08973, lr:1.00e-02, fs:0.76786 (r=0.796,p=0.741),  time:31.859, tt:828.340\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08877, lr:1.00e-02, fs:0.75676 (r=0.778,p=0.737),  time:31.881, tt:860.782\n",
      "Ep:27, loss:0.00015, loss_test:0.08708, lr:1.00e-02, fs:0.76786 (r=0.796,p=0.741),  time:31.943, tt:894.406\n",
      "Ep:28, loss:0.00015, loss_test:0.08583, lr:1.00e-02, fs:0.78947 (r=0.833,p=0.750),  time:31.963, tt:926.933\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.08458, lr:1.00e-02, fs:0.78182 (r=0.796,p=0.768),  time:31.990, tt:959.710\n",
      "Ep:30, loss:0.00014, loss_test:0.08270, lr:1.00e-02, fs:0.83051 (r=0.907,p=0.766),  time:32.002, tt:992.077\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.08100, lr:1.00e-02, fs:0.83051 (r=0.907,p=0.766),  time:32.008, tt:1024.241\n",
      "Ep:32, loss:0.00013, loss_test:0.08026, lr:1.00e-02, fs:0.83761 (r=0.907,p=0.778),  time:32.050, tt:1057.636\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07877, lr:1.00e-02, fs:0.83051 (r=0.907,p=0.766),  time:32.063, tt:1090.135\n",
      "Ep:34, loss:0.00013, loss_test:0.07730, lr:1.00e-02, fs:0.84483 (r=0.907,p=0.790),  time:32.094, tt:1123.275\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.07616, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.083, tt:1154.987\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.07506, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.066, tt:1186.456\n",
      "Ep:37, loss:0.00012, loss_test:0.07378, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.048, tt:1217.839\n",
      "Ep:38, loss:0.00012, loss_test:0.07182, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.074, tt:1250.898\n",
      "Ep:39, loss:0.00011, loss_test:0.07118, lr:1.00e-02, fs:0.85965 (r=0.907,p=0.817),  time:32.033, tt:1281.310\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.07025, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.042, tt:1313.727\n",
      "Ep:41, loss:0.00011, loss_test:0.06921, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.050, tt:1346.102\n",
      "Ep:42, loss:0.00011, loss_test:0.06797, lr:1.00e-02, fs:0.85965 (r=0.907,p=0.817),  time:32.057, tt:1378.470\n",
      "Ep:43, loss:0.00010, loss_test:0.06684, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:32.101, tt:1412.429\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.06643, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:32.086, tt:1443.853\n",
      "Ep:45, loss:0.00010, loss_test:0.06411, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:32.061, tt:1474.816\n",
      "Ep:46, loss:0.00010, loss_test:0.06441, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.048, tt:1506.259\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.06268, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:32.080, tt:1539.840\n",
      "Ep:48, loss:0.00009, loss_test:0.06135, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.097, tt:1572.758\n",
      "Ep:49, loss:0.00009, loss_test:0.06084, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.117, tt:1605.868\n",
      "Ep:50, loss:0.00009, loss_test:0.05953, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:32.122, tt:1638.230\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.05957, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.115, tt:1669.973\n",
      "Ep:52, loss:0.00009, loss_test:0.05727, lr:1.00e-02, fs:0.88889 (r=0.963,p=0.825),  time:32.094, tt:1700.984\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.05782, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.113, tt:1734.111\n",
      "Ep:54, loss:0.00008, loss_test:0.05587, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.089, tt:1764.890\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.05469, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.085, tt:1796.751\n",
      "Ep:56, loss:0.00008, loss_test:0.05532, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.074, tt:1828.231\n",
      "Ep:57, loss:0.00008, loss_test:0.05329, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.094, tt:1861.430\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00008, loss_test:0.05313, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.100, tt:1893.919\n",
      "Ep:59, loss:0.00007, loss_test:0.05223, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.112, tt:1926.693\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00007, loss_test:0.05178, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.113, tt:1958.895\n",
      "Ep:61, loss:0.00007, loss_test:0.05080, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.107, tt:1990.651\n",
      "Ep:62, loss:0.00007, loss_test:0.05033, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:32.105, tt:2022.622\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00007, loss_test:0.04946, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.092, tt:2053.880\n",
      "Ep:64, loss:0.00007, loss_test:0.04862, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:32.105, tt:2086.803\n",
      "Ep:65, loss:0.00006, loss_test:0.04866, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:32.080, tt:2117.250\n",
      "Ep:66, loss:0.00006, loss_test:0.04691, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.075, tt:2149.036\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00006, loss_test:0.04646, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.069, tt:2180.722\n",
      "Ep:68, loss:0.00006, loss_test:0.04650, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.095, tt:2214.533\n",
      "Ep:69, loss:0.00006, loss_test:0.04542, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.094, tt:2246.556\n",
      "Ep:70, loss:0.00006, loss_test:0.04488, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.127, tt:2281.006\n",
      "Ep:71, loss:0.00006, loss_test:0.04485, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.121, tt:2312.706\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00006, loss_test:0.04343, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.120, tt:2344.724\n",
      "Ep:73, loss:0.00005, loss_test:0.04365, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.114, tt:2376.407\n",
      "Ep:74, loss:0.00005, loss_test:0.04237, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.127, tt:2409.550\n",
      "Ep:75, loss:0.00005, loss_test:0.04200, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.130, tt:2441.917\n",
      "Ep:76, loss:0.00005, loss_test:0.04158, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.123, tt:2473.500\n",
      "Ep:77, loss:0.00005, loss_test:0.04044, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:32.120, tt:2505.371\n",
      "Ep:78, loss:0.00005, loss_test:0.04115, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.118, tt:2537.318\n",
      "Ep:79, loss:0.00005, loss_test:0.03933, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.122, tt:2569.752\n",
      "Ep:80, loss:0.00005, loss_test:0.03971, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.122, tt:2601.919\n",
      "Ep:81, loss:0.00005, loss_test:0.03853, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.117, tt:2633.602\n",
      "Ep:82, loss:0.00005, loss_test:0.03831, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.150, tt:2668.434\n",
      "Ep:83, loss:0.00004, loss_test:0.03776, lr:9.90e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.151, tt:2700.718\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00004, loss_test:0.03708, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.157, tt:2733.354\n",
      "Ep:85, loss:0.00004, loss_test:0.03649, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.170, tt:2766.658\n",
      "Ep:86, loss:0.00004, loss_test:0.03625, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.190, tt:2800.494\n",
      "Ep:87, loss:0.00004, loss_test:0.03545, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.200, tt:2833.621\n",
      "Ep:88, loss:0.00004, loss_test:0.03521, lr:9.90e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.204, tt:2866.172\n",
      "Ep:89, loss:0.00004, loss_test:0.03474, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.215, tt:2899.327\n",
      "Ep:90, loss:0.00004, loss_test:0.03395, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.234, tt:2933.270\n",
      "Ep:91, loss:0.00004, loss_test:0.03468, lr:9.90e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.232, tt:2965.347\n",
      "Ep:92, loss:0.00004, loss_test:0.03311, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.265, tt:3000.662\n",
      "Ep:93, loss:0.00004, loss_test:0.03349, lr:9.90e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.275, tt:3033.821\n",
      "Ep:94, loss:0.00003, loss_test:0.03248, lr:9.90e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.286, tt:3067.172\n",
      "Ep:95, loss:0.00003, loss_test:0.03241, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.334, tt:3104.071\n",
      "Ep:96, loss:0.00003, loss_test:0.03107, lr:9.70e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.349, tt:3137.899\n",
      "Ep:97, loss:0.00003, loss_test:0.03169, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.346, tt:3169.888\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00003, loss_test:0.03000, lr:9.61e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.360, tt:3203.668\n",
      "Ep:99, loss:0.00003, loss_test:0.03070, lr:9.61e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.398, tt:3239.779\n",
      "Ep:100, loss:0.00003, loss_test:0.02955, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.417, tt:3274.116\n",
      "Ep:101, loss:0.00003, loss_test:0.02990, lr:9.61e-03, fs:0.93805 (r=0.981,p=0.898),  time:32.430, tt:3307.887\n",
      "Ep:102, loss:0.00003, loss_test:0.02908, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.450, tt:3342.314\n",
      "Ep:103, loss:0.00003, loss_test:0.02824, lr:9.61e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.451, tt:3374.858\n",
      "Ep:104, loss:0.00003, loss_test:0.02867, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.465, tt:3408.797\n",
      "Ep:105, loss:0.00003, loss_test:0.02777, lr:9.61e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.461, tt:3440.907\n",
      "Ep:106, loss:0.00003, loss_test:0.02759, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.444, tt:3471.558\n",
      "Ep:107, loss:0.00003, loss_test:0.02714, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.448, tt:3504.436\n",
      "Ep:108, loss:0.00003, loss_test:0.02751, lr:9.61e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.460, tt:3538.163\n",
      "Ep:109, loss:0.00002, loss_test:0.02631, lr:9.51e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.467, tt:3571.382\n",
      "Ep:110, loss:0.00002, loss_test:0.02650, lr:9.41e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.469, tt:3604.024\n",
      "Ep:111, loss:0.00002, loss_test:0.02587, lr:9.32e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.475, tt:3637.180\n",
      "Ep:112, loss:0.00002, loss_test:0.02562, lr:9.23e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.474, tt:3669.587\n",
      "Ep:113, loss:0.00002, loss_test:0.02532, lr:9.14e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.476, tt:3702.209\n",
      "Ep:114, loss:0.00002, loss_test:0.02557, lr:9.04e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.480, tt:3735.160\n",
      "Ep:115, loss:0.00002, loss_test:0.02500, lr:8.95e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.485, tt:3768.267\n",
      "Ep:116, loss:0.00002, loss_test:0.02475, lr:8.86e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.483, tt:3800.554\n",
      "Ep:117, loss:0.00002, loss_test:0.02463, lr:8.78e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.481, tt:3832.757\n",
      "Ep:118, loss:0.00002, loss_test:0.02426, lr:8.69e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.472, tt:3864.119\n",
      "Ep:119, loss:0.00002, loss_test:0.02415, lr:8.60e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.457, tt:3894.894\n",
      "Ep:120, loss:0.00002, loss_test:0.02393, lr:8.51e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.455, tt:3927.040\n",
      "Ep:121, loss:0.00002, loss_test:0.02377, lr:8.43e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.453, tt:3959.271\n",
      "Ep:122, loss:0.00002, loss_test:0.02323, lr:8.35e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.462, tt:3992.818\n",
      "Ep:123, loss:0.00002, loss_test:0.02338, lr:8.26e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.462, tt:4025.250\n",
      "Ep:124, loss:0.00002, loss_test:0.02288, lr:8.18e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.468, tt:4058.456\n",
      "Ep:125, loss:0.00002, loss_test:0.02326, lr:8.10e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.476, tt:4091.996\n",
      "Ep:126, loss:0.00002, loss_test:0.02263, lr:8.02e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.474, tt:4124.226\n",
      "Ep:127, loss:0.00002, loss_test:0.02306, lr:7.94e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.482, tt:4157.667\n",
      "Ep:128, loss:0.00002, loss_test:0.02223, lr:7.86e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.482, tt:4190.138\n",
      "Ep:129, loss:0.00002, loss_test:0.02225, lr:7.78e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.494, tt:4224.221\n",
      "Ep:130, loss:0.00002, loss_test:0.02207, lr:7.70e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.489, tt:4256.018\n",
      "Ep:131, loss:0.00002, loss_test:0.02157, lr:7.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.500, tt:4290.029\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00002, loss_test:0.02186, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.498, tt:4322.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00002, loss_test:0.02159, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.491, tt:4353.776\n",
      "Ep:134, loss:0.00002, loss_test:0.02125, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.499, tt:4387.329\n",
      "Ep:135, loss:0.00002, loss_test:0.02142, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.499, tt:4419.889\n",
      "Ep:136, loss:0.00002, loss_test:0.02134, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.501, tt:4452.621\n",
      "Ep:137, loss:0.00002, loss_test:0.02082, lr:7.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.504, tt:4485.572\n",
      "Ep:138, loss:0.00002, loss_test:0.02090, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.498, tt:4517.207\n",
      "Ep:139, loss:0.00002, loss_test:0.02063, lr:7.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.497, tt:4549.553\n",
      "Ep:140, loss:0.00002, loss_test:0.02074, lr:7.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.504, tt:4583.080\n",
      "Ep:141, loss:0.00002, loss_test:0.02063, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.510, tt:4616.411\n",
      "Ep:142, loss:0.00001, loss_test:0.02023, lr:7.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.510, tt:4648.982\n",
      "Ep:143, loss:0.00001, loss_test:0.02038, lr:7.55e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.508, tt:4681.185\n",
      "Ep:144, loss:0.00001, loss_test:0.02043, lr:7.47e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.508, tt:4713.697\n",
      "Ep:145, loss:0.00001, loss_test:0.02012, lr:7.40e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.501, tt:4745.101\n",
      "Ep:146, loss:0.00001, loss_test:0.02000, lr:7.32e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.494, tt:4776.676\n",
      "Ep:147, loss:0.00001, loss_test:0.01999, lr:7.25e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.494, tt:4809.128\n",
      "Ep:148, loss:0.00001, loss_test:0.01946, lr:7.18e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.483, tt:4839.994\n",
      "Ep:149, loss:0.00001, loss_test:0.01985, lr:7.11e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.484, tt:4872.649\n",
      "Ep:150, loss:0.00001, loss_test:0.01955, lr:7.03e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.466, tt:4902.436\n",
      "Ep:151, loss:0.00001, loss_test:0.01949, lr:6.96e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.462, tt:4934.224\n",
      "Ep:152, loss:0.00001, loss_test:0.01921, lr:6.89e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.462, tt:4966.727\n",
      "Ep:153, loss:0.00001, loss_test:0.01948, lr:6.83e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.454, tt:4997.934\n",
      "Ep:154, loss:0.00001, loss_test:0.01917, lr:6.76e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.451, tt:5029.902\n",
      "Ep:155, loss:0.00001, loss_test:0.01910, lr:6.69e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.446, tt:5061.499\n",
      "Ep:156, loss:0.00001, loss_test:0.01904, lr:6.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.437, tt:5092.666\n",
      "Ep:157, loss:0.00001, loss_test:0.01891, lr:6.56e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.458, tt:5128.358\n",
      "Ep:158, loss:0.00001, loss_test:0.01897, lr:6.49e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.441, tt:5158.064\n",
      "Ep:159, loss:0.00001, loss_test:0.01885, lr:6.43e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.440, tt:5190.387\n",
      "Ep:160, loss:0.00001, loss_test:0.01849, lr:6.36e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.441, tt:5223.009\n",
      "Ep:161, loss:0.00001, loss_test:0.01881, lr:6.30e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.440, tt:5255.336\n",
      "Ep:162, loss:0.00001, loss_test:0.01855, lr:6.24e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.436, tt:5287.075\n",
      "Ep:163, loss:0.00001, loss_test:0.01833, lr:6.17e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.427, tt:5318.015\n",
      "Ep:164, loss:0.00001, loss_test:0.01855, lr:6.11e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.427, tt:5350.498\n",
      "Ep:165, loss:0.00001, loss_test:0.01837, lr:6.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.417, tt:5381.149\n",
      "Ep:166, loss:0.00001, loss_test:0.01804, lr:5.99e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.403, tt:5411.299\n",
      "Ep:167, loss:0.00001, loss_test:0.01849, lr:5.93e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.394, tt:5442.170\n",
      "Ep:168, loss:0.00001, loss_test:0.01805, lr:5.87e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.387, tt:5473.414\n",
      "Ep:169, loss:0.00001, loss_test:0.01791, lr:5.81e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.381, tt:5504.809\n",
      "Ep:170, loss:0.00001, loss_test:0.01830, lr:5.75e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.375, tt:5536.157\n",
      "Ep:171, loss:0.00001, loss_test:0.01805, lr:5.70e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.372, tt:5567.985\n",
      "Ep:172, loss:0.00001, loss_test:0.01779, lr:5.64e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.365, tt:5599.147\n",
      "Ep:173, loss:0.00001, loss_test:0.01805, lr:5.58e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.356, tt:5629.861\n",
      "Ep:174, loss:0.00001, loss_test:0.01783, lr:5.53e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.349, tt:5661.159\n",
      "Ep:175, loss:0.00001, loss_test:0.01770, lr:5.47e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.344, tt:5692.478\n",
      "Ep:176, loss:0.00001, loss_test:0.01762, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.345, tt:5725.024\n",
      "Ep:177, loss:0.00001, loss_test:0.01780, lr:5.36e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.336, tt:5755.830\n",
      "Ep:178, loss:0.00001, loss_test:0.01778, lr:5.31e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.333, tt:5787.676\n",
      "Ep:179, loss:0.00001, loss_test:0.01763, lr:5.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.324, tt:5818.302\n",
      "Ep:180, loss:0.00001, loss_test:0.01761, lr:5.20e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.316, tt:5849.106\n",
      "Ep:181, loss:0.00001, loss_test:0.01749, lr:5.15e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.302, tt:5878.985\n",
      "Ep:182, loss:0.00001, loss_test:0.01726, lr:5.10e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.298, tt:5910.445\n",
      "Ep:183, loss:0.00001, loss_test:0.01739, lr:5.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.313, tt:5945.669\n",
      "Ep:184, loss:0.00001, loss_test:0.01757, lr:5.00e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.308, tt:5977.045\n",
      "Ep:185, loss:0.00001, loss_test:0.01716, lr:4.95e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.302, tt:6008.196\n",
      "Ep:186, loss:0.00001, loss_test:0.01712, lr:4.90e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.306, tt:6041.286\n",
      "Ep:187, loss:0.00001, loss_test:0.01747, lr:4.85e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.308, tt:6073.938\n",
      "Ep:188, loss:0.00001, loss_test:0.01705, lr:4.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.299, tt:6104.553\n",
      "Ep:189, loss:0.00001, loss_test:0.01679, lr:4.75e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.293, tt:6135.697\n",
      "Ep:190, loss:0.00001, loss_test:0.01727, lr:4.71e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.297, tt:6168.747\n",
      "Ep:191, loss:0.00001, loss_test:0.01687, lr:4.66e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.291, tt:6199.817\n",
      "Ep:192, loss:0.00001, loss_test:0.01674, lr:4.61e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.289, tt:6231.695\n",
      "Ep:193, loss:0.00001, loss_test:0.01702, lr:4.57e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.287, tt:6263.582\n",
      "Ep:194, loss:0.00001, loss_test:0.01700, lr:4.52e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.287, tt:6295.957\n",
      "Ep:195, loss:0.00001, loss_test:0.01685, lr:4.48e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.283, tt:6327.512\n",
      "Ep:196, loss:0.00001, loss_test:0.01648, lr:4.43e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.281, tt:6359.288\n",
      "Ep:197, loss:0.00001, loss_test:0.01675, lr:4.39e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.264, tt:6388.221\n",
      "Ep:198, loss:0.00001, loss_test:0.01699, lr:4.34e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.254, tt:6418.584\n",
      "Ep:199, loss:0.00001, loss_test:0.01652, lr:4.30e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.253, tt:6450.687\n",
      "Ep:200, loss:0.00001, loss_test:0.01660, lr:4.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.253, tt:6482.818\n",
      "Ep:201, loss:0.00001, loss_test:0.01687, lr:4.21e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.254, tt:6515.211\n",
      "Ep:202, loss:0.00001, loss_test:0.01669, lr:4.17e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.245, tt:6545.696\n",
      "Ep:203, loss:0.00001, loss_test:0.01631, lr:4.13e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.235, tt:6575.843\n",
      "Ep:204, loss:0.00001, loss_test:0.01662, lr:4.09e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.240, tt:6609.146\n",
      "Ep:205, loss:0.00001, loss_test:0.01661, lr:4.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.212, tt:6635.644\n",
      "Ep:206, loss:0.00001, loss_test:0.01628, lr:4.01e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.131, tt:6651.134\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14532, lr:1.00e-02, fs:0.67089 (r=0.981,p=0.510),  time:36.655, tt:36.655\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14357, lr:1.00e-02, fs:0.64935 (r=0.926,p=0.500),  time:36.737, tt:73.473\n",
      "Ep:2, loss:0.00026, loss_test:0.14144, lr:1.00e-02, fs:0.60563 (r=0.796,p=0.489),  time:36.871, tt:110.613\n",
      "Ep:3, loss:0.00025, loss_test:0.13912, lr:1.00e-02, fs:0.61538 (r=0.741,p=0.526),  time:36.471, tt:145.885\n",
      "Ep:4, loss:0.00024, loss_test:0.13589, lr:1.00e-02, fs:0.61417 (r=0.722,p=0.534),  time:36.364, tt:181.818\n",
      "Ep:5, loss:0.00024, loss_test:0.13083, lr:1.00e-02, fs:0.62400 (r=0.722,p=0.549),  time:36.135, tt:216.807\n",
      "Ep:6, loss:0.00023, loss_test:0.12721, lr:1.00e-02, fs:0.64000 (r=0.741,p=0.563),  time:36.391, tt:254.735\n",
      "Ep:7, loss:0.00022, loss_test:0.12352, lr:1.00e-02, fs:0.64463 (r=0.722,p=0.582),  time:36.993, tt:295.946\n",
      "Ep:8, loss:0.00021, loss_test:0.11969, lr:1.00e-02, fs:0.64407 (r=0.704,p=0.594),  time:37.011, tt:333.103\n",
      "Ep:9, loss:0.00021, loss_test:0.11714, lr:1.00e-02, fs:0.65517 (r=0.704,p=0.613),  time:36.923, tt:369.228\n",
      "Ep:10, loss:0.00020, loss_test:0.11432, lr:1.00e-02, fs:0.66667 (r=0.741,p=0.606),  time:36.899, tt:405.891\n",
      "Ep:11, loss:0.00020, loss_test:0.11224, lr:1.00e-02, fs:0.66667 (r=0.741,p=0.606),  time:36.891, tt:442.691\n",
      "Ep:12, loss:0.00019, loss_test:0.11011, lr:9.90e-03, fs:0.66667 (r=0.741,p=0.606),  time:36.891, tt:479.587\n",
      "Ep:13, loss:0.00018, loss_test:0.10887, lr:9.80e-03, fs:0.67227 (r=0.741,p=0.615),  time:36.873, tt:516.217\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10717, lr:9.80e-03, fs:0.67797 (r=0.741,p=0.625),  time:36.817, tt:552.259\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10484, lr:9.80e-03, fs:0.68376 (r=0.741,p=0.635),  time:36.781, tt:588.502\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.10300, lr:9.80e-03, fs:0.67797 (r=0.741,p=0.625),  time:36.801, tt:625.609\n",
      "Ep:17, loss:0.00017, loss_test:0.10081, lr:9.80e-03, fs:0.68376 (r=0.741,p=0.635),  time:36.784, tt:662.120\n",
      "Ep:18, loss:0.00016, loss_test:0.09920, lr:9.80e-03, fs:0.72072 (r=0.741,p=0.702),  time:36.666, tt:696.651\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09617, lr:9.80e-03, fs:0.70796 (r=0.741,p=0.678),  time:36.654, tt:733.072\n",
      "Ep:20, loss:0.00015, loss_test:0.09379, lr:9.80e-03, fs:0.74138 (r=0.796,p=0.694),  time:36.640, tt:769.448\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09155, lr:9.80e-03, fs:0.77477 (r=0.796,p=0.754),  time:36.721, tt:807.852\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08836, lr:9.80e-03, fs:0.80672 (r=0.889,p=0.738),  time:36.709, tt:844.299\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08527, lr:9.80e-03, fs:0.81356 (r=0.889,p=0.750),  time:36.689, tt:880.546\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08312, lr:9.80e-03, fs:0.82759 (r=0.889,p=0.774),  time:36.636, tt:915.890\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08036, lr:9.80e-03, fs:0.83478 (r=0.889,p=0.787),  time:36.617, tt:952.049\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07793, lr:9.80e-03, fs:0.86207 (r=0.926,p=0.806),  time:36.560, tt:987.121\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07595, lr:9.80e-03, fs:0.87179 (r=0.944,p=0.810),  time:36.533, tt:1022.937\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07395, lr:9.80e-03, fs:0.87179 (r=0.944,p=0.810),  time:36.515, tt:1058.936\n",
      "Ep:29, loss:0.00012, loss_test:0.07137, lr:9.80e-03, fs:0.87179 (r=0.944,p=0.810),  time:36.541, tt:1096.235\n",
      "Ep:30, loss:0.00011, loss_test:0.07050, lr:9.80e-03, fs:0.87179 (r=0.944,p=0.810),  time:36.573, tt:1133.754\n",
      "Ep:31, loss:0.00011, loss_test:0.06788, lr:9.80e-03, fs:0.87179 (r=0.944,p=0.810),  time:36.529, tt:1168.942\n",
      "Ep:32, loss:0.00010, loss_test:0.06632, lr:9.80e-03, fs:0.87931 (r=0.944,p=0.823),  time:36.511, tt:1204.847\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.06425, lr:9.80e-03, fs:0.87931 (r=0.944,p=0.823),  time:36.528, tt:1241.949\n",
      "Ep:34, loss:0.00010, loss_test:0.06304, lr:9.80e-03, fs:0.86207 (r=0.926,p=0.806),  time:36.483, tt:1276.908\n",
      "Ep:35, loss:0.00010, loss_test:0.06214, lr:9.80e-03, fs:0.88696 (r=0.944,p=0.836),  time:36.556, tt:1316.006\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.06151, lr:9.80e-03, fs:0.86957 (r=0.926,p=0.820),  time:36.536, tt:1351.814\n",
      "Ep:37, loss:0.00009, loss_test:0.05813, lr:9.80e-03, fs:0.88889 (r=0.963,p=0.825),  time:36.532, tt:1388.221\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.05836, lr:9.80e-03, fs:0.88696 (r=0.944,p=0.836),  time:36.442, tt:1421.248\n",
      "Ep:39, loss:0.00008, loss_test:0.05480, lr:9.80e-03, fs:0.89655 (r=0.963,p=0.839),  time:36.444, tt:1457.772\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.05525, lr:9.80e-03, fs:0.87931 (r=0.944,p=0.823),  time:36.386, tt:1491.835\n",
      "Ep:41, loss:0.00008, loss_test:0.05225, lr:9.80e-03, fs:0.88889 (r=0.963,p=0.825),  time:36.387, tt:1528.235\n",
      "Ep:42, loss:0.00008, loss_test:0.05162, lr:9.80e-03, fs:0.90435 (r=0.963,p=0.852),  time:36.383, tt:1564.453\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.05000, lr:9.80e-03, fs:0.89655 (r=0.963,p=0.839),  time:36.359, tt:1599.775\n",
      "Ep:44, loss:0.00007, loss_test:0.04863, lr:9.80e-03, fs:0.89655 (r=0.963,p=0.839),  time:36.357, tt:1636.083\n",
      "Ep:45, loss:0.00007, loss_test:0.04750, lr:9.80e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.360, tt:1672.566\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.04603, lr:9.80e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.368, tt:1709.279\n",
      "Ep:47, loss:0.00007, loss_test:0.04698, lr:9.80e-03, fs:0.89655 (r=0.963,p=0.839),  time:36.353, tt:1744.963\n",
      "Ep:48, loss:0.00007, loss_test:0.04952, lr:9.80e-03, fs:0.88696 (r=0.944,p=0.836),  time:36.365, tt:1781.898\n",
      "Ep:49, loss:0.00007, loss_test:0.04562, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:36.361, tt:1818.069\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.04568, lr:9.80e-03, fs:0.90435 (r=0.963,p=0.852),  time:36.371, tt:1854.897\n",
      "Ep:51, loss:0.00006, loss_test:0.04110, lr:9.80e-03, fs:0.92174 (r=0.981,p=0.869),  time:36.358, tt:1890.629\n",
      "Ep:52, loss:0.00006, loss_test:0.04033, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.352, tt:1926.636\n",
      "Ep:53, loss:0.00006, loss_test:0.04138, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.321, tt:1961.307\n",
      "Ep:54, loss:0.00006, loss_test:0.03934, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:36.317, tt:1997.421\n",
      "Ep:55, loss:0.00006, loss_test:0.03839, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:36.347, tt:2035.413\n",
      "Ep:56, loss:0.00005, loss_test:0.03869, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:36.256, tt:2066.587\n",
      "Ep:57, loss:0.00005, loss_test:0.03731, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:35.966, tt:2086.026\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.03667, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:35.617, tt:2101.425\n",
      "Ep:59, loss:0.00005, loss_test:0.03592, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:35.206, tt:2112.365\n",
      "Ep:60, loss:0.00005, loss_test:0.03480, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:34.771, tt:2121.037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00005, loss_test:0.03400, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:34.350, tt:2129.707\n",
      "Ep:62, loss:0.00005, loss_test:0.03753, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:33.941, tt:2138.288\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.03356, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:33.545, tt:2146.861\n",
      "Ep:64, loss:0.00005, loss_test:0.03306, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:33.162, tt:2155.562\n",
      "Ep:65, loss:0.00004, loss_test:0.03328, lr:9.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:32.791, tt:2164.216\n",
      "Ep:66, loss:0.00004, loss_test:0.03356, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.431, tt:2172.896\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.03177, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.080, tt:2181.466\n",
      "Ep:68, loss:0.00004, loss_test:0.03215, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.741, tt:2190.162\n",
      "Ep:69, loss:0.00004, loss_test:0.03203, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:31.412, tt:2198.853\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00004, loss_test:0.03155, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.092, tt:2207.537\n",
      "Ep:71, loss:0.00004, loss_test:0.02945, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:30.780, tt:2216.149\n",
      "Ep:72, loss:0.00004, loss_test:0.02888, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:30.478, tt:2224.881\n",
      "Ep:73, loss:0.00004, loss_test:0.02875, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:30.184, tt:2233.595\n",
      "Ep:74, loss:0.00003, loss_test:0.02763, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:29.898, tt:2242.367\n",
      "Ep:75, loss:0.00003, loss_test:0.02784, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:29.619, tt:2251.036\n",
      "Ep:76, loss:0.00003, loss_test:0.02745, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:29.346, tt:2259.652\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00003, loss_test:0.02804, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:29.081, tt:2268.283\n",
      "Ep:78, loss:0.00003, loss_test:0.02550, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:28.823, tt:2276.983\n",
      "Ep:79, loss:0.00003, loss_test:0.02485, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:28.586, tt:2286.854\n",
      "Ep:80, loss:0.00003, loss_test:0.02908, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:28.340, tt:2295.517\n",
      "Ep:81, loss:0.00003, loss_test:0.02415, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:28.099, tt:2304.157\n",
      "Ep:82, loss:0.00003, loss_test:0.02407, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:27.866, tt:2312.853\n",
      "Ep:83, loss:0.00003, loss_test:0.02642, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:27.638, tt:2321.562\n",
      "Ep:84, loss:0.00003, loss_test:0.02430, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:27.415, tt:2330.272\n",
      "Ep:85, loss:0.00003, loss_test:0.02686, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:27.197, tt:2338.903\n",
      "Ep:86, loss:0.00003, loss_test:0.02381, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:26.984, tt:2347.643\n",
      "Ep:87, loss:0.00002, loss_test:0.02450, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:26.777, tt:2356.350\n",
      "Ep:88, loss:0.00002, loss_test:0.02239, lr:9.70e-03, fs:0.96364 (r=0.981,p=0.946),  time:26.573, tt:2365.014\n",
      "Ep:89, loss:0.00002, loss_test:0.02203, lr:9.61e-03, fs:0.96364 (r=0.981,p=0.946),  time:26.375, tt:2373.718\n",
      "Ep:90, loss:0.00002, loss_test:0.02338, lr:9.51e-03, fs:0.95495 (r=0.981,p=0.930),  time:26.181, tt:2382.498\n",
      "Ep:91, loss:0.00002, loss_test:0.02112, lr:9.41e-03, fs:0.96364 (r=0.981,p=0.946),  time:25.991, tt:2391.182\n",
      "Ep:92, loss:0.00002, loss_test:0.02192, lr:9.32e-03, fs:0.96364 (r=0.981,p=0.946),  time:25.807, tt:2400.026\n",
      "Ep:93, loss:0.00002, loss_test:0.02308, lr:9.23e-03, fs:0.94643 (r=0.981,p=0.914),  time:25.625, tt:2408.730\n",
      "Ep:94, loss:0.00002, loss_test:0.02081, lr:9.14e-03, fs:0.96364 (r=0.981,p=0.946),  time:25.446, tt:2417.351\n",
      "Ep:95, loss:0.00002, loss_test:0.01987, lr:9.04e-03, fs:0.96364 (r=0.981,p=0.946),  time:25.271, tt:2426.060\n",
      "Ep:96, loss:0.00002, loss_test:0.02190, lr:8.95e-03, fs:0.95495 (r=0.981,p=0.930),  time:25.100, tt:2434.713\n",
      "Ep:97, loss:0.00002, loss_test:0.01934, lr:8.86e-03, fs:0.96364 (r=0.981,p=0.946),  time:24.932, tt:2443.380\n",
      "Ep:98, loss:0.00002, loss_test:0.02180, lr:8.78e-03, fs:0.96364 (r=0.981,p=0.946),  time:24.769, tt:2452.085\n",
      "Ep:99, loss:0.00002, loss_test:0.01954, lr:8.69e-03, fs:0.96364 (r=0.981,p=0.946),  time:24.608, tt:2460.805\n",
      "Ep:100, loss:0.00002, loss_test:0.02060, lr:8.60e-03, fs:0.96364 (r=0.981,p=0.946),  time:24.451, tt:2469.513\n",
      "Ep:101, loss:0.00002, loss_test:0.01930, lr:8.51e-03, fs:0.96364 (r=0.981,p=0.946),  time:24.297, tt:2478.316\n",
      "Ep:102, loss:0.00002, loss_test:0.01903, lr:8.43e-03, fs:0.96364 (r=0.981,p=0.946),  time:24.146, tt:2487.037\n",
      "Ep:103, loss:0.00002, loss_test:0.01946, lr:8.35e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.998, tt:2495.804\n",
      "Ep:104, loss:0.00002, loss_test:0.01921, lr:8.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.852, tt:2504.492\n",
      "Ep:105, loss:0.00002, loss_test:0.01955, lr:8.18e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.709, tt:2513.192\n",
      "Ep:106, loss:0.00002, loss_test:0.01829, lr:8.10e-03, fs:0.97248 (r=0.981,p=0.964),  time:23.568, tt:2521.812\n",
      "Ep:107, loss:0.00002, loss_test:0.01931, lr:8.02e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.430, tt:2530.479\n",
      "Ep:108, loss:0.00002, loss_test:0.01858, lr:7.94e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.295, tt:2539.191\n",
      "Ep:109, loss:0.00002, loss_test:0.01824, lr:7.86e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.163, tt:2547.895\n",
      "Ep:110, loss:0.00002, loss_test:0.02031, lr:7.78e-03, fs:0.96364 (r=0.981,p=0.946),  time:23.032, tt:2556.565\n",
      "Ep:111, loss:0.00002, loss_test:0.01862, lr:7.70e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.905, tt:2565.336\n",
      "Ep:112, loss:0.00002, loss_test:0.01866, lr:7.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.780, tt:2574.096\n",
      "Ep:113, loss:0.00002, loss_test:0.01719, lr:7.55e-03, fs:0.97248 (r=0.981,p=0.964),  time:22.656, tt:2582.820\n",
      "Ep:114, loss:0.00002, loss_test:0.01824, lr:7.47e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.535, tt:2591.537\n",
      "Ep:115, loss:0.00002, loss_test:0.01690, lr:7.40e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.416, tt:2600.228\n",
      "Ep:116, loss:0.00001, loss_test:0.01743, lr:7.32e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.298, tt:2608.871\n",
      "Ep:117, loss:0.00001, loss_test:0.01801, lr:7.25e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.183, tt:2617.547\n",
      "Ep:118, loss:0.00001, loss_test:0.01699, lr:7.18e-03, fs:0.96364 (r=0.981,p=0.946),  time:22.069, tt:2626.219\n",
      "Ep:119, loss:0.00001, loss_test:0.01768, lr:7.11e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.958, tt:2634.954\n",
      "Ep:120, loss:0.00001, loss_test:0.01657, lr:7.03e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.848, tt:2643.578\n",
      "Ep:121, loss:0.00001, loss_test:0.01663, lr:6.96e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.740, tt:2652.330\n",
      "Ep:122, loss:0.00001, loss_test:0.01779, lr:6.89e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.635, tt:2661.057\n",
      "Ep:123, loss:0.00001, loss_test:0.01685, lr:6.83e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.530, tt:2669.762\n",
      "Ep:124, loss:0.00001, loss_test:0.01655, lr:6.76e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.428, tt:2678.475\n",
      "Ep:125, loss:0.00001, loss_test:0.01744, lr:6.69e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.327, tt:2687.203\n",
      "Ep:126, loss:0.00001, loss_test:0.01592, lr:6.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.227, tt:2695.863\n",
      "Ep:127, loss:0.00001, loss_test:0.01730, lr:6.56e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.130, tt:2704.603\n",
      "Ep:128, loss:0.00001, loss_test:0.01586, lr:6.49e-03, fs:0.96364 (r=0.981,p=0.946),  time:21.033, tt:2713.281\n",
      "Ep:129, loss:0.00001, loss_test:0.01638, lr:6.43e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.938, tt:2721.979\n",
      "Ep:130, loss:0.00001, loss_test:0.01671, lr:6.36e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.845, tt:2730.641\n",
      "Ep:131, loss:0.00001, loss_test:0.01563, lr:6.30e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.753, tt:2739.341\n",
      "Ep:132, loss:0.00001, loss_test:0.01653, lr:6.24e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.662, tt:2748.073\n",
      "Ep:133, loss:0.00001, loss_test:0.01563, lr:6.17e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.573, tt:2756.738\n",
      "Ep:134, loss:0.00001, loss_test:0.01612, lr:6.11e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.485, tt:2765.461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.01587, lr:6.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.399, tt:2774.221\n",
      "Ep:136, loss:0.00001, loss_test:0.01557, lr:5.99e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.313, tt:2782.936\n",
      "Ep:137, loss:0.00001, loss_test:0.01564, lr:5.93e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.228, tt:2791.530\n",
      "Ep:138, loss:0.00001, loss_test:0.01549, lr:5.87e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.145, tt:2800.193\n",
      "Ep:139, loss:0.00001, loss_test:0.01584, lr:5.81e-03, fs:0.96364 (r=0.981,p=0.946),  time:20.063, tt:2808.852\n",
      "Ep:140, loss:0.00001, loss_test:0.01537, lr:5.75e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.982, tt:2817.508\n",
      "Ep:141, loss:0.00001, loss_test:0.01539, lr:5.70e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.903, tt:2826.192\n",
      "Ep:142, loss:0.00001, loss_test:0.01524, lr:5.64e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.824, tt:2834.832\n",
      "Ep:143, loss:0.00001, loss_test:0.01517, lr:5.58e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.746, tt:2843.440\n",
      "Ep:144, loss:0.00001, loss_test:0.01540, lr:5.53e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.670, tt:2852.128\n",
      "Ep:145, loss:0.00001, loss_test:0.01516, lr:5.47e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.594, tt:2860.784\n",
      "Ep:146, loss:0.00001, loss_test:0.01524, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.521, tt:2869.528\n",
      "Ep:147, loss:0.00001, loss_test:0.01527, lr:5.36e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.447, tt:2878.212\n",
      "Ep:148, loss:0.00001, loss_test:0.01504, lr:5.31e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.376, tt:2886.952\n",
      "Ep:149, loss:0.00001, loss_test:0.01494, lr:5.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.305, tt:2895.776\n",
      "Ep:150, loss:0.00001, loss_test:0.01510, lr:5.20e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.235, tt:2904.535\n",
      "Ep:151, loss:0.00001, loss_test:0.01468, lr:5.15e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.166, tt:2913.280\n",
      "Ep:152, loss:0.00001, loss_test:0.01509, lr:5.10e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.098, tt:2921.962\n",
      "Ep:153, loss:0.00001, loss_test:0.01484, lr:5.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:19.030, tt:2930.650\n",
      "Ep:154, loss:0.00001, loss_test:0.01512, lr:5.00e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.963, tt:2939.323\n",
      "Ep:155, loss:0.00001, loss_test:0.01477, lr:4.95e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.898, tt:2948.023\n",
      "Ep:156, loss:0.00001, loss_test:0.01454, lr:4.90e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.832, tt:2956.703\n",
      "Ep:157, loss:0.00001, loss_test:0.01483, lr:4.85e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.768, tt:2965.391\n",
      "Ep:158, loss:0.00001, loss_test:0.01458, lr:4.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.706, tt:2974.223\n",
      "Ep:159, loss:0.00001, loss_test:0.01465, lr:4.75e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.643, tt:2982.911\n",
      "Ep:160, loss:0.00001, loss_test:0.01478, lr:4.71e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.581, tt:2991.568\n",
      "Ep:161, loss:0.00001, loss_test:0.01424, lr:4.66e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.520, tt:3000.251\n",
      "Ep:162, loss:0.00001, loss_test:0.01429, lr:4.61e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.459, tt:3008.891\n",
      "Ep:163, loss:0.00001, loss_test:0.01460, lr:4.57e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.400, tt:3017.558\n",
      "Ep:164, loss:0.00001, loss_test:0.01437, lr:4.52e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.341, tt:3026.270\n",
      "Ep:165, loss:0.00001, loss_test:0.01432, lr:4.48e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.283, tt:3034.959\n",
      "Ep:166, loss:0.00001, loss_test:0.01432, lr:4.43e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.225, tt:3043.616\n",
      "Ep:167, loss:0.00001, loss_test:0.01408, lr:4.39e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.169, tt:3052.388\n",
      "Ep:168, loss:0.00001, loss_test:0.01424, lr:4.34e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.113, tt:3061.045\n",
      "Ep:169, loss:0.00001, loss_test:0.01405, lr:4.30e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.057, tt:3069.721\n",
      "Ep:170, loss:0.00001, loss_test:0.01409, lr:4.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:18.003, tt:3078.439\n",
      "Ep:171, loss:0.00001, loss_test:0.01385, lr:4.21e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.948, tt:3087.131\n",
      "Ep:172, loss:0.00001, loss_test:0.01401, lr:4.17e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.895, tt:3095.864\n",
      "Ep:173, loss:0.00001, loss_test:0.01399, lr:4.13e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.842, tt:3104.544\n",
      "Ep:174, loss:0.00001, loss_test:0.01379, lr:4.09e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.790, tt:3113.244\n",
      "Ep:175, loss:0.00001, loss_test:0.01411, lr:4.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.738, tt:3121.975\n",
      "Ep:176, loss:0.00001, loss_test:0.01363, lr:4.01e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.687, tt:3130.611\n",
      "Ep:177, loss:0.00001, loss_test:0.01384, lr:3.97e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.637, tt:3139.302\n",
      "Ep:178, loss:0.00001, loss_test:0.01402, lr:3.93e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.587, tt:3148.069\n",
      "Ep:179, loss:0.00001, loss_test:0.01385, lr:3.89e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.538, tt:3156.803\n",
      "Ep:180, loss:0.00001, loss_test:0.01374, lr:3.85e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.489, tt:3165.455\n",
      "Ep:181, loss:0.00001, loss_test:0.01385, lr:3.81e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.440, tt:3174.159\n",
      "Ep:182, loss:0.00001, loss_test:0.01370, lr:3.77e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.393, tt:3182.871\n",
      "Ep:183, loss:0.00001, loss_test:0.01361, lr:3.73e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.345, tt:3191.490\n",
      "Ep:184, loss:0.00001, loss_test:0.01364, lr:3.70e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.298, tt:3200.165\n",
      "Ep:185, loss:0.00001, loss_test:0.01360, lr:3.66e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.252, tt:3208.833\n",
      "Ep:186, loss:0.00001, loss_test:0.01346, lr:3.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.206, tt:3217.540\n",
      "Ep:187, loss:0.00001, loss_test:0.01353, lr:3.59e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.161, tt:3226.244\n",
      "Ep:188, loss:0.00001, loss_test:0.01357, lr:3.55e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.116, tt:3234.902\n",
      "Ep:189, loss:0.00001, loss_test:0.01355, lr:3.52e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.071, tt:3243.555\n",
      "Ep:190, loss:0.00001, loss_test:0.01341, lr:3.48e-03, fs:0.96364 (r=0.981,p=0.946),  time:17.027, tt:3252.195\n",
      "Ep:191, loss:0.00001, loss_test:0.01343, lr:3.45e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.989, tt:3261.807\n",
      "Ep:192, loss:0.00001, loss_test:0.01343, lr:3.41e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.945, tt:3270.459\n",
      "Ep:193, loss:0.00001, loss_test:0.01335, lr:3.38e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.903, tt:3279.189\n",
      "Ep:194, loss:0.00001, loss_test:0.01338, lr:3.34e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.861, tt:3287.910\n",
      "Ep:195, loss:0.00001, loss_test:0.01355, lr:3.31e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.819, tt:3296.529\n",
      "Ep:196, loss:0.00001, loss_test:0.01325, lr:3.28e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.778, tt:3305.173\n",
      "Ep:197, loss:0.00001, loss_test:0.01326, lr:3.24e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.737, tt:3313.841\n",
      "Ep:198, loss:0.00001, loss_test:0.01333, lr:3.21e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.696, tt:3322.557\n",
      "Ep:199, loss:0.00001, loss_test:0.01324, lr:3.18e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.656, tt:3331.266\n",
      "Ep:200, loss:0.00001, loss_test:0.01323, lr:3.15e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.617, tt:3339.998\n",
      "Ep:201, loss:0.00001, loss_test:0.01321, lr:3.12e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.578, tt:3348.710\n",
      "Ep:202, loss:0.00001, loss_test:0.01321, lr:3.09e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.539, tt:3357.346\n",
      "Ep:203, loss:0.00001, loss_test:0.01320, lr:3.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.500, tt:3366.064\n",
      "Ep:204, loss:0.00001, loss_test:0.01321, lr:3.02e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.471, tt:3376.531\n",
      "Ep:205, loss:0.00001, loss_test:0.01328, lr:2.99e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.434, tt:3385.314\n",
      "Ep:206, loss:0.00001, loss_test:0.01298, lr:2.96e-03, fs:0.96364 (r=0.981,p=0.946),  time:16.396, tt:3393.953\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02729, lr:6.00e-02, fs:0.61654 (r=0.759,p=0.519),  time:35.106, tt:35.106\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02865, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.632, tt:71.264\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.03071, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.984, tt:107.952\n",
      "Ep:3, loss:0.00006, loss_test:0.03098, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.076, tt:144.303\n",
      "Ep:4, loss:0.00006, loss_test:0.03042, lr:6.00e-02, fs:0.67500 (r=1.000,p=0.509),  time:36.052, tt:180.259\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00006, loss_test:0.02969, lr:6.00e-02, fs:0.66242 (r=0.963,p=0.505),  time:35.865, tt:215.187\n",
      "Ep:6, loss:0.00005, loss_test:0.02937, lr:6.00e-02, fs:0.63158 (r=0.889,p=0.490),  time:35.623, tt:249.358\n",
      "Ep:7, loss:0.00005, loss_test:0.02936, lr:6.00e-02, fs:0.60690 (r=0.815,p=0.484),  time:35.378, tt:283.022\n",
      "Ep:8, loss:0.00005, loss_test:0.02929, lr:6.00e-02, fs:0.60432 (r=0.778,p=0.494),  time:35.853, tt:322.673\n",
      "Ep:9, loss:0.00005, loss_test:0.02876, lr:6.00e-02, fs:0.60993 (r=0.796,p=0.494),  time:35.680, tt:356.800\n",
      "Ep:10, loss:0.00005, loss_test:0.02800, lr:6.00e-02, fs:0.60811 (r=0.833,p=0.479),  time:35.635, tt:391.990\n",
      "Ep:11, loss:0.00005, loss_test:0.02759, lr:6.00e-02, fs:0.62252 (r=0.870,p=0.485),  time:35.566, tt:426.794\n",
      "Ep:12, loss:0.00005, loss_test:0.02718, lr:6.00e-02, fs:0.61333 (r=0.852,p=0.479),  time:35.589, tt:462.660\n",
      "Ep:13, loss:0.00005, loss_test:0.02695, lr:6.00e-02, fs:0.61224 (r=0.833,p=0.484),  time:35.596, tt:498.350\n",
      "Ep:14, loss:0.00005, loss_test:0.02673, lr:6.00e-02, fs:0.62411 (r=0.815,p=0.506),  time:35.468, tt:532.015\n",
      "Ep:15, loss:0.00005, loss_test:0.02587, lr:6.00e-02, fs:0.60140 (r=0.796,p=0.483),  time:35.333, tt:565.328\n",
      "Ep:16, loss:0.00004, loss_test:0.02497, lr:5.94e-02, fs:0.59864 (r=0.815,p=0.473),  time:35.276, tt:599.687\n",
      "Ep:17, loss:0.00004, loss_test:0.02421, lr:5.88e-02, fs:0.62937 (r=0.833,p=0.506),  time:35.400, tt:637.196\n",
      "Ep:18, loss:0.00004, loss_test:0.02380, lr:5.82e-02, fs:0.63704 (r=0.796,p=0.531),  time:35.420, tt:672.972\n",
      "Ep:19, loss:0.00004, loss_test:0.02329, lr:5.76e-02, fs:0.65152 (r=0.796,p=0.551),  time:35.350, tt:706.991\n",
      "Ep:20, loss:0.00004, loss_test:0.02223, lr:5.71e-02, fs:0.66187 (r=0.852,p=0.541),  time:35.300, tt:741.306\n",
      "Ep:21, loss:0.00004, loss_test:0.02163, lr:5.65e-02, fs:0.67133 (r=0.889,p=0.539),  time:35.353, tt:777.769\n",
      "Ep:22, loss:0.00004, loss_test:0.02123, lr:5.59e-02, fs:0.67626 (r=0.870,p=0.553),  time:35.375, tt:813.622\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.02097, lr:5.59e-02, fs:0.65693 (r=0.833,p=0.542),  time:35.339, tt:848.139\n",
      "Ep:24, loss:0.00004, loss_test:0.02056, lr:5.59e-02, fs:0.65693 (r=0.833,p=0.542),  time:35.409, tt:885.213\n",
      "Ep:25, loss:0.00004, loss_test:0.02006, lr:5.59e-02, fs:0.65693 (r=0.833,p=0.542),  time:35.360, tt:919.370\n",
      "Ep:26, loss:0.00004, loss_test:0.01956, lr:5.59e-02, fs:0.66176 (r=0.833,p=0.549),  time:35.344, tt:954.288\n",
      "Ep:27, loss:0.00003, loss_test:0.01920, lr:5.59e-02, fs:0.66176 (r=0.833,p=0.549),  time:35.283, tt:987.918\n",
      "Ep:28, loss:0.00003, loss_test:0.01895, lr:5.59e-02, fs:0.67669 (r=0.833,p=0.570),  time:35.423, tt:1027.266\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01856, lr:5.59e-02, fs:0.67669 (r=0.833,p=0.570),  time:35.405, tt:1062.153\n",
      "Ep:30, loss:0.00003, loss_test:0.01820, lr:5.59e-02, fs:0.68182 (r=0.833,p=0.577),  time:35.409, tt:1097.682\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01795, lr:5.59e-02, fs:0.68702 (r=0.833,p=0.584),  time:35.356, tt:1131.381\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01770, lr:5.59e-02, fs:0.68702 (r=0.833,p=0.584),  time:35.370, tt:1167.207\n",
      "Ep:33, loss:0.00003, loss_test:0.01731, lr:5.59e-02, fs:0.70229 (r=0.852,p=0.597),  time:35.359, tt:1202.198\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01721, lr:5.59e-02, fs:0.70229 (r=0.852,p=0.597),  time:35.332, tt:1236.622\n",
      "Ep:35, loss:0.00003, loss_test:0.01700, lr:5.59e-02, fs:0.70769 (r=0.852,p=0.605),  time:35.323, tt:1271.619\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01663, lr:5.59e-02, fs:0.72727 (r=0.889,p=0.615),  time:35.307, tt:1306.375\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02535, lr:6.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:34.160, tt:34.160\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02454, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:34.474, tt:68.948\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02722, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:34.371, tt:103.113\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00006, loss_test:0.02808, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.878, tt:135.510\n",
      "Ep:4, loss:0.00006, loss_test:0.02751, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:33.647, tt:168.235\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00006, loss_test:0.02664, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:33.821, tt:202.929\n",
      "Ep:6, loss:0.00005, loss_test:0.02579, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:33.990, tt:237.929\n",
      "Ep:7, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:34.070, tt:272.560\n",
      "Ep:8, loss:0.00005, loss_test:0.02474, lr:6.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:34.055, tt:306.491\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00005, loss_test:0.02455, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:33.930, tt:339.295\n",
      "Ep:10, loss:0.00005, loss_test:0.02417, lr:6.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:34.020, tt:374.220\n",
      "Ep:11, loss:0.00005, loss_test:0.02341, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:34.071, tt:408.848\n",
      "Ep:12, loss:0.00005, loss_test:0.02249, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:34.083, tt:443.082\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00005, loss_test:0.02167, lr:6.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.102, tt:477.425\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00005, loss_test:0.02089, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:34.145, tt:512.182\n",
      "Ep:15, loss:0.00004, loss_test:0.02024, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:34.111, tt:545.770\n",
      "Ep:16, loss:0.00004, loss_test:0.01972, lr:6.00e-02, fs:0.65844 (r=0.808,p=0.556),  time:34.124, tt:580.115\n",
      "Ep:17, loss:0.00004, loss_test:0.01888, lr:6.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:34.247, tt:616.441\n",
      "Ep:18, loss:0.00004, loss_test:0.01830, lr:6.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:34.186, tt:649.531\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01782, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:34.171, tt:683.417\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01747, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:34.188, tt:717.944\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01726, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:34.234, tt:753.145\n",
      "Ep:22, loss:0.00004, loss_test:0.01696, lr:6.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:34.237, tt:787.449\n",
      "Ep:23, loss:0.00004, loss_test:0.01685, lr:6.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:34.211, tt:821.059\n",
      "Ep:24, loss:0.00004, loss_test:0.01656, lr:6.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:34.248, tt:856.210\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01637, lr:6.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:34.322, tt:892.361\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01622, lr:6.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:34.268, tt:925.233\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:34.273, tt:959.635\n",
      "Ep:28, loss:0.00003, loss_test:0.01581, lr:6.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:34.264, tt:993.667\n",
      "Ep:29, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:34.268, tt:1028.028\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01540, lr:6.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:34.245, tt:1061.598\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:34.252, tt:1096.060\n",
      "Ep:32, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.216, tt:1129.121\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:34.239, tt:1164.136\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:34.229, tt:1198.019\n",
      "Ep:35, loss:0.00003, loss_test:0.01456, lr:6.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:34.212, tt:1231.632\n",
      "Ep:36, loss:0.00003, loss_test:0.01421, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:34.155, tt:1263.733\n",
      "Ep:37, loss:0.00003, loss_test:0.01399, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:34.117, tt:1296.435\n",
      "Ep:38, loss:0.00003, loss_test:0.01388, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:34.100, tt:1329.906\n",
      "Ep:39, loss:0.00003, loss_test:0.01358, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:34.091, tt:1363.649\n",
      "Ep:40, loss:0.00003, loss_test:0.01320, lr:6.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:34.083, tt:1397.408\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:34.122, tt:1433.127\n",
      "Ep:42, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:34.085, tt:1465.668\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:34.081, tt:1499.549\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01220, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:34.105, tt:1534.715\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01234, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:34.123, tt:1569.660\n",
      "Ep:46, loss:0.00002, loss_test:0.01179, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:34.138, tt:1604.474\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:34.141, tt:1638.749\n",
      "Ep:48, loss:0.00002, loss_test:0.01138, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:34.154, tt:1673.551\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01159, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:34.143, tt:1707.159\n",
      "Ep:50, loss:0.00002, loss_test:0.01131, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.102, tt:1739.179\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01112, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:34.086, tt:1772.446\n",
      "Ep:52, loss:0.00002, loss_test:0.01133, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:34.076, tt:1806.016\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01119, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:34.084, tt:1840.523\n",
      "Ep:54, loss:0.00002, loss_test:0.01054, lr:6.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:34.077, tt:1874.229\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:34.073, tt:1908.109\n",
      "Ep:56, loss:0.00002, loss_test:0.01050, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.080, tt:1942.573\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01103, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.076, tt:1976.428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00002, loss_test:0.01007, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:34.065, tt:2009.862\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01027, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:34.032, tt:2041.912\n",
      "Ep:60, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.047, tt:2076.844\n",
      "Ep:61, loss:0.00001, loss_test:0.01007, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:34.040, tt:2110.486\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01013, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:34.042, tt:2144.657\n",
      "Ep:63, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:34.046, tt:2178.952\n",
      "Ep:64, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:34.044, tt:2212.828\n",
      "Ep:65, loss:0.00001, loss_test:0.00927, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:34.026, tt:2245.699\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01033, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:34.015, tt:2279.030\n",
      "Ep:67, loss:0.00001, loss_test:0.00901, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:34.000, tt:2311.984\n",
      "Ep:68, loss:0.00001, loss_test:0.00890, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:33.993, tt:2345.509\n",
      "Ep:69, loss:0.00001, loss_test:0.00951, lr:6.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:33.994, tt:2379.562\n",
      "Ep:70, loss:0.00001, loss_test:0.00890, lr:6.00e-02, fs:0.89815 (r=0.980,p=0.829),  time:33.996, tt:2413.732\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.00910, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:34.000, tt:2448.031\n",
      "Ep:72, loss:0.00001, loss_test:0.00845, lr:6.00e-02, fs:0.89593 (r=1.000,p=0.811),  time:34.020, tt:2483.492\n",
      "Ep:73, loss:0.00001, loss_test:0.00879, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:34.049, tt:2519.615\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:34.064, tt:2554.820\n",
      "Ep:75, loss:0.00001, loss_test:0.00819, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:34.094, tt:2591.122\n",
      "Ep:76, loss:0.00001, loss_test:0.00824, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:34.110, tt:2626.436\n",
      "Ep:77, loss:0.00001, loss_test:0.00853, lr:6.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:34.146, tt:2663.378\n",
      "Ep:78, loss:0.00001, loss_test:0.00862, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:34.169, tt:2699.321\n",
      "Ep:79, loss:0.00001, loss_test:0.00935, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:34.183, tt:2734.669\n",
      "Ep:80, loss:0.00001, loss_test:0.00776, lr:6.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:34.212, tt:2771.175\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:34.228, tt:2806.698\n",
      "Ep:82, loss:0.00001, loss_test:0.00788, lr:6.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:34.230, tt:2841.065\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.00861, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:34.227, tt:2875.038\n",
      "Ep:84, loss:0.00001, loss_test:0.00821, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:34.213, tt:2908.099\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.00865, lr:6.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.208, tt:2941.873\n",
      "Ep:86, loss:0.00001, loss_test:0.00787, lr:6.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:34.206, tt:2975.900\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:34.191, tt:3008.838\n",
      "Ep:88, loss:0.00001, loss_test:0.00846, lr:6.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:34.179, tt:3041.918\n",
      "Ep:89, loss:0.00001, loss_test:0.00861, lr:6.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:34.167, tt:3075.060\n",
      "Ep:90, loss:0.00001, loss_test:0.00756, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.160, tt:3108.593\n",
      "Ep:91, loss:0.00001, loss_test:0.00944, lr:6.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:34.150, tt:3141.812\n",
      "Ep:92, loss:0.00001, loss_test:0.00890, lr:6.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:34.155, tt:3176.380\n",
      "Ep:93, loss:0.00001, loss_test:0.00744, lr:6.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:34.140, tt:3209.173\n",
      "Ep:94, loss:0.00001, loss_test:0.00928, lr:6.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:34.137, tt:3243.027\n",
      "Ep:95, loss:0.00001, loss_test:0.00798, lr:6.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:34.137, tt:3277.135\n",
      "Ep:96, loss:0.00001, loss_test:0.00803, lr:6.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:34.140, tt:3311.622\n",
      "Ep:97, loss:0.00000, loss_test:0.00984, lr:6.00e-02, fs:0.90355 (r=0.899,p=0.908),  time:34.127, tt:3344.486\n",
      "Ep:98, loss:0.00000, loss_test:0.00769, lr:5.94e-02, fs:0.91371 (r=0.909,p=0.918),  time:34.110, tt:3376.904\n",
      "Ep:99, loss:0.00000, loss_test:0.00855, lr:5.88e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.098, tt:3409.846\n",
      "Ep:100, loss:0.00000, loss_test:0.00894, lr:5.82e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.089, tt:3442.958\n",
      "Ep:101, loss:0.00000, loss_test:0.00752, lr:5.76e-02, fs:0.91192 (r=0.889,p=0.936),  time:34.090, tt:3477.167\n",
      "Ep:102, loss:0.00000, loss_test:0.00957, lr:5.71e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.091, tt:3511.345\n",
      "Ep:103, loss:0.00000, loss_test:0.00809, lr:5.65e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.092, tt:3545.553\n",
      "Ep:104, loss:0.00000, loss_test:0.00870, lr:5.59e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.088, tt:3579.271\n",
      "Ep:105, loss:0.00000, loss_test:0.00856, lr:5.54e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.102, tt:3614.775\n",
      "Ep:106, loss:0.00000, loss_test:0.00800, lr:5.48e-02, fs:0.92929 (r=0.929,p=0.929),  time:34.112, tt:3649.964\n",
      "Ep:107, loss:0.00000, loss_test:0.00862, lr:5.43e-02, fs:0.93137 (r=0.960,p=0.905),  time:34.120, tt:3685.000\n",
      "Ep:108, loss:0.00000, loss_test:0.00812, lr:5.37e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.121, tt:3719.215\n",
      "Ep:109, loss:0.00000, loss_test:0.00833, lr:5.32e-02, fs:0.90155 (r=0.879,p=0.926),  time:34.123, tt:3753.584\n",
      "Ep:110, loss:0.00000, loss_test:0.00888, lr:5.27e-02, fs:0.91542 (r=0.929,p=0.902),  time:34.150, tt:3790.675\n",
      "Ep:111, loss:0.00000, loss_test:0.00846, lr:5.21e-02, fs:0.92308 (r=0.909,p=0.938),  time:34.146, tt:3824.303\n",
      "Ep:112, loss:0.00000, loss_test:0.00829, lr:5.16e-02, fs:0.90722 (r=0.889,p=0.926),  time:34.144, tt:3858.266\n",
      "Ep:113, loss:0.00000, loss_test:0.00957, lr:5.11e-02, fs:0.91919 (r=0.919,p=0.919),  time:34.142, tt:3892.185\n",
      "Ep:114, loss:0.00000, loss_test:0.00801, lr:5.06e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.147, tt:3926.857\n",
      "Ep:115, loss:0.00000, loss_test:0.00908, lr:5.01e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.126, tt:3958.610\n",
      "Ep:116, loss:0.00000, loss_test:0.00851, lr:4.96e-02, fs:0.93069 (r=0.949,p=0.913),  time:34.116, tt:3991.528\n",
      "Ep:117, loss:0.00000, loss_test:0.00849, lr:4.91e-02, fs:0.91005 (r=0.869,p=0.956),  time:34.107, tt:4024.653\n",
      "Ep:118, loss:0.00000, loss_test:0.00883, lr:4.86e-02, fs:0.92000 (r=0.929,p=0.911),  time:34.105, tt:4058.444\n",
      "Ep:119, loss:0.00000, loss_test:0.00860, lr:4.81e-02, fs:0.91192 (r=0.889,p=0.936),  time:34.091, tt:4090.892\n",
      "Ep:120, loss:0.00000, loss_test:0.00880, lr:4.76e-02, fs:0.94000 (r=0.949,p=0.931),  time:34.019, tt:4116.275\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00000, loss_test:0.00894, lr:4.76e-02, fs:0.89231 (r=0.879,p=0.906),  time:33.927, tt:4139.055\n",
      "Ep:122, loss:0.00000, loss_test:0.00872, lr:4.76e-02, fs:0.95477 (r=0.960,p=0.950),  time:33.870, tt:4166.035\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.00854, lr:4.76e-02, fs:0.90625 (r=0.879,p=0.935),  time:33.814, tt:4192.936\n",
      "Ep:124, loss:0.00000, loss_test:0.00909, lr:4.76e-02, fs:0.94949 (r=0.949,p=0.949),  time:33.751, tt:4218.840\n",
      "Ep:125, loss:0.00000, loss_test:0.00869, lr:4.76e-02, fs:0.89362 (r=0.848,p=0.944),  time:33.711, tt:4247.646\n",
      "Ep:126, loss:0.00000, loss_test:0.00920, lr:4.76e-02, fs:0.94949 (r=0.949,p=0.949),  time:33.706, tt:4280.643\n",
      "Ep:127, loss:0.00000, loss_test:0.00895, lr:4.76e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.722, tt:4316.443\n",
      "Ep:128, loss:0.00000, loss_test:0.00914, lr:4.76e-02, fs:0.94472 (r=0.949,p=0.940),  time:33.750, tt:4353.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00000, loss_test:0.00904, lr:4.76e-02, fs:0.90526 (r=0.869,p=0.945),  time:33.766, tt:4389.523\n",
      "Ep:130, loss:0.00000, loss_test:0.00911, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:33.784, tt:4425.740\n",
      "Ep:131, loss:0.00000, loss_test:0.00938, lr:4.76e-02, fs:0.91579 (r=0.879,p=0.956),  time:33.802, tt:4461.843\n",
      "Ep:132, loss:0.00000, loss_test:0.00908, lr:4.76e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.818, tt:4497.734\n",
      "Ep:133, loss:0.00000, loss_test:0.00917, lr:4.76e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.835, tt:4533.941\n",
      "Ep:134, loss:0.00000, loss_test:0.00923, lr:4.71e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.849, tt:4569.586\n",
      "Ep:135, loss:0.00000, loss_test:0.00945, lr:4.67e-02, fs:0.89947 (r=0.859,p=0.944),  time:33.876, tt:4607.126\n",
      "Ep:136, loss:0.00000, loss_test:0.00935, lr:4.62e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.894, tt:4643.436\n",
      "Ep:137, loss:0.00000, loss_test:0.00926, lr:4.57e-02, fs:0.90909 (r=0.859,p=0.966),  time:33.910, tt:4679.602\n",
      "Ep:138, loss:0.00000, loss_test:0.00966, lr:4.53e-02, fs:0.88542 (r=0.859,p=0.914),  time:33.927, tt:4715.879\n",
      "Ep:139, loss:0.00000, loss_test:0.00940, lr:4.48e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.943, tt:4752.036\n",
      "Ep:140, loss:0.00000, loss_test:0.00916, lr:4.44e-02, fs:0.90909 (r=0.859,p=0.966),  time:33.971, tt:4789.892\n",
      "Ep:141, loss:0.00000, loss_test:0.00970, lr:4.39e-02, fs:0.88889 (r=0.848,p=0.933),  time:33.990, tt:4826.523\n",
      "Ep:142, loss:0.00000, loss_test:0.00947, lr:4.35e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.985, tt:4859.829\n",
      "Ep:143, loss:0.00000, loss_test:0.00936, lr:4.31e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.981, tt:4893.315\n",
      "Ep:144, loss:0.00000, loss_test:0.00966, lr:4.26e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.979, tt:4926.899\n",
      "Ep:145, loss:0.00000, loss_test:0.00908, lr:4.22e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.976, tt:4960.507\n",
      "Ep:146, loss:0.00000, loss_test:0.00998, lr:4.18e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.973, tt:4994.001\n",
      "Ep:147, loss:0.00000, loss_test:0.00945, lr:4.14e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.963, tt:5026.480\n",
      "Ep:148, loss:0.00000, loss_test:0.00985, lr:4.10e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.961, tt:5060.124\n",
      "Ep:149, loss:0.00000, loss_test:0.00977, lr:4.05e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.963, tt:5094.444\n",
      "Ep:150, loss:0.00000, loss_test:0.00960, lr:4.01e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.960, tt:5127.936\n",
      "Ep:151, loss:0.00000, loss_test:0.00984, lr:3.97e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.959, tt:5161.706\n",
      "Ep:152, loss:0.00000, loss_test:0.00969, lr:3.93e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.957, tt:5195.409\n",
      "Ep:153, loss:0.00000, loss_test:0.01012, lr:3.89e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.952, tt:5228.612\n",
      "Ep:154, loss:0.00000, loss_test:0.00931, lr:3.86e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.955, tt:5263.060\n",
      "Ep:155, loss:0.00000, loss_test:0.01040, lr:3.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.949, tt:5296.091\n",
      "Ep:156, loss:0.00000, loss_test:0.00932, lr:3.78e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.952, tt:5330.499\n",
      "Ep:157, loss:0.00000, loss_test:0.01043, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.957, tt:5365.230\n",
      "Ep:158, loss:0.00000, loss_test:0.00947, lr:3.70e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.958, tt:5399.321\n",
      "Ep:159, loss:0.00000, loss_test:0.01026, lr:3.67e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.958, tt:5433.236\n",
      "Ep:160, loss:0.00000, loss_test:0.00961, lr:3.63e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.973, tt:5469.599\n",
      "Ep:161, loss:0.00000, loss_test:0.01028, lr:3.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.975, tt:5504.016\n",
      "Ep:162, loss:0.00000, loss_test:0.00974, lr:3.56e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.975, tt:5537.972\n",
      "Ep:163, loss:0.00000, loss_test:0.01049, lr:3.52e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.979, tt:5572.549\n",
      "Ep:164, loss:0.00000, loss_test:0.00971, lr:3.49e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.979, tt:5606.573\n",
      "Ep:165, loss:0.00000, loss_test:0.01045, lr:3.45e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.983, tt:5641.258\n",
      "Ep:166, loss:0.00000, loss_test:0.01001, lr:3.42e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.983, tt:5675.164\n",
      "Ep:167, loss:0.00000, loss_test:0.01025, lr:3.38e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.993, tt:5710.764\n",
      "Ep:168, loss:0.00000, loss_test:0.00995, lr:3.35e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.994, tt:5745.046\n",
      "Ep:169, loss:0.00000, loss_test:0.01034, lr:3.32e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.991, tt:5778.537\n",
      "Ep:170, loss:0.00000, loss_test:0.01002, lr:3.28e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.997, tt:5813.489\n",
      "Ep:171, loss:0.00000, loss_test:0.01035, lr:3.25e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.999, tt:5847.870\n",
      "Ep:172, loss:0.00000, loss_test:0.01023, lr:3.22e-02, fs:0.90323 (r=0.848,p=0.966),  time:34.002, tt:5882.348\n",
      "Ep:173, loss:0.00000, loss_test:0.01037, lr:3.19e-02, fs:0.90323 (r=0.848,p=0.966),  time:34.004, tt:5916.652\n",
      "Ep:174, loss:0.00000, loss_test:0.01024, lr:3.15e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.996, tt:5949.367\n",
      "Ep:175, loss:0.00000, loss_test:0.01036, lr:3.12e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.997, tt:5983.530\n",
      "Ep:176, loss:0.00000, loss_test:0.01033, lr:3.09e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.994, tt:6016.871\n",
      "Ep:177, loss:0.00000, loss_test:0.01043, lr:3.06e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.994, tt:6050.907\n",
      "Ep:178, loss:0.00000, loss_test:0.01037, lr:3.03e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.987, tt:6083.653\n",
      "Ep:179, loss:0.00000, loss_test:0.01045, lr:3.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.986, tt:6117.549\n",
      "Ep:180, loss:0.00000, loss_test:0.01047, lr:2.97e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.998, tt:6153.643\n",
      "Ep:181, loss:0.00000, loss_test:0.01046, lr:2.94e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.993, tt:6186.667\n",
      "Ep:182, loss:0.00000, loss_test:0.01046, lr:2.91e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.983, tt:6218.935\n",
      "Ep:183, loss:0.00000, loss_test:0.01048, lr:2.88e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.969, tt:6250.295\n",
      "Ep:184, loss:0.00000, loss_test:0.01046, lr:2.85e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.968, tt:6284.124\n",
      "Ep:185, loss:0.00000, loss_test:0.01052, lr:2.82e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.964, tt:6317.228\n",
      "Ep:186, loss:0.00000, loss_test:0.01047, lr:2.80e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.965, tt:6351.432\n",
      "Ep:187, loss:0.00000, loss_test:0.01053, lr:2.77e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.964, tt:6385.304\n",
      "Ep:188, loss:0.00000, loss_test:0.01059, lr:2.74e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.960, tt:6418.359\n",
      "Ep:189, loss:0.00000, loss_test:0.01051, lr:2.71e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.950, tt:6450.459\n",
      "Ep:190, loss:0.00000, loss_test:0.01057, lr:2.69e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.949, tt:6484.211\n",
      "Ep:191, loss:0.00000, loss_test:0.01052, lr:2.66e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.946, tt:6517.600\n",
      "Ep:192, loss:0.00000, loss_test:0.01060, lr:2.63e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.942, tt:6550.780\n",
      "Ep:193, loss:0.00000, loss_test:0.01065, lr:2.61e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.933, tt:6582.987\n",
      "Ep:194, loss:0.00000, loss_test:0.01063, lr:2.58e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.930, tt:6616.327\n",
      "Ep:195, loss:0.00000, loss_test:0.01059, lr:2.55e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.935, tt:6651.194\n",
      "Ep:196, loss:0.00000, loss_test:0.01057, lr:2.53e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.939, tt:6685.969\n",
      "Ep:197, loss:0.00000, loss_test:0.01069, lr:2.50e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.949, tt:6721.965\n",
      "Ep:198, loss:0.00000, loss_test:0.01062, lr:2.48e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.948, tt:6755.600\n",
      "Ep:199, loss:0.00000, loss_test:0.01066, lr:2.45e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.941, tt:6788.285\n",
      "Ep:200, loss:0.00000, loss_test:0.01073, lr:2.43e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.937, tt:6821.367\n",
      "Ep:201, loss:0.00000, loss_test:0.01062, lr:2.40e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.941, tt:6856.156\n",
      "Ep:202, loss:0.00000, loss_test:0.01071, lr:2.38e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.949, tt:6891.724\n",
      "Ep:203, loss:0.00000, loss_test:0.01067, lr:2.36e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.944, tt:6924.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.01075, lr:2.33e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.950, tt:6959.755\n",
      "Ep:205, loss:0.00000, loss_test:0.01069, lr:2.31e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.953, tt:6994.419\n",
      "Ep:206, loss:0.00000, loss_test:0.01071, lr:2.29e-02, fs:0.90323 (r=0.848,p=0.966),  time:33.964, tt:7030.449\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12553, lr:1.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:36.742, tt:36.742\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12383, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:38.388, tt:76.775\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12271, lr:1.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:37.622, tt:112.866\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12221, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:37.042, tt:148.166\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12186, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:36.976, tt:184.882\n",
      "Ep:5, loss:0.00026, loss_test:0.12139, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:37.435, tt:224.609\n",
      "Ep:6, loss:0.00025, loss_test:0.12082, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:37.423, tt:261.964\n",
      "Ep:7, loss:0.00025, loss_test:0.12005, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:37.375, tt:299.003\n",
      "Ep:8, loss:0.00025, loss_test:0.11927, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:37.241, tt:335.167\n",
      "Ep:9, loss:0.00025, loss_test:0.11864, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:37.049, tt:370.488\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.11812, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:36.900, tt:405.904\n",
      "Ep:11, loss:0.00025, loss_test:0.11759, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:36.727, tt:440.720\n",
      "Ep:12, loss:0.00024, loss_test:0.11685, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:36.729, tt:477.474\n",
      "Ep:13, loss:0.00024, loss_test:0.11573, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:36.626, tt:512.759\n",
      "Ep:14, loss:0.00024, loss_test:0.11471, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:36.627, tt:549.412\n",
      "Ep:15, loss:0.00023, loss_test:0.11321, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:36.869, tt:589.904\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.11066, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:36.801, tt:625.617\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.10858, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:36.739, tt:661.301\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10717, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:36.719, tt:697.668\n",
      "Ep:19, loss:0.00022, loss_test:0.10475, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:36.683, tt:733.656\n",
      "Ep:20, loss:0.00021, loss_test:0.10296, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:36.677, tt:770.220\n",
      "Ep:21, loss:0.00021, loss_test:0.10080, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:36.581, tt:804.777\n",
      "Ep:22, loss:0.00020, loss_test:0.09923, lr:1.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:36.619, tt:842.229\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.09590, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:36.659, tt:879.817\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.09386, lr:1.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:36.681, tt:917.024\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.08953, lr:1.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:36.654, tt:952.992\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.08774, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:36.568, tt:987.349\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.08322, lr:1.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:36.540, tt:1023.129\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.08882, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:36.481, tt:1057.954\n",
      "Ep:29, loss:0.00017, loss_test:0.08105, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.466, tt:1093.992\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.07973, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:36.476, tt:1130.764\n",
      "Ep:31, loss:0.00016, loss_test:0.07765, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:36.460, tt:1166.723\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.07740, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:36.500, tt:1204.488\n",
      "Ep:33, loss:0.00015, loss_test:0.07842, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:36.449, tt:1239.268\n",
      "Ep:34, loss:0.00015, loss_test:0.07312, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:36.470, tt:1276.459\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.07810, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:36.412, tt:1310.823\n",
      "Ep:36, loss:0.00014, loss_test:0.07106, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:36.422, tt:1347.629\n",
      "Ep:37, loss:0.00013, loss_test:0.06904, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:36.375, tt:1382.237\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.07337, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:36.332, tt:1416.945\n",
      "Ep:39, loss:0.00012, loss_test:0.06687, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:36.314, tt:1452.565\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00012, loss_test:0.06598, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:36.318, tt:1489.053\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.06497, lr:1.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:36.303, tt:1524.731\n",
      "Ep:42, loss:0.00011, loss_test:0.06377, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:36.282, tt:1560.117\n",
      "Ep:43, loss:0.00010, loss_test:0.06119, lr:1.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:36.233, tt:1594.246\n",
      "Ep:44, loss:0.00010, loss_test:0.05938, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:36.172, tt:1627.731\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.05840, lr:1.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:36.157, tt:1663.213\n",
      "Ep:46, loss:0.00009, loss_test:0.07498, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:36.179, tt:1700.408\n",
      "Ep:47, loss:0.00013, loss_test:0.10174, lr:1.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:36.181, tt:1736.680\n",
      "Ep:48, loss:0.00015, loss_test:0.07514, lr:1.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:36.205, tt:1774.037\n",
      "Ep:49, loss:0.00013, loss_test:0.07290, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:36.209, tt:1810.448\n",
      "Ep:50, loss:0.00013, loss_test:0.06876, lr:1.00e-02, fs:0.82845 (r=1.000,p=0.707),  time:36.190, tt:1845.707\n",
      "Ep:51, loss:0.00011, loss_test:0.06006, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:36.205, tt:1882.675\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00010, loss_test:0.06497, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:36.212, tt:1919.234\n",
      "Ep:53, loss:0.00010, loss_test:0.05673, lr:1.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:36.213, tt:1955.492\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00010, loss_test:0.06093, lr:1.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:36.205, tt:1991.288\n",
      "Ep:55, loss:0.00009, loss_test:0.05512, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:36.184, tt:2026.313\n",
      "Ep:56, loss:0.00009, loss_test:0.05660, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:36.203, tt:2063.586\n",
      "Ep:57, loss:0.00008, loss_test:0.04953, lr:1.00e-02, fs:0.89498 (r=0.990,p=0.817),  time:36.237, tt:2101.766\n",
      "Ep:58, loss:0.00008, loss_test:0.04714, lr:1.00e-02, fs:0.92891 (r=0.990,p=0.875),  time:36.250, tt:2138.730\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00007, loss_test:0.04666, lr:1.00e-02, fs:0.90826 (r=1.000,p=0.832),  time:36.260, tt:2175.587\n",
      "Ep:60, loss:0.00007, loss_test:0.04787, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:36.250, tt:2211.241\n",
      "Ep:61, loss:0.00007, loss_test:0.04808, lr:1.00e-02, fs:0.89498 (r=0.990,p=0.817),  time:36.226, tt:2246.029\n",
      "Ep:62, loss:0.00007, loss_test:0.04429, lr:1.00e-02, fs:0.92823 (r=0.980,p=0.882),  time:36.187, tt:2279.776\n",
      "Ep:63, loss:0.00006, loss_test:0.04370, lr:1.00e-02, fs:0.90826 (r=1.000,p=0.832),  time:36.193, tt:2316.370\n",
      "Ep:64, loss:0.00006, loss_test:0.04288, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:36.178, tt:2351.602\n",
      "Ep:65, loss:0.00006, loss_test:0.04201, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:36.172, tt:2387.364\n",
      "Ep:66, loss:0.00005, loss_test:0.04288, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:36.151, tt:2422.100\n",
      "Ep:67, loss:0.00005, loss_test:0.04418, lr:1.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:36.167, tt:2459.378\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.04299, lr:1.00e-02, fs:0.90826 (r=1.000,p=0.832),  time:36.181, tt:2496.483\n",
      "Ep:69, loss:0.00005, loss_test:0.04154, lr:1.00e-02, fs:0.92523 (r=1.000,p=0.861),  time:36.203, tt:2534.196\n",
      "Ep:70, loss:0.00005, loss_test:0.03971, lr:1.00e-02, fs:0.93333 (r=0.990,p=0.883),  time:36.209, tt:2570.832\n",
      "Ep:71, loss:0.00004, loss_test:0.04112, lr:1.00e-02, fs:0.92093 (r=1.000,p=0.853),  time:36.229, tt:2608.462\n",
      "Ep:72, loss:0.00004, loss_test:0.04157, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:36.245, tt:2645.895\n",
      "Ep:73, loss:0.00004, loss_test:0.03875, lr:1.00e-02, fs:0.92958 (r=1.000,p=0.868),  time:36.255, tt:2682.863\n",
      "Ep:74, loss:0.00004, loss_test:0.03770, lr:1.00e-02, fs:0.93396 (r=1.000,p=0.876),  time:36.273, tt:2720.466\n",
      "Ep:75, loss:0.00004, loss_test:0.03821, lr:1.00e-02, fs:0.93780 (r=0.990,p=0.891),  time:36.294, tt:2758.345\n",
      "Ep:76, loss:0.00004, loss_test:0.03966, lr:1.00e-02, fs:0.92958 (r=1.000,p=0.868),  time:36.292, tt:2794.468\n",
      "Ep:77, loss:0.00003, loss_test:0.03687, lr:1.00e-02, fs:0.94286 (r=1.000,p=0.892),  time:36.305, tt:2831.816\n",
      "Ep:78, loss:0.00004, loss_test:0.04154, lr:1.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:36.301, tt:2867.811\n",
      "Ep:79, loss:0.00004, loss_test:0.04493, lr:9.90e-03, fs:0.93204 (r=0.970,p=0.897),  time:36.284, tt:2902.705\n",
      "Ep:80, loss:0.00004, loss_test:0.04553, lr:9.80e-03, fs:0.88462 (r=0.929,p=0.844),  time:36.275, tt:2938.278\n",
      "Ep:81, loss:0.00004, loss_test:0.04369, lr:9.70e-03, fs:0.92381 (r=0.980,p=0.874),  time:36.273, tt:2974.421\n",
      "Ep:82, loss:0.00004, loss_test:0.04666, lr:9.61e-03, fs:0.88152 (r=0.939,p=0.830),  time:36.252, tt:3008.905\n",
      "Ep:83, loss:0.00004, loss_test:0.04865, lr:9.51e-03, fs:0.92683 (r=0.960,p=0.896),  time:36.241, tt:3044.225\n",
      "Ep:84, loss:0.00004, loss_test:0.04247, lr:9.41e-03, fs:0.89952 (r=0.949,p=0.855),  time:36.239, tt:3080.299\n",
      "Ep:85, loss:0.00004, loss_test:0.04599, lr:9.32e-03, fs:0.92308 (r=0.970,p=0.881),  time:36.225, tt:3115.383\n",
      "Ep:86, loss:0.00004, loss_test:0.04091, lr:9.23e-03, fs:0.90411 (r=1.000,p=0.825),  time:36.207, tt:3150.023\n",
      "Ep:87, loss:0.00004, loss_test:0.03524, lr:9.14e-03, fs:0.94286 (r=1.000,p=0.892),  time:36.208, tt:3186.347\n",
      "Ep:88, loss:0.00003, loss_test:0.03913, lr:9.04e-03, fs:0.94581 (r=0.970,p=0.923),  time:36.212, tt:3222.855\n",
      "Ep:89, loss:0.00003, loss_test:0.03473, lr:8.95e-03, fs:0.92958 (r=1.000,p=0.868),  time:36.219, tt:3259.681\n",
      "Ep:90, loss:0.00003, loss_test:0.03606, lr:8.86e-03, fs:0.92958 (r=1.000,p=0.868),  time:36.192, tt:3293.460\n",
      "Ep:91, loss:0.00003, loss_test:0.03466, lr:8.78e-03, fs:0.93720 (r=0.980,p=0.898),  time:36.217, tt:3331.942\n",
      "Ep:92, loss:0.00002, loss_test:0.03401, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.212, tt:3367.758\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.03543, lr:8.69e-03, fs:0.92958 (r=1.000,p=0.868),  time:36.229, tt:3405.543\n",
      "Ep:94, loss:0.00002, loss_test:0.03224, lr:8.69e-03, fs:0.97000 (r=0.980,p=0.960),  time:36.237, tt:3442.534\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.03456, lr:8.69e-03, fs:0.94286 (r=1.000,p=0.892),  time:36.247, tt:3479.713\n",
      "Ep:96, loss:0.00002, loss_test:0.03439, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.266, tt:3517.773\n",
      "Ep:97, loss:0.00002, loss_test:0.03411, lr:8.69e-03, fs:0.95522 (r=0.970,p=0.941),  time:36.267, tt:3554.142\n",
      "Ep:98, loss:0.00002, loss_test:0.03358, lr:8.69e-03, fs:0.93839 (r=1.000,p=0.884),  time:36.259, tt:3589.683\n",
      "Ep:99, loss:0.00002, loss_test:0.03051, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.273, tt:3627.319\n",
      "Ep:100, loss:0.00002, loss_test:0.03231, lr:8.69e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.273, tt:3663.592\n",
      "Ep:101, loss:0.00002, loss_test:0.03584, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.295, tt:3702.101\n",
      "Ep:102, loss:0.00002, loss_test:0.03196, lr:8.69e-03, fs:0.98000 (r=0.990,p=0.970),  time:36.297, tt:3738.603\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00002, loss_test:0.03131, lr:8.69e-03, fs:0.95192 (r=1.000,p=0.908),  time:36.291, tt:3774.214\n",
      "Ep:104, loss:0.00002, loss_test:0.03235, lr:8.69e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.277, tt:3809.088\n",
      "Ep:105, loss:0.00001, loss_test:0.03168, lr:8.69e-03, fs:0.95567 (r=0.980,p=0.933),  time:36.272, tt:3844.815\n",
      "Ep:106, loss:0.00001, loss_test:0.03091, lr:8.69e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.274, tt:3881.319\n",
      "Ep:107, loss:0.00001, loss_test:0.02934, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.266, tt:3916.778\n",
      "Ep:108, loss:0.00001, loss_test:0.03062, lr:8.69e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.267, tt:3953.143\n",
      "Ep:109, loss:0.00001, loss_test:0.03057, lr:8.69e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.266, tt:3989.207\n",
      "Ep:110, loss:0.00001, loss_test:0.02865, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.258, tt:4024.622\n",
      "Ep:111, loss:0.00001, loss_test:0.03192, lr:8.69e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.260, tt:4061.074\n",
      "Ep:112, loss:0.00001, loss_test:0.03123, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.265, tt:4097.929\n",
      "Ep:113, loss:0.00001, loss_test:0.02930, lr:8.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.271, tt:4134.850\n",
      "Ep:114, loss:0.00001, loss_test:0.02983, lr:8.60e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.278, tt:4171.987\n",
      "Ep:115, loss:0.00001, loss_test:0.02990, lr:8.51e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.290, tt:4209.670\n",
      "Ep:116, loss:0.00001, loss_test:0.03172, lr:8.43e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.299, tt:4246.993\n",
      "Ep:117, loss:0.00001, loss_test:0.03029, lr:8.35e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.314, tt:4285.069\n",
      "Ep:118, loss:0.00001, loss_test:0.02862, lr:8.26e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.313, tt:4321.204\n",
      "Ep:119, loss:0.00001, loss_test:0.02898, lr:8.18e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.274, tt:4352.825\n",
      "Ep:120, loss:0.00001, loss_test:0.03138, lr:8.10e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.211, tt:4381.546\n",
      "Ep:121, loss:0.00001, loss_test:0.02944, lr:8.02e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.173, tt:4413.049\n",
      "Ep:122, loss:0.00001, loss_test:0.03037, lr:7.94e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.137, tt:4444.814\n",
      "Ep:123, loss:0.00001, loss_test:0.03007, lr:7.86e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.111, tt:4477.742\n",
      "Ep:124, loss:0.00001, loss_test:0.02864, lr:7.78e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.128, tt:4515.951\n",
      "Ep:125, loss:0.00001, loss_test:0.03112, lr:7.70e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.139, tt:4553.464\n",
      "Ep:126, loss:0.00001, loss_test:0.02920, lr:7.62e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.156, tt:4591.812\n",
      "Ep:127, loss:0.00001, loss_test:0.03056, lr:7.55e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.164, tt:4628.948\n",
      "Ep:128, loss:0.00001, loss_test:0.02878, lr:7.47e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.168, tt:4665.673\n",
      "Ep:129, loss:0.00001, loss_test:0.02983, lr:7.40e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.196, tt:4705.496\n",
      "Ep:130, loss:0.00001, loss_test:0.02889, lr:7.32e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.192, tt:4741.126\n",
      "Ep:131, loss:0.00000, loss_test:0.02991, lr:7.25e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.197, tt:4777.998\n",
      "Ep:132, loss:0.00000, loss_test:0.02833, lr:7.18e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.201, tt:4814.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.02943, lr:7.11e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.195, tt:4850.157\n",
      "Ep:134, loss:0.00000, loss_test:0.02950, lr:7.03e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.189, tt:4885.529\n",
      "Ep:135, loss:0.00000, loss_test:0.02926, lr:6.96e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.174, tt:4919.684\n",
      "Ep:136, loss:0.00000, loss_test:0.02913, lr:6.89e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.155, tt:4953.267\n",
      "Ep:137, loss:0.00000, loss_test:0.02954, lr:6.83e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.143, tt:4987.693\n",
      "Ep:138, loss:0.00000, loss_test:0.02870, lr:6.76e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.126, tt:5021.561\n",
      "Ep:139, loss:0.00000, loss_test:0.02950, lr:6.69e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.127, tt:5057.789\n",
      "Ep:140, loss:0.00000, loss_test:0.02984, lr:6.62e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.124, tt:5093.549\n",
      "Ep:141, loss:0.00000, loss_test:0.02807, lr:6.56e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.130, tt:5130.486\n",
      "Ep:142, loss:0.00000, loss_test:0.03065, lr:6.49e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.133, tt:5167.010\n",
      "Ep:143, loss:0.00000, loss_test:0.02798, lr:6.43e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.131, tt:5202.908\n",
      "Ep:144, loss:0.00000, loss_test:0.03153, lr:6.36e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.124, tt:5238.034\n",
      "Ep:145, loss:0.00000, loss_test:0.02923, lr:6.30e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.120, tt:5273.553\n",
      "Ep:146, loss:0.00000, loss_test:0.03004, lr:6.24e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.113, tt:5308.550\n",
      "Ep:147, loss:0.00000, loss_test:0.02820, lr:6.17e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.114, tt:5344.908\n",
      "Ep:148, loss:0.00000, loss_test:0.03068, lr:6.11e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.106, tt:5379.755\n",
      "Ep:149, loss:0.00000, loss_test:0.02885, lr:6.05e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.096, tt:5414.351\n",
      "Ep:150, loss:0.00000, loss_test:0.03023, lr:5.99e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.094, tt:5450.135\n",
      "Ep:151, loss:0.00000, loss_test:0.02803, lr:5.93e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.080, tt:5484.089\n",
      "Ep:152, loss:0.00000, loss_test:0.03097, lr:5.87e-03, fs:0.95652 (r=1.000,p=0.917),  time:36.082, tt:5520.608\n",
      "Ep:153, loss:0.00000, loss_test:0.02981, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.084, tt:5556.979\n",
      "Ep:154, loss:0.00000, loss_test:0.02990, lr:5.75e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.081, tt:5592.549\n",
      "Ep:155, loss:0.00000, loss_test:0.02845, lr:5.70e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.095, tt:5630.823\n",
      "Ep:156, loss:0.00000, loss_test:0.02939, lr:5.64e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.105, tt:5668.490\n",
      "Ep:157, loss:0.00000, loss_test:0.02907, lr:5.58e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.113, tt:5705.886\n",
      "Ep:158, loss:0.00000, loss_test:0.03024, lr:5.53e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.132, tt:5745.026\n",
      "Ep:159, loss:0.00000, loss_test:0.02903, lr:5.47e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.139, tt:5782.285\n",
      "Ep:160, loss:0.00000, loss_test:0.02884, lr:5.42e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.152, tt:5820.483\n",
      "Ep:161, loss:0.00000, loss_test:0.03010, lr:5.36e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.169, tt:5859.310\n",
      "Ep:162, loss:0.00000, loss_test:0.02989, lr:5.31e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.187, tt:5898.502\n",
      "Ep:163, loss:0.00000, loss_test:0.02940, lr:5.26e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.187, tt:5934.746\n",
      "Ep:164, loss:0.00000, loss_test:0.02818, lr:5.20e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.185, tt:5970.570\n",
      "Ep:165, loss:0.00000, loss_test:0.03084, lr:5.15e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.174, tt:6004.880\n",
      "Ep:166, loss:0.00000, loss_test:0.02857, lr:5.10e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.170, tt:6040.372\n",
      "Ep:167, loss:0.00000, loss_test:0.03042, lr:5.05e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.156, tt:6074.220\n",
      "Ep:168, loss:0.00000, loss_test:0.02831, lr:5.00e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.148, tt:6109.009\n",
      "Ep:169, loss:0.00000, loss_test:0.02949, lr:4.95e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.135, tt:6143.026\n",
      "Ep:170, loss:0.00000, loss_test:0.02883, lr:4.90e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.130, tt:6178.247\n",
      "Ep:171, loss:0.00000, loss_test:0.02891, lr:4.85e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.124, tt:6213.398\n",
      "Ep:172, loss:0.00000, loss_test:0.02958, lr:4.80e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.109, tt:6246.784\n",
      "Ep:173, loss:0.00000, loss_test:0.02934, lr:4.75e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.103, tt:6281.915\n",
      "Ep:174, loss:0.00000, loss_test:0.02891, lr:4.71e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.102, tt:6317.895\n",
      "Ep:175, loss:0.00000, loss_test:0.02882, lr:4.66e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.094, tt:6352.587\n",
      "Ep:176, loss:0.00000, loss_test:0.02894, lr:4.61e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.087, tt:6387.447\n",
      "Ep:177, loss:0.00000, loss_test:0.02889, lr:4.57e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.080, tt:6422.175\n",
      "Ep:178, loss:0.00000, loss_test:0.02928, lr:4.52e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.083, tt:6458.908\n",
      "Ep:179, loss:0.00000, loss_test:0.02860, lr:4.48e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.088, tt:6495.924\n",
      "Ep:180, loss:0.00000, loss_test:0.02940, lr:4.43e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.086, tt:6531.624\n",
      "Ep:181, loss:0.00000, loss_test:0.02854, lr:4.39e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.086, tt:6567.691\n",
      "Ep:182, loss:0.00000, loss_test:0.02920, lr:4.34e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.079, tt:6602.388\n",
      "Ep:183, loss:0.00000, loss_test:0.02865, lr:4.30e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.079, tt:6638.626\n",
      "Ep:184, loss:0.00000, loss_test:0.02953, lr:4.26e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.081, tt:6674.919\n",
      "Ep:185, loss:0.00000, loss_test:0.02901, lr:4.21e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.083, tt:6711.496\n",
      "Ep:186, loss:0.00000, loss_test:0.02904, lr:4.17e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.089, tt:6748.649\n",
      "Ep:187, loss:0.00000, loss_test:0.02952, lr:4.13e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.096, tt:6785.989\n",
      "Ep:188, loss:0.00000, loss_test:0.02840, lr:4.09e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.100, tt:6822.932\n",
      "Ep:189, loss:0.00000, loss_test:0.02957, lr:4.05e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.097, tt:6858.419\n",
      "Ep:190, loss:0.00000, loss_test:0.02857, lr:4.01e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.106, tt:6896.217\n",
      "Ep:191, loss:0.00000, loss_test:0.02911, lr:3.97e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.111, tt:6933.355\n",
      "Ep:192, loss:0.00000, loss_test:0.02969, lr:3.93e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.113, tt:6969.879\n",
      "Ep:193, loss:0.00000, loss_test:0.02834, lr:3.89e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.118, tt:7006.976\n",
      "Ep:194, loss:0.00000, loss_test:0.02916, lr:3.85e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.127, tt:7044.668\n",
      "Ep:195, loss:0.00000, loss_test:0.02953, lr:3.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.130, tt:7081.509\n",
      "Ep:196, loss:0.00000, loss_test:0.02936, lr:3.77e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.127, tt:7117.099\n",
      "Ep:197, loss:0.00000, loss_test:0.02926, lr:3.73e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.138, tt:7155.299\n",
      "Ep:198, loss:0.00000, loss_test:0.02852, lr:3.70e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.147, tt:7193.217\n",
      "Ep:199, loss:0.00000, loss_test:0.02930, lr:3.66e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.148, tt:7229.594\n",
      "Ep:200, loss:0.00000, loss_test:0.02916, lr:3.62e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.162, tt:7268.595\n",
      "Ep:201, loss:0.00000, loss_test:0.02894, lr:3.59e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.161, tt:7304.531\n",
      "Ep:202, loss:0.00000, loss_test:0.02871, lr:3.55e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.165, tt:7341.474\n",
      "Ep:203, loss:0.00000, loss_test:0.02904, lr:3.52e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.161, tt:7376.869\n",
      "Ep:204, loss:0.00000, loss_test:0.02917, lr:3.48e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.168, tt:7414.504\n",
      "Ep:205, loss:0.00000, loss_test:0.02877, lr:3.45e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.163, tt:7449.489\n",
      "Ep:206, loss:0.00000, loss_test:0.02936, lr:3.41e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.161, tt:7485.375\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02727, lr:6.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:33.132, tt:33.132\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02333, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:33.565, tt:67.129\n",
      "Ep:2, loss:0.00005, loss_test:0.02405, lr:6.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:33.512, tt:100.537\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02348, lr:6.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:33.273, tt:133.091\n",
      "Ep:4, loss:0.00005, loss_test:0.02448, lr:6.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:33.352, tt:166.759\n",
      "Ep:5, loss:0.00005, loss_test:0.02442, lr:6.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:33.731, tt:202.386\n",
      "Ep:6, loss:0.00005, loss_test:0.02369, lr:6.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:33.765, tt:236.353\n",
      "Ep:7, loss:0.00005, loss_test:0.02281, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:33.875, tt:270.997\n",
      "Ep:8, loss:0.00005, loss_test:0.02205, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:33.945, tt:305.504\n",
      "Ep:9, loss:0.00004, loss_test:0.02116, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:33.956, tt:339.564\n",
      "Ep:10, loss:0.00004, loss_test:0.02037, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:34.032, tt:374.356\n",
      "Ep:11, loss:0.00004, loss_test:0.01971, lr:6.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:33.942, tt:407.306\n",
      "Ep:12, loss:0.00004, loss_test:0.01878, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:33.964, tt:441.526\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01803, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:33.987, tt:475.811\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01767, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:33.878, tt:508.177\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01744, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:33.924, tt:542.791\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01716, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:33.943, tt:577.025\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01676, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:33.937, tt:610.859\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01640, lr:6.00e-02, fs:0.74104 (r=0.939,p=0.612),  time:34.018, tt:646.336\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01597, lr:6.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:34.000, tt:680.006\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:33.889, tt:711.663\n",
      "Ep:21, loss:0.00003, loss_test:0.01525, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:33.899, tt:745.770\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:33.937, tt:780.555\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01453, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:33.878, tt:813.071\n",
      "Ep:24, loss:0.00003, loss_test:0.01421, lr:6.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:33.870, tt:846.758\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01412, lr:6.00e-02, fs:0.77419 (r=0.970,p=0.644),  time:33.876, tt:880.782\n",
      "Ep:26, loss:0.00003, loss_test:0.01369, lr:6.00e-02, fs:0.78226 (r=0.980,p=0.651),  time:33.843, tt:913.772\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01335, lr:6.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:33.920, tt:949.754\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01326, lr:6.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:33.891, tt:982.826\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01304, lr:6.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:33.996, tt:1019.890\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01268, lr:6.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:33.975, tt:1053.237\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01255, lr:6.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:33.969, tt:1087.013\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:33.954, tt:1120.489\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01210, lr:6.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:33.913, tt:1153.051\n",
      "Ep:34, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:33.902, tt:1186.579\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01145, lr:6.00e-02, fs:0.82700 (r=0.990,p=0.710),  time:33.902, tt:1220.471\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01143, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:33.881, tt:1253.605\n",
      "Ep:37, loss:0.00002, loss_test:0.01136, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:33.906, tt:1288.424\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01109, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:33.913, tt:1322.595\n",
      "Ep:39, loss:0.00002, loss_test:0.01090, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:33.946, tt:1357.843\n",
      "Ep:40, loss:0.00002, loss_test:0.01079, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:33.991, tt:1393.611\n",
      "Ep:41, loss:0.00002, loss_test:0.01051, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:34.008, tt:1428.327\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01060, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.012, tt:1462.528\n",
      "Ep:43, loss:0.00002, loss_test:0.01028, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:34.020, tt:1496.884\n",
      "Ep:44, loss:0.00002, loss_test:0.01057, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:34.066, tt:1532.953\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.00982, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:34.111, tt:1569.100\n",
      "Ep:46, loss:0.00002, loss_test:0.00991, lr:6.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.155, tt:1605.274\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.00960, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:34.193, tt:1641.271\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.00994, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:34.230, tt:1677.269\n",
      "Ep:49, loss:0.00001, loss_test:0.01028, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:34.290, tt:1714.495\n",
      "Ep:50, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:34.330, tt:1750.817\n",
      "Ep:51, loss:0.00002, loss_test:0.00877, lr:6.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.374, tt:1787.453\n",
      "Ep:52, loss:0.00001, loss_test:0.01094, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:34.378, tt:1822.020\n",
      "Ep:53, loss:0.00001, loss_test:0.01047, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:34.404, tt:1857.793\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:34.393, tt:1891.595\n",
      "Ep:55, loss:0.00002, loss_test:0.01062, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:34.409, tt:1926.928\n",
      "Ep:56, loss:0.00002, loss_test:0.01103, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:34.376, tt:1959.413\n",
      "Ep:57, loss:0.00001, loss_test:0.00918, lr:6.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:34.383, tt:1994.196\n",
      "Ep:58, loss:0.00001, loss_test:0.00905, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:34.383, tt:2028.607\n",
      "Ep:59, loss:0.00001, loss_test:0.00847, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:34.379, tt:2062.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.00851, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:34.354, tt:2095.564\n",
      "Ep:61, loss:0.00001, loss_test:0.00878, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:34.340, tt:2129.097\n",
      "Ep:62, loss:0.00001, loss_test:0.00793, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:34.323, tt:2162.363\n",
      "Ep:63, loss:0.00001, loss_test:0.00856, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:34.319, tt:2196.390\n",
      "Ep:64, loss:0.00001, loss_test:0.00767, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:34.321, tt:2230.882\n",
      "Ep:65, loss:0.00001, loss_test:0.00820, lr:5.94e-02, fs:0.86512 (r=0.939,p=0.802),  time:34.281, tt:2262.574\n",
      "Ep:66, loss:0.00001, loss_test:0.00764, lr:5.88e-02, fs:0.88479 (r=0.970,p=0.814),  time:34.263, tt:2295.651\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.00829, lr:5.88e-02, fs:0.86111 (r=0.939,p=0.795),  time:34.247, tt:2328.823\n",
      "Ep:68, loss:0.00001, loss_test:0.00748, lr:5.88e-02, fs:0.90566 (r=0.970,p=0.850),  time:34.222, tt:2361.343\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.00784, lr:5.88e-02, fs:0.88679 (r=0.949,p=0.832),  time:34.204, tt:2394.303\n",
      "Ep:70, loss:0.00001, loss_test:0.00714, lr:5.88e-02, fs:0.89623 (r=0.960,p=0.841),  time:34.192, tt:2427.656\n",
      "Ep:71, loss:0.00001, loss_test:0.00761, lr:5.88e-02, fs:0.89423 (r=0.939,p=0.853),  time:34.170, tt:2460.226\n",
      "Ep:72, loss:0.00001, loss_test:0.00710, lr:5.88e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.167, tt:2494.205\n",
      "Ep:73, loss:0.00001, loss_test:0.00748, lr:5.88e-02, fs:0.88679 (r=0.949,p=0.832),  time:34.169, tt:2528.475\n",
      "Ep:74, loss:0.00001, loss_test:0.00753, lr:5.88e-02, fs:0.89100 (r=0.949,p=0.839),  time:34.186, tt:2563.920\n",
      "Ep:75, loss:0.00001, loss_test:0.00721, lr:5.88e-02, fs:0.89100 (r=0.949,p=0.839),  time:34.187, tt:2598.236\n",
      "Ep:76, loss:0.00001, loss_test:0.00698, lr:5.88e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.168, tt:2630.965\n",
      "Ep:77, loss:0.00001, loss_test:0.00644, lr:5.88e-02, fs:0.91866 (r=0.970,p=0.873),  time:34.167, tt:2665.046\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.00723, lr:5.88e-02, fs:0.89952 (r=0.949,p=0.855),  time:34.179, tt:2700.160\n",
      "Ep:79, loss:0.00001, loss_test:0.00782, lr:5.88e-02, fs:0.89423 (r=0.939,p=0.853),  time:34.192, tt:2735.360\n",
      "Ep:80, loss:0.00001, loss_test:0.00962, lr:5.88e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.202, tt:2770.376\n",
      "Ep:81, loss:0.00001, loss_test:0.00775, lr:5.88e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.232, tt:2806.998\n",
      "Ep:82, loss:0.00001, loss_test:0.00856, lr:5.88e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.249, tt:2842.626\n",
      "Ep:83, loss:0.00001, loss_test:0.00704, lr:5.88e-02, fs:0.87850 (r=0.949,p=0.817),  time:34.253, tt:2877.223\n",
      "Ep:84, loss:0.00001, loss_test:0.00807, lr:5.88e-02, fs:0.88462 (r=0.929,p=0.844),  time:34.262, tt:2912.235\n",
      "Ep:85, loss:0.00001, loss_test:0.00689, lr:5.88e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.269, tt:2947.157\n",
      "Ep:86, loss:0.00001, loss_test:0.00789, lr:5.88e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.279, tt:2982.265\n",
      "Ep:87, loss:0.00001, loss_test:0.00667, lr:5.88e-02, fs:0.92157 (r=0.949,p=0.895),  time:34.304, tt:3018.761\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.00727, lr:5.88e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.317, tt:3054.180\n",
      "Ep:89, loss:0.00001, loss_test:0.00687, lr:5.88e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.322, tt:3088.949\n",
      "Ep:90, loss:0.00001, loss_test:0.00706, lr:5.88e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.330, tt:3124.008\n",
      "Ep:91, loss:0.00001, loss_test:0.00703, lr:5.88e-02, fs:0.89655 (r=0.919,p=0.875),  time:34.343, tt:3159.573\n",
      "Ep:92, loss:0.00000, loss_test:0.00662, lr:5.88e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.352, tt:3194.780\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00000, loss_test:0.00765, lr:5.88e-02, fs:0.89756 (r=0.929,p=0.868),  time:34.364, tt:3230.259\n",
      "Ep:94, loss:0.00000, loss_test:0.00669, lr:5.88e-02, fs:0.93000 (r=0.939,p=0.921),  time:34.367, tt:3264.862\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00000, loss_test:0.00696, lr:5.88e-02, fs:0.90732 (r=0.939,p=0.877),  time:34.368, tt:3299.364\n",
      "Ep:96, loss:0.00000, loss_test:0.00799, lr:5.88e-02, fs:0.91000 (r=0.919,p=0.901),  time:34.376, tt:3334.484\n",
      "Ep:97, loss:0.00000, loss_test:0.00659, lr:5.88e-02, fs:0.93467 (r=0.939,p=0.930),  time:34.370, tt:3368.265\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00000, loss_test:0.00704, lr:5.88e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.366, tt:3402.258\n",
      "Ep:99, loss:0.00000, loss_test:0.00746, lr:5.88e-02, fs:0.92000 (r=0.929,p=0.911),  time:34.361, tt:3436.072\n",
      "Ep:100, loss:0.00000, loss_test:0.00656, lr:5.88e-02, fs:0.94527 (r=0.960,p=0.931),  time:34.359, tt:3470.302\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00000, loss_test:0.00724, lr:5.88e-02, fs:0.92929 (r=0.929,p=0.929),  time:34.357, tt:3504.424\n",
      "Ep:102, loss:0.00000, loss_test:0.00701, lr:5.88e-02, fs:0.93532 (r=0.949,p=0.922),  time:34.354, tt:3538.478\n",
      "Ep:103, loss:0.00000, loss_test:0.00658, lr:5.88e-02, fs:0.94000 (r=0.949,p=0.931),  time:34.341, tt:3571.426\n",
      "Ep:104, loss:0.00000, loss_test:0.00775, lr:5.88e-02, fs:0.91089 (r=0.929,p=0.893),  time:34.322, tt:3603.814\n",
      "Ep:105, loss:0.00000, loss_test:0.00833, lr:5.88e-02, fs:0.90722 (r=0.889,p=0.926),  time:34.311, tt:3636.925\n",
      "Ep:106, loss:0.00000, loss_test:0.00672, lr:5.88e-02, fs:0.93069 (r=0.949,p=0.913),  time:34.296, tt:3669.686\n",
      "Ep:107, loss:0.00000, loss_test:0.00660, lr:5.88e-02, fs:0.94949 (r=0.949,p=0.949),  time:34.292, tt:3703.559\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.00769, lr:5.88e-02, fs:0.93401 (r=0.929,p=0.939),  time:34.291, tt:3737.692\n",
      "Ep:109, loss:0.00000, loss_test:0.00792, lr:5.88e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.279, tt:3770.663\n",
      "Ep:110, loss:0.00000, loss_test:0.00877, lr:5.88e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.261, tt:3802.921\n",
      "Ep:111, loss:0.00000, loss_test:0.00707, lr:5.88e-02, fs:0.94000 (r=0.949,p=0.931),  time:34.250, tt:3835.990\n",
      "Ep:112, loss:0.00000, loss_test:0.00698, lr:5.88e-02, fs:0.93467 (r=0.939,p=0.930),  time:34.253, tt:3870.597\n",
      "Ep:113, loss:0.00000, loss_test:0.00870, lr:5.88e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.251, tt:3904.576\n",
      "Ep:114, loss:0.00000, loss_test:0.00718, lr:5.88e-02, fs:0.94472 (r=0.949,p=0.940),  time:34.268, tt:3940.863\n",
      "Ep:115, loss:0.00000, loss_test:0.00720, lr:5.88e-02, fs:0.92857 (r=0.919,p=0.938),  time:34.273, tt:3975.621\n",
      "Ep:116, loss:0.00000, loss_test:0.00881, lr:5.88e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.277, tt:4010.462\n",
      "Ep:117, loss:0.00000, loss_test:0.00891, lr:5.88e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.274, tt:4044.274\n",
      "Ep:118, loss:0.00000, loss_test:0.00809, lr:5.88e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.287, tt:4080.134\n",
      "Ep:119, loss:0.00000, loss_test:0.00905, lr:5.82e-02, fs:0.90155 (r=0.879,p=0.926),  time:34.278, tt:4113.324\n",
      "Ep:120, loss:0.00000, loss_test:0.00782, lr:5.76e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.277, tt:4147.535\n",
      "Ep:121, loss:0.00000, loss_test:0.00771, lr:5.71e-02, fs:0.92857 (r=0.919,p=0.938),  time:34.265, tt:4180.324\n",
      "Ep:122, loss:0.00000, loss_test:0.00797, lr:5.65e-02, fs:0.92228 (r=0.899,p=0.947),  time:34.222, tt:4209.265\n",
      "Ep:123, loss:0.00000, loss_test:0.00778, lr:5.59e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.129, tt:4232.047\n",
      "Ep:124, loss:0.00000, loss_test:0.00887, lr:5.54e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.056, tt:4257.055\n",
      "Ep:125, loss:0.00000, loss_test:0.00756, lr:5.48e-02, fs:0.87831 (r=0.838,p=0.922),  time:34.007, tt:4284.932\n",
      "Ep:126, loss:0.00000, loss_test:0.00799, lr:5.43e-02, fs:0.91192 (r=0.889,p=0.936),  time:33.968, tt:4313.890\n",
      "Ep:127, loss:0.00000, loss_test:0.00776, lr:5.37e-02, fs:0.90625 (r=0.879,p=0.935),  time:33.934, tt:4343.519\n",
      "Ep:128, loss:0.00000, loss_test:0.00749, lr:5.32e-02, fs:0.91192 (r=0.889,p=0.936),  time:33.934, tt:4377.520\n",
      "Ep:129, loss:0.00000, loss_test:0.00785, lr:5.27e-02, fs:0.91667 (r=0.889,p=0.946),  time:33.933, tt:4411.334\n",
      "Ep:130, loss:0.00000, loss_test:0.00797, lr:5.21e-02, fs:0.87097 (r=0.818,p=0.931),  time:33.939, tt:4445.993\n",
      "Ep:131, loss:0.00000, loss_test:0.00890, lr:5.16e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.953, tt:4481.861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.00836, lr:5.11e-02, fs:0.85870 (r=0.798,p=0.929),  time:33.967, tt:4517.645\n",
      "Ep:133, loss:0.00000, loss_test:0.00771, lr:5.06e-02, fs:0.88889 (r=0.848,p=0.933),  time:33.981, tt:4553.389\n",
      "Ep:134, loss:0.00000, loss_test:0.00854, lr:5.01e-02, fs:0.86813 (r=0.798,p=0.952),  time:33.990, tt:4588.688\n",
      "Ep:135, loss:0.00000, loss_test:0.00889, lr:4.96e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.009, tt:4625.247\n",
      "Ep:136, loss:0.00000, loss_test:0.00891, lr:4.91e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.022, tt:4660.984\n",
      "Ep:137, loss:0.00000, loss_test:0.00812, lr:4.86e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.032, tt:4696.362\n",
      "Ep:138, loss:0.00000, loss_test:0.00840, lr:4.81e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.051, tt:4733.048\n",
      "Ep:139, loss:0.00000, loss_test:0.00887, lr:4.76e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.062, tt:4768.700\n",
      "Ep:140, loss:0.00000, loss_test:0.00899, lr:4.71e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.074, tt:4804.441\n",
      "Ep:141, loss:0.00000, loss_test:0.00853, lr:4.67e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.088, tt:4840.507\n",
      "Ep:142, loss:0.00000, loss_test:0.00783, lr:4.62e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.094, tt:4875.431\n",
      "Ep:143, loss:0.00000, loss_test:0.00880, lr:4.57e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.101, tt:4910.593\n",
      "Ep:144, loss:0.00000, loss_test:0.00920, lr:4.53e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.108, tt:4945.633\n",
      "Ep:145, loss:0.00000, loss_test:0.00808, lr:4.48e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.115, tt:4980.761\n",
      "Ep:146, loss:0.00000, loss_test:0.00863, lr:4.44e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.130, tt:5017.101\n",
      "Ep:147, loss:0.00000, loss_test:0.00907, lr:4.39e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.130, tt:5051.284\n",
      "Ep:148, loss:0.00000, loss_test:0.00929, lr:4.35e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.137, tt:5086.376\n",
      "Ep:149, loss:0.00000, loss_test:0.00865, lr:4.31e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.166, tt:5124.912\n",
      "Ep:150, loss:0.00000, loss_test:0.00880, lr:4.26e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.165, tt:5158.873\n",
      "Ep:151, loss:0.00000, loss_test:0.00984, lr:4.22e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.169, tt:5193.673\n",
      "Ep:152, loss:0.00000, loss_test:0.00843, lr:4.18e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.183, tt:5230.028\n",
      "Ep:153, loss:0.00000, loss_test:0.00891, lr:4.14e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.192, tt:5265.541\n",
      "Ep:154, loss:0.00000, loss_test:0.00926, lr:4.10e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.187, tt:5298.952\n",
      "Ep:155, loss:0.00000, loss_test:0.00897, lr:4.05e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.184, tt:5332.652\n",
      "Ep:156, loss:0.00000, loss_test:0.00905, lr:4.01e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.189, tt:5367.733\n",
      "Ep:157, loss:0.00000, loss_test:0.00894, lr:3.97e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.186, tt:5401.444\n",
      "Ep:158, loss:0.00000, loss_test:0.00932, lr:3.93e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.179, tt:5434.467\n",
      "Ep:159, loss:0.00000, loss_test:0.00914, lr:3.89e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.187, tt:5469.987\n",
      "Ep:160, loss:0.00000, loss_test:0.00924, lr:3.86e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.196, tt:5505.595\n",
      "Ep:161, loss:0.00000, loss_test:0.00892, lr:3.82e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.194, tt:5539.390\n",
      "Ep:162, loss:0.00000, loss_test:0.00940, lr:3.78e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.191, tt:5573.082\n",
      "Ep:163, loss:0.00000, loss_test:0.00928, lr:3.74e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.193, tt:5607.618\n",
      "Ep:164, loss:0.00000, loss_test:0.00900, lr:3.70e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.190, tt:5641.276\n",
      "Ep:165, loss:0.00000, loss_test:0.00942, lr:3.67e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.191, tt:5675.656\n",
      "Ep:166, loss:0.00000, loss_test:0.00910, lr:3.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.185, tt:5708.853\n",
      "Ep:167, loss:0.00000, loss_test:0.00942, lr:3.59e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.178, tt:5741.910\n",
      "Ep:168, loss:0.00000, loss_test:0.00928, lr:3.56e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.178, tt:5776.138\n",
      "Ep:169, loss:0.00000, loss_test:0.00966, lr:3.52e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.182, tt:5810.955\n",
      "Ep:170, loss:0.00000, loss_test:0.00911, lr:3.49e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.185, tt:5845.660\n",
      "Ep:171, loss:0.00000, loss_test:0.01012, lr:3.45e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.181, tt:5879.140\n",
      "Ep:172, loss:0.00000, loss_test:0.00906, lr:3.42e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.181, tt:5913.354\n",
      "Ep:173, loss:0.00000, loss_test:0.00978, lr:3.38e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.176, tt:5946.666\n",
      "Ep:174, loss:0.00000, loss_test:0.00971, lr:3.35e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.174, tt:5980.502\n",
      "Ep:175, loss:0.00000, loss_test:0.00939, lr:3.32e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.173, tt:6014.430\n",
      "Ep:176, loss:0.00000, loss_test:0.00924, lr:3.28e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.170, tt:6048.036\n",
      "Ep:177, loss:0.00000, loss_test:0.01003, lr:3.25e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.171, tt:6082.464\n",
      "Ep:178, loss:0.00000, loss_test:0.00898, lr:3.22e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.173, tt:6116.956\n",
      "Ep:179, loss:0.00000, loss_test:0.00986, lr:3.19e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.169, tt:6150.467\n",
      "Ep:180, loss:0.00000, loss_test:0.00982, lr:3.15e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.170, tt:6184.855\n",
      "Ep:181, loss:0.00000, loss_test:0.00937, lr:3.12e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.177, tt:6220.254\n",
      "Ep:182, loss:0.00000, loss_test:0.01001, lr:3.09e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.174, tt:6253.795\n",
      "Ep:183, loss:0.00000, loss_test:0.00957, lr:3.06e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.173, tt:6287.908\n",
      "Ep:184, loss:0.00000, loss_test:0.00964, lr:3.03e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.174, tt:6322.217\n",
      "Ep:185, loss:0.00000, loss_test:0.00988, lr:3.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.172, tt:6355.965\n",
      "Ep:186, loss:0.00000, loss_test:0.00950, lr:2.97e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.175, tt:6390.789\n",
      "Ep:187, loss:0.00000, loss_test:0.00993, lr:2.94e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.184, tt:6426.533\n",
      "Ep:188, loss:0.00000, loss_test:0.00957, lr:2.91e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.185, tt:6461.049\n",
      "Ep:189, loss:0.00000, loss_test:0.01009, lr:2.88e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.192, tt:6496.453\n",
      "Ep:190, loss:0.00000, loss_test:0.00972, lr:2.85e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.198, tt:6531.877\n",
      "Ep:191, loss:0.00000, loss_test:0.00991, lr:2.82e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.201, tt:6566.524\n",
      "Ep:192, loss:0.00000, loss_test:0.00977, lr:2.80e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.204, tt:6601.408\n",
      "Ep:193, loss:0.00000, loss_test:0.00985, lr:2.77e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.210, tt:6636.688\n",
      "Ep:194, loss:0.00000, loss_test:0.01004, lr:2.74e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.216, tt:6672.056\n",
      "Ep:195, loss:0.00000, loss_test:0.00944, lr:2.71e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.227, tt:6708.542\n",
      "Ep:196, loss:0.00000, loss_test:0.01047, lr:2.69e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.233, tt:6743.955\n",
      "Ep:197, loss:0.00000, loss_test:0.00942, lr:2.66e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.234, tt:6778.369\n",
      "Ep:198, loss:0.00000, loss_test:0.01039, lr:2.63e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.230, tt:6811.813\n",
      "Ep:199, loss:0.00000, loss_test:0.00946, lr:2.61e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.226, tt:6845.142\n",
      "Ep:200, loss:0.00000, loss_test:0.01048, lr:2.58e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.228, tt:6879.734\n",
      "Ep:201, loss:0.00000, loss_test:0.00961, lr:2.55e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.221, tt:6912.682\n",
      "Ep:202, loss:0.00000, loss_test:0.01019, lr:2.53e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.219, tt:6946.485\n",
      "Ep:203, loss:0.00000, loss_test:0.00991, lr:2.50e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.212, tt:6979.164\n",
      "Ep:204, loss:0.00000, loss_test:0.00994, lr:2.48e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.208, tt:7012.594\n",
      "Ep:205, loss:0.00000, loss_test:0.01020, lr:2.45e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.215, tt:7048.350\n",
      "Ep:206, loss:0.00000, loss_test:0.00987, lr:2.43e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.212, tt:7081.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.01025, lr:2.40e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.212, tt:7116.044\n",
      "Ep:208, loss:0.00000, loss_test:0.00988, lr:2.38e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.219, tt:7151.701\n",
      "Ep:209, loss:0.00000, loss_test:0.01027, lr:2.36e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.219, tt:7186.018\n",
      "Ep:210, loss:0.00000, loss_test:0.01000, lr:2.33e-02, fs:0.87151 (r=0.788,p=0.975),  time:34.217, tt:7219.876\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.12431, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:34.703, tt:34.703\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12355, lr:1.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:35.010, tt:70.021\n",
      "Ep:2, loss:0.00025, loss_test:0.12280, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:35.530, tt:106.589\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12206, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:35.382, tt:141.526\n",
      "Ep:4, loss:0.00025, loss_test:0.12124, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:35.060, tt:175.301\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12009, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:35.036, tt:210.218\n",
      "Ep:6, loss:0.00025, loss_test:0.11918, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:34.800, tt:243.597\n",
      "Ep:7, loss:0.00025, loss_test:0.11857, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:34.744, tt:277.953\n",
      "Ep:8, loss:0.00024, loss_test:0.11794, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:34.706, tt:312.357\n",
      "Ep:9, loss:0.00024, loss_test:0.11727, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:34.757, tt:347.571\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.11627, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:34.903, tt:383.931\n",
      "Ep:11, loss:0.00024, loss_test:0.11494, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:34.922, tt:419.061\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.11329, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:34.892, tt:453.602\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.11170, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:34.809, tt:487.323\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11012, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:34.759, tt:521.386\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.10788, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:34.765, tt:556.235\n",
      "Ep:16, loss:0.00022, loss_test:0.10600, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:34.809, tt:591.747\n",
      "Ep:17, loss:0.00022, loss_test:0.10376, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:34.746, tt:625.429\n",
      "Ep:18, loss:0.00021, loss_test:0.10142, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:34.755, tt:660.350\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.09842, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:34.837, tt:696.730\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09574, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:34.859, tt:732.050\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.09434, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.909, tt:768.004\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.09219, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.984, tt:804.629\n",
      "Ep:23, loss:0.00019, loss_test:0.08930, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:35.045, tt:841.091\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.08689, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:35.155, tt:878.863\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.08390, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:35.234, tt:916.083\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.08068, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:35.312, tt:953.425\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.07935, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:35.336, tt:989.402\n",
      "Ep:28, loss:0.00016, loss_test:0.07669, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:35.419, tt:1027.160\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.07573, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.480, tt:1064.411\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.07279, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:35.488, tt:1100.128\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.06961, lr:1.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:35.542, tt:1137.353\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.06747, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.571, tt:1173.851\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.06616, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:35.608, tt:1210.689\n",
      "Ep:34, loss:0.00013, loss_test:0.06716, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.687, tt:1249.049\n",
      "Ep:35, loss:0.00013, loss_test:0.06376, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:35.666, tt:1283.974\n",
      "Ep:36, loss:0.00012, loss_test:0.07402, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:35.659, tt:1319.365\n",
      "Ep:37, loss:0.00012, loss_test:0.07238, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:35.641, tt:1354.367\n",
      "Ep:38, loss:0.00014, loss_test:0.06255, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:35.638, tt:1389.862\n",
      "Ep:39, loss:0.00012, loss_test:0.06235, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:35.655, tt:1426.181\n",
      "Ep:40, loss:0.00012, loss_test:0.06240, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:35.672, tt:1462.532\n",
      "Ep:41, loss:0.00011, loss_test:0.06484, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:35.660, tt:1497.724\n",
      "Ep:42, loss:0.00010, loss_test:0.06108, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:35.658, tt:1533.312\n",
      "Ep:43, loss:0.00009, loss_test:0.05924, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:35.633, tt:1567.850\n",
      "Ep:44, loss:0.00009, loss_test:0.05775, lr:9.90e-03, fs:0.84545 (r=0.939,p=0.769),  time:35.598, tt:1601.930\n",
      "Ep:45, loss:0.00009, loss_test:0.05847, lr:9.80e-03, fs:0.86408 (r=0.899,p=0.832),  time:35.582, tt:1636.759\n",
      "Ep:46, loss:0.00008, loss_test:0.05665, lr:9.70e-03, fs:0.85586 (r=0.960,p=0.772),  time:35.556, tt:1671.137\n",
      "Ep:47, loss:0.00008, loss_test:0.05625, lr:9.61e-03, fs:0.87805 (r=0.909,p=0.849),  time:35.532, tt:1705.537\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.05537, lr:9.61e-03, fs:0.84651 (r=0.919,p=0.784),  time:35.528, tt:1740.848\n",
      "Ep:49, loss:0.00008, loss_test:0.05247, lr:9.61e-03, fs:0.87736 (r=0.939,p=0.823),  time:35.560, tt:1777.993\n",
      "Ep:50, loss:0.00007, loss_test:0.05420, lr:9.61e-03, fs:0.88670 (r=0.909,p=0.865),  time:35.627, tt:1816.992\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.04805, lr:9.61e-03, fs:0.88889 (r=0.929,p=0.852),  time:35.664, tt:1854.540\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.05081, lr:9.61e-03, fs:0.85047 (r=0.919,p=0.791),  time:35.706, tt:1892.399\n",
      "Ep:53, loss:0.00006, loss_test:0.04668, lr:9.61e-03, fs:0.90385 (r=0.949,p=0.862),  time:35.798, tt:1933.089\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.04784, lr:9.61e-03, fs:0.89855 (r=0.939,p=0.861),  time:35.845, tt:1971.464\n",
      "Ep:55, loss:0.00006, loss_test:0.05190, lr:9.61e-03, fs:0.85586 (r=0.960,p=0.772),  time:35.888, tt:2009.716\n",
      "Ep:56, loss:0.00006, loss_test:0.05244, lr:9.61e-03, fs:0.87437 (r=0.879,p=0.870),  time:35.911, tt:2046.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00005, loss_test:0.04539, lr:9.61e-03, fs:0.90995 (r=0.970,p=0.857),  time:35.905, tt:2082.497\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.04539, lr:9.61e-03, fs:0.88889 (r=0.929,p=0.852),  time:35.894, tt:2117.739\n",
      "Ep:59, loss:0.00005, loss_test:0.04782, lr:9.61e-03, fs:0.89623 (r=0.960,p=0.841),  time:35.890, tt:2153.403\n",
      "Ep:60, loss:0.00005, loss_test:0.04929, lr:9.61e-03, fs:0.90385 (r=0.949,p=0.862),  time:35.873, tt:2188.232\n",
      "Ep:61, loss:0.00006, loss_test:0.04747, lr:9.61e-03, fs:0.91262 (r=0.949,p=0.879),  time:35.845, tt:2222.384\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00005, loss_test:0.05185, lr:9.61e-03, fs:0.86916 (r=0.939,p=0.809),  time:35.809, tt:2255.988\n",
      "Ep:63, loss:0.00005, loss_test:0.04684, lr:9.61e-03, fs:0.92157 (r=0.949,p=0.895),  time:35.804, tt:2291.432\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.04467, lr:9.61e-03, fs:0.91089 (r=0.929,p=0.893),  time:35.825, tt:2328.611\n",
      "Ep:65, loss:0.00005, loss_test:0.04708, lr:9.61e-03, fs:0.89899 (r=0.899,p=0.899),  time:35.861, tt:2366.851\n",
      "Ep:66, loss:0.00004, loss_test:0.04262, lr:9.61e-03, fs:0.92823 (r=0.980,p=0.882),  time:35.885, tt:2404.312\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.05226, lr:9.61e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.911, tt:2441.915\n",
      "Ep:68, loss:0.00005, loss_test:0.04947, lr:9.61e-03, fs:0.89815 (r=0.980,p=0.829),  time:35.898, tt:2476.944\n",
      "Ep:69, loss:0.00006, loss_test:0.05387, lr:9.61e-03, fs:0.85279 (r=0.848,p=0.857),  time:35.910, tt:2513.704\n",
      "Ep:70, loss:0.00005, loss_test:0.04189, lr:9.61e-03, fs:0.90099 (r=0.919,p=0.883),  time:35.867, tt:2546.553\n",
      "Ep:71, loss:0.00005, loss_test:0.04223, lr:9.61e-03, fs:0.92233 (r=0.960,p=0.888),  time:35.857, tt:2581.729\n",
      "Ep:72, loss:0.00004, loss_test:0.05534, lr:9.61e-03, fs:0.85446 (r=0.919,p=0.798),  time:35.839, tt:2616.227\n",
      "Ep:73, loss:0.00005, loss_test:0.04610, lr:9.61e-03, fs:0.88235 (r=0.909,p=0.857),  time:35.838, tt:2651.993\n",
      "Ep:74, loss:0.00004, loss_test:0.04624, lr:9.61e-03, fs:0.90099 (r=0.919,p=0.883),  time:35.815, tt:2686.115\n",
      "Ep:75, loss:0.00004, loss_test:0.04249, lr:9.61e-03, fs:0.89655 (r=0.919,p=0.875),  time:35.814, tt:2721.856\n",
      "Ep:76, loss:0.00004, loss_test:0.04954, lr:9.61e-03, fs:0.86022 (r=0.808,p=0.920),  time:35.822, tt:2758.308\n",
      "Ep:77, loss:0.00004, loss_test:0.04487, lr:9.61e-03, fs:0.90291 (r=0.939,p=0.869),  time:35.844, tt:2795.837\n",
      "Ep:78, loss:0.00004, loss_test:0.04545, lr:9.51e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.841, tt:2831.451\n",
      "Ep:79, loss:0.00003, loss_test:0.03854, lr:9.41e-03, fs:0.92537 (r=0.939,p=0.912),  time:35.853, tt:2868.206\n",
      "Ep:80, loss:0.00003, loss_test:0.04280, lr:9.32e-03, fs:0.91837 (r=0.909,p=0.928),  time:35.871, tt:2905.540\n",
      "Ep:81, loss:0.00003, loss_test:0.04060, lr:9.23e-03, fs:0.90099 (r=0.919,p=0.883),  time:35.888, tt:2942.845\n",
      "Ep:82, loss:0.00003, loss_test:0.04448, lr:9.14e-03, fs:0.86631 (r=0.818,p=0.920),  time:35.928, tt:2981.996\n",
      "Ep:83, loss:0.00002, loss_test:0.05025, lr:9.04e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.928, tt:3017.910\n",
      "Ep:84, loss:0.00002, loss_test:0.04024, lr:8.95e-03, fs:0.91457 (r=0.919,p=0.910),  time:35.952, tt:3055.919\n",
      "Ep:85, loss:0.00002, loss_test:0.04564, lr:8.86e-03, fs:0.92929 (r=0.929,p=0.929),  time:35.957, tt:3092.326\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00003, loss_test:0.04294, lr:8.86e-03, fs:0.90196 (r=0.929,p=0.876),  time:35.962, tt:3128.726\n",
      "Ep:87, loss:0.00002, loss_test:0.04502, lr:8.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.953, tt:3163.820\n",
      "Ep:88, loss:0.00002, loss_test:0.04291, lr:8.86e-03, fs:0.91371 (r=0.909,p=0.918),  time:35.939, tt:3198.571\n",
      "Ep:89, loss:0.00002, loss_test:0.04387, lr:8.86e-03, fs:0.90256 (r=0.889,p=0.917),  time:35.914, tt:3232.229\n",
      "Ep:90, loss:0.00002, loss_test:0.04501, lr:8.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.896, tt:3266.562\n",
      "Ep:91, loss:0.00002, loss_test:0.04298, lr:8.86e-03, fs:0.91371 (r=0.909,p=0.918),  time:35.872, tt:3300.244\n",
      "Ep:92, loss:0.00002, loss_test:0.04560, lr:8.86e-03, fs:0.86598 (r=0.848,p=0.884),  time:35.849, tt:3333.962\n",
      "Ep:93, loss:0.00002, loss_test:0.04711, lr:8.86e-03, fs:0.89005 (r=0.859,p=0.924),  time:35.834, tt:3368.378\n",
      "Ep:94, loss:0.00002, loss_test:0.04741, lr:8.86e-03, fs:0.89216 (r=0.919,p=0.867),  time:35.818, tt:3402.690\n",
      "Ep:95, loss:0.00002, loss_test:0.04036, lr:8.86e-03, fs:0.92386 (r=0.919,p=0.929),  time:35.805, tt:3437.261\n",
      "Ep:96, loss:0.00002, loss_test:0.04380, lr:8.86e-03, fs:0.87879 (r=0.879,p=0.879),  time:35.788, tt:3471.423\n",
      "Ep:97, loss:0.00002, loss_test:0.05074, lr:8.78e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.784, tt:3506.839\n",
      "Ep:98, loss:0.00002, loss_test:0.04571, lr:8.69e-03, fs:0.88000 (r=0.889,p=0.871),  time:35.763, tt:3540.550\n",
      "Ep:99, loss:0.00002, loss_test:0.04215, lr:8.60e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.757, tt:3575.658\n",
      "Ep:100, loss:0.00002, loss_test:0.04915, lr:8.51e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.785, tt:3614.245\n",
      "Ep:101, loss:0.00002, loss_test:0.04537, lr:8.43e-03, fs:0.90722 (r=0.889,p=0.926),  time:35.778, tt:3649.321\n",
      "Ep:102, loss:0.00002, loss_test:0.04220, lr:8.35e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.755, tt:3682.755\n",
      "Ep:103, loss:0.00001, loss_test:0.04528, lr:8.26e-03, fs:0.88889 (r=0.889,p=0.889),  time:35.720, tt:3714.891\n",
      "Ep:104, loss:0.00001, loss_test:0.04323, lr:8.18e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.704, tt:3748.933\n",
      "Ep:105, loss:0.00001, loss_test:0.03982, lr:8.10e-03, fs:0.91371 (r=0.909,p=0.918),  time:35.697, tt:3783.883\n",
      "Ep:106, loss:0.00001, loss_test:0.04333, lr:8.02e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.700, tt:3819.855\n",
      "Ep:107, loss:0.00001, loss_test:0.04702, lr:7.94e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.691, tt:3854.627\n",
      "Ep:108, loss:0.00001, loss_test:0.04579, lr:7.86e-03, fs:0.83871 (r=0.788,p=0.897),  time:35.696, tt:3890.867\n",
      "Ep:109, loss:0.00001, loss_test:0.04710, lr:7.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.703, tt:3927.385\n",
      "Ep:110, loss:0.00001, loss_test:0.04855, lr:7.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.702, tt:3962.945\n",
      "Ep:111, loss:0.00001, loss_test:0.04420, lr:7.62e-03, fs:0.85714 (r=0.818,p=0.900),  time:35.710, tt:3999.549\n",
      "Ep:112, loss:0.00001, loss_test:0.04853, lr:7.55e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.709, tt:4035.170\n",
      "Ep:113, loss:0.00001, loss_test:0.04760, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.714, tt:4071.418\n",
      "Ep:114, loss:0.00001, loss_test:0.04935, lr:7.40e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.714, tt:4107.075\n",
      "Ep:115, loss:0.00001, loss_test:0.05024, lr:7.32e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.709, tt:4142.291\n",
      "Ep:116, loss:0.00001, loss_test:0.04949, lr:7.25e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.709, tt:4177.942\n",
      "Ep:117, loss:0.00001, loss_test:0.04626, lr:7.18e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.721, tt:4215.019\n",
      "Ep:118, loss:0.00001, loss_test:0.05477, lr:7.11e-03, fs:0.82222 (r=0.747,p=0.914),  time:35.723, tt:4251.018\n",
      "Ep:119, loss:0.00001, loss_test:0.04931, lr:7.03e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.686, tt:4282.336\n",
      "Ep:120, loss:0.00001, loss_test:0.05227, lr:6.96e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.662, tt:4315.102\n",
      "Ep:121, loss:0.00001, loss_test:0.04899, lr:6.89e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.643, tt:4348.459\n",
      "Ep:122, loss:0.00001, loss_test:0.05210, lr:6.83e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.616, tt:4380.806\n",
      "Ep:123, loss:0.00001, loss_test:0.04928, lr:6.76e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.564, tt:4409.922\n",
      "Ep:124, loss:0.00001, loss_test:0.05254, lr:6.69e-03, fs:0.83516 (r=0.768,p=0.916),  time:35.566, tt:4445.714\n",
      "Ep:125, loss:0.00001, loss_test:0.05031, lr:6.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.553, tt:4479.702\n",
      "Ep:126, loss:0.00001, loss_test:0.05203, lr:6.56e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.561, tt:4516.291\n",
      "Ep:127, loss:0.00001, loss_test:0.04956, lr:6.49e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.562, tt:4551.947\n",
      "Ep:128, loss:0.00001, loss_test:0.05437, lr:6.43e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.581, tt:4589.927\n",
      "Ep:129, loss:0.00001, loss_test:0.05160, lr:6.36e-03, fs:0.82873 (r=0.758,p=0.915),  time:35.583, tt:4625.778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00001, loss_test:0.05219, lr:6.30e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.611, tt:4664.981\n",
      "Ep:131, loss:0.00001, loss_test:0.05544, lr:6.24e-03, fs:0.82222 (r=0.747,p=0.914),  time:35.620, tt:4701.783\n",
      "Ep:132, loss:0.00001, loss_test:0.04945, lr:6.17e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.631, tt:4738.980\n",
      "Ep:133, loss:0.00001, loss_test:0.05121, lr:6.11e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.650, tt:4777.042\n",
      "Ep:134, loss:0.00000, loss_test:0.05054, lr:6.05e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.655, tt:4813.482\n",
      "Ep:135, loss:0.00000, loss_test:0.05188, lr:5.99e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.657, tt:4849.346\n",
      "Ep:136, loss:0.00000, loss_test:0.05047, lr:5.93e-03, fs:0.82873 (r=0.758,p=0.915),  time:35.655, tt:4884.735\n",
      "Ep:137, loss:0.00000, loss_test:0.05393, lr:5.87e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.671, tt:4922.588\n",
      "Ep:138, loss:0.00001, loss_test:0.05457, lr:5.81e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.675, tt:4958.789\n",
      "Ep:139, loss:0.00000, loss_test:0.04940, lr:5.75e-03, fs:0.82873 (r=0.758,p=0.915),  time:35.678, tt:4994.912\n",
      "Ep:140, loss:0.00000, loss_test:0.04883, lr:5.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.679, tt:5030.682\n",
      "Ep:141, loss:0.00000, loss_test:0.05256, lr:5.64e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.684, tt:5067.133\n",
      "Ep:142, loss:0.00000, loss_test:0.05002, lr:5.58e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.695, tt:5104.418\n",
      "Ep:143, loss:0.00000, loss_test:0.04793, lr:5.53e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.704, tt:5141.442\n",
      "Ep:144, loss:0.00000, loss_test:0.05102, lr:5.47e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.724, tt:5179.934\n",
      "Ep:145, loss:0.00000, loss_test:0.04863, lr:5.42e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.717, tt:5214.645\n",
      "Ep:146, loss:0.00000, loss_test:0.04851, lr:5.36e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.721, tt:5251.015\n",
      "Ep:147, loss:0.00000, loss_test:0.04968, lr:5.31e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.735, tt:5288.815\n",
      "Ep:148, loss:0.00000, loss_test:0.05066, lr:5.26e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.735, tt:5324.534\n",
      "Ep:149, loss:0.00000, loss_test:0.04895, lr:5.20e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.765, tt:5364.790\n",
      "Ep:150, loss:0.00000, loss_test:0.04866, lr:5.15e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.770, tt:5401.316\n",
      "Ep:151, loss:0.00000, loss_test:0.04800, lr:5.10e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.777, tt:5438.111\n",
      "Ep:152, loss:0.00000, loss_test:0.04930, lr:5.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.788, tt:5475.536\n",
      "Ep:153, loss:0.00000, loss_test:0.04964, lr:5.00e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.795, tt:5512.494\n",
      "Ep:154, loss:0.00000, loss_test:0.05043, lr:4.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.805, tt:5549.768\n",
      "Ep:155, loss:0.00000, loss_test:0.04916, lr:4.90e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.808, tt:5586.061\n",
      "Ep:156, loss:0.00000, loss_test:0.04742, lr:4.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.818, tt:5623.458\n",
      "Ep:157, loss:0.00000, loss_test:0.05034, lr:4.80e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.828, tt:5660.864\n",
      "Ep:158, loss:0.00000, loss_test:0.04808, lr:4.75e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.825, tt:5696.126\n",
      "Ep:159, loss:0.00000, loss_test:0.05059, lr:4.71e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.835, tt:5733.547\n",
      "Ep:160, loss:0.00000, loss_test:0.05052, lr:4.66e-03, fs:0.85870 (r=0.798,p=0.929),  time:35.842, tt:5770.575\n",
      "Ep:161, loss:0.00000, loss_test:0.05010, lr:4.61e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.847, tt:5807.230\n",
      "Ep:162, loss:0.00000, loss_test:0.04877, lr:4.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.849, tt:5843.347\n",
      "Ep:163, loss:0.00000, loss_test:0.04781, lr:4.52e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.854, tt:5880.012\n",
      "Ep:164, loss:0.00000, loss_test:0.04956, lr:4.48e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.867, tt:5918.009\n",
      "Ep:165, loss:0.00000, loss_test:0.04763, lr:4.43e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.872, tt:5954.810\n",
      "Ep:166, loss:0.00000, loss_test:0.04896, lr:4.39e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.883, tt:5992.455\n",
      "Ep:167, loss:0.00000, loss_test:0.04924, lr:4.34e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.886, tt:6028.890\n",
      "Ep:168, loss:0.00000, loss_test:0.04879, lr:4.30e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.899, tt:6066.975\n",
      "Ep:169, loss:0.00000, loss_test:0.05011, lr:4.26e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.907, tt:6104.153\n",
      "Ep:170, loss:0.00000, loss_test:0.05022, lr:4.21e-03, fs:0.85870 (r=0.798,p=0.929),  time:35.910, tt:6140.680\n",
      "Ep:171, loss:0.00000, loss_test:0.04864, lr:4.17e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.916, tt:6177.474\n",
      "Ep:172, loss:0.00000, loss_test:0.04901, lr:4.13e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.917, tt:6213.558\n",
      "Ep:173, loss:0.00000, loss_test:0.04911, lr:4.09e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.917, tt:6249.586\n",
      "Ep:174, loss:0.00000, loss_test:0.04831, lr:4.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.924, tt:6286.742\n",
      "Ep:175, loss:0.00000, loss_test:0.04762, lr:4.01e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.936, tt:6324.777\n",
      "Ep:176, loss:0.00000, loss_test:0.04828, lr:3.97e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.941, tt:6361.479\n",
      "Ep:177, loss:0.00000, loss_test:0.04845, lr:3.93e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.949, tt:6398.915\n",
      "Ep:178, loss:0.00000, loss_test:0.04889, lr:3.89e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.960, tt:6436.774\n",
      "Ep:179, loss:0.00000, loss_test:0.04938, lr:3.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.955, tt:6471.868\n",
      "Ep:180, loss:0.00000, loss_test:0.04758, lr:3.81e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.968, tt:6510.250\n",
      "Ep:181, loss:0.00000, loss_test:0.04891, lr:3.77e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.973, tt:6547.101\n",
      "Ep:182, loss:0.00000, loss_test:0.04937, lr:3.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.976, tt:6583.666\n",
      "Ep:183, loss:0.00000, loss_test:0.04807, lr:3.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.991, tt:6622.376\n",
      "Ep:184, loss:0.00000, loss_test:0.04805, lr:3.66e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.994, tt:6658.869\n",
      "Ep:185, loss:0.00000, loss_test:0.04833, lr:3.62e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.000, tt:6695.925\n",
      "Ep:186, loss:0.00000, loss_test:0.04803, lr:3.59e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.010, tt:6733.822\n",
      "Ep:187, loss:0.00000, loss_test:0.04735, lr:3.55e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.015, tt:6770.901\n",
      "Ep:188, loss:0.00000, loss_test:0.04760, lr:3.52e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.018, tt:6807.482\n",
      "Ep:189, loss:0.00000, loss_test:0.04820, lr:3.48e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.020, tt:6843.713\n",
      "Ep:190, loss:0.00000, loss_test:0.04763, lr:3.45e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.020, tt:6879.829\n",
      "Ep:191, loss:0.00000, loss_test:0.04795, lr:3.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.024, tt:6916.550\n",
      "Ep:192, loss:0.00000, loss_test:0.04867, lr:3.38e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.027, tt:6953.149\n",
      "Ep:193, loss:0.00000, loss_test:0.04802, lr:3.34e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.039, tt:6991.475\n",
      "Ep:194, loss:0.00000, loss_test:0.04741, lr:3.31e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.039, tt:7027.639\n",
      "Ep:195, loss:0.00000, loss_test:0.04775, lr:3.28e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.051, tt:7066.025\n",
      "Ep:196, loss:0.00000, loss_test:0.04777, lr:3.24e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.052, tt:7102.276\n",
      "Ep:197, loss:0.00000, loss_test:0.04801, lr:3.21e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.061, tt:7140.047\n",
      "Ep:198, loss:0.00000, loss_test:0.04795, lr:3.18e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.065, tt:7176.967\n",
      "Ep:199, loss:0.00000, loss_test:0.04747, lr:3.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.062, tt:7212.416\n",
      "Ep:200, loss:0.00000, loss_test:0.04750, lr:3.12e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.061, tt:7248.173\n",
      "Ep:201, loss:0.00000, loss_test:0.04798, lr:3.09e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.065, tt:7285.213\n",
      "Ep:202, loss:0.00000, loss_test:0.04768, lr:3.05e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.062, tt:7320.547\n",
      "Ep:203, loss:0.00000, loss_test:0.04726, lr:3.02e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.061, tt:7356.400\n",
      "Ep:204, loss:0.00000, loss_test:0.04749, lr:2.99e-03, fs:0.87701 (r=0.828,p=0.932),  time:36.060, tt:7392.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.04741, lr:2.96e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.055, tt:7427.313\n",
      "Ep:206, loss:0.00000, loss_test:0.04698, lr:2.93e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.056, tt:7463.505\n",
      "Ep:207, loss:0.00000, loss_test:0.04788, lr:2.90e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.060, tt:7500.390\n",
      "Ep:208, loss:0.00000, loss_test:0.04817, lr:2.88e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.052, tt:7534.866\n",
      "Ep:209, loss:0.00000, loss_test:0.04801, lr:2.85e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.056, tt:7571.835\n",
      "Ep:210, loss:0.00000, loss_test:0.04754, lr:2.82e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.062, tt:7609.103\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02910, lr:6.00e-02, fs:0.61972 (r=0.667,p=0.579),  time:32.019, tt:32.019\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02328, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:33.264, tt:66.529\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:33.466, tt:100.398\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:33.999, tt:135.995\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02465, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:34.517, tt:172.583\n",
      "Ep:5, loss:0.00005, loss_test:0.02455, lr:6.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:34.693, tt:208.156\n",
      "Ep:6, loss:0.00005, loss_test:0.02466, lr:6.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:34.833, tt:243.832\n",
      "Ep:7, loss:0.00005, loss_test:0.02461, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:34.899, tt:279.191\n",
      "Ep:8, loss:0.00005, loss_test:0.02419, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:35.043, tt:315.390\n",
      "Ep:9, loss:0.00005, loss_test:0.02364, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:35.039, tt:350.389\n",
      "Ep:10, loss:0.00005, loss_test:0.02296, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:34.936, tt:384.300\n",
      "Ep:11, loss:0.00005, loss_test:0.02229, lr:6.00e-02, fs:0.65354 (r=0.838,p=0.535),  time:34.959, tt:419.511\n",
      "Ep:12, loss:0.00004, loss_test:0.02168, lr:6.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:35.038, tt:455.495\n",
      "Ep:13, loss:0.00004, loss_test:0.02099, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:35.020, tt:490.278\n",
      "Ep:14, loss:0.00004, loss_test:0.02037, lr:6.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:34.779, tt:521.690\n",
      "Ep:15, loss:0.00004, loss_test:0.01981, lr:5.94e-02, fs:0.66667 (r=0.828,p=0.558),  time:34.599, tt:553.586\n",
      "Ep:16, loss:0.00004, loss_test:0.01932, lr:5.88e-02, fs:0.66667 (r=0.838,p=0.553),  time:34.529, tt:586.986\n",
      "Ep:17, loss:0.00004, loss_test:0.01897, lr:5.82e-02, fs:0.69291 (r=0.889,p=0.568),  time:34.532, tt:621.582\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01867, lr:5.82e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.453, tt:654.614\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01839, lr:5.82e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.442, tt:688.836\n",
      "Ep:20, loss:0.00004, loss_test:0.01816, lr:5.82e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.445, tt:723.338\n",
      "Ep:21, loss:0.00004, loss_test:0.01789, lr:5.82e-02, fs:0.69323 (r=0.879,p=0.572),  time:34.397, tt:756.740\n",
      "Ep:22, loss:0.00004, loss_test:0.01769, lr:5.82e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.366, tt:790.420\n",
      "Ep:23, loss:0.00004, loss_test:0.01747, lr:5.82e-02, fs:0.71318 (r=0.929,p=0.579),  time:34.298, tt:823.155\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01719, lr:5.82e-02, fs:0.71815 (r=0.939,p=0.581),  time:34.216, tt:855.403\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01685, lr:5.82e-02, fs:0.72656 (r=0.939,p=0.592),  time:34.187, tt:888.872\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01647, lr:5.82e-02, fs:0.73518 (r=0.939,p=0.604),  time:34.148, tt:921.989\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01605, lr:5.82e-02, fs:0.74699 (r=0.939,p=0.620),  time:34.140, tt:955.912\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01565, lr:5.82e-02, fs:0.75000 (r=0.939,p=0.624),  time:34.116, tt:989.361\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01532, lr:5.82e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.085, tt:1022.552\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01503, lr:5.82e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.080, tt:1056.482\n",
      "Ep:31, loss:0.00003, loss_test:0.01473, lr:5.82e-02, fs:0.76735 (r=0.949,p=0.644),  time:34.099, tt:1091.180\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01433, lr:5.82e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.058, tt:1123.899\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01402, lr:5.82e-02, fs:0.77366 (r=0.949,p=0.653),  time:34.068, tt:1158.318\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01382, lr:5.82e-02, fs:0.77366 (r=0.949,p=0.653),  time:34.057, tt:1191.982\n",
      "Ep:35, loss:0.00003, loss_test:0.01351, lr:5.82e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.081, tt:1226.904\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01329, lr:5.82e-02, fs:0.78512 (r=0.960,p=0.664),  time:34.106, tt:1261.933\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01307, lr:5.82e-02, fs:0.78189 (r=0.960,p=0.660),  time:34.140, tt:1297.337\n",
      "Ep:38, loss:0.00003, loss_test:0.01289, lr:5.82e-02, fs:0.79167 (r=0.960,p=0.674),  time:34.140, tt:1331.452\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01265, lr:5.82e-02, fs:0.80000 (r=0.970,p=0.681),  time:34.171, tt:1366.831\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01251, lr:5.82e-02, fs:0.80335 (r=0.970,p=0.686),  time:34.155, tt:1400.338\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01229, lr:5.82e-02, fs:0.80165 (r=0.980,p=0.678),  time:34.150, tt:1434.294\n",
      "Ep:42, loss:0.00002, loss_test:0.01207, lr:5.82e-02, fs:0.80508 (r=0.960,p=0.693),  time:34.166, tt:1469.138\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01184, lr:5.82e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.183, tt:1504.058\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01166, lr:5.82e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.226, tt:1540.160\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01151, lr:5.82e-02, fs:0.81197 (r=0.960,p=0.704),  time:34.247, tt:1575.384\n",
      "Ep:46, loss:0.00002, loss_test:0.01126, lr:5.82e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.283, tt:1611.299\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01123, lr:5.82e-02, fs:0.83262 (r=0.980,p=0.724),  time:34.293, tt:1646.076\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01118, lr:5.82e-02, fs:0.82906 (r=0.980,p=0.719),  time:34.310, tt:1681.193\n",
      "Ep:49, loss:0.00002, loss_test:0.01088, lr:5.82e-02, fs:0.83478 (r=0.970,p=0.733),  time:34.313, tt:1715.653\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01089, lr:5.82e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.301, tt:1749.369\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00002, loss_test:0.01090, lr:5.82e-02, fs:0.83843 (r=0.970,p=0.738),  time:34.315, tt:1784.366\n",
      "Ep:52, loss:0.00002, loss_test:0.01052, lr:5.82e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.290, tt:1817.375\n",
      "Ep:53, loss:0.00002, loss_test:0.01068, lr:5.82e-02, fs:0.84211 (r=0.970,p=0.744),  time:34.267, tt:1850.420\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01049, lr:5.82e-02, fs:0.84211 (r=0.970,p=0.744),  time:34.272, tt:1884.953\n",
      "Ep:55, loss:0.00002, loss_test:0.01056, lr:5.82e-02, fs:0.83843 (r=0.970,p=0.738),  time:34.263, tt:1918.726\n",
      "Ep:56, loss:0.00002, loss_test:0.01029, lr:5.82e-02, fs:0.84956 (r=0.970,p=0.756),  time:34.229, tt:1951.072\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01025, lr:5.82e-02, fs:0.84821 (r=0.960,p=0.760),  time:34.208, tt:1984.037\n",
      "Ep:58, loss:0.00002, loss_test:0.01016, lr:5.82e-02, fs:0.85333 (r=0.970,p=0.762),  time:34.186, tt:2016.973\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01002, lr:5.82e-02, fs:0.86486 (r=0.970,p=0.780),  time:34.184, tt:2051.068\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01028, lr:5.82e-02, fs:0.87156 (r=0.960,p=0.798),  time:34.183, tt:2085.160\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.00971, lr:5.82e-02, fs:0.87783 (r=0.980,p=0.795),  time:34.154, tt:2117.557\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.00956, lr:5.82e-02, fs:0.87273 (r=0.970,p=0.793),  time:34.151, tt:2151.526\n",
      "Ep:63, loss:0.00001, loss_test:0.01019, lr:5.82e-02, fs:0.87558 (r=0.960,p=0.805),  time:34.199, tt:2188.735\n",
      "Ep:64, loss:0.00001, loss_test:0.01013, lr:5.82e-02, fs:0.86878 (r=0.970,p=0.787),  time:34.201, tt:2223.083\n",
      "Ep:65, loss:0.00001, loss_test:0.00994, lr:5.82e-02, fs:0.88584 (r=0.980,p=0.808),  time:34.201, tt:2257.266\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.00902, lr:5.82e-02, fs:0.87671 (r=0.970,p=0.800),  time:34.195, tt:2291.051\n",
      "Ep:67, loss:0.00001, loss_test:0.01008, lr:5.82e-02, fs:0.86996 (r=0.980,p=0.782),  time:34.185, tt:2324.606\n",
      "Ep:68, loss:0.00001, loss_test:0.00976, lr:5.82e-02, fs:0.89498 (r=0.990,p=0.817),  time:34.194, tt:2359.399\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01081, lr:5.82e-02, fs:0.85308 (r=0.909,p=0.804),  time:34.188, tt:2393.136\n",
      "Ep:70, loss:0.00001, loss_test:0.00964, lr:5.82e-02, fs:0.88889 (r=0.970,p=0.821),  time:34.167, tt:2425.858\n",
      "Ep:71, loss:0.00001, loss_test:0.00934, lr:5.82e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.141, tt:2458.130\n",
      "Ep:72, loss:0.00001, loss_test:0.00832, lr:5.82e-02, fs:0.89401 (r=0.980,p=0.822),  time:34.119, tt:2490.699\n",
      "Ep:73, loss:0.00001, loss_test:0.00979, lr:5.82e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.118, tt:2524.731\n",
      "Ep:74, loss:0.00001, loss_test:0.00834, lr:5.82e-02, fs:0.88785 (r=0.960,p=0.826),  time:34.115, tt:2558.651\n",
      "Ep:75, loss:0.00001, loss_test:0.00893, lr:5.82e-02, fs:0.88479 (r=0.970,p=0.814),  time:34.126, tt:2593.544\n",
      "Ep:76, loss:0.00001, loss_test:0.00832, lr:5.82e-02, fs:0.88785 (r=0.960,p=0.826),  time:34.133, tt:2628.254\n",
      "Ep:77, loss:0.00001, loss_test:0.00926, lr:5.82e-02, fs:0.87850 (r=0.949,p=0.817),  time:34.144, tt:2663.218\n",
      "Ep:78, loss:0.00001, loss_test:0.00877, lr:5.82e-02, fs:0.89302 (r=0.970,p=0.828),  time:34.148, tt:2697.708\n",
      "Ep:79, loss:0.00001, loss_test:0.00825, lr:5.82e-02, fs:0.90995 (r=0.970,p=0.857),  time:34.165, tt:2733.204\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.00864, lr:5.82e-02, fs:0.89302 (r=0.970,p=0.828),  time:34.203, tt:2770.441\n",
      "Ep:81, loss:0.00001, loss_test:0.00845, lr:5.82e-02, fs:0.90141 (r=0.970,p=0.842),  time:34.235, tt:2807.305\n",
      "Ep:82, loss:0.00001, loss_test:0.00827, lr:5.82e-02, fs:0.91429 (r=0.970,p=0.865),  time:34.239, tt:2841.867\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.00887, lr:5.82e-02, fs:0.90141 (r=0.970,p=0.842),  time:34.277, tt:2879.242\n",
      "Ep:84, loss:0.00001, loss_test:0.00859, lr:5.82e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.305, tt:2915.952\n",
      "Ep:85, loss:0.00001, loss_test:0.00841, lr:5.82e-02, fs:0.90566 (r=0.970,p=0.850),  time:34.319, tt:2951.445\n",
      "Ep:86, loss:0.00001, loss_test:0.00851, lr:5.82e-02, fs:0.90566 (r=0.970,p=0.850),  time:34.350, tt:2988.486\n",
      "Ep:87, loss:0.00001, loss_test:0.00824, lr:5.82e-02, fs:0.89623 (r=0.960,p=0.841),  time:34.366, tt:3024.172\n",
      "Ep:88, loss:0.00001, loss_test:0.00883, lr:5.82e-02, fs:0.89423 (r=0.939,p=0.853),  time:34.369, tt:3058.813\n",
      "Ep:89, loss:0.00001, loss_test:0.00927, lr:5.82e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.373, tt:3093.589\n",
      "Ep:90, loss:0.00001, loss_test:0.00829, lr:5.82e-02, fs:0.90566 (r=0.970,p=0.850),  time:34.394, tt:3129.851\n",
      "Ep:91, loss:0.00001, loss_test:0.00866, lr:5.82e-02, fs:0.90047 (r=0.960,p=0.848),  time:34.384, tt:3163.313\n",
      "Ep:92, loss:0.00001, loss_test:0.00788, lr:5.82e-02, fs:0.90909 (r=0.960,p=0.864),  time:34.379, tt:3197.260\n",
      "Ep:93, loss:0.00001, loss_test:0.00829, lr:5.82e-02, fs:0.90909 (r=0.960,p=0.864),  time:34.366, tt:3230.359\n",
      "Ep:94, loss:0.00001, loss_test:0.00876, lr:5.76e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.346, tt:3262.899\n",
      "Ep:95, loss:0.00001, loss_test:0.00914, lr:5.71e-02, fs:0.88235 (r=0.909,p=0.857),  time:34.342, tt:3296.846\n",
      "Ep:96, loss:0.00001, loss_test:0.00878, lr:5.65e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.335, tt:3330.499\n",
      "Ep:97, loss:0.00001, loss_test:0.00903, lr:5.59e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.321, tt:3363.449\n",
      "Ep:98, loss:0.00001, loss_test:0.00819, lr:5.54e-02, fs:0.91346 (r=0.960,p=0.872),  time:34.334, tt:3399.045\n",
      "Ep:99, loss:0.00001, loss_test:0.00938, lr:5.48e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.346, tt:3434.586\n",
      "Ep:100, loss:0.00001, loss_test:0.00838, lr:5.43e-02, fs:0.91346 (r=0.960,p=0.872),  time:34.328, tt:3467.082\n",
      "Ep:101, loss:0.00001, loss_test:0.00937, lr:5.37e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.326, tt:3501.235\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.00814, lr:5.37e-02, fs:0.91787 (r=0.960,p=0.880),  time:34.322, tt:3535.179\n",
      "Ep:103, loss:0.00001, loss_test:0.00919, lr:5.37e-02, fs:0.93532 (r=0.949,p=0.922),  time:34.302, tt:3567.377\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00000, loss_test:0.00854, lr:5.37e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.298, tt:3601.257\n",
      "Ep:105, loss:0.00000, loss_test:0.00928, lr:5.37e-02, fs:0.93596 (r=0.960,p=0.913),  time:34.284, tt:3634.092\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00000, loss_test:0.00806, lr:5.37e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.283, tt:3668.247\n",
      "Ep:107, loss:0.00000, loss_test:0.00982, lr:5.37e-02, fs:0.89447 (r=0.899,p=0.890),  time:34.279, tt:3702.099\n",
      "Ep:108, loss:0.00000, loss_test:0.00841, lr:5.37e-02, fs:0.92157 (r=0.949,p=0.895),  time:34.266, tt:3734.943\n",
      "Ep:109, loss:0.00000, loss_test:0.00924, lr:5.37e-02, fs:0.93596 (r=0.960,p=0.913),  time:34.262, tt:3768.807\n",
      "Ep:110, loss:0.00000, loss_test:0.00862, lr:5.37e-02, fs:0.92683 (r=0.960,p=0.896),  time:34.246, tt:3801.295\n",
      "Ep:111, loss:0.00000, loss_test:0.00924, lr:5.37e-02, fs:0.94527 (r=0.960,p=0.931),  time:34.244, tt:3835.327\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.00866, lr:5.37e-02, fs:0.93596 (r=0.960,p=0.913),  time:34.247, tt:3869.904\n",
      "Ep:113, loss:0.00000, loss_test:0.00913, lr:5.37e-02, fs:0.95000 (r=0.960,p=0.941),  time:34.248, tt:3904.232\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00000, loss_test:0.00935, lr:5.37e-02, fs:0.90816 (r=0.899,p=0.918),  time:34.249, tt:3938.646\n",
      "Ep:115, loss:0.00000, loss_test:0.00896, lr:5.37e-02, fs:0.93137 (r=0.960,p=0.905),  time:34.258, tt:3973.963\n",
      "Ep:116, loss:0.00000, loss_test:0.00926, lr:5.37e-02, fs:0.92462 (r=0.929,p=0.920),  time:34.270, tt:4009.553\n",
      "Ep:117, loss:0.00000, loss_test:0.00912, lr:5.37e-02, fs:0.91457 (r=0.919,p=0.910),  time:34.279, tt:4044.865\n",
      "Ep:118, loss:0.00000, loss_test:0.00960, lr:5.37e-02, fs:0.92462 (r=0.929,p=0.920),  time:34.291, tt:4080.594\n",
      "Ep:119, loss:0.00000, loss_test:0.00921, lr:5.37e-02, fs:0.93467 (r=0.939,p=0.930),  time:34.311, tt:4117.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00000, loss_test:0.00962, lr:5.37e-02, fs:0.93000 (r=0.939,p=0.921),  time:34.322, tt:4152.904\n",
      "Ep:121, loss:0.00000, loss_test:0.00957, lr:5.37e-02, fs:0.89005 (r=0.859,p=0.924),  time:34.335, tt:4188.902\n",
      "Ep:122, loss:0.00000, loss_test:0.00958, lr:5.37e-02, fs:0.93000 (r=0.939,p=0.921),  time:34.307, tt:4219.779\n",
      "Ep:123, loss:0.00000, loss_test:0.01007, lr:5.37e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.251, tt:4247.168\n",
      "Ep:124, loss:0.00000, loss_test:0.00888, lr:5.37e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.187, tt:4273.385\n",
      "Ep:125, loss:0.00000, loss_test:0.00995, lr:5.32e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.149, tt:4302.833\n",
      "Ep:126, loss:0.00000, loss_test:0.00974, lr:5.27e-02, fs:0.90816 (r=0.899,p=0.918),  time:34.068, tt:4326.603\n",
      "Ep:127, loss:0.00000, loss_test:0.00949, lr:5.21e-02, fs:0.88542 (r=0.859,p=0.914),  time:33.991, tt:4350.907\n",
      "Ep:128, loss:0.00000, loss_test:0.01006, lr:5.16e-02, fs:0.89583 (r=0.869,p=0.925),  time:33.967, tt:4381.701\n",
      "Ep:129, loss:0.00000, loss_test:0.00927, lr:5.11e-02, fs:0.92386 (r=0.919,p=0.929),  time:33.945, tt:4412.859\n",
      "Ep:130, loss:0.00000, loss_test:0.01016, lr:5.06e-02, fs:0.89583 (r=0.869,p=0.925),  time:33.935, tt:4445.426\n",
      "Ep:131, loss:0.00000, loss_test:0.00981, lr:5.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:33.935, tt:4479.442\n",
      "Ep:132, loss:0.00000, loss_test:0.00966, lr:4.96e-02, fs:0.91837 (r=0.909,p=0.928),  time:33.926, tt:4512.162\n",
      "Ep:133, loss:0.00000, loss_test:0.00999, lr:4.91e-02, fs:0.90052 (r=0.869,p=0.935),  time:33.923, tt:4545.636\n",
      "Ep:134, loss:0.00000, loss_test:0.00957, lr:4.86e-02, fs:0.89583 (r=0.869,p=0.925),  time:33.957, tt:4584.159\n",
      "Ep:135, loss:0.00000, loss_test:0.01052, lr:4.81e-02, fs:0.88889 (r=0.848,p=0.933),  time:33.956, tt:4617.982\n",
      "Ep:136, loss:0.00000, loss_test:0.00975, lr:4.76e-02, fs:0.90155 (r=0.879,p=0.926),  time:33.941, tt:4649.895\n",
      "Ep:137, loss:0.00000, loss_test:0.00974, lr:4.71e-02, fs:0.89583 (r=0.869,p=0.925),  time:33.935, tt:4683.071\n",
      "Ep:138, loss:0.00000, loss_test:0.01017, lr:4.67e-02, fs:0.89474 (r=0.859,p=0.934),  time:33.937, tt:4717.226\n",
      "Ep:139, loss:0.00000, loss_test:0.00972, lr:4.62e-02, fs:0.89005 (r=0.859,p=0.924),  time:33.929, tt:4750.059\n",
      "Ep:140, loss:0.00000, loss_test:0.01032, lr:4.57e-02, fs:0.87958 (r=0.848,p=0.913),  time:33.925, tt:4783.380\n",
      "Ep:141, loss:0.00000, loss_test:0.00961, lr:4.53e-02, fs:0.90052 (r=0.869,p=0.935),  time:33.926, tt:4817.442\n",
      "Ep:142, loss:0.00000, loss_test:0.01016, lr:4.48e-02, fs:0.88889 (r=0.848,p=0.933),  time:33.913, tt:4849.611\n",
      "Ep:143, loss:0.00000, loss_test:0.00923, lr:4.44e-02, fs:0.94000 (r=0.949,p=0.931),  time:33.904, tt:4882.124\n",
      "Ep:144, loss:0.00000, loss_test:0.01014, lr:4.39e-02, fs:0.91099 (r=0.879,p=0.946),  time:33.904, tt:4916.092\n",
      "Ep:145, loss:0.00000, loss_test:0.00937, lr:4.35e-02, fs:0.92929 (r=0.929,p=0.929),  time:33.902, tt:4949.664\n",
      "Ep:146, loss:0.00000, loss_test:0.00962, lr:4.31e-02, fs:0.94000 (r=0.949,p=0.931),  time:33.899, tt:4983.139\n",
      "Ep:147, loss:0.00000, loss_test:0.00982, lr:4.26e-02, fs:0.94527 (r=0.960,p=0.931),  time:33.893, tt:5016.187\n",
      "Ep:148, loss:0.00000, loss_test:0.00958, lr:4.22e-02, fs:0.93467 (r=0.939,p=0.930),  time:33.900, tt:5051.163\n",
      "Ep:149, loss:0.00000, loss_test:0.01042, lr:4.18e-02, fs:0.88770 (r=0.838,p=0.943),  time:33.902, tt:5085.348\n",
      "Ep:150, loss:0.00000, loss_test:0.00974, lr:4.14e-02, fs:0.93939 (r=0.939,p=0.939),  time:33.907, tt:5119.971\n",
      "Ep:151, loss:0.00000, loss_test:0.01035, lr:4.10e-02, fs:0.83146 (r=0.747,p=0.937),  time:33.913, tt:5154.763\n",
      "Ep:152, loss:0.00000, loss_test:0.00993, lr:4.05e-02, fs:0.90052 (r=0.869,p=0.935),  time:33.915, tt:5189.000\n",
      "Ep:153, loss:0.00000, loss_test:0.01041, lr:4.01e-02, fs:0.87701 (r=0.828,p=0.932),  time:33.905, tt:5221.327\n",
      "Ep:154, loss:0.00000, loss_test:0.01026, lr:3.97e-02, fs:0.89362 (r=0.848,p=0.944),  time:33.898, tt:5254.255\n",
      "Ep:155, loss:0.00000, loss_test:0.01016, lr:3.93e-02, fs:0.87097 (r=0.818,p=0.931),  time:33.899, tt:5288.314\n",
      "Ep:156, loss:0.00000, loss_test:0.01014, lr:3.89e-02, fs:0.85246 (r=0.788,p=0.929),  time:33.903, tt:5322.825\n",
      "Ep:157, loss:0.00000, loss_test:0.01046, lr:3.86e-02, fs:0.88770 (r=0.838,p=0.943),  time:33.907, tt:5357.275\n",
      "Ep:158, loss:0.00000, loss_test:0.01022, lr:3.82e-02, fs:0.85246 (r=0.788,p=0.929),  time:33.922, tt:5393.671\n",
      "Ep:159, loss:0.00000, loss_test:0.01031, lr:3.78e-02, fs:0.89947 (r=0.859,p=0.944),  time:33.926, tt:5428.088\n",
      "Ep:160, loss:0.00000, loss_test:0.01031, lr:3.74e-02, fs:0.83799 (r=0.758,p=0.938),  time:33.933, tt:5463.257\n",
      "Ep:161, loss:0.00000, loss_test:0.01038, lr:3.70e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.938, tt:5497.991\n",
      "Ep:162, loss:0.00000, loss_test:0.01050, lr:3.67e-02, fs:0.82486 (r=0.737,p=0.936),  time:33.941, tt:5532.389\n",
      "Ep:163, loss:0.00000, loss_test:0.01005, lr:3.63e-02, fs:0.89362 (r=0.848,p=0.944),  time:33.941, tt:5566.258\n",
      "Ep:164, loss:0.00000, loss_test:0.01076, lr:3.59e-02, fs:0.82486 (r=0.737,p=0.936),  time:33.950, tt:5601.739\n",
      "Ep:165, loss:0.00000, loss_test:0.01026, lr:3.56e-02, fs:0.83799 (r=0.758,p=0.938),  time:33.957, tt:5636.877\n",
      "Ep:166, loss:0.00000, loss_test:0.01081, lr:3.52e-02, fs:0.81818 (r=0.727,p=0.935),  time:33.969, tt:5672.844\n",
      "Ep:167, loss:0.00000, loss_test:0.01032, lr:3.49e-02, fs:0.88770 (r=0.838,p=0.943),  time:33.975, tt:5707.785\n",
      "Ep:168, loss:0.00000, loss_test:0.01072, lr:3.45e-02, fs:0.81818 (r=0.727,p=0.935),  time:33.986, tt:5743.580\n",
      "Ep:169, loss:0.00000, loss_test:0.01041, lr:3.42e-02, fs:0.88172 (r=0.828,p=0.943),  time:33.995, tt:5779.224\n",
      "Ep:170, loss:0.00000, loss_test:0.01084, lr:3.38e-02, fs:0.81818 (r=0.727,p=0.935),  time:33.992, tt:5812.632\n",
      "Ep:171, loss:0.00000, loss_test:0.01046, lr:3.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:33.992, tt:5846.584\n",
      "Ep:172, loss:0.00000, loss_test:0.01090, lr:3.32e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.004, tt:5882.632\n",
      "Ep:173, loss:0.00000, loss_test:0.01046, lr:3.28e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.006, tt:5917.082\n",
      "Ep:174, loss:0.00000, loss_test:0.01095, lr:3.25e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.014, tt:5952.525\n",
      "Ep:175, loss:0.00000, loss_test:0.01057, lr:3.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.018, tt:5987.122\n",
      "Ep:176, loss:0.00000, loss_test:0.01087, lr:3.19e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.026, tt:6022.655\n",
      "Ep:177, loss:0.00000, loss_test:0.01056, lr:3.15e-02, fs:0.88172 (r=0.828,p=0.943),  time:34.032, tt:6057.735\n",
      "Ep:178, loss:0.00000, loss_test:0.01085, lr:3.12e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.033, tt:6091.995\n",
      "Ep:179, loss:0.00000, loss_test:0.01077, lr:3.09e-02, fs:0.83799 (r=0.758,p=0.938),  time:34.041, tt:6127.400\n",
      "Ep:180, loss:0.00000, loss_test:0.01084, lr:3.06e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.046, tt:6162.260\n",
      "Ep:181, loss:0.00000, loss_test:0.01072, lr:3.03e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.054, tt:6197.861\n",
      "Ep:182, loss:0.00000, loss_test:0.01099, lr:3.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.054, tt:6231.893\n",
      "Ep:183, loss:0.00000, loss_test:0.01075, lr:2.97e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.058, tt:6266.590\n",
      "Ep:184, loss:0.00000, loss_test:0.01100, lr:2.94e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.060, tt:6301.136\n",
      "Ep:185, loss:0.00000, loss_test:0.01083, lr:2.91e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.063, tt:6335.700\n",
      "Ep:186, loss:0.00000, loss_test:0.01098, lr:2.88e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.073, tt:6371.595\n",
      "Ep:187, loss:0.00000, loss_test:0.01085, lr:2.85e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.074, tt:6405.854\n",
      "Ep:188, loss:0.00000, loss_test:0.01086, lr:2.82e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.071, tt:6439.347\n",
      "Ep:189, loss:0.00000, loss_test:0.01101, lr:2.80e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.070, tt:6473.227\n",
      "Ep:190, loss:0.00000, loss_test:0.01095, lr:2.77e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.070, tt:6507.446\n",
      "Ep:191, loss:0.00000, loss_test:0.01103, lr:2.74e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.069, tt:6541.206\n",
      "Ep:192, loss:0.00000, loss_test:0.01090, lr:2.71e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.069, tt:6575.273\n",
      "Ep:193, loss:0.00000, loss_test:0.01097, lr:2.69e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.074, tt:6610.365\n",
      "Ep:194, loss:0.00000, loss_test:0.01098, lr:2.66e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.076, tt:6644.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00000, loss_test:0.01103, lr:2.63e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.081, tt:6679.869\n",
      "Ep:196, loss:0.00000, loss_test:0.01100, lr:2.61e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.078, tt:6713.385\n",
      "Ep:197, loss:0.00000, loss_test:0.01104, lr:2.58e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.078, tt:6747.444\n",
      "Ep:198, loss:0.00000, loss_test:0.01109, lr:2.55e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.084, tt:6782.644\n",
      "Ep:199, loss:0.00000, loss_test:0.01104, lr:2.53e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.084, tt:6816.800\n",
      "Ep:200, loss:0.00000, loss_test:0.01117, lr:2.50e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.081, tt:6850.246\n",
      "Ep:201, loss:0.00000, loss_test:0.01100, lr:2.48e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.078, tt:6883.778\n",
      "Ep:202, loss:0.00000, loss_test:0.01121, lr:2.45e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.083, tt:6918.830\n",
      "Ep:203, loss:0.00000, loss_test:0.01103, lr:2.43e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.090, tt:6954.337\n",
      "Ep:204, loss:0.00000, loss_test:0.01127, lr:2.40e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.092, tt:6988.862\n",
      "Ep:205, loss:0.00000, loss_test:0.01106, lr:2.38e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.094, tt:7023.349\n",
      "Ep:206, loss:0.00000, loss_test:0.01124, lr:2.36e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.093, tt:7057.210\n",
      "Ep:207, loss:0.00000, loss_test:0.01105, lr:2.33e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.091, tt:7090.837\n",
      "Ep:208, loss:0.00000, loss_test:0.01120, lr:2.31e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.092, tt:7125.278\n",
      "Ep:209, loss:0.00000, loss_test:0.01119, lr:2.29e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.098, tt:7160.588\n",
      "Ep:210, loss:0.00000, loss_test:0.01114, lr:2.26e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.095, tt:7194.043\n",
      "Ep:211, loss:0.00000, loss_test:0.01115, lr:2.24e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.089, tt:7226.965\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.12591, lr:1.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:37.152, tt:37.152\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12485, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:37.455, tt:74.910\n",
      "Ep:2, loss:0.00026, loss_test:0.12433, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:36.843, tt:110.530\n",
      "Ep:3, loss:0.00026, loss_test:0.12372, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:36.665, tt:146.659\n",
      "Ep:4, loss:0.00025, loss_test:0.12304, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:36.546, tt:182.731\n",
      "Ep:5, loss:0.00025, loss_test:0.12242, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:36.969, tt:221.814\n",
      "Ep:6, loss:0.00025, loss_test:0.12164, lr:1.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:36.851, tt:257.954\n",
      "Ep:7, loss:0.00025, loss_test:0.12099, lr:1.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:36.643, tt:293.144\n",
      "Ep:8, loss:0.00024, loss_test:0.11997, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:36.554, tt:328.982\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11925, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:36.524, tt:365.241\n",
      "Ep:10, loss:0.00024, loss_test:0.11858, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:36.495, tt:401.444\n",
      "Ep:11, loss:0.00024, loss_test:0.11812, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:36.403, tt:436.832\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.11698, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:36.338, tt:472.388\n",
      "Ep:13, loss:0.00023, loss_test:0.11593, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:36.147, tt:506.060\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11506, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:35.999, tt:539.990\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.11380, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:35.929, tt:574.862\n",
      "Ep:16, loss:0.00023, loss_test:0.11237, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:35.950, tt:611.155\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.11089, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:35.854, tt:645.363\n",
      "Ep:18, loss:0.00022, loss_test:0.10932, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:35.808, tt:680.351\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.10719, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:35.693, tt:713.868\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10532, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:35.597, tt:747.542\n",
      "Ep:21, loss:0.00021, loss_test:0.10328, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:35.589, tt:782.959\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.10047, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:35.528, tt:817.143\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.09892, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:35.517, tt:852.407\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.09464, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:35.499, tt:887.475\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.09459, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:35.445, tt:921.574\n",
      "Ep:26, loss:0.00018, loss_test:0.08901, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:35.466, tt:957.575\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.08757, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:35.426, tt:991.933\n",
      "Ep:28, loss:0.00017, loss_test:0.08335, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:35.396, tt:1026.484\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.08064, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:35.330, tt:1059.911\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.08159, lr:1.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:35.293, tt:1094.071\n",
      "Ep:31, loss:0.00015, loss_test:0.07534, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:35.255, tt:1128.150\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.07759, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:35.225, tt:1162.423\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.07352, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:35.198, tt:1196.737\n",
      "Ep:34, loss:0.00014, loss_test:0.06942, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:35.160, tt:1230.597\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.07065, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:35.178, tt:1266.426\n",
      "Ep:36, loss:0.00013, loss_test:0.06793, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:35.169, tt:1301.264\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.06600, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:35.142, tt:1335.400\n",
      "Ep:38, loss:0.00012, loss_test:0.06311, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:35.112, tt:1369.376\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.06209, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:35.099, tt:1403.962\n",
      "Ep:40, loss:0.00011, loss_test:0.07181, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:35.097, tt:1438.975\n",
      "Ep:41, loss:0.00011, loss_test:0.07976, lr:1.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:35.110, tt:1474.625\n",
      "Ep:42, loss:0.00012, loss_test:0.06363, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:35.118, tt:1510.089\n",
      "Ep:43, loss:0.00010, loss_test:0.05897, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:35.072, tt:1543.181\n",
      "Ep:44, loss:0.00010, loss_test:0.05872, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:35.115, tt:1580.186\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.06059, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:35.106, tt:1614.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00009, loss_test:0.05628, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:35.077, tt:1648.634\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.05515, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:35.081, tt:1683.901\n",
      "Ep:48, loss:0.00008, loss_test:0.05080, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:35.057, tt:1717.817\n",
      "Ep:49, loss:0.00007, loss_test:0.06825, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:35.010, tt:1750.513\n",
      "Ep:50, loss:0.00009, loss_test:0.05779, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:34.974, tt:1783.678\n",
      "Ep:51, loss:0.00008, loss_test:0.04711, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.954, tt:1817.626\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.05385, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:34.933, tt:1851.468\n",
      "Ep:53, loss:0.00007, loss_test:0.04953, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:34.909, tt:1885.065\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.05614, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:34.913, tt:1920.197\n",
      "Ep:55, loss:0.00008, loss_test:0.04287, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:34.905, tt:1954.662\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.04806, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:34.937, tt:1991.434\n",
      "Ep:57, loss:0.00006, loss_test:0.04435, lr:1.00e-02, fs:0.92823 (r=0.980,p=0.882),  time:34.986, tt:2029.163\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.04494, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:35.022, tt:2066.285\n",
      "Ep:59, loss:0.00006, loss_test:0.04589, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.066, tt:2103.956\n",
      "Ep:60, loss:0.00006, loss_test:0.04267, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:35.081, tt:2139.925\n",
      "Ep:61, loss:0.00006, loss_test:0.04288, lr:1.00e-02, fs:0.92891 (r=0.990,p=0.875),  time:35.087, tt:2175.404\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.05074, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:35.098, tt:2211.160\n",
      "Ep:63, loss:0.00006, loss_test:0.03564, lr:1.00e-02, fs:0.95192 (r=1.000,p=0.908),  time:35.140, tt:2248.985\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.04279, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:35.161, tt:2285.473\n",
      "Ep:65, loss:0.00005, loss_test:0.04209, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.196, tt:2322.925\n",
      "Ep:66, loss:0.00004, loss_test:0.03561, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:35.225, tt:2360.072\n",
      "Ep:67, loss:0.00004, loss_test:0.03472, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.268, tt:2398.253\n",
      "Ep:68, loss:0.00004, loss_test:0.03818, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:35.283, tt:2434.519\n",
      "Ep:69, loss:0.00004, loss_test:0.03486, lr:1.00e-02, fs:0.93467 (r=0.939,p=0.930),  time:35.310, tt:2471.707\n",
      "Ep:70, loss:0.00003, loss_test:0.03444, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.313, tt:2507.221\n",
      "Ep:71, loss:0.00003, loss_test:0.03452, lr:1.00e-02, fs:0.97000 (r=0.980,p=0.960),  time:35.325, tt:2543.397\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00003, loss_test:0.03843, lr:1.00e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.317, tt:2578.167\n",
      "Ep:73, loss:0.00003, loss_test:0.03215, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:35.322, tt:2613.850\n",
      "Ep:74, loss:0.00003, loss_test:0.04005, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:35.327, tt:2649.545\n",
      "Ep:75, loss:0.00003, loss_test:0.03401, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:35.348, tt:2686.423\n",
      "Ep:76, loss:0.00003, loss_test:0.03278, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:35.365, tt:2723.076\n",
      "Ep:77, loss:0.00003, loss_test:0.04059, lr:1.00e-02, fs:0.90256 (r=0.889,p=0.917),  time:35.358, tt:2757.888\n",
      "Ep:78, loss:0.00003, loss_test:0.03097, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:35.359, tt:2793.372\n",
      "Ep:79, loss:0.00002, loss_test:0.03492, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:35.389, tt:2831.099\n",
      "Ep:80, loss:0.00002, loss_test:0.03017, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:35.384, tt:2866.091\n",
      "Ep:81, loss:0.00002, loss_test:0.03568, lr:1.00e-02, fs:0.92784 (r=0.909,p=0.947),  time:35.384, tt:2901.474\n",
      "Ep:82, loss:0.00002, loss_test:0.03347, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.393, tt:2937.653\n",
      "Ep:83, loss:0.00002, loss_test:0.03205, lr:9.90e-03, fs:0.93401 (r=0.929,p=0.939),  time:35.388, tt:2972.576\n",
      "Ep:84, loss:0.00002, loss_test:0.03121, lr:9.80e-03, fs:0.92857 (r=0.919,p=0.938),  time:35.402, tt:3009.211\n",
      "Ep:85, loss:0.00002, loss_test:0.03096, lr:9.70e-03, fs:0.92784 (r=0.909,p=0.947),  time:35.408, tt:3045.083\n",
      "Ep:86, loss:0.00001, loss_test:0.02803, lr:9.61e-03, fs:0.94845 (r=0.929,p=0.968),  time:35.397, tt:3079.506\n",
      "Ep:87, loss:0.00001, loss_test:0.03040, lr:9.51e-03, fs:0.95337 (r=0.929,p=0.979),  time:35.381, tt:3113.504\n",
      "Ep:88, loss:0.00001, loss_test:0.02931, lr:9.41e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.371, tt:3147.998\n",
      "Ep:89, loss:0.00001, loss_test:0.03187, lr:9.32e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.366, tt:3182.958\n",
      "Ep:90, loss:0.00001, loss_test:0.02857, lr:9.23e-03, fs:0.95876 (r=0.939,p=0.979),  time:35.349, tt:3216.794\n",
      "Ep:91, loss:0.00001, loss_test:0.03322, lr:9.14e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.355, tt:3252.623\n",
      "Ep:92, loss:0.00001, loss_test:0.03170, lr:9.04e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.358, tt:3288.299\n",
      "Ep:93, loss:0.00001, loss_test:0.02888, lr:8.95e-03, fs:0.96373 (r=0.939,p=0.989),  time:35.359, tt:3323.731\n",
      "Ep:94, loss:0.00001, loss_test:0.03604, lr:8.86e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.354, tt:3358.651\n",
      "Ep:95, loss:0.00001, loss_test:0.02798, lr:8.78e-03, fs:0.97409 (r=0.949,p=1.000),  time:35.370, tt:3395.498\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.03054, lr:8.78e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.370, tt:3430.881\n",
      "Ep:97, loss:0.00001, loss_test:0.03216, lr:8.78e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.380, tt:3467.211\n",
      "Ep:98, loss:0.00001, loss_test:0.02949, lr:8.78e-03, fs:0.95238 (r=0.909,p=1.000),  time:35.386, tt:3503.167\n",
      "Ep:99, loss:0.00001, loss_test:0.03800, lr:8.78e-03, fs:0.91803 (r=0.848,p=1.000),  time:35.379, tt:3537.931\n",
      "Ep:100, loss:0.00001, loss_test:0.03160, lr:8.78e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.382, tt:3573.532\n",
      "Ep:101, loss:0.00001, loss_test:0.03361, lr:8.78e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.420, tt:3612.845\n",
      "Ep:102, loss:0.00001, loss_test:0.02924, lr:8.78e-03, fs:0.95337 (r=0.929,p=0.979),  time:35.431, tt:3649.373\n",
      "Ep:103, loss:0.00001, loss_test:0.02968, lr:8.78e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.441, tt:3685.856\n",
      "Ep:104, loss:0.00001, loss_test:0.03627, lr:8.78e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.472, tt:3724.610\n",
      "Ep:105, loss:0.00001, loss_test:0.03119, lr:8.78e-03, fs:0.95238 (r=0.909,p=1.000),  time:35.485, tt:3761.448\n",
      "Ep:106, loss:0.00001, loss_test:0.02702, lr:8.78e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.479, tt:3796.240\n",
      "Ep:107, loss:0.00001, loss_test:0.03320, lr:8.69e-03, fs:0.88136 (r=0.788,p=1.000),  time:35.493, tt:3833.285\n",
      "Ep:108, loss:0.00001, loss_test:0.02964, lr:8.60e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.499, tt:3869.354\n",
      "Ep:109, loss:0.00001, loss_test:0.02908, lr:8.51e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.506, tt:3905.702\n",
      "Ep:110, loss:0.00001, loss_test:0.03189, lr:8.43e-03, fs:0.88136 (r=0.788,p=1.000),  time:35.525, tt:3943.301\n",
      "Ep:111, loss:0.00000, loss_test:0.03174, lr:8.35e-03, fs:0.91209 (r=0.838,p=1.000),  time:35.533, tt:3979.703\n",
      "Ep:112, loss:0.00000, loss_test:0.02955, lr:8.26e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.513, tt:4012.979\n",
      "Ep:113, loss:0.00000, loss_test:0.03013, lr:8.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:35.463, tt:4042.809\n",
      "Ep:114, loss:0.00000, loss_test:0.03423, lr:8.10e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.431, tt:4074.557\n",
      "Ep:115, loss:0.00000, loss_test:0.03038, lr:8.02e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.424, tt:4109.148\n",
      "Ep:116, loss:0.00000, loss_test:0.03240, lr:7.94e-03, fs:0.90110 (r=0.828,p=0.988),  time:35.362, tt:4137.316\n",
      "Ep:117, loss:0.00000, loss_test:0.03158, lr:7.86e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.323, tt:4168.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:118, loss:0.00000, loss_test:0.03075, lr:7.78e-03, fs:0.90110 (r=0.828,p=0.988),  time:35.295, tt:4200.050\n",
      "Ep:119, loss:0.00000, loss_test:0.02936, lr:7.70e-03, fs:0.90110 (r=0.828,p=0.988),  time:35.305, tt:4236.645\n",
      "Ep:120, loss:0.00000, loss_test:0.03280, lr:7.62e-03, fs:0.90608 (r=0.828,p=1.000),  time:35.316, tt:4273.209\n",
      "Ep:121, loss:0.00000, loss_test:0.02918, lr:7.55e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.308, tt:4307.630\n",
      "Ep:122, loss:0.00000, loss_test:0.03171, lr:7.47e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.315, tt:4343.710\n",
      "Ep:123, loss:0.00000, loss_test:0.03112, lr:7.40e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.320, tt:4379.707\n",
      "Ep:124, loss:0.00000, loss_test:0.03099, lr:7.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:35.320, tt:4414.940\n",
      "Ep:125, loss:0.00000, loss_test:0.03105, lr:7.25e-03, fs:0.94737 (r=0.909,p=0.989),  time:35.321, tt:4450.494\n",
      "Ep:126, loss:0.00000, loss_test:0.03153, lr:7.18e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.320, tt:4485.583\n",
      "Ep:127, loss:0.00000, loss_test:0.03084, lr:7.11e-03, fs:0.88268 (r=0.798,p=0.988),  time:35.322, tt:4521.215\n",
      "Ep:128, loss:0.00000, loss_test:0.03270, lr:7.03e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.313, tt:4555.383\n",
      "Ep:129, loss:0.00000, loss_test:0.03111, lr:6.96e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.312, tt:4590.574\n",
      "Ep:130, loss:0.00000, loss_test:0.03128, lr:6.89e-03, fs:0.88136 (r=0.788,p=1.000),  time:35.325, tt:4627.566\n",
      "Ep:131, loss:0.00000, loss_test:0.03395, lr:6.83e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.323, tt:4662.634\n",
      "Ep:132, loss:0.00000, loss_test:0.03080, lr:6.76e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.324, tt:4698.066\n",
      "Ep:133, loss:0.00000, loss_test:0.03318, lr:6.69e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.305, tt:4730.936\n",
      "Ep:134, loss:0.00000, loss_test:0.03168, lr:6.62e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.307, tt:4766.411\n",
      "Ep:135, loss:0.00000, loss_test:0.03193, lr:6.56e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.321, tt:4803.656\n",
      "Ep:136, loss:0.00000, loss_test:0.03192, lr:6.49e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.320, tt:4838.883\n",
      "Ep:137, loss:0.00000, loss_test:0.03266, lr:6.43e-03, fs:0.88268 (r=0.798,p=0.988),  time:35.316, tt:4873.543\n",
      "Ep:138, loss:0.00000, loss_test:0.03136, lr:6.36e-03, fs:0.88889 (r=0.808,p=0.988),  time:35.306, tt:4907.539\n",
      "Ep:139, loss:0.00000, loss_test:0.03302, lr:6.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.320, tt:4944.862\n",
      "Ep:140, loss:0.00000, loss_test:0.03123, lr:6.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.319, tt:4980.039\n",
      "Ep:141, loss:0.00000, loss_test:0.03176, lr:6.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.315, tt:5014.743\n",
      "Ep:142, loss:0.00000, loss_test:0.03280, lr:6.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.317, tt:5050.372\n",
      "Ep:143, loss:0.00000, loss_test:0.03217, lr:6.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.319, tt:5085.972\n",
      "Ep:144, loss:0.00000, loss_test:0.03160, lr:5.99e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.317, tt:5121.007\n",
      "Ep:145, loss:0.00000, loss_test:0.03263, lr:5.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.316, tt:5156.119\n",
      "Ep:146, loss:0.00000, loss_test:0.03189, lr:5.87e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.318, tt:5191.747\n",
      "Ep:147, loss:0.00000, loss_test:0.03284, lr:5.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.315, tt:5226.598\n",
      "Ep:148, loss:0.00000, loss_test:0.03170, lr:5.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.307, tt:5260.688\n",
      "Ep:149, loss:0.00000, loss_test:0.03234, lr:5.70e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.313, tt:5296.914\n",
      "Ep:150, loss:0.00000, loss_test:0.03177, lr:5.64e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.327, tt:5334.390\n",
      "Ep:151, loss:0.00000, loss_test:0.03228, lr:5.58e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.326, tt:5369.569\n",
      "Ep:152, loss:0.00000, loss_test:0.03158, lr:5.53e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.333, tt:5405.876\n",
      "Ep:153, loss:0.00000, loss_test:0.03190, lr:5.47e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.328, tt:5440.439\n",
      "Ep:154, loss:0.00000, loss_test:0.03182, lr:5.42e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.339, tt:5477.476\n",
      "Ep:155, loss:0.00000, loss_test:0.03212, lr:5.36e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.340, tt:5513.011\n",
      "Ep:156, loss:0.00000, loss_test:0.03265, lr:5.31e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.350, tt:5550.023\n",
      "Ep:157, loss:0.00000, loss_test:0.03215, lr:5.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.360, tt:5586.850\n",
      "Ep:158, loss:0.00000, loss_test:0.03241, lr:5.20e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.357, tt:5621.702\n",
      "Ep:159, loss:0.00000, loss_test:0.03240, lr:5.15e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.355, tt:5656.847\n",
      "Ep:160, loss:0.00000, loss_test:0.03255, lr:5.10e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.357, tt:5692.415\n",
      "Ep:161, loss:0.00000, loss_test:0.03107, lr:5.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.354, tt:5727.362\n",
      "Ep:162, loss:0.00000, loss_test:0.03348, lr:5.00e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.351, tt:5762.158\n",
      "Ep:163, loss:0.00000, loss_test:0.03168, lr:4.95e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.349, tt:5797.220\n",
      "Ep:164, loss:0.00000, loss_test:0.03342, lr:4.90e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.359, tt:5834.208\n",
      "Ep:165, loss:0.00000, loss_test:0.03222, lr:4.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.358, tt:5869.444\n",
      "Ep:166, loss:0.00000, loss_test:0.03266, lr:4.80e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.360, tt:5905.045\n",
      "Ep:167, loss:0.00000, loss_test:0.03315, lr:4.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.356, tt:5939.840\n",
      "Ep:168, loss:0.00000, loss_test:0.03100, lr:4.71e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.360, tt:5975.916\n",
      "Ep:169, loss:0.00000, loss_test:0.03298, lr:4.66e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.357, tt:6010.744\n",
      "Ep:170, loss:0.00000, loss_test:0.03263, lr:4.61e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.368, tt:6047.855\n",
      "Ep:171, loss:0.00000, loss_test:0.03296, lr:4.57e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.370, tt:6083.604\n",
      "Ep:172, loss:0.00000, loss_test:0.03305, lr:4.52e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.372, tt:6119.410\n",
      "Ep:173, loss:0.00000, loss_test:0.03236, lr:4.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.371, tt:6154.627\n",
      "Ep:174, loss:0.00000, loss_test:0.03316, lr:4.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.377, tt:6191.047\n",
      "Ep:175, loss:0.00000, loss_test:0.03281, lr:4.39e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.383, tt:6227.463\n",
      "Ep:176, loss:0.00000, loss_test:0.03238, lr:4.34e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.391, tt:6264.235\n",
      "Ep:177, loss:0.00000, loss_test:0.03242, lr:4.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.397, tt:6300.584\n",
      "Ep:178, loss:0.00000, loss_test:0.03311, lr:4.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.401, tt:6336.864\n",
      "Ep:179, loss:0.00000, loss_test:0.03227, lr:4.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.398, tt:6371.728\n",
      "Ep:180, loss:0.00000, loss_test:0.03229, lr:4.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.405, tt:6408.245\n",
      "Ep:181, loss:0.00000, loss_test:0.03261, lr:4.13e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.407, tt:6444.166\n",
      "Ep:182, loss:0.00000, loss_test:0.03242, lr:4.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.408, tt:6479.646\n",
      "Ep:183, loss:0.00000, loss_test:0.03244, lr:4.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.403, tt:6514.228\n",
      "Ep:184, loss:0.00000, loss_test:0.03256, lr:4.01e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.398, tt:6548.636\n",
      "Ep:185, loss:0.00000, loss_test:0.03215, lr:3.97e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.401, tt:6584.622\n",
      "Ep:186, loss:0.00000, loss_test:0.03279, lr:3.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.400, tt:6619.749\n",
      "Ep:187, loss:0.00000, loss_test:0.03290, lr:3.89e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.406, tt:6656.340\n",
      "Ep:188, loss:0.00000, loss_test:0.03278, lr:3.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.419, tt:6694.126\n",
      "Ep:189, loss:0.00000, loss_test:0.03254, lr:3.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.418, tt:6729.390\n",
      "Ep:190, loss:0.00000, loss_test:0.03285, lr:3.77e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.416, tt:6764.421\n",
      "Ep:191, loss:0.00000, loss_test:0.03229, lr:3.73e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.417, tt:6800.116\n",
      "Ep:192, loss:0.00000, loss_test:0.03303, lr:3.70e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.414, tt:6834.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:193, loss:0.00000, loss_test:0.03283, lr:3.66e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.413, tt:6870.103\n",
      "Ep:194, loss:0.00000, loss_test:0.03239, lr:3.62e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.410, tt:6905.036\n",
      "Ep:195, loss:0.00000, loss_test:0.03251, lr:3.59e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.416, tt:6941.492\n",
      "Ep:196, loss:0.00000, loss_test:0.03277, lr:3.55e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.418, tt:6977.289\n",
      "Ep:197, loss:0.00000, loss_test:0.03294, lr:3.52e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.419, tt:7012.953\n",
      "Ep:198, loss:0.00000, loss_test:0.03264, lr:3.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.421, tt:7048.757\n",
      "Ep:199, loss:0.00000, loss_test:0.03244, lr:3.45e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.423, tt:7084.513\n",
      "Ep:200, loss:0.00000, loss_test:0.03249, lr:3.41e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.421, tt:7119.592\n",
      "Ep:201, loss:0.00000, loss_test:0.03297, lr:3.38e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.416, tt:7154.091\n",
      "Ep:202, loss:0.00000, loss_test:0.03297, lr:3.34e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.418, tt:7189.811\n",
      "Ep:203, loss:0.00000, loss_test:0.03288, lr:3.31e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.409, tt:7223.515\n",
      "Ep:204, loss:0.00000, loss_test:0.03295, lr:3.28e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.413, tt:7259.596\n",
      "Ep:205, loss:0.00000, loss_test:0.03280, lr:3.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.411, tt:7294.726\n",
      "Ep:206, loss:0.00000, loss_test:0.03278, lr:3.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.420, tt:7331.971\n",
      "Ep:207, loss:0.00000, loss_test:0.03300, lr:3.18e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.432, tt:7369.805\n",
      "Ep:208, loss:0.00000, loss_test:0.03241, lr:3.15e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.444, tt:7407.844\n",
      "Ep:209, loss:0.00000, loss_test:0.03270, lr:3.12e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.455, tt:7445.576\n",
      "Ep:210, loss:0.00000, loss_test:0.03283, lr:3.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.466, tt:7483.318\n",
      "Ep:211, loss:0.00000, loss_test:0.03304, lr:3.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.482, tt:7522.214\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03700, lr:6.00e-02, fs:0.58462 (r=0.576,p=0.594),  time:36.862, tt:36.862\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02372, lr:6.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:36.931, tt:73.862\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02421, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:36.575, tt:109.724\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02435, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:36.483, tt:145.930\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02331, lr:6.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:36.454, tt:182.271\n",
      "Ep:5, loss:0.00005, loss_test:0.02342, lr:6.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:36.289, tt:217.735\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02356, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:36.241, tt:253.684\n",
      "Ep:7, loss:0.00005, loss_test:0.02310, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:36.427, tt:291.420\n",
      "Ep:8, loss:0.00005, loss_test:0.02250, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:36.247, tt:326.219\n",
      "Ep:9, loss:0.00005, loss_test:0.02206, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:36.135, tt:361.347\n",
      "Ep:10, loss:0.00005, loss_test:0.02162, lr:6.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:35.948, tt:395.427\n",
      "Ep:11, loss:0.00005, loss_test:0.02111, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:35.805, tt:429.655\n",
      "Ep:12, loss:0.00004, loss_test:0.02058, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:35.623, tt:463.105\n",
      "Ep:13, loss:0.00004, loss_test:0.01997, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:35.532, tt:497.454\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01918, lr:6.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:35.462, tt:531.927\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01836, lr:6.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:35.387, tt:566.188\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01769, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:35.303, tt:600.154\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01718, lr:6.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:35.266, tt:634.780\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01676, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:35.178, tt:668.373\n",
      "Ep:19, loss:0.00004, loss_test:0.01634, lr:6.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:35.170, tt:703.393\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:35.155, tt:738.260\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:35.115, tt:772.532\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01522, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:35.069, tt:806.588\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:35.116, tt:842.794\n",
      "Ep:24, loss:0.00003, loss_test:0.01444, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:35.111, tt:877.765\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:35.088, tt:912.285\n",
      "Ep:26, loss:0.00003, loss_test:0.01381, lr:6.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:35.047, tt:946.262\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01353, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:35.057, tt:981.587\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:35.078, tt:1017.258\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:35.102, tt:1053.069\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:35.073, tt:1087.258\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:35.039, tt:1121.253\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:34.999, tt:1154.975\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01215, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:35.009, tt:1190.295\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01191, lr:6.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:34.977, tt:1224.206\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01187, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.080, tt:1262.872\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01152, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.060, tt:1297.237\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01143, lr:6.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:35.058, tt:1332.188\n",
      "Ep:38, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:35.042, tt:1366.629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00001, loss_test:0.01097, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.048, tt:1401.901\n",
      "Ep:40, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.003, tt:1435.135\n",
      "Ep:41, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:34.984, tt:1469.334\n",
      "Ep:42, loss:0.00001, loss_test:0.01053, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:34.941, tt:1502.442\n",
      "Ep:43, loss:0.00001, loss_test:0.01046, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:34.894, tt:1535.332\n",
      "Ep:44, loss:0.00001, loss_test:0.01029, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.888, tt:1569.972\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:34.881, tt:1604.528\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01019, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:34.822, tt:1636.618\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01029, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:34.809, tt:1670.846\n",
      "Ep:48, loss:0.00001, loss_test:0.01018, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:34.819, tt:1706.127\n",
      "Ep:49, loss:0.00001, loss_test:0.01022, lr:6.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:34.847, tt:1742.351\n",
      "Ep:50, loss:0.00001, loss_test:0.01021, lr:6.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:34.852, tt:1777.456\n",
      "Ep:51, loss:0.00001, loss_test:0.01034, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:34.833, tt:1811.324\n",
      "Ep:52, loss:0.00001, loss_test:0.01046, lr:6.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.811, tt:1844.965\n",
      "Ep:55, loss:0.00001, loss_test:0.01056, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.814, tt:1949.597\n",
      "Ep:56, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.824, tt:1984.943\n",
      "Ep:57, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.815, tt:2019.284\n",
      "Ep:58, loss:0.00001, loss_test:0.01088, lr:5.94e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.821, tt:2054.436\n",
      "Ep:59, loss:0.00001, loss_test:0.01100, lr:5.88e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.825, tt:2089.488\n",
      "Ep:60, loss:0.00001, loss_test:0.01099, lr:5.82e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.834, tt:2124.861\n",
      "Ep:61, loss:0.00001, loss_test:0.01104, lr:5.76e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.828, tt:2159.367\n",
      "Ep:62, loss:0.00001, loss_test:0.01108, lr:5.71e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.813, tt:2193.191\n",
      "Ep:63, loss:0.00001, loss_test:0.01129, lr:5.65e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.787, tt:2226.367\n",
      "Ep:64, loss:0.00001, loss_test:0.01119, lr:5.59e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.763, tt:2259.567\n",
      "Ep:65, loss:0.00000, loss_test:0.01127, lr:5.54e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.750, tt:2293.511\n",
      "Ep:66, loss:0.00000, loss_test:0.01142, lr:5.48e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.746, tt:2328.009\n",
      "Ep:67, loss:0.00000, loss_test:0.01144, lr:5.43e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.731, tt:2361.739\n",
      "Ep:68, loss:0.00000, loss_test:0.01149, lr:5.37e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.707, tt:2394.806\n",
      "Ep:69, loss:0.00000, loss_test:0.01174, lr:5.32e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.720, tt:2430.397\n",
      "Ep:70, loss:0.00000, loss_test:0.01146, lr:5.27e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.719, tt:2465.016\n",
      "Ep:71, loss:0.00000, loss_test:0.01179, lr:5.21e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.743, tt:2501.464\n",
      "Ep:72, loss:0.00000, loss_test:0.01173, lr:5.16e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.734, tt:2535.558\n",
      "Ep:73, loss:0.00000, loss_test:0.01176, lr:5.11e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.745, tt:2571.094\n",
      "Ep:74, loss:0.00000, loss_test:0.01177, lr:5.06e-02, fs:0.89005 (r=0.859,p=0.924),  time:34.749, tt:2606.174\n",
      "Ep:75, loss:0.00000, loss_test:0.01189, lr:5.01e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.758, tt:2641.634\n",
      "Ep:76, loss:0.00000, loss_test:0.01186, lr:4.96e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.767, tt:2677.064\n",
      "Ep:77, loss:0.00000, loss_test:0.01191, lr:4.91e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.772, tt:2712.188\n",
      "Ep:78, loss:0.00000, loss_test:0.01190, lr:4.86e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.791, tt:2748.479\n",
      "Ep:79, loss:0.00000, loss_test:0.01219, lr:4.81e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.796, tt:2783.659\n",
      "Ep:80, loss:0.00000, loss_test:0.01194, lr:4.76e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.783, tt:2817.395\n",
      "Ep:81, loss:0.00000, loss_test:0.01233, lr:4.71e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.791, tt:2852.836\n",
      "Ep:82, loss:0.00000, loss_test:0.01203, lr:4.67e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.788, tt:2887.427\n",
      "Ep:83, loss:0.00000, loss_test:0.01229, lr:4.62e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.789, tt:2922.288\n",
      "Ep:84, loss:0.00000, loss_test:0.01205, lr:4.57e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.779, tt:2956.176\n",
      "Ep:85, loss:0.00000, loss_test:0.01245, lr:4.53e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.763, tt:2989.654\n",
      "Ep:86, loss:0.00000, loss_test:0.01217, lr:4.48e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.759, tt:3024.074\n",
      "Ep:87, loss:0.00000, loss_test:0.01242, lr:4.44e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.743, tt:3057.394\n",
      "Ep:88, loss:0.00000, loss_test:0.01244, lr:4.39e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.736, tt:3091.499\n",
      "Ep:89, loss:0.00000, loss_test:0.01242, lr:4.35e-02, fs:0.90426 (r=0.859,p=0.955),  time:34.724, tt:3125.169\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00000, loss_test:0.01243, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.720, tt:3159.478\n",
      "Ep:91, loss:0.00000, loss_test:0.01272, lr:4.35e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.715, tt:3193.778\n",
      "Ep:92, loss:0.00000, loss_test:0.01244, lr:4.35e-02, fs:0.88770 (r=0.838,p=0.943),  time:34.712, tt:3228.197\n",
      "Ep:93, loss:0.00000, loss_test:0.01277, lr:4.35e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.709, tt:3262.666\n",
      "Ep:94, loss:0.00000, loss_test:0.01258, lr:4.35e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.710, tt:3297.465\n",
      "Ep:95, loss:0.00000, loss_test:0.01265, lr:4.35e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.703, tt:3331.526\n",
      "Ep:96, loss:0.00000, loss_test:0.01280, lr:4.35e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.698, tt:3365.718\n",
      "Ep:97, loss:0.00000, loss_test:0.01266, lr:4.35e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.703, tt:3400.930\n",
      "Ep:98, loss:0.00000, loss_test:0.01278, lr:4.35e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.690, tt:3434.316\n",
      "Ep:99, loss:0.00000, loss_test:0.01274, lr:4.35e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.684, tt:3468.422\n",
      "Ep:100, loss:0.00000, loss_test:0.01284, lr:4.35e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.687, tt:3503.363\n",
      "Ep:101, loss:0.00000, loss_test:0.01291, lr:4.31e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.684, tt:3537.805\n",
      "Ep:102, loss:0.00000, loss_test:0.01291, lr:4.26e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.674, tt:3571.439\n",
      "Ep:103, loss:0.00000, loss_test:0.01291, lr:4.22e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.645, tt:3603.063\n",
      "Ep:104, loss:0.00000, loss_test:0.01297, lr:4.18e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.564, tt:3629.212\n",
      "Ep:105, loss:0.00000, loss_test:0.01290, lr:4.14e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.491, tt:3656.017\n",
      "Ep:106, loss:0.00000, loss_test:0.01307, lr:4.10e-02, fs:0.84270 (r=0.758,p=0.949),  time:34.440, tt:3685.109\n",
      "Ep:107, loss:0.00000, loss_test:0.01305, lr:4.05e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.377, tt:3712.668\n",
      "Ep:108, loss:0.00000, loss_test:0.01304, lr:4.01e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.309, tt:3739.652\n",
      "Ep:109, loss:0.00000, loss_test:0.01317, lr:3.97e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.264, tt:3769.020\n",
      "Ep:110, loss:0.00000, loss_test:0.01305, lr:3.93e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.223, tt:3798.763\n",
      "Ep:111, loss:0.00000, loss_test:0.01307, lr:3.89e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.226, tt:3833.345\n",
      "Ep:112, loss:0.00000, loss_test:0.01328, lr:3.86e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.234, tt:3868.451\n",
      "Ep:113, loss:0.00000, loss_test:0.01313, lr:3.82e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.252, tt:3904.692\n",
      "Ep:114, loss:0.00000, loss_test:0.01325, lr:3.78e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.260, tt:3939.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00000, loss_test:0.01332, lr:3.74e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.267, tt:3974.995\n",
      "Ep:116, loss:0.00000, loss_test:0.01334, lr:3.70e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.278, tt:4010.575\n",
      "Ep:117, loss:0.00000, loss_test:0.01332, lr:3.67e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.285, tt:4045.642\n",
      "Ep:118, loss:0.00000, loss_test:0.01337, lr:3.63e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.297, tt:4081.370\n",
      "Ep:119, loss:0.00000, loss_test:0.01333, lr:3.59e-02, fs:0.82955 (r=0.737,p=0.948),  time:34.300, tt:4115.964\n",
      "Ep:120, loss:0.00000, loss_test:0.01345, lr:3.56e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.317, tt:4152.354\n",
      "Ep:121, loss:0.00000, loss_test:0.01338, lr:3.52e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.311, tt:4185.922\n",
      "Ep:122, loss:0.00000, loss_test:0.01353, lr:3.49e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.320, tt:4221.308\n",
      "Ep:123, loss:0.00000, loss_test:0.01348, lr:3.45e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.327, tt:4256.513\n",
      "Ep:124, loss:0.00000, loss_test:0.01350, lr:3.42e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.339, tt:4292.403\n",
      "Ep:125, loss:0.00000, loss_test:0.01359, lr:3.38e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.348, tt:4327.875\n",
      "Ep:126, loss:0.00000, loss_test:0.01357, lr:3.35e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.360, tt:4363.703\n",
      "Ep:127, loss:0.00000, loss_test:0.01359, lr:3.32e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.366, tt:4398.907\n",
      "Ep:128, loss:0.00000, loss_test:0.01362, lr:3.28e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.374, tt:4434.243\n",
      "Ep:129, loss:0.00000, loss_test:0.01373, lr:3.25e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.388, tt:4470.411\n",
      "Ep:130, loss:0.00000, loss_test:0.01365, lr:3.22e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.391, tt:4505.180\n",
      "Ep:131, loss:0.00000, loss_test:0.01369, lr:3.19e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.388, tt:4539.272\n",
      "Ep:132, loss:0.00000, loss_test:0.01373, lr:3.15e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.389, tt:4573.733\n",
      "Ep:133, loss:0.00000, loss_test:0.01379, lr:3.12e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.399, tt:4609.530\n",
      "Ep:134, loss:0.00000, loss_test:0.01371, lr:3.09e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.419, tt:4646.590\n",
      "Ep:135, loss:0.00000, loss_test:0.01384, lr:3.06e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.428, tt:4682.220\n",
      "Ep:136, loss:0.00000, loss_test:0.01380, lr:3.03e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.443, tt:4718.645\n",
      "Ep:137, loss:0.00000, loss_test:0.01384, lr:3.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.450, tt:4754.111\n",
      "Ep:138, loss:0.00000, loss_test:0.01391, lr:2.97e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.458, tt:4789.616\n",
      "Ep:139, loss:0.00000, loss_test:0.01383, lr:2.94e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.472, tt:4826.134\n",
      "Ep:140, loss:0.00000, loss_test:0.01387, lr:2.91e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.479, tt:4861.489\n",
      "Ep:141, loss:0.00000, loss_test:0.01391, lr:2.88e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.480, tt:4896.190\n",
      "Ep:142, loss:0.00000, loss_test:0.01393, lr:2.85e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.482, tt:4930.902\n",
      "Ep:143, loss:0.00000, loss_test:0.01396, lr:2.82e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.491, tt:4966.634\n",
      "Ep:144, loss:0.00000, loss_test:0.01395, lr:2.80e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.487, tt:5000.601\n",
      "Ep:145, loss:0.00000, loss_test:0.01394, lr:2.77e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.495, tt:5036.327\n",
      "Ep:146, loss:0.00000, loss_test:0.01400, lr:2.74e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.496, tt:5070.916\n",
      "Ep:147, loss:0.00000, loss_test:0.01400, lr:2.71e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.497, tt:5105.540\n",
      "Ep:148, loss:0.00000, loss_test:0.01399, lr:2.69e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.509, tt:5141.887\n",
      "Ep:149, loss:0.00000, loss_test:0.01408, lr:2.66e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.516, tt:5177.420\n",
      "Ep:150, loss:0.00000, loss_test:0.01402, lr:2.63e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.525, tt:5213.292\n",
      "Ep:151, loss:0.00000, loss_test:0.01409, lr:2.61e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.531, tt:5248.775\n",
      "Ep:152, loss:0.00000, loss_test:0.01407, lr:2.58e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.529, tt:5282.988\n",
      "Ep:153, loss:0.00000, loss_test:0.01407, lr:2.55e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.524, tt:5316.711\n",
      "Ep:154, loss:0.00000, loss_test:0.01413, lr:2.53e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.533, tt:5352.655\n",
      "Ep:155, loss:0.00000, loss_test:0.01410, lr:2.50e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.540, tt:5388.247\n",
      "Ep:156, loss:0.00000, loss_test:0.01415, lr:2.48e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.541, tt:5422.926\n",
      "Ep:157, loss:0.00000, loss_test:0.01415, lr:2.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.546, tt:5458.298\n",
      "Ep:158, loss:0.00000, loss_test:0.01413, lr:2.43e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.551, tt:5493.570\n",
      "Ep:159, loss:0.00000, loss_test:0.01420, lr:2.40e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.552, tt:5528.296\n",
      "Ep:160, loss:0.00000, loss_test:0.01417, lr:2.38e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.558, tt:5563.872\n",
      "Ep:161, loss:0.00000, loss_test:0.01421, lr:2.36e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.568, tt:5599.936\n",
      "Ep:162, loss:0.00000, loss_test:0.01421, lr:2.33e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.566, tt:5634.201\n",
      "Ep:163, loss:0.00000, loss_test:0.01420, lr:2.31e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.582, tt:5671.431\n",
      "Ep:164, loss:0.00000, loss_test:0.01424, lr:2.29e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.581, tt:5705.819\n",
      "Ep:165, loss:0.00000, loss_test:0.01424, lr:2.26e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.587, tt:5741.456\n",
      "Ep:166, loss:0.00000, loss_test:0.01428, lr:2.24e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.590, tt:5776.472\n",
      "Ep:167, loss:0.00000, loss_test:0.01421, lr:2.22e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.588, tt:5810.813\n",
      "Ep:168, loss:0.00000, loss_test:0.01425, lr:2.20e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.586, tt:5844.979\n",
      "Ep:169, loss:0.00000, loss_test:0.01434, lr:2.17e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.586, tt:5879.546\n",
      "Ep:170, loss:0.00000, loss_test:0.01427, lr:2.15e-02, fs:0.84091 (r=0.747,p=0.961),  time:34.588, tt:5914.627\n",
      "Ep:171, loss:0.00000, loss_test:0.01430, lr:2.13e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.595, tt:5950.300\n",
      "Ep:172, loss:0.00000, loss_test:0.01430, lr:2.11e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.601, tt:5985.988\n",
      "Ep:173, loss:0.00000, loss_test:0.01430, lr:2.09e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.594, tt:6019.412\n",
      "Ep:174, loss:0.00000, loss_test:0.01434, lr:2.07e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.600, tt:6054.948\n",
      "Ep:175, loss:0.00000, loss_test:0.01430, lr:2.05e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.598, tt:6089.166\n",
      "Ep:176, loss:0.00000, loss_test:0.01436, lr:2.03e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.605, tt:6125.050\n",
      "Ep:177, loss:0.00000, loss_test:0.01434, lr:2.01e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.609, tt:6160.439\n",
      "Ep:178, loss:0.00000, loss_test:0.01435, lr:1.99e-02, fs:0.84746 (r=0.758,p=0.962),  time:34.626, tt:6198.002\n",
      "Ep:179, loss:0.00000, loss_test:0.01439, lr:1.97e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.628, tt:6232.983\n",
      "Ep:180, loss:0.00000, loss_test:0.01435, lr:1.95e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.632, tt:6268.410\n",
      "Ep:181, loss:0.00000, loss_test:0.01436, lr:1.93e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.641, tt:6304.654\n",
      "Ep:182, loss:0.00000, loss_test:0.01440, lr:1.91e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.650, tt:6340.909\n",
      "Ep:183, loss:0.00000, loss_test:0.01439, lr:1.89e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.653, tt:6376.179\n",
      "Ep:184, loss:0.00000, loss_test:0.01438, lr:1.87e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.651, tt:6410.508\n",
      "Ep:185, loss:0.00000, loss_test:0.01442, lr:1.85e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.646, tt:6444.228\n",
      "Ep:186, loss:0.00000, loss_test:0.01439, lr:1.83e-02, fs:0.84746 (r=0.758,p=0.962),  time:34.653, tt:6480.160\n",
      "Ep:187, loss:0.00000, loss_test:0.01441, lr:1.81e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.660, tt:6516.104\n",
      "Ep:188, loss:0.00000, loss_test:0.01442, lr:1.80e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.660, tt:6550.695\n",
      "Ep:189, loss:0.00000, loss_test:0.01443, lr:1.78e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.659, tt:6585.163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.01444, lr:1.76e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.650, tt:6618.120\n",
      "Ep:191, loss:0.00000, loss_test:0.01445, lr:1.74e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.641, tt:6651.062\n",
      "Ep:192, loss:0.00000, loss_test:0.01444, lr:1.73e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.645, tt:6686.389\n",
      "Ep:193, loss:0.00000, loss_test:0.01444, lr:1.71e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.656, tt:6723.269\n",
      "Ep:194, loss:0.00000, loss_test:0.01446, lr:1.69e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.662, tt:6759.077\n",
      "Ep:195, loss:0.00000, loss_test:0.01445, lr:1.67e-02, fs:0.84746 (r=0.758,p=0.962),  time:34.658, tt:6793.037\n",
      "Ep:196, loss:0.00000, loss_test:0.01445, lr:1.66e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.661, tt:6828.297\n",
      "Ep:197, loss:0.00000, loss_test:0.01447, lr:1.64e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.666, tt:6863.877\n",
      "Ep:198, loss:0.00000, loss_test:0.01446, lr:1.62e-02, fs:0.84746 (r=0.758,p=0.962),  time:34.672, tt:6899.638\n",
      "Ep:199, loss:0.00000, loss_test:0.01448, lr:1.61e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.679, tt:6935.808\n",
      "Ep:200, loss:0.00000, loss_test:0.01449, lr:1.59e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.675, tt:6969.715\n",
      "Ep:201, loss:0.00000, loss_test:0.01449, lr:1.58e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.679, tt:7005.087\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13512, lr:1.00e-02, fs:0.65613 (r=0.838,p=0.539),  time:37.088, tt:37.088\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13152, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:35.214, tt:70.429\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12746, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:35.330, tt:105.990\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12451, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:35.784, tt:143.136\n",
      "Ep:4, loss:0.00026, loss_test:0.12283, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:36.122, tt:180.611\n",
      "Ep:5, loss:0.00026, loss_test:0.12213, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:36.149, tt:216.892\n",
      "Ep:6, loss:0.00026, loss_test:0.12165, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:36.163, tt:253.140\n",
      "Ep:7, loss:0.00026, loss_test:0.12137, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:35.826, tt:286.608\n",
      "Ep:8, loss:0.00026, loss_test:0.12099, lr:1.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:35.935, tt:323.412\n",
      "Ep:9, loss:0.00025, loss_test:0.12045, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:36.026, tt:360.263\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.11985, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:35.777, tt:393.544\n",
      "Ep:11, loss:0.00025, loss_test:0.11942, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:35.877, tt:430.530\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.11886, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:35.905, tt:466.763\n",
      "Ep:13, loss:0.00025, loss_test:0.11821, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:35.950, tt:503.302\n",
      "Ep:14, loss:0.00025, loss_test:0.11741, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:35.910, tt:538.651\n",
      "Ep:15, loss:0.00025, loss_test:0.11658, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:35.894, tt:574.308\n",
      "Ep:16, loss:0.00024, loss_test:0.11570, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:35.891, tt:610.139\n",
      "Ep:17, loss:0.00024, loss_test:0.11480, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:35.907, tt:646.323\n",
      "Ep:18, loss:0.00024, loss_test:0.11381, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:35.987, tt:683.752\n",
      "Ep:19, loss:0.00024, loss_test:0.11250, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:35.946, tt:718.911\n",
      "Ep:20, loss:0.00023, loss_test:0.11083, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:35.917, tt:754.249\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.10893, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:35.891, tt:789.599\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.10647, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:35.918, tt:826.122\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00022, loss_test:0.10378, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:35.950, tt:862.800\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00022, loss_test:0.10087, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:35.971, tt:899.285\n",
      "Ep:25, loss:0.00021, loss_test:0.09768, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:36.033, tt:936.860\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00021, loss_test:0.09433, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:35.947, tt:970.580\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.09030, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:35.981, tt:1007.479\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.08677, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:35.989, tt:1043.685\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00019, loss_test:0.08398, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:36.009, tt:1080.279\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00018, loss_test:0.08223, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:36.175, tt:1121.425\n",
      "Ep:31, loss:0.00017, loss_test:0.08028, lr:1.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:36.141, tt:1156.525\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.07845, lr:1.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:36.134, tt:1192.412\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.07719, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:36.105, tt:1227.586\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.07539, lr:1.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:36.129, tt:1264.502\n",
      "Ep:35, loss:0.00014, loss_test:0.07329, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:36.088, tt:1299.150\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.07116, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:36.073, tt:1334.716\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.06993, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:36.071, tt:1370.680\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.06546, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:36.039, tt:1405.537\n",
      "Ep:39, loss:0.00011, loss_test:0.06447, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:36.051, tt:1442.030\n",
      "Ep:40, loss:0.00010, loss_test:0.06214, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:35.993, tt:1475.728\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.06274, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.981, tt:1511.220\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.05921, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.993, tt:1547.710\n",
      "Ep:43, loss:0.00008, loss_test:0.06015, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:35.991, tt:1583.605\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.05769, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:35.977, tt:1618.960\n",
      "Ep:45, loss:0.00007, loss_test:0.05583, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:35.985, tt:1655.312\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.05368, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.971, tt:1690.625\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.05539, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:35.967, tt:1726.395\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.05235, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.988, tt:1763.418\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00005, loss_test:0.05076, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.966, tt:1798.279\n",
      "Ep:50, loss:0.00005, loss_test:0.05586, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:35.976, tt:1834.775\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00005, loss_test:0.04938, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:36.058, tt:1874.995\n",
      "Ep:52, loss:0.00005, loss_test:0.05117, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:36.052, tt:1910.749\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.05467, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:36.044, tt:1946.391\n",
      "Ep:54, loss:0.00004, loss_test:0.04724, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:36.034, tt:1981.879\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.05182, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:36.042, tt:2018.365\n",
      "Ep:56, loss:0.00004, loss_test:0.04828, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:36.042, tt:2054.380\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.05080, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:36.066, tt:2091.808\n",
      "Ep:58, loss:0.00003, loss_test:0.04709, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:36.058, tt:2127.440\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.04961, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:36.067, tt:2164.018\n",
      "Ep:60, loss:0.00003, loss_test:0.04833, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:36.045, tt:2198.722\n",
      "Ep:61, loss:0.00003, loss_test:0.05003, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:36.057, tt:2235.540\n",
      "Ep:62, loss:0.00003, loss_test:0.04622, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:36.044, tt:2270.770\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.05005, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:36.032, tt:2306.073\n",
      "Ep:64, loss:0.00002, loss_test:0.04410, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:36.029, tt:2341.861\n",
      "Ep:65, loss:0.00002, loss_test:0.04887, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:36.033, tt:2378.160\n",
      "Ep:66, loss:0.00002, loss_test:0.04492, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:36.051, tt:2415.420\n",
      "Ep:67, loss:0.00002, loss_test:0.04614, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:36.030, tt:2450.009\n",
      "Ep:68, loss:0.00002, loss_test:0.04909, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.997, tt:2483.769\n",
      "Ep:69, loss:0.00002, loss_test:0.05025, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:36.011, tt:2520.798\n",
      "Ep:70, loss:0.00002, loss_test:0.04549, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:35.973, tt:2554.061\n",
      "Ep:71, loss:0.00002, loss_test:0.05016, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.950, tt:2588.409\n",
      "Ep:72, loss:0.00002, loss_test:0.04797, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.939, tt:2623.562\n",
      "Ep:73, loss:0.00002, loss_test:0.04528, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:35.865, tt:2654.041\n",
      "Ep:74, loss:0.00002, loss_test:0.04442, lr:9.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.812, tt:2685.921\n",
      "Ep:75, loss:0.00002, loss_test:0.04250, lr:9.80e-03, fs:0.90355 (r=0.899,p=0.908),  time:35.714, tt:2714.240\n",
      "Ep:76, loss:0.00002, loss_test:0.04466, lr:9.70e-03, fs:0.90256 (r=0.889,p=0.917),  time:35.663, tt:2746.036\n",
      "Ep:77, loss:0.00002, loss_test:0.04467, lr:9.61e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.676, tt:2782.760\n",
      "Ep:78, loss:0.00001, loss_test:0.04915, lr:9.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.661, tt:2817.249\n",
      "Ep:79, loss:0.00001, loss_test:0.04036, lr:9.41e-03, fs:0.92308 (r=0.909,p=0.938),  time:35.663, tt:2853.065\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.04718, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.712, tt:2892.691\n",
      "Ep:81, loss:0.00001, loss_test:0.04531, lr:9.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.730, tt:2929.882\n",
      "Ep:82, loss:0.00001, loss_test:0.04307, lr:9.41e-03, fs:0.90816 (r=0.899,p=0.918),  time:35.741, tt:2966.511\n",
      "Ep:83, loss:0.00001, loss_test:0.04388, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.753, tt:3003.273\n",
      "Ep:84, loss:0.00001, loss_test:0.04576, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.766, tt:3040.070\n",
      "Ep:85, loss:0.00001, loss_test:0.04155, lr:9.41e-03, fs:0.91837 (r=0.909,p=0.928),  time:35.763, tt:3075.585\n",
      "Ep:86, loss:0.00001, loss_test:0.04186, lr:9.41e-03, fs:0.90722 (r=0.889,p=0.926),  time:35.776, tt:3112.485\n",
      "Ep:87, loss:0.00001, loss_test:0.04331, lr:9.41e-03, fs:0.85561 (r=0.808,p=0.909),  time:35.787, tt:3149.293\n",
      "Ep:88, loss:0.00001, loss_test:0.04174, lr:9.41e-03, fs:0.92308 (r=0.909,p=0.938),  time:35.790, tt:3185.297\n",
      "Ep:89, loss:0.00001, loss_test:0.04535, lr:9.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:35.793, tt:3221.338\n",
      "Ep:90, loss:0.00001, loss_test:0.04083, lr:9.41e-03, fs:0.91192 (r=0.889,p=0.936),  time:35.801, tt:3257.881\n",
      "Ep:91, loss:0.00001, loss_test:0.04374, lr:9.32e-03, fs:0.90722 (r=0.889,p=0.926),  time:35.801, tt:3293.666\n",
      "Ep:92, loss:0.00001, loss_test:0.04134, lr:9.23e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.790, tt:3328.509\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.04316, lr:9.23e-03, fs:0.85870 (r=0.798,p=0.929),  time:35.785, tt:3363.808\n",
      "Ep:94, loss:0.00001, loss_test:0.04234, lr:9.23e-03, fs:0.90323 (r=0.848,p=0.966),  time:35.782, tt:3399.271\n",
      "Ep:95, loss:0.00001, loss_test:0.04129, lr:9.23e-03, fs:0.92784 (r=0.909,p=0.947),  time:35.777, tt:3434.594\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.04257, lr:9.23e-03, fs:0.88542 (r=0.859,p=0.914),  time:35.781, tt:3470.776\n",
      "Ep:97, loss:0.00001, loss_test:0.04148, lr:9.23e-03, fs:0.88649 (r=0.828,p=0.953),  time:35.780, tt:3506.433\n",
      "Ep:98, loss:0.00001, loss_test:0.04495, lr:9.23e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.781, tt:3542.294\n",
      "Ep:99, loss:0.00001, loss_test:0.04252, lr:9.23e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.781, tt:3578.057\n",
      "Ep:100, loss:0.00001, loss_test:0.04259, lr:9.23e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.776, tt:3613.388\n",
      "Ep:101, loss:0.00001, loss_test:0.04398, lr:9.23e-03, fs:0.88172 (r=0.828,p=0.943),  time:35.788, tt:3650.356\n",
      "Ep:102, loss:0.00001, loss_test:0.04225, lr:9.23e-03, fs:0.87778 (r=0.798,p=0.975),  time:35.788, tt:3686.119\n",
      "Ep:103, loss:0.00001, loss_test:0.04875, lr:9.23e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.785, tt:3721.679\n",
      "Ep:104, loss:0.00001, loss_test:0.04076, lr:9.23e-03, fs:0.90323 (r=0.848,p=0.966),  time:35.810, tt:3760.056\n",
      "Ep:105, loss:0.00001, loss_test:0.04694, lr:9.23e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.806, tt:3795.474\n",
      "Ep:106, loss:0.00001, loss_test:0.04369, lr:9.23e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.810, tt:3831.662\n",
      "Ep:107, loss:0.00001, loss_test:0.04559, lr:9.14e-03, fs:0.85714 (r=0.788,p=0.940),  time:35.818, tt:3868.345\n",
      "Ep:108, loss:0.00001, loss_test:0.03905, lr:9.04e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.806, tt:3902.835\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.04496, lr:9.04e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.799, tt:3937.906\n",
      "Ep:110, loss:0.00000, loss_test:0.04013, lr:9.04e-03, fs:0.93122 (r=0.889,p=0.978),  time:35.802, tt:3974.033\n",
      "Ep:111, loss:0.00000, loss_test:0.04545, lr:9.04e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.806, tt:4010.298\n",
      "Ep:112, loss:0.00000, loss_test:0.04164, lr:9.04e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.811, tt:4046.678\n",
      "Ep:113, loss:0.00000, loss_test:0.04428, lr:9.04e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.813, tt:4082.699\n",
      "Ep:114, loss:0.00000, loss_test:0.04106, lr:9.04e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.814, tt:4118.618\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00000, loss_test:0.04443, lr:9.04e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.828, tt:4156.010\n",
      "Ep:116, loss:0.00000, loss_test:0.04037, lr:9.04e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.823, tt:4191.314\n",
      "Ep:117, loss:0.00000, loss_test:0.04619, lr:9.04e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.833, tt:4228.291\n",
      "Ep:118, loss:0.00000, loss_test:0.04338, lr:9.04e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.836, tt:4264.507\n",
      "Ep:119, loss:0.00000, loss_test:0.04622, lr:9.04e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.835, tt:4300.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00000, loss_test:0.04200, lr:9.04e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.841, tt:4336.772\n",
      "Ep:121, loss:0.00000, loss_test:0.04116, lr:9.04e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.840, tt:4372.441\n",
      "Ep:122, loss:0.00000, loss_test:0.04313, lr:9.04e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.844, tt:4408.858\n",
      "Ep:123, loss:0.00000, loss_test:0.04164, lr:9.04e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.852, tt:4445.689\n",
      "Ep:124, loss:0.00000, loss_test:0.04411, lr:9.04e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.847, tt:4480.840\n",
      "Ep:125, loss:0.00000, loss_test:0.04186, lr:9.04e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.843, tt:4516.273\n",
      "Ep:126, loss:0.00000, loss_test:0.04336, lr:8.95e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.848, tt:4552.752\n",
      "Ep:127, loss:0.00000, loss_test:0.04180, lr:8.86e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.850, tt:4588.850\n",
      "Ep:128, loss:0.00000, loss_test:0.04108, lr:8.78e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.854, tt:4625.155\n",
      "Ep:129, loss:0.00000, loss_test:0.04340, lr:8.69e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.859, tt:4661.642\n",
      "Ep:130, loss:0.00000, loss_test:0.04101, lr:8.60e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.852, tt:4696.662\n",
      "Ep:131, loss:0.00000, loss_test:0.04238, lr:8.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.851, tt:4732.308\n",
      "Ep:132, loss:0.00000, loss_test:0.04124, lr:8.43e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.861, tt:4769.552\n",
      "Ep:133, loss:0.00000, loss_test:0.04256, lr:8.35e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.871, tt:4806.708\n",
      "Ep:134, loss:0.00000, loss_test:0.04170, lr:8.26e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.856, tt:4840.621\n",
      "Ep:135, loss:0.00000, loss_test:0.04096, lr:8.18e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.860, tt:4876.961\n",
      "Ep:136, loss:0.00000, loss_test:0.04205, lr:8.10e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.845, tt:4910.737\n",
      "Ep:137, loss:0.00000, loss_test:0.04119, lr:8.02e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.868, tt:4949.726\n",
      "Ep:138, loss:0.00000, loss_test:0.04133, lr:7.94e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.882, tt:4987.613\n",
      "Ep:139, loss:0.00000, loss_test:0.04154, lr:7.86e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.893, tt:5024.992\n",
      "Ep:140, loss:0.00000, loss_test:0.04118, lr:7.78e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.898, tt:5061.628\n",
      "Ep:141, loss:0.00000, loss_test:0.04129, lr:7.70e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.889, tt:5096.247\n",
      "Ep:142, loss:0.00000, loss_test:0.04068, lr:7.62e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.882, tt:5131.071\n",
      "Ep:143, loss:0.00000, loss_test:0.04030, lr:7.55e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.883, tt:5167.084\n",
      "Ep:144, loss:0.00000, loss_test:0.04178, lr:7.47e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.876, tt:5202.056\n",
      "Ep:145, loss:0.00000, loss_test:0.04131, lr:7.40e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.883, tt:5238.847\n",
      "Ep:146, loss:0.00000, loss_test:0.04070, lr:7.32e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.887, tt:5275.400\n",
      "Ep:147, loss:0.00000, loss_test:0.04128, lr:7.25e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.876, tt:5309.704\n",
      "Ep:148, loss:0.00000, loss_test:0.04135, lr:7.18e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.876, tt:5345.571\n",
      "Ep:149, loss:0.00000, loss_test:0.04100, lr:7.11e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.873, tt:5380.879\n",
      "Ep:150, loss:0.00000, loss_test:0.04068, lr:7.03e-03, fs:0.92063 (r=0.879,p=0.967),  time:35.864, tt:5415.493\n",
      "Ep:151, loss:0.00000, loss_test:0.04067, lr:6.96e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.864, tt:5451.325\n",
      "Ep:152, loss:0.00000, loss_test:0.04054, lr:6.89e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.859, tt:5486.371\n",
      "Ep:153, loss:0.00000, loss_test:0.04136, lr:6.83e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.857, tt:5521.932\n",
      "Ep:154, loss:0.00000, loss_test:0.04099, lr:6.76e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.867, tt:5559.440\n",
      "Ep:155, loss:0.00000, loss_test:0.04068, lr:6.69e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.865, tt:5594.896\n",
      "Ep:156, loss:0.00000, loss_test:0.04080, lr:6.62e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.856, tt:5629.455\n",
      "Ep:157, loss:0.00000, loss_test:0.04070, lr:6.56e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.849, tt:5664.143\n",
      "Ep:158, loss:0.00000, loss_test:0.04111, lr:6.49e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.854, tt:5700.711\n",
      "Ep:159, loss:0.00000, loss_test:0.04105, lr:6.43e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.858, tt:5737.275\n",
      "Ep:160, loss:0.00000, loss_test:0.04044, lr:6.36e-03, fs:0.89130 (r=0.828,p=0.965),  time:35.869, tt:5774.852\n",
      "Ep:161, loss:0.00000, loss_test:0.04114, lr:6.30e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.886, tt:5813.523\n",
      "Ep:162, loss:0.00000, loss_test:0.04090, lr:6.24e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.883, tt:5848.887\n",
      "Ep:163, loss:0.00000, loss_test:0.04067, lr:6.17e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.885, tt:5885.162\n",
      "Ep:164, loss:0.00000, loss_test:0.04071, lr:6.11e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.885, tt:5921.077\n",
      "Ep:165, loss:0.00000, loss_test:0.04059, lr:6.05e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.885, tt:5956.978\n",
      "Ep:166, loss:0.00000, loss_test:0.04050, lr:5.99e-03, fs:0.91489 (r=0.869,p=0.966),  time:35.889, tt:5993.505\n",
      "Ep:167, loss:0.00000, loss_test:0.04050, lr:5.93e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.882, tt:6028.225\n",
      "Ep:168, loss:0.00000, loss_test:0.04188, lr:5.87e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.884, tt:6064.313\n",
      "Ep:169, loss:0.00000, loss_test:0.04119, lr:5.81e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.878, tt:6099.283\n",
      "Ep:170, loss:0.00000, loss_test:0.04088, lr:5.75e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.878, tt:6135.149\n",
      "Ep:171, loss:0.00000, loss_test:0.04059, lr:5.70e-03, fs:0.90323 (r=0.848,p=0.966),  time:35.873, tt:6170.070\n",
      "Ep:172, loss:0.00000, loss_test:0.04123, lr:5.64e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.878, tt:6206.948\n",
      "Ep:173, loss:0.00000, loss_test:0.04175, lr:5.58e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.874, tt:6242.092\n",
      "Ep:174, loss:0.00000, loss_test:0.04088, lr:5.53e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.879, tt:6278.819\n",
      "Ep:175, loss:0.00000, loss_test:0.04050, lr:5.47e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.873, tt:6313.634\n",
      "Ep:176, loss:0.00000, loss_test:0.04067, lr:5.42e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.874, tt:6349.708\n",
      "Ep:177, loss:0.00000, loss_test:0.04063, lr:5.36e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.877, tt:6386.131\n",
      "Ep:178, loss:0.00000, loss_test:0.04056, lr:5.31e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.888, tt:6423.962\n",
      "Ep:179, loss:0.00000, loss_test:0.04028, lr:5.26e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.879, tt:6458.296\n",
      "Ep:180, loss:0.00000, loss_test:0.04030, lr:5.20e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.903, tt:6498.529\n",
      "Ep:181, loss:0.00000, loss_test:0.04120, lr:5.15e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.899, tt:6533.693\n",
      "Ep:182, loss:0.00000, loss_test:0.04089, lr:5.10e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.885, tt:6567.034\n",
      "Ep:183, loss:0.00000, loss_test:0.04145, lr:5.05e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.891, tt:6603.862\n",
      "Ep:184, loss:0.00000, loss_test:0.04135, lr:5.00e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.885, tt:6638.814\n",
      "Ep:185, loss:0.00000, loss_test:0.04067, lr:4.95e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.882, tt:6674.133\n",
      "Ep:186, loss:0.00000, loss_test:0.04033, lr:4.90e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.884, tt:6710.225\n",
      "Ep:187, loss:0.00000, loss_test:0.04052, lr:4.85e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.875, tt:6744.584\n",
      "Ep:188, loss:0.00000, loss_test:0.04084, lr:4.80e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.864, tt:6778.390\n",
      "Ep:189, loss:0.00000, loss_test:0.04141, lr:4.75e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.866, tt:6814.555\n",
      "Ep:190, loss:0.00000, loss_test:0.04168, lr:4.71e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.870, tt:6851.221\n",
      "Ep:191, loss:0.00000, loss_test:0.04089, lr:4.66e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.869, tt:6886.914\n",
      "Ep:192, loss:0.00000, loss_test:0.04071, lr:4.61e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.869, tt:6922.626\n",
      "Ep:193, loss:0.00000, loss_test:0.04073, lr:4.57e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.863, tt:6957.374\n",
      "Ep:194, loss:0.00000, loss_test:0.04031, lr:4.52e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.859, tt:6992.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00000, loss_test:0.04024, lr:4.48e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.854, tt:7027.455\n",
      "Ep:196, loss:0.00000, loss_test:0.04029, lr:4.43e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.861, tt:7064.556\n",
      "Ep:197, loss:0.00000, loss_test:0.04107, lr:4.39e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.859, tt:7100.045\n",
      "Ep:198, loss:0.00000, loss_test:0.04133, lr:4.34e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.868, tt:7137.643\n",
      "Ep:199, loss:0.00000, loss_test:0.04084, lr:4.30e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.868, tt:7173.515\n",
      "Ep:200, loss:0.00000, loss_test:0.04058, lr:4.26e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.869, tt:7209.615\n",
      "Ep:201, loss:0.00000, loss_test:0.04056, lr:4.21e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.873, tt:7246.403\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.03079, lr:6.00e-02, fs:0.61765 (r=0.636,p=0.600),  time:29.047, tt:29.047\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02225, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:28.953, tt:57.907\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02332, lr:6.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:28.705, tt:86.115\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02338, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:28.502, tt:114.008\n",
      "Ep:4, loss:0.00005, loss_test:0.02302, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:28.555, tt:142.777\n",
      "Ep:5, loss:0.00005, loss_test:0.02275, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:28.580, tt:171.478\n",
      "Ep:6, loss:0.00005, loss_test:0.02259, lr:6.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:28.605, tt:200.232\n",
      "Ep:7, loss:0.00005, loss_test:0.02224, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:28.709, tt:229.671\n",
      "Ep:8, loss:0.00005, loss_test:0.02160, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:28.779, tt:259.013\n",
      "Ep:9, loss:0.00005, loss_test:0.02078, lr:6.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:28.917, tt:289.174\n",
      "Ep:10, loss:0.00004, loss_test:0.02005, lr:6.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:29.138, tt:320.514\n",
      "Ep:11, loss:0.00004, loss_test:0.01949, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:29.321, tt:351.850\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:29.354, tt:381.607\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01890, lr:6.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:29.461, tt:412.448\n",
      "Ep:14, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:29.379, tt:440.680\n",
      "Ep:15, loss:0.00004, loss_test:0.01845, lr:6.00e-02, fs:0.68936 (r=0.818,p=0.596),  time:29.381, tt:470.092\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01828, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:29.403, tt:499.849\n",
      "Ep:17, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:29.585, tt:532.538\n",
      "Ep:18, loss:0.00004, loss_test:0.01806, lr:6.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:29.578, tt:561.988\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01800, lr:6.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:29.591, tt:591.827\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01789, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:29.613, tt:621.863\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01781, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:29.601, tt:651.214\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01775, lr:6.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:29.610, tt:681.021\n",
      "Ep:23, loss:0.00004, loss_test:0.01768, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:29.680, tt:712.325\n",
      "Ep:24, loss:0.00004, loss_test:0.01760, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:29.735, tt:743.365\n",
      "Ep:25, loss:0.00004, loss_test:0.01749, lr:6.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:29.767, tt:773.955\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01739, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:29.825, tt:805.263\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01726, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:29.838, tt:835.461\n",
      "Ep:28, loss:0.00004, loss_test:0.01717, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:29.874, tt:866.345\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01711, lr:6.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:29.871, tt:896.142\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.01696, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:29.872, tt:926.018\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:29.884, tt:956.277\n",
      "Ep:32, loss:0.00003, loss_test:0.01668, lr:6.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:29.897, tt:986.603\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:29.873, tt:1015.668\n",
      "Ep:34, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.74894 (r=0.889,p=0.647),  time:29.843, tt:1044.500\n",
      "Ep:35, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:29.833, tt:1073.976\n",
      "Ep:36, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:29.764, tt:1101.266\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01575, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.769, tt:1131.216\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01553, lr:6.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:29.746, tt:1160.097\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01530, lr:6.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:29.707, tt:1188.292\n",
      "Ep:40, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:29.675, tt:1216.672\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01491, lr:6.00e-02, fs:0.77119 (r=0.919,p=0.664),  time:29.660, tt:1245.713\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:29.626, tt:1273.925\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01454, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:29.606, tt:1302.650\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01432, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:29.617, tt:1332.746\n",
      "Ep:45, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:29.595, tt:1361.390\n",
      "Ep:46, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:29.621, tt:1392.186\n",
      "Ep:47, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:29.548, tt:1418.288\n",
      "Ep:48, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:29.476, tt:1444.315\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.328, tt:1466.379\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:29.204, tt:1489.389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:29.016, tt:1508.818\n",
      "Ep:52, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:28.890, tt:1531.189\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:28.740, tt:1551.966\n",
      "Ep:54, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:28.681, tt:1577.476\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:28.673, tt:1605.696\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01204, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:28.682, tt:1634.852\n",
      "Ep:57, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:28.700, tt:1664.591\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01169, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:28.710, tt:1693.918\n",
      "Ep:59, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:28.730, tt:1723.811\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:28.711, tt:1751.344\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01219, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:28.679, tt:1778.110\n",
      "Ep:62, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:28.652, tt:1805.101\n",
      "Ep:63, loss:0.00001, loss_test:0.01160, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:28.633, tt:1832.491\n",
      "Ep:64, loss:0.00001, loss_test:0.01285, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:28.611, tt:1859.704\n",
      "Ep:65, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:28.608, tt:1888.136\n",
      "Ep:66, loss:0.00001, loss_test:0.01231, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:28.623, tt:1917.729\n",
      "Ep:67, loss:0.00001, loss_test:0.01262, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:28.662, tt:1949.017\n",
      "Ep:68, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:28.667, tt:1978.017\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:28.680, tt:2007.605\n",
      "Ep:70, loss:0.00001, loss_test:0.01249, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:28.687, tt:2036.743\n",
      "Ep:71, loss:0.00001, loss_test:0.01286, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:28.712, tt:2067.277\n",
      "Ep:72, loss:0.00001, loss_test:0.01293, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:28.711, tt:2095.935\n",
      "Ep:73, loss:0.00001, loss_test:0.01355, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:28.699, tt:2123.694\n",
      "Ep:74, loss:0.00001, loss_test:0.01398, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:28.683, tt:2151.241\n",
      "Ep:75, loss:0.00001, loss_test:0.01448, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:28.689, tt:2180.386\n",
      "Ep:76, loss:0.00001, loss_test:0.01318, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:28.694, tt:2209.476\n",
      "Ep:77, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:28.723, tt:2240.400\n",
      "Ep:78, loss:0.00001, loss_test:0.01162, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:28.761, tt:2272.117\n",
      "Ep:79, loss:0.00001, loss_test:0.01631, lr:6.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:28.762, tt:2300.972\n",
      "Ep:80, loss:0.00001, loss_test:0.01098, lr:5.94e-02, fs:0.83568 (r=0.899,p=0.781),  time:28.758, tt:2329.368\n",
      "Ep:81, loss:0.00001, loss_test:0.01198, lr:5.88e-02, fs:0.83654 (r=0.879,p=0.798),  time:28.766, tt:2358.772\n",
      "Ep:82, loss:0.00001, loss_test:0.01176, lr:5.82e-02, fs:0.81731 (r=0.859,p=0.780),  time:28.754, tt:2386.586\n",
      "Ep:83, loss:0.00001, loss_test:0.01109, lr:5.76e-02, fs:0.81340 (r=0.859,p=0.773),  time:28.739, tt:2414.102\n",
      "Ep:84, loss:0.00001, loss_test:0.01426, lr:5.71e-02, fs:0.80392 (r=0.828,p=0.781),  time:28.719, tt:2441.126\n",
      "Ep:85, loss:0.00001, loss_test:0.01219, lr:5.65e-02, fs:0.81773 (r=0.838,p=0.798),  time:28.719, tt:2469.835\n",
      "Ep:86, loss:0.00001, loss_test:0.01419, lr:5.59e-02, fs:0.81373 (r=0.838,p=0.790),  time:28.733, tt:2499.748\n",
      "Ep:87, loss:0.00001, loss_test:0.01264, lr:5.54e-02, fs:0.80788 (r=0.828,p=0.788),  time:28.742, tt:2529.321\n",
      "Ep:88, loss:0.00001, loss_test:0.01157, lr:5.48e-02, fs:0.80976 (r=0.838,p=0.783),  time:28.750, tt:2558.739\n",
      "Ep:89, loss:0.00001, loss_test:0.01648, lr:5.43e-02, fs:0.77778 (r=0.778,p=0.778),  time:28.774, tt:2589.671\n",
      "Ep:90, loss:0.00001, loss_test:0.01218, lr:5.37e-02, fs:0.81188 (r=0.828,p=0.796),  time:28.770, tt:2618.099\n",
      "Ep:91, loss:0.00001, loss_test:0.01171, lr:5.32e-02, fs:0.81188 (r=0.828,p=0.796),  time:28.771, tt:2646.937\n",
      "Ep:92, loss:0.00001, loss_test:0.01453, lr:5.27e-02, fs:0.81773 (r=0.838,p=0.798),  time:28.771, tt:2675.681\n",
      "Ep:93, loss:0.00001, loss_test:0.01171, lr:5.21e-02, fs:0.80788 (r=0.828,p=0.788),  time:28.767, tt:2704.106\n",
      "Ep:94, loss:0.00001, loss_test:0.01350, lr:5.16e-02, fs:0.82412 (r=0.828,p=0.820),  time:28.756, tt:2731.774\n",
      "Ep:95, loss:0.00001, loss_test:0.01335, lr:5.11e-02, fs:0.83000 (r=0.838,p=0.822),  time:28.765, tt:2761.393\n",
      "Ep:96, loss:0.00000, loss_test:0.01319, lr:5.06e-02, fs:0.82653 (r=0.818,p=0.835),  time:28.767, tt:2790.427\n",
      "Ep:97, loss:0.00000, loss_test:0.01458, lr:5.01e-02, fs:0.81026 (r=0.798,p=0.823),  time:28.785, tt:2820.947\n",
      "Ep:98, loss:0.00000, loss_test:0.01346, lr:4.96e-02, fs:0.81026 (r=0.798,p=0.823),  time:28.787, tt:2849.895\n",
      "Ep:99, loss:0.00000, loss_test:0.01420, lr:4.91e-02, fs:0.80628 (r=0.778,p=0.837),  time:28.802, tt:2880.165\n",
      "Ep:100, loss:0.00000, loss_test:0.01475, lr:4.86e-02, fs:0.80829 (r=0.788,p=0.830),  time:28.818, tt:2910.652\n",
      "Ep:101, loss:0.00000, loss_test:0.01339, lr:4.81e-02, fs:0.80208 (r=0.778,p=0.828),  time:28.830, tt:2940.643\n",
      "Ep:102, loss:0.00000, loss_test:0.01521, lr:4.76e-02, fs:0.80628 (r=0.778,p=0.837),  time:28.838, tt:2970.283\n",
      "Ep:103, loss:0.00000, loss_test:0.01478, lr:4.71e-02, fs:0.81443 (r=0.798,p=0.832),  time:28.814, tt:2996.702\n",
      "Ep:104, loss:0.00000, loss_test:0.01358, lr:4.67e-02, fs:0.80628 (r=0.778,p=0.837),  time:28.810, tt:3025.036\n",
      "Ep:105, loss:0.00000, loss_test:0.01465, lr:4.62e-02, fs:0.80208 (r=0.778,p=0.828),  time:28.803, tt:3053.130\n",
      "Ep:106, loss:0.00000, loss_test:0.01409, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:28.796, tt:3081.166\n",
      "Ep:107, loss:0.00000, loss_test:0.01536, lr:4.53e-02, fs:0.80000 (r=0.768,p=0.835),  time:28.802, tt:3110.566\n",
      "Ep:108, loss:0.00000, loss_test:0.01288, lr:4.48e-02, fs:0.81633 (r=0.808,p=0.825),  time:28.796, tt:3138.756\n",
      "Ep:109, loss:0.00000, loss_test:0.01471, lr:4.44e-02, fs:0.80000 (r=0.768,p=0.835),  time:28.799, tt:3167.911\n",
      "Ep:110, loss:0.00000, loss_test:0.01647, lr:4.39e-02, fs:0.80208 (r=0.778,p=0.828),  time:28.803, tt:3197.093\n",
      "Ep:111, loss:0.00000, loss_test:0.01521, lr:4.35e-02, fs:0.80208 (r=0.778,p=0.828),  time:28.810, tt:3226.754\n",
      "Ep:112, loss:0.00000, loss_test:0.01310, lr:4.31e-02, fs:0.82051 (r=0.808,p=0.833),  time:28.823, tt:3256.994\n",
      "Ep:113, loss:0.00000, loss_test:0.01604, lr:4.26e-02, fs:0.80208 (r=0.778,p=0.828),  time:28.844, tt:3288.224\n",
      "Ep:114, loss:0.00000, loss_test:0.01480, lr:4.22e-02, fs:0.81443 (r=0.798,p=0.832),  time:28.830, tt:3315.489\n",
      "Ep:115, loss:0.00000, loss_test:0.01309, lr:4.18e-02, fs:0.82051 (r=0.808,p=0.833),  time:28.816, tt:3342.597\n",
      "Ep:116, loss:0.00000, loss_test:0.01709, lr:4.14e-02, fs:0.76503 (r=0.707,p=0.833),  time:28.820, tt:3371.990\n",
      "Ep:117, loss:0.00000, loss_test:0.01330, lr:4.10e-02, fs:0.82653 (r=0.818,p=0.835),  time:28.823, tt:3401.077\n",
      "Ep:118, loss:0.00000, loss_test:0.01465, lr:4.05e-02, fs:0.81865 (r=0.798,p=0.840),  time:28.821, tt:3429.749\n",
      "Ep:119, loss:0.00000, loss_test:0.01407, lr:4.01e-02, fs:0.82051 (r=0.808,p=0.833),  time:28.824, tt:3458.939\n",
      "Ep:120, loss:0.00000, loss_test:0.01428, lr:3.97e-02, fs:0.82292 (r=0.798,p=0.849),  time:28.831, tt:3488.536\n",
      "Ep:121, loss:0.00000, loss_test:0.01385, lr:3.93e-02, fs:0.82902 (r=0.808,p=0.851),  time:28.836, tt:3517.939\n",
      "Ep:122, loss:0.00000, loss_test:0.01490, lr:3.89e-02, fs:0.80628 (r=0.778,p=0.837),  time:28.847, tt:3548.150\n",
      "Ep:123, loss:0.00000, loss_test:0.01348, lr:3.86e-02, fs:0.81865 (r=0.798,p=0.840),  time:28.838, tt:3575.884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00000, loss_test:0.01601, lr:3.82e-02, fs:0.80000 (r=0.768,p=0.835),  time:28.833, tt:3604.127\n",
      "Ep:125, loss:0.00000, loss_test:0.01333, lr:3.78e-02, fs:0.82292 (r=0.798,p=0.849),  time:28.822, tt:3631.521\n",
      "Ep:126, loss:0.00000, loss_test:0.01593, lr:3.74e-02, fs:0.80000 (r=0.768,p=0.835),  time:28.819, tt:3660.046\n",
      "Ep:127, loss:0.00000, loss_test:0.01414, lr:3.70e-02, fs:0.81053 (r=0.778,p=0.846),  time:28.813, tt:3688.012\n",
      "Ep:128, loss:0.00000, loss_test:0.01530, lr:3.67e-02, fs:0.80423 (r=0.768,p=0.844),  time:28.808, tt:3716.174\n",
      "Ep:129, loss:0.00000, loss_test:0.01529, lr:3.63e-02, fs:0.81053 (r=0.778,p=0.846),  time:28.809, tt:3745.164\n",
      "Ep:130, loss:0.00000, loss_test:0.01461, lr:3.59e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.807, tt:3773.683\n",
      "Ep:131, loss:0.00000, loss_test:0.01535, lr:3.56e-02, fs:0.80423 (r=0.768,p=0.844),  time:28.815, tt:3803.581\n",
      "Ep:132, loss:0.00000, loss_test:0.01481, lr:3.52e-02, fs:0.80423 (r=0.768,p=0.844),  time:28.804, tt:3830.979\n",
      "Ep:133, loss:0.00000, loss_test:0.01558, lr:3.49e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.816, tt:3861.300\n",
      "Ep:134, loss:0.00000, loss_test:0.01529, lr:3.45e-02, fs:0.80423 (r=0.768,p=0.844),  time:28.817, tt:3890.231\n",
      "Ep:135, loss:0.00000, loss_test:0.01532, lr:3.42e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.818, tt:3919.210\n",
      "Ep:136, loss:0.00000, loss_test:0.01547, lr:3.38e-02, fs:0.80423 (r=0.768,p=0.844),  time:28.818, tt:3948.080\n",
      "Ep:137, loss:0.00000, loss_test:0.01563, lr:3.35e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.825, tt:3977.847\n",
      "Ep:138, loss:0.00000, loss_test:0.01562, lr:3.32e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.833, tt:4007.749\n",
      "Ep:139, loss:0.00000, loss_test:0.01554, lr:3.28e-02, fs:0.80423 (r=0.768,p=0.844),  time:28.830, tt:4036.190\n",
      "Ep:140, loss:0.00000, loss_test:0.01584, lr:3.25e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.835, tt:4065.727\n",
      "Ep:141, loss:0.00000, loss_test:0.01540, lr:3.22e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.842, tt:4095.619\n",
      "Ep:142, loss:0.00000, loss_test:0.01640, lr:3.19e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.844, tt:4124.756\n",
      "Ep:143, loss:0.00000, loss_test:0.01534, lr:3.15e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.855, tt:4155.184\n",
      "Ep:144, loss:0.00000, loss_test:0.01586, lr:3.12e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.844, tt:4182.381\n",
      "Ep:145, loss:0.00000, loss_test:0.01585, lr:3.09e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.853, tt:4212.484\n",
      "Ep:146, loss:0.00000, loss_test:0.01566, lr:3.06e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.850, tt:4241.008\n",
      "Ep:147, loss:0.00000, loss_test:0.01628, lr:3.03e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.840, tt:4268.355\n",
      "Ep:148, loss:0.00000, loss_test:0.01599, lr:3.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.838, tt:4296.790\n",
      "Ep:149, loss:0.00000, loss_test:0.01607, lr:2.97e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.831, tt:4324.630\n",
      "Ep:150, loss:0.00000, loss_test:0.01579, lr:2.94e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.832, tt:4353.615\n",
      "Ep:151, loss:0.00000, loss_test:0.01640, lr:2.91e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.835, tt:4382.968\n",
      "Ep:152, loss:0.00000, loss_test:0.01610, lr:2.88e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.843, tt:4413.046\n",
      "Ep:153, loss:0.00000, loss_test:0.01606, lr:2.85e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.846, tt:4442.210\n",
      "Ep:154, loss:0.00000, loss_test:0.01636, lr:2.82e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.843, tt:4470.738\n",
      "Ep:155, loss:0.00000, loss_test:0.01617, lr:2.80e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.853, tt:4501.072\n",
      "Ep:156, loss:0.00000, loss_test:0.01669, lr:2.77e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.841, tt:4528.088\n",
      "Ep:157, loss:0.00000, loss_test:0.01595, lr:2.74e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.839, tt:4556.615\n",
      "Ep:158, loss:0.00000, loss_test:0.01667, lr:2.71e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.832, tt:4584.227\n",
      "Ep:159, loss:0.00000, loss_test:0.01624, lr:2.69e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.822, tt:4611.573\n",
      "Ep:160, loss:0.00000, loss_test:0.01648, lr:2.66e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.827, tt:4641.113\n",
      "Ep:161, loss:0.00000, loss_test:0.01634, lr:2.63e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.839, tt:4671.936\n",
      "Ep:162, loss:0.00000, loss_test:0.01626, lr:2.61e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.852, tt:4702.832\n",
      "Ep:163, loss:0.00000, loss_test:0.01677, lr:2.58e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.856, tt:4732.335\n",
      "Ep:164, loss:0.00000, loss_test:0.01577, lr:2.55e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.855, tt:4761.114\n",
      "Ep:165, loss:0.00000, loss_test:0.01749, lr:2.53e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.856, tt:4790.022\n",
      "Ep:166, loss:0.00000, loss_test:0.01578, lr:2.50e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.854, tt:4818.649\n",
      "Ep:167, loss:0.00000, loss_test:0.01737, lr:2.48e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.848, tt:4846.440\n",
      "Ep:168, loss:0.00000, loss_test:0.01578, lr:2.45e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.838, tt:4873.650\n",
      "Ep:169, loss:0.00000, loss_test:0.01696, lr:2.43e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.838, tt:4902.408\n",
      "Ep:170, loss:0.00000, loss_test:0.01600, lr:2.40e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.840, tt:4931.608\n",
      "Ep:171, loss:0.00000, loss_test:0.01681, lr:2.38e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.843, tt:4961.012\n",
      "Ep:172, loss:0.00000, loss_test:0.01636, lr:2.36e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.850, tt:4991.006\n",
      "Ep:173, loss:0.00000, loss_test:0.01645, lr:2.33e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.856, tt:5020.861\n",
      "Ep:174, loss:0.00000, loss_test:0.01661, lr:2.31e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.856, tt:5049.812\n",
      "Ep:175, loss:0.00000, loss_test:0.01655, lr:2.29e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.856, tt:5078.684\n",
      "Ep:176, loss:0.00000, loss_test:0.01671, lr:2.26e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.854, tt:5107.165\n",
      "Ep:177, loss:0.00000, loss_test:0.01641, lr:2.24e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.851, tt:5135.551\n",
      "Ep:178, loss:0.00000, loss_test:0.01659, lr:2.22e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.850, tt:5164.095\n",
      "Ep:179, loss:0.00000, loss_test:0.01662, lr:2.20e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.854, tt:5193.659\n",
      "Ep:180, loss:0.00000, loss_test:0.01664, lr:2.17e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.851, tt:5222.112\n",
      "Ep:181, loss:0.00000, loss_test:0.01681, lr:2.15e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.857, tt:5251.966\n",
      "Ep:182, loss:0.00000, loss_test:0.01662, lr:2.13e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.862, tt:5281.714\n",
      "Ep:183, loss:0.00000, loss_test:0.01673, lr:2.11e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.872, tt:5312.450\n",
      "Ep:184, loss:0.00000, loss_test:0.01686, lr:2.09e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.867, tt:5340.362\n",
      "Ep:185, loss:0.00000, loss_test:0.01647, lr:2.07e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.868, tt:5369.528\n",
      "Ep:186, loss:0.00000, loss_test:0.01725, lr:2.05e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.862, tt:5397.201\n",
      "Ep:187, loss:0.00000, loss_test:0.01649, lr:2.03e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.864, tt:5426.357\n",
      "Ep:188, loss:0.00000, loss_test:0.01720, lr:2.01e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.865, tt:5455.430\n",
      "Ep:189, loss:0.00000, loss_test:0.01666, lr:1.99e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.866, tt:5484.460\n",
      "Ep:190, loss:0.00000, loss_test:0.01685, lr:1.97e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.853, tt:5510.983\n",
      "Ep:191, loss:0.00000, loss_test:0.01693, lr:1.95e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.855, tt:5540.185\n",
      "Ep:192, loss:0.00000, loss_test:0.01697, lr:1.93e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.858, tt:5569.514\n",
      "Ep:193, loss:0.00000, loss_test:0.01679, lr:1.91e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.852, tt:5597.337\n",
      "Ep:194, loss:0.00000, loss_test:0.01731, lr:1.89e-02, fs:0.80851 (r=0.768,p=0.854),  time:28.850, tt:5625.670\n",
      "Ep:195, loss:0.00000, loss_test:0.01682, lr:1.87e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.850, tt:5654.640\n",
      "Ep:196, loss:0.00000, loss_test:0.01719, lr:1.85e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.843, tt:5682.079\n",
      "Ep:197, loss:0.00000, loss_test:0.01702, lr:1.83e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.833, tt:5709.000\n",
      "Ep:198, loss:0.00000, loss_test:0.01718, lr:1.81e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.830, tt:5737.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:199, loss:0.00000, loss_test:0.01704, lr:1.80e-02, fs:0.81283 (r=0.768,p=0.864),  time:28.827, tt:5765.491\n",
      "Ep:200, loss:0.00000, loss_test:0.01719, lr:1.78e-02, fs:0.81720 (r=0.768,p=0.874),  time:28.828, tt:5794.367\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.12298, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:29.239, tt:29.239\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12172, lr:1.00e-02, fs:0.68595 (r=0.838,p=0.580),  time:29.039, tt:58.078\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12036, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:29.013, tt:87.039\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11916, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:29.117, tt:116.467\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11759, lr:1.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:29.040, tt:145.199\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11583, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:29.168, tt:175.011\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11391, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:29.496, tt:206.469\n",
      "Ep:7, loss:0.00025, loss_test:0.11170, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:29.733, tt:237.867\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.10890, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:29.825, tt:268.427\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.10581, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:30.092, tt:300.925\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.10298, lr:1.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:30.143, tt:331.578\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10071, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:30.163, tt:361.954\n",
      "Ep:12, loss:0.00023, loss_test:0.09897, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:30.107, tt:391.388\n",
      "Ep:13, loss:0.00023, loss_test:0.09771, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:30.075, tt:421.047\n",
      "Ep:14, loss:0.00022, loss_test:0.09653, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:29.995, tt:449.922\n",
      "Ep:15, loss:0.00022, loss_test:0.09525, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:29.907, tt:478.518\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.09420, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:29.804, tt:506.662\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.09310, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:29.851, tt:537.314\n",
      "Ep:18, loss:0.00021, loss_test:0.09241, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:29.889, tt:567.886\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.09124, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:29.857, tt:597.145\n",
      "Ep:20, loss:0.00020, loss_test:0.09021, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:29.882, tt:627.530\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.08847, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:29.874, tt:657.226\n",
      "Ep:22, loss:0.00020, loss_test:0.08808, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:29.874, tt:687.096\n",
      "Ep:23, loss:0.00019, loss_test:0.08630, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:29.879, tt:717.106\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.08575, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:29.904, tt:747.590\n",
      "Ep:25, loss:0.00018, loss_test:0.08393, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:29.931, tt:778.199\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.08330, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:29.932, tt:808.175\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.08259, lr:1.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:29.934, tt:838.163\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.08069, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:29.933, tt:868.054\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.07906, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:29.918, tt:897.535\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.07829, lr:1.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:29.923, tt:927.608\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.07670, lr:1.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:29.862, tt:955.579\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.07416, lr:1.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.874, tt:985.851\n",
      "Ep:33, loss:0.00014, loss_test:0.07397, lr:1.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:29.858, tt:1015.160\n",
      "Ep:34, loss:0.00014, loss_test:0.07019, lr:1.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:29.851, tt:1044.788\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.06616, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:29.844, tt:1074.401\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.07875, lr:1.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:29.850, tt:1104.453\n",
      "Ep:37, loss:0.00014, loss_test:0.06256, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:29.839, tt:1133.875\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.06206, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:29.836, tt:1163.587\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.05935, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:29.825, tt:1193.001\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.05870, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:29.828, tt:1222.941\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.05866, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:29.924, tt:1256.813\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.05691, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:29.886, tt:1285.100\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.06006, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.936, tt:1317.187\n",
      "Ep:44, loss:0.00009, loss_test:0.05862, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:29.911, tt:1346.008\n",
      "Ep:45, loss:0.00009, loss_test:0.05672, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:29.918, tt:1376.235\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.05797, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:29.922, tt:1406.351\n",
      "Ep:47, loss:0.00008, loss_test:0.05917, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:29.907, tt:1435.551\n",
      "Ep:48, loss:0.00008, loss_test:0.05720, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:29.915, tt:1465.859\n",
      "Ep:49, loss:0.00008, loss_test:0.05990, lr:1.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:29.886, tt:1494.324\n",
      "Ep:50, loss:0.00007, loss_test:0.06269, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:29.872, tt:1523.480\n",
      "Ep:51, loss:0.00007, loss_test:0.06360, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:29.866, tt:1553.006\n",
      "Ep:52, loss:0.00007, loss_test:0.06383, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:29.873, tt:1583.279\n",
      "Ep:53, loss:0.00007, loss_test:0.05618, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:29.852, tt:1612.027\n",
      "Ep:54, loss:0.00006, loss_test:0.06162, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.833, tt:1640.830\n",
      "Ep:55, loss:0.00006, loss_test:0.05656, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:29.822, tt:1670.007\n",
      "Ep:56, loss:0.00006, loss_test:0.05655, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:29.828, tt:1700.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00006, loss_test:0.05475, lr:9.90e-03, fs:0.84000 (r=0.848,p=0.832),  time:29.839, tt:1730.666\n",
      "Ep:58, loss:0.00005, loss_test:0.05197, lr:9.80e-03, fs:0.85000 (r=0.859,p=0.842),  time:29.853, tt:1761.326\n",
      "Ep:59, loss:0.00005, loss_test:0.05713, lr:9.70e-03, fs:0.83673 (r=0.828,p=0.845),  time:29.826, tt:1789.568\n",
      "Ep:60, loss:0.00005, loss_test:0.05570, lr:9.61e-03, fs:0.81865 (r=0.798,p=0.840),  time:29.830, tt:1819.641\n",
      "Ep:61, loss:0.00004, loss_test:0.05578, lr:9.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:29.833, tt:1849.666\n",
      "Ep:62, loss:0.00004, loss_test:0.05714, lr:9.41e-03, fs:0.81865 (r=0.798,p=0.840),  time:29.815, tt:1878.354\n",
      "Ep:63, loss:0.00004, loss_test:0.05844, lr:9.32e-03, fs:0.82540 (r=0.788,p=0.867),  time:29.818, tt:1908.365\n",
      "Ep:64, loss:0.00004, loss_test:0.05745, lr:9.23e-03, fs:0.84264 (r=0.838,p=0.847),  time:29.794, tt:1936.597\n",
      "Ep:65, loss:0.00005, loss_test:0.06349, lr:9.14e-03, fs:0.85417 (r=0.828,p=0.882),  time:29.807, tt:1967.271\n",
      "Ep:66, loss:0.00004, loss_test:0.06186, lr:9.04e-03, fs:0.82540 (r=0.788,p=0.867),  time:29.806, tt:1997.004\n",
      "Ep:67, loss:0.00004, loss_test:0.06578, lr:8.95e-03, fs:0.83422 (r=0.788,p=0.886),  time:29.812, tt:2027.204\n",
      "Ep:68, loss:0.00004, loss_test:0.05907, lr:8.86e-03, fs:0.82292 (r=0.798,p=0.849),  time:29.826, tt:2057.995\n",
      "Ep:69, loss:0.00004, loss_test:0.05991, lr:8.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:29.813, tt:2086.877\n",
      "Ep:70, loss:0.00004, loss_test:0.06331, lr:8.69e-03, fs:0.82979 (r=0.788,p=0.876),  time:29.802, tt:2115.965\n",
      "Ep:71, loss:0.00004, loss_test:0.05779, lr:8.60e-03, fs:0.82540 (r=0.788,p=0.867),  time:29.786, tt:2144.587\n",
      "Ep:72, loss:0.00003, loss_test:0.05589, lr:8.51e-03, fs:0.86316 (r=0.828,p=0.901),  time:29.781, tt:2174.024\n",
      "Ep:73, loss:0.00003, loss_test:0.05819, lr:8.43e-03, fs:0.82979 (r=0.788,p=0.876),  time:29.774, tt:2203.305\n",
      "Ep:74, loss:0.00003, loss_test:0.06203, lr:8.35e-03, fs:0.82540 (r=0.788,p=0.867),  time:29.754, tt:2231.519\n",
      "Ep:75, loss:0.00003, loss_test:0.06553, lr:8.26e-03, fs:0.83422 (r=0.788,p=0.886),  time:29.743, tt:2260.454\n",
      "Ep:76, loss:0.00003, loss_test:0.06737, lr:8.18e-03, fs:0.84324 (r=0.788,p=0.907),  time:29.798, tt:2294.460\n",
      "Ep:77, loss:0.00003, loss_test:0.06343, lr:8.10e-03, fs:0.81081 (r=0.758,p=0.872),  time:29.746, tt:2320.177\n",
      "Ep:78, loss:0.00003, loss_test:0.06234, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:29.656, tt:2342.857\n",
      "Ep:79, loss:0.00003, loss_test:0.06653, lr:7.94e-03, fs:0.84324 (r=0.788,p=0.907),  time:29.571, tt:2365.677\n",
      "Ep:80, loss:0.00003, loss_test:0.06239, lr:7.86e-03, fs:0.82540 (r=0.788,p=0.867),  time:29.573, tt:2395.417\n",
      "Ep:81, loss:0.00003, loss_test:0.06122, lr:7.78e-03, fs:0.85417 (r=0.828,p=0.882),  time:29.572, tt:2424.876\n",
      "Ep:82, loss:0.00003, loss_test:0.06933, lr:7.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.574, tt:2454.627\n",
      "Ep:83, loss:0.00003, loss_test:0.05825, lr:7.62e-03, fs:0.82979 (r=0.788,p=0.876),  time:29.573, tt:2484.155\n",
      "Ep:84, loss:0.00003, loss_test:0.06831, lr:7.55e-03, fs:0.86667 (r=0.788,p=0.963),  time:29.561, tt:2512.652\n",
      "Ep:85, loss:0.00003, loss_test:0.06844, lr:7.47e-03, fs:0.81081 (r=0.758,p=0.872),  time:29.557, tt:2541.910\n",
      "Ep:86, loss:0.00003, loss_test:0.06592, lr:7.40e-03, fs:0.84324 (r=0.788,p=0.907),  time:29.570, tt:2572.610\n",
      "Ep:87, loss:0.00002, loss_test:0.06604, lr:7.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:29.580, tt:2603.042\n",
      "Ep:88, loss:0.00002, loss_test:0.06668, lr:7.25e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.580, tt:2632.619\n",
      "Ep:89, loss:0.00002, loss_test:0.06670, lr:7.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.583, tt:2662.442\n",
      "Ep:90, loss:0.00002, loss_test:0.06139, lr:7.11e-03, fs:0.84783 (r=0.788,p=0.918),  time:29.593, tt:2692.920\n",
      "Ep:91, loss:0.00002, loss_test:0.06551, lr:7.03e-03, fs:0.84783 (r=0.788,p=0.918),  time:29.603, tt:2723.513\n",
      "Ep:92, loss:0.00002, loss_test:0.06869, lr:6.96e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.603, tt:2753.075\n",
      "Ep:93, loss:0.00002, loss_test:0.06779, lr:6.89e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.617, tt:2784.040\n",
      "Ep:94, loss:0.00002, loss_test:0.06743, lr:6.83e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.626, tt:2814.454\n",
      "Ep:95, loss:0.00001, loss_test:0.06748, lr:6.76e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.636, tt:2845.062\n",
      "Ep:96, loss:0.00001, loss_test:0.06826, lr:6.69e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.636, tt:2874.678\n",
      "Ep:97, loss:0.00001, loss_test:0.06907, lr:6.62e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.631, tt:2903.850\n",
      "Ep:98, loss:0.00001, loss_test:0.06511, lr:6.56e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.630, tt:2933.341\n",
      "Ep:99, loss:0.00001, loss_test:0.06716, lr:6.49e-03, fs:0.84324 (r=0.788,p=0.907),  time:29.627, tt:2962.670\n",
      "Ep:100, loss:0.00001, loss_test:0.07141, lr:6.43e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.641, tt:2993.738\n",
      "Ep:101, loss:0.00001, loss_test:0.06709, lr:6.36e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.649, tt:3024.168\n",
      "Ep:102, loss:0.00001, loss_test:0.06665, lr:6.30e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.653, tt:3054.239\n",
      "Ep:103, loss:0.00001, loss_test:0.06951, lr:6.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.658, tt:3084.471\n",
      "Ep:104, loss:0.00001, loss_test:0.07085, lr:6.17e-03, fs:0.84783 (r=0.788,p=0.918),  time:29.673, tt:3115.714\n",
      "Ep:105, loss:0.00001, loss_test:0.07021, lr:6.11e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.723, tt:3150.655\n",
      "Ep:106, loss:0.00001, loss_test:0.06911, lr:6.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:29.724, tt:3180.519\n",
      "Ep:107, loss:0.00001, loss_test:0.06868, lr:5.99e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.717, tt:3209.439\n",
      "Ep:108, loss:0.00001, loss_test:0.07264, lr:5.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:29.710, tt:3238.414\n",
      "Ep:109, loss:0.00001, loss_test:0.06973, lr:5.87e-03, fs:0.85246 (r=0.788,p=0.929),  time:29.726, tt:3269.867\n",
      "Ep:110, loss:0.00001, loss_test:0.07008, lr:5.81e-03, fs:0.86188 (r=0.788,p=0.951),  time:29.733, tt:3300.356\n",
      "Ep:111, loss:0.00001, loss_test:0.07192, lr:5.75e-03, fs:0.86188 (r=0.788,p=0.951),  time:29.740, tt:3330.906\n",
      "Ep:112, loss:0.00001, loss_test:0.07214, lr:5.70e-03, fs:0.87151 (r=0.788,p=0.975),  time:29.746, tt:3361.335\n",
      "Ep:113, loss:0.00001, loss_test:0.07364, lr:5.64e-03, fs:0.86188 (r=0.788,p=0.951),  time:29.757, tt:3392.349\n",
      "Ep:114, loss:0.00001, loss_test:0.07058, lr:5.58e-03, fs:0.86667 (r=0.788,p=0.963),  time:29.764, tt:3422.911\n",
      "Ep:115, loss:0.00001, loss_test:0.07044, lr:5.53e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.771, tt:3453.455\n",
      "Ep:116, loss:0.00001, loss_test:0.07226, lr:5.47e-03, fs:0.86188 (r=0.788,p=0.951),  time:29.775, tt:3483.659\n",
      "Ep:117, loss:0.00001, loss_test:0.07263, lr:5.42e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.783, tt:3514.415\n",
      "Ep:118, loss:0.00001, loss_test:0.06982, lr:5.36e-03, fs:0.86188 (r=0.788,p=0.951),  time:29.783, tt:3544.155\n",
      "Ep:119, loss:0.00001, loss_test:0.07189, lr:5.31e-03, fs:0.87151 (r=0.788,p=0.975),  time:29.784, tt:3574.044\n",
      "Ep:120, loss:0.00001, loss_test:0.07627, lr:5.26e-03, fs:0.86667 (r=0.788,p=0.963),  time:29.785, tt:3603.980\n",
      "Ep:121, loss:0.00001, loss_test:0.07183, lr:5.20e-03, fs:0.87151 (r=0.788,p=0.975),  time:29.788, tt:3634.084\n",
      "Ep:124, loss:0.00001, loss_test:0.07015, lr:5.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.789, tt:3723.646\n",
      "Ep:125, loss:0.00001, loss_test:0.07039, lr:5.00e-03, fs:0.87151 (r=0.788,p=0.975),  time:29.800, tt:3754.827\n",
      "Ep:126, loss:0.00001, loss_test:0.07268, lr:4.95e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.815, tt:3786.558\n",
      "Ep:127, loss:0.00001, loss_test:0.07120, lr:4.90e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.805, tt:3815.068\n",
      "Ep:128, loss:0.00001, loss_test:0.06966, lr:4.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.804, tt:3844.682\n",
      "Ep:129, loss:0.00000, loss_test:0.07346, lr:4.80e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.809, tt:3875.136\n",
      "Ep:130, loss:0.00000, loss_test:0.07262, lr:4.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.815, tt:3905.744\n",
      "Ep:131, loss:0.00000, loss_test:0.06986, lr:4.71e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.826, tt:3936.969\n",
      "Ep:132, loss:0.00000, loss_test:0.07084, lr:4.66e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.831, tt:3967.463\n",
      "Ep:133, loss:0.00000, loss_test:0.07328, lr:4.61e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.828, tt:3997.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.07207, lr:4.57e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.831, tt:4027.200\n",
      "Ep:135, loss:0.00000, loss_test:0.07161, lr:4.52e-03, fs:0.87151 (r=0.788,p=0.975),  time:29.837, tt:4057.774\n",
      "Ep:136, loss:0.00000, loss_test:0.07289, lr:4.48e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.839, tt:4087.915\n",
      "Ep:137, loss:0.00000, loss_test:0.07243, lr:4.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.843, tt:4118.369\n",
      "Ep:138, loss:0.00000, loss_test:0.07273, lr:4.39e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.844, tt:4148.300\n",
      "Ep:139, loss:0.00000, loss_test:0.07133, lr:4.34e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.845, tt:4178.256\n",
      "Ep:140, loss:0.00000, loss_test:0.07264, lr:4.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.843, tt:4207.928\n",
      "Ep:141, loss:0.00000, loss_test:0.07291, lr:4.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.856, tt:4239.547\n",
      "Ep:142, loss:0.00000, loss_test:0.07113, lr:4.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.852, tt:4268.767\n",
      "Ep:143, loss:0.00000, loss_test:0.07165, lr:4.17e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.860, tt:4299.880\n",
      "Ep:144, loss:0.00000, loss_test:0.07016, lr:4.13e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.854, tt:4328.860\n",
      "Ep:145, loss:0.00000, loss_test:0.07342, lr:4.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.864, tt:4360.172\n",
      "Ep:146, loss:0.00000, loss_test:0.07182, lr:4.05e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.866, tt:4390.280\n",
      "Ep:147, loss:0.00000, loss_test:0.07226, lr:4.01e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.863, tt:4419.770\n",
      "Ep:148, loss:0.00000, loss_test:0.07260, lr:3.97e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.861, tt:4449.243\n",
      "Ep:149, loss:0.00000, loss_test:0.07037, lr:3.93e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.861, tt:4479.207\n",
      "Ep:150, loss:0.00000, loss_test:0.07174, lr:3.89e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.866, tt:4509.780\n",
      "Ep:151, loss:0.00000, loss_test:0.07200, lr:3.85e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.868, tt:4539.953\n",
      "Ep:152, loss:0.00000, loss_test:0.07228, lr:3.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.871, tt:4570.257\n",
      "Ep:153, loss:0.00000, loss_test:0.07310, lr:3.77e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.869, tt:4599.842\n",
      "Ep:154, loss:0.00000, loss_test:0.07195, lr:3.73e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.870, tt:4629.805\n",
      "Ep:155, loss:0.00000, loss_test:0.07228, lr:3.70e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.873, tt:4660.260\n",
      "Ep:156, loss:0.00000, loss_test:0.07088, lr:3.66e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.885, tt:4691.896\n",
      "Ep:157, loss:0.00000, loss_test:0.07168, lr:3.62e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.889, tt:4722.537\n",
      "Ep:158, loss:0.00000, loss_test:0.07216, lr:3.59e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.884, tt:4751.559\n",
      "Ep:159, loss:0.00000, loss_test:0.07122, lr:3.55e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.890, tt:4782.332\n",
      "Ep:160, loss:0.00000, loss_test:0.07181, lr:3.52e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.885, tt:4811.560\n",
      "Ep:161, loss:0.00000, loss_test:0.07291, lr:3.48e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.889, tt:4841.979\n",
      "Ep:162, loss:0.00000, loss_test:0.07180, lr:3.45e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.887, tt:4871.662\n",
      "Ep:163, loss:0.00000, loss_test:0.07155, lr:3.41e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.888, tt:4901.578\n",
      "Ep:164, loss:0.00000, loss_test:0.07156, lr:3.38e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.890, tt:4931.836\n",
      "Ep:165, loss:0.00000, loss_test:0.07104, lr:3.34e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.890, tt:4961.728\n",
      "Ep:166, loss:0.00000, loss_test:0.07180, lr:3.31e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.898, tt:4992.889\n",
      "Ep:167, loss:0.00000, loss_test:0.07114, lr:3.28e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.903, tt:5023.623\n",
      "Ep:168, loss:0.00000, loss_test:0.07190, lr:3.24e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.910, tt:5054.714\n",
      "Ep:169, loss:0.00000, loss_test:0.07176, lr:3.21e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.918, tt:5086.110\n",
      "Ep:170, loss:0.00000, loss_test:0.07183, lr:3.18e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.916, tt:5115.552\n",
      "Ep:171, loss:0.00000, loss_test:0.07115, lr:3.15e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.911, tt:5144.622\n",
      "Ep:172, loss:0.00000, loss_test:0.07169, lr:3.12e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.911, tt:5174.617\n",
      "Ep:173, loss:0.00000, loss_test:0.07135, lr:3.09e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.917, tt:5205.595\n",
      "Ep:174, loss:0.00000, loss_test:0.07149, lr:3.05e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.904, tt:5233.256\n",
      "Ep:175, loss:0.00000, loss_test:0.07122, lr:3.02e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.898, tt:5261.991\n",
      "Ep:176, loss:0.00000, loss_test:0.07096, lr:2.99e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.895, tt:5291.479\n",
      "Ep:177, loss:0.00000, loss_test:0.07307, lr:2.96e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.896, tt:5321.567\n",
      "Ep:178, loss:0.00000, loss_test:0.07180, lr:2.93e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.893, tt:5350.904\n",
      "Ep:179, loss:0.00000, loss_test:0.07172, lr:2.90e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.900, tt:5381.951\n",
      "Ep:180, loss:0.00000, loss_test:0.07211, lr:2.88e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.891, tt:5410.246\n",
      "Ep:181, loss:0.00000, loss_test:0.07184, lr:2.85e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.902, tt:5442.094\n",
      "Ep:182, loss:0.00000, loss_test:0.07143, lr:2.82e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.903, tt:5472.215\n",
      "Ep:183, loss:0.00000, loss_test:0.07121, lr:2.79e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.897, tt:5501.135\n",
      "Ep:184, loss:0.00000, loss_test:0.07202, lr:2.76e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.894, tt:5530.430\n",
      "Ep:185, loss:0.00000, loss_test:0.07245, lr:2.73e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.895, tt:5560.562\n",
      "Ep:186, loss:0.00000, loss_test:0.07207, lr:2.71e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.897, tt:5590.650\n",
      "Ep:187, loss:0.00000, loss_test:0.07139, lr:2.68e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.903, tt:5621.684\n",
      "Ep:188, loss:0.00000, loss_test:0.07199, lr:2.65e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.903, tt:5651.712\n",
      "Ep:189, loss:0.00000, loss_test:0.07122, lr:2.63e-03, fs:0.87640 (r=0.788,p=0.987),  time:29.904, tt:5681.669\n",
      "Ep:190, loss:0.00000, loss_test:0.07161, lr:2.60e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.903, tt:5711.551\n",
      "Ep:191, loss:0.00000, loss_test:0.07203, lr:2.57e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.904, tt:5741.578\n",
      "Ep:192, loss:0.00000, loss_test:0.07183, lr:2.55e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.901, tt:5770.977\n",
      "Ep:193, loss:0.00000, loss_test:0.07300, lr:2.52e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.897, tt:5800.006\n",
      "Ep:194, loss:0.00000, loss_test:0.07210, lr:2.50e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.896, tt:5829.690\n",
      "Ep:195, loss:0.00000, loss_test:0.07106, lr:2.47e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.900, tt:5860.491\n",
      "Ep:196, loss:0.00000, loss_test:0.07272, lr:2.45e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.907, tt:5891.605\n",
      "Ep:197, loss:0.00000, loss_test:0.07272, lr:2.42e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.924, tt:5924.875\n",
      "Ep:198, loss:0.00000, loss_test:0.07103, lr:2.40e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.921, tt:5954.202\n",
      "Ep:199, loss:0.00000, loss_test:0.07093, lr:2.38e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.916, tt:5983.131\n",
      "Ep:200, loss:0.00000, loss_test:0.07269, lr:2.35e-03, fs:0.88136 (r=0.788,p=1.000),  time:29.918, tt:6013.579\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02010, lr:6.00e-02, fs:0.61603 (r=0.737,p=0.529),  time:30.483, tt:30.483\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:30.780, tt:61.560\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.191, tt:90.573\n",
      "Ep:3, loss:0.00004, loss_test:0.02259, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.068, tt:120.273\n",
      "Ep:4, loss:0.00004, loss_test:0.02211, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:30.096, tt:150.480\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02106, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:30.183, tt:181.098\n",
      "Ep:6, loss:0.00004, loss_test:0.01997, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:30.096, tt:210.673\n",
      "Ep:7, loss:0.00004, loss_test:0.01905, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:29.955, tt:239.636\n",
      "Ep:8, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:29.785, tt:268.062\n",
      "Ep:9, loss:0.00004, loss_test:0.01818, lr:6.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:29.910, tt:299.101\n",
      "Ep:10, loss:0.00004, loss_test:0.01776, lr:6.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:30.047, tt:330.516\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01704, lr:6.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:30.098, tt:361.173\n",
      "Ep:12, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:30.100, tt:391.300\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01603, lr:6.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:30.105, tt:421.475\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:30.269, tt:454.037\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:30.240, tt:483.834\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:30.224, tt:513.804\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01521, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:30.148, tt:542.665\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:30.148, tt:572.811\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01491, lr:6.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:30.268, tt:605.357\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:30.231, tt:634.841\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01462, lr:6.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:30.276, tt:666.074\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01445, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:30.302, tt:696.936\n",
      "Ep:23, loss:0.00003, loss_test:0.01425, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:30.315, tt:727.563\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01405, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:30.325, tt:758.137\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01384, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:30.365, tt:789.490\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01365, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:30.292, tt:817.884\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01347, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:30.262, tt:847.343\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:30.225, tt:876.530\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:30.211, tt:906.341\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01304, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:30.231, tt:937.162\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01291, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:30.226, tt:967.246\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01278, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:30.392, tt:1002.927\n",
      "Ep:33, loss:0.00002, loss_test:0.01263, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:30.405, tt:1033.774\n",
      "Ep:34, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:30.408, tt:1064.273\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01236, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:30.426, tt:1095.348\n",
      "Ep:36, loss:0.00002, loss_test:0.01224, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.452, tt:1126.722\n",
      "Ep:37, loss:0.00002, loss_test:0.01214, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:30.469, tt:1157.809\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:30.481, tt:1188.766\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01195, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:30.490, tt:1219.587\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01186, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:30.504, tt:1250.670\n",
      "Ep:41, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:30.511, tt:1281.475\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01169, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:30.528, tt:1312.703\n",
      "Ep:43, loss:0.00002, loss_test:0.01160, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:30.536, tt:1343.574\n",
      "Ep:44, loss:0.00002, loss_test:0.01151, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:30.570, tt:1375.629\n",
      "Ep:45, loss:0.00002, loss_test:0.01142, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:30.570, tt:1406.243\n",
      "Ep:46, loss:0.00002, loss_test:0.01134, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:30.583, tt:1437.407\n",
      "Ep:47, loss:0.00002, loss_test:0.01128, lr:6.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:30.587, tt:1468.165\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01121, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:30.595, tt:1499.144\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01116, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:30.612, tt:1530.593\n",
      "Ep:50, loss:0.00002, loss_test:0.01109, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:30.609, tt:1561.040\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01103, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:30.619, tt:1592.211\n",
      "Ep:52, loss:0.00002, loss_test:0.01097, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:30.631, tt:1623.458\n",
      "Ep:53, loss:0.00002, loss_test:0.01090, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.658, tt:1655.521\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01084, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.631, tt:1684.709\n",
      "Ep:55, loss:0.00002, loss_test:0.01077, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.631, tt:1715.328\n",
      "Ep:56, loss:0.00002, loss_test:0.01070, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.618, tt:1745.212\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01064, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.602, tt:1774.889\n",
      "Ep:58, loss:0.00002, loss_test:0.01059, lr:6.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:30.597, tt:1805.252\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01055, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:30.647, tt:1838.798\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01048, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:30.653, tt:1869.839\n",
      "Ep:61, loss:0.00001, loss_test:0.01043, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:30.679, tt:1902.070\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01038, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:30.682, tt:1932.965\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01034, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:30.679, tt:1963.428\n",
      "Ep:64, loss:0.00001, loss_test:0.01028, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:30.670, tt:1993.574\n",
      "Ep:65, loss:0.00001, loss_test:0.01022, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:30.667, tt:2024.033\n",
      "Ep:66, loss:0.00001, loss_test:0.01017, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:30.689, tt:2056.136\n",
      "Ep:67, loss:0.00001, loss_test:0.01011, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:30.680, tt:2086.211\n",
      "Ep:68, loss:0.00001, loss_test:0.01008, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:30.682, tt:2117.090\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01005, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.670, tt:2146.912\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01002, lr:6.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:30.662, tt:2177.002\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.00997, lr:6.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:30.655, tt:2207.142\n",
      "Ep:72, loss:0.00001, loss_test:0.00993, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:30.665, tt:2238.522\n",
      "Ep:73, loss:0.00001, loss_test:0.00988, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:30.666, tt:2269.290\n",
      "Ep:74, loss:0.00001, loss_test:0.00985, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:30.663, tt:2299.754\n",
      "Ep:75, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.664, tt:2330.490\n",
      "Ep:76, loss:0.00001, loss_test:0.00980, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.659, tt:2360.713\n",
      "Ep:77, loss:0.00001, loss_test:0.00976, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.678, tt:2392.868\n",
      "Ep:78, loss:0.00001, loss_test:0.00970, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.688, tt:2424.352\n",
      "Ep:79, loss:0.00001, loss_test:0.00966, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.698, tt:2455.815\n",
      "Ep:80, loss:0.00001, loss_test:0.00962, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.706, tt:2487.209\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.00958, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.701, tt:2517.486\n",
      "Ep:82, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.698, tt:2547.924\n",
      "Ep:83, loss:0.00001, loss_test:0.00954, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.680, tt:2577.086\n",
      "Ep:84, loss:0.00001, loss_test:0.00953, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.677, tt:2607.574\n",
      "Ep:85, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.676, tt:2638.154\n",
      "Ep:86, loss:0.00001, loss_test:0.00948, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.684, tt:2669.501\n",
      "Ep:87, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.689, tt:2700.648\n",
      "Ep:88, loss:0.00001, loss_test:0.00943, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:30.693, tt:2731.687\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.00942, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:30.701, tt:2763.100\n",
      "Ep:90, loss:0.00001, loss_test:0.00938, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:30.716, tt:2795.123\n",
      "Ep:91, loss:0.00001, loss_test:0.00936, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.711, tt:2825.407\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.00935, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.719, tt:2856.845\n",
      "Ep:93, loss:0.00001, loss_test:0.00935, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.723, tt:2887.991\n",
      "Ep:94, loss:0.00001, loss_test:0.00934, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.702, tt:2916.686\n",
      "Ep:95, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.672, tt:2944.527\n",
      "Ep:96, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.627, tt:2970.770\n",
      "Ep:97, loss:0.00001, loss_test:0.00928, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.603, tt:2999.085\n",
      "Ep:98, loss:0.00001, loss_test:0.00926, lr:6.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:30.582, tt:3027.629\n",
      "Ep:99, loss:0.00001, loss_test:0.00926, lr:6.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:30.484, tt:3048.366\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.00923, lr:6.00e-02, fs:0.92823 (r=0.980,p=0.882),  time:30.379, tt:3068.261\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.00923, lr:6.00e-02, fs:0.92823 (r=0.980,p=0.882),  time:30.292, tt:3089.830\n",
      "Ep:102, loss:0.00001, loss_test:0.00925, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:30.254, tt:3116.111\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.00923, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:30.230, tt:3143.951\n",
      "Ep:104, loss:0.00001, loss_test:0.00922, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:30.228, tt:3173.928\n",
      "Ep:105, loss:0.00001, loss_test:0.00921, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:30.221, tt:3203.467\n",
      "Ep:106, loss:0.00001, loss_test:0.00920, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:30.226, tt:3234.234\n",
      "Ep:107, loss:0.00001, loss_test:0.00922, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:30.224, tt:3264.205\n",
      "Ep:108, loss:0.00001, loss_test:0.00921, lr:6.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:30.233, tt:3295.389\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:30.261, tt:3328.753\n",
      "Ep:110, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:30.283, tt:3361.466\n",
      "Ep:111, loss:0.00001, loss_test:0.00920, lr:6.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:30.315, tt:3395.238\n",
      "Ep:112, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:30.331, tt:3427.366\n",
      "Ep:113, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:30.343, tt:3459.052\n",
      "Ep:114, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:30.353, tt:3490.640\n",
      "Ep:115, loss:0.00001, loss_test:0.00918, lr:6.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:30.373, tt:3523.293\n",
      "Ep:116, loss:0.00001, loss_test:0.00918, lr:6.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:30.385, tt:3555.041\n",
      "Ep:117, loss:0.00001, loss_test:0.00920, lr:6.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:30.403, tt:3587.556\n",
      "Ep:118, loss:0.00001, loss_test:0.00922, lr:6.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:30.413, tt:3619.184\n",
      "Ep:119, loss:0.00001, loss_test:0.00922, lr:6.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:30.426, tt:3651.087\n",
      "Ep:120, loss:0.00001, loss_test:0.00922, lr:5.94e-02, fs:0.93532 (r=0.949,p=0.922),  time:30.440, tt:3683.253\n",
      "Ep:121, loss:0.00001, loss_test:0.00922, lr:5.88e-02, fs:0.94000 (r=0.949,p=0.931),  time:30.453, tt:3715.316\n",
      "Ep:122, loss:0.00001, loss_test:0.00922, lr:5.82e-02, fs:0.94472 (r=0.949,p=0.940),  time:30.457, tt:3746.270\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.00924, lr:5.82e-02, fs:0.94472 (r=0.949,p=0.940),  time:30.461, tt:3777.178\n",
      "Ep:124, loss:0.00001, loss_test:0.00925, lr:5.82e-02, fs:0.94472 (r=0.949,p=0.940),  time:30.478, tt:3809.770\n",
      "Ep:125, loss:0.00001, loss_test:0.00928, lr:5.82e-02, fs:0.94949 (r=0.949,p=0.949),  time:30.477, tt:3840.106\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00001, loss_test:0.00927, lr:5.82e-02, fs:0.94949 (r=0.949,p=0.949),  time:30.480, tt:3870.907\n",
      "Ep:127, loss:0.00001, loss_test:0.00927, lr:5.82e-02, fs:0.95431 (r=0.949,p=0.959),  time:30.478, tt:3901.181\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.00930, lr:5.82e-02, fs:0.94949 (r=0.949,p=0.949),  time:30.490, tt:3933.246\n",
      "Ep:129, loss:0.00001, loss_test:0.00930, lr:5.82e-02, fs:0.94416 (r=0.939,p=0.949),  time:30.483, tt:3962.730\n",
      "Ep:130, loss:0.00001, loss_test:0.00928, lr:5.82e-02, fs:0.94898 (r=0.939,p=0.959),  time:30.470, tt:3991.525\n",
      "Ep:131, loss:0.00001, loss_test:0.00930, lr:5.82e-02, fs:0.94898 (r=0.939,p=0.959),  time:30.473, tt:4022.467\n",
      "Ep:132, loss:0.00001, loss_test:0.00933, lr:5.82e-02, fs:0.94416 (r=0.939,p=0.949),  time:30.480, tt:4053.843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.00933, lr:5.82e-02, fs:0.93814 (r=0.919,p=0.958),  time:30.474, tt:4083.490\n",
      "Ep:134, loss:0.00001, loss_test:0.00937, lr:5.82e-02, fs:0.92708 (r=0.899,p=0.957),  time:30.483, tt:4115.182\n",
      "Ep:135, loss:0.00001, loss_test:0.00939, lr:5.82e-02, fs:0.93264 (r=0.909,p=0.957),  time:30.479, tt:4145.165\n",
      "Ep:136, loss:0.00001, loss_test:0.00937, lr:5.82e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.482, tt:4176.058\n",
      "Ep:137, loss:0.00001, loss_test:0.00937, lr:5.82e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.476, tt:4205.625\n",
      "Ep:138, loss:0.00001, loss_test:0.00941, lr:5.82e-02, fs:0.92708 (r=0.899,p=0.957),  time:30.471, tt:4235.444\n",
      "Ep:139, loss:0.00001, loss_test:0.00943, lr:5.76e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.471, tt:4265.932\n",
      "Ep:140, loss:0.00001, loss_test:0.00942, lr:5.71e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.471, tt:4296.344\n",
      "Ep:141, loss:0.00001, loss_test:0.00944, lr:5.65e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.478, tt:4327.808\n",
      "Ep:142, loss:0.00001, loss_test:0.00946, lr:5.59e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.473, tt:4357.571\n",
      "Ep:143, loss:0.00001, loss_test:0.00947, lr:5.54e-02, fs:0.92147 (r=0.889,p=0.957),  time:30.484, tt:4389.687\n",
      "Ep:144, loss:0.00000, loss_test:0.00949, lr:5.48e-02, fs:0.91579 (r=0.879,p=0.956),  time:30.500, tt:4422.443\n",
      "Ep:145, loss:0.00000, loss_test:0.00951, lr:5.43e-02, fs:0.91579 (r=0.879,p=0.956),  time:30.517, tt:4455.432\n",
      "Ep:146, loss:0.00000, loss_test:0.00951, lr:5.37e-02, fs:0.91005 (r=0.869,p=0.956),  time:30.534, tt:4488.479\n",
      "Ep:147, loss:0.00000, loss_test:0.00951, lr:5.32e-02, fs:0.91005 (r=0.869,p=0.956),  time:30.544, tt:4520.458\n",
      "Ep:148, loss:0.00000, loss_test:0.00954, lr:5.27e-02, fs:0.91005 (r=0.869,p=0.956),  time:30.545, tt:4551.161\n",
      "Ep:149, loss:0.00000, loss_test:0.00955, lr:5.21e-02, fs:0.91005 (r=0.869,p=0.956),  time:30.560, tt:4583.940\n",
      "Ep:150, loss:0.00000, loss_test:0.00954, lr:5.16e-02, fs:0.91005 (r=0.869,p=0.956),  time:30.572, tt:4616.304\n",
      "Ep:151, loss:0.00000, loss_test:0.00956, lr:5.11e-02, fs:0.91005 (r=0.869,p=0.956),  time:30.572, tt:4646.953\n",
      "Ep:152, loss:0.00000, loss_test:0.00959, lr:5.06e-02, fs:0.90426 (r=0.859,p=0.955),  time:30.574, tt:4677.771\n",
      "Ep:153, loss:0.00000, loss_test:0.00961, lr:5.01e-02, fs:0.90426 (r=0.859,p=0.955),  time:30.576, tt:4708.698\n",
      "Ep:154, loss:0.00000, loss_test:0.00961, lr:4.96e-02, fs:0.90426 (r=0.859,p=0.955),  time:30.582, tt:4740.245\n",
      "Ep:155, loss:0.00000, loss_test:0.00962, lr:4.91e-02, fs:0.90426 (r=0.859,p=0.955),  time:30.589, tt:4771.824\n",
      "Ep:156, loss:0.00000, loss_test:0.00962, lr:4.86e-02, fs:0.89840 (r=0.848,p=0.955),  time:30.591, tt:4802.823\n",
      "Ep:157, loss:0.00000, loss_test:0.00967, lr:4.81e-02, fs:0.89840 (r=0.848,p=0.955),  time:30.599, tt:4834.606\n",
      "Ep:158, loss:0.00000, loss_test:0.00967, lr:4.76e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.598, tt:4865.022\n",
      "Ep:159, loss:0.00000, loss_test:0.00967, lr:4.71e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.603, tt:4896.441\n",
      "Ep:160, loss:0.00000, loss_test:0.00970, lr:4.67e-02, fs:0.89840 (r=0.848,p=0.955),  time:30.610, tt:4928.236\n",
      "Ep:161, loss:0.00000, loss_test:0.00970, lr:4.62e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.625, tt:4961.212\n",
      "Ep:162, loss:0.00000, loss_test:0.00970, lr:4.57e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.632, tt:4993.020\n",
      "Ep:163, loss:0.00000, loss_test:0.00973, lr:4.53e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.629, tt:5023.107\n",
      "Ep:164, loss:0.00000, loss_test:0.00975, lr:4.48e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.632, tt:5054.325\n",
      "Ep:165, loss:0.00000, loss_test:0.00976, lr:4.44e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.632, tt:5084.884\n",
      "Ep:166, loss:0.00000, loss_test:0.00978, lr:4.39e-02, fs:0.88649 (r=0.828,p=0.953),  time:30.631, tt:5115.315\n",
      "Ep:167, loss:0.00000, loss_test:0.00980, lr:4.35e-02, fs:0.88649 (r=0.828,p=0.953),  time:30.630, tt:5145.766\n",
      "Ep:168, loss:0.00000, loss_test:0.00981, lr:4.31e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.632, tt:5176.728\n",
      "Ep:169, loss:0.00000, loss_test:0.00981, lr:4.26e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.639, tt:5208.620\n",
      "Ep:170, loss:0.00000, loss_test:0.00983, lr:4.22e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.647, tt:5240.620\n",
      "Ep:171, loss:0.00000, loss_test:0.00983, lr:4.18e-02, fs:0.88525 (r=0.818,p=0.964),  time:30.647, tt:5271.272\n",
      "Ep:172, loss:0.00000, loss_test:0.00985, lr:4.14e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.647, tt:5301.956\n",
      "Ep:173, loss:0.00000, loss_test:0.00988, lr:4.10e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.654, tt:5333.723\n",
      "Ep:174, loss:0.00000, loss_test:0.00987, lr:4.05e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.653, tt:5364.230\n",
      "Ep:175, loss:0.00000, loss_test:0.00988, lr:4.01e-02, fs:0.85393 (r=0.768,p=0.962),  time:30.658, tt:5395.814\n",
      "Ep:176, loss:0.00000, loss_test:0.00989, lr:3.97e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.665, tt:5427.742\n",
      "Ep:177, loss:0.00000, loss_test:0.00991, lr:3.93e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.670, tt:5459.298\n",
      "Ep:178, loss:0.00000, loss_test:0.00991, lr:3.89e-02, fs:0.84270 (r=0.758,p=0.949),  time:30.677, tt:5491.164\n",
      "Ep:179, loss:0.00000, loss_test:0.00994, lr:3.86e-02, fs:0.82759 (r=0.727,p=0.960),  time:30.671, tt:5520.817\n",
      "Ep:180, loss:0.00000, loss_test:0.00995, lr:3.82e-02, fs:0.81395 (r=0.707,p=0.959),  time:30.673, tt:5551.816\n",
      "Ep:181, loss:0.00000, loss_test:0.00995, lr:3.78e-02, fs:0.82759 (r=0.727,p=0.960),  time:30.681, tt:5583.891\n",
      "Ep:182, loss:0.00000, loss_test:0.00996, lr:3.74e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.682, tt:5614.883\n",
      "Ep:183, loss:0.00000, loss_test:0.01000, lr:3.70e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.688, tt:5646.624\n",
      "Ep:184, loss:0.00000, loss_test:0.01001, lr:3.67e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.693, tt:5678.239\n",
      "Ep:185, loss:0.00000, loss_test:0.01001, lr:3.63e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.698, tt:5709.749\n",
      "Ep:186, loss:0.00000, loss_test:0.01004, lr:3.59e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.699, tt:5740.657\n",
      "Ep:187, loss:0.00000, loss_test:0.01005, lr:3.56e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.702, tt:5772.023\n",
      "Ep:188, loss:0.00000, loss_test:0.01005, lr:3.52e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.710, tt:5804.186\n",
      "Ep:189, loss:0.00000, loss_test:0.01004, lr:3.49e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.716, tt:5836.072\n",
      "Ep:190, loss:0.00000, loss_test:0.01005, lr:3.45e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.724, tt:5868.290\n",
      "Ep:191, loss:0.00000, loss_test:0.01008, lr:3.42e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.736, tt:5901.222\n",
      "Ep:192, loss:0.00000, loss_test:0.01009, lr:3.38e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.735, tt:5931.869\n",
      "Ep:193, loss:0.00000, loss_test:0.01011, lr:3.35e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.744, tt:5964.264\n",
      "Ep:194, loss:0.00000, loss_test:0.01014, lr:3.32e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.741, tt:5994.416\n",
      "Ep:195, loss:0.00000, loss_test:0.01013, lr:3.28e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.743, tt:6025.624\n",
      "Ep:196, loss:0.00000, loss_test:0.01013, lr:3.25e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.752, tt:6058.167\n",
      "Ep:197, loss:0.00000, loss_test:0.01013, lr:3.22e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.754, tt:6089.249\n",
      "Ep:198, loss:0.00000, loss_test:0.01016, lr:3.19e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.759, tt:6120.965\n",
      "Ep:199, loss:0.00000, loss_test:0.01017, lr:3.15e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.763, tt:6152.683\n",
      "Ep:200, loss:0.00000, loss_test:0.01017, lr:3.12e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.763, tt:6183.446\n",
      "Ep:201, loss:0.00000, loss_test:0.01019, lr:3.09e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.771, tt:6215.794\n",
      "Ep:202, loss:0.00000, loss_test:0.01019, lr:3.06e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.759, tt:6244.034\n",
      "Ep:203, loss:0.00000, loss_test:0.01019, lr:3.03e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.767, tt:6276.474\n",
      "Ep:204, loss:0.00000, loss_test:0.01021, lr:3.00e-02, fs:0.81176 (r=0.697,p=0.972),  time:30.771, tt:6308.093\n",
      "Ep:205, loss:0.00000, loss_test:0.01023, lr:2.97e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.775, tt:6339.644\n",
      "Ep:206, loss:0.00000, loss_test:0.01023, lr:2.94e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.772, tt:6369.762\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13850, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.252, tt:31.252\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13684, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.225, tt:62.449\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13403, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.553, tt:94.659\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12979, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:31.827, tt:127.308\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12369, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:32.012, tt:160.061\n",
      "Ep:5, loss:0.00026, loss_test:0.11664, lr:1.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:32.193, tt:193.156\n",
      "Ep:6, loss:0.00025, loss_test:0.10937, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:32.247, tt:225.731\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10380, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:32.249, tt:257.992\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10118, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:32.106, tt:288.958\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10036, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:32.160, tt:321.603\n",
      "Ep:10, loss:0.00022, loss_test:0.10000, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:32.330, tt:355.627\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09605, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:32.420, tt:389.036\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09256, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:32.493, tt:422.406\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09106, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:32.426, tt:453.963\n",
      "Ep:14, loss:0.00020, loss_test:0.08974, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:32.395, tt:485.931\n",
      "Ep:15, loss:0.00019, loss_test:0.08754, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:32.537, tt:520.598\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.08579, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:32.598, tt:554.174\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.08425, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:32.729, tt:589.131\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08326, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:32.697, tt:621.243\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08105, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:32.693, tt:653.864\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08018, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:32.631, tt:685.253\n",
      "Ep:21, loss:0.00016, loss_test:0.07943, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:32.579, tt:716.729\n",
      "Ep:22, loss:0.00016, loss_test:0.07699, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:32.653, tt:751.024\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.07533, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:32.668, tt:784.025\n",
      "Ep:24, loss:0.00015, loss_test:0.07431, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:32.664, tt:816.588\n",
      "Ep:25, loss:0.00015, loss_test:0.07370, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:32.631, tt:848.411\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.07177, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:32.533, tt:878.389\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.07054, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:32.499, tt:909.962\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.07001, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:32.487, tt:942.118\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.06842, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:32.501, tt:975.043\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.06729, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:32.469, tt:1006.533\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.06629, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:32.435, tt:1037.906\n",
      "Ep:32, loss:0.00012, loss_test:0.06511, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:32.461, tt:1071.225\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06414, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:32.440, tt:1102.954\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.06366, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:32.434, tt:1135.189\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.06264, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:32.427, tt:1167.382\n",
      "Ep:36, loss:0.00011, loss_test:0.06157, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:32.412, tt:1199.252\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.06086, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:32.370, tt:1230.045\n",
      "Ep:38, loss:0.00011, loss_test:0.05990, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:32.332, tt:1260.957\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.05883, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:32.317, tt:1292.695\n",
      "Ep:40, loss:0.00010, loss_test:0.05821, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:32.334, tt:1325.701\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.05765, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:32.350, tt:1358.697\n",
      "Ep:42, loss:0.00010, loss_test:0.05594, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:32.392, tt:1392.873\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.05585, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:32.364, tt:1424.036\n",
      "Ep:44, loss:0.00009, loss_test:0.05480, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:32.363, tt:1456.332\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.05438, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:32.386, tt:1489.779\n",
      "Ep:46, loss:0.00009, loss_test:0.05323, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:32.368, tt:1521.318\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.05379, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:32.355, tt:1553.024\n",
      "Ep:48, loss:0.00008, loss_test:0.05326, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:32.364, tt:1585.812\n",
      "Ep:49, loss:0.00008, loss_test:0.05200, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:32.360, tt:1617.990\n",
      "Ep:50, loss:0.00008, loss_test:0.05193, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:32.327, tt:1648.676\n",
      "Ep:51, loss:0.00008, loss_test:0.05103, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:32.302, tt:1679.681\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.05140, lr:1.00e-02, fs:0.93204 (r=0.970,p=0.897),  time:32.280, tt:1710.823\n",
      "Ep:53, loss:0.00007, loss_test:0.04999, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:32.243, tt:1741.111\n",
      "Ep:54, loss:0.00007, loss_test:0.04993, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:32.231, tt:1772.680\n",
      "Ep:55, loss:0.00007, loss_test:0.04898, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:32.225, tt:1804.579\n",
      "Ep:56, loss:0.00007, loss_test:0.04927, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:32.245, tt:1837.938\n",
      "Ep:57, loss:0.00006, loss_test:0.04848, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:32.250, tt:1870.472\n",
      "Ep:58, loss:0.00006, loss_test:0.04804, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:32.256, tt:1903.104\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.04774, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:32.251, tt:1935.071\n",
      "Ep:60, loss:0.00006, loss_test:0.04759, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:32.237, tt:1966.447\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.04711, lr:1.00e-02, fs:0.95567 (r=0.980,p=0.933),  time:32.250, tt:1999.519\n",
      "Ep:62, loss:0.00006, loss_test:0.04600, lr:1.00e-02, fs:0.94949 (r=0.949,p=0.949),  time:32.255, tt:2032.069\n",
      "Ep:63, loss:0.00006, loss_test:0.04583, lr:1.00e-02, fs:0.96078 (r=0.990,p=0.933),  time:32.265, tt:2064.933\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.04508, lr:1.00e-02, fs:0.96517 (r=0.980,p=0.951),  time:32.287, tt:2098.668\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.04497, lr:1.00e-02, fs:0.96078 (r=0.990,p=0.933),  time:32.269, tt:2129.770\n",
      "Ep:66, loss:0.00005, loss_test:0.04460, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:32.276, tt:2162.521\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.04417, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:32.293, tt:2195.936\n",
      "Ep:68, loss:0.00005, loss_test:0.04390, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:32.298, tt:2228.597\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.04353, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:32.291, tt:2260.384\n",
      "Ep:70, loss:0.00005, loss_test:0.04264, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:32.271, tt:2291.248\n",
      "Ep:71, loss:0.00005, loss_test:0.04270, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:32.276, tt:2323.884\n",
      "Ep:72, loss:0.00005, loss_test:0.04247, lr:1.00e-02, fs:0.97030 (r=0.990,p=0.951),  time:32.232, tt:2352.919\n",
      "Ep:73, loss:0.00004, loss_test:0.04305, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:32.230, tt:2385.040\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.04323, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:32.233, tt:2417.500\n",
      "Ep:75, loss:0.00004, loss_test:0.04221, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:32.243, tt:2450.500\n",
      "Ep:76, loss:0.00004, loss_test:0.04190, lr:1.00e-02, fs:0.97030 (r=0.990,p=0.951),  time:32.265, tt:2484.371\n",
      "Ep:77, loss:0.00004, loss_test:0.04174, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:32.266, tt:2516.731\n",
      "Ep:78, loss:0.00004, loss_test:0.04183, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:32.263, tt:2548.750\n",
      "Ep:79, loss:0.00004, loss_test:0.04118, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:32.284, tt:2582.685\n",
      "Ep:80, loss:0.00004, loss_test:0.04167, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:32.288, tt:2615.360\n",
      "Ep:81, loss:0.00004, loss_test:0.04058, lr:1.00e-02, fs:0.97030 (r=0.990,p=0.951),  time:32.274, tt:2646.504\n",
      "Ep:82, loss:0.00003, loss_test:0.04141, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:32.293, tt:2680.335\n",
      "Ep:83, loss:0.00003, loss_test:0.04044, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:32.290, tt:2712.349\n",
      "Ep:84, loss:0.00003, loss_test:0.03978, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:32.306, tt:2746.009\n",
      "Ep:85, loss:0.00003, loss_test:0.04034, lr:9.90e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.312, tt:2778.799\n",
      "Ep:86, loss:0.00003, loss_test:0.03933, lr:9.80e-03, fs:0.97030 (r=0.990,p=0.951),  time:32.305, tt:2810.523\n",
      "Ep:87, loss:0.00003, loss_test:0.04013, lr:9.70e-03, fs:0.98492 (r=0.990,p=0.980),  time:32.273, tt:2840.012\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.03921, lr:9.70e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.266, tt:2871.645\n",
      "Ep:89, loss:0.00003, loss_test:0.03939, lr:9.70e-03, fs:0.98492 (r=0.990,p=0.980),  time:32.277, tt:2904.924\n",
      "Ep:90, loss:0.00003, loss_test:0.03893, lr:9.70e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.255, tt:2935.231\n",
      "Ep:91, loss:0.00003, loss_test:0.03864, lr:9.70e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.237, tt:2965.835\n",
      "Ep:92, loss:0.00003, loss_test:0.03988, lr:9.70e-03, fs:0.98492 (r=0.990,p=0.980),  time:32.221, tt:2996.566\n",
      "Ep:93, loss:0.00003, loss_test:0.03833, lr:9.70e-03, fs:0.96552 (r=0.990,p=0.942),  time:32.198, tt:3026.621\n",
      "Ep:94, loss:0.00003, loss_test:0.03958, lr:9.70e-03, fs:0.98492 (r=0.990,p=0.980),  time:32.171, tt:3056.217\n",
      "Ep:95, loss:0.00003, loss_test:0.03859, lr:9.70e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.132, tt:3084.711\n",
      "Ep:96, loss:0.00003, loss_test:0.03941, lr:9.70e-03, fs:0.98492 (r=0.990,p=0.980),  time:32.105, tt:3114.170\n",
      "Ep:97, loss:0.00003, loss_test:0.03799, lr:9.70e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.062, tt:3142.089\n",
      "Ep:98, loss:0.00002, loss_test:0.03781, lr:9.70e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.057, tt:3173.656\n",
      "Ep:99, loss:0.00002, loss_test:0.03900, lr:9.61e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.061, tt:3206.127\n",
      "Ep:100, loss:0.00002, loss_test:0.03739, lr:9.51e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.058, tt:3237.886\n",
      "Ep:101, loss:0.00002, loss_test:0.03818, lr:9.41e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.062, tt:3270.361\n",
      "Ep:102, loss:0.00002, loss_test:0.03752, lr:9.32e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.084, tt:3304.616\n",
      "Ep:103, loss:0.00002, loss_test:0.03763, lr:9.23e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.095, tt:3337.901\n",
      "Ep:104, loss:0.00002, loss_test:0.03763, lr:9.14e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.110, tt:3371.511\n",
      "Ep:105, loss:0.00002, loss_test:0.03758, lr:9.04e-03, fs:0.98492 (r=0.990,p=0.980),  time:32.120, tt:3404.717\n",
      "Ep:106, loss:0.00002, loss_test:0.03739, lr:8.95e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.124, tt:3437.269\n",
      "Ep:107, loss:0.00002, loss_test:0.03716, lr:8.86e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.135, tt:3470.541\n",
      "Ep:108, loss:0.00002, loss_test:0.03688, lr:8.78e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.143, tt:3503.635\n",
      "Ep:109, loss:0.00002, loss_test:0.03659, lr:8.69e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.156, tt:3537.178\n",
      "Ep:110, loss:0.00002, loss_test:0.03783, lr:8.60e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.190, tt:3573.049\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00002, loss_test:0.03665, lr:8.60e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.211, tt:3607.622\n",
      "Ep:112, loss:0.00002, loss_test:0.03652, lr:8.60e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.223, tt:3641.181\n",
      "Ep:113, loss:0.00002, loss_test:0.03701, lr:8.60e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.242, tt:3675.584\n",
      "Ep:114, loss:0.00002, loss_test:0.03604, lr:8.60e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.253, tt:3709.086\n",
      "Ep:115, loss:0.00002, loss_test:0.03724, lr:8.60e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.271, tt:3743.453\n",
      "Ep:116, loss:0.00002, loss_test:0.03668, lr:8.60e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.293, tt:3778.312\n",
      "Ep:117, loss:0.00002, loss_test:0.03582, lr:8.60e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.308, tt:3812.311\n",
      "Ep:118, loss:0.00002, loss_test:0.03793, lr:8.60e-03, fs:0.96970 (r=0.970,p=0.970),  time:32.312, tt:3845.171\n",
      "Ep:119, loss:0.00002, loss_test:0.03549, lr:8.60e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.327, tt:3879.217\n",
      "Ep:120, loss:0.00002, loss_test:0.03653, lr:8.60e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.351, tt:3914.456\n",
      "Ep:121, loss:0.00002, loss_test:0.03625, lr:8.60e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.362, tt:3948.205\n",
      "Ep:122, loss:0.00002, loss_test:0.03562, lr:8.51e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.373, tt:3981.941\n",
      "Ep:123, loss:0.00002, loss_test:0.03679, lr:8.43e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.381, tt:4015.208\n",
      "Ep:124, loss:0.00002, loss_test:0.03579, lr:8.35e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.399, tt:4049.907\n",
      "Ep:125, loss:0.00001, loss_test:0.03650, lr:8.26e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.411, tt:4083.828\n",
      "Ep:126, loss:0.00001, loss_test:0.03626, lr:8.18e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.405, tt:4115.415\n",
      "Ep:127, loss:0.00001, loss_test:0.03487, lr:8.10e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.406, tt:4147.938\n",
      "Ep:128, loss:0.00001, loss_test:0.03712, lr:8.02e-03, fs:0.96970 (r=0.970,p=0.970),  time:32.408, tt:4180.629\n",
      "Ep:129, loss:0.00001, loss_test:0.03480, lr:7.94e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.422, tt:4214.924\n",
      "Ep:130, loss:0.00001, loss_test:0.03586, lr:7.86e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.415, tt:4246.345\n",
      "Ep:131, loss:0.00001, loss_test:0.03652, lr:7.78e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.425, tt:4280.132\n",
      "Ep:132, loss:0.00001, loss_test:0.03486, lr:7.70e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.431, tt:4313.375\n",
      "Ep:133, loss:0.00001, loss_test:0.03666, lr:7.62e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.439, tt:4346.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.03603, lr:7.55e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.441, tt:4379.585\n",
      "Ep:135, loss:0.00001, loss_test:0.03498, lr:7.47e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.451, tt:4413.329\n",
      "Ep:136, loss:0.00001, loss_test:0.03599, lr:7.40e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.469, tt:4448.279\n",
      "Ep:137, loss:0.00001, loss_test:0.03521, lr:7.32e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.477, tt:4481.803\n",
      "Ep:138, loss:0.00001, loss_test:0.03524, lr:7.25e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.483, tt:4515.187\n",
      "Ep:139, loss:0.00001, loss_test:0.03531, lr:7.18e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.476, tt:4546.638\n",
      "Ep:140, loss:0.00001, loss_test:0.03532, lr:7.11e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.472, tt:4578.616\n",
      "Ep:141, loss:0.00001, loss_test:0.03537, lr:7.03e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.467, tt:4610.255\n",
      "Ep:142, loss:0.00001, loss_test:0.03533, lr:6.96e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.464, tt:4642.311\n",
      "Ep:143, loss:0.00001, loss_test:0.03533, lr:6.89e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.463, tt:4674.732\n",
      "Ep:144, loss:0.00001, loss_test:0.03527, lr:6.83e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.455, tt:4705.952\n",
      "Ep:145, loss:0.00001, loss_test:0.03553, lr:6.76e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.447, tt:4737.331\n",
      "Ep:146, loss:0.00001, loss_test:0.03530, lr:6.69e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.432, tt:4767.495\n",
      "Ep:147, loss:0.00001, loss_test:0.03510, lr:6.62e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.439, tt:4800.914\n",
      "Ep:148, loss:0.00001, loss_test:0.03570, lr:6.56e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.442, tt:4833.927\n",
      "Ep:149, loss:0.00001, loss_test:0.03557, lr:6.49e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.441, tt:4866.191\n",
      "Ep:150, loss:0.00001, loss_test:0.03472, lr:6.43e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.428, tt:4896.603\n",
      "Ep:151, loss:0.00001, loss_test:0.03520, lr:6.36e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.435, tt:4930.123\n",
      "Ep:152, loss:0.00001, loss_test:0.03586, lr:6.30e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.440, tt:4963.282\n",
      "Ep:153, loss:0.00001, loss_test:0.03440, lr:6.24e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.441, tt:4995.906\n",
      "Ep:154, loss:0.00001, loss_test:0.03565, lr:6.17e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.425, tt:5025.945\n",
      "Ep:155, loss:0.00001, loss_test:0.03565, lr:6.11e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.428, tt:5058.739\n",
      "Ep:156, loss:0.00001, loss_test:0.03481, lr:6.05e-03, fs:0.98020 (r=1.000,p=0.961),  time:32.433, tt:5091.910\n",
      "Ep:157, loss:0.00001, loss_test:0.03571, lr:5.99e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.420, tt:5122.282\n",
      "Ep:158, loss:0.00001, loss_test:0.03555, lr:5.93e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.416, tt:5154.090\n",
      "Ep:159, loss:0.00001, loss_test:0.03536, lr:5.87e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.412, tt:5185.849\n",
      "Ep:160, loss:0.00001, loss_test:0.03621, lr:5.81e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.402, tt:5216.726\n",
      "Ep:161, loss:0.00001, loss_test:0.03616, lr:5.75e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.400, tt:5248.749\n",
      "Ep:162, loss:0.00001, loss_test:0.03591, lr:5.70e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.400, tt:5281.164\n",
      "##########Best model found so far##########\n",
      "Ep:163, loss:0.00001, loss_test:0.03572, lr:5.70e-03, fs:0.97512 (r=0.990,p=0.961),  time:32.395, tt:5312.791\n",
      "Ep:164, loss:0.00001, loss_test:0.03613, lr:5.70e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.403, tt:5346.545\n",
      "Ep:165, loss:0.00001, loss_test:0.03607, lr:5.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.397, tt:5377.873\n",
      "Ep:166, loss:0.00001, loss_test:0.03489, lr:5.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.396, tt:5410.160\n",
      "Ep:167, loss:0.00001, loss_test:0.03611, lr:5.70e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.408, tt:5444.611\n",
      "Ep:168, loss:0.00001, loss_test:0.03609, lr:5.70e-03, fs:0.98000 (r=0.990,p=0.970),  time:32.416, tt:5478.362\n",
      "Ep:169, loss:0.00001, loss_test:0.03511, lr:5.70e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.417, tt:5510.840\n",
      "Ep:170, loss:0.00001, loss_test:0.03587, lr:5.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.414, tt:5542.875\n",
      "Ep:171, loss:0.00001, loss_test:0.03588, lr:5.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.430, tt:5577.942\n",
      "Ep:172, loss:0.00001, loss_test:0.03548, lr:5.70e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.434, tt:5611.033\n",
      "Ep:173, loss:0.00001, loss_test:0.03536, lr:5.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.434, tt:5643.526\n",
      "Ep:174, loss:0.00001, loss_test:0.03564, lr:5.64e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.439, tt:5676.800\n",
      "Ep:175, loss:0.00001, loss_test:0.03545, lr:5.58e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.443, tt:5710.040\n",
      "Ep:176, loss:0.00001, loss_test:0.03554, lr:5.53e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.443, tt:5742.391\n",
      "Ep:177, loss:0.00001, loss_test:0.03525, lr:5.47e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.447, tt:5775.574\n",
      "Ep:178, loss:0.00001, loss_test:0.03580, lr:5.42e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.457, tt:5809.733\n",
      "Ep:179, loss:0.00001, loss_test:0.03593, lr:5.36e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.462, tt:5843.171\n",
      "Ep:180, loss:0.00001, loss_test:0.03510, lr:5.31e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.462, tt:5875.546\n",
      "Ep:181, loss:0.00001, loss_test:0.03627, lr:5.26e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.457, tt:5907.181\n",
      "Ep:182, loss:0.00001, loss_test:0.03601, lr:5.20e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.452, tt:5938.679\n",
      "Ep:183, loss:0.00001, loss_test:0.03522, lr:5.15e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.452, tt:5971.122\n",
      "Ep:184, loss:0.00001, loss_test:0.03595, lr:5.10e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.453, tt:6003.884\n",
      "Ep:185, loss:0.00001, loss_test:0.03560, lr:5.05e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.467, tt:6038.856\n",
      "Ep:186, loss:0.00001, loss_test:0.03509, lr:5.00e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.468, tt:6071.563\n",
      "Ep:187, loss:0.00001, loss_test:0.03609, lr:4.95e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.479, tt:6105.990\n",
      "Ep:188, loss:0.00001, loss_test:0.03599, lr:4.90e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.485, tt:6139.581\n",
      "Ep:189, loss:0.00001, loss_test:0.03513, lr:4.85e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.488, tt:6172.777\n",
      "Ep:190, loss:0.00001, loss_test:0.03582, lr:4.80e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.493, tt:6206.183\n",
      "Ep:191, loss:0.00001, loss_test:0.03559, lr:4.75e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.498, tt:6239.693\n",
      "Ep:192, loss:0.00001, loss_test:0.03567, lr:4.71e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.503, tt:6273.108\n",
      "Ep:193, loss:0.00001, loss_test:0.03559, lr:4.66e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.508, tt:6306.528\n",
      "Ep:194, loss:0.00001, loss_test:0.03565, lr:4.61e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.514, tt:6340.276\n",
      "Ep:195, loss:0.00001, loss_test:0.03580, lr:4.57e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.509, tt:6371.831\n",
      "Ep:196, loss:0.00001, loss_test:0.03554, lr:4.52e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.500, tt:6402.414\n",
      "Ep:197, loss:0.00001, loss_test:0.03570, lr:4.48e-03, fs:0.98507 (r=1.000,p=0.971),  time:32.503, tt:6435.533\n",
      "Ep:198, loss:0.00001, loss_test:0.03577, lr:4.43e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.511, tt:6469.614\n",
      "Ep:199, loss:0.00001, loss_test:0.03554, lr:4.39e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.512, tt:6502.381\n",
      "Ep:200, loss:0.00001, loss_test:0.03598, lr:4.34e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.512, tt:6534.892\n",
      "Ep:201, loss:0.00001, loss_test:0.03650, lr:4.30e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.517, tt:6568.443\n",
      "Ep:202, loss:0.00001, loss_test:0.03604, lr:4.26e-03, fs:0.99497 (r=1.000,p=0.990),  time:32.532, tt:6603.994\n",
      "Ep:203, loss:0.00001, loss_test:0.03550, lr:4.21e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.531, tt:6636.368\n",
      "Ep:204, loss:0.00001, loss_test:0.03580, lr:4.17e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.532, tt:6669.031\n",
      "Ep:205, loss:0.00001, loss_test:0.03587, lr:4.13e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.526, tt:6700.438\n",
      "Ep:206, loss:0.00001, loss_test:0.03580, lr:4.09e-03, fs:0.99000 (r=1.000,p=0.980),  time:32.528, tt:6733.237\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02080, lr:6.00e-02, fs:0.61947 (r=0.707,p=0.551),  time:30.962, tt:30.962\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02009, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:30.450, tt:60.901\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02093, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.140, tt:90.419\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02081, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.998, tt:119.991\n",
      "Ep:4, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:29.973, tt:149.866\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01905, lr:6.00e-02, fs:0.68794 (r=0.980,p=0.530),  time:29.810, tt:178.862\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01813, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:29.619, tt:207.336\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01760, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:29.650, tt:237.201\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01728, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:29.486, tt:265.377\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01687, lr:6.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:29.550, tt:295.503\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:29.560, tt:325.156\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:29.818, tt:357.822\n",
      "Ep:12, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.71587 (r=0.980,p=0.564),  time:29.891, tt:388.585\n",
      "Ep:13, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.71910 (r=0.970,p=0.571),  time:29.999, tt:419.992\n",
      "Ep:14, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:30.307, tt:454.611\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:30.353, tt:485.646\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01560, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:30.437, tt:517.423\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01540, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:30.473, tt:548.516\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01521, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:30.434, tt:578.242\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01502, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:30.437, tt:608.736\n",
      "Ep:20, loss:0.00003, loss_test:0.01485, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:30.465, tt:639.770\n",
      "Ep:21, loss:0.00003, loss_test:0.01467, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:30.423, tt:669.309\n",
      "Ep:22, loss:0.00003, loss_test:0.01452, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:30.399, tt:699.176\n",
      "Ep:23, loss:0.00003, loss_test:0.01438, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:30.362, tt:728.679\n",
      "Ep:24, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:30.392, tt:759.799\n",
      "Ep:25, loss:0.00003, loss_test:0.01415, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:30.435, tt:791.307\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01402, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:30.431, tt:821.628\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01391, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:30.460, tt:852.892\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:30.447, tt:882.965\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:30.399, tt:911.973\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01366, lr:6.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:30.375, tt:941.610\n",
      "Ep:31, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:30.431, tt:973.793\n",
      "Ep:32, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.381, tt:1002.564\n",
      "Ep:33, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:30.417, tt:1034.194\n",
      "Ep:34, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:30.418, tt:1064.636\n",
      "Ep:35, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:30.420, tt:1095.130\n",
      "Ep:36, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.545, tt:1130.175\n",
      "Ep:37, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.532, tt:1160.219\n",
      "Ep:38, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:30.544, tt:1191.211\n",
      "Ep:39, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:30.558, tt:1222.336\n",
      "Ep:40, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:30.564, tt:1253.115\n",
      "Ep:41, loss:0.00002, loss_test:0.01289, lr:5.94e-02, fs:0.77143 (r=0.818,p=0.730),  time:30.584, tt:1284.525\n",
      "Ep:42, loss:0.00002, loss_test:0.01283, lr:5.88e-02, fs:0.77725 (r=0.828,p=0.732),  time:30.580, tt:1314.936\n",
      "Ep:43, loss:0.00002, loss_test:0.01280, lr:5.82e-02, fs:0.77512 (r=0.818,p=0.736),  time:30.566, tt:1344.882\n",
      "Ep:44, loss:0.00002, loss_test:0.01276, lr:5.76e-02, fs:0.77885 (r=0.818,p=0.743),  time:30.529, tt:1373.826\n",
      "Ep:45, loss:0.00002, loss_test:0.01273, lr:5.71e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.500, tt:1402.981\n",
      "Ep:46, loss:0.00002, loss_test:0.01268, lr:5.65e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.499, tt:1433.436\n",
      "Ep:47, loss:0.00002, loss_test:0.01265, lr:5.59e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.502, tt:1464.108\n",
      "Ep:48, loss:0.00002, loss_test:0.01262, lr:5.54e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.495, tt:1494.260\n",
      "Ep:49, loss:0.00002, loss_test:0.01258, lr:5.48e-02, fs:0.76098 (r=0.788,p=0.736),  time:30.495, tt:1524.775\n",
      "Ep:50, loss:0.00002, loss_test:0.01256, lr:5.43e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.511, tt:1556.039\n",
      "Ep:51, loss:0.00002, loss_test:0.01252, lr:5.37e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.482, tt:1585.066\n",
      "Ep:52, loss:0.00002, loss_test:0.01247, lr:5.32e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.524, tt:1617.756\n",
      "Ep:53, loss:0.00002, loss_test:0.01245, lr:5.27e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.533, tt:1648.799\n",
      "Ep:54, loss:0.00002, loss_test:0.01243, lr:5.21e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.540, tt:1679.702\n",
      "Ep:55, loss:0.00002, loss_test:0.01242, lr:5.16e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.521, tt:1709.161\n",
      "Ep:56, loss:0.00002, loss_test:0.01243, lr:5.11e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.491, tt:1737.972\n",
      "Ep:57, loss:0.00002, loss_test:0.01238, lr:5.06e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.476, tt:1767.611\n",
      "Ep:58, loss:0.00002, loss_test:0.01235, lr:5.01e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.499, tt:1799.458\n",
      "Ep:59, loss:0.00002, loss_test:0.01233, lr:4.96e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.497, tt:1829.829\n",
      "Ep:60, loss:0.00002, loss_test:0.01231, lr:4.91e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.489, tt:1859.840\n",
      "Ep:61, loss:0.00002, loss_test:0.01228, lr:4.86e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.491, tt:1890.426\n",
      "Ep:62, loss:0.00001, loss_test:0.01226, lr:4.81e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.486, tt:1920.625\n",
      "Ep:63, loss:0.00001, loss_test:0.01224, lr:4.76e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.487, tt:1951.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01224, lr:4.71e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.450, tt:1979.242\n",
      "Ep:65, loss:0.00001, loss_test:0.01224, lr:4.67e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.448, tt:2009.568\n",
      "Ep:66, loss:0.00001, loss_test:0.01223, lr:4.62e-02, fs:0.80203 (r=0.798,p=0.806),  time:30.448, tt:2040.032\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01218, lr:4.62e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.447, tt:2070.365\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01217, lr:4.62e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.452, tt:2101.177\n",
      "Ep:69, loss:0.00001, loss_test:0.01218, lr:4.62e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.435, tt:2130.475\n",
      "Ep:70, loss:0.00001, loss_test:0.01218, lr:4.62e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.422, tt:2159.966\n",
      "Ep:71, loss:0.00001, loss_test:0.01216, lr:4.62e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.416, tt:2189.933\n",
      "Ep:72, loss:0.00001, loss_test:0.01215, lr:4.62e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.409, tt:2219.876\n",
      "Ep:73, loss:0.00001, loss_test:0.01212, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.404, tt:2249.904\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01212, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.442, tt:2283.174\n",
      "Ep:75, loss:0.00001, loss_test:0.01211, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.448, tt:2314.078\n",
      "Ep:76, loss:0.00001, loss_test:0.01209, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.437, tt:2343.669\n",
      "Ep:77, loss:0.00001, loss_test:0.01209, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.441, tt:2374.431\n",
      "Ep:78, loss:0.00001, loss_test:0.01209, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.439, tt:2404.710\n",
      "Ep:79, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.446, tt:2435.661\n",
      "Ep:80, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.451, tt:2466.545\n",
      "Ep:81, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.444, tt:2496.429\n",
      "Ep:82, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.431, tt:2525.787\n",
      "Ep:83, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.437, tt:2556.726\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.428, tt:2586.340\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01210, lr:4.62e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.426, tt:2616.669\n",
      "Ep:86, loss:0.00001, loss_test:0.01210, lr:4.62e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.409, tt:2645.544\n",
      "Ep:87, loss:0.00001, loss_test:0.01210, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.419, tt:2676.896\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01211, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.402, tt:2705.808\n",
      "Ep:89, loss:0.00001, loss_test:0.01209, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.409, tt:2736.832\n",
      "Ep:90, loss:0.00001, loss_test:0.01208, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.412, tt:2767.515\n",
      "Ep:91, loss:0.00001, loss_test:0.01209, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.418, tt:2798.479\n",
      "Ep:92, loss:0.00001, loss_test:0.01210, lr:4.62e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.421, tt:2829.166\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01211, lr:4.62e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.415, tt:2859.055\n",
      "Ep:94, loss:0.00001, loss_test:0.01209, lr:4.62e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.419, tt:2889.804\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01212, lr:4.62e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.419, tt:2920.259\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01213, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.440, tt:2952.704\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01211, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.432, tt:2982.358\n",
      "Ep:98, loss:0.00001, loss_test:0.01213, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.434, tt:3013.013\n",
      "Ep:99, loss:0.00001, loss_test:0.01215, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.398, tt:3039.752\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01217, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.355, tt:3065.852\n",
      "Ep:101, loss:0.00001, loss_test:0.01217, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.265, tt:3087.036\n",
      "Ep:102, loss:0.00001, loss_test:0.01217, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.161, tt:3106.579\n",
      "Ep:103, loss:0.00001, loss_test:0.01222, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.081, tt:3128.468\n",
      "Ep:104, loss:0.00001, loss_test:0.01221, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.065, tt:3156.787\n",
      "Ep:105, loss:0.00001, loss_test:0.01221, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.063, tt:3186.653\n",
      "Ep:106, loss:0.00001, loss_test:0.01221, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.052, tt:3215.606\n",
      "Ep:107, loss:0.00001, loss_test:0.01222, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.034, tt:3243.725\n",
      "Ep:108, loss:0.00001, loss_test:0.01225, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.016, tt:3271.716\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00001, loss_test:0.01226, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.026, tt:3302.877\n",
      "Ep:110, loss:0.00001, loss_test:0.01224, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.019, tt:3332.110\n",
      "Ep:111, loss:0.00001, loss_test:0.01227, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.028, tt:3363.128\n",
      "Ep:112, loss:0.00001, loss_test:0.01232, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.037, tt:3394.139\n",
      "Ep:113, loss:0.00001, loss_test:0.01231, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.041, tt:3424.677\n",
      "Ep:114, loss:0.00001, loss_test:0.01230, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.043, tt:3454.969\n",
      "Ep:115, loss:0.00001, loss_test:0.01233, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.044, tt:3485.112\n",
      "Ep:116, loss:0.00001, loss_test:0.01232, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.052, tt:3516.067\n",
      "Ep:117, loss:0.00001, loss_test:0.01236, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.054, tt:3546.347\n",
      "Ep:118, loss:0.00001, loss_test:0.01239, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.049, tt:3575.849\n",
      "Ep:119, loss:0.00001, loss_test:0.01234, lr:4.62e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.052, tt:3606.245\n",
      "Ep:120, loss:0.00001, loss_test:0.01237, lr:4.57e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.056, tt:3636.772\n",
      "Ep:121, loss:0.00001, loss_test:0.01245, lr:4.53e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.055, tt:3666.726\n",
      "Ep:122, loss:0.00001, loss_test:0.01245, lr:4.48e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.049, tt:3696.041\n",
      "Ep:123, loss:0.00001, loss_test:0.01242, lr:4.44e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.046, tt:3725.718\n",
      "Ep:124, loss:0.00001, loss_test:0.01246, lr:4.39e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.059, tt:3757.360\n",
      "Ep:125, loss:0.00001, loss_test:0.01251, lr:4.35e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.073, tt:3789.209\n",
      "Ep:126, loss:0.00001, loss_test:0.01251, lr:4.31e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.073, tt:3819.239\n",
      "Ep:127, loss:0.00001, loss_test:0.01256, lr:4.26e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.068, tt:3848.689\n",
      "Ep:128, loss:0.00001, loss_test:0.01259, lr:4.22e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.054, tt:3877.021\n",
      "Ep:129, loss:0.00001, loss_test:0.01255, lr:4.18e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.056, tt:3907.296\n",
      "Ep:130, loss:0.00001, loss_test:0.01259, lr:4.14e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.083, tt:3940.823\n",
      "Ep:131, loss:0.00001, loss_test:0.01262, lr:4.10e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.080, tt:3970.533\n",
      "Ep:132, loss:0.00001, loss_test:0.01262, lr:4.05e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.081, tt:4000.832\n",
      "Ep:133, loss:0.00001, loss_test:0.01265, lr:4.01e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.087, tt:4031.700\n",
      "Ep:134, loss:0.00001, loss_test:0.01267, lr:3.97e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.085, tt:4061.442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.01268, lr:3.93e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.089, tt:4092.112\n",
      "Ep:136, loss:0.00001, loss_test:0.01271, lr:3.89e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.093, tt:4122.755\n",
      "Ep:137, loss:0.00001, loss_test:0.01274, lr:3.86e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.105, tt:4154.518\n",
      "Ep:138, loss:0.00001, loss_test:0.01274, lr:3.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.099, tt:4183.781\n",
      "Ep:139, loss:0.00001, loss_test:0.01276, lr:3.78e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.094, tt:4213.151\n",
      "Ep:140, loss:0.00001, loss_test:0.01282, lr:3.74e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.101, tt:4244.244\n",
      "Ep:141, loss:0.00001, loss_test:0.01284, lr:3.70e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.109, tt:4275.502\n",
      "Ep:142, loss:0.00001, loss_test:0.01284, lr:3.67e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.120, tt:4307.225\n",
      "Ep:143, loss:0.00001, loss_test:0.01288, lr:3.63e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.125, tt:4337.961\n",
      "Ep:144, loss:0.00001, loss_test:0.01290, lr:3.59e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.125, tt:4368.107\n",
      "Ep:145, loss:0.00001, loss_test:0.01287, lr:3.56e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.138, tt:4400.107\n",
      "Ep:146, loss:0.00001, loss_test:0.01289, lr:3.52e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.146, tt:4431.529\n",
      "Ep:147, loss:0.00001, loss_test:0.01295, lr:3.49e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.159, tt:4463.521\n",
      "Ep:148, loss:0.00001, loss_test:0.01296, lr:3.45e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.155, tt:4493.156\n",
      "Ep:149, loss:0.00001, loss_test:0.01297, lr:3.42e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.165, tt:4524.683\n",
      "Ep:150, loss:0.00001, loss_test:0.01304, lr:3.38e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.167, tt:4555.222\n",
      "Ep:151, loss:0.00001, loss_test:0.01305, lr:3.35e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.165, tt:4585.033\n",
      "Ep:152, loss:0.00001, loss_test:0.01304, lr:3.32e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.172, tt:4616.323\n",
      "Ep:153, loss:0.00001, loss_test:0.01307, lr:3.28e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.175, tt:4646.966\n",
      "Ep:154, loss:0.00001, loss_test:0.01306, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.175, tt:4677.160\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.01308, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.175, tt:4707.294\n",
      "Ep:156, loss:0.00001, loss_test:0.01313, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.173, tt:4737.094\n",
      "Ep:157, loss:0.00001, loss_test:0.01314, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.173, tt:4767.323\n",
      "Ep:158, loss:0.00001, loss_test:0.01314, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.171, tt:4797.150\n",
      "Ep:159, loss:0.00001, loss_test:0.01316, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.169, tt:4826.990\n",
      "Ep:160, loss:0.00001, loss_test:0.01319, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.171, tt:4857.546\n",
      "Ep:161, loss:0.00001, loss_test:0.01320, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.167, tt:4887.073\n",
      "Ep:162, loss:0.00001, loss_test:0.01325, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.174, tt:4918.332\n",
      "Ep:163, loss:0.00001, loss_test:0.01326, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.173, tt:4948.415\n",
      "Ep:164, loss:0.00001, loss_test:0.01324, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.175, tt:4978.882\n",
      "Ep:165, loss:0.00001, loss_test:0.01329, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.182, tt:5010.237\n",
      "Ep:166, loss:0.00001, loss_test:0.01330, lr:3.22e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.195, tt:5042.564\n",
      "Ep:167, loss:0.00001, loss_test:0.01331, lr:3.19e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.197, tt:5073.136\n",
      "Ep:168, loss:0.00001, loss_test:0.01334, lr:3.15e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.192, tt:5102.509\n",
      "Ep:169, loss:0.00001, loss_test:0.01340, lr:3.12e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.191, tt:5132.507\n",
      "Ep:170, loss:0.00001, loss_test:0.01340, lr:3.09e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.187, tt:5162.030\n",
      "Ep:171, loss:0.00001, loss_test:0.01343, lr:3.06e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.182, tt:5191.241\n",
      "Ep:172, loss:0.00001, loss_test:0.01346, lr:3.03e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.184, tt:5221.875\n",
      "Ep:173, loss:0.00001, loss_test:0.01346, lr:3.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.183, tt:5251.767\n",
      "Ep:174, loss:0.00001, loss_test:0.01347, lr:2.97e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.181, tt:5281.720\n",
      "Ep:175, loss:0.00001, loss_test:0.01350, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.177, tt:5311.186\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00001, loss_test:0.01353, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.179, tt:5341.681\n",
      "Ep:177, loss:0.00001, loss_test:0.01357, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.177, tt:5371.520\n",
      "Ep:178, loss:0.00000, loss_test:0.01355, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.178, tt:5401.838\n",
      "Ep:179, loss:0.00000, loss_test:0.01359, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.181, tt:5432.661\n",
      "Ep:180, loss:0.00000, loss_test:0.01364, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.177, tt:5462.113\n",
      "Ep:181, loss:0.00000, loss_test:0.01365, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.173, tt:5491.484\n",
      "##########Best model found so far##########\n",
      "Ep:182, loss:0.00000, loss_test:0.01365, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.173, tt:5521.583\n",
      "Ep:183, loss:0.00000, loss_test:0.01367, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.175, tt:5552.250\n",
      "Ep:184, loss:0.00000, loss_test:0.01369, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.188, tt:5584.749\n",
      "Ep:185, loss:0.00000, loss_test:0.01372, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.191, tt:5615.537\n",
      "Ep:186, loss:0.00000, loss_test:0.01374, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.189, tt:5645.431\n",
      "Ep:187, loss:0.00000, loss_test:0.01377, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.193, tt:5676.276\n",
      "Ep:188, loss:0.00000, loss_test:0.01379, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.192, tt:5706.223\n",
      "Ep:189, loss:0.00000, loss_test:0.01381, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.191, tt:5736.310\n",
      "Ep:190, loss:0.00000, loss_test:0.01384, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.188, tt:5765.825\n",
      "Ep:191, loss:0.00000, loss_test:0.01387, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.196, tt:5797.645\n",
      "Ep:192, loss:0.00000, loss_test:0.01387, lr:2.94e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.197, tt:5827.968\n",
      "Ep:193, loss:0.00000, loss_test:0.01391, lr:2.91e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.198, tt:5858.331\n",
      "Ep:194, loss:0.00000, loss_test:0.01394, lr:2.88e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.203, tt:5889.506\n",
      "Ep:195, loss:0.00000, loss_test:0.01394, lr:2.85e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.197, tt:5918.517\n",
      "Ep:196, loss:0.00000, loss_test:0.01397, lr:2.82e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.198, tt:5948.953\n",
      "Ep:197, loss:0.00000, loss_test:0.01400, lr:2.80e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.189, tt:5977.449\n",
      "Ep:198, loss:0.00000, loss_test:0.01400, lr:2.77e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.188, tt:6007.355\n",
      "Ep:199, loss:0.00000, loss_test:0.01402, lr:2.74e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.194, tt:6038.868\n",
      "Ep:200, loss:0.00000, loss_test:0.01405, lr:2.71e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.194, tt:6068.923\n",
      "Ep:201, loss:0.00000, loss_test:0.01406, lr:2.69e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.200, tt:6100.446\n",
      "Ep:202, loss:0.00000, loss_test:0.01406, lr:2.66e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.204, tt:6131.340\n",
      "Ep:203, loss:0.00000, loss_test:0.01407, lr:2.63e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.209, tt:6162.546\n",
      "Ep:204, loss:0.00000, loss_test:0.01412, lr:2.61e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.213, tt:6193.614\n",
      "Ep:205, loss:0.00000, loss_test:0.01414, lr:2.58e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.215, tt:6224.349\n",
      "Ep:206, loss:0.00000, loss_test:0.01417, lr:2.55e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.225, tt:6256.572\n",
      "Ep:207, loss:0.00000, loss_test:0.01417, lr:2.53e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.224, tt:6286.527\n",
      "Ep:208, loss:0.00000, loss_test:0.01420, lr:2.50e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.226, tt:6317.275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.01422, lr:2.48e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.224, tt:6347.103\n",
      "Ep:210, loss:0.00000, loss_test:0.01423, lr:2.45e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.230, tt:6378.497\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14214, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.521, tt:30.521\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14126, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.079, tt:62.159\n",
      "Ep:2, loss:0.00028, loss_test:0.13982, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.647, tt:94.941\n",
      "Ep:3, loss:0.00028, loss_test:0.13764, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.815, tt:127.260\n",
      "Ep:4, loss:0.00027, loss_test:0.13429, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:31.584, tt:157.918\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00027, loss_test:0.12906, lr:1.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:31.710, tt:190.262\n",
      "Ep:6, loss:0.00026, loss_test:0.12238, lr:1.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:31.622, tt:221.353\n",
      "Ep:7, loss:0.00025, loss_test:0.11708, lr:1.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:31.591, tt:252.729\n",
      "Ep:8, loss:0.00024, loss_test:0.11279, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:31.560, tt:284.040\n",
      "Ep:9, loss:0.00024, loss_test:0.10917, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:31.581, tt:315.812\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.10769, lr:1.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:31.612, tt:347.729\n",
      "Ep:11, loss:0.00023, loss_test:0.10653, lr:1.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:31.569, tt:378.830\n",
      "Ep:12, loss:0.00022, loss_test:0.10540, lr:1.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:31.568, tt:410.382\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10407, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:31.645, tt:443.023\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10252, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:31.673, tt:475.093\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.09936, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:31.878, tt:510.055\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09615, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:31.895, tt:542.221\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.09323, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:31.911, tt:574.405\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.09197, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:31.924, tt:606.556\n",
      "Ep:19, loss:0.00019, loss_test:0.09163, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:31.883, tt:637.663\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.08977, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:31.897, tt:669.844\n",
      "Ep:21, loss:0.00018, loss_test:0.08696, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:31.797, tt:699.531\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.08566, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:31.783, tt:730.999\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08465, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:31.734, tt:761.616\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.08259, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:31.758, tt:793.957\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.08135, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:31.796, tt:826.689\n",
      "Ep:26, loss:0.00016, loss_test:0.07990, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.782, tt:858.119\n",
      "Ep:27, loss:0.00016, loss_test:0.07833, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:31.777, tt:889.760\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.07713, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.802, tt:922.264\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.07623, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:31.794, tt:953.810\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.07470, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.825, tt:986.563\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.07446, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:31.784, tt:1017.091\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.07327, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:31.739, tt:1047.396\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07191, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:31.764, tt:1079.990\n",
      "Ep:34, loss:0.00013, loss_test:0.07124, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:31.711, tt:1109.894\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.06988, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:31.672, tt:1140.207\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.06891, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:31.636, tt:1170.524\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.06854, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:31.665, tt:1203.253\n",
      "Ep:38, loss:0.00012, loss_test:0.06831, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:31.671, tt:1235.161\n",
      "Ep:39, loss:0.00011, loss_test:0.06711, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:31.703, tt:1268.120\n",
      "Ep:40, loss:0.00011, loss_test:0.06525, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:31.691, tt:1299.315\n",
      "Ep:41, loss:0.00011, loss_test:0.06602, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:31.736, tt:1332.930\n",
      "Ep:42, loss:0.00011, loss_test:0.06305, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:31.742, tt:1364.904\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.06415, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:31.755, tt:1397.228\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.06200, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:31.776, tt:1429.925\n",
      "Ep:45, loss:0.00010, loss_test:0.06173, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.775, tt:1461.645\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.06101, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:31.736, tt:1491.615\n",
      "Ep:47, loss:0.00009, loss_test:0.06147, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:31.706, tt:1521.887\n",
      "Ep:48, loss:0.00009, loss_test:0.05983, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:31.735, tt:1555.022\n",
      "Ep:49, loss:0.00009, loss_test:0.05910, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:31.734, tt:1586.710\n",
      "Ep:50, loss:0.00009, loss_test:0.05830, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.704, tt:1616.886\n",
      "Ep:51, loss:0.00008, loss_test:0.05745, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.699, tt:1648.353\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.05655, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:31.722, tt:1681.244\n",
      "Ep:53, loss:0.00008, loss_test:0.05832, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:31.756, tt:1714.823\n",
      "Ep:54, loss:0.00008, loss_test:0.05484, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:31.723, tt:1744.765\n",
      "Ep:55, loss:0.00008, loss_test:0.05646, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:31.716, tt:1776.096\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.05416, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:31.689, tt:1806.289\n",
      "Ep:57, loss:0.00007, loss_test:0.05634, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:31.763, tt:1842.232\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00007, loss_test:0.05326, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.754, tt:1873.464\n",
      "Ep:59, loss:0.00007, loss_test:0.05436, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:31.728, tt:1903.701\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00007, loss_test:0.05323, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.724, tt:1935.137\n",
      "Ep:61, loss:0.00006, loss_test:0.05310, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:31.719, tt:1966.557\n",
      "Ep:62, loss:0.00006, loss_test:0.05234, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.715, tt:1998.025\n",
      "Ep:63, loss:0.00006, loss_test:0.05032, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:31.718, tt:2029.949\n",
      "Ep:64, loss:0.00006, loss_test:0.05082, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.708, tt:2061.034\n",
      "Ep:65, loss:0.00006, loss_test:0.04985, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:31.724, tt:2093.753\n",
      "Ep:66, loss:0.00006, loss_test:0.05241, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.728, tt:2125.745\n",
      "Ep:67, loss:0.00006, loss_test:0.05012, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.713, tt:2156.484\n",
      "Ep:68, loss:0.00006, loss_test:0.05375, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:31.699, tt:2187.231\n",
      "Ep:69, loss:0.00006, loss_test:0.04989, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.700, tt:2219.015\n",
      "Ep:70, loss:0.00005, loss_test:0.05146, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:31.699, tt:2250.638\n",
      "Ep:71, loss:0.00005, loss_test:0.05048, lr:9.90e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.709, tt:2283.029\n",
      "Ep:72, loss:0.00005, loss_test:0.05065, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.713, tt:2315.040\n",
      "Ep:73, loss:0.00005, loss_test:0.04776, lr:9.70e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.713, tt:2346.735\n",
      "Ep:74, loss:0.00005, loss_test:0.04802, lr:9.61e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.713, tt:2378.474\n",
      "Ep:75, loss:0.00005, loss_test:0.04855, lr:9.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.715, tt:2410.366\n",
      "Ep:76, loss:0.00005, loss_test:0.04856, lr:9.41e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.708, tt:2441.554\n",
      "Ep:77, loss:0.00004, loss_test:0.04838, lr:9.32e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.691, tt:2471.893\n",
      "Ep:78, loss:0.00004, loss_test:0.04744, lr:9.23e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.671, tt:2502.029\n",
      "Ep:79, loss:0.00004, loss_test:0.04722, lr:9.14e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.656, tt:2532.483\n",
      "Ep:80, loss:0.00004, loss_test:0.04668, lr:9.04e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.667, tt:2565.019\n",
      "Ep:81, loss:0.00004, loss_test:0.04873, lr:8.95e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.676, tt:2597.444\n",
      "Ep:82, loss:0.00004, loss_test:0.04761, lr:8.86e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.667, tt:2628.355\n",
      "Ep:83, loss:0.00004, loss_test:0.04802, lr:8.78e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.674, tt:2660.591\n",
      "Ep:84, loss:0.00004, loss_test:0.04651, lr:8.69e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.681, tt:2692.858\n",
      "Ep:85, loss:0.00004, loss_test:0.04772, lr:8.60e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.690, tt:2725.313\n",
      "Ep:86, loss:0.00003, loss_test:0.04627, lr:8.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.692, tt:2757.178\n",
      "Ep:87, loss:0.00003, loss_test:0.04705, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.670, tt:2786.961\n",
      "Ep:88, loss:0.00003, loss_test:0.04588, lr:8.35e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.671, tt:2818.737\n",
      "Ep:89, loss:0.00003, loss_test:0.04671, lr:8.26e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.681, tt:2851.264\n",
      "Ep:90, loss:0.00003, loss_test:0.04613, lr:8.18e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.683, tt:2883.144\n",
      "Ep:91, loss:0.00003, loss_test:0.04669, lr:8.10e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.664, tt:2913.097\n",
      "Ep:92, loss:0.00003, loss_test:0.04545, lr:8.02e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.676, tt:2945.880\n",
      "Ep:93, loss:0.00003, loss_test:0.04731, lr:7.94e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.681, tt:2978.054\n",
      "Ep:94, loss:0.00003, loss_test:0.04615, lr:7.86e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.661, tt:3007.816\n",
      "Ep:95, loss:0.00003, loss_test:0.04651, lr:7.78e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.661, tt:3039.428\n",
      "Ep:96, loss:0.00003, loss_test:0.04552, lr:7.70e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.648, tt:3069.867\n",
      "Ep:97, loss:0.00003, loss_test:0.04624, lr:7.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.611, tt:3097.836\n",
      "Ep:98, loss:0.00003, loss_test:0.04570, lr:7.55e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.575, tt:3125.949\n",
      "Ep:99, loss:0.00003, loss_test:0.04533, lr:7.47e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.517, tt:3151.722\n",
      "Ep:100, loss:0.00003, loss_test:0.04598, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.523, tt:3183.791\n",
      "Ep:101, loss:0.00002, loss_test:0.04587, lr:7.32e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.514, tt:3214.466\n",
      "Ep:102, loss:0.00002, loss_test:0.04539, lr:7.25e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.512, tt:3245.704\n",
      "Ep:103, loss:0.00002, loss_test:0.04579, lr:7.18e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.520, tt:3278.120\n",
      "Ep:104, loss:0.00002, loss_test:0.04650, lr:7.11e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.519, tt:3309.526\n",
      "Ep:105, loss:0.00002, loss_test:0.04585, lr:7.03e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.513, tt:3340.353\n",
      "Ep:108, loss:0.00002, loss_test:0.04540, lr:6.83e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.551, tt:3439.060\n",
      "Ep:109, loss:0.00002, loss_test:0.04603, lr:6.76e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.567, tt:3472.409\n",
      "Ep:110, loss:0.00002, loss_test:0.04495, lr:6.69e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.586, tt:3506.092\n",
      "Ep:111, loss:0.00002, loss_test:0.04607, lr:6.62e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.597, tt:3538.890\n",
      "Ep:112, loss:0.00002, loss_test:0.04562, lr:6.56e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.610, tt:3571.975\n",
      "Ep:113, loss:0.00002, loss_test:0.04549, lr:6.49e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.621, tt:3604.741\n",
      "Ep:114, loss:0.00002, loss_test:0.04561, lr:6.43e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.629, tt:3637.352\n",
      "Ep:115, loss:0.00002, loss_test:0.04564, lr:6.36e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.636, tt:3669.815\n",
      "Ep:116, loss:0.00002, loss_test:0.04536, lr:6.30e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.644, tt:3702.388\n",
      "Ep:117, loss:0.00002, loss_test:0.04559, lr:6.24e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.661, tt:3735.958\n",
      "Ep:118, loss:0.00002, loss_test:0.04520, lr:6.17e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.663, tt:3767.866\n",
      "Ep:119, loss:0.00002, loss_test:0.04531, lr:6.11e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.669, tt:3800.224\n",
      "Ep:120, loss:0.00002, loss_test:0.04533, lr:6.05e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.668, tt:3831.792\n",
      "Ep:121, loss:0.00002, loss_test:0.04478, lr:5.99e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.683, tt:3865.371\n",
      "Ep:122, loss:0.00002, loss_test:0.04574, lr:5.93e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.685, tt:3897.286\n",
      "Ep:123, loss:0.00002, loss_test:0.04575, lr:5.87e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.702, tt:3930.989\n",
      "Ep:124, loss:0.00002, loss_test:0.04464, lr:5.81e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.717, tt:3964.647\n",
      "Ep:125, loss:0.00002, loss_test:0.04544, lr:5.75e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.719, tt:3996.535\n",
      "Ep:126, loss:0.00002, loss_test:0.04513, lr:5.70e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.732, tt:4030.000\n",
      "Ep:127, loss:0.00002, loss_test:0.04551, lr:5.64e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.730, tt:4061.411\n",
      "Ep:128, loss:0.00002, loss_test:0.04482, lr:5.58e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.733, tt:4093.492\n",
      "Ep:129, loss:0.00002, loss_test:0.04531, lr:5.53e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.737, tt:4125.823\n",
      "Ep:130, loss:0.00001, loss_test:0.04557, lr:5.47e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.740, tt:4157.903\n",
      "Ep:131, loss:0.00001, loss_test:0.04448, lr:5.42e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.746, tt:4190.419\n",
      "Ep:132, loss:0.00001, loss_test:0.04540, lr:5.36e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.743, tt:4221.811\n",
      "Ep:133, loss:0.00001, loss_test:0.04501, lr:5.31e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.744, tt:4253.714\n",
      "Ep:134, loss:0.00001, loss_test:0.04481, lr:5.26e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.739, tt:4284.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.04550, lr:5.20e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.738, tt:4316.328\n",
      "Ep:136, loss:0.00001, loss_test:0.04517, lr:5.15e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.733, tt:4347.400\n",
      "Ep:137, loss:0.00001, loss_test:0.04490, lr:5.10e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.731, tt:4378.895\n",
      "Ep:138, loss:0.00001, loss_test:0.04502, lr:5.05e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.737, tt:4411.498\n",
      "Ep:139, loss:0.00001, loss_test:0.04530, lr:5.00e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.731, tt:4442.281\n",
      "Ep:140, loss:0.00001, loss_test:0.04469, lr:4.95e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.730, tt:4473.916\n",
      "Ep:141, loss:0.00001, loss_test:0.04503, lr:4.90e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.734, tt:4506.257\n",
      "Ep:142, loss:0.00001, loss_test:0.04495, lr:4.85e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.740, tt:4538.817\n",
      "Ep:143, loss:0.00001, loss_test:0.04496, lr:4.80e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.741, tt:4570.664\n",
      "Ep:144, loss:0.00001, loss_test:0.04473, lr:4.75e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.743, tt:4602.768\n",
      "Ep:145, loss:0.00001, loss_test:0.04509, lr:4.71e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.747, tt:4635.074\n",
      "Ep:146, loss:0.00001, loss_test:0.04472, lr:4.66e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.747, tt:4666.882\n",
      "Ep:147, loss:0.00001, loss_test:0.04515, lr:4.61e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.741, tt:4697.601\n",
      "Ep:148, loss:0.00001, loss_test:0.04482, lr:4.57e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.741, tt:4729.427\n",
      "Ep:149, loss:0.00001, loss_test:0.04475, lr:4.52e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.742, tt:4761.228\n",
      "Ep:150, loss:0.00001, loss_test:0.04480, lr:4.48e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.745, tt:4793.439\n",
      "Ep:151, loss:0.00001, loss_test:0.04424, lr:4.43e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.744, tt:4825.051\n",
      "Ep:152, loss:0.00001, loss_test:0.04547, lr:4.39e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.743, tt:4856.718\n",
      "Ep:153, loss:0.00001, loss_test:0.04465, lr:4.34e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.741, tt:4888.093\n",
      "Ep:154, loss:0.00001, loss_test:0.04467, lr:4.30e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.743, tt:4920.088\n",
      "Ep:155, loss:0.00001, loss_test:0.04503, lr:4.26e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.740, tt:4951.382\n",
      "Ep:156, loss:0.00001, loss_test:0.04411, lr:4.21e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.726, tt:4981.005\n",
      "Ep:157, loss:0.00001, loss_test:0.04513, lr:4.17e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.726, tt:5012.764\n",
      "Ep:158, loss:0.00001, loss_test:0.04473, lr:4.13e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.724, tt:5044.049\n",
      "Ep:159, loss:0.00001, loss_test:0.04417, lr:4.09e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.717, tt:5074.660\n",
      "Ep:160, loss:0.00001, loss_test:0.04522, lr:4.05e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.711, tt:5105.531\n",
      "Ep:161, loss:0.00001, loss_test:0.04445, lr:4.01e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.716, tt:5138.063\n",
      "Ep:162, loss:0.00001, loss_test:0.04472, lr:3.97e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.704, tt:5167.714\n",
      "Ep:163, loss:0.00001, loss_test:0.04549, lr:3.93e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.703, tt:5199.269\n",
      "Ep:164, loss:0.00001, loss_test:0.04460, lr:3.89e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.699, tt:5230.327\n",
      "Ep:165, loss:0.00001, loss_test:0.04481, lr:3.85e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.693, tt:5261.004\n",
      "Ep:166, loss:0.00001, loss_test:0.04499, lr:3.81e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.694, tt:5292.887\n",
      "Ep:167, loss:0.00001, loss_test:0.04457, lr:3.77e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.703, tt:5326.055\n",
      "Ep:168, loss:0.00001, loss_test:0.04472, lr:3.73e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.695, tt:5356.410\n",
      "Ep:169, loss:0.00001, loss_test:0.04461, lr:3.70e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.699, tt:5388.838\n",
      "Ep:170, loss:0.00001, loss_test:0.04456, lr:3.66e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.700, tt:5420.721\n",
      "Ep:171, loss:0.00001, loss_test:0.04500, lr:3.62e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.699, tt:5452.183\n",
      "Ep:172, loss:0.00001, loss_test:0.04468, lr:3.59e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.697, tt:5483.655\n",
      "Ep:173, loss:0.00001, loss_test:0.04460, lr:3.55e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.701, tt:5515.994\n",
      "Ep:174, loss:0.00001, loss_test:0.04447, lr:3.52e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.704, tt:5548.150\n",
      "Ep:175, loss:0.00001, loss_test:0.04498, lr:3.48e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.695, tt:5578.271\n",
      "Ep:176, loss:0.00001, loss_test:0.04468, lr:3.45e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.687, tt:5608.654\n",
      "Ep:177, loss:0.00001, loss_test:0.04504, lr:3.41e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.688, tt:5640.464\n",
      "Ep:178, loss:0.00001, loss_test:0.04510, lr:3.38e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.681, tt:5670.918\n",
      "Ep:179, loss:0.00001, loss_test:0.04430, lr:3.34e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.686, tt:5703.485\n",
      "Ep:180, loss:0.00001, loss_test:0.04503, lr:3.31e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.686, tt:5735.217\n",
      "Ep:181, loss:0.00001, loss_test:0.04540, lr:3.28e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.687, tt:5767.055\n",
      "Ep:182, loss:0.00001, loss_test:0.04447, lr:3.24e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.679, tt:5797.174\n",
      "Ep:183, loss:0.00001, loss_test:0.04465, lr:3.21e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.691, tt:5831.171\n",
      "Ep:184, loss:0.00001, loss_test:0.04528, lr:3.18e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.697, tt:5863.902\n",
      "Ep:185, loss:0.00001, loss_test:0.04470, lr:3.15e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.699, tt:5895.974\n",
      "Ep:186, loss:0.00001, loss_test:0.04474, lr:3.12e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.690, tt:5926.046\n",
      "Ep:187, loss:0.00001, loss_test:0.04486, lr:3.09e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.691, tt:5957.974\n",
      "Ep:188, loss:0.00001, loss_test:0.04468, lr:3.05e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.691, tt:5989.553\n",
      "Ep:189, loss:0.00001, loss_test:0.04483, lr:3.02e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.688, tt:6020.780\n",
      "Ep:190, loss:0.00001, loss_test:0.04479, lr:2.99e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.683, tt:6051.382\n",
      "Ep:191, loss:0.00001, loss_test:0.04448, lr:2.96e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.675, tt:6081.530\n",
      "Ep:192, loss:0.00001, loss_test:0.04487, lr:2.93e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.673, tt:6112.889\n",
      "Ep:193, loss:0.00001, loss_test:0.04480, lr:2.90e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.675, tt:6144.880\n",
      "Ep:194, loss:0.00001, loss_test:0.04448, lr:2.88e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.669, tt:6175.528\n",
      "Ep:195, loss:0.00001, loss_test:0.04527, lr:2.85e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.673, tt:6207.840\n",
      "Ep:196, loss:0.00001, loss_test:0.04561, lr:2.82e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.670, tt:6238.931\n",
      "Ep:197, loss:0.00001, loss_test:0.04490, lr:2.79e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.660, tt:6268.730\n",
      "Ep:198, loss:0.00001, loss_test:0.04465, lr:2.76e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.660, tt:6300.305\n",
      "Ep:199, loss:0.00001, loss_test:0.04458, lr:2.73e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.652, tt:6330.320\n",
      "Ep:200, loss:0.00001, loss_test:0.04454, lr:2.71e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.656, tt:6362.915\n",
      "Ep:201, loss:0.00001, loss_test:0.04493, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.658, tt:6394.829\n",
      "Ep:202, loss:0.00001, loss_test:0.04503, lr:2.65e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.654, tt:6425.776\n",
      "Ep:203, loss:0.00001, loss_test:0.04490, lr:2.63e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.650, tt:6456.573\n",
      "Ep:204, loss:0.00001, loss_test:0.04464, lr:2.60e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.651, tt:6488.472\n",
      "Ep:205, loss:0.00001, loss_test:0.04473, lr:2.57e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.653, tt:6520.459\n",
      "Ep:206, loss:0.00001, loss_test:0.04474, lr:2.55e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.644, tt:6550.382\n",
      "Ep:207, loss:0.00001, loss_test:0.04464, lr:2.52e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.637, tt:6580.502\n",
      "Ep:208, loss:0.00001, loss_test:0.04486, lr:2.50e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.636, tt:6611.850\n",
      "Ep:209, loss:0.00001, loss_test:0.04495, lr:2.47e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.638, tt:6643.934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00001, loss_test:0.04474, lr:2.45e-03, fs:0.90110 (r=0.828,p=0.988),  time:31.642, tt:6676.517\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02029, lr:6.00e-02, fs:0.63793 (r=0.747,p=0.556),  time:29.353, tt:29.353\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02081, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:30.084, tt:60.168\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02228, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.966, tt:89.897\n",
      "Ep:3, loss:0.00004, loss_test:0.02208, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.939, tt:119.756\n",
      "Ep:4, loss:0.00004, loss_test:0.02106, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:29.864, tt:149.320\n",
      "Ep:5, loss:0.00004, loss_test:0.01994, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:29.787, tt:178.723\n",
      "Ep:6, loss:0.00004, loss_test:0.01909, lr:6.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:30.032, tt:210.227\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01863, lr:6.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:30.180, tt:241.441\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01827, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:30.227, tt:272.039\n",
      "Ep:9, loss:0.00004, loss_test:0.01757, lr:6.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:30.306, tt:303.062\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01697, lr:6.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:30.451, tt:334.956\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:30.477, tt:365.721\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:30.361, tt:394.694\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.73962 (r=0.990,p=0.590),  time:30.328, tt:424.596\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.75096 (r=0.990,p=0.605),  time:30.415, tt:456.222\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.75676 (r=0.990,p=0.613),  time:30.513, tt:488.211\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.75294 (r=0.970,p=0.615),  time:30.532, tt:519.042\n",
      "Ep:17, loss:0.00003, loss_test:0.01520, lr:6.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:30.616, tt:551.090\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:30.585, tt:581.123\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01483, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:30.592, tt:611.845\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01465, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:30.571, tt:641.995\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01445, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:30.492, tt:670.831\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01426, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:30.492, tt:701.326\n",
      "Ep:23, loss:0.00003, loss_test:0.01403, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:30.467, tt:731.218\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01380, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:30.463, tt:761.582\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01359, lr:6.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:30.385, tt:790.020\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01342, lr:6.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:30.340, tt:819.192\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01329, lr:6.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:30.279, tt:847.810\n",
      "Ep:28, loss:0.00003, loss_test:0.01316, lr:6.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:30.241, tt:876.993\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:30.250, tt:907.514\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01290, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:30.271, tt:938.395\n",
      "Ep:31, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:30.300, tt:969.606\n",
      "Ep:32, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:30.294, tt:999.716\n",
      "Ep:33, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:30.347, tt:1031.812\n",
      "Ep:34, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:30.338, tt:1061.846\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:30.343, tt:1092.337\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01229, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.322, tt:1121.905\n",
      "Ep:37, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:30.341, tt:1152.956\n",
      "Ep:38, loss:0.00002, loss_test:0.01209, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.350, tt:1183.642\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01200, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.343, tt:1213.729\n",
      "Ep:40, loss:0.00002, loss_test:0.01191, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.369, tt:1245.120\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.359, tt:1275.075\n",
      "Ep:42, loss:0.00002, loss_test:0.01174, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.353, tt:1305.167\n",
      "Ep:43, loss:0.00002, loss_test:0.01165, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.373, tt:1336.398\n",
      "Ep:44, loss:0.00002, loss_test:0.01156, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.360, tt:1366.217\n",
      "Ep:45, loss:0.00002, loss_test:0.01149, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.362, tt:1396.672\n",
      "Ep:46, loss:0.00002, loss_test:0.01141, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.329, tt:1425.463\n",
      "Ep:47, loss:0.00002, loss_test:0.01133, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.330, tt:1455.830\n",
      "Ep:48, loss:0.00002, loss_test:0.01127, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:30.296, tt:1484.516\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:30.302, tt:1515.118\n",
      "Ep:50, loss:0.00002, loss_test:0.01115, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:30.304, tt:1545.486\n",
      "Ep:51, loss:0.00002, loss_test:0.01108, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:30.284, tt:1574.766\n",
      "Ep:52, loss:0.00002, loss_test:0.01101, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.307, tt:1606.292\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01095, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.323, tt:1637.459\n",
      "Ep:54, loss:0.00002, loss_test:0.01091, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.332, tt:1668.258\n",
      "Ep:55, loss:0.00002, loss_test:0.01085, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.348, tt:1699.501\n",
      "Ep:56, loss:0.00002, loss_test:0.01079, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:30.367, tt:1730.895\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00002, loss_test:0.01076, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:30.369, tt:1761.382\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01071, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:30.371, tt:1791.874\n",
      "Ep:59, loss:0.00002, loss_test:0.01064, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:30.372, tt:1822.309\n",
      "Ep:60, loss:0.00002, loss_test:0.01060, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:30.397, tt:1854.212\n",
      "Ep:61, loss:0.00002, loss_test:0.01053, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:30.392, tt:1884.279\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01046, lr:6.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:30.396, tt:1914.938\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01041, lr:6.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:30.391, tt:1945.028\n",
      "Ep:64, loss:0.00001, loss_test:0.01037, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:30.375, tt:1974.368\n",
      "Ep:65, loss:0.00001, loss_test:0.01033, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.362, tt:2003.863\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01029, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.341, tt:2032.816\n",
      "Ep:67, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.324, tt:2062.052\n",
      "Ep:68, loss:0.00001, loss_test:0.01020, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.315, tt:2091.763\n",
      "Ep:69, loss:0.00001, loss_test:0.01017, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.332, tt:2123.273\n",
      "Ep:70, loss:0.00001, loss_test:0.01013, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.336, tt:2153.865\n",
      "Ep:71, loss:0.00001, loss_test:0.01009, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.334, tt:2184.033\n",
      "Ep:72, loss:0.00001, loss_test:0.01006, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.341, tt:2214.860\n",
      "Ep:73, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.332, tt:2244.604\n",
      "Ep:74, loss:0.00001, loss_test:0.01000, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.330, tt:2274.739\n",
      "Ep:75, loss:0.00001, loss_test:0.00995, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.331, tt:2305.138\n",
      "Ep:76, loss:0.00001, loss_test:0.00990, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.355, tt:2337.373\n",
      "Ep:77, loss:0.00001, loss_test:0.00990, lr:5.94e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.398, tt:2371.043\n",
      "Ep:78, loss:0.00001, loss_test:0.00988, lr:5.88e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.389, tt:2400.766\n",
      "Ep:79, loss:0.00001, loss_test:0.00985, lr:5.82e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.406, tt:2432.474\n",
      "Ep:80, loss:0.00001, loss_test:0.00983, lr:5.76e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.415, tt:2463.650\n",
      "Ep:81, loss:0.00001, loss_test:0.00980, lr:5.71e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.427, tt:2494.974\n",
      "Ep:82, loss:0.00001, loss_test:0.00978, lr:5.65e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.439, tt:2526.449\n",
      "Ep:83, loss:0.00001, loss_test:0.00975, lr:5.59e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.449, tt:2557.735\n",
      "Ep:84, loss:0.00001, loss_test:0.00972, lr:5.54e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.445, tt:2587.796\n",
      "Ep:85, loss:0.00001, loss_test:0.00969, lr:5.48e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.436, tt:2617.511\n",
      "Ep:86, loss:0.00001, loss_test:0.00968, lr:5.43e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.420, tt:2646.514\n",
      "Ep:87, loss:0.00001, loss_test:0.00967, lr:5.37e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.419, tt:2676.916\n",
      "Ep:88, loss:0.00001, loss_test:0.00966, lr:5.32e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.417, tt:2707.151\n",
      "Ep:89, loss:0.00001, loss_test:0.00962, lr:5.27e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.424, tt:2738.190\n",
      "Ep:90, loss:0.00001, loss_test:0.00962, lr:5.21e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.423, tt:2768.449\n",
      "Ep:91, loss:0.00001, loss_test:0.00961, lr:5.16e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.425, tt:2799.107\n",
      "Ep:92, loss:0.00001, loss_test:0.00958, lr:5.11e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.434, tt:2830.394\n",
      "Ep:93, loss:0.00001, loss_test:0.00957, lr:5.06e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.427, tt:2860.094\n",
      "Ep:94, loss:0.00001, loss_test:0.00956, lr:5.01e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.434, tt:2891.213\n",
      "Ep:95, loss:0.00001, loss_test:0.00955, lr:4.96e-02, fs:0.85714 (r=0.879,p=0.837),  time:30.421, tt:2920.419\n",
      "Ep:96, loss:0.00001, loss_test:0.00953, lr:4.91e-02, fs:0.85714 (r=0.879,p=0.837),  time:30.422, tt:2950.924\n",
      "Ep:97, loss:0.00001, loss_test:0.00952, lr:4.86e-02, fs:0.85714 (r=0.879,p=0.837),  time:30.423, tt:2981.416\n",
      "Ep:98, loss:0.00001, loss_test:0.00951, lr:4.81e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.405, tt:3010.067\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.00950, lr:4.81e-02, fs:0.85714 (r=0.879,p=0.837),  time:30.433, tt:3043.265\n",
      "Ep:100, loss:0.00001, loss_test:0.00948, lr:4.81e-02, fs:0.85714 (r=0.879,p=0.837),  time:30.438, tt:3074.228\n",
      "Ep:101, loss:0.00001, loss_test:0.00948, lr:4.81e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.401, tt:3100.922\n",
      "Ep:102, loss:0.00001, loss_test:0.00944, lr:4.81e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.352, tt:3126.214\n",
      "Ep:103, loss:0.00001, loss_test:0.00945, lr:4.81e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.245, tt:3145.524\n",
      "Ep:104, loss:0.00001, loss_test:0.00948, lr:4.81e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.165, tt:3167.351\n",
      "Ep:105, loss:0.00001, loss_test:0.00945, lr:4.81e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.116, tt:3192.338\n",
      "Ep:106, loss:0.00001, loss_test:0.00942, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.104, tt:3221.165\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.00941, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.102, tt:3251.017\n",
      "Ep:108, loss:0.00001, loss_test:0.00944, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.102, tt:3281.102\n",
      "Ep:109, loss:0.00001, loss_test:0.00942, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.100, tt:3310.969\n",
      "Ep:110, loss:0.00001, loss_test:0.00941, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.076, tt:3338.408\n",
      "Ep:111, loss:0.00001, loss_test:0.00941, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.057, tt:3366.417\n",
      "Ep:112, loss:0.00001, loss_test:0.00939, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.054, tt:3396.116\n",
      "Ep:113, loss:0.00001, loss_test:0.00940, lr:4.81e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.053, tt:3426.051\n",
      "Ep:114, loss:0.00001, loss_test:0.00939, lr:4.81e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.055, tt:3456.345\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.00939, lr:4.81e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.050, tt:3485.781\n",
      "Ep:116, loss:0.00001, loss_test:0.00938, lr:4.81e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.053, tt:3516.247\n",
      "Ep:117, loss:0.00001, loss_test:0.00936, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.054, tt:3546.359\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.00936, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.050, tt:3575.947\n",
      "Ep:119, loss:0.00001, loss_test:0.00937, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.065, tt:3607.841\n",
      "Ep:120, loss:0.00001, loss_test:0.00935, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.064, tt:3637.766\n",
      "Ep:121, loss:0.00001, loss_test:0.00936, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.072, tt:3668.804\n",
      "Ep:122, loss:0.00001, loss_test:0.00936, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.094, tt:3701.540\n",
      "Ep:123, loss:0.00001, loss_test:0.00936, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.095, tt:3731.779\n",
      "Ep:124, loss:0.00001, loss_test:0.00935, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.099, tt:3762.326\n",
      "Ep:125, loss:0.00001, loss_test:0.00933, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.105, tt:3793.241\n",
      "Ep:126, loss:0.00001, loss_test:0.00934, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.112, tt:3824.227\n",
      "Ep:127, loss:0.00001, loss_test:0.00933, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.119, tt:3855.246\n",
      "Ep:128, loss:0.00001, loss_test:0.00932, lr:4.81e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.125, tt:3886.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.00932, lr:4.76e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.134, tt:3917.360\n",
      "Ep:130, loss:0.00001, loss_test:0.00930, lr:4.71e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.136, tt:3947.839\n",
      "Ep:131, loss:0.00001, loss_test:0.00930, lr:4.67e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.156, tt:3980.606\n",
      "Ep:132, loss:0.00001, loss_test:0.00932, lr:4.62e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.154, tt:4010.465\n",
      "Ep:133, loss:0.00001, loss_test:0.00930, lr:4.57e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.165, tt:4042.125\n",
      "Ep:134, loss:0.00001, loss_test:0.00929, lr:4.53e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.179, tt:4074.220\n",
      "Ep:135, loss:0.00001, loss_test:0.00929, lr:4.48e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.185, tt:4105.175\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.00929, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.194, tt:4136.534\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00001, loss_test:0.00928, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.196, tt:4167.035\n",
      "Ep:138, loss:0.00001, loss_test:0.00930, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.203, tt:4198.171\n",
      "Ep:139, loss:0.00001, loss_test:0.00930, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.195, tt:4227.269\n",
      "Ep:140, loss:0.00001, loss_test:0.00929, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.208, tt:4259.296\n",
      "Ep:141, loss:0.00001, loss_test:0.00928, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.221, tt:4291.371\n",
      "Ep:142, loss:0.00001, loss_test:0.00927, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.224, tt:4322.046\n",
      "Ep:143, loss:0.00001, loss_test:0.00928, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.223, tt:4352.077\n",
      "Ep:144, loss:0.00001, loss_test:0.00931, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.218, tt:4381.624\n",
      "Ep:145, loss:0.00001, loss_test:0.00928, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.224, tt:4412.655\n",
      "Ep:146, loss:0.00001, loss_test:0.00928, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.233, tt:4444.299\n",
      "Ep:147, loss:0.00001, loss_test:0.00929, lr:4.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.227, tt:4473.567\n",
      "Ep:148, loss:0.00001, loss_test:0.00928, lr:4.44e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.232, tt:4504.510\n",
      "Ep:149, loss:0.00001, loss_test:0.00930, lr:4.39e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.229, tt:4534.385\n",
      "Ep:150, loss:0.00001, loss_test:0.00931, lr:4.35e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.225, tt:4564.048\n",
      "Ep:151, loss:0.00001, loss_test:0.00929, lr:4.31e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.223, tt:4593.911\n",
      "Ep:152, loss:0.00001, loss_test:0.00930, lr:4.26e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.218, tt:4623.365\n",
      "Ep:153, loss:0.00001, loss_test:0.00932, lr:4.22e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.208, tt:4652.097\n",
      "Ep:154, loss:0.00001, loss_test:0.00930, lr:4.18e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.207, tt:4682.104\n",
      "Ep:155, loss:0.00001, loss_test:0.00930, lr:4.14e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.216, tt:4713.647\n",
      "Ep:156, loss:0.00001, loss_test:0.00930, lr:4.10e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.209, tt:4742.855\n",
      "Ep:157, loss:0.00001, loss_test:0.00931, lr:4.05e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.207, tt:4772.783\n",
      "Ep:158, loss:0.00001, loss_test:0.00931, lr:4.01e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.211, tt:4803.603\n",
      "Ep:159, loss:0.00001, loss_test:0.00932, lr:3.97e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.216, tt:4834.587\n",
      "Ep:160, loss:0.00001, loss_test:0.00934, lr:3.93e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.209, tt:4863.587\n",
      "Ep:161, loss:0.00001, loss_test:0.00934, lr:3.89e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.217, tt:4895.186\n",
      "Ep:162, loss:0.00000, loss_test:0.00934, lr:3.86e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.218, tt:4925.461\n",
      "Ep:163, loss:0.00000, loss_test:0.00933, lr:3.82e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.208, tt:4954.056\n",
      "Ep:164, loss:0.00000, loss_test:0.00934, lr:3.78e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.210, tt:4984.726\n",
      "Ep:165, loss:0.00000, loss_test:0.00935, lr:3.74e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.211, tt:5014.978\n",
      "Ep:166, loss:0.00000, loss_test:0.00937, lr:3.70e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.209, tt:5044.897\n",
      "Ep:167, loss:0.00000, loss_test:0.00935, lr:3.67e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.203, tt:5074.132\n",
      "Ep:168, loss:0.00000, loss_test:0.00934, lr:3.63e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.203, tt:5104.389\n",
      "Ep:169, loss:0.00000, loss_test:0.00935, lr:3.59e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.202, tt:5134.261\n",
      "Ep:170, loss:0.00000, loss_test:0.00934, lr:3.56e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.202, tt:5164.458\n",
      "Ep:171, loss:0.00000, loss_test:0.00934, lr:3.52e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.206, tt:5195.361\n",
      "Ep:172, loss:0.00000, loss_test:0.00935, lr:3.49e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.202, tt:5225.024\n",
      "Ep:173, loss:0.00000, loss_test:0.00938, lr:3.45e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.192, tt:5253.372\n",
      "Ep:174, loss:0.00000, loss_test:0.00938, lr:3.42e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.197, tt:5284.403\n",
      "Ep:175, loss:0.00000, loss_test:0.00936, lr:3.38e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.199, tt:5315.018\n",
      "Ep:176, loss:0.00000, loss_test:0.00938, lr:3.35e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.209, tt:5346.982\n",
      "Ep:177, loss:0.00000, loss_test:0.00940, lr:3.32e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.204, tt:5376.232\n",
      "Ep:178, loss:0.00000, loss_test:0.00938, lr:3.28e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.199, tt:5405.687\n",
      "Ep:179, loss:0.00000, loss_test:0.00939, lr:3.25e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.195, tt:5435.173\n",
      "Ep:180, loss:0.00000, loss_test:0.00940, lr:3.22e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.191, tt:5464.553\n",
      "Ep:181, loss:0.00000, loss_test:0.00942, lr:3.19e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.186, tt:5493.872\n",
      "Ep:182, loss:0.00000, loss_test:0.00942, lr:3.15e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.180, tt:5522.903\n",
      "Ep:183, loss:0.00000, loss_test:0.00941, lr:3.12e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.178, tt:5552.769\n",
      "Ep:184, loss:0.00000, loss_test:0.00940, lr:3.09e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.176, tt:5582.616\n",
      "Ep:185, loss:0.00000, loss_test:0.00942, lr:3.06e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.172, tt:5611.935\n",
      "Ep:186, loss:0.00000, loss_test:0.00944, lr:3.03e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.167, tt:5641.269\n",
      "Ep:187, loss:0.00000, loss_test:0.00945, lr:3.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.160, tt:5670.156\n",
      "Ep:188, loss:0.00000, loss_test:0.00945, lr:2.97e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.161, tt:5700.340\n",
      "Ep:189, loss:0.00000, loss_test:0.00946, lr:2.94e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.160, tt:5730.328\n",
      "Ep:190, loss:0.00000, loss_test:0.00947, lr:2.91e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.157, tt:5760.020\n",
      "Ep:191, loss:0.00000, loss_test:0.00945, lr:2.88e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.155, tt:5789.672\n",
      "Ep:192, loss:0.00000, loss_test:0.00945, lr:2.85e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.148, tt:5818.563\n",
      "Ep:193, loss:0.00000, loss_test:0.00947, lr:2.82e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.145, tt:5848.113\n",
      "Ep:194, loss:0.00000, loss_test:0.00949, lr:2.80e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.137, tt:5876.715\n",
      "Ep:195, loss:0.00000, loss_test:0.00948, lr:2.77e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.140, tt:5907.437\n",
      "Ep:196, loss:0.00000, loss_test:0.00948, lr:2.74e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.139, tt:5937.480\n",
      "Ep:197, loss:0.00000, loss_test:0.00949, lr:2.71e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.127, tt:5965.046\n",
      "Ep:198, loss:0.00000, loss_test:0.00950, lr:2.69e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.118, tt:5993.406\n",
      "Ep:199, loss:0.00000, loss_test:0.00950, lr:2.66e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.115, tt:6022.951\n",
      "Ep:200, loss:0.00000, loss_test:0.00950, lr:2.63e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.113, tt:6052.634\n",
      "Ep:201, loss:0.00000, loss_test:0.00950, lr:2.61e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.111, tt:6082.388\n",
      "Ep:202, loss:0.00000, loss_test:0.00950, lr:2.58e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.107, tt:6111.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.00951, lr:2.55e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.107, tt:6141.746\n",
      "Ep:204, loss:0.00000, loss_test:0.00953, lr:2.53e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.101, tt:6170.689\n",
      "Ep:205, loss:0.00000, loss_test:0.00952, lr:2.50e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.099, tt:6200.375\n",
      "Ep:206, loss:0.00000, loss_test:0.00952, lr:2.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.094, tt:6229.462\n",
      "Ep:207, loss:0.00000, loss_test:0.00953, lr:2.45e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.086, tt:6257.960\n",
      "Ep:208, loss:0.00000, loss_test:0.00955, lr:2.43e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.092, tt:6289.211\n",
      "Ep:209, loss:0.00000, loss_test:0.00954, lr:2.40e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.090, tt:6318.803\n",
      "Ep:210, loss:0.00000, loss_test:0.00954, lr:2.38e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.092, tt:6349.374\n",
      "Ep:211, loss:0.00000, loss_test:0.00954, lr:2.36e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.087, tt:6378.448\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13949, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.136, tt:33.136\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13805, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.909, tt:65.818\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13548, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.870, tt:95.609\n",
      "Ep:3, loss:0.00027, loss_test:0.13127, lr:1.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:31.798, tt:127.192\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12484, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:31.769, tt:158.846\n",
      "Ep:5, loss:0.00026, loss_test:0.11732, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:31.805, tt:190.829\n",
      "Ep:6, loss:0.00024, loss_test:0.11326, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:31.661, tt:221.630\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11183, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:31.681, tt:253.451\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10904, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:31.688, tt:285.188\n",
      "Ep:9, loss:0.00023, loss_test:0.10684, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:31.727, tt:317.267\n",
      "Ep:10, loss:0.00022, loss_test:0.10560, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:31.678, tt:348.453\n",
      "Ep:11, loss:0.00022, loss_test:0.10405, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:31.678, tt:380.136\n",
      "Ep:12, loss:0.00021, loss_test:0.10242, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:31.892, tt:414.595\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.09995, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:31.949, tt:447.293\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09746, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:31.990, tt:479.846\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09444, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:32.013, tt:512.200\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09168, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:31.944, tt:543.045\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.08963, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:31.918, tt:574.526\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08729, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:31.952, tt:607.091\n",
      "Ep:19, loss:0.00018, loss_test:0.08460, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.957, tt:639.142\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08300, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.956, tt:671.071\n",
      "Ep:21, loss:0.00017, loss_test:0.08214, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:31.906, tt:701.936\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.08068, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.916, tt:734.075\n",
      "Ep:23, loss:0.00016, loss_test:0.07968, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:31.877, tt:765.055\n",
      "Ep:24, loss:0.00016, loss_test:0.07818, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:31.865, tt:796.618\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.07707, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.849, tt:828.083\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.07622, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.799, tt:858.578\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.07501, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:31.802, tt:890.462\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.07348, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.812, tt:922.554\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.07252, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:31.860, tt:955.795\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.07281, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.830, tt:986.731\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.07176, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:31.770, tt:1016.639\n",
      "Ep:32, loss:0.00013, loss_test:0.07090, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:31.775, tt:1048.584\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07139, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.859, tt:1083.199\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.07027, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:31.885, tt:1115.985\n",
      "Ep:35, loss:0.00012, loss_test:0.06898, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.870, tt:1147.320\n",
      "Ep:36, loss:0.00012, loss_test:0.06934, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:31.883, tt:1179.679\n",
      "Ep:37, loss:0.00012, loss_test:0.06745, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:31.857, tt:1210.555\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.06689, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:31.844, tt:1241.928\n",
      "Ep:39, loss:0.00011, loss_test:0.06700, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:31.853, tt:1274.137\n",
      "Ep:40, loss:0.00011, loss_test:0.06580, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:31.834, tt:1305.196\n",
      "Ep:41, loss:0.00011, loss_test:0.06503, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.834, tt:1337.012\n",
      "Ep:42, loss:0.00010, loss_test:0.06498, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:31.849, tt:1369.523\n",
      "Ep:43, loss:0.00010, loss_test:0.06503, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:31.865, tt:1402.080\n",
      "Ep:44, loss:0.00010, loss_test:0.06516, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:31.858, tt:1433.596\n",
      "Ep:45, loss:0.00010, loss_test:0.06451, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.849, tt:1465.039\n",
      "Ep:46, loss:0.00010, loss_test:0.06451, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:31.844, tt:1496.650\n",
      "Ep:47, loss:0.00009, loss_test:0.06312, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.863, tt:1529.436\n",
      "Ep:48, loss:0.00009, loss_test:0.06447, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:31.891, tt:1562.663\n",
      "Ep:49, loss:0.00009, loss_test:0.06074, lr:9.90e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.910, tt:1595.515\n",
      "Ep:50, loss:0.00009, loss_test:0.06186, lr:9.80e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.897, tt:1626.737\n",
      "Ep:51, loss:0.00009, loss_test:0.06194, lr:9.70e-03, fs:0.83770 (r=0.808,p=0.870),  time:31.878, tt:1657.632\n",
      "Ep:52, loss:0.00008, loss_test:0.05904, lr:9.61e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.882, tt:1689.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00008, loss_test:0.06050, lr:9.51e-03, fs:0.82474 (r=0.808,p=0.842),  time:31.877, tt:1721.353\n",
      "Ep:54, loss:0.00008, loss_test:0.05850, lr:9.41e-03, fs:0.85263 (r=0.818,p=0.890),  time:31.884, tt:1753.630\n",
      "Ep:55, loss:0.00008, loss_test:0.05878, lr:9.32e-03, fs:0.84817 (r=0.818,p=0.880),  time:31.857, tt:1784.008\n",
      "Ep:56, loss:0.00007, loss_test:0.05962, lr:9.23e-03, fs:0.84211 (r=0.808,p=0.879),  time:31.852, tt:1815.540\n",
      "Ep:57, loss:0.00007, loss_test:0.05819, lr:9.14e-03, fs:0.85279 (r=0.848,p=0.857),  time:31.850, tt:1847.292\n",
      "Ep:58, loss:0.00007, loss_test:0.05778, lr:9.04e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.852, tt:1879.278\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00007, loss_test:0.05874, lr:9.04e-03, fs:0.84848 (r=0.848,p=0.848),  time:31.843, tt:1910.588\n",
      "Ep:60, loss:0.00007, loss_test:0.05651, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.806, tt:1940.186\n",
      "Ep:61, loss:0.00007, loss_test:0.05663, lr:9.04e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.786, tt:1970.734\n",
      "Ep:62, loss:0.00007, loss_test:0.05581, lr:9.04e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.764, tt:2001.149\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.05689, lr:9.04e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.742, tt:2031.486\n",
      "Ep:64, loss:0.00006, loss_test:0.05579, lr:9.04e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.726, tt:2062.190\n",
      "Ep:65, loss:0.00006, loss_test:0.05727, lr:9.04e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.718, tt:2093.417\n",
      "Ep:66, loss:0.00006, loss_test:0.05486, lr:9.04e-03, fs:0.86598 (r=0.848,p=0.884),  time:31.701, tt:2123.984\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00006, loss_test:0.05594, lr:9.04e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.728, tt:2157.536\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.05407, lr:9.04e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.724, tt:2188.940\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.05403, lr:9.04e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.735, tt:2221.418\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.05468, lr:9.04e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.758, tt:2254.813\n",
      "Ep:71, loss:0.00005, loss_test:0.05436, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:31.758, tt:2286.588\n",
      "Ep:72, loss:0.00005, loss_test:0.05514, lr:9.04e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.752, tt:2317.899\n",
      "Ep:73, loss:0.00005, loss_test:0.05259, lr:9.04e-03, fs:0.86911 (r=0.838,p=0.902),  time:31.752, tt:2349.639\n",
      "Ep:74, loss:0.00005, loss_test:0.05370, lr:9.04e-03, fs:0.86316 (r=0.828,p=0.901),  time:31.750, tt:2381.286\n",
      "Ep:75, loss:0.00005, loss_test:0.05256, lr:9.04e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.750, tt:2413.005\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00005, loss_test:0.05298, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:31.770, tt:2446.260\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.05202, lr:9.04e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.756, tt:2476.967\n",
      "Ep:78, loss:0.00004, loss_test:0.05188, lr:9.04e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.756, tt:2508.710\n",
      "Ep:79, loss:0.00004, loss_test:0.05381, lr:9.04e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.764, tt:2541.121\n",
      "Ep:80, loss:0.00004, loss_test:0.05306, lr:9.04e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.754, tt:2572.073\n",
      "Ep:81, loss:0.00004, loss_test:0.05300, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:31.747, tt:2603.271\n",
      "Ep:82, loss:0.00004, loss_test:0.05137, lr:9.04e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.752, tt:2635.415\n",
      "Ep:83, loss:0.00004, loss_test:0.05700, lr:9.04e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.748, tt:2666.818\n",
      "Ep:84, loss:0.00004, loss_test:0.05072, lr:9.04e-03, fs:0.88542 (r=0.859,p=0.914),  time:31.733, tt:2697.324\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.05429, lr:9.04e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.715, tt:2727.455\n",
      "Ep:86, loss:0.00004, loss_test:0.05100, lr:9.04e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.690, tt:2757.042\n",
      "Ep:87, loss:0.00004, loss_test:0.05441, lr:9.04e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.686, tt:2788.350\n",
      "Ep:88, loss:0.00004, loss_test:0.05063, lr:9.04e-03, fs:0.86911 (r=0.838,p=0.902),  time:31.683, tt:2819.785\n",
      "Ep:89, loss:0.00004, loss_test:0.05398, lr:9.04e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.628, tt:2846.509\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00004, loss_test:0.05171, lr:9.04e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.561, tt:2872.023\n",
      "Ep:91, loss:0.00004, loss_test:0.05208, lr:9.04e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.473, tt:2895.546\n",
      "Ep:92, loss:0.00004, loss_test:0.05191, lr:9.04e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.447, tt:2924.617\n",
      "Ep:93, loss:0.00003, loss_test:0.05028, lr:9.04e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.435, tt:2954.877\n",
      "Ep:94, loss:0.00003, loss_test:0.05113, lr:9.04e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.427, tt:2985.599\n",
      "Ep:95, loss:0.00003, loss_test:0.04970, lr:9.04e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.410, tt:3015.334\n",
      "Ep:96, loss:0.00003, loss_test:0.05117, lr:9.04e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.409, tt:3046.657\n",
      "Ep:97, loss:0.00003, loss_test:0.04922, lr:9.04e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.442, tt:3081.317\n",
      "Ep:98, loss:0.00003, loss_test:0.05126, lr:9.04e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.439, tt:3112.431\n",
      "Ep:99, loss:0.00003, loss_test:0.04887, lr:9.04e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.432, tt:3143.173\n",
      "Ep:100, loss:0.00003, loss_test:0.05101, lr:9.04e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.425, tt:3173.924\n",
      "Ep:101, loss:0.00003, loss_test:0.05059, lr:8.95e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.423, tt:3205.194\n",
      "Ep:102, loss:0.00003, loss_test:0.04892, lr:8.86e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.423, tt:3236.613\n",
      "Ep:103, loss:0.00003, loss_test:0.05094, lr:8.78e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.412, tt:3266.896\n",
      "Ep:104, loss:0.00003, loss_test:0.04807, lr:8.69e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.395, tt:3296.487\n",
      "Ep:105, loss:0.00003, loss_test:0.05076, lr:8.60e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.390, tt:3327.378\n",
      "Ep:106, loss:0.00003, loss_test:0.04910, lr:8.51e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.388, tt:3358.505\n",
      "Ep:107, loss:0.00002, loss_test:0.04834, lr:8.43e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.390, tt:3390.108\n",
      "Ep:108, loss:0.00002, loss_test:0.05009, lr:8.35e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.394, tt:3421.945\n",
      "Ep:109, loss:0.00002, loss_test:0.04847, lr:8.26e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.407, tt:3454.732\n",
      "Ep:110, loss:0.00002, loss_test:0.04920, lr:8.18e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.409, tt:3486.411\n",
      "Ep:111, loss:0.00002, loss_test:0.04900, lr:8.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.414, tt:3518.374\n",
      "Ep:112, loss:0.00002, loss_test:0.04878, lr:8.02e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.407, tt:3549.038\n",
      "Ep:113, loss:0.00002, loss_test:0.04920, lr:7.94e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.411, tt:3580.857\n",
      "Ep:114, loss:0.00002, loss_test:0.04843, lr:7.86e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.400, tt:3611.000\n",
      "Ep:115, loss:0.00002, loss_test:0.04994, lr:7.78e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.387, tt:3640.918\n",
      "Ep:116, loss:0.00002, loss_test:0.04769, lr:7.70e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.405, tt:3674.407\n",
      "Ep:117, loss:0.00002, loss_test:0.04946, lr:7.62e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.408, tt:3706.096\n",
      "Ep:118, loss:0.00002, loss_test:0.04816, lr:7.55e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.402, tt:3736.802\n",
      "Ep:119, loss:0.00002, loss_test:0.04903, lr:7.47e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.399, tt:3767.822\n",
      "Ep:120, loss:0.00002, loss_test:0.04946, lr:7.40e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.409, tt:3800.544\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00002, loss_test:0.04716, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.417, tt:3832.850\n",
      "Ep:122, loss:0.00002, loss_test:0.04921, lr:7.40e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.406, tt:3862.950\n",
      "Ep:123, loss:0.00002, loss_test:0.04783, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.402, tt:3893.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00002, loss_test:0.04753, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.386, tt:3923.276\n",
      "Ep:125, loss:0.00002, loss_test:0.04851, lr:7.40e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.396, tt:3955.888\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00002, loss_test:0.04746, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.395, tt:3987.153\n",
      "Ep:127, loss:0.00002, loss_test:0.04835, lr:7.40e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.396, tt:4018.692\n",
      "Ep:128, loss:0.00002, loss_test:0.04799, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.409, tt:4051.769\n",
      "Ep:129, loss:0.00002, loss_test:0.04692, lr:7.40e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.400, tt:4081.981\n",
      "Ep:130, loss:0.00002, loss_test:0.04871, lr:7.40e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.395, tt:4112.734\n",
      "Ep:131, loss:0.00002, loss_test:0.04660, lr:7.40e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.394, tt:4143.945\n",
      "Ep:132, loss:0.00002, loss_test:0.04770, lr:7.40e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.401, tt:4176.316\n",
      "Ep:133, loss:0.00002, loss_test:0.04740, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.400, tt:4207.560\n",
      "Ep:134, loss:0.00002, loss_test:0.04731, lr:7.40e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.406, tt:4239.788\n",
      "Ep:135, loss:0.00002, loss_test:0.04807, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.408, tt:4271.554\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.04681, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.411, tt:4303.362\n",
      "Ep:137, loss:0.00001, loss_test:0.04797, lr:7.40e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.411, tt:4334.673\n",
      "Ep:138, loss:0.00001, loss_test:0.04783, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.411, tt:4366.085\n",
      "Ep:139, loss:0.00001, loss_test:0.04713, lr:7.40e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.408, tt:4397.100\n",
      "Ep:140, loss:0.00001, loss_test:0.04859, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.412, tt:4429.159\n",
      "Ep:141, loss:0.00001, loss_test:0.04807, lr:7.40e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.424, tt:4462.144\n",
      "Ep:142, loss:0.00001, loss_test:0.04673, lr:7.40e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.419, tt:4492.950\n",
      "Ep:143, loss:0.00001, loss_test:0.04956, lr:7.40e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.410, tt:4523.101\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00001, loss_test:0.04666, lr:7.40e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.408, tt:4554.186\n",
      "Ep:145, loss:0.00001, loss_test:0.04745, lr:7.40e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.399, tt:4584.317\n",
      "Ep:146, loss:0.00001, loss_test:0.04781, lr:7.40e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.391, tt:4614.494\n",
      "Ep:147, loss:0.00001, loss_test:0.04771, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.384, tt:4644.830\n",
      "Ep:148, loss:0.00001, loss_test:0.04768, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.391, tt:4677.252\n",
      "Ep:149, loss:0.00001, loss_test:0.04687, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.382, tt:4707.323\n",
      "Ep:150, loss:0.00001, loss_test:0.04762, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.387, tt:4739.462\n",
      "Ep:151, loss:0.00001, loss_test:0.04754, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.391, tt:4771.397\n",
      "Ep:152, loss:0.00001, loss_test:0.04671, lr:7.40e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.404, tt:4804.735\n",
      "Ep:153, loss:0.00001, loss_test:0.04739, lr:7.40e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.399, tt:4835.466\n",
      "Ep:154, loss:0.00001, loss_test:0.04752, lr:7.40e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.401, tt:4867.096\n",
      "Ep:155, loss:0.00001, loss_test:0.04664, lr:7.32e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.394, tt:4897.458\n",
      "Ep:156, loss:0.00001, loss_test:0.04745, lr:7.25e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.375, tt:4925.822\n",
      "Ep:157, loss:0.00001, loss_test:0.04662, lr:7.18e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.371, tt:4956.600\n",
      "Ep:158, loss:0.00001, loss_test:0.04779, lr:7.11e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.369, tt:4987.635\n",
      "Ep:159, loss:0.00001, loss_test:0.04654, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.369, tt:5019.094\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00001, loss_test:0.04766, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.381, tt:5052.262\n",
      "Ep:161, loss:0.00001, loss_test:0.04717, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.380, tt:5083.597\n",
      "Ep:162, loss:0.00001, loss_test:0.04729, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.384, tt:5115.636\n",
      "Ep:163, loss:0.00001, loss_test:0.04842, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.395, tt:5148.795\n",
      "Ep:164, loss:0.00001, loss_test:0.04638, lr:7.03e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.399, tt:5180.843\n",
      "Ep:165, loss:0.00001, loss_test:0.04821, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.413, tt:5214.530\n",
      "Ep:166, loss:0.00001, loss_test:0.04741, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.422, tt:5247.546\n",
      "Ep:167, loss:0.00001, loss_test:0.04712, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.427, tt:5279.689\n",
      "Ep:168, loss:0.00001, loss_test:0.04801, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.425, tt:5310.801\n",
      "Ep:169, loss:0.00001, loss_test:0.04787, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.430, tt:5343.129\n",
      "Ep:170, loss:0.00001, loss_test:0.04715, lr:7.03e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.437, tt:5375.664\n",
      "Ep:171, loss:0.00001, loss_test:0.04925, lr:6.96e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.444, tt:5408.303\n",
      "Ep:172, loss:0.00001, loss_test:0.04897, lr:6.89e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.448, tt:5440.530\n",
      "Ep:173, loss:0.00001, loss_test:0.04763, lr:6.83e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.444, tt:5471.305\n",
      "Ep:174, loss:0.00001, loss_test:0.04921, lr:6.76e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.457, tt:5504.965\n",
      "Ep:175, loss:0.00001, loss_test:0.04895, lr:6.69e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.468, tt:5538.444\n",
      "Ep:176, loss:0.00001, loss_test:0.04836, lr:6.62e-03, fs:0.90217 (r=0.838,p=0.976),  time:31.468, tt:5569.888\n",
      "Ep:177, loss:0.00001, loss_test:0.04974, lr:6.56e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.471, tt:5601.830\n",
      "Ep:178, loss:0.00001, loss_test:0.04833, lr:6.49e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.476, tt:5634.260\n",
      "Ep:179, loss:0.00001, loss_test:0.04902, lr:6.43e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.482, tt:5666.761\n",
      "Ep:180, loss:0.00001, loss_test:0.04949, lr:6.36e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.490, tt:5699.761\n",
      "Ep:181, loss:0.00001, loss_test:0.04762, lr:6.30e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.489, tt:5731.029\n",
      "Ep:182, loss:0.00001, loss_test:0.05029, lr:6.24e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.496, tt:5763.704\n",
      "Ep:183, loss:0.00001, loss_test:0.04856, lr:6.17e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.501, tt:5796.212\n",
      "Ep:184, loss:0.00001, loss_test:0.04785, lr:6.11e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.499, tt:5827.363\n",
      "Ep:185, loss:0.00001, loss_test:0.04958, lr:6.05e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.497, tt:5858.430\n",
      "Ep:186, loss:0.00001, loss_test:0.04886, lr:5.99e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.498, tt:5890.045\n",
      "Ep:187, loss:0.00001, loss_test:0.04839, lr:5.93e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.485, tt:5919.229\n",
      "Ep:188, loss:0.00001, loss_test:0.05003, lr:5.87e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.477, tt:5949.217\n",
      "Ep:189, loss:0.00001, loss_test:0.04867, lr:5.81e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.490, tt:5983.048\n",
      "Ep:190, loss:0.00001, loss_test:0.04862, lr:5.75e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.500, tt:6016.479\n",
      "Ep:191, loss:0.00001, loss_test:0.05009, lr:5.70e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.510, tt:6049.914\n",
      "Ep:192, loss:0.00001, loss_test:0.04861, lr:5.64e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.514, tt:6082.129\n",
      "Ep:193, loss:0.00001, loss_test:0.04824, lr:5.58e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.521, tt:6115.011\n",
      "Ep:194, loss:0.00001, loss_test:0.04930, lr:5.53e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.520, tt:6146.478\n",
      "Ep:195, loss:0.00001, loss_test:0.04843, lr:5.47e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.524, tt:6178.718\n",
      "Ep:196, loss:0.00001, loss_test:0.04856, lr:5.42e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.544, tt:6214.137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00001, loss_test:0.04931, lr:5.36e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.539, tt:6244.776\n",
      "Ep:198, loss:0.00001, loss_test:0.04879, lr:5.31e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.547, tt:6277.890\n",
      "Ep:199, loss:0.00001, loss_test:0.04844, lr:5.26e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.544, tt:6308.822\n",
      "Ep:200, loss:0.00001, loss_test:0.04900, lr:5.20e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.541, tt:6339.721\n",
      "Ep:201, loss:0.00001, loss_test:0.04944, lr:5.15e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.553, tt:6373.772\n",
      "Ep:202, loss:0.00001, loss_test:0.04877, lr:5.10e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.556, tt:6405.799\n",
      "Ep:203, loss:0.00001, loss_test:0.04867, lr:5.05e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.557, tt:6437.671\n",
      "Ep:204, loss:0.00001, loss_test:0.04950, lr:5.00e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.557, tt:6469.151\n",
      "Ep:205, loss:0.00001, loss_test:0.04925, lr:4.95e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.554, tt:6500.199\n",
      "Ep:206, loss:0.00001, loss_test:0.04946, lr:4.90e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.557, tt:6532.386\n",
      "Ep:207, loss:0.00001, loss_test:0.04880, lr:4.85e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.550, tt:6562.392\n",
      "Ep:208, loss:0.00001, loss_test:0.04950, lr:4.80e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.551, tt:6594.084\n",
      "Ep:209, loss:0.00001, loss_test:0.04942, lr:4.75e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.551, tt:6625.792\n",
      "Ep:210, loss:0.00001, loss_test:0.04847, lr:4.71e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.553, tt:6657.663\n",
      "Ep:211, loss:0.00001, loss_test:0.04905, lr:4.66e-03, fs:0.91209 (r=0.838,p=1.000),  time:31.554, tt:6689.459\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.01978, lr:6.00e-02, fs:0.61925 (r=0.747,p=0.529),  time:32.346, tt:32.346\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02245, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.201, tt:62.401\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02585, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.195, tt:93.584\n",
      "Ep:3, loss:0.00005, loss_test:0.02734, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.105, tt:124.419\n",
      "Ep:4, loss:0.00005, loss_test:0.02781, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.122, tt:155.610\n",
      "Ep:5, loss:0.00006, loss_test:0.02780, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.817, tt:184.901\n",
      "Ep:6, loss:0.00006, loss_test:0.02732, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.716, tt:215.010\n",
      "Ep:7, loss:0.00005, loss_test:0.02632, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.643, tt:245.141\n",
      "Ep:8, loss:0.00005, loss_test:0.02491, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.912, tt:278.208\n",
      "Ep:9, loss:0.00005, loss_test:0.02320, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.879, tt:308.787\n",
      "Ep:10, loss:0.00005, loss_test:0.02135, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.892, tt:339.807\n",
      "Ep:11, loss:0.00004, loss_test:0.01960, lr:6.00e-02, fs:0.68531 (r=0.990,p=0.524),  time:30.718, tt:368.611\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01829, lr:6.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:30.660, tt:398.575\n",
      "Ep:13, loss:0.00004, loss_test:0.01776, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:30.676, tt:429.469\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01782, lr:6.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:30.738, tt:461.063\n",
      "Ep:15, loss:0.00004, loss_test:0.01783, lr:6.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:30.619, tt:489.907\n",
      "Ep:16, loss:0.00004, loss_test:0.01732, lr:6.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:30.532, tt:519.037\n",
      "Ep:17, loss:0.00004, loss_test:0.01664, lr:6.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:30.502, tt:549.040\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:30.454, tt:578.618\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:30.388, tt:607.750\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01584, lr:6.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:30.373, tt:637.834\n",
      "Ep:21, loss:0.00003, loss_test:0.01565, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:30.377, tt:668.289\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:30.344, tt:697.902\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01523, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:30.380, tt:729.111\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01510, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:30.368, tt:759.212\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:30.263, tt:786.836\n",
      "Ep:26, loss:0.00003, loss_test:0.01497, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:30.267, tt:817.208\n",
      "Ep:27, loss:0.00003, loss_test:0.01488, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:30.256, tt:847.155\n",
      "Ep:28, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:30.262, tt:877.593\n",
      "Ep:29, loss:0.00003, loss_test:0.01470, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:30.264, tt:907.909\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01459, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:30.398, tt:942.337\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01449, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:30.395, tt:972.650\n",
      "Ep:32, loss:0.00003, loss_test:0.01441, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:30.419, tt:1003.837\n",
      "Ep:33, loss:0.00002, loss_test:0.01435, lr:6.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:30.420, tt:1034.281\n",
      "Ep:34, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.439, tt:1065.351\n",
      "Ep:35, loss:0.00002, loss_test:0.01428, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.448, tt:1096.134\n",
      "Ep:36, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.488, tt:1128.073\n",
      "Ep:37, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.515, tt:1159.581\n",
      "Ep:38, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:30.518, tt:1190.192\n",
      "Ep:39, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.538, tt:1221.540\n",
      "Ep:40, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.544, tt:1252.302\n",
      "Ep:41, loss:0.00002, loss_test:0.01379, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.551, tt:1283.149\n",
      "Ep:42, loss:0.00002, loss_test:0.01373, lr:5.94e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.545, tt:1313.456\n",
      "Ep:43, loss:0.00002, loss_test:0.01368, lr:5.88e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.538, tt:1343.654\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01363, lr:5.88e-02, fs:0.79808 (r=0.838,p=0.761),  time:30.509, tt:1372.892\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01357, lr:5.88e-02, fs:0.79808 (r=0.838,p=0.761),  time:30.482, tt:1402.181\n",
      "Ep:46, loss:0.00002, loss_test:0.01351, lr:5.88e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.488, tt:1432.944\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00002, loss_test:0.01345, lr:5.88e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.477, tt:1462.920\n",
      "Ep:48, loss:0.00002, loss_test:0.01341, lr:5.88e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.475, tt:1493.298\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01336, lr:5.88e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.483, tt:1524.159\n",
      "Ep:50, loss:0.00002, loss_test:0.01333, lr:5.88e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.474, tt:1554.180\n",
      "Ep:51, loss:0.00002, loss_test:0.01329, lr:5.88e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.442, tt:1582.977\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01325, lr:5.88e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.462, tt:1614.466\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01322, lr:5.88e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.467, tt:1645.214\n",
      "Ep:54, loss:0.00002, loss_test:0.01319, lr:5.88e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.473, tt:1675.989\n",
      "Ep:55, loss:0.00002, loss_test:0.01315, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.471, tt:1706.392\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01312, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.476, tt:1737.111\n",
      "Ep:57, loss:0.00002, loss_test:0.01309, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.516, tt:1769.921\n",
      "Ep:58, loss:0.00002, loss_test:0.01306, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.527, tt:1801.109\n",
      "Ep:59, loss:0.00001, loss_test:0.01304, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.527, tt:1831.599\n",
      "Ep:60, loss:0.00001, loss_test:0.01303, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.506, tt:1860.853\n",
      "Ep:61, loss:0.00001, loss_test:0.01301, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.482, tt:1889.870\n",
      "Ep:62, loss:0.00001, loss_test:0.01299, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.492, tt:1920.969\n",
      "Ep:63, loss:0.00001, loss_test:0.01297, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.496, tt:1951.715\n",
      "Ep:64, loss:0.00001, loss_test:0.01295, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.473, tt:1980.747\n",
      "Ep:65, loss:0.00001, loss_test:0.01295, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.469, tt:2010.948\n",
      "Ep:66, loss:0.00001, loss_test:0.01294, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.447, tt:2039.964\n",
      "Ep:67, loss:0.00001, loss_test:0.01295, lr:5.82e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.447, tt:2070.384\n",
      "Ep:68, loss:0.00001, loss_test:0.01294, lr:5.76e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.435, tt:2100.009\n",
      "Ep:69, loss:0.00001, loss_test:0.01294, lr:5.71e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.423, tt:2129.592\n",
      "Ep:70, loss:0.00001, loss_test:0.01292, lr:5.65e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.414, tt:2159.373\n",
      "Ep:71, loss:0.00001, loss_test:0.01291, lr:5.59e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.440, tt:2191.704\n",
      "Ep:72, loss:0.00001, loss_test:0.01290, lr:5.54e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.439, tt:2222.025\n",
      "Ep:73, loss:0.00001, loss_test:0.01291, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.439, tt:2252.484\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01290, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.447, tt:2283.550\n",
      "Ep:75, loss:0.00001, loss_test:0.01290, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.435, tt:2313.044\n",
      "Ep:76, loss:0.00001, loss_test:0.01291, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.434, tt:2343.415\n",
      "Ep:77, loss:0.00001, loss_test:0.01291, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.438, tt:2374.130\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01291, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.427, tt:2403.736\n",
      "Ep:79, loss:0.00001, loss_test:0.01292, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.411, tt:2432.856\n",
      "Ep:80, loss:0.00001, loss_test:0.01292, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.370, tt:2459.983\n",
      "Ep:81, loss:0.00001, loss_test:0.01291, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.306, tt:2485.095\n",
      "Ep:82, loss:0.00001, loss_test:0.01292, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.235, tt:2509.527\n",
      "Ep:83, loss:0.00001, loss_test:0.01292, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.180, tt:2535.079\n",
      "Ep:84, loss:0.00001, loss_test:0.01294, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.141, tt:2561.998\n",
      "Ep:85, loss:0.00001, loss_test:0.01295, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.062, tt:2585.300\n",
      "Ep:86, loss:0.00001, loss_test:0.01297, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.035, tt:2613.028\n",
      "Ep:87, loss:0.00001, loss_test:0.01298, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.978, tt:2638.106\n",
      "Ep:88, loss:0.00001, loss_test:0.01299, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.962, tt:2666.601\n",
      "Ep:89, loss:0.00001, loss_test:0.01299, lr:5.43e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.959, tt:2696.308\n",
      "Ep:90, loss:0.00001, loss_test:0.01299, lr:5.37e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.955, tt:2725.883\n",
      "Ep:91, loss:0.00001, loss_test:0.01301, lr:5.32e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.948, tt:2755.190\n",
      "Ep:92, loss:0.00001, loss_test:0.01303, lr:5.27e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.931, tt:2783.613\n",
      "Ep:93, loss:0.00001, loss_test:0.01303, lr:5.21e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.905, tt:2811.044\n",
      "Ep:94, loss:0.00001, loss_test:0.01302, lr:5.16e-02, fs:0.81592 (r=0.828,p=0.804),  time:29.903, tt:2840.819\n",
      "Ep:95, loss:0.00001, loss_test:0.01303, lr:5.11e-02, fs:0.81592 (r=0.828,p=0.804),  time:29.913, tt:2871.661\n",
      "Ep:96, loss:0.00001, loss_test:0.01305, lr:5.06e-02, fs:0.81592 (r=0.828,p=0.804),  time:29.911, tt:2901.368\n",
      "Ep:97, loss:0.00001, loss_test:0.01306, lr:5.01e-02, fs:0.81592 (r=0.828,p=0.804),  time:29.912, tt:2931.405\n",
      "Ep:98, loss:0.00001, loss_test:0.01308, lr:4.96e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.926, tt:2962.659\n",
      "Ep:99, loss:0.00001, loss_test:0.01308, lr:4.91e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.926, tt:2992.602\n",
      "Ep:100, loss:0.00001, loss_test:0.01309, lr:4.86e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.943, tt:3024.289\n",
      "Ep:101, loss:0.00001, loss_test:0.01310, lr:4.81e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.930, tt:3052.849\n",
      "Ep:102, loss:0.00001, loss_test:0.01312, lr:4.76e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.945, tt:3084.286\n",
      "Ep:103, loss:0.00001, loss_test:0.01314, lr:4.71e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.934, tt:3113.172\n",
      "Ep:104, loss:0.00001, loss_test:0.01315, lr:4.67e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.943, tt:3143.991\n",
      "Ep:105, loss:0.00001, loss_test:0.01315, lr:4.62e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.960, tt:3175.727\n",
      "Ep:106, loss:0.00001, loss_test:0.01317, lr:4.57e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.954, tt:3205.070\n",
      "Ep:107, loss:0.00001, loss_test:0.01319, lr:4.53e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.958, tt:3235.450\n",
      "Ep:108, loss:0.00001, loss_test:0.01321, lr:4.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.985, tt:3268.333\n",
      "Ep:109, loss:0.00001, loss_test:0.01323, lr:4.44e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.996, tt:3299.613\n",
      "Ep:110, loss:0.00001, loss_test:0.01323, lr:4.39e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.001, tt:3330.141\n",
      "Ep:111, loss:0.00001, loss_test:0.01325, lr:4.35e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.004, tt:3360.500\n",
      "Ep:112, loss:0.00001, loss_test:0.01327, lr:4.31e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.999, tt:3389.887\n",
      "Ep:113, loss:0.00001, loss_test:0.01328, lr:4.26e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.010, tt:3421.086\n",
      "Ep:114, loss:0.00001, loss_test:0.01330, lr:4.22e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.006, tt:3450.737\n",
      "Ep:115, loss:0.00001, loss_test:0.01330, lr:4.18e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.015, tt:3481.764\n",
      "Ep:116, loss:0.00001, loss_test:0.01332, lr:4.14e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.024, tt:3512.780\n",
      "Ep:117, loss:0.00001, loss_test:0.01333, lr:4.10e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.023, tt:3542.739\n",
      "Ep:118, loss:0.00001, loss_test:0.01335, lr:4.05e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.025, tt:3572.974\n",
      "Ep:119, loss:0.00001, loss_test:0.01336, lr:4.01e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.026, tt:3603.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00001, loss_test:0.01337, lr:3.97e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.034, tt:3634.078\n",
      "Ep:121, loss:0.00001, loss_test:0.01338, lr:3.93e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.034, tt:3664.145\n",
      "Ep:122, loss:0.00001, loss_test:0.01339, lr:3.89e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.030, tt:3693.708\n",
      "Ep:123, loss:0.00001, loss_test:0.01340, lr:3.86e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.031, tt:3723.888\n",
      "Ep:124, loss:0.00001, loss_test:0.01341, lr:3.82e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.037, tt:3754.618\n",
      "Ep:125, loss:0.00001, loss_test:0.01342, lr:3.78e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.040, tt:3785.054\n",
      "Ep:126, loss:0.00001, loss_test:0.01343, lr:3.74e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.031, tt:3813.889\n",
      "Ep:127, loss:0.00001, loss_test:0.01345, lr:3.70e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.033, tt:3844.268\n",
      "Ep:128, loss:0.00001, loss_test:0.01345, lr:3.67e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.031, tt:3874.048\n",
      "Ep:129, loss:0.00001, loss_test:0.01347, lr:3.63e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.044, tt:3905.697\n",
      "Ep:130, loss:0.00001, loss_test:0.01348, lr:3.59e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.068, tt:3938.945\n",
      "Ep:131, loss:0.00001, loss_test:0.01349, lr:3.56e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.069, tt:3969.167\n",
      "Ep:132, loss:0.00001, loss_test:0.01350, lr:3.52e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.072, tt:3999.639\n",
      "Ep:133, loss:0.00001, loss_test:0.01351, lr:3.49e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.072, tt:4029.714\n",
      "Ep:134, loss:0.00001, loss_test:0.01353, lr:3.45e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.078, tt:4060.589\n",
      "Ep:135, loss:0.00001, loss_test:0.01354, lr:3.42e-02, fs:0.81818 (r=0.818,p=0.818),  time:30.077, tt:4090.436\n",
      "Ep:136, loss:0.00001, loss_test:0.01355, lr:3.38e-02, fs:0.81218 (r=0.808,p=0.816),  time:30.090, tt:4122.363\n",
      "Ep:137, loss:0.00001, loss_test:0.01356, lr:3.35e-02, fs:0.81218 (r=0.808,p=0.816),  time:30.094, tt:4152.955\n",
      "Ep:138, loss:0.00001, loss_test:0.01358, lr:3.32e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.102, tt:4184.198\n",
      "Ep:139, loss:0.00001, loss_test:0.01359, lr:3.28e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.102, tt:4214.330\n",
      "Ep:140, loss:0.00001, loss_test:0.01360, lr:3.25e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.108, tt:4245.294\n",
      "Ep:141, loss:0.00001, loss_test:0.01361, lr:3.22e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.116, tt:4276.438\n",
      "Ep:142, loss:0.00001, loss_test:0.01362, lr:3.19e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.132, tt:4308.885\n",
      "Ep:143, loss:0.00001, loss_test:0.01363, lr:3.15e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.130, tt:4338.691\n",
      "Ep:144, loss:0.00001, loss_test:0.01363, lr:3.12e-02, fs:0.81026 (r=0.798,p=0.823),  time:30.137, tt:4369.847\n",
      "Ep:145, loss:0.00001, loss_test:0.01364, lr:3.09e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.142, tt:4400.762\n",
      "Ep:146, loss:0.00001, loss_test:0.01365, lr:3.06e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.146, tt:4431.489\n",
      "Ep:147, loss:0.00001, loss_test:0.01366, lr:3.03e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.148, tt:4461.932\n",
      "Ep:148, loss:0.00001, loss_test:0.01367, lr:3.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.149, tt:4492.189\n",
      "Ep:149, loss:0.00001, loss_test:0.01368, lr:2.97e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.148, tt:4522.157\n",
      "Ep:150, loss:0.00001, loss_test:0.01369, lr:2.94e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.150, tt:4552.659\n",
      "Ep:151, loss:0.00001, loss_test:0.01369, lr:2.91e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.155, tt:4583.630\n",
      "Ep:152, loss:0.00001, loss_test:0.01370, lr:2.88e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.168, tt:4615.660\n",
      "Ep:153, loss:0.00001, loss_test:0.01371, lr:2.85e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.168, tt:4645.932\n",
      "Ep:154, loss:0.00000, loss_test:0.01373, lr:2.82e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.162, tt:4675.062\n",
      "Ep:155, loss:0.00000, loss_test:0.01374, lr:2.80e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.169, tt:4706.318\n",
      "Ep:156, loss:0.00000, loss_test:0.01375, lr:2.77e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.176, tt:4737.690\n",
      "Ep:157, loss:0.00000, loss_test:0.01376, lr:2.74e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.169, tt:4766.725\n",
      "Ep:158, loss:0.00000, loss_test:0.01375, lr:2.71e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.163, tt:4795.915\n",
      "Ep:159, loss:0.00000, loss_test:0.01376, lr:2.69e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.164, tt:4826.258\n",
      "Ep:160, loss:0.00000, loss_test:0.01377, lr:2.66e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.174, tt:4857.941\n",
      "Ep:161, loss:0.00000, loss_test:0.01378, lr:2.63e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.181, tt:4889.330\n",
      "Ep:162, loss:0.00000, loss_test:0.01379, lr:2.61e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.176, tt:4918.695\n",
      "Ep:163, loss:0.00000, loss_test:0.01380, lr:2.58e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.176, tt:4948.838\n",
      "Ep:164, loss:0.00000, loss_test:0.01380, lr:2.55e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.180, tt:4979.626\n",
      "Ep:165, loss:0.00000, loss_test:0.01381, lr:2.53e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.178, tt:5009.560\n",
      "Ep:166, loss:0.00000, loss_test:0.01381, lr:2.50e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.175, tt:5039.195\n",
      "Ep:167, loss:0.00000, loss_test:0.01382, lr:2.48e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.174, tt:5069.239\n",
      "Ep:168, loss:0.00000, loss_test:0.01383, lr:2.45e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.172, tt:5099.002\n",
      "Ep:169, loss:0.00000, loss_test:0.01384, lr:2.43e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.180, tt:5130.582\n",
      "Ep:170, loss:0.00000, loss_test:0.01385, lr:2.40e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.189, tt:5162.298\n",
      "Ep:171, loss:0.00000, loss_test:0.01385, lr:2.38e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.190, tt:5192.669\n",
      "Ep:172, loss:0.00000, loss_test:0.01386, lr:2.36e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.187, tt:5222.331\n",
      "Ep:173, loss:0.00000, loss_test:0.01386, lr:2.33e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.192, tt:5253.410\n",
      "Ep:174, loss:0.00000, loss_test:0.01387, lr:2.31e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.192, tt:5283.553\n",
      "Ep:175, loss:0.00000, loss_test:0.01388, lr:2.29e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.199, tt:5315.091\n",
      "Ep:176, loss:0.00000, loss_test:0.01388, lr:2.26e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.210, tt:5347.162\n",
      "Ep:177, loss:0.00000, loss_test:0.01389, lr:2.24e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.204, tt:5376.377\n",
      "Ep:178, loss:0.00000, loss_test:0.01390, lr:2.22e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.203, tt:5406.373\n",
      "Ep:179, loss:0.00000, loss_test:0.01391, lr:2.20e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.205, tt:5436.943\n",
      "Ep:180, loss:0.00000, loss_test:0.01391, lr:2.17e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.209, tt:5467.798\n",
      "Ep:181, loss:0.00000, loss_test:0.01392, lr:2.15e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.215, tt:5499.113\n",
      "Ep:182, loss:0.00000, loss_test:0.01393, lr:2.13e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.218, tt:5529.832\n",
      "Ep:183, loss:0.00000, loss_test:0.01394, lr:2.11e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.225, tt:5561.331\n",
      "Ep:184, loss:0.00000, loss_test:0.01395, lr:2.09e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.222, tt:5591.122\n",
      "Ep:185, loss:0.00000, loss_test:0.01396, lr:2.07e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.226, tt:5621.956\n",
      "Ep:186, loss:0.00000, loss_test:0.01397, lr:2.05e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.224, tt:5651.840\n",
      "Ep:187, loss:0.00000, loss_test:0.01397, lr:2.03e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.232, tt:5683.648\n",
      "Ep:188, loss:0.00000, loss_test:0.01398, lr:2.01e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.222, tt:5711.971\n",
      "Ep:189, loss:0.00000, loss_test:0.01399, lr:1.99e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.219, tt:5741.549\n",
      "Ep:190, loss:0.00000, loss_test:0.01400, lr:1.97e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.220, tt:5772.063\n",
      "Ep:191, loss:0.00000, loss_test:0.01400, lr:1.95e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.212, tt:5800.768\n",
      "Ep:192, loss:0.00000, loss_test:0.01401, lr:1.93e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.218, tt:5831.999\n",
      "Ep:193, loss:0.00000, loss_test:0.01401, lr:1.91e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.222, tt:5863.030\n",
      "Ep:194, loss:0.00000, loss_test:0.01402, lr:1.89e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.225, tt:5893.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00000, loss_test:0.01403, lr:1.87e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.242, tt:5927.525\n",
      "Ep:196, loss:0.00000, loss_test:0.01403, lr:1.85e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.238, tt:5956.906\n",
      "Ep:197, loss:0.00000, loss_test:0.01404, lr:1.83e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.243, tt:5988.187\n",
      "Ep:198, loss:0.00000, loss_test:0.01404, lr:1.81e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.249, tt:6019.485\n",
      "Ep:199, loss:0.00000, loss_test:0.01405, lr:1.80e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.249, tt:6049.794\n",
      "Ep:200, loss:0.00000, loss_test:0.01405, lr:1.78e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.242, tt:6078.662\n",
      "Ep:201, loss:0.00000, loss_test:0.01406, lr:1.76e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.244, tt:6109.272\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13846, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.557, tt:31.557\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13725, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.500, tt:62.999\n",
      "Ep:2, loss:0.00028, loss_test:0.13531, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.493, tt:94.479\n",
      "Ep:3, loss:0.00027, loss_test:0.13245, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.404, tt:125.616\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12819, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:31.327, tt:156.637\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12197, lr:1.00e-02, fs:0.69343 (r=0.960,p=0.543),  time:31.476, tt:188.856\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11441, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:31.401, tt:219.809\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10933, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:31.377, tt:251.018\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10868, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:31.480, tt:283.316\n",
      "Ep:9, loss:0.00023, loss_test:0.10755, lr:1.00e-02, fs:0.64481 (r=0.596,p=0.702),  time:31.623, tt:316.232\n",
      "Ep:10, loss:0.00022, loss_test:0.10374, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:31.760, tt:349.363\n",
      "Ep:11, loss:0.00022, loss_test:0.10061, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:31.903, tt:382.830\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09818, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:31.933, tt:415.131\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09658, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:32.288, tt:452.037\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09591, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:32.203, tt:483.042\n",
      "Ep:15, loss:0.00019, loss_test:0.09408, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:32.155, tt:514.476\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09192, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:32.136, tt:546.318\n",
      "Ep:17, loss:0.00018, loss_test:0.09004, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:32.150, tt:578.695\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08898, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:32.075, tt:609.432\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08827, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:32.062, tt:641.243\n",
      "Ep:20, loss:0.00016, loss_test:0.08738, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:32.065, tt:673.370\n",
      "Ep:21, loss:0.00016, loss_test:0.08626, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:32.100, tt:706.189\n",
      "Ep:22, loss:0.00015, loss_test:0.08503, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:32.092, tt:738.118\n",
      "Ep:23, loss:0.00015, loss_test:0.08381, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:32.093, tt:770.233\n",
      "Ep:24, loss:0.00014, loss_test:0.08274, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:32.081, tt:802.024\n",
      "Ep:25, loss:0.00014, loss_test:0.08197, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.027, tt:832.694\n",
      "Ep:26, loss:0.00014, loss_test:0.08143, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:32.015, tt:864.393\n",
      "Ep:27, loss:0.00013, loss_test:0.08057, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:31.986, tt:895.605\n",
      "Ep:28, loss:0.00013, loss_test:0.07954, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:32.014, tt:928.404\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07886, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:31.963, tt:958.892\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07828, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:31.929, tt:989.806\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07739, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:31.930, tt:1021.746\n",
      "Ep:32, loss:0.00011, loss_test:0.07637, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.911, tt:1053.056\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07591, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:31.877, tt:1083.809\n",
      "Ep:34, loss:0.00010, loss_test:0.07540, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.974, tt:1119.084\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07465, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:31.996, tt:1151.846\n",
      "Ep:36, loss:0.00010, loss_test:0.07450, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.990, tt:1183.641\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07368, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.962, tt:1214.571\n",
      "Ep:38, loss:0.00009, loss_test:0.07296, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:31.944, tt:1245.808\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07309, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.965, tt:1278.595\n",
      "Ep:40, loss:0.00009, loss_test:0.07190, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.950, tt:1309.931\n",
      "Ep:41, loss:0.00008, loss_test:0.07104, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:31.951, tt:1341.934\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07102, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.931, tt:1373.028\n",
      "Ep:43, loss:0.00008, loss_test:0.07060, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.937, tt:1405.235\n",
      "Ep:44, loss:0.00008, loss_test:0.06985, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:31.951, tt:1437.778\n",
      "Ep:45, loss:0.00007, loss_test:0.06941, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.884, tt:1466.677\n",
      "Ep:46, loss:0.00007, loss_test:0.06902, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.814, tt:1495.278\n",
      "Ep:47, loss:0.00007, loss_test:0.06859, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:31.745, tt:1523.782\n",
      "Ep:48, loss:0.00007, loss_test:0.06813, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.698, tt:1553.200\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.06745, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:31.663, tt:1583.136\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.06708, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:31.566, tt:1609.879\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.06713, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.489, tt:1637.441\n",
      "Ep:52, loss:0.00006, loss_test:0.06648, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.460, tt:1667.392\n",
      "Ep:53, loss:0.00006, loss_test:0.06587, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:31.429, tt:1697.171\n",
      "Ep:54, loss:0.00006, loss_test:0.06586, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.414, tt:1727.771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00006, loss_test:0.06545, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.414, tt:1759.182\n",
      "Ep:56, loss:0.00006, loss_test:0.06495, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.438, tt:1791.964\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.06461, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.440, tt:1823.500\n",
      "Ep:58, loss:0.00005, loss_test:0.06424, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.454, tt:1855.764\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00005, loss_test:0.06392, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.477, tt:1888.635\n",
      "Ep:60, loss:0.00005, loss_test:0.06369, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.487, tt:1920.706\n",
      "Ep:61, loss:0.00005, loss_test:0.06330, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.530, tt:1954.869\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00005, loss_test:0.06317, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.547, tt:1987.447\n",
      "Ep:63, loss:0.00005, loss_test:0.06296, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.555, tt:2019.533\n",
      "Ep:64, loss:0.00005, loss_test:0.06244, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.584, tt:2052.941\n",
      "Ep:65, loss:0.00004, loss_test:0.06228, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.584, tt:2084.519\n",
      "Ep:66, loss:0.00004, loss_test:0.06233, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.568, tt:2115.070\n",
      "Ep:67, loss:0.00004, loss_test:0.06162, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.570, tt:2146.770\n",
      "Ep:68, loss:0.00004, loss_test:0.06128, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:31.585, tt:2179.368\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.06146, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.593, tt:2211.515\n",
      "Ep:70, loss:0.00004, loss_test:0.06118, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.604, tt:2243.885\n",
      "Ep:71, loss:0.00004, loss_test:0.06102, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.610, tt:2275.932\n",
      "Ep:72, loss:0.00004, loss_test:0.06091, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.625, tt:2308.612\n",
      "Ep:73, loss:0.00004, loss_test:0.06062, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.622, tt:2340.030\n",
      "Ep:74, loss:0.00004, loss_test:0.06059, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.655, tt:2374.101\n",
      "Ep:75, loss:0.00004, loss_test:0.06044, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.663, tt:2406.368\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00003, loss_test:0.06001, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.703, tt:2441.131\n",
      "Ep:77, loss:0.00003, loss_test:0.06019, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.722, tt:2474.346\n",
      "Ep:78, loss:0.00003, loss_test:0.06003, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.713, tt:2505.303\n",
      "Ep:79, loss:0.00003, loss_test:0.05945, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:31.723, tt:2537.822\n",
      "Ep:80, loss:0.00003, loss_test:0.05965, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.725, tt:2569.757\n",
      "Ep:81, loss:0.00003, loss_test:0.05968, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.701, tt:2599.506\n",
      "Ep:82, loss:0.00003, loss_test:0.05895, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.705, tt:2631.532\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00003, loss_test:0.05887, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.719, tt:2664.418\n",
      "Ep:84, loss:0.00003, loss_test:0.05895, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.710, tt:2695.321\n",
      "Ep:85, loss:0.00003, loss_test:0.05875, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.709, tt:2726.947\n",
      "Ep:86, loss:0.00003, loss_test:0.05829, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.705, tt:2758.301\n",
      "Ep:87, loss:0.00003, loss_test:0.05811, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.709, tt:2790.380\n",
      "Ep:88, loss:0.00003, loss_test:0.05810, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.713, tt:2822.427\n",
      "Ep:89, loss:0.00003, loss_test:0.05786, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.717, tt:2854.506\n",
      "Ep:90, loss:0.00003, loss_test:0.05773, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.736, tt:2887.938\n",
      "Ep:91, loss:0.00003, loss_test:0.05761, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.733, tt:2919.430\n",
      "Ep:92, loss:0.00003, loss_test:0.05726, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.736, tt:2951.481\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.05748, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.720, tt:2981.707\n",
      "Ep:94, loss:0.00002, loss_test:0.05745, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.706, tt:3012.086\n",
      "Ep:95, loss:0.00002, loss_test:0.05713, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.706, tt:3043.817\n",
      "Ep:96, loss:0.00002, loss_test:0.05717, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.716, tt:3076.452\n",
      "Ep:97, loss:0.00002, loss_test:0.05683, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.744, tt:3110.910\n",
      "Ep:98, loss:0.00002, loss_test:0.05675, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.768, tt:3144.998\n",
      "Ep:99, loss:0.00002, loss_test:0.05676, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.772, tt:3177.177\n",
      "Ep:100, loss:0.00002, loss_test:0.05636, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.781, tt:3209.916\n",
      "Ep:101, loss:0.00002, loss_test:0.05646, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.766, tt:3240.091\n",
      "Ep:102, loss:0.00002, loss_test:0.05619, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.767, tt:3271.961\n",
      "Ep:103, loss:0.00002, loss_test:0.05611, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.772, tt:3304.335\n",
      "Ep:104, loss:0.00002, loss_test:0.05592, lr:9.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.774, tt:3336.282\n",
      "Ep:105, loss:0.00002, loss_test:0.05547, lr:9.80e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.758, tt:3366.321\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.05581, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.768, tt:3399.222\n",
      "Ep:107, loss:0.00002, loss_test:0.05566, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.762, tt:3430.278\n",
      "Ep:108, loss:0.00002, loss_test:0.05555, lr:9.80e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.767, tt:3462.561\n",
      "Ep:109, loss:0.00002, loss_test:0.05553, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:31.759, tt:3493.476\n",
      "Ep:110, loss:0.00002, loss_test:0.05511, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.756, tt:3524.903\n",
      "Ep:111, loss:0.00002, loss_test:0.05522, lr:9.80e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.744, tt:3555.358\n",
      "Ep:112, loss:0.00002, loss_test:0.05525, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.744, tt:3587.112\n",
      "Ep:113, loss:0.00002, loss_test:0.05501, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:31.747, tt:3619.215\n",
      "Ep:114, loss:0.00002, loss_test:0.05493, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.746, tt:3650.781\n",
      "Ep:115, loss:0.00002, loss_test:0.05502, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.755, tt:3683.633\n",
      "Ep:116, loss:0.00002, loss_test:0.05473, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:31.759, tt:3715.828\n",
      "Ep:117, loss:0.00002, loss_test:0.05480, lr:9.70e-03, fs:0.89840 (r=0.848,p=0.955),  time:31.765, tt:3748.256\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00002, loss_test:0.05469, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.769, tt:3780.541\n",
      "Ep:119, loss:0.00002, loss_test:0.05455, lr:9.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.780, tt:3813.614\n",
      "Ep:120, loss:0.00002, loss_test:0.05433, lr:9.70e-03, fs:0.89840 (r=0.848,p=0.955),  time:31.778, tt:3845.148\n",
      "Ep:121, loss:0.00002, loss_test:0.05450, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.776, tt:3876.611\n",
      "Ep:122, loss:0.00002, loss_test:0.05411, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.787, tt:3909.815\n",
      "Ep:123, loss:0.00001, loss_test:0.05408, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.784, tt:3941.258\n",
      "Ep:124, loss:0.00001, loss_test:0.05400, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.788, tt:3973.514\n",
      "Ep:125, loss:0.00001, loss_test:0.05386, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.783, tt:4004.661\n",
      "Ep:126, loss:0.00001, loss_test:0.05394, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.787, tt:4036.912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00001, loss_test:0.05391, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.789, tt:4068.958\n",
      "Ep:128, loss:0.00001, loss_test:0.05385, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.796, tt:4101.631\n",
      "Ep:129, loss:0.00001, loss_test:0.05397, lr:9.61e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.797, tt:4133.554\n",
      "Ep:130, loss:0.00001, loss_test:0.05354, lr:9.51e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.793, tt:4164.853\n",
      "Ep:131, loss:0.00001, loss_test:0.05379, lr:9.41e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.785, tt:4195.684\n",
      "Ep:132, loss:0.00001, loss_test:0.05362, lr:9.32e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.771, tt:4225.495\n",
      "Ep:133, loss:0.00001, loss_test:0.05321, lr:9.23e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.788, tt:4259.553\n",
      "Ep:134, loss:0.00001, loss_test:0.05355, lr:9.14e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.776, tt:4289.729\n",
      "Ep:135, loss:0.00001, loss_test:0.05333, lr:9.04e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.764, tt:4319.854\n",
      "Ep:136, loss:0.00001, loss_test:0.05319, lr:8.95e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.757, tt:4350.642\n",
      "Ep:137, loss:0.00001, loss_test:0.05330, lr:8.86e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.758, tt:4382.665\n",
      "Ep:138, loss:0.00001, loss_test:0.05324, lr:8.78e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.756, tt:4414.028\n",
      "Ep:139, loss:0.00001, loss_test:0.05332, lr:8.69e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.769, tt:4447.723\n",
      "Ep:140, loss:0.00001, loss_test:0.05335, lr:8.60e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.774, tt:4480.194\n",
      "Ep:141, loss:0.00001, loss_test:0.05278, lr:8.51e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.762, tt:4510.246\n",
      "Ep:142, loss:0.00001, loss_test:0.05299, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.762, tt:4541.948\n",
      "Ep:143, loss:0.00001, loss_test:0.05333, lr:8.35e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.766, tt:4574.324\n",
      "Ep:144, loss:0.00001, loss_test:0.05302, lr:8.26e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.762, tt:4605.554\n",
      "Ep:145, loss:0.00001, loss_test:0.05281, lr:8.18e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.766, tt:4637.777\n",
      "Ep:146, loss:0.00001, loss_test:0.05318, lr:8.10e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.760, tt:4668.749\n",
      "Ep:147, loss:0.00001, loss_test:0.05305, lr:8.02e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.757, tt:4700.052\n",
      "Ep:148, loss:0.00001, loss_test:0.05246, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.756, tt:4731.682\n",
      "Ep:149, loss:0.00001, loss_test:0.05294, lr:7.86e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.759, tt:4763.797\n",
      "Ep:150, loss:0.00001, loss_test:0.05286, lr:7.78e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.765, tt:4796.444\n",
      "Ep:151, loss:0.00001, loss_test:0.05264, lr:7.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.762, tt:4827.802\n",
      "Ep:152, loss:0.00001, loss_test:0.05282, lr:7.62e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.753, tt:4858.217\n",
      "Ep:153, loss:0.00001, loss_test:0.05251, lr:7.55e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.753, tt:4889.932\n",
      "Ep:154, loss:0.00001, loss_test:0.05229, lr:7.47e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.750, tt:4921.300\n",
      "Ep:155, loss:0.00001, loss_test:0.05254, lr:7.40e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.741, tt:4951.587\n",
      "Ep:156, loss:0.00001, loss_test:0.05255, lr:7.32e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.751, tt:4984.919\n",
      "Ep:157, loss:0.00001, loss_test:0.05244, lr:7.25e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.767, tt:5019.172\n",
      "Ep:158, loss:0.00001, loss_test:0.05255, lr:7.18e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.788, tt:5054.274\n",
      "Ep:159, loss:0.00001, loss_test:0.05240, lr:7.11e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.791, tt:5086.510\n",
      "Ep:160, loss:0.00001, loss_test:0.05240, lr:7.03e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.793, tt:5118.607\n",
      "Ep:161, loss:0.00001, loss_test:0.05240, lr:6.96e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.796, tt:5151.010\n",
      "Ep:162, loss:0.00001, loss_test:0.05233, lr:6.89e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.797, tt:5182.962\n",
      "Ep:163, loss:0.00001, loss_test:0.05228, lr:6.83e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.795, tt:5214.460\n",
      "Ep:164, loss:0.00001, loss_test:0.05225, lr:6.76e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.801, tt:5247.199\n",
      "Ep:165, loss:0.00001, loss_test:0.05215, lr:6.69e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.805, tt:5279.653\n",
      "Ep:166, loss:0.00001, loss_test:0.05216, lr:6.62e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.798, tt:5310.281\n",
      "Ep:167, loss:0.00001, loss_test:0.05234, lr:6.56e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.799, tt:5342.284\n",
      "Ep:168, loss:0.00001, loss_test:0.05216, lr:6.49e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.805, tt:5375.000\n",
      "Ep:169, loss:0.00001, loss_test:0.05217, lr:6.43e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.810, tt:5407.781\n",
      "Ep:170, loss:0.00001, loss_test:0.05243, lr:6.36e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.821, tt:5441.360\n",
      "Ep:171, loss:0.00001, loss_test:0.05238, lr:6.30e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.850, tt:5478.196\n",
      "Ep:172, loss:0.00001, loss_test:0.05224, lr:6.24e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.849, tt:5509.899\n",
      "Ep:173, loss:0.00001, loss_test:0.05207, lr:6.17e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.852, tt:5542.266\n",
      "Ep:174, loss:0.00001, loss_test:0.05246, lr:6.11e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.841, tt:5572.157\n",
      "Ep:175, loss:0.00001, loss_test:0.05236, lr:6.05e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.827, tt:5601.617\n",
      "Ep:176, loss:0.00001, loss_test:0.05217, lr:5.99e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.825, tt:5633.092\n",
      "Ep:177, loss:0.00001, loss_test:0.05217, lr:5.93e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.829, tt:5665.535\n",
      "Ep:178, loss:0.00001, loss_test:0.05219, lr:5.87e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.832, tt:5697.866\n",
      "Ep:179, loss:0.00001, loss_test:0.05231, lr:5.81e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.839, tt:5731.081\n",
      "Ep:180, loss:0.00001, loss_test:0.05225, lr:5.75e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.848, tt:5764.409\n",
      "Ep:181, loss:0.00001, loss_test:0.05202, lr:5.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.854, tt:5797.504\n",
      "Ep:182, loss:0.00001, loss_test:0.05218, lr:5.64e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.856, tt:5829.597\n",
      "Ep:183, loss:0.00001, loss_test:0.05218, lr:5.58e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.857, tt:5861.655\n",
      "Ep:184, loss:0.00001, loss_test:0.05197, lr:5.53e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.865, tt:5895.018\n",
      "Ep:185, loss:0.00001, loss_test:0.05225, lr:5.47e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.869, tt:5927.679\n",
      "Ep:186, loss:0.00001, loss_test:0.05241, lr:5.42e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.868, tt:5959.290\n",
      "Ep:187, loss:0.00001, loss_test:0.05211, lr:5.36e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.872, tt:5992.005\n",
      "Ep:188, loss:0.00001, loss_test:0.05201, lr:5.31e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.866, tt:6022.764\n",
      "Ep:189, loss:0.00001, loss_test:0.05235, lr:5.26e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.873, tt:6055.819\n",
      "Ep:190, loss:0.00001, loss_test:0.05248, lr:5.20e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.872, tt:6087.474\n",
      "Ep:191, loss:0.00001, loss_test:0.05227, lr:5.15e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.871, tt:6119.141\n",
      "Ep:192, loss:0.00001, loss_test:0.05216, lr:5.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.868, tt:6150.600\n",
      "Ep:193, loss:0.00001, loss_test:0.05212, lr:5.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.867, tt:6182.132\n",
      "Ep:194, loss:0.00001, loss_test:0.05203, lr:5.00e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.855, tt:6211.646\n",
      "Ep:195, loss:0.00001, loss_test:0.05207, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.862, tt:6244.897\n",
      "Ep:196, loss:0.00001, loss_test:0.05213, lr:4.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.867, tt:6277.764\n",
      "Ep:197, loss:0.00001, loss_test:0.05199, lr:4.85e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.863, tt:6308.887\n",
      "Ep:198, loss:0.00001, loss_test:0.05194, lr:4.80e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.865, tt:6341.191\n",
      "Ep:199, loss:0.00001, loss_test:0.05207, lr:4.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.863, tt:6372.604\n",
      "Ep:200, loss:0.00001, loss_test:0.05199, lr:4.71e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.866, tt:6405.077\n",
      "Ep:201, loss:0.00001, loss_test:0.05196, lr:4.66e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.859, tt:6435.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02045, lr:6.00e-02, fs:0.59821 (r=0.677,p=0.536),  time:24.663, tt:24.663\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02062, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:26.194, tt:52.388\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02209, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.415, tt:79.246\n",
      "Ep:3, loss:0.00005, loss_test:0.02234, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.713, tt:106.853\n",
      "Ep:4, loss:0.00005, loss_test:0.02167, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.399, tt:131.993\n",
      "Ep:5, loss:0.00004, loss_test:0.02048, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:26.261, tt:157.567\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01907, lr:6.00e-02, fs:0.68310 (r=0.980,p=0.524),  time:25.940, tt:181.581\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01799, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:26.045, tt:208.363\n",
      "Ep:8, loss:0.00004, loss_test:0.01773, lr:6.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:26.209, tt:235.879\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01778, lr:6.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:26.128, tt:261.284\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01750, lr:6.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:26.121, tt:287.332\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01689, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:26.181, tt:314.171\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01641, lr:6.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:26.134, tt:339.737\n",
      "Ep:13, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:26.019, tt:364.260\n",
      "Ep:14, loss:0.00003, loss_test:0.01606, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:25.911, tt:388.664\n",
      "Ep:15, loss:0.00003, loss_test:0.01584, lr:6.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:25.782, tt:412.516\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01560, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:25.583, tt:434.913\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01538, lr:6.00e-02, fs:0.75314 (r=0.909,p=0.643),  time:25.446, tt:458.030\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01524, lr:6.00e-02, fs:0.76596 (r=0.909,p=0.662),  time:25.274, tt:480.199\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01512, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:25.083, tt:501.659\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:24.904, tt:522.989\n",
      "Ep:21, loss:0.00003, loss_test:0.01486, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:24.691, tt:543.194\n",
      "Ep:22, loss:0.00003, loss_test:0.01474, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:24.491, tt:563.293\n",
      "Ep:23, loss:0.00003, loss_test:0.01462, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:24.268, tt:582.432\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01447, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:24.137, tt:603.428\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01431, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:24.081, tt:626.100\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01416, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:24.086, tt:650.327\n",
      "Ep:27, loss:0.00003, loss_test:0.01402, lr:6.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:24.077, tt:674.158\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01389, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:24.123, tt:699.555\n",
      "Ep:29, loss:0.00003, loss_test:0.01376, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:24.146, tt:724.382\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:24.210, tt:750.519\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:24.229, tt:775.338\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:24.337, tt:803.124\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:24.423, tt:830.397\n",
      "Ep:34, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:24.498, tt:857.416\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01298, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:24.522, tt:882.806\n",
      "Ep:36, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:24.560, tt:908.718\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:24.615, tt:935.352\n",
      "Ep:38, loss:0.00002, loss_test:0.01258, lr:6.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:24.670, tt:962.143\n",
      "Ep:39, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:24.687, tt:987.479\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:24.735, tt:1014.120\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01229, lr:6.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:24.792, tt:1041.248\n",
      "Ep:42, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:24.807, tt:1066.694\n",
      "Ep:43, loss:0.00002, loss_test:0.01209, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:24.848, tt:1093.293\n",
      "Ep:44, loss:0.00002, loss_test:0.01199, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:24.898, tt:1120.400\n",
      "Ep:45, loss:0.00002, loss_test:0.01188, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:24.949, tt:1147.651\n",
      "Ep:46, loss:0.00002, loss_test:0.01178, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:24.965, tt:1173.378\n",
      "Ep:47, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:24.984, tt:1199.224\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01163, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:25.024, tt:1226.163\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01156, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:25.078, tt:1253.901\n",
      "Ep:50, loss:0.00002, loss_test:0.01149, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:25.097, tt:1279.925\n",
      "Ep:51, loss:0.00002, loss_test:0.01142, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:25.121, tt:1306.316\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01135, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:25.152, tt:1333.058\n",
      "Ep:53, loss:0.00002, loss_test:0.01130, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:25.157, tt:1358.475\n",
      "Ep:54, loss:0.00002, loss_test:0.01123, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:25.156, tt:1383.599\n",
      "Ep:55, loss:0.00002, loss_test:0.01117, lr:6.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:25.165, tt:1409.257\n",
      "Ep:56, loss:0.00001, loss_test:0.01111, lr:6.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:25.187, tt:1435.643\n",
      "Ep:57, loss:0.00001, loss_test:0.01104, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:25.218, tt:1462.627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01100, lr:6.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:25.208, tt:1487.266\n",
      "Ep:59, loss:0.00001, loss_test:0.01095, lr:6.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:25.227, tt:1513.615\n",
      "Ep:60, loss:0.00001, loss_test:0.01092, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:25.263, tt:1541.044\n",
      "Ep:61, loss:0.00001, loss_test:0.01088, lr:6.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:25.283, tt:1567.551\n",
      "Ep:62, loss:0.00001, loss_test:0.01085, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:25.333, tt:1596.002\n",
      "Ep:63, loss:0.00001, loss_test:0.01083, lr:5.94e-02, fs:0.83495 (r=0.869,p=0.804),  time:25.356, tt:1622.792\n",
      "Ep:64, loss:0.00001, loss_test:0.01080, lr:5.88e-02, fs:0.84058 (r=0.879,p=0.806),  time:25.392, tt:1650.507\n",
      "Ep:65, loss:0.00001, loss_test:0.01078, lr:5.82e-02, fs:0.84058 (r=0.879,p=0.806),  time:25.408, tt:1676.918\n",
      "Ep:66, loss:0.00001, loss_test:0.01076, lr:5.76e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.419, tt:1703.060\n",
      "Ep:67, loss:0.00001, loss_test:0.01072, lr:5.71e-02, fs:0.84058 (r=0.879,p=0.806),  time:25.432, tt:1729.403\n",
      "Ep:68, loss:0.00001, loss_test:0.01069, lr:5.65e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.459, tt:1756.699\n",
      "Ep:69, loss:0.00001, loss_test:0.01068, lr:5.59e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.473, tt:1783.087\n",
      "Ep:70, loss:0.00001, loss_test:0.01067, lr:5.54e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.496, tt:1810.198\n",
      "Ep:71, loss:0.00001, loss_test:0.01063, lr:5.48e-02, fs:0.84878 (r=0.879,p=0.821),  time:25.512, tt:1836.866\n",
      "Ep:72, loss:0.00001, loss_test:0.01061, lr:5.43e-02, fs:0.85294 (r=0.879,p=0.829),  time:25.521, tt:1863.005\n",
      "Ep:73, loss:0.00001, loss_test:0.01058, lr:5.37e-02, fs:0.85294 (r=0.879,p=0.829),  time:25.516, tt:1888.220\n",
      "Ep:74, loss:0.00001, loss_test:0.01056, lr:5.32e-02, fs:0.85294 (r=0.879,p=0.829),  time:25.534, tt:1915.044\n",
      "Ep:75, loss:0.00001, loss_test:0.01055, lr:5.27e-02, fs:0.85294 (r=0.879,p=0.829),  time:25.565, tt:1942.932\n",
      "Ep:76, loss:0.00001, loss_test:0.01056, lr:5.21e-02, fs:0.86139 (r=0.879,p=0.845),  time:25.578, tt:1969.527\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01057, lr:5.21e-02, fs:0.86567 (r=0.879,p=0.853),  time:25.588, tt:1995.829\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01057, lr:5.21e-02, fs:0.86567 (r=0.879,p=0.853),  time:25.597, tt:2022.201\n",
      "Ep:79, loss:0.00001, loss_test:0.01056, lr:5.21e-02, fs:0.87000 (r=0.879,p=0.861),  time:25.617, tt:2049.376\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01055, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.655, tt:2078.075\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01054, lr:5.21e-02, fs:0.87000 (r=0.879,p=0.861),  time:25.691, tt:2106.658\n",
      "Ep:82, loss:0.00001, loss_test:0.01054, lr:5.21e-02, fs:0.87000 (r=0.879,p=0.861),  time:25.679, tt:2131.365\n",
      "Ep:83, loss:0.00001, loss_test:0.01053, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.697, tt:2158.540\n",
      "Ep:84, loss:0.00001, loss_test:0.01053, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.722, tt:2186.373\n",
      "Ep:85, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.736, tt:2213.255\n",
      "Ep:86, loss:0.00001, loss_test:0.01051, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.736, tt:2239.050\n",
      "Ep:87, loss:0.00001, loss_test:0.01050, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.769, tt:2267.672\n",
      "Ep:88, loss:0.00001, loss_test:0.01049, lr:5.21e-02, fs:0.87437 (r=0.879,p=0.870),  time:25.780, tt:2294.403\n",
      "Ep:89, loss:0.00001, loss_test:0.01050, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.795, tt:2321.542\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01050, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.813, tt:2348.947\n",
      "Ep:91, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.821, tt:2375.521\n",
      "Ep:92, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.821, tt:2401.358\n",
      "Ep:93, loss:0.00001, loss_test:0.01051, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.840, tt:2428.985\n",
      "Ep:94, loss:0.00001, loss_test:0.01051, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.862, tt:2456.916\n",
      "Ep:95, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.868, tt:2483.358\n",
      "Ep:96, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.872, tt:2509.609\n",
      "Ep:97, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.890, tt:2537.259\n",
      "Ep:98, loss:0.00001, loss_test:0.01051, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.893, tt:2563.402\n",
      "Ep:99, loss:0.00001, loss_test:0.01052, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.873, tt:2587.338\n",
      "Ep:100, loss:0.00001, loss_test:0.01053, lr:5.21e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.874, tt:2613.241\n",
      "Ep:101, loss:0.00001, loss_test:0.01055, lr:5.16e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.893, tt:2641.117\n",
      "Ep:102, loss:0.00001, loss_test:0.01055, lr:5.11e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.914, tt:2669.176\n",
      "Ep:103, loss:0.00001, loss_test:0.01054, lr:5.06e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.909, tt:2694.543\n",
      "Ep:104, loss:0.00001, loss_test:0.01054, lr:5.01e-02, fs:0.87879 (r=0.879,p=0.879),  time:25.910, tt:2720.570\n",
      "Ep:105, loss:0.00001, loss_test:0.01054, lr:4.96e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.932, tt:2748.749\n",
      "Ep:106, loss:0.00001, loss_test:0.01054, lr:4.91e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.957, tt:2777.363\n",
      "Ep:107, loss:0.00001, loss_test:0.01054, lr:4.86e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.957, tt:2803.327\n",
      "Ep:108, loss:0.00001, loss_test:0.01055, lr:4.81e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.942, tt:2827.662\n",
      "Ep:109, loss:0.00001, loss_test:0.01055, lr:4.76e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.945, tt:2853.910\n",
      "Ep:110, loss:0.00001, loss_test:0.01056, lr:4.71e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.961, tt:2881.672\n",
      "Ep:111, loss:0.00001, loss_test:0.01056, lr:4.67e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.966, tt:2908.207\n",
      "Ep:112, loss:0.00001, loss_test:0.01057, lr:4.62e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.977, tt:2935.422\n",
      "Ep:113, loss:0.00001, loss_test:0.01058, lr:4.57e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.985, tt:2962.297\n",
      "Ep:114, loss:0.00001, loss_test:0.01058, lr:4.53e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.007, tt:2990.755\n",
      "Ep:115, loss:0.00001, loss_test:0.01060, lr:4.48e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.008, tt:3016.907\n",
      "Ep:116, loss:0.00001, loss_test:0.01060, lr:4.44e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.002, tt:3042.289\n",
      "Ep:117, loss:0.00001, loss_test:0.01061, lr:4.39e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.003, tt:3068.364\n",
      "Ep:118, loss:0.00001, loss_test:0.01061, lr:4.35e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.020, tt:3096.393\n",
      "Ep:119, loss:0.00001, loss_test:0.01062, lr:4.31e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.030, tt:3123.552\n",
      "Ep:120, loss:0.00001, loss_test:0.01062, lr:4.26e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.029, tt:3149.536\n",
      "Ep:121, loss:0.00001, loss_test:0.01062, lr:4.22e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.023, tt:3174.782\n",
      "Ep:122, loss:0.00001, loss_test:0.01060, lr:4.18e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.034, tt:3202.175\n",
      "Ep:123, loss:0.00001, loss_test:0.01061, lr:4.14e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.040, tt:3228.991\n",
      "Ep:124, loss:0.00001, loss_test:0.01064, lr:4.10e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.044, tt:3255.547\n",
      "Ep:125, loss:0.00001, loss_test:0.01064, lr:4.05e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.043, tt:3281.414\n",
      "Ep:126, loss:0.00001, loss_test:0.01064, lr:4.01e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.055, tt:3308.945\n",
      "Ep:127, loss:0.00001, loss_test:0.01063, lr:3.97e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.065, tt:3336.284\n",
      "Ep:128, loss:0.00001, loss_test:0.01063, lr:3.93e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.066, tt:3362.496\n",
      "Ep:129, loss:0.00001, loss_test:0.01064, lr:3.89e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.056, tt:3387.292\n",
      "Ep:130, loss:0.00001, loss_test:0.01064, lr:3.86e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.064, tt:3414.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.01063, lr:3.82e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.076, tt:3442.095\n",
      "Ep:132, loss:0.00001, loss_test:0.01064, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.080, tt:3468.686\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00001, loss_test:0.01066, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.081, tt:3494.859\n",
      "Ep:134, loss:0.00001, loss_test:0.01067, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.074, tt:3519.984\n",
      "Ep:135, loss:0.00001, loss_test:0.01067, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.085, tt:3547.552\n",
      "Ep:136, loss:0.00001, loss_test:0.01066, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.102, tt:3576.011\n",
      "Ep:137, loss:0.00001, loss_test:0.01065, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.132, tt:3606.266\n",
      "Ep:138, loss:0.00001, loss_test:0.01066, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.128, tt:3631.838\n",
      "Ep:139, loss:0.00001, loss_test:0.01066, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.129, tt:3658.043\n",
      "Ep:140, loss:0.00001, loss_test:0.01067, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.143, tt:3686.109\n",
      "Ep:141, loss:0.00001, loss_test:0.01067, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.146, tt:3712.788\n",
      "Ep:142, loss:0.00001, loss_test:0.01068, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.148, tt:3739.187\n",
      "Ep:143, loss:0.00001, loss_test:0.01067, lr:3.78e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.148, tt:3765.287\n",
      "Ep:144, loss:0.00001, loss_test:0.01067, lr:3.74e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.145, tt:3791.027\n",
      "Ep:145, loss:0.00001, loss_test:0.01069, lr:3.70e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.151, tt:3818.044\n",
      "Ep:146, loss:0.00001, loss_test:0.01068, lr:3.67e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.155, tt:3844.785\n",
      "Ep:147, loss:0.00001, loss_test:0.01068, lr:3.63e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.151, tt:3870.375\n",
      "Ep:148, loss:0.00001, loss_test:0.01068, lr:3.59e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.146, tt:3895.765\n",
      "Ep:149, loss:0.00000, loss_test:0.01069, lr:3.56e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.160, tt:3924.021\n",
      "Ep:150, loss:0.00000, loss_test:0.01071, lr:3.52e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.162, tt:3950.484\n",
      "Ep:151, loss:0.00000, loss_test:0.01071, lr:3.49e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.157, tt:3975.903\n",
      "Ep:152, loss:0.00000, loss_test:0.01071, lr:3.45e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.156, tt:4001.894\n",
      "Ep:153, loss:0.00000, loss_test:0.01072, lr:3.42e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.160, tt:4028.621\n",
      "Ep:154, loss:0.00000, loss_test:0.01073, lr:3.38e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.167, tt:4055.896\n",
      "Ep:155, loss:0.00000, loss_test:0.01072, lr:3.35e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.171, tt:4082.724\n",
      "Ep:156, loss:0.00000, loss_test:0.01072, lr:3.32e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.172, tt:4109.030\n",
      "Ep:157, loss:0.00000, loss_test:0.01073, lr:3.28e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.181, tt:4136.661\n",
      "Ep:158, loss:0.00000, loss_test:0.01074, lr:3.25e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.182, tt:4162.864\n",
      "Ep:159, loss:0.00000, loss_test:0.01075, lr:3.22e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.171, tt:4187.391\n",
      "Ep:160, loss:0.00000, loss_test:0.01076, lr:3.19e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.172, tt:4213.671\n",
      "Ep:161, loss:0.00000, loss_test:0.01076, lr:3.15e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.174, tt:4240.175\n",
      "Ep:162, loss:0.00000, loss_test:0.01077, lr:3.12e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.197, tt:4270.158\n",
      "Ep:163, loss:0.00000, loss_test:0.01077, lr:3.09e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.189, tt:4294.963\n",
      "Ep:164, loss:0.00000, loss_test:0.01077, lr:3.06e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.186, tt:4320.753\n",
      "Ep:165, loss:0.00000, loss_test:0.01078, lr:3.03e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.197, tt:4348.728\n",
      "Ep:166, loss:0.00000, loss_test:0.01079, lr:3.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.206, tt:4376.454\n",
      "Ep:167, loss:0.00000, loss_test:0.01079, lr:2.97e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.212, tt:4403.621\n",
      "Ep:168, loss:0.00000, loss_test:0.01080, lr:2.94e-02, fs:0.88205 (r=0.869,p=0.896),  time:26.205, tt:4428.613\n",
      "Ep:169, loss:0.00000, loss_test:0.01081, lr:2.91e-02, fs:0.88660 (r=0.869,p=0.905),  time:26.210, tt:4455.711\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00000, loss_test:0.01081, lr:2.91e-02, fs:0.88660 (r=0.869,p=0.905),  time:26.218, tt:4483.294\n",
      "Ep:171, loss:0.00000, loss_test:0.01082, lr:2.91e-02, fs:0.88660 (r=0.869,p=0.905),  time:26.208, tt:4507.797\n",
      "Ep:172, loss:0.00000, loss_test:0.01083, lr:2.91e-02, fs:0.88660 (r=0.869,p=0.905),  time:26.215, tt:4535.237\n",
      "Ep:173, loss:0.00000, loss_test:0.01084, lr:2.91e-02, fs:0.88660 (r=0.869,p=0.905),  time:26.214, tt:4561.292\n",
      "Ep:174, loss:0.00000, loss_test:0.01084, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.220, tt:4588.522\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00000, loss_test:0.01084, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.219, tt:4614.629\n",
      "Ep:176, loss:0.00000, loss_test:0.01084, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.215, tt:4640.061\n",
      "Ep:177, loss:0.00000, loss_test:0.01085, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.212, tt:4665.696\n",
      "Ep:178, loss:0.00000, loss_test:0.01087, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.232, tt:4695.587\n",
      "Ep:179, loss:0.00000, loss_test:0.01087, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.230, tt:4721.354\n",
      "Ep:180, loss:0.00000, loss_test:0.01087, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.217, tt:4745.348\n",
      "Ep:181, loss:0.00000, loss_test:0.01087, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.225, tt:4773.030\n",
      "Ep:182, loss:0.00000, loss_test:0.01088, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.228, tt:4799.734\n",
      "Ep:183, loss:0.00000, loss_test:0.01088, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.229, tt:4826.065\n",
      "Ep:184, loss:0.00000, loss_test:0.01089, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.231, tt:4852.713\n",
      "Ep:185, loss:0.00000, loss_test:0.01089, lr:2.91e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.234, tt:4879.496\n",
      "Ep:186, loss:0.00000, loss_test:0.01090, lr:2.88e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.241, tt:4907.136\n",
      "Ep:187, loss:0.00000, loss_test:0.01091, lr:2.85e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.247, tt:4934.398\n",
      "Ep:188, loss:0.00000, loss_test:0.01091, lr:2.82e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.247, tt:4960.621\n",
      "Ep:189, loss:0.00000, loss_test:0.01092, lr:2.80e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.245, tt:4986.584\n",
      "Ep:190, loss:0.00000, loss_test:0.01092, lr:2.77e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.252, tt:5014.088\n",
      "Ep:191, loss:0.00000, loss_test:0.01092, lr:2.74e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.263, tt:5042.546\n",
      "Ep:192, loss:0.00000, loss_test:0.01093, lr:2.71e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.269, tt:5069.866\n",
      "Ep:193, loss:0.00000, loss_test:0.01094, lr:2.69e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.266, tt:5095.689\n",
      "Ep:194, loss:0.00000, loss_test:0.01095, lr:2.66e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.264, tt:5121.530\n",
      "Ep:195, loss:0.00000, loss_test:0.01095, lr:2.63e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.267, tt:5148.300\n",
      "Ep:196, loss:0.00000, loss_test:0.01095, lr:2.61e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.272, tt:5175.675\n",
      "Ep:197, loss:0.00000, loss_test:0.01095, lr:2.58e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.269, tt:5201.184\n",
      "Ep:198, loss:0.00000, loss_test:0.01096, lr:2.55e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.270, tt:5227.667\n",
      "Ep:199, loss:0.00000, loss_test:0.01097, lr:2.53e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.274, tt:5254.758\n",
      "Ep:200, loss:0.00000, loss_test:0.01097, lr:2.50e-02, fs:0.89119 (r=0.869,p=0.915),  time:26.278, tt:5281.920\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13608, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:27.851, tt:27.851\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13364, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:26.684, tt:53.367\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12914, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:26.474, tt:79.422\n",
      "Ep:3, loss:0.00026, loss_test:0.12191, lr:1.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:26.779, tt:107.117\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11319, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:27.154, tt:135.768\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10853, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:27.236, tt:163.419\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10834, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:26.985, tt:188.898\n",
      "Ep:7, loss:0.00023, loss_test:0.10559, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:26.763, tt:214.100\n",
      "Ep:8, loss:0.00023, loss_test:0.10352, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:27.088, tt:243.788\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10193, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:27.220, tt:272.197\n",
      "Ep:10, loss:0.00022, loss_test:0.09906, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:27.210, tt:299.311\n",
      "Ep:11, loss:0.00021, loss_test:0.09711, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:27.161, tt:325.927\n",
      "Ep:12, loss:0.00021, loss_test:0.09558, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:27.134, tt:352.744\n",
      "Ep:13, loss:0.00020, loss_test:0.09398, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:27.200, tt:380.796\n",
      "Ep:14, loss:0.00020, loss_test:0.09311, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:27.286, tt:409.287\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09236, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:27.291, tt:436.660\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09239, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:27.291, tt:463.942\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09154, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:27.263, tt:490.738\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08943, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:27.367, tt:519.968\n",
      "Ep:19, loss:0.00017, loss_test:0.08831, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:27.445, tt:548.897\n",
      "Ep:20, loss:0.00017, loss_test:0.08745, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:27.460, tt:576.656\n",
      "Ep:21, loss:0.00016, loss_test:0.08653, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:27.464, tt:604.204\n",
      "Ep:22, loss:0.00016, loss_test:0.08583, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:27.480, tt:632.033\n",
      "Ep:23, loss:0.00015, loss_test:0.08472, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:27.547, tt:661.117\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08442, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:27.620, tt:690.491\n",
      "Ep:25, loss:0.00014, loss_test:0.08384, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:27.660, tt:719.152\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08239, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:27.604, tt:745.321\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08111, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:27.608, tt:773.027\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08026, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:27.641, tt:801.601\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07982, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:27.710, tt:831.290\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07855, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:27.705, tt:858.867\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07775, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:27.649, tt:884.776\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07621, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:27.603, tt:910.909\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07537, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:27.640, tt:939.745\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.07487, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:27.677, tt:968.690\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07358, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:27.654, tt:995.559\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.07303, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:27.618, tt:1021.861\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07173, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:27.603, tt:1048.925\n",
      "Ep:38, loss:0.00009, loss_test:0.07135, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:27.623, tt:1077.301\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07029, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:27.617, tt:1104.698\n",
      "Ep:40, loss:0.00009, loss_test:0.07046, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:27.610, tt:1132.009\n",
      "Ep:41, loss:0.00009, loss_test:0.06927, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:27.635, tt:1160.665\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.06894, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:27.653, tt:1189.098\n",
      "Ep:43, loss:0.00008, loss_test:0.06820, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:27.670, tt:1217.501\n",
      "Ep:44, loss:0.00008, loss_test:0.06701, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:27.674, tt:1245.320\n",
      "Ep:45, loss:0.00008, loss_test:0.06752, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:27.678, tt:1273.201\n",
      "Ep:46, loss:0.00007, loss_test:0.06658, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:27.671, tt:1300.557\n",
      "Ep:47, loss:0.00007, loss_test:0.06623, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:27.678, tt:1328.528\n",
      "Ep:48, loss:0.00007, loss_test:0.06564, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:27.696, tt:1357.116\n",
      "Ep:49, loss:0.00007, loss_test:0.06520, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:27.715, tt:1385.767\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.06556, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:27.737, tt:1414.574\n",
      "Ep:51, loss:0.00006, loss_test:0.06538, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:27.738, tt:1442.361\n",
      "Ep:52, loss:0.00006, loss_test:0.06322, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:27.753, tt:1470.930\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.06457, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:27.772, tt:1499.710\n",
      "Ep:54, loss:0.00006, loss_test:0.06264, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:27.779, tt:1527.829\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.06280, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:27.751, tt:1554.034\n",
      "Ep:56, loss:0.00006, loss_test:0.06294, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:27.737, tt:1581.033\n",
      "Ep:57, loss:0.00005, loss_test:0.06186, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:27.757, tt:1609.909\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.06218, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:27.779, tt:1638.940\n",
      "Ep:59, loss:0.00005, loss_test:0.06226, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:27.776, tt:1666.587\n",
      "Ep:60, loss:0.00005, loss_test:0.06101, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:27.770, tt:1693.961\n",
      "Ep:61, loss:0.00005, loss_test:0.06141, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:27.778, tt:1722.221\n",
      "Ep:62, loss:0.00005, loss_test:0.06128, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:27.806, tt:1751.771\n",
      "Ep:63, loss:0.00005, loss_test:0.05984, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:27.782, tt:1778.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00004, loss_test:0.06072, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:27.781, tt:1805.778\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00004, loss_test:0.06008, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.789, tt:1834.046\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.05888, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.804, tt:1862.848\n",
      "Ep:67, loss:0.00004, loss_test:0.05964, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.834, tt:1892.702\n",
      "Ep:68, loss:0.00004, loss_test:0.05911, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.813, tt:1919.083\n",
      "Ep:69, loss:0.00004, loss_test:0.05835, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.805, tt:1946.355\n",
      "Ep:70, loss:0.00004, loss_test:0.05913, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.820, tt:1975.190\n",
      "Ep:71, loss:0.00004, loss_test:0.05869, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.813, tt:2002.565\n",
      "Ep:72, loss:0.00004, loss_test:0.05797, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:27.826, tt:2031.292\n",
      "Ep:73, loss:0.00004, loss_test:0.05797, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.813, tt:2058.152\n",
      "Ep:74, loss:0.00003, loss_test:0.05741, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.786, tt:2083.940\n",
      "Ep:75, loss:0.00003, loss_test:0.05785, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.784, tt:2111.602\n",
      "Ep:76, loss:0.00003, loss_test:0.05735, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:27.821, tt:2142.216\n",
      "Ep:77, loss:0.00003, loss_test:0.05734, lr:9.90e-03, fs:0.89119 (r=0.869,p=0.915),  time:27.822, tt:2170.100\n",
      "Ep:78, loss:0.00003, loss_test:0.05722, lr:9.80e-03, fs:0.88542 (r=0.859,p=0.914),  time:27.812, tt:2197.131\n",
      "Ep:79, loss:0.00003, loss_test:0.05656, lr:9.70e-03, fs:0.88660 (r=0.869,p=0.905),  time:27.806, tt:2224.515\n",
      "Ep:80, loss:0.00003, loss_test:0.05735, lr:9.61e-03, fs:0.89119 (r=0.869,p=0.915),  time:27.821, tt:2253.502\n",
      "Ep:81, loss:0.00003, loss_test:0.05634, lr:9.51e-03, fs:0.89005 (r=0.859,p=0.924),  time:27.804, tt:2279.913\n",
      "Ep:82, loss:0.00003, loss_test:0.05703, lr:9.41e-03, fs:0.88660 (r=0.869,p=0.905),  time:27.764, tt:2304.397\n",
      "Ep:83, loss:0.00003, loss_test:0.05704, lr:9.32e-03, fs:0.89005 (r=0.859,p=0.924),  time:27.744, tt:2330.516\n",
      "Ep:84, loss:0.00003, loss_test:0.05592, lr:9.23e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.713, tt:2355.575\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00003, loss_test:0.05680, lr:9.23e-03, fs:0.89005 (r=0.859,p=0.924),  time:27.667, tt:2379.402\n",
      "Ep:86, loss:0.00003, loss_test:0.05604, lr:9.23e-03, fs:0.89005 (r=0.859,p=0.924),  time:27.685, tt:2408.580\n",
      "Ep:87, loss:0.00003, loss_test:0.05654, lr:9.23e-03, fs:0.89119 (r=0.869,p=0.915),  time:27.630, tt:2431.444\n",
      "Ep:88, loss:0.00003, loss_test:0.05606, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.626, tt:2458.734\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00003, loss_test:0.05603, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.624, tt:2486.200\n",
      "Ep:90, loss:0.00003, loss_test:0.05591, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:27.631, tt:2514.404\n",
      "Ep:91, loss:0.00002, loss_test:0.05612, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:27.584, tt:2537.772\n",
      "Ep:92, loss:0.00002, loss_test:0.05626, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.568, tt:2563.831\n",
      "Ep:93, loss:0.00002, loss_test:0.05539, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.560, tt:2590.675\n",
      "Ep:94, loss:0.00002, loss_test:0.05605, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:27.556, tt:2617.817\n",
      "Ep:95, loss:0.00002, loss_test:0.05549, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.520, tt:2641.956\n",
      "Ep:96, loss:0.00002, loss_test:0.05567, lr:9.23e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.482, tt:2665.731\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.05624, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:27.483, tt:2693.361\n",
      "Ep:98, loss:0.00002, loss_test:0.05467, lr:9.23e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.495, tt:2722.041\n",
      "Ep:99, loss:0.00002, loss_test:0.05616, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:27.490, tt:2748.960\n",
      "Ep:100, loss:0.00002, loss_test:0.05499, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.485, tt:2775.971\n",
      "Ep:101, loss:0.00002, loss_test:0.05523, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:27.483, tt:2803.268\n",
      "Ep:102, loss:0.00002, loss_test:0.05507, lr:9.23e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.501, tt:2832.611\n",
      "Ep:103, loss:0.00002, loss_test:0.05510, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.505, tt:2860.526\n",
      "Ep:104, loss:0.00002, loss_test:0.05534, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.495, tt:2886.993\n",
      "Ep:105, loss:0.00002, loss_test:0.05492, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.504, tt:2915.420\n",
      "Ep:106, loss:0.00002, loss_test:0.05446, lr:9.23e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.530, tt:2945.660\n",
      "Ep:107, loss:0.00002, loss_test:0.05513, lr:9.23e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.540, tt:2974.367\n",
      "Ep:108, loss:0.00002, loss_test:0.05468, lr:9.14e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.542, tt:3002.066\n",
      "Ep:109, loss:0.00002, loss_test:0.05450, lr:9.04e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.530, tt:3028.333\n",
      "Ep:110, loss:0.00002, loss_test:0.05498, lr:8.95e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.548, tt:3057.833\n",
      "Ep:111, loss:0.00002, loss_test:0.05422, lr:8.86e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.558, tt:3086.441\n",
      "Ep:112, loss:0.00002, loss_test:0.05479, lr:8.78e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.551, tt:3113.304\n",
      "Ep:113, loss:0.00002, loss_test:0.05420, lr:8.69e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.548, tt:3140.526\n",
      "Ep:114, loss:0.00002, loss_test:0.05457, lr:8.60e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.551, tt:3168.369\n",
      "Ep:115, loss:0.00002, loss_test:0.05403, lr:8.51e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.573, tt:3198.526\n",
      "Ep:116, loss:0.00002, loss_test:0.05343, lr:8.43e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.572, tt:3225.952\n",
      "Ep:117, loss:0.00002, loss_test:0.05381, lr:8.35e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.566, tt:3252.772\n",
      "Ep:118, loss:0.00002, loss_test:0.05356, lr:8.26e-03, fs:0.89583 (r=0.869,p=0.925),  time:27.566, tt:3280.403\n",
      "Ep:119, loss:0.00002, loss_test:0.05419, lr:8.18e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.572, tt:3308.638\n",
      "Ep:120, loss:0.00002, loss_test:0.05457, lr:8.10e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.583, tt:3337.588\n",
      "Ep:121, loss:0.00001, loss_test:0.05345, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.582, tt:3364.973\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00001, loss_test:0.05356, lr:8.02e-03, fs:0.90052 (r=0.869,p=0.935),  time:27.573, tt:3391.484\n",
      "Ep:123, loss:0.00001, loss_test:0.05388, lr:8.02e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.570, tt:3418.643\n",
      "Ep:124, loss:0.00001, loss_test:0.05346, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.580, tt:3447.474\n",
      "Ep:125, loss:0.00001, loss_test:0.05352, lr:8.02e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.595, tt:3476.938\n",
      "Ep:126, loss:0.00001, loss_test:0.05386, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.578, tt:3502.470\n",
      "Ep:127, loss:0.00001, loss_test:0.05304, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.586, tt:3530.977\n",
      "Ep:128, loss:0.00001, loss_test:0.05329, lr:8.02e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.597, tt:3559.965\n",
      "Ep:129, loss:0.00001, loss_test:0.05341, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.597, tt:3587.608\n",
      "Ep:130, loss:0.00001, loss_test:0.05271, lr:8.02e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.599, tt:3615.447\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.05392, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.591, tt:3641.978\n",
      "Ep:132, loss:0.00001, loss_test:0.05328, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.602, tt:3671.125\n",
      "Ep:133, loss:0.00001, loss_test:0.05291, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.608, tt:3699.405\n",
      "Ep:134, loss:0.00001, loss_test:0.05306, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.614, tt:3727.880\n",
      "Ep:135, loss:0.00001, loss_test:0.05265, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.614, tt:3755.443\n",
      "Ep:136, loss:0.00001, loss_test:0.05315, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.606, tt:3782.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.05271, lr:8.02e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.614, tt:3810.782\n",
      "Ep:138, loss:0.00001, loss_test:0.05294, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.626, tt:3839.953\n",
      "Ep:139, loss:0.00001, loss_test:0.05303, lr:8.02e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.625, tt:3867.530\n",
      "Ep:140, loss:0.00001, loss_test:0.05301, lr:8.02e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.627, tt:3895.473\n",
      "Ep:141, loss:0.00001, loss_test:0.05264, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.639, tt:3924.776\n",
      "Ep:142, loss:0.00001, loss_test:0.05263, lr:7.94e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.632, tt:3951.423\n",
      "Ep:143, loss:0.00001, loss_test:0.05265, lr:7.86e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.623, tt:3977.671\n",
      "Ep:144, loss:0.00001, loss_test:0.05279, lr:7.78e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.622, tt:4005.167\n",
      "Ep:145, loss:0.00001, loss_test:0.05331, lr:7.70e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.631, tt:4034.066\n",
      "Ep:146, loss:0.00001, loss_test:0.05320, lr:7.62e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.633, tt:4062.005\n",
      "Ep:147, loss:0.00001, loss_test:0.05297, lr:7.55e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.636, tt:4090.066\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00001, loss_test:0.05272, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.633, tt:4117.331\n",
      "Ep:149, loss:0.00001, loss_test:0.05255, lr:7.55e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.640, tt:4145.974\n",
      "Ep:150, loss:0.00001, loss_test:0.05324, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.646, tt:4174.564\n",
      "Ep:151, loss:0.00001, loss_test:0.05267, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.652, tt:4203.176\n",
      "Ep:152, loss:0.00001, loss_test:0.05226, lr:7.55e-03, fs:0.90625 (r=0.879,p=0.935),  time:27.652, tt:4230.789\n",
      "Ep:153, loss:0.00001, loss_test:0.05287, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.651, tt:4258.277\n",
      "Ep:154, loss:0.00001, loss_test:0.05232, lr:7.55e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.658, tt:4286.976\n",
      "Ep:155, loss:0.00001, loss_test:0.05240, lr:7.55e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.672, tt:4316.862\n",
      "Ep:156, loss:0.00001, loss_test:0.05261, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.679, tt:4345.666\n",
      "Ep:157, loss:0.00001, loss_test:0.05246, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.679, tt:4373.257\n",
      "Ep:158, loss:0.00001, loss_test:0.05236, lr:7.55e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.680, tt:4401.044\n",
      "Ep:159, loss:0.00001, loss_test:0.05279, lr:7.47e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.682, tt:4429.123\n",
      "Ep:160, loss:0.00001, loss_test:0.05218, lr:7.40e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.684, tt:4457.155\n",
      "Ep:161, loss:0.00001, loss_test:0.05166, lr:7.32e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.676, tt:4483.476\n",
      "Ep:162, loss:0.00001, loss_test:0.05214, lr:7.25e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.671, tt:4510.330\n",
      "Ep:163, loss:0.00001, loss_test:0.05253, lr:7.18e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.676, tt:4538.937\n",
      "Ep:164, loss:0.00001, loss_test:0.05151, lr:7.11e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.689, tt:4568.700\n",
      "Ep:165, loss:0.00001, loss_test:0.05261, lr:7.03e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.697, tt:4597.648\n",
      "Ep:166, loss:0.00001, loss_test:0.05283, lr:6.96e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.698, tt:4625.496\n",
      "Ep:167, loss:0.00001, loss_test:0.05244, lr:6.89e-03, fs:0.92063 (r=0.879,p=0.967),  time:27.702, tt:4653.940\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00001, loss_test:0.05265, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.700, tt:4681.268\n",
      "Ep:169, loss:0.00001, loss_test:0.05236, lr:6.89e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.700, tt:4709.028\n",
      "Ep:170, loss:0.00001, loss_test:0.05273, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.702, tt:4737.047\n",
      "Ep:171, loss:0.00001, loss_test:0.05239, lr:6.89e-03, fs:0.92063 (r=0.879,p=0.967),  time:27.703, tt:4764.874\n",
      "Ep:172, loss:0.00001, loss_test:0.05226, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.707, tt:4793.338\n",
      "Ep:173, loss:0.00001, loss_test:0.05203, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.710, tt:4821.552\n",
      "Ep:174, loss:0.00001, loss_test:0.05233, lr:6.89e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.703, tt:4847.984\n",
      "Ep:175, loss:0.00001, loss_test:0.05242, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.705, tt:4875.994\n",
      "Ep:176, loss:0.00001, loss_test:0.05202, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.706, tt:4903.945\n",
      "Ep:177, loss:0.00001, loss_test:0.05263, lr:6.89e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.704, tt:4931.264\n",
      "Ep:178, loss:0.00001, loss_test:0.05202, lr:6.89e-03, fs:0.92063 (r=0.879,p=0.967),  time:27.694, tt:4957.273\n",
      "Ep:179, loss:0.00001, loss_test:0.05246, lr:6.83e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.703, tt:4986.532\n",
      "Ep:180, loss:0.00001, loss_test:0.05280, lr:6.76e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.700, tt:5013.615\n",
      "Ep:181, loss:0.00001, loss_test:0.05172, lr:6.69e-03, fs:0.91005 (r=0.869,p=0.956),  time:27.697, tt:5040.770\n",
      "Ep:182, loss:0.00001, loss_test:0.05245, lr:6.62e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.702, tt:5069.545\n",
      "Ep:183, loss:0.00001, loss_test:0.05275, lr:6.56e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.702, tt:5097.252\n",
      "Ep:184, loss:0.00001, loss_test:0.05163, lr:6.49e-03, fs:0.91489 (r=0.869,p=0.966),  time:27.693, tt:5123.249\n",
      "Ep:185, loss:0.00001, loss_test:0.05196, lr:6.43e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.692, tt:5150.652\n",
      "Ep:186, loss:0.00001, loss_test:0.05197, lr:6.36e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.698, tt:5179.616\n",
      "Ep:187, loss:0.00001, loss_test:0.05150, lr:6.30e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.702, tt:5208.007\n",
      "Ep:188, loss:0.00001, loss_test:0.05196, lr:6.24e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.696, tt:5234.634\n",
      "Ep:189, loss:0.00001, loss_test:0.05215, lr:6.17e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.698, tt:5262.550\n",
      "Ep:190, loss:0.00001, loss_test:0.05162, lr:6.11e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.698, tt:5290.304\n",
      "Ep:191, loss:0.00001, loss_test:0.05200, lr:6.05e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.705, tt:5319.428\n",
      "Ep:192, loss:0.00001, loss_test:0.05195, lr:5.99e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.694, tt:5344.859\n",
      "Ep:193, loss:0.00001, loss_test:0.05156, lr:5.93e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.687, tt:5371.338\n",
      "Ep:194, loss:0.00001, loss_test:0.05199, lr:5.87e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.695, tt:5400.477\n",
      "Ep:195, loss:0.00001, loss_test:0.05197, lr:5.81e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.705, tt:5430.140\n",
      "Ep:196, loss:0.00001, loss_test:0.05176, lr:5.75e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.702, tt:5457.276\n",
      "Ep:197, loss:0.00001, loss_test:0.05173, lr:5.70e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.701, tt:5484.700\n",
      "Ep:198, loss:0.00001, loss_test:0.05172, lr:5.64e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.699, tt:5512.188\n",
      "Ep:199, loss:0.00001, loss_test:0.05181, lr:5.58e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.705, tt:5540.948\n",
      "Ep:200, loss:0.00001, loss_test:0.05187, lr:5.53e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.713, tt:5570.263\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02157, lr:6.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:35.548, tt:35.548\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02249, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:35.416, tt:70.832\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00005, loss_test:0.02381, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.666, tt:106.998\n",
      "Ep:3, loss:0.00005, loss_test:0.02371, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.434, tt:141.736\n",
      "Ep:4, loss:0.00005, loss_test:0.02251, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:36.265, tt:181.323\n",
      "Ep:5, loss:0.00004, loss_test:0.02055, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:36.099, tt:216.591\n",
      "Ep:6, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:35.956, tt:251.689\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:35.999, tt:287.996\n",
      "Ep:8, loss:0.00004, loss_test:0.01720, lr:6.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:35.926, tt:323.335\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01685, lr:6.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:35.763, tt:357.626\n",
      "Ep:10, loss:0.00004, loss_test:0.01671, lr:6.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:35.695, tt:392.641\n",
      "Ep:11, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:35.565, tt:426.778\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:35.408, tt:460.308\n",
      "Ep:13, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:35.346, tt:494.838\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:35.336, tt:530.037\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01507, lr:6.00e-02, fs:0.75314 (r=0.909,p=0.643),  time:35.271, tt:564.333\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01474, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:35.232, tt:598.938\n",
      "Ep:17, loss:0.00003, loss_test:0.01441, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:35.205, tt:633.693\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01408, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:35.238, tt:669.521\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01373, lr:6.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:35.245, tt:704.890\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01338, lr:6.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:35.211, tt:739.423\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01301, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:35.236, tt:775.184\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:35.194, tt:809.464\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:35.179, tt:844.284\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:35.241, tt:881.029\n",
      "Ep:25, loss:0.00002, loss_test:0.01206, lr:6.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:35.274, tt:917.137\n",
      "Ep:26, loss:0.00002, loss_test:0.01188, lr:6.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:35.214, tt:950.768\n",
      "Ep:27, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:35.185, tt:985.191\n",
      "Ep:28, loss:0.00002, loss_test:0.01154, lr:6.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:35.171, tt:1019.951\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01141, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:35.159, tt:1054.763\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01128, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:35.168, tt:1090.196\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01114, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:35.171, tt:1125.475\n",
      "Ep:32, loss:0.00002, loss_test:0.01103, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:35.153, tt:1160.033\n",
      "Ep:33, loss:0.00002, loss_test:0.01096, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:35.173, tt:1195.892\n",
      "Ep:34, loss:0.00002, loss_test:0.01091, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:35.187, tt:1231.532\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01080, lr:6.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:35.149, tt:1265.377\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01072, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:35.152, tt:1300.614\n",
      "Ep:37, loss:0.00002, loss_test:0.01070, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:35.164, tt:1336.222\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01060, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:35.162, tt:1371.326\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01050, lr:6.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:35.152, tt:1406.083\n",
      "Ep:40, loss:0.00001, loss_test:0.01046, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:35.196, tt:1443.029\n",
      "Ep:41, loss:0.00001, loss_test:0.01036, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:35.187, tt:1477.848\n",
      "Ep:42, loss:0.00001, loss_test:0.01029, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:35.178, tt:1512.643\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01028, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:35.151, tt:1546.642\n",
      "Ep:44, loss:0.00001, loss_test:0.01023, lr:6.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:35.132, tt:1580.946\n",
      "Ep:45, loss:0.00001, loss_test:0.01016, lr:6.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:35.126, tt:1615.773\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01014, lr:6.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.142, tt:1651.665\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01011, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.158, tt:1687.588\n",
      "Ep:48, loss:0.00001, loss_test:0.01010, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:35.147, tt:1722.203\n",
      "Ep:49, loss:0.00001, loss_test:0.01008, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:35.153, tt:1757.639\n",
      "Ep:50, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:35.177, tt:1794.038\n",
      "Ep:51, loss:0.00001, loss_test:0.01008, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:35.170, tt:1828.821\n",
      "Ep:52, loss:0.00001, loss_test:0.01012, lr:6.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:35.149, tt:1862.907\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01012, lr:6.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:35.135, tt:1897.264\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01011, lr:6.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:35.115, tt:1931.344\n",
      "Ep:55, loss:0.00001, loss_test:0.01024, lr:6.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.084, tt:1964.723\n",
      "Ep:56, loss:0.00001, loss_test:0.01026, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:35.082, tt:1999.674\n",
      "Ep:57, loss:0.00001, loss_test:0.01027, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:35.082, tt:2034.782\n",
      "Ep:58, loss:0.00001, loss_test:0.01034, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:35.097, tt:2070.752\n",
      "Ep:59, loss:0.00001, loss_test:0.01039, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:35.074, tt:2104.448\n",
      "Ep:60, loss:0.00001, loss_test:0.01049, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:35.047, tt:2137.871\n",
      "Ep:61, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.023, tt:2171.450\n",
      "Ep:62, loss:0.00001, loss_test:0.01059, lr:6.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.009, tt:2205.586\n",
      "Ep:63, loss:0.00001, loss_test:0.01068, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.003, tt:2240.192\n",
      "Ep:64, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.000, tt:2275.019\n",
      "Ep:65, loss:0.00001, loss_test:0.01084, lr:5.94e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.998, tt:2309.839\n",
      "Ep:66, loss:0.00001, loss_test:0.01091, lr:5.88e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.011, tt:2345.718\n",
      "Ep:67, loss:0.00001, loss_test:0.01098, lr:5.82e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.013, tt:2380.899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.01110, lr:5.76e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.989, tt:2414.267\n",
      "Ep:69, loss:0.00001, loss_test:0.01120, lr:5.71e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.983, tt:2448.838\n",
      "Ep:70, loss:0.00001, loss_test:0.01122, lr:5.65e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.005, tt:2485.345\n",
      "Ep:71, loss:0.00001, loss_test:0.01133, lr:5.59e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.011, tt:2520.788\n",
      "Ep:72, loss:0.00001, loss_test:0.01140, lr:5.54e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.003, tt:2555.205\n",
      "Ep:73, loss:0.00001, loss_test:0.01144, lr:5.48e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.021, tt:2591.544\n",
      "Ep:74, loss:0.00001, loss_test:0.01150, lr:5.43e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.025, tt:2626.910\n",
      "Ep:75, loss:0.00001, loss_test:0.01156, lr:5.37e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.052, tt:2663.974\n",
      "Ep:76, loss:0.00001, loss_test:0.01172, lr:5.32e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.052, tt:2699.000\n",
      "Ep:77, loss:0.00001, loss_test:0.01175, lr:5.27e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.063, tt:2734.943\n",
      "Ep:78, loss:0.00001, loss_test:0.01178, lr:5.21e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.071, tt:2770.633\n",
      "Ep:79, loss:0.00001, loss_test:0.01186, lr:5.16e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.080, tt:2806.401\n",
      "Ep:80, loss:0.00001, loss_test:0.01195, lr:5.11e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.092, tt:2842.472\n",
      "Ep:81, loss:0.00001, loss_test:0.01198, lr:5.06e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.104, tt:2878.563\n",
      "Ep:82, loss:0.00001, loss_test:0.01207, lr:5.01e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.095, tt:2912.873\n",
      "Ep:83, loss:0.00001, loss_test:0.01211, lr:4.96e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.083, tt:2947.013\n",
      "Ep:84, loss:0.00001, loss_test:0.01221, lr:4.91e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.093, tt:2982.873\n",
      "Ep:85, loss:0.00001, loss_test:0.01218, lr:4.86e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.081, tt:3016.999\n",
      "Ep:86, loss:0.00001, loss_test:0.01227, lr:4.81e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.080, tt:3051.946\n",
      "Ep:87, loss:0.00000, loss_test:0.01237, lr:4.76e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.077, tt:3086.757\n",
      "Ep:88, loss:0.00000, loss_test:0.01238, lr:4.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.064, tt:3120.684\n",
      "Ep:89, loss:0.00000, loss_test:0.01241, lr:4.67e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.053, tt:3154.735\n",
      "Ep:90, loss:0.00000, loss_test:0.01249, lr:4.62e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.068, tt:3191.173\n",
      "Ep:91, loss:0.00000, loss_test:0.01260, lr:4.57e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.067, tt:3226.134\n",
      "Ep:92, loss:0.00000, loss_test:0.01261, lr:4.53e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.079, tt:3262.345\n",
      "Ep:93, loss:0.00000, loss_test:0.01262, lr:4.48e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.090, tt:3298.413\n",
      "Ep:94, loss:0.00000, loss_test:0.01270, lr:4.44e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.099, tt:3334.436\n",
      "Ep:95, loss:0.00000, loss_test:0.01271, lr:4.39e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.095, tt:3369.101\n",
      "Ep:96, loss:0.00000, loss_test:0.01277, lr:4.35e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.095, tt:3404.216\n",
      "Ep:97, loss:0.00000, loss_test:0.01288, lr:4.31e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.106, tt:3440.436\n",
      "Ep:98, loss:0.00000, loss_test:0.01292, lr:4.26e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.116, tt:3476.532\n",
      "Ep:99, loss:0.00000, loss_test:0.01292, lr:4.22e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.120, tt:3512.036\n",
      "Ep:100, loss:0.00000, loss_test:0.01296, lr:4.18e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.138, tt:3548.900\n",
      "Ep:101, loss:0.00000, loss_test:0.01297, lr:4.14e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.143, tt:3584.599\n",
      "Ep:102, loss:0.00000, loss_test:0.01310, lr:4.10e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.140, tt:3619.463\n",
      "Ep:103, loss:0.00000, loss_test:0.01312, lr:4.05e-02, fs:0.85405 (r=0.798,p=0.919),  time:35.156, tt:3656.247\n",
      "Ep:104, loss:0.00000, loss_test:0.01313, lr:4.01e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.151, tt:3690.819\n",
      "Ep:105, loss:0.00000, loss_test:0.01312, lr:3.97e-02, fs:0.85405 (r=0.798,p=0.919),  time:35.163, tt:3727.262\n",
      "Ep:106, loss:0.00000, loss_test:0.01330, lr:3.93e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.164, tt:3762.501\n",
      "Ep:107, loss:0.00000, loss_test:0.01333, lr:3.89e-02, fs:0.85405 (r=0.798,p=0.919),  time:35.180, tt:3799.475\n",
      "Ep:108, loss:0.00000, loss_test:0.01330, lr:3.86e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.180, tt:3834.669\n",
      "Ep:109, loss:0.00000, loss_test:0.01332, lr:3.82e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.178, tt:3869.575\n",
      "Ep:110, loss:0.00000, loss_test:0.01339, lr:3.78e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.175, tt:3904.405\n",
      "Ep:111, loss:0.00000, loss_test:0.01346, lr:3.74e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.180, tt:3940.176\n",
      "Ep:112, loss:0.00000, loss_test:0.01352, lr:3.70e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.179, tt:3975.284\n",
      "Ep:113, loss:0.00000, loss_test:0.01349, lr:3.67e-02, fs:0.85405 (r=0.798,p=0.919),  time:35.173, tt:4009.743\n",
      "Ep:114, loss:0.00000, loss_test:0.01353, lr:3.63e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.162, tt:4043.586\n",
      "Ep:115, loss:0.00000, loss_test:0.01357, lr:3.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.151, tt:4077.513\n",
      "Ep:116, loss:0.00000, loss_test:0.01361, lr:3.56e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.130, tt:4110.168\n",
      "Ep:117, loss:0.00000, loss_test:0.01362, lr:3.52e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.116, tt:4143.659\n",
      "Ep:118, loss:0.00000, loss_test:0.01366, lr:3.49e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.083, tt:4174.822\n",
      "Ep:119, loss:0.00000, loss_test:0.01377, lr:3.45e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.070, tt:4208.454\n",
      "Ep:120, loss:0.00000, loss_test:0.01378, lr:3.42e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.044, tt:4240.348\n",
      "Ep:121, loss:0.00000, loss_test:0.01375, lr:3.38e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.007, tt:4270.811\n",
      "Ep:122, loss:0.00000, loss_test:0.01378, lr:3.35e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.970, tt:4301.351\n",
      "Ep:123, loss:0.00000, loss_test:0.01386, lr:3.32e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.916, tt:4329.622\n",
      "Ep:124, loss:0.00000, loss_test:0.01388, lr:3.28e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.870, tt:4358.785\n",
      "Ep:125, loss:0.00000, loss_test:0.01393, lr:3.25e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.828, tt:4388.327\n",
      "Ep:126, loss:0.00000, loss_test:0.01395, lr:3.22e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.821, tt:4422.274\n",
      "Ep:127, loss:0.00000, loss_test:0.01395, lr:3.19e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.827, tt:4457.897\n",
      "Ep:128, loss:0.00000, loss_test:0.01397, lr:3.15e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.788, tt:4487.636\n",
      "Ep:129, loss:0.00000, loss_test:0.01406, lr:3.12e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.793, tt:4523.062\n",
      "Ep:130, loss:0.00000, loss_test:0.01411, lr:3.09e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.785, tt:4556.828\n",
      "Ep:131, loss:0.00000, loss_test:0.01403, lr:3.06e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.771, tt:4589.829\n",
      "Ep:132, loss:0.00000, loss_test:0.01407, lr:3.03e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.770, tt:4624.415\n",
      "Ep:133, loss:0.00000, loss_test:0.01411, lr:3.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.777, tt:4660.059\n",
      "Ep:134, loss:0.00000, loss_test:0.01414, lr:2.97e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.798, tt:4697.742\n",
      "Ep:135, loss:0.00000, loss_test:0.01419, lr:2.94e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.812, tt:4734.493\n",
      "Ep:136, loss:0.00000, loss_test:0.01423, lr:2.91e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.828, tt:4771.464\n",
      "Ep:137, loss:0.00000, loss_test:0.01422, lr:2.88e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.847, tt:4808.947\n",
      "Ep:138, loss:0.00000, loss_test:0.01423, lr:2.85e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.864, tt:4846.110\n",
      "Ep:139, loss:0.00000, loss_test:0.01429, lr:2.82e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.864, tt:4880.981\n",
      "Ep:140, loss:0.00000, loss_test:0.01428, lr:2.80e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.876, tt:4917.468\n",
      "Ep:141, loss:0.00000, loss_test:0.01435, lr:2.77e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.884, tt:4953.495\n",
      "Ep:142, loss:0.00000, loss_test:0.01434, lr:2.74e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.896, tt:4990.190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.01437, lr:2.71e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.913, tt:5027.481\n",
      "Ep:144, loss:0.00000, loss_test:0.01440, lr:2.69e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.922, tt:5063.629\n",
      "Ep:145, loss:0.00000, loss_test:0.01440, lr:2.66e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.935, tt:5100.460\n",
      "Ep:146, loss:0.00000, loss_test:0.01444, lr:2.63e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.947, tt:5137.158\n",
      "Ep:147, loss:0.00000, loss_test:0.01445, lr:2.61e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.962, tt:5174.402\n",
      "Ep:148, loss:0.00000, loss_test:0.01448, lr:2.58e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.984, tt:5212.688\n",
      "Ep:149, loss:0.00000, loss_test:0.01451, lr:2.55e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.996, tt:5249.361\n",
      "Ep:150, loss:0.00000, loss_test:0.01452, lr:2.53e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.010, tt:5286.499\n",
      "Ep:151, loss:0.00000, loss_test:0.01453, lr:2.50e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.023, tt:5323.431\n",
      "Ep:152, loss:0.00000, loss_test:0.01457, lr:2.48e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.031, tt:5359.719\n",
      "Ep:153, loss:0.00000, loss_test:0.01454, lr:2.45e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.039, tt:5396.055\n",
      "Ep:154, loss:0.00000, loss_test:0.01458, lr:2.43e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.048, tt:5432.392\n",
      "Ep:155, loss:0.00000, loss_test:0.01455, lr:2.40e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.048, tt:5467.547\n",
      "Ep:156, loss:0.00000, loss_test:0.01458, lr:2.38e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.047, tt:5502.394\n",
      "Ep:157, loss:0.00000, loss_test:0.01462, lr:2.36e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.041, tt:5536.549\n",
      "Ep:158, loss:0.00000, loss_test:0.01464, lr:2.33e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.043, tt:5571.866\n",
      "Ep:159, loss:0.00000, loss_test:0.01466, lr:2.31e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.036, tt:5605.808\n",
      "Ep:160, loss:0.00000, loss_test:0.01467, lr:2.29e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.035, tt:5640.624\n",
      "Ep:161, loss:0.00000, loss_test:0.01472, lr:2.26e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.031, tt:5675.037\n",
      "Ep:162, loss:0.00000, loss_test:0.01466, lr:2.24e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.029, tt:5709.740\n",
      "Ep:163, loss:0.00000, loss_test:0.01469, lr:2.22e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.020, tt:5743.291\n",
      "Ep:164, loss:0.00000, loss_test:0.01471, lr:2.20e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.017, tt:5777.839\n",
      "Ep:165, loss:0.00000, loss_test:0.01473, lr:2.17e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.016, tt:5812.617\n",
      "Ep:166, loss:0.00000, loss_test:0.01476, lr:2.15e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.016, tt:5847.606\n",
      "Ep:167, loss:0.00000, loss_test:0.01472, lr:2.13e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.012, tt:5882.061\n",
      "Ep:168, loss:0.00000, loss_test:0.01477, lr:2.11e-02, fs:0.83799 (r=0.758,p=0.938),  time:35.014, tt:5917.282\n",
      "Ep:169, loss:0.00000, loss_test:0.01478, lr:2.09e-02, fs:0.82682 (r=0.747,p=0.925),  time:35.012, tt:5952.002\n",
      "Ep:170, loss:0.00000, loss_test:0.01478, lr:2.07e-02, fs:0.82682 (r=0.747,p=0.925),  time:35.008, tt:5986.369\n",
      "Ep:171, loss:0.00000, loss_test:0.01483, lr:2.05e-02, fs:0.83146 (r=0.747,p=0.937),  time:35.014, tt:6022.341\n",
      "Ep:172, loss:0.00000, loss_test:0.01484, lr:2.03e-02, fs:0.83146 (r=0.747,p=0.937),  time:35.014, tt:6057.372\n",
      "Ep:173, loss:0.00000, loss_test:0.01483, lr:2.01e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.017, tt:6092.940\n",
      "Ep:174, loss:0.00000, loss_test:0.01486, lr:1.99e-02, fs:0.82486 (r=0.737,p=0.936),  time:35.021, tt:6128.646\n",
      "Ep:175, loss:0.00000, loss_test:0.01487, lr:1.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.023, tt:6164.136\n",
      "Ep:176, loss:0.00000, loss_test:0.01489, lr:1.95e-02, fs:0.82486 (r=0.737,p=0.936),  time:35.020, tt:6198.531\n",
      "Ep:177, loss:0.00000, loss_test:0.01491, lr:1.93e-02, fs:0.82486 (r=0.737,p=0.936),  time:35.018, tt:6233.258\n",
      "Ep:178, loss:0.00000, loss_test:0.01490, lr:1.91e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.015, tt:6267.769\n",
      "Ep:179, loss:0.00000, loss_test:0.01494, lr:1.89e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.013, tt:6302.251\n",
      "Ep:180, loss:0.00000, loss_test:0.01493, lr:1.87e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.010, tt:6336.881\n",
      "Ep:181, loss:0.00000, loss_test:0.01493, lr:1.85e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.015, tt:6372.774\n",
      "Ep:182, loss:0.00000, loss_test:0.01498, lr:1.83e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.014, tt:6407.605\n",
      "Ep:183, loss:0.00000, loss_test:0.01495, lr:1.81e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.011, tt:6442.107\n",
      "Ep:184, loss:0.00000, loss_test:0.01496, lr:1.80e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.012, tt:6477.178\n",
      "Ep:185, loss:0.00000, loss_test:0.01502, lr:1.78e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.013, tt:6512.497\n",
      "Ep:186, loss:0.00000, loss_test:0.01499, lr:1.76e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.024, tt:6549.541\n",
      "Ep:187, loss:0.00000, loss_test:0.01500, lr:1.74e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.023, tt:6584.283\n",
      "Ep:188, loss:0.00000, loss_test:0.01505, lr:1.73e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.033, tt:6621.166\n",
      "Ep:189, loss:0.00000, loss_test:0.01504, lr:1.71e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.040, tt:6657.524\n",
      "Ep:190, loss:0.00000, loss_test:0.01503, lr:1.69e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.045, tt:6693.654\n",
      "Ep:191, loss:0.00000, loss_test:0.01507, lr:1.67e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.053, tt:6730.253\n",
      "Ep:192, loss:0.00000, loss_test:0.01505, lr:1.66e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.060, tt:6766.519\n",
      "Ep:193, loss:0.00000, loss_test:0.01508, lr:1.64e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.063, tt:6802.221\n",
      "Ep:194, loss:0.00000, loss_test:0.01510, lr:1.62e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.063, tt:6837.311\n",
      "Ep:195, loss:0.00000, loss_test:0.01508, lr:1.61e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.071, tt:6873.938\n",
      "Ep:196, loss:0.00000, loss_test:0.01509, lr:1.59e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.078, tt:6910.336\n",
      "Ep:197, loss:0.00000, loss_test:0.01513, lr:1.58e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.087, tt:6947.230\n",
      "Ep:198, loss:0.00000, loss_test:0.01512, lr:1.56e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.088, tt:6982.597\n",
      "Ep:199, loss:0.00000, loss_test:0.01513, lr:1.54e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.099, tt:7019.733\n",
      "Ep:200, loss:0.00000, loss_test:0.01516, lr:1.53e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.115, tt:7058.076\n",
      "Ep:201, loss:0.00000, loss_test:0.01514, lr:1.51e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.126, tt:7095.471\n",
      "Ep:202, loss:0.00000, loss_test:0.01514, lr:1.50e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.131, tt:7131.621\n",
      "Ep:203, loss:0.00000, loss_test:0.01517, lr:1.48e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.139, tt:7168.446\n",
      "Ep:204, loss:0.00000, loss_test:0.01516, lr:1.47e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.143, tt:7204.232\n",
      "Ep:205, loss:0.00000, loss_test:0.01518, lr:1.45e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.151, tt:7241.127\n",
      "Ep:206, loss:0.00000, loss_test:0.01520, lr:1.44e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.159, tt:7277.963\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13013, lr:1.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:34.559, tt:34.559\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12587, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:35.074, tt:70.149\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12133, lr:1.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:35.244, tt:105.733\n",
      "Ep:3, loss:0.00025, loss_test:0.11697, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:35.425, tt:141.701\n",
      "Ep:4, loss:0.00025, loss_test:0.11278, lr:1.00e-02, fs:0.68421 (r=0.788,p=0.605),  time:35.494, tt:177.468\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10945, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:35.487, tt:212.922\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00023, loss_test:0.10656, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:35.900, tt:251.299\n",
      "Ep:7, loss:0.00023, loss_test:0.10275, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:36.034, tt:288.270\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.09917, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:36.221, tt:325.985\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09533, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:36.091, tt:360.910\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09223, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:36.263, tt:398.894\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09033, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:36.369, tt:436.434\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.08850, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:36.504, tt:474.558\n",
      "Ep:13, loss:0.00019, loss_test:0.08746, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:36.420, tt:509.873\n",
      "Ep:14, loss:0.00018, loss_test:0.08482, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:36.284, tt:544.254\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08253, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:36.181, tt:578.889\n",
      "Ep:16, loss:0.00017, loss_test:0.08186, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:36.208, tt:615.536\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08004, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:36.218, tt:651.924\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.07755, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:36.280, tt:689.329\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.07707, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:36.237, tt:724.746\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.07598, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:36.249, tt:761.226\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.07428, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:36.270, tt:797.934\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07496, lr:1.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:36.304, tt:834.997\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07221, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:36.373, tt:872.949\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07198, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:36.445, tt:911.132\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07001, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:36.495, tt:948.867\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.06888, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:36.552, tt:986.892\n",
      "Ep:27, loss:0.00012, loss_test:0.06748, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:36.552, tt:1023.464\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.06639, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:36.578, tt:1060.760\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.06454, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:36.620, tt:1098.596\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.06463, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:36.652, tt:1136.202\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.06257, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:36.644, tt:1172.610\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.06193, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:36.611, tt:1208.169\n",
      "Ep:33, loss:0.00010, loss_test:0.05956, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:36.580, tt:1243.731\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06123, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:36.624, tt:1281.848\n",
      "Ep:35, loss:0.00010, loss_test:0.05733, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:36.664, tt:1319.908\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.05874, lr:1.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:36.712, tt:1358.340\n",
      "Ep:37, loss:0.00009, loss_test:0.05521, lr:1.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:36.730, tt:1395.727\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.05412, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:36.738, tt:1432.793\n",
      "Ep:39, loss:0.00008, loss_test:0.05458, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:36.759, tt:1470.348\n",
      "Ep:40, loss:0.00008, loss_test:0.05208, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:36.763, tt:1507.267\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.05209, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:36.711, tt:1541.847\n",
      "Ep:42, loss:0.00008, loss_test:0.05068, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:36.689, tt:1577.619\n",
      "Ep:43, loss:0.00007, loss_test:0.04918, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:36.741, tt:1616.596\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.05080, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:36.773, tt:1654.763\n",
      "Ep:45, loss:0.00007, loss_test:0.04710, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:36.773, tt:1691.538\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.04641, lr:1.00e-02, fs:0.94231 (r=0.990,p=0.899),  time:36.783, tt:1728.823\n",
      "Ep:47, loss:0.00006, loss_test:0.04643, lr:1.00e-02, fs:0.93396 (r=1.000,p=0.876),  time:36.867, tt:1769.626\n",
      "Ep:48, loss:0.00006, loss_test:0.04447, lr:1.00e-02, fs:0.95146 (r=0.990,p=0.916),  time:36.909, tt:1808.534\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.04435, lr:1.00e-02, fs:0.94737 (r=1.000,p=0.900),  time:36.940, tt:1847.000\n",
      "Ep:50, loss:0.00006, loss_test:0.04418, lr:1.00e-02, fs:0.94286 (r=1.000,p=0.892),  time:36.980, tt:1886.003\n",
      "Ep:51, loss:0.00006, loss_test:0.04266, lr:1.00e-02, fs:0.95146 (r=0.990,p=0.916),  time:37.006, tt:1924.323\n",
      "Ep:52, loss:0.00006, loss_test:0.04582, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:36.983, tt:1960.094\n",
      "Ep:53, loss:0.00005, loss_test:0.04272, lr:1.00e-02, fs:0.95146 (r=0.990,p=0.916),  time:36.960, tt:1995.825\n",
      "Ep:54, loss:0.00005, loss_test:0.04143, lr:1.00e-02, fs:0.94286 (r=1.000,p=0.892),  time:36.949, tt:2032.184\n",
      "Ep:55, loss:0.00005, loss_test:0.04356, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:36.931, tt:2068.148\n",
      "Ep:56, loss:0.00005, loss_test:0.04023, lr:1.00e-02, fs:0.94737 (r=1.000,p=0.900),  time:36.955, tt:2106.439\n",
      "Ep:57, loss:0.00005, loss_test:0.04132, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:36.960, tt:2143.651\n",
      "Ep:58, loss:0.00005, loss_test:0.04032, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:36.977, tt:2181.655\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00005, loss_test:0.04307, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:36.980, tt:2218.785\n",
      "Ep:60, loss:0.00005, loss_test:0.03912, lr:1.00e-02, fs:0.95192 (r=1.000,p=0.908),  time:37.022, tt:2258.360\n",
      "Ep:61, loss:0.00004, loss_test:0.03878, lr:1.00e-02, fs:0.96585 (r=1.000,p=0.934),  time:37.004, tt:2294.263\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.04059, lr:1.00e-02, fs:0.92523 (r=1.000,p=0.861),  time:37.011, tt:2331.681\n",
      "Ep:63, loss:0.00004, loss_test:0.03815, lr:1.00e-02, fs:0.97059 (r=1.000,p=0.943),  time:37.008, tt:2368.480\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.03997, lr:1.00e-02, fs:0.93780 (r=0.990,p=0.891),  time:37.003, tt:2405.199\n",
      "Ep:65, loss:0.00004, loss_test:0.03721, lr:1.00e-02, fs:0.96585 (r=1.000,p=0.934),  time:37.023, tt:2443.521\n",
      "Ep:66, loss:0.00004, loss_test:0.03668, lr:1.00e-02, fs:0.96117 (r=1.000,p=0.925),  time:37.050, tt:2482.326\n",
      "Ep:67, loss:0.00004, loss_test:0.03889, lr:1.00e-02, fs:0.95567 (r=0.980,p=0.933),  time:37.056, tt:2519.781\n",
      "Ep:68, loss:0.00004, loss_test:0.03691, lr:1.00e-02, fs:0.96117 (r=1.000,p=0.925),  time:37.046, tt:2556.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00004, loss_test:0.03829, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:37.031, tt:2592.201\n",
      "Ep:70, loss:0.00003, loss_test:0.03655, lr:1.00e-02, fs:0.96117 (r=1.000,p=0.925),  time:37.023, tt:2628.651\n",
      "Ep:71, loss:0.00003, loss_test:0.03723, lr:1.00e-02, fs:0.97059 (r=1.000,p=0.943),  time:37.009, tt:2664.651\n",
      "Ep:72, loss:0.00003, loss_test:0.03887, lr:1.00e-02, fs:0.94286 (r=1.000,p=0.892),  time:37.004, tt:2701.297\n",
      "Ep:73, loss:0.00003, loss_test:0.03562, lr:1.00e-02, fs:0.97059 (r=1.000,p=0.943),  time:36.991, tt:2737.305\n",
      "Ep:74, loss:0.00003, loss_test:0.03733, lr:1.00e-02, fs:0.96117 (r=1.000,p=0.925),  time:37.023, tt:2776.700\n",
      "Ep:75, loss:0.00003, loss_test:0.03576, lr:9.90e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.014, tt:2813.094\n",
      "Ep:76, loss:0.00003, loss_test:0.03448, lr:9.80e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.030, tt:2851.289\n",
      "Ep:77, loss:0.00003, loss_test:0.03897, lr:9.70e-03, fs:0.95522 (r=0.970,p=0.941),  time:37.051, tt:2890.008\n",
      "Ep:78, loss:0.00003, loss_test:0.03469, lr:9.61e-03, fs:0.96585 (r=1.000,p=0.934),  time:37.069, tt:2928.456\n",
      "Ep:79, loss:0.00003, loss_test:0.04045, lr:9.51e-03, fs:0.94527 (r=0.960,p=0.931),  time:37.065, tt:2965.183\n",
      "Ep:80, loss:0.00003, loss_test:0.03485, lr:9.41e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.071, tt:3002.752\n",
      "Ep:81, loss:0.00003, loss_test:0.03522, lr:9.32e-03, fs:0.96585 (r=1.000,p=0.934),  time:37.090, tt:3041.356\n",
      "Ep:82, loss:0.00003, loss_test:0.03526, lr:9.23e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.112, tt:3080.274\n",
      "Ep:83, loss:0.00003, loss_test:0.03486, lr:9.14e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.092, tt:3115.686\n",
      "Ep:84, loss:0.00003, loss_test:0.03637, lr:9.04e-03, fs:0.95192 (r=1.000,p=0.908),  time:37.091, tt:3152.730\n",
      "Ep:85, loss:0.00003, loss_test:0.03550, lr:8.95e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.073, tt:3188.262\n",
      "Ep:86, loss:0.00002, loss_test:0.03617, lr:8.86e-03, fs:0.96078 (r=0.990,p=0.933),  time:37.056, tt:3223.893\n",
      "Ep:87, loss:0.00002, loss_test:0.03236, lr:8.78e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.045, tt:3259.927\n",
      "Ep:88, loss:0.00002, loss_test:0.03742, lr:8.69e-03, fs:0.95567 (r=0.980,p=0.933),  time:37.030, tt:3295.654\n",
      "Ep:89, loss:0.00002, loss_test:0.03286, lr:8.60e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.031, tt:3332.745\n",
      "Ep:90, loss:0.00002, loss_test:0.03489, lr:8.51e-03, fs:0.96585 (r=1.000,p=0.934),  time:37.041, tt:3370.777\n",
      "Ep:91, loss:0.00002, loss_test:0.03412, lr:8.43e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.048, tt:3408.407\n",
      "Ep:92, loss:0.00002, loss_test:0.03441, lr:8.35e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.064, tt:3446.910\n",
      "Ep:93, loss:0.00002, loss_test:0.03307, lr:8.26e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.073, tt:3484.889\n",
      "Ep:94, loss:0.00002, loss_test:0.03478, lr:8.18e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.079, tt:3522.537\n",
      "Ep:95, loss:0.00002, loss_test:0.03347, lr:8.10e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.079, tt:3559.618\n",
      "Ep:96, loss:0.00002, loss_test:0.03409, lr:8.02e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.084, tt:3597.173\n",
      "Ep:97, loss:0.00002, loss_test:0.03337, lr:7.94e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.090, tt:3634.772\n",
      "Ep:98, loss:0.00002, loss_test:0.03578, lr:7.86e-03, fs:0.96552 (r=0.990,p=0.942),  time:37.090, tt:3671.923\n",
      "Ep:99, loss:0.00002, loss_test:0.03251, lr:7.78e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.080, tt:3707.965\n",
      "Ep:100, loss:0.00002, loss_test:0.03584, lr:7.70e-03, fs:0.96040 (r=0.980,p=0.942),  time:37.075, tt:3744.596\n",
      "Ep:101, loss:0.00002, loss_test:0.03276, lr:7.62e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.107, tt:3784.923\n",
      "Ep:102, loss:0.00002, loss_test:0.03468, lr:7.55e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.119, tt:3823.215\n",
      "Ep:103, loss:0.00002, loss_test:0.03269, lr:7.47e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.097, tt:3858.095\n",
      "Ep:104, loss:0.00002, loss_test:0.03325, lr:7.40e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.091, tt:3894.522\n",
      "Ep:105, loss:0.00002, loss_test:0.03329, lr:7.32e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.072, tt:3929.593\n",
      "Ep:106, loss:0.00002, loss_test:0.03298, lr:7.25e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.068, tt:3966.274\n",
      "Ep:107, loss:0.00002, loss_test:0.03312, lr:7.18e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.066, tt:4003.169\n",
      "Ep:108, loss:0.00002, loss_test:0.03331, lr:7.11e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.072, tt:4040.877\n",
      "Ep:109, loss:0.00002, loss_test:0.03283, lr:7.03e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.066, tt:4077.219\n",
      "Ep:110, loss:0.00001, loss_test:0.03403, lr:6.96e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.071, tt:4114.869\n",
      "Ep:111, loss:0.00001, loss_test:0.03217, lr:6.89e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.078, tt:4152.772\n",
      "Ep:112, loss:0.00001, loss_test:0.03339, lr:6.83e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.076, tt:4189.548\n",
      "Ep:113, loss:0.00001, loss_test:0.03237, lr:6.76e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.087, tt:4227.930\n",
      "Ep:114, loss:0.00001, loss_test:0.03250, lr:6.69e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.077, tt:4263.831\n",
      "Ep:115, loss:0.00001, loss_test:0.03283, lr:6.62e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.083, tt:4301.626\n",
      "Ep:116, loss:0.00001, loss_test:0.03178, lr:6.56e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.090, tt:4339.535\n",
      "Ep:117, loss:0.00001, loss_test:0.03340, lr:6.49e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.063, tt:4373.483\n",
      "Ep:118, loss:0.00001, loss_test:0.03215, lr:6.43e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.036, tt:4407.290\n",
      "Ep:119, loss:0.00001, loss_test:0.03252, lr:6.36e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.015, tt:4441.801\n",
      "Ep:120, loss:0.00001, loss_test:0.03299, lr:6.30e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.994, tt:4476.292\n",
      "Ep:121, loss:0.00001, loss_test:0.03213, lr:6.24e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.964, tt:4509.667\n",
      "Ep:122, loss:0.00001, loss_test:0.03245, lr:6.17e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.919, tt:4541.026\n",
      "Ep:123, loss:0.00001, loss_test:0.03232, lr:6.11e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.915, tt:4577.421\n",
      "Ep:124, loss:0.00001, loss_test:0.03231, lr:6.05e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.906, tt:4613.232\n",
      "Ep:125, loss:0.00001, loss_test:0.03234, lr:5.99e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.895, tt:4648.831\n",
      "Ep:126, loss:0.00001, loss_test:0.03198, lr:5.93e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.897, tt:4685.947\n",
      "Ep:127, loss:0.00001, loss_test:0.03293, lr:5.87e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.883, tt:4721.066\n",
      "Ep:128, loss:0.00001, loss_test:0.03212, lr:5.81e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.881, tt:4757.674\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.03277, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.872, tt:4793.418\n",
      "Ep:130, loss:0.00001, loss_test:0.03210, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.867, tt:4829.554\n",
      "Ep:131, loss:0.00001, loss_test:0.03191, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.861, tt:4865.685\n",
      "Ep:132, loss:0.00001, loss_test:0.03315, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.862, tt:4902.708\n",
      "Ep:133, loss:0.00001, loss_test:0.03215, lr:5.81e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.863, tt:4939.676\n",
      "Ep:134, loss:0.00001, loss_test:0.03321, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.859, tt:4975.911\n",
      "Ep:135, loss:0.00001, loss_test:0.03169, lr:5.81e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.863, tt:5013.302\n",
      "Ep:136, loss:0.00001, loss_test:0.03274, lr:5.81e-03, fs:0.96552 (r=0.990,p=0.942),  time:36.858, tt:5049.514\n",
      "Ep:137, loss:0.00001, loss_test:0.03190, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.870, tt:5088.116\n",
      "Ep:138, loss:0.00001, loss_test:0.03227, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.876, tt:5125.767\n",
      "Ep:139, loss:0.00001, loss_test:0.03179, lr:5.81e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.878, tt:5162.955\n",
      "Ep:140, loss:0.00001, loss_test:0.03171, lr:5.75e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.878, tt:5199.790\n",
      "Ep:141, loss:0.00001, loss_test:0.03173, lr:5.70e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.879, tt:5236.748\n",
      "Ep:142, loss:0.00001, loss_test:0.03213, lr:5.64e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.883, tt:5274.236\n",
      "Ep:143, loss:0.00001, loss_test:0.03146, lr:5.58e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.894, tt:5312.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.03244, lr:5.53e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.899, tt:5350.375\n",
      "Ep:145, loss:0.00001, loss_test:0.03153, lr:5.47e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.913, tt:5389.235\n",
      "Ep:146, loss:0.00001, loss_test:0.03216, lr:5.42e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.928, tt:5428.387\n",
      "Ep:147, loss:0.00001, loss_test:0.03164, lr:5.36e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.931, tt:5465.786\n",
      "Ep:148, loss:0.00001, loss_test:0.03215, lr:5.31e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.943, tt:5504.548\n",
      "Ep:149, loss:0.00001, loss_test:0.03146, lr:5.26e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.953, tt:5543.015\n",
      "Ep:150, loss:0.00001, loss_test:0.03210, lr:5.20e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.970, tt:5582.532\n",
      "Ep:151, loss:0.00001, loss_test:0.03153, lr:5.15e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.981, tt:5621.126\n",
      "Ep:152, loss:0.00001, loss_test:0.03161, lr:5.10e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.992, tt:5659.750\n",
      "Ep:153, loss:0.00001, loss_test:0.03254, lr:5.05e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.998, tt:5697.639\n",
      "Ep:154, loss:0.00001, loss_test:0.03113, lr:5.00e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.999, tt:5734.867\n",
      "Ep:155, loss:0.00001, loss_test:0.03246, lr:4.95e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.008, tt:5773.238\n",
      "Ep:156, loss:0.00001, loss_test:0.03202, lr:4.90e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.020, tt:5812.086\n",
      "Ep:157, loss:0.00001, loss_test:0.03154, lr:4.85e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.031, tt:5850.829\n",
      "Ep:158, loss:0.00001, loss_test:0.03180, lr:4.80e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.032, tt:5888.111\n",
      "Ep:159, loss:0.00001, loss_test:0.03192, lr:4.75e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.033, tt:5925.330\n",
      "Ep:160, loss:0.00001, loss_test:0.03175, lr:4.71e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.034, tt:5962.405\n",
      "Ep:161, loss:0.00001, loss_test:0.03159, lr:4.66e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.029, tt:5998.636\n",
      "Ep:162, loss:0.00001, loss_test:0.03222, lr:4.61e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.018, tt:6033.854\n",
      "Ep:163, loss:0.00001, loss_test:0.03156, lr:4.57e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.011, tt:6069.833\n",
      "Ep:164, loss:0.00001, loss_test:0.03199, lr:4.52e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.012, tt:6106.952\n",
      "Ep:165, loss:0.00001, loss_test:0.03169, lr:4.48e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.026, tt:6146.362\n",
      "Ep:166, loss:0.00001, loss_test:0.03189, lr:4.43e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.019, tt:6182.166\n",
      "Ep:167, loss:0.00001, loss_test:0.03138, lr:4.39e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.016, tt:6218.633\n",
      "Ep:168, loss:0.00001, loss_test:0.03183, lr:4.34e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.007, tt:6254.256\n",
      "Ep:169, loss:0.00001, loss_test:0.03137, lr:4.30e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.002, tt:6290.326\n",
      "Ep:170, loss:0.00001, loss_test:0.03172, lr:4.26e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.994, tt:6326.029\n",
      "Ep:171, loss:0.00001, loss_test:0.03144, lr:4.21e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.997, tt:6363.556\n",
      "Ep:172, loss:0.00001, loss_test:0.03156, lr:4.17e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.006, tt:6402.048\n",
      "Ep:173, loss:0.00001, loss_test:0.03185, lr:4.13e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.011, tt:6439.851\n",
      "Ep:174, loss:0.00001, loss_test:0.03141, lr:4.09e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.013, tt:6477.192\n",
      "Ep:175, loss:0.00001, loss_test:0.03177, lr:4.05e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.000, tt:6512.067\n",
      "Ep:176, loss:0.00001, loss_test:0.03131, lr:4.01e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.996, tt:6548.350\n",
      "Ep:177, loss:0.00001, loss_test:0.03145, lr:3.97e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.987, tt:6583.624\n",
      "Ep:178, loss:0.00001, loss_test:0.03167, lr:3.93e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.987, tt:6620.668\n",
      "Ep:179, loss:0.00001, loss_test:0.03162, lr:3.89e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.983, tt:6656.887\n",
      "Ep:180, loss:0.00001, loss_test:0.03136, lr:3.85e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.985, tt:6694.335\n",
      "Ep:181, loss:0.00001, loss_test:0.03147, lr:3.81e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.985, tt:6731.221\n",
      "Ep:182, loss:0.00001, loss_test:0.03166, lr:3.77e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.992, tt:6769.502\n",
      "Ep:183, loss:0.00001, loss_test:0.03136, lr:3.73e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.014, tt:6810.603\n",
      "Ep:184, loss:0.00001, loss_test:0.03168, lr:3.70e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.016, tt:6847.994\n",
      "Ep:185, loss:0.00001, loss_test:0.03131, lr:3.66e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.015, tt:6884.734\n",
      "Ep:186, loss:0.00001, loss_test:0.03153, lr:3.62e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.015, tt:6921.821\n",
      "Ep:187, loss:0.00001, loss_test:0.03142, lr:3.59e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.015, tt:6958.797\n",
      "Ep:188, loss:0.00001, loss_test:0.03137, lr:3.55e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.022, tt:6997.119\n",
      "Ep:189, loss:0.00001, loss_test:0.03132, lr:3.52e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.023, tt:7034.358\n",
      "Ep:190, loss:0.00001, loss_test:0.03167, lr:3.48e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.035, tt:7073.638\n",
      "Ep:191, loss:0.00001, loss_test:0.03125, lr:3.45e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.046, tt:7112.790\n",
      "Ep:192, loss:0.00001, loss_test:0.03153, lr:3.41e-03, fs:0.97059 (r=1.000,p=0.943),  time:37.052, tt:7151.098\n",
      "Ep:193, loss:0.00001, loss_test:0.03149, lr:3.38e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.040, tt:7185.701\n",
      "Ep:194, loss:0.00001, loss_test:0.03166, lr:3.34e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.043, tt:7223.399\n",
      "Ep:195, loss:0.00001, loss_test:0.03149, lr:3.31e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.045, tt:7260.909\n",
      "Ep:196, loss:0.00001, loss_test:0.03121, lr:3.28e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.052, tt:7299.199\n",
      "Ep:197, loss:0.00001, loss_test:0.03141, lr:3.24e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.052, tt:7336.366\n",
      "Ep:198, loss:0.00001, loss_test:0.03138, lr:3.21e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.047, tt:7372.340\n",
      "Ep:199, loss:0.00001, loss_test:0.03151, lr:3.18e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.047, tt:7409.409\n",
      "Ep:200, loss:0.00001, loss_test:0.03150, lr:3.15e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.054, tt:7447.936\n",
      "Ep:201, loss:0.00001, loss_test:0.03142, lr:3.12e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.055, tt:7485.099\n",
      "Ep:202, loss:0.00001, loss_test:0.03163, lr:3.09e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.053, tt:7521.681\n",
      "Ep:203, loss:0.00001, loss_test:0.03122, lr:3.05e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.063, tt:7560.836\n",
      "Ep:204, loss:0.00001, loss_test:0.03140, lr:3.02e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.072, tt:7599.775\n",
      "Ep:205, loss:0.00001, loss_test:0.03159, lr:2.99e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.080, tt:7638.556\n",
      "Ep:206, loss:0.00001, loss_test:0.03130, lr:2.96e-03, fs:0.97537 (r=1.000,p=0.952),  time:37.083, tt:7676.255\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02149, lr:6.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:35.649, tt:35.649\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02294, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:36.821, tt:73.643\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02414, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:36.877, tt:110.630\n",
      "Ep:3, loss:0.00005, loss_test:0.02348, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:36.312, tt:145.249\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00005, loss_test:0.02206, lr:6.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:35.519, tt:177.593\n",
      "Ep:5, loss:0.00004, loss_test:0.02083, lr:6.00e-02, fs:0.67925 (r=0.909,p=0.542),  time:35.106, tt:210.638\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.084, tt:245.591\n",
      "Ep:7, loss:0.00004, loss_test:0.01922, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:34.970, tt:279.762\n",
      "Ep:8, loss:0.00004, loss_test:0.01861, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:35.035, tt:315.312\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01829, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.911, tt:349.109\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01793, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.743, tt:382.175\n",
      "Ep:11, loss:0.00004, loss_test:0.01752, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.685, tt:416.223\n",
      "Ep:12, loss:0.00004, loss_test:0.01714, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:34.757, tt:451.847\n",
      "Ep:13, loss:0.00004, loss_test:0.01679, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:34.829, tt:487.605\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01649, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:34.891, tt:523.370\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:34.882, tt:558.115\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:34.867, tt:592.740\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01544, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:34.897, tt:628.138\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01511, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.932, tt:663.706\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01482, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.926, tt:698.515\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01452, lr:6.00e-02, fs:0.77912 (r=0.980,p=0.647),  time:34.965, tt:734.272\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01424, lr:6.00e-02, fs:0.77778 (r=0.990,p=0.641),  time:34.954, tt:768.985\n",
      "Ep:22, loss:0.00003, loss_test:0.01397, lr:6.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:34.939, tt:803.596\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01368, lr:6.00e-02, fs:0.78226 (r=0.980,p=0.651),  time:34.978, tt:839.465\n",
      "Ep:24, loss:0.00003, loss_test:0.01341, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:35.004, tt:875.101\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01325, lr:6.00e-02, fs:0.79668 (r=0.970,p=0.676),  time:35.048, tt:911.245\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01305, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:35.036, tt:945.973\n",
      "Ep:27, loss:0.00003, loss_test:0.01283, lr:6.00e-02, fs:0.80000 (r=0.970,p=0.681),  time:35.031, tt:980.872\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:35.094, tt:1017.715\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:35.133, tt:1053.986\n",
      "Ep:30, loss:0.00002, loss_test:0.01207, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:35.123, tt:1088.819\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01193, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:35.097, tt:1123.118\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01174, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:35.102, tt:1158.358\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01156, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:35.106, tt:1193.603\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01142, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:35.037, tt:1226.311\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01127, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:35.004, tt:1260.135\n",
      "Ep:36, loss:0.00002, loss_test:0.01115, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:35.009, tt:1295.322\n",
      "Ep:37, loss:0.00002, loss_test:0.01097, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.049, tt:1331.850\n",
      "Ep:38, loss:0.00002, loss_test:0.01090, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:35.035, tt:1366.346\n",
      "Ep:39, loss:0.00002, loss_test:0.01081, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:35.000, tt:1400.005\n",
      "Ep:40, loss:0.00002, loss_test:0.01070, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:35.019, tt:1435.776\n",
      "Ep:41, loss:0.00002, loss_test:0.01059, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.993, tt:1469.704\n",
      "Ep:42, loss:0.00002, loss_test:0.01048, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.980, tt:1504.155\n",
      "Ep:43, loss:0.00002, loss_test:0.01040, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.990, tt:1539.567\n",
      "Ep:44, loss:0.00002, loss_test:0.01031, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:35.047, tt:1577.134\n",
      "Ep:45, loss:0.00002, loss_test:0.01026, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:35.034, tt:1611.554\n",
      "Ep:46, loss:0.00002, loss_test:0.01013, lr:5.94e-02, fs:0.83929 (r=0.949,p=0.752),  time:35.012, tt:1645.545\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01005, lr:5.94e-02, fs:0.83929 (r=0.949,p=0.752),  time:34.999, tt:1679.972\n",
      "Ep:48, loss:0.00001, loss_test:0.00999, lr:5.94e-02, fs:0.83929 (r=0.949,p=0.752),  time:35.012, tt:1715.591\n",
      "Ep:49, loss:0.00001, loss_test:0.00996, lr:5.94e-02, fs:0.84305 (r=0.949,p=0.758),  time:35.016, tt:1750.782\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.00985, lr:5.94e-02, fs:0.85455 (r=0.949,p=0.777),  time:35.037, tt:1786.874\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.00984, lr:5.94e-02, fs:0.84685 (r=0.949,p=0.764),  time:35.028, tt:1821.431\n",
      "Ep:52, loss:0.00001, loss_test:0.00970, lr:5.94e-02, fs:0.86239 (r=0.949,p=0.790),  time:34.997, tt:1854.831\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.00966, lr:5.94e-02, fs:0.86239 (r=0.949,p=0.790),  time:34.999, tt:1889.959\n",
      "Ep:54, loss:0.00001, loss_test:0.00954, lr:5.94e-02, fs:0.85845 (r=0.949,p=0.783),  time:35.002, tt:1925.115\n",
      "Ep:55, loss:0.00001, loss_test:0.00952, lr:5.94e-02, fs:0.86512 (r=0.939,p=0.802),  time:35.002, tt:1960.134\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.00955, lr:5.94e-02, fs:0.87736 (r=0.939,p=0.823),  time:34.995, tt:1994.705\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.00945, lr:5.94e-02, fs:0.87736 (r=0.939,p=0.823),  time:35.006, tt:2030.366\n",
      "Ep:58, loss:0.00001, loss_test:0.00941, lr:5.94e-02, fs:0.87736 (r=0.939,p=0.823),  time:35.006, tt:2065.369\n",
      "Ep:59, loss:0.00001, loss_test:0.00935, lr:5.94e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.023, tt:2101.372\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.00925, lr:5.94e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.048, tt:2137.939\n",
      "Ep:61, loss:0.00001, loss_test:0.00929, lr:5.94e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.082, tt:2175.064\n",
      "Ep:62, loss:0.00001, loss_test:0.00925, lr:5.94e-02, fs:0.88571 (r=0.939,p=0.838),  time:35.054, tt:2208.378\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.00915, lr:5.94e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.100, tt:2246.425\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.00918, lr:5.94e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.109, tt:2282.083\n",
      "Ep:65, loss:0.00001, loss_test:0.00919, lr:5.94e-02, fs:0.88038 (r=0.929,p=0.836),  time:35.111, tt:2317.324\n",
      "Ep:66, loss:0.00001, loss_test:0.00910, lr:5.94e-02, fs:0.88038 (r=0.929,p=0.836),  time:35.116, tt:2352.756\n",
      "Ep:67, loss:0.00001, loss_test:0.00923, lr:5.94e-02, fs:0.88038 (r=0.929,p=0.836),  time:35.097, tt:2386.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.00912, lr:5.94e-02, fs:0.88462 (r=0.929,p=0.844),  time:35.087, tt:2420.990\n",
      "Ep:69, loss:0.00001, loss_test:0.00908, lr:5.94e-02, fs:0.88350 (r=0.919,p=0.850),  time:35.083, tt:2455.782\n",
      "Ep:70, loss:0.00001, loss_test:0.00901, lr:5.94e-02, fs:0.88350 (r=0.919,p=0.850),  time:35.065, tt:2489.590\n",
      "Ep:71, loss:0.00001, loss_test:0.00899, lr:5.94e-02, fs:0.88780 (r=0.919,p=0.858),  time:35.071, tt:2525.092\n",
      "Ep:72, loss:0.00001, loss_test:0.00904, lr:5.94e-02, fs:0.88780 (r=0.919,p=0.858),  time:35.075, tt:2560.444\n",
      "Ep:73, loss:0.00001, loss_test:0.00918, lr:5.94e-02, fs:0.88670 (r=0.909,p=0.865),  time:35.080, tt:2595.948\n",
      "Ep:74, loss:0.00001, loss_test:0.00949, lr:5.94e-02, fs:0.88670 (r=0.909,p=0.865),  time:35.093, tt:2631.988\n",
      "Ep:75, loss:0.00001, loss_test:0.00891, lr:5.88e-02, fs:0.89216 (r=0.919,p=0.867),  time:35.102, tt:2667.739\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.00899, lr:5.88e-02, fs:0.89655 (r=0.919,p=0.875),  time:35.122, tt:2704.399\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.00920, lr:5.88e-02, fs:0.88670 (r=0.909,p=0.865),  time:35.127, tt:2739.910\n",
      "Ep:78, loss:0.00001, loss_test:0.00923, lr:5.88e-02, fs:0.88670 (r=0.909,p=0.865),  time:35.139, tt:2775.946\n",
      "Ep:79, loss:0.00001, loss_test:0.00904, lr:5.88e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.159, tt:2812.741\n",
      "Ep:80, loss:0.00001, loss_test:0.00902, lr:5.88e-02, fs:0.90099 (r=0.919,p=0.883),  time:35.158, tt:2847.809\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.00918, lr:5.88e-02, fs:0.90099 (r=0.919,p=0.883),  time:35.173, tt:2884.179\n",
      "Ep:82, loss:0.00001, loss_test:0.00891, lr:5.88e-02, fs:0.90099 (r=0.919,p=0.883),  time:35.199, tt:2921.530\n",
      "Ep:83, loss:0.00001, loss_test:0.01081, lr:5.88e-02, fs:0.85024 (r=0.889,p=0.815),  time:35.215, tt:2958.072\n",
      "Ep:84, loss:0.00001, loss_test:0.00989, lr:5.88e-02, fs:0.90909 (r=0.960,p=0.864),  time:35.221, tt:2993.802\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01057, lr:5.88e-02, fs:0.83810 (r=0.889,p=0.793),  time:35.227, tt:3029.509\n",
      "Ep:86, loss:0.00001, loss_test:0.00873, lr:5.88e-02, fs:0.91866 (r=0.970,p=0.873),  time:35.234, tt:3065.381\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.00978, lr:5.88e-02, fs:0.85854 (r=0.889,p=0.830),  time:35.215, tt:3098.891\n",
      "Ep:88, loss:0.00001, loss_test:0.00865, lr:5.88e-02, fs:0.91787 (r=0.960,p=0.880),  time:35.236, tt:3136.014\n",
      "Ep:89, loss:0.00001, loss_test:0.00932, lr:5.88e-02, fs:0.87685 (r=0.899,p=0.856),  time:35.240, tt:3171.637\n",
      "Ep:90, loss:0.00001, loss_test:0.00868, lr:5.88e-02, fs:0.91707 (r=0.949,p=0.887),  time:35.254, tt:3208.150\n",
      "Ep:91, loss:0.00001, loss_test:0.00960, lr:5.88e-02, fs:0.87562 (r=0.889,p=0.863),  time:35.264, tt:3244.328\n",
      "Ep:92, loss:0.00001, loss_test:0.00877, lr:5.88e-02, fs:0.91000 (r=0.919,p=0.901),  time:35.278, tt:3280.815\n",
      "Ep:93, loss:0.00001, loss_test:0.00923, lr:5.88e-02, fs:0.88557 (r=0.899,p=0.873),  time:35.274, tt:3315.798\n",
      "Ep:94, loss:0.00001, loss_test:0.00885, lr:5.88e-02, fs:0.91000 (r=0.919,p=0.901),  time:35.269, tt:3350.566\n",
      "Ep:95, loss:0.00001, loss_test:0.00907, lr:5.88e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.261, tt:3385.036\n",
      "Ep:96, loss:0.00001, loss_test:0.00923, lr:5.88e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.256, tt:3419.830\n",
      "Ep:97, loss:0.00000, loss_test:0.00880, lr:5.88e-02, fs:0.91000 (r=0.919,p=0.901),  time:35.234, tt:3452.919\n",
      "Ep:98, loss:0.00000, loss_test:0.00907, lr:5.82e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.218, tt:3486.558\n",
      "Ep:99, loss:0.00000, loss_test:0.00899, lr:5.76e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.216, tt:3521.553\n",
      "Ep:100, loss:0.00000, loss_test:0.00906, lr:5.71e-02, fs:0.91000 (r=0.919,p=0.901),  time:35.212, tt:3556.406\n",
      "Ep:101, loss:0.00000, loss_test:0.00926, lr:5.65e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.221, tt:3592.509\n",
      "Ep:102, loss:0.00000, loss_test:0.00899, lr:5.59e-02, fs:0.91457 (r=0.919,p=0.910),  time:35.215, tt:3627.102\n",
      "Ep:103, loss:0.00000, loss_test:0.00934, lr:5.54e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.205, tt:3661.292\n",
      "Ep:104, loss:0.00000, loss_test:0.00936, lr:5.48e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.210, tt:3697.086\n",
      "Ep:105, loss:0.00000, loss_test:0.00927, lr:5.43e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.220, tt:3733.316\n",
      "Ep:106, loss:0.00000, loss_test:0.00934, lr:5.37e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.201, tt:3766.555\n",
      "Ep:107, loss:0.00000, loss_test:0.00938, lr:5.32e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.195, tt:3801.027\n",
      "Ep:108, loss:0.00000, loss_test:0.00952, lr:5.27e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.196, tt:3836.377\n",
      "Ep:109, loss:0.00000, loss_test:0.00931, lr:5.21e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.188, tt:3870.723\n",
      "Ep:110, loss:0.00000, loss_test:0.00959, lr:5.16e-02, fs:0.90355 (r=0.899,p=0.908),  time:35.181, tt:3905.078\n",
      "Ep:111, loss:0.00000, loss_test:0.00940, lr:5.11e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.197, tt:3942.008\n",
      "Ep:112, loss:0.00000, loss_test:0.00950, lr:5.06e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.191, tt:3976.591\n",
      "Ep:113, loss:0.00000, loss_test:0.00972, lr:5.01e-02, fs:0.90355 (r=0.899,p=0.908),  time:35.191, tt:4011.766\n",
      "Ep:114, loss:0.00000, loss_test:0.00961, lr:4.96e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.208, tt:4048.969\n",
      "Ep:115, loss:0.00000, loss_test:0.00960, lr:4.91e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.218, tt:4085.231\n",
      "Ep:116, loss:0.00000, loss_test:0.00984, lr:4.86e-02, fs:0.89231 (r=0.879,p=0.906),  time:35.219, tt:4120.658\n",
      "Ep:117, loss:0.00000, loss_test:0.00973, lr:4.81e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.228, tt:4156.925\n",
      "Ep:118, loss:0.00000, loss_test:0.00954, lr:4.76e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.225, tt:4191.791\n",
      "Ep:119, loss:0.00000, loss_test:0.01000, lr:4.71e-02, fs:0.88660 (r=0.869,p=0.905),  time:35.200, tt:4224.034\n",
      "Ep:120, loss:0.00000, loss_test:0.00966, lr:4.67e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.182, tt:4257.050\n",
      "Ep:121, loss:0.00000, loss_test:0.00973, lr:4.62e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.172, tt:4291.022\n",
      "Ep:122, loss:0.00000, loss_test:0.01009, lr:4.57e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.145, tt:4322.869\n",
      "Ep:123, loss:0.00000, loss_test:0.00973, lr:4.53e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.116, tt:4354.415\n",
      "Ep:124, loss:0.00000, loss_test:0.01001, lr:4.48e-02, fs:0.90256 (r=0.889,p=0.917),  time:35.068, tt:4383.522\n",
      "Ep:125, loss:0.00000, loss_test:0.00993, lr:4.44e-02, fs:0.90909 (r=0.909,p=0.909),  time:35.049, tt:4416.168\n",
      "Ep:126, loss:0.00000, loss_test:0.00997, lr:4.39e-02, fs:0.90355 (r=0.899,p=0.908),  time:35.004, tt:4445.489\n",
      "Ep:127, loss:0.00000, loss_test:0.01013, lr:4.35e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.941, tt:4472.513\n",
      "Ep:128, loss:0.00000, loss_test:0.00994, lr:4.31e-02, fs:0.90909 (r=0.909,p=0.909),  time:34.902, tt:4502.395\n",
      "Ep:129, loss:0.00000, loss_test:0.01002, lr:4.26e-02, fs:0.90816 (r=0.899,p=0.918),  time:34.895, tt:4536.351\n",
      "Ep:130, loss:0.00000, loss_test:0.01016, lr:4.22e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.884, tt:4569.822\n",
      "Ep:131, loss:0.00000, loss_test:0.01001, lr:4.18e-02, fs:0.90909 (r=0.909,p=0.909),  time:34.883, tt:4604.553\n",
      "Ep:132, loss:0.00000, loss_test:0.01028, lr:4.14e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.853, tt:4635.397\n",
      "Ep:133, loss:0.00000, loss_test:0.01017, lr:4.10e-02, fs:0.89691 (r=0.879,p=0.916),  time:34.832, tt:4667.441\n",
      "Ep:134, loss:0.00000, loss_test:0.01010, lr:4.05e-02, fs:0.90816 (r=0.899,p=0.918),  time:34.821, tt:4700.777\n",
      "Ep:135, loss:0.00000, loss_test:0.01030, lr:4.01e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.823, tt:4735.929\n",
      "Ep:136, loss:0.00000, loss_test:0.01030, lr:3.97e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.842, tt:4773.300\n",
      "Ep:137, loss:0.00000, loss_test:0.01033, lr:3.93e-02, fs:0.87368 (r=0.838,p=0.912),  time:34.858, tt:4810.459\n",
      "Ep:138, loss:0.00000, loss_test:0.01018, lr:3.89e-02, fs:0.91371 (r=0.909,p=0.918),  time:34.865, tt:4846.177\n",
      "Ep:139, loss:0.00000, loss_test:0.01054, lr:3.86e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.879, tt:4883.044\n",
      "Ep:140, loss:0.00000, loss_test:0.01037, lr:3.82e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.879, tt:4917.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.01029, lr:3.78e-02, fs:0.90256 (r=0.889,p=0.917),  time:34.890, tt:4954.348\n",
      "Ep:142, loss:0.00000, loss_test:0.01062, lr:3.74e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.881, tt:4988.020\n",
      "Ep:143, loss:0.00000, loss_test:0.01038, lr:3.70e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.887, tt:5023.660\n",
      "Ep:144, loss:0.00000, loss_test:0.01048, lr:3.67e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.886, tt:5058.406\n",
      "Ep:145, loss:0.00000, loss_test:0.01064, lr:3.63e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.890, tt:5094.001\n",
      "Ep:146, loss:0.00000, loss_test:0.01042, lr:3.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:34.894, tt:5129.453\n",
      "Ep:147, loss:0.00000, loss_test:0.01064, lr:3.56e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.897, tt:5164.705\n",
      "Ep:148, loss:0.00000, loss_test:0.01052, lr:3.52e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.900, tt:5200.140\n",
      "Ep:149, loss:0.00000, loss_test:0.01053, lr:3.49e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.917, tt:5237.496\n",
      "Ep:150, loss:0.00000, loss_test:0.01084, lr:3.45e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.929, tt:5274.343\n",
      "Ep:151, loss:0.00000, loss_test:0.01052, lr:3.42e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.925, tt:5308.603\n",
      "Ep:152, loss:0.00000, loss_test:0.01073, lr:3.38e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.938, tt:5345.540\n",
      "Ep:153, loss:0.00000, loss_test:0.01047, lr:3.35e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.952, tt:5382.627\n",
      "Ep:154, loss:0.00000, loss_test:0.01076, lr:3.32e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.961, tt:5418.906\n",
      "Ep:155, loss:0.00000, loss_test:0.01062, lr:3.28e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.975, tt:5456.073\n",
      "Ep:156, loss:0.00000, loss_test:0.01065, lr:3.25e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.980, tt:5491.936\n",
      "Ep:157, loss:0.00000, loss_test:0.01070, lr:3.22e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.985, tt:5527.595\n",
      "Ep:158, loss:0.00000, loss_test:0.01067, lr:3.19e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.989, tt:5563.186\n",
      "Ep:159, loss:0.00000, loss_test:0.01078, lr:3.15e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.001, tt:5600.213\n",
      "Ep:160, loss:0.00000, loss_test:0.01075, lr:3.12e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.992, tt:5633.769\n",
      "Ep:161, loss:0.00000, loss_test:0.01087, lr:3.09e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.004, tt:5670.688\n",
      "Ep:162, loss:0.00000, loss_test:0.01085, lr:3.06e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.013, tt:5707.059\n",
      "Ep:163, loss:0.00000, loss_test:0.01087, lr:3.03e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.027, tt:5744.358\n",
      "Ep:164, loss:0.00000, loss_test:0.01089, lr:3.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.028, tt:5779.564\n",
      "Ep:165, loss:0.00000, loss_test:0.01090, lr:2.97e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.033, tt:5815.427\n",
      "Ep:166, loss:0.00000, loss_test:0.01093, lr:2.94e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.029, tt:5849.904\n",
      "Ep:167, loss:0.00000, loss_test:0.01092, lr:2.91e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.031, tt:5885.287\n",
      "Ep:168, loss:0.00000, loss_test:0.01094, lr:2.88e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.031, tt:5920.194\n",
      "Ep:169, loss:0.00000, loss_test:0.01092, lr:2.85e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.039, tt:5956.558\n",
      "Ep:170, loss:0.00000, loss_test:0.01113, lr:2.82e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.048, tt:5993.289\n",
      "Ep:171, loss:0.00000, loss_test:0.01094, lr:2.80e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.046, tt:6027.923\n",
      "Ep:172, loss:0.00000, loss_test:0.01110, lr:2.77e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.053, tt:6064.210\n",
      "Ep:173, loss:0.00000, loss_test:0.01100, lr:2.74e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.060, tt:6100.482\n",
      "Ep:174, loss:0.00000, loss_test:0.01106, lr:2.71e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.068, tt:6136.838\n",
      "Ep:175, loss:0.00000, loss_test:0.01107, lr:2.69e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.077, tt:6173.482\n",
      "Ep:176, loss:0.00000, loss_test:0.01114, lr:2.66e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.075, tt:6208.210\n",
      "Ep:177, loss:0.00000, loss_test:0.01109, lr:2.63e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.073, tt:6242.948\n",
      "Ep:178, loss:0.00000, loss_test:0.01110, lr:2.61e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.078, tt:6278.972\n",
      "Ep:179, loss:0.00000, loss_test:0.01115, lr:2.58e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.093, tt:6316.703\n",
      "Ep:180, loss:0.00000, loss_test:0.01117, lr:2.55e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.100, tt:6353.062\n",
      "Ep:181, loss:0.00000, loss_test:0.01119, lr:2.53e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.105, tt:6389.186\n",
      "Ep:182, loss:0.00000, loss_test:0.01114, lr:2.50e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.106, tt:6424.487\n",
      "Ep:183, loss:0.00000, loss_test:0.01123, lr:2.48e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.106, tt:6459.482\n",
      "Ep:184, loss:0.00000, loss_test:0.01123, lr:2.45e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.111, tt:6495.589\n",
      "Ep:185, loss:0.00000, loss_test:0.01126, lr:2.43e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.117, tt:6531.776\n",
      "Ep:186, loss:0.00000, loss_test:0.01120, lr:2.40e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.122, tt:6567.728\n",
      "Ep:187, loss:0.00000, loss_test:0.01135, lr:2.38e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.120, tt:6602.571\n",
      "Ep:188, loss:0.00000, loss_test:0.01119, lr:2.36e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.128, tt:6639.281\n",
      "Ep:189, loss:0.00000, loss_test:0.01135, lr:2.33e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.138, tt:6676.181\n",
      "Ep:190, loss:0.00000, loss_test:0.01123, lr:2.31e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.143, tt:6712.356\n",
      "Ep:191, loss:0.00000, loss_test:0.01138, lr:2.29e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.153, tt:6749.446\n",
      "Ep:192, loss:0.00000, loss_test:0.01123, lr:2.26e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.164, tt:6786.591\n",
      "Ep:193, loss:0.00000, loss_test:0.01140, lr:2.24e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.161, tt:6821.303\n",
      "Ep:194, loss:0.00000, loss_test:0.01129, lr:2.22e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.165, tt:6857.271\n",
      "Ep:195, loss:0.00000, loss_test:0.01136, lr:2.20e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.169, tt:6893.172\n",
      "Ep:196, loss:0.00000, loss_test:0.01138, lr:2.17e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.174, tt:6929.335\n",
      "Ep:197, loss:0.00000, loss_test:0.01138, lr:2.15e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.176, tt:6964.850\n",
      "Ep:198, loss:0.00000, loss_test:0.01128, lr:2.13e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.179, tt:7000.628\n",
      "Ep:199, loss:0.00000, loss_test:0.01147, lr:2.11e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.186, tt:7037.196\n",
      "Ep:200, loss:0.00000, loss_test:0.01135, lr:2.09e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.189, tt:7073.006\n",
      "Ep:201, loss:0.00000, loss_test:0.01143, lr:2.07e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.189, tt:7108.162\n",
      "Ep:202, loss:0.00000, loss_test:0.01145, lr:2.05e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.190, tt:7143.478\n",
      "Ep:203, loss:0.00000, loss_test:0.01137, lr:2.03e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.202, tt:7181.264\n",
      "Ep:204, loss:0.00000, loss_test:0.01140, lr:2.01e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.213, tt:7218.723\n",
      "Ep:205, loss:0.00000, loss_test:0.01148, lr:1.99e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.221, tt:7255.471\n",
      "Ep:206, loss:0.00000, loss_test:0.01144, lr:1.97e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.230, tt:7292.682\n",
      "Ep:207, loss:0.00000, loss_test:0.01147, lr:1.95e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.225, tt:7326.845\n",
      "Ep:208, loss:0.00000, loss_test:0.01147, lr:1.93e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.230, tt:7363.152\n",
      "Ep:209, loss:0.00000, loss_test:0.01147, lr:1.91e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.231, tt:7398.453\n",
      "Ep:210, loss:0.00000, loss_test:0.01149, lr:1.89e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.234, tt:7434.373\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13330, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:35.421, tt:35.421\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00027, loss_test:0.12909, lr:1.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:35.264, tt:70.527\n",
      "Ep:2, loss:0.00026, loss_test:0.12329, lr:1.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:35.140, tt:105.419\n",
      "Ep:3, loss:0.00025, loss_test:0.11946, lr:1.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:35.209, tt:140.834\n",
      "Ep:4, loss:0.00025, loss_test:0.11796, lr:1.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:35.062, tt:175.308\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11600, lr:1.00e-02, fs:0.67532 (r=0.788,p=0.591),  time:35.211, tt:211.265\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11424, lr:1.00e-02, fs:0.67532 (r=0.788,p=0.591),  time:35.212, tt:246.483\n",
      "Ep:7, loss:0.00024, loss_test:0.11256, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:35.321, tt:282.570\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11122, lr:1.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:35.383, tt:318.443\n",
      "Ep:9, loss:0.00023, loss_test:0.10871, lr:1.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:35.525, tt:355.250\n",
      "Ep:10, loss:0.00022, loss_test:0.10529, lr:1.00e-02, fs:0.69643 (r=0.788,p=0.624),  time:35.341, tt:388.750\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10274, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:35.380, tt:424.556\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10163, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:35.441, tt:460.730\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10003, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:35.488, tt:496.827\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.09762, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:35.451, tt:531.760\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09523, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:35.514, tt:568.231\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09390, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:35.565, tt:604.602\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09066, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:35.592, tt:640.665\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.08758, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:35.601, tt:676.428\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.08653, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:35.588, tt:711.759\n",
      "Ep:20, loss:0.00018, loss_test:0.08411, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:35.619, tt:747.991\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.08144, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:35.639, tt:784.068\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.08025, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.728, tt:821.736\n",
      "Ep:23, loss:0.00016, loss_test:0.07842, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:35.885, tt:861.246\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.07711, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:35.956, tt:898.903\n",
      "Ep:25, loss:0.00015, loss_test:0.07610, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:35.998, tt:935.938\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.07376, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:36.065, tt:973.748\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.07284, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:36.115, tt:1011.223\n",
      "Ep:28, loss:0.00014, loss_test:0.07106, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:36.148, tt:1048.278\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.06881, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:36.064, tt:1081.935\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.06910, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:36.039, tt:1117.197\n",
      "Ep:31, loss:0.00013, loss_test:0.06609, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:36.024, tt:1152.769\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.06621, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:35.992, tt:1187.735\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06495, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:36.017, tt:1224.579\n",
      "Ep:34, loss:0.00012, loss_test:0.06231, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:36.008, tt:1260.271\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.06352, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.979, tt:1295.237\n",
      "Ep:36, loss:0.00011, loss_test:0.06099, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:35.984, tt:1331.393\n",
      "Ep:37, loss:0.00010, loss_test:0.05995, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.986, tt:1367.484\n",
      "Ep:38, loss:0.00010, loss_test:0.05963, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:36.047, tt:1405.832\n",
      "Ep:39, loss:0.00010, loss_test:0.05739, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:36.050, tt:1442.006\n",
      "Ep:40, loss:0.00009, loss_test:0.05864, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:36.032, tt:1477.315\n",
      "Ep:41, loss:0.00009, loss_test:0.05788, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:36.052, tt:1514.187\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.05495, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:36.059, tt:1550.558\n",
      "Ep:43, loss:0.00009, loss_test:0.05537, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:36.055, tt:1586.421\n",
      "Ep:44, loss:0.00008, loss_test:0.05527, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:36.006, tt:1620.268\n",
      "Ep:45, loss:0.00008, loss_test:0.05326, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:36.023, tt:1657.055\n",
      "Ep:46, loss:0.00008, loss_test:0.05459, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:36.026, tt:1693.201\n",
      "Ep:47, loss:0.00008, loss_test:0.05164, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:36.046, tt:1730.192\n",
      "Ep:48, loss:0.00008, loss_test:0.05169, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:36.036, tt:1765.755\n",
      "Ep:49, loss:0.00007, loss_test:0.05283, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:36.033, tt:1801.626\n",
      "Ep:50, loss:0.00007, loss_test:0.04949, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:36.017, tt:1836.862\n",
      "Ep:51, loss:0.00007, loss_test:0.05077, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:36.033, tt:1873.725\n",
      "Ep:52, loss:0.00007, loss_test:0.05787, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:36.032, tt:1909.708\n",
      "Ep:53, loss:0.00007, loss_test:0.05107, lr:9.90e-03, fs:0.93720 (r=0.980,p=0.898),  time:36.054, tt:1946.927\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.04971, lr:9.90e-03, fs:0.87963 (r=0.960,p=0.812),  time:36.059, tt:1983.228\n",
      "Ep:55, loss:0.00007, loss_test:0.05141, lr:9.90e-03, fs:0.89100 (r=0.949,p=0.839),  time:36.073, tt:2020.075\n",
      "Ep:56, loss:0.00006, loss_test:0.04956, lr:9.90e-03, fs:0.89100 (r=0.949,p=0.839),  time:36.034, tt:2053.922\n",
      "Ep:57, loss:0.00006, loss_test:0.04766, lr:9.90e-03, fs:0.89498 (r=0.990,p=0.817),  time:36.027, tt:2089.587\n",
      "Ep:58, loss:0.00006, loss_test:0.04843, lr:9.90e-03, fs:0.89100 (r=0.949,p=0.839),  time:36.004, tt:2124.213\n",
      "Ep:59, loss:0.00006, loss_test:0.04822, lr:9.90e-03, fs:0.87850 (r=0.949,p=0.817),  time:36.012, tt:2160.725\n",
      "Ep:60, loss:0.00005, loss_test:0.04753, lr:9.90e-03, fs:0.89623 (r=0.960,p=0.841),  time:35.985, tt:2195.100\n",
      "Ep:61, loss:0.00005, loss_test:0.04611, lr:9.90e-03, fs:0.92891 (r=0.990,p=0.875),  time:35.978, tt:2230.643\n",
      "Ep:62, loss:0.00005, loss_test:0.05071, lr:9.90e-03, fs:0.87324 (r=0.939,p=0.816),  time:35.975, tt:2266.446\n",
      "Ep:63, loss:0.00006, loss_test:0.05331, lr:9.90e-03, fs:0.87500 (r=0.919,p=0.835),  time:35.941, tt:2300.204\n",
      "Ep:64, loss:0.00005, loss_test:0.04606, lr:9.90e-03, fs:0.92891 (r=0.990,p=0.875),  time:35.937, tt:2335.899\n",
      "Ep:65, loss:0.00005, loss_test:0.04702, lr:9.80e-03, fs:0.89202 (r=0.960,p=0.833),  time:35.951, tt:2372.756\n",
      "Ep:66, loss:0.00005, loss_test:0.04935, lr:9.70e-03, fs:0.88571 (r=0.939,p=0.838),  time:35.930, tt:2407.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00005, loss_test:0.04597, lr:9.61e-03, fs:0.92891 (r=0.990,p=0.875),  time:35.935, tt:2443.574\n",
      "Ep:68, loss:0.00005, loss_test:0.04626, lr:9.51e-03, fs:0.88995 (r=0.939,p=0.845),  time:35.924, tt:2478.761\n",
      "Ep:69, loss:0.00004, loss_test:0.04495, lr:9.41e-03, fs:0.92453 (r=0.990,p=0.867),  time:35.900, tt:2512.999\n",
      "Ep:70, loss:0.00004, loss_test:0.04696, lr:9.32e-03, fs:0.88571 (r=0.939,p=0.838),  time:35.876, tt:2547.223\n",
      "Ep:71, loss:0.00005, loss_test:0.05217, lr:9.23e-03, fs:0.88263 (r=0.949,p=0.825),  time:35.864, tt:2582.230\n",
      "Ep:72, loss:0.00004, loss_test:0.04374, lr:9.14e-03, fs:0.92823 (r=0.980,p=0.882),  time:35.886, tt:2619.666\n",
      "Ep:73, loss:0.00005, loss_test:0.04718, lr:9.04e-03, fs:0.88995 (r=0.939,p=0.845),  time:35.885, tt:2655.482\n",
      "Ep:74, loss:0.00004, loss_test:0.04529, lr:8.95e-03, fs:0.90476 (r=0.960,p=0.856),  time:35.878, tt:2690.878\n",
      "Ep:75, loss:0.00004, loss_test:0.04323, lr:8.86e-03, fs:0.92381 (r=0.980,p=0.874),  time:35.906, tt:2728.874\n",
      "Ep:76, loss:0.00004, loss_test:0.04676, lr:8.78e-03, fs:0.89524 (r=0.949,p=0.847),  time:35.891, tt:2763.581\n",
      "Ep:77, loss:0.00004, loss_test:0.04536, lr:8.69e-03, fs:0.90385 (r=0.949,p=0.862),  time:35.921, tt:2801.831\n",
      "Ep:78, loss:0.00004, loss_test:0.04516, lr:8.60e-03, fs:0.89524 (r=0.949,p=0.847),  time:35.926, tt:2838.178\n",
      "Ep:79, loss:0.00003, loss_test:0.04372, lr:8.51e-03, fs:0.91346 (r=0.960,p=0.872),  time:35.939, tt:2875.089\n",
      "Ep:80, loss:0.00003, loss_test:0.04384, lr:8.43e-03, fs:0.89952 (r=0.949,p=0.855),  time:35.953, tt:2912.160\n",
      "Ep:81, loss:0.00003, loss_test:0.04384, lr:8.35e-03, fs:0.89855 (r=0.939,p=0.861),  time:35.958, tt:2948.572\n",
      "Ep:82, loss:0.00003, loss_test:0.04380, lr:8.26e-03, fs:0.91866 (r=0.970,p=0.873),  time:35.958, tt:2984.530\n",
      "Ep:83, loss:0.00003, loss_test:0.04777, lr:8.18e-03, fs:0.89100 (r=0.949,p=0.839),  time:35.949, tt:3019.697\n",
      "Ep:84, loss:0.00003, loss_test:0.04280, lr:8.10e-03, fs:0.93269 (r=0.980,p=0.890),  time:35.961, tt:3056.679\n",
      "Ep:85, loss:0.00003, loss_test:0.04567, lr:8.02e-03, fs:0.88679 (r=0.949,p=0.832),  time:35.972, tt:3093.631\n",
      "Ep:86, loss:0.00003, loss_test:0.04217, lr:7.94e-03, fs:0.92381 (r=0.980,p=0.874),  time:35.973, tt:3129.678\n",
      "Ep:87, loss:0.00003, loss_test:0.04701, lr:7.86e-03, fs:0.88462 (r=0.929,p=0.844),  time:36.000, tt:3167.974\n",
      "Ep:88, loss:0.00003, loss_test:0.04319, lr:7.78e-03, fs:0.91787 (r=0.960,p=0.880),  time:36.015, tt:3205.358\n",
      "Ep:89, loss:0.00003, loss_test:0.04448, lr:7.70e-03, fs:0.90047 (r=0.960,p=0.848),  time:36.044, tt:3243.977\n",
      "Ep:90, loss:0.00003, loss_test:0.05052, lr:7.62e-03, fs:0.83168 (r=0.848,p=0.816),  time:36.033, tt:3279.043\n",
      "Ep:91, loss:0.00004, loss_test:0.04258, lr:7.55e-03, fs:0.92381 (r=0.980,p=0.874),  time:36.028, tt:3314.618\n",
      "Ep:92, loss:0.00003, loss_test:0.04209, lr:7.47e-03, fs:0.91943 (r=0.980,p=0.866),  time:36.031, tt:3350.917\n",
      "Ep:93, loss:0.00003, loss_test:0.04479, lr:7.40e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.044, tt:3388.116\n",
      "Ep:94, loss:0.00003, loss_test:0.04230, lr:7.32e-03, fs:0.92453 (r=0.990,p=0.867),  time:36.071, tt:3426.739\n",
      "Ep:95, loss:0.00003, loss_test:0.04633, lr:7.25e-03, fs:0.85279 (r=0.848,p=0.857),  time:36.063, tt:3462.069\n",
      "Ep:96, loss:0.00003, loss_test:0.04307, lr:7.18e-03, fs:0.91429 (r=0.970,p=0.865),  time:36.057, tt:3497.564\n",
      "Ep:97, loss:0.00003, loss_test:0.04618, lr:7.11e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.062, tt:3534.116\n",
      "Ep:98, loss:0.00003, loss_test:0.04229, lr:7.03e-03, fs:0.92381 (r=0.980,p=0.874),  time:36.045, tt:3568.468\n",
      "Ep:99, loss:0.00003, loss_test:0.04536, lr:6.96e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.056, tt:3605.570\n",
      "Ep:100, loss:0.00003, loss_test:0.04069, lr:6.89e-03, fs:0.92891 (r=0.990,p=0.875),  time:36.045, tt:3640.535\n",
      "Ep:101, loss:0.00003, loss_test:0.04405, lr:6.83e-03, fs:0.85864 (r=0.828,p=0.891),  time:36.037, tt:3675.770\n",
      "Ep:102, loss:0.00002, loss_test:0.04149, lr:6.76e-03, fs:0.92157 (r=0.949,p=0.895),  time:36.031, tt:3711.185\n",
      "Ep:103, loss:0.00002, loss_test:0.04245, lr:6.69e-03, fs:0.88325 (r=0.879,p=0.888),  time:36.036, tt:3747.701\n",
      "Ep:104, loss:0.00002, loss_test:0.04194, lr:6.62e-03, fs:0.89447 (r=0.899,p=0.890),  time:36.062, tt:3786.495\n",
      "Ep:105, loss:0.00002, loss_test:0.04199, lr:6.56e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.077, tt:3824.163\n",
      "Ep:106, loss:0.00002, loss_test:0.04414, lr:6.49e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.092, tt:3861.806\n",
      "Ep:107, loss:0.00002, loss_test:0.04237, lr:6.43e-03, fs:0.87310 (r=0.869,p=0.878),  time:36.103, tt:3899.097\n",
      "Ep:108, loss:0.00002, loss_test:0.04323, lr:6.36e-03, fs:0.87047 (r=0.848,p=0.894),  time:36.103, tt:3935.251\n",
      "Ep:109, loss:0.00002, loss_test:0.04208, lr:6.30e-03, fs:0.88889 (r=0.889,p=0.889),  time:36.111, tt:3972.194\n",
      "Ep:110, loss:0.00002, loss_test:0.04229, lr:6.24e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.109, tt:4008.139\n",
      "Ep:111, loss:0.00002, loss_test:0.04243, lr:6.17e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.093, tt:4042.395\n",
      "Ep:112, loss:0.00002, loss_test:0.04215, lr:6.11e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.088, tt:4077.950\n",
      "Ep:113, loss:0.00002, loss_test:0.04374, lr:6.05e-03, fs:0.85864 (r=0.828,p=0.891),  time:36.100, tt:4115.441\n",
      "Ep:114, loss:0.00002, loss_test:0.04188, lr:5.99e-03, fs:0.89231 (r=0.879,p=0.906),  time:36.085, tt:4149.773\n",
      "Ep:115, loss:0.00002, loss_test:0.04355, lr:5.93e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.082, tt:4185.536\n",
      "Ep:116, loss:0.00002, loss_test:0.04194, lr:5.87e-03, fs:0.89231 (r=0.879,p=0.906),  time:36.080, tt:4221.360\n",
      "Ep:117, loss:0.00002, loss_test:0.04413, lr:5.81e-03, fs:0.85417 (r=0.828,p=0.882),  time:36.095, tt:4259.252\n",
      "Ep:118, loss:0.00002, loss_test:0.04232, lr:5.75e-03, fs:0.88083 (r=0.859,p=0.904),  time:36.084, tt:4294.044\n",
      "Ep:119, loss:0.00002, loss_test:0.04299, lr:5.70e-03, fs:0.86598 (r=0.848,p=0.884),  time:36.067, tt:4327.989\n",
      "Ep:120, loss:0.00002, loss_test:0.04336, lr:5.64e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.038, tt:4360.612\n",
      "Ep:121, loss:0.00002, loss_test:0.04112, lr:5.58e-03, fs:0.89340 (r=0.889,p=0.898),  time:36.007, tt:4392.883\n",
      "Ep:122, loss:0.00002, loss_test:0.04418, lr:5.53e-03, fs:0.86458 (r=0.838,p=0.892),  time:35.993, tt:4427.090\n",
      "Ep:123, loss:0.00002, loss_test:0.04141, lr:5.47e-03, fs:0.88776 (r=0.879,p=0.897),  time:35.965, tt:4459.645\n",
      "Ep:124, loss:0.00002, loss_test:0.04454, lr:5.42e-03, fs:0.85864 (r=0.828,p=0.891),  time:35.922, tt:4490.293\n",
      "Ep:125, loss:0.00002, loss_test:0.04168, lr:5.36e-03, fs:0.89231 (r=0.879,p=0.906),  time:35.894, tt:4522.616\n",
      "Ep:126, loss:0.00002, loss_test:0.04417, lr:5.31e-03, fs:0.85417 (r=0.828,p=0.882),  time:35.897, tt:4558.929\n",
      "Ep:127, loss:0.00002, loss_test:0.04126, lr:5.26e-03, fs:0.89231 (r=0.879,p=0.906),  time:35.899, tt:4595.019\n",
      "Ep:128, loss:0.00002, loss_test:0.04394, lr:5.20e-03, fs:0.85864 (r=0.828,p=0.891),  time:35.903, tt:4631.429\n",
      "Ep:129, loss:0.00002, loss_test:0.04081, lr:5.15e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.887, tt:4665.345\n",
      "Ep:130, loss:0.00002, loss_test:0.04497, lr:5.10e-03, fs:0.85864 (r=0.828,p=0.891),  time:35.867, tt:4698.571\n",
      "Ep:131, loss:0.00002, loss_test:0.04116, lr:5.05e-03, fs:0.88776 (r=0.879,p=0.897),  time:35.874, tt:4735.402\n",
      "Ep:132, loss:0.00002, loss_test:0.04268, lr:5.00e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.871, tt:4770.819\n",
      "Ep:133, loss:0.00002, loss_test:0.04183, lr:4.95e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.871, tt:4806.779\n",
      "Ep:134, loss:0.00002, loss_test:0.04289, lr:4.90e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.876, tt:4843.320\n",
      "Ep:135, loss:0.00002, loss_test:0.04183, lr:4.85e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.880, tt:4879.634\n",
      "Ep:136, loss:0.00002, loss_test:0.04272, lr:4.80e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.878, tt:4915.254\n",
      "Ep:137, loss:0.00002, loss_test:0.04175, lr:4.75e-03, fs:0.87629 (r=0.859,p=0.895),  time:35.885, tt:4952.061\n",
      "Ep:138, loss:0.00002, loss_test:0.04349, lr:4.71e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.891, tt:4988.832\n",
      "Ep:139, loss:0.00002, loss_test:0.04140, lr:4.66e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.892, tt:5024.913\n",
      "Ep:140, loss:0.00002, loss_test:0.04300, lr:4.61e-03, fs:0.86911 (r=0.838,p=0.902),  time:35.896, tt:5061.350\n",
      "Ep:141, loss:0.00001, loss_test:0.04098, lr:4.57e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.905, tt:5098.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.04358, lr:4.52e-03, fs:0.85864 (r=0.828,p=0.891),  time:35.912, tt:5135.436\n",
      "Ep:143, loss:0.00001, loss_test:0.04094, lr:4.48e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.922, tt:5172.807\n",
      "Ep:144, loss:0.00001, loss_test:0.04367, lr:4.43e-03, fs:0.86316 (r=0.828,p=0.901),  time:35.931, tt:5209.950\n",
      "Ep:145, loss:0.00001, loss_test:0.04114, lr:4.39e-03, fs:0.89231 (r=0.879,p=0.906),  time:35.942, tt:5247.592\n",
      "Ep:146, loss:0.00001, loss_test:0.04323, lr:4.34e-03, fs:0.87047 (r=0.848,p=0.894),  time:35.950, tt:5284.671\n",
      "Ep:147, loss:0.00001, loss_test:0.04148, lr:4.30e-03, fs:0.88776 (r=0.879,p=0.897),  time:35.951, tt:5320.678\n",
      "Ep:148, loss:0.00001, loss_test:0.04250, lr:4.26e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.950, tt:5356.529\n",
      "Ep:149, loss:0.00001, loss_test:0.04195, lr:4.21e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.952, tt:5392.860\n",
      "Ep:150, loss:0.00001, loss_test:0.04229, lr:4.17e-03, fs:0.89231 (r=0.879,p=0.906),  time:35.961, tt:5430.169\n",
      "Ep:151, loss:0.00001, loss_test:0.04235, lr:4.13e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.953, tt:5464.900\n",
      "Ep:152, loss:0.00001, loss_test:0.04249, lr:4.09e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.955, tt:5501.123\n",
      "Ep:153, loss:0.00001, loss_test:0.04273, lr:4.05e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.951, tt:5536.465\n",
      "Ep:154, loss:0.00001, loss_test:0.04229, lr:4.01e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.945, tt:5571.538\n",
      "Ep:155, loss:0.00001, loss_test:0.04258, lr:3.97e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.955, tt:5609.029\n",
      "Ep:156, loss:0.00001, loss_test:0.04238, lr:3.93e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.966, tt:5646.624\n",
      "Ep:157, loss:0.00001, loss_test:0.04209, lr:3.89e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.967, tt:5682.855\n",
      "Ep:158, loss:0.00001, loss_test:0.04271, lr:3.85e-03, fs:0.89231 (r=0.879,p=0.906),  time:35.961, tt:5717.733\n",
      "Ep:159, loss:0.00001, loss_test:0.04273, lr:3.81e-03, fs:0.88542 (r=0.859,p=0.914),  time:35.960, tt:5753.671\n",
      "Ep:160, loss:0.00001, loss_test:0.04289, lr:3.77e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.966, tt:5790.605\n",
      "Ep:161, loss:0.00001, loss_test:0.04292, lr:3.73e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.967, tt:5826.608\n",
      "Ep:162, loss:0.00001, loss_test:0.04229, lr:3.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.964, tt:5862.167\n",
      "Ep:163, loss:0.00001, loss_test:0.04326, lr:3.66e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.963, tt:5897.926\n",
      "Ep:164, loss:0.00001, loss_test:0.04252, lr:3.62e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.959, tt:5933.176\n",
      "Ep:165, loss:0.00001, loss_test:0.04346, lr:3.59e-03, fs:0.87500 (r=0.848,p=0.903),  time:35.962, tt:5969.635\n",
      "Ep:166, loss:0.00001, loss_test:0.04222, lr:3.55e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.965, tt:6006.194\n",
      "Ep:167, loss:0.00001, loss_test:0.04373, lr:3.52e-03, fs:0.88542 (r=0.859,p=0.914),  time:35.958, tt:6041.009\n",
      "Ep:168, loss:0.00001, loss_test:0.04282, lr:3.48e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.955, tt:6076.452\n",
      "Ep:169, loss:0.00001, loss_test:0.04284, lr:3.45e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.954, tt:6112.169\n",
      "Ep:170, loss:0.00001, loss_test:0.04338, lr:3.41e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.948, tt:6147.078\n",
      "Ep:171, loss:0.00001, loss_test:0.04268, lr:3.38e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.948, tt:6183.113\n",
      "Ep:172, loss:0.00001, loss_test:0.04464, lr:3.34e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.946, tt:6218.644\n",
      "Ep:173, loss:0.00001, loss_test:0.04223, lr:3.31e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.943, tt:6254.111\n",
      "Ep:174, loss:0.00001, loss_test:0.04356, lr:3.28e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.947, tt:6290.779\n",
      "Ep:175, loss:0.00001, loss_test:0.04330, lr:3.24e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.947, tt:6326.615\n",
      "Ep:176, loss:0.00001, loss_test:0.04298, lr:3.21e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.944, tt:6362.049\n",
      "Ep:177, loss:0.00001, loss_test:0.04366, lr:3.18e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.943, tt:6397.800\n",
      "Ep:178, loss:0.00001, loss_test:0.04271, lr:3.15e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.945, tt:6434.118\n",
      "Ep:179, loss:0.00001, loss_test:0.04392, lr:3.12e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.936, tt:6468.497\n",
      "Ep:180, loss:0.00001, loss_test:0.04314, lr:3.09e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.928, tt:6502.937\n",
      "Ep:181, loss:0.00001, loss_test:0.04319, lr:3.05e-03, fs:0.89119 (r=0.869,p=0.915),  time:35.928, tt:6538.908\n",
      "Ep:182, loss:0.00001, loss_test:0.04354, lr:3.02e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.930, tt:6575.127\n",
      "Ep:183, loss:0.00001, loss_test:0.04284, lr:2.99e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.928, tt:6610.802\n",
      "Ep:184, loss:0.00001, loss_test:0.04347, lr:2.96e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.924, tt:6645.874\n",
      "Ep:185, loss:0.00001, loss_test:0.04335, lr:2.93e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.921, tt:6681.293\n",
      "Ep:186, loss:0.00001, loss_test:0.04316, lr:2.90e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.927, tt:6718.369\n",
      "Ep:187, loss:0.00001, loss_test:0.04366, lr:2.88e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.924, tt:6753.631\n",
      "Ep:188, loss:0.00001, loss_test:0.04270, lr:2.85e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.926, tt:6790.074\n",
      "Ep:189, loss:0.00001, loss_test:0.04386, lr:2.82e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.919, tt:6824.654\n",
      "Ep:190, loss:0.00001, loss_test:0.04334, lr:2.79e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.918, tt:6860.374\n",
      "Ep:191, loss:0.00001, loss_test:0.04373, lr:2.76e-03, fs:0.89119 (r=0.869,p=0.915),  time:35.922, tt:6897.084\n",
      "Ep:192, loss:0.00001, loss_test:0.04364, lr:2.73e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.920, tt:6932.507\n",
      "Ep:193, loss:0.00001, loss_test:0.04327, lr:2.71e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.914, tt:6967.397\n",
      "Ep:194, loss:0.00001, loss_test:0.04395, lr:2.68e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.914, tt:7003.139\n",
      "Ep:195, loss:0.00001, loss_test:0.04303, lr:2.65e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.917, tt:7039.782\n",
      "Ep:196, loss:0.00001, loss_test:0.04426, lr:2.63e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.914, tt:7075.063\n",
      "Ep:197, loss:0.00001, loss_test:0.04343, lr:2.60e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.917, tt:7111.614\n",
      "Ep:198, loss:0.00001, loss_test:0.04358, lr:2.57e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.924, tt:7148.885\n",
      "Ep:199, loss:0.00001, loss_test:0.04408, lr:2.55e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.924, tt:7184.826\n",
      "Ep:200, loss:0.00001, loss_test:0.04398, lr:2.52e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.916, tt:7219.036\n",
      "Ep:201, loss:0.00001, loss_test:0.04391, lr:2.50e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.914, tt:7254.571\n",
      "Ep:202, loss:0.00001, loss_test:0.04405, lr:2.47e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.913, tt:7290.418\n",
      "Ep:203, loss:0.00001, loss_test:0.04393, lr:2.45e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.910, tt:7325.722\n",
      "Ep:204, loss:0.00001, loss_test:0.04410, lr:2.42e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.909, tt:7361.442\n",
      "Ep:205, loss:0.00001, loss_test:0.04404, lr:2.40e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.908, tt:7397.061\n",
      "Ep:206, loss:0.00001, loss_test:0.04420, lr:2.38e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.913, tt:7434.032\n",
      "Ep:207, loss:0.00001, loss_test:0.04396, lr:2.35e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.909, tt:7469.159\n",
      "Ep:208, loss:0.00001, loss_test:0.04405, lr:2.33e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.905, tt:7504.174\n",
      "Ep:209, loss:0.00001, loss_test:0.04425, lr:2.31e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.900, tt:7538.936\n",
      "Ep:210, loss:0.00001, loss_test:0.04355, lr:2.28e-03, fs:0.89691 (r=0.879,p=0.916),  time:35.891, tt:7573.014\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02213, lr:6.00e-02, fs:0.62185 (r=0.747,p=0.532),  time:35.977, tt:35.977\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02341, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:35.720, tt:71.439\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02539, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.785, tt:107.354\n",
      "Ep:3, loss:0.00005, loss_test:0.02501, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.805, tt:143.221\n",
      "Ep:4, loss:0.00005, loss_test:0.02353, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.415, tt:177.075\n",
      "Ep:5, loss:0.00005, loss_test:0.02170, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:35.082, tt:210.491\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02015, lr:6.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:35.003, tt:245.020\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01962, lr:6.00e-02, fs:0.66667 (r=0.818,p=0.562),  time:34.734, tt:277.868\n",
      "Ep:8, loss:0.00004, loss_test:0.01934, lr:6.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:34.559, tt:311.027\n",
      "Ep:9, loss:0.00004, loss_test:0.01867, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:34.593, tt:345.926\n",
      "Ep:10, loss:0.00004, loss_test:0.01840, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.479, tt:379.270\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01845, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:34.527, tt:414.324\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01828, lr:6.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:34.530, tt:448.885\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01780, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:34.581, tt:484.134\n",
      "Ep:14, loss:0.00004, loss_test:0.01741, lr:6.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:34.570, tt:518.552\n",
      "Ep:15, loss:0.00004, loss_test:0.01714, lr:6.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:34.530, tt:552.487\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01678, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:34.540, tt:587.180\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:34.594, tt:622.696\n",
      "Ep:18, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:34.654, tt:658.418\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:34.736, tt:694.729\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01538, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.768, tt:730.138\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.882, tt:767.411\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01469, lr:6.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:34.922, tt:803.210\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01433, lr:6.00e-02, fs:0.78571 (r=1.000,p=0.647),  time:34.930, tt:838.324\n",
      "Ep:24, loss:0.00003, loss_test:0.01402, lr:6.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:34.922, tt:873.039\n",
      "Ep:25, loss:0.00003, loss_test:0.01370, lr:6.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:34.988, tt:909.675\n",
      "Ep:26, loss:0.00003, loss_test:0.01341, lr:6.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:35.021, tt:945.554\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01310, lr:6.00e-02, fs:0.80488 (r=1.000,p=0.673),  time:35.089, tt:982.479\n",
      "Ep:28, loss:0.00003, loss_test:0.01282, lr:6.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:35.104, tt:1018.030\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01259, lr:6.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:35.192, tt:1055.759\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01239, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:35.227, tt:1092.026\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:35.269, tt:1128.621\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01196, lr:6.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:35.287, tt:1164.462\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:35.271, tt:1199.198\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01156, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:35.310, tt:1235.846\n",
      "Ep:35, loss:0.00002, loss_test:0.01139, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:35.327, tt:1271.776\n",
      "Ep:36, loss:0.00002, loss_test:0.01126, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:35.315, tt:1306.651\n",
      "Ep:37, loss:0.00002, loss_test:0.01114, lr:6.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:35.276, tt:1340.505\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01102, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:35.241, tt:1374.410\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01093, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:35.225, tt:1409.003\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01081, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:35.192, tt:1442.865\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01073, lr:6.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.195, tt:1478.199\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01066, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:35.185, tt:1512.962\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01055, lr:6.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:35.160, tt:1547.062\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01049, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:35.159, tt:1582.153\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01045, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:35.156, tt:1617.188\n",
      "Ep:46, loss:0.00002, loss_test:0.01037, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:35.094, tt:1649.403\n",
      "Ep:47, loss:0.00002, loss_test:0.01035, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.075, tt:1683.623\n",
      "Ep:48, loss:0.00002, loss_test:0.01035, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.064, tt:1718.134\n",
      "Ep:49, loss:0.00002, loss_test:0.01024, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.098, tt:1754.902\n",
      "Ep:50, loss:0.00001, loss_test:0.01024, lr:6.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:35.114, tt:1790.806\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01026, lr:6.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:35.092, tt:1824.794\n",
      "Ep:52, loss:0.00001, loss_test:0.01017, lr:6.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.050, tt:1857.641\n",
      "Ep:53, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:35.009, tt:1890.473\n",
      "Ep:54, loss:0.00001, loss_test:0.01010, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:34.978, tt:1923.779\n",
      "Ep:55, loss:0.00001, loss_test:0.01018, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:34.975, tt:1958.608\n",
      "Ep:56, loss:0.00001, loss_test:0.01019, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:34.975, tt:1993.594\n",
      "Ep:57, loss:0.00001, loss_test:0.01014, lr:6.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:35.004, tt:2030.205\n",
      "Ep:58, loss:0.00001, loss_test:0.01018, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:35.022, tt:2066.290\n",
      "Ep:59, loss:0.00001, loss_test:0.01014, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:35.079, tt:2104.754\n",
      "Ep:60, loss:0.00001, loss_test:0.01005, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:35.094, tt:2140.709\n",
      "Ep:61, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:35.113, tt:2177.015\n",
      "Ep:62, loss:0.00001, loss_test:0.00999, lr:5.94e-02, fs:0.84615 (r=0.889,p=0.807),  time:35.114, tt:2212.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01020, lr:5.88e-02, fs:0.83333 (r=0.859,p=0.810),  time:35.119, tt:2247.641\n",
      "Ep:64, loss:0.00001, loss_test:0.01011, lr:5.82e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.165, tt:2285.741\n",
      "Ep:65, loss:0.00001, loss_test:0.01028, lr:5.76e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.190, tt:2322.508\n",
      "Ep:66, loss:0.00001, loss_test:0.01000, lr:5.71e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.204, tt:2358.667\n",
      "Ep:67, loss:0.00001, loss_test:0.01026, lr:5.65e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.206, tt:2394.031\n",
      "Ep:68, loss:0.00001, loss_test:0.01009, lr:5.59e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.198, tt:2428.682\n",
      "Ep:69, loss:0.00001, loss_test:0.01027, lr:5.54e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.215, tt:2465.081\n",
      "Ep:70, loss:0.00001, loss_test:0.01008, lr:5.48e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.200, tt:2499.191\n",
      "Ep:71, loss:0.00001, loss_test:0.01026, lr:5.43e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.218, tt:2535.680\n",
      "Ep:72, loss:0.00001, loss_test:0.01015, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.213, tt:2570.583\n",
      "Ep:73, loss:0.00001, loss_test:0.01016, lr:5.32e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.196, tt:2604.500\n",
      "Ep:74, loss:0.00001, loss_test:0.01047, lr:5.27e-02, fs:0.82051 (r=0.808,p=0.833),  time:35.209, tt:2640.639\n",
      "Ep:75, loss:0.00001, loss_test:0.01021, lr:5.21e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.220, tt:2676.694\n",
      "Ep:76, loss:0.00001, loss_test:0.01032, lr:5.16e-02, fs:0.83249 (r=0.828,p=0.837),  time:35.210, tt:2711.165\n",
      "Ep:77, loss:0.00001, loss_test:0.01036, lr:5.11e-02, fs:0.83673 (r=0.828,p=0.845),  time:35.196, tt:2745.265\n",
      "Ep:78, loss:0.00001, loss_test:0.01013, lr:5.06e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.245, tt:2784.325\n",
      "Ep:79, loss:0.00001, loss_test:0.01090, lr:5.01e-02, fs:0.82292 (r=0.798,p=0.849),  time:35.225, tt:2817.999\n",
      "Ep:80, loss:0.00001, loss_test:0.01018, lr:4.96e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.218, tt:2852.646\n",
      "Ep:81, loss:0.00001, loss_test:0.01052, lr:4.91e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.218, tt:2887.844\n",
      "Ep:82, loss:0.00001, loss_test:0.01050, lr:4.86e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.216, tt:2922.911\n",
      "Ep:83, loss:0.00001, loss_test:0.01047, lr:4.81e-02, fs:0.83938 (r=0.818,p=0.862),  time:35.217, tt:2958.202\n",
      "Ep:84, loss:0.00001, loss_test:0.01043, lr:4.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.220, tt:2993.676\n",
      "Ep:85, loss:0.00001, loss_test:0.01079, lr:4.71e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.221, tt:3028.971\n",
      "Ep:86, loss:0.00001, loss_test:0.01040, lr:4.67e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.193, tt:3061.826\n",
      "Ep:87, loss:0.00001, loss_test:0.01093, lr:4.62e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.209, tt:3098.433\n",
      "Ep:88, loss:0.00001, loss_test:0.01054, lr:4.57e-02, fs:0.83938 (r=0.818,p=0.862),  time:35.199, tt:3132.684\n",
      "Ep:89, loss:0.00001, loss_test:0.01074, lr:4.53e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.202, tt:3168.142\n",
      "Ep:90, loss:0.00001, loss_test:0.01083, lr:4.48e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.211, tt:3204.168\n",
      "Ep:91, loss:0.00001, loss_test:0.01067, lr:4.44e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.225, tt:3240.655\n",
      "Ep:92, loss:0.00001, loss_test:0.01103, lr:4.39e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.248, tt:3278.050\n",
      "Ep:93, loss:0.00001, loss_test:0.01089, lr:4.35e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.263, tt:3314.757\n",
      "Ep:94, loss:0.00001, loss_test:0.01108, lr:4.31e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.256, tt:3349.308\n",
      "Ep:95, loss:0.00001, loss_test:0.01105, lr:4.26e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.256, tt:3384.622\n",
      "Ep:96, loss:0.00001, loss_test:0.01095, lr:4.22e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.257, tt:3419.914\n",
      "Ep:97, loss:0.00001, loss_test:0.01132, lr:4.18e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.274, tt:3456.809\n",
      "Ep:98, loss:0.00001, loss_test:0.01123, lr:4.14e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.270, tt:3491.768\n",
      "Ep:99, loss:0.00001, loss_test:0.01114, lr:4.10e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.267, tt:3526.731\n",
      "Ep:100, loss:0.00001, loss_test:0.01130, lr:4.05e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.243, tt:3559.550\n",
      "Ep:101, loss:0.00001, loss_test:0.01134, lr:4.01e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.238, tt:3594.269\n",
      "Ep:102, loss:0.00001, loss_test:0.01131, lr:3.97e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.229, tt:3628.543\n",
      "Ep:103, loss:0.00001, loss_test:0.01156, lr:3.93e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.236, tt:3664.536\n",
      "Ep:104, loss:0.00001, loss_test:0.01155, lr:3.89e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.224, tt:3698.508\n",
      "Ep:105, loss:0.00001, loss_test:0.01156, lr:3.86e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.234, tt:3734.752\n",
      "Ep:106, loss:0.00000, loss_test:0.01159, lr:3.82e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.247, tt:3771.416\n",
      "Ep:107, loss:0.00000, loss_test:0.01161, lr:3.78e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.262, tt:3808.292\n",
      "Ep:108, loss:0.00000, loss_test:0.01186, lr:3.74e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.271, tt:3844.564\n",
      "Ep:109, loss:0.00000, loss_test:0.01172, lr:3.70e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.275, tt:3880.294\n",
      "Ep:110, loss:0.00000, loss_test:0.01169, lr:3.67e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.280, tt:3916.104\n",
      "Ep:111, loss:0.00000, loss_test:0.01192, lr:3.63e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.278, tt:3951.127\n",
      "Ep:112, loss:0.00000, loss_test:0.01188, lr:3.59e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.275, tt:3986.095\n",
      "Ep:113, loss:0.00000, loss_test:0.01175, lr:3.56e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.278, tt:4021.722\n",
      "Ep:114, loss:0.00000, loss_test:0.01223, lr:3.52e-02, fs:0.82979 (r=0.788,p=0.876),  time:35.282, tt:4057.460\n",
      "Ep:115, loss:0.00000, loss_test:0.01197, lr:3.49e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.290, tt:4093.604\n",
      "Ep:116, loss:0.00000, loss_test:0.01194, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.289, tt:4128.770\n",
      "Ep:117, loss:0.00000, loss_test:0.01226, lr:3.42e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.285, tt:4163.683\n",
      "Ep:118, loss:0.00000, loss_test:0.01211, lr:3.38e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.282, tt:4198.570\n",
      "Ep:119, loss:0.00000, loss_test:0.01224, lr:3.35e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.293, tt:4235.154\n",
      "Ep:120, loss:0.00000, loss_test:0.01244, lr:3.32e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.301, tt:4271.418\n",
      "Ep:121, loss:0.00000, loss_test:0.01218, lr:3.28e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.309, tt:4307.709\n",
      "Ep:122, loss:0.00000, loss_test:0.01238, lr:3.25e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.294, tt:4341.103\n",
      "Ep:123, loss:0.00000, loss_test:0.01251, lr:3.22e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.255, tt:4371.626\n",
      "Ep:124, loss:0.00000, loss_test:0.01227, lr:3.19e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.230, tt:4403.796\n",
      "Ep:125, loss:0.00000, loss_test:0.01281, lr:3.15e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.186, tt:4433.443\n",
      "Ep:126, loss:0.00000, loss_test:0.01248, lr:3.12e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.139, tt:4462.632\n",
      "Ep:127, loss:0.00000, loss_test:0.01249, lr:3.09e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.098, tt:4492.532\n",
      "Ep:128, loss:0.00000, loss_test:0.01281, lr:3.06e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.018, tt:4517.377\n",
      "Ep:129, loss:0.00000, loss_test:0.01254, lr:3.03e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.958, tt:4544.499\n",
      "Ep:130, loss:0.00000, loss_test:0.01291, lr:3.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.936, tt:4576.644\n",
      "Ep:131, loss:0.00000, loss_test:0.01272, lr:2.97e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.923, tt:4609.839\n",
      "Ep:132, loss:0.00000, loss_test:0.01280, lr:2.94e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.917, tt:4643.905\n",
      "Ep:133, loss:0.00000, loss_test:0.01288, lr:2.91e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.923, tt:4679.737\n",
      "Ep:134, loss:0.00000, loss_test:0.01281, lr:2.88e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.883, tt:4709.168\n",
      "Ep:135, loss:0.00000, loss_test:0.01309, lr:2.85e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.839, tt:4738.167\n",
      "Ep:136, loss:0.00000, loss_test:0.01300, lr:2.82e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.814, tt:4769.511\n",
      "Ep:137, loss:0.00000, loss_test:0.01300, lr:2.80e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.811, tt:4803.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.01329, lr:2.77e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.815, tt:4839.257\n",
      "Ep:139, loss:0.00000, loss_test:0.01304, lr:2.74e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.816, tt:4874.304\n",
      "Ep:140, loss:0.00000, loss_test:0.01314, lr:2.71e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.818, tt:4909.340\n",
      "Ep:141, loss:0.00000, loss_test:0.01327, lr:2.69e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.826, tt:4945.313\n",
      "Ep:142, loss:0.00000, loss_test:0.01330, lr:2.66e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.826, tt:4980.180\n",
      "Ep:143, loss:0.00000, loss_test:0.01338, lr:2.63e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.827, tt:5015.039\n",
      "Ep:144, loss:0.00000, loss_test:0.01336, lr:2.61e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.835, tt:5051.043\n",
      "Ep:145, loss:0.00000, loss_test:0.01343, lr:2.58e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.826, tt:5084.646\n",
      "Ep:146, loss:0.00000, loss_test:0.01343, lr:2.55e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.822, tt:5118.857\n",
      "Ep:147, loss:0.00000, loss_test:0.01359, lr:2.53e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.844, tt:5156.881\n",
      "Ep:148, loss:0.00000, loss_test:0.01352, lr:2.50e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.857, tt:5193.728\n",
      "Ep:149, loss:0.00000, loss_test:0.01365, lr:2.48e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.855, tt:5228.186\n",
      "Ep:150, loss:0.00000, loss_test:0.01358, lr:2.45e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.846, tt:5261.771\n",
      "Ep:151, loss:0.00000, loss_test:0.01379, lr:2.43e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.853, tt:5297.730\n",
      "Ep:152, loss:0.00000, loss_test:0.01363, lr:2.40e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.865, tt:5334.370\n",
      "Ep:153, loss:0.00000, loss_test:0.01382, lr:2.38e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.873, tt:5370.388\n",
      "Ep:154, loss:0.00000, loss_test:0.01371, lr:2.36e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.884, tt:5407.043\n",
      "Ep:155, loss:0.00000, loss_test:0.01381, lr:2.33e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.890, tt:5442.773\n",
      "Ep:156, loss:0.00000, loss_test:0.01388, lr:2.31e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.887, tt:5477.293\n",
      "Ep:157, loss:0.00000, loss_test:0.01373, lr:2.29e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.895, tt:5513.388\n",
      "Ep:158, loss:0.00000, loss_test:0.01407, lr:2.26e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.896, tt:5548.458\n",
      "Ep:159, loss:0.00000, loss_test:0.01375, lr:2.24e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.907, tt:5585.105\n",
      "Ep:160, loss:0.00000, loss_test:0.01415, lr:2.22e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.914, tt:5621.215\n",
      "Ep:161, loss:0.00000, loss_test:0.01384, lr:2.20e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.920, tt:5656.983\n",
      "Ep:162, loss:0.00000, loss_test:0.01418, lr:2.17e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.916, tt:5691.368\n",
      "Ep:163, loss:0.00000, loss_test:0.01395, lr:2.15e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.907, tt:5724.752\n",
      "Ep:164, loss:0.00000, loss_test:0.01420, lr:2.13e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.903, tt:5758.967\n",
      "Ep:165, loss:0.00000, loss_test:0.01400, lr:2.11e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.897, tt:5792.849\n",
      "Ep:166, loss:0.00000, loss_test:0.01433, lr:2.09e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.907, tt:5829.492\n",
      "Ep:167, loss:0.00000, loss_test:0.01408, lr:2.07e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.905, tt:5863.988\n",
      "Ep:168, loss:0.00000, loss_test:0.01434, lr:2.05e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.896, tt:5897.359\n",
      "Ep:169, loss:0.00000, loss_test:0.01411, lr:2.03e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.892, tt:5931.685\n",
      "Ep:170, loss:0.00000, loss_test:0.01433, lr:2.01e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.891, tt:5966.384\n",
      "Ep:171, loss:0.00000, loss_test:0.01416, lr:1.99e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.894, tt:6001.787\n",
      "Ep:172, loss:0.00000, loss_test:0.01444, lr:1.97e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.889, tt:6035.828\n",
      "Ep:173, loss:0.00000, loss_test:0.01428, lr:1.95e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.892, tt:6071.209\n",
      "Ep:174, loss:0.00000, loss_test:0.01454, lr:1.93e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.896, tt:6106.867\n",
      "Ep:175, loss:0.00000, loss_test:0.01432, lr:1.91e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.895, tt:6141.470\n",
      "Ep:176, loss:0.00000, loss_test:0.01456, lr:1.89e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.893, tt:6176.102\n",
      "Ep:177, loss:0.00000, loss_test:0.01439, lr:1.87e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.893, tt:6210.868\n",
      "Ep:178, loss:0.00000, loss_test:0.01457, lr:1.85e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.893, tt:6245.843\n",
      "Ep:179, loss:0.00000, loss_test:0.01448, lr:1.83e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.883, tt:6278.982\n",
      "Ep:180, loss:0.00000, loss_test:0.01461, lr:1.81e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.890, tt:6315.069\n",
      "Ep:181, loss:0.00000, loss_test:0.01457, lr:1.80e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.902, tt:6352.208\n",
      "Ep:182, loss:0.00000, loss_test:0.01465, lr:1.78e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.898, tt:6386.391\n",
      "Ep:183, loss:0.00000, loss_test:0.01460, lr:1.76e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.902, tt:6421.886\n",
      "Ep:184, loss:0.00000, loss_test:0.01471, lr:1.74e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.907, tt:6457.734\n",
      "Ep:185, loss:0.00000, loss_test:0.01466, lr:1.73e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.902, tt:6491.793\n",
      "Ep:186, loss:0.00000, loss_test:0.01475, lr:1.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.912, tt:6528.585\n",
      "Ep:187, loss:0.00000, loss_test:0.01469, lr:1.69e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.922, tt:6565.429\n",
      "Ep:188, loss:0.00000, loss_test:0.01484, lr:1.67e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.926, tt:6600.997\n",
      "Ep:189, loss:0.00000, loss_test:0.01475, lr:1.66e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.927, tt:6636.193\n",
      "Ep:190, loss:0.00000, loss_test:0.01484, lr:1.64e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.922, tt:6670.097\n",
      "Ep:191, loss:0.00000, loss_test:0.01480, lr:1.62e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.926, tt:6705.708\n",
      "Ep:192, loss:0.00000, loss_test:0.01486, lr:1.61e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.911, tt:6737.871\n",
      "Ep:193, loss:0.00000, loss_test:0.01491, lr:1.59e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.914, tt:6773.247\n",
      "Ep:194, loss:0.00000, loss_test:0.01488, lr:1.58e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.914, tt:6808.293\n",
      "Ep:195, loss:0.00000, loss_test:0.01493, lr:1.56e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.925, tt:6845.222\n",
      "Ep:196, loss:0.00000, loss_test:0.01492, lr:1.54e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.923, tt:6879.812\n",
      "Ep:197, loss:0.00000, loss_test:0.01503, lr:1.53e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.928, tt:6915.679\n",
      "Ep:198, loss:0.00000, loss_test:0.01493, lr:1.51e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.923, tt:6949.630\n",
      "Ep:199, loss:0.00000, loss_test:0.01509, lr:1.50e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.916, tt:6983.178\n",
      "Ep:200, loss:0.00000, loss_test:0.01504, lr:1.48e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.911, tt:7017.119\n",
      "Ep:201, loss:0.00000, loss_test:0.01506, lr:1.47e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.912, tt:7052.277\n",
      "Ep:202, loss:0.00000, loss_test:0.01503, lr:1.45e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.908, tt:7086.397\n",
      "Ep:203, loss:0.00000, loss_test:0.01511, lr:1.44e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.894, tt:7118.444\n",
      "Ep:204, loss:0.00000, loss_test:0.01515, lr:1.43e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.889, tt:7152.162\n",
      "Ep:205, loss:0.00000, loss_test:0.01505, lr:1.41e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.892, tt:7187.797\n",
      "Ep:206, loss:0.00000, loss_test:0.01519, lr:1.40e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.895, tt:7223.164\n",
      "Ep:207, loss:0.00000, loss_test:0.01518, lr:1.38e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.894, tt:7257.964\n",
      "Ep:208, loss:0.00000, loss_test:0.01519, lr:1.37e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.896, tt:7293.163\n",
      "Ep:209, loss:0.00000, loss_test:0.01518, lr:1.36e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.900, tt:7329.078\n",
      "Ep:210, loss:0.00000, loss_test:0.01525, lr:1.34e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.899, tt:7363.685\n",
      "Ep:211, loss:0.00000, loss_test:0.01529, lr:1.33e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.906, tt:7400.156\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13112, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:33.992, tt:33.992\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12736, lr:1.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:35.129, tt:70.258\n",
      "Ep:2, loss:0.00026, loss_test:0.12445, lr:1.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:35.275, tt:105.825\n",
      "Ep:3, loss:0.00025, loss_test:0.12281, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:35.216, tt:140.865\n",
      "Ep:4, loss:0.00025, loss_test:0.12038, lr:1.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:35.297, tt:176.484\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11763, lr:1.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:35.153, tt:210.916\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11568, lr:1.00e-02, fs:0.66942 (r=0.818,p=0.566),  time:35.343, tt:247.404\n",
      "Ep:7, loss:0.00024, loss_test:0.11399, lr:1.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:35.597, tt:284.779\n",
      "Ep:8, loss:0.00023, loss_test:0.11197, lr:1.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:35.513, tt:319.619\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10897, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:35.649, tt:356.492\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.10546, lr:1.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:35.709, tt:392.800\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10369, lr:1.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:35.871, tt:430.453\n",
      "Ep:12, loss:0.00022, loss_test:0.10185, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:35.835, tt:465.849\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.09882, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:35.850, tt:501.897\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09639, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:35.842, tt:537.637\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09527, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:35.941, tt:575.061\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09288, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:36.000, tt:611.994\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09030, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:35.999, tt:647.989\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.08845, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:36.073, tt:685.395\n",
      "Ep:19, loss:0.00018, loss_test:0.08629, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:36.059, tt:721.175\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.08408, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:36.037, tt:756.787\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.08300, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.992, tt:791.824\n",
      "Ep:22, loss:0.00017, loss_test:0.08008, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:35.934, tt:826.479\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.07844, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:35.876, tt:861.031\n",
      "Ep:24, loss:0.00016, loss_test:0.07741, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:35.876, tt:896.890\n",
      "Ep:25, loss:0.00015, loss_test:0.07552, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:35.824, tt:931.433\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.07445, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.893, tt:969.113\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.07256, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:35.912, tt:1005.542\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.07172, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:35.900, tt:1041.087\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.06980, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:35.920, tt:1077.604\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.06952, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:35.883, tt:1112.383\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.06712, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:35.876, tt:1148.035\n",
      "Ep:32, loss:0.00012, loss_test:0.06611, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:35.880, tt:1184.046\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06689, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:35.819, tt:1217.845\n",
      "Ep:34, loss:0.00012, loss_test:0.06555, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:35.798, tt:1252.944\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.06319, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:35.815, tt:1289.347\n",
      "Ep:36, loss:0.00011, loss_test:0.06518, lr:1.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:35.809, tt:1324.941\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.06019, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:35.865, tt:1362.867\n",
      "Ep:38, loss:0.00010, loss_test:0.06293, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:35.834, tt:1397.534\n",
      "Ep:39, loss:0.00010, loss_test:0.06211, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:35.856, tt:1434.239\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.05864, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:35.872, tt:1470.752\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.06218, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:35.867, tt:1506.426\n",
      "Ep:42, loss:0.00010, loss_test:0.05845, lr:1.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:35.902, tt:1543.789\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.05691, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:35.961, tt:1582.283\n",
      "Ep:44, loss:0.00009, loss_test:0.06029, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.993, tt:1619.688\n",
      "Ep:45, loss:0.00009, loss_test:0.05671, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:36.037, tt:1657.688\n",
      "Ep:46, loss:0.00008, loss_test:0.05823, lr:1.00e-02, fs:0.88000 (r=1.000,p=0.786),  time:36.072, tt:1695.367\n",
      "Ep:47, loss:0.00008, loss_test:0.05528, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:36.069, tt:1731.309\n",
      "Ep:48, loss:0.00008, loss_test:0.05630, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:36.026, tt:1765.297\n",
      "Ep:49, loss:0.00008, loss_test:0.05579, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:36.033, tt:1801.656\n",
      "Ep:50, loss:0.00007, loss_test:0.05342, lr:1.00e-02, fs:0.89593 (r=1.000,p=0.811),  time:36.068, tt:1839.463\n",
      "Ep:51, loss:0.00007, loss_test:0.05250, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:36.089, tt:1876.646\n",
      "Ep:52, loss:0.00007, loss_test:0.05213, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:36.091, tt:1912.842\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.05884, lr:1.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:36.079, tt:1948.270\n",
      "Ep:54, loss:0.00007, loss_test:0.05324, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:36.083, tt:1984.559\n",
      "Ep:55, loss:0.00007, loss_test:0.04936, lr:1.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:36.085, tt:2020.758\n",
      "Ep:56, loss:0.00007, loss_test:0.05612, lr:1.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:36.083, tt:2056.749\n",
      "Ep:57, loss:0.00007, loss_test:0.04950, lr:1.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:36.071, tt:2092.104\n",
      "Ep:58, loss:0.00006, loss_test:0.04952, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:36.065, tt:2127.845\n",
      "Ep:59, loss:0.00006, loss_test:0.04767, lr:1.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:36.074, tt:2164.469\n",
      "Ep:60, loss:0.00006, loss_test:0.05016, lr:1.00e-02, fs:0.90000 (r=1.000,p=0.818),  time:36.071, tt:2200.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.05542, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:36.090, tt:2237.580\n",
      "Ep:62, loss:0.00006, loss_test:0.05127, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:36.096, tt:2274.036\n",
      "Ep:63, loss:0.00006, loss_test:0.04823, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:36.103, tt:2310.591\n",
      "Ep:64, loss:0.00006, loss_test:0.05572, lr:9.90e-03, fs:0.88288 (r=0.990,p=0.797),  time:36.097, tt:2346.311\n",
      "Ep:65, loss:0.00006, loss_test:0.04901, lr:9.80e-03, fs:0.91509 (r=0.980,p=0.858),  time:36.109, tt:2383.189\n",
      "Ep:66, loss:0.00006, loss_test:0.05040, lr:9.70e-03, fs:0.89908 (r=0.990,p=0.824),  time:36.094, tt:2418.283\n",
      "Ep:67, loss:0.00005, loss_test:0.04510, lr:9.61e-03, fs:0.92891 (r=0.990,p=0.875),  time:36.071, tt:2452.814\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.04579, lr:9.61e-03, fs:0.90995 (r=0.970,p=0.857),  time:36.047, tt:2487.211\n",
      "Ep:69, loss:0.00005, loss_test:0.04509, lr:9.61e-03, fs:0.92093 (r=1.000,p=0.853),  time:36.051, tt:2523.547\n",
      "Ep:70, loss:0.00005, loss_test:0.04417, lr:9.61e-03, fs:0.91866 (r=0.970,p=0.873),  time:36.049, tt:2559.490\n",
      "Ep:71, loss:0.00004, loss_test:0.04596, lr:9.61e-03, fs:0.91667 (r=1.000,p=0.846),  time:36.051, tt:2595.682\n",
      "Ep:72, loss:0.00004, loss_test:0.04411, lr:9.61e-03, fs:0.92308 (r=0.970,p=0.881),  time:36.036, tt:2630.653\n",
      "Ep:73, loss:0.00004, loss_test:0.04436, lr:9.61e-03, fs:0.91244 (r=1.000,p=0.839),  time:36.047, tt:2667.455\n",
      "Ep:74, loss:0.00004, loss_test:0.04476, lr:9.61e-03, fs:0.89447 (r=0.899,p=0.890),  time:36.045, tt:2703.351\n",
      "Ep:75, loss:0.00004, loss_test:0.04513, lr:9.61e-03, fs:0.91943 (r=0.980,p=0.866),  time:36.028, tt:2738.130\n",
      "Ep:76, loss:0.00004, loss_test:0.04624, lr:9.61e-03, fs:0.86567 (r=0.879,p=0.853),  time:36.021, tt:2773.620\n",
      "Ep:77, loss:0.00004, loss_test:0.04292, lr:9.61e-03, fs:0.93396 (r=1.000,p=0.876),  time:36.046, tt:2811.583\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00004, loss_test:0.04351, lr:9.61e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.051, tt:2848.000\n",
      "Ep:79, loss:0.00004, loss_test:0.04284, lr:9.61e-03, fs:0.92453 (r=0.990,p=0.867),  time:36.067, tt:2885.328\n",
      "Ep:80, loss:0.00004, loss_test:0.04260, lr:9.61e-03, fs:0.91707 (r=0.949,p=0.887),  time:36.095, tt:2923.657\n",
      "Ep:81, loss:0.00004, loss_test:0.04283, lr:9.61e-03, fs:0.91509 (r=0.980,p=0.858),  time:36.104, tt:2960.557\n",
      "Ep:82, loss:0.00003, loss_test:0.04157, lr:9.61e-03, fs:0.93204 (r=0.970,p=0.897),  time:36.108, tt:2996.942\n",
      "Ep:83, loss:0.00003, loss_test:0.04365, lr:9.61e-03, fs:0.92453 (r=0.990,p=0.867),  time:36.133, tt:3035.177\n",
      "Ep:84, loss:0.00003, loss_test:0.04382, lr:9.61e-03, fs:0.89109 (r=0.909,p=0.874),  time:36.160, tt:3073.567\n",
      "Ep:85, loss:0.00003, loss_test:0.04094, lr:9.61e-03, fs:0.91866 (r=0.970,p=0.873),  time:36.147, tt:3108.678\n",
      "Ep:86, loss:0.00003, loss_test:0.04189, lr:9.61e-03, fs:0.92308 (r=0.970,p=0.881),  time:36.159, tt:3145.820\n",
      "Ep:87, loss:0.00003, loss_test:0.04265, lr:9.61e-03, fs:0.91346 (r=0.960,p=0.872),  time:36.150, tt:3181.168\n",
      "Ep:88, loss:0.00003, loss_test:0.04169, lr:9.61e-03, fs:0.90821 (r=0.949,p=0.870),  time:36.144, tt:3216.851\n",
      "Ep:89, loss:0.00003, loss_test:0.04321, lr:9.51e-03, fs:0.87562 (r=0.889,p=0.863),  time:36.127, tt:3251.394\n",
      "Ep:90, loss:0.00003, loss_test:0.04192, lr:9.41e-03, fs:0.92683 (r=0.960,p=0.896),  time:36.110, tt:3285.985\n",
      "Ep:91, loss:0.00003, loss_test:0.04233, lr:9.32e-03, fs:0.92308 (r=0.970,p=0.881),  time:36.114, tt:3322.455\n",
      "Ep:92, loss:0.00003, loss_test:0.04187, lr:9.23e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.117, tt:3358.899\n",
      "Ep:93, loss:0.00003, loss_test:0.04189, lr:9.14e-03, fs:0.91866 (r=0.970,p=0.873),  time:36.123, tt:3395.550\n",
      "Ep:94, loss:0.00003, loss_test:0.04492, lr:9.04e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.122, tt:3431.582\n",
      "Ep:95, loss:0.00003, loss_test:0.04309, lr:8.95e-03, fs:0.91429 (r=0.970,p=0.865),  time:36.110, tt:3466.580\n",
      "Ep:96, loss:0.00003, loss_test:0.04452, lr:8.86e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.104, tt:3502.068\n",
      "Ep:97, loss:0.00003, loss_test:0.04533, lr:8.78e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.097, tt:3537.511\n",
      "Ep:98, loss:0.00003, loss_test:0.04172, lr:8.69e-03, fs:0.90291 (r=0.939,p=0.869),  time:36.093, tt:3573.246\n",
      "Ep:99, loss:0.00003, loss_test:0.04571, lr:8.60e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.105, tt:3610.521\n",
      "Ep:100, loss:0.00002, loss_test:0.04215, lr:8.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.097, tt:3645.789\n",
      "Ep:101, loss:0.00002, loss_test:0.04248, lr:8.43e-03, fs:0.84694 (r=0.838,p=0.856),  time:36.094, tt:3681.544\n",
      "Ep:102, loss:0.00002, loss_test:0.04483, lr:8.35e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.102, tt:3718.518\n",
      "Ep:103, loss:0.00002, loss_test:0.04315, lr:8.26e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.092, tt:3753.617\n",
      "Ep:104, loss:0.00002, loss_test:0.04175, lr:8.18e-03, fs:0.86567 (r=0.879,p=0.853),  time:36.090, tt:3789.444\n",
      "Ep:105, loss:0.00002, loss_test:0.04266, lr:8.10e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.075, tt:3823.959\n",
      "Ep:106, loss:0.00002, loss_test:0.04348, lr:8.02e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.064, tt:3858.849\n",
      "Ep:107, loss:0.00002, loss_test:0.04284, lr:7.94e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.048, tt:3893.139\n",
      "Ep:108, loss:0.00002, loss_test:0.04182, lr:7.86e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.045, tt:3928.876\n",
      "Ep:109, loss:0.00002, loss_test:0.04421, lr:7.78e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.060, tt:3966.594\n",
      "Ep:110, loss:0.00002, loss_test:0.04218, lr:7.70e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.054, tt:4001.964\n",
      "Ep:111, loss:0.00002, loss_test:0.04362, lr:7.62e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.036, tt:4036.083\n",
      "Ep:112, loss:0.00002, loss_test:0.04363, lr:7.55e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.061, tt:4074.908\n",
      "Ep:113, loss:0.00002, loss_test:0.04358, lr:7.47e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.058, tt:4110.588\n",
      "Ep:114, loss:0.00002, loss_test:0.04361, lr:7.40e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.036, tt:4144.143\n",
      "Ep:115, loss:0.00002, loss_test:0.04422, lr:7.32e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.033, tt:4179.843\n",
      "Ep:116, loss:0.00002, loss_test:0.04352, lr:7.25e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.008, tt:4212.943\n",
      "Ep:117, loss:0.00002, loss_test:0.04511, lr:7.18e-03, fs:0.86458 (r=0.838,p=0.892),  time:35.993, tt:4247.152\n",
      "Ep:118, loss:0.00002, loss_test:0.04406, lr:7.11e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.022, tt:4286.627\n",
      "Ep:119, loss:0.00002, loss_test:0.04416, lr:7.03e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.032, tt:4323.894\n",
      "Ep:120, loss:0.00002, loss_test:0.04479, lr:6.96e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.049, tt:4361.925\n",
      "Ep:121, loss:0.00002, loss_test:0.04437, lr:6.89e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.056, tt:4398.787\n",
      "Ep:122, loss:0.00002, loss_test:0.04612, lr:6.83e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.042, tt:4433.154\n",
      "Ep:123, loss:0.00001, loss_test:0.04325, lr:6.76e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.030, tt:4467.734\n",
      "Ep:124, loss:0.00001, loss_test:0.04478, lr:6.69e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.049, tt:4506.071\n",
      "Ep:125, loss:0.00001, loss_test:0.04296, lr:6.62e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.076, tt:4545.545\n",
      "Ep:126, loss:0.00001, loss_test:0.04544, lr:6.56e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.097, tt:4584.260\n",
      "Ep:127, loss:0.00002, loss_test:0.04356, lr:6.49e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.130, tt:4624.664\n",
      "Ep:128, loss:0.00001, loss_test:0.04404, lr:6.43e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.153, tt:4663.742\n",
      "Ep:129, loss:0.00001, loss_test:0.04372, lr:6.36e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.171, tt:4702.250\n",
      "Ep:130, loss:0.00001, loss_test:0.04337, lr:6.30e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.188, tt:4740.606\n",
      "Ep:131, loss:0.00001, loss_test:0.04450, lr:6.24e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.206, tt:4779.197\n",
      "Ep:132, loss:0.00001, loss_test:0.04299, lr:6.17e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.219, tt:4817.087\n",
      "Ep:133, loss:0.00001, loss_test:0.04419, lr:6.11e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.230, tt:4854.754\n",
      "Ep:134, loss:0.00001, loss_test:0.04436, lr:6.05e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.240, tt:4892.425\n",
      "Ep:135, loss:0.00001, loss_test:0.04396, lr:5.99e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.252, tt:4930.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00001, loss_test:0.04329, lr:5.93e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.271, tt:4969.139\n",
      "Ep:137, loss:0.00001, loss_test:0.04392, lr:5.87e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.288, tt:5007.695\n",
      "Ep:138, loss:0.00001, loss_test:0.04355, lr:5.81e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.300, tt:5045.640\n",
      "Ep:139, loss:0.00001, loss_test:0.04379, lr:5.75e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.319, tt:5084.670\n",
      "Ep:140, loss:0.00001, loss_test:0.04339, lr:5.70e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.336, tt:5123.376\n",
      "Ep:141, loss:0.00001, loss_test:0.04411, lr:5.64e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.349, tt:5161.618\n",
      "Ep:142, loss:0.00001, loss_test:0.04346, lr:5.58e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.370, tt:5200.920\n",
      "Ep:143, loss:0.00001, loss_test:0.04316, lr:5.53e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.385, tt:5239.395\n",
      "Ep:144, loss:0.00001, loss_test:0.04399, lr:5.47e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.396, tt:5277.406\n",
      "Ep:145, loss:0.00001, loss_test:0.04345, lr:5.42e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.408, tt:5315.548\n",
      "Ep:146, loss:0.00001, loss_test:0.04318, lr:5.36e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.423, tt:5354.199\n",
      "Ep:147, loss:0.00001, loss_test:0.04391, lr:5.31e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.429, tt:5391.473\n",
      "Ep:148, loss:0.00001, loss_test:0.04298, lr:5.26e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.437, tt:5429.181\n",
      "Ep:149, loss:0.00001, loss_test:0.04446, lr:5.20e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.444, tt:5466.629\n",
      "Ep:150, loss:0.00001, loss_test:0.04360, lr:5.15e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.462, tt:5505.760\n",
      "Ep:151, loss:0.00001, loss_test:0.04450, lr:5.10e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.472, tt:5543.800\n",
      "Ep:152, loss:0.00001, loss_test:0.04328, lr:5.05e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.474, tt:5580.568\n",
      "Ep:153, loss:0.00001, loss_test:0.04325, lr:5.00e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.484, tt:5618.494\n",
      "Ep:154, loss:0.00001, loss_test:0.04380, lr:4.95e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.485, tt:5655.214\n",
      "Ep:155, loss:0.00001, loss_test:0.04278, lr:4.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.483, tt:5691.302\n",
      "Ep:156, loss:0.00001, loss_test:0.04346, lr:4.85e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.487, tt:5728.498\n",
      "Ep:157, loss:0.00001, loss_test:0.04321, lr:4.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.502, tt:5767.297\n",
      "Ep:158, loss:0.00001, loss_test:0.04345, lr:4.75e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.508, tt:5804.835\n",
      "Ep:159, loss:0.00001, loss_test:0.04313, lr:4.71e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.515, tt:5842.377\n",
      "Ep:160, loss:0.00001, loss_test:0.04315, lr:4.66e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.517, tt:5879.292\n",
      "Ep:161, loss:0.00001, loss_test:0.04347, lr:4.61e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.516, tt:5915.601\n",
      "Ep:162, loss:0.00001, loss_test:0.04283, lr:4.57e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.526, tt:5953.728\n",
      "Ep:163, loss:0.00001, loss_test:0.04342, lr:4.52e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.528, tt:5990.594\n",
      "Ep:164, loss:0.00001, loss_test:0.04321, lr:4.48e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.541, tt:6029.184\n",
      "Ep:165, loss:0.00001, loss_test:0.04319, lr:4.43e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.547, tt:6066.784\n",
      "Ep:166, loss:0.00001, loss_test:0.04241, lr:4.39e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.544, tt:6102.895\n",
      "Ep:167, loss:0.00001, loss_test:0.04336, lr:4.34e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.543, tt:6139.278\n",
      "Ep:168, loss:0.00001, loss_test:0.04316, lr:4.30e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.543, tt:6175.717\n",
      "Ep:169, loss:0.00001, loss_test:0.04280, lr:4.26e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.538, tt:6211.496\n",
      "Ep:170, loss:0.00001, loss_test:0.04283, lr:4.21e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.531, tt:6246.727\n",
      "Ep:171, loss:0.00001, loss_test:0.04247, lr:4.17e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.528, tt:6282.851\n",
      "Ep:172, loss:0.00001, loss_test:0.04312, lr:4.13e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.526, tt:6319.070\n",
      "Ep:173, loss:0.00001, loss_test:0.04304, lr:4.09e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.515, tt:6353.558\n",
      "Ep:174, loss:0.00001, loss_test:0.04286, lr:4.05e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.509, tt:6388.997\n",
      "Ep:175, loss:0.00001, loss_test:0.04285, lr:4.01e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.510, tt:6425.834\n",
      "Ep:176, loss:0.00001, loss_test:0.04285, lr:3.97e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.500, tt:6460.510\n",
      "Ep:177, loss:0.00001, loss_test:0.04273, lr:3.93e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.489, tt:6495.042\n",
      "Ep:178, loss:0.00001, loss_test:0.04292, lr:3.89e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.472, tt:6528.439\n",
      "Ep:179, loss:0.00001, loss_test:0.04333, lr:3.85e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.477, tt:6565.915\n",
      "Ep:180, loss:0.00001, loss_test:0.04292, lr:3.81e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.476, tt:6602.233\n",
      "Ep:181, loss:0.00001, loss_test:0.04270, lr:3.77e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.475, tt:6638.446\n",
      "Ep:182, loss:0.00001, loss_test:0.04320, lr:3.73e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.473, tt:6674.632\n",
      "Ep:183, loss:0.00001, loss_test:0.04273, lr:3.70e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.473, tt:6711.088\n",
      "Ep:184, loss:0.00001, loss_test:0.04291, lr:3.66e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.463, tt:6745.624\n",
      "Ep:185, loss:0.00001, loss_test:0.04271, lr:3.62e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.459, tt:6781.455\n",
      "Ep:186, loss:0.00001, loss_test:0.04280, lr:3.59e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.461, tt:6818.137\n",
      "Ep:187, loss:0.00001, loss_test:0.04268, lr:3.55e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.459, tt:6854.377\n",
      "Ep:188, loss:0.00001, loss_test:0.04298, lr:3.52e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.455, tt:6890.015\n",
      "Ep:189, loss:0.00001, loss_test:0.04288, lr:3.48e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.450, tt:6925.521\n",
      "Ep:190, loss:0.00001, loss_test:0.04276, lr:3.45e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.444, tt:6960.751\n",
      "Ep:191, loss:0.00001, loss_test:0.04280, lr:3.41e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.433, tt:6995.103\n",
      "Ep:192, loss:0.00001, loss_test:0.04277, lr:3.38e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.428, tt:7030.660\n",
      "Ep:193, loss:0.00001, loss_test:0.04246, lr:3.34e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.420, tt:7065.395\n",
      "Ep:194, loss:0.00001, loss_test:0.04237, lr:3.31e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.411, tt:7100.100\n",
      "Ep:195, loss:0.00001, loss_test:0.04236, lr:3.28e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.400, tt:7134.394\n",
      "Ep:196, loss:0.00001, loss_test:0.04279, lr:3.24e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.397, tt:7170.216\n",
      "Ep:197, loss:0.00001, loss_test:0.04301, lr:3.21e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.389, tt:7204.952\n",
      "Ep:198, loss:0.00001, loss_test:0.04266, lr:3.18e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.381, tt:7239.843\n",
      "Ep:199, loss:0.00001, loss_test:0.04245, lr:3.15e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.380, tt:7276.078\n",
      "Ep:200, loss:0.00001, loss_test:0.04254, lr:3.12e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.379, tt:7312.105\n",
      "Ep:201, loss:0.00001, loss_test:0.04256, lr:3.09e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.379, tt:7348.541\n",
      "Ep:202, loss:0.00001, loss_test:0.04254, lr:3.05e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.370, tt:7383.025\n",
      "Ep:203, loss:0.00001, loss_test:0.04316, lr:3.02e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.366, tt:7418.697\n",
      "Ep:204, loss:0.00001, loss_test:0.04252, lr:2.99e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.369, tt:7455.684\n",
      "Ep:205, loss:0.00001, loss_test:0.04264, lr:2.96e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.370, tt:7492.207\n",
      "Ep:206, loss:0.00001, loss_test:0.04291, lr:2.93e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.363, tt:7527.218\n",
      "Ep:207, loss:0.00001, loss_test:0.04264, lr:2.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.361, tt:7563.081\n",
      "Ep:208, loss:0.00001, loss_test:0.04274, lr:2.88e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.358, tt:7598.736\n",
      "Ep:209, loss:0.00001, loss_test:0.04262, lr:2.85e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.352, tt:7633.832\n",
      "Ep:210, loss:0.00001, loss_test:0.04279, lr:2.82e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.348, tt:7669.343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:211, loss:0.00001, loss_test:0.04279, lr:2.79e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.336, tt:7703.286\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02443, lr:6.00e-02, fs:0.65728 (r=0.707,p=0.614),  time:36.292, tt:36.292\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02145, lr:6.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:36.207, tt:72.414\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02421, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.099, tt:108.298\n",
      "Ep:3, loss:0.00005, loss_test:0.02520, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.039, tt:144.158\n",
      "Ep:4, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.688, tt:178.440\n",
      "Ep:5, loss:0.00005, loss_test:0.02408, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:35.825, tt:214.947\n",
      "Ep:6, loss:0.00005, loss_test:0.02282, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:35.658, tt:249.603\n",
      "Ep:7, loss:0.00005, loss_test:0.02153, lr:6.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:35.373, tt:282.986\n",
      "Ep:8, loss:0.00005, loss_test:0.02063, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:35.233, tt:317.098\n",
      "Ep:9, loss:0.00004, loss_test:0.02038, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:35.176, tt:351.765\n",
      "Ep:10, loss:0.00004, loss_test:0.02054, lr:6.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:35.104, tt:386.143\n",
      "Ep:11, loss:0.00004, loss_test:0.02025, lr:6.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:35.032, tt:420.382\n",
      "Ep:12, loss:0.00004, loss_test:0.01926, lr:6.00e-02, fs:0.68398 (r=0.798,p=0.598),  time:34.940, tt:454.216\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:34.949, tt:489.284\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01761, lr:6.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:34.859, tt:522.882\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01715, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:34.763, tt:556.215\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01675, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:34.791, tt:591.455\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:34.843, tt:627.179\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01628, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:34.884, tt:662.793\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:34.882, tt:697.633\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01591, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:34.959, tt:734.142\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:35.002, tt:770.043\n",
      "Ep:22, loss:0.00003, loss_test:0.01544, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:35.107, tt:807.460\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:35.099, tt:842.385\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01509, lr:6.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:35.152, tt:878.796\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:35.159, tt:914.144\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01477, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:35.163, tt:949.393\n",
      "Ep:27, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:35.138, tt:983.856\n",
      "Ep:28, loss:0.00002, loss_test:0.01443, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:35.180, tt:1020.219\n",
      "Ep:29, loss:0.00002, loss_test:0.01425, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:35.201, tt:1056.041\n",
      "Ep:30, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:35.209, tt:1091.487\n",
      "Ep:31, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:35.205, tt:1126.566\n",
      "Ep:32, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:35.186, tt:1161.137\n",
      "Ep:33, loss:0.00002, loss_test:0.01383, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:35.220, tt:1197.464\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:35.235, tt:1233.215\n",
      "Ep:35, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:35.203, tt:1267.315\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:35.199, tt:1302.369\n",
      "Ep:37, loss:0.00002, loss_test:0.01326, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:35.250, tt:1339.496\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:35.263, tt:1375.251\n",
      "Ep:39, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:35.247, tt:1409.875\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:35.233, tt:1444.534\n",
      "Ep:41, loss:0.00001, loss_test:0.01277, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.196, tt:1478.246\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.185, tt:1512.941\n",
      "Ep:43, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.184, tt:1548.086\n",
      "Ep:44, loss:0.00001, loss_test:0.01250, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:35.181, tt:1583.132\n",
      "Ep:45, loss:0.00001, loss_test:0.01247, lr:6.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:35.188, tt:1618.667\n",
      "Ep:46, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.225, tt:1655.554\n",
      "Ep:47, loss:0.00001, loss_test:0.01238, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.248, tt:1691.905\n",
      "Ep:48, loss:0.00001, loss_test:0.01236, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.237, tt:1726.612\n",
      "Ep:49, loss:0.00001, loss_test:0.01235, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.228, tt:1761.397\n",
      "Ep:50, loss:0.00001, loss_test:0.01220, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.210, tt:1795.725\n",
      "Ep:51, loss:0.00001, loss_test:0.01214, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.207, tt:1830.752\n",
      "Ep:52, loss:0.00001, loss_test:0.01216, lr:6.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.218, tt:1866.559\n",
      "Ep:53, loss:0.00001, loss_test:0.01213, lr:5.94e-02, fs:0.80402 (r=0.808,p=0.800),  time:35.233, tt:1902.566\n",
      "Ep:54, loss:0.00001, loss_test:0.01211, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.226, tt:1937.449\n",
      "Ep:55, loss:0.00001, loss_test:0.01209, lr:5.82e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.236, tt:1973.201\n",
      "Ep:56, loss:0.00001, loss_test:0.01208, lr:5.76e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.264, tt:2010.068\n",
      "Ep:57, loss:0.00001, loss_test:0.01211, lr:5.71e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.268, tt:2045.518\n",
      "Ep:58, loss:0.00001, loss_test:0.01214, lr:5.65e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.246, tt:2079.498\n",
      "Ep:59, loss:0.00001, loss_test:0.01213, lr:5.59e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.235, tt:2114.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01214, lr:5.54e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.209, tt:2147.737\n",
      "Ep:61, loss:0.00001, loss_test:0.01215, lr:5.48e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.197, tt:2182.192\n",
      "Ep:62, loss:0.00001, loss_test:0.01212, lr:5.43e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.214, tt:2218.509\n",
      "Ep:63, loss:0.00001, loss_test:0.01215, lr:5.37e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.229, tt:2254.678\n",
      "Ep:64, loss:0.00001, loss_test:0.01216, lr:5.32e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.208, tt:2288.518\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01216, lr:5.32e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.206, tt:2323.582\n",
      "Ep:66, loss:0.00001, loss_test:0.01221, lr:5.32e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.191, tt:2357.828\n",
      "Ep:67, loss:0.00001, loss_test:0.01219, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.184, tt:2392.528\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01223, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.181, tt:2427.477\n",
      "Ep:69, loss:0.00001, loss_test:0.01224, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.202, tt:2464.130\n",
      "Ep:70, loss:0.00001, loss_test:0.01222, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.215, tt:2500.274\n",
      "Ep:71, loss:0.00001, loss_test:0.01228, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.217, tt:2535.656\n",
      "Ep:72, loss:0.00001, loss_test:0.01233, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.238, tt:2572.363\n",
      "Ep:73, loss:0.00001, loss_test:0.01228, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.244, tt:2608.022\n",
      "Ep:74, loss:0.00001, loss_test:0.01234, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.226, tt:2641.985\n",
      "Ep:75, loss:0.00001, loss_test:0.01238, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.205, tt:2675.613\n",
      "Ep:76, loss:0.00001, loss_test:0.01238, lr:5.32e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.201, tt:2710.447\n",
      "Ep:77, loss:0.00001, loss_test:0.01241, lr:5.32e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.233, tt:2748.202\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01241, lr:5.32e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.240, tt:2783.953\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01241, lr:5.32e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.254, tt:2820.330\n",
      "Ep:80, loss:0.00001, loss_test:0.01244, lr:5.32e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.267, tt:2856.634\n",
      "Ep:81, loss:0.00001, loss_test:0.01252, lr:5.32e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.264, tt:2891.617\n",
      "Ep:82, loss:0.00001, loss_test:0.01248, lr:5.32e-02, fs:0.84492 (r=0.798,p=0.898),  time:35.261, tt:2926.642\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00000, loss_test:0.01259, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.248, tt:2960.807\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00000, loss_test:0.01259, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.241, tt:2995.521\n",
      "Ep:85, loss:0.00000, loss_test:0.01259, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.242, tt:3030.821\n",
      "Ep:86, loss:0.00000, loss_test:0.01265, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.238, tt:3065.720\n",
      "Ep:87, loss:0.00000, loss_test:0.01266, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.231, tt:3100.347\n",
      "Ep:88, loss:0.00000, loss_test:0.01267, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.212, tt:3133.839\n",
      "Ep:89, loss:0.00000, loss_test:0.01273, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.211, tt:3169.012\n",
      "Ep:90, loss:0.00000, loss_test:0.01275, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.212, tt:3204.322\n",
      "Ep:91, loss:0.00000, loss_test:0.01276, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.210, tt:3239.303\n",
      "Ep:92, loss:0.00000, loss_test:0.01278, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.221, tt:3275.542\n",
      "Ep:93, loss:0.00000, loss_test:0.01277, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.236, tt:3312.185\n",
      "Ep:94, loss:0.00000, loss_test:0.01281, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.230, tt:3346.808\n",
      "Ep:95, loss:0.00000, loss_test:0.01281, lr:5.27e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.212, tt:3380.363\n",
      "Ep:96, loss:0.00000, loss_test:0.01284, lr:5.21e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.235, tt:3417.766\n",
      "Ep:97, loss:0.00000, loss_test:0.01291, lr:5.16e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.245, tt:3454.025\n",
      "Ep:98, loss:0.00000, loss_test:0.01288, lr:5.11e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.261, tt:3490.790\n",
      "Ep:99, loss:0.00000, loss_test:0.01291, lr:5.06e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.266, tt:3526.627\n",
      "Ep:100, loss:0.00000, loss_test:0.01301, lr:5.01e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.265, tt:3561.779\n",
      "Ep:101, loss:0.00000, loss_test:0.01298, lr:4.96e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.275, tt:3598.066\n",
      "Ep:102, loss:0.00000, loss_test:0.01300, lr:4.91e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.278, tt:3633.597\n",
      "Ep:103, loss:0.00000, loss_test:0.01302, lr:4.86e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.271, tt:3668.140\n",
      "Ep:104, loss:0.00000, loss_test:0.01298, lr:4.81e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.250, tt:3701.296\n",
      "Ep:105, loss:0.00000, loss_test:0.01312, lr:4.76e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.227, tt:3734.042\n",
      "Ep:106, loss:0.00000, loss_test:0.01309, lr:4.71e-02, fs:0.80226 (r=0.717,p=0.910),  time:35.176, tt:3763.840\n",
      "Ep:107, loss:0.00000, loss_test:0.01304, lr:4.67e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.130, tt:3794.020\n",
      "Ep:108, loss:0.00000, loss_test:0.01320, lr:4.62e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.074, tt:3823.084\n",
      "Ep:109, loss:0.00000, loss_test:0.01321, lr:4.57e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.001, tt:3850.058\n",
      "Ep:110, loss:0.00000, loss_test:0.01312, lr:4.53e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.906, tt:3874.597\n",
      "Ep:111, loss:0.00000, loss_test:0.01321, lr:4.48e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.850, tt:3903.190\n",
      "Ep:112, loss:0.00000, loss_test:0.01329, lr:4.44e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.839, tt:3936.830\n",
      "Ep:113, loss:0.00000, loss_test:0.01321, lr:4.39e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.845, tt:3972.297\n",
      "Ep:114, loss:0.00000, loss_test:0.01330, lr:4.35e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.859, tt:4008.828\n",
      "Ep:115, loss:0.00000, loss_test:0.01330, lr:4.31e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.840, tt:4041.436\n",
      "Ep:116, loss:0.00000, loss_test:0.01336, lr:4.26e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.816, tt:4073.527\n",
      "Ep:117, loss:0.00000, loss_test:0.01340, lr:4.22e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.802, tt:4106.642\n",
      "Ep:118, loss:0.00000, loss_test:0.01338, lr:4.18e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.777, tt:4138.460\n",
      "Ep:119, loss:0.00000, loss_test:0.01343, lr:4.14e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.785, tt:4174.162\n",
      "Ep:120, loss:0.00000, loss_test:0.01352, lr:4.10e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.797, tt:4210.406\n",
      "Ep:121, loss:0.00000, loss_test:0.01352, lr:4.05e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.804, tt:4246.142\n",
      "Ep:122, loss:0.00000, loss_test:0.01352, lr:4.01e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.815, tt:4282.205\n",
      "Ep:123, loss:0.00000, loss_test:0.01355, lr:3.97e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.833, tt:4319.262\n",
      "Ep:124, loss:0.00000, loss_test:0.01359, lr:3.93e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.838, tt:4354.772\n",
      "Ep:125, loss:0.00000, loss_test:0.01365, lr:3.89e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.850, tt:4391.144\n",
      "Ep:126, loss:0.00000, loss_test:0.01368, lr:3.86e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.851, tt:4426.019\n",
      "Ep:127, loss:0.00000, loss_test:0.01367, lr:3.82e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.854, tt:4461.311\n",
      "Ep:128, loss:0.00000, loss_test:0.01370, lr:3.78e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.846, tt:4495.082\n",
      "Ep:129, loss:0.00000, loss_test:0.01375, lr:3.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.858, tt:4531.530\n",
      "Ep:130, loss:0.00000, loss_test:0.01374, lr:3.70e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.868, tt:4567.728\n",
      "Ep:131, loss:0.00000, loss_test:0.01378, lr:3.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.883, tt:4604.509\n",
      "Ep:132, loss:0.00000, loss_test:0.01382, lr:3.63e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.886, tt:4639.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01379, lr:3.59e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.888, tt:4674.963\n",
      "Ep:134, loss:0.00000, loss_test:0.01387, lr:3.56e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.905, tt:4712.126\n",
      "Ep:135, loss:0.00000, loss_test:0.01391, lr:3.52e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.914, tt:4748.343\n",
      "Ep:136, loss:0.00000, loss_test:0.01390, lr:3.49e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.929, tt:4785.284\n",
      "Ep:137, loss:0.00000, loss_test:0.01392, lr:3.45e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.942, tt:4822.050\n",
      "Ep:138, loss:0.00000, loss_test:0.01397, lr:3.42e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.939, tt:4856.489\n",
      "Ep:139, loss:0.00000, loss_test:0.01399, lr:3.38e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.951, tt:4893.120\n",
      "Ep:140, loss:0.00000, loss_test:0.01400, lr:3.35e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.952, tt:4928.259\n",
      "Ep:141, loss:0.00000, loss_test:0.01406, lr:3.32e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.958, tt:4963.996\n",
      "Ep:142, loss:0.00000, loss_test:0.01404, lr:3.28e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.968, tt:5000.379\n",
      "Ep:143, loss:0.00000, loss_test:0.01408, lr:3.25e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.982, tt:5037.377\n",
      "Ep:144, loss:0.00000, loss_test:0.01415, lr:3.22e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.996, tt:5074.491\n",
      "Ep:145, loss:0.00000, loss_test:0.01412, lr:3.19e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.998, tt:5109.650\n",
      "Ep:146, loss:0.00000, loss_test:0.01413, lr:3.15e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.008, tt:5146.225\n",
      "Ep:147, loss:0.00000, loss_test:0.01419, lr:3.12e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.006, tt:5180.960\n",
      "Ep:148, loss:0.00000, loss_test:0.01419, lr:3.09e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.012, tt:5216.734\n",
      "Ep:149, loss:0.00000, loss_test:0.01421, lr:3.06e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.017, tt:5252.584\n",
      "Ep:150, loss:0.00000, loss_test:0.01426, lr:3.03e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.035, tt:5290.326\n",
      "Ep:151, loss:0.00000, loss_test:0.01425, lr:3.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.044, tt:5326.762\n",
      "Ep:152, loss:0.00000, loss_test:0.01426, lr:2.97e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.050, tt:5362.693\n",
      "Ep:153, loss:0.00000, loss_test:0.01431, lr:2.94e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.049, tt:5397.582\n",
      "Ep:154, loss:0.00000, loss_test:0.01434, lr:2.91e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.047, tt:5432.342\n",
      "Ep:155, loss:0.00000, loss_test:0.01439, lr:2.88e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.059, tt:5469.177\n",
      "Ep:156, loss:0.00000, loss_test:0.01436, lr:2.85e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.050, tt:5502.844\n",
      "Ep:157, loss:0.00000, loss_test:0.01438, lr:2.82e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.058, tt:5539.195\n",
      "Ep:158, loss:0.00000, loss_test:0.01445, lr:2.80e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.068, tt:5575.858\n",
      "Ep:159, loss:0.00000, loss_test:0.01445, lr:2.77e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.076, tt:5612.094\n",
      "Ep:160, loss:0.00000, loss_test:0.01444, lr:2.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.086, tt:5648.769\n",
      "Ep:161, loss:0.00000, loss_test:0.01447, lr:2.71e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.070, tt:5681.293\n",
      "Ep:162, loss:0.00000, loss_test:0.01450, lr:2.69e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.064, tt:5715.409\n",
      "Ep:163, loss:0.00000, loss_test:0.01454, lr:2.66e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.055, tt:5749.085\n",
      "Ep:164, loss:0.00000, loss_test:0.01455, lr:2.63e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.065, tt:5785.731\n",
      "Ep:165, loss:0.00000, loss_test:0.01456, lr:2.61e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.072, tt:5821.937\n",
      "Ep:166, loss:0.00000, loss_test:0.01457, lr:2.58e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.069, tt:5856.504\n",
      "Ep:167, loss:0.00000, loss_test:0.01459, lr:2.55e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.076, tt:5892.712\n",
      "Ep:168, loss:0.00000, loss_test:0.01462, lr:2.53e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.070, tt:5926.827\n",
      "Ep:169, loss:0.00000, loss_test:0.01460, lr:2.50e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.081, tt:5963.798\n",
      "Ep:170, loss:0.00000, loss_test:0.01462, lr:2.48e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.077, tt:5998.221\n",
      "Ep:171, loss:0.00000, loss_test:0.01467, lr:2.45e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.083, tt:6034.272\n",
      "Ep:172, loss:0.00000, loss_test:0.01469, lr:2.43e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.077, tt:6068.362\n",
      "Ep:173, loss:0.00000, loss_test:0.01470, lr:2.40e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.083, tt:6104.386\n",
      "Ep:174, loss:0.00000, loss_test:0.01471, lr:2.38e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.081, tt:6139.093\n",
      "Ep:175, loss:0.00000, loss_test:0.01473, lr:2.36e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.088, tt:6175.507\n",
      "Ep:176, loss:0.00000, loss_test:0.01476, lr:2.33e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.095, tt:6211.819\n",
      "Ep:177, loss:0.00000, loss_test:0.01477, lr:2.31e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.095, tt:6246.942\n",
      "Ep:178, loss:0.00000, loss_test:0.01480, lr:2.29e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.101, tt:6283.165\n",
      "Ep:179, loss:0.00000, loss_test:0.01483, lr:2.26e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.101, tt:6318.136\n",
      "Ep:180, loss:0.00000, loss_test:0.01482, lr:2.24e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.105, tt:6354.028\n",
      "Ep:181, loss:0.00000, loss_test:0.01484, lr:2.22e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.118, tt:6391.539\n",
      "Ep:182, loss:0.00000, loss_test:0.01485, lr:2.20e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.116, tt:6426.301\n",
      "Ep:183, loss:0.00000, loss_test:0.01489, lr:2.17e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.117, tt:6461.620\n",
      "Ep:184, loss:0.00000, loss_test:0.01490, lr:2.15e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.120, tt:6497.155\n",
      "Ep:185, loss:0.00000, loss_test:0.01492, lr:2.13e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.117, tt:6531.826\n",
      "Ep:186, loss:0.00000, loss_test:0.01491, lr:2.11e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.119, tt:6567.253\n",
      "Ep:187, loss:0.00000, loss_test:0.01493, lr:2.09e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.121, tt:6602.685\n",
      "Ep:188, loss:0.00000, loss_test:0.01496, lr:2.07e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.120, tt:6637.704\n",
      "Ep:189, loss:0.00000, loss_test:0.01499, lr:2.05e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.122, tt:6673.244\n",
      "Ep:190, loss:0.00000, loss_test:0.01499, lr:2.03e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.121, tt:6708.156\n",
      "Ep:191, loss:0.00000, loss_test:0.01499, lr:2.01e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.124, tt:6743.817\n",
      "Ep:192, loss:0.00000, loss_test:0.01502, lr:1.99e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.124, tt:6778.966\n",
      "Ep:193, loss:0.00000, loss_test:0.01505, lr:1.97e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.120, tt:6813.257\n",
      "Ep:194, loss:0.00000, loss_test:0.01505, lr:1.95e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.125, tt:6849.333\n",
      "Ep:195, loss:0.00000, loss_test:0.01505, lr:1.93e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.118, tt:6883.190\n",
      "Ep:196, loss:0.00000, loss_test:0.01508, lr:1.91e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.122, tt:6919.113\n",
      "Ep:197, loss:0.00000, loss_test:0.01511, lr:1.89e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.123, tt:6954.359\n",
      "Ep:198, loss:0.00000, loss_test:0.01509, lr:1.87e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.123, tt:6989.397\n",
      "Ep:199, loss:0.00000, loss_test:0.01510, lr:1.85e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.130, tt:7026.096\n",
      "Ep:200, loss:0.00000, loss_test:0.01514, lr:1.83e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.140, tt:7063.223\n",
      "Ep:201, loss:0.00000, loss_test:0.01516, lr:1.81e-02, fs:0.78824 (r=0.677,p=0.944),  time:35.138, tt:7097.866\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.12093, lr:1.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:34.836, tt:34.836\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00026, loss_test:0.12008, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:36.061, tt:72.122\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11947, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:35.821, tt:107.463\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11879, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:36.086, tt:144.344\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11814, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:36.167, tt:180.837\n",
      "Ep:5, loss:0.00025, loss_test:0.11727, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:36.489, tt:218.932\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11611, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:36.255, tt:253.788\n",
      "Ep:7, loss:0.00025, loss_test:0.11477, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:36.297, tt:290.376\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.11308, lr:1.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:36.348, tt:327.133\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11126, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:36.552, tt:365.517\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.10928, lr:1.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:36.438, tt:400.823\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10691, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:36.245, tt:434.944\n",
      "Ep:12, loss:0.00023, loss_test:0.10442, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:36.186, tt:470.412\n",
      "Ep:13, loss:0.00022, loss_test:0.10188, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:36.359, tt:509.026\n",
      "Ep:14, loss:0.00022, loss_test:0.09939, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:36.388, tt:545.818\n",
      "Ep:15, loss:0.00021, loss_test:0.09675, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:36.438, tt:583.002\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09468, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:36.527, tt:620.959\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.09229, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:36.570, tt:658.259\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.08971, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:36.602, tt:695.430\n",
      "Ep:19, loss:0.00018, loss_test:0.08799, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:36.621, tt:732.419\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.08668, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:36.592, tt:768.426\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.08434, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:36.594, tt:805.065\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.08246, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:36.615, tt:842.137\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08190, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:36.556, tt:877.344\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.07913, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:36.537, tt:913.417\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07717, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:36.628, tt:952.329\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07577, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:36.649, tt:989.514\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07423, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:36.626, tt:1025.519\n",
      "Ep:28, loss:0.00012, loss_test:0.07308, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:36.613, tt:1061.775\n",
      "Ep:29, loss:0.00011, loss_test:0.07117, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:36.617, tt:1098.524\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.07086, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:36.637, tt:1135.752\n",
      "Ep:31, loss:0.00010, loss_test:0.06902, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:36.675, tt:1173.592\n",
      "Ep:32, loss:0.00010, loss_test:0.06807, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:36.641, tt:1209.167\n",
      "Ep:33, loss:0.00010, loss_test:0.06689, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:36.611, tt:1244.774\n",
      "Ep:34, loss:0.00009, loss_test:0.06656, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:36.583, tt:1280.399\n",
      "Ep:35, loss:0.00009, loss_test:0.06593, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:36.550, tt:1315.815\n",
      "Ep:36, loss:0.00008, loss_test:0.06478, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:36.587, tt:1353.722\n",
      "Ep:37, loss:0.00008, loss_test:0.06539, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:36.565, tt:1389.469\n",
      "Ep:38, loss:0.00008, loss_test:0.06350, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:36.549, tt:1425.429\n",
      "Ep:39, loss:0.00007, loss_test:0.06414, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:36.533, tt:1461.322\n",
      "Ep:40, loss:0.00007, loss_test:0.06331, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:36.516, tt:1497.157\n",
      "Ep:41, loss:0.00007, loss_test:0.06287, lr:9.90e-03, fs:0.85279 (r=0.848,p=0.857),  time:36.489, tt:1532.533\n",
      "Ep:42, loss:0.00007, loss_test:0.06552, lr:9.80e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.484, tt:1568.812\n",
      "Ep:43, loss:0.00006, loss_test:0.06196, lr:9.70e-03, fs:0.85279 (r=0.848,p=0.857),  time:36.479, tt:1605.066\n",
      "Ep:44, loss:0.00006, loss_test:0.06368, lr:9.61e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.471, tt:1641.213\n",
      "Ep:45, loss:0.00006, loss_test:0.06302, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.532, tt:1680.484\n",
      "Ep:46, loss:0.00006, loss_test:0.06247, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.508, tt:1715.855\n",
      "Ep:47, loss:0.00006, loss_test:0.06276, lr:9.32e-03, fs:0.85128 (r=0.838,p=0.865),  time:36.497, tt:1751.850\n",
      "Ep:48, loss:0.00005, loss_test:0.06109, lr:9.23e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.504, tt:1788.673\n",
      "Ep:49, loss:0.00005, loss_test:0.06268, lr:9.14e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.552, tt:1827.599\n",
      "Ep:50, loss:0.00005, loss_test:0.06081, lr:9.04e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.560, tt:1864.579\n",
      "Ep:51, loss:0.00005, loss_test:0.06215, lr:8.95e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.578, tt:1902.058\n",
      "Ep:52, loss:0.00005, loss_test:0.06171, lr:8.86e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.616, tt:1940.666\n",
      "Ep:53, loss:0.00005, loss_test:0.06025, lr:8.78e-03, fs:0.86294 (r=0.859,p=0.867),  time:36.615, tt:1977.198\n",
      "Ep:54, loss:0.00004, loss_test:0.06176, lr:8.69e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.613, tt:2013.737\n",
      "Ep:55, loss:0.00004, loss_test:0.06058, lr:8.60e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.603, tt:2049.744\n",
      "Ep:56, loss:0.00004, loss_test:0.06015, lr:8.51e-03, fs:0.86154 (r=0.848,p=0.875),  time:36.627, tt:2087.731\n",
      "Ep:57, loss:0.00004, loss_test:0.06118, lr:8.43e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.638, tt:2125.026\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00004, loss_test:0.05959, lr:8.43e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.613, tt:2160.192\n",
      "Ep:59, loss:0.00004, loss_test:0.06002, lr:8.43e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.611, tt:2196.686\n",
      "Ep:60, loss:0.00004, loss_test:0.06021, lr:8.43e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.634, tt:2234.685\n",
      "Ep:61, loss:0.00004, loss_test:0.05925, lr:8.43e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.645, tt:2271.981\n",
      "Ep:62, loss:0.00004, loss_test:0.05990, lr:8.43e-03, fs:0.85864 (r=0.828,p=0.891),  time:36.627, tt:2307.516\n",
      "Ep:63, loss:0.00003, loss_test:0.05932, lr:8.43e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.684, tt:2347.795\n",
      "Ep:64, loss:0.00003, loss_test:0.05996, lr:8.43e-03, fs:0.84817 (r=0.818,p=0.880),  time:36.702, tt:2385.653\n",
      "Ep:65, loss:0.00003, loss_test:0.05867, lr:8.43e-03, fs:0.85864 (r=0.828,p=0.891),  time:36.728, tt:2424.073\n",
      "Ep:66, loss:0.00003, loss_test:0.05904, lr:8.43e-03, fs:0.85263 (r=0.818,p=0.890),  time:36.737, tt:2461.403\n",
      "Ep:67, loss:0.00003, loss_test:0.05897, lr:8.43e-03, fs:0.84817 (r=0.818,p=0.880),  time:36.727, tt:2497.460\n",
      "Ep:68, loss:0.00003, loss_test:0.05884, lr:8.43e-03, fs:0.84043 (r=0.798,p=0.888),  time:36.702, tt:2532.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00003, loss_test:0.05886, lr:8.35e-03, fs:0.83598 (r=0.798,p=0.878),  time:36.669, tt:2566.829\n",
      "Ep:70, loss:0.00003, loss_test:0.05858, lr:8.26e-03, fs:0.84656 (r=0.808,p=0.889),  time:36.677, tt:2604.096\n",
      "Ep:71, loss:0.00003, loss_test:0.05918, lr:8.18e-03, fs:0.84043 (r=0.798,p=0.888),  time:36.608, tt:2635.811\n",
      "Ep:72, loss:0.00003, loss_test:0.05910, lr:8.10e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.559, tt:2668.843\n",
      "Ep:73, loss:0.00003, loss_test:0.05888, lr:8.02e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.507, tt:2701.553\n",
      "Ep:74, loss:0.00003, loss_test:0.05898, lr:7.94e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.426, tt:2731.948\n",
      "Ep:75, loss:0.00003, loss_test:0.05855, lr:7.86e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.386, tt:2765.327\n",
      "Ep:76, loss:0.00003, loss_test:0.05905, lr:7.78e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.401, tt:2802.902\n",
      "Ep:77, loss:0.00003, loss_test:0.05904, lr:7.70e-03, fs:0.83871 (r=0.788,p=0.897),  time:36.429, tt:2841.443\n",
      "Ep:78, loss:0.00002, loss_test:0.05902, lr:7.62e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.440, tt:2878.783\n",
      "Ep:79, loss:0.00002, loss_test:0.05846, lr:7.55e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.427, tt:2914.159\n",
      "Ep:80, loss:0.00002, loss_test:0.05884, lr:7.47e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.401, tt:2948.491\n",
      "Ep:81, loss:0.00002, loss_test:0.05758, lr:7.40e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.378, tt:2983.034\n",
      "Ep:82, loss:0.00002, loss_test:0.06026, lr:7.32e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.412, tt:3022.165\n",
      "Ep:83, loss:0.00002, loss_test:0.05806, lr:7.25e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.412, tt:3058.599\n",
      "Ep:84, loss:0.00002, loss_test:0.05749, lr:7.18e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.408, tt:3094.685\n",
      "Ep:85, loss:0.00002, loss_test:0.05848, lr:7.11e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.429, tt:3132.888\n",
      "Ep:86, loss:0.00002, loss_test:0.05819, lr:7.03e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.423, tt:3168.774\n",
      "Ep:87, loss:0.00002, loss_test:0.05708, lr:6.96e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.452, tt:3207.811\n",
      "Ep:88, loss:0.00002, loss_test:0.05753, lr:6.89e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.468, tt:3245.663\n",
      "Ep:89, loss:0.00002, loss_test:0.05832, lr:6.83e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.464, tt:3281.766\n",
      "Ep:90, loss:0.00002, loss_test:0.05756, lr:6.76e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.465, tt:3318.345\n",
      "Ep:91, loss:0.00002, loss_test:0.05651, lr:6.69e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.461, tt:3354.397\n",
      "Ep:92, loss:0.00002, loss_test:0.05869, lr:6.62e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.454, tt:3390.241\n",
      "Ep:93, loss:0.00002, loss_test:0.05783, lr:6.56e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.470, tt:3428.192\n",
      "Ep:94, loss:0.00002, loss_test:0.05737, lr:6.49e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.483, tt:3465.843\n",
      "Ep:95, loss:0.00002, loss_test:0.05790, lr:6.43e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.496, tt:3503.609\n",
      "Ep:96, loss:0.00002, loss_test:0.05639, lr:6.36e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.497, tt:3540.176\n",
      "Ep:97, loss:0.00002, loss_test:0.05778, lr:6.30e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.491, tt:3576.100\n",
      "Ep:98, loss:0.00002, loss_test:0.05743, lr:6.24e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.486, tt:3612.124\n",
      "Ep:99, loss:0.00002, loss_test:0.05824, lr:6.17e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.503, tt:3650.288\n",
      "Ep:100, loss:0.00002, loss_test:0.05713, lr:6.11e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.509, tt:3687.402\n",
      "Ep:101, loss:0.00002, loss_test:0.05697, lr:6.05e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.500, tt:3722.981\n",
      "Ep:102, loss:0.00002, loss_test:0.05696, lr:5.99e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.502, tt:3759.692\n",
      "Ep:103, loss:0.00002, loss_test:0.05695, lr:5.93e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.506, tt:3796.639\n",
      "Ep:104, loss:0.00002, loss_test:0.05721, lr:5.87e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.509, tt:3833.484\n",
      "Ep:105, loss:0.00002, loss_test:0.05707, lr:5.81e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.509, tt:3869.910\n",
      "Ep:106, loss:0.00002, loss_test:0.05720, lr:5.75e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.510, tt:3906.550\n",
      "Ep:107, loss:0.00002, loss_test:0.05653, lr:5.70e-03, fs:0.83871 (r=0.788,p=0.897),  time:36.522, tt:3944.336\n",
      "Ep:108, loss:0.00002, loss_test:0.05671, lr:5.64e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.523, tt:3980.968\n",
      "Ep:109, loss:0.00002, loss_test:0.05634, lr:5.58e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.528, tt:4018.047\n",
      "Ep:110, loss:0.00001, loss_test:0.05675, lr:5.53e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.538, tt:4055.663\n",
      "Ep:111, loss:0.00001, loss_test:0.05659, lr:5.47e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.537, tt:4092.183\n",
      "Ep:112, loss:0.00001, loss_test:0.05747, lr:5.42e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.531, tt:4128.015\n",
      "Ep:113, loss:0.00001, loss_test:0.05576, lr:5.36e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.544, tt:4166.043\n",
      "Ep:114, loss:0.00001, loss_test:0.05657, lr:5.31e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.540, tt:4202.122\n",
      "Ep:115, loss:0.00001, loss_test:0.05709, lr:5.26e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.537, tt:4238.254\n",
      "Ep:116, loss:0.00001, loss_test:0.05659, lr:5.20e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.545, tt:4275.798\n",
      "Ep:117, loss:0.00001, loss_test:0.05599, lr:5.15e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.539, tt:4311.561\n",
      "Ep:118, loss:0.00001, loss_test:0.05602, lr:5.10e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.548, tt:4349.219\n",
      "Ep:119, loss:0.00001, loss_test:0.05664, lr:5.05e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.547, tt:4385.627\n",
      "Ep:120, loss:0.00001, loss_test:0.05618, lr:5.00e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.537, tt:4420.922\n",
      "Ep:121, loss:0.00001, loss_test:0.05569, lr:4.95e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.532, tt:4456.850\n",
      "Ep:122, loss:0.00001, loss_test:0.05585, lr:4.90e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.535, tt:4493.805\n",
      "Ep:123, loss:0.00001, loss_test:0.05586, lr:4.85e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.540, tt:4530.940\n",
      "Ep:124, loss:0.00001, loss_test:0.05598, lr:4.80e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.543, tt:4567.835\n",
      "Ep:125, loss:0.00001, loss_test:0.05548, lr:4.75e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.562, tt:4606.866\n",
      "Ep:126, loss:0.00001, loss_test:0.05607, lr:4.71e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.557, tt:4642.757\n",
      "Ep:127, loss:0.00001, loss_test:0.05556, lr:4.66e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.571, tt:4681.132\n",
      "Ep:128, loss:0.00001, loss_test:0.05517, lr:4.61e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.573, tt:4717.959\n",
      "Ep:129, loss:0.00001, loss_test:0.05568, lr:4.57e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.556, tt:4752.338\n",
      "Ep:130, loss:0.00001, loss_test:0.05531, lr:4.52e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.551, tt:4788.218\n",
      "Ep:131, loss:0.00001, loss_test:0.05535, lr:4.48e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.560, tt:4825.964\n",
      "Ep:132, loss:0.00001, loss_test:0.05474, lr:4.43e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.574, tt:4864.385\n",
      "Ep:133, loss:0.00001, loss_test:0.05510, lr:4.39e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.568, tt:4900.094\n",
      "Ep:134, loss:0.00001, loss_test:0.05584, lr:4.34e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.569, tt:4936.818\n",
      "Ep:135, loss:0.00001, loss_test:0.05508, lr:4.30e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.555, tt:4971.514\n",
      "Ep:136, loss:0.00001, loss_test:0.05503, lr:4.26e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.568, tt:5009.752\n",
      "Ep:137, loss:0.00001, loss_test:0.05486, lr:4.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.580, tt:5048.052\n",
      "Ep:138, loss:0.00001, loss_test:0.05501, lr:4.17e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.588, tt:5085.716\n",
      "Ep:139, loss:0.00001, loss_test:0.05464, lr:4.13e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.587, tt:5122.226\n",
      "Ep:140, loss:0.00001, loss_test:0.05461, lr:4.09e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.583, tt:5158.149\n",
      "Ep:141, loss:0.00001, loss_test:0.05464, lr:4.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.580, tt:5194.402\n",
      "Ep:142, loss:0.00001, loss_test:0.05436, lr:4.01e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.581, tt:5231.119\n",
      "Ep:143, loss:0.00001, loss_test:0.05434, lr:3.97e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.590, tt:5268.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.05463, lr:3.93e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.591, tt:5305.624\n",
      "Ep:145, loss:0.00001, loss_test:0.05453, lr:3.89e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.590, tt:5342.143\n",
      "Ep:146, loss:0.00001, loss_test:0.05429, lr:3.85e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.599, tt:5380.021\n",
      "Ep:147, loss:0.00001, loss_test:0.05405, lr:3.81e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.610, tt:5418.333\n",
      "Ep:148, loss:0.00001, loss_test:0.05418, lr:3.77e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.603, tt:5453.892\n",
      "Ep:149, loss:0.00001, loss_test:0.05402, lr:3.73e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.588, tt:5488.208\n",
      "Ep:150, loss:0.00001, loss_test:0.05428, lr:3.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.591, tt:5525.194\n",
      "Ep:151, loss:0.00001, loss_test:0.05365, lr:3.66e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.594, tt:5562.263\n",
      "Ep:152, loss:0.00001, loss_test:0.05369, lr:3.62e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.595, tt:5599.047\n",
      "Ep:153, loss:0.00001, loss_test:0.05478, lr:3.59e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.599, tt:5636.210\n",
      "Ep:154, loss:0.00001, loss_test:0.05389, lr:3.55e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.583, tt:5670.304\n",
      "Ep:155, loss:0.00001, loss_test:0.05380, lr:3.52e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.582, tt:5706.823\n",
      "Ep:156, loss:0.00001, loss_test:0.05351, lr:3.48e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.588, tt:5744.342\n",
      "Ep:157, loss:0.00001, loss_test:0.05346, lr:3.45e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.584, tt:5780.228\n",
      "Ep:158, loss:0.00001, loss_test:0.05419, lr:3.41e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.585, tt:5817.088\n",
      "Ep:159, loss:0.00001, loss_test:0.05366, lr:3.38e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.586, tt:5853.697\n",
      "Ep:160, loss:0.00001, loss_test:0.05322, lr:3.34e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.586, tt:5890.350\n",
      "Ep:161, loss:0.00001, loss_test:0.05341, lr:3.31e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.591, tt:5927.706\n",
      "Ep:162, loss:0.00001, loss_test:0.05372, lr:3.28e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.597, tt:5965.361\n",
      "Ep:163, loss:0.00001, loss_test:0.05354, lr:3.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.600, tt:6002.453\n",
      "Ep:164, loss:0.00001, loss_test:0.05315, lr:3.21e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.607, tt:6040.146\n",
      "Ep:165, loss:0.00001, loss_test:0.05313, lr:3.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.606, tt:6076.521\n",
      "Ep:166, loss:0.00001, loss_test:0.05333, lr:3.15e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.598, tt:6111.800\n",
      "Ep:167, loss:0.00001, loss_test:0.05340, lr:3.12e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.601, tt:6148.899\n",
      "Ep:168, loss:0.00001, loss_test:0.05292, lr:3.09e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.603, tt:6185.880\n",
      "Ep:169, loss:0.00001, loss_test:0.05294, lr:3.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.605, tt:6222.847\n",
      "Ep:170, loss:0.00001, loss_test:0.05296, lr:3.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.606, tt:6259.630\n",
      "Ep:171, loss:0.00001, loss_test:0.05269, lr:2.99e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.610, tt:6296.876\n",
      "Ep:172, loss:0.00001, loss_test:0.05292, lr:2.96e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.606, tt:6332.775\n",
      "Ep:173, loss:0.00001, loss_test:0.05263, lr:2.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.616, tt:6371.246\n",
      "Ep:174, loss:0.00001, loss_test:0.05265, lr:2.90e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.633, tt:6410.733\n",
      "Ep:175, loss:0.00001, loss_test:0.05291, lr:2.88e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.636, tt:6447.933\n",
      "Ep:176, loss:0.00001, loss_test:0.05296, lr:2.85e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.628, tt:6483.132\n",
      "Ep:177, loss:0.00001, loss_test:0.05264, lr:2.82e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.618, tt:6518.075\n",
      "Ep:178, loss:0.00001, loss_test:0.05239, lr:2.79e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.621, tt:6555.071\n",
      "Ep:179, loss:0.00001, loss_test:0.05267, lr:2.76e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.629, tt:6593.282\n",
      "Ep:180, loss:0.00001, loss_test:0.05255, lr:2.73e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.635, tt:6630.890\n",
      "Ep:181, loss:0.00001, loss_test:0.05268, lr:2.71e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.640, tt:6668.514\n",
      "Ep:182, loss:0.00001, loss_test:0.05273, lr:2.68e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.636, tt:6704.412\n",
      "Ep:183, loss:0.00001, loss_test:0.05214, lr:2.65e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.633, tt:6740.556\n",
      "Ep:184, loss:0.00001, loss_test:0.05263, lr:2.63e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.633, tt:6777.134\n",
      "Ep:185, loss:0.00001, loss_test:0.05297, lr:2.60e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.628, tt:6812.833\n",
      "Ep:186, loss:0.00001, loss_test:0.05243, lr:2.57e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.638, tt:6851.272\n",
      "Ep:187, loss:0.00001, loss_test:0.05238, lr:2.55e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.632, tt:6886.776\n",
      "Ep:188, loss:0.00001, loss_test:0.05229, lr:2.52e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.634, tt:6923.778\n",
      "Ep:189, loss:0.00001, loss_test:0.05206, lr:2.50e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.631, tt:6959.917\n",
      "Ep:190, loss:0.00001, loss_test:0.05258, lr:2.47e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.635, tt:6997.352\n",
      "Ep:191, loss:0.00001, loss_test:0.05257, lr:2.45e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.636, tt:7034.150\n",
      "Ep:192, loss:0.00001, loss_test:0.05194, lr:2.42e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.637, tt:7070.864\n",
      "Ep:193, loss:0.00001, loss_test:0.05237, lr:2.40e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.639, tt:7107.904\n",
      "Ep:194, loss:0.00001, loss_test:0.05259, lr:2.38e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.640, tt:7144.758\n",
      "Ep:195, loss:0.00001, loss_test:0.05246, lr:2.35e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.642, tt:7181.876\n",
      "Ep:196, loss:0.00001, loss_test:0.05215, lr:2.33e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.645, tt:7219.066\n",
      "Ep:197, loss:0.00001, loss_test:0.05207, lr:2.31e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.647, tt:7256.009\n",
      "Ep:198, loss:0.00001, loss_test:0.05212, lr:2.28e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.644, tt:7292.069\n",
      "Ep:199, loss:0.00001, loss_test:0.05226, lr:2.26e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.640, tt:7328.050\n",
      "Ep:200, loss:0.00001, loss_test:0.05220, lr:2.24e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.640, tt:7364.597\n",
      "Ep:201, loss:0.00001, loss_test:0.05209, lr:2.21e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.643, tt:7401.797\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02313, lr:6.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:30.701, tt:30.701\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02433, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:31.235, tt:62.470\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02741, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.792, tt:92.377\n",
      "Ep:3, loss:0.00006, loss_test:0.02844, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.662, tt:122.648\n",
      "Ep:4, loss:0.00006, loss_test:0.02829, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.562, tt:152.808\n",
      "Ep:5, loss:0.00006, loss_test:0.02728, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.211, tt:181.264\n",
      "Ep:6, loss:0.00006, loss_test:0.02560, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.025, tt:210.172\n",
      "Ep:7, loss:0.00005, loss_test:0.02370, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:29.912, tt:239.299\n",
      "Ep:8, loss:0.00005, loss_test:0.02206, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:30.063, tt:270.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00005, loss_test:0.02122, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:29.927, tt:299.267\n",
      "Ep:10, loss:0.00005, loss_test:0.02109, lr:6.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:29.866, tt:328.529\n",
      "Ep:11, loss:0.00004, loss_test:0.02066, lr:6.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:29.801, tt:357.608\n",
      "Ep:12, loss:0.00004, loss_test:0.01956, lr:6.00e-02, fs:0.67521 (r=0.798,p=0.585),  time:29.757, tt:386.847\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:29.674, tt:415.438\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:29.672, tt:445.079\n",
      "Ep:15, loss:0.00004, loss_test:0.01791, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:29.645, tt:474.318\n",
      "Ep:16, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:29.652, tt:504.092\n",
      "Ep:17, loss:0.00004, loss_test:0.01747, lr:6.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:29.625, tt:533.245\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01732, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:29.665, tt:563.635\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01722, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:29.710, tt:594.202\n",
      "Ep:20, loss:0.00004, loss_test:0.01718, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:29.713, tt:623.977\n",
      "Ep:21, loss:0.00004, loss_test:0.01714, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:29.735, tt:654.165\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01707, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:29.797, tt:685.322\n",
      "Ep:23, loss:0.00004, loss_test:0.01694, lr:6.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:29.801, tt:715.218\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01678, lr:6.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:29.841, tt:746.030\n",
      "Ep:25, loss:0.00004, loss_test:0.01663, lr:6.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:29.849, tt:776.062\n",
      "Ep:26, loss:0.00004, loss_test:0.01647, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:29.800, tt:804.593\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:29.793, tt:834.192\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01623, lr:6.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:29.758, tt:862.992\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01604, lr:6.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:29.733, tt:891.976\n",
      "Ep:30, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:29.717, tt:921.239\n",
      "Ep:31, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:29.780, tt:952.966\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01548, lr:6.00e-02, fs:0.75862 (r=0.889,p=0.662),  time:29.778, tt:982.683\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01524, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:29.775, tt:1012.334\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:29.769, tt:1041.931\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01472, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.792, tt:1072.507\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01445, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:29.758, tt:1101.032\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01416, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:29.774, tt:1131.400\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01390, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:29.781, tt:1161.458\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01360, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:29.760, tt:1190.394\n",
      "Ep:40, loss:0.00003, loss_test:0.01328, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.756, tt:1219.982\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01294, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.770, tt:1250.329\n",
      "Ep:42, loss:0.00002, loss_test:0.01260, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:29.808, tt:1281.725\n",
      "Ep:43, loss:0.00002, loss_test:0.01228, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:29.834, tt:1312.681\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01196, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:29.797, tt:1340.885\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01168, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:29.780, tt:1369.857\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01139, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:29.723, tt:1396.958\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01110, lr:6.00e-02, fs:0.87225 (r=1.000,p=0.773),  time:29.712, tt:1426.186\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01083, lr:6.00e-02, fs:0.87225 (r=1.000,p=0.773),  time:29.663, tt:1453.474\n",
      "Ep:49, loss:0.00002, loss_test:0.01060, lr:6.00e-02, fs:0.87611 (r=1.000,p=0.780),  time:29.562, tt:1478.081\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01036, lr:6.00e-02, fs:0.88393 (r=1.000,p=0.792),  time:29.392, tt:1498.980\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01014, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:29.257, tt:1521.381\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.00995, lr:6.00e-02, fs:0.88393 (r=1.000,p=0.792),  time:29.208, tt:1548.024\n",
      "Ep:53, loss:0.00002, loss_test:0.00975, lr:6.00e-02, fs:0.89189 (r=1.000,p=0.805),  time:29.164, tt:1574.872\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.00959, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:29.108, tt:1600.935\n",
      "Ep:55, loss:0.00002, loss_test:0.00947, lr:6.00e-02, fs:0.88393 (r=1.000,p=0.792),  time:29.097, tt:1629.410\n",
      "Ep:56, loss:0.00002, loss_test:0.00931, lr:6.00e-02, fs:0.88393 (r=1.000,p=0.792),  time:29.088, tt:1657.997\n",
      "Ep:57, loss:0.00002, loss_test:0.00916, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:29.061, tt:1685.535\n",
      "Ep:58, loss:0.00002, loss_test:0.00907, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:29.030, tt:1712.754\n",
      "Ep:59, loss:0.00001, loss_test:0.00905, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:28.993, tt:1739.594\n",
      "Ep:60, loss:0.00001, loss_test:0.00900, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:28.927, tt:1764.533\n",
      "Ep:61, loss:0.00001, loss_test:0.00888, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:28.902, tt:1791.901\n",
      "Ep:62, loss:0.00001, loss_test:0.00882, lr:6.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:28.890, tt:1820.040\n",
      "Ep:63, loss:0.00001, loss_test:0.00880, lr:6.00e-02, fs:0.89189 (r=1.000,p=0.805),  time:28.900, tt:1849.595\n",
      "Ep:64, loss:0.00001, loss_test:0.00874, lr:6.00e-02, fs:0.89593 (r=1.000,p=0.811),  time:28.909, tt:1879.055\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.00866, lr:6.00e-02, fs:0.90000 (r=1.000,p=0.818),  time:28.911, tt:1908.108\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.00863, lr:6.00e-02, fs:0.89593 (r=1.000,p=0.811),  time:28.904, tt:1936.600\n",
      "Ep:67, loss:0.00001, loss_test:0.00859, lr:6.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:28.889, tt:1964.447\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.00856, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:28.888, tt:1993.239\n",
      "Ep:69, loss:0.00001, loss_test:0.00846, lr:6.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:28.896, tt:2022.745\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.00848, lr:6.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:28.915, tt:2052.981\n",
      "Ep:71, loss:0.00001, loss_test:0.00848, lr:6.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:28.918, tt:2082.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.00838, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:28.899, tt:2109.623\n",
      "Ep:73, loss:0.00001, loss_test:0.00844, lr:6.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:28.882, tt:2137.284\n",
      "Ep:74, loss:0.00001, loss_test:0.00835, lr:6.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:28.880, tt:2165.984\n",
      "Ep:75, loss:0.00001, loss_test:0.00839, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:28.888, tt:2195.459\n",
      "Ep:76, loss:0.00001, loss_test:0.00840, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:28.903, tt:2225.541\n",
      "Ep:77, loss:0.00001, loss_test:0.00838, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:28.893, tt:2253.668\n",
      "Ep:78, loss:0.00001, loss_test:0.00846, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:28.872, tt:2280.925\n",
      "Ep:79, loss:0.00001, loss_test:0.00836, lr:6.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:28.869, tt:2309.488\n",
      "Ep:80, loss:0.00001, loss_test:0.00846, lr:6.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:28.866, tt:2338.149\n",
      "Ep:81, loss:0.00001, loss_test:0.00835, lr:5.94e-02, fs:0.88571 (r=0.939,p=0.838),  time:28.875, tt:2367.757\n",
      "Ep:82, loss:0.00001, loss_test:0.00852, lr:5.88e-02, fs:0.86957 (r=0.909,p=0.833),  time:28.890, tt:2397.888\n",
      "Ep:83, loss:0.00001, loss_test:0.00841, lr:5.82e-02, fs:0.87805 (r=0.909,p=0.849),  time:28.898, tt:2427.439\n",
      "Ep:84, loss:0.00001, loss_test:0.00845, lr:5.76e-02, fs:0.87685 (r=0.899,p=0.856),  time:28.886, tt:2455.334\n",
      "Ep:85, loss:0.00001, loss_test:0.00842, lr:5.71e-02, fs:0.86700 (r=0.889,p=0.846),  time:28.887, tt:2484.241\n",
      "Ep:86, loss:0.00001, loss_test:0.00845, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:28.880, tt:2512.571\n",
      "Ep:87, loss:0.00001, loss_test:0.00846, lr:5.59e-02, fs:0.87562 (r=0.889,p=0.863),  time:28.886, tt:2541.998\n",
      "Ep:88, loss:0.00001, loss_test:0.00847, lr:5.54e-02, fs:0.88000 (r=0.889,p=0.871),  time:28.879, tt:2570.215\n",
      "Ep:89, loss:0.00001, loss_test:0.00848, lr:5.48e-02, fs:0.88000 (r=0.889,p=0.871),  time:28.875, tt:2598.723\n",
      "Ep:90, loss:0.00001, loss_test:0.00846, lr:5.43e-02, fs:0.88000 (r=0.889,p=0.871),  time:28.878, tt:2627.910\n",
      "Ep:91, loss:0.00001, loss_test:0.00864, lr:5.37e-02, fs:0.87562 (r=0.889,p=0.863),  time:28.864, tt:2655.456\n",
      "Ep:92, loss:0.00001, loss_test:0.00841, lr:5.32e-02, fs:0.88442 (r=0.889,p=0.880),  time:28.869, tt:2684.791\n",
      "Ep:93, loss:0.00001, loss_test:0.00858, lr:5.27e-02, fs:0.88442 (r=0.889,p=0.880),  time:28.862, tt:2713.030\n",
      "Ep:94, loss:0.00001, loss_test:0.00850, lr:5.21e-02, fs:0.88442 (r=0.889,p=0.880),  time:28.861, tt:2741.842\n",
      "Ep:95, loss:0.00001, loss_test:0.00851, lr:5.16e-02, fs:0.87562 (r=0.889,p=0.863),  time:28.870, tt:2771.501\n",
      "Ep:96, loss:0.00001, loss_test:0.00855, lr:5.11e-02, fs:0.88442 (r=0.889,p=0.880),  time:28.860, tt:2799.418\n",
      "Ep:97, loss:0.00001, loss_test:0.00849, lr:5.06e-02, fs:0.88442 (r=0.889,p=0.880),  time:28.852, tt:2827.486\n",
      "Ep:98, loss:0.00001, loss_test:0.00858, lr:5.01e-02, fs:0.88442 (r=0.889,p=0.880),  time:28.844, tt:2855.534\n",
      "Ep:99, loss:0.00001, loss_test:0.00852, lr:4.96e-02, fs:0.88889 (r=0.889,p=0.889),  time:28.847, tt:2884.658\n",
      "Ep:100, loss:0.00001, loss_test:0.00860, lr:4.91e-02, fs:0.88889 (r=0.889,p=0.889),  time:28.858, tt:2914.690\n",
      "Ep:101, loss:0.00001, loss_test:0.00849, lr:4.86e-02, fs:0.89796 (r=0.889,p=0.907),  time:28.863, tt:2944.052\n",
      "Ep:102, loss:0.00001, loss_test:0.00854, lr:4.81e-02, fs:0.89796 (r=0.889,p=0.907),  time:28.839, tt:2970.411\n",
      "Ep:103, loss:0.00001, loss_test:0.00859, lr:4.76e-02, fs:0.88889 (r=0.889,p=0.889),  time:28.826, tt:2997.923\n",
      "Ep:104, loss:0.00001, loss_test:0.00859, lr:4.71e-02, fs:0.89796 (r=0.889,p=0.907),  time:28.833, tt:3027.421\n",
      "Ep:105, loss:0.00001, loss_test:0.00857, lr:4.67e-02, fs:0.89796 (r=0.889,p=0.907),  time:28.830, tt:3055.996\n",
      "Ep:106, loss:0.00001, loss_test:0.00860, lr:4.62e-02, fs:0.89340 (r=0.889,p=0.898),  time:28.842, tt:3086.075\n",
      "Ep:107, loss:0.00001, loss_test:0.00853, lr:4.57e-02, fs:0.89796 (r=0.889,p=0.907),  time:28.841, tt:3114.820\n",
      "Ep:108, loss:0.00000, loss_test:0.00852, lr:4.53e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.844, tt:3143.969\n",
      "Ep:109, loss:0.00000, loss_test:0.00867, lr:4.48e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.840, tt:3172.417\n",
      "Ep:110, loss:0.00000, loss_test:0.00849, lr:4.44e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.834, tt:3200.581\n",
      "Ep:111, loss:0.00000, loss_test:0.00869, lr:4.39e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.840, tt:3230.123\n",
      "Ep:112, loss:0.00000, loss_test:0.00854, lr:4.35e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.837, tt:3258.546\n",
      "Ep:113, loss:0.00000, loss_test:0.00869, lr:4.31e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.831, tt:3286.689\n",
      "Ep:114, loss:0.00000, loss_test:0.00857, lr:4.26e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.755, tt:3306.853\n",
      "Ep:115, loss:0.00000, loss_test:0.00862, lr:4.22e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.567, tt:3313.823\n",
      "Ep:116, loss:0.00000, loss_test:0.00864, lr:4.18e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.381, tt:3320.533\n",
      "Ep:117, loss:0.00000, loss_test:0.00863, lr:4.14e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.197, tt:3327.204\n",
      "Ep:118, loss:0.00000, loss_test:0.00865, lr:4.10e-02, fs:0.90256 (r=0.889,p=0.917),  time:28.027, tt:3335.231\n",
      "Ep:119, loss:0.00000, loss_test:0.00863, lr:4.05e-02, fs:0.90256 (r=0.889,p=0.917),  time:27.859, tt:3343.122\n",
      "Ep:120, loss:0.00000, loss_test:0.00866, lr:4.01e-02, fs:0.90256 (r=0.889,p=0.917),  time:27.693, tt:3350.803\n",
      "Ep:121, loss:0.00000, loss_test:0.00869, lr:3.97e-02, fs:0.90256 (r=0.889,p=0.917),  time:27.520, tt:3357.501\n",
      "Ep:122, loss:0.00000, loss_test:0.00864, lr:3.93e-02, fs:0.90256 (r=0.889,p=0.917),  time:27.352, tt:3364.306\n",
      "Ep:123, loss:0.00000, loss_test:0.00869, lr:3.89e-02, fs:0.90256 (r=0.889,p=0.917),  time:27.187, tt:3371.168\n",
      "Ep:124, loss:0.00000, loss_test:0.00868, lr:3.86e-02, fs:0.90256 (r=0.889,p=0.917),  time:27.024, tt:3377.996\n",
      "Ep:125, loss:0.00000, loss_test:0.00874, lr:3.82e-02, fs:0.90256 (r=0.889,p=0.917),  time:26.864, tt:3384.815\n",
      "Ep:126, loss:0.00000, loss_test:0.00875, lr:3.78e-02, fs:0.90722 (r=0.889,p=0.926),  time:26.705, tt:3391.565\n",
      "Ep:127, loss:0.00000, loss_test:0.00870, lr:3.74e-02, fs:0.90722 (r=0.889,p=0.926),  time:26.550, tt:3398.361\n",
      "Ep:128, loss:0.00000, loss_test:0.00881, lr:3.70e-02, fs:0.90722 (r=0.889,p=0.926),  time:26.397, tt:3405.153\n",
      "Ep:129, loss:0.00000, loss_test:0.00869, lr:3.67e-02, fs:0.90256 (r=0.889,p=0.917),  time:26.245, tt:3411.883\n",
      "Ep:130, loss:0.00000, loss_test:0.00877, lr:3.63e-02, fs:0.90722 (r=0.889,p=0.926),  time:26.099, tt:3418.963\n",
      "Ep:131, loss:0.00000, loss_test:0.00878, lr:3.59e-02, fs:0.90722 (r=0.889,p=0.926),  time:25.958, tt:3426.395\n",
      "Ep:132, loss:0.00000, loss_test:0.00875, lr:3.56e-02, fs:0.90722 (r=0.889,p=0.926),  time:25.818, tt:3433.843\n",
      "Ep:133, loss:0.00000, loss_test:0.00881, lr:3.52e-02, fs:0.90722 (r=0.889,p=0.926),  time:25.681, tt:3441.306\n",
      "Ep:134, loss:0.00000, loss_test:0.00880, lr:3.49e-02, fs:0.90722 (r=0.889,p=0.926),  time:25.546, tt:3448.758\n",
      "Ep:135, loss:0.00000, loss_test:0.00883, lr:3.45e-02, fs:0.90722 (r=0.889,p=0.926),  time:25.414, tt:3456.273\n",
      "Ep:136, loss:0.00000, loss_test:0.00874, lr:3.42e-02, fs:0.90155 (r=0.879,p=0.926),  time:25.278, tt:3463.118\n",
      "Ep:137, loss:0.00000, loss_test:0.00884, lr:3.38e-02, fs:0.90155 (r=0.879,p=0.926),  time:25.144, tt:3469.922\n",
      "Ep:138, loss:0.00000, loss_test:0.00886, lr:3.35e-02, fs:0.90155 (r=0.879,p=0.926),  time:25.013, tt:3476.761\n",
      "Ep:139, loss:0.00000, loss_test:0.00877, lr:3.32e-02, fs:0.90155 (r=0.879,p=0.926),  time:24.883, tt:3483.621\n",
      "Ep:140, loss:0.00000, loss_test:0.00890, lr:3.28e-02, fs:0.90625 (r=0.879,p=0.935),  time:24.755, tt:3490.433\n",
      "Ep:141, loss:0.00000, loss_test:0.00888, lr:3.25e-02, fs:0.90155 (r=0.879,p=0.926),  time:24.628, tt:3497.220\n",
      "Ep:142, loss:0.00000, loss_test:0.00883, lr:3.22e-02, fs:0.90155 (r=0.879,p=0.926),  time:24.503, tt:3503.937\n",
      "Ep:143, loss:0.00000, loss_test:0.00892, lr:3.19e-02, fs:0.90625 (r=0.879,p=0.935),  time:24.380, tt:3510.658\n",
      "Ep:144, loss:0.00000, loss_test:0.00891, lr:3.15e-02, fs:0.90155 (r=0.879,p=0.926),  time:24.258, tt:3517.467\n",
      "Ep:145, loss:0.00000, loss_test:0.00895, lr:3.12e-02, fs:0.90155 (r=0.879,p=0.926),  time:24.139, tt:3524.306\n",
      "Ep:146, loss:0.00000, loss_test:0.00896, lr:3.09e-02, fs:0.90155 (r=0.879,p=0.926),  time:24.020, tt:3531.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.00894, lr:3.06e-02, fs:0.90625 (r=0.879,p=0.935),  time:23.904, tt:3537.744\n",
      "Ep:148, loss:0.00000, loss_test:0.00896, lr:3.03e-02, fs:0.90155 (r=0.879,p=0.926),  time:23.790, tt:3544.637\n",
      "Ep:149, loss:0.00000, loss_test:0.00901, lr:3.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:23.676, tt:3551.382\n",
      "Ep:150, loss:0.00000, loss_test:0.00900, lr:2.97e-02, fs:0.90625 (r=0.879,p=0.935),  time:23.564, tt:3558.170\n",
      "Ep:151, loss:0.00000, loss_test:0.00898, lr:2.94e-02, fs:0.90155 (r=0.879,p=0.926),  time:23.453, tt:3564.874\n",
      "Ep:152, loss:0.00000, loss_test:0.00912, lr:2.91e-02, fs:0.90155 (r=0.879,p=0.926),  time:23.344, tt:3571.616\n",
      "Ep:153, loss:0.00000, loss_test:0.00900, lr:2.88e-02, fs:0.90625 (r=0.879,p=0.935),  time:23.236, tt:3578.376\n",
      "Ep:154, loss:0.00000, loss_test:0.00909, lr:2.85e-02, fs:0.90625 (r=0.879,p=0.935),  time:23.130, tt:3585.081\n",
      "Ep:155, loss:0.00000, loss_test:0.00909, lr:2.82e-02, fs:0.90155 (r=0.879,p=0.926),  time:23.025, tt:3591.880\n",
      "Ep:156, loss:0.00000, loss_test:0.00905, lr:2.80e-02, fs:0.90155 (r=0.879,p=0.926),  time:22.921, tt:3598.613\n",
      "Ep:157, loss:0.00000, loss_test:0.00915, lr:2.77e-02, fs:0.90625 (r=0.879,p=0.935),  time:22.819, tt:3605.344\n",
      "Ep:158, loss:0.00000, loss_test:0.00912, lr:2.74e-02, fs:0.90625 (r=0.879,p=0.935),  time:22.718, tt:3612.145\n",
      "Ep:159, loss:0.00000, loss_test:0.00912, lr:2.71e-02, fs:0.90625 (r=0.879,p=0.935),  time:22.618, tt:3618.913\n",
      "Ep:160, loss:0.00000, loss_test:0.00920, lr:2.69e-02, fs:0.91099 (r=0.879,p=0.946),  time:22.528, tt:3627.022\n",
      "##########Best model found so far##########\n",
      "Ep:161, loss:0.00000, loss_test:0.00919, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:22.431, tt:3633.774\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00000, loss_test:0.00915, lr:2.69e-02, fs:0.91099 (r=0.879,p=0.946),  time:22.335, tt:3640.575\n",
      "Ep:163, loss:0.00000, loss_test:0.00921, lr:2.69e-02, fs:0.91099 (r=0.879,p=0.946),  time:22.240, tt:3647.364\n",
      "Ep:164, loss:0.00000, loss_test:0.00925, lr:2.69e-02, fs:0.91099 (r=0.879,p=0.946),  time:22.147, tt:3654.212\n",
      "Ep:165, loss:0.00000, loss_test:0.00919, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:22.054, tt:3660.957\n",
      "Ep:166, loss:0.00000, loss_test:0.00927, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.962, tt:3667.695\n",
      "Ep:167, loss:0.00000, loss_test:0.00928, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.872, tt:3674.412\n",
      "Ep:168, loss:0.00000, loss_test:0.00924, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.782, tt:3681.207\n",
      "Ep:169, loss:0.00000, loss_test:0.00933, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.695, tt:3688.079\n",
      "Ep:170, loss:0.00000, loss_test:0.00931, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.607, tt:3694.812\n",
      "Ep:171, loss:0.00000, loss_test:0.00932, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.521, tt:3701.551\n",
      "Ep:172, loss:0.00000, loss_test:0.00940, lr:2.69e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.435, tt:3708.329\n",
      "Ep:173, loss:0.00000, loss_test:0.00937, lr:2.66e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.351, tt:3715.059\n",
      "Ep:174, loss:0.00000, loss_test:0.00939, lr:2.63e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.267, tt:3721.803\n",
      "Ep:175, loss:0.00000, loss_test:0.00937, lr:2.61e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.185, tt:3728.593\n",
      "Ep:176, loss:0.00000, loss_test:0.00946, lr:2.58e-02, fs:0.91005 (r=0.869,p=0.956),  time:21.104, tt:3735.323\n",
      "Ep:177, loss:0.00000, loss_test:0.00941, lr:2.55e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.022, tt:3741.979\n",
      "Ep:178, loss:0.00000, loss_test:0.00947, lr:2.53e-02, fs:0.91579 (r=0.879,p=0.956),  time:20.943, tt:3748.758\n",
      "Ep:179, loss:0.00000, loss_test:0.00953, lr:2.50e-02, fs:0.91005 (r=0.869,p=0.956),  time:20.864, tt:3755.542\n",
      "Ep:180, loss:0.00000, loss_test:0.00940, lr:2.48e-02, fs:0.91099 (r=0.879,p=0.946),  time:20.786, tt:3762.354\n",
      "Ep:181, loss:0.00000, loss_test:0.00951, lr:2.45e-02, fs:0.91579 (r=0.879,p=0.956),  time:20.710, tt:3769.204\n",
      "Ep:182, loss:0.00000, loss_test:0.00954, lr:2.43e-02, fs:0.91005 (r=0.869,p=0.956),  time:20.634, tt:3775.993\n",
      "Ep:183, loss:0.00000, loss_test:0.00951, lr:2.40e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.559, tt:3782.802\n",
      "Ep:184, loss:0.00000, loss_test:0.00955, lr:2.38e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.484, tt:3789.584\n",
      "Ep:185, loss:0.00000, loss_test:0.00959, lr:2.36e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.410, tt:3796.328\n",
      "Ep:186, loss:0.00000, loss_test:0.00956, lr:2.33e-02, fs:0.91099 (r=0.879,p=0.946),  time:20.337, tt:3803.105\n",
      "Ep:187, loss:0.00000, loss_test:0.00959, lr:2.31e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.265, tt:3809.821\n",
      "Ep:188, loss:0.00000, loss_test:0.00962, lr:2.29e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.193, tt:3816.536\n",
      "Ep:189, loss:0.00000, loss_test:0.00960, lr:2.26e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.122, tt:3823.273\n",
      "Ep:190, loss:0.00000, loss_test:0.00965, lr:2.24e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.052, tt:3830.001\n",
      "Ep:191, loss:0.00000, loss_test:0.00964, lr:2.22e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.983, tt:3836.782\n",
      "Ep:192, loss:0.00000, loss_test:0.00966, lr:2.20e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.915, tt:3843.624\n",
      "Ep:193, loss:0.00000, loss_test:0.00968, lr:2.17e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.847, tt:3850.379\n",
      "Ep:194, loss:0.00000, loss_test:0.00964, lr:2.15e-02, fs:0.91099 (r=0.879,p=0.946),  time:19.780, tt:3857.174\n",
      "Ep:195, loss:0.00000, loss_test:0.00977, lr:2.13e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.714, tt:3863.902\n",
      "Ep:196, loss:0.00000, loss_test:0.00969, lr:2.11e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.648, tt:3870.703\n",
      "Ep:197, loss:0.00000, loss_test:0.00964, lr:2.09e-02, fs:0.91099 (r=0.879,p=0.946),  time:19.583, tt:3877.491\n",
      "Ep:198, loss:0.00000, loss_test:0.00981, lr:2.07e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.519, tt:3884.285\n",
      "Ep:199, loss:0.00000, loss_test:0.00977, lr:2.05e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.455, tt:3891.080\n",
      "Ep:200, loss:0.00000, loss_test:0.00972, lr:2.03e-02, fs:0.90526 (r=0.869,p=0.945),  time:19.393, tt:3897.913\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12437, lr:1.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:6.996, tt:6.996\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12096, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:6.963, tt:13.927\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11744, lr:1.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:6.962, tt:20.887\n",
      "Ep:3, loss:0.00025, loss_test:0.11410, lr:1.00e-02, fs:0.69298 (r=0.798,p=0.612),  time:6.973, tt:27.891\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11046, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:6.962, tt:34.811\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10591, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:6.955, tt:41.732\n",
      "Ep:6, loss:0.00024, loss_test:0.10192, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:6.952, tt:48.663\n",
      "Ep:7, loss:0.00023, loss_test:0.09956, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:6.945, tt:55.559\n",
      "Ep:8, loss:0.00023, loss_test:0.09741, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:6.942, tt:62.474\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09540, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:6.940, tt:69.402\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.09380, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:6.940, tt:76.338\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.09282, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:6.941, tt:83.290\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09190, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:6.942, tt:90.252\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00021, loss_test:0.09093, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:6.940, tt:97.165\n",
      "Ep:14, loss:0.00020, loss_test:0.09023, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:6.941, tt:104.117\n",
      "Ep:15, loss:0.00020, loss_test:0.08944, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:6.946, tt:111.134\n",
      "Ep:16, loss:0.00020, loss_test:0.08857, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:6.967, tt:118.441\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.08780, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:6.968, tt:125.417\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.08714, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:6.964, tt:132.317\n",
      "Ep:19, loss:0.00019, loss_test:0.08609, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:6.965, tt:139.305\n",
      "Ep:20, loss:0.00019, loss_test:0.08416, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:6.964, tt:146.237\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.08386, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:6.968, tt:153.307\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.08270, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:6.965, tt:160.187\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08105, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:6.962, tt:167.099\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.08103, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:6.967, tt:174.173\n",
      "Ep:25, loss:0.00017, loss_test:0.07950, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:6.976, tt:181.372\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.07780, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:6.973, tt:188.263\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.07749, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:6.972, tt:195.206\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.07633, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:6.971, tt:202.169\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.07570, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:6.971, tt:209.136\n",
      "Ep:30, loss:0.00015, loss_test:0.07471, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:6.969, tt:216.051\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.07390, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:6.969, tt:223.022\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.07382, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:6.971, tt:230.033\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07225, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:6.971, tt:237.024\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.07152, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:6.970, tt:243.942\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.07090, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:6.970, tt:250.905\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.06937, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:6.970, tt:257.879\n",
      "Ep:37, loss:0.00012, loss_test:0.06918, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:6.971, tt:264.881\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.06768, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:6.969, tt:271.805\n",
      "Ep:39, loss:0.00011, loss_test:0.06737, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:6.969, tt:278.749\n",
      "Ep:40, loss:0.00010, loss_test:0.06812, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:6.972, tt:285.841\n",
      "Ep:41, loss:0.00010, loss_test:0.06619, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:6.973, tt:292.859\n",
      "Ep:42, loss:0.00010, loss_test:0.06469, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:6.973, tt:299.839\n",
      "Ep:43, loss:0.00009, loss_test:0.06332, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:6.974, tt:306.838\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.06252, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:6.973, tt:313.792\n",
      "Ep:45, loss:0.00009, loss_test:0.06193, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:6.975, tt:320.856\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.06289, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:6.975, tt:327.806\n",
      "Ep:47, loss:0.00008, loss_test:0.06147, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:6.976, tt:334.834\n",
      "Ep:48, loss:0.00008, loss_test:0.06043, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:6.977, tt:341.858\n",
      "Ep:49, loss:0.00007, loss_test:0.05920, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:6.980, tt:348.990\n",
      "Ep:50, loss:0.00007, loss_test:0.05826, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:6.980, tt:355.994\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.05900, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:6.982, tt:363.052\n",
      "Ep:52, loss:0.00007, loss_test:0.05734, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:6.982, tt:370.064\n",
      "Ep:53, loss:0.00007, loss_test:0.05730, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:6.983, tt:377.080\n",
      "Ep:54, loss:0.00006, loss_test:0.05765, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:6.984, tt:384.100\n",
      "Ep:55, loss:0.00006, loss_test:0.05717, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:6.985, tt:391.147\n",
      "Ep:56, loss:0.00006, loss_test:0.05808, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:6.986, tt:398.197\n",
      "Ep:57, loss:0.00006, loss_test:0.05626, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:6.999, tt:405.935\n",
      "Ep:58, loss:0.00006, loss_test:0.05594, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:7.000, tt:413.009\n",
      "Ep:59, loss:0.00006, loss_test:0.05310, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:7.001, tt:420.036\n",
      "Ep:60, loss:0.00005, loss_test:0.05470, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:7.000, tt:426.984\n",
      "Ep:61, loss:0.00005, loss_test:0.05459, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:7.000, tt:434.007\n",
      "Ep:62, loss:0.00005, loss_test:0.05268, lr:9.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:6.999, tt:440.961\n",
      "Ep:63, loss:0.00005, loss_test:0.05368, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:7.000, tt:447.981\n",
      "Ep:64, loss:0.00005, loss_test:0.05163, lr:9.70e-03, fs:0.87179 (r=0.859,p=0.885),  time:6.998, tt:454.885\n",
      "Ep:65, loss:0.00005, loss_test:0.05246, lr:9.61e-03, fs:0.88542 (r=0.859,p=0.914),  time:7.011, tt:462.697\n",
      "Ep:66, loss:0.00004, loss_test:0.04925, lr:9.51e-03, fs:0.87958 (r=0.848,p=0.913),  time:7.043, tt:471.896\n",
      "Ep:67, loss:0.00004, loss_test:0.05212, lr:9.41e-03, fs:0.88205 (r=0.869,p=0.896),  time:7.059, tt:479.985\n",
      "Ep:68, loss:0.00004, loss_test:0.04873, lr:9.32e-03, fs:0.88660 (r=0.869,p=0.905),  time:7.110, tt:490.596\n",
      "Ep:69, loss:0.00004, loss_test:0.05122, lr:9.23e-03, fs:0.87755 (r=0.869,p=0.887),  time:7.210, tt:504.715\n",
      "Ep:70, loss:0.00004, loss_test:0.04950, lr:9.14e-03, fs:0.89691 (r=0.879,p=0.916),  time:7.399, tt:525.295\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.04942, lr:9.14e-03, fs:0.87500 (r=0.848,p=0.903),  time:7.663, tt:551.770\n",
      "Ep:72, loss:0.00004, loss_test:0.04990, lr:9.14e-03, fs:0.88776 (r=0.879,p=0.897),  time:7.982, tt:582.701\n",
      "Ep:73, loss:0.00004, loss_test:0.04895, lr:9.14e-03, fs:0.88083 (r=0.859,p=0.904),  time:8.288, tt:613.294\n",
      "Ep:74, loss:0.00003, loss_test:0.05115, lr:9.14e-03, fs:0.88205 (r=0.869,p=0.896),  time:8.593, tt:644.453\n",
      "Ep:75, loss:0.00003, loss_test:0.04796, lr:9.14e-03, fs:0.88325 (r=0.879,p=0.888),  time:8.896, tt:676.133\n",
      "Ep:76, loss:0.00003, loss_test:0.04862, lr:9.14e-03, fs:0.88205 (r=0.869,p=0.896),  time:9.165, tt:705.737\n",
      "Ep:77, loss:0.00003, loss_test:0.04821, lr:9.14e-03, fs:0.87879 (r=0.879,p=0.879),  time:9.446, tt:736.764\n",
      "Ep:78, loss:0.00003, loss_test:0.04731, lr:9.14e-03, fs:0.89474 (r=0.859,p=0.934),  time:9.726, tt:768.343\n",
      "Ep:79, loss:0.00003, loss_test:0.04934, lr:9.14e-03, fs:0.88776 (r=0.879,p=0.897),  time:9.988, tt:799.037\n",
      "Ep:80, loss:0.00003, loss_test:0.04642, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:10.280, tt:832.641\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:81, loss:0.00003, loss_test:0.05107, lr:9.14e-03, fs:0.87629 (r=0.859,p=0.895),  time:10.532, tt:863.638\n",
      "Ep:82, loss:0.00003, loss_test:0.04688, lr:9.14e-03, fs:0.88776 (r=0.879,p=0.897),  time:10.790, tt:895.606\n",
      "Ep:83, loss:0.00003, loss_test:0.04823, lr:9.14e-03, fs:0.89005 (r=0.859,p=0.924),  time:11.024, tt:926.002\n",
      "Ep:84, loss:0.00003, loss_test:0.04603, lr:9.14e-03, fs:0.88776 (r=0.879,p=0.897),  time:11.260, tt:957.114\n",
      "Ep:85, loss:0.00003, loss_test:0.04565, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:11.482, tt:987.487\n",
      "Ep:86, loss:0.00003, loss_test:0.04465, lr:9.14e-03, fs:0.89583 (r=0.869,p=0.925),  time:11.691, tt:1017.097\n",
      "Ep:87, loss:0.00002, loss_test:0.04561, lr:9.14e-03, fs:0.88776 (r=0.879,p=0.897),  time:11.907, tt:1047.821\n",
      "Ep:88, loss:0.00002, loss_test:0.04698, lr:9.14e-03, fs:0.89474 (r=0.859,p=0.934),  time:12.114, tt:1078.156\n",
      "Ep:89, loss:0.00002, loss_test:0.04507, lr:9.14e-03, fs:0.88776 (r=0.879,p=0.897),  time:12.344, tt:1110.999\n",
      "Ep:90, loss:0.00002, loss_test:0.04548, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:12.550, tt:1142.038\n",
      "Ep:91, loss:0.00002, loss_test:0.04371, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:12.741, tt:1172.165\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.04611, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:12.922, tt:1201.776\n",
      "Ep:93, loss:0.00002, loss_test:0.04262, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:13.103, tt:1231.653\n",
      "Ep:94, loss:0.00002, loss_test:0.04360, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:13.286, tt:1262.128\n",
      "Ep:95, loss:0.00002, loss_test:0.04535, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:13.467, tt:1292.820\n",
      "Ep:96, loss:0.00002, loss_test:0.04382, lr:9.14e-03, fs:0.89947 (r=0.859,p=0.944),  time:13.644, tt:1323.452\n",
      "Ep:97, loss:0.00002, loss_test:0.04351, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:13.802, tt:1352.583\n",
      "Ep:98, loss:0.00002, loss_test:0.04408, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:13.963, tt:1382.374\n",
      "Ep:99, loss:0.00002, loss_test:0.04469, lr:9.14e-03, fs:0.88660 (r=0.869,p=0.905),  time:14.159, tt:1415.893\n",
      "Ep:100, loss:0.00002, loss_test:0.04531, lr:9.14e-03, fs:0.89691 (r=0.879,p=0.916),  time:14.324, tt:1446.740\n",
      "Ep:101, loss:0.00002, loss_test:0.04166, lr:9.14e-03, fs:0.91099 (r=0.879,p=0.946),  time:14.482, tt:1477.127\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00002, loss_test:0.04476, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:14.644, tt:1508.373\n",
      "Ep:103, loss:0.00002, loss_test:0.04059, lr:9.14e-03, fs:0.91099 (r=0.879,p=0.946),  time:14.788, tt:1537.920\n",
      "Ep:104, loss:0.00002, loss_test:0.04503, lr:9.14e-03, fs:0.89583 (r=0.869,p=0.925),  time:14.936, tt:1568.240\n",
      "Ep:105, loss:0.00002, loss_test:0.04108, lr:9.14e-03, fs:0.91099 (r=0.879,p=0.946),  time:15.082, tt:1598.677\n",
      "Ep:106, loss:0.00002, loss_test:0.04511, lr:9.14e-03, fs:0.89691 (r=0.879,p=0.916),  time:15.224, tt:1629.021\n",
      "Ep:107, loss:0.00002, loss_test:0.04105, lr:9.14e-03, fs:0.91579 (r=0.879,p=0.956),  time:15.380, tt:1661.092\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00002, loss_test:0.04386, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:15.523, tt:1692.015\n",
      "Ep:109, loss:0.00002, loss_test:0.04292, lr:9.14e-03, fs:0.91099 (r=0.879,p=0.946),  time:15.648, tt:1721.327\n",
      "Ep:110, loss:0.00002, loss_test:0.04242, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:15.799, tt:1753.722\n",
      "Ep:111, loss:0.00001, loss_test:0.04257, lr:9.14e-03, fs:0.91099 (r=0.879,p=0.946),  time:15.941, tt:1785.405\n",
      "Ep:112, loss:0.00001, loss_test:0.04232, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:16.069, tt:1815.744\n",
      "Ep:113, loss:0.00001, loss_test:0.04303, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:16.209, tt:1847.771\n",
      "Ep:114, loss:0.00001, loss_test:0.04208, lr:9.14e-03, fs:0.91579 (r=0.879,p=0.956),  time:16.340, tt:1879.052\n",
      "Ep:115, loss:0.00001, loss_test:0.04338, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:16.449, tt:1908.103\n",
      "Ep:116, loss:0.00001, loss_test:0.04131, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:16.573, tt:1939.081\n",
      "Ep:117, loss:0.00001, loss_test:0.04099, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:16.699, tt:1970.440\n",
      "Ep:118, loss:0.00001, loss_test:0.04264, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:16.824, tt:2002.011\n",
      "Ep:119, loss:0.00001, loss_test:0.04155, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:16.940, tt:2032.826\n",
      "Ep:120, loss:0.00001, loss_test:0.04310, lr:8.95e-03, fs:0.90155 (r=0.879,p=0.926),  time:17.056, tt:2063.794\n",
      "Ep:121, loss:0.00001, loss_test:0.04169, lr:8.86e-03, fs:0.90625 (r=0.879,p=0.935),  time:17.161, tt:2093.606\n",
      "Ep:122, loss:0.00001, loss_test:0.04317, lr:8.78e-03, fs:0.90155 (r=0.879,p=0.926),  time:17.266, tt:2123.671\n",
      "Ep:123, loss:0.00001, loss_test:0.04184, lr:8.69e-03, fs:0.90155 (r=0.879,p=0.926),  time:17.378, tt:2154.912\n",
      "Ep:124, loss:0.00001, loss_test:0.04337, lr:8.60e-03, fs:0.91579 (r=0.879,p=0.956),  time:17.482, tt:2185.225\n",
      "Ep:125, loss:0.00001, loss_test:0.04213, lr:8.51e-03, fs:0.90155 (r=0.879,p=0.926),  time:17.599, tt:2217.468\n",
      "Ep:126, loss:0.00001, loss_test:0.04318, lr:8.43e-03, fs:0.90625 (r=0.879,p=0.935),  time:17.691, tt:2246.713\n",
      "Ep:127, loss:0.00001, loss_test:0.04222, lr:8.35e-03, fs:0.90155 (r=0.879,p=0.926),  time:17.798, tt:2278.157\n",
      "Ep:128, loss:0.00001, loss_test:0.04311, lr:8.26e-03, fs:0.90155 (r=0.879,p=0.926),  time:17.908, tt:2310.136\n",
      "Ep:129, loss:0.00001, loss_test:0.04183, lr:8.18e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.021, tt:2342.788\n",
      "Ep:130, loss:0.00001, loss_test:0.04347, lr:8.10e-03, fs:0.90155 (r=0.879,p=0.926),  time:18.110, tt:2372.406\n",
      "Ep:131, loss:0.00001, loss_test:0.04247, lr:8.02e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.203, tt:2402.850\n",
      "Ep:132, loss:0.00001, loss_test:0.04280, lr:7.94e-03, fs:0.90155 (r=0.879,p=0.926),  time:18.294, tt:2433.052\n",
      "Ep:133, loss:0.00001, loss_test:0.04314, lr:7.86e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.377, tt:2462.528\n",
      "Ep:134, loss:0.00001, loss_test:0.04241, lr:7.78e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.478, tt:2494.527\n",
      "Ep:135, loss:0.00001, loss_test:0.04407, lr:7.70e-03, fs:0.90155 (r=0.879,p=0.926),  time:18.585, tt:2527.558\n",
      "Ep:136, loss:0.00001, loss_test:0.04336, lr:7.62e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.670, tt:2557.781\n",
      "Ep:137, loss:0.00001, loss_test:0.04339, lr:7.55e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.758, tt:2588.556\n",
      "Ep:138, loss:0.00001, loss_test:0.04469, lr:7.47e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.842, tt:2619.013\n",
      "Ep:139, loss:0.00001, loss_test:0.04280, lr:7.40e-03, fs:0.90625 (r=0.879,p=0.935),  time:18.921, tt:2648.940\n",
      "Ep:143, loss:0.00001, loss_test:0.04301, lr:7.11e-03, fs:0.90625 (r=0.879,p=0.935),  time:19.255, tt:2772.751\n",
      "Ep:144, loss:0.00001, loss_test:0.04523, lr:7.03e-03, fs:0.90625 (r=0.879,p=0.935),  time:19.332, tt:2803.196\n",
      "Ep:145, loss:0.00001, loss_test:0.04341, lr:6.96e-03, fs:0.90625 (r=0.879,p=0.935),  time:19.413, tt:2834.358\n",
      "Ep:146, loss:0.00001, loss_test:0.04674, lr:6.89e-03, fs:0.90155 (r=0.879,p=0.926),  time:19.494, tt:2865.621\n",
      "Ep:147, loss:0.00001, loss_test:0.04367, lr:6.83e-03, fs:0.91099 (r=0.879,p=0.946),  time:19.565, tt:2895.685\n",
      "Ep:148, loss:0.00001, loss_test:0.04653, lr:6.76e-03, fs:0.90155 (r=0.879,p=0.926),  time:19.645, tt:2927.108\n",
      "Ep:149, loss:0.00001, loss_test:0.04499, lr:6.69e-03, fs:0.90625 (r=0.879,p=0.935),  time:19.723, tt:2958.487\n",
      "Ep:150, loss:0.00001, loss_test:0.04725, lr:6.62e-03, fs:0.90625 (r=0.879,p=0.935),  time:19.815, tt:2992.057\n",
      "Ep:151, loss:0.00001, loss_test:0.04443, lr:6.56e-03, fs:0.91579 (r=0.879,p=0.956),  time:19.886, tt:3022.648\n",
      "Ep:152, loss:0.00001, loss_test:0.04600, lr:6.49e-03, fs:0.90625 (r=0.879,p=0.935),  time:19.951, tt:3052.470\n",
      "Ep:153, loss:0.00001, loss_test:0.04522, lr:6.43e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.021, tt:3083.246\n",
      "Ep:154, loss:0.00001, loss_test:0.04609, lr:6.36e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.091, tt:3114.146\n",
      "Ep:155, loss:0.00001, loss_test:0.04666, lr:6.30e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.159, tt:3144.815\n",
      "Ep:156, loss:0.00001, loss_test:0.04595, lr:6.24e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.228, tt:3175.843\n",
      "Ep:157, loss:0.00001, loss_test:0.04604, lr:6.17e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.293, tt:3206.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:158, loss:0.00001, loss_test:0.04528, lr:6.11e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.359, tt:3237.004\n",
      "Ep:159, loss:0.00001, loss_test:0.04600, lr:6.05e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.424, tt:3267.796\n",
      "Ep:160, loss:0.00001, loss_test:0.04666, lr:5.99e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.478, tt:3296.995\n",
      "Ep:161, loss:0.00001, loss_test:0.04563, lr:5.93e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.546, tt:3328.472\n",
      "Ep:162, loss:0.00001, loss_test:0.04742, lr:5.87e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.614, tt:3360.158\n",
      "Ep:163, loss:0.00001, loss_test:0.04594, lr:5.81e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.670, tt:3389.854\n",
      "Ep:164, loss:0.00001, loss_test:0.04715, lr:5.75e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.734, tt:3421.097\n",
      "Ep:165, loss:0.00001, loss_test:0.04638, lr:5.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.794, tt:3451.764\n",
      "Ep:166, loss:0.00001, loss_test:0.04690, lr:5.64e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.854, tt:3482.700\n",
      "Ep:167, loss:0.00001, loss_test:0.04720, lr:5.58e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.908, tt:3512.532\n",
      "Ep:168, loss:0.00001, loss_test:0.04679, lr:5.53e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.971, tt:3544.027\n",
      "Ep:169, loss:0.00001, loss_test:0.04570, lr:5.47e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.034, tt:3575.861\n",
      "Ep:170, loss:0.00001, loss_test:0.04772, lr:5.42e-03, fs:0.90625 (r=0.879,p=0.935),  time:21.090, tt:3606.373\n",
      "Ep:171, loss:0.00001, loss_test:0.04585, lr:5.36e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.148, tt:3637.389\n",
      "Ep:172, loss:0.00001, loss_test:0.04752, lr:5.31e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.198, tt:3667.234\n",
      "Ep:173, loss:0.00001, loss_test:0.04655, lr:5.26e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.250, tt:3697.428\n",
      "Ep:174, loss:0.00001, loss_test:0.04750, lr:5.20e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.319, tt:3730.897\n",
      "Ep:175, loss:0.00001, loss_test:0.04719, lr:5.15e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.377, tt:3762.332\n",
      "Ep:176, loss:0.00001, loss_test:0.04696, lr:5.10e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.423, tt:3791.904\n",
      "Ep:177, loss:0.00001, loss_test:0.04712, lr:5.05e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.470, tt:3821.663\n",
      "Ep:178, loss:0.00001, loss_test:0.04713, lr:5.00e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.530, tt:3853.905\n",
      "Ep:179, loss:0.00001, loss_test:0.04617, lr:4.95e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.581, tt:3884.561\n",
      "Ep:180, loss:0.00001, loss_test:0.04693, lr:4.90e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.620, tt:3913.217\n",
      "Ep:181, loss:0.00001, loss_test:0.04751, lr:4.85e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.680, tt:3945.697\n",
      "Ep:182, loss:0.00001, loss_test:0.04709, lr:4.80e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.737, tt:3977.895\n",
      "Ep:183, loss:0.00001, loss_test:0.04732, lr:4.75e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.781, tt:4007.643\n",
      "Ep:184, loss:0.00001, loss_test:0.04713, lr:4.71e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.818, tt:4036.414\n",
      "Ep:185, loss:0.00001, loss_test:0.04738, lr:4.66e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.863, tt:4066.533\n",
      "Ep:186, loss:0.00001, loss_test:0.04744, lr:4.61e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.919, tt:4098.871\n",
      "Ep:187, loss:0.00001, loss_test:0.04750, lr:4.57e-03, fs:0.91099 (r=0.879,p=0.946),  time:21.966, tt:4129.621\n",
      "Ep:188, loss:0.00001, loss_test:0.04757, lr:4.52e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.014, tt:4160.728\n",
      "Ep:189, loss:0.00001, loss_test:0.04655, lr:4.48e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.055, tt:4190.527\n",
      "Ep:190, loss:0.00001, loss_test:0.04760, lr:4.43e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.098, tt:4220.770\n",
      "Ep:191, loss:0.00000, loss_test:0.04636, lr:4.39e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.134, tt:4249.649\n",
      "Ep:192, loss:0.00000, loss_test:0.04782, lr:4.34e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.183, tt:4281.341\n",
      "Ep:193, loss:0.00000, loss_test:0.04658, lr:4.30e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.235, tt:4313.665\n",
      "Ep:194, loss:0.00000, loss_test:0.04777, lr:4.26e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.280, tt:4344.526\n",
      "Ep:195, loss:0.00000, loss_test:0.04701, lr:4.21e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.311, tt:4372.961\n",
      "Ep:196, loss:0.00000, loss_test:0.04756, lr:4.17e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.353, tt:4403.448\n",
      "Ep:197, loss:0.00000, loss_test:0.04677, lr:4.13e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.396, tt:4434.364\n",
      "Ep:198, loss:0.00000, loss_test:0.04797, lr:4.09e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.427, tt:4462.975\n",
      "Ep:199, loss:0.00000, loss_test:0.04826, lr:4.05e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.473, tt:4494.691\n",
      "Ep:200, loss:0.00000, loss_test:0.04711, lr:4.01e-03, fs:0.91099 (r=0.879,p=0.946),  time:22.523, tt:4527.130\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01974, lr:6.00e-02, fs:0.63559 (r=0.758,p=0.547),  time:36.645, tt:36.645\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02145, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.393, tt:76.785\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02366, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.119, tt:117.358\n",
      "Ep:3, loss:0.00005, loss_test:0.02404, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.908, tt:155.631\n",
      "Ep:4, loss:0.00005, loss_test:0.02347, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.302, tt:196.509\n",
      "Ep:5, loss:0.00005, loss_test:0.02214, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.401, tt:236.406\n",
      "Ep:6, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.541, tt:276.790\n",
      "Ep:7, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.68070 (r=0.980,p=0.522),  time:39.456, tt:315.645\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01781, lr:6.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:39.527, tt:355.741\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01798, lr:6.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:39.465, tt:394.648\n",
      "Ep:10, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:39.409, tt:433.496\n",
      "Ep:11, loss:0.00004, loss_test:0.01761, lr:6.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:39.511, tt:474.132\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:39.589, tt:514.655\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:39.761, tt:556.657\n",
      "Ep:14, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:39.797, tt:596.960\n",
      "Ep:15, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.74419 (r=0.970,p=0.604),  time:39.874, tt:637.988\n",
      "Ep:16, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:39.787, tt:676.378\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:39.910, tt:718.378\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:39.812, tt:756.427\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:39.765, tt:795.303\n",
      "Ep:20, loss:0.00003, loss_test:0.01484, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:39.859, tt:837.038\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01466, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:39.842, tt:876.518\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:39.902, tt:917.753\n",
      "Ep:23, loss:0.00002, loss_test:0.01428, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:39.916, tt:957.993\n",
      "Ep:24, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:39.916, tt:997.907\n",
      "Ep:25, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:39.922, tt:1037.969\n",
      "Ep:26, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:40.009, tt:1080.234\n",
      "Ep:27, loss:0.00002, loss_test:0.01379, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:40.029, tt:1120.813\n",
      "Ep:28, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:39.993, tt:1159.784\n",
      "Ep:29, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:39.990, tt:1199.711\n",
      "Ep:30, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:40.043, tt:1241.342\n",
      "Ep:31, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:40.030, tt:1280.960\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:40.022, tt:1320.732\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:40.035, tt:1361.176\n",
      "Ep:34, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:39.960, tt:1398.593\n",
      "Ep:35, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:40.005, tt:1440.181\n",
      "Ep:36, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:40.065, tt:1482.399\n",
      "Ep:37, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:40.098, tt:1523.725\n",
      "Ep:38, loss:0.00002, loss_test:0.01288, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:40.141, tt:1565.506\n",
      "Ep:39, loss:0.00002, loss_test:0.01284, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:40.118, tt:1604.717\n",
      "Ep:40, loss:0.00001, loss_test:0.01282, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.145, tt:1645.926\n",
      "Ep:41, loss:0.00001, loss_test:0.01280, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:40.205, tt:1688.631\n",
      "Ep:42, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:40.194, tt:1728.352\n",
      "Ep:43, loss:0.00001, loss_test:0.01276, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:40.166, tt:1767.288\n",
      "Ep:44, loss:0.00001, loss_test:0.01276, lr:5.94e-02, fs:0.79612 (r=0.828,p=0.766),  time:40.195, tt:1808.794\n",
      "Ep:45, loss:0.00001, loss_test:0.01277, lr:5.88e-02, fs:0.78431 (r=0.808,p=0.762),  time:40.216, tt:1849.953\n",
      "Ep:46, loss:0.00001, loss_test:0.01277, lr:5.82e-02, fs:0.78431 (r=0.808,p=0.762),  time:40.200, tt:1889.389\n",
      "Ep:47, loss:0.00001, loss_test:0.01274, lr:5.76e-02, fs:0.78818 (r=0.808,p=0.769),  time:40.137, tt:1926.589\n",
      "Ep:48, loss:0.00001, loss_test:0.01274, lr:5.71e-02, fs:0.78818 (r=0.808,p=0.769),  time:40.158, tt:1967.731\n",
      "Ep:49, loss:0.00001, loss_test:0.01276, lr:5.65e-02, fs:0.78818 (r=0.808,p=0.769),  time:40.132, tt:2006.622\n",
      "Ep:50, loss:0.00001, loss_test:0.01276, lr:5.59e-02, fs:0.78818 (r=0.808,p=0.769),  time:40.100, tt:2045.085\n",
      "Ep:51, loss:0.00001, loss_test:0.01277, lr:5.54e-02, fs:0.79208 (r=0.808,p=0.777),  time:40.206, tt:2090.734\n",
      "Ep:52, loss:0.00001, loss_test:0.01280, lr:5.48e-02, fs:0.79208 (r=0.808,p=0.777),  time:40.230, tt:2132.192\n",
      "Ep:53, loss:0.00001, loss_test:0.01281, lr:5.43e-02, fs:0.79208 (r=0.808,p=0.777),  time:40.218, tt:2171.754\n",
      "Ep:54, loss:0.00001, loss_test:0.01282, lr:5.37e-02, fs:0.80000 (r=0.808,p=0.792),  time:40.228, tt:2212.518\n",
      "Ep:55, loss:0.00001, loss_test:0.01287, lr:5.32e-02, fs:0.80402 (r=0.808,p=0.800),  time:40.236, tt:2253.234\n",
      "Ep:56, loss:0.00001, loss_test:0.01292, lr:5.27e-02, fs:0.79188 (r=0.788,p=0.796),  time:40.266, tt:2295.158\n",
      "Ep:57, loss:0.00001, loss_test:0.01295, lr:5.21e-02, fs:0.79798 (r=0.798,p=0.798),  time:40.270, tt:2335.677\n",
      "Ep:58, loss:0.00001, loss_test:0.01297, lr:5.16e-02, fs:0.79798 (r=0.798,p=0.798),  time:40.256, tt:2375.096\n",
      "Ep:59, loss:0.00001, loss_test:0.01302, lr:5.11e-02, fs:0.79188 (r=0.788,p=0.796),  time:40.254, tt:2415.238\n",
      "Ep:60, loss:0.00001, loss_test:0.01303, lr:5.06e-02, fs:0.79592 (r=0.788,p=0.804),  time:40.255, tt:2455.525\n",
      "Ep:61, loss:0.00001, loss_test:0.01306, lr:5.01e-02, fs:0.79592 (r=0.788,p=0.804),  time:40.245, tt:2495.203\n",
      "Ep:62, loss:0.00001, loss_test:0.01311, lr:4.96e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.224, tt:2534.139\n",
      "Ep:63, loss:0.00001, loss_test:0.01314, lr:4.91e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.217, tt:2573.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01317, lr:4.86e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.201, tt:2613.065\n",
      "Ep:65, loss:0.00001, loss_test:0.01321, lr:4.81e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.193, tt:2652.769\n",
      "Ep:66, loss:0.00001, loss_test:0.01325, lr:4.76e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.169, tt:2691.316\n",
      "Ep:67, loss:0.00001, loss_test:0.01329, lr:4.71e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.161, tt:2730.951\n",
      "Ep:68, loss:0.00001, loss_test:0.01332, lr:4.67e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.225, tt:2775.525\n",
      "Ep:69, loss:0.00001, loss_test:0.01337, lr:4.62e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.213, tt:2814.914\n",
      "Ep:70, loss:0.00001, loss_test:0.01339, lr:4.57e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.230, tt:2856.325\n",
      "Ep:71, loss:0.00001, loss_test:0.01344, lr:4.53e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.249, tt:2897.949\n",
      "Ep:72, loss:0.00001, loss_test:0.01349, lr:4.48e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.270, tt:2939.681\n",
      "Ep:73, loss:0.00001, loss_test:0.01351, lr:4.44e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.276, tt:2980.444\n",
      "Ep:74, loss:0.00001, loss_test:0.01353, lr:4.39e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.283, tt:3021.210\n",
      "Ep:75, loss:0.00001, loss_test:0.01357, lr:4.35e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.279, tt:3061.169\n",
      "Ep:76, loss:0.00001, loss_test:0.01362, lr:4.31e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.274, tt:3101.115\n",
      "Ep:77, loss:0.00001, loss_test:0.01366, lr:4.26e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.265, tt:3140.649\n",
      "Ep:78, loss:0.00001, loss_test:0.01372, lr:4.22e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.281, tt:3182.200\n",
      "Ep:79, loss:0.00001, loss_test:0.01374, lr:4.18e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.269, tt:3221.498\n",
      "Ep:80, loss:0.00001, loss_test:0.01379, lr:4.14e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.268, tt:3261.732\n",
      "Ep:81, loss:0.00001, loss_test:0.01385, lr:4.10e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.288, tt:3303.581\n",
      "Ep:82, loss:0.00001, loss_test:0.01389, lr:4.05e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.296, tt:3344.592\n",
      "Ep:83, loss:0.00001, loss_test:0.01392, lr:4.01e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.292, tt:3384.559\n",
      "Ep:84, loss:0.00001, loss_test:0.01395, lr:3.97e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.276, tt:3423.489\n",
      "Ep:85, loss:0.00001, loss_test:0.01400, lr:3.93e-02, fs:0.81250 (r=0.788,p=0.839),  time:40.276, tt:3463.696\n",
      "Ep:86, loss:0.00001, loss_test:0.01403, lr:3.89e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.281, tt:3504.459\n",
      "Ep:87, loss:0.00001, loss_test:0.01407, lr:3.86e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.277, tt:3544.382\n",
      "Ep:88, loss:0.00001, loss_test:0.01410, lr:3.82e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.285, tt:3585.365\n",
      "Ep:89, loss:0.00001, loss_test:0.01416, lr:3.78e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.278, tt:3625.027\n",
      "Ep:90, loss:0.00001, loss_test:0.01421, lr:3.74e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.277, tt:3665.168\n",
      "Ep:91, loss:0.00001, loss_test:0.01424, lr:3.70e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.266, tt:3704.462\n",
      "Ep:92, loss:0.00001, loss_test:0.01429, lr:3.67e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.272, tt:3745.265\n",
      "Ep:93, loss:0.00001, loss_test:0.01434, lr:3.63e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.334, tt:3791.436\n",
      "Ep:94, loss:0.00001, loss_test:0.01437, lr:3.59e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.325, tt:3830.860\n",
      "Ep:95, loss:0.00001, loss_test:0.01439, lr:3.56e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.328, tt:3871.508\n",
      "Ep:96, loss:0.00001, loss_test:0.01442, lr:3.52e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.328, tt:3911.798\n",
      "Ep:97, loss:0.00001, loss_test:0.01448, lr:3.49e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.317, tt:3951.085\n",
      "Ep:98, loss:0.00001, loss_test:0.01452, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.329, tt:3992.532\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01458, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.331, tt:4033.083\n",
      "Ep:100, loss:0.00001, loss_test:0.01459, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.319, tt:4072.248\n",
      "Ep:101, loss:0.00001, loss_test:0.01464, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.318, tt:4112.476\n",
      "Ep:102, loss:0.00001, loss_test:0.01469, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.288, tt:4149.713\n",
      "Ep:103, loss:0.00001, loss_test:0.01473, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.288, tt:4189.960\n",
      "Ep:104, loss:0.00001, loss_test:0.01476, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.283, tt:4229.768\n",
      "Ep:105, loss:0.00001, loss_test:0.01478, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.295, tt:4271.237\n",
      "Ep:106, loss:0.00001, loss_test:0.01483, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.299, tt:4311.951\n",
      "Ep:107, loss:0.00000, loss_test:0.01487, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.297, tt:4352.046\n",
      "Ep:108, loss:0.00000, loss_test:0.01491, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.296, tt:4392.216\n",
      "Ep:109, loss:0.00000, loss_test:0.01493, lr:3.45e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.296, tt:4432.561\n",
      "Ep:110, loss:0.00000, loss_test:0.01498, lr:3.42e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.288, tt:4471.939\n",
      "Ep:111, loss:0.00000, loss_test:0.01502, lr:3.38e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.259, tt:4509.006\n",
      "Ep:112, loss:0.00000, loss_test:0.01506, lr:3.35e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.245, tt:4547.705\n",
      "Ep:113, loss:0.00000, loss_test:0.01510, lr:3.32e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.243, tt:4587.751\n",
      "Ep:114, loss:0.00000, loss_test:0.01514, lr:3.28e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.252, tt:4629.014\n",
      "Ep:115, loss:0.00000, loss_test:0.01516, lr:3.25e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.242, tt:4668.049\n",
      "Ep:116, loss:0.00000, loss_test:0.01519, lr:3.22e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.262, tt:4710.693\n",
      "Ep:117, loss:0.00000, loss_test:0.01523, lr:3.19e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.263, tt:4751.016\n",
      "Ep:118, loss:0.00000, loss_test:0.01525, lr:3.15e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.263, tt:4791.297\n",
      "Ep:119, loss:0.00000, loss_test:0.01531, lr:3.12e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.280, tt:4833.609\n",
      "Ep:120, loss:0.00000, loss_test:0.01534, lr:3.09e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.287, tt:4874.779\n",
      "Ep:121, loss:0.00000, loss_test:0.01538, lr:3.06e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.279, tt:4914.039\n",
      "Ep:122, loss:0.00000, loss_test:0.01540, lr:3.03e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.281, tt:4954.621\n",
      "Ep:123, loss:0.00000, loss_test:0.01542, lr:3.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.280, tt:4994.734\n",
      "Ep:124, loss:0.00000, loss_test:0.01546, lr:2.97e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.271, tt:5033.881\n",
      "Ep:125, loss:0.00000, loss_test:0.01548, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.267, tt:5073.682\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.01552, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.295, tt:5117.474\n",
      "Ep:127, loss:0.00000, loss_test:0.01555, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.274, tt:5155.089\n",
      "Ep:128, loss:0.00000, loss_test:0.01558, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.278, tt:5195.864\n",
      "Ep:129, loss:0.00000, loss_test:0.01561, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.280, tt:5236.360\n",
      "Ep:130, loss:0.00000, loss_test:0.01565, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.288, tt:5277.709\n",
      "Ep:131, loss:0.00000, loss_test:0.01567, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.293, tt:5318.733\n",
      "Ep:132, loss:0.00000, loss_test:0.01570, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.294, tt:5359.136\n",
      "Ep:133, loss:0.00000, loss_test:0.01573, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.291, tt:5398.949\n",
      "Ep:134, loss:0.00000, loss_test:0.01577, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.302, tt:5440.825\n",
      "Ep:135, loss:0.00000, loss_test:0.01582, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.304, tt:5481.303\n",
      "Ep:136, loss:0.00000, loss_test:0.01583, lr:2.94e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.302, tt:5521.342\n",
      "Ep:137, loss:0.00000, loss_test:0.01585, lr:2.91e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.298, tt:5561.117\n",
      "Ep:138, loss:0.00000, loss_test:0.01589, lr:2.88e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.294, tt:5600.824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.01592, lr:2.85e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.301, tt:5642.187\n",
      "Ep:140, loss:0.00000, loss_test:0.01595, lr:2.82e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.295, tt:5681.582\n",
      "Ep:141, loss:0.00000, loss_test:0.01599, lr:2.80e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.287, tt:5720.809\n",
      "Ep:142, loss:0.00000, loss_test:0.01600, lr:2.77e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.278, tt:5759.800\n",
      "Ep:143, loss:0.00000, loss_test:0.01603, lr:2.74e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.284, tt:5800.857\n",
      "Ep:144, loss:0.00000, loss_test:0.01606, lr:2.71e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.285, tt:5841.292\n",
      "Ep:145, loss:0.00000, loss_test:0.01608, lr:2.69e-02, fs:0.83422 (r=0.788,p=0.886),  time:40.283, tt:5881.326\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00000, loss_test:0.01610, lr:2.69e-02, fs:0.83422 (r=0.788,p=0.886),  time:40.277, tt:5920.759\n",
      "Ep:147, loss:0.00000, loss_test:0.01614, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.265, tt:5959.199\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00000, loss_test:0.01617, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.254, tt:5997.876\n",
      "Ep:149, loss:0.00000, loss_test:0.01619, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.263, tt:6039.424\n",
      "Ep:150, loss:0.00000, loss_test:0.01621, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.256, tt:6078.626\n",
      "Ep:151, loss:0.00000, loss_test:0.01625, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.258, tt:6119.161\n",
      "Ep:152, loss:0.00000, loss_test:0.01627, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.255, tt:6159.068\n",
      "Ep:153, loss:0.00000, loss_test:0.01630, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.261, tt:6200.119\n",
      "Ep:154, loss:0.00000, loss_test:0.01632, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.264, tt:6240.922\n",
      "Ep:155, loss:0.00000, loss_test:0.01633, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.254, tt:6279.633\n",
      "Ep:156, loss:0.00000, loss_test:0.01636, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.242, tt:6317.959\n",
      "Ep:157, loss:0.00000, loss_test:0.01640, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.244, tt:6358.558\n",
      "Ep:158, loss:0.00000, loss_test:0.01641, lr:2.69e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.247, tt:6399.221\n",
      "Ep:159, loss:0.00000, loss_test:0.01644, lr:2.66e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.257, tt:6441.132\n",
      "Ep:160, loss:0.00000, loss_test:0.01645, lr:2.63e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.274, tt:6484.051\n",
      "Ep:161, loss:0.00000, loss_test:0.01648, lr:2.61e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.286, tt:6526.386\n",
      "Ep:162, loss:0.00000, loss_test:0.01651, lr:2.58e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.299, tt:6568.713\n",
      "Ep:163, loss:0.00000, loss_test:0.01654, lr:2.55e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.304, tt:6609.876\n",
      "Ep:164, loss:0.00000, loss_test:0.01655, lr:2.53e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.316, tt:6652.063\n",
      "Ep:165, loss:0.00000, loss_test:0.01657, lr:2.50e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.318, tt:6692.806\n",
      "Ep:166, loss:0.00000, loss_test:0.01660, lr:2.48e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.331, tt:6735.280\n",
      "Ep:167, loss:0.00000, loss_test:0.01662, lr:2.45e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.330, tt:6775.467\n",
      "Ep:168, loss:0.00000, loss_test:0.01664, lr:2.43e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.323, tt:6814.666\n",
      "Ep:169, loss:0.00000, loss_test:0.01665, lr:2.40e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.328, tt:6855.797\n",
      "Ep:170, loss:0.00000, loss_test:0.01668, lr:2.38e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.329, tt:6896.203\n",
      "Ep:171, loss:0.00000, loss_test:0.01671, lr:2.36e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.334, tt:6937.404\n",
      "Ep:172, loss:0.00000, loss_test:0.01673, lr:2.33e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.332, tt:6977.362\n",
      "Ep:173, loss:0.00000, loss_test:0.01675, lr:2.31e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.330, tt:7017.449\n",
      "Ep:174, loss:0.00000, loss_test:0.01677, lr:2.29e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.339, tt:7059.391\n",
      "Ep:175, loss:0.00000, loss_test:0.01679, lr:2.26e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.333, tt:7098.685\n",
      "Ep:176, loss:0.00000, loss_test:0.01681, lr:2.24e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.368, tt:7145.149\n",
      "Ep:177, loss:0.00000, loss_test:0.01684, lr:2.22e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.368, tt:7185.503\n",
      "Ep:178, loss:0.00000, loss_test:0.01686, lr:2.20e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.366, tt:7225.489\n",
      "Ep:179, loss:0.00000, loss_test:0.01688, lr:2.17e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.359, tt:7264.551\n",
      "Ep:180, loss:0.00000, loss_test:0.01691, lr:2.15e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.359, tt:7304.966\n",
      "Ep:181, loss:0.00000, loss_test:0.01692, lr:2.13e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.371, tt:7347.608\n",
      "Ep:182, loss:0.00000, loss_test:0.01693, lr:2.11e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.364, tt:7386.571\n",
      "Ep:183, loss:0.00000, loss_test:0.01695, lr:2.09e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.360, tt:7426.314\n",
      "Ep:184, loss:0.00000, loss_test:0.01696, lr:2.07e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.363, tt:7467.136\n",
      "Ep:185, loss:0.00000, loss_test:0.01697, lr:2.05e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.361, tt:7507.215\n",
      "Ep:186, loss:0.00000, loss_test:0.01699, lr:2.03e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.362, tt:7547.674\n",
      "Ep:187, loss:0.00000, loss_test:0.01702, lr:2.01e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.369, tt:7589.370\n",
      "Ep:188, loss:0.00000, loss_test:0.01704, lr:1.99e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.369, tt:7629.743\n",
      "Ep:189, loss:0.00000, loss_test:0.01704, lr:1.97e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.363, tt:7668.982\n",
      "Ep:190, loss:0.00000, loss_test:0.01706, lr:1.95e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.349, tt:7706.693\n",
      "Ep:191, loss:0.00000, loss_test:0.01708, lr:1.93e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.344, tt:7746.048\n",
      "Ep:192, loss:0.00000, loss_test:0.01710, lr:1.91e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.342, tt:7786.023\n",
      "Ep:193, loss:0.00000, loss_test:0.01711, lr:1.89e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.343, tt:7826.531\n",
      "Ep:194, loss:0.00000, loss_test:0.01713, lr:1.87e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.345, tt:7867.275\n",
      "Ep:195, loss:0.00000, loss_test:0.01714, lr:1.85e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.341, tt:7906.899\n",
      "Ep:196, loss:0.00000, loss_test:0.01716, lr:1.83e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.345, tt:7947.920\n",
      "Ep:197, loss:0.00000, loss_test:0.01718, lr:1.81e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.376, tt:7994.415\n",
      "Ep:198, loss:0.00000, loss_test:0.01719, lr:1.80e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.363, tt:8032.285\n",
      "Ep:199, loss:0.00000, loss_test:0.01720, lr:1.78e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.352, tt:8070.335\n",
      "Ep:200, loss:0.00000, loss_test:0.01722, lr:1.76e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.319, tt:8104.110\n",
      "Ep:201, loss:0.00000, loss_test:0.01724, lr:1.74e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.278, tt:8136.113\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13524, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.935, tt:40.935\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13260, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:42.096, tt:84.192\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12773, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:42.548, tt:127.644\n",
      "Ep:3, loss:0.00026, loss_test:0.12030, lr:1.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:42.592, tt:170.367\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11285, lr:1.00e-02, fs:0.66667 (r=0.798,p=0.572),  time:42.764, tt:213.820\n",
      "Ep:5, loss:0.00024, loss_test:0.10909, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:42.512, tt:255.072\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00023, loss_test:0.10621, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:42.365, tt:296.552\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10193, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:42.457, tt:339.654\n",
      "Ep:8, loss:0.00022, loss_test:0.09924, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:42.377, tt:381.393\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09592, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:42.211, tt:422.112\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09200, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:42.316, tt:465.476\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.08946, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:42.325, tt:507.897\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.08684, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:42.282, tt:549.663\n",
      "Ep:13, loss:0.00018, loss_test:0.08440, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:42.183, tt:590.558\n",
      "Ep:14, loss:0.00017, loss_test:0.08220, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:42.161, tt:632.413\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08073, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:42.214, tt:675.431\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.07825, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:42.103, tt:715.750\n",
      "Ep:17, loss:0.00015, loss_test:0.07624, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:42.014, tt:756.259\n",
      "Ep:18, loss:0.00014, loss_test:0.07397, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:41.923, tt:796.546\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.07216, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.861, tt:837.225\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.07068, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:41.777, tt:877.310\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.06930, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.694, tt:917.274\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.06820, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:41.587, tt:956.511\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.06712, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:41.598, tt:998.355\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.06614, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:41.603, tt:1040.083\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.06501, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:41.557, tt:1080.491\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.06368, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:41.585, tt:1122.799\n",
      "Ep:27, loss:0.00009, loss_test:0.06277, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:41.547, tt:1163.306\n",
      "Ep:28, loss:0.00009, loss_test:0.06156, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:41.498, tt:1203.433\n",
      "Ep:29, loss:0.00008, loss_test:0.06045, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:41.485, tt:1244.545\n",
      "Ep:30, loss:0.00008, loss_test:0.05990, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:41.427, tt:1284.234\n",
      "Ep:31, loss:0.00008, loss_test:0.05907, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:41.571, tt:1330.266\n",
      "Ep:32, loss:0.00007, loss_test:0.05848, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:41.581, tt:1372.175\n",
      "Ep:33, loss:0.00007, loss_test:0.05832, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:41.572, tt:1413.436\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.05720, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:41.577, tt:1455.212\n",
      "Ep:35, loss:0.00006, loss_test:0.05685, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:41.533, tt:1495.202\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.05628, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:41.524, tt:1536.401\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.05564, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:41.535, tt:1578.339\n",
      "Ep:38, loss:0.00006, loss_test:0.05483, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:41.559, tt:1620.799\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.05426, lr:1.00e-02, fs:0.92079 (r=0.939,p=0.903),  time:41.559, tt:1662.373\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.05402, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:41.540, tt:1703.125\n",
      "Ep:41, loss:0.00005, loss_test:0.05313, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:41.576, tt:1746.192\n",
      "Ep:42, loss:0.00005, loss_test:0.05292, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:41.565, tt:1787.283\n",
      "Ep:43, loss:0.00005, loss_test:0.05296, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:41.535, tt:1827.519\n",
      "Ep:44, loss:0.00004, loss_test:0.05205, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:41.516, tt:1868.206\n",
      "Ep:45, loss:0.00004, loss_test:0.05191, lr:1.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:41.494, tt:1908.733\n",
      "Ep:46, loss:0.00004, loss_test:0.05148, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:41.523, tt:1951.578\n",
      "Ep:47, loss:0.00004, loss_test:0.05161, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:41.555, tt:1994.617\n",
      "Ep:48, loss:0.00004, loss_test:0.05072, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:41.544, tt:2035.679\n",
      "Ep:49, loss:0.00004, loss_test:0.05047, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:41.518, tt:2075.922\n",
      "Ep:50, loss:0.00003, loss_test:0.04986, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:41.536, tt:2118.361\n",
      "Ep:51, loss:0.00003, loss_test:0.04914, lr:9.90e-03, fs:0.89231 (r=0.879,p=0.906),  time:41.525, tt:2159.277\n",
      "Ep:52, loss:0.00003, loss_test:0.04988, lr:9.80e-03, fs:0.91626 (r=0.939,p=0.894),  time:41.554, tt:2202.361\n",
      "Ep:53, loss:0.00003, loss_test:0.04889, lr:9.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:41.582, tt:2245.416\n",
      "Ep:54, loss:0.00003, loss_test:0.04866, lr:9.61e-03, fs:0.90909 (r=0.909,p=0.909),  time:41.577, tt:2286.744\n",
      "Ep:55, loss:0.00003, loss_test:0.04901, lr:9.51e-03, fs:0.91542 (r=0.929,p=0.902),  time:41.615, tt:2330.423\n",
      "Ep:56, loss:0.00003, loss_test:0.04810, lr:9.41e-03, fs:0.89119 (r=0.869,p=0.915),  time:41.571, tt:2369.554\n",
      "Ep:57, loss:0.00003, loss_test:0.04802, lr:9.32e-03, fs:0.91000 (r=0.919,p=0.901),  time:41.546, tt:2409.640\n",
      "Ep:58, loss:0.00003, loss_test:0.04815, lr:9.23e-03, fs:0.89899 (r=0.899,p=0.899),  time:41.510, tt:2449.098\n",
      "Ep:59, loss:0.00002, loss_test:0.04769, lr:9.14e-03, fs:0.89119 (r=0.869,p=0.915),  time:41.489, tt:2489.321\n",
      "Ep:60, loss:0.00002, loss_test:0.04758, lr:9.04e-03, fs:0.88660 (r=0.869,p=0.905),  time:41.476, tt:2530.028\n",
      "Ep:61, loss:0.00002, loss_test:0.04738, lr:8.95e-03, fs:0.88542 (r=0.859,p=0.914),  time:41.456, tt:2570.291\n",
      "Ep:62, loss:0.00002, loss_test:0.04724, lr:8.86e-03, fs:0.88542 (r=0.859,p=0.914),  time:41.426, tt:2609.863\n",
      "Ep:63, loss:0.00002, loss_test:0.04735, lr:8.78e-03, fs:0.87368 (r=0.838,p=0.912),  time:41.457, tt:2653.249\n",
      "Ep:64, loss:0.00002, loss_test:0.04715, lr:8.69e-03, fs:0.84946 (r=0.798,p=0.908),  time:41.434, tt:2693.188\n",
      "Ep:65, loss:0.00002, loss_test:0.04709, lr:8.60e-03, fs:0.87047 (r=0.848,p=0.894),  time:41.428, tt:2734.230\n",
      "Ep:66, loss:0.00002, loss_test:0.04682, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:41.401, tt:2773.889\n",
      "Ep:67, loss:0.00002, loss_test:0.04645, lr:8.43e-03, fs:0.86170 (r=0.818,p=0.910),  time:41.383, tt:2814.056\n",
      "Ep:68, loss:0.00002, loss_test:0.04617, lr:8.35e-03, fs:0.84946 (r=0.798,p=0.908),  time:41.388, tt:2855.764\n",
      "Ep:69, loss:0.00002, loss_test:0.04630, lr:8.26e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.395, tt:2897.638\n",
      "Ep:70, loss:0.00002, loss_test:0.04611, lr:8.18e-03, fs:0.84946 (r=0.798,p=0.908),  time:41.355, tt:2936.224\n",
      "Ep:71, loss:0.00002, loss_test:0.04592, lr:8.10e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.322, tt:2975.199\n",
      "Ep:72, loss:0.00002, loss_test:0.04590, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.293, tt:3014.394\n",
      "Ep:73, loss:0.00002, loss_test:0.04572, lr:7.94e-03, fs:0.84946 (r=0.798,p=0.908),  time:41.277, tt:3054.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00002, loss_test:0.04566, lr:7.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:41.253, tt:3093.949\n",
      "Ep:75, loss:0.00002, loss_test:0.04555, lr:7.78e-03, fs:0.85405 (r=0.798,p=0.919),  time:41.245, tt:3134.623\n",
      "Ep:76, loss:0.00002, loss_test:0.04545, lr:7.70e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.257, tt:3176.777\n",
      "Ep:77, loss:0.00002, loss_test:0.04524, lr:7.62e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.252, tt:3217.648\n",
      "Ep:78, loss:0.00001, loss_test:0.04516, lr:7.55e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.234, tt:3257.502\n",
      "Ep:79, loss:0.00001, loss_test:0.04509, lr:7.47e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.249, tt:3299.926\n",
      "Ep:80, loss:0.00001, loss_test:0.04494, lr:7.40e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.232, tt:3339.796\n",
      "Ep:81, loss:0.00001, loss_test:0.04481, lr:7.32e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.221, tt:3380.118\n",
      "Ep:82, loss:0.00001, loss_test:0.04474, lr:7.25e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.206, tt:3420.057\n",
      "Ep:83, loss:0.00001, loss_test:0.04477, lr:7.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.220, tt:3462.481\n",
      "Ep:84, loss:0.00001, loss_test:0.04446, lr:7.11e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.225, tt:3504.141\n",
      "Ep:85, loss:0.00001, loss_test:0.04466, lr:7.03e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.224, tt:3545.298\n",
      "Ep:86, loss:0.00001, loss_test:0.04460, lr:6.96e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.225, tt:3586.552\n",
      "Ep:87, loss:0.00001, loss_test:0.04436, lr:6.89e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.215, tt:3626.963\n",
      "Ep:88, loss:0.00001, loss_test:0.04455, lr:6.83e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.208, tt:3667.533\n",
      "Ep:89, loss:0.00001, loss_test:0.04429, lr:6.76e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.220, tt:3709.828\n",
      "Ep:90, loss:0.00001, loss_test:0.04411, lr:6.69e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.214, tt:3750.479\n",
      "Ep:91, loss:0.00001, loss_test:0.04420, lr:6.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.226, tt:3792.826\n",
      "Ep:92, loss:0.00001, loss_test:0.04394, lr:6.56e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.259, tt:3837.069\n",
      "Ep:93, loss:0.00001, loss_test:0.04369, lr:6.49e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.258, tt:3878.236\n",
      "Ep:94, loss:0.00001, loss_test:0.04393, lr:6.43e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.279, tt:3921.540\n",
      "Ep:95, loss:0.00001, loss_test:0.04380, lr:6.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.306, tt:3965.357\n",
      "Ep:96, loss:0.00001, loss_test:0.04363, lr:6.30e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.330, tt:4009.052\n",
      "Ep:97, loss:0.00001, loss_test:0.04359, lr:6.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.354, tt:4052.692\n",
      "Ep:98, loss:0.00001, loss_test:0.04356, lr:6.17e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.384, tt:4096.988\n",
      "Ep:99, loss:0.00001, loss_test:0.04361, lr:6.11e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.422, tt:4142.236\n",
      "Ep:100, loss:0.00001, loss_test:0.04365, lr:6.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.452, tt:4186.662\n",
      "Ep:101, loss:0.00001, loss_test:0.04353, lr:5.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.467, tt:4229.614\n",
      "Ep:102, loss:0.00001, loss_test:0.04367, lr:5.93e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.479, tt:4272.288\n",
      "Ep:103, loss:0.00001, loss_test:0.04347, lr:5.87e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.520, tt:4318.101\n",
      "Ep:104, loss:0.00001, loss_test:0.04345, lr:5.81e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.529, tt:4360.571\n",
      "Ep:105, loss:0.00001, loss_test:0.04341, lr:5.75e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.551, tt:4404.451\n",
      "Ep:106, loss:0.00001, loss_test:0.04320, lr:5.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.558, tt:4446.708\n",
      "Ep:107, loss:0.00001, loss_test:0.04323, lr:5.64e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.574, tt:4489.958\n",
      "Ep:108, loss:0.00001, loss_test:0.04326, lr:5.58e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.593, tt:4533.690\n",
      "Ep:109, loss:0.00001, loss_test:0.04319, lr:5.53e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.595, tt:4575.437\n",
      "Ep:110, loss:0.00001, loss_test:0.04308, lr:5.47e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.583, tt:4615.722\n",
      "Ep:111, loss:0.00001, loss_test:0.04299, lr:5.42e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.598, tt:4659.014\n",
      "Ep:112, loss:0.00001, loss_test:0.04299, lr:5.36e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.614, tt:4702.331\n",
      "Ep:113, loss:0.00001, loss_test:0.04306, lr:5.31e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.623, tt:4745.014\n",
      "Ep:114, loss:0.00001, loss_test:0.04297, lr:5.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.632, tt:4787.725\n",
      "Ep:115, loss:0.00001, loss_test:0.04298, lr:5.20e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.643, tt:4830.554\n",
      "Ep:116, loss:0.00001, loss_test:0.04303, lr:5.15e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.669, tt:4875.309\n",
      "Ep:117, loss:0.00001, loss_test:0.04292, lr:5.10e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.688, tt:4919.175\n",
      "Ep:118, loss:0.00001, loss_test:0.04296, lr:5.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.688, tt:4960.842\n",
      "Ep:119, loss:0.00001, loss_test:0.04290, lr:5.00e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.692, tt:5002.989\n",
      "Ep:120, loss:0.00001, loss_test:0.04290, lr:4.95e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.689, tt:5044.384\n",
      "Ep:121, loss:0.00001, loss_test:0.04293, lr:4.90e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.704, tt:5087.887\n",
      "Ep:122, loss:0.00001, loss_test:0.04272, lr:4.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.719, tt:5131.396\n",
      "Ep:123, loss:0.00001, loss_test:0.04261, lr:4.80e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.735, tt:5175.104\n",
      "Ep:124, loss:0.00001, loss_test:0.04274, lr:4.75e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.766, tt:5220.747\n",
      "Ep:125, loss:0.00001, loss_test:0.04255, lr:4.71e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.774, tt:5263.561\n",
      "Ep:126, loss:0.00001, loss_test:0.04255, lr:4.66e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.800, tt:5308.537\n",
      "Ep:127, loss:0.00001, loss_test:0.04257, lr:4.61e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.800, tt:5350.421\n",
      "Ep:128, loss:0.00001, loss_test:0.04249, lr:4.57e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.816, tt:5394.314\n",
      "Ep:129, loss:0.00001, loss_test:0.04260, lr:4.52e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.807, tt:5434.850\n",
      "Ep:130, loss:0.00001, loss_test:0.04263, lr:4.48e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.790, tt:5474.479\n",
      "Ep:131, loss:0.00001, loss_test:0.04258, lr:4.43e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.790, tt:5516.235\n",
      "Ep:132, loss:0.00001, loss_test:0.04254, lr:4.39e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.808, tt:5560.502\n",
      "Ep:133, loss:0.00001, loss_test:0.04254, lr:4.34e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.822, tt:5604.102\n",
      "Ep:134, loss:0.00001, loss_test:0.04234, lr:4.30e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.825, tt:5646.328\n",
      "Ep:135, loss:0.00001, loss_test:0.04255, lr:4.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.820, tt:5687.478\n",
      "Ep:136, loss:0.00001, loss_test:0.04253, lr:4.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.839, tt:5731.881\n",
      "Ep:137, loss:0.00001, loss_test:0.04236, lr:4.17e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.845, tt:5774.608\n",
      "Ep:138, loss:0.00001, loss_test:0.04240, lr:4.13e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.833, tt:5814.839\n",
      "Ep:139, loss:0.00001, loss_test:0.04243, lr:4.09e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.861, tt:5860.602\n",
      "Ep:140, loss:0.00001, loss_test:0.04239, lr:4.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.864, tt:5902.870\n",
      "Ep:141, loss:0.00001, loss_test:0.04238, lr:4.01e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.862, tt:5944.437\n",
      "Ep:142, loss:0.00001, loss_test:0.04250, lr:3.97e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.869, tt:5987.303\n",
      "Ep:143, loss:0.00001, loss_test:0.04239, lr:3.93e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.869, tt:6029.163\n",
      "Ep:144, loss:0.00001, loss_test:0.04258, lr:3.89e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.868, tt:6070.834\n",
      "Ep:145, loss:0.00001, loss_test:0.04272, lr:3.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.872, tt:6113.380\n",
      "Ep:146, loss:0.00001, loss_test:0.04240, lr:3.81e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.872, tt:6155.207\n",
      "Ep:147, loss:0.00001, loss_test:0.04247, lr:3.77e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.875, tt:6197.478\n",
      "Ep:148, loss:0.00001, loss_test:0.04272, lr:3.73e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.878, tt:6239.848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:149, loss:0.00001, loss_test:0.04251, lr:3.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.881, tt:6282.157\n",
      "Ep:150, loss:0.00001, loss_test:0.04227, lr:3.66e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.881, tt:6324.024\n",
      "Ep:151, loss:0.00001, loss_test:0.04245, lr:3.62e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.882, tt:6366.001\n",
      "Ep:152, loss:0.00001, loss_test:0.04246, lr:3.59e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.888, tt:6408.873\n",
      "Ep:153, loss:0.00001, loss_test:0.04242, lr:3.55e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.892, tt:6451.334\n",
      "Ep:154, loss:0.00001, loss_test:0.04243, lr:3.52e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.889, tt:6492.776\n",
      "Ep:155, loss:0.00001, loss_test:0.04252, lr:3.48e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.880, tt:6533.227\n",
      "Ep:156, loss:0.00001, loss_test:0.04239, lr:3.45e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.882, tt:6575.518\n",
      "Ep:157, loss:0.00001, loss_test:0.04244, lr:3.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.883, tt:6617.530\n",
      "Ep:158, loss:0.00001, loss_test:0.04235, lr:3.38e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.872, tt:6657.680\n",
      "Ep:159, loss:0.00000, loss_test:0.04246, lr:3.34e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.879, tt:6700.684\n",
      "Ep:160, loss:0.00000, loss_test:0.04247, lr:3.31e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.877, tt:6742.275\n",
      "Ep:161, loss:0.00000, loss_test:0.04241, lr:3.28e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.863, tt:6781.776\n",
      "Ep:162, loss:0.00000, loss_test:0.04252, lr:3.24e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.853, tt:6822.023\n",
      "Ep:163, loss:0.00000, loss_test:0.04244, lr:3.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.858, tt:6864.747\n",
      "Ep:164, loss:0.00000, loss_test:0.04231, lr:3.18e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.838, tt:6903.199\n",
      "Ep:165, loss:0.00000, loss_test:0.04252, lr:3.15e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.844, tt:6946.129\n",
      "Ep:166, loss:0.00000, loss_test:0.04268, lr:3.12e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.846, tt:6988.337\n",
      "Ep:167, loss:0.00000, loss_test:0.04247, lr:3.09e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.844, tt:7029.854\n",
      "Ep:168, loss:0.00000, loss_test:0.04237, lr:3.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.857, tt:7073.757\n",
      "Ep:169, loss:0.00000, loss_test:0.04252, lr:3.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.856, tt:7115.589\n",
      "Ep:170, loss:0.00000, loss_test:0.04251, lr:2.99e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.845, tt:7155.431\n",
      "Ep:171, loss:0.00000, loss_test:0.04235, lr:2.96e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.845, tt:7197.308\n",
      "Ep:172, loss:0.00000, loss_test:0.04241, lr:2.93e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.838, tt:7238.027\n",
      "Ep:173, loss:0.00000, loss_test:0.04237, lr:2.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.818, tt:7276.283\n",
      "Ep:174, loss:0.00000, loss_test:0.04237, lr:2.88e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.804, tt:7315.641\n",
      "Ep:175, loss:0.00000, loss_test:0.04258, lr:2.85e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.785, tt:7354.073\n",
      "Ep:176, loss:0.00000, loss_test:0.04250, lr:2.82e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.791, tt:7397.019\n",
      "Ep:177, loss:0.00000, loss_test:0.04242, lr:2.79e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.791, tt:7438.826\n",
      "Ep:178, loss:0.00000, loss_test:0.04260, lr:2.76e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.775, tt:7477.752\n",
      "Ep:179, loss:0.00000, loss_test:0.04257, lr:2.73e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.776, tt:7519.687\n",
      "Ep:180, loss:0.00000, loss_test:0.04233, lr:2.71e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.792, tt:7564.336\n",
      "Ep:181, loss:0.00000, loss_test:0.04237, lr:2.68e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.794, tt:7606.439\n",
      "Ep:182, loss:0.00000, loss_test:0.04268, lr:2.65e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.801, tt:7649.586\n",
      "Ep:183, loss:0.00000, loss_test:0.04263, lr:2.63e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.805, tt:7692.068\n",
      "Ep:184, loss:0.00000, loss_test:0.04243, lr:2.60e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.811, tt:7735.050\n",
      "Ep:185, loss:0.00000, loss_test:0.04252, lr:2.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.825, tt:7779.528\n",
      "Ep:186, loss:0.00000, loss_test:0.04252, lr:2.55e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.834, tt:7822.972\n",
      "Ep:187, loss:0.00000, loss_test:0.04249, lr:2.52e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.834, tt:7864.748\n",
      "Ep:188, loss:0.00000, loss_test:0.04243, lr:2.50e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.837, tt:7907.209\n",
      "Ep:189, loss:0.00000, loss_test:0.04249, lr:2.47e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.832, tt:7948.028\n",
      "Ep:190, loss:0.00000, loss_test:0.04254, lr:2.45e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.834, tt:7990.388\n",
      "Ep:191, loss:0.00000, loss_test:0.04250, lr:2.42e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.835, tt:8032.370\n",
      "Ep:192, loss:0.00000, loss_test:0.04248, lr:2.40e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.847, tt:8076.503\n",
      "Ep:193, loss:0.00000, loss_test:0.04253, lr:2.38e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.860, tt:8120.910\n",
      "Ep:194, loss:0.00000, loss_test:0.04248, lr:2.35e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.874, tt:8165.517\n",
      "Ep:195, loss:0.00000, loss_test:0.04247, lr:2.33e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.887, tt:8209.809\n",
      "Ep:196, loss:0.00000, loss_test:0.04252, lr:2.31e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.892, tt:8252.677\n",
      "Ep:197, loss:0.00000, loss_test:0.04253, lr:2.28e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.896, tt:8295.352\n",
      "Ep:198, loss:0.00000, loss_test:0.04249, lr:2.26e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.884, tt:8334.839\n",
      "Ep:199, loss:0.00000, loss_test:0.04262, lr:2.24e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.889, tt:8377.795\n",
      "Ep:200, loss:0.00000, loss_test:0.04265, lr:2.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.852, tt:8412.350\n",
      "Ep:201, loss:0.00000, loss_test:0.04252, lr:2.19e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.802, tt:8443.964\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01969, lr:6.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:26.031, tt:26.031\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.547, tt:55.093\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02330, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.602, tt:88.805\n",
      "Ep:3, loss:0.00005, loss_test:0.02274, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.933, tt:123.733\n",
      "Ep:4, loss:0.00005, loss_test:0.02126, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.743, tt:158.716\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01945, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:32.269, tt:193.612\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01820, lr:6.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:32.637, tt:228.461\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01796, lr:6.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:32.984, tt:263.870\n",
      "Ep:8, loss:0.00004, loss_test:0.01779, lr:6.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:33.037, tt:297.335\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01707, lr:6.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:33.198, tt:331.976\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01645, lr:6.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:33.239, tt:365.624\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01617, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:33.412, tt:400.940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00003, loss_test:0.01584, lr:6.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:33.545, tt:436.086\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01548, lr:6.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:33.687, tt:471.622\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:33.674, tt:505.108\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01517, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:33.650, tt:538.397\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01502, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:33.695, tt:572.809\n",
      "Ep:17, loss:0.00003, loss_test:0.01481, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:33.744, tt:607.389\n",
      "Ep:18, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.75949 (r=0.909,p=0.652),  time:33.793, tt:642.069\n",
      "Ep:19, loss:0.00003, loss_test:0.01443, lr:6.00e-02, fs:0.75949 (r=0.909,p=0.652),  time:33.774, tt:675.476\n",
      "Ep:20, loss:0.00003, loss_test:0.01426, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:33.955, tt:713.045\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:33.976, tt:747.461\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01398, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:34.061, tt:783.406\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01385, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:34.073, tt:817.761\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01371, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:34.074, tt:851.851\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:34.120, tt:887.127\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:34.135, tt:921.650\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:34.148, tt:956.134\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:34.180, tt:991.232\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:34.192, tt:1025.772\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01277, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:34.223, tt:1060.918\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01263, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:34.191, tt:1094.105\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01251, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:34.168, tt:1127.536\n",
      "Ep:33, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:34.144, tt:1160.886\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01225, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:34.140, tt:1194.910\n",
      "Ep:35, loss:0.00002, loss_test:0.01214, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:34.113, tt:1228.075\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01204, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:34.117, tt:1262.319\n",
      "Ep:37, loss:0.00002, loss_test:0.01193, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:34.100, tt:1295.785\n",
      "Ep:38, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:34.064, tt:1328.508\n",
      "Ep:39, loss:0.00002, loss_test:0.01168, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:34.066, tt:1362.623\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01155, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:34.075, tt:1397.081\n",
      "Ep:41, loss:0.00002, loss_test:0.01145, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:34.075, tt:1431.159\n",
      "Ep:42, loss:0.00002, loss_test:0.01136, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.070, tt:1464.999\n",
      "Ep:43, loss:0.00001, loss_test:0.01127, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.090, tt:1499.975\n",
      "Ep:44, loss:0.00001, loss_test:0.01116, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.078, tt:1533.519\n",
      "Ep:45, loss:0.00001, loss_test:0.01106, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.140, tt:1570.420\n",
      "Ep:46, loss:0.00001, loss_test:0.01097, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.151, tt:1605.088\n",
      "Ep:47, loss:0.00001, loss_test:0.01088, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.172, tt:1640.246\n",
      "Ep:48, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:34.179, tt:1674.773\n",
      "Ep:49, loss:0.00001, loss_test:0.01076, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.197, tt:1709.865\n",
      "Ep:50, loss:0.00001, loss_test:0.01067, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.218, tt:1745.139\n",
      "Ep:51, loss:0.00001, loss_test:0.01064, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.235, tt:1780.226\n",
      "Ep:52, loss:0.00001, loss_test:0.01057, lr:5.88e-02, fs:0.85149 (r=0.869,p=0.835),  time:34.237, tt:1814.535\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01052, lr:5.88e-02, fs:0.85149 (r=0.869,p=0.835),  time:34.220, tt:1847.899\n",
      "Ep:54, loss:0.00001, loss_test:0.01047, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.223, tt:1882.266\n",
      "Ep:55, loss:0.00001, loss_test:0.01043, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.215, tt:1916.049\n",
      "Ep:56, loss:0.00001, loss_test:0.01039, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.235, tt:1951.387\n",
      "Ep:57, loss:0.00001, loss_test:0.01033, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.244, tt:1986.170\n",
      "Ep:58, loss:0.00001, loss_test:0.01029, lr:5.88e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.246, tt:2020.497\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01028, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.242, tt:2054.525\n",
      "Ep:60, loss:0.00001, loss_test:0.01028, lr:5.88e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.241, tt:2088.676\n",
      "Ep:61, loss:0.00001, loss_test:0.01024, lr:5.88e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.234, tt:2122.514\n",
      "Ep:62, loss:0.00001, loss_test:0.01023, lr:5.88e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.243, tt:2157.287\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01022, lr:5.88e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.230, tt:2190.726\n",
      "Ep:64, loss:0.00001, loss_test:0.01022, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.228, tt:2224.818\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01024, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.229, tt:2259.129\n",
      "Ep:66, loss:0.00001, loss_test:0.01021, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.233, tt:2293.623\n",
      "Ep:67, loss:0.00001, loss_test:0.01019, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.222, tt:2327.090\n",
      "Ep:68, loss:0.00001, loss_test:0.01020, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.220, tt:2361.153\n",
      "Ep:69, loss:0.00001, loss_test:0.01020, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.228, tt:2395.981\n",
      "Ep:70, loss:0.00001, loss_test:0.01018, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.213, tt:2429.088\n",
      "Ep:71, loss:0.00001, loss_test:0.01018, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.222, tt:2464.011\n",
      "Ep:72, loss:0.00001, loss_test:0.01018, lr:5.88e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.190, tt:2495.894\n",
      "Ep:73, loss:0.00001, loss_test:0.01018, lr:5.88e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.176, tt:2529.001\n",
      "Ep:74, loss:0.00001, loss_test:0.01018, lr:5.88e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.189, tt:2564.172\n",
      "Ep:75, loss:0.00001, loss_test:0.01019, lr:5.88e-02, fs:0.86735 (r=0.859,p=0.876),  time:34.181, tt:2597.767\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01022, lr:5.88e-02, fs:0.86735 (r=0.859,p=0.876),  time:34.174, tt:2631.388\n",
      "Ep:77, loss:0.00001, loss_test:0.01027, lr:5.88e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.165, tt:2664.835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00001, loss_test:0.01021, lr:5.88e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.169, tt:2699.314\n",
      "Ep:79, loss:0.00001, loss_test:0.01020, lr:5.88e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.189, tt:2735.094\n",
      "Ep:80, loss:0.00001, loss_test:0.01028, lr:5.88e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.187, tt:2769.115\n",
      "Ep:81, loss:0.00001, loss_test:0.01028, lr:5.88e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.173, tt:2802.159\n",
      "Ep:82, loss:0.00001, loss_test:0.01027, lr:5.88e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.194, tt:2838.118\n",
      "Ep:83, loss:0.00001, loss_test:0.01028, lr:5.88e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.214, tt:2873.993\n",
      "Ep:84, loss:0.00001, loss_test:0.01033, lr:5.88e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.228, tt:2909.408\n",
      "Ep:85, loss:0.00001, loss_test:0.01037, lr:5.88e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.220, tt:2942.880\n",
      "Ep:86, loss:0.00001, loss_test:0.01036, lr:5.88e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.228, tt:2977.839\n",
      "Ep:87, loss:0.00001, loss_test:0.01043, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.224, tt:3011.745\n",
      "Ep:88, loss:0.00001, loss_test:0.01042, lr:5.76e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.192, tt:3043.052\n",
      "Ep:89, loss:0.00001, loss_test:0.01046, lr:5.71e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.191, tt:3077.158\n",
      "Ep:90, loss:0.00001, loss_test:0.01048, lr:5.65e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.188, tt:3111.069\n",
      "Ep:91, loss:0.00001, loss_test:0.01049, lr:5.59e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.181, tt:3144.665\n",
      "Ep:92, loss:0.00001, loss_test:0.01050, lr:5.54e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.188, tt:3179.450\n",
      "Ep:93, loss:0.00001, loss_test:0.01055, lr:5.48e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.191, tt:3213.916\n",
      "Ep:94, loss:0.00001, loss_test:0.01053, lr:5.43e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.205, tt:3249.445\n",
      "Ep:95, loss:0.00001, loss_test:0.01061, lr:5.37e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.193, tt:3282.544\n",
      "Ep:96, loss:0.00001, loss_test:0.01066, lr:5.32e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.205, tt:3317.871\n",
      "Ep:97, loss:0.00000, loss_test:0.01064, lr:5.27e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.205, tt:3352.059\n",
      "Ep:98, loss:0.00000, loss_test:0.01062, lr:5.21e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.190, tt:3384.810\n",
      "Ep:99, loss:0.00000, loss_test:0.01072, lr:5.16e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.179, tt:3417.912\n",
      "Ep:100, loss:0.00000, loss_test:0.01072, lr:5.11e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.189, tt:3453.083\n",
      "Ep:101, loss:0.00000, loss_test:0.01073, lr:5.06e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.205, tt:3488.889\n",
      "Ep:102, loss:0.00000, loss_test:0.01081, lr:5.01e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.205, tt:3523.144\n",
      "Ep:103, loss:0.00000, loss_test:0.01082, lr:4.96e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.214, tt:3558.235\n",
      "Ep:104, loss:0.00000, loss_test:0.01080, lr:4.91e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.258, tt:3597.084\n",
      "Ep:105, loss:0.00000, loss_test:0.01086, lr:4.86e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.252, tt:3630.708\n",
      "Ep:106, loss:0.00000, loss_test:0.01088, lr:4.81e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.263, tt:3666.170\n",
      "Ep:107, loss:0.00000, loss_test:0.01086, lr:4.76e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.267, tt:3700.882\n",
      "Ep:108, loss:0.00000, loss_test:0.01093, lr:4.71e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.276, tt:3736.082\n",
      "Ep:109, loss:0.00000, loss_test:0.01097, lr:4.67e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.275, tt:3770.252\n",
      "Ep:110, loss:0.00000, loss_test:0.01098, lr:4.62e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.271, tt:3804.062\n",
      "Ep:111, loss:0.00000, loss_test:0.01101, lr:4.57e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.264, tt:3837.534\n",
      "Ep:112, loss:0.00000, loss_test:0.01108, lr:4.53e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.243, tt:3869.457\n",
      "Ep:113, loss:0.00000, loss_test:0.01113, lr:4.48e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.236, tt:3902.944\n",
      "Ep:114, loss:0.00000, loss_test:0.01111, lr:4.44e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.242, tt:3937.792\n",
      "Ep:115, loss:0.00000, loss_test:0.01110, lr:4.39e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.238, tt:3971.619\n",
      "Ep:116, loss:0.00000, loss_test:0.01117, lr:4.35e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.239, tt:4005.990\n",
      "Ep:117, loss:0.00000, loss_test:0.01121, lr:4.31e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.244, tt:4040.745\n",
      "Ep:118, loss:0.00000, loss_test:0.01118, lr:4.26e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.241, tt:4074.644\n",
      "Ep:119, loss:0.00000, loss_test:0.01117, lr:4.22e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.245, tt:4109.374\n",
      "Ep:120, loss:0.00000, loss_test:0.01120, lr:4.18e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.257, tt:4145.106\n",
      "Ep:121, loss:0.00000, loss_test:0.01129, lr:4.14e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.258, tt:4179.425\n",
      "Ep:122, loss:0.00000, loss_test:0.01129, lr:4.10e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.263, tt:4214.399\n",
      "Ep:123, loss:0.00000, loss_test:0.01131, lr:4.05e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.256, tt:4247.766\n",
      "Ep:124, loss:0.00000, loss_test:0.01136, lr:4.01e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.254, tt:4281.778\n",
      "Ep:125, loss:0.00000, loss_test:0.01138, lr:3.97e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.269, tt:4317.845\n",
      "Ep:126, loss:0.00000, loss_test:0.01141, lr:3.93e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.277, tt:4353.119\n",
      "Ep:127, loss:0.00000, loss_test:0.01141, lr:3.89e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.270, tt:4386.562\n",
      "Ep:128, loss:0.00000, loss_test:0.01143, lr:3.86e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.274, tt:4421.409\n",
      "Ep:129, loss:0.00000, loss_test:0.01146, lr:3.82e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.285, tt:4457.068\n",
      "Ep:130, loss:0.00000, loss_test:0.01148, lr:3.78e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.292, tt:4492.251\n",
      "Ep:131, loss:0.00000, loss_test:0.01150, lr:3.74e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.289, tt:4526.094\n",
      "Ep:132, loss:0.00000, loss_test:0.01152, lr:3.70e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.290, tt:4560.603\n",
      "Ep:133, loss:0.00000, loss_test:0.01155, lr:3.67e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.300, tt:4596.223\n",
      "Ep:134, loss:0.00000, loss_test:0.01156, lr:3.63e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.336, tt:4635.350\n",
      "Ep:135, loss:0.00000, loss_test:0.01158, lr:3.59e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.331, tt:4668.977\n",
      "Ep:136, loss:0.00000, loss_test:0.01159, lr:3.56e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.315, tt:4701.192\n",
      "Ep:137, loss:0.00000, loss_test:0.01159, lr:3.52e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.313, tt:4735.169\n",
      "Ep:138, loss:0.00000, loss_test:0.01166, lr:3.49e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.312, tt:4769.383\n",
      "Ep:139, loss:0.00000, loss_test:0.01166, lr:3.45e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.310, tt:4803.389\n",
      "Ep:140, loss:0.00000, loss_test:0.01169, lr:3.42e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.303, tt:4836.724\n",
      "Ep:141, loss:0.00000, loss_test:0.01169, lr:3.38e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.295, tt:4869.907\n",
      "Ep:142, loss:0.00000, loss_test:0.01171, lr:3.35e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.299, tt:4904.686\n",
      "Ep:143, loss:0.00000, loss_test:0.01174, lr:3.32e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.295, tt:4938.489\n",
      "Ep:144, loss:0.00000, loss_test:0.01176, lr:3.28e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.296, tt:4972.936\n",
      "Ep:145, loss:0.00000, loss_test:0.01181, lr:3.25e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.292, tt:5006.595\n",
      "Ep:146, loss:0.00000, loss_test:0.01181, lr:3.22e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.282, tt:5039.454\n",
      "Ep:147, loss:0.00000, loss_test:0.01182, lr:3.19e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.276, tt:5072.865\n",
      "Ep:148, loss:0.00000, loss_test:0.01185, lr:3.15e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.276, tt:5107.112\n",
      "Ep:149, loss:0.00000, loss_test:0.01186, lr:3.12e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.272, tt:5140.868\n",
      "Ep:150, loss:0.00000, loss_test:0.01185, lr:3.09e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.282, tt:5176.515\n",
      "Ep:151, loss:0.00000, loss_test:0.01191, lr:3.06e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.289, tt:5211.870\n",
      "Ep:152, loss:0.00000, loss_test:0.01190, lr:3.03e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.288, tt:5246.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00000, loss_test:0.01189, lr:3.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.279, tt:5278.976\n",
      "Ep:154, loss:0.00000, loss_test:0.01193, lr:2.97e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.271, tt:5312.055\n",
      "Ep:155, loss:0.00000, loss_test:0.01197, lr:2.94e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.281, tt:5347.774\n",
      "Ep:156, loss:0.00000, loss_test:0.01196, lr:2.91e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.279, tt:5381.797\n",
      "Ep:157, loss:0.00000, loss_test:0.01198, lr:2.88e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.272, tt:5415.030\n",
      "Ep:158, loss:0.00000, loss_test:0.01201, lr:2.85e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.274, tt:5449.629\n",
      "Ep:159, loss:0.00000, loss_test:0.01203, lr:2.82e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.284, tt:5485.502\n",
      "Ep:160, loss:0.00000, loss_test:0.01203, lr:2.80e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.275, tt:5518.316\n",
      "Ep:161, loss:0.00000, loss_test:0.01206, lr:2.77e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.261, tt:5550.252\n",
      "Ep:162, loss:0.00000, loss_test:0.01207, lr:2.74e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.261, tt:5584.488\n",
      "Ep:163, loss:0.00000, loss_test:0.01206, lr:2.71e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.249, tt:5616.867\n",
      "Ep:164, loss:0.00000, loss_test:0.01206, lr:2.69e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.252, tt:5651.533\n",
      "Ep:165, loss:0.00000, loss_test:0.01210, lr:2.66e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.249, tt:5685.364\n",
      "Ep:166, loss:0.00000, loss_test:0.01213, lr:2.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.242, tt:5718.375\n",
      "Ep:167, loss:0.00000, loss_test:0.01212, lr:2.61e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.256, tt:5755.015\n",
      "Ep:168, loss:0.00000, loss_test:0.01214, lr:2.58e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.263, tt:5790.466\n",
      "Ep:169, loss:0.00000, loss_test:0.01216, lr:2.55e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.273, tt:5826.396\n",
      "Ep:170, loss:0.00000, loss_test:0.01219, lr:2.53e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.267, tt:5859.633\n",
      "Ep:171, loss:0.00000, loss_test:0.01220, lr:2.50e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.267, tt:5893.880\n",
      "Ep:172, loss:0.00000, loss_test:0.01219, lr:2.48e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.267, tt:5928.255\n",
      "Ep:173, loss:0.00000, loss_test:0.01222, lr:2.45e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.266, tt:5962.208\n",
      "Ep:174, loss:0.00000, loss_test:0.01224, lr:2.43e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.273, tt:5997.828\n",
      "Ep:175, loss:0.00000, loss_test:0.01227, lr:2.40e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.280, tt:6033.247\n",
      "Ep:176, loss:0.00000, loss_test:0.01226, lr:2.38e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.284, tt:6068.328\n",
      "Ep:177, loss:0.00000, loss_test:0.01228, lr:2.36e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.289, tt:6103.476\n",
      "Ep:178, loss:0.00000, loss_test:0.01233, lr:2.33e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.299, tt:6139.546\n",
      "Ep:179, loss:0.00000, loss_test:0.01234, lr:2.31e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.308, tt:6175.525\n",
      "Ep:180, loss:0.00000, loss_test:0.01231, lr:2.29e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.316, tt:6211.132\n",
      "Ep:181, loss:0.00000, loss_test:0.01234, lr:2.26e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.323, tt:6246.812\n",
      "Ep:182, loss:0.00000, loss_test:0.01238, lr:2.24e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.321, tt:6280.778\n",
      "Ep:183, loss:0.00000, loss_test:0.01238, lr:2.22e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.318, tt:6314.478\n",
      "Ep:184, loss:0.00000, loss_test:0.01239, lr:2.20e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.320, tt:6349.290\n",
      "Ep:185, loss:0.00000, loss_test:0.01243, lr:2.17e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.317, tt:6382.960\n",
      "Ep:186, loss:0.00000, loss_test:0.01244, lr:2.15e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.323, tt:6418.460\n",
      "Ep:187, loss:0.00000, loss_test:0.01241, lr:2.13e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.320, tt:6452.115\n",
      "Ep:188, loss:0.00000, loss_test:0.01245, lr:2.11e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.317, tt:6485.865\n",
      "Ep:189, loss:0.00000, loss_test:0.01249, lr:2.09e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.323, tt:6521.387\n",
      "Ep:190, loss:0.00000, loss_test:0.01249, lr:2.07e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.325, tt:6556.090\n",
      "Ep:191, loss:0.00000, loss_test:0.01247, lr:2.05e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.318, tt:6589.117\n",
      "Ep:192, loss:0.00000, loss_test:0.01250, lr:2.03e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.323, tt:6624.424\n",
      "Ep:193, loss:0.00000, loss_test:0.01253, lr:2.01e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.321, tt:6658.283\n",
      "Ep:194, loss:0.00000, loss_test:0.01254, lr:1.99e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.323, tt:6692.909\n",
      "Ep:195, loss:0.00000, loss_test:0.01253, lr:1.97e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.315, tt:6725.833\n",
      "Ep:196, loss:0.00000, loss_test:0.01255, lr:1.95e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.326, tt:6762.304\n",
      "Ep:197, loss:0.00000, loss_test:0.01258, lr:1.93e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.333, tt:6797.934\n",
      "Ep:198, loss:0.00000, loss_test:0.01258, lr:1.91e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.328, tt:6831.269\n",
      "Ep:199, loss:0.00000, loss_test:0.01258, lr:1.89e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.315, tt:6863.049\n",
      "Ep:200, loss:0.00000, loss_test:0.01259, lr:1.87e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.303, tt:6894.883\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13568, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.628, tt:28.628\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13256, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:28.937, tt:57.873\n",
      "Ep:2, loss:0.00027, loss_test:0.12675, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:30.356, tt:91.069\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11643, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:31.910, tt:127.640\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.10376, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:32.707, tt:163.537\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.09939, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:32.922, tt:197.535\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.09755, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:33.101, tt:231.709\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.09543, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:33.476, tt:267.806\n",
      "Ep:8, loss:0.00022, loss_test:0.09443, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:33.969, tt:305.719\n",
      "Ep:9, loss:0.00021, loss_test:0.09140, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:34.201, tt:342.010\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.08975, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:34.476, tt:379.238\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.08720, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:35.037, tt:420.440\n",
      "Ep:12, loss:0.00019, loss_test:0.08529, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:35.235, tt:458.056\n",
      "Ep:13, loss:0.00019, loss_test:0.08354, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:35.338, tt:494.738\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.08254, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:35.404, tt:531.062\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08060, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.545, tt:568.712\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.07974, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.667, tt:606.341\n",
      "Ep:17, loss:0.00017, loss_test:0.07937, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.698, tt:642.564\n",
      "Ep:18, loss:0.00016, loss_test:0.07836, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:35.684, tt:678.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00015, loss_test:0.07788, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.681, tt:713.614\n",
      "Ep:20, loss:0.00015, loss_test:0.07667, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.766, tt:751.077\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07579, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.818, tt:787.996\n",
      "Ep:22, loss:0.00014, loss_test:0.07485, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:35.846, tt:824.451\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.07339, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:35.887, tt:861.284\n",
      "Ep:24, loss:0.00012, loss_test:0.07274, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.915, tt:897.870\n",
      "Ep:25, loss:0.00012, loss_test:0.07101, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:35.970, tt:935.225\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07014, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:36.088, tt:974.384\n",
      "Ep:27, loss:0.00011, loss_test:0.06825, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:36.146, tt:1012.075\n",
      "Ep:28, loss:0.00010, loss_test:0.06710, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:36.141, tt:1048.084\n",
      "Ep:29, loss:0.00010, loss_test:0.06689, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:36.143, tt:1084.288\n",
      "Ep:30, loss:0.00009, loss_test:0.06485, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:36.231, tt:1123.147\n",
      "Ep:31, loss:0.00009, loss_test:0.06482, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:36.282, tt:1161.014\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06237, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:36.263, tt:1196.673\n",
      "Ep:33, loss:0.00008, loss_test:0.06240, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:36.299, tt:1234.159\n",
      "Ep:34, loss:0.00008, loss_test:0.06123, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:36.331, tt:1271.602\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06062, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:36.363, tt:1309.074\n",
      "Ep:36, loss:0.00007, loss_test:0.06050, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:36.416, tt:1347.395\n",
      "Ep:37, loss:0.00007, loss_test:0.05810, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.443, tt:1384.831\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00006, loss_test:0.05904, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:36.489, tt:1423.073\n",
      "Ep:39, loss:0.00006, loss_test:0.05760, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.553, tt:1462.109\n",
      "Ep:40, loss:0.00006, loss_test:0.05992, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:36.571, tt:1499.416\n",
      "Ep:41, loss:0.00006, loss_test:0.05645, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.585, tt:1536.569\n",
      "Ep:42, loss:0.00005, loss_test:0.05752, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:36.620, tt:1574.677\n",
      "Ep:43, loss:0.00005, loss_test:0.05693, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:36.648, tt:1612.523\n",
      "Ep:44, loss:0.00005, loss_test:0.05532, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.718, tt:1652.321\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.05553, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:36.726, tt:1689.412\n",
      "Ep:46, loss:0.00004, loss_test:0.05510, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:36.753, tt:1727.377\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.05431, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.765, tt:1764.698\n",
      "Ep:48, loss:0.00004, loss_test:0.05492, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.879, tt:1807.066\n",
      "Ep:49, loss:0.00004, loss_test:0.05382, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.934, tt:1846.706\n",
      "Ep:50, loss:0.00004, loss_test:0.05411, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.899, tt:1881.845\n",
      "Ep:51, loss:0.00004, loss_test:0.05329, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.921, tt:1919.881\n",
      "Ep:52, loss:0.00003, loss_test:0.05408, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:36.962, tt:1958.968\n",
      "Ep:53, loss:0.00003, loss_test:0.05220, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.928, tt:1994.091\n",
      "Ep:54, loss:0.00003, loss_test:0.05451, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:37.000, tt:2035.027\n",
      "Ep:55, loss:0.00003, loss_test:0.05260, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.960, tt:2069.758\n",
      "Ep:56, loss:0.00003, loss_test:0.05315, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.938, tt:2105.445\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.05372, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.916, tt:2141.124\n",
      "Ep:58, loss:0.00003, loss_test:0.05271, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.887, tt:2176.314\n",
      "Ep:59, loss:0.00003, loss_test:0.05509, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.852, tt:2211.132\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.05390, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.845, tt:2247.542\n",
      "Ep:61, loss:0.00003, loss_test:0.05393, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.819, tt:2282.766\n",
      "Ep:62, loss:0.00002, loss_test:0.05579, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.801, tt:2318.480\n",
      "Ep:63, loss:0.00002, loss_test:0.05195, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.778, tt:2353.818\n",
      "Ep:64, loss:0.00002, loss_test:0.05430, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.773, tt:2390.241\n",
      "Ep:65, loss:0.00002, loss_test:0.05315, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.743, tt:2425.037\n",
      "Ep:66, loss:0.00002, loss_test:0.05204, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.747, tt:2462.063\n",
      "Ep:67, loss:0.00002, loss_test:0.05297, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.716, tt:2496.710\n",
      "Ep:68, loss:0.00002, loss_test:0.05341, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.698, tt:2532.168\n",
      "Ep:69, loss:0.00002, loss_test:0.05226, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.681, tt:2567.663\n",
      "Ep:70, loss:0.00002, loss_test:0.05380, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.691, tt:2605.086\n",
      "Ep:71, loss:0.00002, loss_test:0.05232, lr:9.90e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.714, tt:2643.425\n",
      "Ep:72, loss:0.00002, loss_test:0.05116, lr:9.80e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.719, tt:2680.485\n",
      "Ep:73, loss:0.00002, loss_test:0.05389, lr:9.70e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.715, tt:2716.905\n",
      "Ep:74, loss:0.00002, loss_test:0.05137, lr:9.61e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.693, tt:2751.977\n",
      "Ep:75, loss:0.00002, loss_test:0.05224, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.669, tt:2786.861\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.05245, lr:9.51e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.679, tt:2824.288\n",
      "Ep:77, loss:0.00002, loss_test:0.05413, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.649, tt:2858.647\n",
      "Ep:78, loss:0.00001, loss_test:0.05493, lr:9.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.627, tt:2893.498\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.05155, lr:9.51e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.600, tt:2928.032\n",
      "Ep:80, loss:0.00001, loss_test:0.05402, lr:9.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.572, tt:2962.371\n",
      "Ep:81, loss:0.00001, loss_test:0.05283, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.564, tt:2998.249\n",
      "Ep:82, loss:0.00001, loss_test:0.05152, lr:9.51e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.571, tt:3035.409\n",
      "Ep:83, loss:0.00001, loss_test:0.05371, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.569, tt:3071.781\n",
      "Ep:84, loss:0.00001, loss_test:0.05127, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.571, tt:3108.536\n",
      "Ep:85, loss:0.00001, loss_test:0.05243, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.570, tt:3145.032\n",
      "Ep:86, loss:0.00001, loss_test:0.05116, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.568, tt:3181.432\n",
      "Ep:87, loss:0.00001, loss_test:0.05271, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.550, tt:3216.364\n",
      "Ep:88, loss:0.00001, loss_test:0.05205, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.544, tt:3252.435\n",
      "Ep:89, loss:0.00001, loss_test:0.05090, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.536, tt:3288.217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.05255, lr:9.41e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.521, tt:3323.432\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.05182, lr:9.41e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.489, tt:3356.960\n",
      "Ep:92, loss:0.00001, loss_test:0.05344, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.476, tt:3392.305\n",
      "Ep:93, loss:0.00001, loss_test:0.05058, lr:9.41e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.442, tt:3425.513\n",
      "Ep:94, loss:0.00001, loss_test:0.05346, lr:9.41e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.427, tt:3460.524\n",
      "Ep:95, loss:0.00001, loss_test:0.05190, lr:9.41e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.413, tt:3495.694\n",
      "Ep:96, loss:0.00001, loss_test:0.05273, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.399, tt:3530.742\n",
      "Ep:97, loss:0.00001, loss_test:0.05342, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.387, tt:3565.909\n",
      "Ep:98, loss:0.00001, loss_test:0.05078, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.362, tt:3599.801\n",
      "Ep:99, loss:0.00001, loss_test:0.05355, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.342, tt:3634.211\n",
      "Ep:100, loss:0.00001, loss_test:0.05175, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.323, tt:3668.642\n",
      "Ep:101, loss:0.00001, loss_test:0.05315, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.296, tt:3702.177\n",
      "Ep:102, loss:0.00001, loss_test:0.05277, lr:9.32e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.255, tt:3734.273\n",
      "Ep:103, loss:0.00001, loss_test:0.05079, lr:9.23e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.234, tt:3768.335\n",
      "Ep:104, loss:0.00001, loss_test:0.05318, lr:9.14e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.204, tt:3801.395\n",
      "Ep:105, loss:0.00001, loss_test:0.05106, lr:9.04e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.170, tt:3833.979\n",
      "Ep:106, loss:0.00001, loss_test:0.05240, lr:8.95e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.148, tt:3867.818\n",
      "Ep:107, loss:0.00001, loss_test:0.05179, lr:8.86e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.120, tt:3900.962\n",
      "Ep:108, loss:0.00001, loss_test:0.05170, lr:8.78e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.105, tt:3935.477\n",
      "Ep:109, loss:0.00001, loss_test:0.05204, lr:8.69e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.090, tt:3969.944\n",
      "Ep:110, loss:0.00001, loss_test:0.05183, lr:8.60e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.073, tt:4004.059\n",
      "Ep:111, loss:0.00000, loss_test:0.05272, lr:8.51e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.045, tt:4037.050\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.05118, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.023, tt:4070.580\n",
      "Ep:113, loss:0.00000, loss_test:0.05251, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.014, tt:4105.575\n",
      "Ep:114, loss:0.00000, loss_test:0.05188, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.987, tt:4138.537\n",
      "Ep:115, loss:0.00000, loss_test:0.05362, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.959, tt:4171.237\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00000, loss_test:0.05265, lr:8.51e-03, fs:0.89247 (r=0.838,p=0.954),  time:35.931, tt:4203.964\n",
      "Ep:117, loss:0.00000, loss_test:0.05156, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:35.891, tt:4235.122\n",
      "Ep:118, loss:0.00000, loss_test:0.05347, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.840, tt:4264.961\n",
      "Ep:119, loss:0.00000, loss_test:0.05152, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.813, tt:4297.602\n",
      "Ep:120, loss:0.00000, loss_test:0.05206, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:35.774, tt:4328.637\n",
      "Ep:121, loss:0.00000, loss_test:0.05328, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.738, tt:4359.995\n",
      "Ep:122, loss:0.00000, loss_test:0.05552, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.704, tt:4391.587\n",
      "Ep:123, loss:0.00000, loss_test:0.05242, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.679, tt:4424.202\n",
      "Ep:124, loss:0.00000, loss_test:0.05387, lr:8.51e-03, fs:0.90217 (r=0.838,p=0.976),  time:35.622, tt:4452.723\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00000, loss_test:0.05363, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.569, tt:4481.693\n",
      "Ep:126, loss:0.00000, loss_test:0.05109, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:35.533, tt:4512.728\n",
      "Ep:127, loss:0.00000, loss_test:0.05454, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.507, tt:4544.919\n",
      "Ep:128, loss:0.00000, loss_test:0.05394, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.475, tt:4576.271\n",
      "Ep:129, loss:0.00000, loss_test:0.05282, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.446, tt:4607.967\n",
      "Ep:130, loss:0.00000, loss_test:0.05345, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.413, tt:4639.138\n",
      "Ep:131, loss:0.00000, loss_test:0.05184, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.397, tt:4672.389\n",
      "Ep:132, loss:0.00000, loss_test:0.05366, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.367, tt:4703.755\n",
      "Ep:133, loss:0.00000, loss_test:0.05243, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.345, tt:4736.223\n",
      "Ep:134, loss:0.00000, loss_test:0.05173, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.317, tt:4767.741\n",
      "Ep:135, loss:0.00000, loss_test:0.05315, lr:8.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.292, tt:4799.765\n",
      "Ep:136, loss:0.00000, loss_test:0.05235, lr:8.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.259, tt:4830.533\n",
      "Ep:137, loss:0.00000, loss_test:0.05221, lr:8.35e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.243, tt:4863.546\n",
      "Ep:138, loss:0.00000, loss_test:0.05261, lr:8.26e-03, fs:0.89247 (r=0.838,p=0.954),  time:35.217, tt:4895.208\n",
      "Ep:139, loss:0.00000, loss_test:0.05218, lr:8.18e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.192, tt:4926.889\n",
      "Ep:140, loss:0.00000, loss_test:0.05279, lr:8.10e-03, fs:0.89247 (r=0.838,p=0.954),  time:35.173, tt:4959.420\n",
      "Ep:141, loss:0.00000, loss_test:0.05298, lr:8.02e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.161, tt:4992.847\n",
      "Ep:142, loss:0.00000, loss_test:0.05323, lr:7.94e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.148, tt:5026.182\n",
      "Ep:143, loss:0.00000, loss_test:0.05284, lr:7.86e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.132, tt:5059.025\n",
      "Ep:144, loss:0.00000, loss_test:0.05304, lr:7.78e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.119, tt:5092.237\n",
      "Ep:145, loss:0.00000, loss_test:0.05225, lr:7.70e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.103, tt:5124.971\n",
      "Ep:146, loss:0.00000, loss_test:0.05342, lr:7.62e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.092, tt:5158.454\n",
      "Ep:147, loss:0.00000, loss_test:0.05319, lr:7.55e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.071, tt:5190.541\n",
      "Ep:148, loss:0.00000, loss_test:0.05219, lr:7.47e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.051, tt:5222.612\n",
      "Ep:149, loss:0.00000, loss_test:0.05303, lr:7.40e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.045, tt:5256.747\n",
      "Ep:150, loss:0.00000, loss_test:0.05290, lr:7.32e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.020, tt:5287.993\n",
      "Ep:151, loss:0.00000, loss_test:0.05355, lr:7.25e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.999, tt:5319.776\n",
      "Ep:152, loss:0.00000, loss_test:0.05282, lr:7.18e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.976, tt:5351.293\n",
      "Ep:153, loss:0.00000, loss_test:0.05216, lr:7.11e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.955, tt:5383.136\n",
      "Ep:154, loss:0.00000, loss_test:0.05319, lr:7.03e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.932, tt:5414.395\n",
      "Ep:155, loss:0.00000, loss_test:0.05266, lr:6.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.910, tt:5445.959\n",
      "Ep:156, loss:0.00000, loss_test:0.05248, lr:6.89e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.877, tt:5475.671\n",
      "Ep:157, loss:0.00000, loss_test:0.05423, lr:6.83e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.857, tt:5507.431\n",
      "Ep:158, loss:0.00000, loss_test:0.05255, lr:6.76e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.830, tt:5537.966\n",
      "Ep:159, loss:0.00000, loss_test:0.05246, lr:6.69e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.798, tt:5567.635\n",
      "Ep:160, loss:0.00000, loss_test:0.05360, lr:6.62e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.771, tt:5598.158\n",
      "Ep:161, loss:0.00000, loss_test:0.05312, lr:6.56e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.750, tt:5629.549\n",
      "Ep:162, loss:0.00000, loss_test:0.05312, lr:6.49e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.737, tt:5662.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00000, loss_test:0.05481, lr:6.43e-03, fs:0.89130 (r=0.828,p=0.965),  time:34.719, tt:5693.963\n",
      "Ep:164, loss:0.00000, loss_test:0.05336, lr:6.36e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.696, tt:5724.859\n",
      "Ep:165, loss:0.00000, loss_test:0.05300, lr:6.30e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.689, tt:5758.400\n",
      "Ep:166, loss:0.00000, loss_test:0.05409, lr:6.24e-03, fs:0.87293 (r=0.798,p=0.963),  time:34.676, tt:5790.907\n",
      "Ep:167, loss:0.00000, loss_test:0.05250, lr:6.17e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.663, tt:5823.366\n",
      "Ep:168, loss:0.00000, loss_test:0.05302, lr:6.11e-03, fs:0.89247 (r=0.838,p=0.954),  time:34.642, tt:5854.517\n",
      "Ep:169, loss:0.00000, loss_test:0.05361, lr:6.05e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.629, tt:5886.901\n",
      "Ep:170, loss:0.00000, loss_test:0.05282, lr:5.99e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.606, tt:5917.596\n",
      "Ep:171, loss:0.00000, loss_test:0.05291, lr:5.93e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.589, tt:5949.368\n",
      "Ep:172, loss:0.00000, loss_test:0.05369, lr:5.87e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.572, tt:5980.911\n",
      "Ep:173, loss:0.00000, loss_test:0.05267, lr:5.81e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.555, tt:6012.527\n",
      "Ep:174, loss:0.00000, loss_test:0.05293, lr:5.75e-03, fs:0.88525 (r=0.818,p=0.964),  time:34.537, tt:6043.983\n",
      "Ep:175, loss:0.00000, loss_test:0.05402, lr:5.70e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.509, tt:6073.666\n",
      "Ep:176, loss:0.00000, loss_test:0.05227, lr:5.64e-03, fs:0.89130 (r=0.828,p=0.965),  time:34.486, tt:6104.057\n",
      "Ep:177, loss:0.00000, loss_test:0.05218, lr:5.58e-03, fs:0.89730 (r=0.838,p=0.965),  time:34.458, tt:6133.576\n",
      "Ep:178, loss:0.00000, loss_test:0.05395, lr:5.53e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.433, tt:6163.560\n",
      "Ep:179, loss:0.00000, loss_test:0.05350, lr:5.47e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.400, tt:6192.031\n",
      "Ep:180, loss:0.00000, loss_test:0.05260, lr:5.42e-03, fs:0.89130 (r=0.828,p=0.965),  time:34.387, tt:6224.110\n",
      "Ep:181, loss:0.00000, loss_test:0.05335, lr:5.36e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.371, tt:6255.601\n",
      "Ep:182, loss:0.00000, loss_test:0.05333, lr:5.31e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.351, tt:6286.212\n",
      "Ep:183, loss:0.00000, loss_test:0.05256, lr:5.26e-03, fs:0.89130 (r=0.828,p=0.965),  time:34.325, tt:6315.738\n",
      "Ep:184, loss:0.00000, loss_test:0.05250, lr:5.20e-03, fs:0.89130 (r=0.828,p=0.965),  time:34.305, tt:6346.362\n",
      "Ep:185, loss:0.00000, loss_test:0.05276, lr:5.15e-03, fs:0.87293 (r=0.798,p=0.963),  time:34.284, tt:6376.793\n",
      "Ep:186, loss:0.00000, loss_test:0.05245, lr:5.10e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.255, tt:6405.699\n",
      "Ep:187, loss:0.00000, loss_test:0.05274, lr:5.05e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.232, tt:6435.593\n",
      "Ep:188, loss:0.00000, loss_test:0.05298, lr:5.00e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.220, tt:6467.588\n",
      "Ep:189, loss:0.00000, loss_test:0.05238, lr:4.95e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.191, tt:6496.238\n",
      "Ep:190, loss:0.00000, loss_test:0.05295, lr:4.90e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.171, tt:6526.681\n",
      "Ep:191, loss:0.00000, loss_test:0.05332, lr:4.85e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.159, tt:6558.437\n",
      "Ep:192, loss:0.00000, loss_test:0.05257, lr:4.80e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.149, tt:6590.740\n",
      "Ep:193, loss:0.00000, loss_test:0.05277, lr:4.75e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.130, tt:6621.124\n",
      "Ep:194, loss:0.00000, loss_test:0.05339, lr:4.71e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.111, tt:6651.743\n",
      "Ep:195, loss:0.00000, loss_test:0.05260, lr:4.66e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.087, tt:6680.995\n",
      "Ep:196, loss:0.00000, loss_test:0.05267, lr:4.61e-03, fs:0.89130 (r=0.828,p=0.965),  time:34.073, tt:6712.378\n",
      "Ep:197, loss:0.00000, loss_test:0.05361, lr:4.57e-03, fs:0.86667 (r=0.788,p=0.963),  time:34.033, tt:6738.525\n",
      "Ep:198, loss:0.00000, loss_test:0.05298, lr:4.52e-03, fs:0.86667 (r=0.788,p=0.963),  time:33.995, tt:6765.080\n",
      "Ep:199, loss:0.00000, loss_test:0.05236, lr:4.48e-03, fs:0.86667 (r=0.788,p=0.963),  time:33.951, tt:6790.253\n",
      "Ep:200, loss:0.00000, loss_test:0.05305, lr:4.43e-03, fs:0.86667 (r=0.788,p=0.963),  time:33.886, tt:6811.152\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02134, lr:6.00e-02, fs:0.62447 (r=0.851,p=0.493),  time:40.227, tt:40.227\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02348, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.671, tt:79.342\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02471, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.694, tt:119.082\n",
      "Ep:3, loss:0.00005, loss_test:0.02435, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.028, tt:160.113\n",
      "Ep:4, loss:0.00005, loss_test:0.02309, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.103, tt:200.517\n",
      "Ep:5, loss:0.00004, loss_test:0.02197, lr:6.00e-02, fs:0.64228 (r=0.908,p=0.497),  time:40.075, tt:240.447\n",
      "Ep:6, loss:0.00004, loss_test:0.02173, lr:6.00e-02, fs:0.63677 (r=0.816,p=0.522),  time:40.155, tt:281.086\n",
      "Ep:7, loss:0.00004, loss_test:0.02272, lr:6.00e-02, fs:0.65686 (r=0.770,p=0.573),  time:40.039, tt:320.312\n",
      "Ep:8, loss:0.00004, loss_test:0.02310, lr:6.00e-02, fs:0.65625 (r=0.724,p=0.600),  time:39.948, tt:359.528\n",
      "Ep:9, loss:0.00004, loss_test:0.02163, lr:6.00e-02, fs:0.65979 (r=0.736,p=0.598),  time:39.809, tt:398.091\n",
      "Ep:10, loss:0.00003, loss_test:0.01994, lr:6.00e-02, fs:0.65025 (r=0.759,p=0.569),  time:39.995, tt:439.946\n",
      "Ep:11, loss:0.00003, loss_test:0.01921, lr:6.00e-02, fs:0.66972 (r=0.839,p=0.557),  time:40.139, tt:481.664\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01897, lr:6.00e-02, fs:0.67580 (r=0.851,p=0.561),  time:40.212, tt:522.756\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01896, lr:6.00e-02, fs:0.67943 (r=0.816,p=0.582),  time:40.158, tt:562.217\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01918, lr:6.00e-02, fs:0.68063 (r=0.747,p=0.625),  time:40.092, tt:601.384\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01941, lr:6.00e-02, fs:0.67797 (r=0.690,p=0.667),  time:40.120, tt:641.914\n",
      "Ep:16, loss:0.00003, loss_test:0.01936, lr:6.00e-02, fs:0.63953 (r=0.632,p=0.647),  time:40.153, tt:682.594\n",
      "Ep:17, loss:0.00003, loss_test:0.01907, lr:6.00e-02, fs:0.65116 (r=0.644,p=0.659),  time:40.217, tt:723.909\n",
      "Ep:18, loss:0.00003, loss_test:0.01878, lr:6.00e-02, fs:0.64773 (r=0.655,p=0.640),  time:40.194, tt:763.695\n",
      "Ep:19, loss:0.00003, loss_test:0.01870, lr:6.00e-02, fs:0.65143 (r=0.655,p=0.648),  time:40.168, tt:803.362\n",
      "Ep:20, loss:0.00002, loss_test:0.01886, lr:6.00e-02, fs:0.65896 (r=0.655,p=0.663),  time:40.214, tt:844.500\n",
      "Ep:21, loss:0.00002, loss_test:0.01908, lr:6.00e-02, fs:0.63905 (r=0.621,p=0.659),  time:40.168, tt:883.688\n",
      "Ep:22, loss:0.00002, loss_test:0.01919, lr:6.00e-02, fs:0.63095 (r=0.609,p=0.654),  time:40.503, tt:931.558\n",
      "Ep:23, loss:0.00002, loss_test:0.01915, lr:6.00e-02, fs:0.63095 (r=0.609,p=0.654),  time:40.529, tt:972.689\n",
      "Ep:24, loss:0.00002, loss_test:0.01903, lr:6.00e-02, fs:0.66667 (r=0.655,p=0.679),  time:40.581, tt:1014.518\n",
      "Ep:25, loss:0.00002, loss_test:0.01898, lr:6.00e-02, fs:0.66667 (r=0.655,p=0.679),  time:40.660, tt:1057.169\n",
      "Ep:26, loss:0.00002, loss_test:0.01903, lr:5.94e-02, fs:0.66667 (r=0.655,p=0.679),  time:40.657, tt:1097.736\n",
      "Ep:27, loss:0.00002, loss_test:0.01913, lr:5.88e-02, fs:0.66272 (r=0.644,p=0.683),  time:40.631, tt:1137.661\n",
      "Ep:28, loss:0.00002, loss_test:0.01929, lr:5.82e-02, fs:0.66265 (r=0.632,p=0.696),  time:40.534, tt:1175.472\n",
      "Ep:29, loss:0.00002, loss_test:0.01939, lr:5.76e-02, fs:0.65455 (r=0.621,p=0.692),  time:40.495, tt:1214.838\n",
      "Ep:30, loss:0.00002, loss_test:0.01947, lr:5.71e-02, fs:0.66667 (r=0.621,p=0.720),  time:40.486, tt:1255.077\n",
      "Ep:31, loss:0.00002, loss_test:0.01944, lr:5.65e-02, fs:0.67485 (r=0.632,p=0.724),  time:40.504, tt:1296.125\n",
      "Ep:32, loss:0.00002, loss_test:0.01943, lr:5.59e-02, fs:0.67485 (r=0.632,p=0.724),  time:40.519, tt:1337.124\n",
      "Ep:33, loss:0.00002, loss_test:0.01955, lr:5.54e-02, fs:0.67901 (r=0.632,p=0.733),  time:40.502, tt:1377.081\n",
      "Ep:34, loss:0.00002, loss_test:0.01966, lr:5.48e-02, fs:0.68323 (r=0.632,p=0.743),  time:40.479, tt:1416.749\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01962, lr:5.48e-02, fs:0.68750 (r=0.632,p=0.753),  time:40.472, tt:1456.981\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01959, lr:5.48e-02, fs:0.69182 (r=0.632,p=0.764),  time:40.448, tt:1496.592\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01972, lr:5.48e-02, fs:0.69620 (r=0.632,p=0.775),  time:40.434, tt:1536.496\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01976, lr:5.48e-02, fs:0.68790 (r=0.621,p=0.771),  time:40.422, tt:1576.465\n",
      "Ep:39, loss:0.00002, loss_test:0.01978, lr:5.48e-02, fs:0.68354 (r=0.621,p=0.761),  time:40.355, tt:1614.208\n",
      "Ep:40, loss:0.00002, loss_test:0.01995, lr:5.48e-02, fs:0.68790 (r=0.621,p=0.771),  time:40.336, tt:1653.787\n",
      "Ep:41, loss:0.00002, loss_test:0.02010, lr:5.48e-02, fs:0.69231 (r=0.621,p=0.783),  time:40.307, tt:1692.883\n",
      "Ep:42, loss:0.00002, loss_test:0.02021, lr:5.48e-02, fs:0.69677 (r=0.621,p=0.794),  time:40.315, tt:1733.562\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.02028, lr:5.48e-02, fs:0.69281 (r=0.609,p=0.803),  time:40.361, tt:1775.868\n",
      "Ep:44, loss:0.00001, loss_test:0.02037, lr:5.48e-02, fs:0.69737 (r=0.609,p=0.815),  time:40.403, tt:1818.116\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.02046, lr:5.48e-02, fs:0.69737 (r=0.609,p=0.815),  time:40.400, tt:1858.403\n",
      "Ep:46, loss:0.00001, loss_test:0.02056, lr:5.48e-02, fs:0.69737 (r=0.609,p=0.815),  time:40.428, tt:1900.094\n",
      "Ep:47, loss:0.00001, loss_test:0.02069, lr:5.48e-02, fs:0.69737 (r=0.609,p=0.815),  time:40.468, tt:1942.453\n",
      "Ep:48, loss:0.00001, loss_test:0.02084, lr:5.48e-02, fs:0.70667 (r=0.609,p=0.841),  time:40.453, tt:1982.196\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.02097, lr:5.48e-02, fs:0.70667 (r=0.609,p=0.841),  time:40.460, tt:2022.999\n",
      "Ep:50, loss:0.00001, loss_test:0.02115, lr:5.48e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.468, tt:2063.869\n",
      "Ep:51, loss:0.00001, loss_test:0.02138, lr:5.48e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.467, tt:2104.305\n",
      "Ep:52, loss:0.00001, loss_test:0.02138, lr:5.48e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.481, tt:2145.478\n",
      "Ep:53, loss:0.00001, loss_test:0.02143, lr:5.48e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.470, tt:2185.373\n",
      "Ep:54, loss:0.00001, loss_test:0.02158, lr:5.48e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.461, tt:2225.364\n",
      "Ep:55, loss:0.00001, loss_test:0.02170, lr:5.48e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.463, tt:2265.950\n",
      "Ep:56, loss:0.00001, loss_test:0.02187, lr:5.48e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.456, tt:2306.001\n",
      "Ep:57, loss:0.00001, loss_test:0.02211, lr:5.48e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.470, tt:2347.236\n",
      "Ep:58, loss:0.00001, loss_test:0.02228, lr:5.48e-02, fs:0.70345 (r=0.586,p=0.879),  time:40.472, tt:2387.857\n",
      "Ep:59, loss:0.00001, loss_test:0.02246, lr:5.48e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.469, tt:2428.112\n",
      "Ep:60, loss:0.00001, loss_test:0.02259, lr:5.43e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.483, tt:2469.437\n",
      "Ep:61, loss:0.00001, loss_test:0.02276, lr:5.37e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.508, tt:2511.480\n",
      "Ep:62, loss:0.00001, loss_test:0.02305, lr:5.32e-02, fs:0.68085 (r=0.552,p=0.889),  time:40.517, tt:2552.580\n",
      "Ep:63, loss:0.00001, loss_test:0.02318, lr:5.27e-02, fs:0.68085 (r=0.552,p=0.889),  time:40.477, tt:2590.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.02327, lr:5.21e-02, fs:0.69014 (r=0.563,p=0.891),  time:40.441, tt:2628.697\n",
      "Ep:65, loss:0.00001, loss_test:0.02345, lr:5.16e-02, fs:0.68085 (r=0.552,p=0.889),  time:40.455, tt:2669.997\n",
      "Ep:66, loss:0.00001, loss_test:0.02364, lr:5.11e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.463, tt:2711.025\n",
      "Ep:67, loss:0.00001, loss_test:0.02369, lr:5.06e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.476, tt:2752.376\n",
      "Ep:68, loss:0.00001, loss_test:0.02396, lr:5.01e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.471, tt:2792.531\n",
      "Ep:69, loss:0.00001, loss_test:0.02426, lr:4.96e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.465, tt:2832.554\n",
      "Ep:70, loss:0.00001, loss_test:0.02431, lr:4.91e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.505, tt:2875.833\n",
      "Ep:71, loss:0.00001, loss_test:0.02452, lr:4.86e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.544, tt:2919.136\n",
      "Ep:72, loss:0.00001, loss_test:0.02466, lr:4.81e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.593, tt:2963.321\n",
      "Ep:73, loss:0.00001, loss_test:0.02494, lr:4.76e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.606, tt:3004.868\n",
      "Ep:74, loss:0.00001, loss_test:0.02503, lr:4.71e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.599, tt:3044.932\n",
      "Ep:75, loss:0.00001, loss_test:0.02517, lr:4.67e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.609, tt:3086.284\n",
      "Ep:76, loss:0.00001, loss_test:0.02536, lr:4.62e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.622, tt:3127.914\n",
      "Ep:77, loss:0.00001, loss_test:0.02556, lr:4.57e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.623, tt:3168.593\n",
      "Ep:78, loss:0.00001, loss_test:0.02553, lr:4.53e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.634, tt:3210.089\n",
      "Ep:79, loss:0.00001, loss_test:0.02572, lr:4.48e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.657, tt:3252.588\n",
      "Ep:80, loss:0.00001, loss_test:0.02597, lr:4.44e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.641, tt:3291.900\n",
      "Ep:81, loss:0.00001, loss_test:0.02616, lr:4.39e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.652, tt:3333.475\n",
      "Ep:82, loss:0.00001, loss_test:0.02630, lr:4.35e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.659, tt:3374.705\n",
      "Ep:83, loss:0.00001, loss_test:0.02640, lr:4.31e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.662, tt:3415.636\n",
      "Ep:84, loss:0.00001, loss_test:0.02657, lr:4.26e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.752, tt:3463.902\n",
      "Ep:85, loss:0.00001, loss_test:0.02670, lr:4.22e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.774, tt:3506.576\n",
      "Ep:86, loss:0.00001, loss_test:0.02695, lr:4.18e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.779, tt:3547.815\n",
      "Ep:87, loss:0.00001, loss_test:0.02721, lr:4.14e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.792, tt:3589.738\n",
      "Ep:88, loss:0.00001, loss_test:0.02731, lr:4.10e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.791, tt:3630.364\n",
      "Ep:89, loss:0.00001, loss_test:0.02750, lr:4.05e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.805, tt:3672.418\n",
      "Ep:90, loss:0.00001, loss_test:0.02759, lr:4.01e-02, fs:0.67143 (r=0.540,p=0.887),  time:40.826, tt:3715.166\n",
      "Ep:91, loss:0.00001, loss_test:0.02776, lr:3.97e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.810, tt:3754.554\n",
      "Ep:92, loss:0.00001, loss_test:0.02789, lr:3.93e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.811, tt:3795.445\n",
      "Ep:93, loss:0.00001, loss_test:0.02808, lr:3.89e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.817, tt:3836.779\n",
      "Ep:94, loss:0.00001, loss_test:0.02824, lr:3.86e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.802, tt:3876.161\n",
      "Ep:95, loss:0.00001, loss_test:0.02833, lr:3.82e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.802, tt:3916.960\n",
      "Ep:96, loss:0.00001, loss_test:0.02851, lr:3.78e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.805, tt:3958.064\n",
      "Ep:97, loss:0.00001, loss_test:0.02862, lr:3.74e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.800, tt:3998.371\n",
      "Ep:98, loss:0.00001, loss_test:0.02876, lr:3.70e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.821, tt:4041.315\n",
      "Ep:99, loss:0.00001, loss_test:0.02895, lr:3.67e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.837, tt:4083.685\n",
      "Ep:100, loss:0.00001, loss_test:0.02901, lr:3.63e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.853, tt:4126.121\n",
      "Ep:101, loss:0.00001, loss_test:0.02930, lr:3.59e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.872, tt:4168.932\n",
      "Ep:102, loss:0.00001, loss_test:0.02942, lr:3.56e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.873, tt:4209.932\n",
      "Ep:103, loss:0.00001, loss_test:0.02956, lr:3.52e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.889, tt:4252.456\n",
      "Ep:104, loss:0.00001, loss_test:0.02962, lr:3.49e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.891, tt:4293.595\n",
      "Ep:105, loss:0.00001, loss_test:0.02974, lr:3.45e-02, fs:0.67626 (r=0.540,p=0.904),  time:40.953, tt:4340.999\n",
      "Ep:106, loss:0.00001, loss_test:0.02987, lr:3.42e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.948, tt:4381.402\n",
      "Ep:107, loss:0.00001, loss_test:0.02997, lr:3.38e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.952, tt:4422.790\n",
      "Ep:108, loss:0.00001, loss_test:0.03018, lr:3.35e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.954, tt:4463.998\n",
      "Ep:109, loss:0.00001, loss_test:0.03021, lr:3.32e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.940, tt:4503.410\n",
      "Ep:110, loss:0.00001, loss_test:0.03034, lr:3.28e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.949, tt:4545.303\n",
      "Ep:111, loss:0.00001, loss_test:0.03066, lr:3.25e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.961, tt:4587.590\n",
      "Ep:112, loss:0.00001, loss_test:0.03079, lr:3.22e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.970, tt:4629.585\n",
      "Ep:113, loss:0.00001, loss_test:0.03084, lr:3.19e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.968, tt:4670.383\n",
      "Ep:114, loss:0.00001, loss_test:0.03100, lr:3.15e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.962, tt:4710.607\n",
      "Ep:115, loss:0.00001, loss_test:0.03113, lr:3.12e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.952, tt:4750.474\n",
      "Ep:116, loss:0.00001, loss_test:0.03123, lr:3.09e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.954, tt:4791.637\n",
      "Ep:117, loss:0.00001, loss_test:0.03135, lr:3.06e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.959, tt:4833.150\n",
      "Ep:118, loss:0.00001, loss_test:0.03148, lr:3.03e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.969, tt:4875.368\n",
      "Ep:119, loss:0.00001, loss_test:0.03164, lr:3.00e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.977, tt:4917.260\n",
      "Ep:120, loss:0.00001, loss_test:0.03171, lr:2.97e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.986, tt:4959.267\n",
      "Ep:121, loss:0.00001, loss_test:0.03182, lr:2.94e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.988, tt:5000.526\n",
      "Ep:122, loss:0.00001, loss_test:0.03198, lr:2.91e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.992, tt:5041.998\n",
      "Ep:123, loss:0.00001, loss_test:0.03205, lr:2.88e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.990, tt:5082.706\n",
      "Ep:124, loss:0.00001, loss_test:0.03218, lr:2.85e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.993, tt:5124.110\n",
      "Ep:125, loss:0.00000, loss_test:0.03225, lr:2.82e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.995, tt:5165.370\n",
      "Ep:126, loss:0.00000, loss_test:0.03241, lr:2.80e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.064, tt:5215.152\n",
      "Ep:127, loss:0.00000, loss_test:0.03251, lr:2.77e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.070, tt:5256.944\n",
      "Ep:128, loss:0.00000, loss_test:0.03263, lr:2.74e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.082, tt:5299.635\n",
      "Ep:129, loss:0.00000, loss_test:0.03275, lr:2.71e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.083, tt:5340.757\n",
      "Ep:130, loss:0.00000, loss_test:0.03284, lr:2.69e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.074, tt:5380.751\n",
      "Ep:131, loss:0.00000, loss_test:0.03296, lr:2.66e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.079, tt:5422.405\n",
      "Ep:132, loss:0.00000, loss_test:0.03302, lr:2.63e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.080, tt:5463.592\n",
      "Ep:133, loss:0.00000, loss_test:0.03316, lr:2.61e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.079, tt:5504.603\n",
      "Ep:134, loss:0.00000, loss_test:0.03333, lr:2.58e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.084, tt:5546.326\n",
      "Ep:135, loss:0.00000, loss_test:0.03336, lr:2.55e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.082, tt:5587.090\n",
      "Ep:136, loss:0.00000, loss_test:0.03346, lr:2.53e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.085, tt:5628.702\n",
      "Ep:137, loss:0.00000, loss_test:0.03361, lr:2.50e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.091, tt:5670.525\n",
      "Ep:138, loss:0.00000, loss_test:0.03366, lr:2.48e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.083, tt:5710.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.03371, lr:2.45e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.087, tt:5752.233\n",
      "Ep:140, loss:0.00000, loss_test:0.03386, lr:2.43e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.087, tt:5793.256\n",
      "Ep:141, loss:0.00000, loss_test:0.03398, lr:2.40e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.088, tt:5834.521\n",
      "Ep:142, loss:0.00000, loss_test:0.03403, lr:2.38e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.092, tt:5876.094\n",
      "Ep:143, loss:0.00000, loss_test:0.03415, lr:2.36e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.083, tt:5915.933\n",
      "Ep:144, loss:0.00000, loss_test:0.03430, lr:2.33e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.087, tt:5957.640\n",
      "Ep:145, loss:0.00000, loss_test:0.03429, lr:2.31e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.084, tt:5998.212\n",
      "Ep:146, loss:0.00000, loss_test:0.03436, lr:2.29e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.089, tt:6040.111\n",
      "Ep:147, loss:0.00000, loss_test:0.03449, lr:2.26e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.093, tt:6081.805\n",
      "Ep:148, loss:0.00000, loss_test:0.03457, lr:2.24e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.084, tt:6121.448\n",
      "Ep:149, loss:0.00000, loss_test:0.03469, lr:2.22e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.077, tt:6161.494\n",
      "Ep:150, loss:0.00000, loss_test:0.03477, lr:2.20e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.076, tt:6202.411\n",
      "Ep:151, loss:0.00000, loss_test:0.03488, lr:2.17e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.062, tt:6241.481\n",
      "Ep:152, loss:0.00000, loss_test:0.03494, lr:2.15e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.053, tt:6281.077\n",
      "Ep:153, loss:0.00000, loss_test:0.03499, lr:2.13e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.036, tt:6319.485\n",
      "Ep:154, loss:0.00000, loss_test:0.03509, lr:2.11e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.015, tt:6357.253\n",
      "Ep:155, loss:0.00000, loss_test:0.03517, lr:2.09e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.019, tt:6399.008\n",
      "Ep:156, loss:0.00000, loss_test:0.03524, lr:2.07e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.023, tt:6440.580\n",
      "Ep:157, loss:0.00000, loss_test:0.03531, lr:2.05e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.027, tt:6482.242\n",
      "Ep:158, loss:0.00000, loss_test:0.03538, lr:2.03e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.017, tt:6521.686\n",
      "Ep:159, loss:0.00000, loss_test:0.03553, lr:2.01e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.022, tt:6563.589\n",
      "Ep:160, loss:0.00000, loss_test:0.03559, lr:1.99e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.017, tt:6603.716\n",
      "Ep:161, loss:0.00000, loss_test:0.03568, lr:1.97e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.016, tt:6644.615\n",
      "Ep:162, loss:0.00000, loss_test:0.03569, lr:1.95e-02, fs:0.68116 (r=0.540,p=0.922),  time:41.004, tt:6683.657\n",
      "Ep:163, loss:0.00000, loss_test:0.03576, lr:1.93e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.990, tt:6722.360\n",
      "Ep:164, loss:0.00000, loss_test:0.03587, lr:1.91e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.993, tt:6763.863\n",
      "Ep:165, loss:0.00000, loss_test:0.03596, lr:1.89e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.986, tt:6803.658\n",
      "Ep:166, loss:0.00000, loss_test:0.03602, lr:1.87e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.976, tt:6843.059\n",
      "Ep:167, loss:0.00000, loss_test:0.03607, lr:1.85e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.997, tt:6887.436\n",
      "Ep:168, loss:0.00000, loss_test:0.03616, lr:1.83e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.993, tt:6927.776\n",
      "Ep:169, loss:0.00000, loss_test:0.03624, lr:1.81e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.990, tt:6968.235\n",
      "Ep:170, loss:0.00000, loss_test:0.03627, lr:1.80e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.982, tt:7007.862\n",
      "Ep:171, loss:0.00000, loss_test:0.03635, lr:1.78e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.978, tt:7048.176\n",
      "Ep:172, loss:0.00000, loss_test:0.03641, lr:1.76e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.967, tt:7087.244\n",
      "Ep:173, loss:0.00000, loss_test:0.03646, lr:1.74e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.959, tt:7126.799\n",
      "Ep:174, loss:0.00000, loss_test:0.03649, lr:1.73e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.961, tt:7168.178\n",
      "Ep:175, loss:0.00000, loss_test:0.03659, lr:1.71e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.957, tt:7208.517\n",
      "Ep:176, loss:0.00000, loss_test:0.03668, lr:1.69e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.951, tt:7248.341\n",
      "Ep:177, loss:0.00000, loss_test:0.03671, lr:1.67e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.942, tt:7287.699\n",
      "Ep:178, loss:0.00000, loss_test:0.03682, lr:1.66e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.929, tt:7326.246\n",
      "Ep:179, loss:0.00000, loss_test:0.03691, lr:1.64e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.933, tt:7367.989\n",
      "Ep:180, loss:0.00000, loss_test:0.03697, lr:1.62e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.928, tt:7408.032\n",
      "Ep:181, loss:0.00000, loss_test:0.03705, lr:1.61e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.935, tt:7450.258\n",
      "Ep:182, loss:0.00000, loss_test:0.03709, lr:1.59e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.935, tt:7491.092\n",
      "Ep:183, loss:0.00000, loss_test:0.03711, lr:1.58e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.939, tt:7532.751\n",
      "Ep:184, loss:0.00000, loss_test:0.03720, lr:1.56e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.940, tt:7573.821\n",
      "Ep:185, loss:0.00000, loss_test:0.03720, lr:1.54e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.936, tt:7614.004\n",
      "Ep:186, loss:0.00000, loss_test:0.03725, lr:1.53e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.938, tt:7655.339\n",
      "Ep:187, loss:0.00000, loss_test:0.03735, lr:1.51e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.937, tt:7696.246\n",
      "Ep:188, loss:0.00000, loss_test:0.03745, lr:1.50e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.963, tt:7742.017\n",
      "Ep:189, loss:0.00000, loss_test:0.03745, lr:1.48e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.960, tt:7782.377\n",
      "Ep:190, loss:0.00000, loss_test:0.03750, lr:1.47e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.960, tt:7823.355\n",
      "Ep:191, loss:0.00000, loss_test:0.03752, lr:1.45e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.948, tt:7861.926\n",
      "Ep:192, loss:0.00000, loss_test:0.03757, lr:1.44e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.939, tt:7901.296\n",
      "Ep:193, loss:0.00000, loss_test:0.03764, lr:1.43e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.931, tt:7940.630\n",
      "Ep:194, loss:0.00000, loss_test:0.03768, lr:1.41e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.926, tt:7980.485\n",
      "Ep:195, loss:0.00000, loss_test:0.03773, lr:1.40e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.921, tt:8020.608\n",
      "Ep:196, loss:0.00000, loss_test:0.03780, lr:1.38e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.912, tt:8059.703\n",
      "Ep:197, loss:0.00000, loss_test:0.03788, lr:1.37e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.903, tt:8098.811\n",
      "Ep:198, loss:0.00000, loss_test:0.03792, lr:1.36e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.893, tt:8137.721\n",
      "Ep:199, loss:0.00000, loss_test:0.03795, lr:1.34e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.884, tt:8176.817\n",
      "Ep:200, loss:0.00000, loss_test:0.03798, lr:1.33e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.887, tt:8218.347\n",
      "Ep:201, loss:0.00000, loss_test:0.03806, lr:1.32e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.884, tt:8258.506\n",
      "Ep:202, loss:0.00000, loss_test:0.03811, lr:1.30e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.881, tt:8298.901\n",
      "Ep:203, loss:0.00000, loss_test:0.03815, lr:1.29e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.875, tt:8338.501\n",
      "Ep:204, loss:0.00000, loss_test:0.03820, lr:1.28e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.878, tt:8380.028\n",
      "Ep:205, loss:0.00000, loss_test:0.03824, lr:1.26e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.882, tt:8421.755\n",
      "Ep:206, loss:0.00000, loss_test:0.03829, lr:1.25e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.883, tt:8462.882\n",
      "Ep:207, loss:0.00000, loss_test:0.03830, lr:1.24e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.880, tt:8503.099\n",
      "Ep:208, loss:0.00000, loss_test:0.03835, lr:1.23e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.864, tt:8540.626\n",
      "Ep:209, loss:0.00000, loss_test:0.03843, lr:1.21e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.869, tt:8582.577\n",
      "Ep:210, loss:0.00000, loss_test:0.03847, lr:1.20e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.855, tt:8620.345\n",
      "Ep:211, loss:0.00000, loss_test:0.03846, lr:1.19e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.824, tt:8654.620\n",
      "Ep:212, loss:0.00000, loss_test:0.03852, lr:1.18e-02, fs:0.68116 (r=0.540,p=0.922),  time:40.813, tt:8693.219\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14632, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.179, tt:41.179\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14504, lr:1.00e-02, fs:0.65370 (r=0.966,p=0.494),  time:41.996, tt:83.992\n",
      "Ep:2, loss:0.00027, loss_test:0.14250, lr:1.00e-02, fs:0.64000 (r=0.920,p=0.491),  time:41.611, tt:124.833\n",
      "Ep:3, loss:0.00026, loss_test:0.13830, lr:1.00e-02, fs:0.63478 (r=0.839,p=0.510),  time:41.708, tt:166.833\n",
      "Ep:4, loss:0.00024, loss_test:0.13393, lr:1.00e-02, fs:0.64322 (r=0.736,p=0.571),  time:41.900, tt:209.500\n",
      "Ep:5, loss:0.00023, loss_test:0.13478, lr:1.00e-02, fs:0.58824 (r=0.575,p=0.602),  time:41.546, tt:249.276\n",
      "Ep:6, loss:0.00022, loss_test:0.13202, lr:1.00e-02, fs:0.61628 (r=0.609,p=0.624),  time:41.491, tt:290.437\n",
      "Ep:7, loss:0.00021, loss_test:0.12701, lr:1.00e-02, fs:0.65608 (r=0.713,p=0.608),  time:41.341, tt:330.727\n",
      "Ep:8, loss:0.00021, loss_test:0.12284, lr:1.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:41.418, tt:372.761\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.12197, lr:1.00e-02, fs:0.64286 (r=0.621,p=0.667),  time:41.459, tt:414.586\n",
      "Ep:10, loss:0.00019, loss_test:0.11773, lr:1.00e-02, fs:0.65143 (r=0.655,p=0.648),  time:41.492, tt:456.409\n",
      "Ep:11, loss:0.00018, loss_test:0.11493, lr:1.00e-02, fs:0.64835 (r=0.678,p=0.621),  time:41.640, tt:499.685\n",
      "Ep:12, loss:0.00018, loss_test:0.11471, lr:1.00e-02, fs:0.59873 (r=0.540,p=0.671),  time:41.678, tt:541.816\n",
      "Ep:13, loss:0.00017, loss_test:0.11222, lr:1.00e-02, fs:0.60645 (r=0.540,p=0.691),  time:41.747, tt:584.454\n",
      "Ep:14, loss:0.00016, loss_test:0.10981, lr:1.00e-02, fs:0.64706 (r=0.632,p=0.663),  time:41.657, tt:624.849\n",
      "Ep:15, loss:0.00016, loss_test:0.10970, lr:1.00e-02, fs:0.64828 (r=0.540,p=0.810),  time:41.666, tt:666.661\n",
      "Ep:16, loss:0.00015, loss_test:0.10774, lr:1.00e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.697, tt:708.857\n",
      "Ep:17, loss:0.00015, loss_test:0.10509, lr:1.00e-02, fs:0.69182 (r=0.632,p=0.764),  time:41.729, tt:751.120\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.10392, lr:1.00e-02, fs:0.68027 (r=0.575,p=0.833),  time:41.825, tt:794.668\n",
      "Ep:19, loss:0.00014, loss_test:0.10166, lr:1.00e-02, fs:0.70968 (r=0.632,p=0.809),  time:41.906, tt:838.115\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.10200, lr:1.00e-02, fs:0.72368 (r=0.632,p=0.846),  time:41.897, tt:879.841\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.10037, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:41.964, tt:923.201\n",
      "Ep:22, loss:0.00012, loss_test:0.09969, lr:1.00e-02, fs:0.72258 (r=0.644,p=0.824),  time:42.092, tt:968.115\n",
      "Ep:23, loss:0.00012, loss_test:0.09966, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.210, tt:1013.042\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09756, lr:1.00e-02, fs:0.72727 (r=0.644,p=0.836),  time:42.240, tt:1056.004\n",
      "Ep:25, loss:0.00011, loss_test:0.10000, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.370, tt:1101.622\n",
      "Ep:26, loss:0.00011, loss_test:0.09686, lr:1.00e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.362, tt:1143.785\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.09715, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.402, tt:1187.253\n",
      "Ep:28, loss:0.00010, loss_test:0.09308, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:42.445, tt:1230.909\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.09774, lr:1.00e-02, fs:0.72848 (r=0.632,p=0.859),  time:42.489, tt:1274.660\n",
      "Ep:30, loss:0.00009, loss_test:0.09472, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:42.475, tt:1316.719\n",
      "Ep:31, loss:0.00009, loss_test:0.09908, lr:1.00e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.501, tt:1360.027\n",
      "Ep:32, loss:0.00009, loss_test:0.09339, lr:1.00e-02, fs:0.74839 (r=0.667,p=0.853),  time:42.515, tt:1403.003\n",
      "Ep:33, loss:0.00008, loss_test:0.10087, lr:1.00e-02, fs:0.70270 (r=0.598,p=0.852),  time:42.480, tt:1444.314\n",
      "Ep:34, loss:0.00008, loss_test:0.09747, lr:1.00e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.521, tt:1488.222\n",
      "Ep:35, loss:0.00008, loss_test:0.09757, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:42.575, tt:1532.692\n",
      "Ep:36, loss:0.00008, loss_test:0.10370, lr:1.00e-02, fs:0.68493 (r=0.575,p=0.847),  time:42.599, tt:1576.156\n",
      "Ep:37, loss:0.00007, loss_test:0.09577, lr:1.00e-02, fs:0.72848 (r=0.632,p=0.859),  time:42.622, tt:1619.622\n",
      "Ep:38, loss:0.00007, loss_test:0.09690, lr:1.00e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.692, tt:1664.972\n",
      "Ep:39, loss:0.00007, loss_test:0.10396, lr:1.00e-02, fs:0.66667 (r=0.552,p=0.842),  time:42.688, tt:1707.508\n",
      "Ep:40, loss:0.00006, loss_test:0.10130, lr:9.90e-03, fs:0.69388 (r=0.586,p=0.850),  time:42.716, tt:1751.343\n",
      "Ep:41, loss:0.00006, loss_test:0.10104, lr:9.80e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.730, tt:1794.679\n",
      "Ep:42, loss:0.00006, loss_test:0.10934, lr:9.70e-03, fs:0.64789 (r=0.529,p=0.836),  time:42.778, tt:1839.469\n",
      "Ep:43, loss:0.00006, loss_test:0.09914, lr:9.61e-03, fs:0.72000 (r=0.621,p=0.857),  time:42.759, tt:1881.381\n",
      "Ep:44, loss:0.00006, loss_test:0.10932, lr:9.51e-03, fs:0.64789 (r=0.529,p=0.836),  time:42.802, tt:1926.092\n",
      "Ep:45, loss:0.00005, loss_test:0.10962, lr:9.41e-03, fs:0.64789 (r=0.529,p=0.836),  time:42.787, tt:1968.187\n",
      "Ep:46, loss:0.00005, loss_test:0.10602, lr:9.32e-03, fs:0.66197 (r=0.540,p=0.855),  time:42.788, tt:2011.034\n",
      "Ep:47, loss:0.00005, loss_test:0.11379, lr:9.23e-03, fs:0.63830 (r=0.517,p=0.833),  time:42.789, tt:2053.894\n",
      "Ep:48, loss:0.00005, loss_test:0.10685, lr:9.14e-03, fs:0.66197 (r=0.540,p=0.855),  time:42.807, tt:2097.529\n",
      "Ep:49, loss:0.00005, loss_test:0.11314, lr:9.04e-03, fs:0.64286 (r=0.517,p=0.849),  time:42.807, tt:2140.340\n",
      "Ep:50, loss:0.00004, loss_test:0.10707, lr:8.95e-03, fs:0.66197 (r=0.540,p=0.855),  time:42.846, tt:2185.127\n",
      "Ep:51, loss:0.00004, loss_test:0.11246, lr:8.86e-03, fs:0.63309 (r=0.506,p=0.846),  time:42.843, tt:2227.852\n",
      "Ep:52, loss:0.00004, loss_test:0.11740, lr:8.78e-03, fs:0.60294 (r=0.471,p=0.837),  time:42.892, tt:2273.277\n",
      "Ep:53, loss:0.00004, loss_test:0.10705, lr:8.69e-03, fs:0.66197 (r=0.540,p=0.855),  time:42.863, tt:2314.619\n",
      "Ep:54, loss:0.00004, loss_test:0.12179, lr:8.60e-03, fs:0.56923 (r=0.425,p=0.860),  time:42.826, tt:2355.435\n",
      "Ep:55, loss:0.00004, loss_test:0.10996, lr:8.51e-03, fs:0.66197 (r=0.540,p=0.855),  time:42.806, tt:2397.130\n",
      "Ep:56, loss:0.00004, loss_test:0.11036, lr:8.43e-03, fs:0.64286 (r=0.517,p=0.849),  time:42.820, tt:2440.751\n",
      "Ep:57, loss:0.00004, loss_test:0.11557, lr:8.35e-03, fs:0.57364 (r=0.425,p=0.881),  time:42.770, tt:2480.683\n",
      "Ep:58, loss:0.00003, loss_test:0.10465, lr:8.26e-03, fs:0.65248 (r=0.529,p=0.852),  time:42.747, tt:2522.065\n",
      "Ep:59, loss:0.00003, loss_test:0.11985, lr:8.18e-03, fs:0.56250 (r=0.414,p=0.878),  time:42.734, tt:2564.020\n",
      "Ep:60, loss:0.00003, loss_test:0.10980, lr:8.10e-03, fs:0.64286 (r=0.517,p=0.849),  time:42.707, tt:2605.147\n",
      "Ep:61, loss:0.00003, loss_test:0.11773, lr:8.02e-03, fs:0.56923 (r=0.425,p=0.860),  time:42.721, tt:2648.699\n",
      "Ep:62, loss:0.00003, loss_test:0.10932, lr:7.94e-03, fs:0.66197 (r=0.540,p=0.855),  time:42.705, tt:2690.426\n",
      "Ep:63, loss:0.00003, loss_test:0.12156, lr:7.86e-03, fs:0.56250 (r=0.414,p=0.878),  time:42.713, tt:2733.656\n",
      "Ep:64, loss:0.00003, loss_test:0.11086, lr:7.78e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.709, tt:2776.103\n",
      "Ep:65, loss:0.00003, loss_test:0.12277, lr:7.70e-03, fs:0.56250 (r=0.414,p=0.878),  time:42.674, tt:2816.513\n",
      "Ep:66, loss:0.00003, loss_test:0.12373, lr:7.62e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.662, tt:2858.332\n",
      "Ep:67, loss:0.00003, loss_test:0.10931, lr:7.55e-03, fs:0.65248 (r=0.529,p=0.852),  time:42.636, tt:2899.266\n",
      "Ep:68, loss:0.00002, loss_test:0.12589, lr:7.47e-03, fs:0.55118 (r=0.402,p=0.875),  time:42.628, tt:2941.338\n",
      "Ep:69, loss:0.00002, loss_test:0.11160, lr:7.40e-03, fs:0.60294 (r=0.471,p=0.837),  time:42.625, tt:2983.785\n",
      "Ep:70, loss:0.00002, loss_test:0.12397, lr:7.32e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.642, tt:3027.587\n",
      "Ep:71, loss:0.00002, loss_test:0.11913, lr:7.25e-03, fs:0.56250 (r=0.414,p=0.878),  time:42.632, tt:3069.481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00002, loss_test:0.11768, lr:7.18e-03, fs:0.56250 (r=0.414,p=0.878),  time:42.624, tt:3111.519\n",
      "Ep:73, loss:0.00002, loss_test:0.12054, lr:7.11e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.598, tt:3152.242\n",
      "Ep:74, loss:0.00002, loss_test:0.11538, lr:7.03e-03, fs:0.56250 (r=0.414,p=0.878),  time:42.587, tt:3194.004\n",
      "Ep:75, loss:0.00002, loss_test:0.12271, lr:6.96e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.584, tt:3236.400\n",
      "Ep:76, loss:0.00002, loss_test:0.11880, lr:6.89e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.594, tt:3279.714\n",
      "Ep:77, loss:0.00002, loss_test:0.11865, lr:6.83e-03, fs:0.55118 (r=0.402,p=0.875),  time:42.583, tt:3321.469\n",
      "Ep:78, loss:0.00002, loss_test:0.11736, lr:6.76e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.590, tt:3364.629\n",
      "Ep:79, loss:0.00002, loss_test:0.12394, lr:6.69e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.599, tt:3407.927\n",
      "Ep:80, loss:0.00002, loss_test:0.11571, lr:6.62e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.614, tt:3451.740\n",
      "Ep:81, loss:0.00002, loss_test:0.12421, lr:6.56e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.599, tt:3493.092\n",
      "Ep:82, loss:0.00002, loss_test:0.11648, lr:6.49e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.609, tt:3536.586\n",
      "Ep:83, loss:0.00002, loss_test:0.12277, lr:6.43e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.579, tt:3576.628\n",
      "Ep:84, loss:0.00002, loss_test:0.12038, lr:6.36e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.570, tt:3618.416\n",
      "Ep:85, loss:0.00001, loss_test:0.12266, lr:6.30e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.549, tt:3659.204\n",
      "Ep:86, loss:0.00001, loss_test:0.11677, lr:6.24e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.563, tt:3702.948\n",
      "Ep:87, loss:0.00001, loss_test:0.13069, lr:6.17e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.530, tt:3742.667\n",
      "Ep:88, loss:0.00001, loss_test:0.11845, lr:6.11e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.524, tt:3784.653\n",
      "Ep:89, loss:0.00001, loss_test:0.12748, lr:6.05e-03, fs:0.54400 (r=0.391,p=0.895),  time:42.531, tt:3827.802\n",
      "Ep:90, loss:0.00001, loss_test:0.12573, lr:5.99e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.530, tt:3870.199\n",
      "Ep:91, loss:0.00001, loss_test:0.12304, lr:5.93e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.542, tt:3913.819\n",
      "Ep:92, loss:0.00001, loss_test:0.12420, lr:5.87e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.528, tt:3955.090\n",
      "Ep:93, loss:0.00001, loss_test:0.12367, lr:5.81e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.539, tt:3998.689\n",
      "Ep:94, loss:0.00001, loss_test:0.12026, lr:5.75e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.547, tt:4041.996\n",
      "Ep:95, loss:0.00001, loss_test:0.12495, lr:5.70e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.600, tt:4089.626\n",
      "Ep:96, loss:0.00001, loss_test:0.12570, lr:5.64e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.607, tt:4132.846\n",
      "Ep:97, loss:0.00001, loss_test:0.11893, lr:5.58e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.595, tt:4174.344\n",
      "Ep:98, loss:0.00001, loss_test:0.12591, lr:5.53e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.576, tt:4215.018\n",
      "Ep:99, loss:0.00001, loss_test:0.12519, lr:5.47e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.582, tt:4258.234\n",
      "Ep:100, loss:0.00001, loss_test:0.12247, lr:5.42e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.582, tt:4300.784\n",
      "Ep:101, loss:0.00001, loss_test:0.12480, lr:5.36e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.571, tt:4342.213\n",
      "Ep:102, loss:0.00001, loss_test:0.12363, lr:5.31e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.556, tt:4383.320\n",
      "Ep:103, loss:0.00001, loss_test:0.12358, lr:5.26e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.558, tt:4426.018\n",
      "Ep:104, loss:0.00001, loss_test:0.12390, lr:5.20e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.559, tt:4468.745\n",
      "Ep:105, loss:0.00001, loss_test:0.12483, lr:5.15e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.539, tt:4509.170\n",
      "Ep:106, loss:0.00001, loss_test:0.12391, lr:5.10e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.521, tt:4549.698\n",
      "Ep:107, loss:0.00001, loss_test:0.12369, lr:5.05e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.493, tt:4589.236\n",
      "Ep:108, loss:0.00001, loss_test:0.12508, lr:5.00e-03, fs:0.54400 (r=0.391,p=0.895),  time:42.489, tt:4631.340\n",
      "Ep:109, loss:0.00001, loss_test:0.12369, lr:4.95e-03, fs:0.55556 (r=0.402,p=0.897),  time:42.464, tt:4671.074\n",
      "Ep:110, loss:0.00001, loss_test:0.12604, lr:4.90e-03, fs:0.54400 (r=0.391,p=0.895),  time:42.454, tt:4712.369\n",
      "Ep:111, loss:0.00001, loss_test:0.12394, lr:4.85e-03, fs:0.54400 (r=0.391,p=0.895),  time:42.433, tt:4752.527\n",
      "Ep:112, loss:0.00001, loss_test:0.12631, lr:4.80e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.410, tt:4792.322\n",
      "Ep:113, loss:0.00001, loss_test:0.12876, lr:4.75e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.417, tt:4835.593\n",
      "Ep:114, loss:0.00001, loss_test:0.12329, lr:4.71e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.415, tt:4877.740\n",
      "Ep:115, loss:0.00001, loss_test:0.12635, lr:4.66e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.406, tt:4919.060\n",
      "Ep:116, loss:0.00001, loss_test:0.12665, lr:4.61e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.400, tt:4960.851\n",
      "Ep:117, loss:0.00001, loss_test:0.12309, lr:4.57e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.392, tt:5002.258\n",
      "Ep:118, loss:0.00001, loss_test:0.12911, lr:4.52e-03, fs:0.52033 (r=0.368,p=0.889),  time:42.386, tt:5043.960\n",
      "Ep:119, loss:0.00001, loss_test:0.12731, lr:4.48e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.389, tt:5086.735\n",
      "Ep:120, loss:0.00001, loss_test:0.12373, lr:4.43e-03, fs:0.52033 (r=0.368,p=0.889),  time:42.385, tt:5128.609\n",
      "Ep:121, loss:0.00001, loss_test:0.12657, lr:4.39e-03, fs:0.53226 (r=0.379,p=0.892),  time:42.378, tt:5170.057\n",
      "Ep:122, loss:0.00001, loss_test:0.12723, lr:4.34e-03, fs:0.52033 (r=0.368,p=0.889),  time:42.365, tt:5210.920\n",
      "Ep:123, loss:0.00001, loss_test:0.12466, lr:4.30e-03, fs:0.52033 (r=0.368,p=0.889),  time:42.346, tt:5250.881\n",
      "Ep:124, loss:0.00001, loss_test:0.12859, lr:4.26e-03, fs:0.50820 (r=0.356,p=0.886),  time:42.358, tt:5294.691\n",
      "Ep:125, loss:0.00001, loss_test:0.13041, lr:4.21e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.366, tt:5338.078\n",
      "Ep:126, loss:0.00001, loss_test:0.12556, lr:4.17e-03, fs:0.50820 (r=0.356,p=0.886),  time:42.369, tt:5380.829\n",
      "Ep:127, loss:0.00001, loss_test:0.12711, lr:4.13e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.372, tt:5423.664\n",
      "Ep:128, loss:0.00001, loss_test:0.12683, lr:4.09e-03, fs:0.50820 (r=0.356,p=0.886),  time:42.379, tt:5466.923\n",
      "Ep:129, loss:0.00001, loss_test:0.12726, lr:4.05e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.386, tt:5510.179\n",
      "Ep:130, loss:0.00001, loss_test:0.12760, lr:4.01e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.389, tt:5553.001\n",
      "Ep:131, loss:0.00001, loss_test:0.12773, lr:3.97e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.397, tt:5596.432\n",
      "Ep:132, loss:0.00001, loss_test:0.12689, lr:3.93e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.399, tt:5639.077\n",
      "Ep:133, loss:0.00001, loss_test:0.12851, lr:3.89e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.388, tt:5680.000\n",
      "Ep:134, loss:0.00001, loss_test:0.13039, lr:3.85e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.378, tt:5721.054\n",
      "Ep:135, loss:0.00001, loss_test:0.12706, lr:3.81e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.376, tt:5763.159\n",
      "Ep:136, loss:0.00001, loss_test:0.12654, lr:3.77e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.388, tt:5807.090\n",
      "Ep:137, loss:0.00001, loss_test:0.12914, lr:3.73e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.384, tt:5849.022\n",
      "Ep:138, loss:0.00001, loss_test:0.12899, lr:3.70e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.384, tt:5891.384\n",
      "Ep:139, loss:0.00001, loss_test:0.12732, lr:3.66e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.387, tt:5934.158\n",
      "Ep:140, loss:0.00001, loss_test:0.13009, lr:3.62e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.396, tt:5977.781\n",
      "Ep:141, loss:0.00001, loss_test:0.12883, lr:3.59e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.403, tt:6021.292\n",
      "Ep:142, loss:0.00001, loss_test:0.12599, lr:3.55e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.408, tt:6064.390\n",
      "Ep:143, loss:0.00001, loss_test:0.12938, lr:3.52e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.407, tt:6106.677\n",
      "Ep:144, loss:0.00001, loss_test:0.13009, lr:3.48e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.400, tt:6147.931\n",
      "Ep:145, loss:0.00001, loss_test:0.12647, lr:3.45e-03, fs:0.49587 (r=0.345,p=0.882),  time:42.386, tt:6188.367\n",
      "Ep:146, loss:0.00001, loss_test:0.12852, lr:3.41e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.384, tt:6230.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.12900, lr:3.38e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.382, tt:6272.516\n",
      "Ep:148, loss:0.00001, loss_test:0.12746, lr:3.34e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.371, tt:6313.280\n",
      "Ep:149, loss:0.00001, loss_test:0.12809, lr:3.31e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.358, tt:6353.648\n",
      "Ep:150, loss:0.00001, loss_test:0.12828, lr:3.28e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.363, tt:6396.879\n",
      "Ep:151, loss:0.00001, loss_test:0.12882, lr:3.24e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.358, tt:6438.400\n",
      "Ep:152, loss:0.00001, loss_test:0.12877, lr:3.21e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.358, tt:6480.715\n",
      "Ep:153, loss:0.00001, loss_test:0.12861, lr:3.18e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.363, tt:6523.914\n",
      "Ep:154, loss:0.00000, loss_test:0.12918, lr:3.15e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.353, tt:6564.675\n",
      "Ep:155, loss:0.00000, loss_test:0.12810, lr:3.12e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.341, tt:6605.197\n",
      "Ep:156, loss:0.00000, loss_test:0.12934, lr:3.09e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.350, tt:6649.008\n",
      "Ep:157, loss:0.00000, loss_test:0.12818, lr:3.05e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.343, tt:6690.199\n",
      "Ep:158, loss:0.00000, loss_test:0.12784, lr:3.02e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.342, tt:6732.336\n",
      "Ep:159, loss:0.00000, loss_test:0.12954, lr:2.99e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.338, tt:6774.114\n",
      "Ep:160, loss:0.00000, loss_test:0.12877, lr:2.96e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.337, tt:6816.234\n",
      "Ep:161, loss:0.00000, loss_test:0.12745, lr:2.93e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.319, tt:6855.686\n",
      "Ep:162, loss:0.00000, loss_test:0.12907, lr:2.90e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.298, tt:6894.573\n",
      "Ep:163, loss:0.00000, loss_test:0.12997, lr:2.88e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.284, tt:6934.613\n",
      "Ep:164, loss:0.00000, loss_test:0.12884, lr:2.85e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.284, tt:6976.930\n",
      "Ep:165, loss:0.00000, loss_test:0.12928, lr:2.82e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.261, tt:7015.318\n",
      "Ep:166, loss:0.00000, loss_test:0.12865, lr:2.79e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.255, tt:7056.546\n",
      "Ep:167, loss:0.00000, loss_test:0.12961, lr:2.76e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.249, tt:7097.848\n",
      "Ep:168, loss:0.00000, loss_test:0.12823, lr:2.73e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.247, tt:7139.771\n",
      "Ep:169, loss:0.00000, loss_test:0.12838, lr:2.71e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.226, tt:7178.421\n",
      "Ep:170, loss:0.00000, loss_test:0.12996, lr:2.68e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.206, tt:7217.298\n",
      "Ep:171, loss:0.00000, loss_test:0.12873, lr:2.65e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.203, tt:7258.895\n",
      "Ep:172, loss:0.00000, loss_test:0.12766, lr:2.63e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.194, tt:7299.609\n",
      "Ep:173, loss:0.00000, loss_test:0.12966, lr:2.60e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.183, tt:7339.869\n",
      "Ep:174, loss:0.00000, loss_test:0.13031, lr:2.57e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.181, tt:7381.657\n",
      "Ep:175, loss:0.00000, loss_test:0.12931, lr:2.55e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.161, tt:7420.404\n",
      "Ep:176, loss:0.00000, loss_test:0.12762, lr:2.52e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.145, tt:7459.686\n",
      "Ep:177, loss:0.00000, loss_test:0.13002, lr:2.50e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.137, tt:7500.451\n",
      "Ep:178, loss:0.00000, loss_test:0.13170, lr:2.47e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.124, tt:7540.197\n",
      "Ep:179, loss:0.00000, loss_test:0.13000, lr:2.45e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.123, tt:7582.089\n",
      "Ep:180, loss:0.00000, loss_test:0.12851, lr:2.42e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.114, tt:7622.644\n",
      "Ep:181, loss:0.00000, loss_test:0.12986, lr:2.40e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.105, tt:7663.044\n",
      "Ep:182, loss:0.00000, loss_test:0.13158, lr:2.38e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.094, tt:7703.262\n",
      "Ep:183, loss:0.00000, loss_test:0.13091, lr:2.35e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.085, tt:7743.691\n",
      "Ep:184, loss:0.00000, loss_test:0.12892, lr:2.33e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.078, tt:7784.386\n",
      "Ep:185, loss:0.00000, loss_test:0.12815, lr:2.31e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.069, tt:7824.810\n",
      "Ep:186, loss:0.00000, loss_test:0.12949, lr:2.28e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.068, tt:7866.690\n",
      "Ep:187, loss:0.00000, loss_test:0.13025, lr:2.26e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.061, tt:7907.385\n",
      "Ep:188, loss:0.00000, loss_test:0.12884, lr:2.24e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.067, tt:7950.611\n",
      "Ep:189, loss:0.00000, loss_test:0.12813, lr:2.21e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.066, tt:7992.538\n",
      "Ep:190, loss:0.00000, loss_test:0.12983, lr:2.19e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.067, tt:8034.736\n",
      "Ep:191, loss:0.00000, loss_test:0.13033, lr:2.17e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.071, tt:8077.715\n",
      "Ep:192, loss:0.00000, loss_test:0.12896, lr:2.15e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.066, tt:8118.783\n",
      "Ep:193, loss:0.00000, loss_test:0.12807, lr:2.13e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.053, tt:8158.184\n",
      "Ep:194, loss:0.00000, loss_test:0.13015, lr:2.11e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.051, tt:8199.922\n",
      "Ep:195, loss:0.00000, loss_test:0.13111, lr:2.08e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.036, tt:8239.004\n",
      "Ep:196, loss:0.00000, loss_test:0.13089, lr:2.06e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.031, tt:8280.154\n",
      "Ep:197, loss:0.00000, loss_test:0.12935, lr:2.04e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.025, tt:8320.973\n",
      "Ep:198, loss:0.00000, loss_test:0.12891, lr:2.02e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.015, tt:8360.940\n",
      "Ep:199, loss:0.00000, loss_test:0.13056, lr:2.00e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.017, tt:8403.331\n",
      "Ep:200, loss:0.00000, loss_test:0.13115, lr:1.98e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.022, tt:8446.390\n",
      "Ep:201, loss:0.00000, loss_test:0.12987, lr:1.96e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.017, tt:8487.530\n",
      "Ep:202, loss:0.00000, loss_test:0.12845, lr:1.94e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.006, tt:8527.221\n",
      "Ep:203, loss:0.00000, loss_test:0.12908, lr:1.92e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.005, tt:8569.097\n",
      "Ep:204, loss:0.00000, loss_test:0.12954, lr:1.90e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.006, tt:8611.329\n",
      "Ep:205, loss:0.00000, loss_test:0.12970, lr:1.89e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.009, tt:8653.783\n",
      "Ep:206, loss:0.00000, loss_test:0.12941, lr:1.87e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.012, tt:8696.575\n",
      "Ep:207, loss:0.00000, loss_test:0.12893, lr:1.85e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.011, tt:8738.242\n",
      "Ep:208, loss:0.00000, loss_test:0.12934, lr:1.83e-03, fs:0.50000 (r=0.345,p=0.909),  time:42.015, tt:8781.229\n",
      "Ep:209, loss:0.00000, loss_test:0.12920, lr:1.81e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.997, tt:8819.328\n",
      "Ep:210, loss:0.00000, loss_test:0.12893, lr:1.79e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.970, tt:8855.736\n",
      "Ep:211, loss:0.00000, loss_test:0.12967, lr:1.78e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.934, tt:8890.051\n",
      "Ep:212, loss:0.00000, loss_test:0.12975, lr:1.76e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.872, tt:8918.775\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02289, lr:6.00e-02, fs:0.56853 (r=0.644,p=0.509),  time:31.203, tt:31.203\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00004, loss_test:0.02174, lr:6.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:34.146, tt:68.292\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02179, lr:6.00e-02, fs:0.66406 (r=0.977,p=0.503),  time:36.234, tt:108.702\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02124, lr:6.00e-02, fs:0.65873 (r=0.954,p=0.503),  time:37.386, tt:149.543\n",
      "Ep:4, loss:0.00004, loss_test:0.02110, lr:6.00e-02, fs:0.64286 (r=0.828,p=0.526),  time:37.915, tt:189.577\n",
      "Ep:5, loss:0.00003, loss_test:0.02214, lr:6.00e-02, fs:0.63918 (r=0.713,p=0.579),  time:38.197, tt:229.185\n",
      "Ep:6, loss:0.00003, loss_test:0.02283, lr:6.00e-02, fs:0.63388 (r=0.667,p=0.604),  time:38.201, tt:267.410\n",
      "Ep:7, loss:0.00003, loss_test:0.02201, lr:6.00e-02, fs:0.65957 (r=0.713,p=0.614),  time:38.351, tt:306.809\n",
      "Ep:8, loss:0.00003, loss_test:0.02089, lr:6.00e-02, fs:0.66667 (r=0.759,p=0.595),  time:38.488, tt:346.395\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.02040, lr:6.00e-02, fs:0.66995 (r=0.782,p=0.586),  time:38.668, tt:386.676\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.02035, lr:6.00e-02, fs:0.68000 (r=0.782,p=0.602),  time:38.796, tt:426.755\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.02055, lr:6.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:38.849, tt:466.191\n",
      "Ep:12, loss:0.00003, loss_test:0.02076, lr:6.00e-02, fs:0.66667 (r=0.724,p=0.618),  time:38.962, tt:506.510\n",
      "Ep:13, loss:0.00003, loss_test:0.02052, lr:6.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:39.114, tt:547.594\n",
      "Ep:14, loss:0.00003, loss_test:0.01994, lr:6.00e-02, fs:0.67725 (r=0.736,p=0.627),  time:39.244, tt:588.664\n",
      "Ep:15, loss:0.00003, loss_test:0.01956, lr:6.00e-02, fs:0.65241 (r=0.701,p=0.610),  time:39.404, tt:630.459\n",
      "Ep:16, loss:0.00003, loss_test:0.01956, lr:6.00e-02, fs:0.64171 (r=0.690,p=0.600),  time:39.447, tt:670.601\n",
      "Ep:17, loss:0.00003, loss_test:0.01986, lr:6.00e-02, fs:0.64088 (r=0.667,p=0.617),  time:39.477, tt:710.579\n",
      "Ep:18, loss:0.00002, loss_test:0.02010, lr:6.00e-02, fs:0.63277 (r=0.644,p=0.622),  time:39.517, tt:750.826\n",
      "Ep:19, loss:0.00002, loss_test:0.01996, lr:6.00e-02, fs:0.62500 (r=0.632,p=0.618),  time:39.494, tt:789.874\n",
      "Ep:20, loss:0.00002, loss_test:0.01980, lr:6.00e-02, fs:0.63218 (r=0.632,p=0.632),  time:39.503, tt:829.560\n",
      "Ep:21, loss:0.00002, loss_test:0.01968, lr:6.00e-02, fs:0.64368 (r=0.644,p=0.644),  time:39.497, tt:868.928\n",
      "Ep:22, loss:0.00002, loss_test:0.01972, lr:5.94e-02, fs:0.64368 (r=0.644,p=0.644),  time:39.479, tt:908.020\n",
      "Ep:23, loss:0.00002, loss_test:0.01982, lr:5.88e-02, fs:0.64740 (r=0.644,p=0.651),  time:39.578, tt:949.884\n",
      "Ep:24, loss:0.00002, loss_test:0.01984, lr:5.82e-02, fs:0.64740 (r=0.644,p=0.651),  time:39.563, tt:989.075\n",
      "Ep:25, loss:0.00002, loss_test:0.01986, lr:5.76e-02, fs:0.64740 (r=0.644,p=0.651),  time:39.581, tt:1029.102\n",
      "Ep:26, loss:0.00002, loss_test:0.01994, lr:5.71e-02, fs:0.64740 (r=0.644,p=0.651),  time:39.607, tt:1069.393\n",
      "Ep:27, loss:0.00002, loss_test:0.01998, lr:5.65e-02, fs:0.65882 (r=0.644,p=0.675),  time:39.605, tt:1108.931\n",
      "Ep:28, loss:0.00002, loss_test:0.02011, lr:5.59e-02, fs:0.66272 (r=0.644,p=0.683),  time:39.596, tt:1148.276\n",
      "Ep:29, loss:0.00002, loss_test:0.02022, lr:5.54e-02, fs:0.66667 (r=0.644,p=0.691),  time:39.588, tt:1187.634\n",
      "Ep:30, loss:0.00002, loss_test:0.02031, lr:5.48e-02, fs:0.67066 (r=0.644,p=0.700),  time:39.656, tt:1229.340\n",
      "Ep:31, loss:0.00002, loss_test:0.02040, lr:5.43e-02, fs:0.67857 (r=0.655,p=0.704),  time:39.642, tt:1268.540\n",
      "Ep:32, loss:0.00002, loss_test:0.02050, lr:5.37e-02, fs:0.68263 (r=0.655,p=0.713),  time:39.664, tt:1308.907\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.02046, lr:5.37e-02, fs:0.68263 (r=0.655,p=0.713),  time:39.707, tt:1350.031\n",
      "Ep:34, loss:0.00002, loss_test:0.02050, lr:5.37e-02, fs:0.68263 (r=0.655,p=0.713),  time:39.720, tt:1390.206\n",
      "Ep:35, loss:0.00002, loss_test:0.02067, lr:5.37e-02, fs:0.68675 (r=0.655,p=0.722),  time:39.740, tt:1430.649\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.02082, lr:5.37e-02, fs:0.69512 (r=0.655,p=0.740),  time:39.818, tt:1473.283\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.02089, lr:5.37e-02, fs:0.69512 (r=0.655,p=0.740),  time:39.832, tt:1513.613\n",
      "Ep:38, loss:0.00002, loss_test:0.02090, lr:5.37e-02, fs:0.69512 (r=0.655,p=0.740),  time:39.797, tt:1552.089\n",
      "Ep:39, loss:0.00001, loss_test:0.02102, lr:5.37e-02, fs:0.69512 (r=0.655,p=0.740),  time:39.764, tt:1590.564\n",
      "Ep:40, loss:0.00001, loss_test:0.02118, lr:5.37e-02, fs:0.69512 (r=0.655,p=0.740),  time:39.780, tt:1630.967\n",
      "Ep:41, loss:0.00001, loss_test:0.02133, lr:5.37e-02, fs:0.68712 (r=0.644,p=0.737),  time:39.755, tt:1669.691\n",
      "Ep:42, loss:0.00001, loss_test:0.02147, lr:5.37e-02, fs:0.67081 (r=0.621,p=0.730),  time:39.752, tt:1709.331\n",
      "Ep:43, loss:0.00001, loss_test:0.02162, lr:5.37e-02, fs:0.66667 (r=0.621,p=0.720),  time:39.743, tt:1748.690\n",
      "Ep:44, loss:0.00001, loss_test:0.02175, lr:5.37e-02, fs:0.67081 (r=0.621,p=0.730),  time:39.713, tt:1787.094\n",
      "Ep:45, loss:0.00001, loss_test:0.02190, lr:5.37e-02, fs:0.69136 (r=0.644,p=0.747),  time:39.714, tt:1826.866\n",
      "Ep:46, loss:0.00001, loss_test:0.02200, lr:5.37e-02, fs:0.68750 (r=0.632,p=0.753),  time:39.720, tt:1866.818\n",
      "Ep:47, loss:0.00001, loss_test:0.02207, lr:5.37e-02, fs:0.68323 (r=0.632,p=0.743),  time:39.704, tt:1905.773\n",
      "Ep:48, loss:0.00001, loss_test:0.02210, lr:5.32e-02, fs:0.68750 (r=0.632,p=0.753),  time:39.732, tt:1946.849\n",
      "Ep:49, loss:0.00001, loss_test:0.02226, lr:5.27e-02, fs:0.68354 (r=0.621,p=0.761),  time:39.711, tt:1985.556\n",
      "Ep:50, loss:0.00001, loss_test:0.02252, lr:5.21e-02, fs:0.68354 (r=0.621,p=0.761),  time:39.698, tt:2024.612\n",
      "Ep:51, loss:0.00001, loss_test:0.02262, lr:5.16e-02, fs:0.68354 (r=0.621,p=0.761),  time:39.702, tt:2064.494\n",
      "Ep:52, loss:0.00001, loss_test:0.02263, lr:5.11e-02, fs:0.68354 (r=0.621,p=0.761),  time:39.711, tt:2104.701\n",
      "Ep:53, loss:0.00001, loss_test:0.02279, lr:5.06e-02, fs:0.67516 (r=0.609,p=0.757),  time:39.720, tt:2144.859\n",
      "Ep:54, loss:0.00001, loss_test:0.02294, lr:5.01e-02, fs:0.68354 (r=0.621,p=0.761),  time:39.720, tt:2184.599\n",
      "Ep:55, loss:0.00001, loss_test:0.02311, lr:4.96e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.754, tt:2226.201\n",
      "Ep:56, loss:0.00001, loss_test:0.02314, lr:4.91e-02, fs:0.69231 (r=0.621,p=0.783),  time:39.776, tt:2267.233\n",
      "Ep:57, loss:0.00001, loss_test:0.02325, lr:4.86e-02, fs:0.69231 (r=0.621,p=0.783),  time:39.783, tt:2307.423\n",
      "Ep:58, loss:0.00001, loss_test:0.02343, lr:4.81e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.788, tt:2347.510\n",
      "Ep:59, loss:0.00001, loss_test:0.02364, lr:4.76e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.742, tt:2384.545\n",
      "Ep:60, loss:0.00001, loss_test:0.02380, lr:4.71e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.784, tt:2426.813\n",
      "Ep:61, loss:0.00001, loss_test:0.02382, lr:4.67e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.822, tt:2468.981\n",
      "Ep:62, loss:0.00001, loss_test:0.02399, lr:4.62e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.837, tt:2509.727\n",
      "Ep:63, loss:0.00001, loss_test:0.02413, lr:4.57e-02, fs:0.67949 (r=0.609,p=0.768),  time:39.828, tt:2549.007\n",
      "Ep:64, loss:0.00001, loss_test:0.02427, lr:4.53e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.810, tt:2587.625\n",
      "Ep:65, loss:0.00001, loss_test:0.02436, lr:4.48e-02, fs:0.68790 (r=0.621,p=0.771),  time:39.772, tt:2624.962\n",
      "Ep:66, loss:0.00001, loss_test:0.02444, lr:4.44e-02, fs:0.67949 (r=0.609,p=0.768),  time:39.775, tt:2664.908\n",
      "Ep:67, loss:0.00001, loss_test:0.02452, lr:4.39e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.797, tt:2706.164\n",
      "Ep:68, loss:0.00001, loss_test:0.02462, lr:4.35e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.774, tt:2744.382\n",
      "Ep:69, loss:0.00001, loss_test:0.02483, lr:4.31e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.785, tt:2784.962\n",
      "Ep:70, loss:0.00001, loss_test:0.02495, lr:4.26e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.816, tt:2826.905\n",
      "Ep:71, loss:0.00001, loss_test:0.02506, lr:4.22e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.831, tt:2867.816\n",
      "Ep:72, loss:0.00001, loss_test:0.02522, lr:4.18e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.823, tt:2907.044\n",
      "Ep:73, loss:0.00001, loss_test:0.02525, lr:4.14e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.797, tt:2944.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00001, loss_test:0.02540, lr:4.10e-02, fs:0.68387 (r=0.609,p=0.779),  time:39.765, tt:2982.377\n",
      "Ep:75, loss:0.00001, loss_test:0.02555, lr:4.05e-02, fs:0.68831 (r=0.609,p=0.791),  time:39.757, tt:3021.495\n",
      "Ep:76, loss:0.00001, loss_test:0.02565, lr:4.01e-02, fs:0.68831 (r=0.609,p=0.791),  time:39.738, tt:3059.830\n",
      "Ep:77, loss:0.00001, loss_test:0.02580, lr:3.97e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.704, tt:3096.909\n",
      "Ep:78, loss:0.00001, loss_test:0.02592, lr:3.93e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.695, tt:3135.916\n",
      "Ep:79, loss:0.00001, loss_test:0.02602, lr:3.89e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.681, tt:3174.502\n",
      "Ep:80, loss:0.00001, loss_test:0.02616, lr:3.86e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.672, tt:3213.432\n",
      "Ep:81, loss:0.00001, loss_test:0.02631, lr:3.82e-02, fs:0.68421 (r=0.598,p=0.800),  time:39.662, tt:3252.280\n",
      "Ep:82, loss:0.00001, loss_test:0.02635, lr:3.78e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.638, tt:3289.927\n",
      "Ep:83, loss:0.00001, loss_test:0.02650, lr:3.74e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.629, tt:3328.832\n",
      "Ep:84, loss:0.00001, loss_test:0.02659, lr:3.70e-02, fs:0.68421 (r=0.598,p=0.800),  time:39.635, tt:3368.967\n",
      "Ep:85, loss:0.00001, loss_test:0.02671, lr:3.67e-02, fs:0.69281 (r=0.609,p=0.803),  time:39.636, tt:3408.689\n",
      "Ep:86, loss:0.00001, loss_test:0.02692, lr:3.63e-02, fs:0.69737 (r=0.609,p=0.815),  time:39.636, tt:3448.345\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.02698, lr:3.63e-02, fs:0.68874 (r=0.598,p=0.812),  time:39.636, tt:3487.965\n",
      "Ep:88, loss:0.00001, loss_test:0.02702, lr:3.63e-02, fs:0.68874 (r=0.598,p=0.812),  time:39.638, tt:3527.771\n",
      "Ep:89, loss:0.00001, loss_test:0.02718, lr:3.63e-02, fs:0.68000 (r=0.586,p=0.810),  time:39.648, tt:3568.345\n",
      "Ep:90, loss:0.00001, loss_test:0.02736, lr:3.63e-02, fs:0.68000 (r=0.586,p=0.810),  time:39.666, tt:3609.628\n",
      "Ep:91, loss:0.00001, loss_test:0.02744, lr:3.63e-02, fs:0.68000 (r=0.586,p=0.810),  time:39.661, tt:3648.848\n",
      "Ep:92, loss:0.00001, loss_test:0.02754, lr:3.63e-02, fs:0.68000 (r=0.586,p=0.810),  time:39.649, tt:3687.352\n",
      "Ep:93, loss:0.00001, loss_test:0.02761, lr:3.63e-02, fs:0.68000 (r=0.586,p=0.810),  time:39.631, tt:3725.343\n",
      "Ep:94, loss:0.00001, loss_test:0.02785, lr:3.63e-02, fs:0.68456 (r=0.586,p=0.823),  time:39.614, tt:3763.318\n",
      "Ep:95, loss:0.00001, loss_test:0.02799, lr:3.63e-02, fs:0.66667 (r=0.563,p=0.817),  time:39.661, tt:3807.501\n",
      "Ep:96, loss:0.00001, loss_test:0.02801, lr:3.63e-02, fs:0.67568 (r=0.575,p=0.820),  time:39.659, tt:3846.924\n",
      "Ep:97, loss:0.00001, loss_test:0.02818, lr:3.63e-02, fs:0.67568 (r=0.575,p=0.820),  time:39.658, tt:3886.487\n",
      "Ep:98, loss:0.00001, loss_test:0.02834, lr:3.59e-02, fs:0.66667 (r=0.563,p=0.817),  time:39.642, tt:3924.518\n",
      "Ep:99, loss:0.00001, loss_test:0.02843, lr:3.56e-02, fs:0.66667 (r=0.563,p=0.817),  time:39.614, tt:3961.370\n",
      "Ep:100, loss:0.00001, loss_test:0.02856, lr:3.52e-02, fs:0.66667 (r=0.563,p=0.817),  time:39.615, tt:4001.155\n",
      "Ep:101, loss:0.00001, loss_test:0.02877, lr:3.49e-02, fs:0.66667 (r=0.563,p=0.817),  time:39.604, tt:4039.574\n",
      "Ep:102, loss:0.00001, loss_test:0.02891, lr:3.45e-02, fs:0.65753 (r=0.552,p=0.814),  time:39.597, tt:4078.456\n",
      "Ep:103, loss:0.00001, loss_test:0.02894, lr:3.42e-02, fs:0.66667 (r=0.563,p=0.817),  time:39.605, tt:4118.966\n",
      "Ep:104, loss:0.00001, loss_test:0.02910, lr:3.38e-02, fs:0.65753 (r=0.552,p=0.814),  time:39.601, tt:4158.056\n",
      "Ep:105, loss:0.00001, loss_test:0.02927, lr:3.35e-02, fs:0.63889 (r=0.529,p=0.807),  time:39.597, tt:4197.288\n",
      "Ep:106, loss:0.00001, loss_test:0.02932, lr:3.32e-02, fs:0.63889 (r=0.529,p=0.807),  time:39.595, tt:4236.668\n",
      "Ep:107, loss:0.00001, loss_test:0.02942, lr:3.28e-02, fs:0.62937 (r=0.517,p=0.804),  time:39.619, tt:4278.870\n",
      "Ep:108, loss:0.00001, loss_test:0.02955, lr:3.25e-02, fs:0.62937 (r=0.517,p=0.804),  time:39.623, tt:4318.882\n",
      "Ep:109, loss:0.00001, loss_test:0.02958, lr:3.22e-02, fs:0.62937 (r=0.517,p=0.804),  time:39.640, tt:4360.443\n",
      "Ep:110, loss:0.00001, loss_test:0.02975, lr:3.19e-02, fs:0.63380 (r=0.517,p=0.818),  time:39.630, tt:4398.980\n",
      "Ep:111, loss:0.00001, loss_test:0.02994, lr:3.15e-02, fs:0.63380 (r=0.517,p=0.818),  time:39.633, tt:4438.930\n",
      "Ep:112, loss:0.00001, loss_test:0.03007, lr:3.12e-02, fs:0.62411 (r=0.506,p=0.815),  time:39.685, tt:4484.457\n",
      "Ep:113, loss:0.00001, loss_test:0.03013, lr:3.09e-02, fs:0.62411 (r=0.506,p=0.815),  time:39.694, tt:4525.132\n",
      "Ep:114, loss:0.00001, loss_test:0.03021, lr:3.06e-02, fs:0.62411 (r=0.506,p=0.815),  time:39.700, tt:4565.544\n",
      "Ep:115, loss:0.00001, loss_test:0.03041, lr:3.03e-02, fs:0.62411 (r=0.506,p=0.815),  time:39.721, tt:4607.625\n",
      "Ep:116, loss:0.00001, loss_test:0.03054, lr:3.00e-02, fs:0.62411 (r=0.506,p=0.815),  time:39.730, tt:4648.434\n",
      "Ep:117, loss:0.00001, loss_test:0.03059, lr:2.97e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.731, tt:4688.225\n",
      "Ep:118, loss:0.00000, loss_test:0.03066, lr:2.94e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.736, tt:4728.605\n",
      "Ep:119, loss:0.00000, loss_test:0.03077, lr:2.91e-02, fs:0.62411 (r=0.506,p=0.815),  time:39.747, tt:4769.588\n",
      "Ep:120, loss:0.00000, loss_test:0.03096, lr:2.88e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.756, tt:4810.510\n",
      "Ep:121, loss:0.00000, loss_test:0.03105, lr:2.85e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.756, tt:4850.267\n",
      "Ep:122, loss:0.00000, loss_test:0.03115, lr:2.82e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.770, tt:4891.704\n",
      "Ep:123, loss:0.00000, loss_test:0.03122, lr:2.80e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.766, tt:4930.953\n",
      "Ep:124, loss:0.00000, loss_test:0.03133, lr:2.77e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.786, tt:4973.220\n",
      "Ep:125, loss:0.00000, loss_test:0.03146, lr:2.74e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.785, tt:5012.847\n",
      "Ep:126, loss:0.00000, loss_test:0.03152, lr:2.71e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.793, tt:5053.663\n",
      "Ep:127, loss:0.00000, loss_test:0.03162, lr:2.69e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.798, tt:5094.121\n",
      "Ep:128, loss:0.00000, loss_test:0.03183, lr:2.66e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.806, tt:5135.028\n",
      "Ep:129, loss:0.00000, loss_test:0.03188, lr:2.63e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.844, tt:5179.671\n",
      "Ep:130, loss:0.00000, loss_test:0.03202, lr:2.61e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.853, tt:5220.725\n",
      "Ep:131, loss:0.00000, loss_test:0.03211, lr:2.58e-02, fs:0.60432 (r=0.483,p=0.808),  time:39.855, tt:5260.855\n",
      "Ep:132, loss:0.00000, loss_test:0.03220, lr:2.55e-02, fs:0.61429 (r=0.494,p=0.811),  time:39.855, tt:5300.755\n",
      "Ep:133, loss:0.00000, loss_test:0.03228, lr:2.53e-02, fs:0.60432 (r=0.483,p=0.808),  time:39.872, tt:5342.806\n",
      "Ep:134, loss:0.00000, loss_test:0.03236, lr:2.50e-02, fs:0.60432 (r=0.483,p=0.808),  time:39.879, tt:5383.664\n",
      "Ep:135, loss:0.00000, loss_test:0.03241, lr:2.48e-02, fs:0.60432 (r=0.483,p=0.808),  time:39.883, tt:5424.123\n",
      "Ep:136, loss:0.00000, loss_test:0.03255, lr:2.45e-02, fs:0.60870 (r=0.483,p=0.824),  time:39.900, tt:5466.296\n",
      "Ep:137, loss:0.00000, loss_test:0.03266, lr:2.43e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.899, tt:5506.019\n",
      "Ep:138, loss:0.00000, loss_test:0.03272, lr:2.40e-02, fs:0.60870 (r=0.483,p=0.824),  time:39.898, tt:5545.829\n",
      "Ep:139, loss:0.00000, loss_test:0.03284, lr:2.38e-02, fs:0.60870 (r=0.483,p=0.824),  time:39.906, tt:5586.801\n",
      "Ep:140, loss:0.00000, loss_test:0.03293, lr:2.36e-02, fs:0.60870 (r=0.483,p=0.824),  time:39.900, tt:5625.945\n",
      "Ep:141, loss:0.00000, loss_test:0.03303, lr:2.33e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.903, tt:5666.160\n",
      "Ep:142, loss:0.00000, loss_test:0.03316, lr:2.31e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.889, tt:5704.192\n",
      "Ep:143, loss:0.00000, loss_test:0.03323, lr:2.29e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.899, tt:5745.520\n",
      "Ep:144, loss:0.00000, loss_test:0.03330, lr:2.26e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.895, tt:5784.838\n",
      "Ep:145, loss:0.00000, loss_test:0.03334, lr:2.24e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.885, tt:5823.269\n",
      "Ep:146, loss:0.00000, loss_test:0.03345, lr:2.22e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.906, tt:5866.138\n",
      "Ep:147, loss:0.00000, loss_test:0.03356, lr:2.20e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.896, tt:5904.670\n",
      "Ep:148, loss:0.00000, loss_test:0.03362, lr:2.17e-02, fs:0.60870 (r=0.483,p=0.824),  time:39.905, tt:5945.837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:149, loss:0.00000, loss_test:0.03372, lr:2.15e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.904, tt:5985.659\n",
      "Ep:150, loss:0.00000, loss_test:0.03382, lr:2.13e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.917, tt:6027.539\n",
      "Ep:151, loss:0.00000, loss_test:0.03390, lr:2.11e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.916, tt:6067.274\n",
      "Ep:152, loss:0.00000, loss_test:0.03394, lr:2.09e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.915, tt:6107.025\n",
      "Ep:153, loss:0.00000, loss_test:0.03404, lr:2.07e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.930, tt:6149.273\n",
      "Ep:154, loss:0.00000, loss_test:0.03410, lr:2.05e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.933, tt:6189.548\n",
      "Ep:155, loss:0.00000, loss_test:0.03418, lr:2.03e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.933, tt:6229.474\n",
      "Ep:156, loss:0.00000, loss_test:0.03425, lr:2.01e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.935, tt:6269.797\n",
      "Ep:157, loss:0.00000, loss_test:0.03437, lr:1.99e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.942, tt:6310.833\n",
      "Ep:158, loss:0.00000, loss_test:0.03445, lr:1.97e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.940, tt:6350.412\n",
      "Ep:159, loss:0.00000, loss_test:0.03448, lr:1.95e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.937, tt:6389.984\n",
      "Ep:160, loss:0.00000, loss_test:0.03457, lr:1.93e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.937, tt:6429.863\n",
      "Ep:161, loss:0.00000, loss_test:0.03459, lr:1.91e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.938, tt:6469.914\n",
      "Ep:162, loss:0.00000, loss_test:0.03463, lr:1.89e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.936, tt:6509.559\n",
      "Ep:163, loss:0.00000, loss_test:0.03473, lr:1.87e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.944, tt:6550.878\n",
      "Ep:164, loss:0.00000, loss_test:0.03481, lr:1.85e-02, fs:0.61314 (r=0.483,p=0.840),  time:39.958, tt:6593.028\n",
      "Ep:165, loss:0.00000, loss_test:0.03490, lr:1.83e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.955, tt:6632.464\n",
      "Ep:166, loss:0.00000, loss_test:0.03494, lr:1.81e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.966, tt:6674.260\n",
      "Ep:167, loss:0.00000, loss_test:0.03501, lr:1.80e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.967, tt:6714.406\n",
      "Ep:168, loss:0.00000, loss_test:0.03510, lr:1.78e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.977, tt:6756.115\n",
      "Ep:169, loss:0.00000, loss_test:0.03521, lr:1.76e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.980, tt:6796.626\n",
      "Ep:170, loss:0.00000, loss_test:0.03524, lr:1.74e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.974, tt:6835.482\n",
      "Ep:171, loss:0.00000, loss_test:0.03529, lr:1.73e-02, fs:0.61765 (r=0.483,p=0.857),  time:39.986, tt:6877.604\n",
      "Ep:172, loss:0.00000, loss_test:0.03539, lr:1.71e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.002, tt:6920.352\n",
      "Ep:173, loss:0.00000, loss_test:0.03543, lr:1.69e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.004, tt:6960.655\n",
      "Ep:174, loss:0.00000, loss_test:0.03552, lr:1.67e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.007, tt:7001.293\n",
      "Ep:175, loss:0.00000, loss_test:0.03560, lr:1.66e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.000, tt:7039.962\n",
      "Ep:176, loss:0.00000, loss_test:0.03566, lr:1.64e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.012, tt:7082.078\n",
      "Ep:177, loss:0.00000, loss_test:0.03570, lr:1.62e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.014, tt:7122.476\n",
      "Ep:178, loss:0.00000, loss_test:0.03578, lr:1.61e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.029, tt:7165.254\n",
      "Ep:179, loss:0.00000, loss_test:0.03582, lr:1.59e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.056, tt:7210.017\n",
      "Ep:180, loss:0.00000, loss_test:0.03587, lr:1.58e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.058, tt:7250.418\n",
      "Ep:181, loss:0.00000, loss_test:0.03594, lr:1.56e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.064, tt:7291.641\n",
      "Ep:182, loss:0.00000, loss_test:0.03604, lr:1.54e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.073, tt:7333.277\n",
      "Ep:183, loss:0.00000, loss_test:0.03611, lr:1.53e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.076, tt:7373.905\n",
      "Ep:184, loss:0.00000, loss_test:0.03613, lr:1.51e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.082, tt:7415.104\n",
      "Ep:185, loss:0.00000, loss_test:0.03614, lr:1.50e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.089, tt:7456.610\n",
      "Ep:186, loss:0.00000, loss_test:0.03626, lr:1.48e-02, fs:0.61765 (r=0.483,p=0.857),  time:40.097, tt:7498.189\n",
      "Ep:187, loss:0.00000, loss_test:0.03633, lr:1.47e-02, fs:0.62222 (r=0.483,p=0.875),  time:40.087, tt:7536.301\n",
      "Ep:188, loss:0.00000, loss_test:0.03640, lr:1.45e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.085, tt:7576.022\n",
      "Ep:189, loss:0.00000, loss_test:0.03644, lr:1.44e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.084, tt:7615.986\n",
      "Ep:190, loss:0.00000, loss_test:0.03648, lr:1.43e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.094, tt:7658.009\n",
      "Ep:191, loss:0.00000, loss_test:0.03654, lr:1.41e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.096, tt:7698.475\n",
      "Ep:192, loss:0.00000, loss_test:0.03659, lr:1.40e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.098, tt:7738.950\n",
      "Ep:193, loss:0.00000, loss_test:0.03666, lr:1.38e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.086, tt:7776.775\n",
      "Ep:194, loss:0.00000, loss_test:0.03673, lr:1.37e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.087, tt:7816.916\n",
      "Ep:195, loss:0.00000, loss_test:0.03674, lr:1.36e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.087, tt:7856.967\n",
      "Ep:196, loss:0.00000, loss_test:0.03680, lr:1.34e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.079, tt:7895.511\n",
      "Ep:197, loss:0.00000, loss_test:0.03685, lr:1.33e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.077, tt:7935.333\n",
      "Ep:198, loss:0.00000, loss_test:0.03688, lr:1.32e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.075, tt:7974.911\n",
      "Ep:199, loss:0.00000, loss_test:0.03695, lr:1.30e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.069, tt:8013.816\n",
      "Ep:200, loss:0.00000, loss_test:0.03703, lr:1.29e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.064, tt:8052.819\n",
      "Ep:201, loss:0.00000, loss_test:0.03705, lr:1.28e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.075, tt:8095.157\n",
      "Ep:202, loss:0.00000, loss_test:0.03707, lr:1.26e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.071, tt:8134.480\n",
      "Ep:203, loss:0.00000, loss_test:0.03714, lr:1.25e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.071, tt:8174.528\n",
      "Ep:204, loss:0.00000, loss_test:0.03720, lr:1.24e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.079, tt:8216.242\n",
      "Ep:205, loss:0.00000, loss_test:0.03720, lr:1.23e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.082, tt:8256.857\n",
      "Ep:206, loss:0.00000, loss_test:0.03726, lr:1.21e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.079, tt:8296.438\n",
      "Ep:207, loss:0.00000, loss_test:0.03733, lr:1.20e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.066, tt:8333.694\n",
      "Ep:208, loss:0.00000, loss_test:0.03739, lr:1.19e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.069, tt:8374.445\n",
      "Ep:209, loss:0.00000, loss_test:0.03743, lr:1.18e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.057, tt:8411.943\n",
      "Ep:210, loss:0.00000, loss_test:0.03748, lr:1.17e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.052, tt:8451.008\n",
      "Ep:211, loss:0.00000, loss_test:0.03752, lr:1.15e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.030, tt:8486.354\n",
      "Ep:212, loss:0.00000, loss_test:0.03754, lr:1.14e-02, fs:0.62687 (r=0.483,p=0.894),  time:40.004, tt:8520.954\n",
      "Ep:213, loss:0.00000, loss_test:0.03760, lr:1.13e-02, fs:0.62687 (r=0.483,p=0.894),  time:39.974, tt:8554.384\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14756, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:31.303, tt:31.303\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14693, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:35.046, tt:70.091\n",
      "Ep:2, loss:0.00027, loss_test:0.14575, lr:1.00e-02, fs:0.65891 (r=0.977,p=0.497),  time:35.428, tt:106.284\n",
      "Ep:3, loss:0.00027, loss_test:0.14392, lr:1.00e-02, fs:0.64490 (r=0.908,p=0.500),  time:37.092, tt:148.370\n",
      "Ep:4, loss:0.00025, loss_test:0.14094, lr:1.00e-02, fs:0.60000 (r=0.759,p=0.496),  time:37.129, tt:185.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00024, loss_test:0.14019, lr:1.00e-02, fs:0.61929 (r=0.701,p=0.555),  time:38.219, tt:229.313\n",
      "Ep:6, loss:0.00023, loss_test:0.13913, lr:1.00e-02, fs:0.59669 (r=0.621,p=0.574),  time:38.637, tt:270.458\n",
      "Ep:7, loss:0.00023, loss_test:0.13336, lr:1.00e-02, fs:0.60000 (r=0.621,p=0.581),  time:39.030, tt:312.240\n",
      "Ep:8, loss:0.00022, loss_test:0.12941, lr:1.00e-02, fs:0.63158 (r=0.690,p=0.583),  time:39.187, tt:352.682\n",
      "Ep:9, loss:0.00021, loss_test:0.12901, lr:1.00e-02, fs:0.61702 (r=0.667,p=0.574),  time:39.611, tt:396.105\n",
      "Ep:10, loss:0.00021, loss_test:0.12875, lr:1.00e-02, fs:0.61111 (r=0.632,p=0.591),  time:39.756, tt:437.317\n",
      "Ep:11, loss:0.00020, loss_test:0.12761, lr:1.00e-02, fs:0.60116 (r=0.598,p=0.605),  time:40.035, tt:480.415\n",
      "Ep:12, loss:0.00020, loss_test:0.12482, lr:9.90e-03, fs:0.62069 (r=0.621,p=0.621),  time:40.012, tt:520.155\n",
      "Ep:13, loss:0.00019, loss_test:0.12146, lr:9.80e-03, fs:0.63687 (r=0.655,p=0.620),  time:40.072, tt:561.002\n",
      "Ep:14, loss:0.00018, loss_test:0.11993, lr:9.70e-03, fs:0.64444 (r=0.667,p=0.624),  time:40.135, tt:602.025\n",
      "Ep:15, loss:0.00018, loss_test:0.11905, lr:9.61e-03, fs:0.65143 (r=0.655,p=0.648),  time:40.110, tt:641.760\n",
      "Ep:16, loss:0.00017, loss_test:0.11760, lr:9.51e-03, fs:0.61905 (r=0.598,p=0.642),  time:40.162, tt:682.756\n",
      "Ep:17, loss:0.00016, loss_test:0.11604, lr:9.41e-03, fs:0.66279 (r=0.655,p=0.671),  time:40.249, tt:724.491\n",
      "Ep:18, loss:0.00016, loss_test:0.11593, lr:9.32e-03, fs:0.63473 (r=0.609,p=0.662),  time:40.382, tt:767.257\n",
      "Ep:19, loss:0.00015, loss_test:0.11563, lr:9.23e-03, fs:0.65432 (r=0.609,p=0.707),  time:40.531, tt:810.617\n",
      "Ep:20, loss:0.00015, loss_test:0.11437, lr:9.14e-03, fs:0.65060 (r=0.621,p=0.684),  time:40.543, tt:851.401\n",
      "Ep:21, loss:0.00014, loss_test:0.11467, lr:9.04e-03, fs:0.65854 (r=0.621,p=0.701),  time:40.588, tt:892.944\n",
      "Ep:22, loss:0.00014, loss_test:0.11364, lr:8.95e-03, fs:0.66667 (r=0.632,p=0.705),  time:40.500, tt:931.502\n",
      "Ep:23, loss:0.00014, loss_test:0.11361, lr:8.86e-03, fs:0.67879 (r=0.644,p=0.718),  time:40.588, tt:974.121\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.11442, lr:8.86e-03, fs:0.67485 (r=0.632,p=0.724),  time:40.598, tt:1014.946\n",
      "Ep:25, loss:0.00013, loss_test:0.11411, lr:8.86e-03, fs:0.67500 (r=0.621,p=0.740),  time:40.668, tt:1057.381\n",
      "Ep:26, loss:0.00012, loss_test:0.11431, lr:8.86e-03, fs:0.68293 (r=0.644,p=0.727),  time:40.749, tt:1100.216\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.11602, lr:8.86e-03, fs:0.68323 (r=0.632,p=0.743),  time:40.775, tt:1141.707\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.11493, lr:8.86e-03, fs:0.68354 (r=0.621,p=0.761),  time:40.843, tt:1184.435\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.11597, lr:8.86e-03, fs:0.67925 (r=0.621,p=0.750),  time:40.914, tt:1227.407\n",
      "Ep:30, loss:0.00011, loss_test:0.11521, lr:8.86e-03, fs:0.67089 (r=0.609,p=0.746),  time:40.968, tt:1269.999\n",
      "Ep:31, loss:0.00011, loss_test:0.11644, lr:8.86e-03, fs:0.65385 (r=0.586,p=0.739),  time:41.039, tt:1313.238\n",
      "Ep:32, loss:0.00010, loss_test:0.11707, lr:8.86e-03, fs:0.65806 (r=0.586,p=0.750),  time:41.122, tt:1357.038\n",
      "Ep:33, loss:0.00010, loss_test:0.11733, lr:8.86e-03, fs:0.67097 (r=0.598,p=0.765),  time:41.175, tt:1399.937\n",
      "Ep:34, loss:0.00010, loss_test:0.11709, lr:8.86e-03, fs:0.65333 (r=0.563,p=0.778),  time:41.183, tt:1441.419\n",
      "Ep:35, loss:0.00009, loss_test:0.11926, lr:8.86e-03, fs:0.64384 (r=0.540,p=0.797),  time:41.238, tt:1484.582\n",
      "Ep:36, loss:0.00009, loss_test:0.11739, lr:8.86e-03, fs:0.65823 (r=0.598,p=0.732),  time:41.288, tt:1527.674\n",
      "Ep:37, loss:0.00009, loss_test:0.12007, lr:8.86e-03, fs:0.64828 (r=0.540,p=0.810),  time:41.329, tt:1570.505\n",
      "Ep:38, loss:0.00008, loss_test:0.12123, lr:8.86e-03, fs:0.63576 (r=0.552,p=0.750),  time:41.378, tt:1613.724\n",
      "Ep:39, loss:0.00008, loss_test:0.12085, lr:8.86e-03, fs:0.64789 (r=0.529,p=0.836),  time:41.436, tt:1657.452\n",
      "Ep:40, loss:0.00008, loss_test:0.12019, lr:8.78e-03, fs:0.65306 (r=0.552,p=0.800),  time:41.456, tt:1699.692\n",
      "Ep:41, loss:0.00008, loss_test:0.12189, lr:8.69e-03, fs:0.64336 (r=0.529,p=0.821),  time:41.495, tt:1742.811\n",
      "Ep:42, loss:0.00008, loss_test:0.12000, lr:8.60e-03, fs:0.64828 (r=0.540,p=0.810),  time:41.512, tt:1785.023\n",
      "Ep:43, loss:0.00007, loss_test:0.11983, lr:8.51e-03, fs:0.65248 (r=0.529,p=0.852),  time:41.537, tt:1827.643\n",
      "Ep:44, loss:0.00007, loss_test:0.11921, lr:8.43e-03, fs:0.65278 (r=0.540,p=0.825),  time:41.533, tt:1868.990\n",
      "Ep:45, loss:0.00007, loss_test:0.12096, lr:8.35e-03, fs:0.66197 (r=0.540,p=0.855),  time:41.564, tt:1911.929\n",
      "Ep:46, loss:0.00006, loss_test:0.12260, lr:8.26e-03, fs:0.66197 (r=0.540,p=0.855),  time:41.623, tt:1956.261\n",
      "Ep:47, loss:0.00006, loss_test:0.11851, lr:8.18e-03, fs:0.63889 (r=0.529,p=0.807),  time:41.634, tt:1998.443\n",
      "Ep:48, loss:0.00006, loss_test:0.12316, lr:8.10e-03, fs:0.66667 (r=0.540,p=0.870),  time:41.687, tt:2042.682\n",
      "Ep:49, loss:0.00006, loss_test:0.11939, lr:8.02e-03, fs:0.65714 (r=0.529,p=0.868),  time:41.700, tt:2084.991\n",
      "Ep:50, loss:0.00006, loss_test:0.11893, lr:7.94e-03, fs:0.65734 (r=0.540,p=0.839),  time:41.720, tt:2127.714\n",
      "Ep:51, loss:0.00005, loss_test:0.12399, lr:7.86e-03, fs:0.65714 (r=0.529,p=0.868),  time:41.769, tt:2171.964\n",
      "Ep:52, loss:0.00005, loss_test:0.12303, lr:7.78e-03, fs:0.65714 (r=0.529,p=0.868),  time:41.769, tt:2213.763\n",
      "Ep:53, loss:0.00005, loss_test:0.11824, lr:7.70e-03, fs:0.66187 (r=0.529,p=0.885),  time:41.697, tt:2251.622\n",
      "Ep:54, loss:0.00005, loss_test:0.12312, lr:7.62e-03, fs:0.66667 (r=0.529,p=0.902),  time:41.703, tt:2293.657\n",
      "Ep:55, loss:0.00005, loss_test:0.11854, lr:7.55e-03, fs:0.64828 (r=0.540,p=0.810),  time:41.738, tt:2337.328\n",
      "Ep:56, loss:0.00005, loss_test:0.12369, lr:7.47e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.747, tt:2379.587\n",
      "Ep:57, loss:0.00005, loss_test:0.11870, lr:7.40e-03, fs:0.66197 (r=0.540,p=0.855),  time:41.791, tt:2423.852\n",
      "Ep:58, loss:0.00004, loss_test:0.12176, lr:7.32e-03, fs:0.67153 (r=0.529,p=0.920),  time:41.803, tt:2466.383\n",
      "Ep:59, loss:0.00004, loss_test:0.11791, lr:7.25e-03, fs:0.64789 (r=0.529,p=0.836),  time:41.809, tt:2508.565\n",
      "Ep:60, loss:0.00004, loss_test:0.12368, lr:7.18e-03, fs:0.67143 (r=0.540,p=0.887),  time:41.839, tt:2552.189\n",
      "Ep:61, loss:0.00004, loss_test:0.11998, lr:7.11e-03, fs:0.66187 (r=0.529,p=0.885),  time:41.868, tt:2595.794\n",
      "Ep:62, loss:0.00004, loss_test:0.12009, lr:7.03e-03, fs:0.66667 (r=0.529,p=0.902),  time:41.857, tt:2636.981\n",
      "Ep:63, loss:0.00004, loss_test:0.12267, lr:6.96e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.840, tt:2677.771\n",
      "Ep:64, loss:0.00004, loss_test:0.11996, lr:6.89e-03, fs:0.67143 (r=0.540,p=0.887),  time:41.831, tt:2719.016\n",
      "Ep:65, loss:0.00004, loss_test:0.12281, lr:6.83e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.866, tt:2763.131\n",
      "Ep:66, loss:0.00004, loss_test:0.12121, lr:6.76e-03, fs:0.67626 (r=0.540,p=0.904),  time:41.890, tt:2806.658\n",
      "Ep:67, loss:0.00003, loss_test:0.12359, lr:6.69e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.919, tt:2850.502\n",
      "Ep:68, loss:0.00003, loss_test:0.11739, lr:6.62e-03, fs:0.66197 (r=0.540,p=0.855),  time:41.936, tt:2893.556\n",
      "Ep:69, loss:0.00003, loss_test:0.12607, lr:6.56e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.949, tt:2936.427\n",
      "Ep:70, loss:0.00003, loss_test:0.11677, lr:6.49e-03, fs:0.66667 (r=0.540,p=0.870),  time:41.982, tt:2980.718\n",
      "Ep:71, loss:0.00003, loss_test:0.12871, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.991, tt:3023.348\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00003, loss_test:0.11792, lr:6.43e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.032, tt:3068.335\n",
      "Ep:73, loss:0.00003, loss_test:0.12688, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.004, tt:3108.273\n",
      "Ep:74, loss:0.00003, loss_test:0.11849, lr:6.43e-03, fs:0.65672 (r=0.506,p=0.936),  time:41.990, tt:3149.270\n",
      "Ep:75, loss:0.00003, loss_test:0.12819, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.027, tt:3194.052\n",
      "Ep:76, loss:0.00003, loss_test:0.11789, lr:6.43e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.024, tt:3235.857\n",
      "Ep:77, loss:0.00003, loss_test:0.13197, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.038, tt:3279.001\n",
      "Ep:78, loss:0.00003, loss_test:0.12089, lr:6.43e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.070, tt:3323.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00003, loss_test:0.13002, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.080, tt:3366.413\n",
      "Ep:80, loss:0.00002, loss_test:0.12727, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.062, tt:3406.988\n",
      "Ep:81, loss:0.00002, loss_test:0.12588, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.049, tt:3448.042\n",
      "Ep:82, loss:0.00002, loss_test:0.12841, lr:6.43e-03, fs:0.69630 (r=0.540,p=0.979),  time:42.054, tt:3490.471\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.12491, lr:6.43e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.059, tt:3532.993\n",
      "Ep:84, loss:0.00002, loss_test:0.12918, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.071, tt:3576.076\n",
      "Ep:85, loss:0.00002, loss_test:0.12530, lr:6.43e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.102, tt:3620.735\n",
      "Ep:86, loss:0.00002, loss_test:0.13139, lr:6.43e-03, fs:0.69630 (r=0.540,p=0.979),  time:42.109, tt:3663.520\n",
      "Ep:87, loss:0.00002, loss_test:0.12130, lr:6.43e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.113, tt:3705.910\n",
      "Ep:88, loss:0.00002, loss_test:0.13561, lr:6.43e-03, fs:0.64615 (r=0.483,p=0.977),  time:42.136, tt:3750.069\n",
      "Ep:89, loss:0.00002, loss_test:0.12291, lr:6.43e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.115, tt:3790.356\n",
      "Ep:90, loss:0.00002, loss_test:0.13023, lr:6.43e-03, fs:0.69630 (r=0.540,p=0.979),  time:42.128, tt:3833.627\n",
      "Ep:91, loss:0.00002, loss_test:0.12618, lr:6.43e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.150, tt:3877.754\n",
      "Ep:92, loss:0.00002, loss_test:0.13043, lr:6.43e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.135, tt:3918.522\n",
      "Ep:93, loss:0.00002, loss_test:0.12483, lr:6.43e-03, fs:0.67647 (r=0.529,p=0.939),  time:42.131, tt:3960.346\n",
      "Ep:94, loss:0.00002, loss_test:0.13378, lr:6.36e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.130, tt:4002.346\n",
      "Ep:95, loss:0.00002, loss_test:0.12724, lr:6.30e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.129, tt:4044.414\n",
      "Ep:96, loss:0.00002, loss_test:0.13228, lr:6.24e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.122, tt:4085.846\n",
      "Ep:97, loss:0.00001, loss_test:0.12994, lr:6.17e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.111, tt:4126.901\n",
      "Ep:98, loss:0.00001, loss_test:0.12923, lr:6.11e-03, fs:0.67647 (r=0.529,p=0.939),  time:42.087, tt:4166.652\n",
      "Ep:99, loss:0.00001, loss_test:0.12878, lr:6.05e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.099, tt:4209.939\n",
      "Ep:100, loss:0.00001, loss_test:0.13217, lr:5.99e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.092, tt:4251.262\n",
      "Ep:101, loss:0.00001, loss_test:0.12671, lr:5.93e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.098, tt:4294.011\n",
      "Ep:102, loss:0.00001, loss_test:0.12477, lr:5.87e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.104, tt:4336.690\n",
      "Ep:103, loss:0.00001, loss_test:0.13655, lr:5.81e-03, fs:0.65649 (r=0.494,p=0.977),  time:42.110, tt:4379.411\n",
      "Ep:104, loss:0.00001, loss_test:0.12864, lr:5.75e-03, fs:0.67647 (r=0.529,p=0.939),  time:42.123, tt:4422.894\n",
      "Ep:105, loss:0.00001, loss_test:0.12755, lr:5.70e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.126, tt:4465.322\n",
      "Ep:106, loss:0.00001, loss_test:0.13170, lr:5.64e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.133, tt:4508.200\n",
      "Ep:107, loss:0.00001, loss_test:0.12899, lr:5.58e-03, fs:0.64662 (r=0.494,p=0.935),  time:42.136, tt:4550.703\n",
      "Ep:108, loss:0.00001, loss_test:0.13347, lr:5.53e-03, fs:0.69630 (r=0.540,p=0.979),  time:42.140, tt:4593.247\n",
      "Ep:109, loss:0.00001, loss_test:0.12935, lr:5.47e-03, fs:0.67647 (r=0.529,p=0.939),  time:42.129, tt:4634.233\n",
      "Ep:110, loss:0.00001, loss_test:0.13352, lr:5.42e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.131, tt:4676.588\n",
      "Ep:111, loss:0.00001, loss_test:0.13026, lr:5.36e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.139, tt:4719.513\n",
      "Ep:112, loss:0.00001, loss_test:0.13378, lr:5.31e-03, fs:0.59200 (r=0.425,p=0.974),  time:42.136, tt:4761.424\n",
      "Ep:113, loss:0.00001, loss_test:0.14049, lr:5.26e-03, fs:0.56911 (r=0.402,p=0.972),  time:42.155, tt:4805.651\n",
      "Ep:114, loss:0.00001, loss_test:0.12557, lr:5.20e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.151, tt:4847.391\n",
      "Ep:115, loss:0.00001, loss_test:0.13698, lr:5.15e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.128, tt:4886.862\n",
      "Ep:116, loss:0.00001, loss_test:0.13287, lr:5.10e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.126, tt:4928.748\n",
      "Ep:117, loss:0.00001, loss_test:0.13176, lr:5.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.118, tt:4969.979\n",
      "Ep:118, loss:0.00001, loss_test:0.13336, lr:5.00e-03, fs:0.69630 (r=0.540,p=0.979),  time:42.114, tt:5011.558\n",
      "Ep:119, loss:0.00001, loss_test:0.13853, lr:4.95e-03, fs:0.55285 (r=0.391,p=0.944),  time:42.113, tt:5053.537\n",
      "Ep:120, loss:0.00001, loss_test:0.12922, lr:4.90e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.104, tt:5094.544\n",
      "Ep:121, loss:0.00001, loss_test:0.13606, lr:4.85e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.120, tt:5138.612\n",
      "Ep:122, loss:0.00001, loss_test:0.13265, lr:4.80e-03, fs:0.59843 (r=0.437,p=0.950),  time:42.121, tt:5180.920\n",
      "Ep:123, loss:0.00001, loss_test:0.13217, lr:4.75e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.135, tt:5224.720\n",
      "Ep:124, loss:0.00001, loss_test:0.13756, lr:4.71e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.138, tt:5267.187\n",
      "Ep:125, loss:0.00001, loss_test:0.13121, lr:4.66e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.130, tt:5308.331\n",
      "Ep:126, loss:0.00001, loss_test:0.13478, lr:4.61e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.122, tt:5349.490\n",
      "Ep:127, loss:0.00001, loss_test:0.13748, lr:4.57e-03, fs:0.56911 (r=0.402,p=0.972),  time:42.119, tt:5391.227\n",
      "Ep:128, loss:0.00001, loss_test:0.12972, lr:4.52e-03, fs:0.60938 (r=0.448,p=0.951),  time:42.103, tt:5431.283\n",
      "Ep:129, loss:0.00001, loss_test:0.13618, lr:4.48e-03, fs:0.62016 (r=0.460,p=0.952),  time:42.107, tt:5473.950\n",
      "Ep:130, loss:0.00001, loss_test:0.13714, lr:4.43e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.101, tt:5515.268\n",
      "Ep:131, loss:0.00001, loss_test:0.13063, lr:4.39e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.109, tt:5558.388\n",
      "Ep:132, loss:0.00001, loss_test:0.13836, lr:4.34e-03, fs:0.56911 (r=0.402,p=0.972),  time:42.092, tt:5598.247\n",
      "Ep:133, loss:0.00001, loss_test:0.13508, lr:4.30e-03, fs:0.58730 (r=0.425,p=0.949),  time:42.095, tt:5640.687\n",
      "Ep:134, loss:0.00001, loss_test:0.13279, lr:4.26e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.088, tt:5681.917\n",
      "Ep:135, loss:0.00001, loss_test:0.13760, lr:4.21e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.079, tt:5722.748\n",
      "Ep:136, loss:0.00001, loss_test:0.13335, lr:4.17e-03, fs:0.59843 (r=0.437,p=0.950),  time:42.098, tt:5767.387\n",
      "Ep:137, loss:0.00001, loss_test:0.13377, lr:4.13e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.110, tt:5811.214\n",
      "Ep:138, loss:0.00001, loss_test:0.13735, lr:4.09e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.103, tt:5852.326\n",
      "Ep:139, loss:0.00001, loss_test:0.13332, lr:4.05e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.104, tt:5894.529\n",
      "Ep:140, loss:0.00001, loss_test:0.13589, lr:4.01e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.121, tt:5939.057\n",
      "Ep:141, loss:0.00001, loss_test:0.14141, lr:3.97e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.131, tt:5982.577\n",
      "Ep:142, loss:0.00001, loss_test:0.13385, lr:3.93e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.143, tt:6026.470\n",
      "Ep:143, loss:0.00001, loss_test:0.13544, lr:3.89e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.149, tt:6069.505\n",
      "Ep:144, loss:0.00001, loss_test:0.13786, lr:3.85e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.125, tt:6108.096\n",
      "Ep:145, loss:0.00001, loss_test:0.13397, lr:3.81e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.127, tt:6150.590\n",
      "Ep:146, loss:0.00001, loss_test:0.13550, lr:3.77e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.127, tt:6192.705\n",
      "Ep:147, loss:0.00001, loss_test:0.13700, lr:3.73e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.130, tt:6235.224\n",
      "Ep:148, loss:0.00001, loss_test:0.13382, lr:3.70e-03, fs:0.58730 (r=0.425,p=0.949),  time:42.162, tt:6282.071\n",
      "Ep:149, loss:0.00000, loss_test:0.13455, lr:3.66e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.168, tt:6325.161\n",
      "Ep:150, loss:0.00000, loss_test:0.13668, lr:3.62e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.162, tt:6366.473\n",
      "Ep:151, loss:0.00000, loss_test:0.13513, lr:3.59e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.160, tt:6408.383\n",
      "Ep:152, loss:0.00000, loss_test:0.13622, lr:3.55e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.160, tt:6450.550\n",
      "Ep:153, loss:0.00000, loss_test:0.14074, lr:3.52e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.159, tt:6492.555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00000, loss_test:0.13456, lr:3.48e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.148, tt:6532.899\n",
      "Ep:155, loss:0.00000, loss_test:0.13562, lr:3.45e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.144, tt:6574.442\n",
      "Ep:156, loss:0.00000, loss_test:0.13709, lr:3.41e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.134, tt:6615.009\n",
      "Ep:157, loss:0.00000, loss_test:0.13657, lr:3.38e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.130, tt:6656.564\n",
      "Ep:158, loss:0.00000, loss_test:0.13678, lr:3.34e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.128, tt:6698.345\n",
      "Ep:159, loss:0.00000, loss_test:0.13644, lr:3.31e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.126, tt:6740.207\n",
      "Ep:160, loss:0.00000, loss_test:0.13448, lr:3.28e-03, fs:0.58730 (r=0.425,p=0.949),  time:42.132, tt:6783.182\n",
      "Ep:161, loss:0.00000, loss_test:0.13625, lr:3.24e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.118, tt:6823.133\n",
      "Ep:162, loss:0.00000, loss_test:0.13885, lr:3.21e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.111, tt:6864.048\n",
      "Ep:163, loss:0.00000, loss_test:0.13420, lr:3.18e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.109, tt:6905.836\n",
      "Ep:164, loss:0.00000, loss_test:0.13632, lr:3.15e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.085, tt:6944.011\n",
      "Ep:165, loss:0.00000, loss_test:0.13885, lr:3.12e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.073, tt:6984.163\n",
      "Ep:166, loss:0.00000, loss_test:0.13435, lr:3.09e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.078, tt:7026.990\n",
      "Ep:167, loss:0.00000, loss_test:0.13605, lr:3.05e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.079, tt:7069.236\n",
      "Ep:168, loss:0.00000, loss_test:0.13677, lr:3.02e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.112, tt:7116.988\n",
      "Ep:169, loss:0.00000, loss_test:0.13680, lr:2.99e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.121, tt:7160.610\n",
      "Ep:170, loss:0.00000, loss_test:0.13702, lr:2.96e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.115, tt:7201.593\n",
      "Ep:171, loss:0.00000, loss_test:0.13635, lr:2.93e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.103, tt:7241.675\n",
      "Ep:172, loss:0.00000, loss_test:0.13644, lr:2.90e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.085, tt:7280.669\n",
      "Ep:173, loss:0.00000, loss_test:0.13555, lr:2.88e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.082, tt:7322.240\n",
      "Ep:174, loss:0.00000, loss_test:0.13933, lr:2.85e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.076, tt:7363.387\n",
      "Ep:175, loss:0.00000, loss_test:0.13644, lr:2.82e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.069, tt:7404.065\n",
      "Ep:176, loss:0.00000, loss_test:0.13437, lr:2.79e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.052, tt:7443.249\n",
      "Ep:177, loss:0.00000, loss_test:0.13804, lr:2.76e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.054, tt:7485.560\n",
      "Ep:178, loss:0.00000, loss_test:0.13650, lr:2.73e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.046, tt:7526.162\n",
      "Ep:179, loss:0.00000, loss_test:0.13670, lr:2.71e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.048, tt:7568.582\n",
      "Ep:180, loss:0.00000, loss_test:0.13624, lr:2.68e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.051, tt:7611.193\n",
      "Ep:181, loss:0.00000, loss_test:0.13626, lr:2.65e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.043, tt:7651.847\n",
      "Ep:182, loss:0.00000, loss_test:0.13534, lr:2.63e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.031, tt:7691.646\n",
      "Ep:183, loss:0.00000, loss_test:0.13669, lr:2.60e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.025, tt:7732.660\n",
      "Ep:184, loss:0.00000, loss_test:0.13663, lr:2.57e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.013, tt:7772.437\n",
      "Ep:185, loss:0.00000, loss_test:0.13549, lr:2.55e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.992, tt:7810.543\n",
      "Ep:186, loss:0.00000, loss_test:0.13618, lr:2.52e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.984, tt:7850.941\n",
      "Ep:187, loss:0.00000, loss_test:0.13650, lr:2.50e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.984, tt:7893.053\n",
      "Ep:188, loss:0.00000, loss_test:0.13470, lr:2.47e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.991, tt:7936.269\n",
      "Ep:189, loss:0.00000, loss_test:0.13697, lr:2.45e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.979, tt:7975.975\n",
      "Ep:190, loss:0.00000, loss_test:0.13635, lr:2.42e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.972, tt:8016.677\n",
      "Ep:191, loss:0.00000, loss_test:0.13518, lr:2.40e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.960, tt:8056.324\n",
      "Ep:192, loss:0.00000, loss_test:0.13724, lr:2.38e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.959, tt:8098.126\n",
      "Ep:193, loss:0.00000, loss_test:0.13699, lr:2.35e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.952, tt:8138.684\n",
      "Ep:194, loss:0.00000, loss_test:0.13578, lr:2.33e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.948, tt:8179.767\n",
      "Ep:195, loss:0.00000, loss_test:0.13660, lr:2.31e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.939, tt:8219.969\n",
      "Ep:196, loss:0.00000, loss_test:0.13693, lr:2.28e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.932, tt:8260.609\n",
      "Ep:197, loss:0.00000, loss_test:0.13626, lr:2.26e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.935, tt:8303.045\n",
      "Ep:198, loss:0.00000, loss_test:0.13612, lr:2.24e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.943, tt:8346.560\n",
      "Ep:199, loss:0.00000, loss_test:0.13677, lr:2.21e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.940, tt:8387.999\n",
      "Ep:200, loss:0.00000, loss_test:0.13707, lr:2.19e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.928, tt:8427.518\n",
      "Ep:201, loss:0.00000, loss_test:0.13626, lr:2.17e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.924, tt:8468.625\n",
      "Ep:202, loss:0.00000, loss_test:0.13629, lr:2.15e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.921, tt:8509.917\n",
      "Ep:203, loss:0.00000, loss_test:0.13628, lr:2.13e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.918, tt:8551.211\n",
      "Ep:204, loss:0.00000, loss_test:0.13631, lr:2.11e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.924, tt:8594.411\n",
      "Ep:205, loss:0.00000, loss_test:0.13610, lr:2.08e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.925, tt:8636.499\n",
      "Ep:206, loss:0.00000, loss_test:0.13684, lr:2.06e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.925, tt:8678.392\n",
      "Ep:207, loss:0.00000, loss_test:0.13677, lr:2.04e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.926, tt:8720.675\n",
      "Ep:208, loss:0.00000, loss_test:0.13615, lr:2.02e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.948, tt:8767.210\n",
      "Ep:209, loss:0.00000, loss_test:0.13624, lr:2.00e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.953, tt:8810.208\n",
      "Ep:210, loss:0.00000, loss_test:0.13734, lr:1.98e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.954, tt:8852.344\n",
      "Ep:211, loss:0.00000, loss_test:0.13708, lr:1.96e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.948, tt:8892.931\n",
      "Ep:212, loss:0.00000, loss_test:0.13586, lr:1.94e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.927, tt:8930.487\n",
      "Ep:213, loss:0.00000, loss_test:0.13631, lr:1.92e-03, fs:0.56452 (r=0.402,p=0.946),  time:41.869, tt:8960.034\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02288, lr:6.00e-02, fs:0.57143 (r=0.667,p=0.500),  time:32.830, tt:32.830\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:33.499, tt:66.998\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02242, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:34.062, tt:102.186\n",
      "Ep:3, loss:0.00004, loss_test:0.02166, lr:6.00e-02, fs:0.66135 (r=0.954,p=0.506),  time:35.021, tt:140.086\n",
      "Ep:4, loss:0.00004, loss_test:0.02169, lr:6.00e-02, fs:0.64840 (r=0.816,p=0.538),  time:36.065, tt:180.326\n",
      "Ep:5, loss:0.00004, loss_test:0.02288, lr:6.00e-02, fs:0.60302 (r=0.690,p=0.536),  time:36.748, tt:220.485\n",
      "Ep:6, loss:0.00004, loss_test:0.02366, lr:6.00e-02, fs:0.60541 (r=0.644,p=0.571),  time:37.320, tt:261.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00004, loss_test:0.02273, lr:6.00e-02, fs:0.61702 (r=0.667,p=0.574),  time:37.785, tt:302.276\n",
      "Ep:8, loss:0.00003, loss_test:0.02140, lr:6.00e-02, fs:0.62564 (r=0.701,p=0.565),  time:37.997, tt:341.975\n",
      "Ep:9, loss:0.00003, loss_test:0.02057, lr:6.00e-02, fs:0.66019 (r=0.782,p=0.571),  time:38.119, tt:381.194\n",
      "Ep:10, loss:0.00003, loss_test:0.02023, lr:6.00e-02, fs:0.67308 (r=0.805,p=0.579),  time:38.465, tt:423.117\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.02022, lr:6.00e-02, fs:0.66337 (r=0.770,p=0.583),  time:38.728, tt:464.738\n",
      "Ep:12, loss:0.00003, loss_test:0.02044, lr:6.00e-02, fs:0.64948 (r=0.724,p=0.589),  time:38.989, tt:506.857\n",
      "Ep:13, loss:0.00003, loss_test:0.02058, lr:6.00e-02, fs:0.66316 (r=0.724,p=0.612),  time:39.310, tt:550.337\n",
      "Ep:14, loss:0.00003, loss_test:0.02041, lr:6.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:39.666, tt:594.983\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.02006, lr:6.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:39.800, tt:636.794\n",
      "Ep:16, loss:0.00003, loss_test:0.01980, lr:6.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:39.917, tt:678.589\n",
      "Ep:17, loss:0.00003, loss_test:0.01965, lr:6.00e-02, fs:0.68085 (r=0.736,p=0.634),  time:39.943, tt:718.969\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01971, lr:6.00e-02, fs:0.65574 (r=0.690,p=0.625),  time:39.952, tt:759.088\n",
      "Ep:19, loss:0.00003, loss_test:0.01971, lr:6.00e-02, fs:0.63277 (r=0.644,p=0.622),  time:40.020, tt:800.404\n",
      "Ep:20, loss:0.00003, loss_test:0.01960, lr:6.00e-02, fs:0.62857 (r=0.632,p=0.625),  time:40.114, tt:842.391\n",
      "Ep:21, loss:0.00002, loss_test:0.01951, lr:6.00e-02, fs:0.62857 (r=0.632,p=0.625),  time:40.287, tt:886.325\n",
      "Ep:22, loss:0.00002, loss_test:0.01943, lr:6.00e-02, fs:0.63584 (r=0.632,p=0.640),  time:40.477, tt:930.961\n",
      "Ep:23, loss:0.00002, loss_test:0.01933, lr:6.00e-02, fs:0.64368 (r=0.644,p=0.644),  time:40.490, tt:971.757\n",
      "Ep:24, loss:0.00002, loss_test:0.01934, lr:6.00e-02, fs:0.64368 (r=0.644,p=0.644),  time:40.489, tt:1012.236\n",
      "Ep:25, loss:0.00002, loss_test:0.01941, lr:6.00e-02, fs:0.62353 (r=0.609,p=0.639),  time:40.555, tt:1054.442\n",
      "Ep:26, loss:0.00002, loss_test:0.01947, lr:6.00e-02, fs:0.63473 (r=0.609,p=0.662),  time:40.610, tt:1096.473\n",
      "Ep:27, loss:0.00002, loss_test:0.01948, lr:6.00e-02, fs:0.64242 (r=0.609,p=0.679),  time:40.705, tt:1139.728\n",
      "Ep:28, loss:0.00002, loss_test:0.01948, lr:6.00e-02, fs:0.64242 (r=0.609,p=0.679),  time:40.839, tt:1184.319\n",
      "Ep:29, loss:0.00002, loss_test:0.01957, lr:5.94e-02, fs:0.64242 (r=0.609,p=0.679),  time:40.912, tt:1227.363\n",
      "Ep:30, loss:0.00002, loss_test:0.01970, lr:5.88e-02, fs:0.64634 (r=0.609,p=0.688),  time:40.943, tt:1269.220\n",
      "Ep:31, loss:0.00002, loss_test:0.01979, lr:5.82e-02, fs:0.65031 (r=0.609,p=0.697),  time:40.930, tt:1309.745\n",
      "Ep:32, loss:0.00002, loss_test:0.01997, lr:5.76e-02, fs:0.65432 (r=0.609,p=0.707),  time:40.968, tt:1351.960\n",
      "Ep:33, loss:0.00002, loss_test:0.02003, lr:5.71e-02, fs:0.65432 (r=0.609,p=0.707),  time:40.962, tt:1392.691\n",
      "Ep:34, loss:0.00002, loss_test:0.02011, lr:5.65e-02, fs:0.65031 (r=0.609,p=0.697),  time:41.004, tt:1435.146\n",
      "Ep:35, loss:0.00002, loss_test:0.02035, lr:5.59e-02, fs:0.65432 (r=0.609,p=0.707),  time:40.993, tt:1475.766\n",
      "Ep:36, loss:0.00002, loss_test:0.02044, lr:5.54e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.008, tt:1517.293\n",
      "Ep:37, loss:0.00002, loss_test:0.02054, lr:5.48e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.074, tt:1560.819\n",
      "Ep:38, loss:0.00002, loss_test:0.02061, lr:5.43e-02, fs:0.65432 (r=0.609,p=0.707),  time:41.147, tt:1604.730\n",
      "Ep:39, loss:0.00002, loss_test:0.02072, lr:5.37e-02, fs:0.65432 (r=0.609,p=0.707),  time:41.186, tt:1647.421\n",
      "Ep:40, loss:0.00002, loss_test:0.02089, lr:5.32e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.241, tt:1690.896\n",
      "Ep:41, loss:0.00002, loss_test:0.02104, lr:5.27e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.300, tt:1734.605\n",
      "Ep:42, loss:0.00002, loss_test:0.02118, lr:5.21e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.298, tt:1775.831\n",
      "Ep:43, loss:0.00002, loss_test:0.02116, lr:5.16e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.268, tt:1815.802\n",
      "Ep:44, loss:0.00002, loss_test:0.02132, lr:5.11e-02, fs:0.65839 (r=0.609,p=0.716),  time:41.289, tt:1858.008\n",
      "Ep:45, loss:0.00001, loss_test:0.02148, lr:5.06e-02, fs:0.66250 (r=0.609,p=0.726),  time:41.280, tt:1898.879\n",
      "Ep:46, loss:0.00001, loss_test:0.02167, lr:5.01e-02, fs:0.66250 (r=0.609,p=0.726),  time:41.291, tt:1940.694\n",
      "Ep:47, loss:0.00001, loss_test:0.02177, lr:4.96e-02, fs:0.66250 (r=0.609,p=0.726),  time:41.275, tt:1981.201\n",
      "Ep:48, loss:0.00001, loss_test:0.02199, lr:4.91e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.317, tt:2024.532\n",
      "Ep:49, loss:0.00001, loss_test:0.02205, lr:4.86e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.333, tt:2066.675\n",
      "Ep:50, loss:0.00001, loss_test:0.02223, lr:4.81e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.361, tt:2109.407\n",
      "Ep:51, loss:0.00001, loss_test:0.02221, lr:4.76e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.358, tt:2150.641\n",
      "Ep:52, loss:0.00001, loss_test:0.02237, lr:4.71e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.343, tt:2191.184\n",
      "Ep:53, loss:0.00001, loss_test:0.02260, lr:4.67e-02, fs:0.66242 (r=0.598,p=0.743),  time:41.348, tt:2232.788\n",
      "Ep:54, loss:0.00001, loss_test:0.02273, lr:4.62e-02, fs:0.66242 (r=0.598,p=0.743),  time:41.295, tt:2271.223\n",
      "Ep:55, loss:0.00001, loss_test:0.02279, lr:4.57e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.324, tt:2314.141\n",
      "Ep:56, loss:0.00001, loss_test:0.02299, lr:4.53e-02, fs:0.65823 (r=0.598,p=0.732),  time:41.332, tt:2355.897\n",
      "Ep:57, loss:0.00001, loss_test:0.02310, lr:4.48e-02, fs:0.65823 (r=0.598,p=0.732),  time:41.366, tt:2399.204\n",
      "Ep:58, loss:0.00001, loss_test:0.02322, lr:4.44e-02, fs:0.65823 (r=0.598,p=0.732),  time:41.384, tt:2441.682\n",
      "Ep:59, loss:0.00001, loss_test:0.02329, lr:4.39e-02, fs:0.65823 (r=0.598,p=0.732),  time:41.412, tt:2484.710\n",
      "Ep:60, loss:0.00001, loss_test:0.02351, lr:4.35e-02, fs:0.66242 (r=0.598,p=0.743),  time:41.422, tt:2526.740\n",
      "Ep:61, loss:0.00001, loss_test:0.02357, lr:4.31e-02, fs:0.66242 (r=0.598,p=0.743),  time:41.421, tt:2568.073\n",
      "Ep:62, loss:0.00001, loss_test:0.02369, lr:4.26e-02, fs:0.66242 (r=0.598,p=0.743),  time:41.466, tt:2612.361\n",
      "Ep:63, loss:0.00001, loss_test:0.02396, lr:4.22e-02, fs:0.65385 (r=0.586,p=0.739),  time:41.493, tt:2655.576\n",
      "Ep:64, loss:0.00001, loss_test:0.02420, lr:4.18e-02, fs:0.65806 (r=0.586,p=0.750),  time:41.490, tt:2696.837\n",
      "Ep:65, loss:0.00001, loss_test:0.02420, lr:4.14e-02, fs:0.64935 (r=0.575,p=0.746),  time:41.486, tt:2738.043\n",
      "Ep:66, loss:0.00001, loss_test:0.02426, lr:4.10e-02, fs:0.64935 (r=0.575,p=0.746),  time:41.499, tt:2780.404\n",
      "Ep:67, loss:0.00001, loss_test:0.02442, lr:4.05e-02, fs:0.64935 (r=0.575,p=0.746),  time:41.480, tt:2820.612\n",
      "Ep:68, loss:0.00001, loss_test:0.02440, lr:4.01e-02, fs:0.65789 (r=0.575,p=0.769),  time:41.485, tt:2862.484\n",
      "Ep:69, loss:0.00001, loss_test:0.02457, lr:3.97e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.459, tt:2902.128\n",
      "Ep:70, loss:0.00001, loss_test:0.02472, lr:3.93e-02, fs:0.65789 (r=0.575,p=0.769),  time:41.483, tt:2945.259\n",
      "Ep:71, loss:0.00001, loss_test:0.02483, lr:3.89e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.490, tt:2987.295\n",
      "Ep:72, loss:0.00001, loss_test:0.02484, lr:3.86e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.514, tt:3030.550\n",
      "Ep:73, loss:0.00001, loss_test:0.02497, lr:3.82e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.527, tt:3072.969\n",
      "Ep:74, loss:0.00001, loss_test:0.02513, lr:3.78e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.539, tt:3115.396\n",
      "Ep:75, loss:0.00001, loss_test:0.02520, lr:3.74e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.534, tt:3156.607\n",
      "Ep:76, loss:0.00001, loss_test:0.02519, lr:3.70e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.548, tt:3199.178\n",
      "Ep:77, loss:0.00001, loss_test:0.02544, lr:3.67e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.531, tt:3239.411\n",
      "Ep:78, loss:0.00001, loss_test:0.02543, lr:3.63e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.528, tt:3280.724\n",
      "Ep:79, loss:0.00001, loss_test:0.02551, lr:3.59e-02, fs:0.66225 (r=0.575,p=0.781),  time:41.535, tt:3322.762\n",
      "Ep:80, loss:0.00001, loss_test:0.02564, lr:3.56e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.537, tt:3364.532\n",
      "Ep:81, loss:0.00001, loss_test:0.02583, lr:3.52e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.541, tt:3406.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:82, loss:0.00001, loss_test:0.02574, lr:3.49e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.535, tt:3447.370\n",
      "Ep:83, loss:0.00001, loss_test:0.02586, lr:3.45e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.554, tt:3490.566\n",
      "Ep:84, loss:0.00001, loss_test:0.02603, lr:3.42e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.562, tt:3532.733\n",
      "Ep:85, loss:0.00001, loss_test:0.02602, lr:3.38e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.568, tt:3574.864\n",
      "Ep:86, loss:0.00001, loss_test:0.02617, lr:3.35e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.573, tt:3616.815\n",
      "Ep:87, loss:0.00001, loss_test:0.02634, lr:3.32e-02, fs:0.65333 (r=0.563,p=0.778),  time:41.578, tt:3658.898\n",
      "Ep:88, loss:0.00001, loss_test:0.02642, lr:3.28e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.592, tt:3701.672\n",
      "Ep:89, loss:0.00001, loss_test:0.02639, lr:3.25e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.615, tt:3745.310\n",
      "Ep:90, loss:0.00001, loss_test:0.02649, lr:3.22e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.610, tt:3786.501\n",
      "Ep:91, loss:0.00001, loss_test:0.02664, lr:3.19e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.616, tt:3828.688\n",
      "Ep:92, loss:0.00001, loss_test:0.02656, lr:3.15e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.617, tt:3870.363\n",
      "Ep:93, loss:0.00001, loss_test:0.02667, lr:3.12e-02, fs:0.65772 (r=0.563,p=0.790),  time:41.590, tt:3909.489\n",
      "Ep:94, loss:0.00001, loss_test:0.02685, lr:3.09e-02, fs:0.65306 (r=0.552,p=0.800),  time:41.580, tt:3950.097\n",
      "Ep:95, loss:0.00001, loss_test:0.02694, lr:3.06e-02, fs:0.64384 (r=0.540,p=0.797),  time:41.551, tt:3988.929\n",
      "Ep:96, loss:0.00001, loss_test:0.02704, lr:3.03e-02, fs:0.63448 (r=0.529,p=0.793),  time:41.545, tt:4029.903\n",
      "Ep:97, loss:0.00001, loss_test:0.02706, lr:3.00e-02, fs:0.63889 (r=0.529,p=0.807),  time:41.539, tt:4070.777\n",
      "Ep:98, loss:0.00001, loss_test:0.02713, lr:2.97e-02, fs:0.63889 (r=0.529,p=0.807),  time:41.532, tt:4111.644\n",
      "Ep:99, loss:0.00001, loss_test:0.02722, lr:2.94e-02, fs:0.63889 (r=0.529,p=0.807),  time:41.510, tt:4151.047\n",
      "Ep:100, loss:0.00001, loss_test:0.02726, lr:2.91e-02, fs:0.64336 (r=0.529,p=0.821),  time:41.542, tt:4195.745\n",
      "Ep:101, loss:0.00001, loss_test:0.02731, lr:2.88e-02, fs:0.64336 (r=0.529,p=0.821),  time:41.554, tt:4238.460\n",
      "Ep:102, loss:0.00001, loss_test:0.02739, lr:2.85e-02, fs:0.64336 (r=0.529,p=0.821),  time:41.578, tt:4282.503\n",
      "Ep:103, loss:0.00001, loss_test:0.02747, lr:2.82e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.587, tt:4325.027\n",
      "Ep:104, loss:0.00001, loss_test:0.02759, lr:2.80e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.595, tt:4367.502\n",
      "Ep:105, loss:0.00001, loss_test:0.02769, lr:2.77e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.597, tt:4409.252\n",
      "Ep:106, loss:0.00001, loss_test:0.02767, lr:2.74e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.582, tt:4449.319\n",
      "Ep:107, loss:0.00001, loss_test:0.02775, lr:2.71e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.595, tt:4492.216\n",
      "Ep:108, loss:0.00001, loss_test:0.02784, lr:2.69e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.580, tt:4532.228\n",
      "Ep:109, loss:0.00001, loss_test:0.02791, lr:2.66e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.583, tt:4574.148\n",
      "Ep:110, loss:0.00001, loss_test:0.02787, lr:2.63e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.579, tt:4615.258\n",
      "Ep:111, loss:0.00001, loss_test:0.02804, lr:2.61e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.580, tt:4656.955\n",
      "Ep:112, loss:0.00001, loss_test:0.02820, lr:2.58e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.563, tt:4696.570\n",
      "Ep:113, loss:0.00001, loss_test:0.02820, lr:2.55e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.563, tt:4738.193\n",
      "Ep:114, loss:0.00001, loss_test:0.02825, lr:2.53e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.564, tt:4779.884\n",
      "Ep:115, loss:0.00001, loss_test:0.02832, lr:2.50e-02, fs:0.64789 (r=0.529,p=0.836),  time:41.572, tt:4822.387\n",
      "Ep:116, loss:0.00001, loss_test:0.02851, lr:2.48e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.571, tt:4863.802\n",
      "Ep:117, loss:0.00001, loss_test:0.02837, lr:2.45e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.563, tt:4904.485\n",
      "Ep:118, loss:0.00001, loss_test:0.02841, lr:2.43e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.536, tt:4942.763\n",
      "Ep:119, loss:0.00001, loss_test:0.02856, lr:2.40e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.525, tt:4982.992\n",
      "Ep:120, loss:0.00001, loss_test:0.02852, lr:2.38e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.547, tt:5027.167\n",
      "Ep:121, loss:0.00001, loss_test:0.02850, lr:2.36e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.549, tt:5068.997\n",
      "Ep:122, loss:0.00001, loss_test:0.02870, lr:2.33e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.537, tt:5109.016\n",
      "Ep:123, loss:0.00001, loss_test:0.02890, lr:2.31e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.520, tt:5148.443\n",
      "Ep:124, loss:0.00001, loss_test:0.02870, lr:2.29e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.517, tt:5189.630\n",
      "Ep:125, loss:0.00001, loss_test:0.02876, lr:2.26e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.519, tt:5231.332\n",
      "Ep:126, loss:0.00001, loss_test:0.02896, lr:2.24e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.514, tt:5272.268\n",
      "Ep:127, loss:0.00001, loss_test:0.02897, lr:2.22e-02, fs:0.65248 (r=0.529,p=0.852),  time:41.500, tt:5311.983\n",
      "Ep:128, loss:0.00001, loss_test:0.02894, lr:2.20e-02, fs:0.64286 (r=0.517,p=0.849),  time:41.491, tt:5352.374\n",
      "Ep:129, loss:0.00001, loss_test:0.02895, lr:2.17e-02, fs:0.64286 (r=0.517,p=0.849),  time:41.479, tt:5392.313\n",
      "Ep:130, loss:0.00001, loss_test:0.02910, lr:2.15e-02, fs:0.64286 (r=0.517,p=0.849),  time:41.472, tt:5432.848\n",
      "Ep:131, loss:0.00001, loss_test:0.02912, lr:2.13e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.469, tt:5473.883\n",
      "Ep:132, loss:0.00001, loss_test:0.02913, lr:2.11e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.468, tt:5515.229\n",
      "Ep:133, loss:0.00001, loss_test:0.02920, lr:2.09e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.460, tt:5555.679\n",
      "Ep:134, loss:0.00001, loss_test:0.02942, lr:2.07e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.465, tt:5597.787\n",
      "Ep:135, loss:0.00001, loss_test:0.02940, lr:2.05e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.463, tt:5638.938\n",
      "Ep:136, loss:0.00001, loss_test:0.02938, lr:2.03e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.477, tt:5682.346\n",
      "Ep:137, loss:0.00001, loss_test:0.02943, lr:2.01e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.483, tt:5724.693\n",
      "Ep:138, loss:0.00001, loss_test:0.02952, lr:1.99e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.467, tt:5763.916\n",
      "Ep:139, loss:0.00001, loss_test:0.02962, lr:1.97e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.468, tt:5805.472\n",
      "Ep:140, loss:0.00001, loss_test:0.02958, lr:1.95e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.469, tt:5847.076\n",
      "Ep:141, loss:0.00001, loss_test:0.02971, lr:1.93e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.475, tt:5889.387\n",
      "Ep:142, loss:0.00001, loss_test:0.02968, lr:1.91e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.469, tt:5930.029\n",
      "Ep:143, loss:0.00001, loss_test:0.02973, lr:1.89e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.480, tt:5973.152\n",
      "Ep:144, loss:0.00001, loss_test:0.02979, lr:1.87e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.481, tt:6014.731\n",
      "Ep:145, loss:0.00001, loss_test:0.02978, lr:1.85e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.481, tt:6056.293\n",
      "Ep:146, loss:0.00001, loss_test:0.02987, lr:1.83e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.496, tt:6099.956\n",
      "Ep:147, loss:0.00001, loss_test:0.02996, lr:1.81e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.504, tt:6142.659\n",
      "Ep:148, loss:0.00001, loss_test:0.02999, lr:1.80e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.516, tt:6185.901\n",
      "Ep:149, loss:0.00001, loss_test:0.03003, lr:1.78e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.519, tt:6227.902\n",
      "Ep:150, loss:0.00001, loss_test:0.03009, lr:1.76e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.530, tt:6271.089\n",
      "Ep:151, loss:0.00001, loss_test:0.03009, lr:1.74e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.548, tt:6315.261\n",
      "Ep:152, loss:0.00001, loss_test:0.03011, lr:1.73e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.550, tt:6357.172\n",
      "Ep:153, loss:0.00000, loss_test:0.03018, lr:1.71e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.552, tt:6399.074\n",
      "Ep:154, loss:0.00000, loss_test:0.03026, lr:1.69e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.555, tt:6441.068\n",
      "Ep:155, loss:0.00000, loss_test:0.03025, lr:1.67e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.560, tt:6483.358\n",
      "Ep:156, loss:0.00000, loss_test:0.03026, lr:1.66e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.569, tt:6526.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:157, loss:0.00000, loss_test:0.03038, lr:1.64e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.577, tt:6569.183\n",
      "Ep:158, loss:0.00000, loss_test:0.03039, lr:1.62e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.591, tt:6612.935\n",
      "Ep:159, loss:0.00000, loss_test:0.03043, lr:1.61e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.606, tt:6656.985\n",
      "Ep:160, loss:0.00000, loss_test:0.03045, lr:1.59e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.623, tt:6701.267\n",
      "Ep:161, loss:0.00000, loss_test:0.03048, lr:1.58e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.641, tt:6745.813\n",
      "Ep:162, loss:0.00000, loss_test:0.03052, lr:1.56e-02, fs:0.63309 (r=0.506,p=0.846),  time:41.654, tt:6789.533\n",
      "Ep:163, loss:0.00000, loss_test:0.03055, lr:1.54e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.673, tt:6834.408\n",
      "Ep:164, loss:0.00000, loss_test:0.03064, lr:1.53e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.694, tt:6879.551\n",
      "Ep:165, loss:0.00000, loss_test:0.03061, lr:1.51e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.712, tt:6924.254\n",
      "Ep:166, loss:0.00000, loss_test:0.03063, lr:1.50e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.718, tt:6966.942\n",
      "Ep:167, loss:0.00000, loss_test:0.03070, lr:1.48e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.729, tt:7010.396\n",
      "Ep:168, loss:0.00000, loss_test:0.03073, lr:1.47e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.748, tt:7055.472\n",
      "Ep:169, loss:0.00000, loss_test:0.03072, lr:1.45e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.759, tt:7099.087\n",
      "Ep:170, loss:0.00000, loss_test:0.03079, lr:1.44e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.780, tt:7144.463\n",
      "Ep:171, loss:0.00000, loss_test:0.03088, lr:1.43e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.768, tt:7184.121\n",
      "Ep:172, loss:0.00000, loss_test:0.03090, lr:1.41e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.778, tt:7227.509\n",
      "Ep:173, loss:0.00000, loss_test:0.03090, lr:1.40e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.779, tt:7269.565\n",
      "Ep:174, loss:0.00000, loss_test:0.03092, lr:1.38e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.793, tt:7313.793\n",
      "Ep:175, loss:0.00000, loss_test:0.03093, lr:1.37e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.796, tt:7356.177\n",
      "Ep:176, loss:0.00000, loss_test:0.03097, lr:1.36e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.794, tt:7397.471\n",
      "Ep:177, loss:0.00000, loss_test:0.03103, lr:1.34e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.793, tt:7439.241\n",
      "Ep:178, loss:0.00000, loss_test:0.03110, lr:1.33e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.784, tt:7479.329\n",
      "Ep:179, loss:0.00000, loss_test:0.03114, lr:1.32e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.787, tt:7521.596\n",
      "Ep:180, loss:0.00000, loss_test:0.03110, lr:1.30e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.778, tt:7561.872\n",
      "Ep:181, loss:0.00000, loss_test:0.03106, lr:1.29e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.785, tt:7604.806\n",
      "Ep:182, loss:0.00000, loss_test:0.03110, lr:1.28e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.800, tt:7649.432\n",
      "Ep:183, loss:0.00000, loss_test:0.03121, lr:1.26e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.803, tt:7691.758\n",
      "Ep:184, loss:0.00000, loss_test:0.03120, lr:1.25e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.803, tt:7733.637\n",
      "Ep:185, loss:0.00000, loss_test:0.03121, lr:1.24e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.791, tt:7773.161\n",
      "Ep:186, loss:0.00000, loss_test:0.03121, lr:1.23e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.774, tt:7811.796\n",
      "Ep:187, loss:0.00000, loss_test:0.03126, lr:1.21e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.768, tt:7852.331\n",
      "Ep:188, loss:0.00000, loss_test:0.03132, lr:1.20e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.760, tt:7892.553\n",
      "Ep:189, loss:0.00000, loss_test:0.03132, lr:1.19e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.756, tt:7933.623\n",
      "Ep:190, loss:0.00000, loss_test:0.03127, lr:1.18e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.753, tt:7974.862\n",
      "Ep:191, loss:0.00000, loss_test:0.03135, lr:1.17e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.742, tt:8014.421\n",
      "Ep:192, loss:0.00000, loss_test:0.03142, lr:1.15e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.752, tt:8058.120\n",
      "Ep:193, loss:0.00000, loss_test:0.03146, lr:1.14e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.747, tt:8098.859\n",
      "Ep:194, loss:0.00000, loss_test:0.03140, lr:1.13e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.747, tt:8140.650\n",
      "Ep:195, loss:0.00000, loss_test:0.03144, lr:1.12e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.735, tt:8180.069\n",
      "Ep:196, loss:0.00000, loss_test:0.03154, lr:1.11e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.723, tt:8219.343\n",
      "Ep:197, loss:0.00000, loss_test:0.03158, lr:1.10e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.715, tt:8259.645\n",
      "Ep:198, loss:0.00000, loss_test:0.03155, lr:1.09e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.711, tt:8300.449\n",
      "Ep:199, loss:0.00000, loss_test:0.03154, lr:1.08e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.697, tt:8339.488\n",
      "Ep:200, loss:0.00000, loss_test:0.03159, lr:1.07e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.683, tt:8378.236\n",
      "Ep:201, loss:0.00000, loss_test:0.03166, lr:1.05e-02, fs:0.62319 (r=0.494,p=0.843),  time:41.682, tt:8419.815\n",
      "Ep:202, loss:0.00000, loss_test:0.03168, lr:1.04e-02, fs:0.62774 (r=0.494,p=0.860),  time:41.679, tt:8460.887\n",
      "Ep:203, loss:0.00000, loss_test:0.03162, lr:1.03e-02, fs:0.62774 (r=0.494,p=0.860),  time:41.679, tt:8502.478\n",
      "Ep:204, loss:0.00000, loss_test:0.03171, lr:1.02e-02, fs:0.62774 (r=0.494,p=0.860),  time:41.675, tt:8543.284\n",
      "Ep:205, loss:0.00000, loss_test:0.03175, lr:1.01e-02, fs:0.62774 (r=0.494,p=0.860),  time:41.680, tt:8586.047\n",
      "Ep:206, loss:0.00000, loss_test:0.03173, lr:1.00e-02, fs:0.62774 (r=0.494,p=0.860),  time:41.680, tt:8627.786\n",
      "Ep:207, loss:0.00000, loss_test:0.03174, lr:9.93e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.677, tt:8668.826\n",
      "Ep:208, loss:0.00000, loss_test:0.03177, lr:9.83e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.681, tt:8711.376\n",
      "Ep:209, loss:0.00000, loss_test:0.03183, lr:9.73e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.681, tt:8752.990\n",
      "Ep:210, loss:0.00000, loss_test:0.03182, lr:9.63e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.674, tt:8793.230\n",
      "Ep:211, loss:0.00000, loss_test:0.03184, lr:9.54e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.667, tt:8833.485\n",
      "Ep:212, loss:0.00000, loss_test:0.03183, lr:9.44e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.658, tt:8873.083\n",
      "Ep:213, loss:0.00000, loss_test:0.03186, lr:9.35e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.658, tt:8914.916\n",
      "Ep:214, loss:0.00000, loss_test:0.03192, lr:9.25e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.633, tt:8951.031\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14742, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:36.630, tt:36.630\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14694, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:36.145, tt:72.290\n",
      "Ep:2, loss:0.00027, loss_test:0.14595, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:37.100, tt:111.300\n",
      "Ep:3, loss:0.00027, loss_test:0.14417, lr:1.00e-02, fs:0.63710 (r=0.908,p=0.491),  time:38.133, tt:152.531\n",
      "Ep:4, loss:0.00026, loss_test:0.14055, lr:1.00e-02, fs:0.60633 (r=0.770,p=0.500),  time:38.533, tt:192.663\n",
      "Ep:5, loss:0.00024, loss_test:0.13948, lr:1.00e-02, fs:0.61307 (r=0.701,p=0.545),  time:38.892, tt:233.350\n",
      "Ep:6, loss:0.00023, loss_test:0.14075, lr:1.00e-02, fs:0.62703 (r=0.667,p=0.592),  time:39.190, tt:274.331\n",
      "Ep:7, loss:0.00023, loss_test:0.13642, lr:1.00e-02, fs:0.61453 (r=0.632,p=0.598),  time:39.302, tt:314.418\n",
      "Ep:8, loss:0.00022, loss_test:0.13231, lr:1.00e-02, fs:0.62295 (r=0.655,p=0.594),  time:39.753, tt:357.781\n",
      "Ep:9, loss:0.00021, loss_test:0.13071, lr:1.00e-02, fs:0.62295 (r=0.655,p=0.594),  time:39.946, tt:399.459\n",
      "Ep:10, loss:0.00021, loss_test:0.13212, lr:1.00e-02, fs:0.62147 (r=0.632,p=0.611),  time:40.054, tt:440.599\n",
      "Ep:11, loss:0.00020, loss_test:0.13110, lr:1.00e-02, fs:0.63953 (r=0.632,p=0.647),  time:40.181, tt:482.170\n",
      "Ep:12, loss:0.00019, loss_test:0.12520, lr:9.90e-03, fs:0.64773 (r=0.655,p=0.640),  time:40.376, tt:524.893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00019, loss_test:0.12114, lr:9.80e-03, fs:0.64368 (r=0.644,p=0.644),  time:40.897, tt:572.555\n",
      "Ep:14, loss:0.00018, loss_test:0.12117, lr:9.70e-03, fs:0.66667 (r=0.644,p=0.691),  time:40.944, tt:614.163\n",
      "Ep:15, loss:0.00017, loss_test:0.11841, lr:9.61e-03, fs:0.66667 (r=0.644,p=0.691),  time:41.122, tt:657.947\n",
      "Ep:16, loss:0.00017, loss_test:0.11704, lr:9.51e-03, fs:0.62500 (r=0.575,p=0.685),  time:41.130, tt:699.217\n",
      "Ep:17, loss:0.00016, loss_test:0.11564, lr:9.41e-03, fs:0.61039 (r=0.540,p=0.701),  time:41.186, tt:741.353\n",
      "Ep:18, loss:0.00015, loss_test:0.11306, lr:9.32e-03, fs:0.62025 (r=0.563,p=0.690),  time:41.219, tt:783.152\n",
      "Ep:19, loss:0.00015, loss_test:0.11264, lr:9.23e-03, fs:0.60927 (r=0.529,p=0.719),  time:41.257, tt:825.139\n",
      "Ep:20, loss:0.00014, loss_test:0.11192, lr:9.14e-03, fs:0.60000 (r=0.517,p=0.714),  time:41.310, tt:867.519\n",
      "Ep:21, loss:0.00014, loss_test:0.10944, lr:9.04e-03, fs:0.61842 (r=0.540,p=0.723),  time:41.429, tt:911.446\n",
      "Ep:22, loss:0.00013, loss_test:0.11046, lr:8.95e-03, fs:0.62252 (r=0.540,p=0.734),  time:41.399, tt:952.173\n",
      "Ep:23, loss:0.00013, loss_test:0.10840, lr:8.86e-03, fs:0.62252 (r=0.540,p=0.734),  time:41.511, tt:996.256\n",
      "Ep:24, loss:0.00013, loss_test:0.10994, lr:8.78e-03, fs:0.61333 (r=0.529,p=0.730),  time:41.631, tt:1040.779\n",
      "Ep:25, loss:0.00012, loss_test:0.10645, lr:8.69e-03, fs:0.64052 (r=0.563,p=0.742),  time:41.692, tt:1083.984\n",
      "Ep:26, loss:0.00012, loss_test:0.11303, lr:8.60e-03, fs:0.59310 (r=0.494,p=0.741),  time:41.738, tt:1126.918\n",
      "Ep:27, loss:0.00012, loss_test:0.10516, lr:8.51e-03, fs:0.63158 (r=0.552,p=0.738),  time:41.762, tt:1169.348\n",
      "Ep:28, loss:0.00011, loss_test:0.11430, lr:8.43e-03, fs:0.59722 (r=0.494,p=0.754),  time:41.786, tt:1211.788\n",
      "Ep:29, loss:0.00011, loss_test:0.10408, lr:8.35e-03, fs:0.64103 (r=0.575,p=0.725),  time:41.722, tt:1251.665\n",
      "Ep:30, loss:0.00011, loss_test:0.11265, lr:8.26e-03, fs:0.62069 (r=0.517,p=0.776),  time:41.769, tt:1294.836\n",
      "Ep:31, loss:0.00010, loss_test:0.10363, lr:8.18e-03, fs:0.63636 (r=0.563,p=0.731),  time:41.750, tt:1335.987\n",
      "Ep:32, loss:0.00010, loss_test:0.11181, lr:8.10e-03, fs:0.62500 (r=0.517,p=0.789),  time:41.788, tt:1379.018\n",
      "Ep:33, loss:0.00009, loss_test:0.10453, lr:8.02e-03, fs:0.64052 (r=0.563,p=0.742),  time:41.890, tt:1424.248\n",
      "Ep:34, loss:0.00009, loss_test:0.11374, lr:7.94e-03, fs:0.62411 (r=0.506,p=0.815),  time:41.897, tt:1466.411\n",
      "Ep:35, loss:0.00009, loss_test:0.10524, lr:7.86e-03, fs:0.64935 (r=0.575,p=0.746),  time:41.878, tt:1507.601\n",
      "Ep:36, loss:0.00009, loss_test:0.11699, lr:7.78e-03, fs:0.63309 (r=0.506,p=0.846),  time:41.930, tt:1551.421\n",
      "Ep:37, loss:0.00008, loss_test:0.10481, lr:7.70e-03, fs:0.64474 (r=0.563,p=0.754),  time:41.921, tt:1593.000\n",
      "Ep:38, loss:0.00008, loss_test:0.11127, lr:7.62e-03, fs:0.62411 (r=0.506,p=0.815),  time:41.889, tt:1633.687\n",
      "Ep:39, loss:0.00008, loss_test:0.10964, lr:7.55e-03, fs:0.65278 (r=0.540,p=0.825),  time:41.891, tt:1675.622\n",
      "Ep:40, loss:0.00007, loss_test:0.10971, lr:7.47e-03, fs:0.64336 (r=0.529,p=0.821),  time:41.902, tt:1717.980\n",
      "Ep:41, loss:0.00007, loss_test:0.11152, lr:7.40e-03, fs:0.63380 (r=0.517,p=0.818),  time:41.858, tt:1758.043\n",
      "Ep:42, loss:0.00007, loss_test:0.10614, lr:7.32e-03, fs:0.65306 (r=0.552,p=0.800),  time:41.865, tt:1800.191\n",
      "Ep:43, loss:0.00007, loss_test:0.11202, lr:7.25e-03, fs:0.64336 (r=0.529,p=0.821),  time:41.838, tt:1840.882\n",
      "Ep:44, loss:0.00007, loss_test:0.10720, lr:7.18e-03, fs:0.67568 (r=0.575,p=0.820),  time:41.748, tt:1878.644\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00006, loss_test:0.11148, lr:7.18e-03, fs:0.61871 (r=0.494,p=0.827),  time:41.729, tt:1919.517\n",
      "Ep:46, loss:0.00006, loss_test:0.10746, lr:7.18e-03, fs:0.67114 (r=0.575,p=0.806),  time:41.691, tt:1959.480\n",
      "Ep:47, loss:0.00006, loss_test:0.11009, lr:7.18e-03, fs:0.62411 (r=0.506,p=0.815),  time:41.675, tt:2000.396\n",
      "Ep:48, loss:0.00006, loss_test:0.10815, lr:7.18e-03, fs:0.65753 (r=0.552,p=0.814),  time:41.682, tt:2042.399\n",
      "Ep:49, loss:0.00006, loss_test:0.11510, lr:7.18e-03, fs:0.63768 (r=0.506,p=0.863),  time:41.658, tt:2082.913\n",
      "Ep:50, loss:0.00006, loss_test:0.10539, lr:7.18e-03, fs:0.66667 (r=0.563,p=0.817),  time:41.645, tt:2123.905\n",
      "Ep:51, loss:0.00006, loss_test:0.11925, lr:7.18e-03, fs:0.65217 (r=0.517,p=0.882),  time:41.598, tt:2163.093\n",
      "Ep:52, loss:0.00005, loss_test:0.10403, lr:7.18e-03, fs:0.64384 (r=0.540,p=0.797),  time:41.547, tt:2202.008\n",
      "Ep:53, loss:0.00005, loss_test:0.12030, lr:7.18e-03, fs:0.66667 (r=0.529,p=0.902),  time:41.498, tt:2240.914\n",
      "Ep:54, loss:0.00005, loss_test:0.10473, lr:7.18e-03, fs:0.67114 (r=0.575,p=0.806),  time:41.458, tt:2280.213\n",
      "Ep:55, loss:0.00005, loss_test:0.12194, lr:7.18e-03, fs:0.63704 (r=0.494,p=0.896),  time:41.442, tt:2320.772\n",
      "Ep:56, loss:0.00005, loss_test:0.10734, lr:7.11e-03, fs:0.65306 (r=0.552,p=0.800),  time:41.331, tt:2355.881\n",
      "Ep:57, loss:0.00005, loss_test:0.12161, lr:7.03e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.294, tt:2395.064\n",
      "Ep:58, loss:0.00005, loss_test:0.10885, lr:6.96e-03, fs:0.67133 (r=0.552,p=0.857),  time:41.244, tt:2433.422\n",
      "Ep:59, loss:0.00004, loss_test:0.11331, lr:6.89e-03, fs:0.65217 (r=0.517,p=0.882),  time:41.213, tt:2472.782\n",
      "Ep:60, loss:0.00004, loss_test:0.11036, lr:6.83e-03, fs:0.65248 (r=0.529,p=0.852),  time:41.185, tt:2512.299\n",
      "Ep:61, loss:0.00004, loss_test:0.11211, lr:6.76e-03, fs:0.64286 (r=0.517,p=0.849),  time:41.165, tt:2552.218\n",
      "Ep:62, loss:0.00004, loss_test:0.11229, lr:6.69e-03, fs:0.65714 (r=0.529,p=0.868),  time:41.155, tt:2592.791\n",
      "Ep:63, loss:0.00004, loss_test:0.11638, lr:6.62e-03, fs:0.66667 (r=0.529,p=0.902),  time:41.152, tt:2633.737\n",
      "Ep:64, loss:0.00004, loss_test:0.10943, lr:6.56e-03, fs:0.63309 (r=0.506,p=0.846),  time:41.157, tt:2675.228\n",
      "Ep:65, loss:0.00004, loss_test:0.11946, lr:6.49e-03, fs:0.66667 (r=0.529,p=0.902),  time:41.157, tt:2716.392\n",
      "Ep:66, loss:0.00004, loss_test:0.11212, lr:6.43e-03, fs:0.62774 (r=0.494,p=0.860),  time:41.148, tt:2756.883\n",
      "Ep:67, loss:0.00003, loss_test:0.12269, lr:6.36e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.157, tt:2798.656\n",
      "Ep:68, loss:0.00003, loss_test:0.11138, lr:6.30e-03, fs:0.65248 (r=0.529,p=0.852),  time:41.152, tt:2839.499\n",
      "Ep:69, loss:0.00003, loss_test:0.12315, lr:6.24e-03, fs:0.64662 (r=0.494,p=0.935),  time:41.175, tt:2882.218\n",
      "Ep:70, loss:0.00003, loss_test:0.10881, lr:6.17e-03, fs:0.65278 (r=0.540,p=0.825),  time:41.176, tt:2923.468\n",
      "Ep:71, loss:0.00003, loss_test:0.12051, lr:6.11e-03, fs:0.64662 (r=0.494,p=0.935),  time:41.180, tt:2964.948\n",
      "Ep:72, loss:0.00003, loss_test:0.11168, lr:6.05e-03, fs:0.63158 (r=0.483,p=0.913),  time:41.195, tt:3007.231\n",
      "Ep:73, loss:0.00003, loss_test:0.11680, lr:5.99e-03, fs:0.64662 (r=0.494,p=0.935),  time:41.250, tt:3052.494\n",
      "Ep:74, loss:0.00003, loss_test:0.11335, lr:5.93e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.262, tt:3094.649\n",
      "Ep:75, loss:0.00003, loss_test:0.11732, lr:5.87e-03, fs:0.64706 (r=0.506,p=0.898),  time:41.261, tt:3135.804\n",
      "Ep:76, loss:0.00003, loss_test:0.11702, lr:5.81e-03, fs:0.65672 (r=0.506,p=0.936),  time:41.263, tt:3177.255\n",
      "Ep:77, loss:0.00002, loss_test:0.11579, lr:5.75e-03, fs:0.62687 (r=0.483,p=0.894),  time:41.262, tt:3218.402\n",
      "Ep:78, loss:0.00002, loss_test:0.11395, lr:5.70e-03, fs:0.63158 (r=0.483,p=0.913),  time:41.253, tt:3259.004\n",
      "Ep:79, loss:0.00002, loss_test:0.11458, lr:5.64e-03, fs:0.63158 (r=0.483,p=0.913),  time:41.250, tt:3300.010\n",
      "Ep:80, loss:0.00002, loss_test:0.11679, lr:5.58e-03, fs:0.65152 (r=0.494,p=0.956),  time:41.251, tt:3341.338\n",
      "Ep:81, loss:0.00002, loss_test:0.11641, lr:5.53e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.295, tt:3386.228\n",
      "Ep:82, loss:0.00002, loss_test:0.11312, lr:5.47e-03, fs:0.64706 (r=0.506,p=0.898),  time:41.317, tt:3429.307\n",
      "Ep:83, loss:0.00002, loss_test:0.12614, lr:5.42e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.329, tt:3471.615\n",
      "Ep:84, loss:0.00002, loss_test:0.12037, lr:5.36e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.334, tt:3513.362\n",
      "Ep:85, loss:0.00002, loss_test:0.11660, lr:5.31e-03, fs:0.59375 (r=0.437,p=0.927),  time:41.351, tt:3556.216\n",
      "Ep:86, loss:0.00002, loss_test:0.12545, lr:5.26e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.369, tt:3599.062\n",
      "Ep:87, loss:0.00002, loss_test:0.11772, lr:5.20e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.377, tt:3641.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:88, loss:0.00002, loss_test:0.12052, lr:5.15e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.404, tt:3684.982\n",
      "Ep:89, loss:0.00002, loss_test:0.12365, lr:5.10e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.423, tt:3728.062\n",
      "Ep:90, loss:0.00002, loss_test:0.11613, lr:5.05e-03, fs:0.61654 (r=0.471,p=0.891),  time:41.418, tt:3769.001\n",
      "Ep:91, loss:0.00002, loss_test:0.12445, lr:5.00e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.413, tt:3809.985\n",
      "Ep:92, loss:0.00002, loss_test:0.12183, lr:4.95e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.424, tt:3852.438\n",
      "Ep:93, loss:0.00002, loss_test:0.11968, lr:4.90e-03, fs:0.51240 (r=0.356,p=0.912),  time:41.421, tt:3893.573\n",
      "Ep:94, loss:0.00002, loss_test:0.12419, lr:4.85e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.410, tt:3933.956\n",
      "Ep:95, loss:0.00002, loss_test:0.12094, lr:4.80e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.421, tt:3976.382\n",
      "Ep:96, loss:0.00002, loss_test:0.12003, lr:4.75e-03, fs:0.53226 (r=0.379,p=0.892),  time:41.406, tt:4016.342\n",
      "Ep:97, loss:0.00001, loss_test:0.12566, lr:4.71e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.425, tt:4059.613\n",
      "Ep:98, loss:0.00001, loss_test:0.11910, lr:4.66e-03, fs:0.51240 (r=0.356,p=0.912),  time:41.429, tt:4101.507\n",
      "Ep:99, loss:0.00001, loss_test:0.12489, lr:4.61e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.417, tt:4141.653\n",
      "Ep:100, loss:0.00001, loss_test:0.12308, lr:4.57e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.408, tt:4182.257\n",
      "Ep:101, loss:0.00001, loss_test:0.11696, lr:4.52e-03, fs:0.53659 (r=0.379,p=0.917),  time:41.410, tt:4223.816\n",
      "Ep:102, loss:0.00001, loss_test:0.12601, lr:4.48e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.406, tt:4264.852\n",
      "Ep:103, loss:0.00001, loss_test:0.12574, lr:4.43e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.415, tt:4307.142\n",
      "Ep:104, loss:0.00001, loss_test:0.12005, lr:4.39e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.402, tt:4347.190\n",
      "Ep:105, loss:0.00001, loss_test:0.12635, lr:4.34e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.398, tt:4388.192\n",
      "Ep:106, loss:0.00001, loss_test:0.12537, lr:4.30e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.402, tt:4430.038\n",
      "Ep:107, loss:0.00001, loss_test:0.12399, lr:4.26e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.403, tt:4471.570\n",
      "Ep:108, loss:0.00001, loss_test:0.12662, lr:4.21e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.403, tt:4512.949\n",
      "Ep:109, loss:0.00001, loss_test:0.12943, lr:4.17e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.400, tt:4554.023\n",
      "Ep:110, loss:0.00001, loss_test:0.12576, lr:4.13e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.382, tt:4593.355\n",
      "Ep:111, loss:0.00001, loss_test:0.12531, lr:4.09e-03, fs:0.50000 (r=0.345,p=0.909),  time:41.381, tt:4634.675\n",
      "Ep:112, loss:0.00001, loss_test:0.13036, lr:4.05e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.365, tt:4674.245\n",
      "Ep:113, loss:0.00001, loss_test:0.12515, lr:4.01e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.364, tt:4715.444\n",
      "Ep:114, loss:0.00001, loss_test:0.12925, lr:3.97e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.337, tt:4753.799\n",
      "Ep:115, loss:0.00001, loss_test:0.12971, lr:3.93e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.312, tt:4792.199\n",
      "Ep:116, loss:0.00001, loss_test:0.12780, lr:3.89e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.316, tt:4833.997\n",
      "Ep:117, loss:0.00001, loss_test:0.12856, lr:3.85e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.313, tt:4874.903\n",
      "Ep:118, loss:0.00001, loss_test:0.13164, lr:3.81e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.324, tt:4917.546\n",
      "Ep:119, loss:0.00001, loss_test:0.12810, lr:3.77e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.319, tt:4958.333\n",
      "Ep:120, loss:0.00001, loss_test:0.12877, lr:3.73e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.309, tt:4998.444\n",
      "Ep:121, loss:0.00001, loss_test:0.12829, lr:3.70e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.313, tt:5040.238\n",
      "Ep:122, loss:0.00001, loss_test:0.12995, lr:3.66e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.305, tt:5080.485\n",
      "Ep:123, loss:0.00001, loss_test:0.13068, lr:3.62e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.299, tt:5121.103\n",
      "Ep:124, loss:0.00001, loss_test:0.13089, lr:3.59e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.297, tt:5162.067\n",
      "Ep:125, loss:0.00001, loss_test:0.13121, lr:3.55e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.290, tt:5202.489\n",
      "Ep:126, loss:0.00001, loss_test:0.12877, lr:3.52e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.294, tt:5244.309\n",
      "Ep:127, loss:0.00001, loss_test:0.13211, lr:3.48e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.296, tt:5285.852\n",
      "Ep:128, loss:0.00001, loss_test:0.12880, lr:3.45e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.296, tt:5327.147\n",
      "Ep:129, loss:0.00001, loss_test:0.12958, lr:3.41e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.291, tt:5367.882\n",
      "Ep:130, loss:0.00001, loss_test:0.13257, lr:3.38e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.302, tt:5410.510\n",
      "Ep:131, loss:0.00001, loss_test:0.12945, lr:3.34e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.306, tt:5452.424\n",
      "Ep:132, loss:0.00001, loss_test:0.13120, lr:3.31e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.312, tt:5494.515\n",
      "Ep:133, loss:0.00001, loss_test:0.13229, lr:3.28e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.318, tt:5536.554\n",
      "Ep:134, loss:0.00001, loss_test:0.12940, lr:3.24e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.357, tt:5583.169\n",
      "Ep:135, loss:0.00001, loss_test:0.13062, lr:3.21e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.340, tt:5622.182\n",
      "Ep:136, loss:0.00001, loss_test:0.12960, lr:3.18e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.326, tt:5661.596\n",
      "Ep:137, loss:0.00001, loss_test:0.13103, lr:3.15e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.318, tt:5701.848\n",
      "Ep:138, loss:0.00001, loss_test:0.12981, lr:3.12e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.297, tt:5740.351\n",
      "Ep:139, loss:0.00001, loss_test:0.13006, lr:3.09e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.279, tt:5779.094\n",
      "Ep:140, loss:0.00001, loss_test:0.13075, lr:3.05e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.272, tt:5819.361\n",
      "Ep:141, loss:0.00001, loss_test:0.13042, lr:3.02e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.277, tt:5861.344\n",
      "Ep:142, loss:0.00001, loss_test:0.13141, lr:2.99e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.263, tt:5900.644\n",
      "Ep:143, loss:0.00001, loss_test:0.13056, lr:2.96e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.264, tt:5942.047\n",
      "Ep:144, loss:0.00001, loss_test:0.13045, lr:2.93e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.255, tt:5981.962\n",
      "Ep:145, loss:0.00001, loss_test:0.13149, lr:2.90e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.259, tt:6023.773\n",
      "Ep:146, loss:0.00001, loss_test:0.13027, lr:2.88e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.252, tt:6064.021\n",
      "Ep:147, loss:0.00001, loss_test:0.13224, lr:2.85e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.234, tt:6102.605\n",
      "Ep:148, loss:0.00001, loss_test:0.13092, lr:2.82e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.241, tt:6144.924\n",
      "Ep:149, loss:0.00001, loss_test:0.12939, lr:2.79e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.241, tt:6186.191\n",
      "Ep:150, loss:0.00001, loss_test:0.13254, lr:2.76e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.246, tt:6228.162\n",
      "Ep:151, loss:0.00001, loss_test:0.13089, lr:2.73e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.250, tt:6269.960\n",
      "Ep:152, loss:0.00000, loss_test:0.12995, lr:2.71e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.241, tt:6309.819\n",
      "Ep:153, loss:0.00000, loss_test:0.13385, lr:2.68e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.235, tt:6350.190\n",
      "Ep:154, loss:0.00000, loss_test:0.13087, lr:2.65e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.239, tt:6392.033\n",
      "Ep:155, loss:0.00000, loss_test:0.13030, lr:2.63e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.236, tt:6432.803\n",
      "Ep:156, loss:0.00000, loss_test:0.13316, lr:2.60e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.233, tt:6473.617\n",
      "Ep:157, loss:0.00000, loss_test:0.13061, lr:2.57e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.233, tt:6514.852\n",
      "Ep:158, loss:0.00000, loss_test:0.13108, lr:2.55e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.222, tt:6554.220\n",
      "Ep:159, loss:0.00000, loss_test:0.13234, lr:2.52e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.209, tt:6593.520\n",
      "Ep:160, loss:0.00000, loss_test:0.13100, lr:2.50e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.205, tt:6634.055\n",
      "Ep:161, loss:0.00000, loss_test:0.13115, lr:2.47e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.204, tt:6675.034\n",
      "Ep:162, loss:0.00000, loss_test:0.13084, lr:2.45e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.204, tt:6716.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00000, loss_test:0.13157, lr:2.42e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.207, tt:6757.990\n",
      "Ep:164, loss:0.00000, loss_test:0.13214, lr:2.40e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.210, tt:6799.593\n",
      "Ep:165, loss:0.00000, loss_test:0.13097, lr:2.38e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.225, tt:6843.300\n",
      "Ep:166, loss:0.00000, loss_test:0.13133, lr:2.35e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.217, tt:6883.319\n",
      "Ep:167, loss:0.00000, loss_test:0.13129, lr:2.33e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.219, tt:6924.778\n",
      "Ep:168, loss:0.00000, loss_test:0.13178, lr:2.31e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.216, tt:6965.465\n",
      "Ep:169, loss:0.00000, loss_test:0.13135, lr:2.28e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.236, tt:7010.120\n",
      "Ep:170, loss:0.00000, loss_test:0.13115, lr:2.26e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.239, tt:7051.918\n",
      "Ep:171, loss:0.00000, loss_test:0.13208, lr:2.24e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.240, tt:7093.298\n",
      "Ep:172, loss:0.00000, loss_test:0.13045, lr:2.21e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.250, tt:7136.300\n",
      "Ep:173, loss:0.00000, loss_test:0.13328, lr:2.19e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.267, tt:7180.387\n",
      "Ep:174, loss:0.00000, loss_test:0.13317, lr:2.17e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.258, tt:7220.208\n",
      "Ep:175, loss:0.00000, loss_test:0.13055, lr:2.15e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.288, tt:7266.675\n",
      "Ep:176, loss:0.00000, loss_test:0.13273, lr:2.13e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.298, tt:7309.702\n",
      "Ep:177, loss:0.00000, loss_test:0.13338, lr:2.11e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.299, tt:7351.252\n",
      "Ep:178, loss:0.00000, loss_test:0.13170, lr:2.08e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.299, tt:7392.560\n",
      "Ep:179, loss:0.00000, loss_test:0.13205, lr:2.06e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.305, tt:7434.879\n",
      "Ep:180, loss:0.00000, loss_test:0.13156, lr:2.04e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.311, tt:7477.266\n",
      "Ep:181, loss:0.00000, loss_test:0.13083, lr:2.02e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.301, tt:7516.862\n",
      "Ep:182, loss:0.00000, loss_test:0.13317, lr:2.00e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.302, tt:7558.329\n",
      "Ep:183, loss:0.00000, loss_test:0.13271, lr:1.98e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.310, tt:7600.953\n",
      "Ep:184, loss:0.00000, loss_test:0.13171, lr:1.96e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.311, tt:7642.459\n",
      "Ep:185, loss:0.00000, loss_test:0.13245, lr:1.94e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.309, tt:7683.454\n",
      "Ep:186, loss:0.00000, loss_test:0.13190, lr:1.92e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.294, tt:7722.002\n",
      "Ep:187, loss:0.00000, loss_test:0.13110, lr:1.90e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.295, tt:7763.539\n",
      "Ep:188, loss:0.00000, loss_test:0.13472, lr:1.89e-03, fs:0.50847 (r=0.345,p=0.968),  time:41.301, tt:7805.829\n",
      "Ep:189, loss:0.00000, loss_test:0.13368, lr:1.87e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.308, tt:7848.429\n",
      "Ep:190, loss:0.00000, loss_test:0.13092, lr:1.85e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.300, tt:7888.212\n",
      "Ep:191, loss:0.00000, loss_test:0.13304, lr:1.83e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.309, tt:7931.407\n",
      "Ep:192, loss:0.00000, loss_test:0.13320, lr:1.81e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.312, tt:7973.155\n",
      "Ep:193, loss:0.00000, loss_test:0.13168, lr:1.79e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.303, tt:8012.783\n",
      "Ep:194, loss:0.00000, loss_test:0.13260, lr:1.78e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.307, tt:8054.782\n",
      "Ep:195, loss:0.00000, loss_test:0.13374, lr:1.76e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.308, tt:8096.434\n",
      "Ep:196, loss:0.00000, loss_test:0.13209, lr:1.74e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.314, tt:8138.768\n",
      "Ep:197, loss:0.00000, loss_test:0.13208, lr:1.72e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.318, tt:8180.923\n",
      "Ep:198, loss:0.00000, loss_test:0.13300, lr:1.71e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.318, tt:8222.221\n",
      "Ep:199, loss:0.00000, loss_test:0.13309, lr:1.69e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.319, tt:8263.889\n",
      "Ep:200, loss:0.00000, loss_test:0.13258, lr:1.67e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.312, tt:8303.800\n",
      "Ep:201, loss:0.00000, loss_test:0.13242, lr:1.65e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.318, tt:8346.270\n",
      "Ep:202, loss:0.00000, loss_test:0.13250, lr:1.64e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.325, tt:8389.023\n",
      "Ep:203, loss:0.00000, loss_test:0.13213, lr:1.62e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.341, tt:8433.649\n",
      "Ep:204, loss:0.00000, loss_test:0.13265, lr:1.61e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.340, tt:8474.764\n",
      "Ep:205, loss:0.00000, loss_test:0.13365, lr:1.59e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.345, tt:8517.023\n",
      "Ep:206, loss:0.00000, loss_test:0.13283, lr:1.57e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.335, tt:8556.370\n",
      "Ep:207, loss:0.00000, loss_test:0.13138, lr:1.56e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.341, tt:8598.971\n",
      "Ep:208, loss:0.00000, loss_test:0.13359, lr:1.54e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.346, tt:8641.213\n",
      "Ep:209, loss:0.00000, loss_test:0.13474, lr:1.53e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.348, tt:8682.995\n",
      "Ep:210, loss:0.00000, loss_test:0.13376, lr:1.51e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.351, tt:8725.086\n",
      "Ep:211, loss:0.00000, loss_test:0.13290, lr:1.50e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.358, tt:8767.973\n",
      "Ep:212, loss:0.00000, loss_test:0.13344, lr:1.48e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.366, tt:8811.028\n",
      "Ep:213, loss:0.00000, loss_test:0.13266, lr:1.47e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.370, tt:8853.242\n",
      "Ep:214, loss:0.00000, loss_test:0.13298, lr:1.45e-03, fs:0.50420 (r=0.345,p=0.938),  time:41.359, tt:8892.191\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01989, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:39.616, tt:39.616\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02223, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.853, tt:81.705\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02292, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.546, tt:121.638\n",
      "Ep:3, loss:0.00005, loss_test:0.02206, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:40.774, tt:163.097\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02046, lr:6.00e-02, fs:0.67832 (r=0.980,p=0.519),  time:40.808, tt:204.038\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01927, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:40.802, tt:244.815\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01900, lr:6.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:41.039, tt:287.270\n",
      "Ep:7, loss:0.00004, loss_test:0.01874, lr:6.00e-02, fs:0.66109 (r=0.798,p=0.564),  time:40.879, tt:327.029\n",
      "Ep:8, loss:0.00004, loss_test:0.01774, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:41.052, tt:369.465\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01706, lr:6.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:41.199, tt:411.988\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.71642 (r=0.970,p=0.568),  time:41.136, tt:452.495\n",
      "Ep:11, loss:0.00003, loss_test:0.01660, lr:6.00e-02, fs:0.70588 (r=0.970,p=0.555),  time:41.259, tt:495.103\n",
      "Ep:12, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.73684 (r=0.990,p=0.587),  time:41.146, tt:534.893\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:40.978, tt:573.687\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:41.013, tt:615.195\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01540, lr:6.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:40.935, tt:654.962\n",
      "Ep:16, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:40.885, tt:695.037\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:40.825, tt:734.844\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01471, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:40.878, tt:776.679\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01446, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:40.878, tt:817.554\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01425, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:40.973, tt:860.432\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01404, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:40.947, tt:900.838\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01385, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:40.903, tt:940.770\n",
      "Ep:23, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:40.874, tt:980.985\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:40.860, tt:1021.501\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:40.865, tt:1062.483\n",
      "Ep:26, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:40.953, tt:1105.739\n",
      "Ep:27, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:40.953, tt:1146.695\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:40.920, tt:1186.687\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:40.875, tt:1226.264\n",
      "Ep:30, loss:0.00002, loss_test:0.01264, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:40.927, tt:1268.731\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01255, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:40.893, tt:1308.590\n",
      "Ep:32, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:40.808, tt:1346.661\n",
      "Ep:33, loss:0.00002, loss_test:0.01236, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:40.842, tt:1388.624\n",
      "Ep:34, loss:0.00002, loss_test:0.01229, lr:6.00e-02, fs:0.81938 (r=0.939,p=0.727),  time:40.844, tt:1429.547\n",
      "Ep:35, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:40.820, tt:1469.506\n",
      "Ep:36, loss:0.00002, loss_test:0.01211, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:40.834, tt:1510.849\n",
      "Ep:37, loss:0.00002, loss_test:0.01201, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:40.879, tt:1553.419\n",
      "Ep:38, loss:0.00002, loss_test:0.01190, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:40.866, tt:1593.759\n",
      "Ep:39, loss:0.00002, loss_test:0.01180, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:40.851, tt:1634.051\n",
      "Ep:40, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:40.845, tt:1674.642\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01160, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:40.829, tt:1714.822\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01151, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:40.810, tt:1754.818\n",
      "Ep:43, loss:0.00002, loss_test:0.01142, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:40.811, tt:1795.694\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01132, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:40.802, tt:1836.076\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01122, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:40.797, tt:1876.675\n",
      "Ep:46, loss:0.00002, loss_test:0.01113, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:40.838, tt:1919.370\n",
      "Ep:47, loss:0.00001, loss_test:0.01106, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:40.879, tt:1962.173\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:40.879, tt:2003.062\n",
      "Ep:49, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:40.897, tt:2044.833\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:40.924, tt:2087.104\n",
      "Ep:51, loss:0.00001, loss_test:0.01071, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:40.921, tt:2127.870\n",
      "Ep:52, loss:0.00001, loss_test:0.01066, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:40.951, tt:2170.417\n",
      "Ep:53, loss:0.00001, loss_test:0.01056, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:40.991, tt:2213.539\n",
      "Ep:54, loss:0.00001, loss_test:0.01049, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:41.009, tt:2255.471\n",
      "Ep:55, loss:0.00001, loss_test:0.01042, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:41.025, tt:2297.398\n",
      "Ep:56, loss:0.00001, loss_test:0.01033, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:41.026, tt:2338.473\n",
      "Ep:57, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:41.013, tt:2378.729\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01021, lr:6.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:41.033, tt:2420.966\n",
      "Ep:59, loss:0.00001, loss_test:0.01014, lr:6.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:41.030, tt:2461.777\n",
      "Ep:60, loss:0.00001, loss_test:0.01010, lr:6.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:41.063, tt:2504.847\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01003, lr:6.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:41.071, tt:2546.385\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01001, lr:6.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:41.062, tt:2586.913\n",
      "Ep:63, loss:0.00001, loss_test:0.00997, lr:6.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:41.094, tt:2630.035\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.00990, lr:6.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:41.131, tt:2673.524\n",
      "Ep:65, loss:0.00001, loss_test:0.00987, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:41.146, tt:2715.611\n",
      "Ep:66, loss:0.00001, loss_test:0.00976, lr:6.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:41.135, tt:2756.030\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.00970, lr:6.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:41.156, tt:2798.589\n",
      "Ep:68, loss:0.00001, loss_test:0.00972, lr:6.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:41.164, tt:2840.350\n",
      "Ep:69, loss:0.00001, loss_test:0.00967, lr:6.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:41.164, tt:2881.515\n",
      "Ep:70, loss:0.00001, loss_test:0.00962, lr:6.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:41.175, tt:2923.450\n",
      "Ep:71, loss:0.00001, loss_test:0.00960, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:41.160, tt:2963.550\n",
      "Ep:72, loss:0.00001, loss_test:0.00950, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:41.168, tt:3005.293\n",
      "Ep:73, loss:0.00001, loss_test:0.00949, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:41.165, tt:3046.208\n",
      "Ep:74, loss:0.00001, loss_test:0.00948, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:41.170, tt:3087.782\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.00944, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:41.153, tt:3127.609\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.00942, lr:6.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:41.131, tt:3167.068\n",
      "Ep:77, loss:0.00001, loss_test:0.00942, lr:6.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.120, tt:3207.380\n",
      "Ep:78, loss:0.00001, loss_test:0.00937, lr:6.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:41.090, tt:3246.135\n",
      "Ep:79, loss:0.00001, loss_test:0.00933, lr:6.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:41.089, tt:3287.122\n",
      "Ep:80, loss:0.00001, loss_test:0.00934, lr:6.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.073, tt:3326.882\n",
      "Ep:81, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.052, tt:3366.245\n",
      "Ep:82, loss:0.00001, loss_test:0.00928, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.034, tt:3405.844\n",
      "Ep:83, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.018, tt:3445.479\n",
      "Ep:84, loss:0.00001, loss_test:0.00929, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.024, tt:3487.020\n",
      "Ep:85, loss:0.00001, loss_test:0.00926, lr:6.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:41.009, tt:3526.807\n",
      "Ep:86, loss:0.00001, loss_test:0.00927, lr:6.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:40.984, tt:3565.616\n",
      "Ep:87, loss:0.00001, loss_test:0.00930, lr:5.94e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.985, tt:3606.679\n",
      "Ep:88, loss:0.00001, loss_test:0.00926, lr:5.88e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.981, tt:3647.269\n",
      "Ep:89, loss:0.00001, loss_test:0.00932, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.975, tt:3687.716\n",
      "Ep:90, loss:0.00001, loss_test:0.00927, lr:5.76e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.958, tt:3727.215\n",
      "Ep:91, loss:0.00001, loss_test:0.00925, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.966, tt:3768.917\n",
      "Ep:92, loss:0.00001, loss_test:0.00934, lr:5.65e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.950, tt:3808.379\n",
      "Ep:93, loss:0.00001, loss_test:0.00928, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.928, tt:3847.188\n",
      "Ep:94, loss:0.00001, loss_test:0.00930, lr:5.54e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.919, tt:3887.291\n",
      "Ep:95, loss:0.00001, loss_test:0.00928, lr:5.48e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.929, tt:3929.170\n",
      "Ep:96, loss:0.00001, loss_test:0.00930, lr:5.43e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.930, tt:3970.174\n",
      "Ep:97, loss:0.00001, loss_test:0.00926, lr:5.37e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.939, tt:4012.004\n",
      "Ep:98, loss:0.00001, loss_test:0.00930, lr:5.32e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.920, tt:4051.117\n",
      "Ep:99, loss:0.00001, loss_test:0.00928, lr:5.27e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.906, tt:4090.594\n",
      "Ep:100, loss:0.00001, loss_test:0.00934, lr:5.21e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.903, tt:4131.252\n",
      "Ep:101, loss:0.00001, loss_test:0.00929, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.898, tt:4171.587\n",
      "Ep:102, loss:0.00001, loss_test:0.00933, lr:5.11e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.904, tt:4213.151\n",
      "Ep:103, loss:0.00001, loss_test:0.00935, lr:5.06e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.898, tt:4253.353\n",
      "Ep:104, loss:0.00001, loss_test:0.00936, lr:5.01e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.892, tt:4293.636\n",
      "Ep:105, loss:0.00001, loss_test:0.00936, lr:4.96e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.880, tt:4333.274\n",
      "Ep:106, loss:0.00001, loss_test:0.00937, lr:4.91e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.883, tt:4374.432\n",
      "Ep:107, loss:0.00001, loss_test:0.00941, lr:4.86e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.862, tt:4413.107\n",
      "Ep:108, loss:0.00000, loss_test:0.00937, lr:4.81e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.855, tt:4453.227\n",
      "Ep:109, loss:0.00000, loss_test:0.00939, lr:4.76e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.855, tt:4494.030\n",
      "Ep:110, loss:0.00000, loss_test:0.00941, lr:4.71e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.847, tt:4533.976\n",
      "Ep:111, loss:0.00000, loss_test:0.00940, lr:4.67e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.853, tt:4575.552\n",
      "Ep:112, loss:0.00000, loss_test:0.00940, lr:4.62e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.851, tt:4616.175\n",
      "Ep:113, loss:0.00000, loss_test:0.00946, lr:4.57e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.834, tt:4655.029\n",
      "Ep:114, loss:0.00000, loss_test:0.00948, lr:4.53e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.825, tt:4694.885\n",
      "Ep:115, loss:0.00000, loss_test:0.00942, lr:4.48e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.827, tt:4735.952\n",
      "Ep:116, loss:0.00000, loss_test:0.00952, lr:4.44e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.828, tt:4776.931\n",
      "Ep:117, loss:0.00000, loss_test:0.00947, lr:4.39e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.818, tt:4816.519\n",
      "Ep:118, loss:0.00000, loss_test:0.00952, lr:4.35e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.795, tt:4854.609\n",
      "Ep:119, loss:0.00000, loss_test:0.00955, lr:4.31e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.790, tt:4894.748\n",
      "Ep:120, loss:0.00000, loss_test:0.00953, lr:4.26e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.769, tt:4933.094\n",
      "Ep:121, loss:0.00000, loss_test:0.00953, lr:4.22e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.752, tt:4971.685\n",
      "Ep:122, loss:0.00000, loss_test:0.00954, lr:4.18e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.749, tt:5012.165\n",
      "Ep:123, loss:0.00000, loss_test:0.00959, lr:4.14e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.761, tt:5054.320\n",
      "Ep:124, loss:0.00000, loss_test:0.00959, lr:4.10e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.750, tt:5093.811\n",
      "Ep:125, loss:0.00000, loss_test:0.00957, lr:4.05e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.742, tt:5133.474\n",
      "Ep:126, loss:0.00000, loss_test:0.00967, lr:4.01e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.737, tt:5173.593\n",
      "Ep:127, loss:0.00000, loss_test:0.00962, lr:3.97e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.737, tt:5214.373\n",
      "Ep:128, loss:0.00000, loss_test:0.00963, lr:3.93e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.717, tt:5252.514\n",
      "Ep:129, loss:0.00000, loss_test:0.00968, lr:3.89e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.698, tt:5290.703\n",
      "Ep:130, loss:0.00000, loss_test:0.00968, lr:3.86e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.688, tt:5330.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.00968, lr:3.82e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.694, tt:5371.668\n",
      "Ep:132, loss:0.00000, loss_test:0.00970, lr:3.78e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.693, tt:5412.177\n",
      "Ep:133, loss:0.00000, loss_test:0.00972, lr:3.74e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.688, tt:5452.191\n",
      "Ep:134, loss:0.00000, loss_test:0.00971, lr:3.70e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.680, tt:5491.746\n",
      "Ep:135, loss:0.00000, loss_test:0.00974, lr:3.67e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.680, tt:5532.477\n",
      "Ep:136, loss:0.00000, loss_test:0.00977, lr:3.63e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.683, tt:5573.529\n",
      "Ep:137, loss:0.00000, loss_test:0.00973, lr:3.59e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.690, tt:5615.229\n",
      "Ep:138, loss:0.00000, loss_test:0.00979, lr:3.56e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.688, tt:5655.636\n",
      "Ep:139, loss:0.00000, loss_test:0.00984, lr:3.52e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.671, tt:5693.882\n",
      "Ep:140, loss:0.00000, loss_test:0.00982, lr:3.49e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.675, tt:5735.176\n",
      "Ep:141, loss:0.00000, loss_test:0.00986, lr:3.45e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.673, tt:5775.534\n",
      "Ep:142, loss:0.00000, loss_test:0.00989, lr:3.42e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.677, tt:5816.759\n",
      "Ep:143, loss:0.00000, loss_test:0.00983, lr:3.38e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.711, tt:5862.405\n",
      "Ep:144, loss:0.00000, loss_test:0.00992, lr:3.35e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.710, tt:5902.984\n",
      "Ep:145, loss:0.00000, loss_test:0.00991, lr:3.32e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.722, tt:5945.345\n",
      "Ep:146, loss:0.00000, loss_test:0.00992, lr:3.28e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.722, tt:5986.189\n",
      "Ep:147, loss:0.00000, loss_test:0.00994, lr:3.25e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.718, tt:6026.294\n",
      "Ep:148, loss:0.00000, loss_test:0.00996, lr:3.22e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.720, tt:6067.272\n",
      "Ep:149, loss:0.00000, loss_test:0.00994, lr:3.19e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.721, tt:6108.124\n",
      "Ep:150, loss:0.00000, loss_test:0.01000, lr:3.15e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.711, tt:6147.285\n",
      "Ep:151, loss:0.00000, loss_test:0.01000, lr:3.12e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.706, tt:6187.301\n",
      "Ep:152, loss:0.00000, loss_test:0.00999, lr:3.09e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.697, tt:6226.711\n",
      "Ep:153, loss:0.00000, loss_test:0.01005, lr:3.06e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.701, tt:6268.013\n",
      "Ep:154, loss:0.00000, loss_test:0.01002, lr:3.03e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.703, tt:6308.983\n",
      "Ep:155, loss:0.00000, loss_test:0.01000, lr:3.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.708, tt:6350.388\n",
      "Ep:156, loss:0.00000, loss_test:0.01010, lr:2.97e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.706, tt:6390.880\n",
      "Ep:157, loss:0.00000, loss_test:0.01003, lr:2.94e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.713, tt:6432.712\n",
      "Ep:158, loss:0.00000, loss_test:0.01006, lr:2.91e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.713, tt:6473.295\n",
      "Ep:159, loss:0.00000, loss_test:0.01014, lr:2.88e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.706, tt:6513.022\n",
      "Ep:160, loss:0.00000, loss_test:0.01009, lr:2.85e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.732, tt:6557.816\n",
      "Ep:161, loss:0.00000, loss_test:0.01012, lr:2.82e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.737, tt:6599.378\n",
      "Ep:162, loss:0.00000, loss_test:0.01016, lr:2.80e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.734, tt:6639.668\n",
      "Ep:163, loss:0.00000, loss_test:0.01013, lr:2.77e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.729, tt:6679.482\n",
      "Ep:164, loss:0.00000, loss_test:0.01016, lr:2.74e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.721, tt:6718.942\n",
      "Ep:165, loss:0.00000, loss_test:0.01018, lr:2.71e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.715, tt:6758.736\n",
      "Ep:166, loss:0.00000, loss_test:0.01019, lr:2.69e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.712, tt:6798.976\n",
      "Ep:167, loss:0.00000, loss_test:0.01020, lr:2.66e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.719, tt:6840.799\n",
      "Ep:168, loss:0.00000, loss_test:0.01021, lr:2.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.717, tt:6881.197\n",
      "Ep:169, loss:0.00000, loss_test:0.01023, lr:2.61e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.720, tt:6922.484\n",
      "Ep:170, loss:0.00000, loss_test:0.01023, lr:2.58e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.709, tt:6961.199\n",
      "Ep:171, loss:0.00000, loss_test:0.01026, lr:2.55e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.697, tt:6999.922\n",
      "Ep:172, loss:0.00000, loss_test:0.01026, lr:2.53e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.696, tt:7040.348\n",
      "Ep:173, loss:0.00000, loss_test:0.01027, lr:2.50e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.696, tt:7081.174\n",
      "Ep:174, loss:0.00000, loss_test:0.01028, lr:2.48e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.685, tt:7119.919\n",
      "Ep:175, loss:0.00000, loss_test:0.01032, lr:2.45e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.694, tt:7162.138\n",
      "Ep:176, loss:0.00000, loss_test:0.01031, lr:2.43e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.695, tt:7202.969\n",
      "Ep:177, loss:0.00000, loss_test:0.01031, lr:2.40e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.742, tt:7252.131\n",
      "Ep:178, loss:0.00000, loss_test:0.01036, lr:2.38e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.744, tt:7293.215\n",
      "Ep:179, loss:0.00000, loss_test:0.01034, lr:2.36e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.747, tt:7334.458\n",
      "Ep:180, loss:0.00000, loss_test:0.01033, lr:2.33e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.754, tt:7376.535\n",
      "Ep:181, loss:0.00000, loss_test:0.01039, lr:2.31e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.768, tt:7419.749\n",
      "Ep:182, loss:0.00000, loss_test:0.01038, lr:2.29e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.779, tt:7462.580\n",
      "Ep:183, loss:0.00000, loss_test:0.01038, lr:2.26e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.772, tt:7502.096\n",
      "Ep:184, loss:0.00000, loss_test:0.01042, lr:2.24e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.758, tt:7540.299\n",
      "Ep:185, loss:0.00000, loss_test:0.01040, lr:2.22e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.764, tt:7582.094\n",
      "Ep:186, loss:0.00000, loss_test:0.01041, lr:2.20e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.767, tt:7623.511\n",
      "Ep:187, loss:0.00000, loss_test:0.01045, lr:2.17e-02, fs:0.85714 (r=0.788,p=0.940),  time:40.768, tt:7664.386\n",
      "Ep:188, loss:0.00000, loss_test:0.01043, lr:2.15e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.765, tt:7704.549\n",
      "Ep:189, loss:0.00000, loss_test:0.01045, lr:2.13e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.759, tt:7744.239\n",
      "Ep:190, loss:0.00000, loss_test:0.01046, lr:2.11e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.757, tt:7784.669\n",
      "Ep:191, loss:0.00000, loss_test:0.01049, lr:2.09e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.762, tt:7826.351\n",
      "Ep:192, loss:0.00000, loss_test:0.01049, lr:2.07e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.763, tt:7867.195\n",
      "Ep:193, loss:0.00000, loss_test:0.01047, lr:2.05e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.760, tt:7907.429\n",
      "Ep:194, loss:0.00000, loss_test:0.01049, lr:2.03e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.758, tt:7947.771\n",
      "Ep:195, loss:0.00000, loss_test:0.01052, lr:2.01e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.756, tt:7988.160\n",
      "Ep:196, loss:0.00000, loss_test:0.01053, lr:1.99e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.765, tt:8030.798\n",
      "Ep:197, loss:0.00000, loss_test:0.01051, lr:1.97e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.768, tt:8072.150\n",
      "Ep:198, loss:0.00000, loss_test:0.01054, lr:1.95e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.770, tt:8113.305\n",
      "Ep:199, loss:0.00000, loss_test:0.01055, lr:1.93e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.763, tt:8152.526\n",
      "Ep:200, loss:0.00000, loss_test:0.01054, lr:1.91e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.764, tt:8193.582\n",
      "Ep:201, loss:0.00000, loss_test:0.01055, lr:1.89e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.749, tt:8231.278\n",
      "Ep:202, loss:0.00000, loss_test:0.01056, lr:1.87e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.751, tt:8272.494\n",
      "Ep:203, loss:0.00000, loss_test:0.01057, lr:1.85e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.755, tt:8314.053\n",
      "Ep:204, loss:0.00000, loss_test:0.01057, lr:1.83e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.755, tt:8354.787\n",
      "Ep:205, loss:0.00000, loss_test:0.01061, lr:1.81e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.758, tt:8396.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.01059, lr:1.80e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.786, tt:8442.805\n",
      "Ep:207, loss:0.00000, loss_test:0.01060, lr:1.78e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.772, tt:8480.631\n",
      "Ep:208, loss:0.00000, loss_test:0.01064, lr:1.76e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.749, tt:8516.641\n",
      "Ep:209, loss:0.00000, loss_test:0.01063, lr:1.74e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.694, tt:8545.641\n",
      "Ep:210, loss:0.00000, loss_test:0.01062, lr:1.73e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.674, tt:8582.149\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14148, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.819, tt:42.819\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14014, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.782, tt:83.565\n",
      "Ep:2, loss:0.00028, loss_test:0.13785, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.193, tt:126.580\n",
      "Ep:3, loss:0.00027, loss_test:0.13413, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:42.423, tt:169.693\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12780, lr:1.00e-02, fs:0.68100 (r=0.960,p=0.528),  time:42.054, tt:210.270\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11864, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:42.043, tt:252.257\n",
      "Ep:6, loss:0.00024, loss_test:0.11275, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:41.986, tt:293.904\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11029, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:42.033, tt:336.264\n",
      "Ep:8, loss:0.00023, loss_test:0.10615, lr:1.00e-02, fs:0.67273 (r=0.747,p=0.612),  time:42.205, tt:379.847\n",
      "Ep:9, loss:0.00022, loss_test:0.10542, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:42.054, tt:420.540\n",
      "Ep:10, loss:0.00022, loss_test:0.10287, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:42.084, tt:462.923\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10072, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:42.015, tt:504.179\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09686, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:41.978, tt:545.711\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09366, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:41.954, tt:587.350\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09068, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:41.941, tt:629.122\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.08727, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:42.103, tt:673.656\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08469, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:42.150, tt:716.544\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08191, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.129, tt:758.324\n",
      "Ep:18, loss:0.00017, loss_test:0.07972, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:42.043, tt:798.808\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.07852, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:42.022, tt:840.441\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.07693, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:42.007, tt:882.153\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.07553, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:41.968, tt:923.290\n",
      "Ep:22, loss:0.00015, loss_test:0.07402, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:41.922, tt:964.213\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07288, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:41.848, tt:1004.362\n",
      "Ep:24, loss:0.00013, loss_test:0.07159, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:41.822, tt:1045.556\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.06955, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:41.803, tt:1086.880\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.06788, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:41.683, tt:1125.447\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.06672, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:41.750, tt:1169.013\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.06458, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:41.736, tt:1210.340\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.06394, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:41.721, tt:1251.627\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.06274, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:41.733, tt:1293.717\n",
      "Ep:31, loss:0.00010, loss_test:0.06065, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:41.660, tt:1333.131\n",
      "Ep:32, loss:0.00010, loss_test:0.06317, lr:1.00e-02, fs:0.89815 (r=0.980,p=0.829),  time:41.715, tt:1376.602\n",
      "Ep:33, loss:0.00010, loss_test:0.05957, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.730, tt:1418.825\n",
      "Ep:34, loss:0.00009, loss_test:0.05996, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:41.671, tt:1458.473\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.05683, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:41.634, tt:1498.817\n",
      "Ep:36, loss:0.00009, loss_test:0.05735, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:41.643, tt:1540.804\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.05465, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:41.643, tt:1582.435\n",
      "Ep:38, loss:0.00008, loss_test:0.05551, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:41.693, tt:1626.034\n",
      "Ep:39, loss:0.00008, loss_test:0.05322, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:41.654, tt:1666.177\n",
      "Ep:40, loss:0.00007, loss_test:0.05326, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:41.608, tt:1705.908\n",
      "Ep:41, loss:0.00007, loss_test:0.05445, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.569, tt:1745.903\n",
      "Ep:42, loss:0.00007, loss_test:0.05170, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:41.565, tt:1787.274\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.05346, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:41.576, tt:1829.341\n",
      "Ep:44, loss:0.00006, loss_test:0.04991, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:41.568, tt:1870.552\n",
      "Ep:45, loss:0.00006, loss_test:0.05107, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:41.589, tt:1913.090\n",
      "Ep:46, loss:0.00006, loss_test:0.05036, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:41.577, tt:1954.138\n",
      "Ep:47, loss:0.00005, loss_test:0.05153, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:41.557, tt:1994.725\n",
      "Ep:48, loss:0.00006, loss_test:0.04982, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.573, tt:2037.080\n",
      "Ep:49, loss:0.00005, loss_test:0.04814, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:41.561, tt:2078.039\n",
      "Ep:50, loss:0.00005, loss_test:0.04859, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:41.552, tt:2119.175\n",
      "Ep:51, loss:0.00005, loss_test:0.04792, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.540, tt:2160.087\n",
      "Ep:52, loss:0.00004, loss_test:0.04675, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.500, tt:2199.512\n",
      "Ep:53, loss:0.00004, loss_test:0.04802, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:41.549, tt:2243.641\n",
      "Ep:54, loss:0.00004, loss_test:0.04569, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:41.525, tt:2283.853\n",
      "Ep:55, loss:0.00004, loss_test:0.04669, lr:9.80e-03, fs:0.88649 (r=0.828,p=0.953),  time:41.522, tt:2325.212\n",
      "Ep:56, loss:0.00004, loss_test:0.04662, lr:9.70e-03, fs:0.86458 (r=0.838,p=0.892),  time:41.543, tt:2367.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00004, loss_test:0.04666, lr:9.61e-03, fs:0.89130 (r=0.828,p=0.965),  time:41.551, tt:2409.959\n",
      "Ep:58, loss:0.00004, loss_test:0.04583, lr:9.51e-03, fs:0.88421 (r=0.848,p=0.923),  time:41.590, tt:2453.831\n",
      "Ep:59, loss:0.00003, loss_test:0.04356, lr:9.41e-03, fs:0.90526 (r=0.869,p=0.945),  time:41.569, tt:2494.112\n",
      "Ep:60, loss:0.00003, loss_test:0.04424, lr:9.32e-03, fs:0.88889 (r=0.848,p=0.933),  time:41.572, tt:2535.862\n",
      "Ep:61, loss:0.00003, loss_test:0.04304, lr:9.23e-03, fs:0.90526 (r=0.869,p=0.945),  time:41.556, tt:2576.480\n",
      "Ep:62, loss:0.00003, loss_test:0.04323, lr:9.14e-03, fs:0.90052 (r=0.869,p=0.935),  time:41.571, tt:2618.968\n",
      "Ep:63, loss:0.00003, loss_test:0.04284, lr:9.04e-03, fs:0.89362 (r=0.848,p=0.944),  time:41.547, tt:2658.984\n",
      "Ep:64, loss:0.00003, loss_test:0.04242, lr:8.95e-03, fs:0.89005 (r=0.859,p=0.924),  time:41.562, tt:2701.558\n",
      "Ep:65, loss:0.00003, loss_test:0.04365, lr:8.86e-03, fs:0.89730 (r=0.838,p=0.965),  time:41.554, tt:2742.591\n",
      "Ep:66, loss:0.00003, loss_test:0.04071, lr:8.78e-03, fs:0.91579 (r=0.879,p=0.956),  time:41.568, tt:2785.060\n",
      "Ep:67, loss:0.00003, loss_test:0.04384, lr:8.69e-03, fs:0.89840 (r=0.848,p=0.955),  time:41.555, tt:2825.722\n",
      "Ep:68, loss:0.00002, loss_test:0.04073, lr:8.60e-03, fs:0.90426 (r=0.859,p=0.955),  time:41.503, tt:2863.725\n",
      "Ep:69, loss:0.00002, loss_test:0.04077, lr:8.51e-03, fs:0.89005 (r=0.859,p=0.924),  time:41.480, tt:2903.588\n",
      "Ep:70, loss:0.00002, loss_test:0.04145, lr:8.43e-03, fs:0.90323 (r=0.848,p=0.966),  time:41.488, tt:2945.655\n",
      "Ep:71, loss:0.00002, loss_test:0.04118, lr:8.35e-03, fs:0.91099 (r=0.879,p=0.946),  time:41.482, tt:2986.725\n",
      "Ep:72, loss:0.00002, loss_test:0.04134, lr:8.26e-03, fs:0.90426 (r=0.859,p=0.955),  time:41.470, tt:3027.329\n",
      "Ep:73, loss:0.00002, loss_test:0.04004, lr:8.18e-03, fs:0.91005 (r=0.869,p=0.956),  time:41.480, tt:3069.487\n",
      "Ep:74, loss:0.00002, loss_test:0.04026, lr:8.10e-03, fs:0.90426 (r=0.859,p=0.955),  time:41.462, tt:3109.666\n",
      "Ep:75, loss:0.00002, loss_test:0.03909, lr:8.02e-03, fs:0.91979 (r=0.869,p=0.977),  time:41.477, tt:3152.245\n",
      "Ep:76, loss:0.00002, loss_test:0.03959, lr:7.94e-03, fs:0.91398 (r=0.859,p=0.977),  time:41.491, tt:3194.809\n",
      "Ep:77, loss:0.00002, loss_test:0.03817, lr:7.86e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.474, tt:3234.945\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.03947, lr:7.86e-03, fs:0.91398 (r=0.859,p=0.977),  time:41.493, tt:3277.970\n",
      "Ep:79, loss:0.00002, loss_test:0.03783, lr:7.86e-03, fs:0.92063 (r=0.879,p=0.967),  time:41.505, tt:3320.404\n",
      "Ep:80, loss:0.00002, loss_test:0.03997, lr:7.86e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.490, tt:3360.672\n",
      "Ep:81, loss:0.00002, loss_test:0.03741, lr:7.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.494, tt:3402.540\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.03951, lr:7.86e-03, fs:0.92063 (r=0.879,p=0.967),  time:41.511, tt:3445.375\n",
      "Ep:83, loss:0.00002, loss_test:0.03862, lr:7.86e-03, fs:0.91892 (r=0.859,p=0.988),  time:41.494, tt:3485.479\n",
      "Ep:84, loss:0.00001, loss_test:0.03892, lr:7.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.501, tt:3527.582\n",
      "Ep:85, loss:0.00001, loss_test:0.03813, lr:7.86e-03, fs:0.91892 (r=0.859,p=0.988),  time:41.511, tt:3569.974\n",
      "Ep:86, loss:0.00001, loss_test:0.03888, lr:7.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.512, tt:3611.554\n",
      "Ep:87, loss:0.00001, loss_test:0.03985, lr:7.86e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.522, tt:3653.960\n",
      "Ep:88, loss:0.00001, loss_test:0.03732, lr:7.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.531, tt:3696.252\n",
      "Ep:89, loss:0.00001, loss_test:0.03964, lr:7.86e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.543, tt:3738.839\n",
      "Ep:90, loss:0.00001, loss_test:0.03827, lr:7.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.533, tt:3779.495\n",
      "Ep:91, loss:0.00001, loss_test:0.03941, lr:7.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.542, tt:3821.905\n",
      "Ep:92, loss:0.00001, loss_test:0.03800, lr:7.86e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.589, tt:3867.817\n",
      "Ep:93, loss:0.00001, loss_test:0.03952, lr:7.78e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.613, tt:3911.645\n",
      "Ep:94, loss:0.00001, loss_test:0.03776, lr:7.70e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.615, tt:3953.451\n",
      "Ep:95, loss:0.00001, loss_test:0.04111, lr:7.62e-03, fs:0.92973 (r=0.869,p=1.000),  time:41.634, tt:3996.826\n",
      "Ep:96, loss:0.00001, loss_test:0.03705, lr:7.55e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.661, tt:4041.125\n",
      "Ep:97, loss:0.00001, loss_test:0.03992, lr:7.47e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.699, tt:4086.492\n",
      "Ep:98, loss:0.00001, loss_test:0.03811, lr:7.40e-03, fs:0.92973 (r=0.869,p=1.000),  time:41.720, tt:4130.267\n",
      "Ep:99, loss:0.00001, loss_test:0.03724, lr:7.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.747, tt:4174.704\n",
      "Ep:100, loss:0.00001, loss_test:0.03831, lr:7.25e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.745, tt:4216.231\n",
      "Ep:101, loss:0.00001, loss_test:0.03720, lr:7.18e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.748, tt:4258.261\n",
      "Ep:102, loss:0.00001, loss_test:0.03752, lr:7.11e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.752, tt:4300.468\n",
      "Ep:103, loss:0.00001, loss_test:0.03622, lr:7.03e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.770, tt:4344.127\n",
      "Ep:104, loss:0.00001, loss_test:0.03779, lr:6.96e-03, fs:0.93548 (r=0.879,p=1.000),  time:41.792, tt:4388.163\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.03697, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.804, tt:4431.228\n",
      "Ep:106, loss:0.00001, loss_test:0.03661, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.811, tt:4473.752\n",
      "Ep:107, loss:0.00001, loss_test:0.03665, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.832, tt:4517.842\n",
      "Ep:108, loss:0.00001, loss_test:0.03694, lr:6.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.844, tt:4561.001\n",
      "Ep:109, loss:0.00001, loss_test:0.03697, lr:6.96e-03, fs:0.93548 (r=0.879,p=1.000),  time:41.862, tt:4604.858\n",
      "Ep:110, loss:0.00001, loss_test:0.03651, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.875, tt:4648.140\n",
      "Ep:111, loss:0.00001, loss_test:0.03753, lr:6.96e-03, fs:0.93548 (r=0.879,p=1.000),  time:41.889, tt:4691.607\n",
      "Ep:112, loss:0.00001, loss_test:0.03610, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.911, tt:4735.996\n",
      "Ep:113, loss:0.00001, loss_test:0.03707, lr:6.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.925, tt:4779.424\n",
      "Ep:114, loss:0.00001, loss_test:0.03690, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.922, tt:4821.015\n",
      "Ep:115, loss:0.00001, loss_test:0.03684, lr:6.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.934, tt:4864.319\n",
      "Ep:116, loss:0.00001, loss_test:0.03755, lr:6.89e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.943, tt:4907.302\n",
      "Ep:117, loss:0.00001, loss_test:0.03836, lr:6.83e-03, fs:0.93548 (r=0.879,p=1.000),  time:41.956, tt:4950.776\n",
      "Ep:118, loss:0.00000, loss_test:0.03631, lr:6.76e-03, fs:0.92553 (r=0.879,p=0.978),  time:41.972, tt:4994.615\n",
      "Ep:119, loss:0.00000, loss_test:0.03793, lr:6.69e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.990, tt:5038.826\n",
      "Ep:120, loss:0.00000, loss_test:0.03673, lr:6.62e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.011, tt:5083.273\n",
      "Ep:121, loss:0.00000, loss_test:0.03748, lr:6.56e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.023, tt:5126.790\n",
      "Ep:122, loss:0.00000, loss_test:0.03725, lr:6.49e-03, fs:0.92473 (r=0.869,p=0.989),  time:42.032, tt:5169.894\n",
      "Ep:123, loss:0.00000, loss_test:0.03724, lr:6.43e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.050, tt:5214.176\n",
      "Ep:124, loss:0.00000, loss_test:0.03706, lr:6.36e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.063, tt:5257.867\n",
      "Ep:125, loss:0.00000, loss_test:0.03672, lr:6.30e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.072, tt:5301.114\n",
      "Ep:126, loss:0.00000, loss_test:0.03727, lr:6.24e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.077, tt:5343.796\n",
      "Ep:127, loss:0.00000, loss_test:0.03754, lr:6.17e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.091, tt:5387.658\n",
      "Ep:128, loss:0.00000, loss_test:0.03736, lr:6.11e-03, fs:0.92473 (r=0.869,p=0.989),  time:42.087, tt:5429.178\n",
      "Ep:129, loss:0.00000, loss_test:0.03916, lr:6.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.102, tt:5473.245\n",
      "Ep:130, loss:0.00000, loss_test:0.03765, lr:5.99e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.116, tt:5517.231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.03793, lr:5.93e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.107, tt:5558.098\n",
      "Ep:132, loss:0.00000, loss_test:0.03766, lr:5.87e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.116, tt:5601.405\n",
      "Ep:133, loss:0.00000, loss_test:0.03781, lr:5.81e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.119, tt:5643.920\n",
      "Ep:134, loss:0.00000, loss_test:0.03696, lr:5.75e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.129, tt:5687.431\n",
      "Ep:135, loss:0.00000, loss_test:0.03732, lr:5.70e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.140, tt:5731.003\n",
      "Ep:136, loss:0.00000, loss_test:0.03651, lr:5.64e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.147, tt:5774.124\n",
      "Ep:137, loss:0.00000, loss_test:0.03764, lr:5.58e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.155, tt:5817.323\n",
      "Ep:138, loss:0.00000, loss_test:0.03637, lr:5.53e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.149, tt:5858.753\n",
      "Ep:139, loss:0.00000, loss_test:0.03741, lr:5.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.190, tt:5906.648\n",
      "Ep:140, loss:0.00000, loss_test:0.03724, lr:5.42e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.197, tt:5949.717\n",
      "Ep:141, loss:0.00000, loss_test:0.03711, lr:5.36e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.197, tt:5991.907\n",
      "Ep:142, loss:0.00000, loss_test:0.03720, lr:5.31e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.193, tt:6033.538\n",
      "Ep:143, loss:0.00000, loss_test:0.03723, lr:5.26e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.207, tt:6077.810\n",
      "Ep:144, loss:0.00000, loss_test:0.03688, lr:5.20e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.196, tt:6118.390\n",
      "Ep:145, loss:0.00000, loss_test:0.03808, lr:5.15e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.202, tt:6161.470\n",
      "Ep:146, loss:0.00000, loss_test:0.03850, lr:5.10e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.214, tt:6205.487\n",
      "Ep:147, loss:0.00000, loss_test:0.03732, lr:5.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.218, tt:6248.330\n",
      "Ep:148, loss:0.00000, loss_test:0.03749, lr:5.00e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.227, tt:6291.777\n",
      "Ep:149, loss:0.00000, loss_test:0.03781, lr:4.95e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.231, tt:6334.721\n",
      "Ep:150, loss:0.00000, loss_test:0.03748, lr:4.90e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.232, tt:6376.986\n",
      "Ep:151, loss:0.00000, loss_test:0.03692, lr:4.85e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.237, tt:6420.051\n",
      "Ep:152, loss:0.00000, loss_test:0.03771, lr:4.80e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.242, tt:6463.087\n",
      "Ep:153, loss:0.00000, loss_test:0.03713, lr:4.75e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.253, tt:6506.938\n",
      "Ep:154, loss:0.00000, loss_test:0.03728, lr:4.71e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.255, tt:6549.534\n",
      "Ep:155, loss:0.00000, loss_test:0.03687, lr:4.66e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.264, tt:6593.136\n",
      "Ep:156, loss:0.00000, loss_test:0.03696, lr:4.61e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.245, tt:6632.454\n",
      "Ep:157, loss:0.00000, loss_test:0.03738, lr:4.57e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.251, tt:6675.634\n",
      "Ep:158, loss:0.00000, loss_test:0.03673, lr:4.52e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.258, tt:6719.000\n",
      "Ep:159, loss:0.00000, loss_test:0.03734, lr:4.48e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.265, tt:6762.383\n",
      "Ep:160, loss:0.00000, loss_test:0.03718, lr:4.43e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.265, tt:6804.605\n",
      "Ep:161, loss:0.00000, loss_test:0.03666, lr:4.39e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.261, tt:6846.354\n",
      "Ep:162, loss:0.00000, loss_test:0.03707, lr:4.34e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.266, tt:6889.421\n",
      "Ep:163, loss:0.00000, loss_test:0.03711, lr:4.30e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.275, tt:6933.034\n",
      "Ep:164, loss:0.00000, loss_test:0.03670, lr:4.26e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.293, tt:6978.317\n",
      "Ep:165, loss:0.00000, loss_test:0.03737, lr:4.21e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.299, tt:7021.715\n",
      "Ep:166, loss:0.00000, loss_test:0.03707, lr:4.17e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.304, tt:7064.744\n",
      "Ep:167, loss:0.00000, loss_test:0.03714, lr:4.13e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.297, tt:7105.859\n",
      "Ep:168, loss:0.00000, loss_test:0.03724, lr:4.09e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.285, tt:7146.083\n",
      "Ep:169, loss:0.00000, loss_test:0.03641, lr:4.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.278, tt:7187.328\n",
      "Ep:170, loss:0.00000, loss_test:0.03684, lr:4.01e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.282, tt:7230.163\n",
      "Ep:171, loss:0.00000, loss_test:0.03712, lr:3.97e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.288, tt:7273.543\n",
      "Ep:172, loss:0.00000, loss_test:0.03671, lr:3.93e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.280, tt:7314.402\n",
      "Ep:173, loss:0.00000, loss_test:0.03671, lr:3.89e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.273, tt:7355.563\n",
      "Ep:174, loss:0.00000, loss_test:0.03725, lr:3.85e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.274, tt:7397.925\n",
      "Ep:175, loss:0.00000, loss_test:0.03663, lr:3.81e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.261, tt:7437.909\n",
      "Ep:176, loss:0.00000, loss_test:0.03650, lr:3.77e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.250, tt:7478.284\n",
      "Ep:177, loss:0.00000, loss_test:0.03713, lr:3.73e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.248, tt:7520.127\n",
      "Ep:178, loss:0.00000, loss_test:0.03704, lr:3.70e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.241, tt:7561.132\n",
      "Ep:179, loss:0.00000, loss_test:0.03623, lr:3.66e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.235, tt:7602.246\n",
      "Ep:180, loss:0.00000, loss_test:0.03726, lr:3.62e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.236, tt:7644.645\n",
      "Ep:181, loss:0.00000, loss_test:0.03684, lr:3.59e-03, fs:0.92553 (r=0.879,p=0.978),  time:42.232, tt:7686.209\n",
      "Ep:182, loss:0.00000, loss_test:0.03674, lr:3.55e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.244, tt:7730.628\n",
      "Ep:183, loss:0.00000, loss_test:0.03732, lr:3.52e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.224, tt:7769.290\n",
      "Ep:184, loss:0.00000, loss_test:0.03696, lr:3.48e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.227, tt:7811.918\n",
      "Ep:185, loss:0.00000, loss_test:0.03668, lr:3.45e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.227, tt:7854.136\n",
      "Ep:186, loss:0.00000, loss_test:0.03675, lr:3.41e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.223, tt:7895.698\n",
      "Ep:187, loss:0.00000, loss_test:0.03697, lr:3.38e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.221, tt:7937.457\n",
      "Ep:188, loss:0.00000, loss_test:0.03707, lr:3.34e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.211, tt:7977.891\n",
      "Ep:189, loss:0.00000, loss_test:0.03677, lr:3.31e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.201, tt:8018.160\n",
      "Ep:190, loss:0.00000, loss_test:0.03677, lr:3.28e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.190, tt:8058.204\n",
      "Ep:191, loss:0.00000, loss_test:0.03684, lr:3.24e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.181, tt:8098.727\n",
      "Ep:192, loss:0.00000, loss_test:0.03665, lr:3.21e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.177, tt:8140.239\n",
      "Ep:193, loss:0.00000, loss_test:0.03659, lr:3.18e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.190, tt:8184.923\n",
      "Ep:194, loss:0.00000, loss_test:0.03707, lr:3.15e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.227, tt:8234.230\n",
      "Ep:195, loss:0.00000, loss_test:0.03697, lr:3.12e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.225, tt:8276.193\n",
      "Ep:196, loss:0.00000, loss_test:0.03676, lr:3.09e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.218, tt:8316.941\n",
      "Ep:197, loss:0.00000, loss_test:0.03668, lr:3.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.223, tt:8360.238\n",
      "Ep:198, loss:0.00000, loss_test:0.03693, lr:3.02e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.226, tt:8402.908\n",
      "Ep:199, loss:0.00000, loss_test:0.03668, lr:2.99e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.231, tt:8446.167\n",
      "Ep:200, loss:0.00000, loss_test:0.03683, lr:2.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.233, tt:8488.870\n",
      "Ep:201, loss:0.00000, loss_test:0.03682, lr:2.93e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.235, tt:8531.377\n",
      "Ep:202, loss:0.00000, loss_test:0.03668, lr:2.90e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.227, tt:8572.172\n",
      "Ep:203, loss:0.00000, loss_test:0.03687, lr:2.88e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.240, tt:8617.027\n",
      "Ep:204, loss:0.00000, loss_test:0.03693, lr:2.85e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.232, tt:8657.637\n",
      "Ep:205, loss:0.00000, loss_test:0.03664, lr:2.82e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.225, tt:8698.347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.03663, lr:2.79e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.224, tt:8740.292\n",
      "Ep:207, loss:0.00000, loss_test:0.03689, lr:2.76e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.189, tt:8775.403\n",
      "Ep:208, loss:0.00000, loss_test:0.03712, lr:2.73e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.159, tt:8811.204\n",
      "Ep:209, loss:0.00000, loss_test:0.03692, lr:2.71e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.112, tt:8843.538\n",
      "Ep:210, loss:0.00000, loss_test:0.03668, lr:2.68e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.044, tt:8871.218\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01957, lr:6.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:43.836, tt:43.836\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02155, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:42.362, tt:84.724\n",
      "Ep:2, loss:0.00004, loss_test:0.02201, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.829, tt:128.488\n",
      "Ep:3, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:42.615, tt:170.459\n",
      "Ep:4, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:42.230, tt:211.150\n",
      "Ep:5, loss:0.00004, loss_test:0.01804, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:42.190, tt:253.141\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01779, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:42.125, tt:294.876\n",
      "Ep:7, loss:0.00004, loss_test:0.01728, lr:6.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:41.986, tt:335.887\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01656, lr:6.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:41.759, tt:375.831\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:41.704, tt:417.037\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.72862 (r=0.990,p=0.576),  time:42.031, tt:462.339\n",
      "Ep:11, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.73684 (r=0.990,p=0.587),  time:41.945, tt:503.341\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01536, lr:6.00e-02, fs:0.74903 (r=0.980,p=0.606),  time:41.853, tt:544.083\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01502, lr:6.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:41.810, tt:585.342\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:41.759, tt:626.382\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01455, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:41.678, tt:666.855\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01433, lr:6.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:41.678, tt:708.517\n",
      "Ep:17, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.77165 (r=0.990,p=0.632),  time:41.576, tt:748.377\n",
      "Ep:18, loss:0.00003, loss_test:0.01388, lr:6.00e-02, fs:0.76078 (r=0.980,p=0.622),  time:41.504, tt:788.581\n",
      "Ep:19, loss:0.00003, loss_test:0.01357, lr:6.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:41.469, tt:829.388\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01332, lr:6.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:41.420, tt:869.819\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:41.480, tt:912.552\n",
      "Ep:22, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:41.420, tt:952.660\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:41.374, tt:992.976\n",
      "Ep:24, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:41.346, tt:1033.640\n",
      "Ep:25, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:41.349, tt:1075.077\n",
      "Ep:26, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:41.283, tt:1114.638\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:41.281, tt:1155.854\n",
      "Ep:28, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:41.288, tt:1197.349\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01193, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:41.305, tt:1239.159\n",
      "Ep:30, loss:0.00002, loss_test:0.01178, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:41.252, tt:1278.820\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01163, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:41.260, tt:1320.333\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01151, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:41.236, tt:1360.797\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01138, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:41.190, tt:1400.464\n",
      "Ep:34, loss:0.00002, loss_test:0.01124, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:41.165, tt:1440.783\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01112, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:41.138, tt:1480.970\n",
      "Ep:36, loss:0.00002, loss_test:0.01103, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:41.038, tt:1518.401\n",
      "Ep:37, loss:0.00002, loss_test:0.01092, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:40.986, tt:1557.460\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01082, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:40.933, tt:1596.403\n",
      "Ep:39, loss:0.00002, loss_test:0.01074, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:40.860, tt:1634.412\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01063, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:40.863, tt:1675.388\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01051, lr:6.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:40.853, tt:1715.824\n",
      "Ep:42, loss:0.00002, loss_test:0.01042, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:40.856, tt:1756.827\n",
      "Ep:43, loss:0.00001, loss_test:0.01034, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:40.860, tt:1797.821\n",
      "Ep:44, loss:0.00001, loss_test:0.01026, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:40.807, tt:1836.332\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01019, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:40.821, tt:1877.783\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01014, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:40.795, tt:1917.379\n",
      "Ep:47, loss:0.00001, loss_test:0.01010, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:40.816, tt:1959.154\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01002, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:40.821, tt:2000.207\n",
      "Ep:49, loss:0.00001, loss_test:0.00996, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:40.806, tt:2040.277\n",
      "Ep:50, loss:0.00001, loss_test:0.00990, lr:6.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:40.808, tt:2081.224\n",
      "Ep:51, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:40.825, tt:2122.907\n",
      "Ep:52, loss:0.00001, loss_test:0.00981, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:40.855, tt:2165.334\n",
      "Ep:53, loss:0.00001, loss_test:0.00976, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:40.878, tt:2207.433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00001, loss_test:0.00969, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:40.881, tt:2248.448\n",
      "Ep:55, loss:0.00001, loss_test:0.00964, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:40.947, tt:2293.018\n",
      "Ep:56, loss:0.00001, loss_test:0.00960, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:40.944, tt:2333.818\n",
      "Ep:57, loss:0.00001, loss_test:0.00958, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:40.986, tt:2377.180\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.00951, lr:6.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:40.992, tt:2418.524\n",
      "Ep:59, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:41.013, tt:2460.799\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:41.048, tt:2503.929\n",
      "Ep:61, loss:0.00001, loss_test:0.00945, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:41.116, tt:2549.186\n",
      "Ep:62, loss:0.00001, loss_test:0.00942, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:41.108, tt:2589.773\n",
      "Ep:63, loss:0.00001, loss_test:0.00937, lr:6.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:41.142, tt:2633.104\n",
      "Ep:64, loss:0.00001, loss_test:0.00937, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:41.164, tt:2675.692\n",
      "Ep:65, loss:0.00001, loss_test:0.00929, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:41.195, tt:2718.870\n",
      "Ep:66, loss:0.00001, loss_test:0.00932, lr:6.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:41.210, tt:2761.096\n",
      "Ep:67, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:41.242, tt:2804.435\n",
      "Ep:68, loss:0.00001, loss_test:0.00934, lr:6.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:41.247, tt:2846.066\n",
      "Ep:69, loss:0.00001, loss_test:0.00930, lr:6.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:41.248, tt:2887.350\n",
      "Ep:70, loss:0.00001, loss_test:0.00927, lr:6.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:41.249, tt:2928.664\n",
      "Ep:71, loss:0.00001, loss_test:0.00928, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:41.251, tt:2970.095\n",
      "Ep:72, loss:0.00001, loss_test:0.00921, lr:5.88e-02, fs:0.87805 (r=0.909,p=0.849),  time:41.247, tt:3011.022\n",
      "Ep:73, loss:0.00001, loss_test:0.00920, lr:5.82e-02, fs:0.87805 (r=0.909,p=0.849),  time:41.249, tt:3052.429\n",
      "Ep:74, loss:0.00001, loss_test:0.00924, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:41.271, tt:3095.301\n",
      "Ep:75, loss:0.00001, loss_test:0.00922, lr:5.71e-02, fs:0.87129 (r=0.889,p=0.854),  time:41.300, tt:3138.832\n",
      "Ep:76, loss:0.00001, loss_test:0.00918, lr:5.65e-02, fs:0.86139 (r=0.879,p=0.845),  time:41.314, tt:3181.163\n",
      "Ep:77, loss:0.00001, loss_test:0.00922, lr:5.59e-02, fs:0.86567 (r=0.879,p=0.853),  time:41.316, tt:3222.612\n",
      "Ep:78, loss:0.00001, loss_test:0.00919, lr:5.54e-02, fs:0.86567 (r=0.879,p=0.853),  time:41.302, tt:3262.848\n",
      "Ep:79, loss:0.00001, loss_test:0.00917, lr:5.48e-02, fs:0.86139 (r=0.879,p=0.845),  time:41.331, tt:3306.446\n",
      "Ep:80, loss:0.00001, loss_test:0.00921, lr:5.43e-02, fs:0.86567 (r=0.879,p=0.853),  time:41.340, tt:3348.529\n",
      "Ep:81, loss:0.00001, loss_test:0.00921, lr:5.37e-02, fs:0.86567 (r=0.879,p=0.853),  time:41.340, tt:3389.903\n",
      "Ep:82, loss:0.00001, loss_test:0.00920, lr:5.32e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.360, tt:3432.912\n",
      "Ep:83, loss:0.00001, loss_test:0.00921, lr:5.27e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.380, tt:3475.914\n",
      "Ep:84, loss:0.00001, loss_test:0.00924, lr:5.21e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.391, tt:3518.210\n",
      "Ep:85, loss:0.00001, loss_test:0.00923, lr:5.16e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.381, tt:3558.741\n",
      "Ep:86, loss:0.00001, loss_test:0.00920, lr:5.11e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.412, tt:3602.849\n",
      "Ep:87, loss:0.00001, loss_test:0.00925, lr:5.06e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.430, tt:3645.872\n",
      "Ep:88, loss:0.00001, loss_test:0.00925, lr:5.01e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.449, tt:3688.971\n",
      "Ep:89, loss:0.00001, loss_test:0.00927, lr:4.96e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.461, tt:3731.453\n",
      "Ep:90, loss:0.00001, loss_test:0.00927, lr:4.91e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.453, tt:3772.180\n",
      "Ep:91, loss:0.00001, loss_test:0.00926, lr:4.86e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.445, tt:3812.894\n",
      "Ep:92, loss:0.00001, loss_test:0.00929, lr:4.81e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.447, tt:3854.533\n",
      "Ep:93, loss:0.00001, loss_test:0.00928, lr:4.76e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.457, tt:3896.969\n",
      "Ep:94, loss:0.00001, loss_test:0.00930, lr:4.71e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.476, tt:3940.187\n",
      "Ep:95, loss:0.00001, loss_test:0.00931, lr:4.67e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.487, tt:3982.758\n",
      "Ep:96, loss:0.00001, loss_test:0.00931, lr:4.62e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.481, tt:4023.705\n",
      "Ep:97, loss:0.00001, loss_test:0.00933, lr:4.57e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.489, tt:4065.944\n",
      "Ep:98, loss:0.00001, loss_test:0.00934, lr:4.53e-02, fs:0.85859 (r=0.859,p=0.859),  time:41.480, tt:4106.559\n",
      "Ep:99, loss:0.00001, loss_test:0.00937, lr:4.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:41.476, tt:4147.586\n",
      "Ep:100, loss:0.00001, loss_test:0.00940, lr:4.44e-02, fs:0.86294 (r=0.859,p=0.867),  time:41.471, tt:4188.549\n",
      "Ep:101, loss:0.00001, loss_test:0.00937, lr:4.39e-02, fs:0.86294 (r=0.859,p=0.867),  time:41.469, tt:4229.859\n",
      "Ep:102, loss:0.00001, loss_test:0.00940, lr:4.35e-02, fs:0.86294 (r=0.859,p=0.867),  time:41.478, tt:4272.230\n",
      "Ep:103, loss:0.00001, loss_test:0.00940, lr:4.31e-02, fs:0.86735 (r=0.859,p=0.876),  time:41.481, tt:4313.975\n",
      "Ep:104, loss:0.00001, loss_test:0.00947, lr:4.26e-02, fs:0.87179 (r=0.859,p=0.885),  time:41.476, tt:4355.015\n",
      "Ep:105, loss:0.00001, loss_test:0.00944, lr:4.22e-02, fs:0.87629 (r=0.859,p=0.895),  time:41.472, tt:4396.026\n",
      "Ep:106, loss:0.00001, loss_test:0.00944, lr:4.18e-02, fs:0.87629 (r=0.859,p=0.895),  time:41.480, tt:4438.322\n",
      "Ep:107, loss:0.00000, loss_test:0.00945, lr:4.14e-02, fs:0.87179 (r=0.859,p=0.885),  time:41.479, tt:4479.714\n",
      "Ep:108, loss:0.00000, loss_test:0.00947, lr:4.10e-02, fs:0.87629 (r=0.859,p=0.895),  time:41.466, tt:4519.837\n",
      "Ep:109, loss:0.00000, loss_test:0.00951, lr:4.05e-02, fs:0.88083 (r=0.859,p=0.904),  time:41.410, tt:4555.084\n",
      "Ep:110, loss:0.00000, loss_test:0.00949, lr:4.01e-02, fs:0.87629 (r=0.859,p=0.895),  time:41.386, tt:4593.836\n",
      "Ep:111, loss:0.00000, loss_test:0.00953, lr:3.97e-02, fs:0.88083 (r=0.859,p=0.904),  time:41.370, tt:4633.438\n",
      "Ep:112, loss:0.00000, loss_test:0.00954, lr:3.93e-02, fs:0.88083 (r=0.859,p=0.904),  time:41.364, tt:4674.129\n",
      "Ep:113, loss:0.00000, loss_test:0.00954, lr:3.89e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.355, tt:4714.474\n",
      "Ep:114, loss:0.00000, loss_test:0.00957, lr:3.86e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.333, tt:4753.324\n",
      "Ep:115, loss:0.00000, loss_test:0.00960, lr:3.82e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.329, tt:4794.216\n",
      "Ep:116, loss:0.00000, loss_test:0.00955, lr:3.78e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.322, tt:4834.706\n",
      "Ep:117, loss:0.00000, loss_test:0.00961, lr:3.74e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.310, tt:4874.592\n",
      "Ep:118, loss:0.00000, loss_test:0.00961, lr:3.70e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.289, tt:4913.439\n",
      "Ep:119, loss:0.00000, loss_test:0.00963, lr:3.67e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.281, tt:4953.666\n",
      "Ep:120, loss:0.00000, loss_test:0.00965, lr:3.63e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.272, tt:4993.892\n",
      "Ep:121, loss:0.00000, loss_test:0.00962, lr:3.59e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.264, tt:5034.235\n",
      "Ep:122, loss:0.00000, loss_test:0.00968, lr:3.56e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.255, tt:5074.417\n",
      "Ep:123, loss:0.00000, loss_test:0.00967, lr:3.52e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.232, tt:5112.813\n",
      "Ep:124, loss:0.00000, loss_test:0.00970, lr:3.49e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.238, tt:5154.744\n",
      "Ep:125, loss:0.00000, loss_test:0.00972, lr:3.45e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.228, tt:5194.748\n",
      "Ep:126, loss:0.00000, loss_test:0.00970, lr:3.42e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.211, tt:5233.851\n",
      "Ep:127, loss:0.00000, loss_test:0.00977, lr:3.38e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.198, tt:5273.334\n",
      "Ep:128, loss:0.00000, loss_test:0.00975, lr:3.35e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.194, tt:5314.080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00000, loss_test:0.00978, lr:3.32e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.176, tt:5352.835\n",
      "Ep:130, loss:0.00000, loss_test:0.00979, lr:3.28e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.159, tt:5391.877\n",
      "Ep:131, loss:0.00000, loss_test:0.00976, lr:3.25e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.137, tt:5430.032\n",
      "Ep:132, loss:0.00000, loss_test:0.00981, lr:3.22e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.138, tt:5471.327\n",
      "Ep:133, loss:0.00000, loss_test:0.00984, lr:3.19e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.122, tt:5510.366\n",
      "Ep:134, loss:0.00000, loss_test:0.00982, lr:3.15e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.112, tt:5550.141\n",
      "Ep:135, loss:0.00000, loss_test:0.00984, lr:3.12e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.109, tt:5590.816\n",
      "Ep:136, loss:0.00000, loss_test:0.00987, lr:3.09e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.091, tt:5629.531\n",
      "Ep:137, loss:0.00000, loss_test:0.00987, lr:3.06e-02, fs:0.87701 (r=0.828,p=0.932),  time:41.085, tt:5669.725\n",
      "Ep:138, loss:0.00000, loss_test:0.00993, lr:3.03e-02, fs:0.85561 (r=0.808,p=0.909),  time:41.075, tt:5709.476\n",
      "Ep:139, loss:0.00000, loss_test:0.00986, lr:3.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:41.055, tt:5747.699\n",
      "Ep:140, loss:0.00000, loss_test:0.00991, lr:2.97e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.048, tt:5787.741\n",
      "Ep:141, loss:0.00000, loss_test:0.00994, lr:2.94e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.023, tt:5825.239\n",
      "Ep:142, loss:0.00000, loss_test:0.00991, lr:2.91e-02, fs:0.87701 (r=0.828,p=0.932),  time:41.012, tt:5864.733\n",
      "Ep:143, loss:0.00000, loss_test:0.00996, lr:2.88e-02, fs:0.86957 (r=0.808,p=0.941),  time:41.015, tt:5906.221\n",
      "Ep:144, loss:0.00000, loss_test:0.00996, lr:2.85e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.003, tt:5945.399\n",
      "Ep:145, loss:0.00000, loss_test:0.00995, lr:2.82e-02, fs:0.87568 (r=0.818,p=0.942),  time:41.007, tt:5987.008\n",
      "Ep:146, loss:0.00000, loss_test:0.00998, lr:2.80e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.998, tt:6026.756\n",
      "Ep:147, loss:0.00000, loss_test:0.00997, lr:2.77e-02, fs:0.88043 (r=0.818,p=0.953),  time:41.003, tt:6068.387\n",
      "Ep:148, loss:0.00000, loss_test:0.01002, lr:2.74e-02, fs:0.87432 (r=0.808,p=0.952),  time:40.992, tt:6107.753\n",
      "Ep:149, loss:0.00000, loss_test:0.01001, lr:2.71e-02, fs:0.88649 (r=0.828,p=0.953),  time:40.987, tt:6148.044\n",
      "Ep:150, loss:0.00000, loss_test:0.01001, lr:2.69e-02, fs:0.89130 (r=0.828,p=0.965),  time:40.970, tt:6186.483\n",
      "Ep:151, loss:0.00000, loss_test:0.01005, lr:2.66e-02, fs:0.86813 (r=0.798,p=0.952),  time:40.955, tt:6225.148\n",
      "Ep:152, loss:0.00000, loss_test:0.01004, lr:2.63e-02, fs:0.87912 (r=0.808,p=0.964),  time:40.948, tt:6265.094\n",
      "Ep:153, loss:0.00000, loss_test:0.01004, lr:2.61e-02, fs:0.87912 (r=0.808,p=0.964),  time:40.979, tt:6310.841\n",
      "Ep:154, loss:0.00000, loss_test:0.01008, lr:2.58e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.979, tt:6351.803\n",
      "Ep:155, loss:0.00000, loss_test:0.01004, lr:2.55e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.977, tt:6392.394\n",
      "Ep:156, loss:0.00000, loss_test:0.01012, lr:2.53e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.974, tt:6432.969\n",
      "Ep:157, loss:0.00000, loss_test:0.01009, lr:2.50e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.962, tt:6472.074\n",
      "Ep:158, loss:0.00000, loss_test:0.01008, lr:2.48e-02, fs:0.87293 (r=0.798,p=0.963),  time:40.954, tt:6511.756\n",
      "Ep:159, loss:0.00000, loss_test:0.01012, lr:2.45e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.942, tt:6550.791\n",
      "Ep:160, loss:0.00000, loss_test:0.01012, lr:2.43e-02, fs:0.87293 (r=0.798,p=0.963),  time:40.922, tt:6588.386\n",
      "Ep:161, loss:0.00000, loss_test:0.01012, lr:2.40e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.918, tt:6628.717\n",
      "Ep:162, loss:0.00000, loss_test:0.01013, lr:2.38e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.907, tt:6667.920\n",
      "Ep:163, loss:0.00000, loss_test:0.01015, lr:2.36e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.888, tt:6705.558\n",
      "Ep:164, loss:0.00000, loss_test:0.01015, lr:2.33e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.882, tt:6745.557\n",
      "Ep:165, loss:0.00000, loss_test:0.01017, lr:2.31e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.869, tt:6784.240\n",
      "Ep:166, loss:0.00000, loss_test:0.01017, lr:2.29e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.863, tt:6824.043\n",
      "Ep:167, loss:0.00000, loss_test:0.01017, lr:2.26e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.851, tt:6862.966\n",
      "Ep:168, loss:0.00000, loss_test:0.01018, lr:2.24e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.840, tt:6901.909\n",
      "Ep:169, loss:0.00000, loss_test:0.01021, lr:2.22e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.825, tt:6940.213\n",
      "Ep:170, loss:0.00000, loss_test:0.01023, lr:2.20e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.816, tt:6979.510\n",
      "Ep:171, loss:0.00000, loss_test:0.01023, lr:2.17e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.810, tt:7019.337\n",
      "Ep:172, loss:0.00000, loss_test:0.01023, lr:2.15e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.804, tt:7059.105\n",
      "Ep:173, loss:0.00000, loss_test:0.01022, lr:2.13e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.794, tt:7098.108\n",
      "Ep:174, loss:0.00000, loss_test:0.01024, lr:2.11e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.808, tt:7141.359\n",
      "Ep:175, loss:0.00000, loss_test:0.01024, lr:2.09e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.799, tt:7180.613\n",
      "Ep:176, loss:0.00000, loss_test:0.01026, lr:2.07e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.790, tt:7219.903\n",
      "Ep:177, loss:0.00000, loss_test:0.01025, lr:2.05e-02, fs:0.87151 (r=0.788,p=0.975),  time:40.787, tt:7260.033\n",
      "Ep:178, loss:0.00000, loss_test:0.01028, lr:2.03e-02, fs:0.86667 (r=0.788,p=0.963),  time:40.778, tt:7299.178\n",
      "Ep:179, loss:0.00000, loss_test:0.01027, lr:2.01e-02, fs:0.87151 (r=0.788,p=0.975),  time:40.774, tt:7339.377\n",
      "Ep:180, loss:0.00000, loss_test:0.01028, lr:1.99e-02, fs:0.87151 (r=0.788,p=0.975),  time:40.769, tt:7379.152\n",
      "Ep:181, loss:0.00000, loss_test:0.01029, lr:1.97e-02, fs:0.87151 (r=0.788,p=0.975),  time:40.775, tt:7421.056\n",
      "Ep:182, loss:0.00000, loss_test:0.01030, lr:1.95e-02, fs:0.87151 (r=0.788,p=0.975),  time:40.769, tt:7460.801\n",
      "Ep:183, loss:0.00000, loss_test:0.01030, lr:1.93e-02, fs:0.86517 (r=0.778,p=0.975),  time:40.765, tt:7500.720\n",
      "Ep:184, loss:0.00000, loss_test:0.01033, lr:1.91e-02, fs:0.87151 (r=0.788,p=0.975),  time:40.748, tt:7538.290\n",
      "Ep:185, loss:0.00000, loss_test:0.01033, lr:1.89e-02, fs:0.86517 (r=0.778,p=0.975),  time:40.738, tt:7577.214\n",
      "Ep:186, loss:0.00000, loss_test:0.01032, lr:1.87e-02, fs:0.86517 (r=0.778,p=0.975),  time:40.729, tt:7616.298\n",
      "Ep:187, loss:0.00000, loss_test:0.01033, lr:1.85e-02, fs:0.86517 (r=0.778,p=0.975),  time:40.727, tt:7656.753\n",
      "Ep:188, loss:0.00000, loss_test:0.01034, lr:1.83e-02, fs:0.85876 (r=0.768,p=0.974),  time:40.732, tt:7698.255\n",
      "Ep:189, loss:0.00000, loss_test:0.01035, lr:1.81e-02, fs:0.85876 (r=0.768,p=0.974),  time:40.724, tt:7737.638\n",
      "Ep:190, loss:0.00000, loss_test:0.01036, lr:1.80e-02, fs:0.85876 (r=0.768,p=0.974),  time:40.726, tt:7778.750\n",
      "Ep:191, loss:0.00000, loss_test:0.01037, lr:1.78e-02, fs:0.84571 (r=0.747,p=0.974),  time:40.717, tt:7817.707\n",
      "Ep:192, loss:0.00000, loss_test:0.01036, lr:1.76e-02, fs:0.85227 (r=0.758,p=0.974),  time:40.709, tt:7856.792\n",
      "Ep:193, loss:0.00000, loss_test:0.01038, lr:1.74e-02, fs:0.85876 (r=0.768,p=0.974),  time:40.715, tt:7898.627\n",
      "Ep:194, loss:0.00000, loss_test:0.01039, lr:1.73e-02, fs:0.84571 (r=0.747,p=0.974),  time:40.708, tt:7938.014\n",
      "Ep:195, loss:0.00000, loss_test:0.01039, lr:1.71e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.742, tt:7985.521\n",
      "Ep:196, loss:0.00000, loss_test:0.01041, lr:1.69e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.731, tt:8023.955\n",
      "Ep:197, loss:0.00000, loss_test:0.01040, lr:1.67e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.730, tt:8064.558\n",
      "Ep:198, loss:0.00000, loss_test:0.01039, lr:1.66e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.723, tt:8103.966\n",
      "Ep:199, loss:0.00000, loss_test:0.01042, lr:1.64e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.713, tt:8142.632\n",
      "Ep:200, loss:0.00000, loss_test:0.01043, lr:1.62e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.714, tt:8183.446\n",
      "Ep:201, loss:0.00000, loss_test:0.01042, lr:1.61e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.707, tt:8222.882\n",
      "Ep:202, loss:0.00000, loss_test:0.01044, lr:1.59e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.715, tt:8265.129\n",
      "Ep:203, loss:0.00000, loss_test:0.01044, lr:1.58e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.701, tt:8302.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.01043, lr:1.56e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.704, tt:8344.259\n",
      "Ep:205, loss:0.00000, loss_test:0.01045, lr:1.54e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.698, tt:8383.863\n",
      "Ep:206, loss:0.00000, loss_test:0.01045, lr:1.53e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.695, tt:8423.792\n",
      "Ep:207, loss:0.00000, loss_test:0.01045, lr:1.51e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.682, tt:8461.947\n",
      "Ep:208, loss:0.00000, loss_test:0.01047, lr:1.50e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.658, tt:8497.514\n",
      "Ep:209, loss:0.00000, loss_test:0.01048, lr:1.48e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.638, tt:8533.929\n",
      "Ep:210, loss:0.00000, loss_test:0.01047, lr:1.47e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.598, tt:8566.105\n",
      "Ep:211, loss:0.00000, loss_test:0.01048, lr:1.45e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.559, tt:8598.581\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13791, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.121, tt:42.121\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13500, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.257, tt:84.514\n",
      "Ep:2, loss:0.00027, loss_test:0.12952, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:42.188, tt:126.565\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11937, lr:1.00e-02, fs:0.68148 (r=0.929,p=0.538),  time:41.726, tt:166.906\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.10787, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:41.525, tt:207.624\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.10575, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:41.521, tt:249.123\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10636, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:42.000, tt:293.998\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10671, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:41.894, tt:335.155\n",
      "Ep:8, loss:0.00021, loss_test:0.09887, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:41.887, tt:376.986\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09479, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:41.903, tt:419.032\n",
      "Ep:10, loss:0.00020, loss_test:0.09451, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:42.082, tt:462.907\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09327, lr:1.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:41.987, tt:503.844\n",
      "Ep:12, loss:0.00019, loss_test:0.08743, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:42.178, tt:548.311\n",
      "Ep:13, loss:0.00018, loss_test:0.08503, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:42.068, tt:588.954\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08444, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:42.139, tt:632.078\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08062, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:42.095, tt:673.513\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.07999, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:42.138, tt:716.342\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.07826, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:42.162, tt:758.907\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07539, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:42.164, tt:801.114\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.07588, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:42.134, tt:842.671\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07149, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.232, tt:886.867\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07236, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:42.226, tt:928.982\n",
      "Ep:22, loss:0.00013, loss_test:0.06831, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:42.266, tt:972.125\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.06943, lr:1.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:42.294, tt:1015.045\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.06694, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:42.191, tt:1054.787\n",
      "Ep:25, loss:0.00012, loss_test:0.06818, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:42.223, tt:1097.785\n",
      "Ep:26, loss:0.00011, loss_test:0.06452, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:42.154, tt:1138.156\n",
      "Ep:27, loss:0.00011, loss_test:0.06536, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:42.118, tt:1179.308\n",
      "Ep:28, loss:0.00010, loss_test:0.06304, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:42.111, tt:1221.215\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.06146, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:42.132, tt:1263.946\n",
      "Ep:30, loss:0.00009, loss_test:0.06078, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:42.126, tt:1305.905\n",
      "Ep:31, loss:0.00009, loss_test:0.06075, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:42.100, tt:1347.197\n",
      "Ep:32, loss:0.00009, loss_test:0.06044, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:42.084, tt:1388.771\n",
      "Ep:33, loss:0.00008, loss_test:0.05814, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:42.115, tt:1431.899\n",
      "Ep:34, loss:0.00008, loss_test:0.05850, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:42.117, tt:1474.099\n",
      "Ep:35, loss:0.00008, loss_test:0.05808, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:42.052, tt:1513.871\n",
      "Ep:36, loss:0.00007, loss_test:0.05729, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:42.053, tt:1555.947\n",
      "Ep:37, loss:0.00007, loss_test:0.06190, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:42.068, tt:1598.572\n",
      "Ep:38, loss:0.00008, loss_test:0.05699, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:42.102, tt:1641.983\n",
      "Ep:39, loss:0.00007, loss_test:0.05668, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:42.127, tt:1685.094\n",
      "Ep:40, loss:0.00007, loss_test:0.05556, lr:9.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:42.131, tt:1727.372\n",
      "Ep:41, loss:0.00006, loss_test:0.05487, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:42.121, tt:1769.079\n",
      "Ep:42, loss:0.00006, loss_test:0.05635, lr:9.70e-03, fs:0.86735 (r=0.859,p=0.876),  time:42.132, tt:1811.663\n",
      "Ep:43, loss:0.00006, loss_test:0.05520, lr:9.61e-03, fs:0.88649 (r=0.828,p=0.953),  time:42.113, tt:1852.955\n",
      "Ep:44, loss:0.00006, loss_test:0.05391, lr:9.51e-03, fs:0.87958 (r=0.848,p=0.913),  time:42.092, tt:1894.156\n",
      "Ep:45, loss:0.00005, loss_test:0.05336, lr:9.41e-03, fs:0.87701 (r=0.828,p=0.932),  time:42.048, tt:1934.193\n",
      "Ep:46, loss:0.00005, loss_test:0.05539, lr:9.32e-03, fs:0.87234 (r=0.828,p=0.921),  time:42.020, tt:1974.936\n",
      "Ep:47, loss:0.00005, loss_test:0.05354, lr:9.23e-03, fs:0.87701 (r=0.828,p=0.932),  time:41.979, tt:2015.009\n",
      "Ep:48, loss:0.00005, loss_test:0.05443, lr:9.14e-03, fs:0.86813 (r=0.798,p=0.952),  time:41.955, tt:2055.808\n",
      "Ep:49, loss:0.00004, loss_test:0.05311, lr:9.04e-03, fs:0.85561 (r=0.808,p=0.909),  time:41.947, tt:2097.328\n",
      "Ep:50, loss:0.00004, loss_test:0.05375, lr:8.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.976, tt:2140.752\n",
      "Ep:51, loss:0.00004, loss_test:0.05260, lr:8.86e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.021, tt:2185.107\n",
      "Ep:52, loss:0.00004, loss_test:0.05242, lr:8.78e-03, fs:0.86486 (r=0.808,p=0.930),  time:42.016, tt:2226.836\n",
      "Ep:53, loss:0.00004, loss_test:0.05339, lr:8.69e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.026, tt:2269.408\n",
      "Ep:54, loss:0.00004, loss_test:0.05338, lr:8.60e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.056, tt:2313.084\n",
      "Ep:55, loss:0.00003, loss_test:0.05358, lr:8.51e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.084, tt:2356.726\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00003, loss_test:0.05231, lr:8.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:42.132, tt:2401.522\n",
      "Ep:57, loss:0.00003, loss_test:0.05108, lr:8.51e-03, fs:0.88525 (r=0.818,p=0.964),  time:42.146, tt:2444.460\n",
      "Ep:58, loss:0.00003, loss_test:0.05287, lr:8.51e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.157, tt:2487.265\n",
      "Ep:59, loss:0.00003, loss_test:0.05189, lr:8.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:42.176, tt:2530.565\n",
      "Ep:60, loss:0.00003, loss_test:0.05059, lr:8.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:42.186, tt:2573.342\n",
      "Ep:61, loss:0.00002, loss_test:0.05140, lr:8.51e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.191, tt:2615.841\n",
      "Ep:62, loss:0.00002, loss_test:0.04988, lr:8.51e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.238, tt:2660.968\n",
      "Ep:63, loss:0.00002, loss_test:0.05242, lr:8.51e-03, fs:0.88764 (r=0.798,p=1.000),  time:42.261, tt:2704.727\n",
      "Ep:64, loss:0.00002, loss_test:0.04998, lr:8.51e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.256, tt:2746.647\n",
      "Ep:65, loss:0.00002, loss_test:0.05120, lr:8.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.243, tt:2788.007\n",
      "Ep:66, loss:0.00002, loss_test:0.05403, lr:8.51e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.252, tt:2830.914\n",
      "Ep:67, loss:0.00002, loss_test:0.04892, lr:8.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:42.287, tt:2875.549\n",
      "Ep:68, loss:0.00002, loss_test:0.05147, lr:8.35e-03, fs:0.88136 (r=0.788,p=1.000),  time:42.296, tt:2918.452\n",
      "Ep:69, loss:0.00002, loss_test:0.05116, lr:8.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.275, tt:2959.216\n",
      "Ep:70, loss:0.00002, loss_test:0.05028, lr:8.18e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.273, tt:3001.371\n",
      "Ep:71, loss:0.00002, loss_test:0.05117, lr:8.10e-03, fs:0.88764 (r=0.798,p=1.000),  time:42.302, tt:3045.742\n",
      "Ep:72, loss:0.00001, loss_test:0.05391, lr:8.02e-03, fs:0.88136 (r=0.788,p=1.000),  time:42.321, tt:3089.453\n",
      "Ep:73, loss:0.00001, loss_test:0.04915, lr:7.94e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.341, tt:3133.211\n",
      "Ep:74, loss:0.00001, loss_test:0.04962, lr:7.86e-03, fs:0.87293 (r=0.798,p=0.963),  time:42.336, tt:3175.187\n",
      "Ep:75, loss:0.00001, loss_test:0.04970, lr:7.78e-03, fs:0.87778 (r=0.798,p=0.975),  time:42.337, tt:3217.629\n",
      "Ep:76, loss:0.00001, loss_test:0.05016, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.321, tt:3258.723\n",
      "Ep:77, loss:0.00001, loss_test:0.05003, lr:7.62e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.346, tt:3302.986\n",
      "Ep:78, loss:0.00001, loss_test:0.05105, lr:7.55e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.350, tt:3345.623\n",
      "Ep:79, loss:0.00001, loss_test:0.04939, lr:7.47e-03, fs:0.87778 (r=0.798,p=0.975),  time:42.349, tt:3387.898\n",
      "Ep:80, loss:0.00001, loss_test:0.04858, lr:7.40e-03, fs:0.87912 (r=0.808,p=0.964),  time:42.341, tt:3429.617\n",
      "Ep:81, loss:0.00001, loss_test:0.04935, lr:7.32e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.324, tt:3470.545\n",
      "Ep:82, loss:0.00001, loss_test:0.04912, lr:7.25e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.321, tt:3512.632\n",
      "Ep:83, loss:0.00001, loss_test:0.04793, lr:7.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.292, tt:3552.539\n",
      "Ep:84, loss:0.00001, loss_test:0.04867, lr:7.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.292, tt:3594.838\n",
      "Ep:85, loss:0.00001, loss_test:0.05061, lr:7.03e-03, fs:0.87778 (r=0.798,p=0.975),  time:42.293, tt:3637.229\n",
      "Ep:86, loss:0.00001, loss_test:0.04847, lr:6.96e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.275, tt:3677.916\n",
      "Ep:87, loss:0.00001, loss_test:0.04902, lr:6.89e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.251, tt:3718.124\n",
      "Ep:88, loss:0.00001, loss_test:0.04812, lr:6.83e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.239, tt:3759.284\n",
      "Ep:89, loss:0.00001, loss_test:0.04900, lr:6.76e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.218, tt:3799.610\n",
      "Ep:90, loss:0.00001, loss_test:0.05008, lr:6.69e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.212, tt:3841.337\n",
      "Ep:91, loss:0.00001, loss_test:0.04944, lr:6.62e-03, fs:0.87293 (r=0.798,p=0.963),  time:42.213, tt:3883.585\n",
      "Ep:92, loss:0.00001, loss_test:0.05041, lr:6.56e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.194, tt:3924.083\n",
      "Ep:93, loss:0.00001, loss_test:0.04898, lr:6.49e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.192, tt:3966.059\n",
      "Ep:94, loss:0.00001, loss_test:0.04883, lr:6.43e-03, fs:0.87778 (r=0.798,p=0.975),  time:42.201, tt:4009.058\n",
      "Ep:95, loss:0.00001, loss_test:0.04872, lr:6.36e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.191, tt:4050.330\n",
      "Ep:96, loss:0.00001, loss_test:0.04877, lr:6.30e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.180, tt:4091.427\n",
      "Ep:97, loss:0.00001, loss_test:0.04950, lr:6.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.172, tt:4132.821\n",
      "Ep:98, loss:0.00001, loss_test:0.04853, lr:6.17e-03, fs:0.87778 (r=0.798,p=0.975),  time:42.185, tt:4176.288\n",
      "Ep:99, loss:0.00001, loss_test:0.04924, lr:6.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.190, tt:4218.955\n",
      "Ep:100, loss:0.00001, loss_test:0.04763, lr:6.05e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.205, tt:4262.697\n",
      "Ep:101, loss:0.00000, loss_test:0.04896, lr:5.99e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.204, tt:4304.810\n",
      "Ep:102, loss:0.00000, loss_test:0.04896, lr:5.93e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.186, tt:4345.121\n",
      "Ep:103, loss:0.00000, loss_test:0.04885, lr:5.87e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.209, tt:4389.760\n",
      "Ep:104, loss:0.00000, loss_test:0.04880, lr:5.81e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.213, tt:4432.403\n",
      "Ep:105, loss:0.00000, loss_test:0.04855, lr:5.75e-03, fs:0.87778 (r=0.798,p=0.975),  time:42.193, tt:4472.507\n",
      "Ep:106, loss:0.00000, loss_test:0.04885, lr:5.70e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.180, tt:4513.282\n",
      "Ep:107, loss:0.00000, loss_test:0.04808, lr:5.64e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.166, tt:4553.893\n",
      "Ep:108, loss:0.00000, loss_test:0.04803, lr:5.58e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.153, tt:4594.681\n",
      "Ep:109, loss:0.00000, loss_test:0.04806, lr:5.53e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.133, tt:4634.579\n",
      "Ep:110, loss:0.00000, loss_test:0.04878, lr:5.47e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.124, tt:4675.718\n",
      "Ep:111, loss:0.00000, loss_test:0.04823, lr:5.42e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.103, tt:4715.586\n",
      "Ep:112, loss:0.00000, loss_test:0.04883, lr:5.36e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.077, tt:4754.649\n",
      "Ep:113, loss:0.00000, loss_test:0.04825, lr:5.31e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.069, tt:4795.819\n",
      "Ep:114, loss:0.00000, loss_test:0.04929, lr:5.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.055, tt:4836.325\n",
      "Ep:115, loss:0.00000, loss_test:0.04902, lr:5.20e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.051, tt:4877.876\n",
      "Ep:116, loss:0.00000, loss_test:0.04859, lr:5.15e-03, fs:0.88268 (r=0.798,p=0.988),  time:42.043, tt:4918.985\n",
      "Ep:117, loss:0.00000, loss_test:0.04948, lr:5.10e-03, fs:0.87640 (r=0.788,p=0.987),  time:42.035, tt:4960.104\n",
      "Ep:118, loss:0.00000, loss_test:0.04872, lr:5.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.995, tt:4997.421\n",
      "Ep:119, loss:0.00000, loss_test:0.04920, lr:5.00e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.985, tt:5038.149\n",
      "Ep:120, loss:0.00000, loss_test:0.04794, lr:4.95e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.963, tt:5077.505\n",
      "Ep:121, loss:0.00000, loss_test:0.04940, lr:4.90e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.944, tt:5117.184\n",
      "Ep:122, loss:0.00000, loss_test:0.04937, lr:4.85e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.941, tt:5158.727\n",
      "Ep:123, loss:0.00000, loss_test:0.04885, lr:4.80e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.928, tt:5199.134\n",
      "Ep:124, loss:0.00000, loss_test:0.04955, lr:4.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.951, tt:5243.838\n",
      "Ep:125, loss:0.00000, loss_test:0.04946, lr:4.71e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.944, tt:5284.894\n",
      "Ep:126, loss:0.00000, loss_test:0.04853, lr:4.66e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.932, tt:5325.405\n",
      "Ep:127, loss:0.00000, loss_test:0.04917, lr:4.61e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.915, tt:5365.167\n",
      "Ep:128, loss:0.00000, loss_test:0.04896, lr:4.57e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.905, tt:5405.690\n",
      "Ep:129, loss:0.00000, loss_test:0.04913, lr:4.52e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.915, tt:5448.972\n",
      "Ep:130, loss:0.00000, loss_test:0.04897, lr:4.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.916, tt:5491.055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.04865, lr:4.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.919, tt:5533.365\n",
      "Ep:132, loss:0.00000, loss_test:0.04890, lr:4.39e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.919, tt:5575.243\n",
      "Ep:133, loss:0.00000, loss_test:0.04861, lr:4.34e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.910, tt:5615.897\n",
      "Ep:134, loss:0.00000, loss_test:0.04923, lr:4.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.889, tt:5655.056\n",
      "Ep:135, loss:0.00000, loss_test:0.04848, lr:4.26e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.877, tt:5695.222\n",
      "Ep:136, loss:0.00000, loss_test:0.04926, lr:4.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.863, tt:5735.285\n",
      "Ep:137, loss:0.00000, loss_test:0.04967, lr:4.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.819, tt:5771.057\n",
      "Ep:138, loss:0.00000, loss_test:0.04821, lr:4.13e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.809, tt:5811.402\n",
      "Ep:139, loss:0.00000, loss_test:0.04978, lr:4.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.802, tt:5852.258\n",
      "Ep:140, loss:0.00000, loss_test:0.05038, lr:4.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.793, tt:5892.781\n",
      "Ep:141, loss:0.00000, loss_test:0.04893, lr:4.01e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.779, tt:5932.597\n",
      "Ep:142, loss:0.00000, loss_test:0.04974, lr:3.97e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.773, tt:5973.521\n",
      "Ep:143, loss:0.00000, loss_test:0.05018, lr:3.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.748, tt:6011.759\n",
      "Ep:144, loss:0.00000, loss_test:0.04868, lr:3.89e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.777, tt:6057.630\n",
      "Ep:145, loss:0.00000, loss_test:0.04934, lr:3.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.764, tt:6097.519\n",
      "Ep:146, loss:0.00000, loss_test:0.04979, lr:3.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.747, tt:6136.824\n",
      "Ep:147, loss:0.00000, loss_test:0.04861, lr:3.77e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.746, tt:6178.443\n",
      "Ep:148, loss:0.00000, loss_test:0.04943, lr:3.73e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.723, tt:6216.762\n",
      "Ep:149, loss:0.00000, loss_test:0.05003, lr:3.70e-03, fs:0.88136 (r=0.788,p=1.000),  time:41.725, tt:6258.817\n",
      "Ep:150, loss:0.00000, loss_test:0.04884, lr:3.66e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.728, tt:6300.936\n",
      "Ep:151, loss:0.00000, loss_test:0.04919, lr:3.62e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.714, tt:6340.579\n",
      "Ep:152, loss:0.00000, loss_test:0.04965, lr:3.59e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.718, tt:6382.926\n",
      "Ep:153, loss:0.00000, loss_test:0.04875, lr:3.55e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.727, tt:6426.006\n",
      "Ep:154, loss:0.00000, loss_test:0.04934, lr:3.52e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.727, tt:6467.694\n",
      "Ep:155, loss:0.00000, loss_test:0.04958, lr:3.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.717, tt:6507.893\n",
      "Ep:156, loss:0.00000, loss_test:0.04908, lr:3.45e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.708, tt:6548.196\n",
      "Ep:157, loss:0.00000, loss_test:0.04926, lr:3.41e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.702, tt:6588.886\n",
      "Ep:158, loss:0.00000, loss_test:0.04925, lr:3.38e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.700, tt:6630.274\n",
      "Ep:159, loss:0.00000, loss_test:0.04864, lr:3.34e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.692, tt:6670.678\n",
      "Ep:160, loss:0.00000, loss_test:0.04927, lr:3.31e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.679, tt:6710.313\n",
      "Ep:161, loss:0.00000, loss_test:0.04889, lr:3.28e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.657, tt:6748.473\n",
      "Ep:162, loss:0.00000, loss_test:0.04873, lr:3.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.637, tt:6786.880\n",
      "Ep:163, loss:0.00000, loss_test:0.04905, lr:3.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.636, tt:6828.348\n",
      "Ep:164, loss:0.00000, loss_test:0.04876, lr:3.18e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.637, tt:6870.037\n",
      "Ep:165, loss:0.00000, loss_test:0.04918, lr:3.15e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.640, tt:6912.305\n",
      "Ep:166, loss:0.00000, loss_test:0.04920, lr:3.12e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.636, tt:6953.148\n",
      "Ep:167, loss:0.00000, loss_test:0.04919, lr:3.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.634, tt:6994.449\n",
      "Ep:168, loss:0.00000, loss_test:0.04920, lr:3.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.633, tt:7035.915\n",
      "Ep:169, loss:0.00000, loss_test:0.04890, lr:3.02e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.630, tt:7077.121\n",
      "Ep:170, loss:0.00000, loss_test:0.04873, lr:2.99e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.623, tt:7117.597\n",
      "Ep:171, loss:0.00000, loss_test:0.04910, lr:2.96e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.632, tt:7160.784\n",
      "Ep:172, loss:0.00000, loss_test:0.04900, lr:2.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.634, tt:7202.735\n",
      "Ep:173, loss:0.00000, loss_test:0.04899, lr:2.90e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.612, tt:7240.499\n",
      "Ep:174, loss:0.00000, loss_test:0.04915, lr:2.88e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.600, tt:7280.074\n",
      "Ep:175, loss:0.00000, loss_test:0.04927, lr:2.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.601, tt:7321.749\n",
      "Ep:176, loss:0.00000, loss_test:0.04906, lr:2.82e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.596, tt:7362.432\n",
      "Ep:177, loss:0.00000, loss_test:0.04880, lr:2.79e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.605, tt:7405.685\n",
      "Ep:178, loss:0.00000, loss_test:0.04930, lr:2.76e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.606, tt:7447.492\n",
      "Ep:179, loss:0.00000, loss_test:0.04972, lr:2.73e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.599, tt:7487.896\n",
      "Ep:180, loss:0.00000, loss_test:0.04921, lr:2.71e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.597, tt:7528.992\n",
      "Ep:181, loss:0.00000, loss_test:0.04924, lr:2.68e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.613, tt:7573.536\n",
      "Ep:182, loss:0.00000, loss_test:0.04948, lr:2.65e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.621, tt:7616.707\n",
      "Ep:183, loss:0.00000, loss_test:0.04893, lr:2.63e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.626, tt:7659.158\n",
      "Ep:184, loss:0.00000, loss_test:0.04878, lr:2.60e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.637, tt:7702.917\n",
      "Ep:185, loss:0.00000, loss_test:0.04891, lr:2.57e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.643, tt:7745.652\n",
      "Ep:186, loss:0.00000, loss_test:0.04902, lr:2.55e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.633, tt:7785.347\n",
      "Ep:187, loss:0.00000, loss_test:0.04875, lr:2.52e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.633, tt:7827.053\n",
      "Ep:188, loss:0.00000, loss_test:0.04925, lr:2.50e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.632, tt:7868.489\n",
      "Ep:189, loss:0.00000, loss_test:0.04914, lr:2.47e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.633, tt:7910.189\n",
      "Ep:190, loss:0.00000, loss_test:0.04882, lr:2.45e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.631, tt:7951.440\n",
      "Ep:191, loss:0.00000, loss_test:0.04906, lr:2.42e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.631, tt:7993.163\n",
      "Ep:192, loss:0.00000, loss_test:0.04928, lr:2.40e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.636, tt:8035.694\n",
      "Ep:193, loss:0.00000, loss_test:0.04907, lr:2.38e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.651, tt:8080.198\n",
      "Ep:194, loss:0.00000, loss_test:0.04904, lr:2.35e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.651, tt:8121.936\n",
      "Ep:195, loss:0.00000, loss_test:0.04886, lr:2.33e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.657, tt:8164.712\n",
      "Ep:196, loss:0.00000, loss_test:0.04883, lr:2.31e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.653, tt:8205.683\n",
      "Ep:197, loss:0.00000, loss_test:0.04899, lr:2.28e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.656, tt:8247.925\n",
      "Ep:198, loss:0.00000, loss_test:0.04908, lr:2.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.640, tt:8286.385\n",
      "Ep:199, loss:0.00000, loss_test:0.04890, lr:2.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.649, tt:8329.783\n",
      "Ep:200, loss:0.00000, loss_test:0.04904, lr:2.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.654, tt:8372.406\n",
      "Ep:201, loss:0.00000, loss_test:0.04892, lr:2.19e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.647, tt:8412.649\n",
      "Ep:202, loss:0.00000, loss_test:0.04884, lr:2.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.647, tt:8454.438\n",
      "Ep:203, loss:0.00000, loss_test:0.04885, lr:2.15e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.633, tt:8493.110\n",
      "Ep:204, loss:0.00000, loss_test:0.04926, lr:2.13e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.636, tt:8535.322\n",
      "Ep:205, loss:0.00000, loss_test:0.04905, lr:2.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.635, tt:8576.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.04917, lr:2.08e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.641, tt:8619.599\n",
      "Ep:207, loss:0.00000, loss_test:0.04956, lr:2.06e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.601, tt:8652.976\n",
      "Ep:208, loss:0.00000, loss_test:0.04945, lr:2.04e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.549, tt:8683.746\n",
      "Ep:209, loss:0.00000, loss_test:0.04899, lr:2.02e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.466, tt:8707.893\n",
      "Ep:210, loss:0.00000, loss_test:0.04917, lr:2.00e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.360, tt:8726.969\n",
      "Ep:211, loss:0.00000, loss_test:0.04941, lr:1.98e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.229, tt:8740.475\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02072, lr:6.00e-02, fs:0.61925 (r=0.851,p=0.487),  time:40.176, tt:40.176\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02298, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.079, tt:80.157\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02343, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.000, tt:120.001\n",
      "Ep:3, loss:0.00005, loss_test:0.02256, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.683, tt:158.733\n",
      "Ep:4, loss:0.00004, loss_test:0.02107, lr:6.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:39.882, tt:199.412\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01973, lr:6.00e-02, fs:0.63866 (r=0.874,p=0.503),  time:39.971, tt:239.823\n",
      "Ep:6, loss:0.00004, loss_test:0.01946, lr:6.00e-02, fs:0.66029 (r=0.793,p=0.566),  time:39.440, tt:276.078\n",
      "Ep:7, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.64975 (r=0.736,p=0.582),  time:39.996, tt:319.965\n",
      "Ep:8, loss:0.00004, loss_test:0.01928, lr:6.00e-02, fs:0.66346 (r=0.793,p=0.570),  time:40.028, tt:360.252\n",
      "Ep:9, loss:0.00003, loss_test:0.01930, lr:6.00e-02, fs:0.66359 (r=0.828,p=0.554),  time:40.150, tt:401.499\n",
      "Ep:10, loss:0.00003, loss_test:0.01933, lr:6.00e-02, fs:0.67890 (r=0.851,p=0.565),  time:39.939, tt:439.326\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01942, lr:6.00e-02, fs:0.68627 (r=0.805,p=0.598),  time:39.807, tt:477.688\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01959, lr:6.00e-02, fs:0.69430 (r=0.770,p=0.632),  time:39.845, tt:517.987\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01955, lr:6.00e-02, fs:0.70899 (r=0.770,p=0.657),  time:39.718, tt:556.045\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01911, lr:6.00e-02, fs:0.71204 (r=0.782,p=0.654),  time:39.586, tt:593.797\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01868, lr:6.00e-02, fs:0.72917 (r=0.805,p=0.667),  time:39.449, tt:631.185\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01847, lr:6.00e-02, fs:0.73298 (r=0.805,p=0.673),  time:39.302, tt:668.141\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01851, lr:6.00e-02, fs:0.74468 (r=0.805,p=0.693),  time:39.279, tt:707.031\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01867, lr:6.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:39.297, tt:746.651\n",
      "Ep:19, loss:0.00002, loss_test:0.01881, lr:6.00e-02, fs:0.75000 (r=0.793,p=0.711),  time:39.302, tt:786.039\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01880, lr:6.00e-02, fs:0.77596 (r=0.816,p=0.740),  time:39.479, tt:829.050\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01863, lr:6.00e-02, fs:0.76923 (r=0.805,p=0.737),  time:39.518, tt:869.398\n",
      "Ep:22, loss:0.00002, loss_test:0.01854, lr:6.00e-02, fs:0.77778 (r=0.805,p=0.753),  time:39.555, tt:909.757\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01846, lr:6.00e-02, fs:0.77778 (r=0.805,p=0.753),  time:39.540, tt:948.958\n",
      "Ep:24, loss:0.00002, loss_test:0.01841, lr:6.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:39.442, tt:986.059\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01854, lr:6.00e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.443, tt:1025.526\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01881, lr:6.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:39.393, tt:1063.604\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01881, lr:6.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:39.339, tt:1101.485\n",
      "Ep:28, loss:0.00002, loss_test:0.01878, lr:6.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:39.360, tt:1141.453\n",
      "Ep:29, loss:0.00002, loss_test:0.01885, lr:6.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:39.300, tt:1179.001\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01921, lr:6.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:39.226, tt:1216.019\n",
      "Ep:31, loss:0.00002, loss_test:0.01957, lr:6.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:39.260, tt:1256.332\n",
      "Ep:32, loss:0.00002, loss_test:0.01990, lr:6.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:39.237, tt:1294.835\n",
      "Ep:33, loss:0.00002, loss_test:0.02008, lr:6.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:39.279, tt:1335.473\n",
      "Ep:34, loss:0.00001, loss_test:0.02005, lr:6.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:39.235, tt:1373.231\n",
      "Ep:35, loss:0.00001, loss_test:0.02022, lr:6.00e-02, fs:0.76433 (r=0.690,p=0.857),  time:39.245, tt:1412.838\n",
      "Ep:36, loss:0.00001, loss_test:0.02058, lr:6.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:39.259, tt:1452.597\n",
      "Ep:37, loss:0.00001, loss_test:0.02090, lr:6.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:39.237, tt:1491.001\n",
      "Ep:38, loss:0.00001, loss_test:0.02097, lr:6.00e-02, fs:0.76623 (r=0.678,p=0.881),  time:39.191, tt:1528.467\n",
      "Ep:39, loss:0.00001, loss_test:0.02139, lr:6.00e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.184, tt:1567.360\n",
      "Ep:40, loss:0.00001, loss_test:0.02164, lr:6.00e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.151, tt:1605.171\n",
      "Ep:41, loss:0.00001, loss_test:0.02188, lr:5.94e-02, fs:0.74830 (r=0.632,p=0.917),  time:39.167, tt:1645.032\n",
      "Ep:42, loss:0.00001, loss_test:0.02216, lr:5.88e-02, fs:0.74830 (r=0.632,p=0.917),  time:39.138, tt:1682.930\n",
      "Ep:43, loss:0.00001, loss_test:0.02244, lr:5.82e-02, fs:0.74830 (r=0.632,p=0.917),  time:39.111, tt:1720.901\n",
      "Ep:44, loss:0.00001, loss_test:0.02264, lr:5.76e-02, fs:0.74830 (r=0.632,p=0.917),  time:39.153, tt:1761.892\n",
      "Ep:45, loss:0.00001, loss_test:0.02285, lr:5.71e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.163, tt:1801.498\n",
      "Ep:46, loss:0.00001, loss_test:0.02309, lr:5.65e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.189, tt:1841.887\n",
      "Ep:47, loss:0.00001, loss_test:0.02299, lr:5.59e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.168, tt:1880.050\n",
      "Ep:48, loss:0.00001, loss_test:0.02338, lr:5.54e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.154, tt:1918.539\n",
      "Ep:49, loss:0.00001, loss_test:0.02396, lr:5.48e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.174, tt:1958.696\n",
      "Ep:50, loss:0.00001, loss_test:0.02408, lr:5.43e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.240, tt:2001.234\n",
      "Ep:51, loss:0.00001, loss_test:0.02416, lr:5.37e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.217, tt:2039.285\n",
      "Ep:52, loss:0.00001, loss_test:0.02456, lr:5.32e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.222, tt:2078.784\n",
      "Ep:53, loss:0.00001, loss_test:0.02449, lr:5.27e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.228, tt:2118.327\n",
      "Ep:54, loss:0.00001, loss_test:0.02463, lr:5.21e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.235, tt:2157.918\n",
      "Ep:55, loss:0.00001, loss_test:0.02526, lr:5.16e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.245, tt:2197.726\n",
      "Ep:56, loss:0.00001, loss_test:0.02542, lr:5.11e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.273, tt:2238.553\n",
      "Ep:57, loss:0.00001, loss_test:0.02553, lr:5.06e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.286, tt:2278.569\n",
      "Ep:58, loss:0.00001, loss_test:0.02573, lr:5.01e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.315, tt:2319.592\n",
      "Ep:59, loss:0.00001, loss_test:0.02592, lr:4.96e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.346, tt:2360.756\n",
      "Ep:60, loss:0.00001, loss_test:0.02621, lr:4.91e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.353, tt:2400.529\n",
      "Ep:61, loss:0.00001, loss_test:0.02623, lr:4.86e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.354, tt:2439.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.02653, lr:4.81e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.390, tt:2481.590\n",
      "Ep:63, loss:0.00001, loss_test:0.02683, lr:4.76e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.395, tt:2521.289\n",
      "Ep:64, loss:0.00001, loss_test:0.02694, lr:4.71e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.429, tt:2562.883\n",
      "Ep:65, loss:0.00001, loss_test:0.02722, lr:4.67e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.454, tt:2603.950\n",
      "Ep:66, loss:0.00001, loss_test:0.02741, lr:4.62e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.469, tt:2644.449\n",
      "Ep:67, loss:0.00000, loss_test:0.02759, lr:4.57e-02, fs:0.74483 (r=0.621,p=0.931),  time:39.620, tt:2694.163\n",
      "Ep:68, loss:0.00000, loss_test:0.02773, lr:4.53e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.627, tt:2734.263\n",
      "Ep:69, loss:0.00000, loss_test:0.02806, lr:4.48e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.636, tt:2774.494\n",
      "Ep:70, loss:0.00000, loss_test:0.02828, lr:4.44e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.617, tt:2812.804\n",
      "Ep:71, loss:0.00000, loss_test:0.02840, lr:4.39e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.640, tt:2854.099\n",
      "Ep:72, loss:0.00000, loss_test:0.02860, lr:4.35e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.665, tt:2895.535\n",
      "Ep:73, loss:0.00000, loss_test:0.02891, lr:4.31e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.663, tt:2935.041\n",
      "Ep:74, loss:0.00000, loss_test:0.02919, lr:4.26e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.671, tt:2975.345\n",
      "Ep:75, loss:0.00000, loss_test:0.02939, lr:4.22e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.681, tt:3015.778\n",
      "Ep:76, loss:0.00000, loss_test:0.02958, lr:4.18e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.674, tt:3054.923\n",
      "Ep:77, loss:0.00000, loss_test:0.02980, lr:4.14e-02, fs:0.75000 (r=0.621,p=0.947),  time:39.698, tt:3096.442\n",
      "Ep:78, loss:0.00000, loss_test:0.02988, lr:4.10e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.680, tt:3134.698\n",
      "Ep:79, loss:0.00000, loss_test:0.03021, lr:4.05e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.663, tt:3173.050\n",
      "Ep:80, loss:0.00000, loss_test:0.03035, lr:4.01e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.659, tt:3212.370\n",
      "Ep:81, loss:0.00000, loss_test:0.03065, lr:3.97e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.671, tt:3252.988\n",
      "Ep:82, loss:0.00000, loss_test:0.03084, lr:3.93e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.648, tt:3290.794\n",
      "Ep:83, loss:0.00000, loss_test:0.03092, lr:3.89e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.602, tt:3326.550\n",
      "Ep:84, loss:0.00000, loss_test:0.03121, lr:3.86e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.576, tt:3364.002\n",
      "Ep:85, loss:0.00000, loss_test:0.03130, lr:3.82e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.573, tt:3403.249\n",
      "Ep:86, loss:0.00000, loss_test:0.03124, lr:3.78e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.585, tt:3443.887\n",
      "Ep:87, loss:0.00000, loss_test:0.03149, lr:3.74e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.582, tt:3483.198\n",
      "Ep:88, loss:0.00000, loss_test:0.03166, lr:3.70e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.598, tt:3524.252\n",
      "Ep:89, loss:0.00000, loss_test:0.03179, lr:3.67e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.656, tt:3569.015\n",
      "Ep:90, loss:0.00000, loss_test:0.03198, lr:3.63e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.669, tt:3609.924\n",
      "Ep:91, loss:0.00000, loss_test:0.03213, lr:3.59e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.670, tt:3649.671\n",
      "Ep:92, loss:0.00000, loss_test:0.03232, lr:3.56e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.699, tt:3692.053\n",
      "Ep:93, loss:0.00000, loss_test:0.03247, lr:3.52e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.726, tt:3734.276\n",
      "Ep:94, loss:0.00000, loss_test:0.03251, lr:3.49e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.725, tt:3773.875\n",
      "Ep:95, loss:0.00000, loss_test:0.03271, lr:3.45e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.746, tt:3815.614\n",
      "Ep:96, loss:0.00000, loss_test:0.03284, lr:3.42e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.760, tt:3856.742\n",
      "Ep:97, loss:0.00000, loss_test:0.03296, lr:3.38e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.760, tt:3896.464\n",
      "Ep:98, loss:0.00000, loss_test:0.03306, lr:3.35e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.769, tt:3937.088\n",
      "Ep:99, loss:0.00000, loss_test:0.03320, lr:3.32e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.785, tt:3978.527\n",
      "Ep:100, loss:0.00000, loss_test:0.03340, lr:3.28e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.799, tt:4019.742\n",
      "Ep:101, loss:0.00000, loss_test:0.03350, lr:3.25e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.809, tt:4060.481\n",
      "Ep:102, loss:0.00000, loss_test:0.03362, lr:3.22e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.813, tt:4100.712\n",
      "Ep:103, loss:0.00000, loss_test:0.03373, lr:3.19e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.822, tt:4141.494\n",
      "Ep:104, loss:0.00000, loss_test:0.03387, lr:3.15e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.826, tt:4181.765\n",
      "Ep:105, loss:0.00000, loss_test:0.03397, lr:3.12e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.827, tt:4221.640\n",
      "Ep:106, loss:0.00000, loss_test:0.03403, lr:3.09e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.843, tt:4263.175\n",
      "Ep:107, loss:0.00000, loss_test:0.03416, lr:3.06e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.859, tt:4304.815\n",
      "Ep:108, loss:0.00000, loss_test:0.03418, lr:3.03e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.853, tt:4344.001\n",
      "Ep:109, loss:0.00000, loss_test:0.03433, lr:3.00e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.852, tt:4383.733\n",
      "Ep:110, loss:0.00000, loss_test:0.03445, lr:2.97e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.882, tt:4426.850\n",
      "Ep:111, loss:0.00000, loss_test:0.03456, lr:2.94e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.884, tt:4466.956\n",
      "Ep:112, loss:0.00000, loss_test:0.03455, lr:2.91e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.902, tt:4508.919\n",
      "Ep:113, loss:0.00000, loss_test:0.03470, lr:2.88e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.911, tt:4549.881\n",
      "Ep:114, loss:0.00000, loss_test:0.03481, lr:2.85e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.911, tt:4589.747\n",
      "Ep:115, loss:0.00000, loss_test:0.03483, lr:2.82e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.910, tt:4629.602\n",
      "Ep:116, loss:0.00000, loss_test:0.03506, lr:2.80e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.902, tt:4668.477\n",
      "Ep:117, loss:0.00000, loss_test:0.03511, lr:2.77e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.900, tt:4708.192\n",
      "Ep:118, loss:0.00000, loss_test:0.03515, lr:2.74e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.905, tt:4748.670\n",
      "Ep:119, loss:0.00000, loss_test:0.03520, lr:2.71e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.916, tt:4789.905\n",
      "Ep:120, loss:0.00000, loss_test:0.03527, lr:2.69e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.921, tt:4830.471\n",
      "Ep:121, loss:0.00000, loss_test:0.03541, lr:2.66e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.928, tt:4871.161\n",
      "Ep:122, loss:0.00000, loss_test:0.03553, lr:2.63e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.932, tt:4911.591\n",
      "Ep:123, loss:0.00000, loss_test:0.03560, lr:2.61e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.923, tt:4950.494\n",
      "Ep:124, loss:0.00000, loss_test:0.03566, lr:2.58e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.930, tt:4991.200\n",
      "Ep:125, loss:0.00000, loss_test:0.03580, lr:2.55e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.942, tt:5032.705\n",
      "Ep:126, loss:0.00000, loss_test:0.03585, lr:2.53e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.935, tt:5071.761\n",
      "Ep:127, loss:0.00000, loss_test:0.03592, lr:2.50e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.942, tt:5112.628\n",
      "Ep:128, loss:0.00000, loss_test:0.03595, lr:2.48e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.958, tt:5154.568\n",
      "Ep:129, loss:0.00000, loss_test:0.03597, lr:2.45e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.966, tt:5195.524\n",
      "Ep:130, loss:0.00000, loss_test:0.03608, lr:2.43e-02, fs:0.76056 (r=0.621,p=0.982),  time:39.979, tt:5237.228\n",
      "Ep:131, loss:0.00000, loss_test:0.03608, lr:2.40e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.024, tt:5283.216\n",
      "Ep:132, loss:0.00000, loss_test:0.03617, lr:2.38e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.025, tt:5323.303\n",
      "Ep:133, loss:0.00000, loss_test:0.03624, lr:2.36e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.032, tt:5364.255\n",
      "Ep:134, loss:0.00000, loss_test:0.03630, lr:2.33e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.040, tt:5405.453\n",
      "Ep:135, loss:0.00000, loss_test:0.03635, lr:2.31e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.047, tt:5446.388\n",
      "Ep:136, loss:0.00000, loss_test:0.03637, lr:2.29e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.036, tt:5484.924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.03648, lr:2.26e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.028, tt:5523.919\n",
      "Ep:138, loss:0.00000, loss_test:0.03650, lr:2.24e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.030, tt:5564.199\n",
      "Ep:139, loss:0.00000, loss_test:0.03656, lr:2.22e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.026, tt:5603.687\n",
      "Ep:140, loss:0.00000, loss_test:0.03655, lr:2.20e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.019, tt:5642.695\n",
      "Ep:141, loss:0.00000, loss_test:0.03664, lr:2.17e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.021, tt:5683.000\n",
      "Ep:142, loss:0.00000, loss_test:0.03667, lr:2.15e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.025, tt:5723.548\n",
      "Ep:143, loss:0.00000, loss_test:0.03666, lr:2.13e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.038, tt:5765.423\n",
      "Ep:144, loss:0.00000, loss_test:0.03676, lr:2.11e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.043, tt:5806.166\n",
      "Ep:145, loss:0.00000, loss_test:0.03680, lr:2.09e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.064, tt:5849.384\n",
      "Ep:146, loss:0.00000, loss_test:0.03683, lr:2.07e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.085, tt:5892.495\n",
      "Ep:147, loss:0.00000, loss_test:0.03683, lr:2.05e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.112, tt:5936.595\n",
      "Ep:148, loss:0.00000, loss_test:0.03692, lr:2.03e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.159, tt:5983.734\n",
      "Ep:149, loss:0.00000, loss_test:0.03692, lr:2.01e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.181, tt:6027.153\n",
      "Ep:150, loss:0.00000, loss_test:0.03694, lr:1.99e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.189, tt:6068.604\n",
      "Ep:151, loss:0.00000, loss_test:0.03698, lr:1.97e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.197, tt:6109.994\n",
      "Ep:152, loss:0.00000, loss_test:0.03703, lr:1.95e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.238, tt:6156.429\n",
      "Ep:153, loss:0.00000, loss_test:0.03703, lr:1.93e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.259, tt:6199.908\n",
      "Ep:154, loss:0.00000, loss_test:0.03708, lr:1.91e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.272, tt:6242.236\n",
      "Ep:155, loss:0.00000, loss_test:0.03717, lr:1.89e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.281, tt:6283.789\n",
      "Ep:156, loss:0.00000, loss_test:0.03722, lr:1.87e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.281, tt:6324.150\n",
      "Ep:157, loss:0.00000, loss_test:0.03723, lr:1.85e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.270, tt:6362.636\n",
      "Ep:158, loss:0.00000, loss_test:0.03725, lr:1.83e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.273, tt:6403.467\n",
      "Ep:159, loss:0.00000, loss_test:0.03729, lr:1.81e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.286, tt:6445.704\n",
      "Ep:160, loss:0.00000, loss_test:0.03730, lr:1.80e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.287, tt:6486.156\n",
      "Ep:161, loss:0.00000, loss_test:0.03734, lr:1.78e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.297, tt:6528.142\n",
      "Ep:162, loss:0.00000, loss_test:0.03735, lr:1.76e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.310, tt:6570.609\n",
      "Ep:163, loss:0.00000, loss_test:0.03738, lr:1.74e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.313, tt:6611.412\n",
      "Ep:164, loss:0.00000, loss_test:0.03746, lr:1.73e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.326, tt:6653.736\n",
      "Ep:165, loss:0.00000, loss_test:0.03750, lr:1.71e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.329, tt:6694.656\n",
      "Ep:166, loss:0.00000, loss_test:0.03751, lr:1.69e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.335, tt:6735.905\n",
      "Ep:167, loss:0.00000, loss_test:0.03752, lr:1.67e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.326, tt:6774.828\n",
      "Ep:168, loss:0.00000, loss_test:0.03754, lr:1.66e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.326, tt:6815.107\n",
      "Ep:169, loss:0.00000, loss_test:0.03755, lr:1.64e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.328, tt:6855.799\n",
      "Ep:170, loss:0.00000, loss_test:0.03754, lr:1.62e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.335, tt:6897.207\n",
      "Ep:171, loss:0.00000, loss_test:0.03759, lr:1.61e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.330, tt:6936.778\n",
      "Ep:172, loss:0.00000, loss_test:0.03762, lr:1.59e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.326, tt:6976.456\n",
      "Ep:173, loss:0.00000, loss_test:0.03763, lr:1.58e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.329, tt:7017.276\n",
      "Ep:174, loss:0.00000, loss_test:0.03768, lr:1.56e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.329, tt:7057.631\n",
      "Ep:175, loss:0.00000, loss_test:0.03771, lr:1.54e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.337, tt:7099.367\n",
      "Ep:176, loss:0.00000, loss_test:0.03776, lr:1.53e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.335, tt:7139.252\n",
      "Ep:177, loss:0.00000, loss_test:0.03775, lr:1.51e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.329, tt:7178.626\n",
      "Ep:178, loss:0.00000, loss_test:0.03776, lr:1.50e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.324, tt:7217.953\n",
      "Ep:179, loss:0.00000, loss_test:0.03781, lr:1.48e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.329, tt:7259.236\n",
      "Ep:180, loss:0.00000, loss_test:0.03784, lr:1.47e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.334, tt:7300.542\n",
      "Ep:181, loss:0.00000, loss_test:0.03784, lr:1.45e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.337, tt:7341.309\n",
      "Ep:182, loss:0.00000, loss_test:0.03785, lr:1.44e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.332, tt:7380.733\n",
      "Ep:183, loss:0.00000, loss_test:0.03791, lr:1.43e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.331, tt:7420.866\n",
      "Ep:184, loss:0.00000, loss_test:0.03794, lr:1.41e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.330, tt:7461.064\n",
      "Ep:185, loss:0.00000, loss_test:0.03792, lr:1.40e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.331, tt:7501.474\n",
      "Ep:186, loss:0.00000, loss_test:0.03794, lr:1.38e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.342, tt:7543.979\n",
      "Ep:187, loss:0.00000, loss_test:0.03797, lr:1.37e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.343, tt:7584.554\n",
      "Ep:188, loss:0.00000, loss_test:0.03800, lr:1.36e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.344, tt:7624.961\n",
      "Ep:189, loss:0.00000, loss_test:0.03800, lr:1.34e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.334, tt:7663.458\n",
      "Ep:190, loss:0.00000, loss_test:0.03802, lr:1.33e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.324, tt:7701.941\n",
      "Ep:191, loss:0.00000, loss_test:0.03808, lr:1.32e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.310, tt:7739.472\n",
      "Ep:192, loss:0.00000, loss_test:0.03807, lr:1.30e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.316, tt:7781.057\n",
      "Ep:193, loss:0.00000, loss_test:0.03806, lr:1.29e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.317, tt:7821.543\n",
      "Ep:194, loss:0.00000, loss_test:0.03809, lr:1.28e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.334, tt:7865.114\n",
      "Ep:195, loss:0.00000, loss_test:0.03812, lr:1.26e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.331, tt:7904.833\n",
      "Ep:196, loss:0.00000, loss_test:0.03812, lr:1.25e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.327, tt:7944.500\n",
      "Ep:197, loss:0.00000, loss_test:0.03814, lr:1.24e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.326, tt:7984.487\n",
      "Ep:198, loss:0.00000, loss_test:0.03816, lr:1.23e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.317, tt:8023.130\n",
      "Ep:199, loss:0.00000, loss_test:0.03819, lr:1.21e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.317, tt:8063.360\n",
      "Ep:200, loss:0.00000, loss_test:0.03819, lr:1.20e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.308, tt:8101.939\n",
      "Ep:201, loss:0.00000, loss_test:0.03821, lr:1.19e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.303, tt:8141.139\n",
      "Ep:202, loss:0.00000, loss_test:0.03821, lr:1.18e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.318, tt:8184.618\n",
      "Ep:203, loss:0.00000, loss_test:0.03822, lr:1.17e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.305, tt:8222.228\n",
      "Ep:204, loss:0.00000, loss_test:0.03825, lr:1.15e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.308, tt:8263.059\n",
      "Ep:205, loss:0.00000, loss_test:0.03826, lr:1.14e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.315, tt:8304.982\n",
      "Ep:206, loss:0.00000, loss_test:0.03826, lr:1.13e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.324, tt:8347.086\n",
      "Ep:207, loss:0.00000, loss_test:0.03828, lr:1.12e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.302, tt:8382.910\n",
      "Ep:208, loss:0.00000, loss_test:0.03829, lr:1.11e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.265, tt:8415.376\n",
      "Ep:209, loss:0.00000, loss_test:0.03833, lr:1.10e-02, fs:0.76056 (r=0.621,p=0.982),  time:40.220, tt:8446.256\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14415, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.436, tt:42.436\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14300, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.390, tt:86.779\n",
      "Ep:2, loss:0.00028, loss_test:0.14090, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.844, tt:128.531\n",
      "Ep:3, loss:0.00027, loss_test:0.13726, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.595, tt:170.381\n",
      "Ep:4, loss:0.00026, loss_test:0.13087, lr:1.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:42.826, tt:214.132\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12012, lr:1.00e-02, fs:0.67241 (r=0.897,p=0.538),  time:42.889, tt:257.335\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11306, lr:1.00e-02, fs:0.68627 (r=0.805,p=0.598),  time:42.716, tt:299.014\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11329, lr:1.00e-02, fs:0.69388 (r=0.782,p=0.624),  time:42.911, tt:343.289\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11362, lr:1.00e-02, fs:0.67677 (r=0.770,p=0.604),  time:42.633, tt:383.701\n",
      "Ep:9, loss:0.00022, loss_test:0.11167, lr:1.00e-02, fs:0.67677 (r=0.770,p=0.604),  time:42.742, tt:427.419\n",
      "Ep:10, loss:0.00021, loss_test:0.10808, lr:1.00e-02, fs:0.67016 (r=0.736,p=0.615),  time:42.791, tt:470.702\n",
      "Ep:11, loss:0.00021, loss_test:0.10636, lr:1.00e-02, fs:0.67039 (r=0.690,p=0.652),  time:42.858, tt:514.293\n",
      "Ep:12, loss:0.00020, loss_test:0.10663, lr:1.00e-02, fs:0.70000 (r=0.724,p=0.677),  time:42.875, tt:557.377\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10572, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:43.001, tt:602.021\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10170, lr:1.00e-02, fs:0.72727 (r=0.690,p=0.769),  time:42.956, tt:644.336\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09926, lr:1.00e-02, fs:0.74534 (r=0.690,p=0.811),  time:42.824, tt:685.191\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09927, lr:1.00e-02, fs:0.74847 (r=0.701,p=0.803),  time:42.870, tt:728.796\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09920, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:42.914, tt:772.448\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09686, lr:1.00e-02, fs:0.75000 (r=0.690,p=0.822),  time:42.918, tt:815.451\n",
      "Ep:19, loss:0.00014, loss_test:0.09577, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:42.870, tt:857.407\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09452, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:42.828, tt:899.383\n",
      "Ep:21, loss:0.00013, loss_test:0.09383, lr:1.00e-02, fs:0.78788 (r=0.747,p=0.833),  time:42.813, tt:941.879\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.09350, lr:1.00e-02, fs:0.78528 (r=0.736,p=0.842),  time:42.803, tt:984.479\n",
      "Ep:23, loss:0.00012, loss_test:0.09026, lr:1.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:42.718, tt:1025.233\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09497, lr:1.00e-02, fs:0.76433 (r=0.690,p=0.857),  time:42.761, tt:1069.017\n",
      "Ep:25, loss:0.00010, loss_test:0.08804, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:42.665, tt:1109.303\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.09869, lr:1.00e-02, fs:0.74667 (r=0.644,p=0.889),  time:42.618, tt:1150.673\n",
      "Ep:27, loss:0.00010, loss_test:0.08849, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:42.626, tt:1193.519\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.08524, lr:1.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:42.597, tt:1235.310\n",
      "Ep:29, loss:0.00008, loss_test:0.09834, lr:1.00e-02, fs:0.74830 (r=0.632,p=0.917),  time:42.583, tt:1277.497\n",
      "Ep:30, loss:0.00008, loss_test:0.07800, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:42.563, tt:1319.468\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.10079, lr:1.00e-02, fs:0.76190 (r=0.644,p=0.933),  time:42.560, tt:1361.925\n",
      "Ep:32, loss:0.00008, loss_test:0.07891, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:42.489, tt:1402.127\n",
      "Ep:33, loss:0.00007, loss_test:0.09493, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:42.441, tt:1442.999\n",
      "Ep:34, loss:0.00006, loss_test:0.08197, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:42.454, tt:1485.891\n",
      "Ep:35, loss:0.00006, loss_test:0.07955, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:42.408, tt:1526.683\n",
      "Ep:36, loss:0.00006, loss_test:0.09468, lr:1.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:42.387, tt:1568.306\n",
      "Ep:37, loss:0.00005, loss_test:0.08323, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:42.272, tt:1606.329\n",
      "Ep:38, loss:0.00005, loss_test:0.08658, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:42.245, tt:1647.537\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.08120, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:42.262, tt:1690.496\n",
      "Ep:40, loss:0.00004, loss_test:0.08657, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:42.215, tt:1730.803\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00004, loss_test:0.08798, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:42.168, tt:1771.061\n",
      "Ep:42, loss:0.00004, loss_test:0.08554, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:42.186, tt:1813.988\n",
      "Ep:43, loss:0.00003, loss_test:0.08791, lr:1.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:42.177, tt:1855.767\n",
      "Ep:44, loss:0.00003, loss_test:0.08638, lr:1.00e-02, fs:0.82895 (r=0.724,p=0.969),  time:42.203, tt:1899.139\n",
      "Ep:45, loss:0.00003, loss_test:0.08575, lr:1.00e-02, fs:0.79730 (r=0.678,p=0.967),  time:42.209, tt:1941.622\n",
      "Ep:46, loss:0.00002, loss_test:0.09272, lr:1.00e-02, fs:0.84416 (r=0.747,p=0.970),  time:42.175, tt:1982.210\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.08912, lr:1.00e-02, fs:0.76056 (r=0.621,p=0.982),  time:42.156, tt:2023.508\n",
      "Ep:48, loss:0.00002, loss_test:0.08816, lr:1.00e-02, fs:0.79452 (r=0.667,p=0.983),  time:42.162, tt:2065.935\n",
      "Ep:49, loss:0.00002, loss_test:0.08359, lr:1.00e-02, fs:0.80000 (r=0.667,p=1.000),  time:42.136, tt:2106.811\n",
      "Ep:50, loss:0.00002, loss_test:0.09098, lr:1.00e-02, fs:0.78322 (r=0.644,p=1.000),  time:42.122, tt:2148.234\n",
      "Ep:51, loss:0.00002, loss_test:0.08542, lr:1.00e-02, fs:0.85526 (r=0.747,p=1.000),  time:42.040, tt:2186.086\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.09032, lr:1.00e-02, fs:0.76596 (r=0.621,p=1.000),  time:42.088, tt:2230.647\n",
      "Ep:53, loss:0.00001, loss_test:0.08882, lr:1.00e-02, fs:0.85714 (r=0.759,p=0.985),  time:42.047, tt:2270.539\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.09134, lr:1.00e-02, fs:0.75714 (r=0.609,p=1.000),  time:42.047, tt:2312.561\n",
      "Ep:55, loss:0.00001, loss_test:0.08965, lr:1.00e-02, fs:0.80000 (r=0.667,p=1.000),  time:41.979, tt:2350.800\n",
      "Ep:56, loss:0.00001, loss_test:0.09429, lr:1.00e-02, fs:0.79167 (r=0.655,p=1.000),  time:41.939, tt:2390.507\n",
      "Ep:57, loss:0.00001, loss_test:0.08555, lr:1.00e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.935, tt:2432.202\n",
      "Ep:58, loss:0.00001, loss_test:0.08990, lr:1.00e-02, fs:0.76596 (r=0.621,p=1.000),  time:41.930, tt:2473.841\n",
      "Ep:59, loss:0.00001, loss_test:0.09330, lr:1.00e-02, fs:0.76596 (r=0.621,p=1.000),  time:41.931, tt:2515.876\n",
      "Ep:60, loss:0.00001, loss_test:0.09152, lr:1.00e-02, fs:0.80822 (r=0.678,p=1.000),  time:41.874, tt:2554.332\n",
      "Ep:61, loss:0.00001, loss_test:0.09062, lr:1.00e-02, fs:0.76596 (r=0.621,p=1.000),  time:41.851, tt:2594.771\n",
      "Ep:62, loss:0.00001, loss_test:0.08955, lr:1.00e-02, fs:0.80822 (r=0.678,p=1.000),  time:41.814, tt:2634.296\n",
      "Ep:63, loss:0.00001, loss_test:0.09341, lr:1.00e-02, fs:0.78322 (r=0.644,p=1.000),  time:41.788, tt:2674.406\n",
      "Ep:64, loss:0.00001, loss_test:0.09121, lr:1.00e-02, fs:0.80822 (r=0.678,p=1.000),  time:41.787, tt:2716.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.08717, lr:9.90e-03, fs:0.76596 (r=0.621,p=1.000),  time:41.767, tt:2756.637\n",
      "Ep:66, loss:0.00001, loss_test:0.09265, lr:9.80e-03, fs:0.80000 (r=0.667,p=1.000),  time:41.747, tt:2797.071\n",
      "Ep:67, loss:0.00001, loss_test:0.09099, lr:9.70e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.757, tt:2839.486\n",
      "Ep:68, loss:0.00000, loss_test:0.09405, lr:9.61e-03, fs:0.80000 (r=0.667,p=1.000),  time:41.712, tt:2878.097\n",
      "Ep:69, loss:0.00000, loss_test:0.08972, lr:9.51e-03, fs:0.79167 (r=0.655,p=1.000),  time:41.707, tt:2919.480\n",
      "Ep:70, loss:0.00000, loss_test:0.09059, lr:9.41e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.682, tt:2959.415\n",
      "Ep:71, loss:0.00000, loss_test:0.09199, lr:9.32e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.647, tt:2998.589\n",
      "Ep:72, loss:0.00000, loss_test:0.09010, lr:9.23e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.650, tt:3040.483\n",
      "Ep:73, loss:0.00000, loss_test:0.08742, lr:9.14e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.624, tt:3080.202\n",
      "Ep:74, loss:0.00000, loss_test:0.08947, lr:9.04e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.632, tt:3122.372\n",
      "Ep:75, loss:0.00000, loss_test:0.08870, lr:8.95e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.613, tt:3162.572\n",
      "Ep:76, loss:0.00000, loss_test:0.09039, lr:8.86e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.597, tt:3202.944\n",
      "Ep:77, loss:0.00000, loss_test:0.08748, lr:8.78e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.593, tt:3244.259\n",
      "Ep:78, loss:0.00000, loss_test:0.08901, lr:8.69e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.584, tt:3285.130\n",
      "Ep:79, loss:0.00000, loss_test:0.09334, lr:8.60e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.568, tt:3325.445\n",
      "Ep:80, loss:0.00000, loss_test:0.09249, lr:8.51e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.551, tt:3365.660\n",
      "Ep:81, loss:0.00000, loss_test:0.09211, lr:8.43e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.527, tt:3405.175\n",
      "Ep:82, loss:0.00000, loss_test:0.08898, lr:8.35e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.507, tt:3445.058\n",
      "Ep:83, loss:0.00000, loss_test:0.09076, lr:8.26e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.510, tt:3486.801\n",
      "Ep:84, loss:0.00000, loss_test:0.08852, lr:8.18e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.492, tt:3526.837\n",
      "Ep:85, loss:0.00000, loss_test:0.09107, lr:8.10e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.489, tt:3568.011\n",
      "Ep:86, loss:0.00000, loss_test:0.09208, lr:8.02e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.475, tt:3608.362\n",
      "Ep:87, loss:0.00000, loss_test:0.08879, lr:7.94e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.462, tt:3648.626\n",
      "Ep:88, loss:0.00000, loss_test:0.08963, lr:7.86e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.455, tt:3689.473\n",
      "Ep:89, loss:0.00000, loss_test:0.08940, lr:7.78e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.455, tt:3730.974\n",
      "Ep:90, loss:0.00000, loss_test:0.08840, lr:7.70e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.481, tt:3774.751\n",
      "Ep:91, loss:0.00000, loss_test:0.08765, lr:7.62e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.470, tt:3815.222\n",
      "Ep:92, loss:0.00000, loss_test:0.08774, lr:7.55e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.483, tt:3857.964\n",
      "Ep:93, loss:0.00000, loss_test:0.08741, lr:7.47e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.525, tt:3903.385\n",
      "Ep:94, loss:0.00000, loss_test:0.08846, lr:7.40e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.519, tt:3944.323\n",
      "Ep:95, loss:0.00000, loss_test:0.08740, lr:7.32e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.526, tt:3986.530\n",
      "Ep:96, loss:0.00000, loss_test:0.08894, lr:7.25e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.527, tt:4028.143\n",
      "Ep:97, loss:0.00000, loss_test:0.08963, lr:7.18e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.531, tt:4070.056\n",
      "Ep:98, loss:0.00000, loss_test:0.08888, lr:7.11e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.522, tt:4110.720\n",
      "Ep:99, loss:0.00000, loss_test:0.08858, lr:7.03e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.532, tt:4153.187\n",
      "Ep:100, loss:0.00000, loss_test:0.08884, lr:6.96e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.544, tt:4195.972\n",
      "Ep:101, loss:0.00000, loss_test:0.08819, lr:6.89e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.552, tt:4238.297\n",
      "Ep:102, loss:0.00000, loss_test:0.08673, lr:6.83e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.536, tt:4278.244\n",
      "Ep:103, loss:0.00000, loss_test:0.08731, lr:6.76e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.526, tt:4318.734\n",
      "Ep:104, loss:0.00000, loss_test:0.08664, lr:6.69e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.525, tt:4360.125\n",
      "Ep:105, loss:0.00000, loss_test:0.08642, lr:6.62e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.488, tt:4397.751\n",
      "Ep:106, loss:0.00000, loss_test:0.08836, lr:6.56e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.485, tt:4438.847\n",
      "Ep:107, loss:0.00000, loss_test:0.08853, lr:6.49e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.483, tt:4480.151\n",
      "Ep:108, loss:0.00000, loss_test:0.08725, lr:6.43e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.480, tt:4521.305\n",
      "Ep:109, loss:0.00000, loss_test:0.08664, lr:6.36e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.486, tt:4563.493\n",
      "Ep:110, loss:0.00000, loss_test:0.08630, lr:6.30e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.486, tt:4604.900\n",
      "Ep:111, loss:0.00000, loss_test:0.08722, lr:6.24e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.464, tt:4644.012\n",
      "Ep:112, loss:0.00000, loss_test:0.08804, lr:6.17e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.468, tt:4685.939\n",
      "Ep:113, loss:0.00000, loss_test:0.08721, lr:6.11e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.465, tt:4727.050\n",
      "Ep:114, loss:0.00000, loss_test:0.08637, lr:6.05e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.475, tt:4769.677\n",
      "Ep:115, loss:0.00000, loss_test:0.08790, lr:5.99e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.457, tt:4808.985\n",
      "Ep:116, loss:0.00000, loss_test:0.08912, lr:5.93e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.476, tt:4852.650\n",
      "Ep:117, loss:0.00000, loss_test:0.08802, lr:5.87e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.478, tt:4894.445\n",
      "Ep:118, loss:0.00000, loss_test:0.08778, lr:5.81e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.455, tt:4933.137\n",
      "Ep:119, loss:0.00000, loss_test:0.08763, lr:5.75e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.434, tt:4972.135\n",
      "Ep:120, loss:0.00000, loss_test:0.08667, lr:5.70e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.433, tt:5013.386\n",
      "Ep:121, loss:0.00000, loss_test:0.08652, lr:5.64e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.425, tt:5053.846\n",
      "Ep:122, loss:0.00000, loss_test:0.08671, lr:5.58e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.416, tt:5094.170\n",
      "Ep:123, loss:0.00000, loss_test:0.08622, lr:5.53e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.406, tt:5134.338\n",
      "Ep:124, loss:0.00000, loss_test:0.08570, lr:5.47e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.400, tt:5175.025\n",
      "Ep:125, loss:0.00000, loss_test:0.08742, lr:5.42e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.407, tt:5217.260\n",
      "Ep:126, loss:0.00000, loss_test:0.08718, lr:5.36e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.411, tt:5259.236\n",
      "Ep:127, loss:0.00000, loss_test:0.08595, lr:5.31e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.401, tt:5299.368\n",
      "Ep:128, loss:0.00000, loss_test:0.08569, lr:5.26e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.399, tt:5340.512\n",
      "Ep:129, loss:0.00000, loss_test:0.08630, lr:5.20e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.397, tt:5381.603\n",
      "Ep:130, loss:0.00000, loss_test:0.08639, lr:5.15e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.442, tt:5428.849\n",
      "Ep:131, loss:0.00000, loss_test:0.08586, lr:5.10e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.438, tt:5469.812\n",
      "Ep:132, loss:0.00000, loss_test:0.08561, lr:5.05e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.422, tt:5509.108\n",
      "Ep:133, loss:0.00000, loss_test:0.08620, lr:5.00e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.418, tt:5550.048\n",
      "Ep:134, loss:0.00000, loss_test:0.08584, lr:4.95e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.412, tt:5590.580\n",
      "Ep:135, loss:0.00000, loss_test:0.08597, lr:4.90e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.408, tt:5631.538\n",
      "Ep:136, loss:0.00000, loss_test:0.08637, lr:4.85e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.398, tt:5671.470\n",
      "Ep:137, loss:0.00000, loss_test:0.08621, lr:4.80e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.389, tt:5711.639\n",
      "Ep:138, loss:0.00000, loss_test:0.08577, lr:4.75e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.378, tt:5751.565\n",
      "Ep:139, loss:0.00000, loss_test:0.08547, lr:4.71e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.364, tt:5791.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.08587, lr:4.66e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.365, tt:5832.488\n",
      "Ep:141, loss:0.00000, loss_test:0.08650, lr:4.61e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.373, tt:5874.978\n",
      "Ep:142, loss:0.00000, loss_test:0.08655, lr:4.57e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.364, tt:5914.995\n",
      "Ep:143, loss:0.00000, loss_test:0.08648, lr:4.52e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.364, tt:5956.423\n",
      "Ep:144, loss:0.00000, loss_test:0.08606, lr:4.48e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.346, tt:5995.232\n",
      "Ep:145, loss:0.00000, loss_test:0.08554, lr:4.43e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.340, tt:6035.708\n",
      "Ep:146, loss:0.00000, loss_test:0.08652, lr:4.39e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.328, tt:6075.251\n",
      "Ep:147, loss:0.00000, loss_test:0.08627, lr:4.34e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.320, tt:6115.320\n",
      "Ep:148, loss:0.00000, loss_test:0.08554, lr:4.30e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.312, tt:6155.491\n",
      "Ep:149, loss:0.00000, loss_test:0.08546, lr:4.26e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.300, tt:6194.933\n",
      "Ep:150, loss:0.00000, loss_test:0.08555, lr:4.21e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.301, tt:6236.380\n",
      "Ep:151, loss:0.00000, loss_test:0.08574, lr:4.17e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.290, tt:6276.089\n",
      "Ep:152, loss:0.00000, loss_test:0.08570, lr:4.13e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.298, tt:6318.523\n",
      "Ep:153, loss:0.00000, loss_test:0.08538, lr:4.09e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.301, tt:6360.375\n",
      "Ep:154, loss:0.00000, loss_test:0.08580, lr:4.05e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.315, tt:6403.871\n",
      "Ep:155, loss:0.00000, loss_test:0.08638, lr:4.01e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.330, tt:6447.438\n",
      "Ep:156, loss:0.00000, loss_test:0.08594, lr:3.97e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.334, tt:6489.381\n",
      "Ep:157, loss:0.00000, loss_test:0.08541, lr:3.93e-03, fs:0.83221 (r=0.713,p=1.000),  time:41.332, tt:6530.413\n",
      "Ep:158, loss:0.00000, loss_test:0.08541, lr:3.89e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.315, tt:6569.009\n",
      "Ep:159, loss:0.00000, loss_test:0.08584, lr:3.85e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.317, tt:6610.749\n",
      "Ep:160, loss:0.00000, loss_test:0.08627, lr:3.81e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.317, tt:6652.022\n",
      "Ep:161, loss:0.00000, loss_test:0.08607, lr:3.77e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.308, tt:6691.912\n",
      "Ep:162, loss:0.00000, loss_test:0.08559, lr:3.73e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.312, tt:6733.882\n",
      "Ep:163, loss:0.00000, loss_test:0.08520, lr:3.70e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.313, tt:6775.408\n",
      "Ep:164, loss:0.00000, loss_test:0.08518, lr:3.66e-03, fs:0.80822 (r=0.678,p=1.000),  time:41.314, tt:6816.763\n",
      "Ep:165, loss:0.00000, loss_test:0.08541, lr:3.62e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.320, tt:6859.097\n",
      "Ep:166, loss:0.00000, loss_test:0.08551, lr:3.59e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.329, tt:6901.868\n",
      "Ep:167, loss:0.00000, loss_test:0.08529, lr:3.55e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.333, tt:6943.976\n",
      "Ep:168, loss:0.00000, loss_test:0.08509, lr:3.52e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.323, tt:6983.535\n",
      "Ep:169, loss:0.00000, loss_test:0.08536, lr:3.48e-03, fs:0.83221 (r=0.713,p=1.000),  time:41.323, tt:7024.827\n",
      "Ep:170, loss:0.00000, loss_test:0.08522, lr:3.45e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.331, tt:7067.545\n",
      "Ep:171, loss:0.00000, loss_test:0.08544, lr:3.41e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.362, tt:7114.308\n",
      "Ep:172, loss:0.00000, loss_test:0.08573, lr:3.38e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.371, tt:7157.219\n",
      "Ep:173, loss:0.00000, loss_test:0.08549, lr:3.34e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.363, tt:7197.227\n",
      "Ep:174, loss:0.00000, loss_test:0.08508, lr:3.31e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.359, tt:7237.822\n",
      "Ep:175, loss:0.00000, loss_test:0.08499, lr:3.28e-03, fs:0.84000 (r=0.724,p=1.000),  time:41.359, tt:7279.240\n",
      "Ep:176, loss:0.00000, loss_test:0.08515, lr:3.24e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.350, tt:7319.031\n",
      "Ep:177, loss:0.00000, loss_test:0.08526, lr:3.21e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.344, tt:7359.283\n",
      "Ep:178, loss:0.00000, loss_test:0.08523, lr:3.18e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.349, tt:7401.534\n",
      "Ep:179, loss:0.00000, loss_test:0.08515, lr:3.15e-03, fs:0.84000 (r=0.724,p=1.000),  time:41.336, tt:7440.398\n",
      "Ep:180, loss:0.00000, loss_test:0.08494, lr:3.12e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.321, tt:7479.175\n",
      "Ep:181, loss:0.00000, loss_test:0.08490, lr:3.09e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.320, tt:7520.177\n",
      "Ep:182, loss:0.00000, loss_test:0.08501, lr:3.05e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.316, tt:7560.793\n",
      "Ep:183, loss:0.00000, loss_test:0.08505, lr:3.02e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.308, tt:7600.704\n",
      "Ep:184, loss:0.00000, loss_test:0.08486, lr:2.99e-03, fs:0.83221 (r=0.713,p=1.000),  time:41.314, tt:7643.008\n",
      "Ep:185, loss:0.00000, loss_test:0.08492, lr:2.96e-03, fs:0.84768 (r=0.736,p=1.000),  time:41.334, tt:7688.045\n",
      "Ep:186, loss:0.00000, loss_test:0.08479, lr:2.93e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.341, tt:7730.715\n",
      "Ep:187, loss:0.00000, loss_test:0.08532, lr:2.90e-03, fs:0.84768 (r=0.736,p=1.000),  time:41.336, tt:7771.094\n",
      "Ep:188, loss:0.00000, loss_test:0.08538, lr:2.88e-03, fs:0.85526 (r=0.747,p=1.000),  time:41.330, tt:7811.330\n",
      "Ep:189, loss:0.00000, loss_test:0.08509, lr:2.85e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.340, tt:7854.648\n",
      "Ep:190, loss:0.00000, loss_test:0.08475, lr:2.82e-03, fs:0.84768 (r=0.736,p=1.000),  time:41.350, tt:7897.822\n",
      "Ep:191, loss:0.00000, loss_test:0.08459, lr:2.79e-03, fs:0.86275 (r=0.759,p=1.000),  time:41.361, tt:7941.341\n",
      "##########Best model found so far##########\n",
      "Ep:192, loss:0.00000, loss_test:0.08484, lr:2.79e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.356, tt:7981.752\n",
      "Ep:193, loss:0.00000, loss_test:0.08494, lr:2.79e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.356, tt:8023.060\n",
      "Ep:194, loss:0.00000, loss_test:0.08478, lr:2.79e-03, fs:0.86275 (r=0.759,p=1.000),  time:41.357, tt:8064.591\n",
      "Ep:195, loss:0.00000, loss_test:0.08484, lr:2.79e-03, fs:0.85526 (r=0.747,p=1.000),  time:41.362, tt:8107.049\n",
      "Ep:196, loss:0.00000, loss_test:0.08508, lr:2.79e-03, fs:0.84000 (r=0.724,p=1.000),  time:41.366, tt:8149.110\n",
      "Ep:197, loss:0.00000, loss_test:0.08508, lr:2.79e-03, fs:0.83221 (r=0.713,p=1.000),  time:41.367, tt:8190.758\n",
      "Ep:198, loss:0.00000, loss_test:0.08486, lr:2.79e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.358, tt:8230.298\n",
      "Ep:199, loss:0.00000, loss_test:0.08485, lr:2.79e-03, fs:0.85526 (r=0.747,p=1.000),  time:41.357, tt:8271.405\n",
      "Ep:200, loss:0.00000, loss_test:0.08510, lr:2.79e-03, fs:0.84768 (r=0.736,p=1.000),  time:41.366, tt:8314.477\n",
      "Ep:201, loss:0.00000, loss_test:0.08536, lr:2.79e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.355, tt:8353.807\n",
      "Ep:202, loss:0.00000, loss_test:0.08511, lr:2.79e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.338, tt:8391.606\n",
      "Ep:203, loss:0.00000, loss_test:0.08557, lr:2.76e-03, fs:0.87013 (r=0.770,p=1.000),  time:41.308, tt:8426.853\n",
      "##########Best model found so far##########\n",
      "Ep:204, loss:0.00000, loss_test:0.08636, lr:2.76e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.274, tt:8461.153\n",
      "Ep:205, loss:0.00000, loss_test:0.08638, lr:2.76e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.251, tt:8497.619\n",
      "Ep:206, loss:0.00000, loss_test:0.08578, lr:2.76e-03, fs:0.81633 (r=0.690,p=1.000),  time:41.231, tt:8534.838\n",
      "Ep:207, loss:0.00000, loss_test:0.08524, lr:2.76e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.157, tt:8560.676\n",
      "Ep:208, loss:0.00000, loss_test:0.08498, lr:2.76e-03, fs:0.82432 (r=0.701,p=1.000),  time:41.042, tt:8577.702\n",
      "Ep:209, loss:0.00000, loss_test:0.08520, lr:2.76e-03, fs:0.82432 (r=0.701,p=1.000),  time:40.908, tt:8590.758\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02193, lr:6.00e-02, fs:0.59155 (r=0.724,p=0.500),  time:32.251, tt:32.251\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02179, lr:6.00e-02, fs:0.65339 (r=0.943,p=0.500),  time:30.851, tt:61.703\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02211, lr:6.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:30.702, tt:92.107\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.67451 (r=0.989,p=0.512),  time:31.089, tt:124.357\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01958, lr:6.00e-02, fs:0.66393 (r=0.931,p=0.516),  time:30.711, tt:153.553\n",
      "Ep:5, loss:0.00004, loss_test:0.01878, lr:6.00e-02, fs:0.66960 (r=0.874,p=0.543),  time:30.812, tt:184.870\n",
      "Ep:6, loss:0.00004, loss_test:0.01888, lr:6.00e-02, fs:0.69565 (r=0.828,p=0.600),  time:30.734, tt:215.141\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00003, loss_test:0.01910, lr:6.00e-02, fs:0.70647 (r=0.816,p=0.623),  time:30.759, tt:246.071\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01908, lr:6.00e-02, fs:0.69268 (r=0.816,p=0.602),  time:30.698, tt:276.282\n",
      "Ep:9, loss:0.00003, loss_test:0.01913, lr:6.00e-02, fs:0.69231 (r=0.828,p=0.595),  time:31.014, tt:310.141\n",
      "Ep:10, loss:0.00003, loss_test:0.01921, lr:6.00e-02, fs:0.69565 (r=0.828,p=0.600),  time:30.956, tt:340.511\n",
      "Ep:11, loss:0.00003, loss_test:0.01930, lr:6.00e-02, fs:0.71357 (r=0.816,p=0.634),  time:30.972, tt:371.667\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01955, lr:6.00e-02, fs:0.71795 (r=0.805,p=0.648),  time:30.912, tt:401.861\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01961, lr:6.00e-02, fs:0.73298 (r=0.805,p=0.673),  time:30.959, tt:433.421\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01948, lr:6.00e-02, fs:0.74074 (r=0.805,p=0.686),  time:31.090, tt:466.352\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01922, lr:6.00e-02, fs:0.74737 (r=0.816,p=0.689),  time:31.187, tt:498.989\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01888, lr:6.00e-02, fs:0.75132 (r=0.816,p=0.696),  time:31.221, tt:530.757\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01857, lr:6.00e-02, fs:0.75132 (r=0.816,p=0.696),  time:31.224, tt:562.025\n",
      "Ep:18, loss:0.00002, loss_test:0.01839, lr:6.00e-02, fs:0.76757 (r=0.816,p=0.724),  time:31.201, tt:592.812\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01830, lr:6.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:31.260, tt:625.196\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01809, lr:6.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:31.219, tt:655.591\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01777, lr:6.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:31.083, tt:683.821\n",
      "Ep:22, loss:0.00002, loss_test:0.01737, lr:6.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:31.069, tt:714.597\n",
      "Ep:23, loss:0.00002, loss_test:0.01711, lr:6.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:31.054, tt:745.302\n",
      "Ep:24, loss:0.00002, loss_test:0.01694, lr:6.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:31.101, tt:777.528\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01685, lr:6.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:31.173, tt:810.497\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01671, lr:6.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:31.218, tt:842.888\n",
      "Ep:27, loss:0.00002, loss_test:0.01670, lr:6.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:31.180, tt:873.027\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01674, lr:6.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:31.190, tt:904.497\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:31.156, tt:934.679\n",
      "Ep:30, loss:0.00002, loss_test:0.01654, lr:6.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:31.187, tt:966.787\n",
      "Ep:31, loss:0.00001, loss_test:0.01657, lr:6.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:31.183, tt:997.847\n",
      "Ep:32, loss:0.00001, loss_test:0.01657, lr:6.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:31.135, tt:1027.469\n",
      "Ep:33, loss:0.00001, loss_test:0.01648, lr:6.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:31.225, tt:1061.661\n",
      "Ep:34, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:31.240, tt:1093.389\n",
      "Ep:35, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:31.209, tt:1123.525\n",
      "Ep:36, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.227, tt:1155.384\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00001, loss_test:0.01659, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.223, tt:1186.475\n",
      "Ep:38, loss:0.00001, loss_test:0.01655, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.214, tt:1217.338\n",
      "Ep:39, loss:0.00001, loss_test:0.01655, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.146, tt:1245.847\n",
      "Ep:40, loss:0.00001, loss_test:0.01663, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.121, tt:1275.967\n",
      "Ep:41, loss:0.00001, loss_test:0.01664, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.131, tt:1307.486\n",
      "Ep:42, loss:0.00001, loss_test:0.01669, lr:6.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:31.181, tt:1340.769\n",
      "Ep:43, loss:0.00001, loss_test:0.01667, lr:6.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:31.210, tt:1373.244\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01669, lr:6.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:31.213, tt:1404.565\n",
      "Ep:45, loss:0.00001, loss_test:0.01674, lr:6.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:31.206, tt:1435.495\n",
      "Ep:46, loss:0.00001, loss_test:0.01683, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:31.164, tt:1464.690\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01697, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:31.137, tt:1494.585\n",
      "Ep:48, loss:0.00001, loss_test:0.01723, lr:6.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:31.117, tt:1524.740\n",
      "Ep:49, loss:0.00001, loss_test:0.01723, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:31.097, tt:1554.836\n",
      "Ep:50, loss:0.00001, loss_test:0.01731, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:31.121, tt:1587.195\n",
      "Ep:51, loss:0.00001, loss_test:0.01734, lr:6.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:31.121, tt:1618.271\n",
      "Ep:52, loss:0.00001, loss_test:0.01748, lr:6.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:31.141, tt:1650.459\n",
      "Ep:53, loss:0.00001, loss_test:0.01771, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:31.141, tt:1681.636\n",
      "Ep:54, loss:0.00001, loss_test:0.01773, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:31.124, tt:1711.838\n",
      "Ep:55, loss:0.00001, loss_test:0.01792, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:31.138, tt:1743.714\n",
      "Ep:56, loss:0.00001, loss_test:0.01799, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:31.126, tt:1774.183\n",
      "Ep:57, loss:0.00001, loss_test:0.01814, lr:6.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:31.109, tt:1804.338\n",
      "Ep:58, loss:0.00001, loss_test:0.01840, lr:5.94e-02, fs:0.82353 (r=0.724,p=0.955),  time:31.088, tt:1834.193\n",
      "Ep:59, loss:0.00001, loss_test:0.01842, lr:5.88e-02, fs:0.82353 (r=0.724,p=0.955),  time:31.058, tt:1863.486\n",
      "Ep:60, loss:0.00001, loss_test:0.01871, lr:5.82e-02, fs:0.82353 (r=0.724,p=0.955),  time:31.050, tt:1894.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01880, lr:5.76e-02, fs:0.82353 (r=0.724,p=0.955),  time:31.043, tt:1924.635\n",
      "Ep:62, loss:0.00001, loss_test:0.01894, lr:5.71e-02, fs:0.81579 (r=0.713,p=0.954),  time:30.999, tt:1952.915\n",
      "Ep:63, loss:0.00001, loss_test:0.01916, lr:5.65e-02, fs:0.80000 (r=0.690,p=0.952),  time:30.965, tt:1981.741\n",
      "Ep:64, loss:0.00000, loss_test:0.01928, lr:5.59e-02, fs:0.80795 (r=0.701,p=0.953),  time:30.949, tt:2011.664\n",
      "Ep:65, loss:0.00000, loss_test:0.01948, lr:5.54e-02, fs:0.80000 (r=0.690,p=0.952),  time:30.951, tt:2042.780\n",
      "Ep:66, loss:0.00000, loss_test:0.01956, lr:5.48e-02, fs:0.79195 (r=0.678,p=0.952),  time:30.947, tt:2073.424\n",
      "Ep:67, loss:0.00000, loss_test:0.01974, lr:5.43e-02, fs:0.79195 (r=0.678,p=0.952),  time:30.927, tt:2103.036\n",
      "Ep:68, loss:0.00000, loss_test:0.01989, lr:5.37e-02, fs:0.77551 (r=0.655,p=0.950),  time:30.923, tt:2133.683\n",
      "Ep:69, loss:0.00000, loss_test:0.01998, lr:5.32e-02, fs:0.77551 (r=0.655,p=0.950),  time:30.903, tt:2163.238\n",
      "Ep:70, loss:0.00000, loss_test:0.02018, lr:5.27e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.924, tt:2195.638\n",
      "Ep:71, loss:0.00000, loss_test:0.02033, lr:5.21e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.906, tt:2225.257\n",
      "Ep:72, loss:0.00000, loss_test:0.02038, lr:5.16e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.913, tt:2256.626\n",
      "Ep:73, loss:0.00000, loss_test:0.02049, lr:5.11e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.921, tt:2288.121\n",
      "Ep:74, loss:0.00000, loss_test:0.02063, lr:5.06e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.926, tt:2319.432\n",
      "Ep:75, loss:0.00000, loss_test:0.02092, lr:5.01e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.945, tt:2351.826\n",
      "Ep:76, loss:0.00000, loss_test:0.02089, lr:4.96e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.942, tt:2382.516\n",
      "Ep:77, loss:0.00000, loss_test:0.02111, lr:4.91e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.947, tt:2413.889\n",
      "Ep:78, loss:0.00000, loss_test:0.02119, lr:4.86e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.956, tt:2445.490\n",
      "Ep:79, loss:0.00000, loss_test:0.02133, lr:4.81e-02, fs:0.76389 (r=0.632,p=0.965),  time:30.943, tt:2475.444\n",
      "Ep:80, loss:0.00000, loss_test:0.02147, lr:4.76e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.937, tt:2505.883\n",
      "Ep:81, loss:0.00000, loss_test:0.02145, lr:4.71e-02, fs:0.77241 (r=0.644,p=0.966),  time:30.885, tt:2532.560\n",
      "Ep:82, loss:0.00000, loss_test:0.02186, lr:4.67e-02, fs:0.75524 (r=0.621,p=0.964),  time:30.884, tt:2563.382\n",
      "Ep:83, loss:0.00000, loss_test:0.02190, lr:4.62e-02, fs:0.75524 (r=0.621,p=0.964),  time:30.858, tt:2592.111\n",
      "Ep:84, loss:0.00000, loss_test:0.02205, lr:4.57e-02, fs:0.75524 (r=0.621,p=0.964),  time:30.836, tt:2621.063\n",
      "Ep:85, loss:0.00000, loss_test:0.02222, lr:4.53e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.833, tt:2651.662\n",
      "Ep:86, loss:0.00000, loss_test:0.02226, lr:4.48e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.817, tt:2681.060\n",
      "Ep:87, loss:0.00000, loss_test:0.02244, lr:4.44e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.801, tt:2710.486\n",
      "Ep:88, loss:0.00000, loss_test:0.02261, lr:4.39e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.794, tt:2740.633\n",
      "Ep:89, loss:0.00000, loss_test:0.02279, lr:4.35e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.779, tt:2770.068\n",
      "Ep:90, loss:0.00000, loss_test:0.02289, lr:4.31e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.780, tt:2800.943\n",
      "Ep:91, loss:0.00000, loss_test:0.02300, lr:4.26e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.776, tt:2831.346\n",
      "Ep:92, loss:0.00000, loss_test:0.02304, lr:4.22e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.742, tt:2858.997\n",
      "Ep:93, loss:0.00000, loss_test:0.02314, lr:4.18e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.742, tt:2889.788\n",
      "Ep:94, loss:0.00000, loss_test:0.02317, lr:4.14e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.734, tt:2919.762\n",
      "Ep:95, loss:0.00000, loss_test:0.02333, lr:4.10e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.736, tt:2950.690\n",
      "Ep:96, loss:0.00000, loss_test:0.02343, lr:4.05e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.757, tt:2983.417\n",
      "Ep:97, loss:0.00000, loss_test:0.02356, lr:4.01e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.753, tt:3013.802\n",
      "Ep:98, loss:0.00000, loss_test:0.02363, lr:3.97e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.755, tt:3044.776\n",
      "Ep:99, loss:0.00000, loss_test:0.02371, lr:3.93e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.741, tt:3074.104\n",
      "Ep:100, loss:0.00000, loss_test:0.02380, lr:3.89e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.716, tt:3102.359\n",
      "Ep:101, loss:0.00000, loss_test:0.02395, lr:3.86e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.714, tt:3132.818\n",
      "Ep:102, loss:0.00000, loss_test:0.02393, lr:3.82e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.706, tt:3162.725\n",
      "Ep:103, loss:0.00000, loss_test:0.02405, lr:3.78e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.713, tt:3194.139\n",
      "Ep:104, loss:0.00000, loss_test:0.02406, lr:3.74e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.719, tt:3225.466\n",
      "Ep:105, loss:0.00000, loss_test:0.02416, lr:3.70e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.722, tt:3256.486\n",
      "Ep:106, loss:0.00000, loss_test:0.02429, lr:3.67e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.712, tt:3286.218\n",
      "Ep:107, loss:0.00000, loss_test:0.02429, lr:3.63e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.704, tt:3315.999\n",
      "Ep:108, loss:0.00000, loss_test:0.02446, lr:3.59e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.707, tt:3347.025\n",
      "Ep:109, loss:0.00000, loss_test:0.02451, lr:3.56e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.709, tt:3377.935\n",
      "Ep:110, loss:0.00000, loss_test:0.02454, lr:3.52e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.703, tt:3408.017\n",
      "Ep:111, loss:0.00000, loss_test:0.02470, lr:3.49e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.712, tt:3439.744\n",
      "Ep:112, loss:0.00000, loss_test:0.02471, lr:3.45e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.720, tt:3471.335\n",
      "Ep:113, loss:0.00000, loss_test:0.02479, lr:3.42e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.720, tt:3502.095\n",
      "Ep:114, loss:0.00000, loss_test:0.02483, lr:3.38e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.715, tt:3532.258\n",
      "Ep:115, loss:0.00000, loss_test:0.02485, lr:3.35e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.694, tt:3560.478\n",
      "Ep:116, loss:0.00000, loss_test:0.02501, lr:3.32e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.709, tt:3592.956\n",
      "Ep:117, loss:0.00000, loss_test:0.02502, lr:3.28e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.719, tt:3624.863\n",
      "Ep:118, loss:0.00000, loss_test:0.02506, lr:3.25e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.702, tt:3653.562\n",
      "Ep:119, loss:0.00000, loss_test:0.02512, lr:3.22e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.736, tt:3688.373\n",
      "Ep:120, loss:0.00000, loss_test:0.02517, lr:3.19e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.746, tt:3720.289\n",
      "Ep:121, loss:0.00000, loss_test:0.02525, lr:3.15e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.737, tt:3749.866\n",
      "Ep:122, loss:0.00000, loss_test:0.02525, lr:3.12e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.741, tt:3781.114\n",
      "Ep:123, loss:0.00000, loss_test:0.02532, lr:3.09e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.731, tt:3810.601\n",
      "Ep:124, loss:0.00000, loss_test:0.02535, lr:3.06e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.730, tt:3841.217\n",
      "Ep:125, loss:0.00000, loss_test:0.02537, lr:3.03e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.725, tt:3871.372\n",
      "Ep:126, loss:0.00000, loss_test:0.02544, lr:3.00e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.724, tt:3901.946\n",
      "Ep:127, loss:0.00000, loss_test:0.02549, lr:2.97e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.714, tt:3931.362\n",
      "Ep:128, loss:0.00000, loss_test:0.02554, lr:2.94e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.705, tt:3960.887\n",
      "Ep:129, loss:0.00000, loss_test:0.02556, lr:2.91e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.680, tt:3988.403\n",
      "Ep:130, loss:0.00000, loss_test:0.02559, lr:2.88e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.667, tt:4017.440\n",
      "Ep:131, loss:0.00000, loss_test:0.02565, lr:2.85e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.666, tt:4047.935\n",
      "Ep:132, loss:0.00000, loss_test:0.02566, lr:2.82e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.668, tt:4078.857\n",
      "Ep:133, loss:0.00000, loss_test:0.02573, lr:2.80e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.658, tt:4108.111\n",
      "Ep:134, loss:0.00000, loss_test:0.02578, lr:2.77e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.647, tt:4137.344\n",
      "Ep:135, loss:0.00000, loss_test:0.02582, lr:2.74e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.636, tt:4166.537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02582, lr:2.71e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.635, tt:4197.022\n",
      "Ep:137, loss:0.00000, loss_test:0.02586, lr:2.69e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.627, tt:4226.589\n",
      "Ep:138, loss:0.00000, loss_test:0.02588, lr:2.66e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.613, tt:4255.172\n",
      "Ep:139, loss:0.00000, loss_test:0.02598, lr:2.63e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.611, tt:4285.519\n",
      "Ep:140, loss:0.00000, loss_test:0.02597, lr:2.61e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.610, tt:4315.946\n",
      "Ep:141, loss:0.00000, loss_test:0.02599, lr:2.58e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.608, tt:4346.288\n",
      "Ep:142, loss:0.00000, loss_test:0.02603, lr:2.55e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.596, tt:4375.209\n",
      "Ep:143, loss:0.00000, loss_test:0.02607, lr:2.53e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.584, tt:4404.166\n",
      "Ep:144, loss:0.00000, loss_test:0.02609, lr:2.50e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.578, tt:4433.839\n",
      "Ep:145, loss:0.00000, loss_test:0.02608, lr:2.48e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.573, tt:4463.639\n",
      "Ep:146, loss:0.00000, loss_test:0.02614, lr:2.45e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.569, tt:4493.595\n",
      "Ep:147, loss:0.00000, loss_test:0.02620, lr:2.43e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.569, tt:4524.182\n",
      "Ep:148, loss:0.00000, loss_test:0.02623, lr:2.40e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.566, tt:4554.338\n",
      "Ep:149, loss:0.00000, loss_test:0.02625, lr:2.38e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.566, tt:4584.970\n",
      "Ep:150, loss:0.00000, loss_test:0.02629, lr:2.36e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.571, tt:4616.238\n",
      "Ep:151, loss:0.00000, loss_test:0.02626, lr:2.33e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.579, tt:4648.024\n",
      "Ep:152, loss:0.00000, loss_test:0.02631, lr:2.31e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.581, tt:4678.893\n",
      "Ep:153, loss:0.00000, loss_test:0.02637, lr:2.29e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.598, tt:4712.092\n",
      "Ep:154, loss:0.00000, loss_test:0.02638, lr:2.26e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.597, tt:4742.566\n",
      "Ep:155, loss:0.00000, loss_test:0.02637, lr:2.24e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.588, tt:4771.741\n",
      "Ep:156, loss:0.00000, loss_test:0.02642, lr:2.22e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.602, tt:4804.567\n",
      "Ep:157, loss:0.00000, loss_test:0.02642, lr:2.20e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.609, tt:4836.233\n",
      "Ep:158, loss:0.00000, loss_test:0.02645, lr:2.17e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.620, tt:4868.532\n",
      "Ep:159, loss:0.00000, loss_test:0.02648, lr:2.15e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.635, tt:4901.543\n",
      "Ep:160, loss:0.00000, loss_test:0.02648, lr:2.13e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.633, tt:4931.839\n",
      "Ep:161, loss:0.00000, loss_test:0.02652, lr:2.11e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.633, tt:4962.561\n",
      "Ep:162, loss:0.00000, loss_test:0.02656, lr:2.09e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.629, tt:4992.448\n",
      "Ep:163, loss:0.00000, loss_test:0.02658, lr:2.07e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.618, tt:5021.357\n",
      "Ep:164, loss:0.00000, loss_test:0.02660, lr:2.05e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.622, tt:5052.711\n",
      "Ep:165, loss:0.00000, loss_test:0.02661, lr:2.03e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.612, tt:5081.618\n",
      "Ep:166, loss:0.00000, loss_test:0.02661, lr:2.01e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.622, tt:5113.799\n",
      "Ep:167, loss:0.00000, loss_test:0.02665, lr:1.99e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.627, tt:5145.299\n",
      "Ep:168, loss:0.00000, loss_test:0.02668, lr:1.97e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.641, tt:5178.389\n",
      "Ep:169, loss:0.00000, loss_test:0.02670, lr:1.95e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.645, tt:5209.721\n",
      "Ep:170, loss:0.00000, loss_test:0.02672, lr:1.93e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.653, tt:5241.731\n",
      "Ep:171, loss:0.00000, loss_test:0.02672, lr:1.91e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.657, tt:5273.039\n",
      "Ep:172, loss:0.00000, loss_test:0.02673, lr:1.89e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.659, tt:5303.930\n",
      "Ep:173, loss:0.00000, loss_test:0.02676, lr:1.87e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.654, tt:5333.822\n",
      "Ep:174, loss:0.00000, loss_test:0.02676, lr:1.85e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.682, tt:5369.411\n",
      "Ep:175, loss:0.00000, loss_test:0.02678, lr:1.83e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.679, tt:5399.483\n",
      "Ep:176, loss:0.00000, loss_test:0.02680, lr:1.81e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.682, tt:5430.631\n",
      "Ep:177, loss:0.00000, loss_test:0.02683, lr:1.80e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.684, tt:5461.714\n",
      "Ep:178, loss:0.00000, loss_test:0.02684, lr:1.78e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.688, tt:5493.098\n",
      "Ep:179, loss:0.00000, loss_test:0.02687, lr:1.76e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.690, tt:5524.267\n",
      "Ep:180, loss:0.00000, loss_test:0.02687, lr:1.74e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.690, tt:5554.837\n",
      "Ep:181, loss:0.00000, loss_test:0.02689, lr:1.73e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.696, tt:5586.651\n",
      "Ep:182, loss:0.00000, loss_test:0.02691, lr:1.71e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.704, tt:5618.837\n",
      "Ep:183, loss:0.00000, loss_test:0.02693, lr:1.69e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.705, tt:5649.732\n",
      "Ep:184, loss:0.00000, loss_test:0.02693, lr:1.67e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.696, tt:5678.799\n",
      "Ep:185, loss:0.00000, loss_test:0.02694, lr:1.66e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.705, tt:5711.189\n",
      "Ep:186, loss:0.00000, loss_test:0.02697, lr:1.64e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.709, tt:5742.668\n",
      "Ep:187, loss:0.00000, loss_test:0.02697, lr:1.62e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.722, tt:5775.687\n",
      "Ep:188, loss:0.00000, loss_test:0.02700, lr:1.61e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.735, tt:5808.946\n",
      "Ep:189, loss:0.00000, loss_test:0.02702, lr:1.59e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.742, tt:5840.962\n",
      "Ep:190, loss:0.00000, loss_test:0.02703, lr:1.58e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.740, tt:5871.332\n",
      "Ep:191, loss:0.00000, loss_test:0.02704, lr:1.56e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.747, tt:5903.329\n",
      "Ep:192, loss:0.00000, loss_test:0.02705, lr:1.54e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.742, tt:5933.221\n",
      "Ep:193, loss:0.00000, loss_test:0.02708, lr:1.53e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.739, tt:5963.462\n",
      "Ep:194, loss:0.00000, loss_test:0.02712, lr:1.51e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.736, tt:5993.437\n",
      "Ep:195, loss:0.00000, loss_test:0.02713, lr:1.50e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.740, tt:6025.064\n",
      "Ep:196, loss:0.00000, loss_test:0.02714, lr:1.48e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.754, tt:6058.576\n",
      "Ep:197, loss:0.00000, loss_test:0.02717, lr:1.47e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.752, tt:6088.890\n",
      "Ep:198, loss:0.00000, loss_test:0.02718, lr:1.45e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.754, tt:6120.021\n",
      "Ep:199, loss:0.00000, loss_test:0.02720, lr:1.44e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.753, tt:6150.580\n",
      "Ep:200, loss:0.00000, loss_test:0.02719, lr:1.43e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.744, tt:6179.591\n",
      "Ep:201, loss:0.00000, loss_test:0.02720, lr:1.41e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.718, tt:6204.941\n",
      "Ep:202, loss:0.00000, loss_test:0.02723, lr:1.40e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.711, tt:6234.391\n",
      "Ep:203, loss:0.00000, loss_test:0.02725, lr:1.38e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.713, tt:6265.365\n",
      "Ep:204, loss:0.00000, loss_test:0.02725, lr:1.37e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.703, tt:6294.094\n",
      "Ep:205, loss:0.00000, loss_test:0.02726, lr:1.36e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.668, tt:6317.639\n",
      "Ep:206, loss:0.00000, loss_test:0.02727, lr:1.34e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.650, tt:6344.574\n",
      "Ep:207, loss:0.00000, loss_test:0.02727, lr:1.33e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.616, tt:6368.098\n",
      "Ep:208, loss:0.00000, loss_test:0.02728, lr:1.32e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.597, tt:6394.682\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14349, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.723, tt:30.723\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14191, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.616, tt:63.232\n",
      "Ep:2, loss:0.00027, loss_test:0.13892, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.989, tt:95.967\n",
      "Ep:3, loss:0.00027, loss_test:0.13367, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:31.448, tt:125.792\n",
      "Ep:4, loss:0.00025, loss_test:0.12420, lr:1.00e-02, fs:0.68880 (r=0.954,p=0.539),  time:31.422, tt:157.112\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11442, lr:1.00e-02, fs:0.65672 (r=0.759,p=0.579),  time:31.221, tt:187.326\n",
      "Ep:6, loss:0.00023, loss_test:0.11485, lr:1.00e-02, fs:0.64865 (r=0.690,p=0.612),  time:30.919, tt:216.434\n",
      "Ep:7, loss:0.00022, loss_test:0.11608, lr:1.00e-02, fs:0.65990 (r=0.747,p=0.591),  time:30.931, tt:247.449\n",
      "Ep:8, loss:0.00021, loss_test:0.11269, lr:1.00e-02, fs:0.70352 (r=0.805,p=0.625),  time:30.997, tt:278.973\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10614, lr:1.00e-02, fs:0.68478 (r=0.724,p=0.649),  time:31.097, tt:310.968\n",
      "Ep:10, loss:0.00020, loss_test:0.10313, lr:1.00e-02, fs:0.75269 (r=0.805,p=0.707),  time:31.160, tt:342.762\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10293, lr:1.00e-02, fs:0.75269 (r=0.805,p=0.707),  time:30.969, tt:371.628\n",
      "Ep:12, loss:0.00018, loss_test:0.10154, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:31.092, tt:404.195\n",
      "Ep:13, loss:0.00018, loss_test:0.09951, lr:1.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:31.009, tt:434.126\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09655, lr:1.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:30.877, tt:463.155\n",
      "Ep:15, loss:0.00016, loss_test:0.09511, lr:1.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:30.819, tt:493.110\n",
      "Ep:16, loss:0.00015, loss_test:0.09481, lr:1.00e-02, fs:0.77907 (r=0.770,p=0.788),  time:30.836, tt:524.218\n",
      "Ep:17, loss:0.00015, loss_test:0.09402, lr:1.00e-02, fs:0.79532 (r=0.782,p=0.810),  time:30.765, tt:553.766\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09251, lr:1.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:30.728, tt:583.830\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.08945, lr:1.00e-02, fs:0.80925 (r=0.805,p=0.814),  time:30.761, tt:615.211\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.09075, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:30.813, tt:647.065\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.08851, lr:1.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:30.761, tt:676.739\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08859, lr:1.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:30.803, tt:708.479\n",
      "Ep:23, loss:0.00011, loss_test:0.08798, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:30.780, tt:738.711\n",
      "Ep:24, loss:0.00010, loss_test:0.08698, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:30.698, tt:767.443\n",
      "Ep:25, loss:0.00010, loss_test:0.08585, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:30.585, tt:795.206\n",
      "Ep:26, loss:0.00009, loss_test:0.08649, lr:1.00e-02, fs:0.81657 (r=0.793,p=0.841),  time:30.499, tt:823.463\n",
      "Ep:27, loss:0.00009, loss_test:0.08567, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:30.526, tt:854.739\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.08579, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:30.519, tt:885.060\n",
      "Ep:29, loss:0.00008, loss_test:0.08452, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:30.538, tt:916.137\n",
      "Ep:30, loss:0.00007, loss_test:0.08385, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:30.476, tt:944.755\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.08288, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:30.393, tt:972.580\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.08027, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:30.339, tt:1001.197\n",
      "Ep:33, loss:0.00006, loss_test:0.08824, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:30.353, tt:1032.004\n",
      "Ep:34, loss:0.00006, loss_test:0.07597, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:30.380, tt:1063.291\n",
      "Ep:35, loss:0.00006, loss_test:0.09235, lr:1.00e-02, fs:0.81818 (r=0.724,p=0.940),  time:30.377, tt:1093.582\n",
      "Ep:36, loss:0.00005, loss_test:0.07655, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:30.432, tt:1125.994\n",
      "Ep:37, loss:0.00005, loss_test:0.08737, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:30.389, tt:1154.798\n",
      "Ep:38, loss:0.00005, loss_test:0.07756, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:30.406, tt:1185.841\n",
      "Ep:39, loss:0.00004, loss_test:0.08638, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:30.431, tt:1217.259\n",
      "Ep:40, loss:0.00004, loss_test:0.07613, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:30.409, tt:1246.763\n",
      "Ep:41, loss:0.00004, loss_test:0.08150, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:30.402, tt:1276.886\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00004, loss_test:0.07474, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:30.361, tt:1305.535\n",
      "Ep:43, loss:0.00004, loss_test:0.08286, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:30.298, tt:1333.123\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.07338, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:30.279, tt:1362.565\n",
      "Ep:45, loss:0.00003, loss_test:0.07991, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.319, tt:1394.661\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.07692, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:30.307, tt:1424.432\n",
      "Ep:47, loss:0.00003, loss_test:0.08235, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:30.307, tt:1454.739\n",
      "Ep:48, loss:0.00002, loss_test:0.07803, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.315, tt:1485.416\n",
      "Ep:49, loss:0.00002, loss_test:0.08106, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.339, tt:1516.951\n",
      "Ep:50, loss:0.00002, loss_test:0.07945, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.318, tt:1546.206\n",
      "Ep:51, loss:0.00002, loss_test:0.07911, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.337, tt:1577.522\n",
      "Ep:52, loss:0.00002, loss_test:0.08283, lr:1.00e-02, fs:0.81879 (r=0.701,p=0.984),  time:30.360, tt:1609.097\n",
      "Ep:53, loss:0.00002, loss_test:0.07832, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.384, tt:1640.746\n",
      "Ep:54, loss:0.00002, loss_test:0.07943, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.374, tt:1670.562\n",
      "Ep:55, loss:0.00001, loss_test:0.07834, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:30.402, tt:1702.488\n",
      "Ep:56, loss:0.00001, loss_test:0.08104, lr:1.00e-02, fs:0.85714 (r=0.759,p=0.985),  time:30.363, tt:1730.715\n",
      "Ep:57, loss:0.00001, loss_test:0.07342, lr:9.90e-03, fs:0.87898 (r=0.793,p=0.986),  time:30.396, tt:1762.982\n",
      "Ep:58, loss:0.00001, loss_test:0.08178, lr:9.80e-03, fs:0.81081 (r=0.690,p=0.984),  time:30.429, tt:1795.293\n",
      "Ep:59, loss:0.00001, loss_test:0.08075, lr:9.70e-03, fs:0.85714 (r=0.759,p=0.985),  time:30.484, tt:1829.020\n",
      "Ep:60, loss:0.00001, loss_test:0.07649, lr:9.61e-03, fs:0.87898 (r=0.793,p=0.986),  time:30.575, tt:1865.055\n",
      "Ep:61, loss:0.00001, loss_test:0.07532, lr:9.51e-03, fs:0.87342 (r=0.793,p=0.972),  time:30.670, tt:1901.565\n",
      "Ep:62, loss:0.00001, loss_test:0.08279, lr:9.41e-03, fs:0.84967 (r=0.747,p=0.985),  time:30.754, tt:1937.493\n",
      "Ep:63, loss:0.00001, loss_test:0.07666, lr:9.32e-03, fs:0.87898 (r=0.793,p=0.986),  time:30.790, tt:1970.568\n",
      "Ep:64, loss:0.00001, loss_test:0.07865, lr:9.23e-03, fs:0.79452 (r=0.667,p=0.983),  time:30.833, tt:2004.164\n",
      "Ep:65, loss:0.00001, loss_test:0.07700, lr:9.14e-03, fs:0.87898 (r=0.793,p=0.986),  time:30.888, tt:2038.596\n",
      "Ep:66, loss:0.00001, loss_test:0.07682, lr:9.04e-03, fs:0.87898 (r=0.793,p=0.986),  time:30.962, tt:2074.468\n",
      "Ep:67, loss:0.00001, loss_test:0.07662, lr:8.95e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.058, tt:2111.947\n",
      "Ep:68, loss:0.00001, loss_test:0.07627, lr:8.86e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.132, tt:2148.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00000, loss_test:0.08033, lr:8.78e-03, fs:0.86452 (r=0.770,p=0.985),  time:31.178, tt:2182.428\n",
      "Ep:70, loss:0.00000, loss_test:0.07822, lr:8.69e-03, fs:0.84967 (r=0.747,p=0.985),  time:31.200, tt:2215.188\n",
      "Ep:71, loss:0.00000, loss_test:0.07712, lr:8.60e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.276, tt:2251.899\n",
      "Ep:72, loss:0.00000, loss_test:0.07744, lr:8.51e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.346, tt:2288.275\n",
      "Ep:73, loss:0.00000, loss_test:0.07748, lr:8.43e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.405, tt:2323.999\n",
      "Ep:74, loss:0.00000, loss_test:0.07956, lr:8.35e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.491, tt:2361.827\n",
      "Ep:75, loss:0.00000, loss_test:0.07608, lr:8.26e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.563, tt:2398.762\n",
      "Ep:76, loss:0.00000, loss_test:0.07800, lr:8.18e-03, fs:0.83444 (r=0.724,p=0.984),  time:31.643, tt:2436.500\n",
      "Ep:77, loss:0.00000, loss_test:0.07612, lr:8.10e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.691, tt:2471.870\n",
      "Ep:78, loss:0.00000, loss_test:0.07759, lr:8.02e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.744, tt:2507.765\n",
      "Ep:79, loss:0.00000, loss_test:0.07722, lr:7.94e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.806, tt:2544.500\n",
      "Ep:80, loss:0.00000, loss_test:0.07690, lr:7.86e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.863, tt:2580.886\n",
      "Ep:81, loss:0.00000, loss_test:0.07605, lr:7.78e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.892, tt:2615.119\n",
      "Ep:82, loss:0.00000, loss_test:0.07601, lr:7.70e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.945, tt:2651.417\n",
      "Ep:83, loss:0.00000, loss_test:0.07655, lr:7.62e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.984, tt:2686.646\n",
      "Ep:84, loss:0.00000, loss_test:0.07664, lr:7.55e-03, fs:0.87898 (r=0.793,p=0.986),  time:31.998, tt:2719.820\n",
      "Ep:85, loss:0.00000, loss_test:0.07465, lr:7.47e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.055, tt:2756.752\n",
      "Ep:86, loss:0.00000, loss_test:0.07875, lr:7.40e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.074, tt:2790.431\n",
      "Ep:87, loss:0.00000, loss_test:0.07594, lr:7.32e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.098, tt:2824.598\n",
      "Ep:88, loss:0.00000, loss_test:0.07540, lr:7.25e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.137, tt:2860.169\n",
      "Ep:89, loss:0.00000, loss_test:0.07563, lr:7.18e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.170, tt:2895.275\n",
      "Ep:90, loss:0.00000, loss_test:0.07670, lr:7.11e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.218, tt:2931.809\n",
      "Ep:91, loss:0.00000, loss_test:0.07490, lr:7.03e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.283, tt:2969.997\n",
      "Ep:92, loss:0.00000, loss_test:0.07658, lr:6.96e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.315, tt:3005.303\n",
      "Ep:93, loss:0.00000, loss_test:0.07691, lr:6.89e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.358, tt:3041.687\n",
      "Ep:94, loss:0.00000, loss_test:0.07502, lr:6.83e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.411, tt:3079.031\n",
      "Ep:95, loss:0.00000, loss_test:0.07711, lr:6.76e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.474, tt:3117.489\n",
      "Ep:96, loss:0.00000, loss_test:0.07774, lr:6.69e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.486, tt:3151.176\n",
      "Ep:97, loss:0.00000, loss_test:0.07500, lr:6.62e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.498, tt:3184.841\n",
      "Ep:98, loss:0.00000, loss_test:0.07631, lr:6.56e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.528, tt:3220.233\n",
      "Ep:99, loss:0.00000, loss_test:0.07829, lr:6.49e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.555, tt:3255.480\n",
      "Ep:100, loss:0.00000, loss_test:0.07607, lr:6.43e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.583, tt:3290.891\n",
      "Ep:101, loss:0.00000, loss_test:0.07520, lr:6.36e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.629, tt:3328.190\n",
      "Ep:102, loss:0.00000, loss_test:0.07635, lr:6.30e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.669, tt:3364.865\n",
      "Ep:103, loss:0.00000, loss_test:0.07609, lr:6.24e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.699, tt:3400.729\n",
      "Ep:104, loss:0.00000, loss_test:0.07457, lr:6.17e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.719, tt:3435.517\n",
      "Ep:105, loss:0.00000, loss_test:0.07487, lr:6.11e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.746, tt:3471.034\n",
      "Ep:106, loss:0.00000, loss_test:0.07475, lr:6.05e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.784, tt:3507.851\n",
      "Ep:107, loss:0.00000, loss_test:0.07498, lr:5.99e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.836, tt:3546.242\n",
      "Ep:108, loss:0.00000, loss_test:0.07510, lr:5.93e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.888, tt:3584.745\n",
      "Ep:109, loss:0.00000, loss_test:0.07593, lr:5.87e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.941, tt:3623.455\n",
      "Ep:110, loss:0.00000, loss_test:0.07573, lr:5.81e-03, fs:0.87898 (r=0.793,p=0.986),  time:32.991, tt:3662.005\n",
      "Ep:111, loss:0.00000, loss_test:0.07384, lr:5.75e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.031, tt:3699.441\n",
      "Ep:112, loss:0.00000, loss_test:0.07618, lr:5.70e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.064, tt:3736.233\n",
      "Ep:113, loss:0.00000, loss_test:0.07579, lr:5.64e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.102, tt:3773.648\n",
      "Ep:114, loss:0.00000, loss_test:0.07424, lr:5.58e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.144, tt:3811.571\n",
      "Ep:115, loss:0.00000, loss_test:0.07576, lr:5.53e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.176, tt:3848.383\n",
      "Ep:116, loss:0.00000, loss_test:0.07583, lr:5.47e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.219, tt:3886.590\n",
      "Ep:117, loss:0.00000, loss_test:0.07518, lr:5.42e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.258, tt:3924.434\n",
      "Ep:118, loss:0.00000, loss_test:0.07474, lr:5.36e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.308, tt:3963.685\n",
      "Ep:119, loss:0.00000, loss_test:0.07437, lr:5.31e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.303, tt:3996.357\n",
      "Ep:120, loss:0.00000, loss_test:0.07499, lr:5.26e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.326, tt:4032.406\n",
      "Ep:121, loss:0.00000, loss_test:0.07418, lr:5.20e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.355, tt:4069.307\n",
      "Ep:122, loss:0.00000, loss_test:0.07487, lr:5.15e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.374, tt:4105.054\n",
      "Ep:123, loss:0.00000, loss_test:0.07562, lr:5.10e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.410, tt:4142.797\n",
      "Ep:124, loss:0.00000, loss_test:0.07445, lr:5.05e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.426, tt:4178.259\n",
      "Ep:125, loss:0.00000, loss_test:0.07375, lr:5.00e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.453, tt:4215.120\n",
      "Ep:126, loss:0.00000, loss_test:0.07450, lr:4.95e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.488, tt:4252.918\n",
      "Ep:127, loss:0.00000, loss_test:0.07452, lr:4.90e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.506, tt:4288.785\n",
      "Ep:128, loss:0.00000, loss_test:0.07434, lr:4.85e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.526, tt:4324.856\n",
      "Ep:129, loss:0.00000, loss_test:0.07429, lr:4.80e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.541, tt:4360.334\n",
      "Ep:130, loss:0.00000, loss_test:0.07427, lr:4.75e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.560, tt:4396.410\n",
      "Ep:131, loss:0.00000, loss_test:0.07397, lr:4.71e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.583, tt:4432.974\n",
      "Ep:132, loss:0.00000, loss_test:0.07401, lr:4.66e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.637, tt:4473.786\n",
      "Ep:133, loss:0.00000, loss_test:0.07386, lr:4.61e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.662, tt:4510.642\n",
      "Ep:134, loss:0.00000, loss_test:0.07384, lr:4.57e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.659, tt:4543.949\n",
      "Ep:135, loss:0.00000, loss_test:0.07417, lr:4.52e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.678, tt:4580.184\n",
      "Ep:136, loss:0.00000, loss_test:0.07437, lr:4.48e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.686, tt:4614.935\n",
      "Ep:137, loss:0.00000, loss_test:0.07391, lr:4.43e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.709, tt:4651.786\n",
      "Ep:138, loss:0.00000, loss_test:0.07377, lr:4.39e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.710, tt:4685.709\n",
      "Ep:139, loss:0.00000, loss_test:0.07384, lr:4.34e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.727, tt:4721.724\n",
      "Ep:140, loss:0.00000, loss_test:0.07473, lr:4.30e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.732, tt:4756.270\n",
      "Ep:141, loss:0.00000, loss_test:0.07441, lr:4.26e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.750, tt:4792.561\n",
      "Ep:142, loss:0.00000, loss_test:0.07382, lr:4.21e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.767, tt:4828.699\n",
      "Ep:143, loss:0.00000, loss_test:0.07418, lr:4.17e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.777, tt:4863.893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.07496, lr:4.13e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.790, tt:4899.532\n",
      "Ep:145, loss:0.00000, loss_test:0.07464, lr:4.09e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.807, tt:4935.844\n",
      "Ep:146, loss:0.00000, loss_test:0.07388, lr:4.05e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.816, tt:4970.947\n",
      "Ep:147, loss:0.00000, loss_test:0.07362, lr:4.01e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.821, tt:5005.471\n",
      "Ep:148, loss:0.00000, loss_test:0.07435, lr:3.97e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.840, tt:5042.202\n",
      "Ep:149, loss:0.00000, loss_test:0.07548, lr:3.93e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.856, tt:5078.361\n",
      "Ep:150, loss:0.00000, loss_test:0.07537, lr:3.89e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.871, tt:5114.591\n",
      "Ep:151, loss:0.00000, loss_test:0.07404, lr:3.85e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.910, tt:5154.314\n",
      "Ep:152, loss:0.00000, loss_test:0.07381, lr:3.81e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.927, tt:5190.770\n",
      "Ep:153, loss:0.00000, loss_test:0.07513, lr:3.77e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.940, tt:5226.781\n",
      "Ep:154, loss:0.00000, loss_test:0.07513, lr:3.73e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.963, tt:5264.196\n",
      "Ep:155, loss:0.00000, loss_test:0.07428, lr:3.70e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.964, tt:5298.329\n",
      "Ep:156, loss:0.00000, loss_test:0.07376, lr:3.66e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.978, tt:5334.507\n",
      "Ep:157, loss:0.00000, loss_test:0.07390, lr:3.62e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.984, tt:5369.401\n",
      "Ep:158, loss:0.00000, loss_test:0.07468, lr:3.59e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.996, tt:5405.335\n",
      "Ep:159, loss:0.00000, loss_test:0.07480, lr:3.55e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.013, tt:5442.010\n",
      "Ep:160, loss:0.00000, loss_test:0.07377, lr:3.52e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.016, tt:5476.502\n",
      "Ep:161, loss:0.00000, loss_test:0.07362, lr:3.48e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.025, tt:5512.036\n",
      "Ep:162, loss:0.00000, loss_test:0.07437, lr:3.45e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.041, tt:5548.740\n",
      "Ep:163, loss:0.00000, loss_test:0.07436, lr:3.41e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.058, tt:5585.575\n",
      "Ep:164, loss:0.00000, loss_test:0.07386, lr:3.38e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.079, tt:5623.057\n",
      "Ep:165, loss:0.00000, loss_test:0.07356, lr:3.34e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.090, tt:5658.943\n",
      "Ep:166, loss:0.00000, loss_test:0.07351, lr:3.31e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.116, tt:5697.382\n",
      "Ep:167, loss:0.00000, loss_test:0.07345, lr:3.28e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.124, tt:5732.758\n",
      "Ep:168, loss:0.00000, loss_test:0.07351, lr:3.24e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.133, tt:5768.529\n",
      "Ep:169, loss:0.00000, loss_test:0.07356, lr:3.21e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.156, tt:5806.484\n",
      "Ep:170, loss:0.00000, loss_test:0.07337, lr:3.18e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.162, tt:5841.696\n",
      "Ep:171, loss:0.00000, loss_test:0.07313, lr:3.15e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.179, tt:5878.843\n",
      "Ep:172, loss:0.00000, loss_test:0.07340, lr:3.12e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.180, tt:5913.067\n",
      "Ep:173, loss:0.00000, loss_test:0.07367, lr:3.09e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.192, tt:5949.437\n",
      "Ep:174, loss:0.00000, loss_test:0.07354, lr:3.05e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.209, tt:5986.631\n",
      "Ep:175, loss:0.00000, loss_test:0.07340, lr:3.02e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.224, tt:6023.478\n",
      "Ep:176, loss:0.00000, loss_test:0.07324, lr:2.99e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.238, tt:6060.041\n",
      "Ep:177, loss:0.00000, loss_test:0.07322, lr:2.96e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.243, tt:6095.217\n",
      "Ep:178, loss:0.00000, loss_test:0.07354, lr:2.93e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.253, tt:6131.297\n",
      "Ep:179, loss:0.00000, loss_test:0.07372, lr:2.90e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.256, tt:6166.125\n",
      "Ep:180, loss:0.00000, loss_test:0.07319, lr:2.88e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.269, tt:6202.756\n",
      "Ep:181, loss:0.00000, loss_test:0.07344, lr:2.85e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.285, tt:6239.949\n",
      "Ep:182, loss:0.00000, loss_test:0.07406, lr:2.82e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.296, tt:6276.092\n",
      "Ep:183, loss:0.00000, loss_test:0.07394, lr:2.79e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.303, tt:6311.688\n",
      "Ep:184, loss:0.00000, loss_test:0.07361, lr:2.76e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.310, tt:6347.398\n",
      "Ep:185, loss:0.00000, loss_test:0.07352, lr:2.73e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.318, tt:6383.117\n",
      "Ep:186, loss:0.00000, loss_test:0.07355, lr:2.71e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.333, tt:6420.178\n",
      "Ep:187, loss:0.00000, loss_test:0.07340, lr:2.68e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.356, tt:6458.949\n",
      "Ep:188, loss:0.00000, loss_test:0.07375, lr:2.65e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.373, tt:6496.403\n",
      "Ep:189, loss:0.00000, loss_test:0.07402, lr:2.63e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.398, tt:6535.622\n",
      "Ep:190, loss:0.00000, loss_test:0.07345, lr:2.60e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.413, tt:6572.810\n",
      "Ep:191, loss:0.00000, loss_test:0.07317, lr:2.57e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.429, tt:6610.426\n",
      "Ep:192, loss:0.00000, loss_test:0.07346, lr:2.55e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.434, tt:6645.810\n",
      "Ep:193, loss:0.00000, loss_test:0.07373, lr:2.52e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.455, tt:6684.172\n",
      "Ep:194, loss:0.00000, loss_test:0.07354, lr:2.50e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.475, tt:6722.578\n",
      "Ep:195, loss:0.00000, loss_test:0.07311, lr:2.47e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.490, tt:6760.060\n",
      "Ep:196, loss:0.00000, loss_test:0.07303, lr:2.45e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.484, tt:6793.396\n",
      "Ep:197, loss:0.00000, loss_test:0.07356, lr:2.42e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.482, tt:6827.498\n",
      "Ep:198, loss:0.00000, loss_test:0.07366, lr:2.40e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.487, tt:6862.992\n",
      "Ep:199, loss:0.00000, loss_test:0.07334, lr:2.38e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.500, tt:6899.915\n",
      "Ep:200, loss:0.00000, loss_test:0.07303, lr:2.35e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.513, tt:6937.048\n",
      "Ep:201, loss:0.00000, loss_test:0.07327, lr:2.33e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.486, tt:6966.235\n",
      "Ep:202, loss:0.00000, loss_test:0.07319, lr:2.31e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.445, tt:6992.405\n",
      "Ep:203, loss:0.00000, loss_test:0.07333, lr:2.28e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.411, tt:7019.889\n",
      "Ep:204, loss:0.00000, loss_test:0.07362, lr:2.26e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.353, tt:7042.458\n",
      "Ep:205, loss:0.00000, loss_test:0.07363, lr:2.24e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.281, tt:7061.977\n",
      "Ep:206, loss:0.00000, loss_test:0.07336, lr:2.21e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.182, tt:7075.733\n",
      "Ep:207, loss:0.00000, loss_test:0.07319, lr:2.19e-03, fs:0.87898 (r=0.793,p=0.986),  time:34.078, tt:7088.329\n",
      "Ep:208, loss:0.00000, loss_test:0.07312, lr:2.17e-03, fs:0.87898 (r=0.793,p=0.986),  time:33.974, tt:7100.598\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01926, lr:6.00e-02, fs:0.64912 (r=0.851,p=0.525),  time:34.496, tt:34.496\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02139, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.694, tt:69.388\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02245, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.643, tt:103.929\n",
      "Ep:3, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.537, tt:138.148\n",
      "Ep:4, loss:0.00004, loss_test:0.02050, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.147, tt:175.733\n",
      "Ep:5, loss:0.00004, loss_test:0.01886, lr:6.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:35.256, tt:211.535\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01776, lr:6.00e-02, fs:0.68354 (r=0.931,p=0.540),  time:35.231, tt:246.619\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01733, lr:6.00e-02, fs:0.69767 (r=0.862,p=0.586),  time:35.182, tt:281.454\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01698, lr:6.00e-02, fs:0.71498 (r=0.851,p=0.617),  time:34.945, tt:314.505\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.71362 (r=0.874,p=0.603),  time:35.108, tt:351.081\n",
      "Ep:10, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.69725 (r=0.874,p=0.580),  time:35.141, tt:386.555\n",
      "Ep:11, loss:0.00003, loss_test:0.01652, lr:6.00e-02, fs:0.70093 (r=0.862,p=0.591),  time:35.067, tt:420.803\n",
      "Ep:12, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.70244 (r=0.828,p=0.610),  time:35.110, tt:456.428\n",
      "Ep:13, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.72081 (r=0.816,p=0.645),  time:35.089, tt:491.243\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.72251 (r=0.793,p=0.663),  time:35.297, tt:529.455\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.71579 (r=0.782,p=0.660),  time:35.339, tt:565.418\n",
      "Ep:16, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:35.448, tt:602.613\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.74866 (r=0.805,p=0.700),  time:35.456, tt:638.210\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:35.670, tt:677.732\n",
      "Ep:19, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.75410 (r=0.793,p=0.719),  time:35.629, tt:712.571\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:35.600, tt:747.610\n",
      "Ep:21, loss:0.00002, loss_test:0.01546, lr:6.00e-02, fs:0.76404 (r=0.782,p=0.747),  time:35.591, tt:783.001\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:35.535, tt:817.313\n",
      "Ep:23, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.75862 (r=0.759,p=0.759),  time:35.479, tt:851.492\n",
      "Ep:24, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.76301 (r=0.759,p=0.767),  time:35.552, tt:888.795\n",
      "Ep:25, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:35.516, tt:923.419\n",
      "Ep:26, loss:0.00002, loss_test:0.01554, lr:6.00e-02, fs:0.77193 (r=0.759,p=0.786),  time:35.422, tt:956.387\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01562, lr:6.00e-02, fs:0.77907 (r=0.770,p=0.788),  time:35.422, tt:991.829\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:35.458, tt:1028.278\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:35.533, tt:1065.978\n",
      "Ep:30, loss:0.00002, loss_test:0.01572, lr:6.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:35.540, tt:1101.745\n",
      "Ep:31, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:35.540, tt:1137.271\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:35.558, tt:1173.415\n",
      "Ep:33, loss:0.00001, loss_test:0.01580, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:35.490, tt:1206.675\n",
      "Ep:34, loss:0.00001, loss_test:0.01587, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:35.491, tt:1242.190\n",
      "Ep:35, loss:0.00001, loss_test:0.01590, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:35.486, tt:1277.480\n",
      "Ep:36, loss:0.00001, loss_test:0.01603, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:35.470, tt:1312.384\n",
      "Ep:37, loss:0.00001, loss_test:0.01617, lr:6.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:35.543, tt:1350.631\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:35.531, tt:1385.722\n",
      "Ep:39, loss:0.00001, loss_test:0.01636, lr:6.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:35.498, tt:1419.905\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01649, lr:6.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:35.483, tt:1454.813\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01660, lr:6.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:35.606, tt:1495.463\n",
      "Ep:42, loss:0.00001, loss_test:0.01673, lr:6.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:35.571, tt:1529.538\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01693, lr:6.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:35.532, tt:1563.416\n",
      "Ep:44, loss:0.00001, loss_test:0.01707, lr:6.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:35.529, tt:1598.787\n",
      "Ep:45, loss:0.00001, loss_test:0.01719, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:35.535, tt:1634.589\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01718, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:35.561, tt:1671.368\n",
      "Ep:47, loss:0.00001, loss_test:0.01743, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:35.591, tt:1708.372\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01770, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:35.605, tt:1744.649\n",
      "Ep:49, loss:0.00001, loss_test:0.01784, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:35.641, tt:1782.045\n",
      "Ep:50, loss:0.00001, loss_test:0.01804, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:35.661, tt:1818.699\n",
      "Ep:51, loss:0.00001, loss_test:0.01827, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:35.673, tt:1854.982\n",
      "Ep:52, loss:0.00001, loss_test:0.01830, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:35.678, tt:1890.942\n",
      "Ep:53, loss:0.00001, loss_test:0.01851, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.696, tt:1927.601\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01862, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.685, tt:1962.699\n",
      "Ep:55, loss:0.00001, loss_test:0.01873, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.701, tt:1999.283\n",
      "Ep:56, loss:0.00001, loss_test:0.01900, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.714, tt:2035.713\n",
      "Ep:57, loss:0.00001, loss_test:0.01908, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.748, tt:2073.399\n",
      "Ep:58, loss:0.00001, loss_test:0.01931, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.762, tt:2109.987\n",
      "Ep:59, loss:0.00001, loss_test:0.01950, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.798, tt:2147.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01950, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.873, tt:2188.244\n",
      "Ep:61, loss:0.00001, loss_test:0.01986, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.864, tt:2223.570\n",
      "Ep:62, loss:0.00001, loss_test:0.01991, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.851, tt:2258.594\n",
      "Ep:63, loss:0.00001, loss_test:0.02015, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.851, tt:2294.457\n",
      "Ep:64, loss:0.00001, loss_test:0.02038, lr:6.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.849, tt:2330.199\n",
      "Ep:65, loss:0.00001, loss_test:0.02037, lr:5.94e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.859, tt:2366.699\n",
      "Ep:66, loss:0.00001, loss_test:0.02064, lr:5.88e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.858, tt:2402.482\n",
      "Ep:67, loss:0.00001, loss_test:0.02080, lr:5.82e-02, fs:0.84472 (r=0.782,p=0.919),  time:35.867, tt:2438.943\n",
      "Ep:68, loss:0.00000, loss_test:0.02094, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.858, tt:2474.181\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00000, loss_test:0.02114, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.843, tt:2509.040\n",
      "Ep:70, loss:0.00000, loss_test:0.02125, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.845, tt:2544.962\n",
      "Ep:71, loss:0.00000, loss_test:0.02157, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.847, tt:2581.008\n",
      "Ep:72, loss:0.00000, loss_test:0.02175, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.836, tt:2615.995\n",
      "Ep:73, loss:0.00000, loss_test:0.02197, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.830, tt:2651.410\n",
      "Ep:74, loss:0.00000, loss_test:0.02224, lr:5.76e-02, fs:0.85000 (r=0.782,p=0.932),  time:35.832, tt:2687.369\n",
      "Ep:75, loss:0.00000, loss_test:0.02232, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.822, tt:2722.437\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00000, loss_test:0.02264, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.822, tt:2758.255\n",
      "Ep:77, loss:0.00000, loss_test:0.02263, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.803, tt:2792.599\n",
      "Ep:78, loss:0.00000, loss_test:0.02284, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.815, tt:2829.419\n",
      "Ep:79, loss:0.00000, loss_test:0.02315, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.826, tt:2866.090\n",
      "Ep:80, loss:0.00000, loss_test:0.02318, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.824, tt:2901.713\n",
      "Ep:81, loss:0.00000, loss_test:0.02344, lr:5.76e-02, fs:0.85535 (r=0.782,p=0.944),  time:35.821, tt:2937.324\n",
      "Ep:82, loss:0.00000, loss_test:0.02343, lr:5.76e-02, fs:0.86076 (r=0.782,p=0.958),  time:35.815, tt:2972.608\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00000, loss_test:0.02376, lr:5.76e-02, fs:0.86076 (r=0.782,p=0.958),  time:35.872, tt:3013.283\n",
      "Ep:84, loss:0.00000, loss_test:0.02373, lr:5.76e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.868, tt:3048.785\n",
      "Ep:85, loss:0.00000, loss_test:0.02401, lr:5.76e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.874, tt:3085.195\n",
      "Ep:86, loss:0.00000, loss_test:0.02407, lr:5.76e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.861, tt:3119.887\n",
      "Ep:87, loss:0.00000, loss_test:0.02420, lr:5.76e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.851, tt:3154.902\n",
      "Ep:88, loss:0.00000, loss_test:0.02446, lr:5.76e-02, fs:0.83871 (r=0.747,p=0.956),  time:35.838, tt:3189.565\n",
      "Ep:89, loss:0.00000, loss_test:0.02441, lr:5.76e-02, fs:0.83871 (r=0.747,p=0.956),  time:35.843, tt:3225.836\n",
      "Ep:90, loss:0.00000, loss_test:0.02465, lr:5.76e-02, fs:0.83871 (r=0.747,p=0.956),  time:35.825, tt:3260.043\n",
      "Ep:91, loss:0.00000, loss_test:0.02476, lr:5.76e-02, fs:0.83871 (r=0.747,p=0.956),  time:35.840, tt:3297.274\n",
      "Ep:92, loss:0.00000, loss_test:0.02488, lr:5.76e-02, fs:0.83117 (r=0.736,p=0.955),  time:35.849, tt:3333.965\n",
      "Ep:93, loss:0.00000, loss_test:0.02514, lr:5.76e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.847, tt:3369.597\n",
      "Ep:94, loss:0.00000, loss_test:0.02516, lr:5.71e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.851, tt:3405.878\n",
      "Ep:95, loss:0.00000, loss_test:0.02522, lr:5.65e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.868, tt:3443.317\n",
      "Ep:96, loss:0.00000, loss_test:0.02544, lr:5.59e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.855, tt:3477.893\n",
      "Ep:97, loss:0.00000, loss_test:0.02559, lr:5.54e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.869, tt:3515.209\n",
      "Ep:98, loss:0.00000, loss_test:0.02571, lr:5.48e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.867, tt:3550.873\n",
      "Ep:99, loss:0.00000, loss_test:0.02575, lr:5.43e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.882, tt:3588.161\n",
      "Ep:100, loss:0.00000, loss_test:0.02595, lr:5.37e-02, fs:0.81879 (r=0.701,p=0.984),  time:35.849, tt:3620.749\n",
      "Ep:101, loss:0.00000, loss_test:0.02605, lr:5.32e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.870, tt:3658.723\n",
      "Ep:102, loss:0.00000, loss_test:0.02607, lr:5.27e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.905, tt:3698.185\n",
      "Ep:103, loss:0.00000, loss_test:0.02627, lr:5.21e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.900, tt:3733.588\n",
      "Ep:104, loss:0.00000, loss_test:0.02628, lr:5.16e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.865, tt:3765.799\n",
      "Ep:105, loss:0.00000, loss_test:0.02640, lr:5.11e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.829, tt:3797.860\n",
      "Ep:106, loss:0.00000, loss_test:0.02654, lr:5.06e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.804, tt:3831.027\n",
      "Ep:107, loss:0.00000, loss_test:0.02654, lr:5.01e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.772, tt:3863.322\n",
      "Ep:108, loss:0.00000, loss_test:0.02669, lr:4.96e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.737, tt:3895.363\n",
      "Ep:109, loss:0.00000, loss_test:0.02679, lr:4.91e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.700, tt:3927.011\n",
      "Ep:110, loss:0.00000, loss_test:0.02685, lr:4.86e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.664, tt:3958.659\n",
      "Ep:111, loss:0.00000, loss_test:0.02669, lr:4.81e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.634, tt:3990.966\n",
      "Ep:112, loss:0.00000, loss_test:0.02717, lr:4.76e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.699, tt:4034.002\n",
      "Ep:113, loss:0.00000, loss_test:0.02705, lr:4.71e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.696, tt:4069.381\n",
      "Ep:114, loss:0.00000, loss_test:0.02712, lr:4.67e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.686, tt:4103.899\n",
      "Ep:115, loss:0.00000, loss_test:0.02726, lr:4.62e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.700, tt:4141.251\n",
      "Ep:116, loss:0.00000, loss_test:0.02717, lr:4.57e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.697, tt:4176.562\n",
      "Ep:117, loss:0.00000, loss_test:0.02748, lr:4.53e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.697, tt:4212.237\n",
      "Ep:118, loss:0.00000, loss_test:0.02746, lr:4.48e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.689, tt:4247.000\n",
      "Ep:119, loss:0.00000, loss_test:0.02750, lr:4.44e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.693, tt:4283.177\n",
      "Ep:120, loss:0.00000, loss_test:0.02757, lr:4.39e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.700, tt:4319.743\n",
      "Ep:121, loss:0.00000, loss_test:0.02759, lr:4.35e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.707, tt:4356.311\n",
      "Ep:122, loss:0.00000, loss_test:0.02772, lr:4.31e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.717, tt:4393.238\n",
      "Ep:123, loss:0.00000, loss_test:0.02766, lr:4.26e-02, fs:0.80272 (r=0.678,p=0.983),  time:35.718, tt:4429.014\n",
      "Ep:124, loss:0.00000, loss_test:0.02780, lr:4.22e-02, fs:0.80272 (r=0.678,p=0.983),  time:35.719, tt:4464.829\n",
      "Ep:125, loss:0.00000, loss_test:0.02780, lr:4.18e-02, fs:0.80272 (r=0.678,p=0.983),  time:35.709, tt:4499.276\n",
      "Ep:126, loss:0.00000, loss_test:0.02791, lr:4.14e-02, fs:0.79452 (r=0.667,p=0.983),  time:35.708, tt:4534.907\n",
      "Ep:127, loss:0.00000, loss_test:0.02798, lr:4.10e-02, fs:0.79452 (r=0.667,p=0.983),  time:35.700, tt:4569.603\n",
      "Ep:128, loss:0.00000, loss_test:0.02791, lr:4.05e-02, fs:0.79452 (r=0.667,p=0.983),  time:35.679, tt:4602.607\n",
      "Ep:129, loss:0.00000, loss_test:0.02801, lr:4.01e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.671, tt:4637.289\n",
      "Ep:130, loss:0.00000, loss_test:0.02808, lr:3.97e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.663, tt:4671.856\n",
      "Ep:131, loss:0.00000, loss_test:0.02810, lr:3.93e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.657, tt:4706.742\n",
      "Ep:132, loss:0.00000, loss_test:0.02810, lr:3.89e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.659, tt:4742.617\n",
      "Ep:133, loss:0.00000, loss_test:0.02825, lr:3.86e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.666, tt:4779.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.02811, lr:3.82e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.661, tt:4814.282\n",
      "Ep:135, loss:0.00000, loss_test:0.02828, lr:3.78e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.659, tt:4849.579\n",
      "Ep:136, loss:0.00000, loss_test:0.02833, lr:3.74e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.718, tt:4893.407\n",
      "Ep:137, loss:0.00000, loss_test:0.02824, lr:3.70e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.726, tt:4930.230\n",
      "Ep:138, loss:0.00000, loss_test:0.02850, lr:3.67e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.726, tt:4965.969\n",
      "Ep:139, loss:0.00000, loss_test:0.02842, lr:3.63e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.731, tt:5002.271\n",
      "Ep:140, loss:0.00000, loss_test:0.02841, lr:3.59e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.740, tt:5039.388\n",
      "Ep:141, loss:0.00000, loss_test:0.02858, lr:3.56e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.728, tt:5073.343\n",
      "Ep:142, loss:0.00000, loss_test:0.02855, lr:3.52e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.734, tt:5109.970\n",
      "Ep:143, loss:0.00000, loss_test:0.02852, lr:3.49e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.720, tt:5143.689\n",
      "Ep:144, loss:0.00000, loss_test:0.02864, lr:3.45e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.708, tt:5177.647\n",
      "Ep:145, loss:0.00000, loss_test:0.02867, lr:3.42e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.705, tt:5212.895\n",
      "Ep:146, loss:0.00000, loss_test:0.02866, lr:3.38e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.696, tt:5247.279\n",
      "Ep:147, loss:0.00000, loss_test:0.02877, lr:3.35e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.699, tt:5283.437\n",
      "Ep:148, loss:0.00000, loss_test:0.02875, lr:3.32e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.693, tt:5318.189\n",
      "Ep:149, loss:0.00000, loss_test:0.02881, lr:3.28e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.694, tt:5354.029\n",
      "Ep:150, loss:0.00000, loss_test:0.02880, lr:3.25e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.701, tt:5390.887\n",
      "Ep:151, loss:0.00000, loss_test:0.02882, lr:3.22e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.695, tt:5425.574\n",
      "Ep:152, loss:0.00000, loss_test:0.02889, lr:3.19e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.704, tt:5462.638\n",
      "Ep:153, loss:0.00000, loss_test:0.02890, lr:3.15e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.699, tt:5497.692\n",
      "Ep:154, loss:0.00000, loss_test:0.02887, lr:3.12e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.695, tt:5532.680\n",
      "Ep:155, loss:0.00000, loss_test:0.02897, lr:3.09e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.692, tt:5567.960\n",
      "Ep:156, loss:0.00000, loss_test:0.02900, lr:3.06e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.693, tt:5603.764\n",
      "Ep:157, loss:0.00000, loss_test:0.02896, lr:3.03e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.685, tt:5638.291\n",
      "Ep:158, loss:0.00000, loss_test:0.02905, lr:3.00e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.694, tt:5675.327\n",
      "Ep:159, loss:0.00000, loss_test:0.02903, lr:2.97e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.693, tt:5710.901\n",
      "Ep:160, loss:0.00000, loss_test:0.02902, lr:2.94e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.702, tt:5748.000\n",
      "Ep:161, loss:0.00000, loss_test:0.02917, lr:2.91e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.701, tt:5783.579\n",
      "Ep:162, loss:0.00000, loss_test:0.02911, lr:2.88e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.702, tt:5819.398\n",
      "Ep:163, loss:0.00000, loss_test:0.02907, lr:2.85e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.708, tt:5856.035\n",
      "Ep:164, loss:0.00000, loss_test:0.02920, lr:2.82e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.713, tt:5892.715\n",
      "Ep:165, loss:0.00000, loss_test:0.02920, lr:2.80e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.728, tt:5930.806\n",
      "Ep:166, loss:0.00000, loss_test:0.02916, lr:2.77e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.722, tt:5965.532\n",
      "Ep:167, loss:0.00000, loss_test:0.02925, lr:2.74e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.727, tt:6002.108\n",
      "Ep:168, loss:0.00000, loss_test:0.02923, lr:2.71e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.733, tt:6038.891\n",
      "Ep:169, loss:0.00000, loss_test:0.02922, lr:2.69e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.743, tt:6076.366\n",
      "Ep:170, loss:0.00000, loss_test:0.02926, lr:2.66e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.747, tt:6112.785\n",
      "Ep:171, loss:0.00000, loss_test:0.02930, lr:2.63e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.756, tt:6150.064\n",
      "Ep:172, loss:0.00000, loss_test:0.02926, lr:2.61e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.763, tt:6186.942\n",
      "Ep:173, loss:0.00000, loss_test:0.02932, lr:2.58e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.768, tt:6223.633\n",
      "Ep:174, loss:0.00000, loss_test:0.02931, lr:2.55e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.773, tt:6260.197\n",
      "Ep:175, loss:0.00000, loss_test:0.02932, lr:2.53e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.778, tt:6296.947\n",
      "Ep:176, loss:0.00000, loss_test:0.02932, lr:2.50e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.780, tt:6333.074\n",
      "Ep:177, loss:0.00000, loss_test:0.02937, lr:2.48e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.778, tt:6368.560\n",
      "Ep:178, loss:0.00000, loss_test:0.02938, lr:2.45e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.783, tt:6405.175\n",
      "Ep:179, loss:0.00000, loss_test:0.02941, lr:2.43e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.794, tt:6442.961\n",
      "Ep:180, loss:0.00000, loss_test:0.02942, lr:2.40e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.791, tt:6478.242\n",
      "Ep:181, loss:0.00000, loss_test:0.02946, lr:2.38e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.797, tt:6515.108\n",
      "Ep:182, loss:0.00000, loss_test:0.02946, lr:2.36e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.802, tt:6551.848\n",
      "Ep:183, loss:0.00000, loss_test:0.02947, lr:2.33e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.811, tt:6589.267\n",
      "Ep:184, loss:0.00000, loss_test:0.02951, lr:2.31e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.818, tt:6626.252\n",
      "Ep:185, loss:0.00000, loss_test:0.02950, lr:2.29e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.819, tt:6662.312\n",
      "Ep:186, loss:0.00000, loss_test:0.02950, lr:2.26e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.861, tt:6706.060\n",
      "Ep:187, loss:0.00000, loss_test:0.02956, lr:2.24e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.869, tt:6743.392\n",
      "Ep:188, loss:0.00000, loss_test:0.02951, lr:2.22e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.871, tt:6779.655\n",
      "Ep:189, loss:0.00000, loss_test:0.02960, lr:2.20e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.870, tt:6815.310\n",
      "Ep:190, loss:0.00000, loss_test:0.02958, lr:2.17e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.877, tt:6852.485\n",
      "Ep:191, loss:0.00000, loss_test:0.02959, lr:2.15e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.886, tt:6890.091\n",
      "Ep:192, loss:0.00000, loss_test:0.02961, lr:2.13e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.891, tt:6926.975\n",
      "Ep:193, loss:0.00000, loss_test:0.02963, lr:2.11e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.892, tt:6963.006\n",
      "Ep:194, loss:0.00000, loss_test:0.02962, lr:2.09e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.899, tt:7000.377\n",
      "Ep:195, loss:0.00000, loss_test:0.02963, lr:2.07e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.916, tt:7039.461\n",
      "Ep:196, loss:0.00000, loss_test:0.02965, lr:2.05e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.923, tt:7076.864\n",
      "Ep:197, loss:0.00000, loss_test:0.02966, lr:2.03e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.934, tt:7114.843\n",
      "Ep:198, loss:0.00000, loss_test:0.02967, lr:2.01e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.944, tt:7152.846\n",
      "Ep:199, loss:0.00000, loss_test:0.02967, lr:1.99e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.957, tt:7191.477\n",
      "Ep:200, loss:0.00000, loss_test:0.02973, lr:1.97e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.961, tt:7228.196\n",
      "Ep:201, loss:0.00000, loss_test:0.02971, lr:1.95e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.967, tt:7265.355\n",
      "Ep:202, loss:0.00000, loss_test:0.02969, lr:1.93e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.956, tt:7299.031\n",
      "Ep:203, loss:0.00000, loss_test:0.02975, lr:1.91e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.953, tt:7334.486\n",
      "Ep:204, loss:0.00000, loss_test:0.02974, lr:1.89e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.950, tt:7369.822\n",
      "Ep:205, loss:0.00000, loss_test:0.02976, lr:1.87e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.935, tt:7402.525\n",
      "Ep:206, loss:0.00000, loss_test:0.02978, lr:1.85e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.909, tt:7433.265\n",
      "Ep:207, loss:0.00000, loss_test:0.02979, lr:1.83e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.906, tt:7468.389\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14438, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.671, tt:36.671\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14341, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.730, tt:73.459\n",
      "Ep:2, loss:0.00028, loss_test:0.14173, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.185, tt:108.556\n",
      "Ep:3, loss:0.00028, loss_test:0.13884, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.124, tt:144.494\n",
      "Ep:4, loss:0.00027, loss_test:0.13367, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:35.667, tt:178.333\n",
      "Ep:5, loss:0.00026, loss_test:0.12396, lr:1.00e-02, fs:0.68293 (r=0.966,p=0.528),  time:35.828, tt:214.968\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11217, lr:1.00e-02, fs:0.69474 (r=0.759,p=0.641),  time:35.671, tt:249.697\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10795, lr:1.00e-02, fs:0.64596 (r=0.598,p=0.703),  time:35.802, tt:286.413\n",
      "Ep:8, loss:0.00022, loss_test:0.10624, lr:1.00e-02, fs:0.68235 (r=0.667,p=0.699),  time:35.475, tt:319.272\n",
      "Ep:9, loss:0.00022, loss_test:0.10465, lr:1.00e-02, fs:0.72131 (r=0.759,p=0.688),  time:35.592, tt:355.923\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09853, lr:1.00e-02, fs:0.69231 (r=0.621,p=0.783),  time:35.962, tt:395.583\n",
      "Ep:11, loss:0.00020, loss_test:0.09660, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:35.927, tt:431.127\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09620, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:35.982, tt:467.763\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09463, lr:1.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:36.047, tt:504.664\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09326, lr:1.00e-02, fs:0.73548 (r=0.655,p=0.838),  time:35.889, tt:538.328\n",
      "Ep:15, loss:0.00016, loss_test:0.09135, lr:1.00e-02, fs:0.74359 (r=0.667,p=0.841),  time:36.034, tt:576.542\n",
      "Ep:16, loss:0.00016, loss_test:0.09008, lr:1.00e-02, fs:0.77019 (r=0.713,p=0.838),  time:36.072, tt:613.225\n",
      "Ep:17, loss:0.00015, loss_test:0.09095, lr:1.00e-02, fs:0.74359 (r=0.667,p=0.841),  time:36.097, tt:649.738\n",
      "Ep:18, loss:0.00014, loss_test:0.08760, lr:1.00e-02, fs:0.77778 (r=0.724,p=0.840),  time:36.008, tt:684.146\n",
      "Ep:19, loss:0.00014, loss_test:0.08690, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:35.968, tt:719.365\n",
      "Ep:20, loss:0.00013, loss_test:0.08757, lr:1.00e-02, fs:0.77419 (r=0.690,p=0.882),  time:35.882, tt:753.532\n",
      "Ep:21, loss:0.00012, loss_test:0.08523, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:35.867, tt:789.065\n",
      "Ep:22, loss:0.00012, loss_test:0.08693, lr:1.00e-02, fs:0.79487 (r=0.713,p=0.899),  time:35.898, tt:825.643\n",
      "Ep:23, loss:0.00011, loss_test:0.08719, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:35.952, tt:862.858\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08473, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:35.896, tt:897.412\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.08837, lr:1.00e-02, fs:0.81013 (r=0.736,p=0.901),  time:35.906, tt:933.559\n",
      "Ep:26, loss:0.00009, loss_test:0.08604, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:35.954, tt:970.763\n",
      "Ep:27, loss:0.00009, loss_test:0.08806, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:35.912, tt:1005.527\n",
      "Ep:28, loss:0.00008, loss_test:0.08489, lr:1.00e-02, fs:0.81013 (r=0.736,p=0.901),  time:35.902, tt:1041.151\n",
      "Ep:29, loss:0.00008, loss_test:0.09034, lr:1.00e-02, fs:0.79221 (r=0.701,p=0.910),  time:35.871, tt:1076.139\n",
      "Ep:30, loss:0.00007, loss_test:0.08834, lr:1.00e-02, fs:0.79487 (r=0.713,p=0.899),  time:35.859, tt:1111.632\n",
      "Ep:31, loss:0.00007, loss_test:0.08930, lr:1.00e-02, fs:0.79221 (r=0.701,p=0.910),  time:35.866, tt:1147.725\n",
      "Ep:32, loss:0.00006, loss_test:0.09281, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:35.977, tt:1187.244\n",
      "Ep:33, loss:0.00006, loss_test:0.08952, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:36.046, tt:1225.567\n",
      "Ep:34, loss:0.00006, loss_test:0.09623, lr:1.00e-02, fs:0.78082 (r=0.655,p=0.966),  time:36.066, tt:1262.320\n",
      "Ep:35, loss:0.00005, loss_test:0.09107, lr:1.00e-02, fs:0.78912 (r=0.667,p=0.967),  time:36.050, tt:1297.806\n",
      "Ep:36, loss:0.00005, loss_test:0.09249, lr:9.90e-03, fs:0.78912 (r=0.667,p=0.967),  time:36.039, tt:1333.453\n",
      "Ep:37, loss:0.00004, loss_test:0.09170, lr:9.80e-03, fs:0.78082 (r=0.655,p=0.966),  time:35.981, tt:1367.285\n",
      "Ep:38, loss:0.00004, loss_test:0.09809, lr:9.70e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.967, tt:1402.700\n",
      "Ep:39, loss:0.00004, loss_test:0.08695, lr:9.61e-03, fs:0.78912 (r=0.667,p=0.967),  time:35.951, tt:1438.044\n",
      "Ep:40, loss:0.00003, loss_test:0.10291, lr:9.51e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.972, tt:1474.855\n",
      "Ep:41, loss:0.00003, loss_test:0.08915, lr:9.41e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.936, tt:1509.295\n",
      "Ep:42, loss:0.00003, loss_test:0.10033, lr:9.32e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.919, tt:1544.502\n",
      "Ep:43, loss:0.00003, loss_test:0.09179, lr:9.23e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.932, tt:1580.996\n",
      "Ep:44, loss:0.00003, loss_test:0.09913, lr:9.14e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.992, tt:1619.635\n",
      "Ep:45, loss:0.00002, loss_test:0.08768, lr:9.04e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.996, tt:1655.810\n",
      "Ep:46, loss:0.00002, loss_test:0.10267, lr:8.95e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.028, tt:1693.301\n",
      "Ep:47, loss:0.00002, loss_test:0.09206, lr:8.86e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.009, tt:1728.409\n",
      "Ep:48, loss:0.00002, loss_test:0.09886, lr:8.78e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.062, tt:1767.061\n",
      "Ep:49, loss:0.00002, loss_test:0.09231, lr:8.69e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.015, tt:1800.742\n",
      "Ep:50, loss:0.00002, loss_test:0.10242, lr:8.60e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.029, tt:1837.464\n",
      "Ep:51, loss:0.00002, loss_test:0.09321, lr:8.51e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.070, tt:1875.619\n",
      "Ep:52, loss:0.00001, loss_test:0.09688, lr:8.43e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.078, tt:1912.114\n",
      "Ep:53, loss:0.00001, loss_test:0.09869, lr:8.35e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.017, tt:1944.911\n",
      "Ep:54, loss:0.00001, loss_test:0.09609, lr:8.26e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.022, tt:1981.234\n",
      "Ep:55, loss:0.00001, loss_test:0.10207, lr:8.18e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.999, tt:2015.918\n",
      "Ep:56, loss:0.00001, loss_test:0.09346, lr:8.10e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.989, tt:2051.353\n",
      "Ep:57, loss:0.00001, loss_test:0.10236, lr:8.02e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.984, tt:2087.083\n",
      "Ep:58, loss:0.00001, loss_test:0.09178, lr:7.94e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.937, tt:2120.282\n",
      "Ep:59, loss:0.00001, loss_test:0.10214, lr:7.86e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.919, tt:2155.132\n",
      "Ep:60, loss:0.00001, loss_test:0.09808, lr:7.78e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.877, tt:2188.488\n",
      "Ep:61, loss:0.00001, loss_test:0.09552, lr:7.70e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.886, tt:2224.938\n",
      "Ep:62, loss:0.00001, loss_test:0.10133, lr:7.62e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.888, tt:2260.926\n",
      "Ep:63, loss:0.00001, loss_test:0.09319, lr:7.55e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.871, tt:2295.730\n",
      "Ep:64, loss:0.00001, loss_test:0.09926, lr:7.47e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.864, tt:2331.131\n",
      "Ep:65, loss:0.00001, loss_test:0.09710, lr:7.40e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.839, tt:2365.398\n",
      "Ep:66, loss:0.00001, loss_test:0.09562, lr:7.32e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.838, tt:2401.142\n",
      "Ep:67, loss:0.00001, loss_test:0.09844, lr:7.25e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.842, tt:2437.230\n",
      "Ep:68, loss:0.00001, loss_test:0.09632, lr:7.18e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.840, tt:2472.937\n",
      "Ep:69, loss:0.00000, loss_test:0.09637, lr:7.11e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.834, tt:2508.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00000, loss_test:0.09475, lr:7.03e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.842, tt:2544.801\n",
      "Ep:71, loss:0.00000, loss_test:0.09525, lr:6.96e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.853, tt:2581.396\n",
      "Ep:72, loss:0.00000, loss_test:0.09582, lr:6.89e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.856, tt:2617.454\n",
      "Ep:73, loss:0.00000, loss_test:0.09407, lr:6.83e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.849, tt:2652.818\n",
      "Ep:74, loss:0.00000, loss_test:0.09974, lr:6.76e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.811, tt:2685.825\n",
      "Ep:75, loss:0.00000, loss_test:0.09773, lr:6.69e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.816, tt:2722.049\n",
      "Ep:76, loss:0.00000, loss_test:0.09439, lr:6.62e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.840, tt:2759.712\n",
      "Ep:77, loss:0.00000, loss_test:0.09945, lr:6.56e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.842, tt:2795.639\n",
      "Ep:78, loss:0.00000, loss_test:0.09705, lr:6.49e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.810, tt:2829.018\n",
      "Ep:79, loss:0.00000, loss_test:0.09387, lr:6.43e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.826, tt:2866.057\n",
      "Ep:80, loss:0.00000, loss_test:0.09819, lr:6.36e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.837, tt:2902.770\n",
      "Ep:81, loss:0.00000, loss_test:0.09648, lr:6.30e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.827, tt:2937.802\n",
      "Ep:82, loss:0.00000, loss_test:0.09675, lr:6.24e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.817, tt:2972.797\n",
      "Ep:83, loss:0.00000, loss_test:0.09727, lr:6.17e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.835, tt:3010.119\n",
      "Ep:84, loss:0.00000, loss_test:0.09378, lr:6.11e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.847, tt:3046.970\n",
      "Ep:85, loss:0.00000, loss_test:0.09997, lr:6.05e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.867, tt:3084.561\n",
      "Ep:86, loss:0.00000, loss_test:0.09859, lr:5.99e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.846, tt:3118.578\n",
      "Ep:87, loss:0.00000, loss_test:0.09351, lr:5.93e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.843, tt:3154.192\n",
      "Ep:88, loss:0.00000, loss_test:0.09609, lr:5.87e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.833, tt:3189.168\n",
      "Ep:89, loss:0.00000, loss_test:0.09715, lr:5.81e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.862, tt:3227.623\n",
      "Ep:90, loss:0.00000, loss_test:0.09525, lr:5.75e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.845, tt:3261.854\n",
      "Ep:91, loss:0.00000, loss_test:0.09600, lr:5.70e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.831, tt:3296.471\n",
      "Ep:92, loss:0.00000, loss_test:0.09501, lr:5.64e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.821, tt:3331.325\n",
      "Ep:93, loss:0.00000, loss_test:0.09424, lr:5.58e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.795, tt:3364.763\n",
      "Ep:94, loss:0.00000, loss_test:0.09630, lr:5.53e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.759, tt:3397.133\n",
      "Ep:95, loss:0.00000, loss_test:0.09574, lr:5.47e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.772, tt:3434.077\n",
      "Ep:96, loss:0.00000, loss_test:0.09399, lr:5.42e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.787, tt:3471.315\n",
      "Ep:97, loss:0.00000, loss_test:0.09536, lr:5.36e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.780, tt:3506.482\n",
      "Ep:98, loss:0.00000, loss_test:0.09495, lr:5.31e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.791, tt:3543.284\n",
      "Ep:99, loss:0.00000, loss_test:0.09464, lr:5.26e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.767, tt:3576.716\n",
      "Ep:100, loss:0.00000, loss_test:0.09565, lr:5.20e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.767, tt:3612.436\n",
      "Ep:101, loss:0.00000, loss_test:0.09487, lr:5.15e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.748, tt:3646.325\n",
      "Ep:102, loss:0.00000, loss_test:0.09460, lr:5.10e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.686, tt:3675.619\n",
      "Ep:103, loss:0.00000, loss_test:0.09497, lr:5.05e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.652, tt:3707.843\n",
      "Ep:104, loss:0.00000, loss_test:0.09483, lr:5.00e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.604, tt:3738.454\n",
      "Ep:105, loss:0.00000, loss_test:0.09472, lr:4.95e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.547, tt:3768.029\n",
      "Ep:106, loss:0.00000, loss_test:0.09485, lr:4.90e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.474, tt:3795.684\n",
      "Ep:107, loss:0.00000, loss_test:0.09488, lr:4.85e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.451, tt:3828.759\n",
      "Ep:108, loss:0.00000, loss_test:0.09442, lr:4.80e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.394, tt:3857.993\n",
      "Ep:109, loss:0.00000, loss_test:0.09456, lr:4.75e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.359, tt:3889.517\n",
      "Ep:110, loss:0.00000, loss_test:0.09613, lr:4.71e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.315, tt:3919.945\n",
      "Ep:111, loss:0.00000, loss_test:0.09477, lr:4.66e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.280, tt:3951.412\n",
      "Ep:112, loss:0.00000, loss_test:0.09432, lr:4.61e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.231, tt:3981.087\n",
      "Ep:113, loss:0.00000, loss_test:0.09508, lr:4.57e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.193, tt:4012.030\n",
      "Ep:114, loss:0.00000, loss_test:0.09451, lr:4.52e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.154, tt:4042.712\n",
      "Ep:115, loss:0.00000, loss_test:0.09402, lr:4.48e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.119, tt:4073.791\n",
      "Ep:116, loss:0.00000, loss_test:0.09573, lr:4.43e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.088, tt:4105.349\n",
      "Ep:117, loss:0.00000, loss_test:0.09519, lr:4.39e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.065, tt:4137.666\n",
      "Ep:118, loss:0.00000, loss_test:0.09400, lr:4.34e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.048, tt:4170.732\n",
      "Ep:119, loss:0.00000, loss_test:0.09489, lr:4.30e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.012, tt:4201.444\n",
      "Ep:120, loss:0.00000, loss_test:0.09576, lr:4.26e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.982, tt:4232.763\n",
      "Ep:121, loss:0.00000, loss_test:0.09485, lr:4.21e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.941, tt:4262.778\n",
      "Ep:122, loss:0.00000, loss_test:0.09407, lr:4.17e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.897, tt:4292.314\n",
      "Ep:123, loss:0.00000, loss_test:0.09466, lr:4.13e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.873, tt:4324.207\n",
      "Ep:124, loss:0.00000, loss_test:0.09468, lr:4.09e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.837, tt:4354.681\n",
      "Ep:125, loss:0.00000, loss_test:0.09447, lr:4.05e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.805, tt:4385.384\n",
      "Ep:126, loss:0.00000, loss_test:0.09392, lr:4.01e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.785, tt:4417.744\n",
      "Ep:127, loss:0.00000, loss_test:0.09512, lr:3.97e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.770, tt:4450.498\n",
      "Ep:128, loss:0.00000, loss_test:0.09471, lr:3.93e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.707, tt:4477.246\n",
      "Ep:129, loss:0.00000, loss_test:0.09402, lr:3.89e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.679, tt:4508.225\n",
      "Ep:130, loss:0.00000, loss_test:0.09426, lr:3.85e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.656, tt:4539.870\n",
      "Ep:131, loss:0.00000, loss_test:0.09459, lr:3.81e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.609, tt:4568.429\n",
      "Ep:132, loss:0.00000, loss_test:0.09447, lr:3.77e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.565, tt:4597.111\n",
      "Ep:133, loss:0.00000, loss_test:0.09467, lr:3.73e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.543, tt:4628.751\n",
      "Ep:134, loss:0.00000, loss_test:0.09485, lr:3.70e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.518, tt:4659.986\n",
      "Ep:135, loss:0.00000, loss_test:0.09451, lr:3.66e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.498, tt:4691.790\n",
      "Ep:136, loss:0.00000, loss_test:0.09425, lr:3.62e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.458, tt:4720.733\n",
      "Ep:137, loss:0.00000, loss_test:0.09389, lr:3.59e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.427, tt:4750.965\n",
      "Ep:138, loss:0.00000, loss_test:0.09457, lr:3.55e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.414, tt:4783.560\n",
      "Ep:139, loss:0.00000, loss_test:0.09451, lr:3.52e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.409, tt:4817.287\n",
      "Ep:140, loss:0.00000, loss_test:0.09412, lr:3.48e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.400, tt:4850.461\n",
      "Ep:141, loss:0.00000, loss_test:0.09479, lr:3.45e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.387, tt:4882.933\n",
      "Ep:142, loss:0.00000, loss_test:0.09487, lr:3.41e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.378, tt:4916.038\n",
      "Ep:143, loss:0.00000, loss_test:0.09405, lr:3.38e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.354, tt:4946.942\n",
      "Ep:144, loss:0.00000, loss_test:0.09375, lr:3.34e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.333, tt:4978.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.09464, lr:3.31e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.313, tt:5009.675\n",
      "Ep:146, loss:0.00000, loss_test:0.09451, lr:3.28e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.304, tt:5042.663\n",
      "Ep:147, loss:0.00000, loss_test:0.09378, lr:3.24e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.273, tt:5072.358\n",
      "Ep:148, loss:0.00000, loss_test:0.09443, lr:3.21e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.247, tt:5102.730\n",
      "Ep:149, loss:0.00000, loss_test:0.09502, lr:3.18e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.224, tt:5133.537\n",
      "Ep:150, loss:0.00000, loss_test:0.09434, lr:3.15e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.208, tt:5165.420\n",
      "Ep:151, loss:0.00000, loss_test:0.09333, lr:3.12e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.181, tt:5195.439\n",
      "Ep:152, loss:0.00000, loss_test:0.09409, lr:3.09e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.164, tt:5227.133\n",
      "Ep:153, loss:0.00000, loss_test:0.09473, lr:3.05e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.138, tt:5257.312\n",
      "Ep:154, loss:0.00000, loss_test:0.09437, lr:3.02e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.126, tt:5289.484\n",
      "Ep:155, loss:0.00000, loss_test:0.09397, lr:2.99e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.105, tt:5320.456\n",
      "Ep:156, loss:0.00000, loss_test:0.09437, lr:2.96e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.095, tt:5352.866\n",
      "Ep:157, loss:0.00000, loss_test:0.09433, lr:2.93e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.086, tt:5385.569\n",
      "Ep:158, loss:0.00000, loss_test:0.09408, lr:2.90e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.059, tt:5415.449\n",
      "Ep:159, loss:0.00000, loss_test:0.09403, lr:2.88e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.039, tt:5446.221\n",
      "Ep:160, loss:0.00000, loss_test:0.09402, lr:2.85e-03, fs:0.78621 (r=0.655,p=0.983),  time:34.015, tt:5476.492\n",
      "Ep:161, loss:0.00000, loss_test:0.09392, lr:2.82e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.998, tt:5507.631\n",
      "Ep:162, loss:0.00000, loss_test:0.09376, lr:2.79e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.995, tt:5541.118\n",
      "Ep:163, loss:0.00000, loss_test:0.09389, lr:2.76e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.982, tt:5573.034\n",
      "Ep:164, loss:0.00000, loss_test:0.09405, lr:2.73e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.959, tt:5603.252\n",
      "Ep:165, loss:0.00000, loss_test:0.09432, lr:2.71e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.940, tt:5634.116\n",
      "Ep:166, loss:0.00000, loss_test:0.09389, lr:2.68e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.920, tt:5664.687\n",
      "Ep:167, loss:0.00000, loss_test:0.09401, lr:2.65e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.881, tt:5691.955\n",
      "Ep:168, loss:0.00000, loss_test:0.09434, lr:2.63e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.873, tt:5724.525\n",
      "Ep:169, loss:0.00000, loss_test:0.09443, lr:2.60e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.857, tt:5755.708\n",
      "Ep:170, loss:0.00000, loss_test:0.09422, lr:2.57e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.840, tt:5786.698\n",
      "Ep:171, loss:0.00000, loss_test:0.09423, lr:2.55e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.831, tt:5818.984\n",
      "Ep:172, loss:0.00000, loss_test:0.09402, lr:2.52e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.823, tt:5851.434\n",
      "Ep:173, loss:0.00000, loss_test:0.09388, lr:2.50e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.807, tt:5882.426\n",
      "Ep:174, loss:0.00000, loss_test:0.09367, lr:2.47e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.792, tt:5913.539\n",
      "Ep:175, loss:0.00000, loss_test:0.09386, lr:2.45e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.768, tt:5943.082\n",
      "Ep:176, loss:0.00000, loss_test:0.09421, lr:2.42e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.745, tt:5972.918\n",
      "Ep:177, loss:0.00000, loss_test:0.09409, lr:2.40e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.737, tt:6005.185\n",
      "Ep:178, loss:0.00000, loss_test:0.09372, lr:2.38e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.723, tt:6036.377\n",
      "Ep:179, loss:0.00000, loss_test:0.09379, lr:2.35e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.717, tt:6069.023\n",
      "Ep:180, loss:0.00000, loss_test:0.09397, lr:2.33e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.705, tt:6100.607\n",
      "Ep:181, loss:0.00000, loss_test:0.09403, lr:2.31e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.690, tt:6131.555\n",
      "Ep:182, loss:0.00000, loss_test:0.09373, lr:2.28e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.681, tt:6163.687\n",
      "Ep:183, loss:0.00000, loss_test:0.09380, lr:2.26e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.661, tt:6193.550\n",
      "Ep:184, loss:0.00000, loss_test:0.09394, lr:2.24e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.631, tt:6221.688\n",
      "Ep:185, loss:0.00000, loss_test:0.09380, lr:2.21e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.639, tt:6256.928\n",
      "Ep:186, loss:0.00000, loss_test:0.09391, lr:2.19e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.628, tt:6288.483\n",
      "Ep:187, loss:0.00000, loss_test:0.09376, lr:2.17e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.620, tt:6320.558\n",
      "Ep:188, loss:0.00000, loss_test:0.09366, lr:2.15e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.597, tt:6349.752\n",
      "Ep:189, loss:0.00000, loss_test:0.09372, lr:2.13e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.576, tt:6379.434\n",
      "Ep:190, loss:0.00000, loss_test:0.09370, lr:2.11e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.547, tt:6407.474\n",
      "Ep:191, loss:0.00000, loss_test:0.09380, lr:2.08e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.533, tt:6438.322\n",
      "Ep:192, loss:0.00000, loss_test:0.09375, lr:2.06e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.511, tt:6467.678\n",
      "Ep:193, loss:0.00000, loss_test:0.09383, lr:2.04e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.499, tt:6498.716\n",
      "Ep:194, loss:0.00000, loss_test:0.09369, lr:2.02e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.482, tt:6529.054\n",
      "Ep:195, loss:0.00000, loss_test:0.09359, lr:2.00e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.462, tt:6558.477\n",
      "Ep:196, loss:0.00000, loss_test:0.09368, lr:1.98e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.457, tt:6591.052\n",
      "Ep:197, loss:0.00000, loss_test:0.09386, lr:1.96e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.449, tt:6622.808\n",
      "Ep:198, loss:0.00000, loss_test:0.09387, lr:1.94e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.442, tt:6654.950\n",
      "Ep:199, loss:0.00000, loss_test:0.09368, lr:1.92e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.427, tt:6685.409\n",
      "Ep:200, loss:0.00000, loss_test:0.09345, lr:1.90e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.420, tt:6717.472\n",
      "Ep:201, loss:0.00000, loss_test:0.09362, lr:1.89e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.426, tt:6752.091\n",
      "Ep:202, loss:0.00000, loss_test:0.09383, lr:1.87e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.404, tt:6780.999\n",
      "Ep:203, loss:0.00000, loss_test:0.09383, lr:1.85e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.377, tt:6808.828\n",
      "Ep:204, loss:0.00000, loss_test:0.09369, lr:1.83e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.330, tt:6832.614\n",
      "Ep:205, loss:0.00000, loss_test:0.09366, lr:1.81e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.283, tt:6856.345\n",
      "Ep:206, loss:0.00000, loss_test:0.09390, lr:1.79e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.243, tt:6881.364\n",
      "Ep:207, loss:0.00000, loss_test:0.09388, lr:1.78e-03, fs:0.78621 (r=0.655,p=0.983),  time:33.186, tt:6902.760\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01921, lr:6.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:33.681, tt:33.681\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02240, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.594, tt:69.188\n",
      "Ep:2, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.178, tt:105.533\n",
      "Ep:3, loss:0.00005, loss_test:0.02338, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.459, tt:145.837\n",
      "Ep:4, loss:0.00005, loss_test:0.02184, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.294, tt:186.472\n",
      "Ep:5, loss:0.00004, loss_test:0.01979, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:37.895, tt:227.372\n",
      "Ep:6, loss:0.00004, loss_test:0.01813, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:38.672, tt:270.703\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01741, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:39.008, tt:312.066\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01707, lr:6.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:38.696, tt:348.266\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01627, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:38.293, tt:382.930\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:38.108, tt:419.189\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01556, lr:6.00e-02, fs:0.73208 (r=0.980,p=0.584),  time:37.930, tt:455.158\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01538, lr:6.00e-02, fs:0.72059 (r=0.990,p=0.566),  time:37.959, tt:493.469\n",
      "Ep:13, loss:0.00003, loss_test:0.01496, lr:6.00e-02, fs:0.73004 (r=0.970,p=0.585),  time:37.799, tt:529.188\n",
      "Ep:14, loss:0.00003, loss_test:0.01454, lr:6.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:37.594, tt:563.915\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01423, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:37.478, tt:599.646\n",
      "Ep:16, loss:0.00003, loss_test:0.01401, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:37.436, tt:636.416\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01384, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:37.337, tt:672.069\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01370, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:37.252, tt:707.783\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01353, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:37.113, tt:742.263\n",
      "Ep:20, loss:0.00003, loss_test:0.01328, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:37.067, tt:778.399\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01302, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:36.991, tt:813.807\n",
      "Ep:22, loss:0.00002, loss_test:0.01277, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:36.946, tt:849.747\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01255, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:36.936, tt:886.475\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:36.814, tt:920.339\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01224, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:36.773, tt:956.101\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01208, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:36.762, tt:992.561\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01192, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:36.723, tt:1028.241\n",
      "Ep:28, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:36.747, tt:1065.661\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01162, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:36.682, tt:1100.474\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01149, lr:6.00e-02, fs:0.84979 (r=1.000,p=0.739),  time:36.571, tt:1133.699\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.84979 (r=1.000,p=0.739),  time:36.563, tt:1170.016\n",
      "Ep:32, loss:0.00002, loss_test:0.01123, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:36.435, tt:1202.351\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01109, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:36.406, tt:1237.814\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01097, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:36.322, tt:1271.287\n",
      "Ep:35, loss:0.00002, loss_test:0.01086, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:36.274, tt:1305.849\n",
      "Ep:36, loss:0.00002, loss_test:0.01078, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:36.238, tt:1340.796\n",
      "Ep:37, loss:0.00002, loss_test:0.01069, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:36.140, tt:1373.321\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01062, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:36.118, tt:1408.602\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01056, lr:6.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:36.159, tt:1446.376\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01049, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:36.116, tt:1480.743\n",
      "Ep:41, loss:0.00002, loss_test:0.01043, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:36.078, tt:1515.278\n",
      "Ep:42, loss:0.00002, loss_test:0.01032, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:36.034, tt:1549.441\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:35.977, tt:1583.001\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01020, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:35.918, tt:1616.308\n",
      "Ep:45, loss:0.00001, loss_test:0.01011, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:35.869, tt:1649.988\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01005, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:35.843, tt:1684.616\n",
      "Ep:47, loss:0.00001, loss_test:0.00999, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:35.792, tt:1717.998\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.00990, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:35.772, tt:1752.827\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.00986, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:35.709, tt:1785.448\n",
      "Ep:50, loss:0.00001, loss_test:0.00979, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:35.663, tt:1818.818\n",
      "Ep:51, loss:0.00001, loss_test:0.00974, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:35.655, tt:1854.049\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.00970, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:35.641, tt:1888.992\n",
      "Ep:53, loss:0.00001, loss_test:0.00970, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:35.616, tt:1923.262\n",
      "Ep:54, loss:0.00001, loss_test:0.00963, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:35.617, tt:1958.926\n",
      "Ep:55, loss:0.00001, loss_test:0.00960, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:35.616, tt:1994.490\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.00956, lr:6.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:35.627, tt:2030.722\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:35.577, tt:2063.472\n",
      "Ep:58, loss:0.00001, loss_test:0.00949, lr:6.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:35.574, tt:2098.858\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.00950, lr:6.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:35.582, tt:2134.913\n",
      "Ep:60, loss:0.00001, loss_test:0.00940, lr:6.00e-02, fs:0.93204 (r=0.970,p=0.897),  time:35.607, tt:2172.056\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.00936, lr:6.00e-02, fs:0.93204 (r=0.970,p=0.897),  time:35.621, tt:2208.482\n",
      "Ep:62, loss:0.00001, loss_test:0.00940, lr:6.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.607, tt:2243.230\n",
      "Ep:63, loss:0.00001, loss_test:0.00932, lr:6.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.634, tt:2280.575\n",
      "Ep:64, loss:0.00001, loss_test:0.00932, lr:6.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.654, tt:2317.518\n",
      "Ep:65, loss:0.00001, loss_test:0.00933, lr:6.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.643, tt:2352.434\n",
      "Ep:66, loss:0.00001, loss_test:0.00927, lr:6.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:35.629, tt:2387.144\n",
      "Ep:67, loss:0.00001, loss_test:0.00927, lr:6.00e-02, fs:0.92079 (r=0.939,p=0.903),  time:35.609, tt:2421.397\n",
      "Ep:68, loss:0.00001, loss_test:0.00928, lr:6.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:35.662, tt:2460.709\n",
      "Ep:69, loss:0.00001, loss_test:0.00924, lr:6.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:35.645, tt:2495.180\n",
      "Ep:70, loss:0.00001, loss_test:0.00922, lr:6.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.636, tt:2530.169\n",
      "Ep:71, loss:0.00001, loss_test:0.00923, lr:6.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:35.614, tt:2564.174\n",
      "Ep:72, loss:0.00001, loss_test:0.00924, lr:5.94e-02, fs:0.88776 (r=0.879,p=0.897),  time:35.621, tt:2600.305\n",
      "Ep:73, loss:0.00001, loss_test:0.00920, lr:5.88e-02, fs:0.88660 (r=0.869,p=0.905),  time:35.612, tt:2635.292\n",
      "Ep:74, loss:0.00001, loss_test:0.00926, lr:5.82e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.593, tt:2669.503\n",
      "Ep:75, loss:0.00001, loss_test:0.00924, lr:5.76e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.602, tt:2705.739\n",
      "Ep:76, loss:0.00001, loss_test:0.00924, lr:5.71e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.585, tt:2740.078\n",
      "Ep:77, loss:0.00001, loss_test:0.00924, lr:5.65e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.589, tt:2775.977\n",
      "Ep:78, loss:0.00001, loss_test:0.00923, lr:5.59e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.556, tt:2808.917\n",
      "Ep:79, loss:0.00001, loss_test:0.00926, lr:5.54e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.549, tt:2843.901\n",
      "Ep:80, loss:0.00001, loss_test:0.00925, lr:5.48e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.538, tt:2878.591\n",
      "Ep:81, loss:0.00001, loss_test:0.00926, lr:5.43e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.529, tt:2913.387\n",
      "Ep:82, loss:0.00001, loss_test:0.00930, lr:5.37e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.527, tt:2948.753\n",
      "Ep:83, loss:0.00001, loss_test:0.00929, lr:5.32e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.521, tt:2983.776\n",
      "Ep:84, loss:0.00001, loss_test:0.00932, lr:5.27e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.522, tt:3019.380\n",
      "Ep:85, loss:0.00001, loss_test:0.00934, lr:5.21e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.530, tt:3055.571\n",
      "Ep:86, loss:0.00001, loss_test:0.00941, lr:5.16e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.529, tt:3091.025\n",
      "Ep:87, loss:0.00001, loss_test:0.00940, lr:5.11e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.610, tt:3133.711\n",
      "Ep:88, loss:0.00001, loss_test:0.00944, lr:5.06e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.614, tt:3169.624\n",
      "Ep:89, loss:0.00001, loss_test:0.00946, lr:5.01e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.600, tt:3203.986\n",
      "Ep:90, loss:0.00001, loss_test:0.00944, lr:4.96e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.598, tt:3239.382\n",
      "Ep:91, loss:0.00001, loss_test:0.00949, lr:4.91e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.587, tt:3274.037\n",
      "Ep:92, loss:0.00001, loss_test:0.00952, lr:4.86e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.576, tt:3308.611\n",
      "Ep:93, loss:0.00001, loss_test:0.00959, lr:4.81e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.582, tt:3344.671\n",
      "Ep:94, loss:0.00001, loss_test:0.00960, lr:4.76e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.571, tt:3379.231\n",
      "Ep:95, loss:0.00001, loss_test:0.00961, lr:4.71e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.576, tt:3415.262\n",
      "Ep:96, loss:0.00001, loss_test:0.00970, lr:4.67e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.582, tt:3451.433\n",
      "Ep:97, loss:0.00001, loss_test:0.00965, lr:4.62e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.597, tt:3488.541\n",
      "Ep:98, loss:0.00001, loss_test:0.00973, lr:4.57e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.597, tt:3524.060\n",
      "Ep:99, loss:0.00001, loss_test:0.00975, lr:4.53e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.593, tt:3559.340\n",
      "Ep:100, loss:0.00001, loss_test:0.00980, lr:4.48e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.575, tt:3593.027\n",
      "Ep:101, loss:0.00001, loss_test:0.00977, lr:4.44e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.566, tt:3627.688\n",
      "Ep:102, loss:0.00001, loss_test:0.00989, lr:4.39e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.563, tt:3663.020\n",
      "Ep:103, loss:0.00001, loss_test:0.00991, lr:4.35e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.563, tt:3698.567\n",
      "Ep:104, loss:0.00001, loss_test:0.00990, lr:4.31e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.567, tt:3734.563\n",
      "Ep:105, loss:0.00000, loss_test:0.01000, lr:4.26e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.571, tt:3770.478\n",
      "Ep:106, loss:0.00000, loss_test:0.00996, lr:4.22e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.568, tt:3805.745\n",
      "Ep:107, loss:0.00000, loss_test:0.01001, lr:4.18e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.574, tt:3841.940\n",
      "Ep:108, loss:0.00000, loss_test:0.01012, lr:4.14e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.585, tt:3878.787\n",
      "Ep:109, loss:0.00000, loss_test:0.01008, lr:4.10e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.598, tt:3915.793\n",
      "Ep:110, loss:0.00000, loss_test:0.01012, lr:4.05e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.579, tt:3949.215\n",
      "Ep:111, loss:0.00000, loss_test:0.01023, lr:4.01e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.583, tt:3985.333\n",
      "Ep:112, loss:0.00000, loss_test:0.01018, lr:3.97e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.581, tt:4020.703\n",
      "Ep:113, loss:0.00000, loss_test:0.01023, lr:3.93e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.589, tt:4057.190\n",
      "Ep:114, loss:0.00000, loss_test:0.01028, lr:3.89e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.598, tt:4093.770\n",
      "Ep:115, loss:0.00000, loss_test:0.01029, lr:3.86e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.611, tt:4130.842\n",
      "Ep:116, loss:0.00000, loss_test:0.01037, lr:3.82e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.666, tt:4172.884\n",
      "Ep:117, loss:0.00000, loss_test:0.01040, lr:3.78e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.672, tt:4209.287\n",
      "Ep:118, loss:0.00000, loss_test:0.01039, lr:3.74e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.677, tt:4245.598\n",
      "Ep:119, loss:0.00000, loss_test:0.01043, lr:3.70e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.662, tt:4279.412\n",
      "Ep:120, loss:0.00000, loss_test:0.01050, lr:3.67e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.639, tt:4312.304\n",
      "Ep:121, loss:0.00000, loss_test:0.01052, lr:3.63e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.632, tt:4347.086\n",
      "Ep:122, loss:0.00000, loss_test:0.01058, lr:3.59e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.615, tt:4380.654\n",
      "Ep:123, loss:0.00000, loss_test:0.01062, lr:3.56e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.614, tt:4416.133\n",
      "Ep:124, loss:0.00000, loss_test:0.01058, lr:3.52e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.613, tt:4451.676\n",
      "Ep:125, loss:0.00000, loss_test:0.01069, lr:3.49e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.619, tt:4488.017\n",
      "Ep:126, loss:0.00000, loss_test:0.01069, lr:3.45e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.601, tt:4521.279\n",
      "Ep:127, loss:0.00000, loss_test:0.01073, lr:3.42e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.602, tt:4557.032\n",
      "Ep:128, loss:0.00000, loss_test:0.01077, lr:3.38e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.591, tt:4591.300\n",
      "Ep:129, loss:0.00000, loss_test:0.01080, lr:3.35e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.586, tt:4626.192\n",
      "Ep:130, loss:0.00000, loss_test:0.01080, lr:3.32e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.580, tt:4661.039\n",
      "Ep:131, loss:0.00000, loss_test:0.01087, lr:3.28e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.575, tt:4695.837\n",
      "Ep:132, loss:0.00000, loss_test:0.01090, lr:3.25e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.573, tt:4731.252\n",
      "Ep:133, loss:0.00000, loss_test:0.01093, lr:3.22e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.573, tt:4766.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01094, lr:3.19e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.574, tt:4802.465\n",
      "Ep:135, loss:0.00000, loss_test:0.01106, lr:3.15e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.579, tt:4838.745\n",
      "Ep:136, loss:0.00000, loss_test:0.01103, lr:3.12e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.584, tt:4874.942\n",
      "Ep:137, loss:0.00000, loss_test:0.01103, lr:3.09e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.582, tt:4910.325\n",
      "Ep:138, loss:0.00000, loss_test:0.01110, lr:3.06e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.582, tt:4945.838\n",
      "Ep:139, loss:0.00000, loss_test:0.01111, lr:3.03e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.588, tt:4982.368\n",
      "Ep:140, loss:0.00000, loss_test:0.01115, lr:3.00e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.632, tt:5024.108\n",
      "Ep:141, loss:0.00000, loss_test:0.01120, lr:2.97e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.632, tt:5059.811\n",
      "Ep:142, loss:0.00000, loss_test:0.01122, lr:2.94e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.639, tt:5096.382\n",
      "Ep:143, loss:0.00000, loss_test:0.01123, lr:2.91e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.644, tt:5132.682\n",
      "Ep:144, loss:0.00000, loss_test:0.01126, lr:2.88e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.633, tt:5166.800\n",
      "Ep:145, loss:0.00000, loss_test:0.01129, lr:2.85e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.634, tt:5202.572\n",
      "Ep:146, loss:0.00000, loss_test:0.01132, lr:2.82e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.639, tt:5238.885\n",
      "Ep:147, loss:0.00000, loss_test:0.01136, lr:2.80e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.636, tt:5274.121\n",
      "Ep:148, loss:0.00000, loss_test:0.01137, lr:2.77e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.634, tt:5309.452\n",
      "Ep:149, loss:0.00000, loss_test:0.01140, lr:2.74e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.610, tt:5341.518\n",
      "Ep:150, loss:0.00000, loss_test:0.01143, lr:2.71e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.603, tt:5376.105\n",
      "Ep:151, loss:0.00000, loss_test:0.01144, lr:2.69e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.602, tt:5411.557\n",
      "Ep:152, loss:0.00000, loss_test:0.01146, lr:2.66e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.586, tt:5444.633\n",
      "Ep:153, loss:0.00000, loss_test:0.01151, lr:2.63e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.580, tt:5479.354\n",
      "Ep:154, loss:0.00000, loss_test:0.01153, lr:2.61e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.561, tt:5511.934\n",
      "Ep:155, loss:0.00000, loss_test:0.01156, lr:2.58e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.559, tt:5547.131\n",
      "Ep:156, loss:0.00000, loss_test:0.01160, lr:2.55e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.546, tt:5580.722\n",
      "Ep:157, loss:0.00000, loss_test:0.01161, lr:2.53e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.533, tt:5614.162\n",
      "Ep:158, loss:0.00000, loss_test:0.01162, lr:2.50e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.522, tt:5648.073\n",
      "Ep:159, loss:0.00000, loss_test:0.01166, lr:2.48e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.508, tt:5681.237\n",
      "Ep:160, loss:0.00000, loss_test:0.01168, lr:2.45e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.487, tt:5713.375\n",
      "Ep:161, loss:0.00000, loss_test:0.01169, lr:2.43e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.470, tt:5746.195\n",
      "Ep:162, loss:0.00000, loss_test:0.01168, lr:2.40e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.452, tt:5778.682\n",
      "Ep:163, loss:0.00000, loss_test:0.01176, lr:2.38e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.436, tt:5811.464\n",
      "Ep:164, loss:0.00000, loss_test:0.01176, lr:2.36e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.425, tt:5845.079\n",
      "Ep:165, loss:0.00000, loss_test:0.01175, lr:2.33e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.423, tt:5880.258\n",
      "Ep:166, loss:0.00000, loss_test:0.01180, lr:2.31e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.414, tt:5914.164\n",
      "Ep:167, loss:0.00000, loss_test:0.01180, lr:2.29e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.414, tt:5949.623\n",
      "Ep:168, loss:0.00000, loss_test:0.01182, lr:2.26e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.418, tt:5985.713\n",
      "Ep:169, loss:0.00000, loss_test:0.01185, lr:2.24e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.423, tt:6021.968\n",
      "Ep:170, loss:0.00000, loss_test:0.01188, lr:2.22e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.423, tt:6057.292\n",
      "Ep:171, loss:0.00000, loss_test:0.01190, lr:2.20e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.431, tt:6094.163\n",
      "Ep:172, loss:0.00000, loss_test:0.01192, lr:2.17e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.430, tt:6129.390\n",
      "Ep:173, loss:0.00000, loss_test:0.01194, lr:2.15e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.426, tt:6164.197\n",
      "Ep:174, loss:0.00000, loss_test:0.01194, lr:2.13e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.419, tt:6198.324\n",
      "Ep:175, loss:0.00000, loss_test:0.01198, lr:2.11e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.412, tt:6232.511\n",
      "Ep:176, loss:0.00000, loss_test:0.01201, lr:2.09e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.392, tt:6264.331\n",
      "Ep:177, loss:0.00000, loss_test:0.01201, lr:2.07e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.386, tt:6298.669\n",
      "Ep:178, loss:0.00000, loss_test:0.01203, lr:2.05e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.387, tt:6334.187\n",
      "Ep:179, loss:0.00000, loss_test:0.01205, lr:2.03e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.397, tt:6371.418\n",
      "Ep:180, loss:0.00000, loss_test:0.01204, lr:2.01e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.394, tt:6406.294\n",
      "Ep:181, loss:0.00000, loss_test:0.01208, lr:1.99e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.385, tt:6440.156\n",
      "Ep:182, loss:0.00000, loss_test:0.01211, lr:1.97e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.377, tt:6474.063\n",
      "Ep:183, loss:0.00000, loss_test:0.01208, lr:1.95e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.374, tt:6508.810\n",
      "Ep:184, loss:0.00000, loss_test:0.01214, lr:1.93e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.370, tt:6543.464\n",
      "Ep:185, loss:0.00000, loss_test:0.01215, lr:1.91e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.359, tt:6576.821\n",
      "Ep:186, loss:0.00000, loss_test:0.01216, lr:1.89e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.357, tt:6611.817\n",
      "Ep:187, loss:0.00000, loss_test:0.01217, lr:1.87e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.353, tt:6646.281\n",
      "Ep:188, loss:0.00000, loss_test:0.01221, lr:1.85e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.351, tt:6681.332\n",
      "Ep:189, loss:0.00000, loss_test:0.01221, lr:1.83e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.354, tt:6717.343\n",
      "Ep:190, loss:0.00000, loss_test:0.01223, lr:1.81e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.361, tt:6753.917\n",
      "Ep:191, loss:0.00000, loss_test:0.01224, lr:1.80e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.359, tt:6788.971\n",
      "Ep:192, loss:0.00000, loss_test:0.01225, lr:1.78e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.349, tt:6822.387\n",
      "Ep:193, loss:0.00000, loss_test:0.01227, lr:1.76e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.357, tt:6859.266\n",
      "Ep:194, loss:0.00000, loss_test:0.01230, lr:1.74e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.359, tt:6895.016\n",
      "Ep:195, loss:0.00000, loss_test:0.01231, lr:1.73e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.361, tt:6930.783\n",
      "Ep:196, loss:0.00000, loss_test:0.01230, lr:1.71e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.349, tt:6963.801\n",
      "Ep:197, loss:0.00000, loss_test:0.01232, lr:1.69e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.336, tt:6996.572\n",
      "Ep:198, loss:0.00000, loss_test:0.01234, lr:1.67e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.335, tt:7031.599\n",
      "Ep:199, loss:0.00000, loss_test:0.01237, lr:1.66e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.331, tt:7066.230\n",
      "Ep:200, loss:0.00000, loss_test:0.01236, lr:1.64e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.321, tt:7099.571\n",
      "Ep:201, loss:0.00000, loss_test:0.01238, lr:1.62e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.309, tt:7132.438\n",
      "Ep:202, loss:0.00000, loss_test:0.01241, lr:1.61e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.299, tt:7165.692\n",
      "Ep:203, loss:0.00000, loss_test:0.01239, lr:1.59e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.287, tt:7198.463\n",
      "Ep:204, loss:0.00000, loss_test:0.01242, lr:1.58e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.272, tt:7230.776\n",
      "Ep:205, loss:0.00000, loss_test:0.01246, lr:1.56e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.235, tt:7258.339\n",
      "Ep:206, loss:0.00000, loss_test:0.01244, lr:1.54e-02, fs:0.89617 (r=0.828,p=0.976),  time:35.146, tt:7275.220\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.04520, lr:1.00e-02, fs:0.56000 (r=0.424,p=0.824),  time:32.657, tt:32.657\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00008, loss_test:0.02824, lr:1.00e-02, fs:0.61000 (r=0.616,p=0.604),  time:33.398, tt:66.796\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02257, lr:1.00e-02, fs:0.62712 (r=0.747,p=0.540),  time:34.322, tt:102.965\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02152, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:33.865, tt:135.459\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02177, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:33.765, tt:168.827\n",
      "Ep:5, loss:0.00004, loss_test:0.02226, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:33.747, tt:202.484\n",
      "Ep:6, loss:0.00005, loss_test:0.02252, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:33.713, tt:235.991\n",
      "Ep:7, loss:0.00005, loss_test:0.02251, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:33.818, tt:270.543\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00005, loss_test:0.02229, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:34.018, tt:306.162\n",
      "Ep:9, loss:0.00005, loss_test:0.02194, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:34.101, tt:341.011\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00005, loss_test:0.02149, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:34.136, tt:375.501\n",
      "Ep:11, loss:0.00004, loss_test:0.02097, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:34.124, tt:409.487\n",
      "Ep:12, loss:0.00004, loss_test:0.02043, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:34.156, tt:444.026\n",
      "Ep:13, loss:0.00004, loss_test:0.01990, lr:1.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:34.087, tt:477.213\n",
      "Ep:14, loss:0.00004, loss_test:0.01940, lr:1.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:34.247, tt:513.705\n",
      "Ep:15, loss:0.00004, loss_test:0.01894, lr:1.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:34.177, tt:546.827\n",
      "Ep:16, loss:0.00004, loss_test:0.01853, lr:1.00e-02, fs:0.68148 (r=0.929,p=0.538),  time:34.118, tt:580.012\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01817, lr:1.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:34.191, tt:615.437\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01786, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:34.244, tt:650.638\n",
      "Ep:19, loss:0.00004, loss_test:0.01760, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.304, tt:686.080\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01739, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.525, tt:725.028\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01720, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:34.519, tt:759.417\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01704, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:34.529, tt:794.173\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01690, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:34.549, tt:829.173\n",
      "Ep:24, loss:0.00004, loss_test:0.01676, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:34.461, tt:861.528\n",
      "Ep:25, loss:0.00004, loss_test:0.01663, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.413, tt:894.750\n",
      "Ep:26, loss:0.00004, loss_test:0.01650, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.418, tt:929.278\n",
      "Ep:27, loss:0.00004, loss_test:0.01638, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.461, tt:964.906\n",
      "Ep:28, loss:0.00003, loss_test:0.01625, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:34.495, tt:1000.354\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01612, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:34.490, tt:1034.701\n",
      "Ep:30, loss:0.00003, loss_test:0.01598, lr:1.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:34.486, tt:1069.064\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01586, lr:1.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:34.529, tt:1104.914\n",
      "Ep:32, loss:0.00003, loss_test:0.01575, lr:1.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:34.542, tt:1139.879\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01565, lr:1.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:34.540, tt:1174.344\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01556, lr:1.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:34.522, tt:1208.284\n",
      "Ep:35, loss:0.00003, loss_test:0.01547, lr:1.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:34.553, tt:1243.907\n",
      "Ep:36, loss:0.00003, loss_test:0.01540, lr:1.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:34.570, tt:1279.103\n",
      "Ep:37, loss:0.00003, loss_test:0.01533, lr:1.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:34.639, tt:1316.274\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01527, lr:1.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:34.648, tt:1351.278\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01519, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.745, tt:1389.811\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01511, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.736, tt:1424.177\n",
      "Ep:41, loss:0.00003, loss_test:0.01502, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.786, tt:1461.008\n",
      "Ep:42, loss:0.00003, loss_test:0.01493, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.803, tt:1496.539\n",
      "Ep:43, loss:0.00003, loss_test:0.01484, lr:1.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:34.811, tt:1531.691\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01476, lr:1.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:34.833, tt:1567.465\n",
      "Ep:45, loss:0.00003, loss_test:0.01469, lr:1.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.853, tt:1603.248\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01462, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.869, tt:1638.820\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01454, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.881, tt:1674.265\n",
      "Ep:48, loss:0.00003, loss_test:0.01447, lr:1.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.858, tt:1708.025\n",
      "Ep:49, loss:0.00003, loss_test:0.01440, lr:1.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:34.847, tt:1742.357\n",
      "Ep:50, loss:0.00003, loss_test:0.01433, lr:1.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:34.846, tt:1777.172\n",
      "Ep:51, loss:0.00003, loss_test:0.01426, lr:1.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:34.859, tt:1812.684\n",
      "Ep:52, loss:0.00003, loss_test:0.01419, lr:1.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.869, tt:1848.059\n",
      "Ep:53, loss:0.00003, loss_test:0.01413, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.884, tt:1883.757\n",
      "Ep:54, loss:0.00003, loss_test:0.01406, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.886, tt:1918.705\n",
      "Ep:55, loss:0.00003, loss_test:0.01400, lr:1.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.897, tt:1954.237\n",
      "Ep:56, loss:0.00003, loss_test:0.01394, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.897, tt:1989.117\n",
      "Ep:57, loss:0.00003, loss_test:0.01387, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.894, tt:2023.864\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01382, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.902, tt:2059.193\n",
      "Ep:59, loss:0.00003, loss_test:0.01375, lr:1.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:34.920, tt:2095.181\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.01369, lr:1.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.926, tt:2130.465\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.01362, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.914, tt:2164.696\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00003, loss_test:0.01356, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.924, tt:2200.192\n",
      "Ep:63, loss:0.00003, loss_test:0.01349, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.960, tt:2237.448\n",
      "Ep:64, loss:0.00003, loss_test:0.01343, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.971, tt:2273.135\n",
      "Ep:65, loss:0.00003, loss_test:0.01336, lr:1.00e-02, fs:0.78543 (r=0.980,p=0.655),  time:35.000, tt:2310.030\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00003, loss_test:0.01331, lr:1.00e-02, fs:0.78862 (r=0.980,p=0.660),  time:35.006, tt:2345.391\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00003, loss_test:0.01325, lr:1.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:35.018, tt:2381.246\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.01319, lr:1.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:35.033, tt:2417.304\n",
      "Ep:69, loss:0.00003, loss_test:0.01313, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:35.032, tt:2452.236\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00003, loss_test:0.01307, lr:1.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:35.035, tt:2487.488\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00003, loss_test:0.01302, lr:1.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:35.046, tt:2523.309\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00003, loss_test:0.01296, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:35.050, tt:2558.679\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.01290, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:35.057, tt:2594.200\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01285, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:35.048, tt:2628.615\n",
      "Ep:75, loss:0.00002, loss_test:0.01279, lr:1.00e-02, fs:0.80328 (r=0.990,p=0.676),  time:35.075, tt:2665.674\n",
      "Ep:76, loss:0.00002, loss_test:0.01274, lr:1.00e-02, fs:0.80328 (r=0.990,p=0.676),  time:35.069, tt:2700.334\n",
      "Ep:77, loss:0.00002, loss_test:0.01269, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:35.082, tt:2736.404\n",
      "Ep:78, loss:0.00002, loss_test:0.01264, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:35.106, tt:2773.347\n",
      "Ep:79, loss:0.00002, loss_test:0.01258, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:35.118, tt:2809.426\n",
      "Ep:80, loss:0.00002, loss_test:0.01253, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:35.138, tt:2846.181\n",
      "Ep:81, loss:0.00002, loss_test:0.01248, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:35.146, tt:2881.941\n",
      "Ep:82, loss:0.00002, loss_test:0.01243, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:35.170, tt:2919.100\n",
      "Ep:83, loss:0.00002, loss_test:0.01238, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:35.198, tt:2956.602\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.01234, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:35.207, tt:2992.609\n",
      "Ep:85, loss:0.00002, loss_test:0.01230, lr:1.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:35.207, tt:3027.831\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01227, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:35.211, tt:3063.397\n",
      "Ep:87, loss:0.00002, loss_test:0.01222, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:35.214, tt:3098.816\n",
      "Ep:88, loss:0.00002, loss_test:0.01218, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.223, tt:3134.842\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00002, loss_test:0.01214, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.224, tt:3170.184\n",
      "Ep:90, loss:0.00002, loss_test:0.01210, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.226, tt:3205.552\n",
      "Ep:91, loss:0.00002, loss_test:0.01206, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.228, tt:3240.946\n",
      "Ep:92, loss:0.00002, loss_test:0.01201, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.213, tt:3274.803\n",
      "Ep:93, loss:0.00002, loss_test:0.01197, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.215, tt:3310.242\n",
      "Ep:94, loss:0.00002, loss_test:0.01193, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.222, tt:3346.102\n",
      "Ep:95, loss:0.00002, loss_test:0.01189, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.218, tt:3380.957\n",
      "Ep:96, loss:0.00002, loss_test:0.01184, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:35.216, tt:3415.972\n",
      "Ep:97, loss:0.00002, loss_test:0.01180, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.228, tt:3452.322\n",
      "Ep:98, loss:0.00002, loss_test:0.01177, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.224, tt:3487.167\n",
      "Ep:99, loss:0.00002, loss_test:0.01173, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:35.217, tt:3521.723\n",
      "Ep:100, loss:0.00002, loss_test:0.01169, lr:9.90e-03, fs:0.81857 (r=0.980,p=0.703),  time:35.225, tt:3557.746\n",
      "Ep:101, loss:0.00002, loss_test:0.01166, lr:9.80e-03, fs:0.81857 (r=0.980,p=0.703),  time:35.222, tt:3592.640\n",
      "Ep:102, loss:0.00002, loss_test:0.01162, lr:9.70e-03, fs:0.81857 (r=0.980,p=0.703),  time:35.218, tt:3627.496\n",
      "Ep:103, loss:0.00002, loss_test:0.01158, lr:9.61e-03, fs:0.81857 (r=0.980,p=0.703),  time:35.208, tt:3661.643\n",
      "Ep:104, loss:0.00002, loss_test:0.01155, lr:9.51e-03, fs:0.81857 (r=0.980,p=0.703),  time:35.212, tt:3697.228\n",
      "Ep:105, loss:0.00002, loss_test:0.01152, lr:9.41e-03, fs:0.82203 (r=0.980,p=0.708),  time:35.199, tt:3731.074\n",
      "Ep:106, loss:0.00002, loss_test:0.01148, lr:9.32e-03, fs:0.82203 (r=0.980,p=0.708),  time:35.200, tt:3766.381\n",
      "Ep:107, loss:0.00002, loss_test:0.01145, lr:9.23e-03, fs:0.82203 (r=0.980,p=0.708),  time:35.197, tt:3801.298\n",
      "Ep:108, loss:0.00002, loss_test:0.01142, lr:9.14e-03, fs:0.82203 (r=0.980,p=0.708),  time:35.198, tt:3836.561\n",
      "Ep:109, loss:0.00002, loss_test:0.01139, lr:9.04e-03, fs:0.83262 (r=0.980,p=0.724),  time:35.190, tt:3870.944\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.01136, lr:9.04e-03, fs:0.83262 (r=0.980,p=0.724),  time:35.169, tt:3903.705\n",
      "Ep:111, loss:0.00002, loss_test:0.01134, lr:9.04e-03, fs:0.83262 (r=0.980,p=0.724),  time:35.173, tt:3939.333\n",
      "Ep:112, loss:0.00002, loss_test:0.01131, lr:9.04e-03, fs:0.83262 (r=0.980,p=0.724),  time:35.176, tt:3974.868\n",
      "Ep:113, loss:0.00002, loss_test:0.01128, lr:9.04e-03, fs:0.83621 (r=0.980,p=0.729),  time:35.187, tt:4011.358\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00002, loss_test:0.01125, lr:9.04e-03, fs:0.83621 (r=0.980,p=0.729),  time:35.166, tt:4044.057\n",
      "Ep:115, loss:0.00002, loss_test:0.01122, lr:9.04e-03, fs:0.83621 (r=0.980,p=0.729),  time:35.155, tt:4078.009\n",
      "Ep:116, loss:0.00002, loss_test:0.01120, lr:9.04e-03, fs:0.83621 (r=0.980,p=0.729),  time:35.151, tt:4112.692\n",
      "Ep:117, loss:0.00002, loss_test:0.01117, lr:9.04e-03, fs:0.83621 (r=0.980,p=0.729),  time:35.141, tt:4146.657\n",
      "Ep:118, loss:0.00002, loss_test:0.01114, lr:9.04e-03, fs:0.84348 (r=0.980,p=0.740),  time:35.141, tt:4181.792\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.01111, lr:9.04e-03, fs:0.84348 (r=0.980,p=0.740),  time:35.149, tt:4217.853\n",
      "Ep:120, loss:0.00002, loss_test:0.01110, lr:9.04e-03, fs:0.84348 (r=0.980,p=0.740),  time:35.157, tt:4253.941\n",
      "Ep:121, loss:0.00002, loss_test:0.01107, lr:9.04e-03, fs:0.84716 (r=0.980,p=0.746),  time:35.162, tt:4289.720\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00002, loss_test:0.01104, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.168, tt:4325.620\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00002, loss_test:0.01102, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.168, tt:4360.873\n",
      "Ep:124, loss:0.00002, loss_test:0.01099, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.169, tt:4396.179\n",
      "Ep:125, loss:0.00002, loss_test:0.01097, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.175, tt:4432.046\n",
      "Ep:126, loss:0.00002, loss_test:0.01094, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.173, tt:4467.020\n",
      "Ep:127, loss:0.00002, loss_test:0.01092, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.170, tt:4501.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00002, loss_test:0.01089, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.162, tt:4535.901\n",
      "Ep:129, loss:0.00002, loss_test:0.01087, lr:9.04e-03, fs:0.85463 (r=0.980,p=0.758),  time:35.163, tt:4571.145\n",
      "Ep:130, loss:0.00002, loss_test:0.01085, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.163, tt:4606.400\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00002, loss_test:0.01083, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.151, tt:4639.978\n",
      "Ep:132, loss:0.00002, loss_test:0.01080, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.161, tt:4676.453\n",
      "Ep:133, loss:0.00002, loss_test:0.01078, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.165, tt:4712.164\n",
      "Ep:134, loss:0.00002, loss_test:0.01076, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.152, tt:4745.531\n",
      "Ep:135, loss:0.00002, loss_test:0.01074, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.158, tt:4781.523\n",
      "Ep:136, loss:0.00002, loss_test:0.01072, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.163, tt:4817.292\n",
      "Ep:137, loss:0.00002, loss_test:0.01069, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.162, tt:4852.331\n",
      "Ep:138, loss:0.00002, loss_test:0.01067, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.152, tt:4886.098\n",
      "Ep:139, loss:0.00002, loss_test:0.01066, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.155, tt:4921.643\n",
      "Ep:140, loss:0.00002, loss_test:0.01064, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.162, tt:4957.782\n",
      "Ep:141, loss:0.00002, loss_test:0.01061, lr:9.04e-03, fs:0.85841 (r=0.980,p=0.764),  time:35.158, tt:4992.445\n",
      "Ep:142, loss:0.00002, loss_test:0.01058, lr:8.95e-03, fs:0.86222 (r=0.980,p=0.770),  time:35.158, tt:5027.636\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00002, loss_test:0.01057, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.158, tt:5062.684\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00002, loss_test:0.01055, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.167, tt:5099.192\n",
      "Ep:145, loss:0.00002, loss_test:0.01054, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.172, tt:5135.164\n",
      "Ep:146, loss:0.00002, loss_test:0.01052, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.184, tt:5172.099\n",
      "Ep:147, loss:0.00002, loss_test:0.01050, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.187, tt:5207.633\n",
      "Ep:148, loss:0.00002, loss_test:0.01048, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.187, tt:5242.916\n",
      "Ep:149, loss:0.00002, loss_test:0.01047, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.194, tt:5279.091\n",
      "Ep:150, loss:0.00002, loss_test:0.01045, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.192, tt:5313.955\n",
      "Ep:151, loss:0.00002, loss_test:0.01043, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.193, tt:5349.387\n",
      "Ep:152, loss:0.00002, loss_test:0.01041, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.185, tt:5383.325\n",
      "Ep:153, loss:0.00002, loss_test:0.01039, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.188, tt:5418.925\n",
      "Ep:154, loss:0.00002, loss_test:0.01037, lr:8.95e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.186, tt:5453.839\n",
      "Ep:155, loss:0.00002, loss_test:0.01035, lr:8.86e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.184, tt:5488.771\n",
      "Ep:156, loss:0.00002, loss_test:0.01034, lr:8.78e-03, fs:0.86607 (r=0.980,p=0.776),  time:35.189, tt:5524.600\n",
      "Ep:157, loss:0.00002, loss_test:0.01033, lr:8.69e-03, fs:0.86996 (r=0.980,p=0.782),  time:35.184, tt:5559.115\n",
      "##########Best model found so far##########\n",
      "Ep:158, loss:0.00002, loss_test:0.01031, lr:8.69e-03, fs:0.86996 (r=0.980,p=0.782),  time:35.191, tt:5595.439\n",
      "Ep:159, loss:0.00002, loss_test:0.01029, lr:8.69e-03, fs:0.86996 (r=0.980,p=0.782),  time:35.207, tt:5633.077\n",
      "Ep:160, loss:0.00002, loss_test:0.01027, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.206, tt:5668.220\n",
      "##########Best model found so far##########\n",
      "Ep:161, loss:0.00002, loss_test:0.01025, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.206, tt:5703.366\n",
      "Ep:162, loss:0.00002, loss_test:0.01024, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.215, tt:5740.050\n",
      "Ep:163, loss:0.00002, loss_test:0.01023, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.222, tt:5776.438\n",
      "Ep:164, loss:0.00002, loss_test:0.01021, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.216, tt:5810.715\n",
      "Ep:165, loss:0.00001, loss_test:0.01019, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.216, tt:5845.855\n",
      "Ep:166, loss:0.00001, loss_test:0.01018, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.216, tt:5881.142\n",
      "Ep:167, loss:0.00001, loss_test:0.01017, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.211, tt:5915.474\n",
      "Ep:168, loss:0.00001, loss_test:0.01015, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.200, tt:5948.765\n",
      "Ep:169, loss:0.00001, loss_test:0.01014, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.193, tt:5982.808\n",
      "Ep:170, loss:0.00001, loss_test:0.01012, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.188, tt:6017.212\n",
      "Ep:171, loss:0.00001, loss_test:0.01011, lr:8.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.183, tt:6051.535\n",
      "Ep:172, loss:0.00001, loss_test:0.01010, lr:8.60e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.180, tt:6086.194\n",
      "Ep:173, loss:0.00001, loss_test:0.01008, lr:8.51e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.180, tt:6121.305\n",
      "Ep:174, loss:0.00001, loss_test:0.01007, lr:8.43e-03, fs:0.87387 (r=0.980,p=0.789),  time:35.169, tt:6154.512\n",
      "Ep:175, loss:0.00001, loss_test:0.01005, lr:8.35e-03, fs:0.87783 (r=0.980,p=0.795),  time:35.165, tt:6189.127\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00001, loss_test:0.01004, lr:8.35e-03, fs:0.87783 (r=0.980,p=0.795),  time:35.162, tt:6223.649\n",
      "Ep:177, loss:0.00001, loss_test:0.01002, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.163, tt:6259.013\n",
      "##########Best model found so far##########\n",
      "Ep:178, loss:0.00001, loss_test:0.01001, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.151, tt:6292.017\n",
      "Ep:179, loss:0.00001, loss_test:0.01000, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.140, tt:6325.117\n",
      "Ep:180, loss:0.00001, loss_test:0.00999, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.125, tt:6357.593\n",
      "Ep:181, loss:0.00001, loss_test:0.00998, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.122, tt:6392.288\n",
      "Ep:182, loss:0.00001, loss_test:0.00996, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.124, tt:6427.623\n",
      "Ep:183, loss:0.00001, loss_test:0.00995, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.123, tt:6462.714\n",
      "Ep:184, loss:0.00001, loss_test:0.00993, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.117, tt:6496.585\n",
      "Ep:185, loss:0.00001, loss_test:0.00992, lr:8.35e-03, fs:0.88688 (r=0.990,p=0.803),  time:35.109, tt:6530.324\n",
      "##########Best model found so far##########\n",
      "Ep:186, loss:0.00001, loss_test:0.00992, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.106, tt:6564.863\n",
      "Ep:187, loss:0.00001, loss_test:0.00991, lr:8.35e-03, fs:0.88688 (r=0.990,p=0.803),  time:35.105, tt:6599.674\n",
      "Ep:188, loss:0.00001, loss_test:0.00989, lr:8.35e-03, fs:0.88288 (r=0.990,p=0.797),  time:35.121, tt:6637.857\n",
      "Ep:189, loss:0.00001, loss_test:0.00988, lr:8.35e-03, fs:0.88688 (r=0.990,p=0.803),  time:35.120, tt:6672.827\n",
      "Ep:190, loss:0.00001, loss_test:0.00987, lr:8.35e-03, fs:0.88688 (r=0.990,p=0.803),  time:35.120, tt:6707.988\n",
      "Ep:191, loss:0.00001, loss_test:0.00985, lr:8.35e-03, fs:0.88688 (r=0.990,p=0.803),  time:35.120, tt:6742.998\n",
      "Ep:192, loss:0.00001, loss_test:0.00985, lr:8.35e-03, fs:0.88688 (r=0.990,p=0.803),  time:35.112, tt:6776.568\n",
      "Ep:193, loss:0.00001, loss_test:0.00984, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.106, tt:6810.615\n",
      "##########Best model found so far##########\n",
      "Ep:194, loss:0.00001, loss_test:0.00982, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.106, tt:6845.674\n",
      "Ep:195, loss:0.00001, loss_test:0.00981, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.101, tt:6879.860\n",
      "Ep:196, loss:0.00001, loss_test:0.00979, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.099, tt:6914.459\n",
      "Ep:197, loss:0.00001, loss_test:0.00978, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.102, tt:6950.269\n",
      "Ep:198, loss:0.00001, loss_test:0.00976, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.096, tt:6984.084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:199, loss:0.00001, loss_test:0.00975, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.090, tt:7018.003\n",
      "Ep:200, loss:0.00001, loss_test:0.00974, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:35.094, tt:7053.922\n",
      "Ep:201, loss:0.00001, loss_test:0.00973, lr:8.35e-03, fs:0.89498 (r=0.990,p=0.817),  time:35.095, tt:7089.276\n",
      "##########Best model found so far##########\n",
      "Ep:202, loss:0.00001, loss_test:0.00971, lr:8.35e-03, fs:0.89498 (r=0.990,p=0.817),  time:35.089, tt:7123.035\n",
      "Ep:203, loss:0.00001, loss_test:0.00970, lr:8.35e-03, fs:0.89498 (r=0.990,p=0.817),  time:35.085, tt:7157.309\n",
      "Ep:204, loss:0.00001, loss_test:0.00969, lr:8.35e-03, fs:0.90323 (r=0.990,p=0.831),  time:35.054, tt:7186.092\n",
      "##########Best model found so far##########\n",
      "Ep:205, loss:0.00001, loss_test:0.00968, lr:8.35e-03, fs:0.90741 (r=0.990,p=0.838),  time:35.029, tt:7215.888\n",
      "##########Best model found so far##########\n",
      "Ep:206, loss:0.00001, loss_test:0.00966, lr:8.35e-03, fs:0.90741 (r=0.990,p=0.838),  time:34.973, tt:7239.367\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02807, lr:1.00e-02, fs:0.58537 (r=0.485,p=0.738),  time:39.824, tt:39.824\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02188, lr:1.00e-02, fs:0.59155 (r=0.636,p=0.553),  time:38.996, tt:77.993\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.01995, lr:1.00e-02, fs:0.62698 (r=0.798,p=0.516),  time:38.643, tt:115.929\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02004, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:38.954, tt:155.818\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02051, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:39.056, tt:195.279\n",
      "Ep:5, loss:0.00004, loss_test:0.02084, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:39.361, tt:236.166\n",
      "Ep:6, loss:0.00004, loss_test:0.02091, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.554, tt:276.878\n",
      "Ep:7, loss:0.00004, loss_test:0.02073, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.227, tt:313.817\n",
      "Ep:8, loss:0.00004, loss_test:0.02036, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:39.166, tt:352.491\n",
      "Ep:9, loss:0.00004, loss_test:0.01984, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:39.107, tt:391.067\n",
      "Ep:10, loss:0.00004, loss_test:0.01927, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:39.071, tt:429.780\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01871, lr:1.00e-02, fs:0.68293 (r=0.990,p=0.521),  time:39.057, tt:468.685\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01822, lr:1.00e-02, fs:0.68794 (r=0.980,p=0.530),  time:39.000, tt:506.994\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01781, lr:1.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:38.938, tt:545.135\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01748, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:38.959, tt:584.383\n",
      "Ep:15, loss:0.00004, loss_test:0.01723, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:38.943, tt:623.087\n",
      "Ep:16, loss:0.00004, loss_test:0.01704, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:38.896, tt:661.230\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01690, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.916, tt:700.488\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01678, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:38.996, tt:740.932\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01666, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:39.001, tt:780.017\n",
      "Ep:20, loss:0.00003, loss_test:0.01656, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:38.996, tt:818.907\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01649, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:39.027, tt:858.586\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01644, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:39.081, tt:898.857\n",
      "Ep:23, loss:0.00003, loss_test:0.01640, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:39.089, tt:938.144\n",
      "Ep:24, loss:0.00003, loss_test:0.01635, lr:1.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:39.058, tt:976.440\n",
      "Ep:25, loss:0.00003, loss_test:0.01628, lr:1.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:39.161, tt:1018.194\n",
      "Ep:26, loss:0.00003, loss_test:0.01619, lr:1.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:39.136, tt:1056.684\n",
      "Ep:27, loss:0.00003, loss_test:0.01609, lr:1.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:39.170, tt:1096.774\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01598, lr:1.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:39.088, tt:1133.559\n",
      "Ep:29, loss:0.00003, loss_test:0.01586, lr:1.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:39.075, tt:1172.242\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01573, lr:1.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:39.025, tt:1209.780\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01562, lr:1.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:39.010, tt:1248.319\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01551, lr:1.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:39.039, tt:1288.297\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01541, lr:1.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:39.040, tt:1327.343\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01533, lr:1.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:39.084, tt:1367.954\n",
      "Ep:35, loss:0.00003, loss_test:0.01526, lr:1.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:39.103, tt:1407.722\n",
      "Ep:36, loss:0.00003, loss_test:0.01519, lr:1.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:39.054, tt:1444.988\n",
      "Ep:37, loss:0.00003, loss_test:0.01511, lr:1.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:39.013, tt:1482.488\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01504, lr:1.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:39.032, tt:1522.255\n",
      "Ep:39, loss:0.00003, loss_test:0.01496, lr:1.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:39.040, tt:1561.613\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01488, lr:1.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:39.037, tt:1600.530\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01480, lr:1.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:39.050, tt:1640.108\n",
      "Ep:42, loss:0.00003, loss_test:0.01474, lr:1.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:39.045, tt:1678.952\n",
      "Ep:43, loss:0.00003, loss_test:0.01467, lr:1.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:39.082, tt:1719.590\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01461, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:39.090, tt:1759.071\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01454, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:39.089, tt:1798.090\n",
      "Ep:46, loss:0.00003, loss_test:0.01447, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:39.072, tt:1836.370\n",
      "Ep:47, loss:0.00003, loss_test:0.01441, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:39.093, tt:1876.469\n",
      "Ep:48, loss:0.00003, loss_test:0.01435, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:39.107, tt:1916.225\n",
      "Ep:49, loss:0.00003, loss_test:0.01429, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:39.115, tt:1955.772\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01424, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:39.134, tt:1995.819\n",
      "Ep:51, loss:0.00003, loss_test:0.01418, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:39.129, tt:2034.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00003, loss_test:0.01412, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:39.124, tt:2073.562\n",
      "Ep:53, loss:0.00003, loss_test:0.01407, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:39.112, tt:2112.033\n",
      "Ep:54, loss:0.00003, loss_test:0.01402, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:39.119, tt:2151.563\n",
      "Ep:55, loss:0.00003, loss_test:0.01397, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.147, tt:2192.231\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.01392, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.151, tt:2231.583\n",
      "Ep:57, loss:0.00003, loss_test:0.01387, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.152, tt:2270.806\n",
      "Ep:58, loss:0.00002, loss_test:0.01382, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:39.160, tt:2310.438\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01377, lr:1.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:39.156, tt:2349.338\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01372, lr:1.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:39.161, tt:2388.841\n",
      "Ep:61, loss:0.00002, loss_test:0.01367, lr:1.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:39.168, tt:2428.404\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01362, lr:1.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:39.191, tt:2469.063\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01358, lr:1.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:39.235, tt:2511.036\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.01353, lr:1.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:39.214, tt:2548.881\n",
      "Ep:65, loss:0.00002, loss_test:0.01349, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:39.203, tt:2587.376\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.01344, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:39.194, tt:2626.010\n",
      "Ep:67, loss:0.00002, loss_test:0.01340, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:39.198, tt:2665.453\n",
      "Ep:68, loss:0.00002, loss_test:0.01335, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:39.177, tt:2703.246\n",
      "Ep:69, loss:0.00002, loss_test:0.01331, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:39.169, tt:2741.851\n",
      "Ep:70, loss:0.00002, loss_test:0.01327, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:39.162, tt:2780.493\n",
      "Ep:71, loss:0.00002, loss_test:0.01323, lr:1.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:39.169, tt:2820.147\n",
      "Ep:72, loss:0.00002, loss_test:0.01319, lr:1.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:39.167, tt:2859.219\n",
      "Ep:73, loss:0.00002, loss_test:0.01315, lr:1.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:39.134, tt:2895.942\n",
      "Ep:74, loss:0.00002, loss_test:0.01311, lr:1.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:39.109, tt:2933.172\n",
      "Ep:75, loss:0.00002, loss_test:0.01306, lr:1.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:39.106, tt:2972.084\n",
      "Ep:76, loss:0.00002, loss_test:0.01302, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:39.098, tt:3010.531\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.01298, lr:1.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:39.095, tt:3049.426\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.01294, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:39.075, tt:3086.909\n",
      "Ep:79, loss:0.00002, loss_test:0.01290, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:39.059, tt:3124.749\n",
      "Ep:80, loss:0.00002, loss_test:0.01287, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:39.035, tt:3161.844\n",
      "Ep:81, loss:0.00002, loss_test:0.01283, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:39.032, tt:3200.626\n",
      "Ep:82, loss:0.00002, loss_test:0.01280, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:39.001, tt:3237.042\n",
      "Ep:83, loss:0.00002, loss_test:0.01276, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:38.976, tt:3274.024\n",
      "Ep:84, loss:0.00002, loss_test:0.01273, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:38.960, tt:3311.586\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.01269, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:38.942, tt:3349.037\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01266, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:38.926, tt:3386.534\n",
      "Ep:87, loss:0.00002, loss_test:0.01263, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:38.921, tt:3425.085\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.01260, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:38.908, tt:3462.840\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00002, loss_test:0.01256, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:38.902, tt:3501.205\n",
      "Ep:90, loss:0.00002, loss_test:0.01253, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:38.898, tt:3539.692\n",
      "Ep:91, loss:0.00002, loss_test:0.01250, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:38.885, tt:3577.443\n",
      "Ep:92, loss:0.00002, loss_test:0.01247, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:38.883, tt:3616.133\n",
      "Ep:93, loss:0.00002, loss_test:0.01244, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:38.926, tt:3659.053\n",
      "Ep:94, loss:0.00002, loss_test:0.01241, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:38.926, tt:3697.964\n",
      "Ep:95, loss:0.00002, loss_test:0.01238, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:38.937, tt:3737.966\n",
      "Ep:96, loss:0.00002, loss_test:0.01234, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.979, tt:3780.921\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.01231, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.967, tt:3818.798\n",
      "Ep:98, loss:0.00002, loss_test:0.01228, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.953, tt:3856.333\n",
      "Ep:99, loss:0.00002, loss_test:0.01225, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.947, tt:3894.732\n",
      "Ep:100, loss:0.00002, loss_test:0.01223, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.940, tt:3932.903\n",
      "Ep:101, loss:0.00002, loss_test:0.01220, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.934, tt:3971.241\n",
      "Ep:102, loss:0.00002, loss_test:0.01217, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.936, tt:4010.433\n",
      "Ep:103, loss:0.00002, loss_test:0.01214, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.952, tt:4051.000\n",
      "Ep:104, loss:0.00002, loss_test:0.01211, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.953, tt:4090.051\n",
      "Ep:105, loss:0.00002, loss_test:0.01209, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.956, tt:4129.319\n",
      "Ep:106, loss:0.00002, loss_test:0.01206, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.944, tt:4167.051\n",
      "Ep:107, loss:0.00002, loss_test:0.01204, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:38.961, tt:4207.809\n",
      "Ep:108, loss:0.00002, loss_test:0.01202, lr:9.90e-03, fs:0.83871 (r=0.919,p=0.771),  time:38.951, tt:4245.704\n",
      "Ep:109, loss:0.00002, loss_test:0.01199, lr:9.80e-03, fs:0.83871 (r=0.919,p=0.771),  time:38.965, tt:4286.169\n",
      "Ep:110, loss:0.00002, loss_test:0.01197, lr:9.70e-03, fs:0.83871 (r=0.919,p=0.771),  time:38.951, tt:4323.524\n",
      "Ep:111, loss:0.00002, loss_test:0.01194, lr:9.61e-03, fs:0.83721 (r=0.909,p=0.776),  time:38.941, tt:4361.340\n",
      "Ep:112, loss:0.00002, loss_test:0.01192, lr:9.51e-03, fs:0.83721 (r=0.909,p=0.776),  time:38.942, tt:4400.443\n",
      "Ep:113, loss:0.00002, loss_test:0.01190, lr:9.41e-03, fs:0.83721 (r=0.909,p=0.776),  time:38.938, tt:4438.961\n",
      "Ep:114, loss:0.00002, loss_test:0.01187, lr:9.32e-03, fs:0.83721 (r=0.909,p=0.776),  time:38.932, tt:4477.189\n",
      "Ep:115, loss:0.00002, loss_test:0.01185, lr:9.23e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.930, tt:4515.880\n",
      "Ep:116, loss:0.00002, loss_test:0.01183, lr:9.14e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.925, tt:4554.203\n",
      "Ep:117, loss:0.00002, loss_test:0.01181, lr:9.04e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.922, tt:4592.802\n",
      "Ep:118, loss:0.00002, loss_test:0.01179, lr:8.95e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.929, tt:4632.577\n",
      "Ep:119, loss:0.00002, loss_test:0.01177, lr:8.86e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.951, tt:4674.077\n",
      "Ep:120, loss:0.00002, loss_test:0.01175, lr:8.78e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.935, tt:4711.076\n",
      "Ep:121, loss:0.00002, loss_test:0.01174, lr:8.69e-03, fs:0.83178 (r=0.899,p=0.774),  time:38.947, tt:4751.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00002, loss_test:0.01172, lr:8.60e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.926, tt:4787.937\n",
      "Ep:123, loss:0.00002, loss_test:0.01170, lr:8.51e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.918, tt:4825.844\n",
      "Ep:124, loss:0.00002, loss_test:0.01168, lr:8.43e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.927, tt:4865.851\n",
      "Ep:125, loss:0.00002, loss_test:0.01166, lr:8.35e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.921, tt:4904.106\n",
      "Ep:126, loss:0.00002, loss_test:0.01164, lr:8.26e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.906, tt:4941.095\n",
      "Ep:127, loss:0.00002, loss_test:0.01163, lr:8.18e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.892, tt:4978.200\n",
      "Ep:128, loss:0.00002, loss_test:0.01161, lr:8.10e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.915, tt:5020.043\n",
      "Ep:129, loss:0.00002, loss_test:0.01159, lr:8.02e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.918, tt:5059.309\n",
      "Ep:130, loss:0.00002, loss_test:0.01157, lr:7.94e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.910, tt:5097.196\n",
      "Ep:131, loss:0.00002, loss_test:0.01156, lr:7.86e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.915, tt:5136.839\n",
      "Ep:132, loss:0.00002, loss_test:0.01154, lr:7.78e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.908, tt:5174.775\n",
      "Ep:133, loss:0.00002, loss_test:0.01153, lr:7.70e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.912, tt:5214.263\n",
      "Ep:134, loss:0.00002, loss_test:0.01151, lr:7.62e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.906, tt:5252.357\n",
      "Ep:135, loss:0.00002, loss_test:0.01150, lr:7.55e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.895, tt:5289.773\n",
      "Ep:136, loss:0.00002, loss_test:0.01149, lr:7.47e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.895, tt:5328.556\n",
      "Ep:137, loss:0.00002, loss_test:0.01147, lr:7.40e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.884, tt:5366.057\n",
      "Ep:138, loss:0.00002, loss_test:0.01146, lr:7.32e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.884, tt:5404.889\n",
      "Ep:139, loss:0.00002, loss_test:0.01144, lr:7.25e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.875, tt:5442.556\n",
      "Ep:140, loss:0.00002, loss_test:0.01142, lr:7.18e-03, fs:0.83568 (r=0.899,p=0.781),  time:38.900, tt:5484.907\n",
      "Ep:141, loss:0.00002, loss_test:0.01141, lr:7.11e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.886, tt:5521.794\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00002, loss_test:0.01139, lr:7.11e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.880, tt:5559.886\n",
      "Ep:143, loss:0.00002, loss_test:0.01138, lr:7.11e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.890, tt:5600.105\n",
      "Ep:144, loss:0.00002, loss_test:0.01136, lr:7.11e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.888, tt:5638.724\n",
      "Ep:145, loss:0.00002, loss_test:0.01134, lr:7.11e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.895, tt:5678.675\n",
      "Ep:146, loss:0.00002, loss_test:0.01133, lr:7.11e-03, fs:0.83962 (r=0.899,p=0.788),  time:38.885, tt:5716.124\n",
      "Ep:147, loss:0.00002, loss_test:0.01131, lr:7.11e-03, fs:0.83412 (r=0.889,p=0.786),  time:38.892, tt:5756.051\n",
      "Ep:148, loss:0.00002, loss_test:0.01130, lr:7.11e-03, fs:0.83412 (r=0.889,p=0.786),  time:38.898, tt:5795.758\n",
      "Ep:149, loss:0.00002, loss_test:0.01128, lr:7.11e-03, fs:0.83412 (r=0.889,p=0.786),  time:38.886, tt:5832.940\n",
      "Ep:150, loss:0.00002, loss_test:0.01127, lr:7.11e-03, fs:0.83810 (r=0.889,p=0.793),  time:38.883, tt:5871.292\n",
      "Ep:151, loss:0.00002, loss_test:0.01125, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.883, tt:5910.151\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00002, loss_test:0.01124, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.885, tt:5949.354\n",
      "Ep:153, loss:0.00002, loss_test:0.01123, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.869, tt:5985.873\n",
      "Ep:154, loss:0.00002, loss_test:0.01121, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.860, tt:6023.293\n",
      "Ep:155, loss:0.00002, loss_test:0.01120, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.853, tt:6061.139\n",
      "Ep:156, loss:0.00002, loss_test:0.01119, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.865, tt:6101.783\n",
      "Ep:157, loss:0.00001, loss_test:0.01118, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.896, tt:6145.624\n",
      "Ep:158, loss:0.00001, loss_test:0.01117, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.887, tt:6182.954\n",
      "Ep:159, loss:0.00001, loss_test:0.01115, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.882, tt:6221.093\n",
      "Ep:160, loss:0.00001, loss_test:0.01114, lr:7.11e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.883, tt:6260.184\n",
      "Ep:161, loss:0.00001, loss_test:0.01113, lr:7.11e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.897, tt:6301.390\n",
      "Ep:162, loss:0.00001, loss_test:0.01112, lr:7.11e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.905, tt:6341.445\n",
      "Ep:163, loss:0.00001, loss_test:0.01111, lr:7.03e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.901, tt:6379.725\n",
      "Ep:164, loss:0.00001, loss_test:0.01110, lr:6.96e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.901, tt:6418.748\n",
      "Ep:165, loss:0.00001, loss_test:0.01109, lr:6.89e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.893, tt:6456.292\n",
      "Ep:166, loss:0.00001, loss_test:0.01108, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.912, tt:6498.275\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00001, loss_test:0.01107, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.918, tt:6538.152\n",
      "Ep:168, loss:0.00001, loss_test:0.01106, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.920, tt:6577.558\n",
      "Ep:169, loss:0.00001, loss_test:0.01105, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.920, tt:6616.394\n",
      "Ep:170, loss:0.00001, loss_test:0.01104, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.925, tt:6656.233\n",
      "Ep:171, loss:0.00001, loss_test:0.01102, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.920, tt:6694.248\n",
      "Ep:172, loss:0.00001, loss_test:0.01101, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.930, tt:6734.951\n",
      "Ep:173, loss:0.00001, loss_test:0.01100, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.930, tt:6773.902\n",
      "Ep:174, loss:0.00001, loss_test:0.01099, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.949, tt:6816.065\n",
      "Ep:175, loss:0.00001, loss_test:0.01097, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.955, tt:6856.000\n",
      "Ep:176, loss:0.00001, loss_test:0.01097, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.956, tt:6895.280\n",
      "Ep:177, loss:0.00001, loss_test:0.01096, lr:6.83e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.955, tt:6934.065\n",
      "Ep:178, loss:0.00001, loss_test:0.01095, lr:6.76e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.952, tt:6972.429\n",
      "Ep:179, loss:0.00001, loss_test:0.01093, lr:6.69e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.957, tt:7012.299\n",
      "Ep:180, loss:0.00001, loss_test:0.01092, lr:6.62e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.953, tt:7050.546\n",
      "Ep:181, loss:0.00001, loss_test:0.01091, lr:6.56e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.956, tt:7090.054\n",
      "Ep:182, loss:0.00001, loss_test:0.01090, lr:6.49e-03, fs:0.84878 (r=0.879,p=0.821),  time:38.958, tt:7129.286\n",
      "##########Best model found so far##########\n",
      "Ep:183, loss:0.00001, loss_test:0.01089, lr:6.49e-03, fs:0.84878 (r=0.879,p=0.821),  time:38.956, tt:7167.951\n",
      "Ep:184, loss:0.00001, loss_test:0.01087, lr:6.49e-03, fs:0.84878 (r=0.879,p=0.821),  time:38.956, tt:7206.899\n",
      "Ep:185, loss:0.00001, loss_test:0.01086, lr:6.49e-03, fs:0.84878 (r=0.879,p=0.821),  time:38.958, tt:7246.214\n",
      "Ep:186, loss:0.00001, loss_test:0.01085, lr:6.49e-03, fs:0.84729 (r=0.869,p=0.827),  time:38.960, tt:7285.568\n",
      "Ep:187, loss:0.00001, loss_test:0.01084, lr:6.49e-03, fs:0.84729 (r=0.869,p=0.827),  time:38.966, tt:7325.527\n",
      "Ep:188, loss:0.00001, loss_test:0.01083, lr:6.49e-03, fs:0.84729 (r=0.869,p=0.827),  time:38.960, tt:7363.397\n",
      "Ep:189, loss:0.00001, loss_test:0.01082, lr:6.49e-03, fs:0.84729 (r=0.869,p=0.827),  time:38.963, tt:7402.996\n",
      "Ep:190, loss:0.00001, loss_test:0.01081, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.963, tt:7441.951\n",
      "##########Best model found so far##########\n",
      "Ep:191, loss:0.00001, loss_test:0.01081, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.989, tt:7485.851\n",
      "Ep:192, loss:0.00001, loss_test:0.01079, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.987, tt:7524.502\n",
      "Ep:193, loss:0.00001, loss_test:0.01078, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.986, tt:7563.341\n",
      "Ep:194, loss:0.00001, loss_test:0.01077, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.984, tt:7601.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00001, loss_test:0.01076, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.983, tt:7640.645\n",
      "Ep:196, loss:0.00001, loss_test:0.01075, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.977, tt:7678.391\n",
      "Ep:197, loss:0.00001, loss_test:0.01074, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.967, tt:7715.462\n",
      "Ep:198, loss:0.00001, loss_test:0.01073, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.966, tt:7754.161\n",
      "Ep:199, loss:0.00001, loss_test:0.01072, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.963, tt:7792.557\n",
      "Ep:200, loss:0.00001, loss_test:0.01071, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.959, tt:7830.781\n",
      "Ep:201, loss:0.00001, loss_test:0.01070, lr:6.49e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.959, tt:7869.686\n",
      "Ep:202, loss:0.00001, loss_test:0.01069, lr:6.43e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.951, tt:7907.135\n",
      "Ep:203, loss:0.00001, loss_test:0.01068, lr:6.36e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.918, tt:7939.198\n",
      "Ep:204, loss:0.00001, loss_test:0.01067, lr:6.30e-03, fs:0.85149 (r=0.869,p=0.835),  time:38.861, tt:7966.509\n",
      "Ep:205, loss:0.00001, loss_test:0.01066, lr:6.24e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.841, tt:8001.151\n",
      "Ep:206, loss:0.00001, loss_test:0.01065, lr:6.17e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.827, tt:8037.136\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12846, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:36.804, tt:36.804\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12428, lr:1.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:36.711, tt:73.421\n",
      "Ep:2, loss:0.00026, loss_test:0.12004, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:37.236, tt:111.709\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11700, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:37.257, tt:149.026\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11454, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:37.206, tt:186.030\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11163, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:37.125, tt:222.747\n",
      "Ep:6, loss:0.00024, loss_test:0.10830, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:36.982, tt:258.875\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10502, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:36.873, tt:294.988\n",
      "Ep:8, loss:0.00022, loss_test:0.10188, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:36.855, tt:331.695\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09856, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:36.671, tt:366.712\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09526, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:36.653, tt:403.180\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09290, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:36.572, tt:438.869\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09081, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:36.579, tt:475.533\n",
      "Ep:13, loss:0.00019, loss_test:0.08874, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:36.658, tt:513.212\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.08693, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:36.600, tt:549.001\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08521, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:36.530, tt:584.483\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08398, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:36.516, tt:620.773\n",
      "Ep:17, loss:0.00017, loss_test:0.08314, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:36.531, tt:657.563\n",
      "Ep:18, loss:0.00017, loss_test:0.08211, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:36.553, tt:694.514\n",
      "Ep:19, loss:0.00016, loss_test:0.08089, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:36.601, tt:732.022\n",
      "Ep:20, loss:0.00016, loss_test:0.07957, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:36.615, tt:768.913\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.07856, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:36.598, tt:805.162\n",
      "Ep:22, loss:0.00015, loss_test:0.07703, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:36.562, tt:840.925\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.07602, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:36.577, tt:877.857\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07564, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:36.598, tt:914.958\n",
      "Ep:25, loss:0.00014, loss_test:0.07385, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:36.525, tt:949.641\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.07330, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:36.531, tt:986.340\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07184, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:36.533, tt:1022.925\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07067, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:36.580, tt:1060.821\n",
      "Ep:29, loss:0.00012, loss_test:0.06872, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:36.536, tt:1096.095\n",
      "Ep:30, loss:0.00012, loss_test:0.06896, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:36.542, tt:1132.804\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.06686, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:36.540, tt:1169.281\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.06708, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:36.533, tt:1205.595\n",
      "Ep:33, loss:0.00011, loss_test:0.06469, lr:1.00e-02, fs:0.92079 (r=0.939,p=0.903),  time:36.527, tt:1241.928\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06351, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:36.518, tt:1278.128\n",
      "Ep:35, loss:0.00010, loss_test:0.06242, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:36.514, tt:1314.507\n",
      "Ep:36, loss:0.00010, loss_test:0.06113, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:36.502, tt:1350.566\n",
      "Ep:37, loss:0.00009, loss_test:0.06085, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:36.597, tt:1390.695\n",
      "Ep:38, loss:0.00009, loss_test:0.05984, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:36.584, tt:1426.783\n",
      "Ep:39, loss:0.00009, loss_test:0.05982, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:36.592, tt:1463.668\n",
      "Ep:40, loss:0.00009, loss_test:0.05832, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:36.521, tt:1497.353\n",
      "Ep:41, loss:0.00008, loss_test:0.05782, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:36.479, tt:1532.135\n",
      "Ep:42, loss:0.00008, loss_test:0.05736, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:36.428, tt:1566.410\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.05609, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:36.461, tt:1604.302\n",
      "Ep:44, loss:0.00008, loss_test:0.05463, lr:1.00e-02, fs:0.92929 (r=0.929,p=0.929),  time:36.453, tt:1640.376\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.05475, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:36.486, tt:1678.333\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.05359, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:36.459, tt:1713.557\n",
      "Ep:47, loss:0.00007, loss_test:0.05258, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:36.446, tt:1749.420\n",
      "Ep:48, loss:0.00007, loss_test:0.05195, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:36.446, tt:1785.871\n",
      "Ep:49, loss:0.00006, loss_test:0.05217, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:36.413, tt:1820.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00006, loss_test:0.05009, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:36.421, tt:1857.469\n",
      "Ep:51, loss:0.00006, loss_test:0.05047, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:36.408, tt:1893.208\n",
      "Ep:52, loss:0.00006, loss_test:0.05053, lr:1.00e-02, fs:0.93532 (r=0.949,p=0.922),  time:36.396, tt:1929.008\n",
      "Ep:53, loss:0.00006, loss_test:0.04908, lr:1.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:36.380, tt:1964.512\n",
      "Ep:54, loss:0.00006, loss_test:0.04790, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:36.383, tt:2001.048\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.04931, lr:1.00e-02, fs:0.93467 (r=0.939,p=0.930),  time:36.380, tt:2037.268\n",
      "Ep:56, loss:0.00005, loss_test:0.04857, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:36.393, tt:2074.429\n",
      "Ep:57, loss:0.00005, loss_test:0.04732, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:36.328, tt:2107.008\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.04817, lr:1.00e-02, fs:0.94472 (r=0.949,p=0.940),  time:36.294, tt:2141.326\n",
      "Ep:59, loss:0.00005, loss_test:0.04645, lr:1.00e-02, fs:0.95050 (r=0.970,p=0.932),  time:36.283, tt:2176.954\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.04597, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:36.236, tt:2210.388\n",
      "Ep:61, loss:0.00005, loss_test:0.04671, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:36.229, tt:2246.171\n",
      "Ep:62, loss:0.00004, loss_test:0.04506, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:36.222, tt:2281.979\n",
      "Ep:63, loss:0.00004, loss_test:0.04436, lr:1.00e-02, fs:0.95000 (r=0.960,p=0.941),  time:36.179, tt:2315.460\n",
      "Ep:64, loss:0.00004, loss_test:0.04431, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:36.176, tt:2351.423\n",
      "Ep:65, loss:0.00004, loss_test:0.04468, lr:1.00e-02, fs:0.94949 (r=0.949,p=0.949),  time:36.161, tt:2386.642\n",
      "Ep:66, loss:0.00004, loss_test:0.04468, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:36.151, tt:2422.104\n",
      "Ep:67, loss:0.00004, loss_test:0.04405, lr:1.00e-02, fs:0.95000 (r=0.960,p=0.941),  time:36.166, tt:2459.275\n",
      "Ep:68, loss:0.00004, loss_test:0.04220, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:36.142, tt:2493.779\n",
      "Ep:69, loss:0.00003, loss_test:0.04388, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:36.149, tt:2530.411\n",
      "Ep:70, loss:0.00003, loss_test:0.04254, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:36.130, tt:2565.221\n",
      "Ep:71, loss:0.00003, loss_test:0.04269, lr:9.90e-03, fs:0.94059 (r=0.960,p=0.922),  time:36.131, tt:2601.404\n",
      "Ep:72, loss:0.00003, loss_test:0.04267, lr:9.80e-03, fs:0.94527 (r=0.960,p=0.931),  time:36.116, tt:2636.469\n",
      "Ep:73, loss:0.00003, loss_test:0.04269, lr:9.70e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.071, tt:2669.264\n",
      "Ep:74, loss:0.00003, loss_test:0.04285, lr:9.61e-03, fs:0.94059 (r=0.960,p=0.922),  time:36.051, tt:2703.791\n",
      "Ep:75, loss:0.00003, loss_test:0.04261, lr:9.51e-03, fs:0.94527 (r=0.960,p=0.931),  time:36.064, tt:2740.879\n",
      "Ep:76, loss:0.00003, loss_test:0.04191, lr:9.41e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.039, tt:2775.041\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00003, loss_test:0.04329, lr:9.41e-03, fs:0.94059 (r=0.960,p=0.922),  time:36.025, tt:2809.955\n",
      "Ep:78, loss:0.00003, loss_test:0.04179, lr:9.41e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.035, tt:2846.782\n",
      "Ep:79, loss:0.00003, loss_test:0.04243, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.050, tt:2884.014\n",
      "Ep:80, loss:0.00003, loss_test:0.04234, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.068, tt:2921.492\n",
      "Ep:81, loss:0.00003, loss_test:0.04111, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.091, tt:2959.491\n",
      "Ep:82, loss:0.00002, loss_test:0.04237, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.102, tt:2996.445\n",
      "Ep:83, loss:0.00002, loss_test:0.04088, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.099, tt:3032.302\n",
      "Ep:84, loss:0.00002, loss_test:0.04122, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.093, tt:3067.920\n",
      "Ep:85, loss:0.00002, loss_test:0.04118, lr:9.41e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.084, tt:3103.202\n",
      "Ep:86, loss:0.00002, loss_test:0.04164, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.078, tt:3138.809\n",
      "Ep:87, loss:0.00002, loss_test:0.04116, lr:9.41e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.073, tt:3174.459\n",
      "Ep:88, loss:0.00002, loss_test:0.04293, lr:9.32e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.071, tt:3210.335\n",
      "Ep:89, loss:0.00002, loss_test:0.04282, lr:9.23e-03, fs:0.93532 (r=0.949,p=0.922),  time:36.076, tt:3246.850\n",
      "Ep:90, loss:0.00003, loss_test:0.04101, lr:9.14e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.091, tt:3284.281\n",
      "Ep:91, loss:0.00002, loss_test:0.04344, lr:9.04e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.079, tt:3319.232\n",
      "Ep:92, loss:0.00002, loss_test:0.04142, lr:8.95e-03, fs:0.96517 (r=0.980,p=0.951),  time:36.076, tt:3355.039\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.04372, lr:8.95e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.087, tt:3392.161\n",
      "Ep:94, loss:0.00002, loss_test:0.04108, lr:8.95e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.084, tt:3427.979\n",
      "Ep:95, loss:0.00002, loss_test:0.04370, lr:8.95e-03, fs:0.94472 (r=0.949,p=0.940),  time:36.069, tt:3462.667\n",
      "Ep:96, loss:0.00002, loss_test:0.04146, lr:8.95e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.062, tt:3498.054\n",
      "Ep:97, loss:0.00002, loss_test:0.04222, lr:8.95e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.073, tt:3535.165\n",
      "Ep:98, loss:0.00002, loss_test:0.04276, lr:8.95e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.088, tt:3572.751\n",
      "Ep:99, loss:0.00002, loss_test:0.04111, lr:8.95e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.087, tt:3608.750\n",
      "Ep:100, loss:0.00002, loss_test:0.04218, lr:8.95e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.091, tt:3645.144\n",
      "Ep:101, loss:0.00002, loss_test:0.04042, lr:8.95e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.087, tt:3680.894\n",
      "Ep:102, loss:0.00002, loss_test:0.04052, lr:8.95e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.092, tt:3717.520\n",
      "Ep:103, loss:0.00002, loss_test:0.04150, lr:8.95e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.102, tt:3754.586\n",
      "Ep:104, loss:0.00002, loss_test:0.03986, lr:8.86e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.088, tt:3789.202\n",
      "Ep:105, loss:0.00002, loss_test:0.04167, lr:8.78e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.076, tt:3824.026\n",
      "Ep:106, loss:0.00002, loss_test:0.04008, lr:8.69e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.080, tt:3860.570\n",
      "Ep:107, loss:0.00002, loss_test:0.04085, lr:8.60e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.085, tt:3897.152\n",
      "Ep:108, loss:0.00002, loss_test:0.04090, lr:8.51e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.089, tt:3933.707\n",
      "Ep:109, loss:0.00001, loss_test:0.03977, lr:8.43e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.104, tt:3971.419\n",
      "Ep:110, loss:0.00001, loss_test:0.04044, lr:8.35e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.104, tt:4007.526\n",
      "Ep:111, loss:0.00001, loss_test:0.03988, lr:8.26e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.150, tt:4048.765\n",
      "Ep:112, loss:0.00001, loss_test:0.04089, lr:8.18e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.164, tt:4086.508\n",
      "Ep:113, loss:0.00001, loss_test:0.04028, lr:8.10e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.162, tt:4122.456\n",
      "Ep:114, loss:0.00001, loss_test:0.04034, lr:8.02e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.159, tt:4158.307\n",
      "Ep:115, loss:0.00001, loss_test:0.04068, lr:7.94e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.152, tt:4193.680\n",
      "Ep:116, loss:0.00001, loss_test:0.03989, lr:7.86e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.147, tt:4229.251\n",
      "Ep:117, loss:0.00001, loss_test:0.04130, lr:7.78e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.146, tt:4265.198\n",
      "Ep:118, loss:0.00001, loss_test:0.04004, lr:7.70e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.163, tt:4303.360\n",
      "Ep:119, loss:0.00001, loss_test:0.04118, lr:7.62e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.163, tt:4339.527\n",
      "Ep:120, loss:0.00001, loss_test:0.04063, lr:7.55e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.158, tt:4375.067\n",
      "Ep:121, loss:0.00001, loss_test:0.04018, lr:7.47e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.164, tt:4412.039\n",
      "Ep:122, loss:0.00001, loss_test:0.04060, lr:7.40e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.169, tt:4448.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00001, loss_test:0.04074, lr:7.32e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.179, tt:4486.247\n",
      "Ep:124, loss:0.00001, loss_test:0.04058, lr:7.25e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.177, tt:4522.155\n",
      "Ep:125, loss:0.00001, loss_test:0.04035, lr:7.18e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.174, tt:4557.878\n",
      "Ep:126, loss:0.00001, loss_test:0.04083, lr:7.11e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.167, tt:4593.181\n",
      "Ep:127, loss:0.00001, loss_test:0.04005, lr:7.03e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.171, tt:4629.917\n",
      "Ep:128, loss:0.00001, loss_test:0.04076, lr:6.96e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.177, tt:4666.829\n",
      "Ep:129, loss:0.00001, loss_test:0.04076, lr:6.89e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.205, tt:4706.589\n",
      "Ep:130, loss:0.00001, loss_test:0.04082, lr:6.83e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.205, tt:4742.890\n",
      "Ep:131, loss:0.00001, loss_test:0.04123, lr:6.76e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.216, tt:4780.462\n",
      "Ep:132, loss:0.00001, loss_test:0.04106, lr:6.69e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.223, tt:4817.716\n",
      "Ep:133, loss:0.00001, loss_test:0.04069, lr:6.62e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.216, tt:4852.975\n",
      "Ep:134, loss:0.00001, loss_test:0.04108, lr:6.56e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.204, tt:4887.543\n",
      "Ep:135, loss:0.00001, loss_test:0.04069, lr:6.49e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.205, tt:4923.849\n",
      "Ep:136, loss:0.00001, loss_test:0.04159, lr:6.43e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.204, tt:4959.881\n",
      "Ep:137, loss:0.00001, loss_test:0.04065, lr:6.36e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.198, tt:4995.372\n",
      "Ep:138, loss:0.00001, loss_test:0.04104, lr:6.30e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.183, tt:5029.424\n",
      "Ep:139, loss:0.00001, loss_test:0.04112, lr:6.24e-03, fs:0.94949 (r=0.949,p=0.949),  time:36.178, tt:5064.916\n",
      "Ep:140, loss:0.00001, loss_test:0.04141, lr:6.17e-03, fs:0.94949 (r=0.949,p=0.949),  time:36.186, tt:5102.226\n",
      "Ep:141, loss:0.00001, loss_test:0.04128, lr:6.11e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.183, tt:5138.013\n",
      "Ep:142, loss:0.00001, loss_test:0.04171, lr:6.05e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.176, tt:5173.200\n",
      "Ep:143, loss:0.00001, loss_test:0.04115, lr:5.99e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.172, tt:5208.748\n",
      "Ep:144, loss:0.00001, loss_test:0.04150, lr:5.93e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.187, tt:5247.098\n",
      "Ep:145, loss:0.00001, loss_test:0.04127, lr:5.87e-03, fs:0.94949 (r=0.949,p=0.949),  time:36.185, tt:5283.005\n",
      "Ep:146, loss:0.00001, loss_test:0.04083, lr:5.81e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.180, tt:5318.472\n",
      "Ep:147, loss:0.00001, loss_test:0.04134, lr:5.75e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.184, tt:5355.267\n",
      "Ep:148, loss:0.00001, loss_test:0.04188, lr:5.70e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.179, tt:5390.683\n",
      "Ep:149, loss:0.00001, loss_test:0.04075, lr:5.64e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.181, tt:5427.125\n",
      "Ep:150, loss:0.00001, loss_test:0.04171, lr:5.58e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.180, tt:5463.249\n",
      "Ep:151, loss:0.00001, loss_test:0.04150, lr:5.53e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.179, tt:5499.155\n",
      "Ep:152, loss:0.00001, loss_test:0.04135, lr:5.47e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.204, tt:5539.239\n",
      "Ep:153, loss:0.00001, loss_test:0.04140, lr:5.42e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.195, tt:5574.093\n",
      "Ep:154, loss:0.00001, loss_test:0.04185, lr:5.36e-03, fs:0.93333 (r=0.919,p=0.948),  time:36.189, tt:5609.352\n",
      "Ep:155, loss:0.00001, loss_test:0.04138, lr:5.31e-03, fs:0.95477 (r=0.960,p=0.950),  time:36.192, tt:5645.922\n",
      "Ep:156, loss:0.00001, loss_test:0.04153, lr:5.26e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.191, tt:5681.967\n",
      "Ep:157, loss:0.00001, loss_test:0.04190, lr:5.20e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.191, tt:5718.189\n",
      "Ep:158, loss:0.00001, loss_test:0.04156, lr:5.15e-03, fs:0.94949 (r=0.949,p=0.949),  time:36.194, tt:5754.825\n",
      "Ep:159, loss:0.00001, loss_test:0.04146, lr:5.10e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.195, tt:5791.208\n",
      "Ep:160, loss:0.00001, loss_test:0.04220, lr:5.05e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.195, tt:5827.346\n",
      "Ep:161, loss:0.00001, loss_test:0.04150, lr:5.00e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.194, tt:5863.436\n",
      "Ep:162, loss:0.00001, loss_test:0.04196, lr:4.95e-03, fs:0.93333 (r=0.919,p=0.948),  time:36.194, tt:5899.566\n",
      "Ep:163, loss:0.00001, loss_test:0.04228, lr:4.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.181, tt:5933.721\n",
      "Ep:164, loss:0.00001, loss_test:0.04206, lr:4.85e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.178, tt:5969.376\n",
      "Ep:165, loss:0.00001, loss_test:0.04201, lr:4.80e-03, fs:0.92228 (r=0.899,p=0.947),  time:36.172, tt:6004.498\n",
      "Ep:166, loss:0.00001, loss_test:0.04192, lr:4.75e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.182, tt:6042.362\n",
      "Ep:167, loss:0.00001, loss_test:0.04214, lr:4.71e-03, fs:0.89947 (r=0.859,p=0.944),  time:36.179, tt:6078.086\n",
      "Ep:168, loss:0.00001, loss_test:0.04204, lr:4.66e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.170, tt:6112.721\n",
      "Ep:169, loss:0.00001, loss_test:0.04258, lr:4.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.164, tt:6147.942\n",
      "Ep:170, loss:0.00001, loss_test:0.04279, lr:4.57e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.156, tt:6182.725\n",
      "Ep:171, loss:0.00001, loss_test:0.04209, lr:4.52e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.156, tt:6218.803\n",
      "Ep:172, loss:0.00001, loss_test:0.04240, lr:4.48e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.154, tt:6254.597\n",
      "Ep:173, loss:0.00001, loss_test:0.04216, lr:4.43e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.149, tt:6289.864\n",
      "Ep:174, loss:0.00001, loss_test:0.04225, lr:4.39e-03, fs:0.89947 (r=0.859,p=0.944),  time:36.144, tt:6325.279\n",
      "Ep:175, loss:0.00001, loss_test:0.04284, lr:4.34e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.142, tt:6360.965\n",
      "Ep:176, loss:0.00001, loss_test:0.04231, lr:4.30e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.139, tt:6396.689\n",
      "Ep:177, loss:0.00001, loss_test:0.04288, lr:4.26e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.138, tt:6432.528\n",
      "Ep:178, loss:0.00001, loss_test:0.04248, lr:4.21e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.133, tt:6467.717\n",
      "Ep:179, loss:0.00001, loss_test:0.04252, lr:4.17e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.131, tt:6503.617\n",
      "Ep:180, loss:0.00001, loss_test:0.04299, lr:4.13e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.129, tt:6539.431\n",
      "Ep:181, loss:0.00001, loss_test:0.04287, lr:4.09e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.123, tt:6574.426\n",
      "Ep:182, loss:0.00001, loss_test:0.04287, lr:4.05e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.124, tt:6610.696\n",
      "Ep:183, loss:0.00001, loss_test:0.04264, lr:4.01e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.133, tt:6648.455\n",
      "Ep:184, loss:0.00001, loss_test:0.04275, lr:3.97e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.129, tt:6683.911\n",
      "Ep:185, loss:0.00001, loss_test:0.04289, lr:3.93e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.131, tt:6720.380\n",
      "Ep:186, loss:0.00001, loss_test:0.04299, lr:3.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.131, tt:6756.510\n",
      "Ep:187, loss:0.00001, loss_test:0.04311, lr:3.85e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.129, tt:6792.200\n",
      "Ep:188, loss:0.00001, loss_test:0.04292, lr:3.81e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.128, tt:6828.203\n",
      "Ep:189, loss:0.00001, loss_test:0.04317, lr:3.77e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.118, tt:6862.338\n",
      "Ep:190, loss:0.00001, loss_test:0.04308, lr:3.73e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.105, tt:6896.109\n",
      "Ep:191, loss:0.00001, loss_test:0.04305, lr:3.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.105, tt:6932.104\n",
      "Ep:192, loss:0.00001, loss_test:0.04309, lr:3.66e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.111, tt:6969.423\n",
      "Ep:193, loss:0.00001, loss_test:0.04318, lr:3.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.116, tt:7006.552\n",
      "Ep:194, loss:0.00001, loss_test:0.04330, lr:3.59e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.117, tt:7042.775\n",
      "Ep:195, loss:0.00001, loss_test:0.04297, lr:3.55e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.114, tt:7078.334\n",
      "Ep:196, loss:0.00001, loss_test:0.04374, lr:3.52e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.104, tt:7112.578\n",
      "Ep:197, loss:0.00001, loss_test:0.04317, lr:3.48e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.107, tt:7149.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:198, loss:0.00001, loss_test:0.04334, lr:3.45e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.124, tt:7188.616\n",
      "Ep:199, loss:0.00001, loss_test:0.04354, lr:3.41e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.131, tt:7226.150\n",
      "Ep:200, loss:0.00001, loss_test:0.04319, lr:3.38e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.136, tt:7263.301\n",
      "Ep:201, loss:0.00001, loss_test:0.04353, lr:3.34e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.141, tt:7300.445\n",
      "Ep:202, loss:0.00001, loss_test:0.04347, lr:3.31e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.132, tt:7334.768\n",
      "Ep:203, loss:0.00001, loss_test:0.04345, lr:3.28e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.109, tt:7366.159\n",
      "Ep:204, loss:0.00001, loss_test:0.04339, lr:3.24e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.017, tt:7383.513\n",
      "Ep:205, loss:0.00001, loss_test:0.04340, lr:3.21e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.005, tt:7416.928\n",
      "Ep:206, loss:0.00001, loss_test:0.04376, lr:3.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.982, tt:7448.310\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13835, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.859, tt:37.859\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13584, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:38.462, tt:76.925\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13141, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:38.402, tt:115.206\n",
      "Ep:3, loss:0.00027, loss_test:0.12434, lr:1.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:38.709, tt:154.837\n",
      "Ep:4, loss:0.00026, loss_test:0.11551, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:38.546, tt:192.730\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10882, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:38.374, tt:230.242\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10585, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:38.365, tt:268.555\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10516, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:38.415, tt:307.324\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10236, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:38.203, tt:343.829\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09460, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:38.046, tt:380.457\n",
      "Ep:10, loss:0.00020, loss_test:0.09272, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:38.179, tt:419.972\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09202, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:38.295, tt:459.538\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.08562, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:38.211, tt:496.749\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.08510, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:38.222, tt:535.111\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08360, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:38.388, tt:575.818\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08003, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:38.368, tt:613.885\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.07964, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:38.269, tt:650.565\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.07670, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:38.342, tt:690.159\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07631, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:38.305, tt:727.787\n",
      "Ep:19, loss:0.00014, loss_test:0.07299, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:38.268, tt:765.351\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07132, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.341, tt:805.155\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.06932, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:38.271, tt:841.967\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.06892, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:38.265, tt:880.092\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.06548, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:38.306, tt:919.354\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.06615, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:38.264, tt:956.601\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.06141, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.306, tt:995.964\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.06177, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:38.365, tt:1035.859\n",
      "Ep:27, loss:0.00010, loss_test:0.05872, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:38.479, tt:1077.400\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.05788, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:38.453, tt:1115.144\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.05644, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:38.458, tt:1153.736\n",
      "Ep:30, loss:0.00009, loss_test:0.05415, lr:1.00e-02, fs:0.94118 (r=0.970,p=0.914),  time:38.509, tt:1193.788\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.05377, lr:1.00e-02, fs:0.92891 (r=0.990,p=0.875),  time:38.636, tt:1236.348\n",
      "Ep:32, loss:0.00008, loss_test:0.05335, lr:1.00e-02, fs:0.93333 (r=0.990,p=0.883),  time:38.601, tt:1273.834\n",
      "Ep:33, loss:0.00008, loss_test:0.05022, lr:1.00e-02, fs:0.95050 (r=0.970,p=0.932),  time:38.592, tt:1312.121\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.05321, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:38.584, tt:1350.457\n",
      "Ep:35, loss:0.00007, loss_test:0.04848, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:38.549, tt:1387.758\n",
      "Ep:36, loss:0.00007, loss_test:0.04854, lr:1.00e-02, fs:0.93333 (r=0.990,p=0.883),  time:38.485, tt:1423.933\n",
      "Ep:37, loss:0.00006, loss_test:0.04679, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:38.441, tt:1460.752\n",
      "Ep:38, loss:0.00006, loss_test:0.04640, lr:1.00e-02, fs:0.96078 (r=0.990,p=0.933),  time:38.406, tt:1497.815\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.04642, lr:1.00e-02, fs:0.93780 (r=0.990,p=0.891),  time:38.362, tt:1534.480\n",
      "Ep:40, loss:0.00006, loss_test:0.04412, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:38.367, tt:1573.035\n",
      "Ep:41, loss:0.00005, loss_test:0.04354, lr:1.00e-02, fs:0.95567 (r=0.980,p=0.933),  time:38.379, tt:1611.920\n",
      "Ep:42, loss:0.00005, loss_test:0.04595, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:38.336, tt:1648.435\n",
      "Ep:43, loss:0.00005, loss_test:0.04294, lr:1.00e-02, fs:0.97487 (r=0.980,p=0.970),  time:38.301, tt:1685.237\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.04397, lr:1.00e-02, fs:0.93396 (r=1.000,p=0.876),  time:38.284, tt:1722.764\n",
      "Ep:45, loss:0.00005, loss_test:0.04358, lr:1.00e-02, fs:0.96970 (r=0.970,p=0.970),  time:38.344, tt:1763.839\n",
      "Ep:46, loss:0.00005, loss_test:0.04500, lr:1.00e-02, fs:0.94737 (r=1.000,p=0.900),  time:38.316, tt:1800.855\n",
      "Ep:47, loss:0.00004, loss_test:0.04459, lr:1.00e-02, fs:0.96000 (r=0.970,p=0.950),  time:38.244, tt:1835.689\n",
      "Ep:48, loss:0.00004, loss_test:0.04204, lr:1.00e-02, fs:0.95192 (r=1.000,p=0.908),  time:38.224, tt:1872.952\n",
      "Ep:49, loss:0.00004, loss_test:0.04214, lr:1.00e-02, fs:0.97487 (r=0.980,p=0.970),  time:38.178, tt:1908.914\n",
      "Ep:50, loss:0.00004, loss_test:0.04057, lr:1.00e-02, fs:0.96078 (r=0.990,p=0.933),  time:38.175, tt:1946.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00004, loss_test:0.04002, lr:1.00e-02, fs:0.97487 (r=0.980,p=0.970),  time:38.156, tt:1984.113\n",
      "Ep:52, loss:0.00004, loss_test:0.04139, lr:1.00e-02, fs:0.96970 (r=0.970,p=0.970),  time:38.118, tt:2020.268\n",
      "Ep:53, loss:0.00003, loss_test:0.04024, lr:1.00e-02, fs:0.98507 (r=1.000,p=0.971),  time:38.093, tt:2057.030\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.03759, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:38.107, tt:2095.868\n",
      "Ep:55, loss:0.00003, loss_test:0.04025, lr:1.00e-02, fs:0.97537 (r=1.000,p=0.952),  time:38.132, tt:2135.415\n",
      "Ep:56, loss:0.00003, loss_test:0.03658, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:38.163, tt:2175.318\n",
      "Ep:57, loss:0.00003, loss_test:0.04084, lr:1.00e-02, fs:0.95050 (r=0.970,p=0.932),  time:38.146, tt:2212.481\n",
      "Ep:58, loss:0.00003, loss_test:0.03838, lr:1.00e-02, fs:0.98990 (r=0.990,p=0.990),  time:38.132, tt:2249.799\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.03672, lr:1.00e-02, fs:0.97512 (r=0.990,p=0.961),  time:38.173, tt:2290.358\n",
      "Ep:60, loss:0.00002, loss_test:0.03946, lr:1.00e-02, fs:0.96970 (r=0.970,p=0.970),  time:38.156, tt:2327.497\n",
      "Ep:61, loss:0.00002, loss_test:0.03499, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:38.163, tt:2366.097\n",
      "Ep:62, loss:0.00002, loss_test:0.03754, lr:1.00e-02, fs:0.98492 (r=0.990,p=0.980),  time:38.158, tt:2403.948\n",
      "Ep:63, loss:0.00002, loss_test:0.03832, lr:1.00e-02, fs:0.98990 (r=0.990,p=0.990),  time:38.161, tt:2442.331\n",
      "Ep:64, loss:0.00002, loss_test:0.03807, lr:1.00e-02, fs:0.99000 (r=1.000,p=0.980),  time:38.154, tt:2480.010\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.03940, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:38.155, tt:2518.213\n",
      "Ep:66, loss:0.00002, loss_test:0.03531, lr:1.00e-02, fs:0.97030 (r=0.990,p=0.951),  time:38.167, tt:2557.209\n",
      "Ep:67, loss:0.00002, loss_test:0.04127, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:38.167, tt:2595.345\n",
      "Ep:68, loss:0.00002, loss_test:0.04244, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:38.117, tt:2630.040\n",
      "Ep:69, loss:0.00002, loss_test:0.03910, lr:1.00e-02, fs:0.95876 (r=0.939,p=0.979),  time:38.110, tt:2667.696\n",
      "Ep:70, loss:0.00002, loss_test:0.04075, lr:1.00e-02, fs:0.91304 (r=0.848,p=0.988),  time:38.102, tt:2705.243\n",
      "Ep:71, loss:0.00002, loss_test:0.03690, lr:1.00e-02, fs:0.97537 (r=1.000,p=0.952),  time:38.109, tt:2743.863\n",
      "Ep:72, loss:0.00002, loss_test:0.03733, lr:1.00e-02, fs:0.92473 (r=0.869,p=0.989),  time:38.133, tt:2783.735\n",
      "Ep:73, loss:0.00001, loss_test:0.03481, lr:1.00e-02, fs:0.98507 (r=1.000,p=0.971),  time:38.099, tt:2819.350\n",
      "Ep:74, loss:0.00001, loss_test:0.03739, lr:1.00e-02, fs:0.91979 (r=0.869,p=0.977),  time:38.112, tt:2858.393\n",
      "Ep:75, loss:0.00001, loss_test:0.03670, lr:1.00e-02, fs:0.95876 (r=0.939,p=0.979),  time:38.134, tt:2898.164\n",
      "Ep:76, loss:0.00001, loss_test:0.03678, lr:9.90e-03, fs:0.93122 (r=0.889,p=0.978),  time:38.147, tt:2937.342\n",
      "Ep:77, loss:0.00001, loss_test:0.03753, lr:9.80e-03, fs:0.93122 (r=0.889,p=0.978),  time:38.160, tt:2976.475\n",
      "Ep:78, loss:0.00001, loss_test:0.03628, lr:9.70e-03, fs:0.95876 (r=0.939,p=0.979),  time:38.144, tt:3013.409\n",
      "Ep:79, loss:0.00001, loss_test:0.03595, lr:9.61e-03, fs:0.93750 (r=0.909,p=0.968),  time:38.146, tt:3051.667\n",
      "Ep:80, loss:0.00001, loss_test:0.03722, lr:9.51e-03, fs:0.92473 (r=0.869,p=0.989),  time:38.155, tt:3090.567\n",
      "Ep:81, loss:0.00001, loss_test:0.03427, lr:9.41e-03, fs:0.99000 (r=1.000,p=0.980),  time:38.179, tt:3130.669\n",
      "Ep:82, loss:0.00001, loss_test:0.03630, lr:9.32e-03, fs:0.91979 (r=0.869,p=0.977),  time:38.172, tt:3168.244\n",
      "Ep:83, loss:0.00001, loss_test:0.03564, lr:9.23e-03, fs:0.91579 (r=0.879,p=0.956),  time:38.185, tt:3207.551\n",
      "Ep:84, loss:0.00001, loss_test:0.03553, lr:9.14e-03, fs:0.93122 (r=0.889,p=0.978),  time:38.198, tt:3246.838\n",
      "Ep:85, loss:0.00001, loss_test:0.03647, lr:9.04e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.239, tt:3288.595\n",
      "Ep:86, loss:0.00001, loss_test:0.03376, lr:8.95e-03, fs:0.97000 (r=0.980,p=0.960),  time:38.261, tt:3328.726\n",
      "Ep:87, loss:0.00001, loss_test:0.03772, lr:8.86e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.272, tt:3367.901\n",
      "Ep:88, loss:0.00001, loss_test:0.03536, lr:8.78e-03, fs:0.93048 (r=0.879,p=0.989),  time:38.272, tt:3406.236\n",
      "Ep:89, loss:0.00001, loss_test:0.03616, lr:8.69e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.270, tt:3444.336\n",
      "Ep:90, loss:0.00001, loss_test:0.03503, lr:8.60e-03, fs:0.93048 (r=0.879,p=0.989),  time:38.252, tt:3480.951\n",
      "Ep:91, loss:0.00000, loss_test:0.03581, lr:8.51e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.258, tt:3519.775\n",
      "Ep:92, loss:0.00000, loss_test:0.03494, lr:8.43e-03, fs:0.93048 (r=0.879,p=0.989),  time:38.265, tt:3558.626\n",
      "Ep:93, loss:0.00000, loss_test:0.03712, lr:8.35e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.232, tt:3593.829\n",
      "Ep:94, loss:0.00000, loss_test:0.03572, lr:8.26e-03, fs:0.93048 (r=0.879,p=0.989),  time:38.240, tt:3632.807\n",
      "Ep:95, loss:0.00000, loss_test:0.03534, lr:8.18e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.255, tt:3672.471\n",
      "Ep:96, loss:0.00000, loss_test:0.03724, lr:8.10e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.241, tt:3709.378\n",
      "Ep:97, loss:0.00000, loss_test:0.03704, lr:8.02e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.255, tt:3748.965\n",
      "Ep:98, loss:0.00000, loss_test:0.03620, lr:7.94e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.268, tt:3788.561\n",
      "Ep:99, loss:0.00000, loss_test:0.03741, lr:7.86e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.248, tt:3824.768\n",
      "Ep:100, loss:0.00000, loss_test:0.03582, lr:7.78e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.217, tt:3859.872\n",
      "Ep:101, loss:0.00000, loss_test:0.03651, lr:7.70e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.205, tt:3896.875\n",
      "Ep:102, loss:0.00000, loss_test:0.03558, lr:7.62e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.216, tt:3936.224\n",
      "Ep:103, loss:0.00000, loss_test:0.03763, lr:7.55e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.256, tt:3978.599\n",
      "Ep:104, loss:0.00000, loss_test:0.03654, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.243, tt:4015.557\n",
      "Ep:105, loss:0.00000, loss_test:0.03714, lr:7.40e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.237, tt:4053.125\n",
      "Ep:106, loss:0.00000, loss_test:0.03793, lr:7.32e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.226, tt:4090.207\n",
      "Ep:107, loss:0.00000, loss_test:0.03622, lr:7.25e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.239, tt:4129.818\n",
      "Ep:108, loss:0.00000, loss_test:0.03700, lr:7.18e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.225, tt:4166.550\n",
      "Ep:109, loss:0.00000, loss_test:0.03671, lr:7.11e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.215, tt:4203.624\n",
      "Ep:110, loss:0.00000, loss_test:0.03738, lr:7.03e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.211, tt:4241.368\n",
      "Ep:111, loss:0.00000, loss_test:0.03668, lr:6.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.221, tt:4280.719\n",
      "Ep:112, loss:0.00000, loss_test:0.03630, lr:6.89e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.229, tt:4319.857\n",
      "Ep:113, loss:0.00000, loss_test:0.03716, lr:6.83e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.234, tt:4358.645\n",
      "Ep:114, loss:0.00000, loss_test:0.03662, lr:6.76e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.209, tt:4394.003\n",
      "Ep:115, loss:0.00000, loss_test:0.03647, lr:6.69e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.192, tt:4430.323\n",
      "Ep:116, loss:0.00000, loss_test:0.03727, lr:6.62e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.196, tt:4468.906\n",
      "Ep:117, loss:0.00000, loss_test:0.03621, lr:6.56e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.194, tt:4506.873\n",
      "Ep:118, loss:0.00000, loss_test:0.03798, lr:6.49e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.187, tt:4544.280\n",
      "Ep:119, loss:0.00000, loss_test:0.03647, lr:6.43e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.209, tt:4585.098\n",
      "Ep:120, loss:0.00000, loss_test:0.03811, lr:6.36e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.205, tt:4622.801\n",
      "Ep:121, loss:0.00000, loss_test:0.03697, lr:6.30e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.217, tt:4662.464\n",
      "Ep:122, loss:0.00000, loss_test:0.03697, lr:6.24e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.212, tt:4700.055\n",
      "Ep:123, loss:0.00000, loss_test:0.03831, lr:6.17e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.201, tt:4736.932\n",
      "Ep:124, loss:0.00000, loss_test:0.03678, lr:6.11e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.209, tt:4776.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00000, loss_test:0.03772, lr:6.05e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.218, tt:4815.486\n",
      "Ep:126, loss:0.00000, loss_test:0.03718, lr:5.99e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.231, tt:4855.372\n",
      "Ep:127, loss:0.00000, loss_test:0.03737, lr:5.93e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.233, tt:4893.788\n",
      "Ep:128, loss:0.00000, loss_test:0.03809, lr:5.87e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.233, tt:4932.067\n",
      "Ep:129, loss:0.00000, loss_test:0.03713, lr:5.81e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.241, tt:4971.337\n",
      "Ep:130, loss:0.00000, loss_test:0.03818, lr:5.75e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.242, tt:5009.696\n",
      "Ep:131, loss:0.00000, loss_test:0.03734, lr:5.70e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.239, tt:5047.597\n",
      "Ep:132, loss:0.00000, loss_test:0.03848, lr:5.64e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.241, tt:5086.076\n",
      "Ep:133, loss:0.00000, loss_test:0.03746, lr:5.58e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.234, tt:5123.331\n",
      "Ep:134, loss:0.00000, loss_test:0.03840, lr:5.53e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.222, tt:5159.982\n",
      "Ep:135, loss:0.00000, loss_test:0.03878, lr:5.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.200, tt:5195.134\n",
      "Ep:136, loss:0.00000, loss_test:0.03793, lr:5.42e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.189, tt:5231.838\n",
      "Ep:137, loss:0.00000, loss_test:0.03714, lr:5.36e-03, fs:0.92063 (r=0.879,p=0.967),  time:38.166, tt:5266.936\n",
      "Ep:138, loss:0.00000, loss_test:0.03783, lr:5.31e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.159, tt:5304.075\n",
      "Ep:139, loss:0.00000, loss_test:0.03753, lr:5.26e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.152, tt:5341.235\n",
      "Ep:140, loss:0.00000, loss_test:0.03783, lr:5.20e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.151, tt:5379.238\n",
      "Ep:141, loss:0.00000, loss_test:0.03812, lr:5.15e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.143, tt:5416.265\n",
      "Ep:142, loss:0.00000, loss_test:0.03709, lr:5.10e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.129, tt:5452.440\n",
      "Ep:143, loss:0.00000, loss_test:0.03716, lr:5.05e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.130, tt:5490.755\n",
      "Ep:144, loss:0.00000, loss_test:0.03775, lr:5.00e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.120, tt:5527.470\n",
      "Ep:145, loss:0.00000, loss_test:0.03667, lr:4.95e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.105, tt:5563.310\n",
      "Ep:146, loss:0.00000, loss_test:0.03728, lr:4.90e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.101, tt:5600.784\n",
      "Ep:147, loss:0.00000, loss_test:0.03774, lr:4.85e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.095, tt:5638.064\n",
      "Ep:148, loss:0.00000, loss_test:0.03713, lr:4.80e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.090, tt:5675.371\n",
      "Ep:149, loss:0.00000, loss_test:0.03731, lr:4.75e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.084, tt:5712.666\n",
      "Ep:150, loss:0.00000, loss_test:0.03732, lr:4.71e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.077, tt:5749.597\n",
      "Ep:151, loss:0.00000, loss_test:0.03771, lr:4.66e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.076, tt:5787.620\n",
      "Ep:152, loss:0.00000, loss_test:0.03714, lr:4.61e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.073, tt:5825.127\n",
      "Ep:153, loss:0.00000, loss_test:0.03697, lr:4.57e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.077, tt:5863.906\n",
      "Ep:154, loss:0.00000, loss_test:0.03714, lr:4.52e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.075, tt:5901.653\n",
      "Ep:155, loss:0.00000, loss_test:0.03745, lr:4.48e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.069, tt:5938.824\n",
      "Ep:156, loss:0.00000, loss_test:0.03689, lr:4.43e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.066, tt:5976.392\n",
      "Ep:157, loss:0.00000, loss_test:0.03754, lr:4.39e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.060, tt:6013.422\n",
      "Ep:158, loss:0.00000, loss_test:0.03743, lr:4.34e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.053, tt:6050.405\n",
      "Ep:159, loss:0.00000, loss_test:0.03673, lr:4.30e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.043, tt:6086.826\n",
      "Ep:160, loss:0.00000, loss_test:0.03734, lr:4.26e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.049, tt:6125.881\n",
      "Ep:161, loss:0.00000, loss_test:0.03712, lr:4.21e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.045, tt:6163.308\n",
      "Ep:162, loss:0.00000, loss_test:0.03676, lr:4.17e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.030, tt:6198.897\n",
      "Ep:163, loss:0.00000, loss_test:0.03726, lr:4.13e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.030, tt:6236.892\n",
      "Ep:164, loss:0.00000, loss_test:0.03690, lr:4.09e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.029, tt:6274.810\n",
      "Ep:165, loss:0.00000, loss_test:0.03649, lr:4.05e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.026, tt:6312.394\n",
      "Ep:166, loss:0.00000, loss_test:0.03697, lr:4.01e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.022, tt:6349.605\n",
      "Ep:167, loss:0.00000, loss_test:0.03723, lr:3.97e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.025, tt:6388.167\n",
      "Ep:168, loss:0.00000, loss_test:0.03664, lr:3.93e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.026, tt:6426.341\n",
      "Ep:169, loss:0.00000, loss_test:0.03735, lr:3.89e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.013, tt:6462.217\n",
      "Ep:170, loss:0.00000, loss_test:0.03725, lr:3.85e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.010, tt:6499.763\n",
      "Ep:171, loss:0.00000, loss_test:0.03663, lr:3.81e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.009, tt:6537.599\n",
      "Ep:172, loss:0.00000, loss_test:0.03658, lr:3.77e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.003, tt:6574.504\n",
      "Ep:173, loss:0.00000, loss_test:0.03718, lr:3.73e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.001, tt:6612.195\n",
      "Ep:174, loss:0.00000, loss_test:0.03703, lr:3.70e-03, fs:0.92553 (r=0.879,p=0.978),  time:38.005, tt:6650.897\n",
      "Ep:175, loss:0.00000, loss_test:0.03665, lr:3.66e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.992, tt:6686.551\n",
      "Ep:176, loss:0.00000, loss_test:0.03672, lr:3.62e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.984, tt:6723.118\n",
      "Ep:177, loss:0.00000, loss_test:0.03654, lr:3.59e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.986, tt:6761.526\n",
      "Ep:178, loss:0.00000, loss_test:0.03649, lr:3.55e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.973, tt:6797.146\n",
      "Ep:179, loss:0.00000, loss_test:0.03669, lr:3.52e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.974, tt:6835.401\n",
      "Ep:180, loss:0.00000, loss_test:0.03643, lr:3.48e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.964, tt:6871.556\n",
      "Ep:181, loss:0.00000, loss_test:0.03629, lr:3.45e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.959, tt:6908.586\n",
      "Ep:182, loss:0.00000, loss_test:0.03645, lr:3.41e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.959, tt:6946.413\n",
      "Ep:183, loss:0.00000, loss_test:0.03673, lr:3.38e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.954, tt:6983.624\n",
      "Ep:184, loss:0.00000, loss_test:0.03658, lr:3.34e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.951, tt:7020.904\n",
      "Ep:185, loss:0.00000, loss_test:0.03665, lr:3.31e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.947, tt:7058.187\n",
      "Ep:186, loss:0.00000, loss_test:0.03647, lr:3.28e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.951, tt:7096.919\n",
      "Ep:187, loss:0.00000, loss_test:0.03619, lr:3.24e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.948, tt:7134.289\n",
      "Ep:188, loss:0.00000, loss_test:0.03701, lr:3.21e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.943, tt:7171.164\n",
      "Ep:189, loss:0.00000, loss_test:0.03750, lr:3.18e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.943, tt:7209.140\n",
      "Ep:190, loss:0.00000, loss_test:0.03684, lr:3.15e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.943, tt:7247.075\n",
      "Ep:191, loss:0.00000, loss_test:0.03629, lr:3.12e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.947, tt:7285.804\n",
      "Ep:192, loss:0.00000, loss_test:0.03639, lr:3.09e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.945, tt:7323.479\n",
      "Ep:193, loss:0.00000, loss_test:0.03667, lr:3.05e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.947, tt:7361.746\n",
      "Ep:194, loss:0.00000, loss_test:0.03638, lr:3.02e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.940, tt:7398.352\n",
      "Ep:195, loss:0.00000, loss_test:0.03614, lr:2.99e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.932, tt:7434.751\n",
      "Ep:196, loss:0.00000, loss_test:0.03670, lr:2.96e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.921, tt:7470.530\n",
      "Ep:197, loss:0.00000, loss_test:0.03663, lr:2.93e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.924, tt:7509.004\n",
      "Ep:198, loss:0.00000, loss_test:0.03624, lr:2.90e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.923, tt:7546.775\n",
      "Ep:199, loss:0.00000, loss_test:0.03608, lr:2.88e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.916, tt:7583.193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00000, loss_test:0.03644, lr:2.85e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.912, tt:7620.269\n",
      "Ep:201, loss:0.00000, loss_test:0.03678, lr:2.82e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.906, tt:7657.035\n",
      "Ep:202, loss:0.00000, loss_test:0.03633, lr:2.79e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.906, tt:7694.998\n",
      "Ep:203, loss:0.00000, loss_test:0.03603, lr:2.76e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.903, tt:7732.243\n",
      "Ep:204, loss:0.00000, loss_test:0.03629, lr:2.73e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.879, tt:7765.093\n",
      "Ep:205, loss:0.00000, loss_test:0.03643, lr:2.71e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.764, tt:7779.434\n",
      "Ep:206, loss:0.00000, loss_test:0.03631, lr:2.68e-03, fs:0.92553 (r=0.879,p=0.978),  time:37.650, tt:7793.602\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00081, loss_test:0.02142, lr:1.00e-02, fs:0.67544 (r=0.885,p=0.546),  time:654.687, tt:654.687\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.02047, lr:1.00e-02, fs:0.66667 (r=0.759,p=0.595),  time:660.412, tt:1320.825\n",
      "Ep:2, loss:0.00052, loss_test:0.02001, lr:1.00e-02, fs:0.70103 (r=0.782,p=0.636),  time:663.438, tt:1990.315\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.02021, lr:1.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:662.666, tt:2650.662\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01993, lr:1.00e-02, fs:0.72340 (r=0.782,p=0.673),  time:661.622, tt:3308.112\n",
      "Ep:5, loss:0.00036, loss_test:0.02010, lr:1.00e-02, fs:0.74725 (r=0.782,p=0.716),  time:660.515, tt:3963.092\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.02014, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:658.321, tt:4608.247\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.02018, lr:1.00e-02, fs:0.75281 (r=0.770,p=0.736),  time:657.761, tt:5262.092\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.02042, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:656.446, tt:5908.015\n",
      "Ep:9, loss:0.00024, loss_test:0.02044, lr:1.00e-02, fs:0.74286 (r=0.747,p=0.739),  time:657.237, tt:6572.374\n",
      "Ep:10, loss:0.00022, loss_test:0.02061, lr:1.00e-02, fs:0.75429 (r=0.759,p=0.750),  time:656.463, tt:7221.091\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.02081, lr:1.00e-02, fs:0.74419 (r=0.736,p=0.753),  time:655.841, tt:7870.088\n",
      "Ep:12, loss:0.00018, loss_test:0.02101, lr:1.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:656.301, tt:8531.912\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.02159, lr:1.00e-02, fs:0.75776 (r=0.701,p=0.824),  time:656.442, tt:9190.182\n",
      "Ep:14, loss:0.00016, loss_test:0.02190, lr:1.00e-02, fs:0.75472 (r=0.690,p=0.833),  time:655.949, tt:9839.233\n",
      "Ep:15, loss:0.00014, loss_test:0.02191, lr:1.00e-02, fs:0.76433 (r=0.690,p=0.857),  time:655.592, tt:10489.467\n",
      "Ep:16, loss:0.00013, loss_test:0.02249, lr:1.00e-02, fs:0.76923 (r=0.690,p=0.870),  time:655.323, tt:11140.491\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00012, loss_test:0.02258, lr:1.00e-02, fs:0.76623 (r=0.678,p=0.881),  time:655.726, tt:11803.070\n",
      "Ep:18, loss:0.00012, loss_test:0.02313, lr:1.00e-02, fs:0.76623 (r=0.678,p=0.881),  time:655.810, tt:12460.393\n",
      "Ep:19, loss:0.00011, loss_test:0.02354, lr:1.00e-02, fs:0.76623 (r=0.678,p=0.881),  time:655.464, tt:13109.279\n",
      "Ep:20, loss:0.00010, loss_test:0.02397, lr:1.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:655.116, tt:13757.430\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00009, loss_test:0.02433, lr:1.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:654.873, tt:14407.208\n",
      "Ep:22, loss:0.00009, loss_test:0.02485, lr:1.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:655.048, tt:15066.108\n",
      "Ep:23, loss:0.00008, loss_test:0.02527, lr:1.00e-02, fs:0.78667 (r=0.678,p=0.937),  time:655.915, tt:15741.962\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00008, loss_test:0.02556, lr:1.00e-02, fs:0.79195 (r=0.678,p=0.952),  time:655.654, tt:16391.341\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.02616, lr:1.00e-02, fs:0.79195 (r=0.678,p=0.952),  time:655.699, tt:17048.165\n",
      "Ep:26, loss:0.00007, loss_test:0.02675, lr:1.00e-02, fs:0.78378 (r=0.667,p=0.951),  time:654.026, tt:17658.712\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00080, loss_test:0.02221, lr:1.00e-02, fs:0.68670 (r=0.920,p=0.548),  time:624.022, tt:624.022\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.02068, lr:1.00e-02, fs:0.66977 (r=0.828,p=0.562),  time:632.056, tt:1264.112\n",
      "Ep:2, loss:0.00055, loss_test:0.02006, lr:1.00e-02, fs:0.70192 (r=0.839,p=0.603),  time:640.004, tt:1920.012\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00049, loss_test:0.01992, lr:1.00e-02, fs:0.71357 (r=0.816,p=0.634),  time:642.774, tt:2571.098\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00043, loss_test:0.01998, lr:1.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:644.732, tt:3223.659\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00039, loss_test:0.01998, lr:1.00e-02, fs:0.71658 (r=0.770,p=0.670),  time:645.519, tt:3873.112\n",
      "Ep:6, loss:0.00035, loss_test:0.02008, lr:1.00e-02, fs:0.72043 (r=0.770,p=0.677),  time:645.932, tt:4521.524\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.02027, lr:1.00e-02, fs:0.74317 (r=0.782,p=0.708),  time:647.449, tt:5179.595\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.02043, lr:1.00e-02, fs:0.75138 (r=0.782,p=0.723),  time:649.862, tt:5848.755\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.02111, lr:1.00e-02, fs:0.76404 (r=0.782,p=0.747),  time:651.381, tt:6513.806\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.02093, lr:1.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:651.990, tt:7171.886\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.02162, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:652.593, tt:7831.117\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.02227, lr:1.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:653.119, tt:8490.548\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.02245, lr:1.00e-02, fs:0.81657 (r=0.793,p=0.841),  time:653.601, tt:9150.418\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.02299, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:653.871, tt:9808.063\n",
      "Ep:15, loss:0.00016, loss_test:0.02327, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:654.854, tt:10477.663\n",
      "Ep:16, loss:0.00015, loss_test:0.02369, lr:1.00e-02, fs:0.75325 (r=0.667,p=0.866),  time:654.584, tt:11127.931\n",
      "Ep:17, loss:0.00014, loss_test:0.02435, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.468, tt:11780.433\n",
      "Ep:18, loss:0.00013, loss_test:0.02475, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.208, tt:12429.959\n",
      "Ep:19, loss:0.00012, loss_test:0.02540, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.288, tt:13085.761\n",
      "Ep:20, loss:0.00011, loss_test:0.02593, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.318, tt:13740.672\n",
      "Ep:21, loss:0.00010, loss_test:0.02665, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.793, tt:14405.451\n",
      "Ep:22, loss:0.00010, loss_test:0.02738, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.895, tt:15062.590\n",
      "Ep:23, loss:0.00009, loss_test:0.02801, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:655.009, tt:15720.214\n",
      "Ep:24, loss:0.00009, loss_test:0.02846, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:654.425, tt:16360.617\n",
      "Ep:25, loss:0.00008, loss_test:0.02922, lr:9.90e-03, fs:0.72973 (r=0.621,p=0.885),  time:654.419, tt:17014.896\n",
      "Ep:26, loss:0.00008, loss_test:0.02969, lr:9.80e-03, fs:0.74483 (r=0.621,p=0.931),  time:654.283, tt:17665.643\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.02109, lr:1.00e-02, fs:0.64935 (r=0.862,p=0.521),  time:682.928, tt:682.928\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.02096, lr:1.00e-02, fs:0.66038 (r=0.805,p=0.560),  time:674.733, tt:1349.467\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.02111, lr:1.00e-02, fs:0.67961 (r=0.805,p=0.588),  time:676.547, tt:2029.640\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.02085, lr:1.00e-02, fs:0.67317 (r=0.793,p=0.585),  time:675.678, tt:2702.712\n",
      "Ep:4, loss:0.00047, loss_test:0.02085, lr:1.00e-02, fs:0.66667 (r=0.759,p=0.595),  time:675.413, tt:3377.064\n",
      "Ep:5, loss:0.00044, loss_test:0.02072, lr:1.00e-02, fs:0.68041 (r=0.759,p=0.617),  time:676.310, tt:4057.862\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.02062, lr:1.00e-02, fs:0.66667 (r=0.724,p=0.618),  time:675.654, tt:4729.575\n",
      "Ep:7, loss:0.00039, loss_test:0.02068, lr:1.00e-02, fs:0.65946 (r=0.701,p=0.622),  time:675.487, tt:5403.899\n",
      "Ep:8, loss:0.00037, loss_test:0.02079, lr:1.00e-02, fs:0.67391 (r=0.713,p=0.639),  time:675.444, tt:6078.998\n",
      "Ep:9, loss:0.00035, loss_test:0.02084, lr:1.00e-02, fs:0.67391 (r=0.713,p=0.639),  time:675.568, tt:6755.685\n",
      "Ep:10, loss:0.00033, loss_test:0.02089, lr:1.00e-02, fs:0.68132 (r=0.713,p=0.653),  time:675.435, tt:7429.787\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.02115, lr:1.00e-02, fs:0.67416 (r=0.690,p=0.659),  time:675.873, tt:8110.480\n",
      "Ep:12, loss:0.00030, loss_test:0.02132, lr:1.00e-02, fs:0.69714 (r=0.701,p=0.693),  time:676.496, tt:8794.442\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.02151, lr:1.00e-02, fs:0.69364 (r=0.690,p=0.698),  time:676.215, tt:9467.006\n",
      "Ep:14, loss:0.00027, loss_test:0.02179, lr:1.00e-02, fs:0.67456 (r=0.655,p=0.695),  time:676.460, tt:10146.901\n",
      "Ep:15, loss:0.00026, loss_test:0.02209, lr:1.00e-02, fs:0.67879 (r=0.644,p=0.718),  time:676.490, tt:10823.843\n",
      "Ep:16, loss:0.00025, loss_test:0.02238, lr:1.00e-02, fs:0.67485 (r=0.632,p=0.724),  time:676.674, tt:11503.450\n",
      "Ep:17, loss:0.00024, loss_test:0.02280, lr:1.00e-02, fs:0.65839 (r=0.609,p=0.716),  time:676.551, tt:12177.909\n",
      "Ep:18, loss:0.00023, loss_test:0.02283, lr:1.00e-02, fs:0.66667 (r=0.609,p=0.736),  time:676.776, tt:12858.735\n",
      "Ep:19, loss:0.00022, loss_test:0.02304, lr:1.00e-02, fs:0.67516 (r=0.609,p=0.757),  time:676.874, tt:13537.472\n",
      "Ep:20, loss:0.00021, loss_test:0.02344, lr:1.00e-02, fs:0.66667 (r=0.586,p=0.773),  time:676.968, tt:14216.334\n",
      "Ep:21, loss:0.00020, loss_test:0.02359, lr:1.00e-02, fs:0.67974 (r=0.598,p=0.788),  time:677.146, tt:14897.219\n",
      "Ep:22, loss:0.00019, loss_test:0.02384, lr:1.00e-02, fs:0.67105 (r=0.586,p=0.785),  time:676.889, tt:15568.449\n",
      "Ep:23, loss:0.00018, loss_test:0.02444, lr:1.00e-02, fs:0.63514 (r=0.540,p=0.770),  time:677.455, tt:16258.915\n",
      "Ep:24, loss:0.00018, loss_test:0.02446, lr:9.90e-03, fs:0.63514 (r=0.540,p=0.770),  time:677.341, tt:16933.532\n",
      "Ep:25, loss:0.00017, loss_test:0.02489, lr:9.80e-03, fs:0.61644 (r=0.517,p=0.763),  time:677.636, tt:17618.529\n",
      "Ep:26, loss:0.00016, loss_test:0.02527, lr:9.70e-03, fs:0.62069 (r=0.517,p=0.776),  time:677.766, tt:18299.672\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.02058, lr:1.00e-02, fs:0.66129 (r=0.943,p=0.509),  time:666.692, tt:666.692\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00062, loss_test:0.02060, lr:1.00e-02, fs:0.65728 (r=0.805,p=0.556),  time:667.999, tt:1335.997\n",
      "Ep:2, loss:0.00057, loss_test:0.02047, lr:1.00e-02, fs:0.65385 (r=0.782,p=0.562),  time:668.119, tt:2004.356\n",
      "Ep:3, loss:0.00054, loss_test:0.02038, lr:1.00e-02, fs:0.66995 (r=0.782,p=0.586),  time:671.403, tt:2685.610\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00052, loss_test:0.02030, lr:1.00e-02, fs:0.67327 (r=0.782,p=0.591),  time:673.483, tt:3367.416\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00050, loss_test:0.02022, lr:1.00e-02, fs:0.68317 (r=0.793,p=0.600),  time:674.147, tt:4044.880\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00048, loss_test:0.02015, lr:1.00e-02, fs:0.68020 (r=0.770,p=0.609),  time:675.653, tt:4729.572\n",
      "Ep:7, loss:0.00046, loss_test:0.02012, lr:1.00e-02, fs:0.68718 (r=0.770,p=0.620),  time:678.163, tt:5425.307\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00044, loss_test:0.02000, lr:1.00e-02, fs:0.69430 (r=0.770,p=0.632),  time:682.922, tt:6146.300\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00042, loss_test:0.02010, lr:1.00e-02, fs:0.68421 (r=0.747,p=0.631),  time:684.029, tt:6840.293\n",
      "Ep:10, loss:0.00041, loss_test:0.02015, lr:1.00e-02, fs:0.68783 (r=0.747,p=0.637),  time:684.422, tt:7528.640\n",
      "Ep:11, loss:0.00039, loss_test:0.02011, lr:1.00e-02, fs:0.68783 (r=0.747,p=0.637),  time:684.424, tt:8213.084\n",
      "Ep:12, loss:0.00038, loss_test:0.02014, lr:1.00e-02, fs:0.69149 (r=0.747,p=0.644),  time:684.717, tt:8901.323\n",
      "Ep:13, loss:0.00037, loss_test:0.02015, lr:1.00e-02, fs:0.69892 (r=0.747,p=0.657),  time:685.814, tt:9601.391\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00035, loss_test:0.02020, lr:1.00e-02, fs:0.71038 (r=0.747,p=0.677),  time:686.343, tt:10295.138\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00034, loss_test:0.02027, lr:1.00e-02, fs:0.70330 (r=0.736,p=0.674),  time:686.220, tt:10979.515\n",
      "Ep:16, loss:0.00033, loss_test:0.02029, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:686.202, tt:11665.436\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00032, loss_test:0.02036, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:686.053, tt:12348.959\n",
      "Ep:18, loss:0.00031, loss_test:0.02049, lr:1.00e-02, fs:0.70787 (r=0.724,p=0.692),  time:685.830, tt:13030.778\n",
      "Ep:19, loss:0.00030, loss_test:0.02051, lr:1.00e-02, fs:0.70056 (r=0.713,p=0.689),  time:686.102, tt:13722.037\n",
      "Ep:20, loss:0.00029, loss_test:0.02066, lr:1.00e-02, fs:0.71264 (r=0.713,p=0.713),  time:686.041, tt:14406.851\n",
      "Ep:21, loss:0.00028, loss_test:0.02076, lr:1.00e-02, fs:0.71264 (r=0.713,p=0.713),  time:685.790, tt:15087.383\n",
      "Ep:22, loss:0.00027, loss_test:0.02092, lr:1.00e-02, fs:0.71345 (r=0.701,p=0.726),  time:685.836, tt:15774.226\n",
      "Ep:23, loss:0.00026, loss_test:0.02100, lr:1.00e-02, fs:0.69822 (r=0.678,p=0.720),  time:685.841, tt:16460.174\n",
      "Ep:24, loss:0.00025, loss_test:0.02121, lr:1.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:685.813, tt:17145.333\n",
      "Ep:25, loss:0.00025, loss_test:0.02128, lr:1.00e-02, fs:0.70303 (r=0.667,p=0.744),  time:686.140, tt:17839.638\n",
      "Ep:26, loss:0.00024, loss_test:0.02139, lr:1.00e-02, fs:0.69939 (r=0.655,p=0.750),  time:686.244, tt:18528.583\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.02071, lr:1.00e-02, fs:0.65801 (r=0.874,p=0.528),  time:554.684, tt:554.684\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.02020, lr:1.00e-02, fs:0.66047 (r=0.816,p=0.555),  time:561.612, tt:1123.224\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.02002, lr:1.00e-02, fs:0.68246 (r=0.828,p=0.581),  time:561.238, tt:1683.715\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01991, lr:1.00e-02, fs:0.68599 (r=0.816,p=0.592),  time:562.842, tt:2251.369\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00046, loss_test:0.01989, lr:1.00e-02, fs:0.69347 (r=0.793,p=0.616),  time:570.336, tt:2851.678\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.01991, lr:1.00e-02, fs:0.68367 (r=0.770,p=0.615),  time:572.036, tt:3432.215\n",
      "Ep:6, loss:0.00041, loss_test:0.01982, lr:1.00e-02, fs:0.69792 (r=0.770,p=0.638),  time:573.405, tt:4013.835\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.01994, lr:1.00e-02, fs:0.70157 (r=0.770,p=0.644),  time:573.578, tt:4588.621\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.01985, lr:1.00e-02, fs:0.71277 (r=0.770,p=0.663),  time:574.210, tt:5167.894\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.01990, lr:1.00e-02, fs:0.72727 (r=0.782,p=0.680),  time:574.247, tt:5742.474\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01988, lr:1.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:574.512, tt:6319.627\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.02015, lr:1.00e-02, fs:0.73913 (r=0.782,p=0.701),  time:575.152, tt:6901.829\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.02025, lr:1.00e-02, fs:0.74595 (r=0.793,p=0.704),  time:575.735, tt:7484.551\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.02047, lr:1.00e-02, fs:0.75000 (r=0.793,p=0.711),  time:576.146, tt:8066.043\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.02063, lr:1.00e-02, fs:0.76243 (r=0.793,p=0.734),  time:575.783, tt:8636.748\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.02071, lr:1.00e-02, fs:0.76667 (r=0.793,p=0.742),  time:576.382, tt:9222.105\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.02092, lr:1.00e-02, fs:0.77966 (r=0.793,p=0.767),  time:576.850, tt:9806.446\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.02104, lr:1.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:577.043, tt:10386.767\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.02114, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:577.353, tt:10969.714\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.02128, lr:1.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:577.375, tt:11547.491\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.02139, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:577.240, tt:12122.043\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.02161, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:577.558, tt:12706.283\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.02187, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:577.848, tt:13290.504\n",
      "Ep:23, loss:0.00018, loss_test:0.02179, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:577.471, tt:13859.315\n",
      "Ep:24, loss:0.00017, loss_test:0.02195, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:577.353, tt:14433.819\n",
      "Ep:25, loss:0.00017, loss_test:0.02209, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:577.032, tt:15002.842\n",
      "Ep:26, loss:0.00016, loss_test:0.02235, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:577.189, tt:15584.112\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.02525, lr:1.00e-02, fs:0.66949 (r=0.908,p=0.530),  time:595.536, tt:595.536\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00071, loss_test:0.02280, lr:1.00e-02, fs:0.64220 (r=0.805,p=0.534),  time:585.983, tt:1171.966\n",
      "Ep:2, loss:0.00060, loss_test:0.02198, lr:1.00e-02, fs:0.65385 (r=0.782,p=0.562),  time:582.634, tt:1747.903\n",
      "Ep:3, loss:0.00053, loss_test:0.02200, lr:1.00e-02, fs:0.66010 (r=0.770,p=0.578),  time:580.856, tt:2323.424\n",
      "Ep:4, loss:0.00047, loss_test:0.02201, lr:1.00e-02, fs:0.66667 (r=0.736,p=0.610),  time:580.906, tt:2904.530\n",
      "Ep:5, loss:0.00041, loss_test:0.02229, lr:1.00e-02, fs:0.64865 (r=0.690,p=0.612),  time:581.813, tt:3490.876\n",
      "Ep:6, loss:0.00036, loss_test:0.02186, lr:1.00e-02, fs:0.67039 (r=0.690,p=0.652),  time:582.604, tt:4078.228\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.02256, lr:1.00e-02, fs:0.66667 (r=0.644,p=0.691),  time:583.505, tt:4668.038\n",
      "Ep:8, loss:0.00027, loss_test:0.02300, lr:1.00e-02, fs:0.65854 (r=0.621,p=0.701),  time:584.237, tt:5258.133\n",
      "Ep:9, loss:0.00023, loss_test:0.02375, lr:1.00e-02, fs:0.66667 (r=0.598,p=0.754),  time:584.273, tt:5842.726\n",
      "Ep:10, loss:0.00020, loss_test:0.02452, lr:1.00e-02, fs:0.64474 (r=0.563,p=0.754),  time:584.012, tt:6424.134\n",
      "Ep:11, loss:0.00017, loss_test:0.02547, lr:1.00e-02, fs:0.65333 (r=0.563,p=0.778),  time:584.254, tt:7011.048\n",
      "Ep:12, loss:0.00015, loss_test:0.02555, lr:1.00e-02, fs:0.67586 (r=0.563,p=0.845),  time:584.044, tt:7592.573\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00013, loss_test:0.02685, lr:1.00e-02, fs:0.69014 (r=0.563,p=0.891),  time:584.649, tt:8185.091\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00012, loss_test:0.02789, lr:1.00e-02, fs:0.69504 (r=0.563,p=0.907),  time:584.615, tt:8769.223\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00011, loss_test:0.02898, lr:1.00e-02, fs:0.69504 (r=0.563,p=0.907),  time:584.751, tt:9356.016\n",
      "Ep:16, loss:0.00010, loss_test:0.02970, lr:1.00e-02, fs:0.69504 (r=0.563,p=0.907),  time:584.527, tt:9936.959\n",
      "Ep:17, loss:0.00009, loss_test:0.03143, lr:1.00e-02, fs:0.69504 (r=0.563,p=0.907),  time:584.585, tt:10522.538\n",
      "Ep:18, loss:0.00008, loss_test:0.03266, lr:1.00e-02, fs:0.70000 (r=0.563,p=0.925),  time:584.523, tt:11105.946\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00007, loss_test:0.03346, lr:1.00e-02, fs:0.70000 (r=0.563,p=0.925),  time:584.440, tt:11688.799\n",
      "Ep:20, loss:0.00007, loss_test:0.03519, lr:1.00e-02, fs:0.70000 (r=0.563,p=0.925),  time:584.026, tt:12264.547\n",
      "Ep:21, loss:0.00006, loss_test:0.03569, lr:1.00e-02, fs:0.70000 (r=0.563,p=0.925),  time:584.009, tt:12848.194\n",
      "Ep:22, loss:0.00006, loss_test:0.03712, lr:1.00e-02, fs:0.70000 (r=0.563,p=0.925),  time:584.424, tt:13441.758\n",
      "Ep:23, loss:0.00005, loss_test:0.03815, lr:1.00e-02, fs:0.70000 (r=0.563,p=0.925),  time:582.981, tt:13991.541\n",
      "Ep:24, loss:0.00005, loss_test:0.03900, lr:1.00e-02, fs:0.70504 (r=0.563,p=0.942),  time:579.415, tt:14485.385\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.03981, lr:1.00e-02, fs:0.70504 (r=0.563,p=0.942),  time:573.979, tt:14923.454\n",
      "Ep:26, loss:0.00004, loss_test:0.04053, lr:1.00e-02, fs:0.69565 (r=0.552,p=0.941),  time:568.997, tt:15362.919\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00068, loss_test:0.02064, lr:1.00e-02, fs:0.66029 (r=0.793,p=0.566),  time:691.561, tt:691.561\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.01984, lr:1.00e-02, fs:0.70297 (r=0.816,p=0.617),  time:669.080, tt:1338.161\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00047, loss_test:0.01942, lr:1.00e-02, fs:0.70051 (r=0.793,p=0.627),  time:663.170, tt:1989.509\n",
      "Ep:3, loss:0.00043, loss_test:0.01940, lr:1.00e-02, fs:0.69792 (r=0.770,p=0.638),  time:661.342, tt:2645.369\n",
      "Ep:4, loss:0.00039, loss_test:0.01937, lr:1.00e-02, fs:0.70968 (r=0.759,p=0.667),  time:659.477, tt:3297.383\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.01935, lr:1.00e-02, fs:0.71186 (r=0.724,p=0.700),  time:658.388, tt:3950.330\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.01941, lr:1.00e-02, fs:0.72093 (r=0.713,p=0.729),  time:657.480, tt:4602.362\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.01952, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:656.078, tt:5248.625\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.01981, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:655.758, tt:5901.823\n",
      "Ep:9, loss:0.00026, loss_test:0.01985, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:657.892, tt:6578.925\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.02031, lr:1.00e-02, fs:0.73810 (r=0.713,p=0.765),  time:664.112, tt:7305.229\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.02025, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:670.009, tt:8040.102\n",
      "Ep:12, loss:0.00021, loss_test:0.02065, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:675.357, tt:8779.647\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.02098, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:679.152, tt:9508.133\n",
      "Ep:14, loss:0.00018, loss_test:0.02119, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:682.587, tt:10238.808\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.02130, lr:1.00e-02, fs:0.76250 (r=0.701,p=0.836),  time:685.445, tt:10967.125\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.02175, lr:1.00e-02, fs:0.73548 (r=0.655,p=0.838),  time:687.968, tt:11695.448\n",
      "Ep:17, loss:0.00015, loss_test:0.02197, lr:1.00e-02, fs:0.69799 (r=0.598,p=0.839),  time:690.114, tt:12422.056\n",
      "Ep:18, loss:0.00014, loss_test:0.02231, lr:1.00e-02, fs:0.68493 (r=0.575,p=0.847),  time:692.463, tt:13156.794\n",
      "Ep:19, loss:0.00013, loss_test:0.02241, lr:1.00e-02, fs:0.65734 (r=0.540,p=0.839),  time:694.477, tt:13889.543\n",
      "Ep:20, loss:0.00013, loss_test:0.02304, lr:1.00e-02, fs:0.64748 (r=0.517,p=0.865),  time:696.257, tt:14621.387\n",
      "Ep:21, loss:0.00012, loss_test:0.02324, lr:1.00e-02, fs:0.66187 (r=0.529,p=0.885),  time:697.815, tt:15351.935\n",
      "Ep:22, loss:0.00011, loss_test:0.02350, lr:1.00e-02, fs:0.66187 (r=0.529,p=0.885),  time:699.471, tt:16087.822\n",
      "Ep:23, loss:0.00011, loss_test:0.02375, lr:1.00e-02, fs:0.65217 (r=0.517,p=0.882),  time:700.726, tt:16817.417\n",
      "Ep:24, loss:0.00010, loss_test:0.02414, lr:1.00e-02, fs:0.64706 (r=0.506,p=0.898),  time:701.735, tt:17543.368\n",
      "Ep:25, loss:0.00010, loss_test:0.02444, lr:1.00e-02, fs:0.64706 (r=0.506,p=0.898),  time:703.108, tt:18280.819\n",
      "Ep:26, loss:0.00009, loss_test:0.02465, lr:1.00e-02, fs:0.64706 (r=0.506,p=0.898),  time:704.144, tt:19011.893\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14534, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.107, tt:48.107\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14433, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.137, tt:96.274\n",
      "Ep:2, loss:0.00001, loss_test:0.14243, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.229, tt:144.686\n",
      "Ep:3, loss:0.00001, loss_test:0.13878, lr:1.00e-02, fs:0.66929 (r=0.977,p=0.509),  time:48.806, tt:195.225\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.13279, lr:1.00e-02, fs:0.68376 (r=0.920,p=0.544),  time:48.690, tt:243.449\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.12971, lr:1.00e-02, fs:0.62887 (r=0.701,p=0.570),  time:48.878, tt:293.267\n",
      "Ep:6, loss:0.00001, loss_test:0.12992, lr:1.00e-02, fs:0.54118 (r=0.529,p=0.554),  time:48.799, tt:341.594\n",
      "Ep:7, loss:0.00001, loss_test:0.12334, lr:1.00e-02, fs:0.61957 (r=0.655,p=0.588),  time:48.847, tt:390.777\n",
      "Ep:8, loss:0.00001, loss_test:0.12063, lr:1.00e-02, fs:0.68367 (r=0.770,p=0.615),  time:48.781, tt:439.028\n",
      "Ep:9, loss:0.00001, loss_test:0.12335, lr:1.00e-02, fs:0.64407 (r=0.655,p=0.633),  time:48.770, tt:487.704\n",
      "Ep:10, loss:0.00001, loss_test:0.12253, lr:1.00e-02, fs:0.65497 (r=0.644,p=0.667),  time:48.905, tt:537.952\n",
      "Ep:11, loss:0.00001, loss_test:0.11755, lr:1.00e-02, fs:0.67039 (r=0.690,p=0.652),  time:48.797, tt:585.569\n",
      "Ep:12, loss:0.00001, loss_test:0.11641, lr:1.00e-02, fs:0.70175 (r=0.690,p=0.714),  time:48.713, tt:633.270\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.11469, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:49.168, tt:688.350\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.11145, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:49.126, tt:736.887\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00001, loss_test:0.11034, lr:1.00e-02, fs:0.78107 (r=0.759,p=0.805),  time:48.995, tt:783.922\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.10765, lr:1.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:49.060, tt:834.018\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.10635, lr:1.00e-02, fs:0.78107 (r=0.759,p=0.805),  time:48.919, tt:880.546\n",
      "Ep:18, loss:0.00001, loss_test:0.10564, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:48.819, tt:927.565\n",
      "Ep:19, loss:0.00001, loss_test:0.10475, lr:1.00e-02, fs:0.76744 (r=0.759,p=0.776),  time:48.715, tt:974.292\n",
      "Ep:20, loss:0.00001, loss_test:0.10456, lr:1.00e-02, fs:0.77907 (r=0.770,p=0.788),  time:48.729, tt:1023.306\n",
      "Ep:21, loss:0.00001, loss_test:0.10387, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:48.771, tt:1072.952\n",
      "Ep:22, loss:0.00001, loss_test:0.10275, lr:1.00e-02, fs:0.77381 (r=0.747,p=0.802),  time:48.677, tt:1119.568\n",
      "Ep:23, loss:0.00001, loss_test:0.10216, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:48.715, tt:1169.151\n",
      "Ep:24, loss:0.00001, loss_test:0.10128, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:48.750, tt:1218.750\n",
      "Ep:25, loss:0.00001, loss_test:0.10122, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:48.756, tt:1267.660\n",
      "Ep:26, loss:0.00001, loss_test:0.09999, lr:1.00e-02, fs:0.79042 (r=0.759,p=0.825),  time:48.727, tt:1315.623\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.09895, lr:1.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:48.736, tt:1364.606\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.09841, lr:1.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:48.821, tt:1415.819\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00001, loss_test:0.09700, lr:1.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:48.838, tt:1465.133\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.09750, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:48.819, tt:1513.389\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.09465, lr:1.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:48.929, tt:1565.735\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.09464, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:48.880, tt:1613.041\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.09334, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:48.903, tt:1662.716\n",
      "Ep:34, loss:0.00000, loss_test:0.09296, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:48.912, tt:1711.911\n",
      "Ep:35, loss:0.00000, loss_test:0.09200, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:48.946, tt:1762.073\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00000, loss_test:0.09166, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:48.994, tt:1812.785\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.09139, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:48.969, tt:1860.805\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00000, loss_test:0.08973, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:48.981, tt:1910.255\n",
      "Ep:39, loss:0.00000, loss_test:0.09058, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:49.005, tt:1960.190\n",
      "Ep:40, loss:0.00000, loss_test:0.08957, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:49.010, tt:2009.403\n",
      "Ep:41, loss:0.00000, loss_test:0.08893, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:48.976, tt:2057.010\n",
      "Ep:42, loss:0.00000, loss_test:0.09005, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:48.950, tt:2104.841\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.08739, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:49.000, tt:2155.995\n",
      "Ep:44, loss:0.00000, loss_test:0.08690, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:48.988, tt:2204.450\n",
      "Ep:45, loss:0.00000, loss_test:0.09002, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:49.038, tt:2255.749\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00000, loss_test:0.08634, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:49.041, tt:2304.938\n",
      "Ep:47, loss:0.00000, loss_test:0.08707, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:49.059, tt:2354.849\n",
      "Ep:48, loss:0.00000, loss_test:0.08665, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:49.060, tt:2403.952\n",
      "Ep:49, loss:0.00000, loss_test:0.08590, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:49.121, tt:2456.068\n",
      "Ep:50, loss:0.00000, loss_test:0.08858, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:49.142, tt:2506.223\n",
      "Ep:51, loss:0.00000, loss_test:0.08665, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:49.180, tt:2557.369\n",
      "Ep:52, loss:0.00000, loss_test:0.08681, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:49.185, tt:2606.802\n",
      "Ep:53, loss:0.00000, loss_test:0.08878, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:49.173, tt:2655.316\n",
      "Ep:54, loss:0.00000, loss_test:0.08542, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:49.187, tt:2705.295\n",
      "Ep:55, loss:0.00000, loss_test:0.08908, lr:1.00e-02, fs:0.83660 (r=0.736,p=0.970),  time:49.218, tt:2756.222\n",
      "Ep:56, loss:0.00000, loss_test:0.08809, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:49.229, tt:2806.061\n",
      "Ep:57, loss:0.00000, loss_test:0.08696, lr:9.90e-03, fs:0.85897 (r=0.770,p=0.971),  time:49.232, tt:2855.461\n",
      "Ep:58, loss:0.00000, loss_test:0.08958, lr:9.80e-03, fs:0.79730 (r=0.678,p=0.967),  time:49.252, tt:2905.840\n",
      "Ep:59, loss:0.00000, loss_test:0.08759, lr:9.70e-03, fs:0.83660 (r=0.736,p=0.970),  time:49.238, tt:2954.269\n",
      "Ep:60, loss:0.00000, loss_test:0.08896, lr:9.61e-03, fs:0.78912 (r=0.667,p=0.967),  time:49.269, tt:3005.419\n",
      "Ep:61, loss:0.00000, loss_test:0.08880, lr:9.51e-03, fs:0.78912 (r=0.667,p=0.967),  time:49.255, tt:3053.831\n",
      "Ep:62, loss:0.00000, loss_test:0.08952, lr:9.41e-03, fs:0.78082 (r=0.655,p=0.966),  time:49.251, tt:3102.831\n",
      "Ep:63, loss:0.00000, loss_test:0.09152, lr:9.32e-03, fs:0.77778 (r=0.644,p=0.982),  time:49.250, tt:3151.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.08900, lr:9.23e-03, fs:0.78621 (r=0.655,p=0.983),  time:49.237, tt:3200.398\n",
      "Ep:65, loss:0.00000, loss_test:0.09173, lr:9.14e-03, fs:0.77778 (r=0.644,p=0.982),  time:49.243, tt:3250.049\n",
      "Ep:66, loss:0.00000, loss_test:0.08935, lr:9.04e-03, fs:0.77778 (r=0.644,p=0.982),  time:49.246, tt:3299.477\n",
      "Ep:67, loss:0.00000, loss_test:0.09048, lr:8.95e-03, fs:0.77778 (r=0.644,p=0.982),  time:49.263, tt:3349.868\n",
      "Ep:68, loss:0.00000, loss_test:0.09117, lr:8.86e-03, fs:0.76923 (r=0.632,p=0.982),  time:49.217, tt:3395.939\n",
      "Ep:69, loss:0.00000, loss_test:0.09090, lr:8.78e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.193, tt:3443.522\n",
      "Ep:70, loss:0.00000, loss_test:0.09091, lr:8.69e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.180, tt:3491.801\n",
      "Ep:71, loss:0.00000, loss_test:0.09201, lr:8.60e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.169, tt:3540.195\n",
      "Ep:72, loss:0.00000, loss_test:0.09195, lr:8.51e-03, fs:0.76923 (r=0.632,p=0.982),  time:49.172, tt:3589.561\n",
      "Ep:73, loss:0.00000, loss_test:0.09211, lr:8.43e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.151, tt:3637.196\n",
      "Ep:74, loss:0.00000, loss_test:0.09292, lr:8.35e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.157, tt:3686.742\n",
      "Ep:75, loss:0.00000, loss_test:0.09351, lr:8.26e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.156, tt:3735.871\n",
      "Ep:76, loss:0.00000, loss_test:0.09260, lr:8.18e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.147, tt:3784.291\n",
      "Ep:77, loss:0.00000, loss_test:0.09316, lr:8.10e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.174, tt:3835.611\n",
      "Ep:78, loss:0.00000, loss_test:0.09408, lr:8.02e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.158, tt:3883.502\n",
      "Ep:79, loss:0.00000, loss_test:0.09281, lr:7.94e-03, fs:0.75177 (r=0.609,p=0.981),  time:49.153, tt:3932.222\n",
      "Ep:80, loss:0.00000, loss_test:0.09529, lr:7.86e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.139, tt:3980.237\n",
      "Ep:81, loss:0.00000, loss_test:0.09421, lr:7.78e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.133, tt:4028.928\n",
      "Ep:82, loss:0.00000, loss_test:0.09454, lr:7.70e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.121, tt:4077.059\n",
      "Ep:83, loss:0.00000, loss_test:0.09509, lr:7.62e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.108, tt:4125.082\n",
      "Ep:84, loss:0.00000, loss_test:0.09507, lr:7.55e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.107, tt:4174.125\n",
      "Ep:85, loss:0.00000, loss_test:0.09583, lr:7.47e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.088, tt:4221.529\n",
      "Ep:86, loss:0.00000, loss_test:0.09626, lr:7.40e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.066, tt:4268.781\n",
      "Ep:87, loss:0.00000, loss_test:0.09602, lr:7.32e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.032, tt:4314.860\n",
      "Ep:88, loss:0.00000, loss_test:0.09694, lr:7.25e-03, fs:0.74286 (r=0.598,p=0.981),  time:49.000, tt:4360.958\n",
      "Ep:89, loss:0.00000, loss_test:0.09750, lr:7.18e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.921, tt:4402.902\n",
      "Ep:90, loss:0.00000, loss_test:0.09761, lr:7.11e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.856, tt:4445.926\n",
      "Ep:91, loss:0.00000, loss_test:0.09732, lr:7.03e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.802, tt:4489.741\n",
      "Ep:92, loss:0.00000, loss_test:0.09828, lr:6.96e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.749, tt:4533.700\n",
      "Ep:93, loss:0.00000, loss_test:0.09827, lr:6.89e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.691, tt:4576.940\n",
      "Ep:94, loss:0.00000, loss_test:0.09816, lr:6.83e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.644, tt:4621.207\n",
      "Ep:95, loss:0.00000, loss_test:0.09891, lr:6.76e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.595, tt:4665.130\n",
      "Ep:96, loss:0.00000, loss_test:0.09902, lr:6.69e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.519, tt:4706.364\n",
      "Ep:97, loss:0.00000, loss_test:0.09897, lr:6.62e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.455, tt:4748.574\n",
      "Ep:98, loss:0.00000, loss_test:0.09941, lr:6.56e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.389, tt:4790.523\n",
      "Ep:99, loss:0.00000, loss_test:0.10007, lr:6.49e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.335, tt:4833.460\n",
      "Ep:100, loss:0.00000, loss_test:0.09985, lr:6.43e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.291, tt:4877.387\n",
      "Ep:101, loss:0.00000, loss_test:0.10068, lr:6.36e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.282, tt:4924.776\n",
      "Ep:102, loss:0.00000, loss_test:0.10081, lr:6.30e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.176, tt:4962.168\n",
      "Ep:103, loss:0.00000, loss_test:0.10169, lr:6.24e-03, fs:0.74286 (r=0.598,p=0.981),  time:48.015, tt:4993.594\n",
      "Ep:104, loss:0.00000, loss_test:0.10191, lr:6.17e-03, fs:0.74286 (r=0.598,p=0.981),  time:47.873, tt:5026.646\n",
      "Ep:105, loss:0.00000, loss_test:0.10264, lr:6.11e-03, fs:0.74286 (r=0.598,p=0.981),  time:47.681, tt:5054.201\n",
      "Ep:106, loss:0.00000, loss_test:0.10354, lr:6.05e-03, fs:0.74286 (r=0.598,p=0.981),  time:47.386, tt:5070.295\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14522, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.739, tt:46.739\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14438, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.368, tt:92.735\n",
      "Ep:2, loss:0.00001, loss_test:0.14290, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:46.750, tt:140.250\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00001, loss_test:0.14028, lr:1.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:46.724, tt:186.894\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.13631, lr:1.00e-02, fs:0.65844 (r=0.920,p=0.513),  time:46.670, tt:233.348\n",
      "Ep:5, loss:0.00001, loss_test:0.13322, lr:1.00e-02, fs:0.63054 (r=0.736,p=0.552),  time:46.927, tt:281.562\n",
      "Ep:6, loss:0.00001, loss_test:0.13912, lr:1.00e-02, fs:0.44872 (r=0.402,p=0.507),  time:48.005, tt:336.038\n",
      "Ep:7, loss:0.00001, loss_test:0.13797, lr:1.00e-02, fs:0.46154 (r=0.414,p=0.522),  time:47.865, tt:382.917\n",
      "Ep:8, loss:0.00001, loss_test:0.12945, lr:1.00e-02, fs:0.61290 (r=0.655,p=0.576),  time:47.687, tt:429.180\n",
      "Ep:9, loss:0.00001, loss_test:0.12763, lr:1.00e-02, fs:0.65608 (r=0.713,p=0.608),  time:47.697, tt:476.971\n",
      "Ep:10, loss:0.00001, loss_test:0.13038, lr:1.00e-02, fs:0.53750 (r=0.494,p=0.589),  time:47.672, tt:524.397\n",
      "Ep:11, loss:0.00001, loss_test:0.12939, lr:1.00e-02, fs:0.56051 (r=0.506,p=0.629),  time:47.540, tt:570.475\n",
      "Ep:12, loss:0.00001, loss_test:0.12265, lr:1.00e-02, fs:0.64804 (r=0.667,p=0.630),  time:47.643, tt:619.365\n",
      "Ep:13, loss:0.00001, loss_test:0.12231, lr:1.00e-02, fs:0.64368 (r=0.644,p=0.644),  time:47.535, tt:665.496\n",
      "Ep:14, loss:0.00001, loss_test:0.12321, lr:1.00e-02, fs:0.59119 (r=0.540,p=0.653),  time:47.455, tt:711.818\n",
      "Ep:15, loss:0.00001, loss_test:0.11945, lr:9.90e-03, fs:0.67797 (r=0.690,p=0.667),  time:47.436, tt:758.976\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.11915, lr:9.90e-03, fs:0.68889 (r=0.713,p=0.667),  time:47.448, tt:806.618\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.12188, lr:9.90e-03, fs:0.66258 (r=0.621,p=0.711),  time:47.446, tt:854.033\n",
      "Ep:18, loss:0.00001, loss_test:0.12048, lr:9.90e-03, fs:0.64671 (r=0.621,p=0.675),  time:47.347, tt:899.591\n",
      "Ep:19, loss:0.00001, loss_test:0.11986, lr:9.90e-03, fs:0.68639 (r=0.667,p=0.707),  time:47.274, tt:945.488\n",
      "Ep:20, loss:0.00001, loss_test:0.12081, lr:9.90e-03, fs:0.68293 (r=0.644,p=0.727),  time:47.220, tt:991.615\n",
      "Ep:21, loss:0.00001, loss_test:0.11845, lr:9.90e-03, fs:0.66272 (r=0.644,p=0.683),  time:47.198, tt:1038.362\n",
      "Ep:22, loss:0.00001, loss_test:0.11861, lr:9.90e-03, fs:0.67857 (r=0.655,p=0.704),  time:47.217, tt:1085.997\n",
      "Ep:23, loss:0.00001, loss_test:0.11881, lr:9.90e-03, fs:0.67879 (r=0.644,p=0.718),  time:47.229, tt:1133.501\n",
      "Ep:24, loss:0.00001, loss_test:0.11774, lr:9.90e-03, fs:0.67059 (r=0.655,p=0.687),  time:47.243, tt:1181.087\n",
      "Ep:25, loss:0.00001, loss_test:0.11764, lr:9.90e-03, fs:0.68263 (r=0.655,p=0.713),  time:47.268, tt:1228.978\n",
      "Ep:26, loss:0.00001, loss_test:0.11651, lr:9.90e-03, fs:0.69461 (r=0.667,p=0.725),  time:47.290, tt:1276.837\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.11610, lr:9.90e-03, fs:0.72619 (r=0.701,p=0.753),  time:47.238, tt:1322.678\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.11631, lr:9.90e-03, fs:0.73494 (r=0.701,p=0.772),  time:47.230, tt:1369.681\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00001, loss_test:0.11502, lr:9.90e-03, fs:0.71951 (r=0.678,p=0.766),  time:47.210, tt:1416.286\n",
      "Ep:30, loss:0.00000, loss_test:0.11508, lr:9.90e-03, fs:0.72393 (r=0.678,p=0.776),  time:47.226, tt:1463.998\n",
      "Ep:31, loss:0.00000, loss_test:0.11534, lr:9.90e-03, fs:0.71605 (r=0.667,p=0.773),  time:47.225, tt:1511.201\n",
      "Ep:32, loss:0.00000, loss_test:0.11415, lr:9.90e-03, fs:0.72840 (r=0.678,p=0.787),  time:47.287, tt:1560.480\n",
      "Ep:33, loss:0.00000, loss_test:0.11398, lr:9.90e-03, fs:0.72500 (r=0.667,p=0.795),  time:47.301, tt:1608.219\n",
      "Ep:34, loss:0.00000, loss_test:0.11378, lr:9.90e-03, fs:0.72956 (r=0.667,p=0.806),  time:47.348, tt:1657.187\n",
      "Ep:35, loss:0.00000, loss_test:0.11378, lr:9.90e-03, fs:0.73885 (r=0.667,p=0.829),  time:47.310, tt:1703.174\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00000, loss_test:0.11387, lr:9.90e-03, fs:0.72258 (r=0.644,p=0.824),  time:47.375, tt:1752.871\n",
      "Ep:37, loss:0.00000, loss_test:0.11160, lr:9.90e-03, fs:0.73077 (r=0.655,p=0.826),  time:47.394, tt:1800.958\n",
      "Ep:38, loss:0.00000, loss_test:0.11304, lr:9.90e-03, fs:0.70667 (r=0.609,p=0.841),  time:47.374, tt:1847.586\n",
      "Ep:39, loss:0.00000, loss_test:0.11145, lr:9.90e-03, fs:0.73203 (r=0.644,p=0.848),  time:47.398, tt:1895.933\n",
      "Ep:40, loss:0.00000, loss_test:0.11277, lr:9.90e-03, fs:0.72973 (r=0.621,p=0.885),  time:47.387, tt:1942.868\n",
      "Ep:41, loss:0.00000, loss_test:0.11414, lr:9.90e-03, fs:0.69444 (r=0.575,p=0.877),  time:47.419, tt:1991.606\n",
      "Ep:42, loss:0.00000, loss_test:0.11080, lr:9.90e-03, fs:0.74172 (r=0.644,p=0.875),  time:47.389, tt:2037.721\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.11516, lr:9.90e-03, fs:0.71329 (r=0.586,p=0.911),  time:47.355, tt:2083.641\n",
      "Ep:44, loss:0.00000, loss_test:0.11148, lr:9.90e-03, fs:0.74667 (r=0.644,p=0.889),  time:47.256, tt:2126.523\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.11368, lr:9.90e-03, fs:0.73973 (r=0.621,p=0.915),  time:47.131, tt:2168.029\n",
      "Ep:46, loss:0.00000, loss_test:0.11279, lr:9.90e-03, fs:0.73973 (r=0.621,p=0.915),  time:47.043, tt:2211.019\n",
      "Ep:47, loss:0.00000, loss_test:0.11261, lr:9.90e-03, fs:0.70833 (r=0.586,p=0.895),  time:47.000, tt:2255.989\n",
      "Ep:48, loss:0.00000, loss_test:0.11617, lr:9.90e-03, fs:0.70423 (r=0.575,p=0.909),  time:46.985, tt:2302.268\n",
      "Ep:49, loss:0.00000, loss_test:0.11352, lr:9.90e-03, fs:0.71329 (r=0.586,p=0.911),  time:47.019, tt:2350.957\n",
      "Ep:50, loss:0.00000, loss_test:0.11590, lr:9.90e-03, fs:0.66667 (r=0.529,p=0.902),  time:47.042, tt:2399.135\n",
      "Ep:51, loss:0.00000, loss_test:0.11567, lr:9.90e-03, fs:0.65693 (r=0.517,p=0.900),  time:47.071, tt:2447.686\n",
      "Ep:52, loss:0.00000, loss_test:0.11403, lr:9.90e-03, fs:0.68571 (r=0.552,p=0.906),  time:47.084, tt:2495.466\n",
      "Ep:53, loss:0.00000, loss_test:0.11832, lr:9.90e-03, fs:0.61654 (r=0.471,p=0.891),  time:47.073, tt:2541.929\n",
      "Ep:54, loss:0.00000, loss_test:0.11376, lr:9.90e-03, fs:0.63704 (r=0.494,p=0.896),  time:47.091, tt:2590.029\n",
      "Ep:55, loss:0.00000, loss_test:0.11710, lr:9.90e-03, fs:0.63158 (r=0.483,p=0.913),  time:47.085, tt:2636.752\n",
      "Ep:56, loss:0.00000, loss_test:0.11631, lr:9.80e-03, fs:0.63158 (r=0.483,p=0.913),  time:47.115, tt:2685.559\n",
      "Ep:57, loss:0.00000, loss_test:0.11549, lr:9.70e-03, fs:0.56250 (r=0.414,p=0.878),  time:47.120, tt:2732.942\n",
      "Ep:58, loss:0.00000, loss_test:0.12019, lr:9.61e-03, fs:0.53226 (r=0.379,p=0.892),  time:47.134, tt:2780.885\n",
      "Ep:59, loss:0.00000, loss_test:0.11510, lr:9.51e-03, fs:0.57812 (r=0.425,p=0.902),  time:47.169, tt:2830.152\n",
      "Ep:60, loss:0.00000, loss_test:0.12373, lr:9.41e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.178, tt:2877.864\n",
      "Ep:61, loss:0.00000, loss_test:0.11640, lr:9.32e-03, fs:0.57812 (r=0.425,p=0.902),  time:47.194, tt:2926.022\n",
      "Ep:62, loss:0.00000, loss_test:0.11998, lr:9.23e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.264, tt:2977.649\n",
      "Ep:63, loss:0.00000, loss_test:0.11987, lr:9.14e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.266, tt:3025.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.12169, lr:9.04e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.271, tt:3072.641\n",
      "Ep:65, loss:0.00000, loss_test:0.12402, lr:8.95e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.267, tt:3119.621\n",
      "Ep:66, loss:0.00000, loss_test:0.12205, lr:8.86e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.265, tt:3166.740\n",
      "Ep:67, loss:0.00000, loss_test:0.12234, lr:8.78e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.298, tt:3216.296\n",
      "Ep:68, loss:0.00000, loss_test:0.12622, lr:8.69e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.309, tt:3264.299\n",
      "Ep:69, loss:0.00000, loss_test:0.12366, lr:8.60e-03, fs:0.54400 (r=0.391,p=0.895),  time:47.321, tt:3312.498\n",
      "Ep:70, loss:0.00000, loss_test:0.12464, lr:8.51e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.321, tt:3359.774\n",
      "Ep:71, loss:0.00000, loss_test:0.12569, lr:8.43e-03, fs:0.52033 (r=0.368,p=0.889),  time:47.353, tt:3409.449\n",
      "Ep:72, loss:0.00000, loss_test:0.12497, lr:8.35e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.361, tt:3457.388\n",
      "Ep:73, loss:0.00000, loss_test:0.12497, lr:8.26e-03, fs:0.53659 (r=0.379,p=0.917),  time:47.399, tt:3507.546\n",
      "Ep:74, loss:0.00000, loss_test:0.12674, lr:8.18e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.425, tt:3556.878\n",
      "Ep:75, loss:0.00000, loss_test:0.12725, lr:8.10e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.429, tt:3604.608\n",
      "Ep:76, loss:0.00000, loss_test:0.12465, lr:8.02e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.472, tt:3655.364\n",
      "Ep:77, loss:0.00000, loss_test:0.12889, lr:7.94e-03, fs:0.53659 (r=0.379,p=0.917),  time:47.490, tt:3704.243\n",
      "Ep:78, loss:0.00000, loss_test:0.12817, lr:7.86e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.533, tt:3755.077\n",
      "Ep:79, loss:0.00000, loss_test:0.12583, lr:7.78e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.553, tt:3804.216\n",
      "Ep:80, loss:0.00000, loss_test:0.13143, lr:7.70e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.573, tt:3853.414\n",
      "Ep:81, loss:0.00000, loss_test:0.12581, lr:7.62e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.585, tt:3901.946\n",
      "Ep:82, loss:0.00000, loss_test:0.13204, lr:7.55e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.619, tt:3952.409\n",
      "Ep:83, loss:0.00000, loss_test:0.12735, lr:7.47e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.630, tt:4000.881\n",
      "Ep:84, loss:0.00000, loss_test:0.13242, lr:7.40e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.653, tt:4050.540\n",
      "Ep:85, loss:0.00000, loss_test:0.13085, lr:7.32e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.661, tt:4098.851\n",
      "Ep:86, loss:0.00000, loss_test:0.12992, lr:7.25e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.676, tt:4147.774\n",
      "Ep:87, loss:0.00000, loss_test:0.13317, lr:7.18e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.697, tt:4197.353\n",
      "Ep:88, loss:0.00000, loss_test:0.12957, lr:7.11e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.731, tt:4248.023\n",
      "Ep:89, loss:0.00000, loss_test:0.13371, lr:7.03e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.758, tt:4298.229\n",
      "Ep:90, loss:0.00000, loss_test:0.13033, lr:6.96e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.777, tt:4347.672\n",
      "Ep:91, loss:0.00000, loss_test:0.13440, lr:6.89e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.833, tt:4400.596\n",
      "Ep:92, loss:0.00000, loss_test:0.13216, lr:6.83e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.837, tt:4448.879\n",
      "Ep:93, loss:0.00000, loss_test:0.13373, lr:6.76e-03, fs:0.52459 (r=0.368,p=0.914),  time:47.870, tt:4499.788\n",
      "Ep:94, loss:0.00000, loss_test:0.13227, lr:6.69e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.895, tt:4549.991\n",
      "Ep:95, loss:0.00000, loss_test:0.13445, lr:6.62e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.902, tt:4598.549\n",
      "Ep:96, loss:0.00000, loss_test:0.13371, lr:6.56e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.853, tt:4641.708\n",
      "Ep:97, loss:0.00000, loss_test:0.13493, lr:6.49e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.813, tt:4685.707\n",
      "Ep:98, loss:0.00000, loss_test:0.13494, lr:6.43e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.775, tt:4729.754\n",
      "Ep:99, loss:0.00000, loss_test:0.13604, lr:6.36e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.753, tt:4775.285\n",
      "Ep:100, loss:0.00000, loss_test:0.13654, lr:6.30e-03, fs:0.52893 (r=0.368,p=0.941),  time:47.721, tt:4819.819\n",
      "Ep:101, loss:0.00000, loss_test:0.13622, lr:6.24e-03, fs:0.53333 (r=0.368,p=0.970),  time:47.679, tt:4863.268\n",
      "Ep:102, loss:0.00000, loss_test:0.13661, lr:6.17e-03, fs:0.53333 (r=0.368,p=0.970),  time:47.591, tt:4901.847\n",
      "Ep:103, loss:0.00000, loss_test:0.13572, lr:6.11e-03, fs:0.51667 (r=0.356,p=0.939),  time:47.562, tt:4946.413\n",
      "Ep:104, loss:0.00000, loss_test:0.13724, lr:6.05e-03, fs:0.52101 (r=0.356,p=0.969),  time:47.570, tt:4994.865\n",
      "Ep:105, loss:0.00000, loss_test:0.13615, lr:5.99e-03, fs:0.53333 (r=0.368,p=0.970),  time:47.554, tt:5040.740\n",
      "Ep:106, loss:0.00000, loss_test:0.13594, lr:5.93e-03, fs:0.52101 (r=0.356,p=0.969),  time:47.469, tt:5079.143\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00357, loss_test:0.14087, lr:4.00e-03, fs:0.61856 (r=0.606,p=0.632),  time:583.627, tt:583.627\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00255, loss_test:0.11637, lr:4.00e-03, fs:0.58140 (r=0.505,p=0.685),  time:584.732, tt:1169.464\n",
      "Ep:2, loss:0.00187, loss_test:0.11325, lr:4.00e-03, fs:0.66272 (r=0.566,p=0.800),  time:581.693, tt:1745.079\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00138, loss_test:0.11091, lr:4.00e-03, fs:0.63415 (r=0.525,p=0.800),  time:581.859, tt:2327.436\n",
      "Ep:4, loss:0.00096, loss_test:0.11419, lr:4.00e-03, fs:0.62025 (r=0.495,p=0.831),  time:580.725, tt:2903.623\n",
      "Ep:5, loss:0.00062, loss_test:0.12990, lr:4.00e-03, fs:0.62585 (r=0.465,p=0.958),  time:581.572, tt:3489.435\n",
      "Ep:6, loss:0.00036, loss_test:0.13909, lr:4.00e-03, fs:0.62585 (r=0.465,p=0.958),  time:582.019, tt:4074.132\n",
      "Ep:7, loss:0.00022, loss_test:0.14640, lr:4.00e-03, fs:0.61644 (r=0.455,p=0.957),  time:582.913, tt:4663.307\n",
      "Ep:8, loss:0.00014, loss_test:0.15068, lr:4.00e-03, fs:0.61644 (r=0.455,p=0.957),  time:582.561, tt:5243.051\n",
      "Ep:9, loss:0.00010, loss_test:0.15588, lr:4.00e-03, fs:0.62500 (r=0.455,p=1.000),  time:582.795, tt:5827.947\n",
      "Ep:10, loss:0.00007, loss_test:0.15870, lr:4.00e-03, fs:0.62069 (r=0.455,p=0.978),  time:578.277, tt:6361.044\n",
      "Ep:11, loss:0.00005, loss_test:0.16310, lr:4.00e-03, fs:0.62069 (r=0.455,p=0.978),  time:573.590, tt:6883.083\n",
      "Ep:12, loss:0.00004, loss_test:0.16326, lr:4.00e-03, fs:0.62500 (r=0.455,p=1.000),  time:570.102, tt:7411.322\n",
      "Ep:13, loss:0.00003, loss_test:0.16197, lr:4.00e-03, fs:0.62069 (r=0.455,p=0.978),  time:566.990, tt:7937.856\n",
      "Ep:14, loss:0.00002, loss_test:0.16180, lr:3.96e-03, fs:0.62069 (r=0.455,p=0.978),  time:564.672, tt:8470.086\n",
      "Ep:15, loss:0.00002, loss_test:0.16164, lr:3.92e-03, fs:0.62500 (r=0.455,p=1.000),  time:562.117, tt:8993.871\n",
      "Ep:16, loss:0.00002, loss_test:0.16116, lr:3.88e-03, fs:0.62500 (r=0.455,p=1.000),  time:555.736, tt:9447.504\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14268, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:81.895, tt:81.895\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14124, lr:4.00e-03, fs:0.66216 (r=0.990,p=0.497),  time:83.210, tt:166.421\n",
      "Ep:2, loss:0.00056, loss_test:0.13871, lr:4.00e-03, fs:0.66441 (r=0.990,p=0.500),  time:83.764, tt:251.292\n",
      "Ep:3, loss:0.00054, loss_test:0.13459, lr:4.00e-03, fs:0.66212 (r=0.980,p=0.500),  time:82.847, tt:331.390\n",
      "Ep:4, loss:0.00053, loss_test:0.12792, lr:4.00e-03, fs:0.65926 (r=0.899,p=0.520),  time:82.853, tt:414.265\n",
      "Ep:5, loss:0.00050, loss_test:0.11986, lr:4.00e-03, fs:0.68333 (r=0.828,p=0.582),  time:82.963, tt:497.780\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00046, loss_test:0.11528, lr:4.00e-03, fs:0.64000 (r=0.646,p=0.634),  time:82.945, tt:580.616\n",
      "Ep:7, loss:0.00044, loss_test:0.11241, lr:4.00e-03, fs:0.65714 (r=0.697,p=0.622),  time:82.849, tt:662.791\n",
      "Ep:8, loss:0.00042, loss_test:0.10943, lr:4.00e-03, fs:0.68317 (r=0.697,p=0.670),  time:82.809, tt:745.281\n",
      "Ep:9, loss:0.00040, loss_test:0.10657, lr:4.00e-03, fs:0.69474 (r=0.667,p=0.725),  time:82.637, tt:826.369\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00038, loss_test:0.10392, lr:4.00e-03, fs:0.71134 (r=0.697,p=0.726),  time:82.932, tt:912.257\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00036, loss_test:0.10057, lr:4.00e-03, fs:0.72340 (r=0.687,p=0.764),  time:82.827, tt:993.926\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.09817, lr:4.00e-03, fs:0.70213 (r=0.667,p=0.742),  time:83.060, tt:1079.782\n",
      "Ep:13, loss:0.00033, loss_test:0.09690, lr:4.00e-03, fs:0.72826 (r=0.677,p=0.788),  time:83.245, tt:1165.429\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00031, loss_test:0.09409, lr:4.00e-03, fs:0.73797 (r=0.697,p=0.784),  time:83.366, tt:1250.497\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.09304, lr:4.00e-03, fs:0.74725 (r=0.687,p=0.819),  time:83.359, tt:1333.747\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00029, loss_test:0.09171, lr:4.00e-03, fs:0.75269 (r=0.707,p=0.805),  time:83.259, tt:1415.408\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00027, loss_test:0.09119, lr:4.00e-03, fs:0.75676 (r=0.707,p=0.814),  time:82.871, tt:1491.672\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.09080, lr:4.00e-03, fs:0.76087 (r=0.707,p=0.824),  time:82.615, tt:1569.683\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.08913, lr:4.00e-03, fs:0.77419 (r=0.727,p=0.828),  time:82.628, tt:1652.555\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.08944, lr:4.00e-03, fs:0.75556 (r=0.687,p=0.840),  time:82.696, tt:1736.623\n",
      "Ep:21, loss:0.00023, loss_test:0.08792, lr:4.00e-03, fs:0.76757 (r=0.717,p=0.826),  time:82.828, tt:1822.206\n",
      "Ep:22, loss:0.00022, loss_test:0.08772, lr:4.00e-03, fs:0.78212 (r=0.707,p=0.875),  time:82.857, tt:1905.700\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.08869, lr:4.00e-03, fs:0.76836 (r=0.687,p=0.872),  time:82.904, tt:1989.688\n",
      "Ep:24, loss:0.00020, loss_test:0.08746, lr:4.00e-03, fs:0.76404 (r=0.687,p=0.861),  time:82.971, tt:2074.283\n",
      "Ep:25, loss:0.00019, loss_test:0.08779, lr:4.00e-03, fs:0.76404 (r=0.687,p=0.861),  time:83.090, tt:2160.338\n",
      "Ep:26, loss:0.00018, loss_test:0.08708, lr:4.00e-03, fs:0.77778 (r=0.707,p=0.864),  time:82.843, tt:2236.749\n",
      "Ep:27, loss:0.00017, loss_test:0.09144, lr:4.00e-03, fs:0.76404 (r=0.687,p=0.861),  time:82.849, tt:2319.778\n",
      "Ep:28, loss:0.00016, loss_test:0.08975, lr:4.00e-03, fs:0.76836 (r=0.687,p=0.872),  time:82.965, tt:2405.997\n",
      "Ep:29, loss:0.00015, loss_test:0.08504, lr:4.00e-03, fs:0.77778 (r=0.707,p=0.864),  time:83.034, tt:2491.005\n",
      "Ep:30, loss:0.00015, loss_test:0.08996, lr:4.00e-03, fs:0.74118 (r=0.636,p=0.887),  time:83.033, tt:2574.028\n",
      "Ep:31, loss:0.00014, loss_test:0.09281, lr:4.00e-03, fs:0.72619 (r=0.616,p=0.884),  time:83.105, tt:2659.371\n",
      "Ep:32, loss:0.00013, loss_test:0.08669, lr:4.00e-03, fs:0.76136 (r=0.677,p=0.870),  time:83.180, tt:2744.934\n",
      "Ep:33, loss:0.00012, loss_test:0.08786, lr:4.00e-03, fs:0.75429 (r=0.667,p=0.868),  time:83.280, tt:2831.517\n",
      "Ep:34, loss:0.00012, loss_test:0.09279, lr:3.96e-03, fs:0.67925 (r=0.545,p=0.900),  time:83.324, tt:2916.332\n",
      "Ep:35, loss:0.00011, loss_test:0.08773, lr:3.92e-03, fs:0.77273 (r=0.687,p=0.883),  time:83.298, tt:2998.718\n",
      "Ep:36, loss:0.00010, loss_test:0.08851, lr:3.88e-03, fs:0.72619 (r=0.616,p=0.884),  time:83.365, tt:3084.518\n",
      "Ep:37, loss:0.00010, loss_test:0.09182, lr:3.84e-03, fs:0.68750 (r=0.556,p=0.902),  time:83.418, tt:3169.886\n",
      "Ep:38, loss:0.00009, loss_test:0.08954, lr:3.80e-03, fs:0.73494 (r=0.616,p=0.910),  time:83.504, tt:3256.669\n",
      "Ep:39, loss:0.00009, loss_test:0.09028, lr:3.77e-03, fs:0.70000 (r=0.566,p=0.918),  time:83.521, tt:3340.837\n",
      "Ep:40, loss:0.00008, loss_test:0.08855, lr:3.73e-03, fs:0.71951 (r=0.596,p=0.908),  time:83.566, tt:3426.189\n",
      "Ep:41, loss:0.00008, loss_test:0.09257, lr:3.69e-03, fs:0.68354 (r=0.545,p=0.915),  time:83.546, tt:3508.944\n",
      "Ep:42, loss:0.00007, loss_test:0.09353, lr:3.65e-03, fs:0.71338 (r=0.566,p=0.966),  time:83.544, tt:3592.388\n",
      "Ep:43, loss:0.00007, loss_test:0.08768, lr:3.62e-03, fs:0.70000 (r=0.566,p=0.918),  time:83.591, tt:3678.020\n",
      "Ep:44, loss:0.00007, loss_test:0.09349, lr:3.58e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.594, tt:3761.735\n",
      "Ep:45, loss:0.00006, loss_test:0.09812, lr:3.55e-03, fs:0.68790 (r=0.545,p=0.931),  time:83.565, tt:3844.006\n",
      "Ep:46, loss:0.00006, loss_test:0.09063, lr:3.51e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.513, tt:3925.114\n",
      "Ep:47, loss:0.00005, loss_test:0.09544, lr:3.47e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.518, tt:4008.874\n",
      "Ep:48, loss:0.00005, loss_test:0.09192, lr:3.44e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.459, tt:4089.502\n",
      "Ep:49, loss:0.00005, loss_test:0.09336, lr:3.41e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.442, tt:4172.125\n",
      "Ep:50, loss:0.00005, loss_test:0.09621, lr:3.37e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.468, tt:4256.873\n",
      "Ep:51, loss:0.00004, loss_test:0.09378, lr:3.34e-03, fs:0.70440 (r=0.566,p=0.933),  time:83.455, tt:4339.637\n",
      "Ep:52, loss:0.00004, loss_test:0.09273, lr:3.30e-03, fs:0.71338 (r=0.566,p=0.966),  time:83.435, tt:4422.081\n",
      "Ep:53, loss:0.00004, loss_test:0.09187, lr:3.27e-03, fs:0.70886 (r=0.566,p=0.949),  time:83.346, tt:4500.705\n",
      "Ep:54, loss:0.00004, loss_test:0.09389, lr:3.24e-03, fs:0.70886 (r=0.566,p=0.949),  time:83.230, tt:4577.655\n",
      "Ep:55, loss:0.00004, loss_test:0.09451, lr:3.21e-03, fs:0.70886 (r=0.566,p=0.949),  time:82.841, tt:4639.114\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00396, loss_test:0.13204, lr:4.00e-03, fs:0.60000 (r=0.515,p=0.718),  time:753.714, tt:753.714\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00261, loss_test:0.11634, lr:4.00e-03, fs:0.59873 (r=0.475,p=0.810),  time:750.159, tt:1500.319\n",
      "Ep:2, loss:0.00187, loss_test:0.10913, lr:4.00e-03, fs:0.66258 (r=0.545,p=0.844),  time:754.060, tt:2262.181\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00133, loss_test:0.10719, lr:4.00e-03, fs:0.67089 (r=0.535,p=0.898),  time:755.930, tt:3023.719\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00095, loss_test:0.10451, lr:4.00e-03, fs:0.70000 (r=0.566,p=0.918),  time:756.268, tt:3781.341\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00068, loss_test:0.11355, lr:4.00e-03, fs:0.58904 (r=0.434,p=0.915),  time:755.256, tt:4531.538\n",
      "Ep:6, loss:0.00050, loss_test:0.11226, lr:4.00e-03, fs:0.61745 (r=0.465,p=0.920),  time:753.275, tt:5272.928\n",
      "Ep:7, loss:0.00037, loss_test:0.11243, lr:4.00e-03, fs:0.63576 (r=0.485,p=0.923),  time:751.223, tt:6009.782\n",
      "Ep:8, loss:0.00027, loss_test:0.12039, lr:4.00e-03, fs:0.59310 (r=0.434,p=0.935),  time:749.937, tt:6749.437\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bd7f0cbe7c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00364, loss_test:0.11499, lr:1.00e-02, fs:0.65909 (r=0.586,p=0.753),  time:756.691, tt:756.691\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00186, loss_test:0.10175, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:755.790, tt:1511.579\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00090, loss_test:0.11044, lr:1.00e-02, fs:0.66234 (r=0.515,p=0.927),  time:751.648, tt:2254.943\n",
      "Ep:3, loss:0.00043, loss_test:0.13446, lr:1.00e-02, fs:0.60140 (r=0.434,p=0.977),  time:751.549, tt:3006.197\n",
      "Ep:4, loss:0.00018, loss_test:0.14981, lr:1.00e-02, fs:0.55072 (r=0.384,p=0.974),  time:749.913, tt:3749.567\n",
      "Ep:5, loss:0.00008, loss_test:0.15684, lr:1.00e-02, fs:0.55072 (r=0.384,p=0.974),  time:749.797, tt:4498.783\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-82debdb22a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00360, loss_test:0.11806, lr:1.00e-02, fs:0.60976 (r=0.505,p=0.769),  time:752.364, tt:752.364\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00197, loss_test:0.12364, lr:1.00e-02, fs:0.61935 (r=0.485,p=0.857),  time:751.484, tt:1502.968\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00109, loss_test:0.12154, lr:1.00e-02, fs:0.59459 (r=0.444,p=0.898),  time:755.820, tt:2267.460\n",
      "Ep:3, loss:0.00060, loss_test:0.14020, lr:1.00e-02, fs:0.51799 (r=0.364,p=0.900),  time:755.787, tt:3023.147\n",
      "Ep:4, loss:0.00031, loss_test:0.14034, lr:1.00e-02, fs:0.52174 (r=0.364,p=0.923),  time:757.824, tt:3789.119\n",
      "Ep:5, loss:0.00017, loss_test:0.14662, lr:1.00e-02, fs:0.52555 (r=0.364,p=0.947),  time:756.688, tt:4540.126\n",
      "Ep:6, loss:0.00009, loss_test:0.14759, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:753.714, tt:5275.995\n",
      "Ep:7, loss:0.00005, loss_test:0.15722, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:752.146, tt:6017.165\n",
      "Ep:8, loss:0.00003, loss_test:0.15556, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:751.067, tt:6759.607\n",
      "Ep:9, loss:0.00002, loss_test:0.15032, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:749.372, tt:7493.718\n",
      "Ep:10, loss:0.00002, loss_test:0.15224, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:748.686, tt:8235.541\n",
      "Ep:11, loss:0.00001, loss_test:0.15112, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:749.478, tt:8993.731\n",
      "Ep:12, loss:0.00001, loss_test:0.14957, lr:1.00e-02, fs:0.47328 (r=0.313,p=0.969),  time:750.649, tt:9758.441\n",
      "Ep:13, loss:0.00001, loss_test:0.15026, lr:9.90e-03, fs:0.47328 (r=0.313,p=0.969),  time:751.077, tt:10515.083\n",
      "Ep:14, loss:0.00001, loss_test:0.14983, lr:9.80e-03, fs:0.47328 (r=0.313,p=0.969),  time:751.810, tt:11277.152\n",
      "Ep:15, loss:0.00001, loss_test:0.14842, lr:9.70e-03, fs:0.47328 (r=0.313,p=0.969),  time:752.701, tt:12043.209\n",
      "Ep:16, loss:0.00001, loss_test:0.14805, lr:9.61e-03, fs:0.47328 (r=0.313,p=0.969),  time:753.130, tt:12803.213\n",
      "Ep:17, loss:0.00001, loss_test:0.14778, lr:9.51e-03, fs:0.47328 (r=0.313,p=0.969),  time:753.829, tt:13568.928\n",
      "Ep:18, loss:0.00001, loss_test:0.14657, lr:9.41e-03, fs:0.47328 (r=0.313,p=0.969),  time:753.973, tt:14325.482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14583, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.246, tt:19.246\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14567, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.005, tt:38.010\n",
      "Ep:2, loss:0.00004, loss_test:0.14543, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.191, tt:57.573\n",
      "Ep:3, loss:0.00004, loss_test:0.14509, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.576, tt:78.303\n",
      "Ep:4, loss:0.00004, loss_test:0.14466, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.800, tt:99.001\n",
      "Ep:5, loss:0.00004, loss_test:0.14410, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.843, tt:119.056\n",
      "Ep:6, loss:0.00004, loss_test:0.14344, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.643, tt:137.504\n",
      "Ep:7, loss:0.00004, loss_test:0.14266, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.492, tt:155.936\n",
      "Ep:8, loss:0.00004, loss_test:0.14171, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.488, tt:175.395\n",
      "Ep:9, loss:0.00004, loss_test:0.14057, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.529, tt:195.291\n",
      "Ep:10, loss:0.00004, loss_test:0.13914, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:19.798, tt:217.782\n",
      "Ep:11, loss:0.00004, loss_test:0.13729, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:19.691, tt:236.294\n",
      "Ep:12, loss:0.00004, loss_test:0.13491, lr:9.90e-03, fs:0.65018 (r=0.929,p=0.500),  time:19.731, tt:256.508\n",
      "Ep:13, loss:0.00004, loss_test:0.13179, lr:9.80e-03, fs:0.67164 (r=0.909,p=0.533),  time:19.664, tt:275.295\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.12870, lr:9.80e-03, fs:0.66935 (r=0.838,p=0.557),  time:19.559, tt:293.385\n",
      "Ep:15, loss:0.00003, loss_test:0.12613, lr:9.80e-03, fs:0.66667 (r=0.717,p=0.623),  time:19.556, tt:312.892\n",
      "Ep:16, loss:0.00003, loss_test:0.12620, lr:9.80e-03, fs:0.60109 (r=0.556,p=0.655),  time:19.559, tt:332.507\n",
      "Ep:17, loss:0.00003, loss_test:0.12673, lr:9.80e-03, fs:0.58621 (r=0.515,p=0.680),  time:19.566, tt:352.179\n",
      "Ep:18, loss:0.00003, loss_test:0.12551, lr:9.80e-03, fs:0.63388 (r=0.586,p=0.690),  time:19.653, tt:373.400\n",
      "Ep:19, loss:0.00003, loss_test:0.12501, lr:9.80e-03, fs:0.66667 (r=0.697,p=0.639),  time:19.654, tt:393.083\n",
      "Ep:20, loss:0.00003, loss_test:0.12491, lr:9.80e-03, fs:0.65766 (r=0.737,p=0.593),  time:19.591, tt:411.415\n",
      "Ep:21, loss:0.00003, loss_test:0.12417, lr:9.80e-03, fs:0.66038 (r=0.707,p=0.619),  time:19.554, tt:430.182\n",
      "Ep:22, loss:0.00003, loss_test:0.12342, lr:9.80e-03, fs:0.63918 (r=0.626,p=0.653),  time:19.558, tt:449.845\n",
      "Ep:23, loss:0.00003, loss_test:0.12376, lr:9.80e-03, fs:0.52632 (r=0.455,p=0.625),  time:19.565, tt:469.563\n",
      "Ep:24, loss:0.00003, loss_test:0.12379, lr:9.80e-03, fs:0.54762 (r=0.465,p=0.667),  time:19.540, tt:488.498\n",
      "Ep:25, loss:0.00003, loss_test:0.12224, lr:9.70e-03, fs:0.57923 (r=0.535,p=0.631),  time:19.488, tt:506.697\n",
      "Ep:26, loss:0.00003, loss_test:0.12179, lr:9.61e-03, fs:0.62745 (r=0.646,p=0.610),  time:19.488, tt:526.172\n",
      "Ep:27, loss:0.00002, loss_test:0.12101, lr:9.51e-03, fs:0.62687 (r=0.636,p=0.618),  time:19.457, tt:544.809\n",
      "Ep:28, loss:0.00002, loss_test:0.12169, lr:9.41e-03, fs:0.59551 (r=0.535,p=0.671),  time:19.450, tt:564.062\n",
      "Ep:29, loss:0.00002, loss_test:0.12289, lr:9.32e-03, fs:0.56287 (r=0.475,p=0.691),  time:19.441, tt:583.233\n",
      "Ep:30, loss:0.00002, loss_test:0.12238, lr:9.23e-03, fs:0.58101 (r=0.525,p=0.650),  time:19.490, tt:604.183\n",
      "Ep:31, loss:0.00002, loss_test:0.12235, lr:9.14e-03, fs:0.66332 (r=0.667,p=0.660),  time:19.459, tt:622.685\n",
      "Ep:32, loss:0.00002, loss_test:0.12292, lr:9.04e-03, fs:0.66332 (r=0.667,p=0.660),  time:19.467, tt:642.412\n",
      "Ep:33, loss:0.00002, loss_test:0.12451, lr:8.95e-03, fs:0.60674 (r=0.545,p=0.684),  time:19.470, tt:661.983\n",
      "Ep:34, loss:0.00002, loss_test:0.12538, lr:8.86e-03, fs:0.58960 (r=0.515,p=0.689),  time:19.464, tt:681.227\n",
      "Ep:35, loss:0.00002, loss_test:0.12477, lr:8.78e-03, fs:0.62105 (r=0.596,p=0.648),  time:19.452, tt:700.284\n",
      "Ep:36, loss:0.00002, loss_test:0.12456, lr:8.69e-03, fs:0.64000 (r=0.646,p=0.634),  time:19.437, tt:719.152\n",
      "Ep:37, loss:0.00002, loss_test:0.12520, lr:8.60e-03, fs:0.60440 (r=0.556,p=0.663),  time:19.449, tt:739.050\n",
      "Ep:38, loss:0.00002, loss_test:0.12599, lr:8.51e-03, fs:0.57647 (r=0.495,p=0.690),  time:19.433, tt:757.873\n",
      "Ep:39, loss:0.00002, loss_test:0.12566, lr:8.43e-03, fs:0.58757 (r=0.525,p=0.667),  time:19.395, tt:775.786\n",
      "Ep:40, loss:0.00002, loss_test:0.12488, lr:8.35e-03, fs:0.61376 (r=0.586,p=0.644),  time:19.371, tt:794.230\n",
      "Ep:41, loss:0.00002, loss_test:0.12458, lr:8.26e-03, fs:0.60638 (r=0.576,p=0.640),  time:19.362, tt:813.214\n",
      "Ep:42, loss:0.00002, loss_test:0.12495, lr:8.18e-03, fs:0.59669 (r=0.545,p=0.659),  time:19.322, tt:830.846\n",
      "Ep:43, loss:0.00002, loss_test:0.12520, lr:8.10e-03, fs:0.56647 (r=0.495,p=0.662),  time:19.330, tt:850.532\n",
      "Ep:44, loss:0.00002, loss_test:0.12472, lr:8.02e-03, fs:0.58696 (r=0.545,p=0.635),  time:19.323, tt:869.531\n",
      "Ep:45, loss:0.00002, loss_test:0.12434, lr:7.94e-03, fs:0.61780 (r=0.596,p=0.641),  time:19.329, tt:889.131\n",
      "Ep:46, loss:0.00002, loss_test:0.12459, lr:7.86e-03, fs:0.62032 (r=0.586,p=0.659),  time:19.335, tt:908.735\n",
      "Ep:47, loss:0.00002, loss_test:0.12511, lr:7.78e-03, fs:0.58286 (r=0.515,p=0.671),  time:19.341, tt:928.377\n",
      "Ep:48, loss:0.00002, loss_test:0.12513, lr:7.70e-03, fs:0.57471 (r=0.505,p=0.667),  time:19.345, tt:947.929\n",
      "Ep:49, loss:0.00002, loss_test:0.12479, lr:7.62e-03, fs:0.58696 (r=0.545,p=0.635),  time:19.354, tt:967.704\n",
      "Ep:50, loss:0.00002, loss_test:0.12485, lr:7.55e-03, fs:0.57459 (r=0.525,p=0.634),  time:19.396, tt:989.179\n",
      "Ep:51, loss:0.00001, loss_test:0.12531, lr:7.47e-03, fs:0.57471 (r=0.505,p=0.667),  time:19.414, tt:1009.528\n",
      "Ep:52, loss:0.00001, loss_test:0.12511, lr:7.40e-03, fs:0.57955 (r=0.515,p=0.662),  time:19.430, tt:1029.777\n",
      "Ep:53, loss:0.00001, loss_test:0.12517, lr:7.32e-03, fs:0.57627 (r=0.515,p=0.654),  time:19.424, tt:1048.888\n",
      "Ep:54, loss:0.00001, loss_test:0.12616, lr:7.25e-03, fs:0.57647 (r=0.495,p=0.690),  time:19.430, tt:1068.670\n",
      "Ep:55, loss:0.00001, loss_test:0.12627, lr:7.18e-03, fs:0.56805 (r=0.485,p=0.686),  time:19.421, tt:1087.577\n",
      "Ep:56, loss:0.00001, loss_test:0.12590, lr:7.11e-03, fs:0.55814 (r=0.485,p=0.658),  time:19.473, tt:1109.941\n",
      "Ep:57, loss:0.00001, loss_test:0.12610, lr:7.03e-03, fs:0.56805 (r=0.485,p=0.686),  time:19.470, tt:1129.233\n",
      "Ep:58, loss:0.00001, loss_test:0.12678, lr:6.96e-03, fs:0.57831 (r=0.485,p=0.716),  time:19.460, tt:1148.117\n",
      "Ep:59, loss:0.00001, loss_test:0.12679, lr:6.89e-03, fs:0.57485 (r=0.485,p=0.706),  time:19.469, tt:1168.125\n",
      "Ep:60, loss:0.00001, loss_test:0.12719, lr:6.83e-03, fs:0.57485 (r=0.485,p=0.706),  time:19.472, tt:1187.765\n",
      "Ep:61, loss:0.00001, loss_test:0.12764, lr:6.76e-03, fs:0.56970 (r=0.475,p=0.712),  time:19.453, tt:1206.083\n",
      "Ep:62, loss:0.00001, loss_test:0.12758, lr:6.69e-03, fs:0.57143 (r=0.485,p=0.696),  time:19.434, tt:1224.331\n",
      "Ep:63, loss:0.00001, loss_test:0.12773, lr:6.62e-03, fs:0.57485 (r=0.485,p=0.706),  time:19.449, tt:1244.754\n",
      "Ep:64, loss:0.00001, loss_test:0.12860, lr:6.56e-03, fs:0.56790 (r=0.465,p=0.730),  time:19.457, tt:1264.674\n",
      "Ep:65, loss:0.00001, loss_test:0.12833, lr:6.49e-03, fs:0.57485 (r=0.485,p=0.706),  time:19.447, tt:1283.493\n",
      "Ep:66, loss:0.00001, loss_test:0.12946, lr:6.43e-03, fs:0.56442 (r=0.465,p=0.719),  time:19.457, tt:1303.648\n",
      "Ep:67, loss:0.00001, loss_test:0.12930, lr:6.36e-03, fs:0.55758 (r=0.465,p=0.697),  time:19.450, tt:1322.583\n",
      "Ep:68, loss:0.00001, loss_test:0.12941, lr:6.30e-03, fs:0.55758 (r=0.465,p=0.697),  time:19.451, tt:1342.106\n",
      "Ep:69, loss:0.00001, loss_test:0.13008, lr:6.24e-03, fs:0.56098 (r=0.465,p=0.708),  time:19.452, tt:1361.649\n",
      "Ep:70, loss:0.00001, loss_test:0.12980, lr:6.17e-03, fs:0.57831 (r=0.485,p=0.716),  time:19.463, tt:1381.868\n",
      "Ep:71, loss:0.00001, loss_test:0.12953, lr:6.11e-03, fs:0.58333 (r=0.495,p=0.710),  time:19.463, tt:1401.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.13022, lr:6.05e-03, fs:0.56442 (r=0.465,p=0.719),  time:19.476, tt:1421.751\n",
      "Ep:73, loss:0.00001, loss_test:0.12968, lr:5.99e-03, fs:0.59036 (r=0.495,p=0.731),  time:19.484, tt:1441.842\n",
      "Ep:74, loss:0.00001, loss_test:0.12927, lr:5.93e-03, fs:0.58480 (r=0.505,p=0.694),  time:19.490, tt:1461.744\n",
      "Ep:75, loss:0.00001, loss_test:0.13246, lr:5.87e-03, fs:0.57143 (r=0.444,p=0.800),  time:19.483, tt:1480.693\n",
      "Ep:76, loss:0.00001, loss_test:0.13273, lr:5.81e-03, fs:0.57143 (r=0.444,p=0.800),  time:19.475, tt:1499.601\n",
      "Ep:77, loss:0.00001, loss_test:0.13006, lr:5.75e-03, fs:0.59172 (r=0.505,p=0.714),  time:19.460, tt:1517.911\n",
      "Ep:78, loss:0.00001, loss_test:0.12935, lr:5.70e-03, fs:0.59649 (r=0.515,p=0.708),  time:19.454, tt:1536.882\n",
      "Ep:79, loss:0.00001, loss_test:0.13256, lr:5.64e-03, fs:0.57895 (r=0.444,p=0.830),  time:19.447, tt:1555.753\n",
      "Ep:80, loss:0.00001, loss_test:0.13374, lr:5.58e-03, fs:0.58278 (r=0.444,p=0.846),  time:19.448, tt:1575.284\n",
      "Ep:81, loss:0.00001, loss_test:0.13081, lr:5.53e-03, fs:0.58896 (r=0.485,p=0.750),  time:19.429, tt:1593.201\n",
      "Ep:82, loss:0.00001, loss_test:0.12895, lr:5.47e-03, fs:0.58621 (r=0.515,p=0.680),  time:19.436, tt:1613.205\n",
      "Ep:83, loss:0.00001, loss_test:0.13142, lr:5.42e-03, fs:0.58537 (r=0.485,p=0.738),  time:19.435, tt:1632.560\n",
      "Ep:84, loss:0.00001, loss_test:0.13414, lr:5.36e-03, fs:0.58667 (r=0.444,p=0.863),  time:19.446, tt:1652.911\n",
      "Ep:85, loss:0.00001, loss_test:0.13300, lr:5.31e-03, fs:0.58442 (r=0.455,p=0.818),  time:19.445, tt:1672.278\n",
      "Ep:86, loss:0.00001, loss_test:0.13108, lr:5.26e-03, fs:0.59880 (r=0.505,p=0.735),  time:19.431, tt:1690.533\n",
      "Ep:87, loss:0.00001, loss_test:0.13091, lr:5.20e-03, fs:0.60355 (r=0.515,p=0.729),  time:19.438, tt:1710.545\n",
      "Ep:88, loss:0.00001, loss_test:0.13280, lr:5.15e-03, fs:0.58385 (r=0.475,p=0.758),  time:19.441, tt:1730.248\n",
      "Ep:89, loss:0.00001, loss_test:0.13429, lr:5.10e-03, fs:0.61039 (r=0.475,p=0.855),  time:19.470, tt:1752.300\n",
      "Ep:90, loss:0.00001, loss_test:0.13323, lr:5.05e-03, fs:0.58025 (r=0.475,p=0.746),  time:19.470, tt:1771.781\n",
      "Ep:91, loss:0.00001, loss_test:0.13153, lr:5.00e-03, fs:0.60714 (r=0.515,p=0.739),  time:19.464, tt:1790.676\n",
      "Ep:92, loss:0.00001, loss_test:0.13191, lr:4.95e-03, fs:0.60241 (r=0.505,p=0.746),  time:19.465, tt:1810.270\n",
      "Ep:93, loss:0.00001, loss_test:0.13347, lr:4.90e-03, fs:0.58385 (r=0.475,p=0.758),  time:19.466, tt:1829.822\n",
      "Ep:94, loss:0.00001, loss_test:0.13396, lr:4.85e-03, fs:0.59119 (r=0.475,p=0.783),  time:19.451, tt:1847.856\n",
      "Ep:95, loss:0.00001, loss_test:0.13302, lr:4.80e-03, fs:0.59259 (r=0.485,p=0.762),  time:19.465, tt:1868.663\n",
      "Ep:96, loss:0.00001, loss_test:0.13224, lr:4.75e-03, fs:0.60241 (r=0.505,p=0.746),  time:19.461, tt:1887.674\n",
      "Ep:97, loss:0.00001, loss_test:0.13362, lr:4.71e-03, fs:0.59259 (r=0.485,p=0.762),  time:19.465, tt:1907.580\n",
      "Ep:98, loss:0.00001, loss_test:0.13465, lr:4.66e-03, fs:0.60256 (r=0.475,p=0.825),  time:19.465, tt:1927.015\n",
      "Ep:99, loss:0.00001, loss_test:0.13374, lr:4.61e-03, fs:0.59627 (r=0.485,p=0.774),  time:19.467, tt:1946.677\n",
      "Ep:100, loss:0.00001, loss_test:0.13288, lr:4.57e-03, fs:0.60606 (r=0.505,p=0.758),  time:19.478, tt:1967.248\n",
      "Ep:101, loss:0.00001, loss_test:0.13351, lr:4.52e-03, fs:0.60123 (r=0.495,p=0.766),  time:19.486, tt:1987.571\n",
      "Ep:102, loss:0.00001, loss_test:0.13447, lr:4.48e-03, fs:0.60000 (r=0.485,p=0.787),  time:19.493, tt:2007.792\n",
      "Ep:103, loss:0.00001, loss_test:0.13451, lr:4.43e-03, fs:0.60000 (r=0.485,p=0.787),  time:19.497, tt:2027.670\n",
      "Ep:104, loss:0.00001, loss_test:0.13391, lr:4.39e-03, fs:0.60123 (r=0.495,p=0.766),  time:19.486, tt:2046.022\n",
      "Ep:105, loss:0.00001, loss_test:0.13399, lr:4.34e-03, fs:0.60123 (r=0.495,p=0.766),  time:19.513, tt:2068.413\n",
      "Ep:106, loss:0.00001, loss_test:0.13566, lr:4.30e-03, fs:0.60377 (r=0.485,p=0.800),  time:19.515, tt:2088.072\n",
      "Ep:107, loss:0.00001, loss_test:0.13573, lr:4.26e-03, fs:0.60377 (r=0.485,p=0.800),  time:19.511, tt:2107.189\n",
      "Ep:108, loss:0.00001, loss_test:0.13435, lr:4.21e-03, fs:0.60494 (r=0.495,p=0.778),  time:19.504, tt:2125.884\n",
      "Ep:109, loss:0.00001, loss_test:0.13470, lr:4.17e-03, fs:0.60494 (r=0.495,p=0.778),  time:19.506, tt:2145.611\n",
      "Ep:110, loss:0.00001, loss_test:0.13583, lr:4.13e-03, fs:0.60377 (r=0.485,p=0.800),  time:19.514, tt:2166.043\n",
      "Ep:111, loss:0.00001, loss_test:0.13611, lr:4.09e-03, fs:0.60377 (r=0.485,p=0.800),  time:19.515, tt:2185.702\n",
      "Ep:112, loss:0.00001, loss_test:0.13571, lr:4.05e-03, fs:0.60123 (r=0.495,p=0.766),  time:19.512, tt:2204.883\n",
      "Ep:113, loss:0.00001, loss_test:0.13564, lr:4.01e-03, fs:0.60123 (r=0.495,p=0.766),  time:19.498, tt:2222.720\n",
      "Ep:114, loss:0.00001, loss_test:0.13614, lr:3.97e-03, fs:0.60000 (r=0.485,p=0.787),  time:19.491, tt:2241.471\n",
      "Ep:115, loss:0.00001, loss_test:0.13640, lr:3.93e-03, fs:0.60377 (r=0.485,p=0.800),  time:19.506, tt:2262.701\n",
      "Ep:116, loss:0.00001, loss_test:0.13634, lr:3.89e-03, fs:0.60494 (r=0.495,p=0.778),  time:19.508, tt:2282.457\n",
      "Ep:117, loss:0.00001, loss_test:0.13642, lr:3.85e-03, fs:0.60123 (r=0.495,p=0.766),  time:19.504, tt:2301.480\n",
      "Ep:118, loss:0.00001, loss_test:0.13752, lr:3.81e-03, fs:0.60759 (r=0.485,p=0.814),  time:19.494, tt:2319.815\n",
      "Ep:119, loss:0.00001, loss_test:0.13747, lr:3.77e-03, fs:0.60759 (r=0.485,p=0.814),  time:19.493, tt:2339.149\n",
      "Ep:120, loss:0.00001, loss_test:0.13668, lr:3.73e-03, fs:0.60870 (r=0.495,p=0.790),  time:19.500, tt:2359.467\n",
      "Ep:121, loss:0.00001, loss_test:0.13691, lr:3.70e-03, fs:0.60870 (r=0.495,p=0.790),  time:19.493, tt:2378.121\n",
      "Ep:122, loss:0.00001, loss_test:0.13741, lr:3.66e-03, fs:0.61250 (r=0.495,p=0.803),  time:19.494, tt:2397.812\n",
      "Ep:123, loss:0.00001, loss_test:0.13732, lr:3.62e-03, fs:0.61250 (r=0.495,p=0.803),  time:19.481, tt:2415.603\n",
      "Ep:124, loss:0.00001, loss_test:0.13708, lr:3.59e-03, fs:0.60870 (r=0.495,p=0.790),  time:19.470, tt:2433.755\n",
      "Ep:125, loss:0.00001, loss_test:0.13779, lr:3.55e-03, fs:0.60377 (r=0.485,p=0.800),  time:19.461, tt:2452.141\n",
      "Ep:126, loss:0.00001, loss_test:0.13786, lr:3.52e-03, fs:0.61250 (r=0.495,p=0.803),  time:19.454, tt:2470.693\n",
      "Ep:127, loss:0.00001, loss_test:0.13761, lr:3.48e-03, fs:0.60870 (r=0.495,p=0.790),  time:19.437, tt:2487.937\n",
      "Ep:128, loss:0.00001, loss_test:0.13819, lr:3.45e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.432, tt:2506.764\n",
      "Ep:129, loss:0.00001, loss_test:0.13807, lr:3.41e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.420, tt:2524.607\n",
      "Ep:130, loss:0.00001, loss_test:0.13732, lr:3.38e-03, fs:0.60870 (r=0.495,p=0.790),  time:19.418, tt:2543.699\n",
      "Ep:131, loss:0.00001, loss_test:0.13809, lr:3.34e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.421, tt:2563.614\n",
      "Ep:132, loss:0.00001, loss_test:0.13886, lr:3.31e-03, fs:0.60759 (r=0.485,p=0.814),  time:19.425, tt:2583.558\n",
      "Ep:133, loss:0.00001, loss_test:0.13856, lr:3.28e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.417, tt:2601.936\n",
      "Ep:134, loss:0.00001, loss_test:0.13866, lr:3.24e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.418, tt:2621.398\n",
      "Ep:135, loss:0.00001, loss_test:0.13859, lr:3.21e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.423, tt:2641.537\n",
      "Ep:136, loss:0.00001, loss_test:0.13803, lr:3.18e-03, fs:0.61250 (r=0.495,p=0.803),  time:19.412, tt:2659.395\n",
      "Ep:137, loss:0.00001, loss_test:0.13835, lr:3.15e-03, fs:0.61250 (r=0.495,p=0.803),  time:19.412, tt:2678.887\n",
      "Ep:138, loss:0.00001, loss_test:0.13874, lr:3.12e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.413, tt:2698.440\n",
      "Ep:139, loss:0.00001, loss_test:0.13903, lr:3.09e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.418, tt:2718.543\n",
      "Ep:140, loss:0.00001, loss_test:0.13890, lr:3.05e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.424, tt:2738.786\n",
      "Ep:141, loss:0.00001, loss_test:0.13881, lr:3.02e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.423, tt:2758.121\n",
      "Ep:142, loss:0.00001, loss_test:0.13890, lr:2.99e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.427, tt:2778.117\n",
      "Ep:143, loss:0.00001, loss_test:0.13891, lr:2.96e-03, fs:0.61635 (r=0.495,p=0.817),  time:19.428, tt:2797.588\n",
      "Ep:144, loss:0.00001, loss_test:0.13931, lr:2.93e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.425, tt:2816.591\n",
      "Ep:145, loss:0.00001, loss_test:0.13904, lr:2.90e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.420, tt:2835.378\n",
      "Ep:146, loss:0.00001, loss_test:0.13909, lr:2.88e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.415, tt:2854.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.13915, lr:2.85e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.424, tt:2874.768\n",
      "Ep:148, loss:0.00001, loss_test:0.13915, lr:2.82e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.438, tt:2896.282\n",
      "Ep:149, loss:0.00001, loss_test:0.13938, lr:2.79e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.442, tt:2916.373\n",
      "Ep:150, loss:0.00001, loss_test:0.13900, lr:2.76e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.454, tt:2937.528\n",
      "Ep:151, loss:0.00001, loss_test:0.13978, lr:2.73e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.457, tt:2957.467\n",
      "Ep:152, loss:0.00001, loss_test:0.13982, lr:2.71e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.462, tt:2977.725\n",
      "Ep:153, loss:0.00001, loss_test:0.13930, lr:2.68e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.469, tt:2998.200\n",
      "Ep:154, loss:0.00001, loss_test:0.13926, lr:2.65e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.463, tt:3016.808\n",
      "Ep:155, loss:0.00001, loss_test:0.13934, lr:2.63e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.472, tt:3037.678\n",
      "Ep:156, loss:0.00001, loss_test:0.13955, lr:2.60e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.486, tt:3059.328\n",
      "Ep:157, loss:0.00001, loss_test:0.13981, lr:2.57e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.495, tt:3080.227\n",
      "Ep:158, loss:0.00001, loss_test:0.14005, lr:2.55e-03, fs:0.62420 (r=0.495,p=0.845),  time:19.500, tt:3100.462\n",
      "Ep:159, loss:0.00001, loss_test:0.13957, lr:2.52e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.506, tt:3120.890\n",
      "Ep:160, loss:0.00001, loss_test:0.13978, lr:2.50e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.509, tt:3140.881\n",
      "Ep:161, loss:0.00001, loss_test:0.13986, lr:2.47e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.508, tt:3160.276\n",
      "Ep:162, loss:0.00001, loss_test:0.14009, lr:2.45e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.514, tt:3180.827\n",
      "Ep:163, loss:0.00001, loss_test:0.13985, lr:2.42e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.519, tt:3201.118\n",
      "Ep:164, loss:0.00001, loss_test:0.14034, lr:2.40e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.523, tt:3221.266\n",
      "Ep:165, loss:0.00001, loss_test:0.14001, lr:2.38e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.530, tt:3241.966\n",
      "Ep:166, loss:0.00001, loss_test:0.14071, lr:2.35e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.536, tt:3262.528\n",
      "Ep:167, loss:0.00001, loss_test:0.14044, lr:2.33e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.544, tt:3283.342\n",
      "Ep:168, loss:0.00001, loss_test:0.13958, lr:2.31e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.553, tt:3304.477\n",
      "Ep:169, loss:0.00001, loss_test:0.14101, lr:2.28e-03, fs:0.61538 (r=0.485,p=0.842),  time:19.566, tt:3326.243\n",
      "Ep:170, loss:0.00001, loss_test:0.14149, lr:2.26e-03, fs:0.61935 (r=0.485,p=0.857),  time:19.575, tt:3347.296\n",
      "Ep:171, loss:0.00001, loss_test:0.14102, lr:2.24e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.583, tt:3368.219\n",
      "Ep:172, loss:0.00001, loss_test:0.14006, lr:2.21e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.586, tt:3388.405\n",
      "Ep:173, loss:0.00001, loss_test:0.14086, lr:2.19e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.594, tt:3409.344\n",
      "Ep:174, loss:0.00001, loss_test:0.14109, lr:2.17e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.600, tt:3429.960\n",
      "Ep:175, loss:0.00001, loss_test:0.14070, lr:2.15e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.608, tt:3451.023\n",
      "Ep:176, loss:0.00001, loss_test:0.13997, lr:2.13e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.613, tt:3471.521\n",
      "Ep:177, loss:0.00001, loss_test:0.14079, lr:2.11e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.612, tt:3490.993\n",
      "Ep:178, loss:0.00001, loss_test:0.14150, lr:2.08e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.612, tt:3510.480\n",
      "Ep:179, loss:0.00001, loss_test:0.14144, lr:2.06e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.615, tt:3530.667\n",
      "Ep:180, loss:0.00001, loss_test:0.14069, lr:2.04e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.620, tt:3551.275\n",
      "Ep:181, loss:0.00001, loss_test:0.14002, lr:2.02e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:3571.080\n",
      "Ep:182, loss:0.00001, loss_test:0.14157, lr:2.00e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:3591.051\n",
      "Ep:183, loss:0.00000, loss_test:0.14225, lr:1.98e-03, fs:0.61538 (r=0.485,p=0.842),  time:19.623, tt:3610.650\n",
      "Ep:184, loss:0.00000, loss_test:0.14191, lr:1.96e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:3629.872\n",
      "Ep:185, loss:0.00000, loss_test:0.14099, lr:1.94e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:3649.543\n",
      "Ep:186, loss:0.00000, loss_test:0.14074, lr:1.92e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.618, tt:3668.595\n",
      "Ep:187, loss:0.00000, loss_test:0.14141, lr:1.90e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.626, tt:3689.634\n",
      "Ep:188, loss:0.00000, loss_test:0.14150, lr:1.89e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.619, tt:3707.940\n",
      "Ep:189, loss:0.00000, loss_test:0.14103, lr:1.87e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:3728.367\n",
      "Ep:190, loss:0.00000, loss_test:0.14072, lr:1.85e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:3747.963\n",
      "Ep:191, loss:0.00000, loss_test:0.14172, lr:1.83e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.615, tt:3766.158\n",
      "Ep:192, loss:0.00000, loss_test:0.14227, lr:1.81e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.615, tt:3785.724\n",
      "Ep:193, loss:0.00000, loss_test:0.14196, lr:1.79e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.616, tt:3805.468\n",
      "Ep:194, loss:0.00000, loss_test:0.14126, lr:1.78e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:3826.038\n",
      "Ep:195, loss:0.00000, loss_test:0.14099, lr:1.76e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:3846.031\n",
      "Ep:196, loss:0.00000, loss_test:0.14180, lr:1.74e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:3865.791\n",
      "Ep:197, loss:0.00000, loss_test:0.14200, lr:1.72e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.620, tt:3884.794\n",
      "Ep:198, loss:0.00000, loss_test:0.14152, lr:1.71e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.619, tt:3904.256\n",
      "Ep:199, loss:0.00000, loss_test:0.14160, lr:1.69e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.616, tt:3923.198\n",
      "Ep:200, loss:0.00000, loss_test:0.14172, lr:1.67e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.627, tt:3945.029\n",
      "Ep:201, loss:0.00000, loss_test:0.14135, lr:1.65e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.632, tt:3965.688\n",
      "Ep:202, loss:0.00000, loss_test:0.14120, lr:1.64e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.635, tt:3985.879\n",
      "Ep:203, loss:0.00000, loss_test:0.14190, lr:1.62e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.638, tt:4006.250\n",
      "Ep:204, loss:0.00000, loss_test:0.14195, lr:1.61e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.640, tt:4026.184\n",
      "Ep:205, loss:0.00000, loss_test:0.14144, lr:1.59e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.638, tt:4045.430\n",
      "Ep:206, loss:0.00000, loss_test:0.14138, lr:1.57e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.640, tt:4065.444\n",
      "Ep:207, loss:0.00000, loss_test:0.14154, lr:1.56e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.642, tt:4085.462\n",
      "Ep:208, loss:0.00000, loss_test:0.14121, lr:1.54e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.645, tt:4105.754\n",
      "Ep:209, loss:0.00000, loss_test:0.14163, lr:1.53e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.646, tt:4125.763\n",
      "Ep:210, loss:0.00000, loss_test:0.14190, lr:1.51e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.650, tt:4146.114\n",
      "Ep:211, loss:0.00000, loss_test:0.14157, lr:1.50e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.651, tt:4165.912\n",
      "Ep:212, loss:0.00000, loss_test:0.14151, lr:1.48e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.654, tt:4186.298\n",
      "Ep:213, loss:0.00000, loss_test:0.14132, lr:1.47e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.657, tt:4206.557\n",
      "Ep:214, loss:0.00000, loss_test:0.14191, lr:1.45e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.663, tt:4227.622\n",
      "Ep:215, loss:0.00000, loss_test:0.14182, lr:1.44e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.662, tt:4247.076\n",
      "Ep:216, loss:0.00000, loss_test:0.14182, lr:1.42e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.661, tt:4266.404\n",
      "Ep:217, loss:0.00000, loss_test:0.14175, lr:1.41e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.653, tt:4284.421\n",
      "Ep:218, loss:0.00000, loss_test:0.14137, lr:1.39e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.651, tt:4303.635\n",
      "Ep:219, loss:0.00000, loss_test:0.14151, lr:1.38e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.642, tt:4321.266\n",
      "Ep:220, loss:0.00000, loss_test:0.14164, lr:1.37e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.638, tt:4339.938\n",
      "Ep:221, loss:0.00000, loss_test:0.14148, lr:1.35e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.638, tt:4359.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:222, loss:0.00000, loss_test:0.14175, lr:1.34e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.632, tt:4378.037\n",
      "Ep:223, loss:0.00000, loss_test:0.14146, lr:1.33e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.636, tt:4398.512\n",
      "Ep:224, loss:0.00000, loss_test:0.14161, lr:1.31e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.628, tt:4416.243\n",
      "Ep:225, loss:0.00000, loss_test:0.14147, lr:1.30e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.630, tt:4436.467\n",
      "Ep:226, loss:0.00000, loss_test:0.14170, lr:1.29e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.629, tt:4455.846\n",
      "Ep:227, loss:0.00000, loss_test:0.14162, lr:1.27e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.627, tt:4475.051\n",
      "Ep:228, loss:0.00000, loss_test:0.14206, lr:1.26e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.633, tt:4496.030\n",
      "Ep:229, loss:0.00000, loss_test:0.14176, lr:1.25e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.630, tt:4514.989\n",
      "Ep:230, loss:0.00000, loss_test:0.14098, lr:1.24e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.634, tt:4535.562\n",
      "Ep:231, loss:0.00000, loss_test:0.14193, lr:1.22e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.635, tt:4555.218\n",
      "Ep:232, loss:0.00000, loss_test:0.14218, lr:1.21e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.629, tt:4573.607\n",
      "Ep:233, loss:0.00000, loss_test:0.14174, lr:1.20e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.633, tt:4594.102\n",
      "Ep:234, loss:0.00000, loss_test:0.14124, lr:1.19e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.631, tt:4613.249\n",
      "Ep:235, loss:0.00000, loss_test:0.14197, lr:1.18e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.631, tt:4632.997\n",
      "Ep:236, loss:0.00000, loss_test:0.14213, lr:1.16e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.632, tt:4652.819\n",
      "Ep:237, loss:0.00000, loss_test:0.14172, lr:1.15e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.631, tt:4672.144\n",
      "Ep:238, loss:0.00000, loss_test:0.14155, lr:1.14e-03, fs:0.62893 (r=0.505,p=0.833),  time:19.630, tt:4691.602\n",
      "Ep:239, loss:0.00000, loss_test:0.14188, lr:1.13e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.632, tt:4711.719\n",
      "Ep:240, loss:0.00000, loss_test:0.14201, lr:1.12e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.627, tt:4730.175\n",
      "Ep:241, loss:0.00000, loss_test:0.14163, lr:1.11e-03, fs:0.62025 (r=0.495,p=0.831),  time:19.627, tt:4749.623\n",
      "Ep:242, loss:0.00000, loss_test:0.14166, lr:1.10e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.628, tt:4769.663\n",
      "Ep:243, loss:0.00000, loss_test:0.14175, lr:1.08e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:4787.950\n",
      "Ep:244, loss:0.00000, loss_test:0.14166, lr:1.07e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:4807.557\n",
      "Ep:245, loss:0.00000, loss_test:0.14170, lr:1.06e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:4827.262\n",
      "Ep:246, loss:0.00000, loss_test:0.14157, lr:1.05e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.623, tt:4846.768\n",
      "Ep:247, loss:0.00000, loss_test:0.14154, lr:1.04e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.620, tt:4865.875\n",
      "Ep:248, loss:0.00000, loss_test:0.14170, lr:1.03e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.616, tt:4884.454\n",
      "Ep:249, loss:0.00000, loss_test:0.14141, lr:1.02e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.607, tt:4901.786\n",
      "Ep:250, loss:0.00000, loss_test:0.14194, lr:1.01e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.607, tt:4921.431\n",
      "Ep:251, loss:0.00000, loss_test:0.14188, lr:1.00e-03, fs:0.61146 (r=0.485,p=0.828),  time:19.605, tt:4940.355\n",
      "Ep:252, loss:0.00000, loss_test:0.14137, lr:9.91e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.602, tt:4959.317\n",
      "Ep:253, loss:0.00000, loss_test:0.14162, lr:9.81e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.629, tt:4985.876\n",
      "Ep:254, loss:0.00000, loss_test:0.14164, lr:9.71e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.628, tt:5005.021\n",
      "Ep:255, loss:0.00000, loss_test:0.14161, lr:9.62e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.622, tt:5023.335\n",
      "Ep:256, loss:0.00000, loss_test:0.14167, lr:9.52e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:5042.662\n",
      "Ep:257, loss:0.00000, loss_test:0.14147, lr:9.42e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:5062.314\n",
      "Ep:258, loss:0.00000, loss_test:0.14165, lr:9.33e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.620, tt:5081.484\n",
      "Ep:259, loss:0.00000, loss_test:0.14154, lr:9.24e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.619, tt:5100.867\n",
      "Ep:260, loss:0.00000, loss_test:0.14139, lr:9.14e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.616, tt:5119.906\n",
      "Ep:261, loss:0.00000, loss_test:0.14185, lr:9.05e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.614, tt:5138.950\n",
      "Ep:262, loss:0.00000, loss_test:0.14183, lr:8.96e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.614, tt:5158.561\n",
      "Ep:263, loss:0.00000, loss_test:0.14139, lr:8.87e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.615, tt:5178.255\n",
      "Ep:264, loss:0.00000, loss_test:0.14155, lr:8.78e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.617, tt:5198.463\n",
      "Ep:265, loss:0.00000, loss_test:0.14168, lr:8.70e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.621, tt:5219.277\n",
      "Ep:266, loss:0.00000, loss_test:0.14143, lr:8.61e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.617, tt:5237.836\n",
      "Ep:267, loss:0.00000, loss_test:0.14161, lr:8.52e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.608, tt:5254.860\n",
      "Ep:268, loss:0.00000, loss_test:0.14152, lr:8.44e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.602, tt:5272.911\n",
      "Ep:269, loss:0.00000, loss_test:0.14139, lr:8.35e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.604, tt:5293.093\n",
      "Ep:270, loss:0.00000, loss_test:0.14179, lr:8.27e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.603, tt:5312.299\n",
      "Ep:271, loss:0.00000, loss_test:0.14179, lr:8.19e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.602, tt:5331.691\n",
      "Ep:272, loss:0.00000, loss_test:0.14141, lr:8.11e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.601, tt:5351.135\n",
      "Ep:273, loss:0.00000, loss_test:0.14149, lr:8.02e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.599, tt:5370.218\n",
      "Ep:274, loss:0.00000, loss_test:0.14165, lr:7.94e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.593, tt:5388.003\n",
      "Ep:275, loss:0.00000, loss_test:0.14153, lr:7.87e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.594, tt:5407.852\n",
      "Ep:276, loss:0.00000, loss_test:0.14126, lr:7.79e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.591, tt:5426.695\n",
      "Ep:277, loss:0.00000, loss_test:0.14173, lr:7.71e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.589, tt:5445.734\n",
      "Ep:278, loss:0.00000, loss_test:0.14185, lr:7.63e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.585, tt:5464.351\n",
      "Ep:279, loss:0.00000, loss_test:0.14161, lr:7.56e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.584, tt:5483.540\n",
      "Ep:280, loss:0.00000, loss_test:0.14135, lr:7.48e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.578, tt:5501.460\n",
      "Ep:281, loss:0.00000, loss_test:0.14149, lr:7.40e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.580, tt:5521.439\n",
      "Ep:282, loss:0.00000, loss_test:0.14164, lr:7.33e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.580, tt:5541.083\n",
      "Ep:283, loss:0.00000, loss_test:0.14150, lr:7.26e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.580, tt:5560.614\n",
      "Ep:284, loss:0.00000, loss_test:0.14129, lr:7.18e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.575, tt:5578.885\n",
      "Ep:285, loss:0.00000, loss_test:0.14179, lr:7.11e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.576, tt:5598.813\n",
      "Ep:286, loss:0.00000, loss_test:0.14192, lr:7.04e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.573, tt:5617.448\n",
      "Ep:287, loss:0.00000, loss_test:0.14172, lr:6.97e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.575, tt:5637.587\n",
      "Ep:288, loss:0.00000, loss_test:0.14137, lr:6.90e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.576, tt:5657.534\n",
      "Ep:289, loss:0.00000, loss_test:0.14141, lr:6.83e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.575, tt:5676.738\n",
      "Ep:290, loss:0.00000, loss_test:0.14162, lr:6.76e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.576, tt:5696.547\n",
      "Ep:291, loss:0.00000, loss_test:0.14161, lr:6.70e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.572, tt:5714.898\n",
      "Ep:292, loss:0.00000, loss_test:0.14140, lr:6.63e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.574, tt:5735.249\n",
      "Ep:293, loss:0.00000, loss_test:0.14143, lr:6.56e-04, fs:0.61146 (r=0.485,p=0.828),  time:19.571, tt:5753.844\n",
      "Ep:294, loss:0.00000, loss_test:0.14168, lr:6.50e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.567, tt:5772.123\n",
      "Ep:295, loss:0.00000, loss_test:0.14167, lr:6.43e-04, fs:0.61538 (r=0.485,p=0.842),  time:19.555, tt:5788.173\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14272, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:15.129, tt:15.129\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14235, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:17.015, tt:34.031\n",
      "Ep:2, loss:0.00004, loss_test:0.14181, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:17.400, tt:52.199\n",
      "Ep:3, loss:0.00004, loss_test:0.14107, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:17.582, tt:70.326\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.14005, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:17.542, tt:87.708\n",
      "Ep:5, loss:0.00004, loss_test:0.13875, lr:1.00e-02, fs:0.65493 (r=0.939,p=0.503),  time:17.739, tt:106.435\n",
      "Ep:6, loss:0.00004, loss_test:0.13713, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:17.770, tt:124.387\n",
      "Ep:7, loss:0.00004, loss_test:0.13571, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:17.850, tt:142.798\n",
      "Ep:8, loss:0.00004, loss_test:0.13442, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:17.962, tt:161.657\n",
      "Ep:9, loss:0.00004, loss_test:0.13314, lr:1.00e-02, fs:0.65354 (r=0.838,p=0.535),  time:18.043, tt:180.429\n",
      "Ep:10, loss:0.00004, loss_test:0.13206, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:18.090, tt:198.986\n",
      "Ep:11, loss:0.00004, loss_test:0.13164, lr:1.00e-02, fs:0.61017 (r=0.727,p=0.526),  time:18.095, tt:217.145\n",
      "Ep:12, loss:0.00003, loss_test:0.13139, lr:1.00e-02, fs:0.59912 (r=0.687,p=0.531),  time:18.029, tt:234.377\n",
      "Ep:13, loss:0.00003, loss_test:0.13101, lr:1.00e-02, fs:0.59556 (r=0.677,p=0.532),  time:18.011, tt:252.161\n",
      "Ep:14, loss:0.00003, loss_test:0.13024, lr:1.00e-02, fs:0.59821 (r=0.677,p=0.536),  time:17.999, tt:269.984\n",
      "Ep:15, loss:0.00003, loss_test:0.12925, lr:9.90e-03, fs:0.60526 (r=0.697,p=0.535),  time:17.920, tt:286.720\n",
      "Ep:16, loss:0.00003, loss_test:0.12828, lr:9.80e-03, fs:0.61472 (r=0.717,p=0.538),  time:17.951, tt:305.171\n",
      "Ep:17, loss:0.00003, loss_test:0.12740, lr:9.70e-03, fs:0.61803 (r=0.727,p=0.537),  time:17.947, tt:323.041\n",
      "Ep:18, loss:0.00003, loss_test:0.12658, lr:9.61e-03, fs:0.62661 (r=0.737,p=0.545),  time:17.995, tt:341.908\n",
      "Ep:19, loss:0.00003, loss_test:0.12572, lr:9.51e-03, fs:0.62281 (r=0.717,p=0.550),  time:17.929, tt:358.575\n",
      "Ep:20, loss:0.00003, loss_test:0.12496, lr:9.41e-03, fs:0.60633 (r=0.677,p=0.549),  time:17.870, tt:375.262\n",
      "Ep:21, loss:0.00003, loss_test:0.12400, lr:9.32e-03, fs:0.60748 (r=0.657,p=0.565),  time:17.831, tt:392.288\n",
      "Ep:22, loss:0.00003, loss_test:0.12284, lr:9.23e-03, fs:0.61905 (r=0.657,p=0.586),  time:17.748, tt:408.193\n",
      "Ep:23, loss:0.00003, loss_test:0.12157, lr:9.14e-03, fs:0.62857 (r=0.667,p=0.595),  time:17.661, tt:423.863\n",
      "Ep:24, loss:0.00003, loss_test:0.12038, lr:9.04e-03, fs:0.62559 (r=0.667,p=0.589),  time:17.691, tt:442.286\n",
      "Ep:25, loss:0.00003, loss_test:0.11930, lr:8.95e-03, fs:0.64789 (r=0.697,p=0.605),  time:17.658, tt:459.103\n",
      "Ep:26, loss:0.00003, loss_test:0.11815, lr:8.86e-03, fs:0.65421 (r=0.707,p=0.609),  time:17.647, tt:476.466\n",
      "Ep:27, loss:0.00003, loss_test:0.11682, lr:8.78e-03, fs:0.66981 (r=0.717,p=0.628),  time:17.590, tt:492.529\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.11571, lr:8.78e-03, fs:0.67299 (r=0.717,p=0.634),  time:17.543, tt:508.745\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.11498, lr:8.78e-03, fs:0.68246 (r=0.727,p=0.643),  time:17.523, tt:525.684\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.11450, lr:8.78e-03, fs:0.68545 (r=0.737,p=0.640),  time:17.476, tt:541.745\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.11395, lr:8.78e-03, fs:0.70093 (r=0.758,p=0.652),  time:17.470, tt:559.034\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.11313, lr:8.78e-03, fs:0.71698 (r=0.768,p=0.673),  time:17.454, tt:575.995\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.11227, lr:8.78e-03, fs:0.72381 (r=0.768,p=0.685),  time:17.492, tt:594.719\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.11141, lr:8.78e-03, fs:0.71154 (r=0.747,p=0.679),  time:17.443, tt:610.517\n",
      "Ep:35, loss:0.00002, loss_test:0.11066, lr:8.78e-03, fs:0.70244 (r=0.727,p=0.679),  time:17.391, tt:626.076\n",
      "Ep:36, loss:0.00002, loss_test:0.11013, lr:8.78e-03, fs:0.70874 (r=0.737,p=0.682),  time:17.373, tt:642.784\n",
      "Ep:37, loss:0.00002, loss_test:0.11000, lr:8.78e-03, fs:0.69307 (r=0.707,p=0.680),  time:17.366, tt:659.916\n",
      "Ep:38, loss:0.00002, loss_test:0.10992, lr:8.78e-03, fs:0.67662 (r=0.687,p=0.667),  time:17.367, tt:677.332\n",
      "Ep:39, loss:0.00002, loss_test:0.10973, lr:8.78e-03, fs:0.68317 (r=0.697,p=0.670),  time:17.345, tt:693.804\n",
      "Ep:40, loss:0.00002, loss_test:0.10931, lr:8.78e-03, fs:0.68342 (r=0.687,p=0.680),  time:17.357, tt:711.635\n",
      "Ep:41, loss:0.00002, loss_test:0.10865, lr:8.78e-03, fs:0.68342 (r=0.687,p=0.680),  time:17.347, tt:728.571\n",
      "Ep:42, loss:0.00002, loss_test:0.10820, lr:8.78e-03, fs:0.68342 (r=0.687,p=0.680),  time:17.332, tt:745.266\n",
      "Ep:43, loss:0.00002, loss_test:0.10794, lr:8.78e-03, fs:0.69000 (r=0.697,p=0.683),  time:17.323, tt:762.214\n",
      "Ep:44, loss:0.00002, loss_test:0.10774, lr:8.78e-03, fs:0.69951 (r=0.717,p=0.683),  time:17.329, tt:779.793\n",
      "Ep:45, loss:0.00002, loss_test:0.10764, lr:8.69e-03, fs:0.69652 (r=0.707,p=0.686),  time:17.312, tt:796.348\n",
      "Ep:46, loss:0.00002, loss_test:0.10762, lr:8.60e-03, fs:0.69347 (r=0.697,p=0.690),  time:17.318, tt:813.928\n",
      "Ep:47, loss:0.00002, loss_test:0.10746, lr:8.51e-03, fs:0.69388 (r=0.687,p=0.701),  time:17.319, tt:831.302\n",
      "Ep:48, loss:0.00002, loss_test:0.10718, lr:8.43e-03, fs:0.70051 (r=0.697,p=0.704),  time:17.324, tt:848.862\n",
      "Ep:49, loss:0.00002, loss_test:0.10699, lr:8.35e-03, fs:0.70408 (r=0.697,p=0.711),  time:17.293, tt:864.673\n",
      "Ep:50, loss:0.00002, loss_test:0.10702, lr:8.26e-03, fs:0.70408 (r=0.697,p=0.711),  time:17.271, tt:880.807\n",
      "Ep:51, loss:0.00002, loss_test:0.10719, lr:8.18e-03, fs:0.70103 (r=0.687,p=0.716),  time:17.269, tt:897.970\n",
      "Ep:52, loss:0.00002, loss_test:0.10710, lr:8.10e-03, fs:0.70833 (r=0.687,p=0.731),  time:17.236, tt:913.505\n",
      "Ep:53, loss:0.00002, loss_test:0.10669, lr:8.02e-03, fs:0.70833 (r=0.687,p=0.731),  time:17.220, tt:929.879\n",
      "Ep:54, loss:0.00002, loss_test:0.10633, lr:7.94e-03, fs:0.70157 (r=0.677,p=0.728),  time:17.199, tt:945.935\n",
      "Ep:55, loss:0.00002, loss_test:0.10621, lr:7.86e-03, fs:0.70157 (r=0.677,p=0.728),  time:17.190, tt:962.618\n",
      "Ep:56, loss:0.00002, loss_test:0.10616, lr:7.78e-03, fs:0.70157 (r=0.677,p=0.728),  time:17.208, tt:980.849\n",
      "Ep:57, loss:0.00002, loss_test:0.10585, lr:7.70e-03, fs:0.71875 (r=0.697,p=0.742),  time:17.206, tt:997.936\n",
      "Ep:58, loss:0.00002, loss_test:0.10547, lr:7.62e-03, fs:0.71503 (r=0.697,p=0.734),  time:17.228, tt:1016.471\n",
      "Ep:59, loss:0.00002, loss_test:0.10536, lr:7.55e-03, fs:0.70833 (r=0.687,p=0.731),  time:17.248, tt:1034.861\n",
      "Ep:60, loss:0.00002, loss_test:0.10548, lr:7.47e-03, fs:0.69841 (r=0.667,p=0.733),  time:17.262, tt:1052.977\n",
      "Ep:61, loss:0.00001, loss_test:0.10549, lr:7.40e-03, fs:0.70526 (r=0.677,p=0.736),  time:17.262, tt:1070.255\n",
      "Ep:62, loss:0.00001, loss_test:0.10532, lr:7.32e-03, fs:0.70526 (r=0.677,p=0.736),  time:17.275, tt:1088.334\n",
      "Ep:63, loss:0.00001, loss_test:0.10523, lr:7.25e-03, fs:0.69841 (r=0.667,p=0.733),  time:17.292, tt:1106.702\n",
      "Ep:64, loss:0.00001, loss_test:0.10540, lr:7.18e-03, fs:0.69841 (r=0.667,p=0.733),  time:17.302, tt:1124.627\n",
      "Ep:65, loss:0.00001, loss_test:0.10550, lr:7.11e-03, fs:0.70526 (r=0.677,p=0.736),  time:17.308, tt:1142.351\n",
      "Ep:66, loss:0.00001, loss_test:0.10565, lr:7.03e-03, fs:0.69841 (r=0.667,p=0.733),  time:17.317, tt:1160.211\n",
      "Ep:67, loss:0.00001, loss_test:0.10568, lr:6.96e-03, fs:0.69149 (r=0.657,p=0.730),  time:17.327, tt:1178.258\n",
      "Ep:68, loss:0.00001, loss_test:0.10562, lr:6.89e-03, fs:0.68449 (r=0.646,p=0.727),  time:17.340, tt:1196.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.10558, lr:6.83e-03, fs:0.69149 (r=0.657,p=0.730),  time:17.358, tt:1215.032\n",
      "Ep:70, loss:0.00001, loss_test:0.10550, lr:6.76e-03, fs:0.68085 (r=0.646,p=0.719),  time:17.376, tt:1233.729\n",
      "Ep:71, loss:0.00001, loss_test:0.10549, lr:6.69e-03, fs:0.67742 (r=0.636,p=0.724),  time:17.386, tt:1251.808\n",
      "Ep:72, loss:0.00001, loss_test:0.10549, lr:6.62e-03, fs:0.66667 (r=0.616,p=0.726),  time:17.397, tt:1269.979\n",
      "Ep:73, loss:0.00001, loss_test:0.10532, lr:6.56e-03, fs:0.67027 (r=0.626,p=0.721),  time:17.387, tt:1286.614\n",
      "Ep:74, loss:0.00001, loss_test:0.10540, lr:6.49e-03, fs:0.65217 (r=0.606,p=0.706),  time:17.400, tt:1305.009\n",
      "Ep:75, loss:0.00001, loss_test:0.10555, lr:6.43e-03, fs:0.65574 (r=0.606,p=0.714),  time:17.410, tt:1323.172\n",
      "Ep:76, loss:0.00001, loss_test:0.10562, lr:6.36e-03, fs:0.65574 (r=0.606,p=0.714),  time:17.422, tt:1341.459\n",
      "Ep:77, loss:0.00001, loss_test:0.10575, lr:6.30e-03, fs:0.64481 (r=0.596,p=0.702),  time:17.435, tt:1359.942\n",
      "Ep:78, loss:0.00001, loss_test:0.10599, lr:6.24e-03, fs:0.64835 (r=0.596,p=0.711),  time:17.435, tt:1377.349\n",
      "Ep:79, loss:0.00001, loss_test:0.10600, lr:6.17e-03, fs:0.64835 (r=0.596,p=0.711),  time:17.446, tt:1395.701\n",
      "Ep:80, loss:0.00001, loss_test:0.10607, lr:6.11e-03, fs:0.64481 (r=0.596,p=0.702),  time:17.452, tt:1413.629\n",
      "Ep:81, loss:0.00001, loss_test:0.10616, lr:6.05e-03, fs:0.64481 (r=0.596,p=0.702),  time:17.475, tt:1432.944\n",
      "Ep:82, loss:0.00001, loss_test:0.10632, lr:5.99e-03, fs:0.63736 (r=0.586,p=0.699),  time:17.485, tt:1451.291\n",
      "Ep:83, loss:0.00001, loss_test:0.10640, lr:5.93e-03, fs:0.63736 (r=0.586,p=0.699),  time:17.504, tt:1470.295\n",
      "Ep:84, loss:0.00001, loss_test:0.10664, lr:5.87e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.512, tt:1488.490\n",
      "Ep:85, loss:0.00001, loss_test:0.10653, lr:5.81e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.524, tt:1507.085\n",
      "Ep:86, loss:0.00001, loss_test:0.10681, lr:5.75e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.532, tt:1525.277\n",
      "Ep:87, loss:0.00001, loss_test:0.10699, lr:5.70e-03, fs:0.63736 (r=0.586,p=0.699),  time:17.536, tt:1543.175\n",
      "Ep:88, loss:0.00001, loss_test:0.10709, lr:5.64e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.543, tt:1561.318\n",
      "Ep:89, loss:0.00001, loss_test:0.10723, lr:5.58e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.551, tt:1579.605\n",
      "Ep:90, loss:0.00001, loss_test:0.10703, lr:5.53e-03, fs:0.63736 (r=0.586,p=0.699),  time:17.564, tt:1598.288\n",
      "Ep:91, loss:0.00001, loss_test:0.10759, lr:5.47e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.568, tt:1616.221\n",
      "Ep:92, loss:0.00001, loss_test:0.10728, lr:5.42e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.574, tt:1634.381\n",
      "Ep:93, loss:0.00001, loss_test:0.10768, lr:5.36e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.591, tt:1653.588\n",
      "Ep:94, loss:0.00001, loss_test:0.10801, lr:5.31e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.599, tt:1671.860\n",
      "Ep:95, loss:0.00001, loss_test:0.10771, lr:5.26e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.603, tt:1689.855\n",
      "Ep:96, loss:0.00001, loss_test:0.10795, lr:5.20e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.611, tt:1708.287\n",
      "Ep:97, loss:0.00001, loss_test:0.10867, lr:5.15e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.616, tt:1726.321\n",
      "Ep:98, loss:0.00001, loss_test:0.10846, lr:5.10e-03, fs:0.64088 (r=0.586,p=0.707),  time:17.616, tt:1744.021\n",
      "Ep:99, loss:0.00001, loss_test:0.10865, lr:5.05e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.619, tt:1761.912\n",
      "Ep:100, loss:0.00001, loss_test:0.10873, lr:5.00e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.625, tt:1780.079\n",
      "Ep:101, loss:0.00001, loss_test:0.10901, lr:4.95e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.628, tt:1798.056\n",
      "Ep:102, loss:0.00001, loss_test:0.10901, lr:4.90e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.627, tt:1815.559\n",
      "Ep:103, loss:0.00001, loss_test:0.10920, lr:4.85e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.616, tt:1832.078\n",
      "Ep:104, loss:0.00001, loss_test:0.10939, lr:4.80e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.618, tt:1849.857\n",
      "Ep:105, loss:0.00001, loss_test:0.10933, lr:4.75e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.616, tt:1867.349\n",
      "Ep:106, loss:0.00001, loss_test:0.10935, lr:4.71e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.622, tt:1885.603\n",
      "Ep:107, loss:0.00001, loss_test:0.10902, lr:4.66e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.628, tt:1903.830\n",
      "Ep:108, loss:0.00001, loss_test:0.11023, lr:4.61e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.640, tt:1922.712\n",
      "Ep:109, loss:0.00001, loss_test:0.11023, lr:4.57e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.640, tt:1940.400\n",
      "Ep:110, loss:0.00001, loss_test:0.10954, lr:4.52e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.639, tt:1957.900\n",
      "Ep:111, loss:0.00001, loss_test:0.11004, lr:4.48e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.648, tt:1976.546\n",
      "Ep:112, loss:0.00001, loss_test:0.10989, lr:4.43e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.650, tt:1994.449\n",
      "Ep:113, loss:0.00001, loss_test:0.10981, lr:4.39e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.659, tt:2013.140\n",
      "Ep:114, loss:0.00001, loss_test:0.11055, lr:4.34e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.660, tt:2030.955\n",
      "Ep:115, loss:0.00001, loss_test:0.11066, lr:4.30e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.652, tt:2047.640\n",
      "Ep:116, loss:0.00001, loss_test:0.11007, lr:4.26e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.654, tt:2065.547\n",
      "Ep:117, loss:0.00001, loss_test:0.11067, lr:4.21e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.664, tt:2084.341\n",
      "Ep:118, loss:0.00001, loss_test:0.11104, lr:4.17e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.666, tt:2102.271\n",
      "Ep:119, loss:0.00001, loss_test:0.11066, lr:4.13e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.676, tt:2121.132\n",
      "Ep:120, loss:0.00001, loss_test:0.11047, lr:4.09e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.677, tt:2138.875\n",
      "Ep:121, loss:0.00001, loss_test:0.11118, lr:4.05e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.679, tt:2156.850\n",
      "Ep:122, loss:0.00001, loss_test:0.11112, lr:4.01e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.672, tt:2173.685\n",
      "Ep:123, loss:0.00001, loss_test:0.11061, lr:3.97e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.671, tt:2191.224\n",
      "Ep:124, loss:0.00001, loss_test:0.11108, lr:3.93e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.670, tt:2208.703\n",
      "Ep:125, loss:0.00001, loss_test:0.11106, lr:3.89e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.674, tt:2226.976\n",
      "Ep:126, loss:0.00001, loss_test:0.11070, lr:3.85e-03, fs:0.62637 (r=0.576,p=0.687),  time:17.668, tt:2243.843\n",
      "Ep:127, loss:0.00001, loss_test:0.11169, lr:3.81e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.673, tt:2262.155\n",
      "Ep:128, loss:0.00001, loss_test:0.11194, lr:3.77e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.670, tt:2279.474\n",
      "Ep:129, loss:0.00001, loss_test:0.11148, lr:3.73e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.668, tt:2296.836\n",
      "Ep:130, loss:0.00001, loss_test:0.11130, lr:3.70e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.670, tt:2314.707\n",
      "Ep:131, loss:0.00001, loss_test:0.11187, lr:3.66e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.672, tt:2332.650\n",
      "Ep:132, loss:0.00001, loss_test:0.11183, lr:3.62e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.672, tt:2350.372\n",
      "Ep:133, loss:0.00001, loss_test:0.11143, lr:3.59e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.668, tt:2367.542\n",
      "Ep:134, loss:0.00001, loss_test:0.11128, lr:3.55e-03, fs:0.62983 (r=0.576,p=0.695),  time:17.678, tt:2386.505\n",
      "Ep:135, loss:0.00001, loss_test:0.11230, lr:3.52e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.676, tt:2403.924\n",
      "Ep:136, loss:0.00001, loss_test:0.11247, lr:3.48e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.684, tt:2422.770\n",
      "Ep:137, loss:0.00001, loss_test:0.11202, lr:3.45e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.685, tt:2440.517\n",
      "Ep:138, loss:0.00001, loss_test:0.11184, lr:3.41e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.688, tt:2458.632\n",
      "Ep:139, loss:0.00001, loss_test:0.11189, lr:3.38e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.698, tt:2477.767\n",
      "Ep:140, loss:0.00001, loss_test:0.11216, lr:3.34e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.706, tt:2496.534\n",
      "Ep:141, loss:0.00001, loss_test:0.11230, lr:3.31e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.719, tt:2516.141\n",
      "Ep:142, loss:0.00001, loss_test:0.11266, lr:3.28e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.731, tt:2535.535\n",
      "Ep:143, loss:0.00001, loss_test:0.11278, lr:3.24e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.735, tt:2553.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.11255, lr:3.21e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.744, tt:2572.857\n",
      "Ep:145, loss:0.00001, loss_test:0.11260, lr:3.18e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.754, tt:2592.100\n",
      "Ep:146, loss:0.00001, loss_test:0.11272, lr:3.15e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.774, tt:2612.778\n",
      "Ep:147, loss:0.00001, loss_test:0.11262, lr:3.12e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.785, tt:2632.206\n",
      "Ep:148, loss:0.00001, loss_test:0.11271, lr:3.09e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.794, tt:2651.316\n",
      "Ep:149, loss:0.00001, loss_test:0.11304, lr:3.05e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.808, tt:2671.167\n",
      "Ep:150, loss:0.00001, loss_test:0.11329, lr:3.02e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.827, tt:2691.856\n",
      "Ep:151, loss:0.00001, loss_test:0.11322, lr:2.99e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.834, tt:2710.780\n",
      "Ep:152, loss:0.00001, loss_test:0.11306, lr:2.96e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.840, tt:2729.459\n",
      "Ep:153, loss:0.00001, loss_test:0.11340, lr:2.93e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.852, tt:2749.132\n",
      "Ep:154, loss:0.00001, loss_test:0.11350, lr:2.90e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.863, tt:2768.705\n",
      "Ep:155, loss:0.00001, loss_test:0.11344, lr:2.88e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.866, tt:2787.086\n",
      "Ep:156, loss:0.00001, loss_test:0.11376, lr:2.85e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.881, tt:2807.273\n",
      "Ep:157, loss:0.00001, loss_test:0.11369, lr:2.82e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.895, tt:2827.390\n",
      "Ep:158, loss:0.00001, loss_test:0.11360, lr:2.79e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.903, tt:2846.650\n",
      "Ep:159, loss:0.00001, loss_test:0.11417, lr:2.76e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.914, tt:2866.193\n",
      "Ep:160, loss:0.00001, loss_test:0.11419, lr:2.73e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.918, tt:2884.805\n",
      "Ep:161, loss:0.00001, loss_test:0.11382, lr:2.71e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.926, tt:2903.999\n",
      "Ep:162, loss:0.00001, loss_test:0.11395, lr:2.68e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.926, tt:2921.955\n",
      "Ep:163, loss:0.00001, loss_test:0.11416, lr:2.65e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.936, tt:2941.491\n",
      "Ep:164, loss:0.00001, loss_test:0.11406, lr:2.63e-03, fs:0.63333 (r=0.576,p=0.704),  time:17.948, tt:2961.491\n",
      "Ep:165, loss:0.00001, loss_test:0.11414, lr:2.60e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.955, tt:2980.573\n",
      "Ep:166, loss:0.00001, loss_test:0.11416, lr:2.57e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.971, tt:3001.177\n",
      "Ep:167, loss:0.00001, loss_test:0.11410, lr:2.55e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.983, tt:3021.220\n",
      "Ep:168, loss:0.00001, loss_test:0.11430, lr:2.52e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.993, tt:3040.866\n",
      "Ep:169, loss:0.00001, loss_test:0.11426, lr:2.50e-03, fs:0.63687 (r=0.576,p=0.713),  time:17.999, tt:3059.751\n",
      "Ep:170, loss:0.00001, loss_test:0.11419, lr:2.47e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.008, tt:3079.297\n",
      "Ep:171, loss:0.00001, loss_test:0.11429, lr:2.45e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.021, tt:3099.536\n",
      "Ep:172, loss:0.00001, loss_test:0.11434, lr:2.42e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.025, tt:3118.315\n",
      "Ep:173, loss:0.00001, loss_test:0.11427, lr:2.40e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.033, tt:3137.743\n",
      "Ep:174, loss:0.00001, loss_test:0.11483, lr:2.38e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.040, tt:3157.053\n",
      "Ep:175, loss:0.00001, loss_test:0.11491, lr:2.35e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.051, tt:3177.048\n",
      "Ep:176, loss:0.00001, loss_test:0.11461, lr:2.33e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.058, tt:3196.307\n",
      "Ep:177, loss:0.00001, loss_test:0.11435, lr:2.31e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.061, tt:3214.915\n",
      "Ep:178, loss:0.00001, loss_test:0.11512, lr:2.28e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.067, tt:3233.932\n",
      "Ep:179, loss:0.00001, loss_test:0.11527, lr:2.26e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.060, tt:3250.725\n",
      "Ep:180, loss:0.00001, loss_test:0.11486, lr:2.24e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.060, tt:3268.895\n",
      "Ep:181, loss:0.00001, loss_test:0.11458, lr:2.21e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.061, tt:3287.088\n",
      "Ep:182, loss:0.00001, loss_test:0.11508, lr:2.19e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.058, tt:3304.628\n",
      "Ep:183, loss:0.00001, loss_test:0.11532, lr:2.17e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.053, tt:3321.708\n",
      "Ep:184, loss:0.00001, loss_test:0.11499, lr:2.15e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.057, tt:3340.532\n",
      "Ep:185, loss:0.00001, loss_test:0.11452, lr:2.13e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.061, tt:3359.323\n",
      "Ep:186, loss:0.00001, loss_test:0.11528, lr:2.11e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.062, tt:3377.670\n",
      "Ep:187, loss:0.00001, loss_test:0.11571, lr:2.08e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.065, tt:3396.273\n",
      "Ep:188, loss:0.00001, loss_test:0.11560, lr:2.06e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.077, tt:3416.577\n",
      "Ep:189, loss:0.00001, loss_test:0.11511, lr:2.04e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.078, tt:3434.856\n",
      "Ep:190, loss:0.00001, loss_test:0.11490, lr:2.02e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.072, tt:3451.687\n",
      "Ep:191, loss:0.00001, loss_test:0.11542, lr:2.00e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.082, tt:3471.711\n",
      "Ep:192, loss:0.00001, loss_test:0.11573, lr:1.98e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.088, tt:3490.933\n",
      "Ep:193, loss:0.00001, loss_test:0.11557, lr:1.96e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.086, tt:3508.752\n",
      "Ep:194, loss:0.00001, loss_test:0.11533, lr:1.94e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.088, tt:3527.211\n",
      "Ep:195, loss:0.00001, loss_test:0.11537, lr:1.92e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.085, tt:3544.642\n",
      "Ep:196, loss:0.00001, loss_test:0.11570, lr:1.90e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.080, tt:3561.717\n",
      "Ep:197, loss:0.00001, loss_test:0.11586, lr:1.89e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.076, tt:3579.067\n",
      "Ep:198, loss:0.00001, loss_test:0.11557, lr:1.87e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.072, tt:3596.258\n",
      "Ep:199, loss:0.00001, loss_test:0.11532, lr:1.85e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.067, tt:3613.351\n",
      "Ep:200, loss:0.00001, loss_test:0.11568, lr:1.83e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.065, tt:3631.075\n",
      "Ep:201, loss:0.00001, loss_test:0.11607, lr:1.81e-03, fs:0.64000 (r=0.566,p=0.737),  time:18.065, tt:3649.178\n",
      "Ep:202, loss:0.00001, loss_test:0.11621, lr:1.79e-03, fs:0.64000 (r=0.566,p=0.737),  time:18.073, tt:3668.813\n",
      "Ep:203, loss:0.00001, loss_test:0.11592, lr:1.78e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.084, tt:3689.045\n",
      "Ep:204, loss:0.00001, loss_test:0.11569, lr:1.76e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.083, tt:3706.937\n",
      "Ep:205, loss:0.00001, loss_test:0.11575, lr:1.74e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.075, tt:3723.535\n",
      "Ep:206, loss:0.00001, loss_test:0.11603, lr:1.72e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.071, tt:3740.603\n",
      "Ep:207, loss:0.00001, loss_test:0.11611, lr:1.71e-03, fs:0.63636 (r=0.566,p=0.727),  time:18.066, tt:3757.679\n",
      "Ep:208, loss:0.00001, loss_test:0.11603, lr:1.69e-03, fs:0.63277 (r=0.566,p=0.718),  time:18.066, tt:3775.743\n",
      "Ep:209, loss:0.00001, loss_test:0.11601, lr:1.67e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.065, tt:3793.642\n",
      "Ep:210, loss:0.00001, loss_test:0.11606, lr:1.65e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.057, tt:3809.927\n",
      "Ep:211, loss:0.00001, loss_test:0.11610, lr:1.64e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.053, tt:3827.294\n",
      "Ep:212, loss:0.00001, loss_test:0.11608, lr:1.62e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.046, tt:3843.838\n",
      "Ep:213, loss:0.00001, loss_test:0.11615, lr:1.61e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.038, tt:3860.233\n",
      "Ep:214, loss:0.00001, loss_test:0.11631, lr:1.59e-03, fs:0.64000 (r=0.566,p=0.737),  time:18.034, tt:3877.416\n",
      "Ep:215, loss:0.00001, loss_test:0.11629, lr:1.57e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.025, tt:3893.448\n",
      "Ep:216, loss:0.00001, loss_test:0.11625, lr:1.56e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.014, tt:3909.098\n",
      "Ep:217, loss:0.00001, loss_test:0.11638, lr:1.54e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.000, tt:3923.967\n",
      "Ep:218, loss:0.00001, loss_test:0.11660, lr:1.53e-03, fs:0.64000 (r=0.566,p=0.737),  time:17.994, tt:3940.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:219, loss:0.00001, loss_test:0.11647, lr:1.51e-03, fs:0.64407 (r=0.576,p=0.731),  time:17.985, tt:3956.729\n",
      "Ep:220, loss:0.00001, loss_test:0.11635, lr:1.50e-03, fs:0.64407 (r=0.576,p=0.731),  time:17.983, tt:3974.322\n",
      "Ep:221, loss:0.00001, loss_test:0.11656, lr:1.48e-03, fs:0.64407 (r=0.576,p=0.731),  time:17.973, tt:3990.102\n",
      "Ep:222, loss:0.00001, loss_test:0.11670, lr:1.47e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.963, tt:4005.654\n",
      "Ep:223, loss:0.00001, loss_test:0.11653, lr:1.45e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.958, tt:4022.650\n",
      "Ep:224, loss:0.00001, loss_test:0.11638, lr:1.44e-03, fs:0.64407 (r=0.576,p=0.731),  time:17.951, tt:4038.904\n",
      "Ep:225, loss:0.00001, loss_test:0.11670, lr:1.42e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.944, tt:4055.235\n",
      "Ep:226, loss:0.00001, loss_test:0.11679, lr:1.41e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.929, tt:4069.813\n",
      "Ep:227, loss:0.00001, loss_test:0.11655, lr:1.39e-03, fs:0.64407 (r=0.576,p=0.731),  time:17.918, tt:4085.253\n",
      "Ep:228, loss:0.00001, loss_test:0.11646, lr:1.38e-03, fs:0.64407 (r=0.576,p=0.731),  time:17.906, tt:4100.534\n",
      "Ep:229, loss:0.00001, loss_test:0.11668, lr:1.37e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.898, tt:4116.481\n",
      "Ep:230, loss:0.00001, loss_test:0.11675, lr:1.35e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.889, tt:4132.295\n",
      "Ep:231, loss:0.00001, loss_test:0.11668, lr:1.34e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.882, tt:4148.530\n",
      "Ep:232, loss:0.00001, loss_test:0.11665, lr:1.33e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.879, tt:4165.730\n",
      "Ep:233, loss:0.00001, loss_test:0.11674, lr:1.31e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.871, tt:4181.866\n",
      "Ep:234, loss:0.00001, loss_test:0.11677, lr:1.30e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.872, tt:4199.836\n",
      "Ep:235, loss:0.00001, loss_test:0.11675, lr:1.29e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.872, tt:4217.890\n",
      "Ep:236, loss:0.00001, loss_test:0.11692, lr:1.27e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.869, tt:4234.982\n",
      "Ep:237, loss:0.00001, loss_test:0.11689, lr:1.26e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.873, tt:4253.693\n",
      "Ep:238, loss:0.00001, loss_test:0.11684, lr:1.25e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.868, tt:4270.555\n",
      "Ep:239, loss:0.00001, loss_test:0.11685, lr:1.24e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.872, tt:4289.258\n",
      "Ep:240, loss:0.00001, loss_test:0.11698, lr:1.22e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.875, tt:4307.801\n",
      "Ep:241, loss:0.00001, loss_test:0.11694, lr:1.21e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.878, tt:4326.559\n",
      "Ep:242, loss:0.00001, loss_test:0.11686, lr:1.20e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.880, tt:4344.942\n",
      "Ep:243, loss:0.00001, loss_test:0.11697, lr:1.19e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.884, tt:4363.589\n",
      "Ep:244, loss:0.00001, loss_test:0.11704, lr:1.18e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.887, tt:4382.275\n",
      "Ep:245, loss:0.00001, loss_test:0.11691, lr:1.16e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.889, tt:4400.690\n",
      "Ep:246, loss:0.00001, loss_test:0.11702, lr:1.15e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.891, tt:4419.070\n",
      "Ep:247, loss:0.00001, loss_test:0.11708, lr:1.14e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.892, tt:4437.212\n",
      "Ep:248, loss:0.00001, loss_test:0.11695, lr:1.13e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.897, tt:4456.243\n",
      "Ep:249, loss:0.00001, loss_test:0.11719, lr:1.12e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.902, tt:4475.500\n",
      "Ep:250, loss:0.00001, loss_test:0.11712, lr:1.11e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.906, tt:4494.432\n",
      "Ep:251, loss:0.00001, loss_test:0.11715, lr:1.10e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.906, tt:4512.391\n",
      "Ep:252, loss:0.00001, loss_test:0.11725, lr:1.08e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.912, tt:4531.797\n",
      "Ep:253, loss:0.00001, loss_test:0.11713, lr:1.07e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.916, tt:4550.648\n",
      "Ep:254, loss:0.00001, loss_test:0.11716, lr:1.06e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.922, tt:4570.054\n",
      "Ep:255, loss:0.00001, loss_test:0.11728, lr:1.05e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.925, tt:4588.769\n",
      "Ep:256, loss:0.00001, loss_test:0.11717, lr:1.04e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.933, tt:4608.892\n",
      "Ep:257, loss:0.00001, loss_test:0.11710, lr:1.03e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.934, tt:4627.035\n",
      "Ep:258, loss:0.00001, loss_test:0.11737, lr:1.02e-03, fs:0.65517 (r=0.576,p=0.760),  time:17.939, tt:4646.194\n",
      "Ep:259, loss:0.00001, loss_test:0.11735, lr:1.01e-03, fs:0.65517 (r=0.576,p=0.760),  time:17.943, tt:4665.276\n",
      "Ep:260, loss:0.00001, loss_test:0.11719, lr:1.00e-03, fs:0.65143 (r=0.576,p=0.750),  time:17.951, tt:4685.114\n",
      "Ep:261, loss:0.00001, loss_test:0.11722, lr:9.91e-04, fs:0.65143 (r=0.576,p=0.750),  time:17.959, tt:4705.177\n",
      "Ep:262, loss:0.00001, loss_test:0.11737, lr:9.81e-04, fs:0.65517 (r=0.576,p=0.760),  time:17.965, tt:4724.872\n",
      "Ep:263, loss:0.00001, loss_test:0.11731, lr:9.71e-04, fs:0.65143 (r=0.576,p=0.750),  time:17.969, tt:4743.719\n",
      "Ep:264, loss:0.00001, loss_test:0.11721, lr:9.62e-04, fs:0.65143 (r=0.576,p=0.750),  time:17.974, tt:4762.978\n",
      "Ep:265, loss:0.00001, loss_test:0.11732, lr:9.52e-04, fs:0.65517 (r=0.576,p=0.760),  time:17.982, tt:4783.080\n",
      "Ep:266, loss:0.00001, loss_test:0.11744, lr:9.42e-04, fs:0.65517 (r=0.576,p=0.760),  time:17.986, tt:4802.287\n",
      "Ep:267, loss:0.00001, loss_test:0.11735, lr:9.33e-04, fs:0.65143 (r=0.576,p=0.750),  time:17.995, tt:4822.596\n",
      "Ep:268, loss:0.00001, loss_test:0.11733, lr:9.24e-04, fs:0.65143 (r=0.576,p=0.750),  time:17.999, tt:4841.826\n",
      "Ep:269, loss:0.00001, loss_test:0.11739, lr:9.14e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.003, tt:4860.721\n",
      "Ep:270, loss:0.00001, loss_test:0.11738, lr:9.05e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.008, tt:4880.079\n",
      "Ep:271, loss:0.00001, loss_test:0.11737, lr:8.96e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.012, tt:4899.199\n",
      "Ep:272, loss:0.00001, loss_test:0.11742, lr:8.87e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.011, tt:4917.027\n",
      "Ep:273, loss:0.00001, loss_test:0.11731, lr:8.78e-04, fs:0.65143 (r=0.576,p=0.750),  time:18.017, tt:4936.522\n",
      "Ep:274, loss:0.00001, loss_test:0.11748, lr:8.70e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.017, tt:4954.674\n",
      "Ep:275, loss:0.00001, loss_test:0.11752, lr:8.61e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.014, tt:4971.791\n",
      "Ep:276, loss:0.00001, loss_test:0.11743, lr:8.52e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.020, tt:4991.541\n",
      "Ep:277, loss:0.00001, loss_test:0.11738, lr:8.44e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.029, tt:5012.043\n",
      "Ep:278, loss:0.00001, loss_test:0.11755, lr:8.35e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.033, tt:5031.166\n",
      "Ep:279, loss:0.00001, loss_test:0.11756, lr:8.27e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.035, tt:5049.868\n",
      "Ep:280, loss:0.00001, loss_test:0.11748, lr:8.19e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.041, tt:5069.446\n",
      "Ep:281, loss:0.00001, loss_test:0.11751, lr:8.11e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.044, tt:5088.394\n",
      "Ep:282, loss:0.00001, loss_test:0.11757, lr:8.02e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.049, tt:5107.897\n",
      "Ep:283, loss:0.00001, loss_test:0.11752, lr:7.94e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.051, tt:5126.571\n",
      "Ep:284, loss:0.00001, loss_test:0.11750, lr:7.87e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.051, tt:5144.525\n",
      "Ep:285, loss:0.00001, loss_test:0.11762, lr:7.79e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.048, tt:5161.725\n",
      "Ep:286, loss:0.00001, loss_test:0.11763, lr:7.71e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.050, tt:5180.343\n",
      "Ep:287, loss:0.00001, loss_test:0.11756, lr:7.63e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.050, tt:5198.402\n",
      "Ep:288, loss:0.00001, loss_test:0.11761, lr:7.56e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.051, tt:5216.659\n",
      "Ep:289, loss:0.00001, loss_test:0.11765, lr:7.48e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.052, tt:5235.007\n",
      "Ep:290, loss:0.00001, loss_test:0.11761, lr:7.40e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.056, tt:5254.257\n",
      "Ep:291, loss:0.00000, loss_test:0.11764, lr:7.33e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.050, tt:5270.568\n",
      "Ep:292, loss:0.00000, loss_test:0.11766, lr:7.26e-04, fs:0.65896 (r=0.576,p=0.770),  time:18.047, tt:5287.775\n",
      "Ep:293, loss:0.00000, loss_test:0.11767, lr:7.18e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.032, tt:5301.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:294, loss:0.00000, loss_test:0.11765, lr:7.11e-04, fs:0.65517 (r=0.576,p=0.760),  time:18.004, tt:5311.260\n",
      "Ep:295, loss:0.00000, loss_test:0.11774, lr:7.04e-04, fs:0.65896 (r=0.576,p=0.770),  time:17.988, tt:5324.498\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13784, lr:1.00e-02, fs:0.65660 (r=0.879,p=0.524),  time:17.386, tt:17.386\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13765, lr:1.00e-02, fs:0.64122 (r=0.848,p=0.515),  time:17.780, tt:35.560\n",
      "Ep:2, loss:0.00004, loss_test:0.13749, lr:1.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:17.784, tt:53.352\n",
      "Ep:3, loss:0.00004, loss_test:0.13727, lr:1.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:17.638, tt:70.553\n",
      "Ep:4, loss:0.00004, loss_test:0.13709, lr:1.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:17.567, tt:87.834\n",
      "Ep:5, loss:0.00004, loss_test:0.13688, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:17.422, tt:104.529\n",
      "Ep:6, loss:0.00004, loss_test:0.13668, lr:1.00e-02, fs:0.62698 (r=0.798,p=0.516),  time:17.399, tt:121.793\n",
      "Ep:7, loss:0.00004, loss_test:0.13632, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:17.520, tt:140.164\n",
      "Ep:8, loss:0.00004, loss_test:0.13587, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:17.613, tt:158.517\n",
      "Ep:9, loss:0.00004, loss_test:0.13532, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:17.601, tt:176.013\n",
      "Ep:10, loss:0.00004, loss_test:0.13467, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:17.549, tt:193.034\n",
      "Ep:11, loss:0.00004, loss_test:0.13390, lr:1.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:17.510, tt:210.124\n",
      "Ep:12, loss:0.00004, loss_test:0.13328, lr:9.90e-03, fs:0.63745 (r=0.808,p=0.526),  time:17.467, tt:227.075\n",
      "Ep:13, loss:0.00003, loss_test:0.13279, lr:9.80e-03, fs:0.63745 (r=0.808,p=0.526),  time:17.399, tt:243.591\n",
      "Ep:14, loss:0.00003, loss_test:0.13236, lr:9.70e-03, fs:0.64516 (r=0.808,p=0.537),  time:17.324, tt:259.866\n",
      "Ep:15, loss:0.00003, loss_test:0.13182, lr:9.61e-03, fs:0.65060 (r=0.818,p=0.540),  time:17.255, tt:276.074\n",
      "Ep:16, loss:0.00003, loss_test:0.13125, lr:9.51e-03, fs:0.65323 (r=0.818,p=0.544),  time:17.164, tt:291.790\n",
      "Ep:17, loss:0.00003, loss_test:0.13080, lr:9.41e-03, fs:0.65041 (r=0.808,p=0.544),  time:17.048, tt:306.865\n",
      "Ep:18, loss:0.00003, loss_test:0.13048, lr:9.32e-03, fs:0.65574 (r=0.808,p=0.552),  time:16.968, tt:322.386\n",
      "Ep:19, loss:0.00003, loss_test:0.13016, lr:9.23e-03, fs:0.65574 (r=0.808,p=0.552),  time:16.980, tt:339.591\n",
      "Ep:20, loss:0.00003, loss_test:0.12989, lr:9.14e-03, fs:0.65560 (r=0.798,p=0.556),  time:16.945, tt:355.851\n",
      "Ep:21, loss:0.00003, loss_test:0.12960, lr:9.04e-03, fs:0.65560 (r=0.798,p=0.556),  time:16.907, tt:371.962\n",
      "Ep:22, loss:0.00003, loss_test:0.12920, lr:8.95e-03, fs:0.65844 (r=0.808,p=0.556),  time:16.877, tt:388.160\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.12876, lr:8.95e-03, fs:0.66116 (r=0.808,p=0.559),  time:16.904, tt:405.690\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.12838, lr:8.95e-03, fs:0.66390 (r=0.808,p=0.563),  time:16.896, tt:422.395\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.12801, lr:8.95e-03, fs:0.66667 (r=0.808,p=0.567),  time:16.903, tt:439.483\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.12763, lr:8.95e-03, fs:0.65546 (r=0.788,p=0.561),  time:16.887, tt:455.948\n",
      "Ep:27, loss:0.00003, loss_test:0.12722, lr:8.95e-03, fs:0.63793 (r=0.747,p=0.556),  time:16.861, tt:472.119\n",
      "Ep:28, loss:0.00003, loss_test:0.12681, lr:8.95e-03, fs:0.62832 (r=0.717,p=0.559),  time:16.850, tt:488.659\n",
      "Ep:29, loss:0.00003, loss_test:0.12663, lr:8.95e-03, fs:0.60360 (r=0.677,p=0.545),  time:16.899, tt:506.977\n",
      "Ep:30, loss:0.00003, loss_test:0.12649, lr:8.95e-03, fs:0.61538 (r=0.687,p=0.557),  time:16.916, tt:524.399\n",
      "Ep:31, loss:0.00003, loss_test:0.12628, lr:8.95e-03, fs:0.60000 (r=0.667,p=0.545),  time:16.916, tt:541.320\n",
      "Ep:32, loss:0.00003, loss_test:0.12591, lr:8.95e-03, fs:0.60829 (r=0.667,p=0.559),  time:16.933, tt:558.789\n",
      "Ep:33, loss:0.00003, loss_test:0.12567, lr:8.95e-03, fs:0.61033 (r=0.657,p=0.570),  time:16.977, tt:577.225\n",
      "Ep:34, loss:0.00003, loss_test:0.12554, lr:8.95e-03, fs:0.60664 (r=0.646,p=0.571),  time:16.976, tt:594.149\n",
      "Ep:35, loss:0.00003, loss_test:0.12534, lr:8.95e-03, fs:0.60577 (r=0.636,p=0.578),  time:16.979, tt:611.256\n",
      "Ep:36, loss:0.00003, loss_test:0.12499, lr:8.95e-03, fs:0.61538 (r=0.646,p=0.587),  time:16.981, tt:628.284\n",
      "Ep:37, loss:0.00003, loss_test:0.12446, lr:8.86e-03, fs:0.60870 (r=0.636,p=0.583),  time:17.004, tt:646.153\n",
      "Ep:38, loss:0.00003, loss_test:0.12373, lr:8.78e-03, fs:0.60870 (r=0.636,p=0.583),  time:16.982, tt:662.298\n",
      "Ep:39, loss:0.00003, loss_test:0.12296, lr:8.69e-03, fs:0.61538 (r=0.646,p=0.587),  time:16.962, tt:678.466\n",
      "Ep:40, loss:0.00003, loss_test:0.12212, lr:8.60e-03, fs:0.61165 (r=0.636,p=0.589),  time:16.978, tt:696.098\n",
      "Ep:41, loss:0.00003, loss_test:0.12120, lr:8.51e-03, fs:0.61165 (r=0.636,p=0.589),  time:16.979, tt:713.126\n",
      "Ep:42, loss:0.00003, loss_test:0.12052, lr:8.43e-03, fs:0.60784 (r=0.626,p=0.590),  time:17.029, tt:732.245\n",
      "Ep:43, loss:0.00003, loss_test:0.11990, lr:8.35e-03, fs:0.60396 (r=0.616,p=0.592),  time:17.043, tt:749.896\n",
      "Ep:44, loss:0.00003, loss_test:0.11921, lr:8.26e-03, fs:0.60396 (r=0.616,p=0.592),  time:17.031, tt:766.375\n",
      "Ep:45, loss:0.00003, loss_test:0.11822, lr:8.18e-03, fs:0.60697 (r=0.616,p=0.598),  time:17.035, tt:783.610\n",
      "Ep:46, loss:0.00003, loss_test:0.11698, lr:8.10e-03, fs:0.60396 (r=0.616,p=0.592),  time:16.991, tt:798.599\n",
      "Ep:47, loss:0.00003, loss_test:0.11578, lr:8.02e-03, fs:0.60697 (r=0.616,p=0.598),  time:16.996, tt:815.799\n",
      "Ep:48, loss:0.00003, loss_test:0.11468, lr:7.94e-03, fs:0.62376 (r=0.636,p=0.612),  time:17.014, tt:833.689\n",
      "Ep:49, loss:0.00003, loss_test:0.11396, lr:7.86e-03, fs:0.63000 (r=0.636,p=0.624),  time:17.039, tt:851.964\n",
      "Ep:50, loss:0.00002, loss_test:0.11326, lr:7.78e-03, fs:0.62312 (r=0.626,p=0.620),  time:17.054, tt:869.765\n",
      "Ep:51, loss:0.00002, loss_test:0.11262, lr:7.70e-03, fs:0.62245 (r=0.616,p=0.629),  time:17.067, tt:887.468\n",
      "Ep:52, loss:0.00002, loss_test:0.11182, lr:7.62e-03, fs:0.62245 (r=0.616,p=0.629),  time:17.074, tt:904.915\n",
      "Ep:53, loss:0.00002, loss_test:0.11076, lr:7.55e-03, fs:0.62245 (r=0.616,p=0.629),  time:17.120, tt:924.505\n",
      "Ep:54, loss:0.00002, loss_test:0.10961, lr:7.47e-03, fs:0.63265 (r=0.626,p=0.639),  time:17.150, tt:943.260\n",
      "Ep:55, loss:0.00002, loss_test:0.10878, lr:7.40e-03, fs:0.64615 (r=0.636,p=0.656),  time:17.199, tt:963.166\n",
      "Ep:56, loss:0.00002, loss_test:0.10819, lr:7.32e-03, fs:0.64948 (r=0.636,p=0.663),  time:17.233, tt:982.302\n",
      "Ep:57, loss:0.00002, loss_test:0.10734, lr:7.25e-03, fs:0.64249 (r=0.626,p=0.660),  time:17.255, tt:1000.814\n",
      "Ep:58, loss:0.00002, loss_test:0.10637, lr:7.18e-03, fs:0.64249 (r=0.626,p=0.660),  time:17.285, tt:1019.843\n",
      "Ep:59, loss:0.00002, loss_test:0.10536, lr:7.11e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.326, tt:1039.562\n",
      "Ep:60, loss:0.00002, loss_test:0.10397, lr:7.03e-03, fs:0.66316 (r=0.636,p=0.692),  time:17.360, tt:1058.982\n",
      "Ep:61, loss:0.00002, loss_test:0.10285, lr:6.96e-03, fs:0.66316 (r=0.636,p=0.692),  time:17.389, tt:1078.108\n",
      "Ep:62, loss:0.00002, loss_test:0.10200, lr:6.89e-03, fs:0.68041 (r=0.667,p=0.695),  time:17.409, tt:1096.744\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.10109, lr:6.89e-03, fs:0.68718 (r=0.677,p=0.698),  time:17.427, tt:1115.308\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.10007, lr:6.89e-03, fs:0.69072 (r=0.677,p=0.705),  time:17.455, tt:1134.602\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.09935, lr:6.89e-03, fs:0.69430 (r=0.677,p=0.713),  time:17.473, tt:1153.208\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.09861, lr:6.89e-03, fs:0.70466 (r=0.687,p=0.723),  time:17.473, tt:1170.676\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.09762, lr:6.89e-03, fs:0.71503 (r=0.697,p=0.734),  time:17.492, tt:1189.425\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00002, loss_test:0.09686, lr:6.89e-03, fs:0.71875 (r=0.697,p=0.742),  time:17.516, tt:1208.625\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.09646, lr:6.89e-03, fs:0.72539 (r=0.707,p=0.745),  time:17.504, tt:1225.283\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.09592, lr:6.89e-03, fs:0.72539 (r=0.707,p=0.745),  time:17.498, tt:1242.389\n",
      "Ep:71, loss:0.00002, loss_test:0.09459, lr:6.89e-03, fs:0.73298 (r=0.707,p=0.761),  time:17.500, tt:1259.990\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.09349, lr:6.89e-03, fs:0.74611 (r=0.727,p=0.766),  time:17.495, tt:1277.108\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.09311, lr:6.89e-03, fs:0.73684 (r=0.707,p=0.769),  time:17.488, tt:1294.136\n",
      "Ep:74, loss:0.00002, loss_test:0.09243, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:17.473, tt:1310.457\n",
      "Ep:75, loss:0.00002, loss_test:0.09113, lr:6.89e-03, fs:0.74737 (r=0.717,p=0.780),  time:17.465, tt:1327.355\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.09010, lr:6.89e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.445, tt:1343.288\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.08976, lr:6.89e-03, fs:0.76190 (r=0.727,p=0.800),  time:17.424, tt:1359.063\n",
      "Ep:78, loss:0.00002, loss_test:0.08871, lr:6.89e-03, fs:0.76190 (r=0.727,p=0.800),  time:17.406, tt:1375.060\n",
      "Ep:79, loss:0.00002, loss_test:0.08763, lr:6.89e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.380, tt:1390.383\n",
      "Ep:80, loss:0.00002, loss_test:0.08718, lr:6.89e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.357, tt:1405.938\n",
      "Ep:81, loss:0.00002, loss_test:0.08645, lr:6.89e-03, fs:0.76190 (r=0.727,p=0.800),  time:17.338, tt:1421.714\n",
      "Ep:82, loss:0.00002, loss_test:0.08530, lr:6.89e-03, fs:0.76596 (r=0.727,p=0.809),  time:17.304, tt:1436.221\n",
      "Ep:83, loss:0.00002, loss_test:0.08491, lr:6.89e-03, fs:0.77249 (r=0.737,p=0.811),  time:17.328, tt:1455.511\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.08462, lr:6.89e-03, fs:0.77660 (r=0.737,p=0.820),  time:17.322, tt:1472.396\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.08315, lr:6.89e-03, fs:0.77660 (r=0.737,p=0.820),  time:17.314, tt:1489.033\n",
      "Ep:86, loss:0.00002, loss_test:0.08264, lr:6.89e-03, fs:0.77660 (r=0.737,p=0.820),  time:17.296, tt:1504.728\n",
      "Ep:87, loss:0.00002, loss_test:0.08290, lr:6.89e-03, fs:0.78495 (r=0.737,p=0.839),  time:17.263, tt:1519.157\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.08177, lr:6.89e-03, fs:0.79570 (r=0.747,p=0.851),  time:17.247, tt:1535.007\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.08188, lr:6.89e-03, fs:0.80874 (r=0.747,p=0.881),  time:17.233, tt:1550.978\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.08232, lr:6.89e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.220, tt:1567.050\n",
      "Ep:91, loss:0.00001, loss_test:0.08129, lr:6.89e-03, fs:0.82022 (r=0.737,p=0.924),  time:17.190, tt:1581.440\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.08063, lr:6.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:17.184, tt:1598.118\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.08066, lr:6.89e-03, fs:0.82022 (r=0.737,p=0.924),  time:17.186, tt:1615.499\n",
      "Ep:94, loss:0.00001, loss_test:0.08026, lr:6.89e-03, fs:0.81356 (r=0.727,p=0.923),  time:17.178, tt:1631.932\n",
      "Ep:95, loss:0.00001, loss_test:0.08083, lr:6.89e-03, fs:0.82022 (r=0.737,p=0.924),  time:17.178, tt:1649.043\n",
      "Ep:96, loss:0.00001, loss_test:0.07999, lr:6.89e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.173, tt:1665.829\n",
      "Ep:97, loss:0.00001, loss_test:0.08258, lr:6.89e-03, fs:0.81609 (r=0.717,p=0.947),  time:17.166, tt:1682.312\n",
      "Ep:98, loss:0.00001, loss_test:0.07882, lr:6.89e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.152, tt:1698.097\n",
      "Ep:99, loss:0.00001, loss_test:0.08703, lr:6.89e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.146, tt:1714.632\n",
      "Ep:100, loss:0.00001, loss_test:0.07527, lr:6.89e-03, fs:0.81967 (r=0.758,p=0.893),  time:17.145, tt:1731.675\n",
      "Ep:101, loss:0.00001, loss_test:0.09979, lr:6.89e-03, fs:0.76301 (r=0.667,p=0.892),  time:17.153, tt:1749.611\n",
      "Ep:102, loss:0.00001, loss_test:0.07459, lr:6.89e-03, fs:0.81283 (r=0.768,p=0.864),  time:17.152, tt:1766.664\n",
      "Ep:103, loss:0.00001, loss_test:0.08367, lr:6.89e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.163, tt:1784.915\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.09034, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.170, tt:1802.872\n",
      "Ep:105, loss:0.00001, loss_test:0.07481, lr:6.89e-03, fs:0.81967 (r=0.758,p=0.893),  time:17.172, tt:1820.234\n",
      "Ep:106, loss:0.00001, loss_test:0.08837, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.167, tt:1836.831\n",
      "Ep:107, loss:0.00001, loss_test:0.08349, lr:6.89e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.175, tt:1854.952\n",
      "Ep:108, loss:0.00001, loss_test:0.07586, lr:6.89e-03, fs:0.82873 (r=0.758,p=0.915),  time:17.185, tt:1873.176\n",
      "Ep:109, loss:0.00001, loss_test:0.09020, lr:6.89e-03, fs:0.84746 (r=0.758,p=0.962),  time:17.198, tt:1891.732\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.07786, lr:6.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:17.199, tt:1909.101\n",
      "Ep:111, loss:0.00001, loss_test:0.07578, lr:6.89e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.219, tt:1928.571\n",
      "Ep:112, loss:0.00001, loss_test:0.09394, lr:6.89e-03, fs:0.84571 (r=0.747,p=0.974),  time:17.231, tt:1947.150\n",
      "Ep:113, loss:0.00001, loss_test:0.07332, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.246, tt:1966.064\n",
      "Ep:114, loss:0.00001, loss_test:0.07906, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.265, tt:1985.448\n",
      "Ep:115, loss:0.00001, loss_test:0.08963, lr:6.89e-03, fs:0.84091 (r=0.747,p=0.961),  time:17.284, tt:2004.957\n",
      "Ep:116, loss:0.00001, loss_test:0.07186, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.287, tt:2022.605\n",
      "Ep:117, loss:0.00001, loss_test:0.08264, lr:6.89e-03, fs:0.84091 (r=0.747,p=0.961),  time:17.296, tt:2040.880\n",
      "Ep:118, loss:0.00001, loss_test:0.08413, lr:6.89e-03, fs:0.82081 (r=0.717,p=0.959),  time:17.302, tt:2058.891\n",
      "Ep:119, loss:0.00001, loss_test:0.07336, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.311, tt:2077.260\n",
      "Ep:120, loss:0.00001, loss_test:0.08771, lr:6.89e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.332, tt:2097.175\n",
      "Ep:121, loss:0.00001, loss_test:0.07598, lr:6.83e-03, fs:0.80702 (r=0.697,p=0.958),  time:17.343, tt:2115.796\n",
      "Ep:122, loss:0.00001, loss_test:0.08651, lr:6.76e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.355, tt:2134.682\n",
      "Ep:123, loss:0.00001, loss_test:0.07755, lr:6.69e-03, fs:0.81176 (r=0.697,p=0.972),  time:17.365, tt:2153.298\n",
      "Ep:124, loss:0.00001, loss_test:0.08021, lr:6.62e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.379, tt:2172.374\n",
      "Ep:125, loss:0.00001, loss_test:0.08813, lr:6.56e-03, fs:0.79762 (r=0.677,p=0.971),  time:17.395, tt:2191.730\n",
      "Ep:126, loss:0.00001, loss_test:0.07280, lr:6.49e-03, fs:0.82558 (r=0.717,p=0.973),  time:17.406, tt:2210.563\n",
      "Ep:127, loss:0.00001, loss_test:0.08582, lr:6.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:17.424, tt:2230.310\n",
      "Ep:128, loss:0.00001, loss_test:0.08041, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:17.433, tt:2248.829\n",
      "Ep:129, loss:0.00001, loss_test:0.07795, lr:6.30e-03, fs:0.82353 (r=0.707,p=0.986),  time:17.453, tt:2268.920\n",
      "Ep:130, loss:0.00001, loss_test:0.08080, lr:6.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:17.460, tt:2287.253\n",
      "Ep:131, loss:0.00001, loss_test:0.08264, lr:6.17e-03, fs:0.77844 (r=0.657,p=0.956),  time:17.465, tt:2305.388\n",
      "Ep:132, loss:0.00001, loss_test:0.08171, lr:6.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.476, tt:2324.369\n",
      "Ep:133, loss:0.00001, loss_test:0.07513, lr:6.05e-03, fs:0.79042 (r=0.667,p=0.971),  time:17.478, tt:2342.046\n",
      "Ep:134, loss:0.00001, loss_test:0.09132, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.488, tt:2360.882\n",
      "Ep:135, loss:0.00001, loss_test:0.07411, lr:5.93e-03, fs:0.79042 (r=0.667,p=0.971),  time:17.491, tt:2378.773\n",
      "Ep:136, loss:0.00001, loss_test:0.08164, lr:5.87e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.497, tt:2397.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.08079, lr:5.81e-03, fs:0.79042 (r=0.667,p=0.971),  time:17.501, tt:2415.194\n",
      "Ep:138, loss:0.00001, loss_test:0.08256, lr:5.75e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.506, tt:2433.325\n",
      "Ep:139, loss:0.00001, loss_test:0.07638, lr:5.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.517, tt:2452.338\n",
      "Ep:140, loss:0.00001, loss_test:0.08914, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:17.531, tt:2471.846\n",
      "Ep:141, loss:0.00001, loss_test:0.07657, lr:5.58e-03, fs:0.79042 (r=0.667,p=0.971),  time:17.544, tt:2491.234\n",
      "Ep:142, loss:0.00001, loss_test:0.07938, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.554, tt:2510.215\n",
      "Ep:143, loss:0.00001, loss_test:0.07891, lr:5.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.570, tt:2530.011\n",
      "Ep:144, loss:0.00001, loss_test:0.08188, lr:5.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.583, tt:2549.546\n",
      "Ep:145, loss:0.00001, loss_test:0.07652, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.587, tt:2567.747\n",
      "Ep:146, loss:0.00001, loss_test:0.08388, lr:5.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.593, tt:2586.164\n",
      "Ep:147, loss:0.00001, loss_test:0.07693, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.607, tt:2605.803\n",
      "Ep:148, loss:0.00001, loss_test:0.08400, lr:5.20e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.622, tt:2625.708\n",
      "Ep:149, loss:0.00001, loss_test:0.07450, lr:5.15e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.636, tt:2645.423\n",
      "Ep:150, loss:0.00000, loss_test:0.09004, lr:5.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:17.647, tt:2664.740\n",
      "Ep:151, loss:0.00001, loss_test:0.07587, lr:5.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:17.656, tt:2683.732\n",
      "Ep:152, loss:0.00000, loss_test:0.07949, lr:5.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.670, tt:2703.460\n",
      "Ep:153, loss:0.00000, loss_test:0.08359, lr:4.95e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.676, tt:2722.150\n",
      "Ep:154, loss:0.00000, loss_test:0.07658, lr:4.90e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.689, tt:2741.732\n",
      "Ep:155, loss:0.00000, loss_test:0.08048, lr:4.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.697, tt:2760.688\n",
      "Ep:156, loss:0.00000, loss_test:0.07794, lr:4.80e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.706, tt:2779.872\n",
      "Ep:157, loss:0.00000, loss_test:0.08079, lr:4.75e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.733, tt:2801.809\n",
      "Ep:158, loss:0.00000, loss_test:0.07854, lr:4.71e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.740, tt:2820.710\n",
      "Ep:159, loss:0.00000, loss_test:0.07758, lr:4.66e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.750, tt:2839.991\n",
      "Ep:160, loss:0.00000, loss_test:0.08601, lr:4.61e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.758, tt:2859.091\n",
      "Ep:161, loss:0.00000, loss_test:0.07660, lr:4.57e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.768, tt:2878.355\n",
      "Ep:162, loss:0.00000, loss_test:0.08196, lr:4.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.771, tt:2896.710\n",
      "Ep:163, loss:0.00000, loss_test:0.08071, lr:4.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.776, tt:2915.186\n",
      "Ep:164, loss:0.00000, loss_test:0.07959, lr:4.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.783, tt:2934.170\n",
      "Ep:165, loss:0.00000, loss_test:0.08078, lr:4.39e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.798, tt:2954.537\n",
      "Ep:166, loss:0.00000, loss_test:0.07989, lr:4.34e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.809, tt:2974.032\n",
      "Ep:167, loss:0.00000, loss_test:0.08335, lr:4.30e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.810, tt:2992.101\n",
      "Ep:168, loss:0.00000, loss_test:0.07910, lr:4.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.820, tt:3011.521\n",
      "Ep:169, loss:0.00000, loss_test:0.08139, lr:4.21e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.821, tt:3029.554\n",
      "Ep:170, loss:0.00000, loss_test:0.08398, lr:4.17e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.832, tt:3049.344\n",
      "Ep:171, loss:0.00000, loss_test:0.07842, lr:4.13e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.830, tt:3066.812\n",
      "Ep:172, loss:0.00000, loss_test:0.08476, lr:4.09e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.837, tt:3085.884\n",
      "Ep:173, loss:0.00000, loss_test:0.08150, lr:4.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.846, tt:3105.185\n",
      "Ep:174, loss:0.00000, loss_test:0.07988, lr:4.01e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.854, tt:3124.505\n",
      "Ep:175, loss:0.00000, loss_test:0.08296, lr:3.97e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.859, tt:3143.119\n",
      "Ep:176, loss:0.00000, loss_test:0.08221, lr:3.93e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.865, tt:3162.118\n",
      "Ep:177, loss:0.00000, loss_test:0.08124, lr:3.89e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.873, tt:3181.358\n",
      "Ep:178, loss:0.00000, loss_test:0.08193, lr:3.85e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.882, tt:3200.839\n",
      "Ep:179, loss:0.00000, loss_test:0.08297, lr:3.81e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.885, tt:3219.218\n",
      "Ep:180, loss:0.00000, loss_test:0.08301, lr:3.77e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.884, tt:3236.925\n",
      "Ep:181, loss:0.00000, loss_test:0.08108, lr:3.73e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.886, tt:3255.246\n",
      "Ep:182, loss:0.00000, loss_test:0.08352, lr:3.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.895, tt:3274.779\n",
      "Ep:183, loss:0.00000, loss_test:0.08233, lr:3.66e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.898, tt:3293.229\n",
      "Ep:184, loss:0.00000, loss_test:0.08104, lr:3.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.902, tt:3311.923\n",
      "Ep:185, loss:0.00000, loss_test:0.08366, lr:3.59e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.909, tt:3331.054\n",
      "Ep:186, loss:0.00000, loss_test:0.08237, lr:3.55e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.914, tt:3349.901\n",
      "Ep:187, loss:0.00000, loss_test:0.08205, lr:3.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.920, tt:3368.927\n",
      "Ep:188, loss:0.00000, loss_test:0.08234, lr:3.48e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.931, tt:3388.900\n",
      "Ep:189, loss:0.00000, loss_test:0.08357, lr:3.45e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.932, tt:3407.105\n",
      "Ep:190, loss:0.00000, loss_test:0.08280, lr:3.41e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.945, tt:3427.564\n",
      "Ep:191, loss:0.00000, loss_test:0.08110, lr:3.38e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.953, tt:3446.948\n",
      "Ep:192, loss:0.00000, loss_test:0.08546, lr:3.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.961, tt:3466.530\n",
      "Ep:193, loss:0.00000, loss_test:0.08338, lr:3.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:17.969, tt:3486.081\n",
      "Ep:194, loss:0.00000, loss_test:0.08122, lr:3.28e-03, fs:0.78788 (r=0.657,p=0.985),  time:17.996, tt:3509.185\n",
      "Ep:195, loss:0.00000, loss_test:0.08429, lr:3.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.003, tt:3528.628\n",
      "Ep:196, loss:0.00000, loss_test:0.08382, lr:3.21e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.008, tt:3547.531\n",
      "Ep:197, loss:0.00000, loss_test:0.08235, lr:3.18e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.014, tt:3566.723\n",
      "Ep:198, loss:0.00000, loss_test:0.08354, lr:3.15e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.019, tt:3585.753\n",
      "Ep:199, loss:0.00000, loss_test:0.08365, lr:3.12e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.019, tt:3603.741\n",
      "Ep:200, loss:0.00000, loss_test:0.08361, lr:3.09e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.030, tt:3624.044\n",
      "Ep:201, loss:0.00000, loss_test:0.08322, lr:3.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.039, tt:3643.811\n",
      "Ep:202, loss:0.00000, loss_test:0.08366, lr:3.02e-03, fs:0.78788 (r=0.657,p=0.985),  time:18.051, tt:3664.272\n",
      "Ep:203, loss:0.00000, loss_test:0.08533, lr:2.99e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.052, tt:3682.688\n",
      "Ep:204, loss:0.00000, loss_test:0.08319, lr:2.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.055, tt:3701.376\n",
      "Ep:205, loss:0.00000, loss_test:0.08218, lr:2.93e-03, fs:0.78788 (r=0.657,p=0.985),  time:18.060, tt:3720.454\n",
      "Ep:206, loss:0.00000, loss_test:0.08607, lr:2.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.066, tt:3739.688\n",
      "Ep:207, loss:0.00000, loss_test:0.08467, lr:2.88e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.076, tt:3759.823\n",
      "Ep:208, loss:0.00000, loss_test:0.08228, lr:2.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.084, tt:3779.606\n",
      "Ep:209, loss:0.00000, loss_test:0.08441, lr:2.82e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.092, tt:3799.382\n",
      "Ep:210, loss:0.00000, loss_test:0.08452, lr:2.79e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.099, tt:3818.852\n",
      "Ep:211, loss:0.00000, loss_test:0.08361, lr:2.76e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.107, tt:3838.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00000, loss_test:0.08416, lr:2.73e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.111, tt:3857.652\n",
      "Ep:213, loss:0.00000, loss_test:0.08435, lr:2.71e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.116, tt:3876.922\n",
      "Ep:214, loss:0.00000, loss_test:0.08429, lr:2.68e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.125, tt:3896.806\n",
      "Ep:215, loss:0.00000, loss_test:0.08452, lr:2.65e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.130, tt:3916.084\n",
      "Ep:216, loss:0.00000, loss_test:0.08403, lr:2.63e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.136, tt:3935.492\n",
      "Ep:217, loss:0.00000, loss_test:0.08416, lr:2.60e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.141, tt:3954.822\n",
      "Ep:218, loss:0.00000, loss_test:0.08449, lr:2.57e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.147, tt:3974.130\n",
      "Ep:219, loss:0.00000, loss_test:0.08423, lr:2.55e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.151, tt:3993.320\n",
      "Ep:220, loss:0.00000, loss_test:0.08511, lr:2.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.152, tt:4011.652\n",
      "Ep:221, loss:0.00000, loss_test:0.08484, lr:2.50e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.158, tt:4031.027\n",
      "Ep:222, loss:0.00000, loss_test:0.08377, lr:2.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.161, tt:4049.933\n",
      "Ep:223, loss:0.00000, loss_test:0.08485, lr:2.45e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.163, tt:4068.573\n",
      "Ep:224, loss:0.00000, loss_test:0.08572, lr:2.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.167, tt:4087.592\n",
      "Ep:225, loss:0.00000, loss_test:0.08443, lr:2.40e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.164, tt:4105.126\n",
      "Ep:226, loss:0.00000, loss_test:0.08408, lr:2.38e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.169, tt:4124.378\n",
      "Ep:227, loss:0.00000, loss_test:0.08548, lr:2.35e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.168, tt:4142.312\n",
      "Ep:228, loss:0.00000, loss_test:0.08502, lr:2.33e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.172, tt:4161.293\n",
      "Ep:229, loss:0.00000, loss_test:0.08408, lr:2.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.172, tt:4179.460\n",
      "Ep:230, loss:0.00000, loss_test:0.08538, lr:2.28e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.172, tt:4197.830\n",
      "Ep:231, loss:0.00000, loss_test:0.08530, lr:2.26e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.176, tt:4216.808\n",
      "Ep:232, loss:0.00000, loss_test:0.08462, lr:2.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.183, tt:4236.583\n",
      "Ep:233, loss:0.00000, loss_test:0.08537, lr:2.21e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.181, tt:4254.279\n",
      "Ep:234, loss:0.00000, loss_test:0.08514, lr:2.19e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.186, tt:4273.699\n",
      "Ep:235, loss:0.00000, loss_test:0.08487, lr:2.17e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.186, tt:4291.957\n",
      "Ep:236, loss:0.00000, loss_test:0.08589, lr:2.15e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.189, tt:4310.730\n",
      "Ep:237, loss:0.00000, loss_test:0.08526, lr:2.13e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.190, tt:4329.194\n",
      "Ep:238, loss:0.00000, loss_test:0.08471, lr:2.11e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.193, tt:4348.241\n",
      "Ep:239, loss:0.00000, loss_test:0.08603, lr:2.08e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.200, tt:4367.924\n",
      "Ep:240, loss:0.00000, loss_test:0.08570, lr:2.06e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.206, tt:4387.535\n",
      "Ep:241, loss:0.00000, loss_test:0.08478, lr:2.04e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.208, tt:4406.441\n",
      "Ep:242, loss:0.00000, loss_test:0.08627, lr:2.02e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.211, tt:4425.189\n",
      "Ep:243, loss:0.00000, loss_test:0.08608, lr:2.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.214, tt:4444.127\n",
      "Ep:244, loss:0.00000, loss_test:0.08508, lr:1.98e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.216, tt:4462.803\n",
      "Ep:245, loss:0.00000, loss_test:0.08602, lr:1.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.218, tt:4481.556\n",
      "Ep:246, loss:0.00000, loss_test:0.08649, lr:1.94e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.221, tt:4500.599\n",
      "Ep:247, loss:0.00000, loss_test:0.08525, lr:1.92e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.220, tt:4518.648\n",
      "Ep:248, loss:0.00000, loss_test:0.08602, lr:1.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.222, tt:4537.277\n",
      "Ep:249, loss:0.00000, loss_test:0.08637, lr:1.89e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.224, tt:4555.906\n",
      "Ep:250, loss:0.00000, loss_test:0.08530, lr:1.87e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.226, tt:4574.686\n",
      "Ep:251, loss:0.00000, loss_test:0.08610, lr:1.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.229, tt:4593.809\n",
      "Ep:252, loss:0.00000, loss_test:0.08668, lr:1.83e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.234, tt:4613.261\n",
      "Ep:253, loss:0.00000, loss_test:0.08572, lr:1.81e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.235, tt:4631.656\n",
      "Ep:254, loss:0.00000, loss_test:0.08566, lr:1.79e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.238, tt:4650.604\n",
      "Ep:255, loss:0.00000, loss_test:0.08688, lr:1.78e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.238, tt:4669.004\n",
      "Ep:256, loss:0.00000, loss_test:0.08664, lr:1.76e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.241, tt:4687.939\n",
      "Ep:257, loss:0.00000, loss_test:0.08565, lr:1.74e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.243, tt:4706.725\n",
      "Ep:258, loss:0.00000, loss_test:0.08652, lr:1.72e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.242, tt:4724.742\n",
      "Ep:259, loss:0.00000, loss_test:0.08679, lr:1.71e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.243, tt:4743.164\n",
      "Ep:260, loss:0.00000, loss_test:0.08605, lr:1.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.246, tt:4762.167\n",
      "Ep:261, loss:0.00000, loss_test:0.08620, lr:1.67e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.256, tt:4783.177\n",
      "Ep:262, loss:0.00000, loss_test:0.08665, lr:1.65e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.261, tt:4802.638\n",
      "Ep:263, loss:0.00000, loss_test:0.08644, lr:1.64e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.260, tt:4820.622\n",
      "Ep:264, loss:0.00000, loss_test:0.08680, lr:1.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.267, tt:4840.717\n",
      "Ep:265, loss:0.00000, loss_test:0.08656, lr:1.61e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.270, tt:4859.735\n",
      "Ep:266, loss:0.00000, loss_test:0.08646, lr:1.59e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.272, tt:4878.751\n",
      "Ep:267, loss:0.00000, loss_test:0.08675, lr:1.57e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.271, tt:4896.655\n",
      "Ep:268, loss:0.00000, loss_test:0.08681, lr:1.56e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.271, tt:4914.805\n",
      "Ep:269, loss:0.00000, loss_test:0.08674, lr:1.54e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.272, tt:4933.375\n",
      "Ep:270, loss:0.00000, loss_test:0.08685, lr:1.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.275, tt:4952.616\n",
      "Ep:271, loss:0.00000, loss_test:0.08705, lr:1.51e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.274, tt:4970.600\n",
      "Ep:272, loss:0.00000, loss_test:0.08694, lr:1.50e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.275, tt:4989.095\n",
      "Ep:273, loss:0.00000, loss_test:0.08690, lr:1.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.275, tt:5007.309\n",
      "Ep:274, loss:0.00000, loss_test:0.08695, lr:1.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.279, tt:5026.782\n",
      "Ep:275, loss:0.00000, loss_test:0.08717, lr:1.45e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.283, tt:5046.096\n",
      "Ep:276, loss:0.00000, loss_test:0.08694, lr:1.44e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.288, tt:5065.785\n",
      "Ep:277, loss:0.00000, loss_test:0.08732, lr:1.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.289, tt:5084.366\n",
      "Ep:278, loss:0.00000, loss_test:0.08704, lr:1.41e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.291, tt:5103.322\n",
      "Ep:279, loss:0.00000, loss_test:0.08720, lr:1.39e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.295, tt:5122.591\n",
      "Ep:280, loss:0.00000, loss_test:0.08743, lr:1.38e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.298, tt:5141.709\n",
      "Ep:281, loss:0.00000, loss_test:0.08752, lr:1.37e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.298, tt:5159.962\n",
      "Ep:282, loss:0.00000, loss_test:0.08712, lr:1.35e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.298, tt:5178.220\n",
      "Ep:283, loss:0.00000, loss_test:0.08765, lr:1.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.308, tt:5199.487\n",
      "Ep:284, loss:0.00000, loss_test:0.08762, lr:1.33e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.313, tt:5219.168\n",
      "Ep:285, loss:0.00000, loss_test:0.08732, lr:1.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.317, tt:5238.764\n",
      "Ep:286, loss:0.00000, loss_test:0.08767, lr:1.30e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.320, tt:5257.834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:287, loss:0.00000, loss_test:0.08775, lr:1.29e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.320, tt:5276.121\n",
      "Ep:288, loss:0.00000, loss_test:0.08773, lr:1.27e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.322, tt:5295.037\n",
      "Ep:289, loss:0.00000, loss_test:0.08785, lr:1.26e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.326, tt:5314.588\n",
      "Ep:290, loss:0.00000, loss_test:0.08791, lr:1.25e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.325, tt:5332.555\n",
      "Ep:291, loss:0.00000, loss_test:0.08747, lr:1.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.327, tt:5351.542\n",
      "Ep:292, loss:0.00000, loss_test:0.08778, lr:1.22e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.330, tt:5370.618\n",
      "Ep:293, loss:0.00000, loss_test:0.08782, lr:1.21e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.326, tt:5387.743\n",
      "Ep:294, loss:0.00000, loss_test:0.08770, lr:1.20e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.307, tt:5400.709\n",
      "Ep:295, loss:0.00000, loss_test:0.08782, lr:1.19e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.285, tt:5412.298\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14543, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.723, tt:15.723\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14521, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.965, tt:29.929\n",
      "Ep:2, loss:0.00004, loss_test:0.14490, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.124, tt:45.372\n",
      "Ep:3, loss:0.00004, loss_test:0.14447, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:15.329, tt:61.314\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.14391, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:15.548, tt:77.742\n",
      "Ep:5, loss:0.00004, loss_test:0.14320, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:15.551, tt:93.306\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.14228, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:15.491, tt:108.435\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.14115, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:15.560, tt:124.477\n",
      "Ep:8, loss:0.00004, loss_test:0.13990, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:15.568, tt:140.116\n",
      "Ep:9, loss:0.00004, loss_test:0.13841, lr:1.00e-02, fs:0.63604 (r=0.909,p=0.489),  time:15.678, tt:156.779\n",
      "Ep:10, loss:0.00004, loss_test:0.13691, lr:1.00e-02, fs:0.63504 (r=0.879,p=0.497),  time:15.706, tt:172.766\n",
      "Ep:11, loss:0.00004, loss_test:0.13509, lr:1.00e-02, fs:0.61355 (r=0.778,p=0.507),  time:15.716, tt:188.587\n",
      "Ep:12, loss:0.00003, loss_test:0.13298, lr:1.00e-02, fs:0.58515 (r=0.677,p=0.515),  time:15.759, tt:204.862\n",
      "Ep:13, loss:0.00003, loss_test:0.13157, lr:1.00e-02, fs:0.59259 (r=0.646,p=0.547),  time:15.765, tt:220.714\n",
      "Ep:14, loss:0.00003, loss_test:0.13138, lr:1.00e-02, fs:0.59512 (r=0.616,p=0.575),  time:15.741, tt:236.121\n",
      "Ep:15, loss:0.00003, loss_test:0.13219, lr:1.00e-02, fs:0.57732 (r=0.566,p=0.589),  time:15.726, tt:251.612\n",
      "Ep:16, loss:0.00003, loss_test:0.13186, lr:1.00e-02, fs:0.58824 (r=0.556,p=0.625),  time:15.746, tt:267.680\n",
      "Ep:17, loss:0.00003, loss_test:0.13009, lr:1.00e-02, fs:0.59259 (r=0.566,p=0.622),  time:15.771, tt:283.887\n",
      "Ep:18, loss:0.00003, loss_test:0.12720, lr:9.90e-03, fs:0.60606 (r=0.606,p=0.606),  time:15.791, tt:300.034\n",
      "Ep:19, loss:0.00003, loss_test:0.12510, lr:9.80e-03, fs:0.59615 (r=0.626,p=0.569),  time:15.828, tt:316.566\n",
      "Ep:20, loss:0.00003, loss_test:0.12403, lr:9.70e-03, fs:0.60664 (r=0.646,p=0.571),  time:15.817, tt:332.154\n",
      "Ep:21, loss:0.00003, loss_test:0.12277, lr:9.61e-03, fs:0.59804 (r=0.616,p=0.581),  time:15.797, tt:347.529\n",
      "Ep:22, loss:0.00003, loss_test:0.12143, lr:9.51e-03, fs:0.60302 (r=0.606,p=0.600),  time:15.840, tt:364.321\n",
      "Ep:23, loss:0.00003, loss_test:0.12112, lr:9.41e-03, fs:0.60963 (r=0.576,p=0.648),  time:15.855, tt:380.529\n",
      "Ep:24, loss:0.00003, loss_test:0.12083, lr:9.32e-03, fs:0.62857 (r=0.556,p=0.724),  time:15.813, tt:395.314\n",
      "Ep:25, loss:0.00003, loss_test:0.11963, lr:9.23e-03, fs:0.62428 (r=0.545,p=0.730),  time:15.805, tt:410.928\n",
      "Ep:26, loss:0.00003, loss_test:0.11739, lr:9.14e-03, fs:0.63277 (r=0.566,p=0.718),  time:15.801, tt:426.640\n",
      "Ep:27, loss:0.00003, loss_test:0.11538, lr:9.04e-03, fs:0.63492 (r=0.606,p=0.667),  time:15.816, tt:442.859\n",
      "Ep:28, loss:0.00003, loss_test:0.11421, lr:8.95e-03, fs:0.64948 (r=0.636,p=0.663),  time:15.843, tt:459.434\n",
      "Ep:29, loss:0.00003, loss_test:0.11325, lr:8.86e-03, fs:0.64948 (r=0.636,p=0.663),  time:15.892, tt:476.752\n",
      "Ep:30, loss:0.00003, loss_test:0.11234, lr:8.78e-03, fs:0.65969 (r=0.636,p=0.685),  time:15.931, tt:493.868\n",
      "Ep:31, loss:0.00003, loss_test:0.11184, lr:8.69e-03, fs:0.65217 (r=0.606,p=0.706),  time:15.911, tt:509.148\n",
      "Ep:32, loss:0.00003, loss_test:0.11140, lr:8.60e-03, fs:0.64444 (r=0.586,p=0.716),  time:15.915, tt:525.200\n",
      "Ep:33, loss:0.00003, loss_test:0.11062, lr:8.51e-03, fs:0.63687 (r=0.576,p=0.713),  time:15.893, tt:540.359\n",
      "Ep:34, loss:0.00002, loss_test:0.10947, lr:8.43e-03, fs:0.65217 (r=0.606,p=0.706),  time:15.887, tt:556.030\n",
      "Ep:35, loss:0.00002, loss_test:0.10826, lr:8.35e-03, fs:0.64516 (r=0.606,p=0.690),  time:15.897, tt:572.309\n",
      "Ep:36, loss:0.00002, loss_test:0.10716, lr:8.26e-03, fs:0.65957 (r=0.626,p=0.697),  time:15.901, tt:588.332\n",
      "Ep:37, loss:0.00002, loss_test:0.10618, lr:8.18e-03, fs:0.69072 (r=0.677,p=0.705),  time:15.885, tt:603.612\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.10532, lr:8.18e-03, fs:0.69110 (r=0.667,p=0.717),  time:15.868, tt:618.850\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.10465, lr:8.18e-03, fs:0.69474 (r=0.667,p=0.725),  time:15.857, tt:634.279\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10405, lr:8.18e-03, fs:0.68449 (r=0.646,p=0.727),  time:15.855, tt:650.059\n",
      "Ep:41, loss:0.00002, loss_test:0.10328, lr:8.18e-03, fs:0.67742 (r=0.636,p=0.724),  time:15.833, tt:664.986\n",
      "Ep:42, loss:0.00002, loss_test:0.10216, lr:8.18e-03, fs:0.67380 (r=0.636,p=0.716),  time:15.906, tt:683.975\n",
      "Ep:43, loss:0.00002, loss_test:0.10085, lr:8.18e-03, fs:0.68421 (r=0.657,p=0.714),  time:15.903, tt:699.734\n",
      "Ep:44, loss:0.00002, loss_test:0.09957, lr:8.18e-03, fs:0.69474 (r=0.667,p=0.725),  time:15.901, tt:715.549\n",
      "Ep:45, loss:0.00002, loss_test:0.09856, lr:8.18e-03, fs:0.69474 (r=0.667,p=0.725),  time:15.902, tt:731.492\n",
      "Ep:46, loss:0.00002, loss_test:0.09793, lr:8.18e-03, fs:0.70213 (r=0.667,p=0.742),  time:15.889, tt:746.759\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.09764, lr:8.18e-03, fs:0.70270 (r=0.657,p=0.756),  time:15.890, tt:762.729\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09737, lr:8.18e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.888, tt:778.522\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.09674, lr:8.18e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.883, tt:794.162\n",
      "Ep:50, loss:0.00002, loss_test:0.09592, lr:8.18e-03, fs:0.71351 (r=0.667,p=0.767),  time:15.876, tt:809.693\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.09517, lr:8.18e-03, fs:0.71658 (r=0.677,p=0.761),  time:15.874, tt:825.429\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.09468, lr:8.18e-03, fs:0.71658 (r=0.677,p=0.761),  time:15.869, tt:841.043\n",
      "Ep:53, loss:0.00002, loss_test:0.09440, lr:8.18e-03, fs:0.71739 (r=0.667,p=0.776),  time:15.855, tt:856.153\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.09416, lr:8.18e-03, fs:0.71739 (r=0.667,p=0.776),  time:15.858, tt:872.181\n",
      "Ep:55, loss:0.00002, loss_test:0.09375, lr:8.18e-03, fs:0.71739 (r=0.667,p=0.776),  time:15.858, tt:888.027\n",
      "Ep:56, loss:0.00002, loss_test:0.09303, lr:8.18e-03, fs:0.71739 (r=0.667,p=0.776),  time:15.851, tt:903.498\n",
      "Ep:57, loss:0.00002, loss_test:0.09226, lr:8.18e-03, fs:0.72432 (r=0.677,p=0.779),  time:15.870, tt:920.475\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00002, loss_test:0.09167, lr:8.18e-03, fs:0.72432 (r=0.677,p=0.779),  time:15.871, tt:936.395\n",
      "Ep:59, loss:0.00002, loss_test:0.09141, lr:8.18e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.874, tt:952.458\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.09139, lr:8.18e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.883, tt:968.864\n",
      "Ep:61, loss:0.00002, loss_test:0.09133, lr:8.18e-03, fs:0.73913 (r=0.687,p=0.800),  time:15.867, tt:983.740\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.09106, lr:8.18e-03, fs:0.73913 (r=0.687,p=0.800),  time:15.860, tt:999.171\n",
      "Ep:63, loss:0.00002, loss_test:0.09063, lr:8.18e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.854, tt:1014.647\n",
      "Ep:64, loss:0.00002, loss_test:0.09031, lr:8.18e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.860, tt:1030.878\n",
      "Ep:65, loss:0.00002, loss_test:0.09017, lr:8.18e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.856, tt:1046.527\n",
      "Ep:66, loss:0.00002, loss_test:0.09010, lr:8.18e-03, fs:0.73913 (r=0.687,p=0.800),  time:15.869, tt:1063.224\n",
      "Ep:67, loss:0.00002, loss_test:0.08987, lr:8.18e-03, fs:0.74595 (r=0.697,p=0.802),  time:15.870, tt:1079.150\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.08955, lr:8.18e-03, fs:0.74595 (r=0.697,p=0.802),  time:15.874, tt:1095.330\n",
      "Ep:69, loss:0.00002, loss_test:0.08918, lr:8.18e-03, fs:0.74595 (r=0.697,p=0.802),  time:15.869, tt:1110.817\n",
      "Ep:70, loss:0.00002, loss_test:0.08887, lr:8.18e-03, fs:0.74317 (r=0.687,p=0.810),  time:15.868, tt:1126.660\n",
      "Ep:71, loss:0.00002, loss_test:0.08862, lr:8.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:15.859, tt:1141.864\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.08840, lr:8.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:15.886, tt:1159.649\n",
      "Ep:73, loss:0.00002, loss_test:0.08826, lr:8.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:15.891, tt:1175.918\n",
      "Ep:74, loss:0.00002, loss_test:0.08815, lr:8.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:15.908, tt:1193.126\n",
      "Ep:75, loss:0.00002, loss_test:0.08807, lr:8.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:15.918, tt:1209.751\n",
      "Ep:76, loss:0.00002, loss_test:0.08788, lr:8.18e-03, fs:0.76087 (r=0.707,p=0.824),  time:15.914, tt:1225.366\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.08764, lr:8.18e-03, fs:0.76087 (r=0.707,p=0.824),  time:15.919, tt:1241.702\n",
      "Ep:78, loss:0.00002, loss_test:0.08750, lr:8.18e-03, fs:0.76087 (r=0.707,p=0.824),  time:15.913, tt:1257.153\n",
      "Ep:79, loss:0.00002, loss_test:0.08742, lr:8.18e-03, fs:0.76087 (r=0.707,p=0.824),  time:15.918, tt:1273.449\n",
      "Ep:80, loss:0.00002, loss_test:0.08729, lr:8.18e-03, fs:0.76923 (r=0.707,p=0.843),  time:15.911, tt:1288.775\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.08701, lr:8.18e-03, fs:0.76923 (r=0.707,p=0.843),  time:15.904, tt:1304.090\n",
      "Ep:82, loss:0.00002, loss_test:0.08680, lr:8.18e-03, fs:0.77174 (r=0.717,p=0.835),  time:15.909, tt:1320.452\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.08670, lr:8.18e-03, fs:0.77174 (r=0.717,p=0.835),  time:15.920, tt:1337.279\n",
      "Ep:84, loss:0.00001, loss_test:0.08677, lr:8.18e-03, fs:0.78022 (r=0.717,p=0.855),  time:15.919, tt:1353.082\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.08682, lr:8.18e-03, fs:0.78453 (r=0.717,p=0.866),  time:15.933, tt:1370.249\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.08665, lr:8.18e-03, fs:0.78453 (r=0.717,p=0.866),  time:15.943, tt:1387.014\n",
      "Ep:87, loss:0.00001, loss_test:0.08630, lr:8.18e-03, fs:0.78453 (r=0.717,p=0.866),  time:15.958, tt:1404.288\n",
      "Ep:88, loss:0.00001, loss_test:0.08605, lr:8.18e-03, fs:0.78022 (r=0.717,p=0.855),  time:15.967, tt:1421.055\n",
      "Ep:89, loss:0.00001, loss_test:0.08608, lr:8.18e-03, fs:0.78022 (r=0.717,p=0.855),  time:15.970, tt:1437.302\n",
      "Ep:90, loss:0.00001, loss_test:0.08615, lr:8.18e-03, fs:0.77778 (r=0.707,p=0.864),  time:15.964, tt:1452.683\n",
      "Ep:91, loss:0.00001, loss_test:0.08587, lr:8.18e-03, fs:0.77778 (r=0.707,p=0.864),  time:15.968, tt:1469.030\n",
      "Ep:92, loss:0.00001, loss_test:0.08553, lr:8.18e-03, fs:0.77348 (r=0.707,p=0.854),  time:15.974, tt:1485.573\n",
      "Ep:93, loss:0.00001, loss_test:0.08547, lr:8.18e-03, fs:0.77778 (r=0.707,p=0.864),  time:15.981, tt:1502.232\n",
      "Ep:94, loss:0.00001, loss_test:0.08563, lr:8.18e-03, fs:0.76836 (r=0.687,p=0.872),  time:15.987, tt:1518.732\n",
      "Ep:95, loss:0.00001, loss_test:0.08550, lr:8.18e-03, fs:0.76836 (r=0.687,p=0.872),  time:15.992, tt:1535.245\n",
      "Ep:96, loss:0.00001, loss_test:0.08509, lr:8.18e-03, fs:0.76404 (r=0.687,p=0.861),  time:15.997, tt:1551.662\n",
      "Ep:97, loss:0.00001, loss_test:0.08492, lr:8.10e-03, fs:0.76836 (r=0.687,p=0.872),  time:16.010, tt:1569.005\n",
      "Ep:98, loss:0.00001, loss_test:0.08503, lr:8.02e-03, fs:0.76836 (r=0.687,p=0.872),  time:16.022, tt:1586.193\n",
      "Ep:99, loss:0.00001, loss_test:0.08522, lr:7.94e-03, fs:0.77273 (r=0.687,p=0.883),  time:16.025, tt:1602.516\n",
      "Ep:100, loss:0.00001, loss_test:0.08524, lr:7.86e-03, fs:0.76571 (r=0.677,p=0.882),  time:16.023, tt:1618.359\n",
      "Ep:101, loss:0.00001, loss_test:0.08500, lr:7.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:16.033, tt:1635.363\n",
      "Ep:102, loss:0.00001, loss_test:0.08471, lr:7.70e-03, fs:0.76301 (r=0.667,p=0.892),  time:16.045, tt:1652.670\n",
      "Ep:103, loss:0.00001, loss_test:0.08469, lr:7.62e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.048, tt:1668.977\n",
      "Ep:104, loss:0.00001, loss_test:0.08462, lr:7.55e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.057, tt:1685.936\n",
      "Ep:105, loss:0.00001, loss_test:0.08454, lr:7.47e-03, fs:0.74854 (r=0.646,p=0.889),  time:16.057, tt:1702.068\n",
      "Ep:106, loss:0.00001, loss_test:0.08445, lr:7.40e-03, fs:0.74854 (r=0.646,p=0.889),  time:16.056, tt:1718.034\n",
      "Ep:107, loss:0.00001, loss_test:0.08440, lr:7.32e-03, fs:0.74854 (r=0.646,p=0.889),  time:16.052, tt:1733.577\n",
      "Ep:108, loss:0.00001, loss_test:0.08436, lr:7.25e-03, fs:0.74118 (r=0.636,p=0.887),  time:16.053, tt:1749.766\n",
      "Ep:109, loss:0.00001, loss_test:0.08444, lr:7.18e-03, fs:0.74118 (r=0.636,p=0.887),  time:16.049, tt:1765.417\n",
      "Ep:110, loss:0.00001, loss_test:0.08458, lr:7.11e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.050, tt:1781.507\n",
      "Ep:111, loss:0.00001, loss_test:0.08463, lr:7.03e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.049, tt:1797.516\n",
      "Ep:112, loss:0.00001, loss_test:0.08462, lr:6.96e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.054, tt:1814.079\n",
      "Ep:113, loss:0.00001, loss_test:0.08460, lr:6.89e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.048, tt:1829.518\n",
      "Ep:114, loss:0.00001, loss_test:0.08459, lr:6.83e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.048, tt:1845.513\n",
      "Ep:115, loss:0.00001, loss_test:0.08460, lr:6.76e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.031, tt:1859.568\n",
      "Ep:116, loss:0.00001, loss_test:0.08463, lr:6.69e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.029, tt:1875.371\n",
      "Ep:117, loss:0.00001, loss_test:0.08466, lr:6.62e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.022, tt:1890.538\n",
      "Ep:118, loss:0.00001, loss_test:0.08480, lr:6.56e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.019, tt:1906.254\n",
      "Ep:119, loss:0.00001, loss_test:0.08472, lr:6.49e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.014, tt:1921.661\n",
      "Ep:120, loss:0.00001, loss_test:0.08461, lr:6.43e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.010, tt:1937.216\n",
      "Ep:121, loss:0.00001, loss_test:0.08460, lr:6.36e-03, fs:0.73373 (r=0.626,p=0.886),  time:16.002, tt:1952.222\n",
      "Ep:122, loss:0.00001, loss_test:0.08473, lr:6.30e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.993, tt:1967.125\n",
      "Ep:123, loss:0.00001, loss_test:0.08478, lr:6.24e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.990, tt:1982.759\n",
      "Ep:124, loss:0.00001, loss_test:0.08472, lr:6.17e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.987, tt:1998.363\n",
      "Ep:125, loss:0.00001, loss_test:0.08463, lr:6.11e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.989, tt:2014.658\n",
      "Ep:126, loss:0.00001, loss_test:0.08469, lr:6.05e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.988, tt:2030.505\n",
      "Ep:127, loss:0.00001, loss_test:0.08488, lr:5.99e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.983, tt:2045.861\n",
      "Ep:128, loss:0.00001, loss_test:0.08491, lr:5.93e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.982, tt:2061.673\n",
      "Ep:129, loss:0.00001, loss_test:0.08485, lr:5.87e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.980, tt:2077.456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00001, loss_test:0.08485, lr:5.81e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.973, tt:2092.471\n",
      "Ep:131, loss:0.00001, loss_test:0.08498, lr:5.75e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.973, tt:2108.471\n",
      "Ep:132, loss:0.00001, loss_test:0.08511, lr:5.70e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.971, tt:2124.134\n",
      "Ep:133, loss:0.00001, loss_test:0.08528, lr:5.64e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.973, tt:2140.337\n",
      "Ep:134, loss:0.00001, loss_test:0.08542, lr:5.58e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.970, tt:2155.920\n",
      "Ep:135, loss:0.00001, loss_test:0.08555, lr:5.53e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.971, tt:2172.021\n",
      "Ep:136, loss:0.00001, loss_test:0.08558, lr:5.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.963, tt:2186.952\n",
      "Ep:137, loss:0.00001, loss_test:0.08562, lr:5.42e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.963, tt:2202.908\n",
      "Ep:138, loss:0.00001, loss_test:0.08570, lr:5.36e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.965, tt:2219.117\n",
      "Ep:139, loss:0.00001, loss_test:0.08583, lr:5.31e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.962, tt:2234.684\n",
      "Ep:140, loss:0.00001, loss_test:0.08585, lr:5.26e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.968, tt:2251.443\n",
      "Ep:141, loss:0.00001, loss_test:0.08577, lr:5.20e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.966, tt:2267.177\n",
      "Ep:142, loss:0.00001, loss_test:0.08563, lr:5.15e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.962, tt:2282.552\n",
      "Ep:143, loss:0.00001, loss_test:0.08561, lr:5.10e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.958, tt:2298.012\n",
      "Ep:144, loss:0.00001, loss_test:0.08568, lr:5.05e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.950, tt:2312.818\n",
      "Ep:145, loss:0.00001, loss_test:0.08574, lr:5.00e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.948, tt:2328.354\n",
      "Ep:146, loss:0.00001, loss_test:0.08579, lr:4.95e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.943, tt:2343.604\n",
      "Ep:147, loss:0.00001, loss_test:0.08586, lr:4.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.937, tt:2358.659\n",
      "Ep:148, loss:0.00001, loss_test:0.08598, lr:4.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.939, tt:2374.914\n",
      "Ep:149, loss:0.00001, loss_test:0.08617, lr:4.80e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.937, tt:2390.483\n",
      "Ep:150, loss:0.00001, loss_test:0.08632, lr:4.75e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.938, tt:2406.563\n",
      "Ep:151, loss:0.00001, loss_test:0.08636, lr:4.71e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.937, tt:2422.449\n",
      "Ep:152, loss:0.00001, loss_test:0.08632, lr:4.66e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.939, tt:2438.660\n",
      "Ep:153, loss:0.00001, loss_test:0.08622, lr:4.61e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.933, tt:2453.731\n",
      "Ep:154, loss:0.00001, loss_test:0.08627, lr:4.57e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.932, tt:2469.459\n",
      "Ep:155, loss:0.00001, loss_test:0.08640, lr:4.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.936, tt:2485.955\n",
      "Ep:156, loss:0.00001, loss_test:0.08640, lr:4.48e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.938, tt:2502.232\n",
      "Ep:157, loss:0.00001, loss_test:0.08632, lr:4.43e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.938, tt:2518.272\n",
      "Ep:158, loss:0.00001, loss_test:0.08637, lr:4.39e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.940, tt:2534.433\n",
      "Ep:159, loss:0.00001, loss_test:0.08653, lr:4.34e-03, fs:0.73494 (r=0.616,p=0.910),  time:15.937, tt:2549.873\n",
      "Ep:160, loss:0.00001, loss_test:0.08665, lr:4.30e-03, fs:0.71951 (r=0.596,p=0.908),  time:15.940, tt:2566.305\n",
      "Ep:161, loss:0.00001, loss_test:0.08667, lr:4.26e-03, fs:0.71951 (r=0.596,p=0.908),  time:15.935, tt:2581.392\n",
      "Ep:162, loss:0.00001, loss_test:0.08665, lr:4.21e-03, fs:0.71951 (r=0.596,p=0.908),  time:15.933, tt:2597.059\n",
      "Ep:163, loss:0.00001, loss_test:0.08668, lr:4.17e-03, fs:0.71951 (r=0.596,p=0.908),  time:15.926, tt:2611.919\n",
      "Ep:164, loss:0.00001, loss_test:0.08678, lr:4.13e-03, fs:0.71951 (r=0.596,p=0.908),  time:15.923, tt:2627.314\n",
      "Ep:165, loss:0.00001, loss_test:0.08688, lr:4.09e-03, fs:0.71951 (r=0.596,p=0.908),  time:15.924, tt:2643.332\n",
      "Ep:166, loss:0.00001, loss_test:0.08695, lr:4.05e-03, fs:0.71166 (r=0.586,p=0.906),  time:15.920, tt:2658.691\n",
      "Ep:167, loss:0.00001, loss_test:0.08702, lr:4.01e-03, fs:0.71166 (r=0.586,p=0.906),  time:15.918, tt:2674.274\n",
      "Ep:168, loss:0.00001, loss_test:0.08706, lr:3.97e-03, fs:0.71166 (r=0.586,p=0.906),  time:15.916, tt:2689.773\n",
      "Ep:169, loss:0.00001, loss_test:0.08712, lr:3.93e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.919, tt:2706.208\n",
      "Ep:170, loss:0.00001, loss_test:0.08713, lr:3.89e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.921, tt:2722.525\n",
      "Ep:171, loss:0.00001, loss_test:0.08710, lr:3.85e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.925, tt:2739.111\n",
      "Ep:172, loss:0.00001, loss_test:0.08711, lr:3.81e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.922, tt:2754.459\n",
      "Ep:173, loss:0.00001, loss_test:0.08717, lr:3.77e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.921, tt:2770.286\n",
      "Ep:174, loss:0.00001, loss_test:0.08714, lr:3.73e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.917, tt:2785.462\n",
      "Ep:175, loss:0.00001, loss_test:0.08710, lr:3.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.913, tt:2800.765\n",
      "Ep:176, loss:0.00001, loss_test:0.08715, lr:3.66e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.909, tt:2815.883\n",
      "Ep:177, loss:0.00001, loss_test:0.08725, lr:3.62e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.903, tt:2830.658\n",
      "Ep:178, loss:0.00001, loss_test:0.08729, lr:3.59e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.900, tt:2846.186\n",
      "Ep:179, loss:0.00001, loss_test:0.08732, lr:3.55e-03, fs:0.71605 (r=0.586,p=0.921),  time:15.900, tt:2862.053\n",
      "Ep:180, loss:0.00001, loss_test:0.08730, lr:3.52e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.899, tt:2877.681\n",
      "Ep:181, loss:0.00001, loss_test:0.08732, lr:3.48e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.893, tt:2892.517\n",
      "Ep:182, loss:0.00001, loss_test:0.08743, lr:3.45e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.896, tt:2908.895\n",
      "Ep:183, loss:0.00001, loss_test:0.08761, lr:3.41e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.889, tt:2923.590\n",
      "Ep:184, loss:0.00001, loss_test:0.08771, lr:3.38e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.881, tt:2938.065\n",
      "Ep:185, loss:0.00001, loss_test:0.08776, lr:3.34e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.879, tt:2953.468\n",
      "Ep:186, loss:0.00001, loss_test:0.08783, lr:3.31e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.874, tt:2968.418\n",
      "Ep:187, loss:0.00001, loss_test:0.08781, lr:3.28e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.868, tt:2983.272\n",
      "Ep:188, loss:0.00001, loss_test:0.08780, lr:3.24e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.872, tt:2999.900\n",
      "Ep:189, loss:0.00001, loss_test:0.08788, lr:3.21e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.871, tt:3015.481\n",
      "Ep:190, loss:0.00001, loss_test:0.08793, lr:3.18e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.870, tt:3031.164\n",
      "Ep:191, loss:0.00001, loss_test:0.08793, lr:3.15e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.868, tt:3046.643\n",
      "Ep:192, loss:0.00001, loss_test:0.08793, lr:3.12e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.867, tt:3062.294\n",
      "Ep:193, loss:0.00001, loss_test:0.08798, lr:3.09e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.867, tt:3078.214\n",
      "Ep:194, loss:0.00001, loss_test:0.08804, lr:3.05e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.865, tt:3093.589\n",
      "Ep:195, loss:0.00001, loss_test:0.08815, lr:3.02e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.860, tt:3108.618\n",
      "Ep:196, loss:0.00001, loss_test:0.08820, lr:2.99e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.870, tt:3126.396\n",
      "Ep:197, loss:0.00001, loss_test:0.08818, lr:2.96e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.870, tt:3142.223\n",
      "Ep:198, loss:0.00001, loss_test:0.08822, lr:2.93e-03, fs:0.70807 (r=0.576,p=0.919),  time:15.866, tt:3157.329\n",
      "Ep:199, loss:0.00001, loss_test:0.08824, lr:2.90e-03, fs:0.71250 (r=0.576,p=0.934),  time:15.867, tt:3173.344\n",
      "Ep:200, loss:0.00001, loss_test:0.08824, lr:2.88e-03, fs:0.71250 (r=0.576,p=0.934),  time:15.870, tt:3189.778\n",
      "Ep:201, loss:0.00001, loss_test:0.08827, lr:2.85e-03, fs:0.71250 (r=0.576,p=0.934),  time:15.871, tt:3205.846\n",
      "Ep:202, loss:0.00001, loss_test:0.08839, lr:2.82e-03, fs:0.71250 (r=0.576,p=0.934),  time:15.870, tt:3221.517\n",
      "Ep:203, loss:0.00001, loss_test:0.08848, lr:2.79e-03, fs:0.71250 (r=0.576,p=0.934),  time:15.862, tt:3235.748\n",
      "Ep:204, loss:0.00001, loss_test:0.08853, lr:2.76e-03, fs:0.71250 (r=0.576,p=0.934),  time:15.866, tt:3252.539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00001, loss_test:0.08852, lr:2.73e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.868, tt:3268.862\n",
      "Ep:206, loss:0.00001, loss_test:0.08855, lr:2.71e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.871, tt:3285.313\n",
      "Ep:207, loss:0.00001, loss_test:0.08861, lr:2.68e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.875, tt:3302.048\n",
      "Ep:208, loss:0.00001, loss_test:0.08867, lr:2.65e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.873, tt:3317.398\n",
      "Ep:209, loss:0.00001, loss_test:0.08874, lr:2.63e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.874, tt:3333.549\n",
      "Ep:210, loss:0.00001, loss_test:0.08874, lr:2.60e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.873, tt:3349.197\n",
      "Ep:211, loss:0.00001, loss_test:0.08875, lr:2.57e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.872, tt:3364.800\n",
      "Ep:212, loss:0.00001, loss_test:0.08879, lr:2.55e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.872, tt:3380.669\n",
      "Ep:213, loss:0.00001, loss_test:0.08887, lr:2.52e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.870, tt:3396.240\n",
      "Ep:214, loss:0.00001, loss_test:0.08896, lr:2.50e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.869, tt:3411.754\n",
      "Ep:215, loss:0.00001, loss_test:0.08903, lr:2.47e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.867, tt:3427.168\n",
      "Ep:216, loss:0.00001, loss_test:0.08904, lr:2.45e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.868, tt:3443.363\n",
      "Ep:217, loss:0.00001, loss_test:0.08905, lr:2.42e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.865, tt:3458.642\n",
      "Ep:218, loss:0.00001, loss_test:0.08909, lr:2.40e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.865, tt:3474.517\n",
      "Ep:219, loss:0.00001, loss_test:0.08913, lr:2.38e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.870, tt:3491.441\n",
      "Ep:220, loss:0.00001, loss_test:0.08915, lr:2.35e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.865, tt:3506.122\n",
      "Ep:221, loss:0.00001, loss_test:0.08918, lr:2.33e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.863, tt:3521.618\n",
      "Ep:222, loss:0.00001, loss_test:0.08923, lr:2.31e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.861, tt:3537.056\n",
      "Ep:223, loss:0.00001, loss_test:0.08927, lr:2.28e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.857, tt:3552.062\n",
      "Ep:224, loss:0.00001, loss_test:0.08926, lr:2.26e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.853, tt:3566.826\n",
      "Ep:225, loss:0.00001, loss_test:0.08929, lr:2.24e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.848, tt:3581.732\n",
      "Ep:226, loss:0.00001, loss_test:0.08935, lr:2.21e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.850, tt:3598.040\n",
      "Ep:227, loss:0.00001, loss_test:0.08930, lr:2.19e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.849, tt:3613.565\n",
      "Ep:228, loss:0.00001, loss_test:0.08930, lr:2.17e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.848, tt:3629.292\n",
      "Ep:229, loss:0.00001, loss_test:0.08940, lr:2.15e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.848, tt:3644.939\n",
      "Ep:230, loss:0.00001, loss_test:0.08947, lr:2.13e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.849, tt:3661.230\n",
      "Ep:231, loss:0.00001, loss_test:0.08943, lr:2.11e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.847, tt:3676.461\n",
      "Ep:232, loss:0.00001, loss_test:0.08941, lr:2.08e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.839, tt:3690.604\n",
      "Ep:233, loss:0.00001, loss_test:0.08947, lr:2.06e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.842, tt:3707.115\n",
      "Ep:234, loss:0.00001, loss_test:0.08951, lr:2.04e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.841, tt:3722.727\n",
      "Ep:235, loss:0.00001, loss_test:0.08946, lr:2.02e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.843, tt:3738.946\n",
      "Ep:236, loss:0.00001, loss_test:0.08949, lr:2.00e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.857, tt:3758.153\n",
      "Ep:237, loss:0.00001, loss_test:0.08958, lr:1.98e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.856, tt:3773.690\n",
      "Ep:238, loss:0.00001, loss_test:0.08957, lr:1.96e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.855, tt:3789.308\n",
      "Ep:239, loss:0.00001, loss_test:0.08951, lr:1.94e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.851, tt:3804.355\n",
      "Ep:240, loss:0.00001, loss_test:0.08952, lr:1.92e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.852, tt:3820.435\n",
      "Ep:241, loss:0.00001, loss_test:0.08959, lr:1.90e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.850, tt:3835.815\n",
      "Ep:242, loss:0.00001, loss_test:0.08963, lr:1.89e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.848, tt:3851.186\n",
      "Ep:243, loss:0.00001, loss_test:0.08961, lr:1.87e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.849, tt:3867.241\n",
      "Ep:244, loss:0.00001, loss_test:0.08961, lr:1.85e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.849, tt:3883.071\n",
      "Ep:245, loss:0.00001, loss_test:0.08964, lr:1.83e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.846, tt:3897.995\n",
      "Ep:246, loss:0.00001, loss_test:0.08965, lr:1.81e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.846, tt:3913.939\n",
      "Ep:247, loss:0.00001, loss_test:0.08967, lr:1.79e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.846, tt:3929.859\n",
      "Ep:248, loss:0.00001, loss_test:0.08969, lr:1.78e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.850, tt:3946.662\n",
      "Ep:249, loss:0.00001, loss_test:0.08970, lr:1.76e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.854, tt:3963.376\n",
      "Ep:250, loss:0.00001, loss_test:0.08968, lr:1.74e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.858, tt:3980.476\n",
      "Ep:251, loss:0.00001, loss_test:0.08970, lr:1.72e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.857, tt:3995.842\n",
      "Ep:252, loss:0.00001, loss_test:0.08975, lr:1.71e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.855, tt:4011.245\n",
      "Ep:253, loss:0.00001, loss_test:0.08977, lr:1.69e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.854, tt:4026.963\n",
      "Ep:254, loss:0.00001, loss_test:0.08970, lr:1.67e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.855, tt:4043.083\n",
      "Ep:255, loss:0.00001, loss_test:0.08971, lr:1.65e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.857, tt:4059.422\n",
      "Ep:256, loss:0.00001, loss_test:0.08982, lr:1.64e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.855, tt:4074.801\n",
      "Ep:257, loss:0.00001, loss_test:0.08986, lr:1.62e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.854, tt:4090.454\n",
      "Ep:258, loss:0.00001, loss_test:0.08980, lr:1.61e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.854, tt:4106.213\n",
      "Ep:259, loss:0.00001, loss_test:0.08975, lr:1.59e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.852, tt:4121.541\n",
      "Ep:260, loss:0.00001, loss_test:0.08977, lr:1.57e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.851, tt:4137.224\n",
      "Ep:261, loss:0.00001, loss_test:0.08984, lr:1.56e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.851, tt:4153.004\n",
      "Ep:262, loss:0.00001, loss_test:0.08987, lr:1.54e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.850, tt:4168.520\n",
      "Ep:263, loss:0.00001, loss_test:0.08984, lr:1.53e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.850, tt:4184.471\n",
      "Ep:264, loss:0.00001, loss_test:0.08982, lr:1.51e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.850, tt:4200.257\n",
      "Ep:265, loss:0.00001, loss_test:0.08986, lr:1.50e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.853, tt:4216.861\n",
      "Ep:266, loss:0.00001, loss_test:0.08989, lr:1.48e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.854, tt:4232.958\n",
      "Ep:267, loss:0.00001, loss_test:0.08987, lr:1.47e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.852, tt:4248.456\n",
      "Ep:268, loss:0.00001, loss_test:0.08983, lr:1.45e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.854, tt:4264.763\n",
      "Ep:269, loss:0.00001, loss_test:0.08985, lr:1.44e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.857, tt:4281.263\n",
      "Ep:270, loss:0.00001, loss_test:0.08988, lr:1.42e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.858, tt:4297.514\n",
      "Ep:271, loss:0.00001, loss_test:0.08985, lr:1.41e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.859, tt:4313.550\n",
      "Ep:272, loss:0.00001, loss_test:0.08981, lr:1.39e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.860, tt:4329.688\n",
      "Ep:273, loss:0.00001, loss_test:0.08981, lr:1.38e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.858, tt:4345.080\n",
      "Ep:274, loss:0.00001, loss_test:0.08981, lr:1.37e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.856, tt:4360.458\n",
      "Ep:275, loss:0.00001, loss_test:0.08983, lr:1.35e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.858, tt:4376.941\n",
      "Ep:276, loss:0.00001, loss_test:0.08985, lr:1.34e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.858, tt:4392.581\n",
      "Ep:277, loss:0.00001, loss_test:0.08982, lr:1.33e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.865, tt:4410.351\n",
      "Ep:278, loss:0.00001, loss_test:0.08978, lr:1.31e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.867, tt:4426.756\n",
      "Ep:279, loss:0.00001, loss_test:0.08981, lr:1.30e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.866, tt:4442.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:280, loss:0.00001, loss_test:0.08984, lr:1.29e-03, fs:0.70440 (r=0.566,p=0.933),  time:15.866, tt:4458.413\n",
      "Ep:281, loss:0.00001, loss_test:0.08980, lr:1.27e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.869, tt:4475.065\n",
      "Ep:282, loss:0.00001, loss_test:0.08978, lr:1.26e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.865, tt:4489.935\n",
      "Ep:283, loss:0.00001, loss_test:0.08981, lr:1.25e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.864, tt:4505.462\n",
      "Ep:284, loss:0.00001, loss_test:0.08982, lr:1.24e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.866, tt:4521.774\n",
      "Ep:285, loss:0.00001, loss_test:0.08980, lr:1.22e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.868, tt:4538.295\n",
      "Ep:286, loss:0.00001, loss_test:0.08979, lr:1.21e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.877, tt:4556.724\n",
      "Ep:287, loss:0.00001, loss_test:0.08983, lr:1.20e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.882, tt:4573.948\n",
      "Ep:288, loss:0.00001, loss_test:0.08980, lr:1.19e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.887, tt:4591.200\n",
      "Ep:289, loss:0.00001, loss_test:0.08981, lr:1.18e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.886, tt:4606.851\n",
      "Ep:290, loss:0.00001, loss_test:0.08982, lr:1.16e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.889, tt:4623.742\n",
      "Ep:291, loss:0.00001, loss_test:0.08981, lr:1.15e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.889, tt:4639.544\n",
      "Ep:292, loss:0.00001, loss_test:0.08983, lr:1.14e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.890, tt:4655.671\n",
      "Ep:293, loss:0.00001, loss_test:0.08981, lr:1.13e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.888, tt:4671.041\n",
      "Ep:294, loss:0.00001, loss_test:0.08981, lr:1.12e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.884, tt:4685.890\n",
      "Ep:295, loss:0.00001, loss_test:0.08983, lr:1.11e-03, fs:0.70886 (r=0.566,p=0.949),  time:15.883, tt:4701.308\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14810, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.772, tt:16.772\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14798, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.599, tt:37.198\n",
      "Ep:2, loss:0.00004, loss_test:0.14779, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.172, tt:57.515\n",
      "Ep:3, loss:0.00004, loss_test:0.14755, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.413, tt:77.653\n",
      "Ep:4, loss:0.00004, loss_test:0.14724, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.999, tt:99.997\n",
      "Ep:5, loss:0.00004, loss_test:0.14686, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.053, tt:120.319\n",
      "Ep:6, loss:0.00004, loss_test:0.14634, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.180, tt:141.263\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.14562, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.284, tt:162.271\n",
      "Ep:8, loss:0.00004, loss_test:0.14465, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:20.296, tt:182.661\n",
      "Ep:9, loss:0.00004, loss_test:0.14334, lr:1.00e-02, fs:0.63380 (r=0.909,p=0.486),  time:20.285, tt:202.848\n",
      "Ep:10, loss:0.00004, loss_test:0.14173, lr:1.00e-02, fs:0.61429 (r=0.869,p=0.475),  time:20.171, tt:221.883\n",
      "Ep:11, loss:0.00004, loss_test:0.13968, lr:1.00e-02, fs:0.61481 (r=0.838,p=0.485),  time:20.169, tt:242.033\n",
      "Ep:12, loss:0.00004, loss_test:0.13745, lr:1.00e-02, fs:0.61417 (r=0.788,p=0.503),  time:20.194, tt:262.523\n",
      "Ep:13, loss:0.00003, loss_test:0.13466, lr:1.00e-02, fs:0.58772 (r=0.677,p=0.519),  time:20.299, tt:284.193\n",
      "Ep:14, loss:0.00003, loss_test:0.13359, lr:1.00e-02, fs:0.56000 (r=0.566,p=0.554),  time:20.311, tt:304.664\n",
      "Ep:15, loss:0.00003, loss_test:0.13311, lr:1.00e-02, fs:0.54737 (r=0.525,p=0.571),  time:20.234, tt:323.741\n",
      "Ep:16, loss:0.00003, loss_test:0.13266, lr:1.00e-02, fs:0.55435 (r=0.515,p=0.600),  time:20.457, tt:347.772\n",
      "Ep:17, loss:0.00003, loss_test:0.13092, lr:1.00e-02, fs:0.57143 (r=0.545,p=0.600),  time:20.454, tt:368.168\n",
      "Ep:18, loss:0.00003, loss_test:0.12863, lr:9.90e-03, fs:0.56701 (r=0.556,p=0.579),  time:20.447, tt:388.487\n",
      "Ep:19, loss:0.00003, loss_test:0.12679, lr:9.80e-03, fs:0.57711 (r=0.586,p=0.569),  time:20.465, tt:409.306\n",
      "Ep:20, loss:0.00003, loss_test:0.12549, lr:9.70e-03, fs:0.59406 (r=0.606,p=0.583),  time:20.457, tt:429.592\n",
      "Ep:21, loss:0.00003, loss_test:0.12406, lr:9.61e-03, fs:0.60302 (r=0.606,p=0.600),  time:20.506, tt:451.139\n",
      "Ep:22, loss:0.00003, loss_test:0.12351, lr:9.51e-03, fs:0.60870 (r=0.566,p=0.659),  time:20.501, tt:471.523\n",
      "Ep:23, loss:0.00003, loss_test:0.12341, lr:9.41e-03, fs:0.60819 (r=0.525,p=0.722),  time:20.488, tt:491.714\n",
      "Ep:24, loss:0.00003, loss_test:0.12274, lr:9.32e-03, fs:0.61538 (r=0.525,p=0.743),  time:20.514, tt:512.845\n",
      "Ep:25, loss:0.00003, loss_test:0.12029, lr:9.23e-03, fs:0.61176 (r=0.525,p=0.732),  time:20.532, tt:533.840\n",
      "Ep:26, loss:0.00003, loss_test:0.11719, lr:9.14e-03, fs:0.63218 (r=0.556,p=0.733),  time:20.569, tt:555.353\n",
      "Ep:27, loss:0.00003, loss_test:0.11449, lr:9.04e-03, fs:0.63736 (r=0.586,p=0.699),  time:20.600, tt:576.795\n",
      "Ep:28, loss:0.00003, loss_test:0.11276, lr:8.95e-03, fs:0.65217 (r=0.606,p=0.706),  time:20.576, tt:596.706\n",
      "Ep:29, loss:0.00003, loss_test:0.11143, lr:8.86e-03, fs:0.65556 (r=0.596,p=0.728),  time:20.528, tt:615.846\n",
      "Ep:30, loss:0.00002, loss_test:0.11038, lr:8.78e-03, fs:0.64407 (r=0.576,p=0.731),  time:20.509, tt:635.776\n",
      "Ep:31, loss:0.00002, loss_test:0.10972, lr:8.69e-03, fs:0.62857 (r=0.556,p=0.724),  time:20.490, tt:655.673\n",
      "Ep:32, loss:0.00002, loss_test:0.10837, lr:8.60e-03, fs:0.62857 (r=0.556,p=0.724),  time:20.525, tt:677.336\n",
      "Ep:33, loss:0.00002, loss_test:0.10632, lr:8.51e-03, fs:0.62857 (r=0.556,p=0.724),  time:20.510, tt:697.328\n",
      "Ep:34, loss:0.00002, loss_test:0.10452, lr:8.43e-03, fs:0.64804 (r=0.586,p=0.725),  time:20.511, tt:717.897\n",
      "Ep:35, loss:0.00002, loss_test:0.10308, lr:8.35e-03, fs:0.67760 (r=0.626,p=0.738),  time:20.519, tt:738.668\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.10161, lr:8.35e-03, fs:0.67033 (r=0.616,p=0.735),  time:20.505, tt:758.691\n",
      "Ep:37, loss:0.00002, loss_test:0.10039, lr:8.35e-03, fs:0.66298 (r=0.606,p=0.732),  time:20.501, tt:779.039\n",
      "Ep:38, loss:0.00002, loss_test:0.09940, lr:8.35e-03, fs:0.67033 (r=0.616,p=0.735),  time:20.492, tt:799.199\n",
      "Ep:39, loss:0.00002, loss_test:0.09828, lr:8.35e-03, fs:0.67760 (r=0.626,p=0.738),  time:20.492, tt:819.680\n",
      "Ep:40, loss:0.00002, loss_test:0.09713, lr:8.35e-03, fs:0.69892 (r=0.657,p=0.747),  time:20.499, tt:840.455\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.09624, lr:8.35e-03, fs:0.71958 (r=0.687,p=0.756),  time:20.510, tt:861.411\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.09556, lr:8.35e-03, fs:0.74737 (r=0.717,p=0.780),  time:20.551, tt:883.710\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.09498, lr:8.35e-03, fs:0.73404 (r=0.697,p=0.775),  time:20.560, tt:904.637\n",
      "Ep:44, loss:0.00002, loss_test:0.09431, lr:8.35e-03, fs:0.73404 (r=0.697,p=0.775),  time:20.543, tt:924.451\n",
      "Ep:45, loss:0.00002, loss_test:0.09344, lr:8.35e-03, fs:0.74737 (r=0.717,p=0.780),  time:20.531, tt:944.418\n",
      "Ep:46, loss:0.00002, loss_test:0.09251, lr:8.35e-03, fs:0.76684 (r=0.747,p=0.787),  time:20.518, tt:964.354\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.09165, lr:8.35e-03, fs:0.76684 (r=0.747,p=0.787),  time:20.544, tt:986.088\n",
      "Ep:48, loss:0.00002, loss_test:0.09098, lr:8.35e-03, fs:0.75393 (r=0.727,p=0.783),  time:20.534, tt:1006.180\n",
      "Ep:49, loss:0.00002, loss_test:0.09039, lr:8.35e-03, fs:0.75789 (r=0.727,p=0.791),  time:20.546, tt:1027.323\n",
      "Ep:50, loss:0.00002, loss_test:0.08975, lr:8.35e-03, fs:0.75132 (r=0.717,p=0.789),  time:20.535, tt:1047.263\n",
      "Ep:51, loss:0.00002, loss_test:0.08904, lr:8.35e-03, fs:0.76842 (r=0.737,p=0.802),  time:20.558, tt:1069.035\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.08836, lr:8.35e-03, fs:0.76440 (r=0.737,p=0.793),  time:20.558, tt:1089.577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00002, loss_test:0.08782, lr:8.35e-03, fs:0.77083 (r=0.747,p=0.796),  time:20.557, tt:1110.061\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.08736, lr:8.35e-03, fs:0.77895 (r=0.747,p=0.813),  time:20.580, tt:1131.895\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.08689, lr:8.35e-03, fs:0.78307 (r=0.747,p=0.822),  time:20.562, tt:1151.500\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.08646, lr:8.35e-03, fs:0.79570 (r=0.747,p=0.851),  time:20.552, tt:1171.467\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.08607, lr:8.35e-03, fs:0.78919 (r=0.737,p=0.849),  time:20.562, tt:1192.572\n",
      "Ep:58, loss:0.00002, loss_test:0.08564, lr:8.35e-03, fs:0.78919 (r=0.737,p=0.849),  time:20.561, tt:1213.090\n",
      "Ep:59, loss:0.00002, loss_test:0.08507, lr:8.35e-03, fs:0.80435 (r=0.747,p=0.871),  time:20.554, tt:1233.249\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.08436, lr:8.35e-03, fs:0.80000 (r=0.747,p=0.860),  time:20.547, tt:1253.367\n",
      "Ep:61, loss:0.00002, loss_test:0.08366, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:20.552, tt:1274.223\n",
      "Ep:62, loss:0.00002, loss_test:0.08332, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.562, tt:1295.409\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.08311, lr:8.35e-03, fs:0.81319 (r=0.747,p=0.892),  time:20.559, tt:1315.806\n",
      "Ep:64, loss:0.00001, loss_test:0.08280, lr:8.35e-03, fs:0.81319 (r=0.747,p=0.892),  time:20.542, tt:1335.214\n",
      "Ep:65, loss:0.00001, loss_test:0.08240, lr:8.35e-03, fs:0.80663 (r=0.737,p=0.890),  time:20.535, tt:1355.337\n",
      "Ep:66, loss:0.00001, loss_test:0.08211, lr:8.35e-03, fs:0.80000 (r=0.727,p=0.889),  time:20.544, tt:1376.473\n",
      "Ep:67, loss:0.00001, loss_test:0.08205, lr:8.35e-03, fs:0.80000 (r=0.727,p=0.889),  time:20.541, tt:1396.762\n",
      "Ep:68, loss:0.00001, loss_test:0.08195, lr:8.35e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.535, tt:1416.895\n",
      "Ep:69, loss:0.00001, loss_test:0.08160, lr:8.35e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.522, tt:1436.509\n",
      "Ep:70, loss:0.00001, loss_test:0.08105, lr:8.35e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.516, tt:1456.651\n",
      "Ep:71, loss:0.00001, loss_test:0.08070, lr:8.35e-03, fs:0.79096 (r=0.707,p=0.897),  time:20.490, tt:1475.282\n",
      "Ep:72, loss:0.00001, loss_test:0.08062, lr:8.35e-03, fs:0.77011 (r=0.677,p=0.893),  time:20.480, tt:1495.050\n",
      "Ep:73, loss:0.00001, loss_test:0.08067, lr:8.35e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.469, tt:1514.690\n",
      "Ep:74, loss:0.00001, loss_test:0.08051, lr:8.26e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.479, tt:1535.952\n",
      "Ep:75, loss:0.00001, loss_test:0.08031, lr:8.18e-03, fs:0.77011 (r=0.677,p=0.893),  time:20.481, tt:1556.535\n",
      "Ep:76, loss:0.00001, loss_test:0.08010, lr:8.10e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.465, tt:1575.794\n",
      "Ep:77, loss:0.00001, loss_test:0.07979, lr:8.02e-03, fs:0.76571 (r=0.677,p=0.882),  time:20.452, tt:1595.221\n",
      "Ep:78, loss:0.00001, loss_test:0.07966, lr:7.94e-03, fs:0.75862 (r=0.667,p=0.880),  time:20.451, tt:1615.627\n",
      "Ep:79, loss:0.00001, loss_test:0.07966, lr:7.86e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.450, tt:1636.008\n",
      "Ep:80, loss:0.00001, loss_test:0.07941, lr:7.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.448, tt:1656.271\n",
      "Ep:81, loss:0.00001, loss_test:0.07887, lr:7.70e-03, fs:0.75145 (r=0.657,p=0.878),  time:20.443, tt:1676.318\n",
      "Ep:82, loss:0.00001, loss_test:0.07854, lr:7.62e-03, fs:0.74854 (r=0.646,p=0.889),  time:20.436, tt:1696.170\n",
      "Ep:83, loss:0.00001, loss_test:0.07855, lr:7.55e-03, fs:0.75294 (r=0.646,p=0.901),  time:20.438, tt:1716.766\n",
      "Ep:84, loss:0.00001, loss_test:0.07853, lr:7.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.424, tt:1736.071\n",
      "Ep:85, loss:0.00001, loss_test:0.07804, lr:7.40e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.418, tt:1755.910\n",
      "Ep:86, loss:0.00001, loss_test:0.07762, lr:7.32e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.417, tt:1776.249\n",
      "Ep:87, loss:0.00001, loss_test:0.07762, lr:7.25e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.426, tt:1797.524\n",
      "Ep:88, loss:0.00001, loss_test:0.07743, lr:7.18e-03, fs:0.77108 (r=0.646,p=0.955),  time:20.426, tt:1817.937\n",
      "Ep:89, loss:0.00001, loss_test:0.07731, lr:7.11e-03, fs:0.77844 (r=0.657,p=0.956),  time:20.426, tt:1838.347\n",
      "Ep:90, loss:0.00001, loss_test:0.07691, lr:7.03e-03, fs:0.77844 (r=0.657,p=0.956),  time:20.431, tt:1859.226\n",
      "Ep:91, loss:0.00001, loss_test:0.07677, lr:6.96e-03, fs:0.77108 (r=0.646,p=0.955),  time:20.440, tt:1880.438\n",
      "Ep:92, loss:0.00001, loss_test:0.07689, lr:6.89e-03, fs:0.76364 (r=0.636,p=0.955),  time:20.432, tt:1900.168\n",
      "Ep:93, loss:0.00001, loss_test:0.07672, lr:6.83e-03, fs:0.75610 (r=0.626,p=0.954),  time:20.431, tt:1920.559\n",
      "Ep:94, loss:0.00001, loss_test:0.07643, lr:6.76e-03, fs:0.75610 (r=0.626,p=0.954),  time:20.429, tt:1940.771\n",
      "Ep:95, loss:0.00001, loss_test:0.07633, lr:6.69e-03, fs:0.75610 (r=0.626,p=0.954),  time:20.419, tt:1960.178\n",
      "Ep:96, loss:0.00001, loss_test:0.07640, lr:6.62e-03, fs:0.75610 (r=0.626,p=0.954),  time:20.415, tt:1980.282\n",
      "Ep:97, loss:0.00001, loss_test:0.07634, lr:6.56e-03, fs:0.74847 (r=0.616,p=0.953),  time:20.410, tt:2000.137\n",
      "Ep:98, loss:0.00001, loss_test:0.07598, lr:6.49e-03, fs:0.74847 (r=0.616,p=0.953),  time:20.402, tt:2019.797\n",
      "Ep:99, loss:0.00001, loss_test:0.07588, lr:6.43e-03, fs:0.74847 (r=0.616,p=0.953),  time:20.395, tt:2039.540\n",
      "Ep:100, loss:0.00001, loss_test:0.07611, lr:6.36e-03, fs:0.75309 (r=0.616,p=0.968),  time:20.391, tt:2059.497\n",
      "Ep:101, loss:0.00001, loss_test:0.07607, lr:6.30e-03, fs:0.75309 (r=0.616,p=0.968),  time:20.372, tt:2077.984\n",
      "Ep:102, loss:0.00001, loss_test:0.07594, lr:6.24e-03, fs:0.74534 (r=0.606,p=0.968),  time:20.373, tt:2098.434\n",
      "Ep:103, loss:0.00001, loss_test:0.07570, lr:6.17e-03, fs:0.75309 (r=0.616,p=0.968),  time:20.381, tt:2119.601\n",
      "Ep:104, loss:0.00001, loss_test:0.07569, lr:6.11e-03, fs:0.74534 (r=0.606,p=0.968),  time:20.374, tt:2139.240\n",
      "Ep:105, loss:0.00001, loss_test:0.07567, lr:6.05e-03, fs:0.74534 (r=0.606,p=0.968),  time:20.361, tt:2158.232\n",
      "Ep:106, loss:0.00001, loss_test:0.07551, lr:5.99e-03, fs:0.76074 (r=0.626,p=0.969),  time:20.352, tt:2177.623\n",
      "Ep:107, loss:0.00001, loss_test:0.07528, lr:5.93e-03, fs:0.76074 (r=0.626,p=0.969),  time:20.373, tt:2200.286\n",
      "Ep:108, loss:0.00001, loss_test:0.07524, lr:5.87e-03, fs:0.76074 (r=0.626,p=0.969),  time:20.375, tt:2220.888\n",
      "Ep:109, loss:0.00001, loss_test:0.07540, lr:5.81e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.380, tt:2241.787\n",
      "Ep:110, loss:0.00001, loss_test:0.07542, lr:5.75e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.378, tt:2261.911\n",
      "Ep:111, loss:0.00001, loss_test:0.07502, lr:5.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.366, tt:2280.962\n",
      "Ep:112, loss:0.00001, loss_test:0.07499, lr:5.64e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.358, tt:2300.502\n",
      "Ep:113, loss:0.00001, loss_test:0.07518, lr:5.58e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.346, tt:2319.489\n",
      "Ep:114, loss:0.00001, loss_test:0.07507, lr:5.53e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.332, tt:2338.138\n",
      "Ep:115, loss:0.00001, loss_test:0.07493, lr:5.47e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.317, tt:2356.790\n",
      "Ep:116, loss:0.00001, loss_test:0.07508, lr:5.42e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.290, tt:2373.981\n",
      "Ep:117, loss:0.00001, loss_test:0.07534, lr:5.36e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.278, tt:2392.815\n",
      "Ep:118, loss:0.00001, loss_test:0.07519, lr:5.31e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.253, tt:2410.130\n",
      "Ep:119, loss:0.00001, loss_test:0.07474, lr:5.26e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.238, tt:2428.535\n",
      "Ep:120, loss:0.00001, loss_test:0.07491, lr:5.20e-03, fs:0.76543 (r=0.626,p=0.984),  time:20.231, tt:2447.943\n",
      "Ep:121, loss:0.00001, loss_test:0.07521, lr:5.15e-03, fs:0.75000 (r=0.606,p=0.984),  time:20.223, tt:2467.255\n",
      "Ep:122, loss:0.00001, loss_test:0.07514, lr:5.10e-03, fs:0.75000 (r=0.606,p=0.984),  time:20.218, tt:2486.842\n",
      "Ep:123, loss:0.00001, loss_test:0.07491, lr:5.05e-03, fs:0.75776 (r=0.616,p=0.984),  time:20.225, tt:2507.918\n",
      "Ep:124, loss:0.00001, loss_test:0.07509, lr:5.00e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.219, tt:2527.352\n",
      "Ep:125, loss:0.00001, loss_test:0.07532, lr:4.95e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.230, tt:2548.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00001, loss_test:0.07515, lr:4.90e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.230, tt:2569.273\n",
      "Ep:127, loss:0.00001, loss_test:0.07502, lr:4.85e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.219, tt:2588.070\n",
      "Ep:128, loss:0.00001, loss_test:0.07506, lr:4.80e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.214, tt:2607.552\n",
      "Ep:129, loss:0.00001, loss_test:0.07513, lr:4.75e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.208, tt:2626.978\n",
      "Ep:130, loss:0.00001, loss_test:0.07498, lr:4.71e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.209, tt:2647.428\n",
      "Ep:131, loss:0.00001, loss_test:0.07499, lr:4.66e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.209, tt:2667.592\n",
      "Ep:132, loss:0.00001, loss_test:0.07496, lr:4.61e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.204, tt:2687.148\n",
      "Ep:133, loss:0.00001, loss_test:0.07490, lr:4.57e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.198, tt:2706.552\n",
      "Ep:134, loss:0.00001, loss_test:0.07492, lr:4.52e-03, fs:0.74214 (r=0.596,p=0.983),  time:20.198, tt:2726.767\n",
      "Ep:135, loss:0.00001, loss_test:0.07499, lr:4.48e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.194, tt:2746.436\n",
      "Ep:136, loss:0.00001, loss_test:0.07497, lr:4.43e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.196, tt:2766.835\n",
      "Ep:137, loss:0.00001, loss_test:0.07500, lr:4.39e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.197, tt:2787.182\n",
      "Ep:138, loss:0.00001, loss_test:0.07517, lr:4.34e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.203, tt:2808.241\n",
      "Ep:139, loss:0.00001, loss_test:0.07518, lr:4.30e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.214, tt:2829.904\n",
      "Ep:140, loss:0.00001, loss_test:0.07515, lr:4.26e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.208, tt:2849.342\n",
      "Ep:141, loss:0.00001, loss_test:0.07521, lr:4.21e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.207, tt:2869.377\n",
      "Ep:142, loss:0.00001, loss_test:0.07516, lr:4.17e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.205, tt:2889.264\n",
      "Ep:143, loss:0.00000, loss_test:0.07519, lr:4.13e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.207, tt:2909.804\n",
      "Ep:144, loss:0.00000, loss_test:0.07532, lr:4.09e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.211, tt:2930.552\n",
      "Ep:145, loss:0.00000, loss_test:0.07525, lr:4.05e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.205, tt:2949.923\n",
      "Ep:146, loss:0.00000, loss_test:0.07514, lr:4.01e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.197, tt:2968.915\n",
      "Ep:147, loss:0.00000, loss_test:0.07510, lr:3.97e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.195, tt:2988.926\n",
      "Ep:148, loss:0.00000, loss_test:0.07530, lr:3.93e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.199, tt:3009.691\n",
      "Ep:149, loss:0.00000, loss_test:0.07527, lr:3.89e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.203, tt:3030.433\n",
      "Ep:150, loss:0.00000, loss_test:0.07509, lr:3.85e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.201, tt:3050.357\n",
      "Ep:151, loss:0.00000, loss_test:0.07511, lr:3.81e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.204, tt:3070.948\n",
      "Ep:152, loss:0.00000, loss_test:0.07529, lr:3.77e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.203, tt:3091.123\n",
      "Ep:153, loss:0.00000, loss_test:0.07528, lr:3.73e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.204, tt:3111.434\n",
      "Ep:154, loss:0.00000, loss_test:0.07515, lr:3.70e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.209, tt:3132.349\n",
      "Ep:155, loss:0.00000, loss_test:0.07536, lr:3.66e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.212, tt:3153.034\n",
      "Ep:156, loss:0.00000, loss_test:0.07530, lr:3.62e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.213, tt:3173.422\n",
      "Ep:157, loss:0.00000, loss_test:0.07519, lr:3.59e-03, fs:0.73418 (r=0.586,p=0.983),  time:20.217, tt:3194.237\n",
      "Ep:158, loss:0.00000, loss_test:0.07542, lr:3.55e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.218, tt:3214.644\n",
      "Ep:159, loss:0.00000, loss_test:0.07550, lr:3.52e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.222, tt:3235.454\n",
      "Ep:160, loss:0.00000, loss_test:0.07536, lr:3.48e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.214, tt:3254.481\n",
      "Ep:161, loss:0.00000, loss_test:0.07562, lr:3.45e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.217, tt:3275.091\n",
      "Ep:162, loss:0.00000, loss_test:0.07573, lr:3.41e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.215, tt:3295.099\n",
      "Ep:163, loss:0.00000, loss_test:0.07560, lr:3.38e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.221, tt:3316.200\n",
      "Ep:164, loss:0.00000, loss_test:0.07568, lr:3.34e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.223, tt:3336.851\n",
      "Ep:165, loss:0.00000, loss_test:0.07583, lr:3.31e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.237, tt:3359.278\n",
      "Ep:166, loss:0.00000, loss_test:0.07589, lr:3.28e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.234, tt:3379.057\n",
      "Ep:167, loss:0.00000, loss_test:0.07584, lr:3.24e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.230, tt:3398.670\n",
      "Ep:168, loss:0.00000, loss_test:0.07600, lr:3.21e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.233, tt:3419.340\n",
      "Ep:169, loss:0.00000, loss_test:0.07614, lr:3.18e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.237, tt:3440.219\n",
      "Ep:170, loss:0.00000, loss_test:0.07608, lr:3.15e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.232, tt:3459.586\n",
      "Ep:171, loss:0.00000, loss_test:0.07620, lr:3.12e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.236, tt:3480.614\n",
      "Ep:172, loss:0.00000, loss_test:0.07628, lr:3.09e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.239, tt:3501.429\n",
      "Ep:173, loss:0.00000, loss_test:0.07626, lr:3.05e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.233, tt:3520.493\n",
      "Ep:174, loss:0.00000, loss_test:0.07627, lr:3.02e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.232, tt:3540.671\n",
      "Ep:175, loss:0.00000, loss_test:0.07634, lr:2.99e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.232, tt:3560.819\n",
      "Ep:176, loss:0.00000, loss_test:0.07637, lr:2.96e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.237, tt:3581.939\n",
      "Ep:177, loss:0.00000, loss_test:0.07639, lr:2.93e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.236, tt:3601.991\n",
      "Ep:178, loss:0.00000, loss_test:0.07650, lr:2.90e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.236, tt:3622.317\n",
      "Ep:179, loss:0.00000, loss_test:0.07666, lr:2.88e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.237, tt:3642.700\n",
      "Ep:180, loss:0.00000, loss_test:0.07661, lr:2.85e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.242, tt:3663.743\n",
      "Ep:181, loss:0.00000, loss_test:0.07675, lr:2.82e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.241, tt:3683.886\n",
      "Ep:182, loss:0.00000, loss_test:0.07689, lr:2.79e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.243, tt:3704.473\n",
      "Ep:183, loss:0.00000, loss_test:0.07681, lr:2.76e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.238, tt:3723.857\n",
      "Ep:184, loss:0.00000, loss_test:0.07682, lr:2.73e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.231, tt:3742.792\n",
      "Ep:185, loss:0.00000, loss_test:0.07708, lr:2.71e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.230, tt:3762.791\n",
      "Ep:186, loss:0.00000, loss_test:0.07718, lr:2.68e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.221, tt:3781.368\n",
      "Ep:187, loss:0.00000, loss_test:0.07708, lr:2.65e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.225, tt:3802.319\n",
      "Ep:188, loss:0.00000, loss_test:0.07710, lr:2.63e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.228, tt:3823.070\n",
      "Ep:189, loss:0.00000, loss_test:0.07736, lr:2.60e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.225, tt:3842.662\n",
      "Ep:190, loss:0.00000, loss_test:0.07749, lr:2.57e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.228, tt:3863.482\n",
      "Ep:191, loss:0.00000, loss_test:0.07744, lr:2.55e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.228, tt:3883.731\n",
      "Ep:192, loss:0.00000, loss_test:0.07748, lr:2.52e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.227, tt:3903.840\n",
      "Ep:193, loss:0.00000, loss_test:0.07764, lr:2.50e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.220, tt:3922.737\n",
      "Ep:194, loss:0.00000, loss_test:0.07768, lr:2.47e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.215, tt:3941.991\n",
      "Ep:195, loss:0.00000, loss_test:0.07765, lr:2.45e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.213, tt:3961.682\n",
      "Ep:196, loss:0.00000, loss_test:0.07787, lr:2.42e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.215, tt:3982.317\n",
      "Ep:197, loss:0.00000, loss_test:0.07797, lr:2.40e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.205, tt:4000.666\n",
      "Ep:198, loss:0.00000, loss_test:0.07795, lr:2.38e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.208, tt:4021.317\n",
      "Ep:199, loss:0.00000, loss_test:0.07800, lr:2.35e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.210, tt:4041.939\n",
      "Ep:200, loss:0.00000, loss_test:0.07814, lr:2.33e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.205, tt:4061.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:201, loss:0.00000, loss_test:0.07812, lr:2.31e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.200, tt:4080.470\n",
      "Ep:202, loss:0.00000, loss_test:0.07808, lr:2.28e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.197, tt:4100.071\n",
      "Ep:203, loss:0.00000, loss_test:0.07827, lr:2.26e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.197, tt:4120.271\n",
      "Ep:204, loss:0.00000, loss_test:0.07829, lr:2.24e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.199, tt:4140.874\n",
      "Ep:205, loss:0.00000, loss_test:0.07821, lr:2.21e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.201, tt:4161.369\n",
      "Ep:206, loss:0.00000, loss_test:0.07833, lr:2.19e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.203, tt:4182.017\n",
      "Ep:207, loss:0.00000, loss_test:0.07842, lr:2.17e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4201.986\n",
      "Ep:208, loss:0.00000, loss_test:0.07836, lr:2.15e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4222.273\n",
      "Ep:209, loss:0.00000, loss_test:0.07851, lr:2.13e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.199, tt:4241.861\n",
      "Ep:210, loss:0.00000, loss_test:0.07854, lr:2.11e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4262.520\n",
      "Ep:211, loss:0.00000, loss_test:0.07848, lr:2.08e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.201, tt:4282.531\n",
      "Ep:212, loss:0.00000, loss_test:0.07864, lr:2.06e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4302.969\n",
      "Ep:213, loss:0.00000, loss_test:0.07868, lr:2.04e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4323.124\n",
      "Ep:214, loss:0.00000, loss_test:0.07862, lr:2.02e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.195, tt:4341.910\n",
      "Ep:215, loss:0.00000, loss_test:0.07872, lr:2.00e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.190, tt:4361.142\n",
      "Ep:216, loss:0.00000, loss_test:0.07879, lr:1.98e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.190, tt:4381.278\n",
      "Ep:217, loss:0.00000, loss_test:0.07877, lr:1.96e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.206, tt:4404.844\n",
      "Ep:218, loss:0.00000, loss_test:0.07874, lr:1.94e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.207, tt:4425.390\n",
      "Ep:219, loss:0.00000, loss_test:0.07883, lr:1.92e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.211, tt:4446.501\n",
      "Ep:220, loss:0.00000, loss_test:0.07887, lr:1.90e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.208, tt:4466.072\n",
      "Ep:221, loss:0.00000, loss_test:0.07886, lr:1.89e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.209, tt:4486.507\n",
      "Ep:222, loss:0.00000, loss_test:0.07881, lr:1.87e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.208, tt:4506.351\n",
      "Ep:223, loss:0.00000, loss_test:0.07896, lr:1.85e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.206, tt:4526.162\n",
      "Ep:224, loss:0.00000, loss_test:0.07891, lr:1.83e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.209, tt:4546.929\n",
      "Ep:225, loss:0.00000, loss_test:0.07890, lr:1.81e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.208, tt:4566.960\n",
      "Ep:226, loss:0.00000, loss_test:0.07894, lr:1.79e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.207, tt:4586.912\n",
      "Ep:227, loss:0.00000, loss_test:0.07894, lr:1.78e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.203, tt:4606.251\n",
      "Ep:228, loss:0.00000, loss_test:0.07894, lr:1.76e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.197, tt:4625.115\n",
      "Ep:229, loss:0.00000, loss_test:0.07902, lr:1.74e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.201, tt:4646.274\n",
      "Ep:230, loss:0.00000, loss_test:0.07898, lr:1.72e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4666.708\n",
      "Ep:231, loss:0.00000, loss_test:0.07904, lr:1.71e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4686.780\n",
      "Ep:232, loss:0.00000, loss_test:0.07901, lr:1.69e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.199, tt:4706.371\n",
      "Ep:233, loss:0.00000, loss_test:0.07907, lr:1.67e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.200, tt:4726.914\n",
      "Ep:234, loss:0.00000, loss_test:0.07914, lr:1.65e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.205, tt:4748.211\n",
      "Ep:235, loss:0.00000, loss_test:0.07910, lr:1.64e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.204, tt:4768.223\n",
      "Ep:236, loss:0.00000, loss_test:0.07906, lr:1.62e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.204, tt:4788.403\n",
      "Ep:237, loss:0.00000, loss_test:0.07918, lr:1.61e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.202, tt:4807.981\n",
      "Ep:238, loss:0.00000, loss_test:0.07921, lr:1.59e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.194, tt:4826.310\n",
      "Ep:239, loss:0.00000, loss_test:0.07915, lr:1.57e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.190, tt:4845.673\n",
      "Ep:240, loss:0.00000, loss_test:0.07922, lr:1.56e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.191, tt:4866.144\n",
      "Ep:241, loss:0.00000, loss_test:0.07922, lr:1.54e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.186, tt:4885.071\n",
      "Ep:242, loss:0.00000, loss_test:0.07919, lr:1.53e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.185, tt:4904.999\n",
      "Ep:243, loss:0.00000, loss_test:0.07932, lr:1.51e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.184, tt:4924.939\n",
      "Ep:244, loss:0.00000, loss_test:0.07934, lr:1.50e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.181, tt:4944.424\n",
      "Ep:245, loss:0.00000, loss_test:0.07925, lr:1.48e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.178, tt:4963.677\n",
      "Ep:246, loss:0.00000, loss_test:0.07924, lr:1.47e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.184, tt:4985.432\n",
      "Ep:247, loss:0.00000, loss_test:0.07937, lr:1.45e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.185, tt:5005.843\n",
      "Ep:248, loss:0.00000, loss_test:0.07940, lr:1.44e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.187, tt:5026.493\n",
      "Ep:249, loss:0.00000, loss_test:0.07943, lr:1.42e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.186, tt:5046.564\n",
      "Ep:250, loss:0.00000, loss_test:0.07948, lr:1.41e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.185, tt:5066.507\n",
      "Ep:251, loss:0.00000, loss_test:0.07944, lr:1.39e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.183, tt:5086.239\n",
      "Ep:252, loss:0.00000, loss_test:0.07953, lr:1.38e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.178, tt:5104.964\n",
      "Ep:253, loss:0.00000, loss_test:0.07959, lr:1.37e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.177, tt:5124.860\n",
      "Ep:254, loss:0.00000, loss_test:0.07953, lr:1.35e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.179, tt:5145.610\n",
      "Ep:255, loss:0.00000, loss_test:0.07959, lr:1.34e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.181, tt:5166.285\n",
      "Ep:256, loss:0.00000, loss_test:0.07964, lr:1.33e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.182, tt:5186.807\n",
      "Ep:257, loss:0.00000, loss_test:0.07961, lr:1.31e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.185, tt:5207.618\n",
      "Ep:258, loss:0.00000, loss_test:0.07966, lr:1.30e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.182, tt:5227.258\n",
      "Ep:259, loss:0.00000, loss_test:0.07970, lr:1.29e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.182, tt:5247.356\n",
      "Ep:260, loss:0.00000, loss_test:0.07972, lr:1.27e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.183, tt:5267.663\n",
      "Ep:261, loss:0.00000, loss_test:0.07973, lr:1.26e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.183, tt:5288.058\n",
      "Ep:262, loss:0.00000, loss_test:0.07978, lr:1.25e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.185, tt:5308.581\n",
      "Ep:263, loss:0.00000, loss_test:0.07981, lr:1.24e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.187, tt:5329.439\n",
      "Ep:264, loss:0.00000, loss_test:0.07977, lr:1.22e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.193, tt:5351.034\n",
      "Ep:265, loss:0.00000, loss_test:0.07986, lr:1.21e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.193, tt:5371.268\n",
      "Ep:266, loss:0.00000, loss_test:0.07988, lr:1.20e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.197, tt:5392.519\n",
      "Ep:267, loss:0.00000, loss_test:0.07984, lr:1.19e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.198, tt:5413.186\n",
      "Ep:268, loss:0.00000, loss_test:0.07988, lr:1.18e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.200, tt:5433.669\n",
      "Ep:269, loss:0.00000, loss_test:0.07995, lr:1.16e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.201, tt:5454.267\n",
      "Ep:270, loss:0.00000, loss_test:0.07995, lr:1.15e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.199, tt:5473.829\n",
      "Ep:271, loss:0.00000, loss_test:0.07991, lr:1.14e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.201, tt:5494.789\n",
      "Ep:272, loss:0.00000, loss_test:0.07992, lr:1.13e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.205, tt:5515.940\n",
      "Ep:273, loss:0.00000, loss_test:0.07995, lr:1.12e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.210, tt:5537.539\n",
      "Ep:274, loss:0.00000, loss_test:0.08001, lr:1.11e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.213, tt:5558.565\n",
      "Ep:275, loss:0.00000, loss_test:0.08004, lr:1.10e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.213, tt:5578.874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:276, loss:0.00000, loss_test:0.08000, lr:1.08e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.219, tt:5600.697\n",
      "Ep:277, loss:0.00000, loss_test:0.08008, lr:1.07e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.222, tt:5621.728\n",
      "Ep:278, loss:0.00000, loss_test:0.08009, lr:1.06e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.228, tt:5643.527\n",
      "Ep:279, loss:0.00000, loss_test:0.08004, lr:1.05e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.227, tt:5663.484\n",
      "Ep:280, loss:0.00000, loss_test:0.08006, lr:1.04e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.229, tt:5684.364\n",
      "Ep:281, loss:0.00000, loss_test:0.08015, lr:1.03e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.231, tt:5705.014\n",
      "Ep:282, loss:0.00000, loss_test:0.08015, lr:1.02e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.239, tt:5727.766\n",
      "Ep:283, loss:0.00000, loss_test:0.08011, lr:1.01e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.238, tt:5747.652\n",
      "Ep:284, loss:0.00000, loss_test:0.08013, lr:1.00e-03, fs:0.72611 (r=0.576,p=0.983),  time:20.242, tt:5769.077\n",
      "Ep:285, loss:0.00000, loss_test:0.08021, lr:9.91e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.241, tt:5788.963\n",
      "Ep:286, loss:0.00000, loss_test:0.08021, lr:9.81e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.241, tt:5809.193\n",
      "Ep:287, loss:0.00000, loss_test:0.08017, lr:9.71e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.240, tt:5829.105\n",
      "Ep:288, loss:0.00000, loss_test:0.08022, lr:9.62e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.240, tt:5849.316\n",
      "Ep:289, loss:0.00000, loss_test:0.08027, lr:9.52e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.241, tt:5869.850\n",
      "Ep:290, loss:0.00000, loss_test:0.08029, lr:9.42e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.241, tt:5890.052\n",
      "Ep:291, loss:0.00000, loss_test:0.08029, lr:9.33e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.243, tt:5910.938\n",
      "Ep:292, loss:0.00000, loss_test:0.08028, lr:9.24e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.245, tt:5931.717\n",
      "Ep:293, loss:0.00000, loss_test:0.08032, lr:9.14e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.249, tt:5953.149\n",
      "Ep:294, loss:0.00000, loss_test:0.08034, lr:9.05e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.248, tt:5973.163\n",
      "Ep:295, loss:0.00000, loss_test:0.08035, lr:8.96e-04, fs:0.72611 (r=0.576,p=0.983),  time:20.250, tt:5994.015\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14439, lr:1.00e-02, fs:0.63121 (r=0.899,p=0.486),  time:8.711, tt:8.711\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14387, lr:1.00e-02, fs:0.62590 (r=0.879,p=0.486),  time:10.212, tt:20.424\n",
      "Ep:2, loss:0.00004, loss_test:0.14307, lr:1.00e-02, fs:0.60584 (r=0.838,p=0.474),  time:12.812, tt:38.436\n",
      "Ep:3, loss:0.00004, loss_test:0.14216, lr:1.00e-02, fs:0.60517 (r=0.828,p=0.477),  time:14.209, tt:56.837\n",
      "Ep:4, loss:0.00004, loss_test:0.14094, lr:1.00e-02, fs:0.61132 (r=0.818,p=0.488),  time:15.187, tt:75.937\n",
      "Ep:5, loss:0.00004, loss_test:0.13955, lr:1.00e-02, fs:0.61176 (r=0.788,p=0.500),  time:15.781, tt:94.684\n",
      "Ep:6, loss:0.00004, loss_test:0.13787, lr:1.00e-02, fs:0.62651 (r=0.788,p=0.520),  time:16.179, tt:113.255\n",
      "Ep:7, loss:0.00003, loss_test:0.13624, lr:1.00e-02, fs:0.63291 (r=0.758,p=0.543),  time:16.453, tt:131.622\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.13492, lr:1.00e-02, fs:0.63519 (r=0.747,p=0.552),  time:16.607, tt:149.458\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.13365, lr:1.00e-02, fs:0.64545 (r=0.717,p=0.587),  time:16.832, tt:168.316\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.13246, lr:1.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:16.958, tt:186.538\n",
      "Ep:11, loss:0.00003, loss_test:0.13180, lr:1.00e-02, fs:0.64545 (r=0.717,p=0.587),  time:16.985, tt:203.825\n",
      "Ep:12, loss:0.00003, loss_test:0.13134, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:17.136, tt:222.764\n",
      "Ep:13, loss:0.00003, loss_test:0.13085, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:17.219, tt:241.065\n",
      "Ep:14, loss:0.00003, loss_test:0.13043, lr:1.00e-02, fs:0.62673 (r=0.687,p=0.576),  time:17.298, tt:259.473\n",
      "Ep:15, loss:0.00003, loss_test:0.13009, lr:1.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:17.432, tt:278.915\n",
      "Ep:16, loss:0.00003, loss_test:0.12947, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:17.605, tt:299.292\n",
      "Ep:17, loss:0.00003, loss_test:0.12884, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:17.655, tt:317.787\n",
      "Ep:18, loss:0.00003, loss_test:0.12802, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:17.679, tt:335.894\n",
      "Ep:19, loss:0.00003, loss_test:0.12694, lr:1.00e-02, fs:0.60952 (r=0.646,p=0.577),  time:17.833, tt:356.667\n",
      "Ep:20, loss:0.00003, loss_test:0.12576, lr:1.00e-02, fs:0.60952 (r=0.646,p=0.577),  time:17.888, tt:375.651\n",
      "Ep:21, loss:0.00003, loss_test:0.12434, lr:9.90e-03, fs:0.62439 (r=0.646,p=0.604),  time:17.973, tt:395.411\n",
      "Ep:22, loss:0.00003, loss_test:0.12265, lr:9.80e-03, fs:0.63682 (r=0.646,p=0.627),  time:18.058, tt:415.345\n",
      "Ep:23, loss:0.00003, loss_test:0.12093, lr:9.70e-03, fs:0.64000 (r=0.646,p=0.634),  time:18.120, tt:434.879\n",
      "Ep:24, loss:0.00003, loss_test:0.11930, lr:9.61e-03, fs:0.64000 (r=0.646,p=0.634),  time:18.158, tt:453.943\n",
      "Ep:25, loss:0.00003, loss_test:0.11766, lr:9.51e-03, fs:0.64000 (r=0.646,p=0.634),  time:18.192, tt:472.999\n",
      "Ep:26, loss:0.00003, loss_test:0.11599, lr:9.41e-03, fs:0.64000 (r=0.646,p=0.634),  time:18.227, tt:492.142\n",
      "Ep:27, loss:0.00003, loss_test:0.11440, lr:9.32e-03, fs:0.64646 (r=0.646,p=0.646),  time:18.218, tt:510.090\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.11309, lr:9.32e-03, fs:0.64646 (r=0.646,p=0.646),  time:18.239, tt:528.930\n",
      "Ep:29, loss:0.00003, loss_test:0.11200, lr:9.32e-03, fs:0.65306 (r=0.646,p=0.660),  time:18.270, tt:548.094\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.11091, lr:9.32e-03, fs:0.65979 (r=0.646,p=0.674),  time:18.329, tt:568.202\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.10977, lr:9.32e-03, fs:0.65285 (r=0.636,p=0.670),  time:18.343, tt:586.969\n",
      "Ep:32, loss:0.00003, loss_test:0.10853, lr:9.32e-03, fs:0.65285 (r=0.636,p=0.670),  time:18.375, tt:606.381\n",
      "Ep:33, loss:0.00003, loss_test:0.10715, lr:9.32e-03, fs:0.65285 (r=0.636,p=0.670),  time:18.391, tt:625.300\n",
      "Ep:34, loss:0.00002, loss_test:0.10587, lr:9.32e-03, fs:0.65641 (r=0.646,p=0.667),  time:18.413, tt:644.456\n",
      "Ep:35, loss:0.00002, loss_test:0.10476, lr:9.32e-03, fs:0.65979 (r=0.646,p=0.674),  time:18.421, tt:663.159\n",
      "Ep:36, loss:0.00002, loss_test:0.10350, lr:9.32e-03, fs:0.68421 (r=0.657,p=0.714),  time:18.447, tt:682.554\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.10204, lr:9.32e-03, fs:0.68783 (r=0.657,p=0.722),  time:18.475, tt:702.050\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.10057, lr:9.32e-03, fs:0.69149 (r=0.657,p=0.730),  time:18.489, tt:721.082\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.09938, lr:9.32e-03, fs:0.69892 (r=0.657,p=0.747),  time:18.489, tt:739.567\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.09854, lr:9.32e-03, fs:0.68817 (r=0.646,p=0.736),  time:18.527, tt:759.595\n",
      "Ep:41, loss:0.00002, loss_test:0.09781, lr:9.32e-03, fs:0.68478 (r=0.636,p=0.741),  time:18.547, tt:778.968\n",
      "Ep:42, loss:0.00002, loss_test:0.09700, lr:9.32e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.555, tt:797.852\n",
      "Ep:43, loss:0.00002, loss_test:0.09627, lr:9.32e-03, fs:0.70652 (r=0.657,p=0.765),  time:18.588, tt:817.859\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.09556, lr:9.32e-03, fs:0.71351 (r=0.667,p=0.767),  time:18.600, tt:836.983\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.09487, lr:9.32e-03, fs:0.72727 (r=0.687,p=0.773),  time:18.600, tt:855.583\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00002, loss_test:0.09408, lr:9.32e-03, fs:0.74074 (r=0.707,p=0.778),  time:18.558, tt:872.233\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.09325, lr:9.32e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.564, tt:891.077\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09226, lr:9.32e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.557, tt:909.300\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.09138, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.547, tt:927.364\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.09069, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.538, tt:945.442\n",
      "Ep:51, loss:0.00002, loss_test:0.09016, lr:9.32e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.538, tt:963.960\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.08959, lr:9.32e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.516, tt:981.351\n",
      "Ep:53, loss:0.00002, loss_test:0.08891, lr:9.32e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.500, tt:998.978\n",
      "Ep:54, loss:0.00002, loss_test:0.08828, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.471, tt:1015.880\n",
      "Ep:55, loss:0.00002, loss_test:0.08784, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.492, tt:1035.531\n",
      "Ep:56, loss:0.00002, loss_test:0.08739, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.465, tt:1052.477\n",
      "Ep:57, loss:0.00002, loss_test:0.08676, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.436, tt:1069.272\n",
      "Ep:58, loss:0.00002, loss_test:0.08610, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.402, tt:1085.737\n",
      "Ep:59, loss:0.00002, loss_test:0.08550, lr:9.32e-03, fs:0.79365 (r=0.758,p=0.833),  time:18.390, tt:1103.378\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.08510, lr:9.32e-03, fs:0.79365 (r=0.758,p=0.833),  time:18.381, tt:1121.235\n",
      "Ep:61, loss:0.00002, loss_test:0.08474, lr:9.32e-03, fs:0.79365 (r=0.758,p=0.833),  time:18.348, tt:1137.591\n",
      "Ep:62, loss:0.00002, loss_test:0.08431, lr:9.32e-03, fs:0.79787 (r=0.758,p=0.843),  time:18.353, tt:1156.230\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.08399, lr:9.32e-03, fs:0.79787 (r=0.758,p=0.843),  time:18.330, tt:1173.118\n",
      "Ep:64, loss:0.00002, loss_test:0.08368, lr:9.32e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.303, tt:1189.675\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.08328, lr:9.32e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.299, tt:1207.762\n",
      "Ep:66, loss:0.00002, loss_test:0.08237, lr:9.32e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.293, tt:1225.612\n",
      "Ep:67, loss:0.00002, loss_test:0.08181, lr:9.32e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.274, tt:1242.616\n",
      "Ep:68, loss:0.00002, loss_test:0.08151, lr:9.32e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.269, tt:1260.535\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.08120, lr:9.32e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.249, tt:1277.457\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.08076, lr:9.32e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.267, tt:1296.955\n",
      "Ep:71, loss:0.00001, loss_test:0.08049, lr:9.32e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.242, tt:1313.457\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.08038, lr:9.32e-03, fs:0.81522 (r=0.758,p=0.882),  time:18.211, tt:1329.400\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.07987, lr:9.32e-03, fs:0.82418 (r=0.758,p=0.904),  time:18.174, tt:1344.885\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.07930, lr:9.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:18.155, tt:1361.591\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.07911, lr:9.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:18.131, tt:1377.947\n",
      "Ep:76, loss:0.00001, loss_test:0.07858, lr:9.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:18.126, tt:1395.709\n",
      "Ep:77, loss:0.00001, loss_test:0.07772, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:18.118, tt:1413.171\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.07790, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:18.103, tt:1430.142\n",
      "Ep:79, loss:0.00001, loss_test:0.07651, lr:9.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:18.079, tt:1446.346\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.07742, lr:9.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:18.052, tt:1462.234\n",
      "Ep:81, loss:0.00001, loss_test:0.07636, lr:9.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:18.046, tt:1479.753\n",
      "Ep:82, loss:0.00001, loss_test:0.07630, lr:9.32e-03, fs:0.85870 (r=0.798,p=0.929),  time:18.026, tt:1496.142\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.07647, lr:9.32e-03, fs:0.85405 (r=0.798,p=0.919),  time:18.020, tt:1513.720\n",
      "Ep:84, loss:0.00001, loss_test:0.07564, lr:9.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:18.021, tt:1531.804\n",
      "Ep:85, loss:0.00001, loss_test:0.07641, lr:9.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:18.008, tt:1548.722\n",
      "Ep:86, loss:0.00001, loss_test:0.07584, lr:9.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:18.000, tt:1566.014\n",
      "Ep:87, loss:0.00001, loss_test:0.07559, lr:9.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.988, tt:1582.966\n",
      "Ep:88, loss:0.00001, loss_test:0.07634, lr:9.32e-03, fs:0.84615 (r=0.778,p=0.928),  time:17.984, tt:1600.545\n",
      "Ep:89, loss:0.00001, loss_test:0.07534, lr:9.32e-03, fs:0.85246 (r=0.788,p=0.929),  time:17.974, tt:1617.631\n",
      "Ep:90, loss:0.00001, loss_test:0.07563, lr:9.32e-03, fs:0.85246 (r=0.788,p=0.929),  time:17.958, tt:1634.158\n",
      "Ep:91, loss:0.00001, loss_test:0.07492, lr:9.32e-03, fs:0.85246 (r=0.788,p=0.929),  time:17.938, tt:1650.298\n",
      "Ep:92, loss:0.00001, loss_test:0.07447, lr:9.32e-03, fs:0.85246 (r=0.788,p=0.929),  time:17.943, tt:1668.738\n",
      "Ep:93, loss:0.00001, loss_test:0.07533, lr:9.32e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.936, tt:1686.013\n",
      "Ep:94, loss:0.00001, loss_test:0.07405, lr:9.23e-03, fs:0.86486 (r=0.808,p=0.930),  time:17.928, tt:1703.140\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.07416, lr:9.23e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.923, tt:1720.618\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.07499, lr:9.23e-03, fs:0.86813 (r=0.798,p=0.952),  time:17.926, tt:1738.826\n",
      "Ep:97, loss:0.00001, loss_test:0.07355, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.930, tt:1757.154\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.07374, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.944, tt:1776.431\n",
      "Ep:99, loss:0.00001, loss_test:0.07398, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.934, tt:1793.447\n",
      "Ep:100, loss:0.00001, loss_test:0.07268, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.933, tt:1811.189\n",
      "Ep:101, loss:0.00001, loss_test:0.07405, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.942, tt:1830.042\n",
      "Ep:102, loss:0.00001, loss_test:0.07248, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.947, tt:1848.581\n",
      "Ep:103, loss:0.00001, loss_test:0.07361, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.960, tt:1867.849\n",
      "Ep:104, loss:0.00001, loss_test:0.07351, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.975, tt:1887.388\n",
      "Ep:105, loss:0.00001, loss_test:0.07275, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.983, tt:1906.163\n",
      "Ep:106, loss:0.00001, loss_test:0.07360, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.995, tt:1925.477\n",
      "Ep:107, loss:0.00001, loss_test:0.07306, lr:9.23e-03, fs:0.86188 (r=0.788,p=0.951),  time:17.996, tt:1943.592\n",
      "Ep:108, loss:0.00001, loss_test:0.07283, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.001, tt:1962.140\n",
      "Ep:109, loss:0.00001, loss_test:0.07339, lr:9.14e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.002, tt:1980.200\n",
      "Ep:110, loss:0.00001, loss_test:0.07217, lr:9.04e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.007, tt:1998.820\n",
      "Ep:111, loss:0.00001, loss_test:0.07308, lr:8.95e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.018, tt:2017.989\n",
      "Ep:112, loss:0.00001, loss_test:0.07278, lr:8.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.024, tt:2036.691\n",
      "Ep:113, loss:0.00001, loss_test:0.07248, lr:8.78e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.036, tt:2056.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00001, loss_test:0.07243, lr:8.69e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.046, tt:2075.288\n",
      "Ep:115, loss:0.00001, loss_test:0.07255, lr:8.60e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.060, tt:2094.953\n",
      "Ep:116, loss:0.00001, loss_test:0.07203, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:18.066, tt:2113.709\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.07260, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:18.071, tt:2132.422\n",
      "Ep:118, loss:0.00001, loss_test:0.07202, lr:8.51e-03, fs:0.88525 (r=0.818,p=0.964),  time:18.085, tt:2152.121\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.07229, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:18.098, tt:2171.711\n",
      "Ep:120, loss:0.00001, loss_test:0.07146, lr:8.51e-03, fs:0.88525 (r=0.818,p=0.964),  time:18.111, tt:2191.389\n",
      "Ep:121, loss:0.00001, loss_test:0.07229, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:18.129, tt:2211.776\n",
      "Ep:122, loss:0.00001, loss_test:0.07067, lr:8.51e-03, fs:0.88525 (r=0.818,p=0.964),  time:18.144, tt:2231.698\n",
      "Ep:123, loss:0.00001, loss_test:0.07199, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:18.162, tt:2252.140\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.07060, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:18.177, tt:2272.132\n",
      "Ep:125, loss:0.00001, loss_test:0.07226, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.183, tt:2291.064\n",
      "Ep:126, loss:0.00001, loss_test:0.07043, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:18.190, tt:2310.152\n",
      "Ep:127, loss:0.00001, loss_test:0.07183, lr:8.51e-03, fs:0.88398 (r=0.808,p=0.976),  time:18.212, tt:2331.118\n",
      "Ep:128, loss:0.00001, loss_test:0.07073, lr:8.51e-03, fs:0.87293 (r=0.798,p=0.963),  time:18.228, tt:2351.412\n",
      "Ep:129, loss:0.00001, loss_test:0.07146, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:18.237, tt:2370.811\n",
      "Ep:130, loss:0.00001, loss_test:0.07109, lr:8.51e-03, fs:0.88398 (r=0.808,p=0.976),  time:18.254, tt:2391.269\n",
      "Ep:131, loss:0.00001, loss_test:0.07120, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:18.267, tt:2411.185\n",
      "Ep:132, loss:0.00001, loss_test:0.07057, lr:8.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:18.280, tt:2431.283\n",
      "Ep:133, loss:0.00001, loss_test:0.07217, lr:8.51e-03, fs:0.89503 (r=0.818,p=0.988),  time:18.287, tt:2450.408\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00001, loss_test:0.06966, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:18.298, tt:2470.276\n",
      "Ep:135, loss:0.00001, loss_test:0.07383, lr:8.51e-03, fs:0.87006 (r=0.778,p=0.987),  time:18.307, tt:2489.750\n",
      "Ep:136, loss:0.00001, loss_test:0.06978, lr:8.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:18.315, tt:2509.165\n",
      "Ep:137, loss:0.00001, loss_test:0.07183, lr:8.51e-03, fs:0.89503 (r=0.818,p=0.988),  time:18.314, tt:2527.384\n",
      "Ep:138, loss:0.00001, loss_test:0.07080, lr:8.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:18.330, tt:2547.931\n",
      "Ep:139, loss:0.00001, loss_test:0.07081, lr:8.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.337, tt:2567.190\n",
      "Ep:140, loss:0.00001, loss_test:0.07170, lr:8.51e-03, fs:0.89503 (r=0.818,p=0.988),  time:18.341, tt:2586.080\n",
      "Ep:141, loss:0.00001, loss_test:0.07006, lr:8.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:18.344, tt:2604.808\n",
      "Ep:142, loss:0.00001, loss_test:0.07256, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.346, tt:2623.419\n",
      "Ep:143, loss:0.00001, loss_test:0.07004, lr:8.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.347, tt:2641.990\n",
      "Ep:144, loss:0.00001, loss_test:0.07100, lr:8.51e-03, fs:0.87293 (r=0.798,p=0.963),  time:18.352, tt:2661.049\n",
      "Ep:145, loss:0.00001, loss_test:0.07126, lr:8.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.351, tt:2679.315\n",
      "Ep:146, loss:0.00000, loss_test:0.07009, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.356, tt:2698.279\n",
      "Ep:147, loss:0.00000, loss_test:0.07152, lr:8.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.362, tt:2717.505\n",
      "Ep:148, loss:0.00000, loss_test:0.06994, lr:8.18e-03, fs:0.86813 (r=0.798,p=0.952),  time:18.366, tt:2736.609\n",
      "Ep:149, loss:0.00000, loss_test:0.07109, lr:8.10e-03, fs:0.86034 (r=0.778,p=0.963),  time:18.376, tt:2756.369\n",
      "Ep:150, loss:0.00000, loss_test:0.07116, lr:8.02e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.386, tt:2776.305\n",
      "Ep:151, loss:0.00000, loss_test:0.07016, lr:7.94e-03, fs:0.84916 (r=0.768,p=0.950),  time:18.390, tt:2795.255\n",
      "Ep:152, loss:0.00000, loss_test:0.07174, lr:7.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.398, tt:2814.916\n",
      "Ep:153, loss:0.00000, loss_test:0.07055, lr:7.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.403, tt:2834.072\n",
      "Ep:154, loss:0.00000, loss_test:0.07026, lr:7.70e-03, fs:0.86034 (r=0.778,p=0.963),  time:18.409, tt:2853.391\n",
      "Ep:155, loss:0.00000, loss_test:0.07148, lr:7.62e-03, fs:0.88398 (r=0.808,p=0.976),  time:18.412, tt:2872.200\n",
      "Ep:156, loss:0.00000, loss_test:0.07022, lr:7.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.416, tt:2891.303\n",
      "Ep:157, loss:0.00000, loss_test:0.07090, lr:7.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.410, tt:2908.820\n",
      "Ep:158, loss:0.00000, loss_test:0.07038, lr:7.40e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.419, tt:2928.592\n",
      "Ep:159, loss:0.00000, loss_test:0.07072, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.424, tt:2947.851\n",
      "Ep:160, loss:0.00000, loss_test:0.07098, lr:7.25e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.431, tt:2967.434\n",
      "Ep:161, loss:0.00000, loss_test:0.07028, lr:7.18e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.437, tt:2986.858\n",
      "Ep:162, loss:0.00000, loss_test:0.07096, lr:7.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.444, tt:3006.394\n",
      "Ep:163, loss:0.00000, loss_test:0.07041, lr:7.03e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.456, tt:3026.774\n",
      "Ep:164, loss:0.00000, loss_test:0.07063, lr:6.96e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.462, tt:3046.253\n",
      "Ep:165, loss:0.00000, loss_test:0.07063, lr:6.89e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.469, tt:3065.804\n",
      "Ep:166, loss:0.00000, loss_test:0.07057, lr:6.83e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.480, tt:3086.107\n",
      "Ep:167, loss:0.00000, loss_test:0.07058, lr:6.76e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.484, tt:3105.383\n",
      "Ep:168, loss:0.00000, loss_test:0.07068, lr:6.69e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.490, tt:3124.852\n",
      "Ep:169, loss:0.00000, loss_test:0.07007, lr:6.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.496, tt:3144.313\n",
      "Ep:170, loss:0.00000, loss_test:0.07086, lr:6.56e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.501, tt:3163.632\n",
      "Ep:171, loss:0.00000, loss_test:0.06996, lr:6.49e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.509, tt:3183.471\n",
      "Ep:172, loss:0.00000, loss_test:0.07069, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.516, tt:3203.194\n",
      "Ep:173, loss:0.00000, loss_test:0.07055, lr:6.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.515, tt:3221.644\n",
      "Ep:174, loss:0.00000, loss_test:0.07010, lr:6.30e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.517, tt:3240.527\n",
      "Ep:175, loss:0.00000, loss_test:0.07035, lr:6.24e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.521, tt:3259.755\n",
      "Ep:176, loss:0.00000, loss_test:0.07052, lr:6.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.524, tt:3278.813\n",
      "Ep:177, loss:0.00000, loss_test:0.07062, lr:6.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.527, tt:3297.812\n",
      "Ep:178, loss:0.00000, loss_test:0.07000, lr:6.05e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.530, tt:3316.872\n",
      "Ep:179, loss:0.00000, loss_test:0.07104, lr:5.99e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.537, tt:3336.614\n",
      "Ep:180, loss:0.00000, loss_test:0.07050, lr:5.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.542, tt:3356.124\n",
      "Ep:181, loss:0.00000, loss_test:0.06973, lr:5.87e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.546, tt:3375.320\n",
      "Ep:182, loss:0.00000, loss_test:0.07113, lr:5.81e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.548, tt:3394.231\n",
      "Ep:183, loss:0.00000, loss_test:0.07046, lr:5.75e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.552, tt:3413.521\n",
      "Ep:184, loss:0.00000, loss_test:0.06984, lr:5.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.564, tt:3434.416\n",
      "Ep:185, loss:0.00000, loss_test:0.07083, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.568, tt:3453.655\n",
      "Ep:186, loss:0.00000, loss_test:0.07085, lr:5.58e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.568, tt:3472.261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:187, loss:0.00000, loss_test:0.07007, lr:5.53e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.576, tt:3492.375\n",
      "Ep:188, loss:0.00000, loss_test:0.07031, lr:5.47e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.576, tt:3510.770\n",
      "Ep:189, loss:0.00000, loss_test:0.07110, lr:5.42e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.584, tt:3530.877\n",
      "Ep:190, loss:0.00000, loss_test:0.07032, lr:5.36e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.584, tt:3549.544\n",
      "Ep:191, loss:0.00000, loss_test:0.07002, lr:5.31e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.582, tt:3567.759\n",
      "Ep:192, loss:0.00000, loss_test:0.07114, lr:5.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.584, tt:3586.713\n",
      "Ep:193, loss:0.00000, loss_test:0.07062, lr:5.20e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.590, tt:3606.394\n",
      "Ep:194, loss:0.00000, loss_test:0.06980, lr:5.15e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.595, tt:3625.954\n",
      "Ep:195, loss:0.00000, loss_test:0.07092, lr:5.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.601, tt:3645.742\n",
      "Ep:196, loss:0.00000, loss_test:0.07098, lr:5.05e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.603, tt:3664.877\n",
      "Ep:197, loss:0.00000, loss_test:0.07021, lr:5.00e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.605, tt:3683.828\n",
      "Ep:198, loss:0.00000, loss_test:0.07027, lr:4.95e-03, fs:0.87151 (r=0.788,p=0.975),  time:18.604, tt:3702.253\n",
      "Ep:199, loss:0.00000, loss_test:0.07074, lr:4.90e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.613, tt:3722.635\n",
      "Ep:200, loss:0.00000, loss_test:0.07095, lr:4.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.619, tt:3742.338\n",
      "Ep:201, loss:0.00000, loss_test:0.07049, lr:4.80e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.620, tt:3761.264\n",
      "Ep:202, loss:0.00000, loss_test:0.07023, lr:4.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.624, tt:3780.572\n",
      "Ep:203, loss:0.00000, loss_test:0.07091, lr:4.71e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.627, tt:3799.889\n",
      "Ep:204, loss:0.00000, loss_test:0.07095, lr:4.66e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.627, tt:3818.471\n",
      "Ep:205, loss:0.00000, loss_test:0.07030, lr:4.61e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.627, tt:3837.131\n",
      "Ep:206, loss:0.00000, loss_test:0.07055, lr:4.57e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.634, tt:3857.142\n",
      "Ep:207, loss:0.00000, loss_test:0.07097, lr:4.52e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.641, tt:3877.260\n",
      "Ep:208, loss:0.00000, loss_test:0.07061, lr:4.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.645, tt:3896.903\n",
      "Ep:209, loss:0.00000, loss_test:0.07038, lr:4.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.647, tt:3915.859\n",
      "Ep:210, loss:0.00000, loss_test:0.07077, lr:4.39e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.652, tt:3935.469\n",
      "Ep:211, loss:0.00000, loss_test:0.07072, lr:4.34e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.655, tt:3954.780\n",
      "Ep:212, loss:0.00000, loss_test:0.07054, lr:4.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.652, tt:3972.920\n",
      "Ep:213, loss:0.00000, loss_test:0.07091, lr:4.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.669, tt:3995.079\n",
      "Ep:214, loss:0.00000, loss_test:0.07071, lr:4.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.675, tt:4015.113\n",
      "Ep:215, loss:0.00000, loss_test:0.07050, lr:4.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.680, tt:4034.922\n",
      "Ep:216, loss:0.00000, loss_test:0.07080, lr:4.13e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.684, tt:4054.492\n",
      "Ep:217, loss:0.00000, loss_test:0.07087, lr:4.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.686, tt:4073.605\n",
      "Ep:218, loss:0.00000, loss_test:0.07058, lr:4.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.694, tt:4093.975\n",
      "Ep:219, loss:0.00000, loss_test:0.07084, lr:4.01e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.695, tt:4112.818\n",
      "Ep:220, loss:0.00000, loss_test:0.07100, lr:3.97e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.699, tt:4132.445\n",
      "Ep:221, loss:0.00000, loss_test:0.07058, lr:3.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.697, tt:4150.774\n",
      "Ep:222, loss:0.00000, loss_test:0.07085, lr:3.89e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.702, tt:4170.618\n",
      "Ep:223, loss:0.00000, loss_test:0.07105, lr:3.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.702, tt:4189.290\n",
      "Ep:224, loss:0.00000, loss_test:0.07059, lr:3.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.703, tt:4208.257\n",
      "Ep:225, loss:0.00000, loss_test:0.07076, lr:3.77e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.707, tt:4227.852\n",
      "Ep:226, loss:0.00000, loss_test:0.07105, lr:3.73e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.710, tt:4247.192\n",
      "Ep:227, loss:0.00000, loss_test:0.07087, lr:3.70e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.717, tt:4267.523\n",
      "Ep:228, loss:0.00000, loss_test:0.07069, lr:3.66e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.725, tt:4288.129\n",
      "Ep:229, loss:0.00000, loss_test:0.07092, lr:3.62e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.733, tt:4308.500\n",
      "Ep:230, loss:0.00000, loss_test:0.07107, lr:3.59e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.740, tt:4328.839\n",
      "Ep:231, loss:0.00000, loss_test:0.07072, lr:3.55e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.745, tt:4348.844\n",
      "Ep:232, loss:0.00000, loss_test:0.07081, lr:3.52e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.747, tt:4368.038\n",
      "Ep:233, loss:0.00000, loss_test:0.07097, lr:3.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.749, tt:4387.288\n",
      "Ep:234, loss:0.00000, loss_test:0.07075, lr:3.45e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.754, tt:4407.158\n",
      "Ep:235, loss:0.00000, loss_test:0.07077, lr:3.41e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.756, tt:4426.467\n",
      "Ep:236, loss:0.00000, loss_test:0.07096, lr:3.38e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.759, tt:4445.963\n",
      "Ep:237, loss:0.00000, loss_test:0.07084, lr:3.34e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.769, tt:4467.061\n",
      "Ep:238, loss:0.00000, loss_test:0.07077, lr:3.31e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.773, tt:4486.669\n",
      "Ep:239, loss:0.00000, loss_test:0.07098, lr:3.28e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.770, tt:4504.780\n",
      "Ep:240, loss:0.00000, loss_test:0.07085, lr:3.24e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.771, tt:4523.736\n",
      "Ep:241, loss:0.00000, loss_test:0.07075, lr:3.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.771, tt:4542.559\n",
      "Ep:242, loss:0.00000, loss_test:0.07084, lr:3.18e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.779, tt:4563.207\n",
      "Ep:243, loss:0.00000, loss_test:0.07077, lr:3.15e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.779, tt:4582.153\n",
      "Ep:244, loss:0.00000, loss_test:0.07089, lr:3.12e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.773, tt:4599.353\n",
      "Ep:245, loss:0.00000, loss_test:0.07082, lr:3.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:18.774, tt:4618.316\n",
      "Ep:246, loss:0.00000, loss_test:0.07076, lr:3.05e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.775, tt:4637.339\n",
      "Ep:247, loss:0.00000, loss_test:0.07085, lr:3.02e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.773, tt:4655.744\n",
      "Ep:248, loss:0.00000, loss_test:0.07092, lr:2.99e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.771, tt:4673.875\n",
      "Ep:249, loss:0.00000, loss_test:0.07084, lr:2.96e-03, fs:0.88268 (r=0.798,p=0.988),  time:18.766, tt:4691.488\n",
      "Ep:250, loss:0.00000, loss_test:0.07087, lr:2.93e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.765, tt:4710.035\n",
      "Ep:251, loss:0.00000, loss_test:0.07076, lr:2.90e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.765, tt:4728.766\n",
      "Ep:252, loss:0.00000, loss_test:0.07061, lr:2.88e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.765, tt:4747.653\n",
      "Ep:253, loss:0.00000, loss_test:0.07086, lr:2.85e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.762, tt:4765.591\n",
      "Ep:254, loss:0.00000, loss_test:0.07092, lr:2.82e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.763, tt:4784.485\n",
      "Ep:255, loss:0.00000, loss_test:0.07067, lr:2.79e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.758, tt:4801.957\n",
      "Ep:256, loss:0.00000, loss_test:0.07068, lr:2.76e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.762, tt:4821.875\n",
      "Ep:257, loss:0.00000, loss_test:0.07088, lr:2.73e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.759, tt:4839.904\n",
      "Ep:258, loss:0.00000, loss_test:0.07076, lr:2.71e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.760, tt:4858.840\n",
      "Ep:259, loss:0.00000, loss_test:0.07064, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.762, tt:4878.059\n",
      "##########Best model found so far##########\n",
      "Ep:260, loss:0.00000, loss_test:0.07069, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.764, tt:4897.439\n",
      "Ep:261, loss:0.00000, loss_test:0.07079, lr:2.68e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.767, tt:4916.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:262, loss:0.00000, loss_test:0.07080, lr:2.68e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.774, tt:4937.537\n",
      "Ep:263, loss:0.00000, loss_test:0.07067, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.776, tt:4956.781\n",
      "Ep:264, loss:0.00000, loss_test:0.07073, lr:2.68e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.776, tt:4975.672\n",
      "##########Best model found so far##########\n",
      "Ep:265, loss:0.00000, loss_test:0.07071, lr:2.68e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.778, tt:4995.016\n",
      "Ep:266, loss:0.00000, loss_test:0.07076, lr:2.68e-03, fs:0.88889 (r=0.808,p=0.988),  time:18.779, tt:5014.076\n",
      "Ep:267, loss:0.00000, loss_test:0.07071, lr:2.68e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.785, tt:5034.386\n",
      "Ep:268, loss:0.00000, loss_test:0.07060, lr:2.68e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.786, tt:5053.501\n",
      "Ep:269, loss:0.00000, loss_test:0.07073, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.792, tt:5073.816\n",
      "Ep:270, loss:0.00000, loss_test:0.07071, lr:2.68e-03, fs:0.89503 (r=0.818,p=0.988),  time:18.793, tt:5092.767\n",
      "Ep:271, loss:0.00000, loss_test:0.07068, lr:2.68e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.796, tt:5112.425\n",
      "Ep:272, loss:0.00000, loss_test:0.07069, lr:2.68e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.799, tt:5132.113\n",
      "Ep:273, loss:0.00000, loss_test:0.07067, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.802, tt:5151.670\n",
      "Ep:274, loss:0.00000, loss_test:0.07063, lr:2.68e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.803, tt:5170.912\n",
      "Ep:275, loss:0.00000, loss_test:0.07075, lr:2.68e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.807, tt:5190.797\n",
      "Ep:276, loss:0.00000, loss_test:0.07074, lr:2.65e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.809, tt:5209.999\n",
      "Ep:277, loss:0.00000, loss_test:0.07069, lr:2.63e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.812, tt:5229.633\n",
      "Ep:278, loss:0.00000, loss_test:0.07070, lr:2.60e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.815, tt:5249.344\n",
      "Ep:279, loss:0.00000, loss_test:0.07067, lr:2.57e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.816, tt:5268.483\n",
      "Ep:280, loss:0.00000, loss_test:0.07065, lr:2.55e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.817, tt:5287.677\n",
      "Ep:281, loss:0.00000, loss_test:0.07076, lr:2.52e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.821, tt:5307.520\n",
      "Ep:282, loss:0.00000, loss_test:0.07087, lr:2.50e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.825, tt:5327.482\n",
      "Ep:283, loss:0.00000, loss_test:0.07070, lr:2.47e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.827, tt:5346.873\n",
      "Ep:284, loss:0.00000, loss_test:0.07053, lr:2.45e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.834, tt:5367.572\n",
      "Ep:285, loss:0.00000, loss_test:0.07071, lr:2.42e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.835, tt:5386.747\n",
      "Ep:286, loss:0.00000, loss_test:0.07091, lr:2.40e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.838, tt:5406.573\n",
      "Ep:287, loss:0.00000, loss_test:0.07083, lr:2.38e-03, fs:0.90110 (r=0.828,p=0.988),  time:18.845, tt:5427.370\n",
      "Ep:288, loss:0.00000, loss_test:0.07061, lr:2.35e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.842, tt:5445.264\n",
      "Ep:289, loss:0.00000, loss_test:0.07075, lr:2.33e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.836, tt:5462.491\n",
      "Ep:290, loss:0.00000, loss_test:0.07089, lr:2.31e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.832, tt:5480.122\n",
      "Ep:291, loss:0.00000, loss_test:0.07080, lr:2.28e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.829, tt:5498.028\n",
      "Ep:292, loss:0.00000, loss_test:0.07077, lr:2.26e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.827, tt:5516.343\n",
      "Ep:293, loss:0.00000, loss_test:0.07079, lr:2.24e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.818, tt:5532.458\n",
      "Ep:294, loss:0.00000, loss_test:0.07073, lr:2.21e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.813, tt:5549.712\n",
      "Ep:295, loss:0.00000, loss_test:0.07075, lr:2.19e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.803, tt:5565.691\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14384, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:61.846, tt:61.846\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13978, lr:1.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:62.506, tt:125.011\n",
      "Ep:2, loss:0.00050, loss_test:0.13395, lr:1.00e-02, fs:0.60581 (r=0.737,p=0.514),  time:63.613, tt:190.839\n",
      "Ep:3, loss:0.00046, loss_test:0.12994, lr:1.00e-02, fs:0.60829 (r=0.667,p=0.559),  time:63.877, tt:255.510\n",
      "Ep:4, loss:0.00043, loss_test:0.12479, lr:1.00e-02, fs:0.61947 (r=0.707,p=0.551),  time:63.908, tt:319.541\n",
      "Ep:5, loss:0.00042, loss_test:0.11857, lr:1.00e-02, fs:0.62687 (r=0.636,p=0.618),  time:64.267, tt:385.605\n",
      "Ep:6, loss:0.00039, loss_test:0.11140, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:64.553, tt:451.872\n",
      "Ep:7, loss:0.00037, loss_test:0.10583, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:64.506, tt:516.046\n",
      "Ep:8, loss:0.00036, loss_test:0.10120, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:64.686, tt:582.178\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09761, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:64.777, tt:647.772\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.09483, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:64.786, tt:712.643\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.09187, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:64.717, tt:776.601\n",
      "Ep:12, loss:0.00030, loss_test:0.08948, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:64.805, tt:842.460\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.08730, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:64.691, tt:905.669\n",
      "Ep:14, loss:0.00027, loss_test:0.08653, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:64.815, tt:972.219\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08470, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:64.759, tt:1036.144\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.08272, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:64.712, tt:1100.101\n",
      "Ep:17, loss:0.00024, loss_test:0.08054, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:64.769, tt:1165.844\n",
      "Ep:18, loss:0.00023, loss_test:0.07962, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:64.716, tt:1229.606\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.07903, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:64.732, tt:1294.647\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.07706, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:64.696, tt:1358.617\n",
      "Ep:21, loss:0.00020, loss_test:0.07594, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:64.637, tt:1422.012\n",
      "Ep:22, loss:0.00019, loss_test:0.07547, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:64.633, tt:1486.563\n",
      "Ep:23, loss:0.00019, loss_test:0.07803, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:64.718, tt:1553.231\n",
      "Ep:24, loss:0.00018, loss_test:0.07354, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:64.789, tt:1619.734\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.07117, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:64.792, tt:1684.589\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.07186, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:64.827, tt:1750.331\n",
      "Ep:27, loss:0.00016, loss_test:0.07397, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:64.882, tt:1816.708\n",
      "Ep:28, loss:0.00015, loss_test:0.07367, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:64.916, tt:1882.551\n",
      "Ep:29, loss:0.00015, loss_test:0.06856, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:64.979, tt:1949.367\n",
      "Ep:30, loss:0.00014, loss_test:0.06986, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:64.967, tt:2013.963\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.06873, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:65.018, tt:2080.574\n",
      "Ep:32, loss:0.00013, loss_test:0.06859, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:65.030, tt:2146.002\n",
      "Ep:33, loss:0.00013, loss_test:0.06886, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:65.027, tt:2210.929\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.06919, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:64.989, tt:2274.624\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.06884, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:65.042, tt:2341.507\n",
      "Ep:36, loss:0.00012, loss_test:0.06939, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:65.014, tt:2405.509\n",
      "Ep:37, loss:0.00011, loss_test:0.06981, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:65.035, tt:2471.340\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.06623, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:65.081, tt:2538.143\n",
      "Ep:39, loss:0.00011, loss_test:0.06488, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:65.083, tt:2603.318\n",
      "Ep:40, loss:0.00010, loss_test:0.06761, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:65.054, tt:2667.228\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.06782, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:65.107, tt:2734.476\n",
      "Ep:42, loss:0.00009, loss_test:0.06531, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:65.174, tt:2802.491\n",
      "Ep:43, loss:0.00009, loss_test:0.06427, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:65.222, tt:2869.750\n",
      "Ep:44, loss:0.00009, loss_test:0.06605, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:65.256, tt:2936.503\n",
      "Ep:45, loss:0.00008, loss_test:0.06612, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:65.257, tt:3001.812\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.06517, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:65.259, tt:3067.178\n",
      "Ep:47, loss:0.00008, loss_test:0.06498, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:65.241, tt:3131.557\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.06535, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:65.247, tt:3197.106\n",
      "Ep:49, loss:0.00008, loss_test:0.06537, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:65.227, tt:3261.362\n",
      "Ep:50, loss:0.00007, loss_test:0.06837, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:65.209, tt:3325.652\n",
      "Ep:51, loss:0.00007, loss_test:0.07008, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:65.203, tt:3390.547\n",
      "Ep:52, loss:0.00007, loss_test:0.06528, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:65.189, tt:3455.026\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.06480, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:65.320, tt:3527.277\n",
      "Ep:54, loss:0.00006, loss_test:0.06666, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:65.346, tt:3594.055\n",
      "Ep:55, loss:0.00006, loss_test:0.06730, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:65.326, tt:3658.230\n",
      "Ep:56, loss:0.00006, loss_test:0.06629, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:65.306, tt:3722.447\n",
      "Ep:57, loss:0.00006, loss_test:0.06694, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:65.292, tt:3786.927\n",
      "Ep:58, loss:0.00006, loss_test:0.06887, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:65.303, tt:3852.892\n",
      "Ep:59, loss:0.00005, loss_test:0.06364, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:65.300, tt:3918.004\n",
      "Ep:60, loss:0.00005, loss_test:0.06407, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:65.288, tt:3982.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00005, loss_test:0.06796, lr:1.00e-02, fs:0.76829 (r=0.636,p=0.969),  time:65.322, tt:4049.959\n",
      "Ep:62, loss:0.00005, loss_test:0.07220, lr:1.00e-02, fs:0.73750 (r=0.596,p=0.967),  time:65.308, tt:4114.436\n",
      "Ep:63, loss:0.00005, loss_test:0.06286, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:65.318, tt:4180.371\n",
      "Ep:64, loss:0.00004, loss_test:0.06273, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.364, tt:4248.664\n",
      "Ep:65, loss:0.00004, loss_test:0.07031, lr:9.80e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.414, tt:4317.312\n",
      "Ep:66, loss:0.00004, loss_test:0.06410, lr:9.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:65.414, tt:4382.745\n",
      "Ep:67, loss:0.00004, loss_test:0.06337, lr:9.61e-03, fs:0.82759 (r=0.727,p=0.960),  time:65.416, tt:4448.276\n",
      "Ep:68, loss:0.00004, loss_test:0.06988, lr:9.51e-03, fs:0.75610 (r=0.626,p=0.954),  time:65.419, tt:4513.884\n",
      "Ep:69, loss:0.00004, loss_test:0.06456, lr:9.41e-03, fs:0.78107 (r=0.667,p=0.943),  time:65.388, tt:4577.168\n",
      "Ep:70, loss:0.00004, loss_test:0.06527, lr:9.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.389, tt:4642.603\n",
      "Ep:71, loss:0.00004, loss_test:0.06816, lr:9.23e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.420, tt:4710.257\n",
      "Ep:72, loss:0.00003, loss_test:0.06821, lr:9.14e-03, fs:0.78107 (r=0.667,p=0.943),  time:65.437, tt:4776.872\n",
      "Ep:73, loss:0.00003, loss_test:0.06577, lr:9.04e-03, fs:0.75610 (r=0.626,p=0.954),  time:65.465, tt:4844.380\n",
      "Ep:74, loss:0.00003, loss_test:0.06690, lr:8.95e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.466, tt:4909.952\n",
      "Ep:75, loss:0.00003, loss_test:0.06781, lr:8.86e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.468, tt:4975.569\n",
      "Ep:76, loss:0.00003, loss_test:0.06616, lr:8.78e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.479, tt:5041.856\n",
      "Ep:77, loss:0.00003, loss_test:0.06476, lr:8.69e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.510, tt:5109.768\n",
      "Ep:78, loss:0.00003, loss_test:0.06571, lr:8.60e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.520, tt:5176.068\n",
      "Ep:79, loss:0.00003, loss_test:0.06493, lr:8.51e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.536, tt:5242.916\n",
      "Ep:80, loss:0.00003, loss_test:0.06502, lr:8.43e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.528, tt:5307.763\n",
      "Ep:81, loss:0.00003, loss_test:0.06515, lr:8.35e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.527, tt:5373.224\n",
      "Ep:82, loss:0.00002, loss_test:0.06521, lr:8.26e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.520, tt:5438.183\n",
      "Ep:83, loss:0.00002, loss_test:0.06452, lr:8.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.502, tt:5502.167\n",
      "Ep:84, loss:0.00002, loss_test:0.06585, lr:8.10e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.503, tt:5567.770\n",
      "Ep:85, loss:0.00002, loss_test:0.06570, lr:8.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.502, tt:5633.205\n",
      "Ep:86, loss:0.00002, loss_test:0.06670, lr:7.94e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.491, tt:5697.679\n",
      "Ep:87, loss:0.00002, loss_test:0.06612, lr:7.86e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.510, tt:5764.894\n",
      "Ep:88, loss:0.00002, loss_test:0.06498, lr:7.78e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.513, tt:5830.693\n",
      "Ep:89, loss:0.00002, loss_test:0.06973, lr:7.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.557, tt:5900.131\n",
      "Ep:90, loss:0.00002, loss_test:0.06791, lr:7.62e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.569, tt:5966.750\n",
      "Ep:91, loss:0.00002, loss_test:0.06669, lr:7.55e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.593, tt:6034.517\n",
      "Ep:92, loss:0.00002, loss_test:0.06719, lr:7.47e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.597, tt:6100.544\n",
      "Ep:93, loss:0.00002, loss_test:0.06807, lr:7.40e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.599, tt:6166.272\n",
      "Ep:94, loss:0.00002, loss_test:0.07118, lr:7.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.612, tt:6233.165\n",
      "Ep:95, loss:0.00002, loss_test:0.06878, lr:7.25e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.612, tt:6298.764\n",
      "Ep:96, loss:0.00002, loss_test:0.06880, lr:7.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.645, tt:6367.568\n",
      "Ep:97, loss:0.00002, loss_test:0.06886, lr:7.11e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.648, tt:6433.495\n",
      "Ep:98, loss:0.00002, loss_test:0.06600, lr:7.03e-03, fs:0.73620 (r=0.606,p=0.938),  time:65.667, tt:6501.040\n",
      "Ep:99, loss:0.00002, loss_test:0.06920, lr:6.96e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.678, tt:6567.768\n",
      "Ep:100, loss:0.00002, loss_test:0.06860, lr:6.89e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.680, tt:6633.691\n",
      "Ep:101, loss:0.00002, loss_test:0.06910, lr:6.83e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.729, tt:6704.370\n",
      "Ep:102, loss:0.00002, loss_test:0.06843, lr:6.76e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.687, tt:6765.713\n",
      "Ep:103, loss:0.00002, loss_test:0.06837, lr:6.69e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.623, tt:6824.813\n",
      "Ep:104, loss:0.00002, loss_test:0.06942, lr:6.62e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.554, tt:6883.216\n",
      "Ep:105, loss:0.00002, loss_test:0.06928, lr:6.56e-03, fs:0.74074 (r=0.606,p=0.952),  time:65.500, tt:6943.030\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14326, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:78.628, tt:78.628\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00052, loss_test:0.13585, lr:1.00e-02, fs:0.62257 (r=0.808,p=0.506),  time:81.802, tt:163.604\n",
      "Ep:2, loss:0.00047, loss_test:0.13121, lr:1.00e-02, fs:0.57292 (r=0.556,p=0.591),  time:82.393, tt:247.180\n",
      "Ep:3, loss:0.00043, loss_test:0.12351, lr:1.00e-02, fs:0.61084 (r=0.626,p=0.596),  time:83.367, tt:333.467\n",
      "Ep:4, loss:0.00040, loss_test:0.11633, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:83.002, tt:415.010\n",
      "Ep:5, loss:0.00037, loss_test:0.11028, lr:1.00e-02, fs:0.65957 (r=0.626,p=0.697),  time:82.970, tt:497.818\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.10398, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:82.855, tt:579.987\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.09512, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:83.041, tt:664.331\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.09075, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:82.999, tt:746.994\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00027, loss_test:0.09042, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:83.011, tt:830.110\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.08660, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:83.046, tt:913.501\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.08627, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:83.071, tt:996.853\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.08359, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:82.889, tt:1077.558\n",
      "Ep:13, loss:0.00020, loss_test:0.07783, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:82.883, tt:1160.362\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.07878, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:82.857, tt:1242.857\n",
      "Ep:15, loss:0.00017, loss_test:0.08143, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:82.958, tt:1327.335\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08223, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:82.968, tt:1410.451\n",
      "Ep:17, loss:0.00015, loss_test:0.08184, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:83.149, tt:1496.688\n",
      "Ep:18, loss:0.00014, loss_test:0.08136, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:83.158, tt:1580.000\n",
      "Ep:19, loss:0.00013, loss_test:0.08010, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:83.300, tt:1666.004\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.07339, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:83.370, tt:1750.763\n",
      "Ep:21, loss:0.00011, loss_test:0.07448, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:83.387, tt:1834.506\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00010, loss_test:0.07751, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:83.501, tt:1920.531\n",
      "Ep:23, loss:0.00009, loss_test:0.07212, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:83.551, tt:2005.234\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00009, loss_test:0.07476, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:83.539, tt:2088.483\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00008, loss_test:0.07369, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:83.596, tt:2173.486\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.07849, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:83.588, tt:2256.878\n",
      "Ep:27, loss:0.00007, loss_test:0.07848, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:83.495, tt:2337.854\n",
      "Ep:28, loss:0.00006, loss_test:0.07330, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:83.508, tt:2421.720\n",
      "Ep:29, loss:0.00006, loss_test:0.07272, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:83.575, tt:2507.247\n",
      "Ep:30, loss:0.00005, loss_test:0.07207, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:83.575, tt:2590.815\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00005, loss_test:0.07437, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:83.667, tt:2677.347\n",
      "Ep:32, loss:0.00004, loss_test:0.07980, lr:1.00e-02, fs:0.74847 (r=0.616,p=0.953),  time:83.648, tt:2760.390\n",
      "Ep:33, loss:0.00004, loss_test:0.07288, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:83.663, tt:2844.557\n",
      "Ep:34, loss:0.00004, loss_test:0.07357, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:83.649, tt:2927.716\n",
      "Ep:35, loss:0.00003, loss_test:0.07423, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:83.626, tt:3010.536\n",
      "Ep:36, loss:0.00003, loss_test:0.07821, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:83.643, tt:3094.804\n",
      "Ep:37, loss:0.00003, loss_test:0.08147, lr:1.00e-02, fs:0.74074 (r=0.606,p=0.952),  time:83.599, tt:3176.755\n",
      "Ep:38, loss:0.00003, loss_test:0.07803, lr:1.00e-02, fs:0.74074 (r=0.606,p=0.952),  time:83.640, tt:3261.968\n",
      "Ep:39, loss:0.00003, loss_test:0.08318, lr:1.00e-02, fs:0.74534 (r=0.606,p=0.968),  time:83.644, tt:3345.748\n",
      "Ep:40, loss:0.00002, loss_test:0.07744, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:83.653, tt:3429.767\n",
      "Ep:41, loss:0.00002, loss_test:0.08031, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:83.781, tt:3518.812\n",
      "Ep:42, loss:0.00002, loss_test:0.07603, lr:9.90e-03, fs:0.79762 (r=0.677,p=0.971),  time:83.727, tt:3600.246\n",
      "Ep:43, loss:0.00002, loss_test:0.08001, lr:9.80e-03, fs:0.76543 (r=0.626,p=0.984),  time:83.699, tt:3682.769\n",
      "Ep:44, loss:0.00002, loss_test:0.07724, lr:9.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:83.661, tt:3764.728\n",
      "Ep:45, loss:0.00002, loss_test:0.07737, lr:9.61e-03, fs:0.74534 (r=0.606,p=0.968),  time:83.677, tt:3849.156\n",
      "Ep:46, loss:0.00002, loss_test:0.08419, lr:9.51e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.632, tt:3930.684\n",
      "Ep:47, loss:0.00002, loss_test:0.08620, lr:9.41e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.580, tt:4011.847\n",
      "Ep:48, loss:0.00001, loss_test:0.08146, lr:9.32e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.590, tt:4095.911\n",
      "Ep:49, loss:0.00001, loss_test:0.07939, lr:9.23e-03, fs:0.75000 (r=0.606,p=0.984),  time:83.568, tt:4178.389\n",
      "Ep:50, loss:0.00001, loss_test:0.08077, lr:9.14e-03, fs:0.76250 (r=0.616,p=1.000),  time:83.566, tt:4261.872\n",
      "Ep:51, loss:0.00001, loss_test:0.07976, lr:9.04e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.555, tt:4344.872\n",
      "Ep:52, loss:0.00001, loss_test:0.08124, lr:8.95e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.542, tt:4427.734\n",
      "Ep:53, loss:0.00001, loss_test:0.08467, lr:8.86e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.555, tt:4511.977\n",
      "Ep:54, loss:0.00001, loss_test:0.08264, lr:8.78e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.556, tt:4595.573\n",
      "Ep:55, loss:0.00001, loss_test:0.08222, lr:8.69e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.487, tt:4675.264\n",
      "Ep:56, loss:0.00001, loss_test:0.08272, lr:8.60e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.507, tt:4759.891\n",
      "Ep:57, loss:0.00001, loss_test:0.08255, lr:8.51e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.490, tt:4842.410\n",
      "Ep:58, loss:0.00001, loss_test:0.08642, lr:8.43e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.456, tt:4923.900\n",
      "Ep:59, loss:0.00001, loss_test:0.08376, lr:8.35e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.440, tt:5006.403\n",
      "Ep:60, loss:0.00001, loss_test:0.07977, lr:8.26e-03, fs:0.75000 (r=0.606,p=0.984),  time:83.422, tt:5088.769\n",
      "Ep:61, loss:0.00001, loss_test:0.08343, lr:8.18e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.385, tt:5169.846\n",
      "Ep:62, loss:0.00001, loss_test:0.08363, lr:8.10e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.410, tt:5254.814\n",
      "Ep:63, loss:0.00000, loss_test:0.08367, lr:8.02e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.418, tt:5338.734\n",
      "Ep:64, loss:0.00000, loss_test:0.08467, lr:7.94e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.421, tt:5422.341\n",
      "Ep:65, loss:0.00000, loss_test:0.08104, lr:7.86e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.436, tt:5506.804\n",
      "Ep:66, loss:0.00000, loss_test:0.08572, lr:7.78e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.465, tt:5592.128\n",
      "Ep:67, loss:0.00000, loss_test:0.08197, lr:7.70e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.509, tt:5678.611\n",
      "Ep:68, loss:0.00000, loss_test:0.08579, lr:7.62e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.522, tt:5763.001\n",
      "Ep:69, loss:0.00000, loss_test:0.08392, lr:7.55e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.482, tt:5843.772\n",
      "Ep:70, loss:0.00000, loss_test:0.08352, lr:7.47e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.456, tt:5925.363\n",
      "Ep:71, loss:0.00000, loss_test:0.08324, lr:7.40e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.439, tt:6007.599\n",
      "Ep:72, loss:0.00000, loss_test:0.08157, lr:7.32e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.437, tt:6090.874\n",
      "Ep:73, loss:0.00000, loss_test:0.08400, lr:7.25e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.439, tt:6174.490\n",
      "Ep:74, loss:0.00000, loss_test:0.08367, lr:7.18e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.427, tt:6257.044\n",
      "Ep:75, loss:0.00000, loss_test:0.08345, lr:7.11e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.399, tt:6338.355\n",
      "Ep:76, loss:0.00000, loss_test:0.08358, lr:7.03e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.405, tt:6422.182\n",
      "Ep:77, loss:0.00000, loss_test:0.08287, lr:6.96e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.465, tt:6510.273\n",
      "Ep:78, loss:0.00000, loss_test:0.08404, lr:6.89e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.461, tt:6593.392\n",
      "Ep:79, loss:0.00000, loss_test:0.08245, lr:6.83e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.453, tt:6676.215\n",
      "Ep:80, loss:0.00000, loss_test:0.08337, lr:6.76e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.433, tt:6758.110\n",
      "Ep:81, loss:0.00000, loss_test:0.08500, lr:6.69e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.436, tt:6841.753\n",
      "Ep:82, loss:0.00000, loss_test:0.08325, lr:6.62e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.436, tt:6925.193\n",
      "Ep:83, loss:0.00000, loss_test:0.08320, lr:6.56e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.422, tt:7007.448\n",
      "Ep:84, loss:0.00000, loss_test:0.08208, lr:6.49e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.421, tt:7090.754\n",
      "Ep:85, loss:0.00000, loss_test:0.08317, lr:6.43e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.406, tt:7172.949\n",
      "Ep:86, loss:0.00000, loss_test:0.08315, lr:6.36e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.385, tt:7254.456\n",
      "Ep:87, loss:0.00000, loss_test:0.08361, lr:6.30e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.364, tt:7336.039\n",
      "Ep:88, loss:0.00000, loss_test:0.08446, lr:6.24e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.353, tt:7418.459\n",
      "Ep:89, loss:0.00000, loss_test:0.08331, lr:6.17e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.375, tt:7503.727\n",
      "Ep:90, loss:0.00000, loss_test:0.08423, lr:6.11e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.334, tt:7583.422\n",
      "Ep:91, loss:0.00000, loss_test:0.08386, lr:6.05e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.362, tt:7669.284\n",
      "Ep:92, loss:0.00000, loss_test:0.08263, lr:5.99e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.372, tt:7753.631\n",
      "Ep:93, loss:0.00000, loss_test:0.08348, lr:5.93e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.322, tt:7832.230\n",
      "Ep:94, loss:0.00000, loss_test:0.08346, lr:5.87e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.307, tt:7914.176\n",
      "Ep:95, loss:0.00000, loss_test:0.08356, lr:5.81e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.290, tt:7995.799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00000, loss_test:0.08263, lr:5.75e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.242, tt:8074.450\n",
      "Ep:97, loss:0.00000, loss_test:0.08346, lr:5.70e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.232, tt:8156.701\n",
      "Ep:98, loss:0.00000, loss_test:0.08313, lr:5.64e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.256, tt:8242.353\n",
      "Ep:99, loss:0.00000, loss_test:0.08238, lr:5.58e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.248, tt:8324.841\n",
      "Ep:100, loss:0.00000, loss_test:0.08544, lr:5.53e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.266, tt:8409.897\n",
      "Ep:101, loss:0.00000, loss_test:0.08263, lr:5.47e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.216, tt:8488.056\n",
      "Ep:102, loss:0.00000, loss_test:0.08381, lr:5.42e-03, fs:0.74684 (r=0.596,p=1.000),  time:83.202, tt:8569.827\n",
      "Ep:103, loss:0.00000, loss_test:0.08327, lr:5.36e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.158, tt:8648.452\n",
      "Ep:104, loss:0.00000, loss_test:0.08306, lr:5.31e-03, fs:0.75472 (r=0.606,p=1.000),  time:83.073, tt:8722.639\n",
      "Ep:105, loss:0.00000, loss_test:0.08466, lr:5.26e-03, fs:0.74684 (r=0.596,p=1.000),  time:83.045, tt:8802.767\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00054, loss_test:0.14551, lr:1.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:75.041, tt:75.041\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00051, loss_test:0.14345, lr:1.00e-02, fs:0.61044 (r=0.768,p=0.507),  time:74.580, tt:149.160\n",
      "Ep:2, loss:0.00049, loss_test:0.14301, lr:1.00e-02, fs:0.61925 (r=0.747,p=0.529),  time:75.317, tt:225.951\n",
      "Ep:3, loss:0.00046, loss_test:0.13572, lr:1.00e-02, fs:0.62979 (r=0.747,p=0.544),  time:75.277, tt:301.106\n",
      "Ep:4, loss:0.00043, loss_test:0.13001, lr:1.00e-02, fs:0.64286 (r=0.727,p=0.576),  time:75.280, tt:376.401\n",
      "Ep:5, loss:0.00040, loss_test:0.12323, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:75.215, tt:451.293\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00037, loss_test:0.11669, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:75.266, tt:526.864\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00035, loss_test:0.10952, lr:1.00e-02, fs:0.68519 (r=0.747,p=0.632),  time:75.299, tt:602.389\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00033, loss_test:0.10718, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:75.233, tt:677.095\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00031, loss_test:0.10014, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:75.244, tt:752.439\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00029, loss_test:0.09872, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:75.423, tt:829.648\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.09399, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:75.394, tt:904.723\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.09160, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:75.465, tt:981.042\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.09077, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:75.564, tt:1057.890\n",
      "Ep:14, loss:0.00023, loss_test:0.08824, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:75.816, tt:1137.244\n",
      "Ep:15, loss:0.00022, loss_test:0.08410, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:75.887, tt:1214.200\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.08443, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:75.881, tt:1289.969\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.08405, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:75.902, tt:1366.242\n",
      "Ep:18, loss:0.00019, loss_test:0.08136, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:76.005, tt:1444.093\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.07836, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:76.020, tt:1520.395\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.07637, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:76.013, tt:1596.264\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.07764, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:75.873, tt:1669.202\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07651, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:75.801, tt:1743.429\n",
      "Ep:23, loss:0.00014, loss_test:0.07446, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:75.762, tt:1818.292\n",
      "Ep:24, loss:0.00013, loss_test:0.07449, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:75.736, tt:1893.407\n",
      "Ep:25, loss:0.00013, loss_test:0.07083, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:75.649, tt:1966.876\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.07216, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:75.510, tt:2038.762\n",
      "Ep:27, loss:0.00011, loss_test:0.07291, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:75.458, tt:2112.815\n",
      "Ep:28, loss:0.00011, loss_test:0.07258, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:75.449, tt:2188.032\n",
      "Ep:29, loss:0.00010, loss_test:0.07117, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:75.439, tt:2263.161\n",
      "Ep:30, loss:0.00009, loss_test:0.07727, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:75.366, tt:2336.360\n",
      "Ep:31, loss:0.00009, loss_test:0.07505, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:75.281, tt:2408.983\n",
      "Ep:32, loss:0.00009, loss_test:0.07608, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:75.329, tt:2485.862\n",
      "Ep:33, loss:0.00010, loss_test:0.07896, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:75.302, tt:2560.273\n",
      "Ep:34, loss:0.00009, loss_test:0.08389, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:75.207, tt:2632.246\n",
      "Ep:35, loss:0.00009, loss_test:0.07974, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:75.187, tt:2706.749\n",
      "Ep:36, loss:0.00008, loss_test:0.07343, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:75.103, tt:2778.795\n",
      "Ep:37, loss:0.00007, loss_test:0.07221, lr:9.90e-03, fs:0.82609 (r=0.768,p=0.894),  time:75.104, tt:2853.966\n",
      "Ep:38, loss:0.00007, loss_test:0.08004, lr:9.80e-03, fs:0.82222 (r=0.747,p=0.914),  time:75.107, tt:2929.189\n",
      "Ep:39, loss:0.00006, loss_test:0.08228, lr:9.70e-03, fs:0.84270 (r=0.758,p=0.949),  time:75.133, tt:3005.308\n",
      "Ep:40, loss:0.00006, loss_test:0.07906, lr:9.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:75.092, tt:3078.759\n",
      "Ep:41, loss:0.00006, loss_test:0.07622, lr:9.51e-03, fs:0.83516 (r=0.768,p=0.916),  time:75.048, tt:3152.030\n",
      "Ep:42, loss:0.00005, loss_test:0.07897, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:75.039, tt:3226.686\n",
      "Ep:43, loss:0.00005, loss_test:0.07829, lr:9.32e-03, fs:0.84444 (r=0.768,p=0.938),  time:75.032, tt:3301.425\n",
      "Ep:44, loss:0.00005, loss_test:0.07766, lr:9.23e-03, fs:0.85393 (r=0.768,p=0.962),  time:75.034, tt:3376.524\n",
      "Ep:45, loss:0.00005, loss_test:0.07909, lr:9.14e-03, fs:0.85393 (r=0.768,p=0.962),  time:74.996, tt:3449.795\n",
      "Ep:46, loss:0.00005, loss_test:0.08173, lr:9.04e-03, fs:0.85393 (r=0.768,p=0.962),  time:74.965, tt:3523.372\n",
      "Ep:47, loss:0.00005, loss_test:0.08566, lr:8.95e-03, fs:0.77647 (r=0.667,p=0.930),  time:74.965, tt:3598.315\n",
      "Ep:48, loss:0.00005, loss_test:0.08058, lr:8.86e-03, fs:0.78409 (r=0.697,p=0.896),  time:74.961, tt:3673.094\n",
      "Ep:49, loss:0.00005, loss_test:0.07906, lr:8.78e-03, fs:0.77714 (r=0.687,p=0.895),  time:74.991, tt:3749.565\n",
      "Ep:50, loss:0.00004, loss_test:0.08082, lr:8.69e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.968, tt:3823.392\n",
      "Ep:51, loss:0.00004, loss_test:0.08197, lr:8.60e-03, fs:0.84916 (r=0.768,p=0.950),  time:75.040, tt:3902.085\n",
      "Ep:52, loss:0.00004, loss_test:0.08258, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:75.044, tt:3977.345\n",
      "Ep:53, loss:0.00004, loss_test:0.07985, lr:8.43e-03, fs:0.80682 (r=0.717,p=0.922),  time:75.007, tt:4050.378\n",
      "Ep:54, loss:0.00004, loss_test:0.08289, lr:8.35e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.967, tt:4123.195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00003, loss_test:0.08126, lr:8.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:75.009, tt:4200.504\n",
      "Ep:56, loss:0.00003, loss_test:0.08184, lr:8.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.999, tt:4274.962\n",
      "Ep:57, loss:0.00003, loss_test:0.08269, lr:8.10e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.968, tt:4348.162\n",
      "Ep:58, loss:0.00003, loss_test:0.08196, lr:8.02e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.953, tt:4422.222\n",
      "Ep:59, loss:0.00003, loss_test:0.08171, lr:7.94e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.904, tt:4494.254\n",
      "Ep:60, loss:0.00003, loss_test:0.08266, lr:7.86e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.900, tt:4568.890\n",
      "Ep:61, loss:0.00003, loss_test:0.08438, lr:7.78e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.887, tt:4642.970\n",
      "Ep:62, loss:0.00003, loss_test:0.08385, lr:7.70e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.892, tt:4718.185\n",
      "Ep:63, loss:0.00003, loss_test:0.08147, lr:7.62e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.857, tt:4790.876\n",
      "Ep:64, loss:0.00002, loss_test:0.08155, lr:7.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.844, tt:4864.867\n",
      "Ep:65, loss:0.00002, loss_test:0.08272, lr:7.47e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.841, tt:4939.494\n",
      "Ep:66, loss:0.00002, loss_test:0.08232, lr:7.40e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.836, tt:5014.032\n",
      "Ep:67, loss:0.00002, loss_test:0.08304, lr:7.32e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.819, tt:5087.717\n",
      "Ep:68, loss:0.00002, loss_test:0.08284, lr:7.25e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.824, tt:5162.826\n",
      "Ep:69, loss:0.00002, loss_test:0.08323, lr:7.18e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.821, tt:5237.477\n",
      "Ep:70, loss:0.00002, loss_test:0.08406, lr:7.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.839, tt:5313.589\n",
      "Ep:71, loss:0.00002, loss_test:0.08360, lr:7.03e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.815, tt:5386.694\n",
      "Ep:72, loss:0.00002, loss_test:0.08342, lr:6.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.838, tt:5463.163\n",
      "Ep:73, loss:0.00002, loss_test:0.08356, lr:6.89e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.833, tt:5537.662\n",
      "Ep:74, loss:0.00002, loss_test:0.08381, lr:6.83e-03, fs:0.78107 (r=0.667,p=0.943),  time:74.791, tt:5609.290\n",
      "Ep:75, loss:0.00002, loss_test:0.08418, lr:6.76e-03, fs:0.79290 (r=0.677,p=0.957),  time:74.805, tt:5685.181\n",
      "Ep:76, loss:0.00002, loss_test:0.08511, lr:6.69e-03, fs:0.78107 (r=0.667,p=0.943),  time:74.826, tt:5761.626\n",
      "Ep:77, loss:0.00002, loss_test:0.08231, lr:6.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.850, tt:5838.292\n",
      "Ep:78, loss:0.00002, loss_test:0.08299, lr:6.56e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.840, tt:5912.343\n",
      "Ep:79, loss:0.00002, loss_test:0.08240, lr:6.49e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.834, tt:5986.731\n",
      "Ep:80, loss:0.00002, loss_test:0.08522, lr:6.43e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.844, tt:6062.394\n",
      "Ep:81, loss:0.00002, loss_test:0.08587, lr:6.36e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.833, tt:6136.333\n",
      "Ep:82, loss:0.00002, loss_test:0.08215, lr:6.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.830, tt:6210.908\n",
      "Ep:83, loss:0.00002, loss_test:0.08402, lr:6.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.817, tt:6284.594\n",
      "Ep:84, loss:0.00002, loss_test:0.08463, lr:6.17e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.813, tt:6359.106\n",
      "Ep:85, loss:0.00002, loss_test:0.08225, lr:6.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.818, tt:6434.390\n",
      "Ep:86, loss:0.00002, loss_test:0.08455, lr:6.05e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.786, tt:6506.373\n",
      "Ep:87, loss:0.00002, loss_test:0.08515, lr:5.99e-03, fs:0.79290 (r=0.677,p=0.957),  time:74.828, tt:6584.821\n",
      "Ep:88, loss:0.00002, loss_test:0.08222, lr:5.93e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.813, tt:6658.341\n",
      "Ep:89, loss:0.00002, loss_test:0.08597, lr:5.87e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.820, tt:6733.816\n",
      "Ep:90, loss:0.00002, loss_test:0.08602, lr:5.81e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.809, tt:6807.614\n",
      "Ep:91, loss:0.00002, loss_test:0.08367, lr:5.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.803, tt:6881.898\n",
      "Ep:92, loss:0.00001, loss_test:0.08443, lr:5.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.777, tt:6954.257\n",
      "Ep:93, loss:0.00002, loss_test:0.08539, lr:5.64e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.781, tt:7029.416\n",
      "Ep:94, loss:0.00002, loss_test:0.08460, lr:5.58e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.782, tt:7104.331\n",
      "Ep:95, loss:0.00001, loss_test:0.08225, lr:5.53e-03, fs:0.80473 (r=0.687,p=0.971),  time:74.790, tt:7179.811\n",
      "Ep:96, loss:0.00001, loss_test:0.08416, lr:5.47e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.776, tt:7253.318\n",
      "Ep:97, loss:0.00001, loss_test:0.08387, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:74.735, tt:7324.037\n",
      "Ep:98, loss:0.00001, loss_test:0.08541, lr:5.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.743, tt:7399.509\n",
      "Ep:99, loss:0.00001, loss_test:0.08355, lr:5.31e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.760, tt:7476.041\n",
      "Ep:100, loss:0.00001, loss_test:0.08541, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:74.746, tt:7549.348\n",
      "Ep:101, loss:0.00001, loss_test:0.08360, lr:5.20e-03, fs:0.80473 (r=0.687,p=0.971),  time:74.698, tt:7619.171\n",
      "Ep:102, loss:0.00001, loss_test:0.08377, lr:5.15e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.609, tt:7684.682\n",
      "Ep:103, loss:0.00001, loss_test:0.08482, lr:5.10e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.346, tt:7731.941\n",
      "Ep:104, loss:0.00001, loss_test:0.08442, lr:5.05e-03, fs:0.79762 (r=0.677,p=0.971),  time:73.901, tt:7759.602\n",
      "Ep:105, loss:0.00001, loss_test:0.08487, lr:5.00e-03, fs:0.79762 (r=0.677,p=0.971),  time:73.418, tt:7782.342\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02547, lr:6.00e-02, fs:0.66063 (r=0.737,p=0.598),  time:34.251, tt:34.251\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02296, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:34.294, tt:68.589\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02430, lr:6.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:34.348, tt:103.045\n",
      "Ep:3, loss:0.00005, loss_test:0.02418, lr:6.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:34.430, tt:137.721\n",
      "Ep:4, loss:0.00005, loss_test:0.02392, lr:6.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:34.570, tt:172.849\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02366, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:34.276, tt:205.658\n",
      "Ep:6, loss:0.00005, loss_test:0.02335, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:34.462, tt:241.231\n",
      "Ep:7, loss:0.00005, loss_test:0.02281, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:34.642, tt:277.132\n",
      "Ep:8, loss:0.00005, loss_test:0.02229, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:34.551, tt:310.959\n",
      "Ep:9, loss:0.00005, loss_test:0.02170, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:34.564, tt:345.639\n",
      "Ep:10, loss:0.00005, loss_test:0.02104, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:34.594, tt:380.535\n",
      "Ep:11, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:34.573, tt:414.877\n",
      "Ep:12, loss:0.00004, loss_test:0.01952, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:34.504, tt:448.550\n",
      "Ep:13, loss:0.00004, loss_test:0.01884, lr:6.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:34.399, tt:481.583\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01817, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:34.391, tt:515.864\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01763, lr:6.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:34.459, tt:551.337\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01721, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:34.457, tt:585.777\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01684, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:34.516, tt:621.294\n",
      "Ep:18, loss:0.00004, loss_test:0.01647, lr:6.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:34.483, tt:655.170\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01611, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:34.440, tt:688.798\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:34.439, tt:723.215\n",
      "Ep:21, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:34.500, tt:758.991\n",
      "Ep:22, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:34.495, tt:793.384\n",
      "Ep:23, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:34.461, tt:827.065\n",
      "Ep:24, loss:0.00003, loss_test:0.01512, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:34.430, tt:860.739\n",
      "Ep:25, loss:0.00003, loss_test:0.01498, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:34.427, tt:895.091\n",
      "Ep:26, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:34.504, tt:931.621\n",
      "Ep:27, loss:0.00003, loss_test:0.01447, lr:6.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:34.486, tt:965.595\n",
      "Ep:28, loss:0.00003, loss_test:0.01426, lr:6.00e-02, fs:0.75105 (r=0.899,p=0.645),  time:34.443, tt:998.851\n",
      "Ep:29, loss:0.00003, loss_test:0.01411, lr:6.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:34.442, tt:1033.267\n",
      "Ep:30, loss:0.00003, loss_test:0.01387, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:34.479, tt:1068.853\n",
      "Ep:31, loss:0.00003, loss_test:0.01371, lr:5.94e-02, fs:0.76596 (r=0.909,p=0.662),  time:34.483, tt:1103.464\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01350, lr:5.94e-02, fs:0.77253 (r=0.909,p=0.672),  time:34.544, tt:1139.968\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01330, lr:5.94e-02, fs:0.78112 (r=0.919,p=0.679),  time:34.542, tt:1174.444\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01318, lr:5.94e-02, fs:0.78112 (r=0.919,p=0.679),  time:34.580, tt:1210.299\n",
      "Ep:35, loss:0.00002, loss_test:0.01306, lr:5.94e-02, fs:0.78261 (r=0.909,p=0.687),  time:34.667, tt:1248.008\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01292, lr:5.94e-02, fs:0.78112 (r=0.919,p=0.679),  time:34.648, tt:1281.976\n",
      "Ep:37, loss:0.00002, loss_test:0.01292, lr:5.94e-02, fs:0.79654 (r=0.929,p=0.697),  time:34.667, tt:1317.336\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01269, lr:5.94e-02, fs:0.82667 (r=0.939,p=0.738),  time:34.722, tt:1354.172\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01256, lr:5.94e-02, fs:0.80687 (r=0.949,p=0.701),  time:34.724, tt:1388.964\n",
      "Ep:40, loss:0.00002, loss_test:0.01283, lr:5.94e-02, fs:0.81614 (r=0.919,p=0.734),  time:34.708, tt:1423.021\n",
      "Ep:41, loss:0.00002, loss_test:0.01249, lr:5.94e-02, fs:0.79646 (r=0.909,p=0.709),  time:34.726, tt:1458.496\n",
      "Ep:42, loss:0.00002, loss_test:0.01240, lr:5.94e-02, fs:0.82143 (r=0.929,p=0.736),  time:34.751, tt:1494.312\n",
      "Ep:43, loss:0.00002, loss_test:0.01256, lr:5.94e-02, fs:0.82143 (r=0.929,p=0.736),  time:34.775, tt:1530.088\n",
      "Ep:44, loss:0.00002, loss_test:0.01232, lr:5.94e-02, fs:0.80531 (r=0.919,p=0.717),  time:34.790, tt:1565.550\n",
      "Ep:45, loss:0.00002, loss_test:0.01259, lr:5.94e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.799, tt:1600.732\n",
      "Ep:46, loss:0.00002, loss_test:0.01257, lr:5.94e-02, fs:0.80357 (r=0.909,p=0.720),  time:34.819, tt:1636.492\n",
      "Ep:47, loss:0.00002, loss_test:0.01286, lr:5.94e-02, fs:0.82407 (r=0.899,p=0.761),  time:34.808, tt:1670.788\n",
      "Ep:48, loss:0.00002, loss_test:0.01230, lr:5.94e-02, fs:0.80909 (r=0.899,p=0.736),  time:34.797, tt:1705.069\n",
      "Ep:49, loss:0.00002, loss_test:0.01220, lr:5.94e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.790, tt:1739.506\n",
      "Ep:50, loss:0.00001, loss_test:0.01198, lr:5.88e-02, fs:0.81690 (r=0.879,p=0.763),  time:34.785, tt:1774.032\n",
      "Ep:51, loss:0.00001, loss_test:0.01174, lr:5.82e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.787, tt:1808.904\n",
      "Ep:52, loss:0.00001, loss_test:0.01228, lr:5.76e-02, fs:0.82791 (r=0.899,p=0.767),  time:34.761, tt:1842.317\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01231, lr:5.76e-02, fs:0.80374 (r=0.869,p=0.748),  time:34.750, tt:1876.497\n",
      "Ep:54, loss:0.00001, loss_test:0.01220, lr:5.76e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.754, tt:1911.497\n",
      "Ep:55, loss:0.00001, loss_test:0.01165, lr:5.76e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.765, tt:1946.844\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01175, lr:5.76e-02, fs:0.82927 (r=0.859,p=0.802),  time:34.778, tt:1982.359\n",
      "Ep:57, loss:0.00001, loss_test:0.01174, lr:5.76e-02, fs:0.83495 (r=0.869,p=0.804),  time:34.782, tt:2017.379\n",
      "Ep:58, loss:0.00001, loss_test:0.01181, lr:5.76e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.797, tt:2053.012\n",
      "Ep:59, loss:0.00001, loss_test:0.01168, lr:5.76e-02, fs:0.82828 (r=0.828,p=0.828),  time:34.812, tt:2088.701\n",
      "Ep:60, loss:0.00001, loss_test:0.01187, lr:5.76e-02, fs:0.82828 (r=0.828,p=0.828),  time:34.822, tt:2124.142\n",
      "Ep:61, loss:0.00001, loss_test:0.01179, lr:5.76e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.831, tt:2159.541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01212, lr:5.76e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.831, tt:2194.349\n",
      "Ep:63, loss:0.00001, loss_test:0.01214, lr:5.76e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.854, tt:2230.638\n",
      "Ep:64, loss:0.00001, loss_test:0.01215, lr:5.76e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.878, tt:2267.073\n",
      "Ep:65, loss:0.00001, loss_test:0.01224, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.887, tt:2302.545\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01165, lr:5.76e-02, fs:0.82828 (r=0.828,p=0.828),  time:34.881, tt:2337.044\n",
      "Ep:67, loss:0.00001, loss_test:0.01210, lr:5.76e-02, fs:0.82000 (r=0.828,p=0.812),  time:34.897, tt:2372.962\n",
      "Ep:68, loss:0.00001, loss_test:0.01210, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.893, tt:2407.634\n",
      "Ep:69, loss:0.00001, loss_test:0.01203, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.904, tt:2443.301\n",
      "Ep:70, loss:0.00001, loss_test:0.01198, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.913, tt:2478.792\n",
      "Ep:71, loss:0.00001, loss_test:0.01224, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.916, tt:2513.966\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01206, lr:5.76e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.905, tt:2548.065\n",
      "Ep:73, loss:0.00001, loss_test:0.01218, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.919, tt:2584.011\n",
      "Ep:74, loss:0.00001, loss_test:0.01283, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.921, tt:2619.055\n",
      "Ep:75, loss:0.00001, loss_test:0.01250, lr:5.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.930, tt:2654.690\n",
      "Ep:76, loss:0.00001, loss_test:0.01259, lr:5.76e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.934, tt:2689.931\n",
      "Ep:77, loss:0.00001, loss_test:0.01302, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.950, tt:2726.127\n",
      "Ep:78, loss:0.00001, loss_test:0.01211, lr:5.76e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.955, tt:2761.412\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01261, lr:5.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.944, tt:2795.543\n",
      "Ep:80, loss:0.00001, loss_test:0.01204, lr:5.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.953, tt:2831.203\n",
      "Ep:81, loss:0.00001, loss_test:0.01214, lr:5.76e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.958, tt:2866.540\n",
      "Ep:82, loss:0.00001, loss_test:0.01254, lr:5.76e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.958, tt:2901.517\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00000, loss_test:0.01199, lr:5.76e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.972, tt:2937.683\n",
      "Ep:84, loss:0.00001, loss_test:0.01306, lr:5.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.970, tt:2972.480\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00000, loss_test:0.01244, lr:5.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.975, tt:3007.808\n",
      "Ep:86, loss:0.00000, loss_test:0.01291, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.976, tt:3042.927\n",
      "Ep:87, loss:0.00000, loss_test:0.01292, lr:5.76e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.988, tt:3078.925\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00000, loss_test:0.01245, lr:5.76e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.979, tt:3113.155\n",
      "Ep:89, loss:0.00000, loss_test:0.01295, lr:5.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.002, tt:3150.203\n",
      "Ep:90, loss:0.00000, loss_test:0.01318, lr:5.76e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.993, tt:3184.342\n",
      "Ep:91, loss:0.00001, loss_test:0.01275, lr:5.76e-02, fs:0.83938 (r=0.818,p=0.862),  time:35.007, tt:3220.605\n",
      "Ep:92, loss:0.00000, loss_test:0.01243, lr:5.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.011, tt:3256.029\n",
      "Ep:93, loss:0.00001, loss_test:0.01228, lr:5.76e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.014, tt:3291.349\n",
      "Ep:94, loss:0.00000, loss_test:0.01198, lr:5.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.017, tt:3326.633\n",
      "Ep:95, loss:0.00000, loss_test:0.01280, lr:5.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.023, tt:3362.180\n",
      "Ep:96, loss:0.00000, loss_test:0.01194, lr:5.76e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.026, tt:3397.552\n",
      "Ep:97, loss:0.00000, loss_test:0.01263, lr:5.76e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.023, tt:3432.285\n",
      "Ep:98, loss:0.00000, loss_test:0.01253, lr:5.76e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.004, tt:3465.423\n",
      "Ep:99, loss:0.00000, loss_test:0.01248, lr:5.71e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.998, tt:3499.777\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00000, loss_test:0.01285, lr:5.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.004, tt:3535.438\n",
      "Ep:101, loss:0.00000, loss_test:0.01275, lr:5.71e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.006, tt:3570.656\n",
      "Ep:102, loss:0.00000, loss_test:0.01247, lr:5.71e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.013, tt:3606.331\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00000, loss_test:0.01301, lr:5.71e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.013, tt:3641.343\n",
      "Ep:104, loss:0.00000, loss_test:0.01301, lr:5.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.022, tt:3677.296\n",
      "Ep:105, loss:0.00000, loss_test:0.01320, lr:5.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.030, tt:3713.152\n",
      "Ep:106, loss:0.00000, loss_test:0.01322, lr:5.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.027, tt:3747.891\n",
      "Ep:107, loss:0.00000, loss_test:0.01330, lr:5.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.020, tt:3782.187\n",
      "Ep:108, loss:0.00000, loss_test:0.01370, lr:5.71e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.036, tt:3818.882\n",
      "Ep:109, loss:0.00000, loss_test:0.01340, lr:5.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.035, tt:3853.878\n",
      "Ep:110, loss:0.00000, loss_test:0.01356, lr:5.71e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.036, tt:3889.029\n",
      "Ep:111, loss:0.00000, loss_test:0.01369, lr:5.71e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.032, tt:3923.595\n",
      "Ep:112, loss:0.00000, loss_test:0.01373, lr:5.71e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.042, tt:3959.732\n",
      "Ep:113, loss:0.00000, loss_test:0.01444, lr:5.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.038, tt:3994.275\n",
      "Ep:114, loss:0.00000, loss_test:0.01383, lr:5.65e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.045, tt:4030.208\n",
      "Ep:115, loss:0.00000, loss_test:0.01430, lr:5.59e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.046, tt:4065.289\n",
      "Ep:116, loss:0.00000, loss_test:0.01444, lr:5.54e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.044, tt:4100.156\n",
      "Ep:117, loss:0.00000, loss_test:0.01409, lr:5.48e-02, fs:0.86772 (r=0.828,p=0.911),  time:35.052, tt:4136.109\n",
      "Ep:118, loss:0.00000, loss_test:0.01440, lr:5.43e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.050, tt:4170.989\n",
      "Ep:119, loss:0.00000, loss_test:0.01464, lr:5.37e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.052, tt:4206.194\n",
      "Ep:120, loss:0.00000, loss_test:0.01462, lr:5.32e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.041, tt:4239.915\n",
      "Ep:121, loss:0.00000, loss_test:0.01461, lr:5.27e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.034, tt:4274.159\n",
      "Ep:122, loss:0.00000, loss_test:0.01457, lr:5.21e-02, fs:0.85561 (r=0.808,p=0.909),  time:35.033, tt:4309.011\n",
      "Ep:123, loss:0.00000, loss_test:0.01518, lr:5.16e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.030, tt:4343.714\n",
      "Ep:124, loss:0.00000, loss_test:0.01485, lr:5.11e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.027, tt:4378.375\n",
      "Ep:125, loss:0.00000, loss_test:0.01499, lr:5.06e-02, fs:0.85561 (r=0.808,p=0.909),  time:35.013, tt:4411.610\n",
      "Ep:126, loss:0.00000, loss_test:0.01556, lr:5.01e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.011, tt:4446.380\n",
      "Ep:127, loss:0.00000, loss_test:0.01518, lr:4.96e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.013, tt:4481.628\n",
      "Ep:128, loss:0.00000, loss_test:0.01545, lr:4.91e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.046, tt:4520.980\n",
      "Ep:129, loss:0.00000, loss_test:0.01548, lr:4.86e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.050, tt:4556.459\n",
      "Ep:130, loss:0.00000, loss_test:0.01560, lr:4.81e-02, fs:0.79096 (r=0.707,p=0.897),  time:35.053, tt:4591.953\n",
      "Ep:131, loss:0.00000, loss_test:0.01565, lr:4.76e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.038, tt:4625.017\n",
      "Ep:132, loss:0.00000, loss_test:0.01578, lr:4.71e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.037, tt:4659.917\n",
      "Ep:133, loss:0.00000, loss_test:0.01587, lr:4.67e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.035, tt:4694.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01588, lr:4.62e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.043, tt:4730.761\n",
      "Ep:135, loss:0.00000, loss_test:0.01606, lr:4.57e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.056, tt:4767.583\n",
      "Ep:136, loss:0.00000, loss_test:0.01613, lr:4.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.048, tt:4801.552\n",
      "Ep:137, loss:0.00000, loss_test:0.01605, lr:4.48e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.054, tt:4837.442\n",
      "Ep:138, loss:0.00000, loss_test:0.01621, lr:4.44e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.058, tt:4873.130\n",
      "Ep:139, loss:0.00000, loss_test:0.01628, lr:4.39e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.053, tt:4907.433\n",
      "Ep:140, loss:0.00000, loss_test:0.01626, lr:4.35e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.068, tt:4944.521\n",
      "Ep:141, loss:0.00000, loss_test:0.01646, lr:4.31e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.082, tt:4981.628\n",
      "Ep:142, loss:0.00000, loss_test:0.01646, lr:4.26e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.090, tt:5017.924\n",
      "Ep:143, loss:0.00000, loss_test:0.01654, lr:4.22e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.088, tt:5052.703\n",
      "Ep:144, loss:0.00000, loss_test:0.01662, lr:4.18e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.084, tt:5087.110\n",
      "Ep:145, loss:0.00000, loss_test:0.01664, lr:4.14e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.074, tt:5120.817\n",
      "Ep:146, loss:0.00000, loss_test:0.01669, lr:4.10e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.070, tt:5155.233\n",
      "Ep:147, loss:0.00000, loss_test:0.01672, lr:4.05e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.068, tt:5190.027\n",
      "Ep:148, loss:0.00000, loss_test:0.01680, lr:4.01e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.062, tt:5224.297\n",
      "Ep:149, loss:0.00000, loss_test:0.01679, lr:3.97e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.054, tt:5258.154\n",
      "Ep:150, loss:0.00000, loss_test:0.01695, lr:3.93e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.042, tt:5291.288\n",
      "Ep:151, loss:0.00000, loss_test:0.01682, lr:3.89e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.042, tt:5326.433\n",
      "Ep:152, loss:0.00000, loss_test:0.01714, lr:3.86e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.039, tt:5361.029\n",
      "Ep:153, loss:0.00000, loss_test:0.01693, lr:3.82e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.032, tt:5395.001\n",
      "Ep:154, loss:0.00000, loss_test:0.01709, lr:3.78e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.017, tt:5427.686\n",
      "Ep:155, loss:0.00000, loss_test:0.01716, lr:3.74e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.016, tt:5462.572\n",
      "Ep:156, loss:0.00000, loss_test:0.01710, lr:3.70e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.007, tt:5496.021\n",
      "Ep:157, loss:0.00000, loss_test:0.01719, lr:3.67e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.010, tt:5531.506\n",
      "Ep:158, loss:0.00000, loss_test:0.01723, lr:3.63e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.010, tt:5566.644\n",
      "Ep:159, loss:0.00000, loss_test:0.01729, lr:3.59e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.003, tt:5600.476\n",
      "Ep:160, loss:0.00000, loss_test:0.01725, lr:3.56e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.998, tt:5634.653\n",
      "Ep:161, loss:0.00000, loss_test:0.01738, lr:3.52e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.997, tt:5669.591\n",
      "Ep:162, loss:0.00000, loss_test:0.01735, lr:3.49e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.995, tt:5704.223\n",
      "Ep:163, loss:0.00000, loss_test:0.01739, lr:3.45e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.992, tt:5738.715\n",
      "Ep:164, loss:0.00000, loss_test:0.01750, lr:3.42e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.986, tt:5772.733\n",
      "Ep:165, loss:0.00000, loss_test:0.01744, lr:3.38e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.974, tt:5805.663\n",
      "Ep:166, loss:0.00000, loss_test:0.01760, lr:3.35e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.960, tt:5838.371\n",
      "Ep:167, loss:0.00000, loss_test:0.01751, lr:3.32e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.941, tt:5870.075\n",
      "Ep:168, loss:0.00000, loss_test:0.01765, lr:3.28e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.930, tt:5903.143\n",
      "Ep:169, loss:0.00000, loss_test:0.01764, lr:3.25e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.922, tt:5936.708\n",
      "Ep:170, loss:0.00000, loss_test:0.01764, lr:3.22e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.918, tt:5971.040\n",
      "Ep:171, loss:0.00000, loss_test:0.01769, lr:3.19e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.912, tt:6004.910\n",
      "Ep:172, loss:0.00000, loss_test:0.01771, lr:3.15e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.917, tt:6040.604\n",
      "Ep:173, loss:0.00000, loss_test:0.01779, lr:3.12e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.916, tt:6075.355\n",
      "Ep:174, loss:0.00000, loss_test:0.01780, lr:3.09e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.910, tt:6109.316\n",
      "Ep:175, loss:0.00000, loss_test:0.01782, lr:3.06e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.907, tt:6143.583\n",
      "Ep:176, loss:0.00000, loss_test:0.01787, lr:3.03e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.897, tt:6176.708\n",
      "Ep:177, loss:0.00000, loss_test:0.01788, lr:3.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.900, tt:6212.164\n",
      "Ep:178, loss:0.00000, loss_test:0.01791, lr:2.97e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.902, tt:6247.490\n",
      "Ep:179, loss:0.00000, loss_test:0.01794, lr:2.94e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.906, tt:6282.994\n",
      "Ep:180, loss:0.00000, loss_test:0.01796, lr:2.91e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.901, tt:6316.998\n",
      "Ep:181, loss:0.00000, loss_test:0.01802, lr:2.88e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.898, tt:6351.475\n",
      "Ep:182, loss:0.00000, loss_test:0.01801, lr:2.85e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.895, tt:6385.737\n",
      "Ep:183, loss:0.00000, loss_test:0.01805, lr:2.82e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.889, tt:6419.664\n",
      "Ep:184, loss:0.00000, loss_test:0.01806, lr:2.80e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.893, tt:6455.276\n",
      "Ep:185, loss:0.00000, loss_test:0.01809, lr:2.77e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.893, tt:6490.143\n",
      "Ep:186, loss:0.00000, loss_test:0.01811, lr:2.74e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.889, tt:6524.329\n",
      "Ep:187, loss:0.00000, loss_test:0.01811, lr:2.71e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.889, tt:6559.056\n",
      "Ep:188, loss:0.00000, loss_test:0.01819, lr:2.69e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.894, tt:6594.955\n",
      "Ep:189, loss:0.00000, loss_test:0.01818, lr:2.66e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.892, tt:6629.556\n",
      "Ep:190, loss:0.00000, loss_test:0.01820, lr:2.63e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.880, tt:6662.022\n",
      "Ep:191, loss:0.00000, loss_test:0.01825, lr:2.61e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.860, tt:6693.150\n",
      "Ep:192, loss:0.00000, loss_test:0.01826, lr:2.58e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.813, tt:6718.911\n",
      "Ep:193, loss:0.00000, loss_test:0.01825, lr:2.55e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.766, tt:6744.509\n",
      "Ep:194, loss:0.00000, loss_test:0.01830, lr:2.53e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.740, tt:6774.208\n",
      "Ep:195, loss:0.00000, loss_test:0.01838, lr:2.50e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.722, tt:6805.559\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02102, lr:6.00e-02, fs:0.59031 (r=0.677,p=0.523),  time:31.078, tt:31.078\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:31.150, tt:62.300\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02265, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.129, tt:93.386\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02307, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.939, tt:123.756\n",
      "Ep:4, loss:0.00005, loss_test:0.02252, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.923, tt:154.617\n",
      "Ep:5, loss:0.00004, loss_test:0.02146, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.979, tt:185.876\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02018, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:30.815, tt:215.702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00004, loss_test:0.01904, lr:6.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:30.893, tt:247.141\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01827, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:30.832, tt:277.487\n",
      "Ep:9, loss:0.00004, loss_test:0.01789, lr:6.00e-02, fs:0.65854 (r=0.818,p=0.551),  time:30.899, tt:308.992\n",
      "Ep:10, loss:0.00004, loss_test:0.01756, lr:6.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:30.719, tt:337.907\n",
      "Ep:11, loss:0.00004, loss_test:0.01706, lr:6.00e-02, fs:0.67521 (r=0.798,p=0.585),  time:30.799, tt:369.591\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:30.849, tt:401.036\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:30.871, tt:432.187\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:30.786, tt:461.797\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:30.801, tt:492.823\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:30.829, tt:524.088\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01532, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:30.888, tt:555.990\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:30.817, tt:585.519\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01488, lr:6.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:30.813, tt:616.261\n",
      "Ep:20, loss:0.00003, loss_test:0.01474, lr:6.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:30.833, tt:647.501\n",
      "Ep:21, loss:0.00003, loss_test:0.01457, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:30.794, tt:677.469\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01439, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:30.723, tt:706.631\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01422, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:30.700, tt:736.808\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01406, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:30.678, tt:766.957\n",
      "Ep:25, loss:0.00003, loss_test:0.01391, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:30.668, tt:797.380\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01377, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:30.624, tt:826.858\n",
      "Ep:27, loss:0.00003, loss_test:0.01364, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:30.587, tt:856.438\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01350, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:30.568, tt:886.474\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01337, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:30.574, tt:917.226\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:30.606, tt:948.786\n",
      "Ep:31, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:30.590, tt:978.890\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:30.586, tt:1009.333\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01291, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:30.654, tt:1042.230\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01282, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:30.705, tt:1074.687\n",
      "Ep:35, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:30.685, tt:1104.654\n",
      "Ep:36, loss:0.00002, loss_test:0.01266, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:30.673, tt:1134.905\n",
      "Ep:37, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:30.676, tt:1165.684\n",
      "Ep:38, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:30.666, tt:1195.979\n",
      "Ep:39, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:30.679, tt:1227.178\n",
      "Ep:40, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:30.674, tt:1257.624\n",
      "Ep:41, loss:0.00002, loss_test:0.01224, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:30.684, tt:1288.715\n",
      "Ep:42, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:30.671, tt:1318.835\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01210, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:30.702, tt:1350.872\n",
      "Ep:44, loss:0.00002, loss_test:0.01203, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:30.705, tt:1381.723\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01195, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:30.717, tt:1413.000\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01189, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:30.718, tt:1443.742\n",
      "Ep:47, loss:0.00002, loss_test:0.01184, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:30.748, tt:1475.918\n",
      "Ep:48, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.767, tt:1507.606\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.770, tt:1538.504\n",
      "Ep:50, loss:0.00002, loss_test:0.01163, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.769, tt:1569.235\n",
      "Ep:51, loss:0.00002, loss_test:0.01157, lr:6.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:30.773, tt:1600.207\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01149, lr:6.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:30.803, tt:1632.560\n",
      "Ep:53, loss:0.00002, loss_test:0.01143, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.806, tt:1663.526\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01138, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.808, tt:1694.444\n",
      "Ep:55, loss:0.00002, loss_test:0.01133, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:30.864, tt:1728.412\n",
      "Ep:56, loss:0.00002, loss_test:0.01129, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:30.831, tt:1757.338\n",
      "Ep:57, loss:0.00002, loss_test:0.01124, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:30.821, tt:1787.618\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01118, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.816, tt:1818.132\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01113, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.779, tt:1846.751\n",
      "Ep:60, loss:0.00002, loss_test:0.01110, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:30.780, tt:1877.574\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01105, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:30.749, tt:1906.417\n",
      "Ep:62, loss:0.00002, loss_test:0.01099, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:30.737, tt:1936.428\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01095, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:30.750, tt:1968.016\n",
      "Ep:64, loss:0.00001, loss_test:0.01092, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.731, tt:1997.526\n",
      "Ep:65, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.726, tt:2027.912\n",
      "Ep:66, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.713, tt:2057.744\n",
      "Ep:67, loss:0.00001, loss_test:0.01079, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.704, tt:2087.883\n",
      "Ep:68, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.707, tt:2118.771\n",
      "Ep:69, loss:0.00001, loss_test:0.01072, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.704, tt:2149.279\n",
      "Ep:70, loss:0.00001, loss_test:0.01068, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.703, tt:2179.877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.01063, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.702, tt:2210.557\n",
      "Ep:72, loss:0.00001, loss_test:0.01059, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.698, tt:2240.928\n",
      "Ep:73, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.709, tt:2272.445\n",
      "Ep:74, loss:0.00001, loss_test:0.01053, lr:5.94e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.702, tt:2302.673\n",
      "Ep:75, loss:0.00001, loss_test:0.01049, lr:5.88e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.699, tt:2333.133\n",
      "Ep:76, loss:0.00001, loss_test:0.01045, lr:5.82e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.722, tt:2365.608\n",
      "Ep:77, loss:0.00001, loss_test:0.01043, lr:5.76e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.712, tt:2395.526\n",
      "Ep:78, loss:0.00001, loss_test:0.01041, lr:5.71e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.718, tt:2426.697\n",
      "Ep:79, loss:0.00001, loss_test:0.01039, lr:5.65e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.716, tt:2457.252\n",
      "Ep:80, loss:0.00001, loss_test:0.01037, lr:5.59e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.712, tt:2487.663\n",
      "Ep:81, loss:0.00001, loss_test:0.01033, lr:5.54e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.724, tt:2519.395\n",
      "Ep:82, loss:0.00001, loss_test:0.01032, lr:5.48e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.728, tt:2550.394\n",
      "Ep:83, loss:0.00001, loss_test:0.01030, lr:5.43e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.725, tt:2580.881\n",
      "Ep:84, loss:0.00001, loss_test:0.01030, lr:5.37e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.719, tt:2611.139\n",
      "Ep:85, loss:0.00001, loss_test:0.01029, lr:5.32e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.726, tt:2642.454\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01027, lr:5.32e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.720, tt:2672.628\n",
      "Ep:87, loss:0.00001, loss_test:0.01025, lr:5.32e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.717, tt:2703.065\n",
      "Ep:88, loss:0.00001, loss_test:0.01023, lr:5.32e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.701, tt:2732.372\n",
      "Ep:89, loss:0.00001, loss_test:0.01020, lr:5.32e-02, fs:0.86000 (r=0.869,p=0.851),  time:30.690, tt:2762.135\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01020, lr:5.32e-02, fs:0.86432 (r=0.869,p=0.860),  time:30.686, tt:2792.395\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01018, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.692, tt:2823.626\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01017, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.684, tt:2853.582\n",
      "Ep:93, loss:0.00001, loss_test:0.01017, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.681, tt:2883.989\n",
      "Ep:94, loss:0.00001, loss_test:0.01017, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.693, tt:2915.864\n",
      "Ep:95, loss:0.00001, loss_test:0.01015, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.687, tt:2945.987\n",
      "Ep:96, loss:0.00001, loss_test:0.01012, lr:5.32e-02, fs:0.87310 (r=0.869,p=0.878),  time:30.682, tt:2976.119\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01011, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.683, tt:3006.904\n",
      "Ep:98, loss:0.00001, loss_test:0.01011, lr:5.32e-02, fs:0.87755 (r=0.869,p=0.887),  time:30.676, tt:3036.951\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01012, lr:5.32e-02, fs:0.87755 (r=0.869,p=0.887),  time:30.684, tt:3068.447\n",
      "Ep:100, loss:0.00001, loss_test:0.01010, lr:5.32e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.676, tt:3098.313\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01008, lr:5.32e-02, fs:0.88660 (r=0.869,p=0.905),  time:30.674, tt:3128.771\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.88660 (r=0.869,p=0.905),  time:30.667, tt:3158.674\n",
      "Ep:103, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.88660 (r=0.869,p=0.905),  time:30.657, tt:3188.323\n",
      "Ep:104, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.88660 (r=0.869,p=0.905),  time:30.670, tt:3220.382\n",
      "Ep:105, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.88660 (r=0.869,p=0.905),  time:30.660, tt:3249.913\n",
      "Ep:106, loss:0.00001, loss_test:0.01006, lr:5.32e-02, fs:0.88660 (r=0.869,p=0.905),  time:30.649, tt:3279.420\n",
      "Ep:107, loss:0.00001, loss_test:0.01005, lr:5.32e-02, fs:0.89119 (r=0.869,p=0.915),  time:30.642, tt:3309.384\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01002, lr:5.32e-02, fs:0.89119 (r=0.869,p=0.915),  time:30.646, tt:3340.423\n",
      "Ep:109, loss:0.00001, loss_test:0.01003, lr:5.32e-02, fs:0.89119 (r=0.869,p=0.915),  time:30.641, tt:3370.555\n",
      "Ep:110, loss:0.00001, loss_test:0.01002, lr:5.32e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.639, tt:3400.917\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01003, lr:5.32e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.625, tt:3429.948\n",
      "Ep:112, loss:0.00001, loss_test:0.01003, lr:5.32e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.624, tt:3460.467\n",
      "Ep:113, loss:0.00001, loss_test:0.01004, lr:5.32e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.616, tt:3490.245\n",
      "Ep:114, loss:0.00001, loss_test:0.01003, lr:5.32e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.609, tt:3520.012\n",
      "Ep:115, loss:0.00001, loss_test:0.01004, lr:5.32e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.602, tt:3549.844\n",
      "Ep:116, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.89005 (r=0.859,p=0.924),  time:30.584, tt:3578.298\n",
      "Ep:117, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.89005 (r=0.859,p=0.924),  time:30.579, tt:3608.313\n",
      "Ep:118, loss:0.00001, loss_test:0.01007, lr:5.32e-02, fs:0.89005 (r=0.859,p=0.924),  time:30.559, tt:3636.464\n",
      "Ep:119, loss:0.00001, loss_test:0.01005, lr:5.32e-02, fs:0.89005 (r=0.859,p=0.924),  time:30.548, tt:3665.771\n",
      "Ep:120, loss:0.00001, loss_test:0.01006, lr:5.32e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.539, tt:3695.218\n",
      "Ep:121, loss:0.00001, loss_test:0.01006, lr:5.32e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.525, tt:3724.084\n",
      "Ep:122, loss:0.00001, loss_test:0.01007, lr:5.27e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.521, tt:3754.099\n",
      "Ep:123, loss:0.00001, loss_test:0.01008, lr:5.21e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.516, tt:3783.986\n",
      "Ep:124, loss:0.00001, loss_test:0.01010, lr:5.16e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.503, tt:3812.904\n",
      "Ep:125, loss:0.00001, loss_test:0.01010, lr:5.11e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.496, tt:3842.523\n",
      "Ep:126, loss:0.00001, loss_test:0.01008, lr:5.06e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.504, tt:3873.985\n",
      "Ep:127, loss:0.00001, loss_test:0.01011, lr:5.01e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.493, tt:3903.148\n",
      "Ep:128, loss:0.00001, loss_test:0.01012, lr:4.96e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.490, tt:3933.152\n",
      "Ep:129, loss:0.00001, loss_test:0.01011, lr:4.91e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.485, tt:3963.008\n",
      "Ep:130, loss:0.00001, loss_test:0.01012, lr:4.86e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.470, tt:3991.615\n",
      "Ep:131, loss:0.00001, loss_test:0.01014, lr:4.81e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.466, tt:4021.482\n",
      "Ep:132, loss:0.00001, loss_test:0.01016, lr:4.76e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.459, tt:4051.083\n",
      "Ep:133, loss:0.00001, loss_test:0.01018, lr:4.71e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.445, tt:4079.660\n",
      "Ep:134, loss:0.00001, loss_test:0.01019, lr:4.67e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.435, tt:4108.752\n",
      "Ep:135, loss:0.00001, loss_test:0.01016, lr:4.62e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.437, tt:4139.435\n",
      "Ep:136, loss:0.00001, loss_test:0.01017, lr:4.57e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.425, tt:4168.197\n",
      "Ep:137, loss:0.00001, loss_test:0.01018, lr:4.53e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.429, tt:4199.140\n",
      "Ep:138, loss:0.00001, loss_test:0.01021, lr:4.48e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.418, tt:4228.083\n",
      "Ep:139, loss:0.00001, loss_test:0.01024, lr:4.44e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.405, tt:4256.691\n",
      "Ep:140, loss:0.00001, loss_test:0.01024, lr:4.39e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.391, tt:4285.078\n",
      "Ep:141, loss:0.00001, loss_test:0.01023, lr:4.35e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.386, tt:4314.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.01023, lr:4.31e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.374, tt:4343.545\n",
      "Ep:143, loss:0.00001, loss_test:0.01027, lr:4.26e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.368, tt:4373.060\n",
      "Ep:144, loss:0.00001, loss_test:0.01028, lr:4.22e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.371, tt:4403.855\n",
      "Ep:145, loss:0.00001, loss_test:0.01028, lr:4.18e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.369, tt:4433.905\n",
      "Ep:146, loss:0.00001, loss_test:0.01028, lr:4.14e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.376, tt:4465.308\n",
      "Ep:147, loss:0.00001, loss_test:0.01029, lr:4.10e-02, fs:0.89730 (r=0.838,p=0.965),  time:30.371, tt:4494.908\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00001, loss_test:0.01031, lr:4.10e-02, fs:0.89730 (r=0.838,p=0.965),  time:30.366, tt:4524.593\n",
      "Ep:149, loss:0.00001, loss_test:0.01031, lr:4.10e-02, fs:0.89730 (r=0.838,p=0.965),  time:30.365, tt:4554.676\n",
      "Ep:150, loss:0.00001, loss_test:0.01033, lr:4.10e-02, fs:0.90217 (r=0.838,p=0.976),  time:30.372, tt:4586.216\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00001, loss_test:0.01033, lr:4.10e-02, fs:0.90217 (r=0.838,p=0.976),  time:30.364, tt:4615.292\n",
      "Ep:152, loss:0.00001, loss_test:0.01034, lr:4.10e-02, fs:0.90217 (r=0.838,p=0.976),  time:30.362, tt:4645.363\n",
      "Ep:153, loss:0.00001, loss_test:0.01033, lr:4.10e-02, fs:0.89617 (r=0.828,p=0.976),  time:30.360, tt:4675.462\n",
      "Ep:154, loss:0.00001, loss_test:0.01035, lr:4.10e-02, fs:0.89617 (r=0.828,p=0.976),  time:30.360, tt:4705.785\n",
      "Ep:155, loss:0.00001, loss_test:0.01037, lr:4.10e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.353, tt:4735.064\n",
      "Ep:156, loss:0.00001, loss_test:0.01037, lr:4.10e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.349, tt:4764.814\n",
      "Ep:157, loss:0.00001, loss_test:0.01037, lr:4.10e-02, fs:0.89617 (r=0.828,p=0.976),  time:30.343, tt:4794.166\n",
      "Ep:158, loss:0.00001, loss_test:0.01040, lr:4.10e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.351, tt:4825.845\n",
      "Ep:159, loss:0.00001, loss_test:0.01041, lr:4.10e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.360, tt:4857.581\n",
      "Ep:160, loss:0.00001, loss_test:0.01041, lr:4.10e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.355, tt:4887.096\n",
      "Ep:161, loss:0.00001, loss_test:0.01041, lr:4.10e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.344, tt:4915.718\n",
      "Ep:162, loss:0.00001, loss_test:0.01041, lr:4.05e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.343, tt:4945.942\n",
      "Ep:163, loss:0.00001, loss_test:0.01043, lr:4.01e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.345, tt:4976.569\n",
      "Ep:164, loss:0.00001, loss_test:0.01048, lr:3.97e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.341, tt:5006.275\n",
      "Ep:165, loss:0.00001, loss_test:0.01048, lr:3.93e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.332, tt:5035.130\n",
      "Ep:166, loss:0.00001, loss_test:0.01048, lr:3.89e-02, fs:0.88398 (r=0.808,p=0.976),  time:30.326, tt:5064.437\n",
      "Ep:167, loss:0.00001, loss_test:0.01049, lr:3.86e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.320, tt:5093.768\n",
      "Ep:168, loss:0.00001, loss_test:0.01048, lr:3.82e-02, fs:0.89011 (r=0.818,p=0.976),  time:30.316, tt:5123.327\n",
      "Ep:169, loss:0.00001, loss_test:0.01050, lr:3.78e-02, fs:0.87778 (r=0.798,p=0.975),  time:30.304, tt:5151.618\n",
      "Ep:170, loss:0.00001, loss_test:0.01052, lr:3.74e-02, fs:0.87778 (r=0.798,p=0.975),  time:30.298, tt:5180.919\n",
      "Ep:171, loss:0.00001, loss_test:0.01054, lr:3.70e-02, fs:0.87778 (r=0.798,p=0.975),  time:30.293, tt:5210.426\n",
      "Ep:172, loss:0.00001, loss_test:0.01055, lr:3.67e-02, fs:0.87151 (r=0.788,p=0.975),  time:30.289, tt:5239.947\n",
      "Ep:173, loss:0.00001, loss_test:0.01055, lr:3.63e-02, fs:0.87151 (r=0.788,p=0.975),  time:30.284, tt:5269.342\n",
      "Ep:174, loss:0.00000, loss_test:0.01057, lr:3.59e-02, fs:0.87151 (r=0.788,p=0.975),  time:30.287, tt:5300.301\n",
      "Ep:175, loss:0.00000, loss_test:0.01058, lr:3.56e-02, fs:0.86517 (r=0.778,p=0.975),  time:30.281, tt:5329.385\n",
      "Ep:176, loss:0.00000, loss_test:0.01058, lr:3.52e-02, fs:0.86517 (r=0.778,p=0.975),  time:30.275, tt:5358.721\n",
      "Ep:177, loss:0.00000, loss_test:0.01058, lr:3.49e-02, fs:0.85876 (r=0.768,p=0.974),  time:30.270, tt:5388.095\n",
      "Ep:178, loss:0.00000, loss_test:0.01060, lr:3.45e-02, fs:0.85876 (r=0.768,p=0.974),  time:30.275, tt:5419.274\n",
      "Ep:179, loss:0.00000, loss_test:0.01062, lr:3.42e-02, fs:0.86364 (r=0.768,p=0.987),  time:30.266, tt:5447.888\n",
      "Ep:180, loss:0.00000, loss_test:0.01062, lr:3.38e-02, fs:0.85876 (r=0.768,p=0.974),  time:30.264, tt:5477.803\n",
      "Ep:181, loss:0.00000, loss_test:0.01062, lr:3.35e-02, fs:0.86364 (r=0.768,p=0.987),  time:30.259, tt:5507.067\n",
      "Ep:182, loss:0.00000, loss_test:0.01064, lr:3.32e-02, fs:0.86364 (r=0.768,p=0.987),  time:30.258, tt:5537.242\n",
      "Ep:183, loss:0.00000, loss_test:0.01066, lr:3.28e-02, fs:0.86364 (r=0.768,p=0.987),  time:30.251, tt:5566.142\n",
      "Ep:184, loss:0.00000, loss_test:0.01066, lr:3.25e-02, fs:0.86364 (r=0.768,p=0.987),  time:30.248, tt:5595.841\n",
      "Ep:185, loss:0.00000, loss_test:0.01067, lr:3.22e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.244, tt:5625.341\n",
      "Ep:186, loss:0.00000, loss_test:0.01066, lr:3.19e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.243, tt:5655.484\n",
      "Ep:187, loss:0.00000, loss_test:0.01068, lr:3.15e-02, fs:0.86364 (r=0.768,p=0.987),  time:30.245, tt:5686.128\n",
      "Ep:188, loss:0.00000, loss_test:0.01070, lr:3.12e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.248, tt:5716.807\n",
      "Ep:189, loss:0.00000, loss_test:0.01070, lr:3.09e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.229, tt:5743.418\n",
      "Ep:190, loss:0.00000, loss_test:0.01071, lr:3.06e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.218, tt:5771.718\n",
      "Ep:191, loss:0.00000, loss_test:0.01072, lr:3.03e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.215, tt:5801.290\n",
      "Ep:192, loss:0.00000, loss_test:0.01074, lr:3.00e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.158, tt:5820.574\n",
      "Ep:193, loss:0.00000, loss_test:0.01075, lr:2.97e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.133, tt:5845.841\n",
      "Ep:194, loss:0.00000, loss_test:0.01075, lr:2.94e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.115, tt:5872.416\n",
      "Ep:195, loss:0.00000, loss_test:0.01076, lr:2.91e-02, fs:0.85714 (r=0.758,p=0.987),  time:30.106, tt:5900.723\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01947, lr:6.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:37.831, tt:37.831\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.666, tt:75.333\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02234, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.646, tt:112.938\n",
      "Ep:3, loss:0.00004, loss_test:0.02135, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.353, tt:149.412\n",
      "Ep:4, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:37.229, tt:186.146\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01806, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:37.278, tt:223.666\n",
      "Ep:6, loss:0.00004, loss_test:0.01744, lr:6.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:37.236, tt:260.650\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01706, lr:6.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:37.096, tt:296.771\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01622, lr:6.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:37.216, tt:334.948\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:37.240, tt:372.401\n",
      "Ep:10, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:37.396, tt:411.352\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:37.682, tt:452.182\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01506, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:37.678, tt:489.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00003, loss_test:0.01471, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:37.785, tt:528.990\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01446, lr:6.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:37.883, tt:568.250\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01430, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:37.995, tt:607.923\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:38.005, tt:646.087\n",
      "Ep:17, loss:0.00003, loss_test:0.01393, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:38.093, tt:685.670\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01368, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:38.013, tt:722.240\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01344, lr:6.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:38.142, tt:762.844\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01324, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:38.136, tt:800.849\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:38.274, tt:842.027\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:38.299, tt:880.867\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:38.264, tt:918.340\n",
      "Ep:24, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:38.267, tt:956.668\n",
      "Ep:25, loss:0.00002, loss_test:0.01236, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:38.279, tt:995.247\n",
      "Ep:26, loss:0.00002, loss_test:0.01221, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:38.256, tt:1032.918\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01206, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:38.298, tt:1072.353\n",
      "Ep:28, loss:0.00002, loss_test:0.01192, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:38.227, tt:1108.591\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01177, lr:6.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:38.227, tt:1146.823\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01163, lr:6.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:38.221, tt:1184.843\n",
      "Ep:31, loss:0.00002, loss_test:0.01149, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:38.176, tt:1221.628\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:38.130, tt:1258.281\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01125, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:38.138, tt:1296.677\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01114, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:38.094, tt:1333.286\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01104, lr:6.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:38.101, tt:1371.631\n",
      "Ep:36, loss:0.00002, loss_test:0.01095, lr:6.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:38.090, tt:1409.338\n",
      "Ep:37, loss:0.00002, loss_test:0.01087, lr:6.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:38.106, tt:1448.025\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01078, lr:6.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:38.071, tt:1484.762\n",
      "Ep:39, loss:0.00002, loss_test:0.01069, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:38.032, tt:1521.283\n",
      "Ep:40, loss:0.00002, loss_test:0.01059, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:38.084, tt:1561.424\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01050, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:38.094, tt:1599.935\n",
      "Ep:42, loss:0.00002, loss_test:0.01043, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:38.046, tt:1635.970\n",
      "Ep:43, loss:0.00002, loss_test:0.01035, lr:6.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:38.047, tt:1674.082\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01029, lr:6.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:38.034, tt:1711.509\n",
      "Ep:45, loss:0.00001, loss_test:0.01023, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:37.990, tt:1747.533\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01015, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:37.917, tt:1782.083\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01008, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:37.938, tt:1821.016\n",
      "Ep:48, loss:0.00001, loss_test:0.00999, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.954, tt:1859.740\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.00996, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.971, tt:1898.535\n",
      "Ep:50, loss:0.00001, loss_test:0.00990, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.988, tt:1937.382\n",
      "Ep:51, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.955, tt:1973.645\n",
      "Ep:52, loss:0.00001, loss_test:0.00976, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:37.945, tt:2011.073\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.00971, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.047, tt:2054.528\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.00965, lr:6.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:38.066, tt:2093.620\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:38.059, tt:2131.324\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.00956, lr:6.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:38.065, tt:2169.687\n",
      "Ep:57, loss:0.00001, loss_test:0.00951, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.078, tt:2208.511\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.090, tt:2247.303\n",
      "Ep:59, loss:0.00001, loss_test:0.00942, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.100, tt:2286.012\n",
      "Ep:60, loss:0.00001, loss_test:0.00938, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.115, tt:2325.027\n",
      "Ep:61, loss:0.00001, loss_test:0.00936, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.120, tt:2363.409\n",
      "Ep:62, loss:0.00001, loss_test:0.00933, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.124, tt:2401.817\n",
      "Ep:63, loss:0.00001, loss_test:0.00930, lr:6.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.114, tt:2439.317\n",
      "Ep:64, loss:0.00001, loss_test:0.00926, lr:6.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:38.125, tt:2478.136\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.00923, lr:6.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:38.124, tt:2516.177\n",
      "Ep:66, loss:0.00001, loss_test:0.00919, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:38.134, tt:2554.948\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.00916, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:38.118, tt:2592.035\n",
      "Ep:68, loss:0.00001, loss_test:0.00912, lr:6.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:38.113, tt:2629.771\n",
      "Ep:69, loss:0.00001, loss_test:0.00912, lr:6.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:38.095, tt:2666.666\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.00907, lr:6.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:38.150, tt:2708.670\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.00906, lr:6.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:38.193, tt:2749.892\n",
      "Ep:72, loss:0.00001, loss_test:0.00906, lr:6.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:38.189, tt:2787.811\n",
      "Ep:73, loss:0.00001, loss_test:0.00906, lr:6.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:38.179, tt:2825.249\n",
      "Ep:74, loss:0.00001, loss_test:0.00904, lr:6.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:38.181, tt:2863.557\n",
      "Ep:75, loss:0.00001, loss_test:0.00901, lr:6.00e-02, fs:0.95567 (r=0.980,p=0.933),  time:38.183, tt:2901.943\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00001, loss_test:0.00899, lr:6.00e-02, fs:0.95098 (r=0.980,p=0.924),  time:38.210, tt:2942.146\n",
      "Ep:77, loss:0.00001, loss_test:0.00899, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.226, tt:2981.629\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.00899, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.235, tt:3020.602\n",
      "Ep:79, loss:0.00001, loss_test:0.00898, lr:6.00e-02, fs:0.95567 (r=0.980,p=0.933),  time:38.234, tt:3058.753\n",
      "Ep:80, loss:0.00001, loss_test:0.00895, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.227, tt:3096.365\n",
      "Ep:81, loss:0.00001, loss_test:0.00896, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.205, tt:3132.793\n",
      "Ep:82, loss:0.00001, loss_test:0.00897, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.200, tt:3170.640\n",
      "Ep:83, loss:0.00001, loss_test:0.00894, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.200, tt:3208.777\n",
      "Ep:84, loss:0.00001, loss_test:0.00896, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.201, tt:3247.064\n",
      "Ep:85, loss:0.00001, loss_test:0.00897, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.203, tt:3285.484\n",
      "Ep:86, loss:0.00001, loss_test:0.00896, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.235, tt:3326.455\n",
      "Ep:87, loss:0.00001, loss_test:0.00897, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.245, tt:3365.559\n",
      "Ep:88, loss:0.00001, loss_test:0.00893, lr:6.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.251, tt:3404.352\n",
      "Ep:89, loss:0.00001, loss_test:0.00895, lr:5.94e-02, fs:0.96040 (r=0.980,p=0.942),  time:38.239, tt:3441.489\n",
      "Ep:90, loss:0.00001, loss_test:0.00895, lr:5.88e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.234, tt:3479.290\n",
      "Ep:91, loss:0.00001, loss_test:0.00897, lr:5.82e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.242, tt:3518.297\n",
      "Ep:92, loss:0.00001, loss_test:0.00900, lr:5.76e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.266, tt:3558.771\n",
      "Ep:93, loss:0.00001, loss_test:0.00898, lr:5.71e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.270, tt:3597.374\n",
      "Ep:94, loss:0.00001, loss_test:0.00899, lr:5.65e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.271, tt:3635.717\n",
      "Ep:95, loss:0.00001, loss_test:0.00901, lr:5.59e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.267, tt:3673.659\n",
      "Ep:96, loss:0.00001, loss_test:0.00900, lr:5.54e-02, fs:0.95000 (r=0.960,p=0.941),  time:38.268, tt:3712.003\n",
      "Ep:97, loss:0.00001, loss_test:0.00900, lr:5.48e-02, fs:0.95522 (r=0.970,p=0.941),  time:38.285, tt:3751.906\n",
      "Ep:98, loss:0.00001, loss_test:0.00902, lr:5.43e-02, fs:0.95000 (r=0.960,p=0.941),  time:38.285, tt:3790.224\n",
      "Ep:99, loss:0.00001, loss_test:0.00903, lr:5.37e-02, fs:0.95000 (r=0.960,p=0.941),  time:38.294, tt:3829.403\n",
      "Ep:100, loss:0.00001, loss_test:0.00904, lr:5.32e-02, fs:0.94949 (r=0.949,p=0.949),  time:38.319, tt:3870.203\n",
      "Ep:101, loss:0.00000, loss_test:0.00907, lr:5.27e-02, fs:0.95431 (r=0.949,p=0.959),  time:38.312, tt:3907.833\n",
      "Ep:102, loss:0.00000, loss_test:0.00906, lr:5.21e-02, fs:0.94898 (r=0.939,p=0.959),  time:38.326, tt:3947.576\n",
      "Ep:103, loss:0.00000, loss_test:0.00906, lr:5.16e-02, fs:0.94898 (r=0.939,p=0.959),  time:38.305, tt:3983.688\n",
      "Ep:104, loss:0.00000, loss_test:0.00909, lr:5.11e-02, fs:0.94898 (r=0.939,p=0.959),  time:38.312, tt:4022.780\n",
      "Ep:105, loss:0.00000, loss_test:0.00911, lr:5.06e-02, fs:0.94359 (r=0.929,p=0.958),  time:38.308, tt:4060.700\n",
      "Ep:106, loss:0.00000, loss_test:0.00914, lr:5.01e-02, fs:0.94359 (r=0.929,p=0.958),  time:38.301, tt:4098.194\n",
      "Ep:107, loss:0.00000, loss_test:0.00914, lr:4.96e-02, fs:0.94359 (r=0.929,p=0.958),  time:38.307, tt:4137.111\n",
      "Ep:108, loss:0.00000, loss_test:0.00914, lr:4.91e-02, fs:0.94359 (r=0.929,p=0.958),  time:38.311, tt:4175.929\n",
      "Ep:109, loss:0.00000, loss_test:0.00916, lr:4.86e-02, fs:0.93814 (r=0.919,p=0.958),  time:38.319, tt:4215.079\n",
      "Ep:110, loss:0.00000, loss_test:0.00918, lr:4.81e-02, fs:0.93814 (r=0.919,p=0.958),  time:38.313, tt:4252.754\n",
      "Ep:111, loss:0.00000, loss_test:0.00917, lr:4.76e-02, fs:0.93814 (r=0.919,p=0.958),  time:38.307, tt:4290.434\n",
      "Ep:112, loss:0.00000, loss_test:0.00918, lr:4.71e-02, fs:0.93814 (r=0.919,p=0.958),  time:38.293, tt:4327.125\n",
      "Ep:113, loss:0.00000, loss_test:0.00920, lr:4.67e-02, fs:0.93814 (r=0.919,p=0.958),  time:38.300, tt:4366.184\n",
      "Ep:114, loss:0.00000, loss_test:0.00919, lr:4.62e-02, fs:0.93814 (r=0.919,p=0.958),  time:38.294, tt:4403.867\n",
      "Ep:115, loss:0.00000, loss_test:0.00923, lr:4.57e-02, fs:0.93264 (r=0.909,p=0.957),  time:38.282, tt:4440.751\n",
      "Ep:116, loss:0.00000, loss_test:0.00926, lr:4.53e-02, fs:0.92147 (r=0.889,p=0.957),  time:38.282, tt:4478.989\n",
      "Ep:117, loss:0.00000, loss_test:0.00926, lr:4.48e-02, fs:0.92147 (r=0.889,p=0.957),  time:38.277, tt:4516.686\n",
      "Ep:118, loss:0.00000, loss_test:0.00927, lr:4.44e-02, fs:0.91579 (r=0.879,p=0.956),  time:38.262, tt:4553.222\n",
      "Ep:119, loss:0.00000, loss_test:0.00929, lr:4.39e-02, fs:0.91579 (r=0.879,p=0.956),  time:38.252, tt:4590.242\n",
      "Ep:120, loss:0.00000, loss_test:0.00931, lr:4.35e-02, fs:0.90426 (r=0.859,p=0.955),  time:38.262, tt:4629.670\n",
      "Ep:121, loss:0.00000, loss_test:0.00931, lr:4.31e-02, fs:0.91579 (r=0.879,p=0.956),  time:38.257, tt:4667.394\n",
      "Ep:122, loss:0.00000, loss_test:0.00934, lr:4.26e-02, fs:0.91005 (r=0.869,p=0.956),  time:38.258, tt:4705.677\n",
      "Ep:123, loss:0.00000, loss_test:0.00934, lr:4.22e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.237, tt:4741.392\n",
      "Ep:124, loss:0.00000, loss_test:0.00935, lr:4.18e-02, fs:0.89247 (r=0.838,p=0.954),  time:38.244, tt:4780.518\n",
      "Ep:125, loss:0.00000, loss_test:0.00938, lr:4.14e-02, fs:0.88043 (r=0.818,p=0.953),  time:38.245, tt:4818.870\n",
      "Ep:126, loss:0.00000, loss_test:0.00940, lr:4.10e-02, fs:0.88043 (r=0.818,p=0.953),  time:38.246, tt:4857.249\n",
      "Ep:127, loss:0.00000, loss_test:0.00940, lr:4.05e-02, fs:0.88043 (r=0.818,p=0.953),  time:38.251, tt:4896.164\n",
      "Ep:128, loss:0.00000, loss_test:0.00941, lr:4.01e-02, fs:0.88043 (r=0.818,p=0.953),  time:38.259, tt:4935.401\n",
      "Ep:129, loss:0.00000, loss_test:0.00943, lr:3.97e-02, fs:0.88043 (r=0.818,p=0.953),  time:38.273, tt:4975.553\n",
      "Ep:130, loss:0.00000, loss_test:0.00945, lr:3.93e-02, fs:0.87432 (r=0.808,p=0.952),  time:38.276, tt:5014.108\n",
      "Ep:131, loss:0.00000, loss_test:0.00945, lr:3.89e-02, fs:0.86813 (r=0.798,p=0.952),  time:38.267, tt:5051.270\n",
      "Ep:132, loss:0.00000, loss_test:0.00944, lr:3.86e-02, fs:0.88043 (r=0.818,p=0.953),  time:38.262, tt:5088.904\n",
      "Ep:133, loss:0.00000, loss_test:0.00946, lr:3.82e-02, fs:0.88398 (r=0.808,p=0.976),  time:38.276, tt:5129.027\n",
      "Ep:134, loss:0.00000, loss_test:0.00948, lr:3.78e-02, fs:0.87778 (r=0.798,p=0.975),  time:38.264, tt:5165.694\n",
      "Ep:135, loss:0.00000, loss_test:0.00947, lr:3.74e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.270, tt:5204.665\n",
      "Ep:136, loss:0.00000, loss_test:0.00947, lr:3.70e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.270, tt:5242.932\n",
      "Ep:137, loss:0.00000, loss_test:0.00951, lr:3.67e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.266, tt:5280.703\n",
      "Ep:138, loss:0.00000, loss_test:0.00953, lr:3.63e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.267, tt:5319.171\n",
      "Ep:139, loss:0.00000, loss_test:0.00951, lr:3.59e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.276, tt:5358.707\n",
      "Ep:140, loss:0.00000, loss_test:0.00952, lr:3.56e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.281, tt:5397.566\n",
      "Ep:141, loss:0.00000, loss_test:0.00955, lr:3.52e-02, fs:0.88268 (r=0.798,p=0.988),  time:38.289, tt:5437.033\n",
      "Ep:142, loss:0.00000, loss_test:0.00957, lr:3.49e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.283, tt:5474.475\n",
      "Ep:143, loss:0.00000, loss_test:0.00958, lr:3.45e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.261, tt:5509.571\n",
      "Ep:144, loss:0.00000, loss_test:0.00960, lr:3.42e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.285, tt:5551.375\n",
      "Ep:145, loss:0.00000, loss_test:0.00960, lr:3.38e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.286, tt:5589.690\n",
      "Ep:146, loss:0.00000, loss_test:0.00960, lr:3.35e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.273, tt:5626.145\n",
      "Ep:147, loss:0.00000, loss_test:0.00962, lr:3.32e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.258, tt:5662.212\n",
      "Ep:148, loss:0.00000, loss_test:0.00963, lr:3.28e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.263, tt:5701.152\n",
      "Ep:149, loss:0.00000, loss_test:0.00966, lr:3.25e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.257, tt:5738.570\n",
      "Ep:150, loss:0.00000, loss_test:0.00967, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.244, tt:5774.849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00000, loss_test:0.00969, lr:3.19e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.238, tt:5812.209\n",
      "Ep:152, loss:0.00000, loss_test:0.00970, lr:3.15e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.230, tt:5849.262\n",
      "Ep:153, loss:0.00000, loss_test:0.00971, lr:3.12e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.245, tt:5889.732\n",
      "Ep:154, loss:0.00000, loss_test:0.00972, lr:3.09e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.236, tt:5926.560\n",
      "Ep:155, loss:0.00000, loss_test:0.00976, lr:3.06e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.238, tt:5965.187\n",
      "Ep:156, loss:0.00000, loss_test:0.00976, lr:3.03e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.232, tt:6002.447\n",
      "Ep:157, loss:0.00000, loss_test:0.00976, lr:3.00e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.233, tt:6040.815\n",
      "Ep:158, loss:0.00000, loss_test:0.00978, lr:2.97e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.250, tt:6081.692\n",
      "Ep:159, loss:0.00000, loss_test:0.00980, lr:2.94e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.249, tt:6119.896\n",
      "Ep:160, loss:0.00000, loss_test:0.00980, lr:2.91e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.249, tt:6158.114\n",
      "Ep:161, loss:0.00000, loss_test:0.00983, lr:2.88e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.241, tt:6195.041\n",
      "Ep:162, loss:0.00000, loss_test:0.00984, lr:2.85e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.241, tt:6233.255\n",
      "Ep:163, loss:0.00000, loss_test:0.00985, lr:2.82e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.238, tt:6271.058\n",
      "Ep:164, loss:0.00000, loss_test:0.00986, lr:2.80e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.231, tt:6308.069\n",
      "Ep:165, loss:0.00000, loss_test:0.00987, lr:2.77e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.215, tt:6343.647\n",
      "Ep:166, loss:0.00000, loss_test:0.00989, lr:2.74e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.216, tt:6382.026\n",
      "Ep:167, loss:0.00000, loss_test:0.00992, lr:2.71e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.202, tt:6418.013\n",
      "Ep:168, loss:0.00000, loss_test:0.00991, lr:2.69e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.209, tt:6457.375\n",
      "Ep:169, loss:0.00000, loss_test:0.00992, lr:2.66e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.199, tt:6493.792\n",
      "Ep:170, loss:0.00000, loss_test:0.00993, lr:2.63e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.197, tt:6531.742\n",
      "Ep:171, loss:0.00000, loss_test:0.00995, lr:2.61e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.195, tt:6569.605\n",
      "Ep:172, loss:0.00000, loss_test:0.00996, lr:2.58e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.191, tt:6607.052\n",
      "Ep:173, loss:0.00000, loss_test:0.00997, lr:2.55e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.191, tt:6645.231\n",
      "Ep:174, loss:0.00000, loss_test:0.00998, lr:2.53e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.190, tt:6683.164\n",
      "Ep:175, loss:0.00000, loss_test:0.00999, lr:2.50e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.189, tt:6721.310\n",
      "Ep:176, loss:0.00000, loss_test:0.01002, lr:2.48e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.197, tt:6760.953\n",
      "Ep:177, loss:0.00000, loss_test:0.01002, lr:2.45e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.202, tt:6800.044\n",
      "Ep:178, loss:0.00000, loss_test:0.01002, lr:2.43e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.209, tt:6839.340\n",
      "Ep:179, loss:0.00000, loss_test:0.01005, lr:2.40e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.221, tt:6879.795\n",
      "Ep:180, loss:0.00000, loss_test:0.01006, lr:2.38e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.225, tt:6918.717\n",
      "Ep:181, loss:0.00000, loss_test:0.01007, lr:2.36e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.229, tt:6957.628\n",
      "Ep:182, loss:0.00000, loss_test:0.01008, lr:2.33e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.233, tt:6996.605\n",
      "Ep:183, loss:0.00000, loss_test:0.01009, lr:2.31e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.232, tt:7034.748\n",
      "Ep:184, loss:0.00000, loss_test:0.01010, lr:2.29e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.234, tt:7073.262\n",
      "Ep:185, loss:0.00000, loss_test:0.01012, lr:2.26e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.241, tt:7112.865\n",
      "Ep:186, loss:0.00000, loss_test:0.01012, lr:2.24e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.239, tt:7150.716\n",
      "Ep:187, loss:0.00000, loss_test:0.01013, lr:2.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.254, tt:7191.678\n",
      "Ep:188, loss:0.00000, loss_test:0.01015, lr:2.20e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.253, tt:7229.757\n",
      "Ep:189, loss:0.00000, loss_test:0.01014, lr:2.17e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.258, tt:7269.104\n",
      "Ep:190, loss:0.00000, loss_test:0.01014, lr:2.15e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.260, tt:7307.614\n",
      "Ep:191, loss:0.00000, loss_test:0.01017, lr:2.13e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.245, tt:7343.048\n",
      "Ep:192, loss:0.00000, loss_test:0.01018, lr:2.11e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.247, tt:7381.731\n",
      "Ep:193, loss:0.00000, loss_test:0.01019, lr:2.09e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.167, tt:7404.373\n",
      "Ep:194, loss:0.00000, loss_test:0.01020, lr:2.07e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.129, tt:7435.137\n",
      "Ep:195, loss:0.00000, loss_test:0.01021, lr:2.05e-02, fs:0.87640 (r=0.788,p=0.987),  time:38.139, tt:7475.236\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02181, lr:6.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:36.835, tt:36.835\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02263, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:34.624, tt:69.249\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02425, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.582, tt:103.747\n",
      "Ep:3, loss:0.00005, loss_test:0.02418, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:34.537, tt:138.147\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02325, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:34.665, tt:173.327\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02167, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:34.789, tt:208.732\n",
      "Ep:6, loss:0.00005, loss_test:0.01988, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:34.704, tt:242.927\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01851, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:34.758, tt:278.060\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01775, lr:6.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:34.664, tt:311.972\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01713, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:34.648, tt:346.477\n",
      "Ep:10, loss:0.00004, loss_test:0.01661, lr:6.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:34.749, tt:382.237\n",
      "Ep:11, loss:0.00004, loss_test:0.01645, lr:6.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:34.648, tt:415.773\n",
      "Ep:12, loss:0.00004, loss_test:0.01646, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:34.682, tt:450.860\n",
      "Ep:13, loss:0.00004, loss_test:0.01620, lr:6.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:34.582, tt:484.152\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01584, lr:6.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:34.476, tt:517.134\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:34.433, tt:550.921\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:34.466, tt:585.923\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01520, lr:6.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:34.476, tt:620.568\n",
      "Ep:18, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:34.487, tt:655.253\n",
      "Ep:19, loss:0.00003, loss_test:0.01484, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:34.513, tt:690.251\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01458, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.542, tt:725.391\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.539, tt:759.856\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01405, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:34.515, tt:793.837\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01385, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:34.535, tt:828.838\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01362, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:34.607, tt:865.165\n",
      "Ep:25, loss:0.00003, loss_test:0.01335, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.570, tt:898.808\n",
      "Ep:26, loss:0.00003, loss_test:0.01311, lr:6.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:34.593, tt:933.999\n",
      "Ep:27, loss:0.00003, loss_test:0.01291, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:34.569, tt:967.939\n",
      "Ep:28, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.543, tt:1001.741\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01247, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.554, tt:1036.618\n",
      "Ep:30, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:34.579, tt:1071.955\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01216, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:34.615, tt:1107.671\n",
      "Ep:32, loss:0.00002, loss_test:0.01198, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:34.606, tt:1141.983\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01181, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.627, tt:1177.332\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01166, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:34.627, tt:1211.955\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01138, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:34.674, tt:1248.271\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01124, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:34.696, tt:1283.745\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01113, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:34.712, tt:1319.052\n",
      "Ep:38, loss:0.00002, loss_test:0.01089, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:34.744, tt:1354.998\n",
      "Ep:39, loss:0.00002, loss_test:0.01080, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:34.797, tt:1391.878\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01068, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:34.807, tt:1427.082\n",
      "Ep:41, loss:0.00002, loss_test:0.01057, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:34.810, tt:1462.025\n",
      "Ep:42, loss:0.00002, loss_test:0.01048, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:34.804, tt:1496.567\n",
      "Ep:43, loss:0.00002, loss_test:0.01037, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:34.907, tt:1535.927\n",
      "Ep:44, loss:0.00002, loss_test:0.01026, lr:6.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:34.935, tt:1572.090\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01019, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.941, tt:1607.292\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01008, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.953, tt:1642.794\n",
      "Ep:47, loss:0.00002, loss_test:0.01002, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.972, tt:1678.634\n",
      "Ep:48, loss:0.00001, loss_test:0.00996, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.999, tt:1714.942\n",
      "Ep:49, loss:0.00001, loss_test:0.00986, lr:6.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:35.015, tt:1750.752\n",
      "Ep:50, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:35.046, tt:1787.367\n",
      "Ep:51, loss:0.00001, loss_test:0.00977, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:35.066, tt:1823.423\n",
      "Ep:52, loss:0.00001, loss_test:0.00974, lr:6.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:35.059, tt:1858.142\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.00969, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:35.078, tt:1894.185\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.00958, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:35.083, tt:1929.578\n",
      "Ep:55, loss:0.00001, loss_test:0.00956, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:35.093, tt:1965.181\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.00953, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:35.105, tt:2001.010\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.00950, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:35.140, tt:2038.138\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.00951, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:35.149, tt:2073.767\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.00941, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:35.136, tt:2108.174\n",
      "Ep:60, loss:0.00001, loss_test:0.00944, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:35.158, tt:2144.642\n",
      "Ep:61, loss:0.00001, loss_test:0.00937, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.170, tt:2180.538\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.00941, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.171, tt:2215.777\n",
      "Ep:63, loss:0.00001, loss_test:0.00940, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.177, tt:2251.345\n",
      "Ep:64, loss:0.00001, loss_test:0.00935, lr:6.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.188, tt:2287.236\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.00937, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:35.194, tt:2322.812\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.00932, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:35.204, tt:2358.668\n",
      "Ep:67, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:35.209, tt:2394.211\n",
      "Ep:68, loss:0.00001, loss_test:0.00930, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:35.225, tt:2430.511\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:35.241, tt:2466.838\n",
      "Ep:70, loss:0.00001, loss_test:0.00925, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:35.225, tt:2500.953\n",
      "Ep:71, loss:0.00001, loss_test:0.00930, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:35.242, tt:2537.408\n",
      "Ep:72, loss:0.00001, loss_test:0.00928, lr:6.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:35.245, tt:2572.859\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.00935, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:35.221, tt:2606.375\n",
      "Ep:74, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.199, tt:2639.939\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.00929, lr:6.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:35.168, tt:2672.735\n",
      "Ep:76, loss:0.00001, loss_test:0.00933, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.144, tt:2706.074\n",
      "Ep:77, loss:0.00001, loss_test:0.00934, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.133, tt:2740.405\n",
      "Ep:78, loss:0.00001, loss_test:0.00937, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.125, tt:2774.842\n",
      "Ep:79, loss:0.00001, loss_test:0.00935, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.105, tt:2808.404\n",
      "Ep:80, loss:0.00001, loss_test:0.00938, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.096, tt:2842.771\n",
      "Ep:81, loss:0.00001, loss_test:0.00938, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.071, tt:2875.843\n",
      "Ep:82, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:35.061, tt:2910.037\n",
      "Ep:83, loss:0.00001, loss_test:0.00942, lr:6.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:35.045, tt:2943.792\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.00938, lr:6.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:35.013, tt:2976.123\n",
      "Ep:85, loss:0.00001, loss_test:0.00945, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:35.005, tt:3010.423\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00001, loss_test:0.00945, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.992, tt:3044.302\n",
      "Ep:87, loss:0.00001, loss_test:0.00950, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.975, tt:3077.829\n",
      "Ep:88, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.950, tt:3110.594\n",
      "Ep:89, loss:0.00001, loss_test:0.00954, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.935, tt:3144.188\n",
      "Ep:90, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.925, tt:3178.203\n",
      "Ep:91, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.933, tt:3213.834\n",
      "Ep:92, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:34.926, tt:3248.136\n",
      "Ep:93, loss:0.00001, loss_test:0.00966, lr:6.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:34.926, tt:3283.053\n",
      "Ep:94, loss:0.00000, loss_test:0.00958, lr:6.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:34.911, tt:3316.581\n",
      "Ep:95, loss:0.00000, loss_test:0.00965, lr:6.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.890, tt:3349.395\n",
      "Ep:96, loss:0.00000, loss_test:0.00963, lr:6.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:34.874, tt:3382.783\n",
      "Ep:97, loss:0.00000, loss_test:0.00965, lr:5.94e-02, fs:0.91089 (r=0.929,p=0.893),  time:34.849, tt:3415.174\n",
      "Ep:98, loss:0.00000, loss_test:0.00977, lr:5.88e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.825, tt:3447.689\n",
      "Ep:99, loss:0.00000, loss_test:0.00965, lr:5.82e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.806, tt:3480.624\n",
      "Ep:100, loss:0.00000, loss_test:0.00976, lr:5.76e-02, fs:0.90547 (r=0.919,p=0.892),  time:34.795, tt:3514.328\n",
      "Ep:101, loss:0.00000, loss_test:0.00982, lr:5.71e-02, fs:0.91089 (r=0.929,p=0.893),  time:34.783, tt:3547.837\n",
      "Ep:102, loss:0.00000, loss_test:0.00979, lr:5.65e-02, fs:0.89447 (r=0.899,p=0.890),  time:34.784, tt:3582.709\n",
      "Ep:103, loss:0.00000, loss_test:0.00981, lr:5.59e-02, fs:0.89447 (r=0.899,p=0.890),  time:34.782, tt:3617.376\n",
      "Ep:104, loss:0.00000, loss_test:0.00987, lr:5.54e-02, fs:0.90547 (r=0.919,p=0.892),  time:34.788, tt:3652.727\n",
      "Ep:105, loss:0.00000, loss_test:0.00983, lr:5.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.776, tt:3686.222\n",
      "Ep:106, loss:0.00000, loss_test:0.00995, lr:5.43e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.768, tt:3720.190\n",
      "Ep:107, loss:0.00000, loss_test:0.00989, lr:5.37e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.774, tt:3755.546\n",
      "Ep:108, loss:0.00000, loss_test:0.00997, lr:5.32e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.754, tt:3788.212\n",
      "Ep:109, loss:0.00000, loss_test:0.00996, lr:5.27e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.756, tt:3823.170\n",
      "Ep:110, loss:0.00000, loss_test:0.00999, lr:5.21e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.758, tt:3858.143\n",
      "Ep:111, loss:0.00000, loss_test:0.01001, lr:5.16e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.752, tt:3892.213\n",
      "Ep:112, loss:0.00000, loss_test:0.01009, lr:5.11e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.761, tt:3928.033\n",
      "Ep:113, loss:0.00000, loss_test:0.01006, lr:5.06e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.773, tt:3964.137\n",
      "Ep:114, loss:0.00000, loss_test:0.01024, lr:5.01e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.768, tt:3998.273\n",
      "Ep:115, loss:0.00000, loss_test:0.01007, lr:4.96e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.765, tt:4032.698\n",
      "Ep:116, loss:0.00000, loss_test:0.01019, lr:4.91e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.763, tt:4067.265\n",
      "Ep:117, loss:0.00000, loss_test:0.01017, lr:4.86e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.773, tt:4103.163\n",
      "Ep:118, loss:0.00000, loss_test:0.01025, lr:4.81e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.781, tt:4138.902\n",
      "Ep:119, loss:0.00000, loss_test:0.01027, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.781, tt:4173.675\n",
      "Ep:120, loss:0.00000, loss_test:0.01027, lr:4.71e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.783, tt:4208.693\n",
      "Ep:121, loss:0.00000, loss_test:0.01038, lr:4.67e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.787, tt:4244.000\n",
      "Ep:122, loss:0.00000, loss_test:0.01036, lr:4.62e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.794, tt:4279.699\n",
      "Ep:123, loss:0.00000, loss_test:0.01041, lr:4.57e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.806, tt:4315.913\n",
      "Ep:124, loss:0.00000, loss_test:0.01041, lr:4.53e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.813, tt:4351.660\n",
      "Ep:125, loss:0.00000, loss_test:0.01040, lr:4.48e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.822, tt:4387.576\n",
      "Ep:126, loss:0.00000, loss_test:0.01050, lr:4.44e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.813, tt:4421.251\n",
      "Ep:127, loss:0.00000, loss_test:0.01050, lr:4.39e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.815, tt:4456.270\n",
      "Ep:128, loss:0.00000, loss_test:0.01055, lr:4.35e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.826, tt:4492.558\n",
      "Ep:129, loss:0.00000, loss_test:0.01056, lr:4.31e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.851, tt:4530.585\n",
      "Ep:130, loss:0.00000, loss_test:0.01062, lr:4.26e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.862, tt:4566.965\n",
      "Ep:131, loss:0.00000, loss_test:0.01063, lr:4.22e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.871, tt:4602.910\n",
      "Ep:132, loss:0.00000, loss_test:0.01065, lr:4.18e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.872, tt:4638.006\n",
      "Ep:133, loss:0.00000, loss_test:0.01063, lr:4.14e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.874, tt:4673.061\n",
      "Ep:134, loss:0.00000, loss_test:0.01075, lr:4.10e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.879, tt:4708.609\n",
      "Ep:135, loss:0.00000, loss_test:0.01074, lr:4.05e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.883, tt:4744.083\n",
      "Ep:136, loss:0.00000, loss_test:0.01078, lr:4.01e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.885, tt:4779.246\n",
      "Ep:137, loss:0.00000, loss_test:0.01079, lr:3.97e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.885, tt:4814.121\n",
      "Ep:138, loss:0.00000, loss_test:0.01082, lr:3.93e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.900, tt:4851.149\n",
      "Ep:139, loss:0.00000, loss_test:0.01093, lr:3.89e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.895, tt:4885.297\n",
      "Ep:140, loss:0.00000, loss_test:0.01087, lr:3.86e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.899, tt:4920.825\n",
      "Ep:141, loss:0.00000, loss_test:0.01090, lr:3.82e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.912, tt:4957.528\n",
      "Ep:142, loss:0.00000, loss_test:0.01096, lr:3.78e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.916, tt:4992.975\n",
      "Ep:143, loss:0.00000, loss_test:0.01099, lr:3.74e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.911, tt:5027.179\n",
      "Ep:144, loss:0.00000, loss_test:0.01099, lr:3.70e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.916, tt:5062.806\n",
      "Ep:145, loss:0.00000, loss_test:0.01103, lr:3.67e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.924, tt:5098.953\n",
      "Ep:146, loss:0.00000, loss_test:0.01103, lr:3.63e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.931, tt:5134.916\n",
      "Ep:147, loss:0.00000, loss_test:0.01111, lr:3.59e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.938, tt:5170.767\n",
      "Ep:148, loss:0.00000, loss_test:0.01111, lr:3.56e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.937, tt:5205.670\n",
      "Ep:149, loss:0.00000, loss_test:0.01112, lr:3.52e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.947, tt:5242.093\n",
      "Ep:150, loss:0.00000, loss_test:0.01113, lr:3.49e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.945, tt:5276.653\n",
      "Ep:151, loss:0.00000, loss_test:0.01117, lr:3.45e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.942, tt:5311.153\n",
      "Ep:152, loss:0.00000, loss_test:0.01119, lr:3.42e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.947, tt:5346.907\n",
      "Ep:153, loss:0.00000, loss_test:0.01123, lr:3.38e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.952, tt:5382.555\n",
      "Ep:154, loss:0.00000, loss_test:0.01121, lr:3.35e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.954, tt:5417.810\n",
      "Ep:155, loss:0.00000, loss_test:0.01124, lr:3.32e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.950, tt:5452.169\n",
      "Ep:156, loss:0.00000, loss_test:0.01128, lr:3.28e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.952, tt:5487.469\n",
      "Ep:157, loss:0.00000, loss_test:0.01127, lr:3.25e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.963, tt:5524.212\n",
      "Ep:158, loss:0.00000, loss_test:0.01132, lr:3.22e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.973, tt:5560.747\n",
      "Ep:159, loss:0.00000, loss_test:0.01135, lr:3.19e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.983, tt:5597.206\n",
      "Ep:160, loss:0.00000, loss_test:0.01139, lr:3.15e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.988, tt:5633.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:161, loss:0.00000, loss_test:0.01138, lr:3.12e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.992, tt:5668.627\n",
      "Ep:162, loss:0.00000, loss_test:0.01141, lr:3.09e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.991, tt:5703.553\n",
      "Ep:163, loss:0.00000, loss_test:0.01144, lr:3.06e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.997, tt:5739.552\n",
      "Ep:164, loss:0.00000, loss_test:0.01145, lr:3.03e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.008, tt:5776.300\n",
      "Ep:165, loss:0.00000, loss_test:0.01145, lr:3.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.008, tt:5811.375\n",
      "Ep:166, loss:0.00000, loss_test:0.01147, lr:2.97e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.012, tt:5847.024\n",
      "Ep:167, loss:0.00000, loss_test:0.01151, lr:2.94e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.008, tt:5881.304\n",
      "Ep:168, loss:0.00000, loss_test:0.01150, lr:2.91e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.018, tt:5918.075\n",
      "Ep:169, loss:0.00000, loss_test:0.01154, lr:2.88e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.028, tt:5954.811\n",
      "Ep:170, loss:0.00000, loss_test:0.01156, lr:2.85e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.034, tt:5990.771\n",
      "Ep:171, loss:0.00000, loss_test:0.01158, lr:2.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.035, tt:6025.967\n",
      "Ep:172, loss:0.00000, loss_test:0.01161, lr:2.80e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.044, tt:6062.551\n",
      "Ep:173, loss:0.00000, loss_test:0.01159, lr:2.77e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.053, tt:6099.218\n",
      "Ep:174, loss:0.00000, loss_test:0.01166, lr:2.74e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.056, tt:6134.769\n",
      "Ep:175, loss:0.00000, loss_test:0.01164, lr:2.71e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.055, tt:6169.763\n",
      "Ep:176, loss:0.00000, loss_test:0.01166, lr:2.69e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.059, tt:6205.462\n",
      "Ep:177, loss:0.00000, loss_test:0.01171, lr:2.66e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.061, tt:6240.910\n",
      "Ep:178, loss:0.00000, loss_test:0.01170, lr:2.63e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.061, tt:6275.864\n",
      "Ep:179, loss:0.00000, loss_test:0.01174, lr:2.61e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.063, tt:6311.426\n",
      "Ep:180, loss:0.00000, loss_test:0.01173, lr:2.58e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.063, tt:6346.322\n",
      "Ep:181, loss:0.00000, loss_test:0.01176, lr:2.55e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.078, tt:6384.234\n",
      "Ep:182, loss:0.00000, loss_test:0.01178, lr:2.53e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.114, tt:6425.930\n",
      "Ep:183, loss:0.00000, loss_test:0.01179, lr:2.50e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.122, tt:6462.520\n",
      "Ep:184, loss:0.00000, loss_test:0.01180, lr:2.48e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.136, tt:6500.068\n",
      "Ep:185, loss:0.00000, loss_test:0.01181, lr:2.45e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.141, tt:6536.217\n",
      "Ep:186, loss:0.00000, loss_test:0.01183, lr:2.43e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.146, tt:6572.333\n",
      "Ep:187, loss:0.00000, loss_test:0.01184, lr:2.40e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.156, tt:6609.324\n",
      "Ep:188, loss:0.00000, loss_test:0.01185, lr:2.38e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.162, tt:6645.667\n",
      "Ep:189, loss:0.00000, loss_test:0.01188, lr:2.36e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.171, tt:6682.490\n",
      "Ep:190, loss:0.00000, loss_test:0.01190, lr:2.33e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.089, tt:6702.082\n",
      "Ep:191, loss:0.00000, loss_test:0.01190, lr:2.31e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.986, tt:6717.321\n",
      "Ep:192, loss:0.00000, loss_test:0.01191, lr:2.29e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.872, tt:6730.280\n",
      "Ep:193, loss:0.00000, loss_test:0.01193, lr:2.26e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.737, tt:6738.947\n",
      "Ep:194, loss:0.00000, loss_test:0.01195, lr:2.24e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.602, tt:6747.371\n",
      "Ep:195, loss:0.00000, loss_test:0.01197, lr:2.22e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.468, tt:6755.816\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14428, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.406, tt:38.406\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14335, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.058, tt:86.117\n",
      "Ep:2, loss:0.00028, loss_test:0.14170, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.605, tt:136.815\n",
      "Ep:3, loss:0.00028, loss_test:0.13901, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.949, tt:187.797\n",
      "Ep:4, loss:0.00027, loss_test:0.13458, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.656, tt:238.280\n",
      "Ep:5, loss:0.00026, loss_test:0.12685, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:48.078, tt:288.470\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11560, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:48.468, tt:339.275\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10875, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:48.794, tt:390.348\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10676, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:49.227, tt:443.042\n",
      "Ep:9, loss:0.00021, loss_test:0.10516, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:49.672, tt:496.722\n",
      "Ep:10, loss:0.00021, loss_test:0.10290, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:49.668, tt:546.346\n",
      "Ep:11, loss:0.00020, loss_test:0.10018, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:50.043, tt:600.513\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09895, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:50.272, tt:653.537\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09730, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:50.397, tt:705.556\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09503, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:50.426, tt:756.395\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09351, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:50.410, tt:806.566\n",
      "Ep:16, loss:0.00017, loss_test:0.09243, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:50.343, tt:855.829\n",
      "Ep:17, loss:0.00017, loss_test:0.09145, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:50.406, tt:907.306\n",
      "Ep:18, loss:0.00016, loss_test:0.09072, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:50.529, tt:960.049\n",
      "Ep:19, loss:0.00016, loss_test:0.08924, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:50.574, tt:1011.477\n",
      "Ep:20, loss:0.00015, loss_test:0.08763, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:50.586, tt:1062.314\n",
      "Ep:21, loss:0.00015, loss_test:0.08521, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:50.634, tt:1113.942\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08484, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:50.670, tt:1165.404\n",
      "Ep:23, loss:0.00014, loss_test:0.08230, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:50.585, tt:1214.045\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08145, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:50.601, tt:1265.026\n",
      "Ep:25, loss:0.00013, loss_test:0.07964, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:50.613, tt:1315.943\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07840, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:50.624, tt:1366.835\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07869, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:50.566, tt:1415.860\n",
      "Ep:28, loss:0.00013, loss_test:0.07607, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:50.597, tt:1467.316\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07854, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:50.660, tt:1519.792\n",
      "Ep:30, loss:0.00012, loss_test:0.07374, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:50.773, tt:1573.955\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07713, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:50.823, tt:1626.324\n",
      "Ep:32, loss:0.00012, loss_test:0.07153, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:50.951, tt:1681.393\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07351, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:50.969, tt:1732.944\n",
      "Ep:34, loss:0.00011, loss_test:0.06937, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:50.980, tt:1784.285\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07125, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:51.001, tt:1836.038\n",
      "Ep:36, loss:0.00010, loss_test:0.06704, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:51.031, tt:1888.162\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.06795, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:51.022, tt:1938.852\n",
      "Ep:38, loss:0.00010, loss_test:0.06936, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:51.079, tt:1992.070\n",
      "Ep:39, loss:0.00010, loss_test:0.06519, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:51.080, tt:2043.197\n",
      "Ep:40, loss:0.00009, loss_test:0.07161, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:51.077, tt:2094.160\n",
      "Ep:41, loss:0.00009, loss_test:0.06389, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:51.075, tt:2145.146\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.06660, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:51.130, tt:2198.600\n",
      "Ep:43, loss:0.00009, loss_test:0.06669, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:51.155, tt:2250.814\n",
      "Ep:44, loss:0.00008, loss_test:0.06310, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:51.171, tt:2302.677\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06959, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:51.159, tt:2353.336\n",
      "Ep:46, loss:0.00008, loss_test:0.06327, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:51.189, tt:2405.874\n",
      "Ep:47, loss:0.00008, loss_test:0.06874, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:51.189, tt:2457.081\n",
      "Ep:48, loss:0.00008, loss_test:0.06026, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:51.179, tt:2507.778\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.06478, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:51.175, tt:2558.746\n",
      "Ep:50, loss:0.00007, loss_test:0.05811, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:51.206, tt:2611.507\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06281, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:51.224, tt:2663.671\n",
      "Ep:52, loss:0.00007, loss_test:0.05725, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:51.286, tt:2718.136\n",
      "Ep:53, loss:0.00007, loss_test:0.05790, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:51.289, tt:2769.596\n",
      "Ep:54, loss:0.00006, loss_test:0.05846, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:51.301, tt:2821.545\n",
      "Ep:55, loss:0.00006, loss_test:0.05588, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:51.339, tt:2874.970\n",
      "Ep:56, loss:0.00006, loss_test:0.06565, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:51.319, tt:2925.182\n",
      "Ep:57, loss:0.00006, loss_test:0.05562, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:51.316, tt:2976.345\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.06240, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:51.321, tt:3027.954\n",
      "Ep:59, loss:0.00005, loss_test:0.05471, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:51.354, tt:3081.263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.05734, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:51.339, tt:3131.697\n",
      "Ep:61, loss:0.00005, loss_test:0.05660, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:51.327, tt:3182.252\n",
      "Ep:62, loss:0.00005, loss_test:0.05683, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:51.324, tt:3233.408\n",
      "Ep:63, loss:0.00004, loss_test:0.05315, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:51.319, tt:3284.408\n",
      "Ep:64, loss:0.00004, loss_test:0.05807, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:51.378, tt:3339.585\n",
      "Ep:65, loss:0.00004, loss_test:0.05751, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:51.356, tt:3389.501\n",
      "Ep:66, loss:0.00004, loss_test:0.05603, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:51.357, tt:3440.887\n",
      "Ep:67, loss:0.00004, loss_test:0.05599, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:51.388, tt:3494.392\n",
      "Ep:68, loss:0.00004, loss_test:0.05643, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:51.411, tt:3547.332\n",
      "Ep:69, loss:0.00004, loss_test:0.05721, lr:9.90e-03, fs:0.84746 (r=0.758,p=0.962),  time:51.423, tt:3599.628\n",
      "Ep:70, loss:0.00003, loss_test:0.05460, lr:9.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:51.434, tt:3651.799\n",
      "Ep:71, loss:0.00003, loss_test:0.05989, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.409, tt:3701.414\n",
      "Ep:72, loss:0.00003, loss_test:0.06423, lr:9.61e-03, fs:0.84571 (r=0.747,p=0.974),  time:51.406, tt:3752.620\n",
      "Ep:73, loss:0.00003, loss_test:0.05523, lr:9.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:51.406, tt:3804.068\n",
      "Ep:74, loss:0.00003, loss_test:0.05835, lr:9.41e-03, fs:0.84746 (r=0.758,p=0.962),  time:51.401, tt:3855.102\n",
      "Ep:75, loss:0.00003, loss_test:0.06359, lr:9.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.385, tt:3905.222\n",
      "Ep:76, loss:0.00003, loss_test:0.05370, lr:9.23e-03, fs:0.86813 (r=0.798,p=0.952),  time:51.397, tt:3957.544\n",
      "Ep:77, loss:0.00003, loss_test:0.06126, lr:9.14e-03, fs:0.85227 (r=0.758,p=0.974),  time:51.416, tt:4010.472\n",
      "Ep:78, loss:0.00003, loss_test:0.05760, lr:9.04e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.413, tt:4061.607\n",
      "Ep:79, loss:0.00003, loss_test:0.05584, lr:8.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:51.421, tt:4113.666\n",
      "Ep:80, loss:0.00003, loss_test:0.05824, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.414, tt:4164.533\n",
      "Ep:81, loss:0.00002, loss_test:0.06290, lr:8.78e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.454, tt:4219.267\n",
      "Ep:82, loss:0.00002, loss_test:0.05401, lr:8.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:51.465, tt:4271.572\n",
      "Ep:83, loss:0.00002, loss_test:0.06593, lr:8.60e-03, fs:0.84571 (r=0.747,p=0.974),  time:51.470, tt:4323.440\n",
      "Ep:84, loss:0.00002, loss_test:0.05916, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.478, tt:4375.654\n",
      "Ep:85, loss:0.00002, loss_test:0.06478, lr:8.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.498, tt:4428.834\n",
      "Ep:86, loss:0.00002, loss_test:0.05939, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.492, tt:4479.803\n",
      "Ep:87, loss:0.00002, loss_test:0.06344, lr:8.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.505, tt:4532.439\n",
      "Ep:88, loss:0.00002, loss_test:0.06049, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.490, tt:4582.640\n",
      "Ep:89, loss:0.00002, loss_test:0.06252, lr:8.10e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.475, tt:4632.756\n",
      "Ep:90, loss:0.00002, loss_test:0.06153, lr:8.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.451, tt:4682.028\n",
      "Ep:91, loss:0.00002, loss_test:0.06462, lr:7.94e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.438, tt:4732.305\n",
      "Ep:92, loss:0.00002, loss_test:0.06348, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.441, tt:4784.008\n",
      "Ep:93, loss:0.00002, loss_test:0.06332, lr:7.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.456, tt:4836.910\n",
      "Ep:94, loss:0.00002, loss_test:0.06492, lr:7.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.456, tt:4888.293\n",
      "Ep:95, loss:0.00001, loss_test:0.06153, lr:7.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.450, tt:4939.185\n",
      "Ep:96, loss:0.00001, loss_test:0.06801, lr:7.55e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.450, tt:4990.686\n",
      "Ep:97, loss:0.00001, loss_test:0.06003, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.461, tt:5043.192\n",
      "Ep:98, loss:0.00001, loss_test:0.07211, lr:7.40e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.455, tt:5094.057\n",
      "Ep:99, loss:0.00001, loss_test:0.06048, lr:7.32e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.442, tt:5144.155\n",
      "Ep:100, loss:0.00001, loss_test:0.07227, lr:7.25e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.447, tt:5196.171\n",
      "Ep:101, loss:0.00001, loss_test:0.06116, lr:7.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.465, tt:5249.406\n",
      "Ep:102, loss:0.00001, loss_test:0.07389, lr:7.11e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.456, tt:5299.969\n",
      "Ep:103, loss:0.00001, loss_test:0.06182, lr:7.03e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.449, tt:5350.682\n",
      "Ep:104, loss:0.00001, loss_test:0.07368, lr:6.96e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.437, tt:5400.913\n",
      "Ep:105, loss:0.00001, loss_test:0.06281, lr:6.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.458, tt:5454.516\n",
      "Ep:106, loss:0.00001, loss_test:0.07343, lr:6.83e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.439, tt:5503.982\n",
      "Ep:107, loss:0.00001, loss_test:0.06446, lr:6.76e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.439, tt:5555.397\n",
      "Ep:108, loss:0.00001, loss_test:0.07408, lr:6.69e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.446, tt:5607.580\n",
      "Ep:109, loss:0.00001, loss_test:0.06857, lr:6.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.452, tt:5659.676\n",
      "Ep:110, loss:0.00001, loss_test:0.06742, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.448, tt:5710.752\n",
      "Ep:111, loss:0.00001, loss_test:0.07135, lr:6.49e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.421, tt:5759.207\n",
      "Ep:112, loss:0.00001, loss_test:0.06449, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.449, tt:5813.710\n",
      "Ep:113, loss:0.00001, loss_test:0.07368, lr:6.36e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.439, tt:5864.023\n",
      "Ep:114, loss:0.00001, loss_test:0.06412, lr:6.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.432, tt:5914.689\n",
      "Ep:115, loss:0.00001, loss_test:0.07061, lr:6.24e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.429, tt:5965.750\n",
      "Ep:116, loss:0.00001, loss_test:0.06820, lr:6.17e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.416, tt:6015.631\n",
      "Ep:117, loss:0.00001, loss_test:0.06636, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.417, tt:6067.162\n",
      "Ep:118, loss:0.00001, loss_test:0.07171, lr:6.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.435, tt:6120.757\n",
      "Ep:119, loss:0.00001, loss_test:0.06657, lr:5.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.437, tt:6172.408\n",
      "Ep:120, loss:0.00001, loss_test:0.07099, lr:5.93e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.443, tt:6224.608\n",
      "Ep:121, loss:0.00001, loss_test:0.06726, lr:5.87e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.440, tt:6275.639\n",
      "Ep:122, loss:0.00001, loss_test:0.07143, lr:5.81e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.434, tt:6326.350\n",
      "Ep:123, loss:0.00001, loss_test:0.06783, lr:5.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.450, tt:6379.806\n",
      "Ep:124, loss:0.00001, loss_test:0.06966, lr:5.70e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.441, tt:6430.120\n",
      "Ep:125, loss:0.00001, loss_test:0.06853, lr:5.64e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.423, tt:6479.351\n",
      "Ep:126, loss:0.00001, loss_test:0.06823, lr:5.58e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.423, tt:6530.692\n",
      "Ep:127, loss:0.00001, loss_test:0.06949, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.407, tt:6580.040\n",
      "Ep:128, loss:0.00001, loss_test:0.06921, lr:5.47e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.407, tt:6631.446\n",
      "Ep:129, loss:0.00001, loss_test:0.06824, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.428, tt:6685.702\n",
      "Ep:130, loss:0.00001, loss_test:0.06940, lr:5.36e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.439, tt:6738.556\n",
      "Ep:131, loss:0.00001, loss_test:0.06799, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.447, tt:6791.038\n",
      "Ep:132, loss:0.00001, loss_test:0.07024, lr:5.26e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.472, tt:6845.821\n",
      "Ep:133, loss:0.00001, loss_test:0.06973, lr:5.20e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.483, tt:6898.756\n",
      "Ep:134, loss:0.00001, loss_test:0.06949, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.488, tt:6950.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.07050, lr:5.10e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.501, tt:7004.108\n",
      "Ep:136, loss:0.00001, loss_test:0.06945, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.516, tt:7057.740\n",
      "Ep:137, loss:0.00001, loss_test:0.07010, lr:5.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.530, tt:7111.200\n",
      "Ep:138, loss:0.00001, loss_test:0.07058, lr:4.95e-03, fs:0.83041 (r=0.717,p=0.986),  time:51.558, tt:7166.517\n",
      "Ep:139, loss:0.00001, loss_test:0.06944, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.567, tt:7219.340\n",
      "Ep:140, loss:0.00001, loss_test:0.07226, lr:4.85e-03, fs:0.80952 (r=0.687,p=0.986),  time:51.592, tt:7274.521\n",
      "Ep:141, loss:0.00001, loss_test:0.07170, lr:4.80e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.596, tt:7326.689\n",
      "Ep:142, loss:0.00001, loss_test:0.06908, lr:4.75e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.601, tt:7378.953\n",
      "Ep:143, loss:0.00001, loss_test:0.07155, lr:4.71e-03, fs:0.83041 (r=0.717,p=0.986),  time:51.634, tt:7435.308\n",
      "Ep:144, loss:0.00001, loss_test:0.07113, lr:4.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.641, tt:7487.899\n",
      "Ep:145, loss:0.00001, loss_test:0.07016, lr:4.61e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.639, tt:7539.291\n",
      "Ep:146, loss:0.00001, loss_test:0.07186, lr:4.57e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.641, tt:7591.199\n",
      "Ep:147, loss:0.00000, loss_test:0.06974, lr:4.52e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.642, tt:7642.976\n",
      "Ep:148, loss:0.00000, loss_test:0.07101, lr:4.48e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.651, tt:7696.066\n",
      "Ep:149, loss:0.00000, loss_test:0.07267, lr:4.43e-03, fs:0.79518 (r=0.667,p=0.985),  time:51.656, tt:7748.364\n",
      "Ep:150, loss:0.00000, loss_test:0.06974, lr:4.39e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.665, tt:7801.391\n",
      "Ep:151, loss:0.00000, loss_test:0.07245, lr:4.34e-03, fs:0.80240 (r=0.677,p=0.985),  time:51.665, tt:7853.128\n",
      "Ep:152, loss:0.00000, loss_test:0.07078, lr:4.30e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.687, tt:7908.059\n",
      "Ep:153, loss:0.00000, loss_test:0.07222, lr:4.26e-03, fs:0.80952 (r=0.687,p=0.986),  time:51.693, tt:7960.796\n",
      "Ep:154, loss:0.00000, loss_test:0.07202, lr:4.21e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.696, tt:8012.947\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14439, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.796, tt:50.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14339, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.159, tt:94.318\n",
      "Ep:2, loss:0.00028, loss_test:0.14161, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.954, tt:146.862\n",
      "Ep:3, loss:0.00027, loss_test:0.13854, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.975, tt:199.898\n",
      "Ep:4, loss:0.00027, loss_test:0.13313, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:50.504, tt:252.519\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12451, lr:1.00e-02, fs:0.69818 (r=0.970,p=0.545),  time:51.136, tt:306.813\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11562, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:51.411, tt:359.877\n",
      "Ep:7, loss:0.00022, loss_test:0.11367, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:51.626, tt:413.004\n",
      "Ep:8, loss:0.00021, loss_test:0.11506, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:52.130, tt:469.169\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11134, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:52.270, tt:522.701\n",
      "Ep:10, loss:0.00020, loss_test:0.10878, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:52.299, tt:575.289\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10696, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:52.306, tt:627.675\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10800, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:52.251, tt:679.269\n",
      "Ep:13, loss:0.00018, loss_test:0.10598, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:52.204, tt:730.853\n",
      "Ep:14, loss:0.00017, loss_test:0.10422, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:52.301, tt:784.513\n",
      "Ep:15, loss:0.00017, loss_test:0.10349, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:52.335, tt:837.354\n",
      "Ep:16, loss:0.00017, loss_test:0.10202, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:52.462, tt:891.861\n",
      "Ep:17, loss:0.00016, loss_test:0.10019, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:52.515, tt:945.269\n",
      "Ep:18, loss:0.00016, loss_test:0.09891, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:52.553, tt:998.516\n",
      "Ep:19, loss:0.00015, loss_test:0.09786, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:52.546, tt:1050.922\n",
      "Ep:20, loss:0.00015, loss_test:0.09576, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:52.536, tt:1103.246\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.09544, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:52.434, tt:1153.543\n",
      "Ep:22, loss:0.00014, loss_test:0.09360, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:52.407, tt:1205.352\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09310, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:52.233, tt:1253.599\n",
      "Ep:24, loss:0.00013, loss_test:0.09182, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:52.277, tt:1306.918\n",
      "Ep:25, loss:0.00013, loss_test:0.09035, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:52.304, tt:1359.898\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09220, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:52.375, tt:1414.121\n",
      "Ep:27, loss:0.00012, loss_test:0.08964, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:52.427, tt:1467.956\n",
      "Ep:28, loss:0.00012, loss_test:0.08865, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:52.417, tt:1520.093\n",
      "Ep:29, loss:0.00012, loss_test:0.08937, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:52.486, tt:1574.575\n",
      "Ep:30, loss:0.00012, loss_test:0.08622, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:52.498, tt:1627.441\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08661, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:52.466, tt:1678.910\n",
      "Ep:32, loss:0.00011, loss_test:0.08553, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:52.440, tt:1730.535\n",
      "Ep:33, loss:0.00011, loss_test:0.08487, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.569, tt:1787.341\n",
      "Ep:34, loss:0.00010, loss_test:0.08509, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:52.648, tt:1842.685\n",
      "Ep:35, loss:0.00010, loss_test:0.08386, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:52.623, tt:1894.426\n",
      "Ep:36, loss:0.00010, loss_test:0.08414, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:52.645, tt:1947.858\n",
      "Ep:37, loss:0.00010, loss_test:0.08327, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.634, tt:2000.098\n",
      "Ep:38, loss:0.00009, loss_test:0.08357, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:52.659, tt:2053.684\n",
      "Ep:39, loss:0.00009, loss_test:0.08261, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.706, tt:2108.235\n",
      "Ep:40, loss:0.00009, loss_test:0.08219, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:52.717, tt:2161.403\n",
      "Ep:41, loss:0.00009, loss_test:0.08228, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:52.781, tt:2216.803\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.08201, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:52.883, tt:2273.950\n",
      "Ep:43, loss:0.00008, loss_test:0.08131, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.965, tt:2330.477\n",
      "Ep:44, loss:0.00008, loss_test:0.08145, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:53.005, tt:2385.245\n",
      "Ep:45, loss:0.00008, loss_test:0.08126, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:52.992, tt:2437.620\n",
      "Ep:46, loss:0.00007, loss_test:0.08086, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:53.035, tt:2492.644\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00007, loss_test:0.08355, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:53.082, tt:2547.956\n",
      "Ep:48, loss:0.00008, loss_test:0.07996, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.091, tt:2601.450\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.09696, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:53.122, tt:2656.089\n",
      "Ep:50, loss:0.00009, loss_test:0.08251, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:53.132, tt:2709.730\n",
      "Ep:51, loss:0.00008, loss_test:0.08348, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:53.155, tt:2764.076\n",
      "Ep:52, loss:0.00008, loss_test:0.08443, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:53.202, tt:2819.691\n",
      "Ep:53, loss:0.00007, loss_test:0.08298, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:53.215, tt:2873.586\n",
      "Ep:54, loss:0.00007, loss_test:0.08213, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:53.246, tt:2928.544\n",
      "Ep:55, loss:0.00007, loss_test:0.07988, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:53.272, tt:2983.209\n",
      "Ep:56, loss:0.00006, loss_test:0.07848, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:53.253, tt:3035.414\n",
      "Ep:57, loss:0.00006, loss_test:0.07682, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:53.272, tt:3089.802\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.07870, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.226, tt:3140.343\n",
      "Ep:59, loss:0.00005, loss_test:0.07918, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:53.240, tt:3194.399\n",
      "Ep:60, loss:0.00005, loss_test:0.08123, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:53.285, tt:3250.387\n",
      "Ep:61, loss:0.00005, loss_test:0.07775, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:53.314, tt:3305.455\n",
      "Ep:62, loss:0.00005, loss_test:0.08362, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:53.315, tt:3358.820\n",
      "Ep:63, loss:0.00005, loss_test:0.07876, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:53.305, tt:3411.540\n",
      "Ep:64, loss:0.00005, loss_test:0.08345, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:53.314, tt:3465.383\n",
      "Ep:65, loss:0.00005, loss_test:0.08252, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:53.319, tt:3519.083\n",
      "Ep:66, loss:0.00004, loss_test:0.07805, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:53.322, tt:3572.549\n",
      "Ep:67, loss:0.00004, loss_test:0.08054, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:53.298, tt:3624.288\n",
      "Ep:68, loss:0.00004, loss_test:0.07473, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.323, tt:3679.311\n",
      "Ep:69, loss:0.00004, loss_test:0.08011, lr:9.90e-03, fs:0.82022 (r=0.737,p=0.924),  time:53.312, tt:3731.838\n",
      "Ep:70, loss:0.00003, loss_test:0.07906, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:53.277, tt:3782.674\n",
      "Ep:71, loss:0.00003, loss_test:0.08109, lr:9.70e-03, fs:0.82955 (r=0.737,p=0.948),  time:53.251, tt:3834.086\n",
      "Ep:72, loss:0.00003, loss_test:0.07846, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:53.247, tt:3887.026\n",
      "Ep:73, loss:0.00003, loss_test:0.07869, lr:9.51e-03, fs:0.82022 (r=0.737,p=0.924),  time:53.241, tt:3939.858\n",
      "Ep:74, loss:0.00003, loss_test:0.08216, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:53.227, tt:3992.038\n",
      "Ep:75, loss:0.00003, loss_test:0.08006, lr:9.32e-03, fs:0.81564 (r=0.737,p=0.912),  time:53.245, tt:4046.637\n",
      "Ep:76, loss:0.00003, loss_test:0.08285, lr:9.23e-03, fs:0.80226 (r=0.717,p=0.910),  time:53.240, tt:4099.482\n",
      "Ep:77, loss:0.00003, loss_test:0.08129, lr:9.14e-03, fs:0.82081 (r=0.717,p=0.959),  time:53.254, tt:4153.847\n",
      "Ep:78, loss:0.00003, loss_test:0.08219, lr:9.04e-03, fs:0.80899 (r=0.727,p=0.911),  time:53.247, tt:4206.534\n",
      "Ep:79, loss:0.00002, loss_test:0.08254, lr:8.95e-03, fs:0.82081 (r=0.717,p=0.959),  time:53.256, tt:4260.509\n",
      "Ep:80, loss:0.00002, loss_test:0.08104, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:53.267, tt:4314.610\n",
      "Ep:81, loss:0.00002, loss_test:0.08519, lr:8.78e-03, fs:0.81143 (r=0.717,p=0.934),  time:53.225, tt:4364.444\n",
      "Ep:82, loss:0.00002, loss_test:0.08530, lr:8.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:53.157, tt:4412.016\n",
      "Ep:83, loss:0.00002, loss_test:0.08752, lr:8.60e-03, fs:0.82558 (r=0.717,p=0.973),  time:53.084, tt:4459.075\n",
      "Ep:84, loss:0.00002, loss_test:0.08192, lr:8.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:53.019, tt:4506.646\n",
      "Ep:85, loss:0.00002, loss_test:0.08883, lr:8.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:52.959, tt:4554.487\n",
      "Ep:86, loss:0.00002, loss_test:0.08199, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.975, tt:4608.855\n",
      "Ep:87, loss:0.00002, loss_test:0.08360, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.984, tt:4662.594\n",
      "Ep:88, loss:0.00002, loss_test:0.08707, lr:8.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.985, tt:4715.698\n",
      "Ep:89, loss:0.00002, loss_test:0.08296, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.994, tt:4769.457\n",
      "Ep:90, loss:0.00002, loss_test:0.09035, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.968, tt:4820.053\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.08249, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.990, tt:4875.060\n",
      "Ep:92, loss:0.00002, loss_test:0.08928, lr:8.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.965, tt:4925.770\n",
      "Ep:93, loss:0.00002, loss_test:0.09073, lr:8.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.946, tt:4976.958\n",
      "Ep:94, loss:0.00002, loss_test:0.08670, lr:8.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.931, tt:5028.431\n",
      "Ep:95, loss:0.00002, loss_test:0.09110, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.912, tt:5079.562\n",
      "Ep:96, loss:0.00002, loss_test:0.08870, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.899, tt:5131.169\n",
      "Ep:97, loss:0.00001, loss_test:0.08921, lr:8.02e-03, fs:0.82558 (r=0.717,p=0.973),  time:52.897, tt:5183.948\n",
      "Ep:98, loss:0.00001, loss_test:0.08861, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.888, tt:5235.900\n",
      "Ep:99, loss:0.00002, loss_test:0.08649, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.887, tt:5288.724\n",
      "Ep:100, loss:0.00001, loss_test:0.09110, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.886, tt:5341.515\n",
      "Ep:101, loss:0.00001, loss_test:0.08884, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.882, tt:5394.007\n",
      "Ep:102, loss:0.00001, loss_test:0.09003, lr:7.94e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.869, tt:5445.540\n",
      "Ep:103, loss:0.00001, loss_test:0.09132, lr:7.86e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.872, tt:5498.648\n",
      "Ep:104, loss:0.00001, loss_test:0.09199, lr:7.78e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.878, tt:5552.182\n",
      "Ep:105, loss:0.00001, loss_test:0.09361, lr:7.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.889, tt:5606.226\n",
      "Ep:106, loss:0.00001, loss_test:0.09020, lr:7.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.869, tt:5656.966\n",
      "Ep:107, loss:0.00001, loss_test:0.09665, lr:7.55e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.862, tt:5709.150\n",
      "Ep:108, loss:0.00001, loss_test:0.09013, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.851, tt:5760.754\n",
      "Ep:109, loss:0.00001, loss_test:0.09803, lr:7.40e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.850, tt:5813.501\n",
      "Ep:110, loss:0.00001, loss_test:0.09522, lr:7.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.858, tt:5867.292\n",
      "Ep:111, loss:0.00001, loss_test:0.08969, lr:7.25e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.860, tt:5920.355\n",
      "Ep:112, loss:0.00001, loss_test:0.09740, lr:7.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.858, tt:5972.902\n",
      "Ep:113, loss:0.00001, loss_test:0.09366, lr:7.11e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.836, tt:6023.326\n",
      "Ep:114, loss:0.00001, loss_test:0.09381, lr:7.03e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.821, tt:6074.469\n",
      "Ep:115, loss:0.00001, loss_test:0.09465, lr:6.96e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.816, tt:6126.680\n",
      "Ep:116, loss:0.00001, loss_test:0.09489, lr:6.89e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.807, tt:6178.379\n",
      "Ep:117, loss:0.00001, loss_test:0.09237, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.800, tt:6230.371\n",
      "Ep:118, loss:0.00001, loss_test:0.09477, lr:6.76e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.784, tt:6281.245\n",
      "Ep:119, loss:0.00001, loss_test:0.09678, lr:6.69e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.779, tt:6333.426\n",
      "Ep:120, loss:0.00001, loss_test:0.09462, lr:6.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.787, tt:6387.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.09552, lr:6.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.784, tt:6439.690\n",
      "Ep:122, loss:0.00001, loss_test:0.09505, lr:6.49e-03, fs:0.82558 (r=0.717,p=0.973),  time:52.808, tt:6495.371\n",
      "Ep:123, loss:0.00001, loss_test:0.09826, lr:6.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.802, tt:6547.452\n",
      "Ep:124, loss:0.00001, loss_test:0.09374, lr:6.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.787, tt:6598.359\n",
      "Ep:125, loss:0.00001, loss_test:0.09880, lr:6.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.775, tt:6649.604\n",
      "Ep:126, loss:0.00001, loss_test:0.09409, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.766, tt:6701.319\n",
      "Ep:127, loss:0.00001, loss_test:0.09902, lr:6.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.772, tt:6754.766\n",
      "Ep:128, loss:0.00001, loss_test:0.09581, lr:6.11e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.762, tt:6806.248\n",
      "Ep:129, loss:0.00001, loss_test:0.09641, lr:6.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.750, tt:6857.564\n",
      "Ep:130, loss:0.00001, loss_test:0.09689, lr:5.99e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.765, tt:6912.279\n",
      "Ep:131, loss:0.00001, loss_test:0.09888, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.752, tt:6963.326\n",
      "Ep:132, loss:0.00001, loss_test:0.09793, lr:5.87e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.744, tt:7014.976\n",
      "Ep:133, loss:0.00001, loss_test:0.09888, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.750, tt:7068.545\n",
      "Ep:134, loss:0.00001, loss_test:0.09727, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.755, tt:7121.953\n",
      "Ep:135, loss:0.00000, loss_test:0.09616, lr:5.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.764, tt:7175.957\n",
      "Ep:136, loss:0.00001, loss_test:0.09848, lr:5.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.744, tt:7225.982\n",
      "Ep:137, loss:0.00001, loss_test:0.09719, lr:5.58e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.741, tt:7278.204\n",
      "Ep:138, loss:0.00000, loss_test:0.09647, lr:5.53e-03, fs:0.79042 (r=0.667,p=0.971),  time:52.743, tt:7331.276\n",
      "Ep:139, loss:0.00000, loss_test:0.09827, lr:5.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.724, tt:7381.426\n",
      "Ep:140, loss:0.00000, loss_test:0.09756, lr:5.42e-03, fs:0.79042 (r=0.667,p=0.971),  time:52.757, tt:7438.793\n",
      "Ep:141, loss:0.00000, loss_test:0.09767, lr:5.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.759, tt:7491.781\n",
      "Ep:142, loss:0.00000, loss_test:0.09825, lr:5.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.753, tt:7543.729\n",
      "Ep:143, loss:0.00000, loss_test:0.09681, lr:5.26e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.749, tt:7595.800\n",
      "Ep:144, loss:0.00000, loss_test:0.09965, lr:5.20e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.733, tt:7646.260\n",
      "Ep:145, loss:0.00000, loss_test:0.09533, lr:5.15e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.726, tt:7698.040\n",
      "Ep:146, loss:0.00000, loss_test:0.09945, lr:5.10e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.725, tt:7750.579\n",
      "Ep:147, loss:0.00000, loss_test:0.10006, lr:5.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.740, tt:7805.525\n",
      "Ep:148, loss:0.00000, loss_test:0.09760, lr:5.00e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.739, tt:7858.077\n",
      "Ep:149, loss:0.00000, loss_test:0.09973, lr:4.95e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.742, tt:7911.363\n",
      "Ep:150, loss:0.00000, loss_test:0.09644, lr:4.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.747, tt:7964.762\n",
      "Ep:151, loss:0.00000, loss_test:0.09898, lr:4.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.754, tt:8018.678\n",
      "Ep:152, loss:0.00000, loss_test:0.09741, lr:4.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.753, tt:8071.239\n",
      "Ep:153, loss:0.00000, loss_test:0.09750, lr:4.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.754, tt:8124.044\n",
      "Ep:154, loss:0.00000, loss_test:0.09818, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.755, tt:8177.022\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14241, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.576, tt:20.576\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14108, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.502, tt:37.005\n",
      "Ep:2, loss:0.00028, loss_test:0.13869, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:17.587, tt:52.761\n",
      "Ep:3, loss:0.00027, loss_test:0.13454, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:17.635, tt:70.539\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12748, lr:1.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:18.216, tt:91.081\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11782, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:18.865, tt:113.189\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11277, lr:1.00e-02, fs:0.67662 (r=0.687,p=0.667),  time:19.900, tt:139.302\n",
      "Ep:7, loss:0.00023, loss_test:0.10970, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:20.361, tt:162.888\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10927, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:20.506, tt:184.554\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10520, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:20.734, tt:207.336\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10312, lr:1.00e-02, fs:0.68783 (r=0.657,p=0.722),  time:20.634, tt:226.979\n",
      "Ep:11, loss:0.00019, loss_test:0.09996, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:20.646, tt:247.751\n",
      "Ep:12, loss:0.00019, loss_test:0.09684, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:20.549, tt:267.136\n",
      "Ep:13, loss:0.00018, loss_test:0.09462, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:20.502, tt:287.031\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09037, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:20.438, tt:306.574\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08910, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:20.388, tt:326.210\n",
      "Ep:16, loss:0.00016, loss_test:0.08738, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:20.377, tt:346.410\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08575, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:20.451, tt:368.114\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08336, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:20.393, tt:387.473\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08156, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:20.493, tt:409.861\n",
      "Ep:20, loss:0.00014, loss_test:0.08182, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:20.530, tt:431.120\n",
      "Ep:21, loss:0.00013, loss_test:0.07882, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:20.598, tt:453.163\n",
      "Ep:22, loss:0.00012, loss_test:0.08061, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:20.614, tt:474.127\n",
      "Ep:23, loss:0.00012, loss_test:0.07580, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:20.701, tt:496.824\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07776, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:20.709, tt:517.725\n",
      "Ep:25, loss:0.00011, loss_test:0.07429, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:20.713, tt:538.533\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07544, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:20.717, tt:559.355\n",
      "Ep:27, loss:0.00010, loss_test:0.07433, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:20.697, tt:579.503\n",
      "Ep:28, loss:0.00010, loss_test:0.07108, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:20.697, tt:600.218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:29, loss:0.00009, loss_test:0.07324, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:20.710, tt:621.310\n",
      "Ep:30, loss:0.00009, loss_test:0.06736, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:20.708, tt:641.941\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06960, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:20.703, tt:662.504\n",
      "Ep:32, loss:0.00008, loss_test:0.07035, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:20.706, tt:683.292\n",
      "Ep:33, loss:0.00008, loss_test:0.06534, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:20.699, tt:703.755\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06913, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:20.686, tt:724.018\n",
      "Ep:35, loss:0.00007, loss_test:0.06527, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:20.730, tt:746.286\n",
      "Ep:36, loss:0.00006, loss_test:0.06644, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:20.710, tt:766.282\n",
      "Ep:37, loss:0.00006, loss_test:0.07107, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:20.707, tt:786.853\n",
      "Ep:38, loss:0.00006, loss_test:0.06291, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:20.661, tt:805.795\n",
      "Ep:39, loss:0.00006, loss_test:0.06949, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.676, tt:827.023\n",
      "Ep:40, loss:0.00005, loss_test:0.06282, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:20.709, tt:849.052\n",
      "Ep:41, loss:0.00005, loss_test:0.06475, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.682, tt:868.647\n",
      "Ep:42, loss:0.00005, loss_test:0.06234, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:20.693, tt:889.819\n",
      "Ep:43, loss:0.00005, loss_test:0.06238, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:20.701, tt:910.864\n",
      "Ep:44, loss:0.00004, loss_test:0.06014, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:20.737, tt:933.166\n",
      "Ep:45, loss:0.00004, loss_test:0.06191, lr:9.90e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.762, tt:955.058\n",
      "Ep:46, loss:0.00004, loss_test:0.06464, lr:9.80e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.780, tt:976.660\n",
      "Ep:47, loss:0.00004, loss_test:0.06089, lr:9.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:20.820, tt:999.339\n",
      "Ep:48, loss:0.00003, loss_test:0.06037, lr:9.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.869, tt:1022.564\n",
      "Ep:49, loss:0.00003, loss_test:0.06553, lr:9.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:20.956, tt:1047.795\n",
      "Ep:50, loss:0.00003, loss_test:0.06026, lr:9.41e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.980, tt:1069.971\n",
      "Ep:51, loss:0.00003, loss_test:0.06217, lr:9.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.000, tt:1092.023\n",
      "Ep:52, loss:0.00003, loss_test:0.05739, lr:9.23e-03, fs:0.81564 (r=0.737,p=0.912),  time:21.058, tt:1116.082\n",
      "Ep:53, loss:0.00003, loss_test:0.06798, lr:9.14e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.085, tt:1138.601\n",
      "Ep:54, loss:0.00003, loss_test:0.06293, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.127, tt:1162.001\n",
      "Ep:55, loss:0.00003, loss_test:0.06368, lr:8.95e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.132, tt:1183.372\n",
      "Ep:56, loss:0.00003, loss_test:0.06300, lr:8.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.151, tt:1205.603\n",
      "Ep:57, loss:0.00002, loss_test:0.06055, lr:8.78e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.179, tt:1228.387\n",
      "Ep:58, loss:0.00002, loss_test:0.06731, lr:8.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.185, tt:1249.893\n",
      "Ep:59, loss:0.00002, loss_test:0.06212, lr:8.60e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.215, tt:1272.876\n",
      "Ep:60, loss:0.00002, loss_test:0.06713, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.214, tt:1294.060\n",
      "Ep:61, loss:0.00002, loss_test:0.06640, lr:8.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.192, tt:1313.875\n",
      "Ep:62, loss:0.00002, loss_test:0.06099, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.183, tt:1334.506\n",
      "Ep:63, loss:0.00002, loss_test:0.06641, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.205, tt:1357.149\n",
      "Ep:64, loss:0.00002, loss_test:0.06207, lr:8.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.296, tt:1384.218\n",
      "Ep:65, loss:0.00002, loss_test:0.06471, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.301, tt:1405.898\n",
      "Ep:66, loss:0.00002, loss_test:0.06333, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.312, tt:1427.934\n",
      "Ep:67, loss:0.00002, loss_test:0.06317, lr:7.94e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.328, tt:1450.330\n",
      "Ep:68, loss:0.00002, loss_test:0.06401, lr:7.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.340, tt:1472.428\n",
      "Ep:69, loss:0.00002, loss_test:0.06840, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.355, tt:1494.854\n",
      "Ep:70, loss:0.00002, loss_test:0.06472, lr:7.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.360, tt:1516.550\n",
      "Ep:71, loss:0.00001, loss_test:0.06639, lr:7.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.348, tt:1537.065\n",
      "Ep:72, loss:0.00001, loss_test:0.06808, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.355, tt:1558.881\n",
      "Ep:73, loss:0.00001, loss_test:0.06593, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.340, tt:1579.185\n",
      "Ep:74, loss:0.00001, loss_test:0.07019, lr:7.40e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.336, tt:1600.192\n",
      "Ep:75, loss:0.00001, loss_test:0.06482, lr:7.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.336, tt:1621.526\n",
      "Ep:76, loss:0.00001, loss_test:0.07183, lr:7.25e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.339, tt:1643.114\n",
      "Ep:77, loss:0.00001, loss_test:0.06921, lr:7.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.320, tt:1662.945\n",
      "Ep:78, loss:0.00001, loss_test:0.06719, lr:7.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.312, tt:1683.651\n",
      "Ep:79, loss:0.00001, loss_test:0.07167, lr:7.03e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.307, tt:1704.567\n",
      "Ep:80, loss:0.00001, loss_test:0.06694, lr:6.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.283, tt:1723.951\n",
      "Ep:81, loss:0.00001, loss_test:0.07221, lr:6.89e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.270, tt:1744.135\n",
      "Ep:82, loss:0.00001, loss_test:0.06912, lr:6.83e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.242, tt:1763.126\n",
      "Ep:83, loss:0.00001, loss_test:0.06920, lr:6.76e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.244, tt:1784.529\n",
      "Ep:84, loss:0.00001, loss_test:0.07126, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.238, tt:1805.261\n",
      "Ep:85, loss:0.00001, loss_test:0.06879, lr:6.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.228, tt:1825.593\n",
      "Ep:86, loss:0.00001, loss_test:0.06930, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.214, tt:1845.613\n",
      "Ep:87, loss:0.00001, loss_test:0.07066, lr:6.49e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.211, tt:1866.561\n",
      "Ep:88, loss:0.00001, loss_test:0.06736, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.190, tt:1885.877\n",
      "Ep:89, loss:0.00001, loss_test:0.07090, lr:6.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.165, tt:1904.841\n",
      "Ep:90, loss:0.00001, loss_test:0.06948, lr:6.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.139, tt:1923.617\n",
      "Ep:91, loss:0.00001, loss_test:0.07220, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.129, tt:1943.912\n",
      "Ep:92, loss:0.00001, loss_test:0.07309, lr:6.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.106, tt:1962.892\n",
      "Ep:93, loss:0.00001, loss_test:0.07002, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.094, tt:1982.829\n",
      "Ep:94, loss:0.00001, loss_test:0.07130, lr:6.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.087, tt:2003.242\n",
      "Ep:95, loss:0.00001, loss_test:0.07096, lr:5.99e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.077, tt:2023.365\n",
      "Ep:96, loss:0.00001, loss_test:0.07005, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.059, tt:2042.713\n",
      "Ep:97, loss:0.00001, loss_test:0.07074, lr:5.87e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.043, tt:2062.203\n",
      "Ep:98, loss:0.00001, loss_test:0.07284, lr:5.81e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.072, tt:2086.114\n",
      "Ep:99, loss:0.00001, loss_test:0.06972, lr:5.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.066, tt:2106.568\n",
      "Ep:100, loss:0.00001, loss_test:0.07337, lr:5.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.063, tt:2127.391\n",
      "Ep:101, loss:0.00001, loss_test:0.07260, lr:5.64e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.053, tt:2147.447\n",
      "Ep:102, loss:0.00001, loss_test:0.07122, lr:5.58e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.067, tt:2169.918\n",
      "Ep:103, loss:0.00001, loss_test:0.07314, lr:5.53e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.053, tt:2189.465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00001, loss_test:0.07219, lr:5.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.052, tt:2210.489\n",
      "Ep:105, loss:0.00001, loss_test:0.07173, lr:5.42e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.045, tt:2230.792\n",
      "Ep:106, loss:0.00001, loss_test:0.07212, lr:5.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.053, tt:2252.715\n",
      "Ep:107, loss:0.00001, loss_test:0.07134, lr:5.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.063, tt:2274.758\n",
      "Ep:108, loss:0.00001, loss_test:0.07300, lr:5.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.063, tt:2295.896\n",
      "Ep:109, loss:0.00001, loss_test:0.07230, lr:5.20e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.075, tt:2318.238\n",
      "Ep:110, loss:0.00001, loss_test:0.07371, lr:5.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.079, tt:2339.761\n",
      "Ep:111, loss:0.00001, loss_test:0.07205, lr:5.10e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.061, tt:2358.870\n",
      "Ep:112, loss:0.00001, loss_test:0.07033, lr:5.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.048, tt:2378.438\n",
      "Ep:113, loss:0.00001, loss_test:0.07544, lr:5.00e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.059, tt:2400.688\n",
      "Ep:114, loss:0.00001, loss_test:0.07415, lr:4.95e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.069, tt:2422.971\n",
      "Ep:115, loss:0.00001, loss_test:0.07199, lr:4.90e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.093, tt:2446.760\n",
      "Ep:116, loss:0.00001, loss_test:0.07442, lr:4.85e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.086, tt:2467.050\n",
      "Ep:117, loss:0.00000, loss_test:0.07356, lr:4.80e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.084, tt:2487.861\n",
      "Ep:118, loss:0.00000, loss_test:0.07302, lr:4.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.079, tt:2508.440\n",
      "Ep:119, loss:0.00000, loss_test:0.07372, lr:4.71e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.090, tt:2530.855\n",
      "Ep:120, loss:0.00000, loss_test:0.07370, lr:4.66e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.111, tt:2554.396\n",
      "Ep:121, loss:0.00000, loss_test:0.07273, lr:4.61e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.106, tt:2574.964\n",
      "Ep:122, loss:0.00000, loss_test:0.07361, lr:4.57e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.107, tt:2596.102\n",
      "Ep:123, loss:0.00000, loss_test:0.07304, lr:4.52e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.112, tt:2617.827\n",
      "Ep:124, loss:0.00000, loss_test:0.07454, lr:4.48e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.113, tt:2639.071\n",
      "Ep:125, loss:0.00000, loss_test:0.07278, lr:4.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.129, tt:2662.311\n",
      "Ep:126, loss:0.00000, loss_test:0.07465, lr:4.39e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.133, tt:2683.922\n",
      "Ep:127, loss:0.00000, loss_test:0.07499, lr:4.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.145, tt:2706.507\n",
      "Ep:128, loss:0.00000, loss_test:0.07409, lr:4.30e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.140, tt:2727.034\n",
      "Ep:129, loss:0.00000, loss_test:0.07378, lr:4.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.151, tt:2749.687\n",
      "Ep:130, loss:0.00000, loss_test:0.07352, lr:4.21e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.154, tt:2771.190\n",
      "Ep:131, loss:0.00000, loss_test:0.07463, lr:4.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.156, tt:2792.591\n",
      "Ep:132, loss:0.00000, loss_test:0.07346, lr:4.13e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.150, tt:2812.899\n",
      "Ep:133, loss:0.00000, loss_test:0.07547, lr:4.09e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.169, tt:2836.603\n",
      "Ep:134, loss:0.00000, loss_test:0.07512, lr:4.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.168, tt:2857.620\n",
      "Ep:135, loss:0.00000, loss_test:0.07444, lr:4.01e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.170, tt:2879.179\n",
      "Ep:136, loss:0.00000, loss_test:0.07367, lr:3.97e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.151, tt:2897.739\n",
      "Ep:137, loss:0.00000, loss_test:0.07496, lr:3.93e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.153, tt:2919.100\n",
      "Ep:138, loss:0.00000, loss_test:0.07648, lr:3.89e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.149, tt:2939.676\n",
      "Ep:139, loss:0.00000, loss_test:0.07393, lr:3.85e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.175, tt:2964.456\n",
      "Ep:140, loss:0.00000, loss_test:0.07366, lr:3.81e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.165, tt:2984.231\n",
      "Ep:141, loss:0.00000, loss_test:0.07561, lr:3.77e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.150, tt:3003.320\n",
      "Ep:142, loss:0.00000, loss_test:0.07520, lr:3.73e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.156, tt:3025.344\n",
      "Ep:143, loss:0.00000, loss_test:0.07495, lr:3.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.154, tt:3046.158\n",
      "Ep:144, loss:0.00000, loss_test:0.07479, lr:3.66e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.165, tt:3068.922\n",
      "Ep:145, loss:0.00000, loss_test:0.07552, lr:3.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.186, tt:3093.209\n",
      "Ep:146, loss:0.00000, loss_test:0.07464, lr:3.59e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.179, tt:3113.260\n",
      "Ep:147, loss:0.00000, loss_test:0.07437, lr:3.55e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.183, tt:3135.148\n",
      "Ep:148, loss:0.00000, loss_test:0.07514, lr:3.52e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.181, tt:3155.956\n",
      "Ep:149, loss:0.00000, loss_test:0.07499, lr:3.48e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.179, tt:3176.920\n",
      "Ep:150, loss:0.00000, loss_test:0.07449, lr:3.45e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.174, tt:3197.219\n",
      "Ep:151, loss:0.00000, loss_test:0.07474, lr:3.41e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.191, tt:3221.086\n",
      "Ep:152, loss:0.00000, loss_test:0.07558, lr:3.38e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.206, tt:3244.481\n",
      "Ep:153, loss:0.00000, loss_test:0.07512, lr:3.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.216, tt:3267.297\n",
      "Ep:154, loss:0.00000, loss_test:0.07422, lr:3.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.214, tt:3288.229\n",
      "Ep:155, loss:0.00000, loss_test:0.07477, lr:3.28e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.220, tt:3310.306\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14328, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.628, tt:21.628\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14186, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.239, tt:42.478\n",
      "Ep:2, loss:0.00027, loss_test:0.13924, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.906, tt:59.717\n",
      "Ep:3, loss:0.00027, loss_test:0.13449, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:20.123, tt:80.492\n",
      "Ep:4, loss:0.00026, loss_test:0.12591, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:20.501, tt:102.503\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11320, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:20.804, tt:124.823\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10836, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:20.924, tt:146.469\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10618, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:20.798, tt:166.380\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10567, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:20.984, tt:188.853\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09928, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:21.006, tt:210.062\n",
      "Ep:10, loss:0.00020, loss_test:0.09782, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:21.016, tt:231.173\n",
      "Ep:11, loss:0.00019, loss_test:0.09512, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:20.936, tt:251.232\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09233, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:21.002, tt:273.021\n",
      "Ep:13, loss:0.00018, loss_test:0.09104, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:20.985, tt:293.783\n",
      "Ep:14, loss:0.00017, loss_test:0.08782, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:21.086, tt:316.296\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08823, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:21.118, tt:337.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00015, loss_test:0.08587, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:21.076, tt:358.293\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08443, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:21.102, tt:379.829\n",
      "Ep:18, loss:0.00014, loss_test:0.08337, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:21.063, tt:400.191\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08170, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:21.226, tt:424.527\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08090, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:21.153, tt:444.211\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07904, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:21.153, tt:465.357\n",
      "Ep:22, loss:0.00012, loss_test:0.07859, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:21.163, tt:486.757\n",
      "Ep:23, loss:0.00012, loss_test:0.07640, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:21.150, tt:507.604\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07716, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:21.178, tt:529.457\n",
      "Ep:25, loss:0.00011, loss_test:0.07418, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:21.232, tt:552.042\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07392, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:21.154, tt:571.154\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07160, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:21.138, tt:591.861\n",
      "Ep:28, loss:0.00009, loss_test:0.07099, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:21.205, tt:614.937\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.06908, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:21.216, tt:636.465\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.06895, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:21.230, tt:658.142\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06713, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:21.206, tt:678.606\n",
      "Ep:32, loss:0.00008, loss_test:0.06851, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:21.208, tt:699.877\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.06463, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:21.256, tt:722.719\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06598, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:21.233, tt:743.143\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06257, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:21.220, tt:763.921\n",
      "Ep:36, loss:0.00007, loss_test:0.06424, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:21.196, tt:784.270\n",
      "Ep:37, loss:0.00007, loss_test:0.06139, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:21.240, tt:807.102\n",
      "Ep:38, loss:0.00006, loss_test:0.06367, lr:1.00e-02, fs:0.93401 (r=0.929,p=0.939),  time:21.244, tt:828.506\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.06038, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:21.214, tt:848.579\n",
      "Ep:40, loss:0.00006, loss_test:0.06483, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:21.189, tt:868.762\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.05907, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:21.220, tt:891.222\n",
      "Ep:42, loss:0.00006, loss_test:0.06338, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:21.234, tt:913.078\n",
      "Ep:43, loss:0.00005, loss_test:0.05756, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:21.223, tt:933.799\n",
      "Ep:44, loss:0.00005, loss_test:0.06208, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:21.213, tt:954.594\n",
      "Ep:45, loss:0.00005, loss_test:0.05635, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:21.243, tt:977.157\n",
      "Ep:46, loss:0.00005, loss_test:0.05832, lr:1.00e-02, fs:0.94359 (r=0.929,p=0.958),  time:21.265, tt:999.432\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.05484, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:21.261, tt:1020.513\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00004, loss_test:0.05650, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.254, tt:1041.468\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.05445, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:21.261, tt:1063.072\n",
      "Ep:50, loss:0.00004, loss_test:0.05562, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.256, tt:1084.071\n",
      "Ep:51, loss:0.00004, loss_test:0.05382, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.260, tt:1105.506\n",
      "Ep:52, loss:0.00004, loss_test:0.05428, lr:1.00e-02, fs:0.95431 (r=0.949,p=0.959),  time:21.244, tt:1125.911\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.05285, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:21.241, tt:1147.006\n",
      "Ep:54, loss:0.00003, loss_test:0.05405, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.223, tt:1167.289\n",
      "Ep:55, loss:0.00003, loss_test:0.05263, lr:1.00e-02, fs:0.94949 (r=0.949,p=0.949),  time:21.220, tt:1188.296\n",
      "Ep:56, loss:0.00003, loss_test:0.05411, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.199, tt:1208.316\n",
      "Ep:57, loss:0.00003, loss_test:0.05308, lr:1.00e-02, fs:0.95431 (r=0.949,p=0.959),  time:21.199, tt:1229.567\n",
      "Ep:58, loss:0.00003, loss_test:0.05477, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.202, tt:1250.914\n",
      "Ep:59, loss:0.00003, loss_test:0.05115, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:21.236, tt:1274.181\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.05559, lr:1.00e-02, fs:0.94845 (r=0.929,p=0.968),  time:21.240, tt:1295.620\n",
      "Ep:61, loss:0.00003, loss_test:0.05119, lr:1.00e-02, fs:0.97537 (r=1.000,p=0.952),  time:21.236, tt:1316.615\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.05397, lr:1.00e-02, fs:0.95385 (r=0.939,p=0.969),  time:21.229, tt:1337.420\n",
      "Ep:63, loss:0.00002, loss_test:0.05222, lr:1.00e-02, fs:0.97487 (r=0.980,p=0.970),  time:21.241, tt:1359.453\n",
      "Ep:64, loss:0.00002, loss_test:0.05416, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:21.236, tt:1380.348\n",
      "Ep:65, loss:0.00002, loss_test:0.05426, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.240, tt:1401.849\n",
      "Ep:66, loss:0.00002, loss_test:0.05346, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:21.255, tt:1424.097\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.05400, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:21.242, tt:1444.459\n",
      "Ep:68, loss:0.00002, loss_test:0.05397, lr:1.00e-02, fs:0.95876 (r=0.939,p=0.979),  time:21.259, tt:1466.866\n",
      "Ep:69, loss:0.00002, loss_test:0.05550, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.285, tt:1489.965\n",
      "Ep:70, loss:0.00002, loss_test:0.05563, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.265, tt:1509.791\n",
      "Ep:71, loss:0.00002, loss_test:0.05531, lr:1.00e-02, fs:0.94792 (r=0.919,p=0.978),  time:21.255, tt:1530.362\n",
      "Ep:72, loss:0.00002, loss_test:0.05484, lr:1.00e-02, fs:0.95337 (r=0.929,p=0.979),  time:21.250, tt:1551.222\n",
      "Ep:73, loss:0.00002, loss_test:0.05555, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.260, tt:1573.221\n",
      "Ep:74, loss:0.00002, loss_test:0.05423, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:21.268, tt:1595.130\n",
      "Ep:75, loss:0.00002, loss_test:0.05693, lr:1.00e-02, fs:0.95337 (r=0.929,p=0.979),  time:21.271, tt:1616.573\n",
      "Ep:76, loss:0.00002, loss_test:0.05422, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.267, tt:1637.535\n",
      "Ep:77, loss:0.00001, loss_test:0.05996, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:21.247, tt:1657.227\n",
      "Ep:78, loss:0.00001, loss_test:0.05385, lr:9.90e-03, fs:0.96410 (r=0.949,p=0.979),  time:21.260, tt:1679.579\n",
      "Ep:79, loss:0.00001, loss_test:0.05798, lr:9.80e-03, fs:0.91979 (r=0.869,p=0.977),  time:21.243, tt:1699.452\n",
      "Ep:80, loss:0.00001, loss_test:0.05626, lr:9.70e-03, fs:0.94792 (r=0.919,p=0.978),  time:21.258, tt:1721.868\n",
      "Ep:81, loss:0.00001, loss_test:0.05717, lr:9.61e-03, fs:0.94241 (r=0.909,p=0.978),  time:21.244, tt:1742.049\n",
      "Ep:82, loss:0.00001, loss_test:0.05885, lr:9.51e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.248, tt:1763.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.05467, lr:9.41e-03, fs:0.96410 (r=0.949,p=0.979),  time:21.241, tt:1784.217\n",
      "Ep:84, loss:0.00001, loss_test:0.05995, lr:9.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.247, tt:1805.964\n",
      "Ep:85, loss:0.00001, loss_test:0.05756, lr:9.23e-03, fs:0.95337 (r=0.929,p=0.979),  time:21.253, tt:1827.775\n",
      "Ep:86, loss:0.00001, loss_test:0.05676, lr:9.14e-03, fs:0.92553 (r=0.879,p=0.978),  time:21.250, tt:1848.779\n",
      "Ep:87, loss:0.00001, loss_test:0.05924, lr:9.04e-03, fs:0.92553 (r=0.879,p=0.978),  time:21.249, tt:1869.871\n",
      "Ep:88, loss:0.00001, loss_test:0.05752, lr:8.95e-03, fs:0.91979 (r=0.869,p=0.977),  time:21.251, tt:1891.309\n",
      "Ep:89, loss:0.00001, loss_test:0.05876, lr:8.86e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.254, tt:1912.892\n",
      "Ep:90, loss:0.00001, loss_test:0.06079, lr:8.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.254, tt:1934.112\n",
      "Ep:91, loss:0.00001, loss_test:0.05767, lr:8.69e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.264, tt:1956.266\n",
      "Ep:92, loss:0.00001, loss_test:0.06052, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.246, tt:1975.845\n",
      "Ep:93, loss:0.00001, loss_test:0.05760, lr:8.51e-03, fs:0.91979 (r=0.869,p=0.977),  time:21.265, tt:1998.928\n",
      "Ep:94, loss:0.00001, loss_test:0.06015, lr:8.43e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.272, tt:2020.835\n",
      "Ep:95, loss:0.00001, loss_test:0.06233, lr:8.35e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.265, tt:2041.482\n",
      "Ep:96, loss:0.00001, loss_test:0.05782, lr:8.26e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.258, tt:2062.023\n",
      "Ep:97, loss:0.00001, loss_test:0.06307, lr:8.18e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.251, tt:2082.582\n",
      "Ep:98, loss:0.00001, loss_test:0.06011, lr:8.10e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.246, tt:2103.318\n",
      "Ep:99, loss:0.00001, loss_test:0.05984, lr:8.02e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.244, tt:2124.433\n",
      "Ep:100, loss:0.00001, loss_test:0.06220, lr:7.94e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.251, tt:2146.401\n",
      "Ep:101, loss:0.00001, loss_test:0.05987, lr:7.86e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.259, tt:2168.413\n",
      "Ep:102, loss:0.00001, loss_test:0.06172, lr:7.78e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.251, tt:2188.852\n",
      "Ep:103, loss:0.00001, loss_test:0.06223, lr:7.70e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.251, tt:2210.151\n",
      "Ep:104, loss:0.00001, loss_test:0.06184, lr:7.62e-03, fs:0.87151 (r=0.788,p=0.975),  time:21.253, tt:2231.577\n",
      "Ep:105, loss:0.00001, loss_test:0.06268, lr:7.55e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.278, tt:2255.443\n",
      "Ep:106, loss:0.00001, loss_test:0.06080, lr:7.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.288, tt:2277.768\n",
      "Ep:107, loss:0.00001, loss_test:0.06393, lr:7.40e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.270, tt:2297.183\n",
      "Ep:108, loss:0.00001, loss_test:0.06299, lr:7.32e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.247, tt:2315.972\n",
      "Ep:109, loss:0.00001, loss_test:0.06079, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.218, tt:2333.975\n",
      "Ep:110, loss:0.00001, loss_test:0.06509, lr:7.18e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.224, tt:2355.914\n",
      "Ep:111, loss:0.00001, loss_test:0.06123, lr:7.11e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.231, tt:2377.824\n",
      "Ep:112, loss:0.00001, loss_test:0.06364, lr:7.03e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.232, tt:2399.227\n",
      "Ep:113, loss:0.00001, loss_test:0.06566, lr:6.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.210, tt:2417.950\n",
      "Ep:114, loss:0.00001, loss_test:0.06164, lr:6.89e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.189, tt:2436.725\n",
      "Ep:115, loss:0.00001, loss_test:0.06506, lr:6.83e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.186, tt:2457.538\n",
      "Ep:116, loss:0.00000, loss_test:0.06479, lr:6.76e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.204, tt:2480.818\n",
      "Ep:117, loss:0.00000, loss_test:0.06301, lr:6.69e-03, fs:0.83908 (r=0.737,p=0.973),  time:21.204, tt:2502.073\n",
      "Ep:118, loss:0.00000, loss_test:0.06658, lr:6.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:21.215, tt:2524.565\n",
      "Ep:119, loss:0.00000, loss_test:0.06360, lr:6.56e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.220, tt:2546.452\n",
      "Ep:120, loss:0.00000, loss_test:0.06507, lr:6.49e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.228, tt:2568.632\n",
      "Ep:121, loss:0.00000, loss_test:0.06594, lr:6.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.218, tt:2588.544\n",
      "Ep:122, loss:0.00000, loss_test:0.06348, lr:6.36e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.235, tt:2611.871\n",
      "Ep:123, loss:0.00000, loss_test:0.06572, lr:6.30e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.225, tt:2631.919\n",
      "Ep:124, loss:0.00000, loss_test:0.06638, lr:6.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:21.217, tt:2652.186\n",
      "Ep:125, loss:0.00000, loss_test:0.06324, lr:6.17e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.215, tt:2673.042\n",
      "Ep:126, loss:0.00000, loss_test:0.06577, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:21.220, tt:2694.890\n",
      "Ep:127, loss:0.00000, loss_test:0.06668, lr:6.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:21.217, tt:2715.834\n",
      "Ep:128, loss:0.00000, loss_test:0.06420, lr:5.99e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.230, tt:2738.645\n",
      "Ep:129, loss:0.00000, loss_test:0.06644, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.226, tt:2759.364\n",
      "Ep:130, loss:0.00000, loss_test:0.06474, lr:5.87e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.221, tt:2779.999\n",
      "Ep:131, loss:0.00000, loss_test:0.06580, lr:5.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.242, tt:2803.998\n",
      "Ep:132, loss:0.00000, loss_test:0.06650, lr:5.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.244, tt:2825.474\n",
      "Ep:133, loss:0.00000, loss_test:0.06597, lr:5.70e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.236, tt:2845.610\n",
      "Ep:134, loss:0.00000, loss_test:0.06520, lr:5.64e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.240, tt:2867.380\n",
      "Ep:135, loss:0.00000, loss_test:0.06722, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.241, tt:2888.715\n",
      "Ep:136, loss:0.00000, loss_test:0.06641, lr:5.53e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.258, tt:2912.310\n",
      "Ep:137, loss:0.00000, loss_test:0.06497, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.255, tt:2933.171\n",
      "Ep:138, loss:0.00000, loss_test:0.06601, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.246, tt:2953.170\n",
      "Ep:139, loss:0.00000, loss_test:0.06511, lr:5.36e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.236, tt:2973.084\n",
      "Ep:140, loss:0.00000, loss_test:0.06628, lr:5.31e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.230, tt:2993.501\n",
      "Ep:141, loss:0.00000, loss_test:0.06521, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.235, tt:3015.383\n",
      "Ep:142, loss:0.00000, loss_test:0.06562, lr:5.20e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.239, tt:3037.158\n",
      "Ep:143, loss:0.00000, loss_test:0.06465, lr:5.15e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.240, tt:3058.570\n",
      "Ep:144, loss:0.00000, loss_test:0.06628, lr:5.10e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.237, tt:3079.303\n",
      "Ep:145, loss:0.00000, loss_test:0.06529, lr:5.05e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.235, tt:3100.352\n",
      "Ep:146, loss:0.00000, loss_test:0.06574, lr:5.00e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.236, tt:3121.765\n",
      "Ep:147, loss:0.00000, loss_test:0.06661, lr:4.95e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.242, tt:3143.764\n",
      "Ep:148, loss:0.00000, loss_test:0.06554, lr:4.90e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.238, tt:3164.507\n",
      "Ep:149, loss:0.00000, loss_test:0.06606, lr:4.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.248, tt:3187.255\n",
      "Ep:150, loss:0.00000, loss_test:0.06567, lr:4.80e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.253, tt:3209.175\n",
      "Ep:151, loss:0.00000, loss_test:0.06595, lr:4.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.249, tt:3229.809\n",
      "Ep:152, loss:0.00000, loss_test:0.06578, lr:4.71e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.262, tt:3253.072\n",
      "Ep:153, loss:0.00000, loss_test:0.06520, lr:4.66e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.261, tt:3274.179\n",
      "Ep:154, loss:0.00000, loss_test:0.06781, lr:4.61e-03, fs:0.70513 (r=0.556,p=0.965),  time:21.267, tt:3296.310\n",
      "Ep:155, loss:0.00000, loss_test:0.06627, lr:4.57e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.258, tt:3316.297\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14343, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.480, tt:24.480\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14233, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.108, tt:44.216\n",
      "Ep:2, loss:0.00028, loss_test:0.14038, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:21.398, tt:64.195\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13682, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:22.445, tt:89.780\n",
      "Ep:4, loss:0.00026, loss_test:0.13164, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:23.088, tt:115.441\n",
      "Ep:5, loss:0.00025, loss_test:0.12687, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:23.369, tt:140.216\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12309, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:23.669, tt:165.685\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11889, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:23.786, tt:190.287\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11623, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:24.017, tt:216.151\n",
      "Ep:9, loss:0.00022, loss_test:0.11217, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:23.985, tt:239.847\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10826, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:23.971, tt:263.682\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10590, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:24.283, tt:291.396\n",
      "Ep:12, loss:0.00019, loss_test:0.10260, lr:1.00e-02, fs:0.76190 (r=0.889,p=0.667),  time:24.269, tt:315.501\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09790, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:24.254, tt:339.554\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09519, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:24.229, tt:363.442\n",
      "Ep:15, loss:0.00017, loss_test:0.09484, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:24.222, tt:387.555\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09322, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:24.498, tt:416.471\n",
      "Ep:17, loss:0.00016, loss_test:0.08985, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:24.631, tt:443.361\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08785, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:24.678, tt:468.879\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08624, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:24.626, tt:492.515\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08501, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:24.626, tt:517.138\n",
      "Ep:21, loss:0.00013, loss_test:0.08385, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:24.620, tt:541.636\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08304, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:24.616, tt:566.179\n",
      "Ep:23, loss:0.00012, loss_test:0.08219, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:24.608, tt:590.585\n",
      "Ep:24, loss:0.00012, loss_test:0.08049, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:24.635, tt:615.866\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07985, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:24.625, tt:640.249\n",
      "Ep:26, loss:0.00011, loss_test:0.07815, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:24.627, tt:664.919\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07690, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:24.678, tt:690.983\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07603, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:24.694, tt:716.114\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.07585, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:24.749, tt:742.465\n",
      "Ep:30, loss:0.00009, loss_test:0.07392, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:24.762, tt:767.637\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07322, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:24.735, tt:791.524\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07236, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:24.746, tt:816.633\n",
      "Ep:33, loss:0.00008, loss_test:0.07045, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:24.796, tt:843.061\n",
      "Ep:34, loss:0.00008, loss_test:0.07028, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:24.809, tt:868.332\n",
      "Ep:35, loss:0.00007, loss_test:0.06923, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:24.839, tt:894.211\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.06937, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:24.887, tt:920.818\n",
      "Ep:37, loss:0.00007, loss_test:0.06827, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.834, tt:943.704\n",
      "Ep:38, loss:0.00007, loss_test:0.06814, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:24.849, tt:969.092\n",
      "Ep:39, loss:0.00006, loss_test:0.06741, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.871, tt:994.855\n",
      "Ep:40, loss:0.00006, loss_test:0.06689, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.904, tt:1021.063\n",
      "Ep:41, loss:0.00006, loss_test:0.06575, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:24.937, tt:1047.371\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06592, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:24.913, tt:1071.242\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.06360, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:24.916, tt:1096.317\n",
      "Ep:44, loss:0.00005, loss_test:0.06557, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:24.922, tt:1121.497\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.06418, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:24.939, tt:1147.173\n",
      "Ep:46, loss:0.00005, loss_test:0.06587, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:24.920, tt:1171.232\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.06317, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:24.910, tt:1195.679\n",
      "Ep:48, loss:0.00004, loss_test:0.06540, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:24.942, tt:1222.167\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.06357, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:24.949, tt:1247.433\n",
      "Ep:50, loss:0.00004, loss_test:0.06719, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:24.949, tt:1272.407\n",
      "Ep:51, loss:0.00004, loss_test:0.06323, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:24.949, tt:1297.335\n",
      "Ep:52, loss:0.00004, loss_test:0.06686, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:24.966, tt:1323.192\n",
      "Ep:53, loss:0.00004, loss_test:0.06347, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:24.974, tt:1348.601\n",
      "Ep:54, loss:0.00003, loss_test:0.06496, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:24.980, tt:1373.909\n",
      "Ep:55, loss:0.00003, loss_test:0.06357, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:24.992, tt:1399.556\n",
      "Ep:56, loss:0.00003, loss_test:0.06393, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:25.018, tt:1426.028\n",
      "Ep:57, loss:0.00003, loss_test:0.06570, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.010, tt:1450.551\n",
      "Ep:58, loss:0.00003, loss_test:0.06425, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:25.037, tt:1477.202\n",
      "Ep:59, loss:0.00003, loss_test:0.06593, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:25.079, tt:1504.732\n",
      "Ep:60, loss:0.00003, loss_test:0.06480, lr:9.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:25.080, tt:1529.907\n",
      "Ep:61, loss:0.00003, loss_test:0.06362, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:25.064, tt:1553.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00003, loss_test:0.06690, lr:9.70e-03, fs:0.82222 (r=0.747,p=0.914),  time:25.076, tt:1579.815\n",
      "Ep:63, loss:0.00002, loss_test:0.06386, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:25.083, tt:1605.344\n",
      "Ep:64, loss:0.00002, loss_test:0.06535, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:25.081, tt:1630.294\n",
      "Ep:65, loss:0.00002, loss_test:0.06311, lr:9.41e-03, fs:0.88542 (r=0.859,p=0.914),  time:25.091, tt:1656.010\n",
      "Ep:66, loss:0.00002, loss_test:0.06693, lr:9.32e-03, fs:0.83429 (r=0.737,p=0.961),  time:25.092, tt:1681.197\n",
      "Ep:67, loss:0.00002, loss_test:0.06308, lr:9.23e-03, fs:0.88542 (r=0.859,p=0.914),  time:25.116, tt:1707.897\n",
      "Ep:68, loss:0.00002, loss_test:0.06434, lr:9.14e-03, fs:0.86813 (r=0.798,p=0.952),  time:25.104, tt:1732.188\n",
      "Ep:69, loss:0.00002, loss_test:0.06474, lr:9.04e-03, fs:0.84615 (r=0.778,p=0.928),  time:25.138, tt:1759.632\n",
      "Ep:70, loss:0.00002, loss_test:0.06364, lr:8.95e-03, fs:0.91489 (r=0.869,p=0.966),  time:25.129, tt:1784.178\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.06491, lr:8.95e-03, fs:0.83429 (r=0.737,p=0.961),  time:25.106, tt:1807.642\n",
      "Ep:72, loss:0.00002, loss_test:0.06360, lr:8.95e-03, fs:0.90811 (r=0.848,p=0.977),  time:25.093, tt:1831.808\n",
      "Ep:73, loss:0.00002, loss_test:0.06276, lr:8.95e-03, fs:0.90323 (r=0.848,p=0.966),  time:25.080, tt:1855.910\n",
      "Ep:74, loss:0.00002, loss_test:0.06444, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:25.103, tt:1882.741\n",
      "Ep:75, loss:0.00002, loss_test:0.06385, lr:8.95e-03, fs:0.88525 (r=0.818,p=0.964),  time:25.115, tt:1908.744\n",
      "Ep:76, loss:0.00002, loss_test:0.06448, lr:8.95e-03, fs:0.91304 (r=0.848,p=0.988),  time:25.103, tt:1932.908\n",
      "Ep:77, loss:0.00001, loss_test:0.06289, lr:8.95e-03, fs:0.90909 (r=0.859,p=0.966),  time:25.077, tt:1956.007\n",
      "Ep:78, loss:0.00001, loss_test:0.06309, lr:8.95e-03, fs:0.87293 (r=0.798,p=0.963),  time:25.091, tt:1982.224\n",
      "Ep:79, loss:0.00001, loss_test:0.06491, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:25.096, tt:2007.706\n",
      "Ep:80, loss:0.00001, loss_test:0.06465, lr:8.95e-03, fs:0.85714 (r=0.758,p=0.987),  time:25.090, tt:2032.317\n",
      "Ep:81, loss:0.00001, loss_test:0.06229, lr:8.95e-03, fs:0.91489 (r=0.869,p=0.966),  time:25.087, tt:2057.128\n",
      "Ep:82, loss:0.00001, loss_test:0.06546, lr:8.86e-03, fs:0.84884 (r=0.737,p=1.000),  time:25.067, tt:2080.549\n",
      "Ep:83, loss:0.00001, loss_test:0.06408, lr:8.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:25.075, tt:2106.298\n",
      "Ep:84, loss:0.00001, loss_test:0.06404, lr:8.69e-03, fs:0.86667 (r=0.788,p=0.963),  time:25.062, tt:2130.233\n",
      "Ep:85, loss:0.00001, loss_test:0.06681, lr:8.60e-03, fs:0.84884 (r=0.737,p=1.000),  time:25.065, tt:2155.592\n",
      "Ep:86, loss:0.00001, loss_test:0.06397, lr:8.51e-03, fs:0.87640 (r=0.788,p=0.987),  time:25.041, tt:2178.603\n",
      "Ep:87, loss:0.00001, loss_test:0.06668, lr:8.43e-03, fs:0.84884 (r=0.737,p=1.000),  time:25.003, tt:2200.261\n",
      "Ep:88, loss:0.00001, loss_test:0.06454, lr:8.35e-03, fs:0.85714 (r=0.758,p=0.987),  time:24.967, tt:2222.025\n",
      "Ep:89, loss:0.00001, loss_test:0.06472, lr:8.26e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.921, tt:2242.870\n",
      "Ep:90, loss:0.00001, loss_test:0.06541, lr:8.18e-03, fs:0.84393 (r=0.737,p=0.986),  time:24.876, tt:2263.672\n",
      "Ep:91, loss:0.00001, loss_test:0.06477, lr:8.10e-03, fs:0.88764 (r=0.798,p=1.000),  time:24.815, tt:2283.000\n",
      "Ep:92, loss:0.00001, loss_test:0.06594, lr:8.02e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.807, tt:2307.028\n",
      "Ep:93, loss:0.00001, loss_test:0.06574, lr:7.94e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.766, tt:2328.012\n",
      "Ep:94, loss:0.00001, loss_test:0.06507, lr:7.86e-03, fs:0.84393 (r=0.737,p=0.986),  time:24.729, tt:2349.224\n",
      "Ep:95, loss:0.00001, loss_test:0.06532, lr:7.78e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.699, tt:2371.089\n",
      "Ep:96, loss:0.00001, loss_test:0.06574, lr:7.70e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.725, tt:2398.357\n",
      "Ep:97, loss:0.00001, loss_test:0.06567, lr:7.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:24.717, tt:2422.296\n",
      "Ep:98, loss:0.00001, loss_test:0.06710, lr:7.55e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.711, tt:2446.356\n",
      "Ep:99, loss:0.00001, loss_test:0.06619, lr:7.47e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.698, tt:2469.815\n",
      "Ep:100, loss:0.00001, loss_test:0.06615, lr:7.40e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.698, tt:2494.514\n",
      "Ep:101, loss:0.00001, loss_test:0.06626, lr:7.32e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.711, tt:2520.477\n",
      "Ep:102, loss:0.00001, loss_test:0.06715, lr:7.25e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.711, tt:2545.226\n",
      "Ep:103, loss:0.00001, loss_test:0.06550, lr:7.18e-03, fs:0.86207 (r=0.758,p=1.000),  time:24.731, tt:2571.985\n",
      "Ep:104, loss:0.00001, loss_test:0.06697, lr:7.11e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.750, tt:2598.719\n",
      "Ep:105, loss:0.00001, loss_test:0.06653, lr:7.03e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.755, tt:2624.066\n",
      "Ep:106, loss:0.00001, loss_test:0.06773, lr:6.96e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.753, tt:2648.610\n",
      "Ep:107, loss:0.00001, loss_test:0.06645, lr:6.89e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.739, tt:2671.838\n",
      "Ep:108, loss:0.00001, loss_test:0.06752, lr:6.83e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.755, tt:2698.309\n",
      "Ep:109, loss:0.00001, loss_test:0.06736, lr:6.76e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.750, tt:2722.504\n",
      "Ep:110, loss:0.00001, loss_test:0.06803, lr:6.69e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.741, tt:2746.216\n",
      "Ep:111, loss:0.00001, loss_test:0.06885, lr:6.62e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.735, tt:2770.305\n",
      "Ep:112, loss:0.00001, loss_test:0.06684, lr:6.56e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.729, tt:2794.412\n",
      "Ep:113, loss:0.00001, loss_test:0.06783, lr:6.49e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.724, tt:2818.540\n",
      "Ep:114, loss:0.00001, loss_test:0.06705, lr:6.43e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.717, tt:2842.497\n",
      "Ep:115, loss:0.00001, loss_test:0.06842, lr:6.36e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.699, tt:2865.089\n",
      "Ep:116, loss:0.00001, loss_test:0.06709, lr:6.30e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.700, tt:2889.919\n",
      "Ep:117, loss:0.00001, loss_test:0.06879, lr:6.24e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.711, tt:2915.929\n",
      "Ep:118, loss:0.00001, loss_test:0.06759, lr:6.17e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.709, tt:2940.325\n",
      "Ep:119, loss:0.00001, loss_test:0.06850, lr:6.11e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.708, tt:2965.010\n",
      "Ep:120, loss:0.00001, loss_test:0.06831, lr:6.05e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.704, tt:2989.242\n",
      "Ep:121, loss:0.00001, loss_test:0.06916, lr:5.99e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.697, tt:3013.019\n",
      "Ep:122, loss:0.00001, loss_test:0.06932, lr:5.93e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.688, tt:3036.602\n",
      "Ep:123, loss:0.00000, loss_test:0.07034, lr:5.87e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.682, tt:3060.590\n",
      "Ep:124, loss:0.00000, loss_test:0.06865, lr:5.81e-03, fs:0.83529 (r=0.717,p=1.000),  time:24.679, tt:3084.913\n",
      "Ep:125, loss:0.00000, loss_test:0.06968, lr:5.75e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.663, tt:3107.494\n",
      "Ep:126, loss:0.00000, loss_test:0.06896, lr:5.70e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.659, tt:3131.753\n",
      "Ep:127, loss:0.00000, loss_test:0.06960, lr:5.64e-03, fs:0.83529 (r=0.717,p=1.000),  time:24.658, tt:3156.195\n",
      "Ep:128, loss:0.00000, loss_test:0.06995, lr:5.58e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.651, tt:3179.922\n",
      "Ep:129, loss:0.00000, loss_test:0.06911, lr:5.53e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.655, tt:3205.099\n",
      "Ep:130, loss:0.00000, loss_test:0.06971, lr:5.47e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.652, tt:3229.410\n",
      "Ep:131, loss:0.00000, loss_test:0.06954, lr:5.42e-03, fs:0.83529 (r=0.717,p=1.000),  time:24.638, tt:3252.198\n",
      "Ep:132, loss:0.00000, loss_test:0.06966, lr:5.36e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.633, tt:3276.192\n",
      "Ep:133, loss:0.00000, loss_test:0.06943, lr:5.31e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.638, tt:3301.535\n",
      "Ep:134, loss:0.00000, loss_test:0.06937, lr:5.26e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.622, tt:3323.935\n",
      "Ep:135, loss:0.00000, loss_test:0.06958, lr:5.20e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.618, tt:3348.042\n",
      "Ep:136, loss:0.00000, loss_test:0.07037, lr:5.15e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.620, tt:3372.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.06923, lr:5.10e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.626, tt:3398.398\n",
      "Ep:138, loss:0.00000, loss_test:0.06987, lr:5.05e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.629, tt:3423.384\n",
      "Ep:139, loss:0.00000, loss_test:0.07121, lr:5.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:24.629, tt:3448.009\n",
      "Ep:140, loss:0.00000, loss_test:0.06937, lr:4.95e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.627, tt:3472.357\n",
      "Ep:141, loss:0.00000, loss_test:0.06986, lr:4.90e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.637, tt:3498.405\n",
      "Ep:142, loss:0.00000, loss_test:0.07151, lr:4.85e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.646, tt:3524.318\n",
      "Ep:143, loss:0.00000, loss_test:0.07036, lr:4.80e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.631, tt:3546.817\n",
      "Ep:144, loss:0.00000, loss_test:0.07003, lr:4.75e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.629, tt:3571.246\n",
      "Ep:145, loss:0.00000, loss_test:0.06993, lr:4.71e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.631, tt:3596.077\n",
      "Ep:146, loss:0.00000, loss_test:0.07053, lr:4.66e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.624, tt:3619.774\n",
      "Ep:147, loss:0.00000, loss_test:0.07061, lr:4.61e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.617, tt:3643.327\n",
      "Ep:148, loss:0.00000, loss_test:0.07040, lr:4.57e-03, fs:0.80000 (r=0.667,p=1.000),  time:24.619, tt:3668.266\n",
      "Ep:149, loss:0.00000, loss_test:0.07131, lr:4.52e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.612, tt:3691.743\n",
      "Ep:150, loss:0.00000, loss_test:0.07014, lr:4.48e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.607, tt:3715.646\n",
      "Ep:151, loss:0.00000, loss_test:0.06996, lr:4.43e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.614, tt:3741.257\n",
      "Ep:152, loss:0.00000, loss_test:0.07116, lr:4.39e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.612, tt:3765.574\n",
      "Ep:153, loss:0.00000, loss_test:0.07087, lr:4.34e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.619, tt:3791.274\n",
      "Ep:154, loss:0.00000, loss_test:0.07018, lr:4.30e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.623, tt:3816.623\n",
      "Ep:155, loss:0.00000, loss_test:0.07028, lr:4.26e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.616, tt:3840.136\n",
      "Ep:156, loss:0.00000, loss_test:0.07130, lr:4.21e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.601, tt:3862.378\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14527, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.842, tt:23.842\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14418, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.390, tt:46.779\n",
      "Ep:2, loss:0.00028, loss_test:0.14234, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.744, tt:65.233\n",
      "Ep:3, loss:0.00027, loss_test:0.13888, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:22.622, tt:90.487\n",
      "Ep:4, loss:0.00026, loss_test:0.13348, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:23.124, tt:115.622\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.13029, lr:1.00e-02, fs:0.63200 (r=0.798,p=0.523),  time:23.313, tt:139.880\n",
      "Ep:6, loss:0.00024, loss_test:0.12819, lr:1.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:23.293, tt:163.052\n",
      "Ep:7, loss:0.00024, loss_test:0.12378, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:23.349, tt:186.793\n",
      "Ep:8, loss:0.00023, loss_test:0.12044, lr:1.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:23.489, tt:211.400\n",
      "Ep:9, loss:0.00022, loss_test:0.11580, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:23.635, tt:236.347\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11259, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:23.833, tt:262.168\n",
      "Ep:11, loss:0.00019, loss_test:0.11030, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:24.079, tt:288.944\n",
      "Ep:12, loss:0.00018, loss_test:0.10802, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:24.180, tt:314.342\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10652, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:24.091, tt:337.276\n",
      "Ep:14, loss:0.00017, loss_test:0.10406, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:24.177, tt:362.650\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.10173, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:24.224, tt:387.588\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09997, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:24.450, tt:415.656\n",
      "Ep:17, loss:0.00014, loss_test:0.09865, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:24.448, tt:440.063\n",
      "Ep:18, loss:0.00014, loss_test:0.09658, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:24.481, tt:465.139\n",
      "Ep:19, loss:0.00013, loss_test:0.09461, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:24.507, tt:490.135\n",
      "Ep:20, loss:0.00013, loss_test:0.09293, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:24.511, tt:514.731\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.09154, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:24.651, tt:542.333\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00011, loss_test:0.08990, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:24.655, tt:567.061\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08995, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:24.722, tt:593.329\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08772, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:24.653, tt:616.329\n",
      "Ep:25, loss:0.00010, loss_test:0.08636, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:24.693, tt:642.008\n",
      "Ep:26, loss:0.00010, loss_test:0.08529, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:24.663, tt:665.892\n",
      "Ep:27, loss:0.00009, loss_test:0.08316, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:24.641, tt:689.961\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.08316, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:24.635, tt:714.417\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.08160, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:24.581, tt:737.435\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.08141, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:24.558, tt:761.288\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.07936, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:24.526, tt:784.845\n",
      "Ep:32, loss:0.00007, loss_test:0.07954, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:24.538, tt:809.765\n",
      "Ep:33, loss:0.00007, loss_test:0.07830, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:24.530, tt:834.006\n",
      "Ep:34, loss:0.00007, loss_test:0.07809, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:24.526, tt:858.393\n",
      "Ep:35, loss:0.00006, loss_test:0.07700, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:24.458, tt:880.499\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.07663, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:24.523, tt:907.346\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.07514, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:24.484, tt:930.383\n",
      "Ep:38, loss:0.00006, loss_test:0.07364, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:24.465, tt:954.122\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07630, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:24.459, tt:978.374\n",
      "Ep:40, loss:0.00005, loss_test:0.07205, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:24.515, tt:1005.123\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.07698, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:24.496, tt:1028.835\n",
      "Ep:42, loss:0.00005, loss_test:0.07463, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.467, tt:1052.078\n",
      "Ep:43, loss:0.00004, loss_test:0.07199, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:24.492, tt:1077.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00004, loss_test:0.07659, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:24.473, tt:1101.279\n",
      "Ep:45, loss:0.00004, loss_test:0.07017, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:24.476, tt:1125.886\n",
      "Ep:46, loss:0.00004, loss_test:0.07582, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:24.442, tt:1148.797\n",
      "Ep:47, loss:0.00004, loss_test:0.06987, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:24.470, tt:1174.545\n",
      "Ep:48, loss:0.00004, loss_test:0.07285, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:24.465, tt:1198.782\n",
      "Ep:49, loss:0.00004, loss_test:0.06894, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:24.491, tt:1224.569\n",
      "Ep:50, loss:0.00003, loss_test:0.07257, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:24.455, tt:1247.195\n",
      "Ep:51, loss:0.00003, loss_test:0.06830, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:24.418, tt:1269.718\n",
      "Ep:52, loss:0.00003, loss_test:0.07207, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.397, tt:1293.049\n",
      "Ep:53, loss:0.00003, loss_test:0.06925, lr:9.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:24.395, tt:1317.338\n",
      "Ep:54, loss:0.00003, loss_test:0.07014, lr:9.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.428, tt:1343.565\n",
      "Ep:55, loss:0.00003, loss_test:0.06771, lr:9.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:24.384, tt:1365.500\n",
      "Ep:56, loss:0.00003, loss_test:0.07019, lr:9.51e-03, fs:0.82682 (r=0.747,p=0.925),  time:24.415, tt:1391.675\n",
      "Ep:57, loss:0.00003, loss_test:0.06618, lr:9.41e-03, fs:0.82222 (r=0.747,p=0.914),  time:24.461, tt:1418.728\n",
      "Ep:58, loss:0.00003, loss_test:0.07309, lr:9.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.466, tt:1443.508\n",
      "Ep:59, loss:0.00002, loss_test:0.06877, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.454, tt:1467.256\n",
      "Ep:60, loss:0.00002, loss_test:0.07079, lr:9.14e-03, fs:0.83146 (r=0.747,p=0.937),  time:24.495, tt:1494.171\n",
      "Ep:61, loss:0.00002, loss_test:0.07180, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.524, tt:1520.482\n",
      "Ep:62, loss:0.00002, loss_test:0.06728, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:24.511, tt:1544.167\n",
      "Ep:63, loss:0.00002, loss_test:0.07046, lr:8.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:24.482, tt:1566.863\n",
      "Ep:64, loss:0.00002, loss_test:0.06874, lr:8.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.469, tt:1590.484\n",
      "Ep:65, loss:0.00002, loss_test:0.07178, lr:8.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:24.483, tt:1615.885\n",
      "Ep:66, loss:0.00002, loss_test:0.07122, lr:8.60e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.486, tt:1640.592\n",
      "Ep:67, loss:0.00002, loss_test:0.06846, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.501, tt:1666.049\n",
      "Ep:68, loss:0.00002, loss_test:0.07237, lr:8.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.503, tt:1690.673\n",
      "Ep:69, loss:0.00002, loss_test:0.06993, lr:8.35e-03, fs:0.82286 (r=0.727,p=0.947),  time:24.513, tt:1715.930\n",
      "Ep:70, loss:0.00002, loss_test:0.07218, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:24.509, tt:1740.174\n",
      "Ep:71, loss:0.00002, loss_test:0.07388, lr:8.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.506, tt:1764.402\n",
      "Ep:72, loss:0.00002, loss_test:0.07109, lr:8.10e-03, fs:0.81609 (r=0.717,p=0.947),  time:24.502, tt:1788.642\n",
      "Ep:73, loss:0.00002, loss_test:0.07359, lr:8.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.504, tt:1813.299\n",
      "Ep:74, loss:0.00002, loss_test:0.07405, lr:7.94e-03, fs:0.78571 (r=0.667,p=0.957),  time:24.498, tt:1837.331\n",
      "Ep:75, loss:0.00002, loss_test:0.07076, lr:7.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.495, tt:1861.634\n",
      "Ep:76, loss:0.00002, loss_test:0.07523, lr:7.78e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.517, tt:1887.847\n",
      "Ep:77, loss:0.00002, loss_test:0.07475, lr:7.70e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.540, tt:1914.119\n",
      "Ep:78, loss:0.00002, loss_test:0.07297, lr:7.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.581, tt:1941.896\n",
      "Ep:79, loss:0.00001, loss_test:0.07641, lr:7.55e-03, fs:0.75610 (r=0.626,p=0.954),  time:24.570, tt:1965.610\n",
      "Ep:80, loss:0.00001, loss_test:0.07358, lr:7.47e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.595, tt:1992.214\n",
      "Ep:81, loss:0.00001, loss_test:0.07626, lr:7.40e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.588, tt:2016.179\n",
      "Ep:82, loss:0.00001, loss_test:0.07443, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.625, tt:2043.843\n",
      "Ep:83, loss:0.00001, loss_test:0.07739, lr:7.25e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.634, tt:2069.243\n",
      "Ep:84, loss:0.00001, loss_test:0.07729, lr:7.18e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.624, tt:2093.007\n",
      "Ep:85, loss:0.00001, loss_test:0.07682, lr:7.11e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.622, tt:2117.514\n",
      "Ep:86, loss:0.00001, loss_test:0.07643, lr:7.03e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.611, tt:2141.120\n",
      "Ep:87, loss:0.00001, loss_test:0.07819, lr:6.96e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.604, tt:2165.123\n",
      "Ep:88, loss:0.00001, loss_test:0.07744, lr:6.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.591, tt:2188.582\n",
      "Ep:89, loss:0.00001, loss_test:0.07876, lr:6.83e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.600, tt:2213.963\n",
      "Ep:90, loss:0.00001, loss_test:0.07833, lr:6.76e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.613, tt:2239.805\n",
      "Ep:91, loss:0.00001, loss_test:0.07721, lr:6.69e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.644, tt:2267.272\n",
      "Ep:92, loss:0.00001, loss_test:0.08183, lr:6.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.650, tt:2292.483\n",
      "Ep:93, loss:0.00001, loss_test:0.08003, lr:6.56e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.671, tt:2319.050\n",
      "Ep:94, loss:0.00001, loss_test:0.07857, lr:6.49e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.650, tt:2341.742\n",
      "Ep:95, loss:0.00001, loss_test:0.08103, lr:6.43e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.649, tt:2366.285\n",
      "Ep:96, loss:0.00001, loss_test:0.07937, lr:6.36e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.626, tt:2388.723\n",
      "Ep:97, loss:0.00001, loss_test:0.08066, lr:6.30e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.615, tt:2412.282\n",
      "Ep:98, loss:0.00001, loss_test:0.08107, lr:6.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.608, tt:2436.145\n",
      "Ep:99, loss:0.00001, loss_test:0.07912, lr:6.17e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.602, tt:2460.226\n",
      "Ep:100, loss:0.00001, loss_test:0.08089, lr:6.11e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.595, tt:2484.123\n",
      "Ep:101, loss:0.00001, loss_test:0.08347, lr:6.05e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.582, tt:2507.413\n",
      "Ep:102, loss:0.00001, loss_test:0.07968, lr:5.99e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.580, tt:2531.717\n",
      "Ep:103, loss:0.00001, loss_test:0.08070, lr:5.93e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.600, tt:2558.392\n",
      "Ep:104, loss:0.00001, loss_test:0.08029, lr:5.87e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.596, tt:2582.545\n",
      "Ep:105, loss:0.00001, loss_test:0.08151, lr:5.81e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.583, tt:2605.760\n",
      "Ep:106, loss:0.00001, loss_test:0.07991, lr:5.75e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.567, tt:2628.703\n",
      "Ep:107, loss:0.00001, loss_test:0.08110, lr:5.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.548, tt:2651.170\n",
      "Ep:108, loss:0.00001, loss_test:0.08106, lr:5.64e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.550, tt:2675.904\n",
      "Ep:109, loss:0.00001, loss_test:0.08336, lr:5.58e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.544, tt:2699.857\n",
      "Ep:110, loss:0.00001, loss_test:0.08015, lr:5.53e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.547, tt:2724.697\n",
      "Ep:111, loss:0.00001, loss_test:0.08150, lr:5.47e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.563, tt:2751.017\n",
      "Ep:112, loss:0.00001, loss_test:0.08142, lr:5.42e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.565, tt:2775.872\n",
      "Ep:113, loss:0.00001, loss_test:0.08062, lr:5.36e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.569, tt:2800.910\n",
      "Ep:114, loss:0.00001, loss_test:0.08334, lr:5.31e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.565, tt:2824.934\n",
      "Ep:115, loss:0.00001, loss_test:0.08110, lr:5.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.567, tt:2849.735\n",
      "Ep:116, loss:0.00001, loss_test:0.08233, lr:5.20e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.559, tt:2873.374\n",
      "Ep:117, loss:0.00001, loss_test:0.08303, lr:5.15e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.566, tt:2898.768\n",
      "Ep:118, loss:0.00001, loss_test:0.08183, lr:5.10e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.554, tt:2921.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00001, loss_test:0.08163, lr:5.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.540, tt:2944.760\n",
      "Ep:120, loss:0.00001, loss_test:0.08112, lr:5.00e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.536, tt:2968.899\n",
      "Ep:121, loss:0.00001, loss_test:0.08563, lr:4.95e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.520, tt:2991.463\n",
      "Ep:122, loss:0.00001, loss_test:0.08245, lr:4.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.531, tt:3017.294\n",
      "Ep:123, loss:0.00001, loss_test:0.08344, lr:4.85e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.523, tt:3040.904\n",
      "Ep:124, loss:0.00001, loss_test:0.08314, lr:4.80e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.519, tt:3064.846\n",
      "Ep:125, loss:0.00001, loss_test:0.08212, lr:4.75e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.522, tt:3089.722\n",
      "Ep:126, loss:0.00001, loss_test:0.08358, lr:4.71e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.524, tt:3114.507\n",
      "Ep:127, loss:0.00001, loss_test:0.08342, lr:4.66e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.526, tt:3139.378\n",
      "Ep:128, loss:0.00001, loss_test:0.08439, lr:4.61e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.522, tt:3163.398\n",
      "Ep:129, loss:0.00001, loss_test:0.08503, lr:4.57e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.525, tt:3188.295\n",
      "Ep:130, loss:0.00001, loss_test:0.08279, lr:4.52e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.533, tt:3213.863\n",
      "Ep:131, loss:0.00001, loss_test:0.08461, lr:4.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.531, tt:3238.076\n",
      "Ep:132, loss:0.00001, loss_test:0.08428, lr:4.43e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.523, tt:3261.503\n",
      "Ep:133, loss:0.00001, loss_test:0.08414, lr:4.39e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.534, tt:3287.583\n",
      "Ep:134, loss:0.00001, loss_test:0.08484, lr:4.34e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.539, tt:3312.750\n",
      "Ep:135, loss:0.00001, loss_test:0.08393, lr:4.30e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.556, tt:3339.623\n",
      "Ep:136, loss:0.00001, loss_test:0.08530, lr:4.26e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.552, tt:3363.570\n",
      "Ep:137, loss:0.00001, loss_test:0.08512, lr:4.21e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.555, tt:3388.635\n",
      "Ep:138, loss:0.00001, loss_test:0.08337, lr:4.17e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.543, tt:3411.485\n",
      "Ep:139, loss:0.00001, loss_test:0.08562, lr:4.13e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.548, tt:3436.701\n",
      "Ep:140, loss:0.00001, loss_test:0.08505, lr:4.09e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.556, tt:3462.341\n",
      "Ep:141, loss:0.00001, loss_test:0.08529, lr:4.05e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.552, tt:3486.373\n",
      "Ep:142, loss:0.00001, loss_test:0.08652, lr:4.01e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3511.100\n",
      "Ep:143, loss:0.00001, loss_test:0.08506, lr:3.97e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.555, tt:3535.906\n",
      "Ep:144, loss:0.00001, loss_test:0.08656, lr:3.93e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.557, tt:3560.765\n",
      "Ep:145, loss:0.00001, loss_test:0.08739, lr:3.89e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.548, tt:3584.077\n",
      "Ep:146, loss:0.00001, loss_test:0.08492, lr:3.85e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.556, tt:3609.750\n",
      "Ep:147, loss:0.00000, loss_test:0.08620, lr:3.81e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.555, tt:3634.134\n",
      "Ep:148, loss:0.00000, loss_test:0.08748, lr:3.77e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3658.445\n",
      "Ep:149, loss:0.00000, loss_test:0.08556, lr:3.73e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3682.889\n",
      "Ep:150, loss:0.00000, loss_test:0.08510, lr:3.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3707.499\n",
      "Ep:151, loss:0.00000, loss_test:0.08591, lr:3.66e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.554, tt:3732.194\n",
      "Ep:152, loss:0.00000, loss_test:0.08669, lr:3.62e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.549, tt:3756.057\n",
      "Ep:153, loss:0.00000, loss_test:0.08628, lr:3.59e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.549, tt:3780.494\n",
      "Ep:154, loss:0.00000, loss_test:0.08546, lr:3.55e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.542, tt:3803.986\n",
      "Ep:155, loss:0.00000, loss_test:0.08593, lr:3.52e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.536, tt:3827.673\n",
      "Ep:156, loss:0.00000, loss_test:0.08604, lr:3.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.537, tt:3852.289\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14128, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.903, tt:31.903\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13860, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:33.207, tt:66.413\n",
      "Ep:2, loss:0.00027, loss_test:0.13378, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:36.577, tt:109.731\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12721, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:37.758, tt:151.033\n",
      "Ep:4, loss:0.00025, loss_test:0.11725, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:38.159, tt:190.796\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.10973, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:38.924, tt:233.545\n",
      "Ep:6, loss:0.00022, loss_test:0.10825, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:39.515, tt:276.608\n",
      "Ep:7, loss:0.00022, loss_test:0.10743, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:40.102, tt:320.817\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10486, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:40.474, tt:364.270\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10319, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:40.730, tt:407.301\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10363, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.823, tt:449.056\n",
      "Ep:11, loss:0.00019, loss_test:0.10261, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:40.895, tt:490.736\n",
      "Ep:12, loss:0.00019, loss_test:0.10062, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:41.026, tt:533.343\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09973, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:41.216, tt:577.030\n",
      "Ep:14, loss:0.00018, loss_test:0.09787, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.359, tt:620.381\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09684, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:41.205, tt:659.286\n",
      "Ep:16, loss:0.00017, loss_test:0.09574, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:41.418, tt:704.109\n",
      "Ep:17, loss:0.00017, loss_test:0.09380, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:41.451, tt:746.113\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09248, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:41.625, tt:790.876\n",
      "Ep:19, loss:0.00016, loss_test:0.09171, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:41.576, tt:831.528\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08990, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:41.622, tt:874.068\n",
      "Ep:21, loss:0.00015, loss_test:0.08828, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.753, tt:918.572\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08716, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.849, tt:962.527\n",
      "Ep:23, loss:0.00015, loss_test:0.08616, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:41.863, tt:1004.713\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08573, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:41.897, tt:1047.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00014, loss_test:0.08511, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:42.014, tt:1092.364\n",
      "Ep:26, loss:0.00013, loss_test:0.08394, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:42.141, tt:1137.799\n",
      "Ep:27, loss:0.00013, loss_test:0.08420, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:42.104, tt:1178.918\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08263, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:42.126, tt:1221.659\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08301, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:42.134, tt:1264.010\n",
      "Ep:30, loss:0.00012, loss_test:0.08244, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:42.145, tt:1306.496\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08097, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:42.146, tt:1348.685\n",
      "Ep:32, loss:0.00012, loss_test:0.08093, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:42.119, tt:1389.928\n",
      "Ep:33, loss:0.00012, loss_test:0.08055, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:42.127, tt:1432.308\n",
      "Ep:34, loss:0.00011, loss_test:0.07826, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:42.113, tt:1473.964\n",
      "Ep:35, loss:0.00011, loss_test:0.08079, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:42.102, tt:1515.659\n",
      "Ep:36, loss:0.00011, loss_test:0.07757, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:42.132, tt:1558.878\n",
      "Ep:37, loss:0.00011, loss_test:0.07858, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:42.087, tt:1599.311\n",
      "Ep:38, loss:0.00010, loss_test:0.07813, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:42.125, tt:1642.866\n",
      "Ep:39, loss:0.00010, loss_test:0.07602, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:42.161, tt:1686.447\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07998, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:42.246, tt:1732.083\n",
      "Ep:41, loss:0.00010, loss_test:0.07573, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:42.273, tt:1775.471\n",
      "Ep:42, loss:0.00009, loss_test:0.07800, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:42.257, tt:1817.058\n",
      "Ep:43, loss:0.00009, loss_test:0.07584, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.238, tt:1858.486\n",
      "Ep:44, loss:0.00009, loss_test:0.07667, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:42.273, tt:1902.306\n",
      "Ep:45, loss:0.00009, loss_test:0.07558, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.256, tt:1943.755\n",
      "Ep:46, loss:0.00008, loss_test:0.07512, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:42.250, tt:1985.750\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07534, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:42.251, tt:2028.025\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.07436, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:42.251, tt:2070.304\n",
      "Ep:49, loss:0.00008, loss_test:0.07658, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:42.298, tt:2114.915\n",
      "Ep:50, loss:0.00008, loss_test:0.07598, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:42.273, tt:2155.910\n",
      "Ep:51, loss:0.00008, loss_test:0.07392, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:42.303, tt:2199.738\n",
      "Ep:52, loss:0.00008, loss_test:0.07174, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:42.335, tt:2243.742\n",
      "Ep:53, loss:0.00008, loss_test:0.07055, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:42.333, tt:2286.000\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07344, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:42.319, tt:2327.559\n",
      "Ep:55, loss:0.00007, loss_test:0.06989, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:42.307, tt:2369.191\n",
      "Ep:56, loss:0.00007, loss_test:0.07324, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:42.330, tt:2412.788\n",
      "Ep:57, loss:0.00007, loss_test:0.06854, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:42.310, tt:2453.963\n",
      "Ep:58, loss:0.00007, loss_test:0.07228, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:42.341, tt:2498.143\n",
      "Ep:59, loss:0.00006, loss_test:0.07097, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:42.346, tt:2540.741\n",
      "Ep:60, loss:0.00006, loss_test:0.07077, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:42.376, tt:2584.938\n",
      "Ep:61, loss:0.00006, loss_test:0.07137, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:42.404, tt:2629.053\n",
      "Ep:62, loss:0.00006, loss_test:0.07117, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.405, tt:2671.534\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.06995, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.407, tt:2714.018\n",
      "Ep:64, loss:0.00006, loss_test:0.07085, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:42.380, tt:2754.677\n",
      "Ep:65, loss:0.00006, loss_test:0.07023, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.400, tt:2798.408\n",
      "Ep:66, loss:0.00005, loss_test:0.07342, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:42.407, tt:2841.264\n",
      "Ep:67, loss:0.00005, loss_test:0.07117, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:42.433, tt:2885.426\n",
      "Ep:68, loss:0.00006, loss_test:0.06858, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:42.437, tt:2928.137\n",
      "Ep:69, loss:0.00005, loss_test:0.07749, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:42.448, tt:2971.349\n",
      "Ep:70, loss:0.00005, loss_test:0.06991, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:42.467, tt:3015.165\n",
      "Ep:71, loss:0.00005, loss_test:0.07539, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:42.484, tt:3058.884\n",
      "Ep:72, loss:0.00005, loss_test:0.06928, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:42.493, tt:3102.002\n",
      "Ep:73, loss:0.00005, loss_test:0.07235, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:42.531, tt:3147.294\n",
      "Ep:74, loss:0.00005, loss_test:0.07006, lr:9.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:42.524, tt:3189.306\n",
      "Ep:75, loss:0.00004, loss_test:0.07027, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:42.522, tt:3231.636\n",
      "Ep:76, loss:0.00004, loss_test:0.07047, lr:9.70e-03, fs:0.83333 (r=0.808,p=0.860),  time:42.579, tt:3278.606\n",
      "Ep:77, loss:0.00004, loss_test:0.06852, lr:9.61e-03, fs:0.82540 (r=0.788,p=0.867),  time:42.618, tt:3324.230\n",
      "Ep:78, loss:0.00004, loss_test:0.06978, lr:9.51e-03, fs:0.84211 (r=0.808,p=0.879),  time:42.654, tt:3369.673\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.06946, lr:9.51e-03, fs:0.82540 (r=0.788,p=0.867),  time:42.674, tt:3413.899\n",
      "Ep:80, loss:0.00004, loss_test:0.06914, lr:9.51e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.684, tt:3457.414\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00004, loss_test:0.06915, lr:9.51e-03, fs:0.81250 (r=0.788,p=0.839),  time:42.709, tt:3502.143\n",
      "Ep:82, loss:0.00004, loss_test:0.06791, lr:9.51e-03, fs:0.81675 (r=0.788,p=0.848),  time:42.725, tt:3546.140\n",
      "Ep:83, loss:0.00004, loss_test:0.07016, lr:9.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:42.732, tt:3589.484\n",
      "Ep:84, loss:0.00004, loss_test:0.06745, lr:9.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:42.734, tt:3632.379\n",
      "Ep:85, loss:0.00003, loss_test:0.07010, lr:9.51e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.737, tt:3675.390\n",
      "Ep:86, loss:0.00003, loss_test:0.06691, lr:9.51e-03, fs:0.84375 (r=0.818,p=0.871),  time:42.746, tt:3718.881\n",
      "Ep:87, loss:0.00003, loss_test:0.06811, lr:9.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.773, tt:3764.013\n",
      "Ep:88, loss:0.00003, loss_test:0.06672, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.776, tt:3807.033\n",
      "Ep:89, loss:0.00003, loss_test:0.06771, lr:9.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.790, tt:3851.116\n",
      "Ep:90, loss:0.00003, loss_test:0.06732, lr:9.51e-03, fs:0.84211 (r=0.808,p=0.879),  time:42.802, tt:3894.964\n",
      "Ep:91, loss:0.00003, loss_test:0.06646, lr:9.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.844, tt:3941.654\n",
      "Ep:92, loss:0.00003, loss_test:0.06723, lr:9.41e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.874, tt:3987.249\n",
      "Ep:93, loss:0.00003, loss_test:0.06529, lr:9.32e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.889, tt:4031.579\n",
      "Ep:94, loss:0.00003, loss_test:0.06990, lr:9.23e-03, fs:0.83516 (r=0.768,p=0.916),  time:42.874, tt:4073.074\n",
      "Ep:95, loss:0.00003, loss_test:0.06619, lr:9.14e-03, fs:0.84656 (r=0.808,p=0.889),  time:42.871, tt:4115.597\n",
      "Ep:96, loss:0.00003, loss_test:0.06904, lr:9.04e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.876, tt:4158.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00003, loss_test:0.06563, lr:8.95e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.894, tt:4203.633\n",
      "Ep:98, loss:0.00003, loss_test:0.06776, lr:8.86e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.930, tt:4250.048\n",
      "Ep:99, loss:0.00003, loss_test:0.06520, lr:8.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.928, tt:4292.784\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00003, loss_test:0.06663, lr:8.78e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.935, tt:4336.400\n",
      "Ep:101, loss:0.00003, loss_test:0.06651, lr:8.78e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.922, tt:4378.034\n",
      "Ep:102, loss:0.00002, loss_test:0.06676, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.919, tt:4420.618\n",
      "Ep:103, loss:0.00002, loss_test:0.06601, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.924, tt:4464.119\n",
      "Ep:104, loss:0.00002, loss_test:0.06706, lr:8.78e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.915, tt:4506.111\n",
      "Ep:105, loss:0.00002, loss_test:0.06589, lr:8.78e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.907, tt:4548.142\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.06725, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.898, tt:4590.073\n",
      "Ep:107, loss:0.00002, loss_test:0.06498, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.911, tt:4634.411\n",
      "Ep:108, loss:0.00002, loss_test:0.06709, lr:8.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.914, tt:4677.600\n",
      "Ep:109, loss:0.00002, loss_test:0.07066, lr:8.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.920, tt:4721.219\n",
      "Ep:110, loss:0.00002, loss_test:0.06550, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.937, tt:4766.059\n",
      "Ep:111, loss:0.00002, loss_test:0.06928, lr:8.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.946, tt:4809.910\n",
      "Ep:112, loss:0.00002, loss_test:0.06587, lr:8.78e-03, fs:0.85561 (r=0.808,p=0.909),  time:42.947, tt:4853.034\n",
      "Ep:113, loss:0.00002, loss_test:0.06981, lr:8.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.946, tt:4895.863\n",
      "Ep:114, loss:0.00002, loss_test:0.06538, lr:8.78e-03, fs:0.85561 (r=0.808,p=0.909),  time:42.930, tt:4936.926\n",
      "Ep:115, loss:0.00002, loss_test:0.06936, lr:8.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:42.931, tt:4980.016\n",
      "Ep:116, loss:0.00002, loss_test:0.06931, lr:8.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.929, tt:5022.718\n",
      "Ep:117, loss:0.00002, loss_test:0.06635, lr:8.69e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.946, tt:5067.621\n",
      "Ep:118, loss:0.00002, loss_test:0.07167, lr:8.60e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.935, tt:5109.323\n",
      "Ep:119, loss:0.00002, loss_test:0.06627, lr:8.51e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.959, tt:5155.022\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00002, loss_test:0.07180, lr:8.51e-03, fs:0.82682 (r=0.747,p=0.925),  time:42.948, tt:5196.693\n",
      "Ep:121, loss:0.00002, loss_test:0.06527, lr:8.51e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.943, tt:5239.089\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00002, loss_test:0.07201, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.935, tt:5281.065\n",
      "Ep:123, loss:0.00002, loss_test:0.06620, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.958, tt:5326.813\n",
      "Ep:124, loss:0.00002, loss_test:0.07133, lr:8.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.972, tt:5371.514\n",
      "Ep:125, loss:0.00002, loss_test:0.06680, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.963, tt:5413.296\n",
      "Ep:126, loss:0.00002, loss_test:0.07031, lr:8.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.969, tt:5457.059\n",
      "Ep:127, loss:0.00002, loss_test:0.06642, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.966, tt:5499.690\n",
      "Ep:128, loss:0.00002, loss_test:0.07078, lr:8.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.966, tt:5542.659\n",
      "Ep:129, loss:0.00002, loss_test:0.06746, lr:8.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.950, tt:5583.541\n",
      "Ep:130, loss:0.00002, loss_test:0.07057, lr:8.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.946, tt:5625.969\n",
      "Ep:131, loss:0.00002, loss_test:0.06934, lr:8.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.960, tt:5670.742\n",
      "Ep:132, loss:0.00002, loss_test:0.06864, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.967, tt:5714.607\n",
      "Ep:133, loss:0.00002, loss_test:0.06959, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.951, tt:5755.492\n",
      "Ep:134, loss:0.00002, loss_test:0.06862, lr:8.35e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.953, tt:5798.712\n",
      "Ep:135, loss:0.00002, loss_test:0.06899, lr:8.26e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.923, tt:5837.511\n",
      "Ep:136, loss:0.00002, loss_test:0.07007, lr:8.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.919, tt:5879.862\n",
      "Ep:137, loss:0.00002, loss_test:0.06799, lr:8.10e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.905, tt:5920.940\n",
      "Ep:138, loss:0.00002, loss_test:0.06941, lr:8.02e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.901, tt:5963.203\n",
      "Ep:139, loss:0.00002, loss_test:0.06904, lr:7.94e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.937, tt:6011.159\n",
      "Ep:140, loss:0.00002, loss_test:0.06973, lr:7.86e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.942, tt:6054.854\n",
      "Ep:141, loss:0.00001, loss_test:0.06869, lr:7.78e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.944, tt:6098.085\n",
      "Ep:142, loss:0.00001, loss_test:0.07079, lr:7.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.940, tt:6140.436\n",
      "Ep:143, loss:0.00001, loss_test:0.06669, lr:7.62e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.925, tt:6181.175\n",
      "Ep:144, loss:0.00002, loss_test:0.07294, lr:7.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:42.943, tt:6226.736\n",
      "Ep:145, loss:0.00002, loss_test:0.07012, lr:7.47e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.929, tt:6267.659\n",
      "Ep:146, loss:0.00001, loss_test:0.07120, lr:7.40e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.935, tt:6311.414\n",
      "Ep:147, loss:0.00001, loss_test:0.07380, lr:7.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:42.931, tt:6353.821\n",
      "Ep:148, loss:0.00001, loss_test:0.07123, lr:7.25e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.939, tt:6397.917\n",
      "Ep:149, loss:0.00001, loss_test:0.07151, lr:7.18e-03, fs:0.82486 (r=0.737,p=0.936),  time:42.939, tt:6440.843\n",
      "Ep:150, loss:0.00001, loss_test:0.07120, lr:7.11e-03, fs:0.82022 (r=0.737,p=0.924),  time:42.942, tt:6484.251\n",
      "Ep:151, loss:0.00001, loss_test:0.06941, lr:7.03e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.944, tt:6527.552\n",
      "Ep:152, loss:0.00001, loss_test:0.07197, lr:6.96e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.932, tt:6568.581\n",
      "Ep:153, loss:0.00001, loss_test:0.07045, lr:6.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.934, tt:6611.896\n",
      "Ep:154, loss:0.00001, loss_test:0.07071, lr:6.83e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.902, tt:6649.852\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14230, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.822, tt:34.822\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13958, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:37.463, tt:74.927\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13443, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:39.357, tt:118.071\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12719, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:40.473, tt:161.893\n",
      "Ep:4, loss:0.00024, loss_test:0.11844, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:40.724, tt:203.621\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11059, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:41.147, tt:246.880\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10852, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:41.307, tt:289.146\n",
      "Ep:7, loss:0.00021, loss_test:0.11057, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:41.494, tt:331.951\n",
      "Ep:8, loss:0.00020, loss_test:0.10782, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:41.551, tt:373.963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00020, loss_test:0.10493, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:41.568, tt:415.679\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10265, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:41.725, tt:458.970\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10201, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:41.801, tt:501.607\n",
      "Ep:12, loss:0.00018, loss_test:0.09966, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:41.798, tt:543.377\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09886, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:41.894, tt:586.516\n",
      "Ep:14, loss:0.00017, loss_test:0.09878, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:41.900, tt:628.495\n",
      "Ep:15, loss:0.00017, loss_test:0.09667, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:41.848, tt:669.563\n",
      "Ep:16, loss:0.00017, loss_test:0.09411, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:41.825, tt:711.024\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09295, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.870, tt:753.655\n",
      "Ep:18, loss:0.00016, loss_test:0.09205, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:41.903, tt:796.162\n",
      "Ep:19, loss:0.00015, loss_test:0.09066, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:41.981, tt:839.625\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09038, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:42.022, tt:882.460\n",
      "Ep:21, loss:0.00015, loss_test:0.08869, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:41.961, tt:923.144\n",
      "Ep:22, loss:0.00014, loss_test:0.08747, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:41.980, tt:965.539\n",
      "Ep:23, loss:0.00014, loss_test:0.08525, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:41.988, tt:1007.712\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08576, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:42.129, tt:1053.216\n",
      "Ep:25, loss:0.00013, loss_test:0.08352, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:42.186, tt:1096.834\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08392, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:42.227, tt:1140.117\n",
      "Ep:27, loss:0.00013, loss_test:0.08340, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:42.212, tt:1181.930\n",
      "Ep:28, loss:0.00012, loss_test:0.08095, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:42.245, tt:1225.097\n",
      "Ep:29, loss:0.00012, loss_test:0.08137, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:42.266, tt:1267.988\n",
      "Ep:30, loss:0.00012, loss_test:0.07869, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.276, tt:1310.556\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07969, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:42.265, tt:1352.482\n",
      "Ep:32, loss:0.00011, loss_test:0.07691, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.307, tt:1396.146\n",
      "Ep:33, loss:0.00011, loss_test:0.07733, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.319, tt:1438.833\n",
      "Ep:34, loss:0.00011, loss_test:0.07593, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.406, tt:1484.224\n",
      "Ep:35, loss:0.00010, loss_test:0.07628, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.346, tt:1524.447\n",
      "Ep:36, loss:0.00010, loss_test:0.07430, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:42.400, tt:1568.817\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07468, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.395, tt:1611.011\n",
      "Ep:38, loss:0.00010, loss_test:0.07397, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:42.414, tt:1654.130\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07391, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:42.401, tt:1696.041\n",
      "Ep:40, loss:0.00009, loss_test:0.07276, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:42.362, tt:1736.840\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07407, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:42.318, tt:1777.338\n",
      "Ep:42, loss:0.00009, loss_test:0.07158, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:42.318, tt:1819.664\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.07394, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:42.337, tt:1862.841\n",
      "Ep:44, loss:0.00009, loss_test:0.07119, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:42.332, tt:1904.957\n",
      "Ep:45, loss:0.00008, loss_test:0.07096, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:42.297, tt:1945.648\n",
      "Ep:46, loss:0.00008, loss_test:0.07341, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:42.339, tt:1989.932\n",
      "Ep:47, loss:0.00008, loss_test:0.07041, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:42.345, tt:2032.567\n",
      "Ep:48, loss:0.00008, loss_test:0.07467, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:42.350, tt:2075.162\n",
      "Ep:49, loss:0.00008, loss_test:0.06862, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:42.326, tt:2116.310\n",
      "Ep:50, loss:0.00008, loss_test:0.06843, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:42.358, tt:2160.251\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.06945, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:42.379, tt:2203.691\n",
      "Ep:52, loss:0.00007, loss_test:0.06867, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:42.403, tt:2247.369\n",
      "Ep:53, loss:0.00007, loss_test:0.08065, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:42.411, tt:2290.188\n",
      "Ep:54, loss:0.00008, loss_test:0.07134, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:42.403, tt:2332.152\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.07525, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:42.431, tt:2376.156\n",
      "Ep:56, loss:0.00008, loss_test:0.06878, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.408, tt:2417.262\n",
      "Ep:57, loss:0.00007, loss_test:0.06827, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:42.391, tt:2458.679\n",
      "Ep:58, loss:0.00007, loss_test:0.07825, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:42.388, tt:2500.879\n",
      "Ep:59, loss:0.00008, loss_test:0.06997, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:42.404, tt:2544.215\n",
      "Ep:60, loss:0.00007, loss_test:0.07271, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:42.405, tt:2586.716\n",
      "Ep:61, loss:0.00007, loss_test:0.06712, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:42.405, tt:2629.118\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.07293, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:42.400, tt:2671.230\n",
      "Ep:63, loss:0.00007, loss_test:0.06710, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:42.388, tt:2712.825\n",
      "Ep:64, loss:0.00006, loss_test:0.07060, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:42.382, tt:2754.821\n",
      "Ep:65, loss:0.00006, loss_test:0.06782, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:42.398, tt:2798.260\n",
      "Ep:66, loss:0.00006, loss_test:0.06830, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:42.380, tt:2839.476\n",
      "Ep:67, loss:0.00006, loss_test:0.06659, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:42.331, tt:2878.489\n",
      "Ep:68, loss:0.00005, loss_test:0.06970, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:42.246, tt:2914.991\n",
      "Ep:69, loss:0.00005, loss_test:0.06755, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:42.140, tt:2949.799\n",
      "Ep:70, loss:0.00005, loss_test:0.06863, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:42.110, tt:2989.783\n",
      "Ep:71, loss:0.00005, loss_test:0.06718, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:42.126, tt:3033.097\n",
      "Ep:72, loss:0.00005, loss_test:0.07255, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:42.115, tt:3074.360\n",
      "Ep:73, loss:0.00005, loss_test:0.06617, lr:9.90e-03, fs:0.87685 (r=0.899,p=0.856),  time:42.129, tt:3117.570\n",
      "Ep:74, loss:0.00005, loss_test:0.06940, lr:9.80e-03, fs:0.87179 (r=0.859,p=0.885),  time:42.134, tt:3160.034\n",
      "Ep:75, loss:0.00005, loss_test:0.06888, lr:9.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:42.153, tt:3203.628\n",
      "Ep:76, loss:0.00005, loss_test:0.07319, lr:9.61e-03, fs:0.86275 (r=0.889,p=0.838),  time:42.168, tt:3246.943\n",
      "Ep:77, loss:0.00005, loss_test:0.06610, lr:9.51e-03, fs:0.81319 (r=0.747,p=0.892),  time:42.168, tt:3289.114\n",
      "Ep:78, loss:0.00005, loss_test:0.06799, lr:9.41e-03, fs:0.77348 (r=0.707,p=0.854),  time:42.148, tt:3329.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00005, loss_test:0.06846, lr:9.32e-03, fs:0.87562 (r=0.889,p=0.863),  time:42.148, tt:3371.822\n",
      "Ep:80, loss:0.00005, loss_test:0.07292, lr:9.23e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.185, tt:3416.969\n",
      "Ep:81, loss:0.00005, loss_test:0.06574, lr:9.14e-03, fs:0.86010 (r=0.838,p=0.883),  time:42.189, tt:3459.508\n",
      "Ep:82, loss:0.00004, loss_test:0.06859, lr:9.04e-03, fs:0.80874 (r=0.747,p=0.881),  time:42.183, tt:3501.208\n",
      "Ep:83, loss:0.00004, loss_test:0.06807, lr:8.95e-03, fs:0.77778 (r=0.707,p=0.864),  time:42.165, tt:3541.852\n",
      "Ep:84, loss:0.00004, loss_test:0.06823, lr:8.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.160, tt:3583.595\n",
      "Ep:85, loss:0.00004, loss_test:0.06816, lr:8.78e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.188, tt:3628.211\n",
      "Ep:86, loss:0.00004, loss_test:0.06857, lr:8.69e-03, fs:0.78212 (r=0.707,p=0.875),  time:42.187, tt:3670.246\n",
      "Ep:87, loss:0.00004, loss_test:0.06706, lr:8.60e-03, fs:0.79558 (r=0.727,p=0.878),  time:42.176, tt:3711.485\n",
      "Ep:88, loss:0.00004, loss_test:0.06780, lr:8.51e-03, fs:0.78889 (r=0.717,p=0.877),  time:42.184, tt:3754.401\n",
      "Ep:89, loss:0.00004, loss_test:0.06864, lr:8.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.170, tt:3795.289\n",
      "Ep:90, loss:0.00004, loss_test:0.06785, lr:8.35e-03, fs:0.84974 (r=0.828,p=0.872),  time:42.171, tt:3837.520\n",
      "Ep:91, loss:0.00004, loss_test:0.06815, lr:8.26e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.181, tt:3880.687\n",
      "Ep:92, loss:0.00004, loss_test:0.06795, lr:8.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.175, tt:3922.275\n",
      "Ep:93, loss:0.00003, loss_test:0.06998, lr:8.10e-03, fs:0.80663 (r=0.737,p=0.890),  time:42.157, tt:3962.760\n",
      "Ep:94, loss:0.00003, loss_test:0.06673, lr:8.02e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.166, tt:4005.792\n",
      "Ep:95, loss:0.00003, loss_test:0.06912, lr:7.94e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.165, tt:4047.836\n",
      "Ep:96, loss:0.00003, loss_test:0.06869, lr:7.86e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.167, tt:4090.162\n",
      "Ep:97, loss:0.00003, loss_test:0.06803, lr:7.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.153, tt:4131.042\n",
      "Ep:98, loss:0.00003, loss_test:0.06688, lr:7.70e-03, fs:0.80220 (r=0.737,p=0.880),  time:42.142, tt:4172.036\n",
      "Ep:99, loss:0.00003, loss_test:0.06885, lr:7.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.139, tt:4213.923\n",
      "Ep:100, loss:0.00003, loss_test:0.06788, lr:7.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.161, tt:4258.224\n",
      "Ep:101, loss:0.00003, loss_test:0.06850, lr:7.47e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.167, tt:4301.084\n",
      "Ep:102, loss:0.00003, loss_test:0.06747, lr:7.40e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.180, tt:4344.520\n",
      "Ep:103, loss:0.00003, loss_test:0.06879, lr:7.32e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.198, tt:4388.612\n",
      "Ep:104, loss:0.00003, loss_test:0.06871, lr:7.25e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.217, tt:4432.751\n",
      "Ep:105, loss:0.00003, loss_test:0.06826, lr:7.18e-03, fs:0.76836 (r=0.687,p=0.872),  time:42.243, tt:4477.786\n",
      "Ep:106, loss:0.00003, loss_test:0.06890, lr:7.11e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.243, tt:4520.054\n",
      "Ep:107, loss:0.00003, loss_test:0.06787, lr:7.03e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.242, tt:4562.185\n",
      "Ep:108, loss:0.00003, loss_test:0.06859, lr:6.96e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.244, tt:4604.613\n",
      "Ep:109, loss:0.00003, loss_test:0.06860, lr:6.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.229, tt:4645.184\n",
      "Ep:110, loss:0.00003, loss_test:0.06866, lr:6.83e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.267, tt:4691.684\n",
      "Ep:111, loss:0.00003, loss_test:0.06771, lr:6.76e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.299, tt:4737.516\n",
      "Ep:112, loss:0.00003, loss_test:0.06844, lr:6.69e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.329, tt:4783.223\n",
      "Ep:113, loss:0.00003, loss_test:0.06783, lr:6.62e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.335, tt:4826.180\n",
      "Ep:114, loss:0.00003, loss_test:0.06872, lr:6.56e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.333, tt:4868.335\n",
      "Ep:115, loss:0.00003, loss_test:0.06872, lr:6.49e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.337, tt:4911.050\n",
      "Ep:116, loss:0.00003, loss_test:0.06904, lr:6.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.333, tt:4952.971\n",
      "Ep:117, loss:0.00003, loss_test:0.06907, lr:6.36e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.325, tt:4994.334\n",
      "Ep:118, loss:0.00003, loss_test:0.06832, lr:6.30e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.303, tt:5034.098\n",
      "Ep:119, loss:0.00002, loss_test:0.06987, lr:6.24e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.307, tt:5076.803\n",
      "Ep:120, loss:0.00002, loss_test:0.06774, lr:6.17e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.307, tt:5119.178\n",
      "Ep:121, loss:0.00002, loss_test:0.06863, lr:6.11e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.312, tt:5162.063\n",
      "Ep:122, loss:0.00002, loss_test:0.06953, lr:6.05e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.312, tt:5204.426\n",
      "Ep:123, loss:0.00002, loss_test:0.06823, lr:5.99e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.298, tt:5244.968\n",
      "Ep:124, loss:0.00002, loss_test:0.06860, lr:5.93e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.300, tt:5287.499\n",
      "Ep:125, loss:0.00002, loss_test:0.06821, lr:5.87e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.294, tt:5329.078\n",
      "Ep:126, loss:0.00002, loss_test:0.06893, lr:5.81e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.311, tt:5373.474\n",
      "Ep:127, loss:0.00002, loss_test:0.06944, lr:5.75e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.307, tt:5415.319\n",
      "Ep:128, loss:0.00002, loss_test:0.06904, lr:5.70e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.312, tt:5458.271\n",
      "Ep:129, loss:0.00002, loss_test:0.06954, lr:5.64e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.329, tt:5502.799\n",
      "Ep:130, loss:0.00002, loss_test:0.06853, lr:5.58e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.347, tt:5547.442\n",
      "Ep:131, loss:0.00002, loss_test:0.06923, lr:5.53e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.357, tt:5591.066\n",
      "Ep:132, loss:0.00002, loss_test:0.06949, lr:5.47e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.345, tt:5631.929\n",
      "Ep:133, loss:0.00002, loss_test:0.07012, lr:5.42e-03, fs:0.80226 (r=0.717,p=0.910),  time:42.337, tt:5673.212\n",
      "Ep:134, loss:0.00002, loss_test:0.06716, lr:5.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.336, tt:5715.395\n",
      "Ep:135, loss:0.00002, loss_test:0.07020, lr:5.31e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.345, tt:5758.863\n",
      "Ep:136, loss:0.00002, loss_test:0.06922, lr:5.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.365, tt:5804.046\n",
      "Ep:137, loss:0.00002, loss_test:0.06860, lr:5.20e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.350, tt:5844.345\n",
      "Ep:138, loss:0.00002, loss_test:0.06843, lr:5.15e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.364, tt:5888.609\n",
      "Ep:139, loss:0.00002, loss_test:0.06939, lr:5.10e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.358, tt:5930.180\n",
      "Ep:140, loss:0.00002, loss_test:0.06842, lr:5.05e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.362, tt:5972.995\n",
      "Ep:141, loss:0.00002, loss_test:0.06905, lr:5.00e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.368, tt:6016.287\n",
      "Ep:142, loss:0.00002, loss_test:0.06881, lr:4.95e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.357, tt:6057.019\n",
      "Ep:143, loss:0.00002, loss_test:0.06938, lr:4.90e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.350, tt:6098.347\n",
      "Ep:144, loss:0.00002, loss_test:0.06908, lr:4.85e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.350, tt:6140.681\n",
      "Ep:145, loss:0.00002, loss_test:0.06905, lr:4.80e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.358, tt:6184.231\n",
      "Ep:146, loss:0.00002, loss_test:0.06888, lr:4.75e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.356, tt:6226.366\n",
      "Ep:147, loss:0.00002, loss_test:0.06893, lr:4.71e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.370, tt:6270.833\n",
      "Ep:148, loss:0.00002, loss_test:0.06972, lr:4.66e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.376, tt:6314.067\n",
      "Ep:149, loss:0.00002, loss_test:0.06852, lr:4.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.377, tt:6356.546\n",
      "Ep:150, loss:0.00002, loss_test:0.06995, lr:4.57e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.369, tt:6397.734\n",
      "Ep:151, loss:0.00002, loss_test:0.06927, lr:4.52e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.363, tt:6439.245\n",
      "Ep:152, loss:0.00002, loss_test:0.06896, lr:4.48e-03, fs:0.79545 (r=0.707,p=0.909),  time:42.363, tt:6481.489\n",
      "Ep:153, loss:0.00002, loss_test:0.06939, lr:4.43e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.360, tt:6523.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00002, loss_test:0.06923, lr:4.39e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.336, tt:6562.115\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14054, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:14.363, tt:14.363\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13810, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:14.784, tt:29.569\n",
      "Ep:2, loss:0.00027, loss_test:0.13535, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:14.426, tt:43.277\n",
      "Ep:3, loss:0.00026, loss_test:0.13333, lr:1.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:15.848, tt:63.393\n",
      "Ep:4, loss:0.00025, loss_test:0.12981, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:16.611, tt:83.055\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12527, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:16.640, tt:99.840\n",
      "Ep:6, loss:0.00024, loss_test:0.12155, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:17.190, tt:120.333\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11921, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:17.250, tt:137.999\n",
      "Ep:8, loss:0.00023, loss_test:0.11686, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:17.538, tt:157.843\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11327, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:17.637, tt:176.367\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11000, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:17.622, tt:193.840\n",
      "Ep:11, loss:0.00021, loss_test:0.10747, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:17.567, tt:210.806\n",
      "Ep:12, loss:0.00021, loss_test:0.10515, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:17.624, tt:229.117\n",
      "Ep:13, loss:0.00020, loss_test:0.10209, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:17.707, tt:247.897\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09946, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:17.735, tt:266.021\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09570, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:17.631, tt:282.101\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09333, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:17.580, tt:298.865\n",
      "Ep:17, loss:0.00017, loss_test:0.09108, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:17.481, tt:314.664\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08797, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:17.567, tt:333.773\n",
      "Ep:19, loss:0.00016, loss_test:0.08645, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:17.574, tt:351.487\n",
      "Ep:20, loss:0.00016, loss_test:0.08485, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:17.546, tt:368.456\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08358, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:17.514, tt:385.304\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08360, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:17.504, tt:402.592\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08260, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:17.608, tt:422.590\n",
      "Ep:24, loss:0.00014, loss_test:0.08110, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:17.666, tt:441.654\n",
      "Ep:25, loss:0.00013, loss_test:0.08076, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:17.610, tt:457.854\n",
      "Ep:26, loss:0.00013, loss_test:0.07986, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:17.628, tt:475.953\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07952, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:17.627, tt:493.545\n",
      "Ep:28, loss:0.00012, loss_test:0.07728, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:17.706, tt:513.466\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07900, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:17.797, tt:533.917\n",
      "Ep:30, loss:0.00011, loss_test:0.07613, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:17.727, tt:549.541\n",
      "Ep:31, loss:0.00011, loss_test:0.07582, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:17.769, tt:568.598\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07322, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:17.785, tt:586.915\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07381, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:17.742, tt:603.222\n",
      "Ep:34, loss:0.00010, loss_test:0.07086, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:17.797, tt:622.902\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07200, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:17.786, tt:640.290\n",
      "Ep:36, loss:0.00009, loss_test:0.06752, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.807, tt:658.875\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07320, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:17.861, tt:678.728\n",
      "Ep:38, loss:0.00009, loss_test:0.06603, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:17.883, tt:697.454\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.06950, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:17.885, tt:715.412\n",
      "Ep:40, loss:0.00008, loss_test:0.06753, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:17.854, tt:732.032\n",
      "Ep:41, loss:0.00008, loss_test:0.06750, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:17.854, tt:749.866\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.06537, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:17.837, tt:766.973\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06792, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:17.840, tt:784.944\n",
      "Ep:44, loss:0.00007, loss_test:0.06259, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:17.862, tt:803.796\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.06411, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:17.822, tt:819.825\n",
      "Ep:46, loss:0.00007, loss_test:0.06370, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:17.847, tt:838.816\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.06188, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:17.851, tt:856.849\n",
      "Ep:48, loss:0.00006, loss_test:0.06800, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:17.829, tt:873.620\n",
      "Ep:49, loss:0.00006, loss_test:0.06073, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:17.805, tt:890.248\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07013, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:17.780, tt:906.759\n",
      "Ep:51, loss:0.00006, loss_test:0.06431, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:17.802, tt:925.703\n",
      "Ep:52, loss:0.00006, loss_test:0.06330, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:17.811, tt:943.990\n",
      "Ep:53, loss:0.00006, loss_test:0.06800, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:17.783, tt:960.257\n",
      "Ep:54, loss:0.00005, loss_test:0.06144, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:17.799, tt:978.945\n",
      "Ep:55, loss:0.00005, loss_test:0.06562, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:17.821, tt:997.994\n",
      "Ep:56, loss:0.00005, loss_test:0.05880, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:17.908, tt:1020.779\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.06976, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:17.972, tt:1042.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00005, loss_test:0.05783, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:18.012, tt:1062.717\n",
      "Ep:59, loss:0.00005, loss_test:0.06349, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:18.041, tt:1082.447\n",
      "Ep:60, loss:0.00004, loss_test:0.05982, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:18.007, tt:1098.410\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.06409, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:18.027, tt:1117.687\n",
      "Ep:62, loss:0.00004, loss_test:0.05789, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:18.017, tt:1135.095\n",
      "Ep:63, loss:0.00004, loss_test:0.06263, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:18.016, tt:1153.010\n",
      "Ep:64, loss:0.00004, loss_test:0.06954, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:18.048, tt:1173.145\n",
      "Ep:65, loss:0.00004, loss_test:0.05589, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:18.020, tt:1189.333\n",
      "Ep:66, loss:0.00004, loss_test:0.07176, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:18.019, tt:1207.260\n",
      "Ep:67, loss:0.00004, loss_test:0.05542, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.997, tt:1223.809\n",
      "Ep:68, loss:0.00004, loss_test:0.06460, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:17.980, tt:1240.612\n",
      "Ep:69, loss:0.00004, loss_test:0.06312, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:17.970, tt:1257.887\n",
      "Ep:70, loss:0.00003, loss_test:0.06157, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.945, tt:1274.092\n",
      "Ep:71, loss:0.00003, loss_test:0.06121, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:17.942, tt:1291.812\n",
      "Ep:72, loss:0.00003, loss_test:0.06230, lr:9.90e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.937, tt:1309.411\n",
      "Ep:73, loss:0.00003, loss_test:0.05952, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.931, tt:1326.870\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00003, loss_test:0.06079, lr:9.80e-03, fs:0.85561 (r=0.808,p=0.909),  time:17.922, tt:1344.178\n",
      "Ep:75, loss:0.00003, loss_test:0.06211, lr:9.80e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.913, tt:1361.393\n",
      "Ep:76, loss:0.00003, loss_test:0.06000, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.947, tt:1381.901\n",
      "Ep:77, loss:0.00003, loss_test:0.06169, lr:9.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:17.947, tt:1399.882\n",
      "Ep:78, loss:0.00003, loss_test:0.05998, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.924, tt:1415.978\n",
      "Ep:79, loss:0.00003, loss_test:0.05865, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.944, tt:1435.491\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.06010, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.927, tt:1452.081\n",
      "Ep:81, loss:0.00002, loss_test:0.06092, lr:9.80e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.924, tt:1469.739\n",
      "Ep:82, loss:0.00002, loss_test:0.06011, lr:9.80e-03, fs:0.86486 (r=0.808,p=0.930),  time:17.935, tt:1488.589\n",
      "Ep:83, loss:0.00002, loss_test:0.06725, lr:9.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:17.913, tt:1504.713\n",
      "Ep:84, loss:0.00002, loss_test:0.05549, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.899, tt:1521.435\n",
      "Ep:85, loss:0.00002, loss_test:0.06310, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:17.875, tt:1537.244\n",
      "Ep:86, loss:0.00002, loss_test:0.05584, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.884, tt:1555.881\n",
      "Ep:87, loss:0.00002, loss_test:0.06584, lr:9.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:17.881, tt:1573.566\n",
      "Ep:88, loss:0.00002, loss_test:0.05590, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.861, tt:1589.617\n",
      "Ep:89, loss:0.00002, loss_test:0.06226, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:17.851, tt:1606.617\n",
      "Ep:90, loss:0.00002, loss_test:0.05606, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.845, tt:1623.905\n",
      "Ep:91, loss:0.00002, loss_test:0.06296, lr:9.70e-03, fs:0.82682 (r=0.747,p=0.925),  time:17.827, tt:1640.096\n",
      "Ep:92, loss:0.00002, loss_test:0.05625, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.827, tt:1657.875\n",
      "Ep:93, loss:0.00002, loss_test:0.06189, lr:9.51e-03, fs:0.83978 (r=0.768,p=0.927),  time:17.812, tt:1674.288\n",
      "Ep:94, loss:0.00002, loss_test:0.05984, lr:9.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:17.826, tt:1693.488\n",
      "Ep:95, loss:0.00002, loss_test:0.06849, lr:9.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.852, tt:1713.818\n",
      "Ep:96, loss:0.00002, loss_test:0.05332, lr:9.23e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.830, tt:1729.497\n",
      "Ep:97, loss:0.00002, loss_test:0.06689, lr:9.14e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.825, tt:1746.828\n",
      "Ep:98, loss:0.00002, loss_test:0.06140, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.807, tt:1762.935\n",
      "Ep:99, loss:0.00002, loss_test:0.05723, lr:8.95e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.812, tt:1781.182\n",
      "Ep:100, loss:0.00002, loss_test:0.06518, lr:8.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.801, tt:1797.885\n",
      "Ep:101, loss:0.00002, loss_test:0.05623, lr:8.78e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.791, tt:1814.732\n",
      "Ep:102, loss:0.00002, loss_test:0.06997, lr:8.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.788, tt:1832.144\n",
      "Ep:103, loss:0.00002, loss_test:0.05555, lr:8.60e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.796, tt:1850.735\n",
      "Ep:104, loss:0.00002, loss_test:0.06793, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.792, tt:1868.193\n",
      "Ep:105, loss:0.00002, loss_test:0.05582, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.790, tt:1885.744\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.06201, lr:8.43e-03, fs:0.83516 (r=0.768,p=0.916),  time:17.775, tt:1901.882\n",
      "Ep:107, loss:0.00002, loss_test:0.06069, lr:8.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:17.770, tt:1919.161\n",
      "Ep:108, loss:0.00002, loss_test:0.05769, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:17.772, tt:1937.138\n",
      "Ep:109, loss:0.00002, loss_test:0.06163, lr:8.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:17.806, tt:1958.648\n",
      "Ep:110, loss:0.00002, loss_test:0.06048, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.880, tt:1984.656\n",
      "Ep:111, loss:0.00002, loss_test:0.05775, lr:8.43e-03, fs:0.89947 (r=0.859,p=0.944),  time:17.885, tt:2003.146\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00002, loss_test:0.06665, lr:8.43e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.904, tt:2023.133\n",
      "Ep:113, loss:0.00002, loss_test:0.05557, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.903, tt:2040.969\n",
      "Ep:114, loss:0.00002, loss_test:0.06196, lr:8.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.925, tt:2061.337\n",
      "Ep:115, loss:0.00002, loss_test:0.05745, lr:8.43e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.941, tt:2081.113\n",
      "Ep:116, loss:0.00001, loss_test:0.06193, lr:8.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:17.956, tt:2100.888\n",
      "Ep:117, loss:0.00002, loss_test:0.05488, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.950, tt:2118.107\n",
      "Ep:118, loss:0.00001, loss_test:0.06390, lr:8.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.952, tt:2136.317\n",
      "Ep:119, loss:0.00001, loss_test:0.05534, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.949, tt:2153.933\n",
      "Ep:120, loss:0.00001, loss_test:0.06368, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.950, tt:2171.997\n",
      "Ep:121, loss:0.00001, loss_test:0.05843, lr:8.43e-03, fs:0.83429 (r=0.737,p=0.961),  time:17.938, tt:2188.384\n",
      "Ep:122, loss:0.00001, loss_test:0.05722, lr:8.43e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.936, tt:2206.169\n",
      "Ep:123, loss:0.00001, loss_test:0.06003, lr:8.35e-03, fs:0.83429 (r=0.737,p=0.961),  time:17.928, tt:2223.091\n",
      "Ep:124, loss:0.00001, loss_test:0.05976, lr:8.26e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.924, tt:2240.483\n",
      "Ep:125, loss:0.00001, loss_test:0.05884, lr:8.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.926, tt:2258.652\n",
      "Ep:126, loss:0.00001, loss_test:0.06049, lr:8.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.921, tt:2275.916\n",
      "Ep:127, loss:0.00001, loss_test:0.05776, lr:8.02e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.923, tt:2294.195\n",
      "Ep:128, loss:0.00001, loss_test:0.05982, lr:7.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.901, tt:2309.196\n",
      "Ep:129, loss:0.00001, loss_test:0.05789, lr:7.86e-03, fs:0.86188 (r=0.788,p=0.951),  time:17.898, tt:2326.696\n",
      "Ep:130, loss:0.00001, loss_test:0.05909, lr:7.78e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.898, tt:2344.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.05871, lr:7.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.889, tt:2361.314\n",
      "Ep:132, loss:0.00001, loss_test:0.05681, lr:7.62e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.896, tt:2380.103\n",
      "Ep:133, loss:0.00001, loss_test:0.05680, lr:7.55e-03, fs:0.90323 (r=0.848,p=0.966),  time:17.879, tt:2395.756\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00001, loss_test:0.05967, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.863, tt:2411.513\n",
      "Ep:135, loss:0.00001, loss_test:0.05863, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.857, tt:2428.596\n",
      "Ep:136, loss:0.00001, loss_test:0.05812, lr:7.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.853, tt:2445.836\n",
      "Ep:137, loss:0.00001, loss_test:0.05916, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.861, tt:2464.801\n",
      "Ep:138, loss:0.00001, loss_test:0.05829, lr:7.55e-03, fs:0.84916 (r=0.768,p=0.950),  time:17.849, tt:2481.068\n",
      "Ep:139, loss:0.00001, loss_test:0.05799, lr:7.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.835, tt:2496.917\n",
      "Ep:140, loss:0.00001, loss_test:0.05889, lr:7.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.836, tt:2514.868\n",
      "Ep:141, loss:0.00001, loss_test:0.05765, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.829, tt:2531.707\n",
      "Ep:142, loss:0.00001, loss_test:0.05894, lr:7.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.830, tt:2549.620\n",
      "Ep:143, loss:0.00001, loss_test:0.05917, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.838, tt:2568.669\n",
      "Ep:144, loss:0.00001, loss_test:0.05766, lr:7.55e-03, fs:0.86188 (r=0.788,p=0.951),  time:17.836, tt:2586.205\n",
      "Ep:145, loss:0.00001, loss_test:0.06065, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.840, tt:2604.571\n",
      "Ep:146, loss:0.00001, loss_test:0.05693, lr:7.40e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.828, tt:2620.758\n",
      "Ep:147, loss:0.00001, loss_test:0.06095, lr:7.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.830, tt:2638.910\n",
      "Ep:148, loss:0.00001, loss_test:0.05807, lr:7.25e-03, fs:0.86813 (r=0.798,p=0.952),  time:17.827, tt:2656.231\n",
      "Ep:149, loss:0.00001, loss_test:0.05926, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.819, tt:2672.912\n",
      "Ep:150, loss:0.00001, loss_test:0.05847, lr:7.11e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.812, tt:2689.611\n",
      "Ep:151, loss:0.00001, loss_test:0.06321, lr:7.03e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.809, tt:2706.970\n",
      "Ep:152, loss:0.00001, loss_test:0.05629, lr:6.96e-03, fs:0.89247 (r=0.838,p=0.954),  time:17.822, tt:2726.819\n",
      "Ep:153, loss:0.00001, loss_test:0.06300, lr:6.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.831, tt:2745.958\n",
      "Ep:154, loss:0.00001, loss_test:0.05783, lr:6.83e-03, fs:0.88043 (r=0.818,p=0.953),  time:17.835, tt:2764.493\n",
      "Ep:155, loss:0.00001, loss_test:0.06251, lr:6.76e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.812, tt:2778.726\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14059, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:16.639, tt:16.639\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13789, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:16.767, tt:33.533\n",
      "Ep:2, loss:0.00027, loss_test:0.13362, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:15.348, tt:46.045\n",
      "Ep:3, loss:0.00026, loss_test:0.12978, lr:1.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:15.798, tt:63.192\n",
      "Ep:4, loss:0.00025, loss_test:0.12653, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:16.100, tt:80.502\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12341, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:16.562, tt:99.371\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11998, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:16.990, tt:118.928\n",
      "Ep:7, loss:0.00024, loss_test:0.11711, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:17.123, tt:136.983\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11402, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:17.230, tt:155.070\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11057, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:17.187, tt:171.872\n",
      "Ep:10, loss:0.00022, loss_test:0.10646, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:17.289, tt:190.180\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10252, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:17.621, tt:211.457\n",
      "Ep:12, loss:0.00020, loss_test:0.09898, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:17.536, tt:227.965\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09590, lr:1.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:17.610, tt:246.536\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09255, lr:1.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:17.501, tt:262.517\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.08983, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:17.437, tt:278.999\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08779, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:17.307, tt:294.224\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08538, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:17.087, tt:307.569\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08364, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:17.027, tt:323.504\n",
      "Ep:19, loss:0.00016, loss_test:0.08230, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:16.917, tt:338.340\n",
      "Ep:20, loss:0.00016, loss_test:0.08121, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:16.972, tt:356.415\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08013, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:17.060, tt:375.324\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07943, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:17.110, tt:393.524\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07897, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:17.190, tt:412.566\n",
      "Ep:24, loss:0.00014, loss_test:0.07831, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:17.202, tt:430.060\n",
      "Ep:25, loss:0.00013, loss_test:0.07750, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:17.243, tt:448.313\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07715, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:17.291, tt:466.846\n",
      "Ep:27, loss:0.00012, loss_test:0.07520, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:17.284, tt:483.965\n",
      "Ep:28, loss:0.00012, loss_test:0.07480, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:17.384, tt:504.125\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07336, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:17.555, tt:526.650\n",
      "Ep:30, loss:0.00011, loss_test:0.07170, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:17.636, tt:546.726\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07076, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:17.739, tt:567.651\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.06947, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:17.753, tt:585.846\n",
      "Ep:33, loss:0.00010, loss_test:0.06844, lr:1.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:17.755, tt:603.658\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06734, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:17.782, tt:622.371\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06611, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:17.809, tt:641.133\n",
      "Ep:36, loss:0.00009, loss_test:0.06447, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:17.811, tt:659.021\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:37, loss:0.00009, loss_test:0.06450, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:17.835, tt:677.715\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.06342, lr:1.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:17.865, tt:696.736\n",
      "Ep:39, loss:0.00008, loss_test:0.06329, lr:1.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:17.847, tt:713.888\n",
      "Ep:40, loss:0.00008, loss_test:0.06069, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:17.921, tt:734.744\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.06256, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:17.925, tt:752.862\n",
      "Ep:42, loss:0.00008, loss_test:0.05934, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:17.996, tt:773.825\n",
      "Ep:43, loss:0.00007, loss_test:0.06147, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:18.073, tt:795.209\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.06034, lr:1.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:18.054, tt:812.415\n",
      "Ep:45, loss:0.00007, loss_test:0.05979, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:18.043, tt:829.983\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.05975, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:18.059, tt:848.779\n",
      "Ep:47, loss:0.00007, loss_test:0.06508, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:18.050, tt:866.415\n",
      "Ep:48, loss:0.00007, loss_test:0.05669, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.071, tt:885.503\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.05869, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:18.065, tt:903.230\n",
      "Ep:50, loss:0.00006, loss_test:0.05884, lr:1.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:18.085, tt:922.357\n",
      "Ep:51, loss:0.00006, loss_test:0.05478, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:18.087, tt:940.514\n",
      "Ep:52, loss:0.00006, loss_test:0.05431, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:18.120, tt:960.354\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.05551, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:18.148, tt:979.994\n",
      "Ep:54, loss:0.00005, loss_test:0.05320, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:18.183, tt:1000.038\n",
      "Ep:55, loss:0.00005, loss_test:0.05420, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:18.205, tt:1019.469\n",
      "Ep:56, loss:0.00005, loss_test:0.05491, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:18.219, tt:1038.477\n",
      "Ep:57, loss:0.00005, loss_test:0.05359, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:18.247, tt:1058.354\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.05253, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.263, tt:1077.501\n",
      "Ep:59, loss:0.00005, loss_test:0.05989, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:18.274, tt:1096.434\n",
      "Ep:60, loss:0.00005, loss_test:0.05094, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.253, tt:1113.415\n",
      "Ep:61, loss:0.00005, loss_test:0.05479, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:18.290, tt:1133.954\n",
      "Ep:62, loss:0.00005, loss_test:0.05351, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.301, tt:1152.962\n",
      "Ep:63, loss:0.00004, loss_test:0.05220, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:18.326, tt:1172.873\n",
      "Ep:64, loss:0.00004, loss_test:0.04966, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:18.331, tt:1191.524\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00004, loss_test:0.05337, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:18.302, tt:1207.917\n",
      "Ep:66, loss:0.00004, loss_test:0.04967, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:18.295, tt:1225.743\n",
      "Ep:67, loss:0.00004, loss_test:0.04957, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:18.296, tt:1244.145\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.05436, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:18.280, tt:1261.344\n",
      "Ep:69, loss:0.00004, loss_test:0.05032, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:18.275, tt:1279.239\n",
      "Ep:70, loss:0.00004, loss_test:0.04966, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:18.281, tt:1297.963\n",
      "Ep:71, loss:0.00004, loss_test:0.05332, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:18.257, tt:1314.527\n",
      "Ep:72, loss:0.00004, loss_test:0.04893, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:18.246, tt:1331.979\n",
      "Ep:73, loss:0.00004, loss_test:0.05107, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:18.225, tt:1348.663\n",
      "Ep:74, loss:0.00004, loss_test:0.04855, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:18.255, tt:1369.139\n",
      "Ep:75, loss:0.00004, loss_test:0.05614, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:18.238, tt:1386.126\n",
      "Ep:76, loss:0.00003, loss_test:0.04710, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:18.224, tt:1403.229\n",
      "Ep:77, loss:0.00003, loss_test:0.05439, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:18.234, tt:1422.265\n",
      "Ep:78, loss:0.00003, loss_test:0.04681, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:18.229, tt:1440.128\n",
      "Ep:79, loss:0.00003, loss_test:0.05141, lr:9.90e-03, fs:0.90816 (r=0.899,p=0.918),  time:18.221, tt:1457.712\n",
      "Ep:80, loss:0.00003, loss_test:0.04760, lr:9.80e-03, fs:0.94472 (r=0.949,p=0.940),  time:18.231, tt:1476.695\n",
      "Ep:81, loss:0.00003, loss_test:0.04956, lr:9.70e-03, fs:0.91282 (r=0.899,p=0.927),  time:18.233, tt:1495.081\n",
      "Ep:82, loss:0.00003, loss_test:0.04538, lr:9.61e-03, fs:0.96552 (r=0.990,p=0.942),  time:18.229, tt:1513.009\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00003, loss_test:0.04714, lr:9.61e-03, fs:0.94000 (r=0.949,p=0.931),  time:18.212, tt:1529.840\n",
      "Ep:84, loss:0.00003, loss_test:0.04751, lr:9.61e-03, fs:0.91837 (r=0.909,p=0.928),  time:18.199, tt:1546.889\n",
      "Ep:85, loss:0.00003, loss_test:0.04516, lr:9.61e-03, fs:0.93939 (r=0.939,p=0.939),  time:18.226, tt:1567.465\n",
      "Ep:86, loss:0.00003, loss_test:0.04918, lr:9.61e-03, fs:0.90909 (r=0.909,p=0.909),  time:18.238, tt:1586.747\n",
      "Ep:87, loss:0.00003, loss_test:0.04524, lr:9.61e-03, fs:0.92929 (r=0.929,p=0.929),  time:18.232, tt:1604.403\n",
      "Ep:88, loss:0.00003, loss_test:0.04539, lr:9.61e-03, fs:0.91371 (r=0.909,p=0.918),  time:18.234, tt:1622.814\n",
      "Ep:89, loss:0.00003, loss_test:0.04771, lr:9.61e-03, fs:0.90052 (r=0.869,p=0.935),  time:18.233, tt:1640.973\n",
      "Ep:90, loss:0.00002, loss_test:0.04480, lr:9.61e-03, fs:0.92784 (r=0.909,p=0.947),  time:18.231, tt:1658.997\n",
      "Ep:91, loss:0.00002, loss_test:0.04876, lr:9.61e-03, fs:0.91192 (r=0.889,p=0.936),  time:18.238, tt:1677.892\n",
      "Ep:92, loss:0.00002, loss_test:0.04740, lr:9.61e-03, fs:0.90052 (r=0.869,p=0.935),  time:18.253, tt:1697.488\n",
      "Ep:93, loss:0.00002, loss_test:0.04480, lr:9.61e-03, fs:0.91192 (r=0.889,p=0.936),  time:18.265, tt:1716.945\n",
      "Ep:94, loss:0.00002, loss_test:0.04482, lr:9.51e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.270, tt:1735.643\n",
      "Ep:95, loss:0.00002, loss_test:0.05071, lr:9.41e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.293, tt:1756.118\n",
      "Ep:96, loss:0.00002, loss_test:0.04327, lr:9.32e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.330, tt:1778.050\n",
      "Ep:97, loss:0.00002, loss_test:0.04871, lr:9.23e-03, fs:0.90526 (r=0.869,p=0.945),  time:18.331, tt:1796.465\n",
      "Ep:98, loss:0.00002, loss_test:0.04330, lr:9.14e-03, fs:0.92308 (r=0.909,p=0.938),  time:18.336, tt:1815.263\n",
      "Ep:99, loss:0.00002, loss_test:0.04399, lr:9.04e-03, fs:0.93264 (r=0.909,p=0.957),  time:18.341, tt:1834.063\n",
      "Ep:100, loss:0.00002, loss_test:0.04774, lr:8.95e-03, fs:0.92228 (r=0.899,p=0.947),  time:18.343, tt:1852.604\n",
      "Ep:101, loss:0.00002, loss_test:0.04268, lr:8.86e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.343, tt:1870.951\n",
      "Ep:102, loss:0.00002, loss_test:0.04756, lr:8.78e-03, fs:0.91005 (r=0.869,p=0.956),  time:18.378, tt:1892.974\n",
      "Ep:103, loss:0.00002, loss_test:0.04329, lr:8.69e-03, fs:0.91667 (r=0.889,p=0.946),  time:18.405, tt:1914.157\n",
      "Ep:104, loss:0.00002, loss_test:0.04845, lr:8.60e-03, fs:0.90323 (r=0.848,p=0.966),  time:18.428, tt:1934.945\n",
      "Ep:105, loss:0.00002, loss_test:0.04296, lr:8.51e-03, fs:0.91192 (r=0.889,p=0.936),  time:18.432, tt:1953.756\n",
      "Ep:106, loss:0.00002, loss_test:0.04683, lr:8.43e-03, fs:0.90323 (r=0.848,p=0.966),  time:18.436, tt:1972.652\n",
      "Ep:107, loss:0.00002, loss_test:0.04387, lr:8.35e-03, fs:0.90426 (r=0.859,p=0.955),  time:18.438, tt:1991.265\n",
      "Ep:108, loss:0.00002, loss_test:0.04390, lr:8.26e-03, fs:0.90052 (r=0.869,p=0.935),  time:18.467, tt:2012.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00002, loss_test:0.04635, lr:8.18e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.464, tt:2031.080\n",
      "Ep:110, loss:0.00002, loss_test:0.04354, lr:8.10e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.471, tt:2050.311\n",
      "Ep:111, loss:0.00002, loss_test:0.04480, lr:8.02e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.470, tt:2068.627\n",
      "Ep:112, loss:0.00002, loss_test:0.04494, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.468, tt:2086.915\n",
      "Ep:113, loss:0.00002, loss_test:0.04469, lr:7.86e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.468, tt:2105.327\n",
      "Ep:114, loss:0.00002, loss_test:0.04339, lr:7.78e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.487, tt:2125.978\n",
      "Ep:115, loss:0.00002, loss_test:0.04784, lr:7.70e-03, fs:0.91489 (r=0.869,p=0.966),  time:18.496, tt:2145.545\n",
      "Ep:116, loss:0.00002, loss_test:0.04272, lr:7.62e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.494, tt:2163.822\n",
      "Ep:117, loss:0.00002, loss_test:0.04717, lr:7.55e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.497, tt:2182.613\n",
      "Ep:118, loss:0.00002, loss_test:0.04278, lr:7.47e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.499, tt:2201.377\n",
      "Ep:119, loss:0.00002, loss_test:0.04718, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.489, tt:2218.648\n",
      "Ep:120, loss:0.00002, loss_test:0.04342, lr:7.32e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.482, tt:2236.347\n",
      "Ep:121, loss:0.00002, loss_test:0.04626, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.502, tt:2257.239\n",
      "Ep:122, loss:0.00002, loss_test:0.04327, lr:7.18e-03, fs:0.90526 (r=0.869,p=0.945),  time:18.505, tt:2276.100\n",
      "Ep:123, loss:0.00002, loss_test:0.04633, lr:7.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.490, tt:2292.759\n",
      "Ep:124, loss:0.00002, loss_test:0.04284, lr:7.03e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.473, tt:2309.139\n",
      "Ep:125, loss:0.00002, loss_test:0.04866, lr:6.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.472, tt:2327.461\n",
      "Ep:126, loss:0.00002, loss_test:0.04264, lr:6.89e-03, fs:0.93333 (r=0.919,p=0.948),  time:18.476, tt:2346.412\n",
      "Ep:127, loss:0.00002, loss_test:0.04927, lr:6.83e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.503, tt:2368.404\n",
      "Ep:128, loss:0.00002, loss_test:0.04204, lr:6.76e-03, fs:0.92784 (r=0.909,p=0.947),  time:18.493, tt:2385.537\n",
      "Ep:129, loss:0.00001, loss_test:0.04720, lr:6.69e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.492, tt:2403.968\n",
      "Ep:130, loss:0.00001, loss_test:0.04286, lr:6.62e-03, fs:0.93684 (r=0.899,p=0.978),  time:18.520, tt:2426.099\n",
      "Ep:131, loss:0.00001, loss_test:0.04572, lr:6.56e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.513, tt:2443.743\n",
      "Ep:132, loss:0.00001, loss_test:0.04346, lr:6.49e-03, fs:0.92553 (r=0.879,p=0.978),  time:18.532, tt:2464.734\n",
      "Ep:133, loss:0.00001, loss_test:0.04530, lr:6.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.532, tt:2483.241\n",
      "Ep:134, loss:0.00001, loss_test:0.04413, lr:6.36e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.533, tt:2501.893\n",
      "Ep:135, loss:0.00001, loss_test:0.04345, lr:6.30e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.529, tt:2519.930\n",
      "Ep:136, loss:0.00001, loss_test:0.04485, lr:6.24e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.527, tt:2538.132\n",
      "Ep:137, loss:0.00001, loss_test:0.04278, lr:6.17e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.537, tt:2558.139\n",
      "Ep:138, loss:0.00001, loss_test:0.04480, lr:6.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.547, tt:2577.977\n",
      "Ep:139, loss:0.00001, loss_test:0.04267, lr:6.05e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.536, tt:2595.049\n",
      "Ep:140, loss:0.00001, loss_test:0.04456, lr:5.99e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.533, tt:2613.136\n",
      "Ep:141, loss:0.00001, loss_test:0.04280, lr:5.93e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.523, tt:2630.231\n",
      "Ep:142, loss:0.00001, loss_test:0.04493, lr:5.87e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.527, tt:2649.422\n",
      "Ep:143, loss:0.00001, loss_test:0.04243, lr:5.81e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.515, tt:2666.106\n",
      "Ep:144, loss:0.00001, loss_test:0.04521, lr:5.75e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.523, tt:2685.877\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"4-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
