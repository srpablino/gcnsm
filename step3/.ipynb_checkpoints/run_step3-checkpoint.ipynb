{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name for the ground_truth and graph embeddings\n",
    "\"\"\"\n",
    "dataset_name = \"openML\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive for the negative sampling (0 to 20)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\n",
    "\"\"\"\n",
    "Choose experiment [\"hold_out\",\"random_subsam\",\"10_cv\"] : \n",
    "- hold_out will get the train/test split within ./ground_truth/dataset_name/hold_out\n",
    "- random_subsam will isolate 1 node from some clusters of similar nodes in the ground truth. The isolated nodes will not be seen during training\n",
    "- 10_cv: will split the ground truth in 10 folds, using each fold as test at least once. \n",
    "\"\"\"\n",
    "strategy = \"random_subsam\"\n",
    "\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "import step3_gcnsm\n",
    "from step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3_gcnsm import train as train\n",
    "from step3_gcnsm import cross_validation as cross_validation\n",
    "from step3_gcnsm import test_mask, train_mask\n",
    "from step3_gcnsm import g\n",
    "import step3_gcn_nn_concatenate as gcn_nn\n",
    "import step3_gcn_loss as gcn_loss\n",
    "import step3_gcn_training as gcn_training\n",
    "import step3_plot_results as plot\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,experiment=strategy,new_split=create_new_split)\n",
    "print(\"\\n SETUP IS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run this to see the different options of NN architectures\n",
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    1024, <br>\n",
    "    2048, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    6e-3, <br>\n",
    "    1e-2, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-2 )\n",
    "#             loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "#             loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# train(training,iterations=120)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, g, g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,iterations_per_fold,range_folds,nsample,create_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of fscore/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) ds_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) experiment</b> = [\"10_cv\",\"random_subsam\",\"hold_out\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Types of chart\n",
    "<b>plot.plot_cv_details:</b> line charts of accuracy and fscore results for the several runs in cv_10 and random_subsampling<br>\n",
    "<b>plot.plot_bar </b>: bar charts of maximum results of accuracy and fscore for the several runs in cv_10 and random_subsampling <br>\n",
    "<b>plot.plot_details</b>: line charts of accuracy, fscore, recall and precision results for a hold_out run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##examples\n",
    "plot.plot_cv_details(0,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"CosineEmbeddingLoss\",nit=[124])\n",
    "plot.plot_bar(0,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"CosineEmbeddingLoss\",nit=[124])\n",
    "plot.plot_details(0,\"monitor\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"CosineEmbeddingLoss\",nit=[50])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
