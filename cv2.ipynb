{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number = \"11-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24614, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.194, tt:11.194\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24416, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:11.471, tt:22.943\n",
      "Ep:2, loss:0.00057, loss_test:0.24003, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:12.395, tt:37.184\n",
      "Ep:3, loss:0.00052, loss_test:0.23126, lr:9.41e-03, fs:0.64828 (r=0.949,p=0.492),  time:13.554, tt:54.217\n",
      "Ep:4, loss:0.00043, loss_test:0.21771, lr:9.22e-03, fs:0.62069 (r=0.818,p=0.500),  time:15.796, tt:78.982\n",
      "Ep:5, loss:0.00033, loss_test:0.22078, lr:9.04e-03, fs:0.64035 (r=0.737,p=0.566),  time:18.044, tt:108.264\n",
      "Ep:6, loss:0.00031, loss_test:0.21647, lr:8.86e-03, fs:0.65455 (r=0.727,p=0.595),  time:20.246, tt:141.724\n",
      "Ep:7, loss:0.00030, loss_test:0.21337, lr:8.68e-03, fs:0.64545 (r=0.717,p=0.587),  time:21.554, tt:172.435\n",
      "Ep:8, loss:0.00029, loss_test:0.20972, lr:8.51e-03, fs:0.65138 (r=0.717,p=0.597),  time:22.823, tt:205.410\n",
      "Ep:9, loss:0.00028, loss_test:0.20822, lr:8.34e-03, fs:0.65094 (r=0.697,p=0.611),  time:23.988, tt:239.882\n",
      "Ep:10, loss:0.00027, loss_test:0.20727, lr:8.17e-03, fs:0.64734 (r=0.677,p=0.620),  time:24.798, tt:272.782\n",
      "Ep:11, loss:0.00026, loss_test:0.20264, lr:8.01e-03, fs:0.62439 (r=0.646,p=0.604),  time:25.512, tt:306.141\n",
      "Ep:12, loss:0.00025, loss_test:0.19479, lr:7.85e-03, fs:0.68807 (r=0.758,p=0.630),  time:26.123, tt:339.600\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.19337, lr:7.69e-03, fs:0.67593 (r=0.737,p=0.624),  time:26.587, tt:372.222\n",
      "Ep:14, loss:0.00024, loss_test:0.19139, lr:7.54e-03, fs:0.68203 (r=0.747,p=0.627),  time:27.033, tt:405.493\n",
      "Ep:15, loss:0.00023, loss_test:0.19235, lr:7.39e-03, fs:0.65366 (r=0.677,p=0.632),  time:27.434, tt:438.944\n",
      "Ep:16, loss:0.00022, loss_test:0.18682, lr:7.24e-03, fs:0.69124 (r=0.758,p=0.636),  time:27.791, tt:472.443\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.18624, lr:7.09e-03, fs:0.69856 (r=0.737,p=0.664),  time:28.155, tt:506.788\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.19056, lr:6.95e-03, fs:0.68966 (r=0.707,p=0.673),  time:28.335, tt:538.370\n",
      "Ep:19, loss:0.00021, loss_test:0.18071, lr:6.81e-03, fs:0.72889 (r=0.828,p=0.651),  time:28.538, tt:570.765\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.18569, lr:6.68e-03, fs:0.71000 (r=0.717,p=0.703),  time:28.761, tt:603.979\n",
      "Ep:21, loss:0.00020, loss_test:0.18123, lr:6.54e-03, fs:0.71698 (r=0.768,p=0.673),  time:28.868, tt:635.089\n",
      "Ep:22, loss:0.00020, loss_test:0.17961, lr:6.41e-03, fs:0.74528 (r=0.798,p=0.699),  time:29.023, tt:667.524\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.17652, lr:6.28e-03, fs:0.73636 (r=0.818,p=0.669),  time:29.113, tt:698.723\n",
      "Ep:24, loss:0.00019, loss_test:0.18241, lr:6.16e-03, fs:0.71921 (r=0.737,p=0.702),  time:29.262, tt:731.542\n",
      "Ep:25, loss:0.00018, loss_test:0.17618, lr:6.03e-03, fs:0.76190 (r=0.808,p=0.721),  time:29.358, tt:763.305\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.17247, lr:5.91e-03, fs:0.76923 (r=0.808,p=0.734),  time:29.510, tt:796.766\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.17328, lr:5.80e-03, fs:0.78873 (r=0.848,p=0.737),  time:29.663, tt:830.568\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.17845, lr:5.68e-03, fs:0.75622 (r=0.768,p=0.745),  time:29.761, tt:863.057\n",
      "Ep:29, loss:0.00016, loss_test:0.16967, lr:5.57e-03, fs:0.77725 (r=0.828,p=0.732),  time:29.857, tt:895.708\n",
      "Ep:30, loss:0.00016, loss_test:0.16782, lr:5.45e-03, fs:0.79808 (r=0.838,p=0.761),  time:29.919, tt:927.491\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.16885, lr:5.35e-03, fs:0.78392 (r=0.788,p=0.780),  time:30.016, tt:960.505\n",
      "Ep:32, loss:0.00015, loss_test:0.16093, lr:5.24e-03, fs:0.81308 (r=0.879,p=0.757),  time:30.085, tt:992.816\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.16504, lr:5.13e-03, fs:0.77451 (r=0.798,p=0.752),  time:30.184, tt:1026.252\n",
      "Ep:34, loss:0.00014, loss_test:0.16086, lr:5.03e-03, fs:0.83654 (r=0.879,p=0.798),  time:30.268, tt:1059.387\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.16373, lr:4.93e-03, fs:0.81026 (r=0.798,p=0.823),  time:30.330, tt:1091.867\n",
      "Ep:36, loss:0.00013, loss_test:0.15158, lr:4.83e-03, fs:0.81517 (r=0.869,p=0.768),  time:30.395, tt:1124.621\n",
      "Ep:37, loss:0.00012, loss_test:0.15121, lr:4.74e-03, fs:0.82692 (r=0.869,p=0.789),  time:30.450, tt:1157.105\n",
      "Ep:38, loss:0.00013, loss_test:0.15503, lr:4.64e-03, fs:0.84000 (r=0.848,p=0.832),  time:30.491, tt:1189.157\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.16150, lr:4.55e-03, fs:0.79787 (r=0.758,p=0.843),  time:30.545, tt:1221.795\n",
      "Ep:40, loss:0.00011, loss_test:0.14396, lr:4.46e-03, fs:0.82629 (r=0.889,p=0.772),  time:30.578, tt:1253.690\n",
      "Ep:41, loss:0.00011, loss_test:0.14732, lr:4.37e-03, fs:0.82587 (r=0.838,p=0.814),  time:30.661, tt:1287.750\n",
      "Ep:42, loss:0.00011, loss_test:0.15743, lr:4.28e-03, fs:0.75138 (r=0.687,p=0.829),  time:30.756, tt:1322.493\n",
      "Ep:43, loss:0.00010, loss_test:0.15164, lr:4.19e-03, fs:0.78947 (r=0.758,p=0.824),  time:30.855, tt:1357.600\n",
      "Ep:44, loss:0.00010, loss_test:0.14330, lr:4.11e-03, fs:0.79208 (r=0.808,p=0.777),  time:30.923, tt:1391.551\n",
      "Ep:45, loss:0.00010, loss_test:0.15350, lr:4.03e-03, fs:0.79581 (r=0.768,p=0.826),  time:30.931, tt:1422.846\n",
      "Ep:46, loss:0.00009, loss_test:0.14650, lr:3.95e-03, fs:0.86538 (r=0.909,p=0.826),  time:31.006, tt:1457.280\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.15078, lr:3.87e-03, fs:0.80851 (r=0.768,p=0.854),  time:31.023, tt:1489.099\n",
      "Ep:48, loss:0.00009, loss_test:0.13492, lr:3.79e-03, fs:0.82464 (r=0.879,p=0.777),  time:31.056, tt:1521.725\n",
      "Ep:49, loss:0.00009, loss_test:0.14045, lr:3.72e-03, fs:0.85000 (r=0.859,p=0.842),  time:31.114, tt:1555.725\n",
      "Ep:50, loss:0.00008, loss_test:0.13634, lr:3.64e-03, fs:0.85854 (r=0.889,p=0.830),  time:31.151, tt:1588.692\n",
      "Ep:51, loss:0.00008, loss_test:0.13745, lr:3.57e-03, fs:0.85427 (r=0.859,p=0.850),  time:31.162, tt:1620.418\n",
      "Ep:52, loss:0.00008, loss_test:0.13683, lr:3.50e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.196, tt:1653.380\n",
      "Ep:53, loss:0.00007, loss_test:0.13995, lr:3.43e-03, fs:0.83582 (r=0.848,p=0.824),  time:31.200, tt:1684.787\n",
      "Ep:54, loss:0.00007, loss_test:0.14268, lr:3.36e-03, fs:0.86000 (r=0.869,p=0.851),  time:31.187, tt:1715.275\n",
      "Ep:55, loss:0.00007, loss_test:0.14208, lr:3.29e-03, fs:0.84848 (r=0.848,p=0.848),  time:31.188, tt:1746.523\n",
      "Ep:56, loss:0.00006, loss_test:0.13186, lr:3.23e-03, fs:0.85714 (r=0.879,p=0.837),  time:31.196, tt:1778.186\n",
      "Ep:57, loss:0.00006, loss_test:0.13361, lr:3.16e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.197, tt:1809.434\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.14425, lr:3.10e-03, fs:0.81283 (r=0.768,p=0.864),  time:31.200, tt:1840.807\n",
      "Ep:59, loss:0.00006, loss_test:0.12758, lr:3.04e-03, fs:0.85714 (r=0.879,p=0.837),  time:31.194, tt:1871.614\n",
      "Ep:60, loss:0.00006, loss_test:0.13504, lr:2.98e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.188, tt:1902.449\n",
      "Ep:61, loss:0.00006, loss_test:0.12493, lr:2.92e-03, fs:0.87562 (r=0.889,p=0.863),  time:31.191, tt:1933.852\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.13612, lr:2.86e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.199, tt:1965.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00005, loss_test:0.13142, lr:2.80e-03, fs:0.88776 (r=0.879,p=0.897),  time:31.233, tt:1998.902\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.14285, lr:2.74e-03, fs:0.84817 (r=0.818,p=0.880),  time:31.261, tt:2031.987\n",
      "Ep:65, loss:0.00005, loss_test:0.13299, lr:2.69e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.298, tt:2065.670\n",
      "Ep:66, loss:0.00005, loss_test:0.13338, lr:2.64e-03, fs:0.87629 (r=0.859,p=0.895),  time:31.339, tt:2099.732\n",
      "Ep:67, loss:0.00004, loss_test:0.13413, lr:2.58e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.346, tt:2131.508\n",
      "Ep:68, loss:0.00005, loss_test:0.13697, lr:2.53e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.326, tt:2161.493\n",
      "Ep:69, loss:0.00004, loss_test:0.13501, lr:2.48e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.347, tt:2194.316\n",
      "Ep:70, loss:0.00005, loss_test:0.13060, lr:2.43e-03, fs:0.87179 (r=0.859,p=0.885),  time:31.355, tt:2226.181\n",
      "Ep:71, loss:0.00004, loss_test:0.13381, lr:2.38e-03, fs:0.87179 (r=0.859,p=0.885),  time:31.361, tt:2258.016\n",
      "Ep:72, loss:0.00004, loss_test:0.13166, lr:2.33e-03, fs:0.88083 (r=0.859,p=0.904),  time:31.386, tt:2291.160\n",
      "Ep:73, loss:0.00004, loss_test:0.14089, lr:2.29e-03, fs:0.81111 (r=0.737,p=0.901),  time:31.360, tt:2320.620\n",
      "Ep:74, loss:0.00004, loss_test:0.13214, lr:2.24e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.391, tt:2354.297\n",
      "Ep:75, loss:0.00003, loss_test:0.13079, lr:2.20e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.412, tt:2387.304\n",
      "Ep:76, loss:0.00004, loss_test:0.13230, lr:2.15e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.453, tt:2421.871\n",
      "Ep:77, loss:0.00003, loss_test:0.12465, lr:2.11e-03, fs:0.88776 (r=0.879,p=0.897),  time:31.449, tt:2453.051\n",
      "Ep:78, loss:0.00003, loss_test:0.13562, lr:2.07e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.499, tt:2488.402\n",
      "Ep:79, loss:0.00003, loss_test:0.12818, lr:2.03e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.507, tt:2520.588\n",
      "Ep:80, loss:0.00003, loss_test:0.12623, lr:1.99e-03, fs:0.87629 (r=0.859,p=0.895),  time:31.513, tt:2552.536\n",
      "Ep:81, loss:0.00003, loss_test:0.13339, lr:1.95e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.514, tt:2584.111\n",
      "Ep:82, loss:0.00003, loss_test:0.13407, lr:1.91e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.524, tt:2616.495\n",
      "Ep:83, loss:0.00003, loss_test:0.12498, lr:1.87e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.549, tt:2650.132\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00003, loss_test:0.12717, lr:1.83e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.544, tt:2681.224\n",
      "Ep:85, loss:0.00003, loss_test:0.13415, lr:1.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.545, tt:2712.892\n",
      "Ep:86, loss:0.00003, loss_test:0.13486, lr:1.76e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.581, tt:2747.551\n",
      "Ep:87, loss:0.00003, loss_test:0.12225, lr:1.72e-03, fs:0.87629 (r=0.859,p=0.895),  time:31.598, tt:2780.611\n",
      "Ep:88, loss:0.00003, loss_test:0.13983, lr:1.69e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.620, tt:2814.220\n",
      "Ep:89, loss:0.00003, loss_test:0.12754, lr:1.66e-03, fs:0.88205 (r=0.869,p=0.896),  time:31.638, tt:2847.463\n",
      "Ep:90, loss:0.00003, loss_test:0.12490, lr:1.62e-03, fs:0.88083 (r=0.859,p=0.904),  time:31.668, tt:2881.751\n",
      "Ep:91, loss:0.00002, loss_test:0.13389, lr:1.59e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.685, tt:2915.026\n",
      "Ep:92, loss:0.00003, loss_test:0.13263, lr:1.56e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.709, tt:2948.929\n",
      "Ep:93, loss:0.00002, loss_test:0.12220, lr:1.53e-03, fs:0.90816 (r=0.899,p=0.918),  time:31.735, tt:2983.061\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.13293, lr:1.50e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.771, tt:3018.259\n",
      "Ep:95, loss:0.00002, loss_test:0.13279, lr:1.47e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.795, tt:3052.295\n",
      "Ep:96, loss:0.00002, loss_test:0.13232, lr:1.44e-03, fs:0.81564 (r=0.737,p=0.912),  time:31.825, tt:3087.014\n",
      "Ep:97, loss:0.00002, loss_test:0.13092, lr:1.41e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.846, tt:3120.927\n",
      "Ep:98, loss:0.00002, loss_test:0.12842, lr:1.38e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.873, tt:3155.398\n",
      "Ep:99, loss:0.00002, loss_test:0.12003, lr:1.35e-03, fs:0.88542 (r=0.859,p=0.914),  time:31.902, tt:3190.214\n",
      "Ep:100, loss:0.00002, loss_test:0.11698, lr:1.33e-03, fs:0.89340 (r=0.889,p=0.898),  time:31.948, tt:3226.729\n",
      "Ep:101, loss:0.00002, loss_test:0.12862, lr:1.30e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.985, tt:3262.421\n",
      "Ep:102, loss:0.00002, loss_test:0.13084, lr:1.27e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.009, tt:3296.896\n",
      "Ep:103, loss:0.00002, loss_test:0.12439, lr:1.25e-03, fs:0.89119 (r=0.869,p=0.915),  time:32.040, tt:3332.205\n",
      "Ep:104, loss:0.00002, loss_test:0.13802, lr:1.22e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.075, tt:3367.849\n",
      "Ep:105, loss:0.00002, loss_test:0.12983, lr:1.20e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.117, tt:3404.365\n",
      "Ep:106, loss:0.00002, loss_test:0.12021, lr:1.17e-03, fs:0.90355 (r=0.899,p=0.908),  time:32.153, tt:3440.368\n",
      "Ep:107, loss:0.00002, loss_test:0.12868, lr:1.15e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.171, tt:3474.512\n",
      "Ep:108, loss:0.00002, loss_test:0.13409, lr:1.13e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.200, tt:3509.820\n",
      "Ep:109, loss:0.00002, loss_test:0.12775, lr:1.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.233, tt:3545.588\n",
      "Ep:110, loss:0.00002, loss_test:0.12309, lr:1.08e-03, fs:0.87629 (r=0.859,p=0.895),  time:32.260, tt:3580.844\n",
      "Ep:111, loss:0.00002, loss_test:0.12618, lr:1.06e-03, fs:0.85106 (r=0.808,p=0.899),  time:32.288, tt:3616.279\n",
      "Ep:112, loss:0.00002, loss_test:0.13676, lr:1.04e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.320, tt:3652.185\n",
      "Ep:113, loss:0.00002, loss_test:0.12875, lr:1.02e-03, fs:0.89474 (r=0.859,p=0.934),  time:32.352, tt:3688.084\n",
      "Ep:114, loss:0.00002, loss_test:0.11955, lr:9.99e-04, fs:0.90722 (r=0.889,p=0.926),  time:32.371, tt:3722.676\n",
      "Ep:115, loss:0.00002, loss_test:0.12388, lr:9.79e-04, fs:0.89005 (r=0.859,p=0.924),  time:32.396, tt:3757.958\n",
      "Ep:116, loss:0.00002, loss_test:0.12472, lr:9.60e-04, fs:0.87500 (r=0.848,p=0.903),  time:32.438, tt:3795.225\n",
      "Ep:117, loss:0.00002, loss_test:0.12963, lr:9.41e-04, fs:0.81967 (r=0.758,p=0.893),  time:32.459, tt:3830.199\n",
      "Ep:118, loss:0.00002, loss_test:0.13384, lr:9.22e-04, fs:0.82873 (r=0.758,p=0.915),  time:32.484, tt:3865.570\n",
      "Ep:119, loss:0.00002, loss_test:0.12913, lr:9.03e-04, fs:0.88083 (r=0.859,p=0.904),  time:32.503, tt:3900.357\n",
      "Ep:120, loss:0.00002, loss_test:0.12351, lr:8.85e-04, fs:0.89231 (r=0.879,p=0.906),  time:32.521, tt:3934.992\n",
      "Ep:121, loss:0.00002, loss_test:0.12912, lr:8.68e-04, fs:0.85405 (r=0.798,p=0.919),  time:32.535, tt:3969.231\n",
      "Ep:122, loss:0.00002, loss_test:0.12942, lr:8.50e-04, fs:0.83516 (r=0.768,p=0.916),  time:32.546, tt:4003.100\n",
      "Ep:123, loss:0.00002, loss_test:0.12734, lr:8.33e-04, fs:0.87831 (r=0.838,p=0.922),  time:32.541, tt:4035.068\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24023, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.147, tt:33.147\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23624, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.495, tt:62.989\n",
      "Ep:2, loss:0.00057, loss_test:0.22775, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.775, tt:95.324\n",
      "Ep:3, loss:0.00053, loss_test:0.20981, lr:9.41e-03, fs:0.65986 (r=0.980,p=0.497),  time:31.632, tt:126.528\n",
      "Ep:4, loss:0.00044, loss_test:0.18556, lr:9.22e-03, fs:0.64964 (r=0.899,p=0.509),  time:31.557, tt:157.786\n",
      "Ep:5, loss:0.00036, loss_test:0.17725, lr:9.04e-03, fs:0.68966 (r=0.808,p=0.602),  time:31.770, tt:190.621\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.17742, lr:8.86e-03, fs:0.70536 (r=0.798,p=0.632),  time:31.778, tt:222.447\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.17428, lr:8.68e-03, fs:0.71560 (r=0.788,p=0.655),  time:32.044, tt:256.349\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00029, loss_test:0.16796, lr:8.51e-03, fs:0.73832 (r=0.798,p=0.687),  time:32.408, tt:291.674\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.16317, lr:8.34e-03, fs:0.74528 (r=0.798,p=0.699),  time:32.712, tt:327.125\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.16295, lr:8.17e-03, fs:0.75000 (r=0.788,p=0.716),  time:33.004, tt:363.048\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.16198, lr:8.01e-03, fs:0.75122 (r=0.778,p=0.726),  time:32.986, tt:395.829\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.15869, lr:7.85e-03, fs:0.76279 (r=0.828,p=0.707),  time:33.019, tt:429.243\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.15404, lr:7.69e-03, fs:0.77358 (r=0.828,p=0.726),  time:33.047, tt:462.665\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.15928, lr:7.54e-03, fs:0.76531 (r=0.758,p=0.773),  time:33.070, tt:496.046\n",
      "Ep:15, loss:0.00025, loss_test:0.15045, lr:7.39e-03, fs:0.76852 (r=0.838,p=0.709),  time:33.132, tt:530.118\n",
      "Ep:16, loss:0.00025, loss_test:0.15074, lr:7.24e-03, fs:0.78392 (r=0.788,p=0.780),  time:33.169, tt:563.878\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.14931, lr:7.09e-03, fs:0.78049 (r=0.808,p=0.755),  time:33.276, tt:598.963\n",
      "Ep:18, loss:0.00024, loss_test:0.14292, lr:6.95e-03, fs:0.77209 (r=0.838,p=0.716),  time:33.324, tt:633.155\n",
      "Ep:19, loss:0.00022, loss_test:0.14730, lr:6.81e-03, fs:0.81000 (r=0.818,p=0.802),  time:33.374, tt:667.478\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.14188, lr:6.68e-03, fs:0.81159 (r=0.848,p=0.778),  time:33.437, tt:702.186\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.14228, lr:6.54e-03, fs:0.79000 (r=0.798,p=0.782),  time:33.455, tt:736.004\n",
      "Ep:22, loss:0.00021, loss_test:0.13753, lr:6.41e-03, fs:0.81188 (r=0.828,p=0.796),  time:33.473, tt:769.871\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.13621, lr:6.28e-03, fs:0.81592 (r=0.828,p=0.804),  time:33.529, tt:804.700\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.13092, lr:6.16e-03, fs:0.80180 (r=0.899,p=0.724),  time:33.532, tt:838.301\n",
      "Ep:25, loss:0.00019, loss_test:0.13624, lr:6.03e-03, fs:0.82412 (r=0.828,p=0.820),  time:33.564, tt:872.664\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00019, loss_test:0.13191, lr:5.91e-03, fs:0.82075 (r=0.879,p=0.770),  time:33.546, tt:905.730\n",
      "Ep:27, loss:0.00018, loss_test:0.13247, lr:5.80e-03, fs:0.81731 (r=0.859,p=0.780),  time:33.547, tt:939.309\n",
      "Ep:28, loss:0.00018, loss_test:0.13457, lr:5.68e-03, fs:0.84577 (r=0.859,p=0.833),  time:33.571, tt:973.556\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.12635, lr:5.57e-03, fs:0.85714 (r=0.909,p=0.811),  time:33.621, tt:1008.637\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.12813, lr:5.45e-03, fs:0.87379 (r=0.909,p=0.841),  time:33.656, tt:1043.324\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.12620, lr:5.35e-03, fs:0.86124 (r=0.909,p=0.818),  time:33.657, tt:1077.026\n",
      "Ep:32, loss:0.00016, loss_test:0.13771, lr:5.24e-03, fs:0.88421 (r=0.848,p=0.923),  time:33.634, tt:1109.913\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00016, loss_test:0.12001, lr:5.13e-03, fs:0.84821 (r=0.960,p=0.760),  time:33.562, tt:1141.114\n",
      "Ep:34, loss:0.00015, loss_test:0.12921, lr:5.03e-03, fs:0.86000 (r=0.869,p=0.851),  time:33.549, tt:1174.205\n",
      "Ep:35, loss:0.00014, loss_test:0.12254, lr:4.93e-03, fs:0.87500 (r=0.919,p=0.835),  time:33.497, tt:1205.884\n",
      "Ep:36, loss:0.00014, loss_test:0.12556, lr:4.83e-03, fs:0.86538 (r=0.909,p=0.826),  time:33.486, tt:1238.991\n",
      "Ep:37, loss:0.00013, loss_test:0.12199, lr:4.74e-03, fs:0.88780 (r=0.919,p=0.858),  time:33.443, tt:1270.832\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.12013, lr:4.64e-03, fs:0.86957 (r=0.909,p=0.833),  time:33.454, tt:1304.724\n",
      "Ep:39, loss:0.00012, loss_test:0.11814, lr:4.55e-03, fs:0.88462 (r=0.929,p=0.844),  time:33.400, tt:1335.982\n",
      "Ep:40, loss:0.00012, loss_test:0.13547, lr:4.46e-03, fs:0.85263 (r=0.818,p=0.890),  time:33.419, tt:1370.162\n",
      "Ep:41, loss:0.00012, loss_test:0.11876, lr:4.37e-03, fs:0.86124 (r=0.909,p=0.818),  time:33.366, tt:1401.387\n",
      "Ep:42, loss:0.00011, loss_test:0.12710, lr:4.28e-03, fs:0.84422 (r=0.848,p=0.840),  time:33.353, tt:1434.159\n",
      "Ep:43, loss:0.00011, loss_test:0.11925, lr:4.19e-03, fs:0.86567 (r=0.879,p=0.853),  time:33.305, tt:1465.411\n",
      "Ep:44, loss:0.00011, loss_test:0.13429, lr:4.11e-03, fs:0.86631 (r=0.818,p=0.920),  time:33.332, tt:1499.943\n",
      "Ep:45, loss:0.00010, loss_test:0.12372, lr:4.03e-03, fs:0.83333 (r=0.808,p=0.860),  time:33.299, tt:1531.750\n",
      "Ep:46, loss:0.00010, loss_test:0.14180, lr:3.95e-03, fs:0.82022 (r=0.737,p=0.924),  time:33.292, tt:1564.713\n",
      "Ep:47, loss:0.00009, loss_test:0.12724, lr:3.87e-03, fs:0.86010 (r=0.838,p=0.883),  time:33.251, tt:1596.033\n",
      "Ep:48, loss:0.00009, loss_test:0.12475, lr:3.79e-03, fs:0.83696 (r=0.778,p=0.906),  time:33.217, tt:1627.628\n",
      "Ep:49, loss:0.00009, loss_test:0.12549, lr:3.72e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.215, tt:1660.732\n",
      "Ep:50, loss:0.00008, loss_test:0.11852, lr:3.64e-03, fs:0.84656 (r=0.808,p=0.889),  time:33.226, tt:1694.544\n",
      "Ep:51, loss:0.00008, loss_test:0.12063, lr:3.57e-03, fs:0.85714 (r=0.818,p=0.900),  time:33.245, tt:1728.751\n",
      "Ep:52, loss:0.00008, loss_test:0.13731, lr:3.50e-03, fs:0.81768 (r=0.747,p=0.902),  time:33.210, tt:1760.110\n",
      "Ep:53, loss:0.00007, loss_test:0.12822, lr:3.43e-03, fs:0.80214 (r=0.758,p=0.852),  time:33.192, tt:1792.354\n",
      "Ep:54, loss:0.00007, loss_test:0.13236, lr:3.36e-03, fs:0.81768 (r=0.747,p=0.902),  time:33.207, tt:1826.382\n",
      "Ep:55, loss:0.00006, loss_test:0.13122, lr:3.29e-03, fs:0.86957 (r=0.808,p=0.941),  time:33.201, tt:1859.242\n",
      "Ep:56, loss:0.00006, loss_test:0.13709, lr:3.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.204, tt:1892.649\n",
      "Ep:57, loss:0.00006, loss_test:0.12693, lr:3.16e-03, fs:0.81081 (r=0.758,p=0.872),  time:33.198, tt:1925.479\n",
      "Ep:58, loss:0.00005, loss_test:0.12628, lr:3.10e-03, fs:0.80874 (r=0.747,p=0.881),  time:33.224, tt:1960.217\n",
      "Ep:59, loss:0.00005, loss_test:0.14221, lr:3.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.250, tt:1995.021\n",
      "Ep:60, loss:0.00006, loss_test:0.11880, lr:2.98e-03, fs:0.85106 (r=0.808,p=0.899),  time:33.271, tt:2029.560\n",
      "Ep:61, loss:0.00005, loss_test:0.13626, lr:2.92e-03, fs:0.84444 (r=0.768,p=0.938),  time:33.288, tt:2063.879\n",
      "Ep:62, loss:0.00005, loss_test:0.11507, lr:2.86e-03, fs:0.84656 (r=0.808,p=0.889),  time:33.302, tt:2098.031\n",
      "Ep:63, loss:0.00005, loss_test:0.13076, lr:2.80e-03, fs:0.83721 (r=0.727,p=0.986),  time:33.291, tt:2130.622\n",
      "Ep:64, loss:0.00005, loss_test:0.11775, lr:2.74e-03, fs:0.83146 (r=0.747,p=0.937),  time:33.304, tt:2164.765\n",
      "Ep:65, loss:0.00005, loss_test:0.10632, lr:2.69e-03, fs:0.85417 (r=0.828,p=0.882),  time:33.311, tt:2198.536\n",
      "Ep:66, loss:0.00004, loss_test:0.13190, lr:2.64e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.315, tt:2232.103\n",
      "Ep:67, loss:0.00005, loss_test:0.12601, lr:2.58e-03, fs:0.85227 (r=0.758,p=0.974),  time:33.341, tt:2267.179\n",
      "Ep:68, loss:0.00004, loss_test:0.11953, lr:2.53e-03, fs:0.86957 (r=0.808,p=0.941),  time:33.327, tt:2299.546\n",
      "Ep:69, loss:0.00004, loss_test:0.12657, lr:2.48e-03, fs:0.83429 (r=0.737,p=0.961),  time:33.312, tt:2331.874\n",
      "Ep:70, loss:0.00004, loss_test:0.12777, lr:2.43e-03, fs:0.84746 (r=0.758,p=0.962),  time:33.309, tt:2364.946\n",
      "Ep:71, loss:0.00004, loss_test:0.15340, lr:2.38e-03, fs:0.83237 (r=0.727,p=0.973),  time:33.268, tt:2395.315\n",
      "Ep:72, loss:0.00004, loss_test:0.14263, lr:2.33e-03, fs:0.83237 (r=0.727,p=0.973),  time:33.283, tt:2429.662\n",
      "Ep:73, loss:0.00003, loss_test:0.12485, lr:2.29e-03, fs:0.87293 (r=0.798,p=0.963),  time:33.257, tt:2460.981\n",
      "Ep:74, loss:0.00004, loss_test:0.11824, lr:2.24e-03, fs:0.87778 (r=0.798,p=0.975),  time:33.245, tt:2493.364\n",
      "Ep:75, loss:0.00003, loss_test:0.13380, lr:2.20e-03, fs:0.83908 (r=0.737,p=0.973),  time:33.229, tt:2525.383\n",
      "Ep:76, loss:0.00003, loss_test:0.12939, lr:2.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:33.207, tt:2556.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00003, loss_test:0.13345, lr:2.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.190, tt:2588.793\n",
      "Ep:78, loss:0.00003, loss_test:0.13845, lr:2.07e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.158, tt:2619.501\n",
      "Ep:79, loss:0.00003, loss_test:0.12080, lr:2.03e-03, fs:0.87234 (r=0.828,p=0.921),  time:33.171, tt:2653.708\n",
      "Ep:80, loss:0.00003, loss_test:0.11222, lr:1.99e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.177, tt:2687.347\n",
      "Ep:81, loss:0.00002, loss_test:0.12310, lr:1.95e-03, fs:0.85870 (r=0.798,p=0.929),  time:33.165, tt:2719.490\n",
      "Ep:82, loss:0.00003, loss_test:0.12998, lr:1.91e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.152, tt:2751.617\n",
      "Ep:83, loss:0.00003, loss_test:0.11861, lr:1.87e-03, fs:0.85393 (r=0.768,p=0.962),  time:33.150, tt:2784.616\n",
      "Ep:84, loss:0.00003, loss_test:0.13152, lr:1.83e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.138, tt:2816.750\n",
      "Ep:85, loss:0.00002, loss_test:0.13600, lr:1.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.148, tt:2850.753\n",
      "Ep:86, loss:0.00002, loss_test:0.13134, lr:1.76e-03, fs:0.85870 (r=0.798,p=0.929),  time:33.144, tt:2883.493\n",
      "Ep:87, loss:0.00002, loss_test:0.13535, lr:1.72e-03, fs:0.83237 (r=0.727,p=0.973),  time:33.137, tt:2916.016\n",
      "Ep:88, loss:0.00002, loss_test:0.12849, lr:1.69e-03, fs:0.86813 (r=0.798,p=0.952),  time:33.148, tt:2950.156\n",
      "Ep:89, loss:0.00002, loss_test:0.12993, lr:1.66e-03, fs:0.86667 (r=0.788,p=0.963),  time:33.157, tt:2984.108\n",
      "Ep:90, loss:0.00002, loss_test:0.13137, lr:1.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.162, tt:3017.728\n",
      "Ep:91, loss:0.00002, loss_test:0.12657, lr:1.59e-03, fs:0.85870 (r=0.798,p=0.929),  time:33.173, tt:3051.923\n",
      "Ep:92, loss:0.00002, loss_test:0.13061, lr:1.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.186, tt:3086.319\n",
      "Ep:93, loss:0.00002, loss_test:0.12661, lr:1.53e-03, fs:0.83429 (r=0.737,p=0.961),  time:33.184, tt:3119.310\n",
      "Ep:94, loss:0.00002, loss_test:0.11931, lr:1.50e-03, fs:0.85870 (r=0.798,p=0.929),  time:33.181, tt:3152.197\n",
      "Ep:95, loss:0.00002, loss_test:0.12294, lr:1.47e-03, fs:0.86813 (r=0.798,p=0.952),  time:33.185, tt:3185.789\n",
      "Ep:96, loss:0.00002, loss_test:0.12512, lr:1.44e-03, fs:0.87293 (r=0.798,p=0.963),  time:33.188, tt:3219.276\n",
      "Ep:97, loss:0.00002, loss_test:0.12348, lr:1.41e-03, fs:0.85870 (r=0.798,p=0.929),  time:33.176, tt:3251.263\n",
      "Ep:98, loss:0.00002, loss_test:0.12534, lr:1.38e-03, fs:0.87778 (r=0.798,p=0.975),  time:33.190, tt:3285.798\n",
      "Ep:99, loss:0.00002, loss_test:0.12430, lr:1.35e-03, fs:0.87778 (r=0.798,p=0.975),  time:33.199, tt:3319.878\n",
      "Ep:100, loss:0.00002, loss_test:0.11949, lr:1.33e-03, fs:0.85405 (r=0.798,p=0.919),  time:33.215, tt:3354.753\n",
      "Ep:101, loss:0.00002, loss_test:0.12868, lr:1.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.219, tt:3388.305\n",
      "Ep:102, loss:0.00002, loss_test:0.13722, lr:1.27e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.209, tt:3420.572\n",
      "Ep:103, loss:0.00002, loss_test:0.13682, lr:1.25e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.214, tt:3454.288\n",
      "Ep:104, loss:0.00002, loss_test:0.12958, lr:1.22e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.194, tt:3485.367\n",
      "Ep:105, loss:0.00002, loss_test:0.12042, lr:1.20e-03, fs:0.87293 (r=0.798,p=0.963),  time:33.194, tt:3518.595\n",
      "Ep:106, loss:0.00001, loss_test:0.11545, lr:1.17e-03, fs:0.86813 (r=0.798,p=0.952),  time:33.199, tt:3552.282\n",
      "Ep:107, loss:0.00002, loss_test:0.11784, lr:1.15e-03, fs:0.87293 (r=0.798,p=0.963),  time:33.191, tt:3584.661\n",
      "Ep:108, loss:0.00001, loss_test:0.12393, lr:1.13e-03, fs:0.87778 (r=0.798,p=0.975),  time:33.177, tt:3616.265\n",
      "Ep:109, loss:0.00002, loss_test:0.12604, lr:1.11e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.166, tt:3648.302\n",
      "Ep:110, loss:0.00001, loss_test:0.12810, lr:1.08e-03, fs:0.86813 (r=0.798,p=0.952),  time:33.167, tt:3681.553\n",
      "Ep:111, loss:0.00001, loss_test:0.12814, lr:1.06e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.162, tt:3714.156\n",
      "Ep:112, loss:0.00001, loss_test:0.12524, lr:1.04e-03, fs:0.87293 (r=0.798,p=0.963),  time:33.162, tt:3747.310\n",
      "Ep:113, loss:0.00001, loss_test:0.12378, lr:1.02e-03, fs:0.86813 (r=0.798,p=0.952),  time:33.170, tt:3781.334\n",
      "Ep:114, loss:0.00001, loss_test:0.12367, lr:9.99e-04, fs:0.87293 (r=0.798,p=0.963),  time:33.179, tt:3815.585\n",
      "Ep:115, loss:0.00001, loss_test:0.12320, lr:9.79e-04, fs:0.86339 (r=0.798,p=0.940),  time:33.168, tt:3847.466\n",
      "Ep:116, loss:0.00001, loss_test:0.12116, lr:9.60e-04, fs:0.86339 (r=0.798,p=0.940),  time:33.165, tt:3880.345\n",
      "Ep:117, loss:0.00001, loss_test:0.12663, lr:9.41e-04, fs:0.87293 (r=0.798,p=0.963),  time:33.156, tt:3912.452\n",
      "Ep:118, loss:0.00001, loss_test:0.13255, lr:9.22e-04, fs:0.84091 (r=0.747,p=0.961),  time:33.151, tt:3944.947\n",
      "Ep:119, loss:0.00001, loss_test:0.13118, lr:9.03e-04, fs:0.86339 (r=0.798,p=0.940),  time:33.139, tt:3976.738\n",
      "Ep:120, loss:0.00001, loss_test:0.12850, lr:8.85e-04, fs:0.86339 (r=0.798,p=0.940),  time:33.128, tt:4008.491\n",
      "Ep:121, loss:0.00001, loss_test:0.12825, lr:8.68e-04, fs:0.87293 (r=0.798,p=0.963),  time:33.116, tt:4040.152\n",
      "Ep:122, loss:0.00001, loss_test:0.12919, lr:8.50e-04, fs:0.84746 (r=0.758,p=0.962),  time:33.103, tt:4071.675\n",
      "Ep:123, loss:0.00001, loss_test:0.13038, lr:8.33e-04, fs:0.83429 (r=0.737,p=0.961),  time:33.082, tt:4102.114\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 12\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24451, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.939, tt:31.939\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24263, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:29.957, tt:59.914\n",
      "Ep:2, loss:0.00057, loss_test:0.23853, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:30.252, tt:90.756\n",
      "Ep:3, loss:0.00053, loss_test:0.22952, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:30.708, tt:122.831\n",
      "Ep:4, loss:0.00044, loss_test:0.22131, lr:9.22e-03, fs:0.63469 (r=0.869,p=0.500),  time:29.645, tt:148.223\n",
      "Ep:5, loss:0.00034, loss_test:0.22467, lr:9.04e-03, fs:0.64198 (r=0.788,p=0.542),  time:30.022, tt:180.131\n",
      "Ep:6, loss:0.00032, loss_test:0.22015, lr:8.86e-03, fs:0.64435 (r=0.778,p=0.550),  time:30.239, tt:211.673\n",
      "Ep:7, loss:0.00030, loss_test:0.21701, lr:8.68e-03, fs:0.64103 (r=0.758,p=0.556),  time:30.715, tt:245.721\n",
      "Ep:8, loss:0.00030, loss_test:0.21194, lr:8.51e-03, fs:0.66087 (r=0.768,p=0.580),  time:30.811, tt:277.300\n",
      "Ep:9, loss:0.00028, loss_test:0.20897, lr:8.34e-03, fs:0.66667 (r=0.758,p=0.595),  time:30.938, tt:309.383\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.21148, lr:8.17e-03, fs:0.67273 (r=0.747,p=0.612),  time:30.995, tt:340.942\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.20510, lr:8.01e-03, fs:0.68493 (r=0.758,p=0.625),  time:31.183, tt:374.200\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.20047, lr:7.85e-03, fs:0.69369 (r=0.778,p=0.626),  time:31.352, tt:407.573\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.20782, lr:7.69e-03, fs:0.69091 (r=0.768,p=0.628),  time:31.477, tt:440.673\n",
      "Ep:14, loss:0.00024, loss_test:0.19659, lr:7.54e-03, fs:0.74138 (r=0.869,p=0.647),  time:31.647, tt:474.708\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.19206, lr:7.39e-03, fs:0.73303 (r=0.818,p=0.664),  time:31.753, tt:508.046\n",
      "Ep:16, loss:0.00023, loss_test:0.20070, lr:7.24e-03, fs:0.70370 (r=0.768,p=0.650),  time:31.949, tt:543.137\n",
      "Ep:17, loss:0.00023, loss_test:0.19655, lr:7.09e-03, fs:0.72146 (r=0.798,p=0.658),  time:32.045, tt:576.808\n",
      "Ep:18, loss:0.00023, loss_test:0.18968, lr:6.95e-03, fs:0.71233 (r=0.788,p=0.650),  time:32.072, tt:609.371\n",
      "Ep:19, loss:0.00023, loss_test:0.18822, lr:6.81e-03, fs:0.70642 (r=0.778,p=0.647),  time:32.088, tt:641.751\n",
      "Ep:20, loss:0.00022, loss_test:0.18522, lr:6.68e-03, fs:0.73488 (r=0.798,p=0.681),  time:32.190, tt:675.986\n",
      "Ep:21, loss:0.00022, loss_test:0.18485, lr:6.54e-03, fs:0.75362 (r=0.788,p=0.722),  time:32.299, tt:710.581\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00021, loss_test:0.17960, lr:6.41e-03, fs:0.72727 (r=0.808,p=0.661),  time:32.352, tt:744.091\n",
      "Ep:23, loss:0.00020, loss_test:0.18313, lr:6.28e-03, fs:0.74882 (r=0.798,p=0.705),  time:32.429, tt:778.290\n",
      "Ep:24, loss:0.00020, loss_test:0.18420, lr:6.16e-03, fs:0.75598 (r=0.798,p=0.718),  time:32.518, tt:812.953\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.17790, lr:6.03e-03, fs:0.75117 (r=0.808,p=0.702),  time:32.589, tt:847.327\n",
      "Ep:26, loss:0.00019, loss_test:0.18336, lr:5.91e-03, fs:0.75472 (r=0.808,p=0.708),  time:32.627, tt:880.918\n",
      "Ep:27, loss:0.00018, loss_test:0.17786, lr:5.80e-03, fs:0.76190 (r=0.808,p=0.721),  time:32.425, tt:907.910\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.17665, lr:5.68e-03, fs:0.75829 (r=0.808,p=0.714),  time:32.051, tt:929.486\n",
      "Ep:29, loss:0.00017, loss_test:0.18760, lr:5.57e-03, fs:0.78000 (r=0.788,p=0.772),  time:31.702, tt:951.073\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.16729, lr:5.45e-03, fs:0.75362 (r=0.788,p=0.722),  time:31.368, tt:972.408\n",
      "Ep:31, loss:0.00017, loss_test:0.17090, lr:5.35e-03, fs:0.74336 (r=0.848,p=0.661),  time:31.088, tt:994.811\n",
      "Ep:32, loss:0.00016, loss_test:0.16951, lr:5.24e-03, fs:0.78431 (r=0.808,p=0.762),  time:30.830, tt:1017.389\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00016, loss_test:0.16211, lr:5.13e-03, fs:0.78302 (r=0.838,p=0.735),  time:30.585, tt:1039.900\n",
      "Ep:34, loss:0.00015, loss_test:0.16546, lr:5.03e-03, fs:0.80392 (r=0.828,p=0.781),  time:30.333, tt:1061.656\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.16704, lr:4.93e-03, fs:0.79381 (r=0.778,p=0.811),  time:30.184, tt:1086.619\n",
      "Ep:36, loss:0.00013, loss_test:0.16453, lr:4.83e-03, fs:0.78846 (r=0.828,p=0.752),  time:29.996, tt:1109.842\n",
      "Ep:37, loss:0.00013, loss_test:0.16497, lr:4.74e-03, fs:0.80208 (r=0.778,p=0.828),  time:29.762, tt:1130.953\n",
      "Ep:38, loss:0.00013, loss_test:0.16947, lr:4.64e-03, fs:0.80000 (r=0.768,p=0.835),  time:29.564, tt:1152.981\n",
      "Ep:39, loss:0.00013, loss_test:0.16804, lr:4.55e-03, fs:0.80000 (r=0.788,p=0.812),  time:29.390, tt:1175.587\n",
      "Ep:40, loss:0.00012, loss_test:0.16193, lr:4.46e-03, fs:0.82292 (r=0.798,p=0.849),  time:29.216, tt:1197.841\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00012, loss_test:0.15793, lr:4.37e-03, fs:0.77570 (r=0.838,p=0.722),  time:29.021, tt:1218.900\n",
      "Ep:42, loss:0.00011, loss_test:0.16101, lr:4.28e-03, fs:0.81053 (r=0.778,p=0.846),  time:28.850, tt:1240.543\n",
      "Ep:43, loss:0.00011, loss_test:0.16253, lr:4.19e-03, fs:0.79188 (r=0.788,p=0.796),  time:28.633, tt:1259.846\n",
      "Ep:44, loss:0.00010, loss_test:0.15386, lr:4.11e-03, fs:0.81865 (r=0.798,p=0.840),  time:28.485, tt:1281.807\n",
      "Ep:45, loss:0.00010, loss_test:0.14750, lr:4.03e-03, fs:0.81188 (r=0.828,p=0.796),  time:28.329, tt:1303.142\n",
      "Ep:46, loss:0.00010, loss_test:0.15530, lr:3.95e-03, fs:0.80612 (r=0.798,p=0.814),  time:28.216, tt:1326.153\n",
      "Ep:47, loss:0.00009, loss_test:0.16544, lr:3.87e-03, fs:0.82979 (r=0.788,p=0.876),  time:28.087, tt:1348.172\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.16254, lr:3.79e-03, fs:0.79227 (r=0.828,p=0.759),  time:27.974, tt:1370.731\n",
      "Ep:49, loss:0.00009, loss_test:0.14797, lr:3.72e-03, fs:0.82723 (r=0.798,p=0.859),  time:27.838, tt:1391.923\n",
      "Ep:50, loss:0.00008, loss_test:0.15737, lr:3.64e-03, fs:0.82292 (r=0.798,p=0.849),  time:27.731, tt:1414.295\n",
      "Ep:51, loss:0.00008, loss_test:0.14505, lr:3.57e-03, fs:0.83333 (r=0.808,p=0.860),  time:27.568, tt:1433.554\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.15169, lr:3.50e-03, fs:0.83505 (r=0.818,p=0.853),  time:27.422, tt:1453.382\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.15384, lr:3.43e-03, fs:0.81218 (r=0.808,p=0.816),  time:27.344, tt:1476.567\n",
      "Ep:54, loss:0.00007, loss_test:0.14562, lr:3.36e-03, fs:0.84492 (r=0.798,p=0.898),  time:27.278, tt:1500.296\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.14811, lr:3.29e-03, fs:0.83243 (r=0.778,p=0.895),  time:27.126, tt:1519.044\n",
      "Ep:56, loss:0.00006, loss_test:0.15442, lr:3.23e-03, fs:0.81218 (r=0.808,p=0.816),  time:26.976, tt:1537.619\n",
      "Ep:57, loss:0.00006, loss_test:0.15877, lr:3.16e-03, fs:0.81773 (r=0.838,p=0.798),  time:26.855, tt:1557.611\n",
      "Ep:58, loss:0.00006, loss_test:0.14176, lr:3.10e-03, fs:0.83598 (r=0.798,p=0.878),  time:26.713, tt:1576.065\n",
      "Ep:59, loss:0.00006, loss_test:0.14233, lr:3.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:26.555, tt:1593.284\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.15317, lr:2.98e-03, fs:0.85714 (r=0.818,p=0.900),  time:26.405, tt:1610.722\n",
      "Ep:61, loss:0.00006, loss_test:0.14564, lr:2.92e-03, fs:0.84043 (r=0.798,p=0.888),  time:26.274, tt:1628.958\n",
      "Ep:62, loss:0.00006, loss_test:0.14491, lr:2.86e-03, fs:0.85279 (r=0.848,p=0.857),  time:26.146, tt:1647.230\n",
      "Ep:63, loss:0.00005, loss_test:0.14374, lr:2.80e-03, fs:0.82723 (r=0.798,p=0.859),  time:26.008, tt:1664.529\n",
      "Ep:64, loss:0.00005, loss_test:0.13985, lr:2.74e-03, fs:0.80612 (r=0.798,p=0.814),  time:25.882, tt:1682.348\n",
      "Ep:65, loss:0.00005, loss_test:0.13562, lr:2.69e-03, fs:0.85561 (r=0.808,p=0.909),  time:25.764, tt:1700.409\n",
      "Ep:66, loss:0.00005, loss_test:0.14025, lr:2.64e-03, fs:0.85714 (r=0.818,p=0.900),  time:25.635, tt:1717.559\n",
      "Ep:67, loss:0.00004, loss_test:0.13696, lr:2.58e-03, fs:0.80628 (r=0.778,p=0.837),  time:25.516, tt:1735.105\n",
      "Ep:68, loss:0.00004, loss_test:0.14678, lr:2.53e-03, fs:0.82353 (r=0.778,p=0.875),  time:25.390, tt:1751.940\n",
      "Ep:69, loss:0.00004, loss_test:0.13854, lr:2.48e-03, fs:0.83770 (r=0.808,p=0.870),  time:25.265, tt:1768.579\n",
      "Ep:70, loss:0.00004, loss_test:0.13886, lr:2.43e-03, fs:0.83598 (r=0.798,p=0.878),  time:25.171, tt:1787.142\n",
      "Ep:71, loss:0.00004, loss_test:0.14823, lr:2.38e-03, fs:0.87097 (r=0.818,p=0.931),  time:25.039, tt:1802.797\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00004, loss_test:0.14277, lr:2.33e-03, fs:0.86316 (r=0.828,p=0.901),  time:24.913, tt:1818.627\n",
      "Ep:73, loss:0.00004, loss_test:0.15116, lr:2.29e-03, fs:0.83871 (r=0.788,p=0.897),  time:24.782, tt:1833.903\n",
      "Ep:74, loss:0.00004, loss_test:0.13901, lr:2.24e-03, fs:0.86631 (r=0.818,p=0.920),  time:24.648, tt:1848.611\n",
      "Ep:75, loss:0.00003, loss_test:0.13364, lr:2.20e-03, fs:0.87368 (r=0.838,p=0.912),  time:24.513, tt:1862.958\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.13927, lr:2.15e-03, fs:0.85561 (r=0.808,p=0.909),  time:24.389, tt:1877.946\n",
      "Ep:77, loss:0.00003, loss_test:0.13430, lr:2.11e-03, fs:0.81915 (r=0.778,p=0.865),  time:24.265, tt:1892.664\n",
      "Ep:78, loss:0.00004, loss_test:0.13594, lr:2.07e-03, fs:0.84324 (r=0.788,p=0.907),  time:24.159, tt:1908.578\n",
      "Ep:79, loss:0.00003, loss_test:0.13896, lr:2.03e-03, fs:0.88043 (r=0.818,p=0.953),  time:24.046, tt:1923.704\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00003, loss_test:0.13781, lr:1.99e-03, fs:0.86631 (r=0.818,p=0.920),  time:23.932, tt:1938.481\n",
      "Ep:81, loss:0.00003, loss_test:0.13985, lr:1.95e-03, fs:0.82796 (r=0.778,p=0.885),  time:23.819, tt:1953.173\n",
      "Ep:82, loss:0.00003, loss_test:0.14146, lr:1.91e-03, fs:0.85083 (r=0.778,p=0.939),  time:23.723, tt:1968.983\n",
      "Ep:83, loss:0.00003, loss_test:0.13914, lr:1.87e-03, fs:0.84615 (r=0.778,p=0.928),  time:23.613, tt:1983.476\n",
      "Ep:84, loss:0.00003, loss_test:0.13980, lr:1.83e-03, fs:0.82353 (r=0.778,p=0.875),  time:23.511, tt:1998.457\n",
      "Ep:85, loss:0.00002, loss_test:0.14121, lr:1.80e-03, fs:0.83696 (r=0.778,p=0.906),  time:23.412, tt:2013.413\n",
      "Ep:86, loss:0.00003, loss_test:0.13876, lr:1.76e-03, fs:0.86170 (r=0.818,p=0.910),  time:23.328, tt:2029.563\n",
      "Ep:87, loss:0.00002, loss_test:0.13671, lr:1.72e-03, fs:0.87568 (r=0.818,p=0.942),  time:23.233, tt:2044.527\n",
      "Ep:88, loss:0.00002, loss_test:0.13788, lr:1.69e-03, fs:0.86034 (r=0.778,p=0.963),  time:23.115, tt:2057.256\n",
      "Ep:89, loss:0.00002, loss_test:0.14240, lr:1.66e-03, fs:0.83696 (r=0.778,p=0.906),  time:23.011, tt:2070.991\n",
      "Ep:90, loss:0.00002, loss_test:0.15466, lr:1.62e-03, fs:0.86631 (r=0.818,p=0.920),  time:22.901, tt:2083.991\n",
      "Ep:91, loss:0.00002, loss_test:0.14850, lr:1.59e-03, fs:0.84615 (r=0.778,p=0.928),  time:22.797, tt:2097.352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:92, loss:0.00002, loss_test:0.14427, lr:1.56e-03, fs:0.85561 (r=0.808,p=0.909),  time:22.697, tt:2110.824\n",
      "Ep:93, loss:0.00002, loss_test:0.14420, lr:1.53e-03, fs:0.83422 (r=0.788,p=0.886),  time:22.597, tt:2124.133\n",
      "Ep:94, loss:0.00002, loss_test:0.14503, lr:1.50e-03, fs:0.84615 (r=0.778,p=0.928),  time:22.512, tt:2138.610\n",
      "Ep:95, loss:0.00002, loss_test:0.14762, lr:1.47e-03, fs:0.86486 (r=0.808,p=0.930),  time:22.414, tt:2151.780\n",
      "Ep:96, loss:0.00002, loss_test:0.14572, lr:1.44e-03, fs:0.86486 (r=0.808,p=0.930),  time:22.324, tt:2165.474\n",
      "Ep:97, loss:0.00002, loss_test:0.14131, lr:1.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:22.236, tt:2179.158\n",
      "Ep:98, loss:0.00002, loss_test:0.13976, lr:1.38e-03, fs:0.83243 (r=0.778,p=0.895),  time:22.149, tt:2192.782\n",
      "Ep:99, loss:0.00002, loss_test:0.14201, lr:1.35e-03, fs:0.83696 (r=0.778,p=0.906),  time:22.065, tt:2206.491\n",
      "Ep:100, loss:0.00002, loss_test:0.14553, lr:1.33e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.981, tt:2220.102\n",
      "Ep:101, loss:0.00002, loss_test:0.14630, lr:1.30e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.905, tt:2234.278\n",
      "Ep:102, loss:0.00002, loss_test:0.15167, lr:1.27e-03, fs:0.85556 (r=0.778,p=0.951),  time:21.823, tt:2247.798\n",
      "Ep:103, loss:0.00002, loss_test:0.14521, lr:1.25e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.750, tt:2262.030\n",
      "Ep:104, loss:0.00002, loss_test:0.14282, lr:1.22e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.671, tt:2275.491\n",
      "Ep:105, loss:0.00002, loss_test:0.14980, lr:1.20e-03, fs:0.85405 (r=0.798,p=0.919),  time:21.601, tt:2289.674\n",
      "Ep:106, loss:0.00002, loss_test:0.15103, lr:1.17e-03, fs:0.85714 (r=0.788,p=0.940),  time:21.529, tt:2303.593\n",
      "Ep:107, loss:0.00002, loss_test:0.14859, lr:1.15e-03, fs:0.83422 (r=0.788,p=0.886),  time:21.457, tt:2317.382\n",
      "Ep:108, loss:0.00002, loss_test:0.15346, lr:1.13e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.387, tt:2331.204\n",
      "Ep:109, loss:0.00002, loss_test:0.15137, lr:1.11e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.322, tt:2345.456\n",
      "Ep:110, loss:0.00002, loss_test:0.14725, lr:1.08e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.259, tt:2359.705\n",
      "Ep:111, loss:0.00001, loss_test:0.14220, lr:1.06e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.189, tt:2373.168\n",
      "Ep:112, loss:0.00001, loss_test:0.14421, lr:1.04e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.121, tt:2386.640\n",
      "Ep:113, loss:0.00002, loss_test:0.14819, lr:1.02e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.056, tt:2400.425\n",
      "Ep:114, loss:0.00001, loss_test:0.14790, lr:9.99e-04, fs:0.83696 (r=0.778,p=0.906),  time:20.992, tt:2414.129\n",
      "Ep:115, loss:0.00001, loss_test:0.14766, lr:9.79e-04, fs:0.84153 (r=0.778,p=0.917),  time:20.929, tt:2427.781\n",
      "Ep:116, loss:0.00001, loss_test:0.14712, lr:9.60e-04, fs:0.83243 (r=0.778,p=0.895),  time:20.869, tt:2441.697\n",
      "Ep:117, loss:0.00001, loss_test:0.14754, lr:9.41e-04, fs:0.83243 (r=0.778,p=0.895),  time:20.815, tt:2456.120\n",
      "Ep:118, loss:0.00001, loss_test:0.15131, lr:9.22e-04, fs:0.84153 (r=0.778,p=0.917),  time:20.757, tt:2470.100\n",
      "Ep:119, loss:0.00001, loss_test:0.15244, lr:9.03e-04, fs:0.84153 (r=0.778,p=0.917),  time:20.696, tt:2483.524\n",
      "Ep:120, loss:0.00001, loss_test:0.14926, lr:8.85e-04, fs:0.84153 (r=0.778,p=0.917),  time:20.643, tt:2497.791\n",
      "Ep:121, loss:0.00001, loss_test:0.14570, lr:8.68e-04, fs:0.83243 (r=0.778,p=0.895),  time:20.582, tt:2511.003\n",
      "Ep:122, loss:0.00001, loss_test:0.14873, lr:8.50e-04, fs:0.85083 (r=0.778,p=0.939),  time:20.529, tt:2525.097\n",
      "Ep:123, loss:0.00001, loss_test:0.14960, lr:8.33e-04, fs:0.84615 (r=0.778,p=0.928),  time:20.472, tt:2538.577\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 13\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24292, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.636, tt:12.636\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24050, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:13.150, tt:26.300\n",
      "Ep:2, loss:0.00057, loss_test:0.23584, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:13.242, tt:39.727\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-072c7752a036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,124,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24752, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.630, tt:14.630\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24565, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:14.758, tt:29.515\n",
      "Ep:2, loss:0.00057, loss_test:0.23998, lr:9.80e-03, fs:0.66892 (r=1.000,p=0.503),  time:15.747, tt:47.241\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.22747, lr:9.70e-03, fs:0.64111 (r=0.929,p=0.489),  time:16.785, tt:67.139\n",
      "Ep:4, loss:0.00041, loss_test:0.21723, lr:9.61e-03, fs:0.63566 (r=0.828,p=0.516),  time:18.653, tt:93.267\n",
      "Ep:5, loss:0.00034, loss_test:0.21360, lr:9.51e-03, fs:0.66116 (r=0.808,p=0.559),  time:20.899, tt:125.395\n",
      "Ep:6, loss:0.00032, loss_test:0.21416, lr:9.41e-03, fs:0.64253 (r=0.717,p=0.582),  time:23.173, tt:162.211\n",
      "Ep:7, loss:0.00031, loss_test:0.21146, lr:9.32e-03, fs:0.63348 (r=0.707,p=0.574),  time:25.375, tt:203.002\n",
      "Ep:8, loss:0.00029, loss_test:0.21179, lr:9.23e-03, fs:0.62963 (r=0.687,p=0.581),  time:27.425, tt:246.825\n",
      "Ep:9, loss:0.00029, loss_test:0.20855, lr:9.14e-03, fs:0.64574 (r=0.727,p=0.581),  time:28.814, tt:288.145\n",
      "Ep:10, loss:0.00028, loss_test:0.21204, lr:9.04e-03, fs:0.65700 (r=0.687,p=0.630),  time:29.767, tt:327.432\n",
      "Ep:11, loss:0.00026, loss_test:0.20021, lr:8.95e-03, fs:0.66667 (r=0.737,p=0.608),  time:30.843, tt:370.122\n",
      "Ep:12, loss:0.00026, loss_test:0.19700, lr:8.86e-03, fs:0.66667 (r=0.727,p=0.615),  time:31.859, tt:414.173\n",
      "Ep:13, loss:0.00025, loss_test:0.19802, lr:8.78e-03, fs:0.66667 (r=0.697,p=0.639),  time:32.686, tt:457.598\n",
      "Ep:14, loss:0.00024, loss_test:0.19432, lr:8.60e-03, fs:0.68269 (r=0.717,p=0.651),  time:33.514, tt:502.709\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.18377, lr:8.51e-03, fs:0.71681 (r=0.818,p=0.638),  time:34.060, tt:544.959\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.18183, lr:8.43e-03, fs:0.72477 (r=0.798,p=0.664),  time:34.316, tt:583.365\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.18264, lr:8.35e-03, fs:0.73394 (r=0.808,p=0.672),  time:34.642, tt:623.563\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.18331, lr:8.26e-03, fs:0.73733 (r=0.808,p=0.678),  time:34.928, tt:663.627\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.18333, lr:8.18e-03, fs:0.70192 (r=0.737,p=0.670),  time:35.244, tt:704.871\n",
      "Ep:20, loss:0.00020, loss_test:0.17162, lr:8.10e-03, fs:0.77729 (r=0.899,p=0.685),  time:35.484, tt:745.162\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.17703, lr:8.02e-03, fs:0.75728 (r=0.788,p=0.729),  time:35.813, tt:787.890\n",
      "Ep:22, loss:0.00020, loss_test:0.17486, lr:7.94e-03, fs:0.74510 (r=0.768,p=0.724),  time:36.218, tt:833.013\n",
      "Ep:23, loss:0.00019, loss_test:0.17027, lr:7.86e-03, fs:0.78873 (r=0.848,p=0.737),  time:36.492, tt:875.804\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.16680, lr:7.78e-03, fs:0.75472 (r=0.808,p=0.708),  time:36.744, tt:918.609\n",
      "Ep:25, loss:0.00018, loss_test:0.17532, lr:7.70e-03, fs:0.78218 (r=0.798,p=0.767),  time:36.835, tt:957.716\n",
      "Ep:26, loss:0.00017, loss_test:0.17400, lr:7.62e-03, fs:0.78788 (r=0.788,p=0.788),  time:36.881, tt:995.791\n",
      "Ep:27, loss:0.00016, loss_test:0.16300, lr:7.55e-03, fs:0.78704 (r=0.859,p=0.726),  time:37.007, tt:1036.183\n",
      "Ep:28, loss:0.00016, loss_test:0.16033, lr:7.47e-03, fs:0.80909 (r=0.899,p=0.736),  time:37.077, tt:1075.246\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.16296, lr:7.40e-03, fs:0.80583 (r=0.838,p=0.776),  time:37.135, tt:1114.053\n",
      "Ep:30, loss:0.00015, loss_test:0.18624, lr:7.32e-03, fs:0.73563 (r=0.646,p=0.853),  time:37.214, tt:1153.623\n",
      "Ep:31, loss:0.00015, loss_test:0.15246, lr:7.25e-03, fs:0.78947 (r=0.909,p=0.698),  time:37.329, tt:1194.517\n",
      "Ep:32, loss:0.00015, loss_test:0.17009, lr:7.18e-03, fs:0.75393 (r=0.727,p=0.783),  time:37.462, tt:1236.248\n",
      "Ep:33, loss:0.00014, loss_test:0.14544, lr:7.11e-03, fs:0.82192 (r=0.909,p=0.750),  time:37.660, tt:1280.444\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.15435, lr:7.03e-03, fs:0.83333 (r=0.859,p=0.810),  time:37.767, tt:1321.857\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.16778, lr:6.96e-03, fs:0.75936 (r=0.717,p=0.807),  time:37.879, tt:1363.654\n",
      "Ep:36, loss:0.00013, loss_test:0.14732, lr:6.89e-03, fs:0.79279 (r=0.889,p=0.715),  time:37.940, tt:1403.797\n",
      "Ep:37, loss:0.00012, loss_test:0.16004, lr:6.83e-03, fs:0.78049 (r=0.808,p=0.755),  time:37.983, tt:1443.343\n",
      "Ep:38, loss:0.00013, loss_test:0.16084, lr:6.76e-03, fs:0.79381 (r=0.778,p=0.811),  time:37.977, tt:1481.091\n",
      "Ep:39, loss:0.00012, loss_test:0.15678, lr:6.69e-03, fs:0.78218 (r=0.798,p=0.767),  time:38.020, tt:1520.795\n",
      "Ep:40, loss:0.00011, loss_test:0.15617, lr:6.62e-03, fs:0.80628 (r=0.778,p=0.837),  time:38.053, tt:1560.162\n",
      "Ep:41, loss:0.00010, loss_test:0.15495, lr:6.56e-03, fs:0.78607 (r=0.798,p=0.775),  time:38.161, tt:1602.742\n",
      "Ep:42, loss:0.00010, loss_test:0.16203, lr:6.49e-03, fs:0.75410 (r=0.697,p=0.821),  time:38.270, tt:1645.589\n",
      "Ep:43, loss:0.00009, loss_test:0.14348, lr:6.43e-03, fs:0.79803 (r=0.818,p=0.779),  time:38.422, tt:1690.575\n",
      "Ep:44, loss:0.00009, loss_test:0.14258, lr:6.36e-03, fs:0.85714 (r=0.879,p=0.837),  time:38.569, tt:1735.614\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.14773, lr:6.30e-03, fs:0.83838 (r=0.838,p=0.838),  time:38.590, tt:1775.152\n",
      "Ep:46, loss:0.00008, loss_test:0.14627, lr:6.24e-03, fs:0.78919 (r=0.737,p=0.849),  time:38.581, tt:1813.316\n",
      "Ep:47, loss:0.00007, loss_test:0.15150, lr:6.17e-03, fs:0.82162 (r=0.768,p=0.884),  time:38.613, tt:1853.436\n",
      "Ep:48, loss:0.00007, loss_test:0.13232, lr:6.11e-03, fs:0.88235 (r=0.909,p=0.857),  time:38.641, tt:1893.433\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.12741, lr:6.05e-03, fs:0.79397 (r=0.798,p=0.790),  time:38.652, tt:1932.605\n",
      "Ep:50, loss:0.00006, loss_test:0.12930, lr:5.99e-03, fs:0.82927 (r=0.859,p=0.802),  time:38.699, tt:1973.640\n",
      "Ep:51, loss:0.00006, loss_test:0.14657, lr:5.93e-03, fs:0.80435 (r=0.747,p=0.871),  time:38.798, tt:2017.476\n",
      "Ep:52, loss:0.00006, loss_test:0.14277, lr:5.87e-03, fs:0.80663 (r=0.737,p=0.890),  time:38.863, tt:2059.735\n",
      "Ep:53, loss:0.00005, loss_test:0.12380, lr:5.81e-03, fs:0.87255 (r=0.899,p=0.848),  time:38.934, tt:2102.443\n",
      "Ep:54, loss:0.00005, loss_test:0.14306, lr:5.75e-03, fs:0.78756 (r=0.768,p=0.809),  time:39.045, tt:2147.482\n",
      "Ep:55, loss:0.00005, loss_test:0.15888, lr:5.70e-03, fs:0.83871 (r=0.788,p=0.897),  time:39.066, tt:2187.693\n",
      "Ep:56, loss:0.00007, loss_test:0.14437, lr:5.64e-03, fs:0.81481 (r=0.778,p=0.856),  time:39.078, tt:2227.460\n",
      "Ep:57, loss:0.00006, loss_test:0.12724, lr:5.58e-03, fs:0.83333 (r=0.909,p=0.769),  time:39.058, tt:2265.383\n",
      "Ep:58, loss:0.00007, loss_test:0.13446, lr:5.53e-03, fs:0.87255 (r=0.899,p=0.848),  time:39.086, tt:2306.054\n",
      "Ep:59, loss:0.00008, loss_test:0.13321, lr:5.47e-03, fs:0.81517 (r=0.869,p=0.768),  time:39.088, tt:2345.289\n",
      "Ep:60, loss:0.00008, loss_test:0.14461, lr:5.36e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.081, tt:2383.920\n",
      "Ep:61, loss:0.00007, loss_test:0.14629, lr:5.26e-03, fs:0.80412 (r=0.788,p=0.821),  time:39.140, tt:2426.707\n",
      "Ep:62, loss:0.00006, loss_test:0.15044, lr:5.15e-03, fs:0.85308 (r=0.909,p=0.804),  time:39.177, tt:2468.154\n",
      "Ep:63, loss:0.00006, loss_test:0.15883, lr:5.05e-03, fs:0.80203 (r=0.798,p=0.806),  time:39.236, tt:2511.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00010, loss_test:0.13187, lr:4.95e-03, fs:0.76800 (r=0.970,p=0.636),  time:39.264, tt:2552.164\n",
      "Ep:65, loss:0.00020, loss_test:0.14354, lr:4.85e-03, fs:0.76154 (r=1.000,p=0.615),  time:39.238, tt:2589.687\n",
      "Ep:66, loss:0.00019, loss_test:0.16842, lr:4.75e-03, fs:0.71795 (r=0.848,p=0.622),  time:39.250, tt:2629.758\n",
      "Ep:67, loss:0.00019, loss_test:0.17842, lr:4.66e-03, fs:0.70707 (r=0.707,p=0.707),  time:39.236, tt:2668.076\n",
      "Ep:68, loss:0.00017, loss_test:0.17368, lr:4.57e-03, fs:0.74038 (r=0.778,p=0.706),  time:39.208, tt:2705.355\n",
      "Ep:69, loss:0.00016, loss_test:0.16365, lr:4.48e-03, fs:0.74257 (r=0.758,p=0.728),  time:39.184, tt:2742.914\n",
      "Ep:70, loss:0.00013, loss_test:0.14616, lr:4.39e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.195, tt:2782.872\n",
      "Ep:71, loss:0.00011, loss_test:0.15447, lr:4.30e-03, fs:0.78571 (r=0.778,p=0.794),  time:39.263, tt:2826.935\n",
      "Ep:72, loss:0.00010, loss_test:0.12301, lr:4.21e-03, fs:0.82028 (r=0.899,p=0.754),  time:39.294, tt:2868.478\n",
      "Ep:73, loss:0.00008, loss_test:0.12964, lr:4.13e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.353, tt:2912.145\n",
      "Ep:74, loss:0.00009, loss_test:0.12705, lr:4.05e-03, fs:0.84615 (r=0.889,p=0.807),  time:39.399, tt:2954.917\n",
      "Ep:75, loss:0.00009, loss_test:0.10979, lr:3.97e-03, fs:0.84259 (r=0.919,p=0.778),  time:39.388, tt:2993.504\n",
      "Ep:76, loss:0.00010, loss_test:0.11044, lr:3.89e-03, fs:0.82511 (r=0.929,p=0.742),  time:39.375, tt:3031.903\n",
      "Ep:77, loss:0.00012, loss_test:0.12115, lr:3.81e-03, fs:0.79821 (r=0.899,p=0.718),  time:39.389, tt:3072.350\n",
      "Ep:78, loss:0.00011, loss_test:0.12741, lr:3.73e-03, fs:0.81517 (r=0.869,p=0.768),  time:39.367, tt:3109.976\n",
      "Ep:79, loss:0.00012, loss_test:0.12400, lr:3.66e-03, fs:0.81132 (r=0.869,p=0.761),  time:39.363, tt:3149.074\n",
      "Ep:80, loss:0.00011, loss_test:0.13193, lr:3.59e-03, fs:0.83412 (r=0.889,p=0.786),  time:39.373, tt:3189.241\n",
      "Ep:81, loss:0.00012, loss_test:0.13601, lr:3.52e-03, fs:0.83333 (r=0.909,p=0.769),  time:39.411, tt:3231.724\n",
      "Ep:82, loss:0.00014, loss_test:0.14867, lr:3.45e-03, fs:0.80952 (r=0.859,p=0.766),  time:39.463, tt:3275.460\n",
      "Ep:83, loss:0.00011, loss_test:0.14862, lr:3.38e-03, fs:0.80189 (r=0.859,p=0.752),  time:39.496, tt:3317.703\n",
      "Ep:84, loss:0.00011, loss_test:0.11943, lr:3.31e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.540, tt:3360.938\n",
      "Ep:85, loss:0.00009, loss_test:0.11244, lr:3.24e-03, fs:0.86099 (r=0.970,p=0.774),  time:39.539, tt:3400.389\n",
      "Ep:86, loss:0.00009, loss_test:0.13890, lr:3.18e-03, fs:0.80198 (r=0.818,p=0.786),  time:39.541, tt:3440.093\n",
      "Ep:87, loss:0.00010, loss_test:0.14448, lr:3.12e-03, fs:0.78095 (r=0.828,p=0.739),  time:39.548, tt:3480.224\n",
      "Ep:88, loss:0.00009, loss_test:0.14026, lr:3.05e-03, fs:0.80543 (r=0.899,p=0.730),  time:39.545, tt:3519.487\n",
      "Ep:89, loss:0.00009, loss_test:0.12186, lr:2.99e-03, fs:0.83333 (r=0.909,p=0.769),  time:39.572, tt:3561.462\n",
      "Ep:90, loss:0.00009, loss_test:0.13184, lr:2.93e-03, fs:0.78539 (r=0.869,p=0.717),  time:39.590, tt:3602.678\n",
      "Ep:91, loss:0.00013, loss_test:0.10876, lr:2.88e-03, fs:0.84507 (r=0.909,p=0.789),  time:39.614, tt:3644.501\n",
      "Ep:92, loss:0.00009, loss_test:0.12633, lr:2.82e-03, fs:0.79426 (r=0.838,p=0.755),  time:39.641, tt:3686.616\n",
      "Ep:93, loss:0.00009, loss_test:0.15184, lr:2.76e-03, fs:0.71795 (r=0.707,p=0.729),  time:39.633, tt:3725.507\n",
      "Ep:94, loss:0.00009, loss_test:0.12176, lr:2.71e-03, fs:0.84058 (r=0.879,p=0.806),  time:39.618, tt:3763.743\n",
      "Ep:95, loss:0.00007, loss_test:0.12829, lr:2.65e-03, fs:0.79612 (r=0.828,p=0.766),  time:39.615, tt:3803.062\n",
      "Ep:96, loss:0.00007, loss_test:0.12703, lr:2.60e-03, fs:0.81553 (r=0.848,p=0.785),  time:39.611, tt:3842.309\n",
      "Ep:97, loss:0.00007, loss_test:0.10345, lr:2.55e-03, fs:0.84422 (r=0.848,p=0.840),  time:39.616, tt:3882.404\n",
      "Ep:98, loss:0.00007, loss_test:0.10308, lr:2.50e-03, fs:0.82524 (r=0.859,p=0.794),  time:39.608, tt:3921.188\n",
      "Ep:99, loss:0.00007, loss_test:0.12593, lr:2.45e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.587, tt:3958.688\n",
      "Ep:100, loss:0.00006, loss_test:0.10836, lr:2.40e-03, fs:0.83495 (r=0.869,p=0.804),  time:39.608, tt:4000.387\n",
      "Ep:101, loss:0.00007, loss_test:0.09912, lr:2.35e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.634, tt:4042.647\n",
      "Ep:102, loss:0.00005, loss_test:0.09269, lr:2.31e-03, fs:0.85714 (r=0.879,p=0.837),  time:39.661, tt:4085.099\n",
      "Ep:103, loss:0.00006, loss_test:0.09385, lr:2.26e-03, fs:0.86154 (r=0.848,p=0.875),  time:39.697, tt:4128.451\n",
      "Ep:104, loss:0.00005, loss_test:0.08255, lr:2.21e-03, fs:0.85294 (r=0.879,p=0.829),  time:39.702, tt:4168.701\n",
      "Ep:105, loss:0.00005, loss_test:0.09222, lr:2.17e-03, fs:0.88780 (r=0.919,p=0.858),  time:39.699, tt:4208.140\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00005, loss_test:0.10217, lr:2.15e-03, fs:0.85714 (r=0.848,p=0.866),  time:39.693, tt:4247.170\n",
      "Ep:107, loss:0.00004, loss_test:0.09469, lr:2.13e-03, fs:0.87562 (r=0.889,p=0.863),  time:39.686, tt:4286.097\n",
      "Ep:108, loss:0.00004, loss_test:0.09854, lr:2.11e-03, fs:0.86567 (r=0.879,p=0.853),  time:39.684, tt:4325.528\n",
      "Ep:109, loss:0.00004, loss_test:0.09224, lr:2.08e-03, fs:0.89216 (r=0.919,p=0.867),  time:39.676, tt:4364.403\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00004, loss_test:0.09674, lr:2.06e-03, fs:0.88780 (r=0.919,p=0.858),  time:39.708, tt:4407.630\n",
      "Ep:111, loss:0.00004, loss_test:0.09839, lr:2.04e-03, fs:0.84694 (r=0.838,p=0.856),  time:39.730, tt:4449.800\n",
      "Ep:112, loss:0.00004, loss_test:0.10031, lr:2.02e-03, fs:0.86010 (r=0.838,p=0.883),  time:39.747, tt:4491.423\n",
      "Ep:113, loss:0.00003, loss_test:0.10055, lr:2.00e-03, fs:0.86010 (r=0.838,p=0.883),  time:39.771, tt:4533.874\n",
      "Ep:114, loss:0.00003, loss_test:0.08907, lr:1.98e-03, fs:0.85714 (r=0.848,p=0.866),  time:39.771, tt:4573.637\n",
      "Ep:115, loss:0.00003, loss_test:0.08683, lr:1.96e-03, fs:0.87923 (r=0.919,p=0.843),  time:39.764, tt:4612.608\n",
      "Ep:116, loss:0.00004, loss_test:0.09720, lr:1.94e-03, fs:0.87923 (r=0.919,p=0.843),  time:39.754, tt:4651.259\n",
      "Ep:117, loss:0.00003, loss_test:0.09511, lr:1.92e-03, fs:0.87000 (r=0.879,p=0.861),  time:39.756, tt:4691.249\n",
      "Ep:118, loss:0.00003, loss_test:0.09119, lr:1.90e-03, fs:0.87047 (r=0.848,p=0.894),  time:39.757, tt:4731.079\n",
      "Ep:119, loss:0.00003, loss_test:0.08866, lr:1.89e-03, fs:0.86010 (r=0.838,p=0.883),  time:39.755, tt:4770.582\n",
      "Ep:120, loss:0.00003, loss_test:0.09644, lr:1.87e-03, fs:0.85567 (r=0.838,p=0.874),  time:39.795, tt:4815.238\n",
      "Ep:121, loss:0.00004, loss_test:0.09479, lr:1.83e-03, fs:0.86735 (r=0.859,p=0.876),  time:39.837, tt:4860.077\n",
      "Ep:122, loss:0.00003, loss_test:0.08057, lr:1.79e-03, fs:0.89552 (r=0.909,p=0.882),  time:39.872, tt:4904.315\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24034, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.756, tt:40.756\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23618, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.061, tt:80.121\n",
      "Ep:2, loss:0.00057, loss_test:0.22607, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.345, tt:121.036\n",
      "Ep:3, loss:0.00052, loss_test:0.20618, lr:9.70e-03, fs:0.66436 (r=0.970,p=0.505),  time:40.343, tt:161.373\n",
      "Ep:4, loss:0.00043, loss_test:0.18741, lr:9.61e-03, fs:0.66412 (r=0.879,p=0.534),  time:39.113, tt:195.567\n",
      "Ep:5, loss:0.00035, loss_test:0.18341, lr:9.51e-03, fs:0.66946 (r=0.808,p=0.571),  time:38.645, tt:231.867\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.18216, lr:9.41e-03, fs:0.68750 (r=0.778,p=0.616),  time:38.571, tt:269.995\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.17523, lr:9.32e-03, fs:0.68807 (r=0.758,p=0.630),  time:39.141, tt:313.127\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.17091, lr:9.23e-03, fs:0.71963 (r=0.778,p=0.670),  time:39.627, tt:356.640\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00029, loss_test:0.16418, lr:9.14e-03, fs:0.73636 (r=0.818,p=0.669),  time:39.889, tt:398.889\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.15956, lr:9.04e-03, fs:0.76279 (r=0.828,p=0.707),  time:39.839, tt:438.227\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.16182, lr:8.95e-03, fs:0.76190 (r=0.808,p=0.721),  time:39.881, tt:478.572\n",
      "Ep:12, loss:0.00027, loss_test:0.15603, lr:8.86e-03, fs:0.76498 (r=0.838,p=0.703),  time:39.880, tt:518.436\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.15160, lr:8.78e-03, fs:0.76498 (r=0.838,p=0.703),  time:39.724, tt:556.130\n",
      "Ep:14, loss:0.00025, loss_test:0.14689, lr:8.69e-03, fs:0.78182 (r=0.869,p=0.711),  time:39.761, tt:596.421\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.14794, lr:8.60e-03, fs:0.81731 (r=0.859,p=0.780),  time:39.888, tt:638.203\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.14266, lr:8.51e-03, fs:0.78539 (r=0.869,p=0.717),  time:40.066, tt:681.120\n",
      "Ep:17, loss:0.00024, loss_test:0.14779, lr:8.43e-03, fs:0.80583 (r=0.838,p=0.776),  time:40.303, tt:725.463\n",
      "Ep:18, loss:0.00023, loss_test:0.13921, lr:8.35e-03, fs:0.79817 (r=0.879,p=0.731),  time:40.582, tt:771.066\n",
      "Ep:19, loss:0.00022, loss_test:0.13953, lr:8.26e-03, fs:0.81132 (r=0.869,p=0.761),  time:40.550, tt:810.994\n",
      "Ep:20, loss:0.00022, loss_test:0.14293, lr:8.18e-03, fs:0.78469 (r=0.828,p=0.745),  time:40.440, tt:849.233\n",
      "Ep:21, loss:0.00021, loss_test:0.13693, lr:8.10e-03, fs:0.79817 (r=0.879,p=0.731),  time:40.344, tt:887.561\n",
      "Ep:22, loss:0.00021, loss_test:0.14179, lr:8.02e-03, fs:0.80788 (r=0.828,p=0.788),  time:40.245, tt:925.624\n",
      "Ep:23, loss:0.00020, loss_test:0.12878, lr:7.94e-03, fs:0.78947 (r=0.909,p=0.698),  time:40.223, tt:965.355\n",
      "Ep:24, loss:0.00020, loss_test:0.13537, lr:7.86e-03, fs:0.82297 (r=0.869,p=0.782),  time:40.237, tt:1005.930\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.12546, lr:7.78e-03, fs:0.83258 (r=0.929,p=0.754),  time:40.311, tt:1048.087\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.12494, lr:7.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:40.431, tt:1091.651\n",
      "Ep:27, loss:0.00018, loss_test:0.11902, lr:7.62e-03, fs:0.82143 (r=0.929,p=0.736),  time:40.492, tt:1133.771\n",
      "Ep:28, loss:0.00017, loss_test:0.13236, lr:7.55e-03, fs:0.86139 (r=0.879,p=0.845),  time:40.563, tt:1176.330\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.11693, lr:7.47e-03, fs:0.81982 (r=0.919,p=0.740),  time:40.492, tt:1214.755\n",
      "Ep:30, loss:0.00016, loss_test:0.12099, lr:7.40e-03, fs:0.85308 (r=0.909,p=0.804),  time:40.424, tt:1253.146\n",
      "Ep:31, loss:0.00017, loss_test:0.11904, lr:7.32e-03, fs:0.83333 (r=0.909,p=0.769),  time:40.377, tt:1292.057\n",
      "Ep:32, loss:0.00015, loss_test:0.11572, lr:7.25e-03, fs:0.82456 (r=0.949,p=0.729),  time:40.391, tt:1332.916\n",
      "Ep:33, loss:0.00015, loss_test:0.12784, lr:7.18e-03, fs:0.92308 (r=0.909,p=0.938),  time:40.349, tt:1371.859\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.10605, lr:7.11e-03, fs:0.84305 (r=0.949,p=0.758),  time:40.253, tt:1408.864\n",
      "Ep:35, loss:0.00014, loss_test:0.11888, lr:7.03e-03, fs:0.86667 (r=0.919,p=0.820),  time:40.322, tt:1451.596\n",
      "Ep:36, loss:0.00014, loss_test:0.10777, lr:6.96e-03, fs:0.80870 (r=0.939,p=0.710),  time:40.498, tt:1498.444\n",
      "Ep:37, loss:0.00014, loss_test:0.10437, lr:6.89e-03, fs:0.85981 (r=0.929,p=0.800),  time:40.555, tt:1541.075\n",
      "Ep:38, loss:0.00013, loss_test:0.12396, lr:6.83e-03, fs:0.92784 (r=0.909,p=0.947),  time:40.677, tt:1586.387\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.10566, lr:6.76e-03, fs:0.85981 (r=0.929,p=0.800),  time:40.679, tt:1627.167\n",
      "Ep:40, loss:0.00012, loss_test:0.11269, lr:6.69e-03, fs:0.92000 (r=0.929,p=0.911),  time:40.658, tt:1666.998\n",
      "Ep:41, loss:0.00012, loss_test:0.11718, lr:6.62e-03, fs:0.90000 (r=0.909,p=0.891),  time:40.692, tt:1709.081\n",
      "Ep:42, loss:0.00012, loss_test:0.11148, lr:6.56e-03, fs:0.84793 (r=0.929,p=0.780),  time:40.694, tt:1749.848\n",
      "Ep:43, loss:0.00011, loss_test:0.10763, lr:6.49e-03, fs:0.89655 (r=0.919,p=0.875),  time:40.712, tt:1791.327\n",
      "Ep:44, loss:0.00010, loss_test:0.11035, lr:6.43e-03, fs:0.88462 (r=0.929,p=0.844),  time:40.745, tt:1833.529\n",
      "Ep:45, loss:0.00010, loss_test:0.11431, lr:6.36e-03, fs:0.89552 (r=0.909,p=0.882),  time:40.788, tt:1876.228\n",
      "Ep:46, loss:0.00010, loss_test:0.09950, lr:6.30e-03, fs:0.88038 (r=0.929,p=0.836),  time:40.832, tt:1919.104\n",
      "Ep:47, loss:0.00009, loss_test:0.11997, lr:6.24e-03, fs:0.89899 (r=0.899,p=0.899),  time:40.922, tt:1964.251\n",
      "Ep:48, loss:0.00009, loss_test:0.12831, lr:6.17e-03, fs:0.87500 (r=0.848,p=0.903),  time:40.999, tt:2008.975\n",
      "Ep:49, loss:0.00009, loss_test:0.09566, lr:6.11e-03, fs:0.81223 (r=0.939,p=0.715),  time:40.993, tt:2049.654\n",
      "Ep:50, loss:0.00011, loss_test:0.10934, lr:5.99e-03, fs:0.84615 (r=0.889,p=0.807),  time:40.965, tt:2089.225\n",
      "Ep:51, loss:0.00010, loss_test:0.11985, lr:5.87e-03, fs:0.88325 (r=0.879,p=0.888),  time:40.994, tt:2131.676\n",
      "Ep:52, loss:0.00010, loss_test:0.11454, lr:5.75e-03, fs:0.83258 (r=0.929,p=0.754),  time:40.984, tt:2172.139\n",
      "Ep:53, loss:0.00010, loss_test:0.11767, lr:5.64e-03, fs:0.81481 (r=0.889,p=0.752),  time:40.921, tt:2209.731\n",
      "Ep:54, loss:0.00010, loss_test:0.11303, lr:5.53e-03, fs:0.91000 (r=0.919,p=0.901),  time:40.954, tt:2252.457\n",
      "Ep:55, loss:0.00010, loss_test:0.11296, lr:5.42e-03, fs:0.90155 (r=0.879,p=0.926),  time:40.992, tt:2295.561\n",
      "Ep:56, loss:0.00008, loss_test:0.10320, lr:5.31e-03, fs:0.84615 (r=0.889,p=0.807),  time:41.031, tt:2338.793\n",
      "Ep:57, loss:0.00008, loss_test:0.11851, lr:5.20e-03, fs:0.88083 (r=0.859,p=0.904),  time:41.073, tt:2382.235\n",
      "Ep:58, loss:0.00007, loss_test:0.08433, lr:5.10e-03, fs:0.90821 (r=0.949,p=0.870),  time:41.130, tt:2426.653\n",
      "Ep:59, loss:0.00006, loss_test:0.10685, lr:5.00e-03, fs:0.86567 (r=0.879,p=0.853),  time:41.144, tt:2468.666\n",
      "Ep:60, loss:0.00006, loss_test:0.08907, lr:4.90e-03, fs:0.87923 (r=0.919,p=0.843),  time:41.158, tt:2510.658\n",
      "Ep:61, loss:0.00006, loss_test:0.11398, lr:4.80e-03, fs:0.83568 (r=0.899,p=0.781),  time:41.172, tt:2552.652\n",
      "Ep:62, loss:0.00006, loss_test:0.09115, lr:4.71e-03, fs:0.89552 (r=0.909,p=0.882),  time:41.192, tt:2595.066\n",
      "Ep:63, loss:0.00006, loss_test:0.11056, lr:4.61e-03, fs:0.85279 (r=0.848,p=0.857),  time:41.201, tt:2636.861\n",
      "Ep:64, loss:0.00007, loss_test:0.10148, lr:4.52e-03, fs:0.86408 (r=0.899,p=0.832),  time:41.217, tt:2679.088\n",
      "Ep:65, loss:0.00007, loss_test:0.13397, lr:4.43e-03, fs:0.78723 (r=0.747,p=0.831),  time:41.295, tt:2725.443\n",
      "Ep:66, loss:0.00007, loss_test:0.11263, lr:4.34e-03, fs:0.87047 (r=0.848,p=0.894),  time:41.363, tt:2771.312\n",
      "Ep:67, loss:0.00007, loss_test:0.13741, lr:4.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.426, tt:2816.971\n",
      "Ep:68, loss:0.00008, loss_test:0.10822, lr:4.17e-03, fs:0.85714 (r=0.848,p=0.866),  time:41.463, tt:2860.978\n",
      "Ep:69, loss:0.00008, loss_test:0.09861, lr:4.09e-03, fs:0.88889 (r=0.889,p=0.889),  time:41.470, tt:2902.902\n",
      "Ep:70, loss:0.00008, loss_test:0.12866, lr:4.01e-03, fs:0.84211 (r=0.808,p=0.879),  time:41.470, tt:2944.358\n",
      "Ep:71, loss:0.00008, loss_test:0.10180, lr:3.93e-03, fs:0.88479 (r=0.970,p=0.814),  time:41.445, tt:2984.038\n",
      "Ep:72, loss:0.00014, loss_test:0.13751, lr:3.85e-03, fs:0.80788 (r=0.828,p=0.788),  time:41.448, tt:3025.669\n",
      "Ep:73, loss:0.00020, loss_test:0.14659, lr:3.77e-03, fs:0.81905 (r=0.869,p=0.775),  time:41.448, tt:3067.133\n",
      "Ep:74, loss:0.00018, loss_test:0.14394, lr:3.70e-03, fs:0.81340 (r=0.859,p=0.773),  time:41.479, tt:3110.949\n",
      "Ep:75, loss:0.00020, loss_test:0.14360, lr:3.62e-03, fs:0.75486 (r=0.980,p=0.614),  time:41.511, tt:3154.833\n",
      "Ep:76, loss:0.00026, loss_test:0.17467, lr:3.55e-03, fs:0.67577 (r=1.000,p=0.510),  time:41.570, tt:3200.889\n",
      "Ep:77, loss:0.00031, loss_test:0.13954, lr:3.48e-03, fs:0.73485 (r=0.980,p=0.588),  time:41.617, tt:3246.134\n",
      "Ep:78, loss:0.00026, loss_test:0.13615, lr:3.41e-03, fs:0.80342 (r=0.949,p=0.696),  time:41.612, tt:3287.373\n",
      "Ep:79, loss:0.00022, loss_test:0.13431, lr:3.34e-03, fs:0.77778 (r=0.990,p=0.641),  time:41.614, tt:3329.096\n",
      "Ep:80, loss:0.00021, loss_test:0.12916, lr:3.28e-03, fs:0.82456 (r=0.949,p=0.729),  time:41.592, tt:3368.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:81, loss:0.00020, loss_test:0.12704, lr:3.21e-03, fs:0.80176 (r=0.919,p=0.711),  time:41.586, tt:3410.072\n",
      "Ep:82, loss:0.00019, loss_test:0.12152, lr:3.15e-03, fs:0.77366 (r=0.949,p=0.653),  time:41.564, tt:3449.783\n",
      "Ep:83, loss:0.00019, loss_test:0.11582, lr:3.09e-03, fs:0.80833 (r=0.980,p=0.688),  time:41.559, tt:3490.985\n",
      "Ep:84, loss:0.00017, loss_test:0.11561, lr:3.02e-03, fs:0.83404 (r=0.990,p=0.721),  time:41.573, tt:3533.737\n",
      "Ep:85, loss:0.00017, loss_test:0.11140, lr:2.96e-03, fs:0.83193 (r=1.000,p=0.712),  time:41.601, tt:3577.661\n",
      "Ep:86, loss:0.00016, loss_test:0.10027, lr:2.90e-03, fs:0.78862 (r=0.980,p=0.660),  time:41.648, tt:3623.357\n",
      "Ep:87, loss:0.00016, loss_test:0.10387, lr:2.85e-03, fs:0.81013 (r=0.970,p=0.696),  time:41.687, tt:3668.420\n",
      "Ep:88, loss:0.00015, loss_test:0.10243, lr:2.79e-03, fs:0.84483 (r=0.990,p=0.737),  time:41.676, tt:3709.171\n",
      "Ep:89, loss:0.00015, loss_test:0.08883, lr:2.73e-03, fs:0.86087 (r=1.000,p=0.756),  time:41.666, tt:3749.946\n",
      "Ep:90, loss:0.00013, loss_test:0.09597, lr:2.68e-03, fs:0.83193 (r=1.000,p=0.712),  time:41.622, tt:3787.606\n",
      "Ep:91, loss:0.00016, loss_test:0.10665, lr:2.63e-03, fs:0.79661 (r=0.949,p=0.686),  time:41.621, tt:3829.142\n",
      "Ep:92, loss:0.00015, loss_test:0.10109, lr:2.57e-03, fs:0.83544 (r=1.000,p=0.717),  time:41.573, tt:3866.281\n",
      "Ep:93, loss:0.00015, loss_test:0.10826, lr:2.52e-03, fs:0.78571 (r=1.000,p=0.647),  time:41.552, tt:3905.846\n",
      "Ep:94, loss:0.00014, loss_test:0.09789, lr:2.47e-03, fs:0.82158 (r=1.000,p=0.697),  time:41.540, tt:3946.280\n",
      "Ep:95, loss:0.00015, loss_test:0.10655, lr:2.42e-03, fs:0.83408 (r=0.939,p=0.750),  time:41.509, tt:3984.854\n",
      "Ep:96, loss:0.00015, loss_test:0.09316, lr:2.38e-03, fs:0.85965 (r=0.990,p=0.760),  time:41.496, tt:4025.121\n",
      "Ep:97, loss:0.00012, loss_test:0.09501, lr:2.33e-03, fs:0.82158 (r=1.000,p=0.697),  time:41.477, tt:4064.707\n",
      "Ep:98, loss:0.00012, loss_test:0.08946, lr:2.28e-03, fs:0.85714 (r=1.000,p=0.750),  time:41.456, tt:4104.130\n",
      "Ep:99, loss:0.00012, loss_test:0.09941, lr:2.24e-03, fs:0.85965 (r=0.990,p=0.760),  time:41.431, tt:4143.060\n",
      "Ep:100, loss:0.00011, loss_test:0.09703, lr:2.19e-03, fs:0.87111 (r=0.990,p=0.778),  time:41.397, tt:4181.071\n",
      "Ep:101, loss:0.00011, loss_test:0.09493, lr:2.15e-03, fs:0.83929 (r=0.949,p=0.752),  time:41.365, tt:4219.252\n",
      "Ep:102, loss:0.00010, loss_test:0.08922, lr:2.11e-03, fs:0.85841 (r=0.980,p=0.764),  time:41.351, tt:4259.183\n",
      "Ep:103, loss:0.00010, loss_test:0.08546, lr:2.06e-03, fs:0.87273 (r=0.970,p=0.793),  time:41.328, tt:4298.108\n",
      "Ep:104, loss:0.00011, loss_test:0.09048, lr:2.02e-03, fs:0.85714 (r=0.970,p=0.768),  time:41.318, tt:4338.431\n",
      "Ep:105, loss:0.00009, loss_test:0.08879, lr:1.98e-03, fs:0.87387 (r=0.980,p=0.789),  time:41.302, tt:4377.982\n",
      "Ep:106, loss:0.00009, loss_test:0.08423, lr:1.94e-03, fs:0.86758 (r=0.960,p=0.792),  time:41.276, tt:4416.523\n",
      "Ep:107, loss:0.00009, loss_test:0.08832, lr:1.90e-03, fs:0.88288 (r=0.990,p=0.797),  time:41.251, tt:4455.098\n",
      "Ep:108, loss:0.00008, loss_test:0.06993, lr:1.87e-03, fs:0.87736 (r=0.939,p=0.823),  time:41.207, tt:4491.576\n",
      "Ep:109, loss:0.00008, loss_test:0.07059, lr:1.83e-03, fs:0.89302 (r=0.970,p=0.828),  time:41.185, tt:4530.394\n",
      "Ep:110, loss:0.00008, loss_test:0.07486, lr:1.79e-03, fs:0.88991 (r=0.980,p=0.815),  time:41.153, tt:4568.030\n",
      "Ep:111, loss:0.00008, loss_test:0.06979, lr:1.76e-03, fs:0.87736 (r=0.939,p=0.823),  time:41.124, tt:4605.850\n",
      "Ep:112, loss:0.00008, loss_test:0.07705, lr:1.72e-03, fs:0.87783 (r=0.980,p=0.795),  time:41.088, tt:4642.983\n",
      "Ep:113, loss:0.00007, loss_test:0.06943, lr:1.69e-03, fs:0.88991 (r=0.980,p=0.815),  time:41.052, tt:4679.946\n",
      "Ep:114, loss:0.00006, loss_test:0.06671, lr:1.65e-03, fs:0.89815 (r=0.980,p=0.829),  time:41.022, tt:4717.493\n",
      "Ep:115, loss:0.00007, loss_test:0.07137, lr:1.62e-03, fs:0.90476 (r=0.960,p=0.856),  time:41.000, tt:4756.004\n",
      "Ep:116, loss:0.00006, loss_test:0.08041, lr:1.59e-03, fs:0.90141 (r=0.970,p=0.842),  time:40.991, tt:4795.959\n",
      "Ep:117, loss:0.00006, loss_test:0.07137, lr:1.56e-03, fs:0.92308 (r=0.970,p=0.881),  time:40.982, tt:4835.902\n",
      "Ep:118, loss:0.00005, loss_test:0.06214, lr:1.53e-03, fs:0.91509 (r=0.980,p=0.858),  time:40.974, tt:4875.949\n",
      "Ep:119, loss:0.00006, loss_test:0.06102, lr:1.50e-03, fs:0.90566 (r=0.970,p=0.850),  time:40.969, tt:4916.273\n",
      "Ep:120, loss:0.00005, loss_test:0.06715, lr:1.47e-03, fs:0.90566 (r=0.970,p=0.850),  time:40.945, tt:4954.317\n",
      "Ep:121, loss:0.00005, loss_test:0.07572, lr:1.44e-03, fs:0.90141 (r=0.970,p=0.842),  time:40.917, tt:4991.888\n",
      "Ep:122, loss:0.00005, loss_test:0.07506, lr:1.41e-03, fs:0.89855 (r=0.939,p=0.861),  time:40.892, tt:5029.767\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 12\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24560, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.715, tt:38.715\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24393, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.023, tt:76.046\n",
      "Ep:2, loss:0.00057, loss_test:0.24013, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.177, tt:114.530\n",
      "Ep:3, loss:0.00051, loss_test:0.23264, lr:9.70e-03, fs:0.64360 (r=0.939,p=0.489),  time:38.001, tt:152.005\n",
      "Ep:4, loss:0.00042, loss_test:0.22601, lr:9.61e-03, fs:0.63158 (r=0.848,p=0.503),  time:37.616, tt:188.078\n",
      "Ep:5, loss:0.00033, loss_test:0.22359, lr:9.51e-03, fs:0.63745 (r=0.808,p=0.526),  time:37.425, tt:224.550\n",
      "Ep:6, loss:0.00031, loss_test:0.22046, lr:9.41e-03, fs:0.64754 (r=0.798,p=0.545),  time:36.896, tt:258.274\n",
      "Ep:7, loss:0.00030, loss_test:0.21661, lr:9.32e-03, fs:0.65532 (r=0.778,p=0.566),  time:36.526, tt:292.204\n",
      "Ep:8, loss:0.00029, loss_test:0.21577, lr:9.23e-03, fs:0.65217 (r=0.758,p=0.573),  time:36.791, tt:331.123\n",
      "Ep:9, loss:0.00028, loss_test:0.21132, lr:9.14e-03, fs:0.65801 (r=0.768,p=0.576),  time:37.012, tt:370.118\n",
      "Ep:10, loss:0.00028, loss_test:0.21028, lr:9.04e-03, fs:0.63303 (r=0.697,p=0.580),  time:37.070, tt:407.765\n",
      "Ep:11, loss:0.00027, loss_test:0.20336, lr:8.95e-03, fs:0.62780 (r=0.707,p=0.565),  time:37.269, tt:447.229\n",
      "Ep:12, loss:0.00026, loss_test:0.20573, lr:8.78e-03, fs:0.68376 (r=0.808,p=0.593),  time:37.336, tt:485.372\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.19522, lr:8.69e-03, fs:0.69604 (r=0.798,p=0.617),  time:37.445, tt:524.231\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.18816, lr:8.60e-03, fs:0.67797 (r=0.808,p=0.584),  time:37.471, tt:562.068\n",
      "Ep:15, loss:0.00023, loss_test:0.19375, lr:8.51e-03, fs:0.68067 (r=0.818,p=0.583),  time:37.534, tt:600.543\n",
      "Ep:16, loss:0.00023, loss_test:0.19529, lr:8.43e-03, fs:0.70852 (r=0.798,p=0.637),  time:37.614, tt:639.431\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.18733, lr:8.35e-03, fs:0.72489 (r=0.838,p=0.638),  time:37.651, tt:677.712\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.18514, lr:8.26e-03, fs:0.70940 (r=0.838,p=0.615),  time:37.735, tt:716.972\n",
      "Ep:19, loss:0.00022, loss_test:0.18917, lr:8.18e-03, fs:0.72362 (r=0.727,p=0.720),  time:37.757, tt:755.143\n",
      "Ep:20, loss:0.00021, loss_test:0.17488, lr:8.10e-03, fs:0.71901 (r=0.879,p=0.608),  time:37.795, tt:793.698\n",
      "Ep:21, loss:0.00021, loss_test:0.18551, lr:8.02e-03, fs:0.74757 (r=0.778,p=0.720),  time:37.940, tt:834.685\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.17485, lr:7.94e-03, fs:0.77570 (r=0.838,p=0.722),  time:37.947, tt:872.771\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.16651, lr:7.86e-03, fs:0.71837 (r=0.889,p=0.603),  time:38.008, tt:912.185\n",
      "Ep:24, loss:0.00020, loss_test:0.18037, lr:7.78e-03, fs:0.80402 (r=0.808,p=0.800),  time:38.045, tt:951.113\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.16937, lr:7.70e-03, fs:0.74894 (r=0.889,p=0.647),  time:38.091, tt:990.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00018, loss_test:0.16123, lr:7.62e-03, fs:0.78378 (r=0.879,p=0.707),  time:38.086, tt:1028.328\n",
      "Ep:27, loss:0.00017, loss_test:0.16810, lr:7.55e-03, fs:0.76271 (r=0.909,p=0.657),  time:38.049, tt:1065.370\n",
      "Ep:28, loss:0.00017, loss_test:0.15798, lr:7.47e-03, fs:0.77778 (r=0.848,p=0.718),  time:38.056, tt:1103.621\n",
      "Ep:29, loss:0.00016, loss_test:0.16694, lr:7.40e-03, fs:0.79803 (r=0.818,p=0.779),  time:38.035, tt:1141.042\n",
      "Ep:30, loss:0.00016, loss_test:0.15804, lr:7.32e-03, fs:0.75745 (r=0.899,p=0.654),  time:38.091, tt:1180.829\n",
      "Ep:31, loss:0.00015, loss_test:0.15475, lr:7.25e-03, fs:0.80193 (r=0.838,p=0.769),  time:38.071, tt:1218.260\n",
      "Ep:32, loss:0.00015, loss_test:0.15359, lr:7.18e-03, fs:0.82524 (r=0.859,p=0.794),  time:38.043, tt:1255.428\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.15311, lr:7.11e-03, fs:0.75862 (r=0.889,p=0.662),  time:38.064, tt:1294.184\n",
      "Ep:34, loss:0.00014, loss_test:0.15976, lr:7.03e-03, fs:0.77982 (r=0.859,p=0.714),  time:38.013, tt:1330.443\n",
      "Ep:35, loss:0.00014, loss_test:0.15870, lr:6.96e-03, fs:0.78431 (r=0.808,p=0.762),  time:38.044, tt:1369.570\n",
      "Ep:36, loss:0.00014, loss_test:0.17345, lr:6.89e-03, fs:0.76712 (r=0.848,p=0.700),  time:38.118, tt:1410.353\n",
      "Ep:37, loss:0.00013, loss_test:0.16323, lr:6.83e-03, fs:0.80829 (r=0.788,p=0.830),  time:38.151, tt:1449.753\n",
      "Ep:38, loss:0.00012, loss_test:0.15390, lr:6.76e-03, fs:0.75630 (r=0.909,p=0.647),  time:38.182, tt:1489.088\n",
      "Ep:39, loss:0.00014, loss_test:0.15562, lr:6.69e-03, fs:0.75362 (r=0.788,p=0.722),  time:38.210, tt:1528.399\n",
      "Ep:40, loss:0.00014, loss_test:0.15656, lr:6.62e-03, fs:0.81675 (r=0.788,p=0.848),  time:38.202, tt:1566.282\n",
      "Ep:41, loss:0.00012, loss_test:0.14399, lr:6.56e-03, fs:0.71369 (r=0.869,p=0.606),  time:38.244, tt:1606.228\n",
      "Ep:42, loss:0.00015, loss_test:0.15079, lr:6.49e-03, fs:0.77253 (r=0.909,p=0.672),  time:38.238, tt:1644.248\n",
      "Ep:43, loss:0.00014, loss_test:0.14464, lr:6.43e-03, fs:0.80569 (r=0.859,p=0.759),  time:38.275, tt:1684.111\n",
      "Ep:44, loss:0.00012, loss_test:0.14320, lr:6.30e-03, fs:0.80383 (r=0.848,p=0.764),  time:38.325, tt:1724.609\n",
      "Ep:45, loss:0.00011, loss_test:0.14556, lr:6.17e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.300, tt:1761.821\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00011, loss_test:0.15333, lr:6.11e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.327, tt:1801.365\n",
      "Ep:47, loss:0.00010, loss_test:0.15392, lr:6.05e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.363, tt:1841.404\n",
      "Ep:48, loss:0.00009, loss_test:0.15854, lr:5.99e-03, fs:0.73797 (r=0.697,p=0.784),  time:38.330, tt:1878.175\n",
      "Ep:49, loss:0.00012, loss_test:0.13446, lr:5.93e-03, fs:0.79508 (r=0.980,p=0.669),  time:38.343, tt:1917.134\n",
      "Ep:50, loss:0.00012, loss_test:0.14481, lr:5.87e-03, fs:0.77934 (r=0.838,p=0.728),  time:38.368, tt:1956.766\n",
      "Ep:51, loss:0.00012, loss_test:0.15113, lr:5.81e-03, fs:0.70817 (r=0.919,p=0.576),  time:38.360, tt:1994.718\n",
      "Ep:52, loss:0.00012, loss_test:0.15175, lr:5.75e-03, fs:0.81340 (r=0.859,p=0.773),  time:38.358, tt:2032.993\n",
      "Ep:53, loss:0.00010, loss_test:0.13483, lr:5.70e-03, fs:0.81132 (r=0.869,p=0.761),  time:38.402, tt:2073.715\n",
      "Ep:54, loss:0.00009, loss_test:0.17713, lr:5.64e-03, fs:0.79096 (r=0.707,p=0.897),  time:38.422, tt:2113.182\n",
      "Ep:55, loss:0.00009, loss_test:0.16825, lr:5.58e-03, fs:0.68526 (r=0.869,p=0.566),  time:38.419, tt:2151.453\n",
      "Ep:56, loss:0.00015, loss_test:0.14454, lr:5.53e-03, fs:0.76078 (r=0.980,p=0.622),  time:38.425, tt:2190.245\n",
      "Ep:57, loss:0.00015, loss_test:0.19893, lr:5.42e-03, fs:0.72165 (r=0.707,p=0.737),  time:38.469, tt:2231.208\n",
      "Ep:58, loss:0.00013, loss_test:0.13275, lr:5.31e-03, fs:0.76923 (r=0.960,p=0.642),  time:38.481, tt:2270.358\n",
      "Ep:59, loss:0.00013, loss_test:0.13304, lr:5.20e-03, fs:0.81651 (r=0.899,p=0.748),  time:38.527, tt:2311.636\n",
      "Ep:60, loss:0.00011, loss_test:0.16502, lr:5.10e-03, fs:0.76142 (r=0.758,p=0.765),  time:38.553, tt:2351.727\n",
      "Ep:61, loss:0.00012, loss_test:0.15467, lr:5.00e-03, fs:0.79167 (r=0.768,p=0.817),  time:38.593, tt:2392.746\n",
      "Ep:62, loss:0.00011, loss_test:0.18168, lr:4.90e-03, fs:0.74444 (r=0.677,p=0.827),  time:38.606, tt:2432.194\n",
      "Ep:63, loss:0.00009, loss_test:0.13859, lr:4.80e-03, fs:0.80423 (r=0.768,p=0.844),  time:38.640, tt:2472.970\n",
      "Ep:64, loss:0.00008, loss_test:0.16046, lr:4.71e-03, fs:0.84000 (r=0.848,p=0.832),  time:38.666, tt:2513.297\n",
      "Ep:65, loss:0.00008, loss_test:0.14397, lr:4.61e-03, fs:0.83019 (r=0.889,p=0.779),  time:38.679, tt:2552.838\n",
      "Ep:66, loss:0.00010, loss_test:0.12722, lr:4.52e-03, fs:0.80851 (r=0.960,p=0.699),  time:38.692, tt:2592.338\n",
      "Ep:67, loss:0.00011, loss_test:0.14212, lr:4.43e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.699, tt:2631.517\n",
      "Ep:68, loss:0.00014, loss_test:0.14808, lr:4.34e-03, fs:0.73554 (r=0.899,p=0.622),  time:38.696, tt:2670.013\n",
      "Ep:69, loss:0.00019, loss_test:0.16679, lr:4.26e-03, fs:0.70213 (r=1.000,p=0.541),  time:38.738, tt:2711.673\n",
      "Ep:70, loss:0.00029, loss_test:0.17621, lr:4.17e-03, fs:0.72932 (r=0.980,p=0.581),  time:38.753, tt:2751.488\n",
      "Ep:71, loss:0.00024, loss_test:0.19559, lr:4.09e-03, fs:0.69811 (r=0.747,p=0.655),  time:38.782, tt:2792.323\n",
      "Ep:72, loss:0.00022, loss_test:0.19213, lr:4.01e-03, fs:0.66667 (r=0.707,p=0.631),  time:38.805, tt:2832.737\n",
      "Ep:73, loss:0.00020, loss_test:0.17638, lr:3.93e-03, fs:0.70356 (r=0.899,p=0.578),  time:38.823, tt:2872.872\n",
      "Ep:74, loss:0.00021, loss_test:0.16893, lr:3.85e-03, fs:0.76018 (r=0.848,p=0.689),  time:38.839, tt:2912.959\n",
      "Ep:75, loss:0.00021, loss_test:0.18297, lr:3.77e-03, fs:0.71560 (r=0.788,p=0.655),  time:38.861, tt:2953.451\n",
      "Ep:76, loss:0.00019, loss_test:0.15962, lr:3.70e-03, fs:0.78607 (r=0.798,p=0.775),  time:38.868, tt:2992.854\n",
      "Ep:77, loss:0.00017, loss_test:0.14108, lr:3.62e-03, fs:0.75983 (r=0.879,p=0.669),  time:38.883, tt:3032.842\n",
      "Ep:78, loss:0.00015, loss_test:0.16307, lr:3.55e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.884, tt:3071.847\n",
      "Ep:79, loss:0.00014, loss_test:0.13358, lr:3.48e-03, fs:0.78899 (r=0.869,p=0.723),  time:38.872, tt:3109.778\n",
      "Ep:80, loss:0.00013, loss_test:0.15117, lr:3.41e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.873, tt:3148.713\n",
      "Ep:81, loss:0.00013, loss_test:0.14735, lr:3.34e-03, fs:0.76364 (r=0.848,p=0.694),  time:38.904, tt:3190.156\n",
      "Ep:82, loss:0.00010, loss_test:0.13347, lr:3.28e-03, fs:0.78027 (r=0.879,p=0.702),  time:38.906, tt:3229.217\n",
      "Ep:83, loss:0.00011, loss_test:0.14219, lr:3.21e-03, fs:0.75349 (r=0.818,p=0.698),  time:38.909, tt:3268.352\n",
      "Ep:84, loss:0.00011, loss_test:0.16780, lr:3.15e-03, fs:0.77209 (r=0.838,p=0.716),  time:38.913, tt:3307.578\n",
      "Ep:85, loss:0.00010, loss_test:0.14351, lr:3.09e-03, fs:0.76555 (r=0.808,p=0.727),  time:38.922, tt:3347.318\n",
      "Ep:86, loss:0.00009, loss_test:0.12326, lr:3.02e-03, fs:0.78704 (r=0.859,p=0.726),  time:38.909, tt:3385.117\n",
      "Ep:87, loss:0.00010, loss_test:0.12573, lr:2.96e-03, fs:0.77512 (r=0.818,p=0.736),  time:38.919, tt:3424.903\n",
      "Ep:88, loss:0.00009, loss_test:0.13871, lr:2.90e-03, fs:0.78302 (r=0.838,p=0.735),  time:38.918, tt:3463.743\n",
      "Ep:89, loss:0.00008, loss_test:0.13415, lr:2.85e-03, fs:0.77143 (r=0.818,p=0.730),  time:38.898, tt:3500.804\n",
      "Ep:90, loss:0.00008, loss_test:0.12314, lr:2.79e-03, fs:0.79412 (r=0.818,p=0.771),  time:38.899, tt:3539.835\n",
      "Ep:91, loss:0.00009, loss_test:0.12466, lr:2.73e-03, fs:0.78302 (r=0.838,p=0.735),  time:38.920, tt:3580.686\n",
      "Ep:92, loss:0.00008, loss_test:0.12926, lr:2.68e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.918, tt:3619.406\n",
      "Ep:93, loss:0.00008, loss_test:0.14446, lr:2.63e-03, fs:0.79412 (r=0.818,p=0.771),  time:38.914, tt:3657.935\n",
      "Ep:94, loss:0.00007, loss_test:0.11590, lr:2.57e-03, fs:0.76847 (r=0.788,p=0.750),  time:38.912, tt:3696.653\n",
      "Ep:95, loss:0.00006, loss_test:0.11530, lr:2.52e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.924, tt:3736.664\n",
      "Ep:96, loss:0.00007, loss_test:0.12762, lr:2.47e-03, fs:0.80198 (r=0.818,p=0.786),  time:38.938, tt:3776.954\n",
      "Ep:97, loss:0.00006, loss_test:0.12759, lr:2.42e-03, fs:0.77833 (r=0.798,p=0.760),  time:38.952, tt:3817.330\n",
      "Ep:98, loss:0.00006, loss_test:0.14542, lr:2.38e-03, fs:0.82412 (r=0.828,p=0.820),  time:38.965, tt:3857.505\n",
      "Ep:99, loss:0.00006, loss_test:0.11572, lr:2.33e-03, fs:0.80808 (r=0.808,p=0.808),  time:38.978, tt:3897.840\n",
      "Ep:100, loss:0.00006, loss_test:0.11492, lr:2.28e-03, fs:0.84360 (r=0.899,p=0.795),  time:38.997, tt:3938.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00006, loss_test:0.11999, lr:2.24e-03, fs:0.82000 (r=0.828,p=0.812),  time:38.994, tt:3977.359\n",
      "Ep:102, loss:0.00005, loss_test:0.13509, lr:2.19e-03, fs:0.78571 (r=0.778,p=0.794),  time:39.005, tt:4017.506\n",
      "Ep:103, loss:0.00005, loss_test:0.13435, lr:2.15e-03, fs:0.80000 (r=0.788,p=0.812),  time:38.999, tt:4055.933\n",
      "Ep:104, loss:0.00005, loss_test:0.12352, lr:2.11e-03, fs:0.81818 (r=0.818,p=0.818),  time:38.995, tt:4094.467\n",
      "Ep:105, loss:0.00005, loss_test:0.11388, lr:2.06e-03, fs:0.83254 (r=0.879,p=0.791),  time:38.982, tt:4132.101\n",
      "Ep:106, loss:0.00004, loss_test:0.10829, lr:2.02e-03, fs:0.84103 (r=0.828,p=0.854),  time:38.976, tt:4170.469\n",
      "Ep:107, loss:0.00005, loss_test:0.11888, lr:1.98e-03, fs:0.80628 (r=0.778,p=0.837),  time:38.983, tt:4210.160\n",
      "Ep:108, loss:0.00004, loss_test:0.11691, lr:1.94e-03, fs:0.81250 (r=0.788,p=0.839),  time:38.988, tt:4249.675\n",
      "Ep:109, loss:0.00004, loss_test:0.10834, lr:1.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:38.983, tt:4288.094\n",
      "Ep:110, loss:0.00004, loss_test:0.13989, lr:1.87e-03, fs:0.75000 (r=0.697,p=0.812),  time:38.986, tt:4327.452\n",
      "Ep:111, loss:0.00004, loss_test:0.13199, lr:1.83e-03, fs:0.82828 (r=0.828,p=0.828),  time:38.983, tt:4366.118\n",
      "Ep:112, loss:0.00004, loss_test:0.11846, lr:1.79e-03, fs:0.82653 (r=0.818,p=0.835),  time:38.977, tt:4404.413\n",
      "Ep:113, loss:0.00004, loss_test:0.10451, lr:1.76e-03, fs:0.83505 (r=0.818,p=0.853),  time:38.981, tt:4443.799\n",
      "Ep:114, loss:0.00004, loss_test:0.10396, lr:1.72e-03, fs:0.84536 (r=0.828,p=0.863),  time:38.974, tt:4482.016\n",
      "Ep:115, loss:0.00004, loss_test:0.11424, lr:1.69e-03, fs:0.84974 (r=0.828,p=0.872),  time:38.978, tt:4521.448\n",
      "Ep:116, loss:0.00004, loss_test:0.11751, lr:1.65e-03, fs:0.83505 (r=0.818,p=0.853),  time:38.974, tt:4559.964\n",
      "Ep:117, loss:0.00004, loss_test:0.12224, lr:1.62e-03, fs:0.83938 (r=0.818,p=0.862),  time:38.960, tt:4597.228\n",
      "Ep:118, loss:0.00004, loss_test:0.12409, lr:1.59e-03, fs:0.83422 (r=0.788,p=0.886),  time:38.982, tt:4638.874\n",
      "Ep:119, loss:0.00003, loss_test:0.10812, lr:1.56e-03, fs:0.82723 (r=0.798,p=0.859),  time:38.996, tt:4679.485\n",
      "Ep:120, loss:0.00003, loss_test:0.10431, lr:1.53e-03, fs:0.83938 (r=0.818,p=0.862),  time:39.012, tt:4720.489\n",
      "Ep:121, loss:0.00004, loss_test:0.10434, lr:1.50e-03, fs:0.82653 (r=0.818,p=0.835),  time:38.987, tt:4756.450\n",
      "Ep:122, loss:0.00004, loss_test:0.09674, lr:1.47e-03, fs:0.84974 (r=0.828,p=0.872),  time:39.004, tt:4797.477\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 13\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24364, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.954, tt:37.954\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24139, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.904, tt:75.808\n",
      "Ep:2, loss:0.00057, loss_test:0.23655, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.155, tt:114.464\n",
      "Ep:3, loss:0.00051, loss_test:0.22954, lr:9.70e-03, fs:0.65505 (r=0.949,p=0.500),  time:38.363, tt:153.451\n",
      "Ep:4, loss:0.00043, loss_test:0.22327, lr:9.61e-03, fs:0.62069 (r=0.818,p=0.500),  time:37.367, tt:186.834\n",
      "Ep:5, loss:0.00035, loss_test:0.22246, lr:9.51e-03, fs:0.61472 (r=0.717,p=0.538),  time:37.678, tt:226.067\n",
      "Ep:6, loss:0.00032, loss_test:0.22077, lr:9.41e-03, fs:0.58929 (r=0.667,p=0.528),  time:37.180, tt:260.259\n",
      "Ep:7, loss:0.00031, loss_test:0.22240, lr:9.32e-03, fs:0.55924 (r=0.596,p=0.527),  time:36.528, tt:292.223\n",
      "Ep:8, loss:0.00029, loss_test:0.21569, lr:9.23e-03, fs:0.62162 (r=0.697,p=0.561),  time:36.438, tt:327.939\n",
      "Ep:9, loss:0.00028, loss_test:0.21421, lr:9.14e-03, fs:0.61682 (r=0.667,p=0.574),  time:36.661, tt:366.606\n",
      "Ep:10, loss:0.00028, loss_test:0.20629, lr:9.04e-03, fs:0.66038 (r=0.707,p=0.619),  time:36.663, tt:403.288\n",
      "Ep:11, loss:0.00027, loss_test:0.20262, lr:8.95e-03, fs:0.68246 (r=0.727,p=0.643),  time:36.612, tt:439.343\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.19641, lr:8.86e-03, fs:0.68142 (r=0.778,p=0.606),  time:36.809, tt:478.513\n",
      "Ep:13, loss:0.00026, loss_test:0.19139, lr:8.78e-03, fs:0.69725 (r=0.768,p=0.639),  time:36.791, tt:515.075\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.18418, lr:8.69e-03, fs:0.70909 (r=0.788,p=0.645),  time:36.929, tt:553.931\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.18452, lr:8.60e-03, fs:0.74336 (r=0.848,p=0.661),  time:36.981, tt:591.688\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.17979, lr:8.51e-03, fs:0.77358 (r=0.828,p=0.726),  time:37.006, tt:629.103\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.17559, lr:8.43e-03, fs:0.76018 (r=0.848,p=0.689),  time:37.131, tt:668.355\n",
      "Ep:18, loss:0.00022, loss_test:0.18234, lr:8.35e-03, fs:0.76555 (r=0.808,p=0.727),  time:37.170, tt:706.222\n",
      "Ep:19, loss:0.00021, loss_test:0.16808, lr:8.26e-03, fs:0.78070 (r=0.899,p=0.690),  time:37.140, tt:742.805\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.18369, lr:8.18e-03, fs:0.74882 (r=0.798,p=0.705),  time:37.171, tt:780.600\n",
      "Ep:21, loss:0.00021, loss_test:0.17628, lr:8.10e-03, fs:0.79812 (r=0.859,p=0.746),  time:37.229, tt:819.031\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.16929, lr:8.02e-03, fs:0.78571 (r=0.889,p=0.704),  time:37.326, tt:858.506\n",
      "Ep:23, loss:0.00019, loss_test:0.17867, lr:7.94e-03, fs:0.75000 (r=0.879,p=0.654),  time:37.400, tt:897.608\n",
      "Ep:24, loss:0.00019, loss_test:0.17295, lr:7.86e-03, fs:0.79245 (r=0.848,p=0.743),  time:37.378, tt:934.455\n",
      "Ep:25, loss:0.00019, loss_test:0.18656, lr:7.78e-03, fs:0.75132 (r=0.717,p=0.789),  time:37.397, tt:972.311\n",
      "Ep:26, loss:0.00018, loss_test:0.17243, lr:7.70e-03, fs:0.72269 (r=0.869,p=0.619),  time:37.420, tt:1010.338\n",
      "Ep:27, loss:0.00018, loss_test:0.17965, lr:7.62e-03, fs:0.73846 (r=0.727,p=0.750),  time:37.407, tt:1047.401\n",
      "Ep:28, loss:0.00017, loss_test:0.16254, lr:7.55e-03, fs:0.75862 (r=0.889,p=0.662),  time:37.423, tt:1085.268\n",
      "Ep:29, loss:0.00016, loss_test:0.16133, lr:7.47e-03, fs:0.76786 (r=0.869,p=0.688),  time:37.447, tt:1123.404\n",
      "Ep:30, loss:0.00016, loss_test:0.17250, lr:7.40e-03, fs:0.76617 (r=0.778,p=0.755),  time:37.476, tt:1161.747\n",
      "Ep:31, loss:0.00015, loss_test:0.16227, lr:7.32e-03, fs:0.78571 (r=0.889,p=0.704),  time:37.604, tt:1203.329\n",
      "Ep:32, loss:0.00015, loss_test:0.16403, lr:7.25e-03, fs:0.79621 (r=0.848,p=0.750),  time:37.615, tt:1241.292\n",
      "Ep:33, loss:0.00015, loss_test:0.17578, lr:7.11e-03, fs:0.70157 (r=0.677,p=0.728),  time:37.510, tt:1275.344\n",
      "Ep:34, loss:0.00014, loss_test:0.15034, lr:6.96e-03, fs:0.78632 (r=0.929,p=0.681),  time:37.477, tt:1311.687\n",
      "Ep:35, loss:0.00013, loss_test:0.16983, lr:6.83e-03, fs:0.74372 (r=0.747,p=0.740),  time:37.471, tt:1348.962\n",
      "Ep:36, loss:0.00013, loss_test:0.16617, lr:6.69e-03, fs:0.77228 (r=0.788,p=0.757),  time:37.477, tt:1386.666\n",
      "Ep:37, loss:0.00013, loss_test:0.15660, lr:6.56e-03, fs:0.79091 (r=0.879,p=0.719),  time:37.530, tt:1426.137\n",
      "Ep:38, loss:0.00012, loss_test:0.16099, lr:6.43e-03, fs:0.78027 (r=0.879,p=0.702),  time:37.566, tt:1465.075\n",
      "Ep:39, loss:0.00012, loss_test:0.15642, lr:6.30e-03, fs:0.77143 (r=0.818,p=0.730),  time:37.594, tt:1503.749\n",
      "Ep:40, loss:0.00011, loss_test:0.16257, lr:6.17e-03, fs:0.78641 (r=0.818,p=0.757),  time:37.651, tt:1543.705\n",
      "Ep:41, loss:0.00010, loss_test:0.18188, lr:6.05e-03, fs:0.65574 (r=0.606,p=0.714),  time:37.696, tt:1583.228\n",
      "Ep:42, loss:0.00010, loss_test:0.17082, lr:5.93e-03, fs:0.76923 (r=0.808,p=0.734),  time:37.727, tt:1622.266\n",
      "Ep:43, loss:0.00010, loss_test:0.16644, lr:5.81e-03, fs:0.73958 (r=0.717,p=0.763),  time:37.759, tt:1661.386\n",
      "Ep:44, loss:0.00009, loss_test:0.14726, lr:5.70e-03, fs:0.81553 (r=0.848,p=0.785),  time:37.775, tt:1699.897\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.16330, lr:5.64e-03, fs:0.77838 (r=0.727,p=0.837),  time:37.769, tt:1737.373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00009, loss_test:0.14927, lr:5.58e-03, fs:0.76382 (r=0.768,p=0.760),  time:37.779, tt:1775.617\n",
      "Ep:47, loss:0.00008, loss_test:0.16257, lr:5.53e-03, fs:0.75936 (r=0.717,p=0.807),  time:37.868, tt:1817.677\n",
      "Ep:48, loss:0.00008, loss_test:0.15634, lr:5.47e-03, fs:0.74372 (r=0.747,p=0.740),  time:37.899, tt:1857.072\n",
      "Ep:49, loss:0.00008, loss_test:0.15161, lr:5.42e-03, fs:0.79803 (r=0.818,p=0.779),  time:37.908, tt:1895.376\n",
      "Ep:50, loss:0.00008, loss_test:0.15380, lr:5.36e-03, fs:0.81773 (r=0.838,p=0.798),  time:37.928, tt:1934.334\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.14285, lr:5.31e-03, fs:0.80189 (r=0.859,p=0.752),  time:37.965, tt:1974.188\n",
      "Ep:52, loss:0.00007, loss_test:0.16733, lr:5.26e-03, fs:0.79121 (r=0.727,p=0.867),  time:37.977, tt:2012.780\n",
      "Ep:53, loss:0.00006, loss_test:0.17012, lr:5.20e-03, fs:0.72189 (r=0.616,p=0.871),  time:37.999, tt:2051.939\n",
      "Ep:54, loss:0.00006, loss_test:0.16300, lr:5.15e-03, fs:0.78261 (r=0.727,p=0.847),  time:37.968, tt:2088.262\n",
      "Ep:55, loss:0.00006, loss_test:0.15500, lr:5.10e-03, fs:0.79412 (r=0.818,p=0.771),  time:37.923, tt:2123.709\n",
      "Ep:56, loss:0.00005, loss_test:0.16857, lr:5.05e-03, fs:0.75393 (r=0.727,p=0.783),  time:37.904, tt:2160.500\n",
      "Ep:57, loss:0.00005, loss_test:0.16692, lr:5.00e-03, fs:0.77596 (r=0.717,p=0.845),  time:37.851, tt:2195.343\n",
      "Ep:58, loss:0.00005, loss_test:0.16840, lr:4.95e-03, fs:0.75556 (r=0.687,p=0.840),  time:37.821, tt:2231.467\n",
      "Ep:59, loss:0.00004, loss_test:0.15236, lr:4.90e-03, fs:0.75532 (r=0.717,p=0.798),  time:37.765, tt:2265.878\n",
      "Ep:60, loss:0.00005, loss_test:0.15309, lr:4.85e-03, fs:0.84577 (r=0.859,p=0.833),  time:37.759, tt:2303.325\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.16645, lr:4.80e-03, fs:0.70659 (r=0.596,p=0.868),  time:37.746, tt:2340.249\n",
      "Ep:62, loss:0.00005, loss_test:0.15212, lr:4.75e-03, fs:0.78261 (r=0.727,p=0.847),  time:37.729, tt:2376.948\n",
      "Ep:63, loss:0.00005, loss_test:0.17628, lr:4.71e-03, fs:0.79545 (r=0.707,p=0.909),  time:37.726, tt:2414.448\n",
      "Ep:64, loss:0.00006, loss_test:0.14965, lr:4.66e-03, fs:0.79793 (r=0.778,p=0.819),  time:37.720, tt:2451.776\n",
      "Ep:65, loss:0.00006, loss_test:0.18461, lr:4.61e-03, fs:0.75581 (r=0.657,p=0.890),  time:37.712, tt:2489.008\n",
      "Ep:66, loss:0.00006, loss_test:0.21397, lr:4.57e-03, fs:0.69822 (r=0.596,p=0.843),  time:37.704, tt:2526.152\n",
      "Ep:67, loss:0.00005, loss_test:0.15850, lr:4.52e-03, fs:0.73514 (r=0.687,p=0.791),  time:37.696, tt:2563.355\n",
      "Ep:68, loss:0.00005, loss_test:0.16570, lr:4.48e-03, fs:0.79096 (r=0.707,p=0.897),  time:37.680, tt:2599.950\n",
      "Ep:69, loss:0.00004, loss_test:0.15919, lr:4.43e-03, fs:0.78689 (r=0.727,p=0.857),  time:37.689, tt:2638.221\n",
      "Ep:70, loss:0.00005, loss_test:0.16456, lr:4.39e-03, fs:0.78261 (r=0.727,p=0.847),  time:37.684, tt:2675.552\n",
      "Ep:71, loss:0.00005, loss_test:0.14783, lr:4.34e-03, fs:0.75258 (r=0.737,p=0.768),  time:37.661, tt:2711.564\n",
      "Ep:72, loss:0.00005, loss_test:0.14789, lr:4.26e-03, fs:0.76596 (r=0.727,p=0.809),  time:37.630, tt:2747.025\n",
      "Ep:73, loss:0.00005, loss_test:0.16633, lr:4.17e-03, fs:0.74576 (r=0.667,p=0.846),  time:37.608, tt:2782.964\n",
      "Ep:74, loss:0.00004, loss_test:0.16953, lr:4.09e-03, fs:0.76571 (r=0.677,p=0.882),  time:37.613, tt:2820.979\n",
      "Ep:75, loss:0.00006, loss_test:0.19711, lr:4.01e-03, fs:0.60116 (r=0.525,p=0.703),  time:37.602, tt:2857.766\n",
      "Ep:76, loss:0.00008, loss_test:0.14299, lr:3.93e-03, fs:0.78992 (r=0.949,p=0.676),  time:37.599, tt:2895.161\n",
      "Ep:77, loss:0.00013, loss_test:0.18059, lr:3.85e-03, fs:0.71498 (r=0.747,p=0.685),  time:37.597, tt:2932.587\n",
      "Ep:78, loss:0.00012, loss_test:0.17124, lr:3.77e-03, fs:0.72251 (r=0.697,p=0.750),  time:37.592, tt:2969.794\n",
      "Ep:79, loss:0.00011, loss_test:0.14816, lr:3.70e-03, fs:0.77949 (r=0.768,p=0.792),  time:37.602, tt:3008.154\n",
      "Ep:80, loss:0.00015, loss_test:0.15053, lr:3.62e-03, fs:0.73469 (r=0.909,p=0.616),  time:37.606, tt:3046.080\n",
      "Ep:81, loss:0.00019, loss_test:0.17969, lr:3.55e-03, fs:0.70813 (r=0.747,p=0.673),  time:37.576, tt:3081.244\n",
      "Ep:82, loss:0.00019, loss_test:0.16172, lr:3.48e-03, fs:0.73984 (r=0.919,p=0.619),  time:37.569, tt:3118.243\n",
      "Ep:83, loss:0.00019, loss_test:0.16045, lr:3.41e-03, fs:0.76577 (r=0.859,p=0.691),  time:37.536, tt:3153.034\n",
      "Ep:84, loss:0.00018, loss_test:0.17524, lr:3.34e-03, fs:0.75000 (r=0.818,p=0.692),  time:37.510, tt:3188.379\n",
      "Ep:85, loss:0.00015, loss_test:0.19907, lr:3.28e-03, fs:0.67016 (r=0.646,p=0.696),  time:37.496, tt:3224.626\n",
      "Ep:86, loss:0.00013, loss_test:0.17051, lr:3.21e-03, fs:0.72539 (r=0.707,p=0.745),  time:37.498, tt:3262.366\n",
      "Ep:87, loss:0.00010, loss_test:0.18182, lr:3.15e-03, fs:0.74468 (r=0.707,p=0.787),  time:37.506, tt:3300.543\n",
      "Ep:88, loss:0.00010, loss_test:0.17538, lr:3.09e-03, fs:0.67778 (r=0.616,p=0.753),  time:37.515, tt:3338.794\n",
      "Ep:89, loss:0.00008, loss_test:0.15269, lr:3.02e-03, fs:0.76842 (r=0.737,p=0.802),  time:37.592, tt:3383.322\n",
      "Ep:90, loss:0.00009, loss_test:0.18590, lr:2.96e-03, fs:0.65946 (r=0.616,p=0.709),  time:37.691, tt:3429.836\n",
      "Ep:91, loss:0.00010, loss_test:0.15524, lr:2.90e-03, fs:0.78182 (r=0.869,p=0.711),  time:37.761, tt:3473.986\n",
      "Ep:92, loss:0.00008, loss_test:0.16793, lr:2.85e-03, fs:0.73958 (r=0.717,p=0.763),  time:37.815, tt:3516.837\n",
      "Ep:93, loss:0.00008, loss_test:0.16309, lr:2.79e-03, fs:0.74372 (r=0.747,p=0.740),  time:37.837, tt:3556.700\n",
      "Ep:94, loss:0.00007, loss_test:0.16922, lr:2.73e-03, fs:0.66298 (r=0.606,p=0.732),  time:37.906, tt:3601.047\n",
      "Ep:95, loss:0.00006, loss_test:0.15853, lr:2.68e-03, fs:0.74510 (r=0.768,p=0.724),  time:37.948, tt:3643.015\n",
      "Ep:96, loss:0.00005, loss_test:0.18065, lr:2.63e-03, fs:0.63784 (r=0.596,p=0.686),  time:37.963, tt:3682.367\n",
      "Ep:97, loss:0.00005, loss_test:0.16479, lr:2.57e-03, fs:0.75000 (r=0.758,p=0.743),  time:37.966, tt:3720.690\n",
      "Ep:98, loss:0.00006, loss_test:0.20120, lr:2.52e-03, fs:0.61628 (r=0.535,p=0.726),  time:37.977, tt:3759.768\n",
      "Ep:99, loss:0.00006, loss_test:0.16407, lr:2.47e-03, fs:0.71739 (r=0.667,p=0.776),  time:38.017, tt:3801.675\n",
      "Ep:100, loss:0.00005, loss_test:0.16410, lr:2.42e-03, fs:0.73333 (r=0.667,p=0.815),  time:38.053, tt:3843.339\n",
      "Ep:101, loss:0.00006, loss_test:0.18722, lr:2.38e-03, fs:0.65455 (r=0.545,p=0.818),  time:38.116, tt:3887.829\n",
      "Ep:102, loss:0.00004, loss_test:0.19238, lr:2.33e-03, fs:0.64045 (r=0.576,p=0.722),  time:38.160, tt:3930.444\n",
      "Ep:103, loss:0.00004, loss_test:0.17675, lr:2.28e-03, fs:0.63584 (r=0.556,p=0.743),  time:38.206, tt:3973.470\n",
      "Ep:104, loss:0.00004, loss_test:0.16630, lr:2.24e-03, fs:0.66667 (r=0.636,p=0.700),  time:38.264, tt:4017.762\n",
      "Ep:105, loss:0.00003, loss_test:0.18349, lr:2.19e-03, fs:0.62857 (r=0.556,p=0.724),  time:38.314, tt:4061.286\n",
      "Ep:106, loss:0.00003, loss_test:0.20807, lr:2.15e-03, fs:0.63473 (r=0.535,p=0.779),  time:38.355, tt:4103.974\n",
      "Ep:107, loss:0.00003, loss_test:0.18410, lr:2.11e-03, fs:0.68208 (r=0.596,p=0.797),  time:38.387, tt:4145.766\n",
      "Ep:108, loss:0.00002, loss_test:0.17719, lr:2.06e-03, fs:0.64706 (r=0.556,p=0.775),  time:38.416, tt:4187.297\n",
      "Ep:109, loss:0.00002, loss_test:0.17225, lr:2.02e-03, fs:0.64740 (r=0.566,p=0.757),  time:38.433, tt:4227.664\n",
      "Ep:110, loss:0.00003, loss_test:0.17792, lr:1.98e-03, fs:0.64286 (r=0.545,p=0.783),  time:38.466, tt:4269.778\n",
      "Ep:111, loss:0.00002, loss_test:0.18005, lr:1.94e-03, fs:0.64671 (r=0.545,p=0.794),  time:38.513, tt:4313.502\n",
      "Ep:112, loss:0.00002, loss_test:0.18142, lr:1.90e-03, fs:0.70930 (r=0.616,p=0.836),  time:38.535, tt:4354.478\n",
      "Ep:113, loss:0.00002, loss_test:0.19762, lr:1.87e-03, fs:0.65060 (r=0.545,p=0.806),  time:38.571, tt:4397.136\n",
      "Ep:114, loss:0.00002, loss_test:0.19453, lr:1.83e-03, fs:0.64286 (r=0.545,p=0.783),  time:38.626, tt:4441.932\n",
      "Ep:115, loss:0.00002, loss_test:0.18034, lr:1.79e-03, fs:0.65060 (r=0.545,p=0.806),  time:38.662, tt:4484.770\n",
      "Ep:116, loss:0.00002, loss_test:0.18138, lr:1.76e-03, fs:0.65455 (r=0.545,p=0.818),  time:38.712, tt:4529.281\n",
      "Ep:117, loss:0.00002, loss_test:0.18713, lr:1.72e-03, fs:0.65455 (r=0.545,p=0.818),  time:38.733, tt:4570.464\n",
      "Ep:118, loss:0.00002, loss_test:0.18489, lr:1.69e-03, fs:0.65455 (r=0.545,p=0.818),  time:38.762, tt:4612.723\n",
      "Ep:119, loss:0.00002, loss_test:0.18422, lr:1.65e-03, fs:0.66258 (r=0.545,p=0.844),  time:38.777, tt:4653.238\n",
      "Ep:120, loss:0.00002, loss_test:0.19184, lr:1.62e-03, fs:0.66258 (r=0.545,p=0.844),  time:38.801, tt:4694.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00002, loss_test:0.19415, lr:1.59e-03, fs:0.65455 (r=0.545,p=0.818),  time:38.826, tt:4736.797\n",
      "Ep:122, loss:0.00002, loss_test:0.19219, lr:1.56e-03, fs:0.65854 (r=0.545,p=0.831),  time:38.854, tt:4779.001\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 14\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24560, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.678, tt:41.678\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1230bd3a7753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m#naive way of testing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mth_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mthreshold_acc\u001b[0;34m(model, g, features, mask, loss, print_details, threshold_dist, threshold_cos, path)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m#mask = np.array([x for x in mask if x[2]==1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m#dist() | max(0, m - dist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,123,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24476, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:12.593, tt:12.593\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24308, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:13.777, tt:27.555\n",
      "Ep:2, loss:0.00058, loss_test:0.23930, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:14.228, tt:42.685\n",
      "Ep:3, loss:0.00055, loss_test:0.23195, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:16.063, tt:64.252\n",
      "Ep:4, loss:0.00050, loss_test:0.21822, lr:8.00e-03, fs:0.65052 (r=0.949,p=0.495),  time:18.081, tt:90.404\n",
      "Ep:5, loss:0.00041, loss_test:0.20485, lr:8.00e-03, fs:0.63241 (r=0.808,p=0.519),  time:19.455, tt:116.728\n",
      "Ep:6, loss:0.00032, loss_test:0.20391, lr:8.00e-03, fs:0.65812 (r=0.778,p=0.570),  time:21.836, tt:152.854\n",
      "Ep:7, loss:0.00031, loss_test:0.20513, lr:8.00e-03, fs:0.66364 (r=0.737,p=0.603),  time:23.782, tt:190.254\n",
      "Ep:8, loss:0.00030, loss_test:0.20097, lr:8.00e-03, fs:0.67265 (r=0.758,p=0.605),  time:25.415, tt:228.735\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.20175, lr:8.00e-03, fs:0.68224 (r=0.737,p=0.635),  time:26.531, tt:265.311\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.19751, lr:8.00e-03, fs:0.66359 (r=0.727,p=0.610),  time:27.777, tt:305.542\n",
      "Ep:11, loss:0.00027, loss_test:0.19448, lr:8.00e-03, fs:0.66667 (r=0.727,p=0.615),  time:28.832, tt:345.989\n",
      "Ep:12, loss:0.00026, loss_test:0.19519, lr:8.00e-03, fs:0.70755 (r=0.758,p=0.664),  time:29.817, tt:387.616\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.19003, lr:8.00e-03, fs:0.70320 (r=0.778,p=0.642),  time:30.637, tt:428.917\n",
      "Ep:14, loss:0.00024, loss_test:0.18585, lr:8.00e-03, fs:0.71681 (r=0.818,p=0.638),  time:30.967, tt:464.509\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.18091, lr:8.00e-03, fs:0.72398 (r=0.808,p=0.656),  time:31.343, tt:501.482\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.18260, lr:8.00e-03, fs:0.72300 (r=0.778,p=0.675),  time:31.639, tt:537.867\n",
      "Ep:17, loss:0.00023, loss_test:0.17907, lr:8.00e-03, fs:0.76147 (r=0.838,p=0.697),  time:31.798, tt:572.366\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.17550, lr:8.00e-03, fs:0.76923 (r=0.859,p=0.697),  time:31.991, tt:607.828\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.17653, lr:8.00e-03, fs:0.74641 (r=0.788,p=0.709),  time:32.202, tt:644.033\n",
      "Ep:20, loss:0.00021, loss_test:0.17428, lr:8.00e-03, fs:0.74396 (r=0.778,p=0.713),  time:32.580, tt:684.173\n",
      "Ep:21, loss:0.00020, loss_test:0.16836, lr:8.00e-03, fs:0.75117 (r=0.808,p=0.702),  time:32.925, tt:724.360\n",
      "Ep:22, loss:0.00020, loss_test:0.16935, lr:8.00e-03, fs:0.77143 (r=0.818,p=0.730),  time:33.274, tt:765.295\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.16805, lr:8.00e-03, fs:0.76329 (r=0.798,p=0.731),  time:33.502, tt:804.047\n",
      "Ep:24, loss:0.00018, loss_test:0.16437, lr:8.00e-03, fs:0.74654 (r=0.818,p=0.686),  time:33.616, tt:840.402\n",
      "Ep:25, loss:0.00019, loss_test:0.16074, lr:8.00e-03, fs:0.78302 (r=0.838,p=0.735),  time:33.739, tt:877.225\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.16161, lr:8.00e-03, fs:0.77934 (r=0.838,p=0.728),  time:33.832, tt:913.474\n",
      "Ep:27, loss:0.00018, loss_test:0.16249, lr:8.00e-03, fs:0.80952 (r=0.859,p=0.766),  time:33.939, tt:950.294\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.15509, lr:8.00e-03, fs:0.78539 (r=0.869,p=0.717),  time:34.035, tt:987.019\n",
      "Ep:29, loss:0.00016, loss_test:0.16386, lr:8.00e-03, fs:0.78431 (r=0.808,p=0.762),  time:34.174, tt:1025.207\n",
      "Ep:30, loss:0.00016, loss_test:0.15450, lr:8.00e-03, fs:0.78182 (r=0.869,p=0.711),  time:34.380, tt:1065.765\n",
      "Ep:31, loss:0.00016, loss_test:0.15661, lr:8.00e-03, fs:0.81373 (r=0.838,p=0.790),  time:34.504, tt:1104.115\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.15157, lr:8.00e-03, fs:0.80930 (r=0.879,p=0.750),  time:34.655, tt:1143.605\n",
      "Ep:33, loss:0.00015, loss_test:0.15065, lr:8.00e-03, fs:0.79630 (r=0.869,p=0.735),  time:34.698, tt:1179.735\n",
      "Ep:34, loss:0.00015, loss_test:0.15346, lr:8.00e-03, fs:0.83744 (r=0.859,p=0.817),  time:34.742, tt:1215.985\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00015, loss_test:0.14582, lr:8.00e-03, fs:0.82569 (r=0.909,p=0.756),  time:34.804, tt:1252.961\n",
      "Ep:36, loss:0.00014, loss_test:0.14827, lr:8.00e-03, fs:0.80000 (r=0.848,p=0.757),  time:34.862, tt:1289.880\n",
      "Ep:37, loss:0.00014, loss_test:0.14172, lr:8.00e-03, fs:0.82791 (r=0.899,p=0.767),  time:34.878, tt:1325.376\n",
      "Ep:38, loss:0.00013, loss_test:0.14682, lr:8.00e-03, fs:0.85437 (r=0.889,p=0.822),  time:34.899, tt:1361.072\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00014, loss_test:0.14470, lr:8.00e-03, fs:0.82028 (r=0.899,p=0.754),  time:35.013, tt:1400.531\n",
      "Ep:40, loss:0.00012, loss_test:0.13921, lr:8.00e-03, fs:0.84762 (r=0.899,p=0.802),  time:35.152, tt:1441.212\n",
      "Ep:41, loss:0.00012, loss_test:0.14185, lr:8.00e-03, fs:0.84211 (r=0.889,p=0.800),  time:35.235, tt:1479.863\n",
      "Ep:42, loss:0.00012, loss_test:0.14026, lr:8.00e-03, fs:0.83721 (r=0.909,p=0.776),  time:35.402, tt:1522.270\n",
      "Ep:43, loss:0.00012, loss_test:0.13832, lr:8.00e-03, fs:0.85714 (r=0.909,p=0.811),  time:35.409, tt:1557.993\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00012, loss_test:0.14001, lr:8.00e-03, fs:0.84211 (r=0.889,p=0.800),  time:35.487, tt:1596.902\n",
      "Ep:45, loss:0.00011, loss_test:0.13646, lr:8.00e-03, fs:0.86124 (r=0.909,p=0.818),  time:35.604, tt:1637.805\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00011, loss_test:0.13848, lr:8.00e-03, fs:0.83962 (r=0.899,p=0.788),  time:35.699, tt:1677.864\n",
      "Ep:47, loss:0.00010, loss_test:0.14443, lr:8.00e-03, fs:0.81951 (r=0.848,p=0.792),  time:35.792, tt:1717.995\n",
      "Ep:48, loss:0.00010, loss_test:0.13623, lr:8.00e-03, fs:0.85167 (r=0.899,p=0.809),  time:35.851, tt:1756.715\n",
      "Ep:49, loss:0.00010, loss_test:0.13529, lr:8.00e-03, fs:0.87129 (r=0.889,p=0.854),  time:35.978, tt:1798.878\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00010, loss_test:0.13586, lr:8.00e-03, fs:0.84615 (r=0.889,p=0.807),  time:36.136, tt:1842.938\n",
      "Ep:51, loss:0.00009, loss_test:0.13763, lr:8.00e-03, fs:0.85437 (r=0.889,p=0.822),  time:36.239, tt:1884.450\n",
      "Ep:52, loss:0.00009, loss_test:0.13486, lr:8.00e-03, fs:0.87562 (r=0.889,p=0.863),  time:36.354, tt:1926.769\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.13257, lr:8.00e-03, fs:0.87685 (r=0.899,p=0.856),  time:36.394, tt:1965.264\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.13240, lr:8.00e-03, fs:0.85577 (r=0.899,p=0.817),  time:36.444, tt:2004.411\n",
      "Ep:55, loss:0.00008, loss_test:0.13358, lr:8.00e-03, fs:0.85437 (r=0.889,p=0.822),  time:36.482, tt:2042.986\n",
      "Ep:56, loss:0.00008, loss_test:0.13269, lr:8.00e-03, fs:0.84878 (r=0.879,p=0.821),  time:36.542, tt:2082.909\n",
      "Ep:57, loss:0.00007, loss_test:0.12994, lr:8.00e-03, fs:0.85437 (r=0.889,p=0.822),  time:36.611, tt:2123.424\n",
      "Ep:58, loss:0.00008, loss_test:0.13689, lr:8.00e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.652, tt:2162.440\n",
      "Ep:59, loss:0.00008, loss_test:0.13056, lr:8.00e-03, fs:0.81951 (r=0.848,p=0.792),  time:36.743, tt:2204.570\n",
      "Ep:60, loss:0.00007, loss_test:0.12477, lr:8.00e-03, fs:0.87255 (r=0.899,p=0.848),  time:36.885, tt:2249.993\n",
      "Ep:61, loss:0.00007, loss_test:0.13370, lr:8.00e-03, fs:0.79381 (r=0.778,p=0.811),  time:36.991, tt:2293.464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00007, loss_test:0.12725, lr:8.00e-03, fs:0.87000 (r=0.879,p=0.861),  time:37.043, tt:2333.703\n",
      "Ep:63, loss:0.00007, loss_test:0.13941, lr:8.00e-03, fs:0.78307 (r=0.747,p=0.822),  time:37.069, tt:2372.414\n",
      "Ep:64, loss:0.00007, loss_test:0.12749, lr:8.00e-03, fs:0.84536 (r=0.828,p=0.863),  time:37.098, tt:2411.354\n",
      "Ep:65, loss:0.00006, loss_test:0.12898, lr:8.00e-03, fs:0.85128 (r=0.838,p=0.865),  time:37.141, tt:2451.337\n",
      "Ep:66, loss:0.00006, loss_test:0.13544, lr:8.00e-03, fs:0.78261 (r=0.727,p=0.847),  time:37.169, tt:2490.312\n",
      "Ep:67, loss:0.00006, loss_test:0.12952, lr:8.00e-03, fs:0.84694 (r=0.838,p=0.856),  time:37.192, tt:2529.035\n",
      "Ep:68, loss:0.00006, loss_test:0.13277, lr:8.00e-03, fs:0.82353 (r=0.778,p=0.875),  time:37.222, tt:2568.314\n",
      "Ep:69, loss:0.00006, loss_test:0.12972, lr:8.00e-03, fs:0.80645 (r=0.758,p=0.862),  time:37.292, tt:2610.466\n",
      "Ep:70, loss:0.00006, loss_test:0.12653, lr:8.00e-03, fs:0.84974 (r=0.828,p=0.872),  time:37.377, tt:2653.801\n",
      "Ep:71, loss:0.00005, loss_test:0.13232, lr:8.00e-03, fs:0.80000 (r=0.747,p=0.860),  time:37.446, tt:2696.096\n",
      "Ep:72, loss:0.00005, loss_test:0.12685, lr:7.92e-03, fs:0.81283 (r=0.768,p=0.864),  time:37.524, tt:2739.239\n",
      "Ep:73, loss:0.00005, loss_test:0.13482, lr:7.84e-03, fs:0.81283 (r=0.768,p=0.864),  time:37.543, tt:2778.186\n",
      "Ep:74, loss:0.00005, loss_test:0.13054, lr:7.76e-03, fs:0.79348 (r=0.737,p=0.859),  time:37.560, tt:2816.997\n",
      "Ep:75, loss:0.00005, loss_test:0.12899, lr:7.68e-03, fs:0.76923 (r=0.707,p=0.843),  time:37.572, tt:2855.506\n",
      "Ep:76, loss:0.00004, loss_test:0.12993, lr:7.61e-03, fs:0.78453 (r=0.717,p=0.866),  time:37.579, tt:2893.585\n",
      "Ep:77, loss:0.00004, loss_test:0.13357, lr:7.53e-03, fs:0.76404 (r=0.687,p=0.861),  time:37.589, tt:2931.904\n",
      "Ep:78, loss:0.00004, loss_test:0.12920, lr:7.46e-03, fs:0.77273 (r=0.687,p=0.883),  time:37.621, tt:2972.031\n",
      "Ep:79, loss:0.00004, loss_test:0.12602, lr:7.38e-03, fs:0.75556 (r=0.687,p=0.840),  time:37.669, tt:3013.495\n",
      "Ep:80, loss:0.00004, loss_test:0.14354, lr:7.31e-03, fs:0.77714 (r=0.687,p=0.895),  time:37.733, tt:3056.346\n",
      "Ep:81, loss:0.00004, loss_test:0.13730, lr:7.24e-03, fs:0.75978 (r=0.687,p=0.850),  time:37.782, tt:3098.133\n",
      "Ep:82, loss:0.00004, loss_test:0.13017, lr:7.16e-03, fs:0.76836 (r=0.687,p=0.872),  time:37.837, tt:3140.483\n",
      "Ep:83, loss:0.00004, loss_test:0.13353, lr:7.09e-03, fs:0.78409 (r=0.697,p=0.896),  time:37.849, tt:3179.278\n",
      "Ep:84, loss:0.00004, loss_test:0.14468, lr:7.02e-03, fs:0.73913 (r=0.687,p=0.800),  time:37.842, tt:3216.561\n",
      "Ep:85, loss:0.00004, loss_test:0.13055, lr:6.95e-03, fs:0.76836 (r=0.687,p=0.872),  time:37.854, tt:3255.444\n",
      "Ep:86, loss:0.00004, loss_test:0.13299, lr:6.88e-03, fs:0.83158 (r=0.798,p=0.868),  time:37.870, tt:3294.656\n",
      "Ep:87, loss:0.00003, loss_test:0.13696, lr:6.81e-03, fs:0.77273 (r=0.687,p=0.883),  time:37.885, tt:3333.918\n",
      "Ep:88, loss:0.00003, loss_test:0.13304, lr:6.74e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.908, tt:3373.788\n",
      "Ep:89, loss:0.00003, loss_test:0.13453, lr:6.68e-03, fs:0.78161 (r=0.687,p=0.907),  time:37.961, tt:3416.498\n",
      "Ep:90, loss:0.00003, loss_test:0.12813, lr:6.61e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.992, tt:3457.314\n",
      "Ep:91, loss:0.00003, loss_test:0.12942, lr:6.54e-03, fs:0.77714 (r=0.687,p=0.895),  time:38.029, tt:3498.681\n",
      "Ep:92, loss:0.00003, loss_test:0.13569, lr:6.48e-03, fs:0.79310 (r=0.697,p=0.920),  time:38.057, tt:3539.296\n",
      "Ep:93, loss:0.00003, loss_test:0.13631, lr:6.41e-03, fs:0.77273 (r=0.687,p=0.883),  time:38.078, tt:3579.322\n",
      "Ep:94, loss:0.00003, loss_test:0.13569, lr:6.35e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.089, tt:3618.485\n",
      "Ep:95, loss:0.00003, loss_test:0.13107, lr:6.29e-03, fs:0.80000 (r=0.727,p=0.889),  time:38.102, tt:3657.836\n",
      "Ep:96, loss:0.00002, loss_test:0.12777, lr:6.22e-03, fs:0.76404 (r=0.687,p=0.861),  time:38.109, tt:3696.615\n",
      "Ep:97, loss:0.00003, loss_test:0.13345, lr:6.16e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.129, tt:3736.595\n",
      "Ep:98, loss:0.00002, loss_test:0.12956, lr:6.10e-03, fs:0.79558 (r=0.727,p=0.878),  time:38.158, tt:3777.658\n",
      "Ep:99, loss:0.00003, loss_test:0.12907, lr:6.04e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.214, tt:3821.445\n",
      "Ep:100, loss:0.00002, loss_test:0.13721, lr:5.98e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.261, tt:3864.392\n",
      "Ep:101, loss:0.00002, loss_test:0.13585, lr:5.92e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.302, tt:3906.755\n",
      "Ep:102, loss:0.00002, loss_test:0.13062, lr:5.86e-03, fs:0.77273 (r=0.687,p=0.883),  time:38.327, tt:3947.678\n",
      "Ep:103, loss:0.00002, loss_test:0.12964, lr:5.80e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.341, tt:3987.473\n",
      "Ep:104, loss:0.00002, loss_test:0.13098, lr:5.74e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.335, tt:4025.152\n",
      "Ep:105, loss:0.00002, loss_test:0.13590, lr:5.68e-03, fs:0.79070 (r=0.687,p=0.932),  time:38.344, tt:4064.491\n",
      "Ep:106, loss:0.00002, loss_test:0.12927, lr:5.63e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.348, tt:4103.243\n",
      "Ep:107, loss:0.00002, loss_test:0.12736, lr:5.57e-03, fs:0.77273 (r=0.687,p=0.883),  time:38.363, tt:4143.243\n",
      "Ep:108, loss:0.00002, loss_test:0.13206, lr:5.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.386, tt:4184.081\n",
      "Ep:109, loss:0.00002, loss_test:0.13320, lr:5.46e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.439, tt:4228.272\n",
      "Ep:110, loss:0.00002, loss_test:0.13174, lr:5.41e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.498, tt:4273.228\n",
      "Ep:111, loss:0.00002, loss_test:0.13158, lr:5.35e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.537, tt:4316.171\n",
      "Ep:112, loss:0.00002, loss_test:0.13144, lr:5.30e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.545, tt:4355.614\n",
      "Ep:113, loss:0.00002, loss_test:0.13447, lr:5.25e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.563, tt:4396.166\n",
      "Ep:114, loss:0.00002, loss_test:0.13729, lr:5.19e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.566, tt:4435.133\n",
      "Ep:115, loss:0.00002, loss_test:0.13221, lr:5.14e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.584, tt:4475.701\n",
      "Ep:116, loss:0.00002, loss_test:0.13123, lr:5.09e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.597, tt:4515.812\n",
      "Ep:117, loss:0.00002, loss_test:0.13284, lr:5.04e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.608, tt:4555.754\n",
      "Ep:118, loss:0.00002, loss_test:0.13407, lr:4.99e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.624, tt:4596.233\n",
      "Ep:119, loss:0.00002, loss_test:0.13596, lr:4.94e-03, fs:0.78613 (r=0.687,p=0.919),  time:38.672, tt:4640.669\n",
      "Ep:120, loss:0.00002, loss_test:0.13264, lr:4.89e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.722, tt:4685.341\n",
      "Ep:121, loss:0.00002, loss_test:0.13250, lr:4.84e-03, fs:0.78161 (r=0.687,p=0.907),  time:38.743, tt:4726.673\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-355502d63c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Meta-feature graph from datasets loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mfrom_networkx\u001b[0;34m(self, nx_graph, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \"\"\"\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# Relabel nodes using consecutive integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m         \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_node_labels_to_integers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sorted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m         \u001b[0;31m# With to_directed we will get a directed version of the original networkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m         \u001b[0;31m# graph, with the original nodes, edges and their attributes preserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/relabel.py\u001b[0m in \u001b[0;36mconvert_node_labels_to_integers\u001b[0;34m(G, first_label, ordering, label_attribute)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mordering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sorted\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mnlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mordering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"increasing degree\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,122,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:0, loss:0.00033, loss_test:0.09698, lr:8.00e-03, fs:0.64605 (r=0.949,p=0.490),  time:26.121, tt:26.121\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:1, loss:0.00030, loss_test:0.09546, lr:8.00e-03, fs:0.63860 (r=0.919,p=0.489),  time:33.388, tt:66.775\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:2, loss:0.00026, loss_test:0.09566, lr:8.00e-03, fs:0.63673 (r=0.788,p=0.534),  time:39.073, tt:117.219\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:3, loss:0.00022, loss_test:0.10829, lr:8.00e-03, fs:0.60099 (r=0.616,p=0.587),  time:42.660, tt:170.639\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:4, loss:0.00021, loss_test:0.10477, lr:8.00e-03, fs:0.58416 (r=0.596,p=0.573),  time:44.861, tt:224.302\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:5, loss:0.00020, loss_test:0.09599, lr:8.00e-03, fs:0.63071 (r=0.768,p=0.535),  time:46.392, tt:278.349\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:6, loss:0.00020, loss_test:0.09446, lr:8.00e-03, fs:0.63559 (r=0.758,p=0.547),  time:47.682, tt:333.776\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:7, loss:0.00019, loss_test:0.09705, lr:8.00e-03, fs:0.63208 (r=0.677,p=0.593),  time:48.958, tt:391.667\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:8, loss:0.00018, loss_test:0.09559, lr:8.00e-03, fs:0.61244 (r=0.646,p=0.582),  time:49.762, tt:447.856\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:9, loss:0.00018, loss_test:0.08952, lr:8.00e-03, fs:0.62500 (r=0.707,p=0.560),  time:50.544, tt:505.435\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:10, loss:0.00017, loss_test:0.08806, lr:8.00e-03, fs:0.61751 (r=0.677,p=0.568),  time:51.346, tt:564.810\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:11, loss:0.00017, loss_test:0.08795, lr:8.00e-03, fs:0.61538 (r=0.646,p=0.587),  time:51.876, tt:622.510\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:12, loss:0.00016, loss_test:0.08472, lr:7.92e-03, fs:0.63256 (r=0.687,p=0.586),  time:52.151, tt:677.969\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:13, loss:0.00016, loss_test:0.08236, lr:7.84e-03, fs:0.63927 (r=0.707,p=0.583),  time:52.257, tt:731.592\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:14, loss:0.00015, loss_test:0.08179, lr:7.76e-03, fs:0.63889 (r=0.697,p=0.590),  time:52.329, tt:784.940\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:15, loss:0.00015, loss_test:0.08023, lr:7.68e-03, fs:0.65438 (r=0.717,p=0.602),  time:52.405, tt:838.476\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:16, loss:0.00015, loss_test:0.07825, lr:7.68e-03, fs:0.67873 (r=0.758,p=0.615),  time:52.523, tt:892.886\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:17, loss:0.00014, loss_test:0.07827, lr:7.68e-03, fs:0.67890 (r=0.747,p=0.622),  time:52.791, tt:950.237\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:18, loss:0.00014, loss_test:0.07767, lr:7.68e-03, fs:0.69767 (r=0.758,p=0.647),  time:53.112, tt:1009.131\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:19, loss:0.00014, loss_test:0.07759, lr:7.68e-03, fs:0.72146 (r=0.798,p=0.658),  time:53.403, tt:1068.060\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:20, loss:0.00014, loss_test:0.07709, lr:7.68e-03, fs:0.71818 (r=0.798,p=0.653),  time:53.717, tt:1128.048\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:21, loss:0.00013, loss_test:0.07562, lr:7.68e-03, fs:0.72321 (r=0.818,p=0.648),  time:54.034, tt:1188.747\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:22, loss:0.00013, loss_test:0.07668, lr:7.68e-03, fs:0.72222 (r=0.788,p=0.667),  time:54.118, tt:1244.716\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:23, loss:0.00013, loss_test:0.07531, lr:7.68e-03, fs:0.72146 (r=0.798,p=0.658),  time:54.029, tt:1296.695\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:24, loss:0.00012, loss_test:0.07349, lr:7.68e-03, fs:0.73913 (r=0.859,p=0.649),  time:53.993, tt:1349.822\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:25, loss:0.00013, loss_test:0.07444, lr:7.68e-03, fs:0.73543 (r=0.828,p=0.661),  time:53.981, tt:1403.516\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:26, loss:0.00012, loss_test:0.07330, lr:7.68e-03, fs:0.74009 (r=0.848,p=0.656),  time:53.985, tt:1457.583\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:27, loss:0.00012, loss_test:0.07256, lr:7.68e-03, fs:0.74890 (r=0.859,p=0.664),  time:54.128, tt:1515.580\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:28, loss:0.00011, loss_test:0.07290, lr:7.68e-03, fs:0.74439 (r=0.838,p=0.669),  time:54.284, tt:1574.228\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:29, loss:0.00011, loss_test:0.07151, lr:7.68e-03, fs:0.76724 (r=0.899,p=0.669),  time:54.413, tt:1632.395\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:30, loss:0.00011, loss_test:0.07121, lr:7.68e-03, fs:0.76856 (r=0.889,p=0.677),  time:54.549, tt:1691.023\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:31, loss:0.00011, loss_test:0.07101, lr:7.68e-03, fs:0.77193 (r=0.889,p=0.682),  time:54.695, tt:1750.228\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:32, loss:0.00011, loss_test:0.07094, lr:7.68e-03, fs:0.77533 (r=0.889,p=0.688),  time:54.730, tt:1806.091\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:33, loss:0.00010, loss_test:0.07062, lr:7.68e-03, fs:0.78761 (r=0.899,p=0.701),  time:54.765, tt:1862.000\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:34, loss:0.00011, loss_test:0.07049, lr:7.68e-03, fs:0.78924 (r=0.889,p=0.710),  time:54.750, tt:1916.266\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:35, loss:0.00010, loss_test:0.06969, lr:7.68e-03, fs:0.79295 (r=0.909,p=0.703),  time:54.766, tt:1971.590\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:36, loss:0.00010, loss_test:0.06967, lr:7.68e-03, fs:0.78571 (r=0.889,p=0.704),  time:54.777, tt:2026.732\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:37, loss:0.00010, loss_test:0.06950, lr:7.68e-03, fs:0.78222 (r=0.889,p=0.698),  time:54.873, tt:2085.183\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:38, loss:0.00009, loss_test:0.06849, lr:7.68e-03, fs:0.79295 (r=0.909,p=0.703),  time:55.022, tt:2145.847\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:39, loss:0.00009, loss_test:0.06856, lr:7.68e-03, fs:0.80000 (r=0.909,p=0.714),  time:55.125, tt:2204.994\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:40, loss:0.00009, loss_test:0.06906, lr:7.68e-03, fs:0.79464 (r=0.899,p=0.712),  time:55.237, tt:2264.731\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:41, loss:0.00009, loss_test:0.06879, lr:7.68e-03, fs:0.79821 (r=0.899,p=0.718),  time:55.333, tt:2324.002\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:42, loss:0.00009, loss_test:0.06840, lr:7.68e-03, fs:0.78924 (r=0.889,p=0.710),  time:55.419, tt:2382.997\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:43, loss:0.00008, loss_test:0.06817, lr:7.68e-03, fs:0.79464 (r=0.899,p=0.712),  time:55.327, tt:2434.409\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:44, loss:0.00008, loss_test:0.06793, lr:7.68e-03, fs:0.78924 (r=0.889,p=0.710),  time:55.333, tt:2490.003\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:45, loss:0.00008, loss_test:0.06831, lr:7.68e-03, fs:0.79817 (r=0.879,p=0.731),  time:55.359, tt:2546.511\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:46, loss:0.00008, loss_test:0.06727, lr:7.68e-03, fs:0.79464 (r=0.899,p=0.712),  time:55.374, tt:2602.580\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:47, loss:0.00008, loss_test:0.06743, lr:7.68e-03, fs:0.79464 (r=0.899,p=0.712),  time:55.403, tt:2659.363\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:48, loss:0.00008, loss_test:0.06819, lr:7.68e-03, fs:0.75926 (r=0.828,p=0.701),  time:55.494, tt:2719.213\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:49, loss:0.00008, loss_test:0.06892, lr:7.68e-03, fs:0.75728 (r=0.788,p=0.729),  time:55.574, tt:2778.704\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:50, loss:0.00007, loss_test:0.06587, lr:7.68e-03, fs:0.78761 (r=0.899,p=0.701),  time:55.733, tt:2842.371\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:51, loss:0.00007, loss_test:0.06823, lr:7.61e-03, fs:0.75962 (r=0.798,p=0.725),  time:55.855, tt:2904.471\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:52, loss:0.00007, loss_test:0.06642, lr:7.53e-03, fs:0.78899 (r=0.869,p=0.723),  time:55.892, tt:2962.292\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:53, loss:0.00007, loss_test:0.06750, lr:7.46e-03, fs:0.74882 (r=0.798,p=0.705),  time:55.831, tt:3014.858\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:54, loss:0.00007, loss_test:0.06801, lr:7.38e-03, fs:0.74286 (r=0.788,p=0.703),  time:55.801, tt:3069.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:55, loss:0.00007, loss_test:0.06709, lr:7.31e-03, fs:0.74528 (r=0.798,p=0.699),  time:55.768, tt:3122.994\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:56, loss:0.00007, loss_test:0.06794, lr:7.24e-03, fs:0.75362 (r=0.788,p=0.722),  time:55.758, tt:3178.181\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:57, loss:0.00006, loss_test:0.06603, lr:7.16e-03, fs:0.76147 (r=0.838,p=0.697),  time:55.809, tt:3236.948\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:58, loss:0.00006, loss_test:0.06853, lr:7.09e-03, fs:0.76471 (r=0.788,p=0.743),  time:55.922, tt:3299.395\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:59, loss:0.00006, loss_test:0.06649, lr:7.02e-03, fs:0.73148 (r=0.798,p=0.675),  time:56.003, tt:3360.190\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:60, loss:0.00006, loss_test:0.06645, lr:6.95e-03, fs:0.74074 (r=0.808,p=0.684),  time:56.101, tt:3422.169\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:61, loss:0.00006, loss_test:0.06764, lr:6.88e-03, fs:0.75362 (r=0.788,p=0.722),  time:56.153, tt:3481.512\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:62, loss:0.00006, loss_test:0.06609, lr:6.81e-03, fs:0.73488 (r=0.798,p=0.681),  time:56.190, tt:3539.991\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:63, loss:0.00006, loss_test:0.06781, lr:6.74e-03, fs:0.76098 (r=0.788,p=0.736),  time:56.187, tt:3595.942\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:64, loss:0.00005, loss_test:0.06550, lr:6.68e-03, fs:0.74178 (r=0.798,p=0.693),  time:56.170, tt:3651.049\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:65, loss:0.00006, loss_test:0.06716, lr:6.61e-03, fs:0.74286 (r=0.788,p=0.703),  time:56.164, tt:3706.838\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:66, loss:0.00005, loss_test:0.06761, lr:6.54e-03, fs:0.74757 (r=0.778,p=0.720),  time:56.129, tt:3760.629\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:67, loss:0.00005, loss_test:0.06541, lr:6.48e-03, fs:0.73832 (r=0.798,p=0.687),  time:56.224, tt:3823.213\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:68, loss:0.00005, loss_test:0.06742, lr:6.41e-03, fs:0.75862 (r=0.778,p=0.740),  time:56.305, tt:3885.012\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:69, loss:0.00005, loss_test:0.06557, lr:6.35e-03, fs:0.75000 (r=0.818,p=0.692),  time:56.356, tt:3944.903\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:70, loss:0.00005, loss_test:0.06747, lr:6.29e-03, fs:0.74038 (r=0.778,p=0.706),  time:56.443, tt:4007.442\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:71, loss:0.00005, loss_test:0.06535, lr:6.22e-03, fs:0.74641 (r=0.788,p=0.709),  time:56.512, tt:4068.877\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:72, loss:0.00005, loss_test:0.06607, lr:6.16e-03, fs:0.75362 (r=0.788,p=0.722),  time:56.524, tt:4126.248\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:73, loss:0.00005, loss_test:0.06700, lr:6.10e-03, fs:0.72816 (r=0.758,p=0.701),  time:56.479, tt:4179.448\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:74, loss:0.00005, loss_test:0.06645, lr:6.04e-03, fs:0.74396 (r=0.778,p=0.713),  time:56.437, tt:4232.784\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:75, loss:0.00005, loss_test:0.06692, lr:5.98e-03, fs:0.75122 (r=0.778,p=0.726),  time:56.407, tt:4286.907\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:76, loss:0.00005, loss_test:0.06588, lr:5.92e-03, fs:0.72986 (r=0.778,p=0.688),  time:56.385, tt:4341.653\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:77, loss:0.00005, loss_test:0.06752, lr:5.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:56.408, tt:4399.852\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:78, loss:0.00005, loss_test:0.06617, lr:5.80e-03, fs:0.75122 (r=0.778,p=0.726),  time:56.436, tt:4458.409\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:79, loss:0.00004, loss_test:0.06548, lr:5.74e-03, fs:0.72986 (r=0.778,p=0.688),  time:56.463, tt:4517.077\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:80, loss:0.00004, loss_test:0.06705, lr:5.68e-03, fs:0.74000 (r=0.747,p=0.733),  time:56.511, tt:4577.398\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:81, loss:0.00004, loss_test:0.06614, lr:5.63e-03, fs:0.74877 (r=0.768,p=0.731),  time:56.532, tt:4635.629\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:82, loss:0.00004, loss_test:0.06473, lr:5.57e-03, fs:0.74641 (r=0.788,p=0.709),  time:56.485, tt:4688.232\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:83, loss:0.00004, loss_test:0.06837, lr:5.52e-03, fs:0.74372 (r=0.747,p=0.740),  time:56.453, tt:4742.091\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:84, loss:0.00004, loss_test:0.06528, lr:5.46e-03, fs:0.75362 (r=0.788,p=0.722),  time:56.413, tt:4795.106\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:85, loss:0.00004, loss_test:0.06614, lr:5.41e-03, fs:0.74146 (r=0.768,p=0.717),  time:56.372, tt:4848.016\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:86, loss:0.00004, loss_test:0.06873, lr:5.35e-03, fs:0.74112 (r=0.737,p=0.745),  time:56.372, tt:4904.390\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:87, loss:0.00004, loss_test:0.06407, lr:5.30e-03, fs:0.75000 (r=0.788,p=0.716),  time:56.398, tt:4963.033\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:88, loss:0.00004, loss_test:0.06562, lr:5.25e-03, fs:0.72464 (r=0.758,p=0.694),  time:56.433, tt:5022.495\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:89, loss:0.00004, loss_test:0.06539, lr:5.19e-03, fs:0.75248 (r=0.768,p=0.738),  time:56.481, tt:5083.295\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:90, loss:0.00004, loss_test:0.06564, lr:5.14e-03, fs:0.74877 (r=0.768,p=0.731),  time:56.478, tt:5139.498\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:91, loss:0.00004, loss_test:0.06609, lr:5.09e-03, fs:0.74257 (r=0.758,p=0.728),  time:56.496, tt:5197.656\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:92, loss:0.00004, loss_test:0.06577, lr:5.04e-03, fs:0.74000 (r=0.747,p=0.733),  time:56.471, tt:5251.772\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:93, loss:0.00004, loss_test:0.06465, lr:4.99e-03, fs:0.75490 (r=0.778,p=0.733),  time:56.440, tt:5305.342\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:94, loss:0.00004, loss_test:0.06560, lr:4.94e-03, fs:0.74510 (r=0.768,p=0.724),  time:56.413, tt:5359.193\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:95, loss:0.00004, loss_test:0.06596, lr:4.89e-03, fs:0.74372 (r=0.747,p=0.740),  time:56.401, tt:5414.456\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:96, loss:0.00004, loss_test:0.06480, lr:4.84e-03, fs:0.74627 (r=0.758,p=0.735),  time:56.405, tt:5471.279\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:97, loss:0.00004, loss_test:0.06546, lr:4.79e-03, fs:0.72549 (r=0.747,p=0.705),  time:56.441, tt:5531.250\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:98, loss:0.00004, loss_test:0.06654, lr:4.74e-03, fs:0.74112 (r=0.737,p=0.745),  time:56.455, tt:5589.069\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:99, loss:0.00004, loss_test:0.06629, lr:4.70e-03, fs:0.74490 (r=0.737,p=0.753),  time:56.467, tt:5646.716\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:100, loss:0.00003, loss_test:0.06492, lr:4.65e-03, fs:0.73171 (r=0.758,p=0.708),  time:56.488, tt:5705.319\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:101, loss:0.00003, loss_test:0.06686, lr:4.60e-03, fs:0.74112 (r=0.737,p=0.745),  time:56.524, tt:5765.427\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:102, loss:0.00003, loss_test:0.06457, lr:4.56e-03, fs:0.74257 (r=0.758,p=0.728),  time:56.493, tt:5818.814\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:103, loss:0.00003, loss_test:0.06565, lr:4.51e-03, fs:0.73367 (r=0.737,p=0.730),  time:56.465, tt:5872.377\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:104, loss:0.00003, loss_test:0.06737, lr:4.47e-03, fs:0.74112 (r=0.737,p=0.745),  time:56.423, tt:5924.436\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:105, loss:0.00003, loss_test:0.06429, lr:4.42e-03, fs:0.74257 (r=0.758,p=0.728),  time:56.402, tt:5978.562\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:106, loss:0.00003, loss_test:0.06471, lr:4.38e-03, fs:0.72906 (r=0.747,p=0.712),  time:56.387, tt:6033.461\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:107, loss:0.00003, loss_test:0.06763, lr:4.33e-03, fs:0.74112 (r=0.737,p=0.745),  time:56.411, tt:6092.420\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:108, loss:0.00003, loss_test:0.06577, lr:4.29e-03, fs:0.74112 (r=0.737,p=0.745),  time:56.434, tt:6151.259\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:109, loss:0.00003, loss_test:0.06420, lr:4.25e-03, fs:0.73267 (r=0.747,p=0.718),  time:56.462, tt:6210.782\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:110, loss:0.00003, loss_test:0.06601, lr:4.20e-03, fs:0.73737 (r=0.737,p=0.737),  time:56.474, tt:6268.631\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:111, loss:0.00003, loss_test:0.06510, lr:4.16e-03, fs:0.73367 (r=0.737,p=0.730),  time:56.484, tt:6326.157\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:112, loss:0.00003, loss_test:0.06454, lr:4.12e-03, fs:0.73000 (r=0.737,p=0.723),  time:56.451, tt:6378.919\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:113, loss:0.00003, loss_test:0.06604, lr:4.08e-03, fs:0.73737 (r=0.737,p=0.737),  time:56.425, tt:6432.479\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:114, loss:0.00003, loss_test:0.06499, lr:4.04e-03, fs:0.73000 (r=0.737,p=0.723),  time:56.387, tt:6484.498\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:115, loss:0.00003, loss_test:0.06574, lr:4.00e-03, fs:0.73367 (r=0.737,p=0.730),  time:56.321, tt:6533.193\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:116, loss:0.00003, loss_test:0.06744, lr:3.96e-03, fs:0.72539 (r=0.707,p=0.745),  time:56.288, tt:6585.648\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:117, loss:0.00003, loss_test:0.06478, lr:3.92e-03, fs:0.73737 (r=0.737,p=0.737),  time:56.275, tt:6640.391\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:118, loss:0.00003, loss_test:0.06497, lr:3.88e-03, fs:0.73367 (r=0.737,p=0.730),  time:56.289, tt:6698.403\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1caed2947355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m119\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for CV out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,119,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:0, loss:0.00031, loss_test:0.09579, lr:1.00e-02, fs:0.64111 (r=0.929,p=0.489),  time:29.253, tt:29.253\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:1, loss:0.00026, loss_test:0.09372, lr:1.00e-02, fs:0.61088 (r=0.737,p=0.521),  time:35.483, tt:70.966\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:2, loss:0.00021, loss_test:0.10658, lr:1.00e-02, fs:0.56684 (r=0.535,p=0.602),  time:43.371, tt:130.113\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:3, loss:0.00020, loss_test:0.09469, lr:1.00e-02, fs:0.59193 (r=0.667,p=0.532),  time:47.024, tt:188.096\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:4, loss:0.00020, loss_test:0.09124, lr:1.00e-02, fs:0.62882 (r=0.727,p=0.554),  time:48.980, tt:244.899\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:5, loss:0.00019, loss_test:0.09371, lr:1.00e-02, fs:0.64151 (r=0.687,p=0.602),  time:50.383, tt:302.297\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:6, loss:0.00018, loss_test:0.09051, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:51.519, tt:360.635\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:7, loss:0.00017, loss_test:0.08401, lr:1.00e-02, fs:0.65789 (r=0.758,p=0.581),  time:52.174, tt:417.389\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:8, loss:0.00017, loss_test:0.08512, lr:1.00e-02, fs:0.65072 (r=0.687,p=0.618),  time:53.001, tt:477.005\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:9, loss:0.00016, loss_test:0.08266, lr:1.00e-02, fs:0.66667 (r=0.717,p=0.623),  time:53.258, tt:532.576\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:10, loss:0.00016, loss_test:0.07862, lr:1.00e-02, fs:0.67857 (r=0.768,p=0.608),  time:53.601, tt:589.611\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:11, loss:0.00015, loss_test:0.07976, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:54.172, tt:650.068\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:12, loss:0.00015, loss_test:0.07684, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:53.994, tt:701.926\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:13, loss:0.00015, loss_test:0.07550, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:54.013, tt:756.180\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:14, loss:0.00014, loss_test:0.07635, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:53.974, tt:809.614\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:15, loss:0.00014, loss_test:0.07338, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:53.901, tt:862.408\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:16, loss:0.00014, loss_test:0.07292, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:53.921, tt:916.659\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:17, loss:0.00013, loss_test:0.07372, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:53.894, tt:970.096\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:18, loss:0.00013, loss_test:0.07166, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:53.878, tt:1023.679\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:19, loss:0.00013, loss_test:0.07244, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:53.856, tt:1077.121\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:20, loss:0.00012, loss_test:0.07095, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:53.923, tt:1132.384\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:21, loss:0.00012, loss_test:0.06996, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:53.870, tt:1185.130\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:22, loss:0.00012, loss_test:0.07258, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:53.899, tt:1239.674\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:23, loss:0.00011, loss_test:0.06809, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:53.951, tt:1294.821\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:24, loss:0.00011, loss_test:0.07233, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:53.935, tt:1348.377\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:25, loss:0.00011, loss_test:0.06725, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:53.894, tt:1401.234\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:26, loss:0.00011, loss_test:0.06911, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:53.882, tt:1454.816\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:27, loss:0.00010, loss_test:0.06769, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:53.767, tt:1505.478\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:28, loss:0.00010, loss_test:0.06799, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:53.687, tt:1556.926\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:29, loss:0.00010, loss_test:0.06726, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:53.701, tt:1611.025\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:30, loss:0.00009, loss_test:0.06615, lr:1.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:53.656, tt:1663.332\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:31, loss:0.00009, loss_test:0.06560, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:53.619, tt:1715.811\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:32, loss:0.00009, loss_test:0.06632, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:53.569, tt:1767.787\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:33, loss:0.00009, loss_test:0.06475, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:53.552, tt:1820.771\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:34, loss:0.00008, loss_test:0.06705, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:53.508, tt:1872.778\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:35, loss:0.00008, loss_test:0.06493, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:53.503, tt:1926.101\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:36, loss:0.00008, loss_test:0.06618, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:53.440, tt:1977.264\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:37, loss:0.00008, loss_test:0.06537, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:53.398, tt:2029.110\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:38, loss:0.00008, loss_test:0.06504, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:53.398, tt:2082.540\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:39, loss:0.00008, loss_test:0.06482, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:53.420, tt:2136.808\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:40, loss:0.00007, loss_test:0.06432, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:53.443, tt:2191.163\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:41, loss:0.00007, loss_test:0.06422, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:53.402, tt:2242.898\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:42, loss:0.00007, loss_test:0.06603, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:53.397, tt:2296.091\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:43, loss:0.00007, loss_test:0.06239, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:53.405, tt:2349.839\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:44, loss:0.00006, loss_test:0.06446, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:53.394, tt:2402.726\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:45, loss:0.00006, loss_test:0.06311, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:53.354, tt:2454.297\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:46, loss:0.00006, loss_test:0.06564, lr:9.90e-03, fs:0.80402 (r=0.808,p=0.800),  time:53.338, tt:2506.909\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:47, loss:0.00006, loss_test:0.06160, lr:9.80e-03, fs:0.80374 (r=0.869,p=0.748),  time:53.314, tt:2559.060\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:48, loss:0.00006, loss_test:0.06394, lr:9.70e-03, fs:0.80976 (r=0.838,p=0.783),  time:53.295, tt:2611.438\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:49, loss:0.00006, loss_test:0.06389, lr:9.61e-03, fs:0.79612 (r=0.828,p=0.766),  time:53.303, tt:2665.158\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:50, loss:0.00006, loss_test:0.06191, lr:9.51e-03, fs:0.79245 (r=0.848,p=0.743),  time:53.288, tt:2717.705\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:51, loss:0.00006, loss_test:0.06369, lr:9.41e-03, fs:0.80808 (r=0.808,p=0.808),  time:53.307, tt:2771.964\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:52, loss:0.00006, loss_test:0.06120, lr:9.32e-03, fs:0.80193 (r=0.838,p=0.769),  time:53.311, tt:2825.472\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:53, loss:0.00005, loss_test:0.06198, lr:9.23e-03, fs:0.79412 (r=0.818,p=0.771),  time:53.301, tt:2878.268\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:54, loss:0.00005, loss_test:0.06184, lr:9.14e-03, fs:0.80769 (r=0.848,p=0.771),  time:53.280, tt:2930.423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:55, loss:0.00005, loss_test:0.06159, lr:9.04e-03, fs:0.79602 (r=0.808,p=0.784),  time:53.260, tt:2982.533\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:56, loss:0.00005, loss_test:0.06207, lr:8.95e-03, fs:0.80583 (r=0.838,p=0.776),  time:53.257, tt:3035.628\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:57, loss:0.00005, loss_test:0.06268, lr:8.86e-03, fs:0.81592 (r=0.828,p=0.804),  time:53.223, tt:3086.955\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:58, loss:0.00005, loss_test:0.06081, lr:8.78e-03, fs:0.79803 (r=0.818,p=0.779),  time:53.223, tt:3140.145\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:59, loss:0.00005, loss_test:0.06168, lr:8.69e-03, fs:0.80788 (r=0.828,p=0.788),  time:53.251, tt:3195.054\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:60, loss:0.00005, loss_test:0.06025, lr:8.60e-03, fs:0.79612 (r=0.828,p=0.766),  time:53.244, tt:3247.877\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:61, loss:0.00005, loss_test:0.06215, lr:8.51e-03, fs:0.81026 (r=0.798,p=0.823),  time:53.274, tt:3303.017\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:62, loss:0.00004, loss_test:0.06105, lr:8.43e-03, fs:0.79227 (r=0.828,p=0.759),  time:53.283, tt:3356.836\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:63, loss:0.00004, loss_test:0.06188, lr:8.35e-03, fs:0.80000 (r=0.808,p=0.792),  time:53.265, tt:3408.951\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:64, loss:0.00004, loss_test:0.06162, lr:8.26e-03, fs:0.80597 (r=0.818,p=0.794),  time:53.267, tt:3462.327\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:65, loss:0.00004, loss_test:0.06145, lr:8.18e-03, fs:0.80203 (r=0.798,p=0.806),  time:53.304, tt:3518.093\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:66, loss:0.00004, loss_test:0.06121, lr:8.10e-03, fs:0.81218 (r=0.808,p=0.816),  time:53.324, tt:3572.685\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:67, loss:0.00004, loss_test:0.06139, lr:8.02e-03, fs:0.81000 (r=0.818,p=0.802),  time:53.334, tt:3626.745\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:68, loss:0.00004, loss_test:0.06137, lr:7.94e-03, fs:0.81026 (r=0.798,p=0.823),  time:53.358, tt:3681.733\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:69, loss:0.00004, loss_test:0.06108, lr:7.86e-03, fs:0.78000 (r=0.788,p=0.772),  time:53.373, tt:3736.087\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:70, loss:0.00004, loss_test:0.06255, lr:7.78e-03, fs:0.80203 (r=0.798,p=0.806),  time:53.381, tt:3790.050\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:71, loss:0.00004, loss_test:0.06119, lr:7.70e-03, fs:0.79397 (r=0.798,p=0.790),  time:53.391, tt:3844.172\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:72, loss:0.00004, loss_test:0.06177, lr:7.62e-03, fs:0.80412 (r=0.788,p=0.821),  time:53.406, tt:3898.670\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:73, loss:0.00004, loss_test:0.06285, lr:7.55e-03, fs:0.80412 (r=0.788,p=0.821),  time:53.444, tt:3954.830\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:74, loss:0.00004, loss_test:0.06022, lr:7.47e-03, fs:0.79024 (r=0.818,p=0.764),  time:53.474, tt:4010.561\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:75, loss:0.00004, loss_test:0.06293, lr:7.40e-03, fs:0.81250 (r=0.788,p=0.839),  time:53.486, tt:4064.952\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:76, loss:0.00004, loss_test:0.06093, lr:7.32e-03, fs:0.79208 (r=0.808,p=0.777),  time:53.488, tt:4118.595\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:77, loss:0.00004, loss_test:0.06155, lr:7.25e-03, fs:0.78818 (r=0.808,p=0.769),  time:53.473, tt:4170.858\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:78, loss:0.00004, loss_test:0.06201, lr:7.18e-03, fs:0.80829 (r=0.788,p=0.830),  time:53.481, tt:4224.993\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:79, loss:0.00003, loss_test:0.06008, lr:7.11e-03, fs:0.78818 (r=0.808,p=0.769),  time:53.488, tt:4279.060\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:80, loss:0.00003, loss_test:0.06148, lr:7.03e-03, fs:0.79188 (r=0.788,p=0.796),  time:53.509, tt:4334.264\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:81, loss:0.00003, loss_test:0.06040, lr:6.96e-03, fs:0.77612 (r=0.788,p=0.765),  time:53.563, tt:4392.195\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:82, loss:0.00003, loss_test:0.06166, lr:6.89e-03, fs:0.80000 (r=0.788,p=0.812),  time:53.576, tt:4446.835\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:83, loss:0.00003, loss_test:0.06277, lr:6.83e-03, fs:0.80208 (r=0.778,p=0.828),  time:53.599, tt:4502.325\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:84, loss:0.00003, loss_test:0.06179, lr:6.76e-03, fs:0.80000 (r=0.788,p=0.812),  time:53.608, tt:4556.680\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:85, loss:0.00003, loss_test:0.06203, lr:6.69e-03, fs:0.79592 (r=0.788,p=0.804),  time:53.620, tt:4611.324\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:86, loss:0.00003, loss_test:0.06199, lr:6.62e-03, fs:0.80208 (r=0.778,p=0.828),  time:53.627, tt:4665.567\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:87, loss:0.00003, loss_test:0.06220, lr:6.56e-03, fs:0.78974 (r=0.778,p=0.802),  time:53.619, tt:4718.446\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:88, loss:0.00003, loss_test:0.06190, lr:6.49e-03, fs:0.79188 (r=0.788,p=0.796),  time:53.611, tt:4771.417\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:89, loss:0.00003, loss_test:0.06248, lr:6.43e-03, fs:0.80208 (r=0.778,p=0.828),  time:53.613, tt:4825.127\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:90, loss:0.00003, loss_test:0.06297, lr:6.36e-03, fs:0.79793 (r=0.778,p=0.819),  time:53.617, tt:4879.192\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:91, loss:0.00003, loss_test:0.06203, lr:6.30e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.618, tt:4932.831\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:92, loss:0.00003, loss_test:0.06218, lr:6.24e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.630, tt:4987.573\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:93, loss:0.00003, loss_test:0.06244, lr:6.17e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.641, tt:5042.237\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:94, loss:0.00003, loss_test:0.06119, lr:6.11e-03, fs:0.78173 (r=0.778,p=0.786),  time:53.654, tt:5097.112\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:95, loss:0.00003, loss_test:0.06419, lr:6.05e-03, fs:0.81053 (r=0.778,p=0.846),  time:53.664, tt:5151.777\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:96, loss:0.00003, loss_test:0.06234, lr:5.99e-03, fs:0.79793 (r=0.778,p=0.819),  time:53.676, tt:5206.530\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:97, loss:0.00003, loss_test:0.06066, lr:5.93e-03, fs:0.78000 (r=0.788,p=0.772),  time:53.649, tt:5257.636\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:98, loss:0.00003, loss_test:0.06308, lr:5.87e-03, fs:0.80628 (r=0.778,p=0.837),  time:53.619, tt:5308.235\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:99, loss:0.00003, loss_test:0.06138, lr:5.81e-03, fs:0.78173 (r=0.778,p=0.786),  time:53.627, tt:5362.668\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:100, loss:0.00003, loss_test:0.06194, lr:5.75e-03, fs:0.78788 (r=0.788,p=0.788),  time:53.620, tt:5415.644\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:101, loss:0.00003, loss_test:0.06353, lr:5.70e-03, fs:0.80628 (r=0.778,p=0.837),  time:53.628, tt:5470.008\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:102, loss:0.00003, loss_test:0.06147, lr:5.64e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.616, tt:5522.431\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:103, loss:0.00003, loss_test:0.06274, lr:5.58e-03, fs:0.80208 (r=0.778,p=0.828),  time:53.609, tt:5575.383\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:104, loss:0.00003, loss_test:0.06188, lr:5.53e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.632, tt:5631.386\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:105, loss:0.00003, loss_test:0.06279, lr:5.47e-03, fs:0.79793 (r=0.778,p=0.819),  time:53.614, tt:5683.055\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:106, loss:0.00002, loss_test:0.06232, lr:5.42e-03, fs:0.79793 (r=0.778,p=0.819),  time:53.611, tt:5736.374\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:107, loss:0.00002, loss_test:0.06147, lr:5.36e-03, fs:0.78000 (r=0.788,p=0.772),  time:53.630, tt:5792.070\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:108, loss:0.00002, loss_test:0.06272, lr:5.31e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.631, tt:5845.752\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:109, loss:0.00002, loss_test:0.06222, lr:5.26e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.643, tt:5900.719\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:110, loss:0.00002, loss_test:0.06156, lr:5.20e-03, fs:0.78788 (r=0.788,p=0.788),  time:53.643, tt:5954.338\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:111, loss:0.00002, loss_test:0.06225, lr:5.15e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.633, tt:6006.897\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:112, loss:0.00002, loss_test:0.06351, lr:5.10e-03, fs:0.81053 (r=0.778,p=0.846),  time:53.639, tt:6061.228\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:113, loss:0.00002, loss_test:0.06194, lr:5.05e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.645, tt:6115.507\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:114, loss:0.00002, loss_test:0.06131, lr:5.00e-03, fs:0.78571 (r=0.778,p=0.794),  time:53.658, tt:6170.673\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:115, loss:0.00002, loss_test:0.06275, lr:4.95e-03, fs:0.79793 (r=0.778,p=0.819),  time:53.677, tt:6226.576\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:116, loss:0.00002, loss_test:0.06231, lr:4.90e-03, fs:0.79381 (r=0.778,p=0.811),  time:53.678, tt:6280.290\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:117, loss:0.00002, loss_test:0.06234, lr:4.85e-03, fs:0.78974 (r=0.778,p=0.802),  time:53.681, tt:6334.368\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:118, loss:0.00002, loss_test:0.06307, lr:4.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:53.671, tt:6386.859\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:119, loss:0.00002, loss_test:0.06192, lr:4.75e-03, fs:0.80208 (r=0.778,p=0.828),  time:53.657, tt:6438.854\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:0, loss:0.00031, loss_test:0.08710, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:47.886, tt:47.886\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:1, loss:0.00026, loss_test:0.07946, lr:1.00e-02, fs:0.62400 (r=0.788,p=0.517),  time:44.124, tt:88.247\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:2, loss:0.00022, loss_test:0.08819, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:44.024, tt:132.072\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:3, loss:0.00021, loss_test:0.07930, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:46.819, tt:187.275\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:4, loss:0.00020, loss_test:0.07525, lr:1.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:48.190, tt:240.950\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:5, loss:0.00020, loss_test:0.07817, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:49.214, tt:295.285\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:6, loss:0.00019, loss_test:0.07252, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:49.897, tt:349.276\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:7, loss:0.00018, loss_test:0.06980, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:50.418, tt:403.342\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:8, loss:0.00017, loss_test:0.07008, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:50.720, tt:456.482\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:9, loss:0.00017, loss_test:0.06523, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:51.135, tt:511.351\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:10, loss:0.00016, loss_test:0.06476, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:51.280, tt:564.085\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:11, loss:0.00016, loss_test:0.06354, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:51.472, tt:617.663\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:12, loss:0.00015, loss_test:0.06059, lr:1.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:51.731, tt:672.500\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:13, loss:0.00015, loss_test:0.06219, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:51.990, tt:727.858\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:14, loss:0.00014, loss_test:0.05991, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:52.211, tt:783.159\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:15, loss:0.00014, loss_test:0.05964, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:52.260, tt:836.162\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:16, loss:0.00014, loss_test:0.05958, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:52.363, tt:890.164\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:17, loss:0.00013, loss_test:0.05745, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:52.401, tt:943.221\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:18, loss:0.00013, loss_test:0.05792, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:52.544, tt:998.327\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:19, loss:0.00013, loss_test:0.05687, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:52.650, tt:1052.998\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:20, loss:0.00013, loss_test:0.05551, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:52.712, tt:1106.945\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:21, loss:0.00012, loss_test:0.05517, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:52.864, tt:1162.998\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:22, loss:0.00012, loss_test:0.05420, lr:1.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:53.134, tt:1222.084\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:23, loss:0.00012, loss_test:0.05436, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:53.470, tt:1283.269\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:24, loss:0.00011, loss_test:0.05346, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:53.808, tt:1345.210\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:25, loss:0.00011, loss_test:0.05244, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:54.045, tt:1405.163\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:26, loss:0.00011, loss_test:0.05314, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:54.279, tt:1465.543\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:27, loss:0.00011, loss_test:0.05172, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:54.387, tt:1522.844\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:28, loss:0.00010, loss_test:0.05146, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:54.439, tt:1578.727\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:29, loss:0.00010, loss_test:0.05101, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:54.464, tt:1633.932\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:30, loss:0.00010, loss_test:0.05017, lr:1.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:54.503, tt:1689.602\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:31, loss:0.00009, loss_test:0.04977, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:54.551, tt:1745.639\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:32, loss:0.00009, loss_test:0.04970, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:54.702, tt:1805.170\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:33, loss:0.00009, loss_test:0.04878, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:54.825, tt:1864.049\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:34, loss:0.00009, loss_test:0.04922, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:54.989, tt:1924.632\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:35, loss:0.00009, loss_test:0.04760, lr:1.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:55.133, tt:1984.783\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:36, loss:0.00008, loss_test:0.04870, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:55.292, tt:2045.814\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:37, loss:0.00008, loss_test:0.04743, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:55.338, tt:2102.839\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:38, loss:0.00008, loss_test:0.04873, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:55.355, tt:2158.850\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:39, loss:0.00008, loss_test:0.04658, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:55.303, tt:2212.131\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:40, loss:0.00007, loss_test:0.04670, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:55.335, tt:2268.755\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:41, loss:0.00007, loss_test:0.04619, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:55.285, tt:2321.971\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:42, loss:0.00007, loss_test:0.04559, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:55.364, tt:2380.650\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:43, loss:0.00007, loss_test:0.04576, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:55.527, tt:2443.205\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:44, loss:0.00007, loss_test:0.04612, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:55.556, tt:2500.028\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:45, loss:0.00006, loss_test:0.04417, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:55.648, tt:2559.820\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:46, loss:0.00006, loss_test:0.04507, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:55.749, tt:2620.199\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:47, loss:0.00006, loss_test:0.04454, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:55.764, tt:2676.690\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:48, loss:0.00006, loss_test:0.04646, lr:1.00e-02, fs:0.92929 (r=0.929,p=0.929),  time:55.727, tt:2730.611\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:49, loss:0.00006, loss_test:0.04212, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:55.727, tt:2786.340\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:50, loss:0.00006, loss_test:0.04725, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:55.696, tt:2840.518\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:51, loss:0.00006, loss_test:0.04338, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:55.661, tt:2894.374\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:52, loss:0.00006, loss_test:0.04548, lr:1.00e-02, fs:0.92462 (r=0.929,p=0.920),  time:55.707, tt:2952.486\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:53, loss:0.00006, loss_test:0.04542, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:55.733, tt:3009.562\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:54, loss:0.00006, loss_test:0.04379, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:55.762, tt:3066.890\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:55, loss:0.00005, loss_test:0.04543, lr:1.00e-02, fs:0.92462 (r=0.929,p=0.920),  time:55.832, tt:3126.592\n",
      "1032\n",
      "1026\n",
      "606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00005, loss_test:0.04278, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:55.888, tt:3185.608\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:57, loss:0.00005, loss_test:0.04489, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:55.815, tt:3237.255\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:58, loss:0.00005, loss_test:0.04426, lr:1.00e-02, fs:0.92462 (r=0.929,p=0.920),  time:55.762, tt:3289.941\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:59, loss:0.00005, loss_test:0.04454, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:55.713, tt:3342.789\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:60, loss:0.00005, loss_test:0.04281, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:55.665, tt:3395.551\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:61, loss:0.00005, loss_test:0.04455, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:55.631, tt:3449.143\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:62, loss:0.00005, loss_test:0.04324, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:55.653, tt:3506.167\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:63, loss:0.00004, loss_test:0.04331, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:55.711, tt:3565.498\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:64, loss:0.00004, loss_test:0.04429, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:55.723, tt:3621.976\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:65, loss:0.00004, loss_test:0.04262, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:55.753, tt:3679.683\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:66, loss:0.00004, loss_test:0.04427, lr:9.90e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.799, tt:3738.528\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:67, loss:0.00004, loss_test:0.04275, lr:9.80e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.725, tt:3789.303\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:68, loss:0.00004, loss_test:0.04218, lr:9.70e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.675, tt:3841.570\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:69, loss:0.00004, loss_test:0.04266, lr:9.61e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.614, tt:3893.015\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:70, loss:0.00004, loss_test:0.04114, lr:9.51e-03, fs:0.92000 (r=0.929,p=0.911),  time:55.556, tt:3944.505\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:71, loss:0.00004, loss_test:0.04276, lr:9.41e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.519, tt:3997.376\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:72, loss:0.00003, loss_test:0.04206, lr:9.32e-03, fs:0.92857 (r=0.919,p=0.938),  time:55.568, tt:4056.495\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:73, loss:0.00004, loss_test:0.04286, lr:9.23e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.593, tt:4113.873\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:74, loss:0.00003, loss_test:0.04314, lr:9.14e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.642, tt:4173.153\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:75, loss:0.00003, loss_test:0.04047, lr:9.04e-03, fs:0.93069 (r=0.949,p=0.913),  time:55.671, tt:4231.033\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:76, loss:0.00003, loss_test:0.04351, lr:9.04e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.705, tt:4289.249\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:77, loss:0.00003, loss_test:0.04101, lr:9.04e-03, fs:0.93000 (r=0.939,p=0.921),  time:55.678, tt:4342.867\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:78, loss:0.00003, loss_test:0.04344, lr:9.04e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.602, tt:4392.542\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:79, loss:0.00003, loss_test:0.04172, lr:9.04e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.566, tt:4445.257\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:80, loss:0.00003, loss_test:0.04140, lr:9.04e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.532, tt:4498.052\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:81, loss:0.00003, loss_test:0.04324, lr:9.04e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.475, tt:4548.991\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:82, loss:0.00003, loss_test:0.04028, lr:9.04e-03, fs:0.92537 (r=0.939,p=0.912),  time:55.498, tt:4606.352\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:83, loss:0.00003, loss_test:0.04327, lr:9.04e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.547, tt:4665.979\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:84, loss:0.00003, loss_test:0.04195, lr:9.04e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.568, tt:4723.287\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:85, loss:0.00003, loss_test:0.04081, lr:9.04e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.564, tt:4778.531\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:86, loss:0.00003, loss_test:0.04383, lr:9.04e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.590, tt:4836.290\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:87, loss:0.00003, loss_test:0.04091, lr:8.95e-03, fs:0.92462 (r=0.929,p=0.920),  time:55.575, tt:4890.601\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:88, loss:0.00003, loss_test:0.04255, lr:8.86e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.537, tt:4942.816\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:89, loss:0.00003, loss_test:0.04187, lr:8.78e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.516, tt:4996.454\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:90, loss:0.00003, loss_test:0.04081, lr:8.69e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.480, tt:5048.645\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:91, loss:0.00002, loss_test:0.04090, lr:8.60e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.439, tt:5100.433\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:92, loss:0.00002, loss_test:0.04128, lr:8.51e-03, fs:0.91919 (r=0.919,p=0.919),  time:55.471, tt:5158.840\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:93, loss:0.00002, loss_test:0.04157, lr:8.43e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.458, tt:5213.088\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:94, loss:0.00002, loss_test:0.04222, lr:8.35e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.480, tt:5270.620\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:95, loss:0.00002, loss_test:0.04164, lr:8.26e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.497, tt:5327.671\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:96, loss:0.00002, loss_test:0.04122, lr:8.18e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.518, tt:5385.206\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:97, loss:0.00002, loss_test:0.04316, lr:8.10e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.489, tt:5437.928\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:98, loss:0.00002, loss_test:0.04277, lr:8.02e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.459, tt:5490.447\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:99, loss:0.00002, loss_test:0.04115, lr:7.94e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.413, tt:5541.273\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:102, loss:0.00002, loss_test:0.04139, lr:7.70e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.426, tt:5708.831\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:103, loss:0.00002, loss_test:0.04278, lr:7.62e-03, fs:0.91837 (r=0.909,p=0.928),  time:55.457, tt:5767.526\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:104, loss:0.00002, loss_test:0.04093, lr:7.55e-03, fs:0.91919 (r=0.919,p=0.919),  time:55.485, tt:5825.921\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:105, loss:0.00002, loss_test:0.04179, lr:7.47e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.521, tt:5885.224\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:106, loss:0.00002, loss_test:0.04208, lr:7.40e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.544, tt:5943.214\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:107, loss:0.00002, loss_test:0.04107, lr:7.32e-03, fs:0.91457 (r=0.919,p=0.910),  time:55.498, tt:5993.833\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:108, loss:0.00002, loss_test:0.04206, lr:7.25e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.472, tt:6046.455\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:109, loss:0.00002, loss_test:0.04222, lr:7.18e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.455, tt:6100.103\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:110, loss:0.00002, loss_test:0.04167, lr:7.11e-03, fs:0.92386 (r=0.919,p=0.929),  time:55.433, tt:6153.056\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:111, loss:0.00002, loss_test:0.04120, lr:7.03e-03, fs:0.92929 (r=0.929,p=0.929),  time:55.438, tt:6209.025\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:112, loss:0.00002, loss_test:0.04191, lr:6.96e-03, fs:0.91837 (r=0.909,p=0.928),  time:55.464, tt:6267.485\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:113, loss:0.00002, loss_test:0.04195, lr:6.89e-03, fs:0.91837 (r=0.909,p=0.928),  time:55.492, tt:6326.140\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:114, loss:0.00002, loss_test:0.04126, lr:6.83e-03, fs:0.92462 (r=0.929,p=0.920),  time:55.516, tt:6384.395\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:115, loss:0.00002, loss_test:0.04232, lr:6.76e-03, fs:0.91837 (r=0.909,p=0.928),  time:55.541, tt:6442.750\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:116, loss:0.00002, loss_test:0.04303, lr:6.69e-03, fs:0.91753 (r=0.899,p=0.937),  time:55.538, tt:6497.997\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:117, loss:0.00002, loss_test:0.04159, lr:6.62e-03, fs:0.91371 (r=0.909,p=0.918),  time:55.508, tt:6549.968\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:118, loss:0.00002, loss_test:0.04179, lr:6.56e-03, fs:0.91837 (r=0.909,p=0.928),  time:55.478, tt:6601.915\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:119, loss:0.00002, loss_test:0.04231, lr:6.49e-03, fs:0.91282 (r=0.899,p=0.927),  time:55.440, tt:6652.790\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 12\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1035\n",
      "1029\n",
      "600\n",
      "Ep:0, loss:0.00031, loss_test:0.09212, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:47.394, tt:47.394\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n",
      "1029\n",
      "600\n",
      "Ep:1, loss:0.00026, loss_test:0.09370, lr:1.00e-02, fs:0.62041 (r=0.768,p=0.521),  time:49.946, tt:99.892\n",
      "1035\n",
      "1029\n",
      "600\n",
      "Ep:2, loss:0.00021, loss_test:0.10324, lr:1.00e-02, fs:0.61463 (r=0.636,p=0.594),  time:50.016, tt:150.049\n",
      "1035\n",
      "1029\n",
      "600\n",
      "Ep:3, loss:0.00020, loss_test:0.09431, lr:1.00e-02, fs:0.63025 (r=0.758,p=0.540),  time:51.489, tt:205.956\n",
      "1035\n",
      "1029\n",
      "600\n",
      "Ep:4, loss:0.00020, loss_test:0.09091, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:52.518, tt:262.592\n",
      "1035\n",
      "1029\n",
      "600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9884dd7af360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09599, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:38.233, tt:38.233\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09416, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:53.763, tt:107.526\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.09051, lr:1.00e-02, fs:0.63309 (r=0.889,p=0.492),  time:59.874, tt:179.621\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08922, lr:1.00e-02, fs:0.62651 (r=0.788,p=0.520),  time:62.946, tt:251.783\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08632, lr:1.00e-02, fs:0.64615 (r=0.848,p=0.522),  time:64.769, tt:323.845\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.08334, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:66.136, tt:396.813\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.08086, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:67.213, tt:470.490\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.07782, lr:1.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:68.460, tt:547.681\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07490, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:69.638, tt:626.740\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07300, lr:1.00e-02, fs:0.71373 (r=0.919,p=0.583),  time:71.107, tt:711.069\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07072, lr:1.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:71.937, tt:791.310\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06926, lr:1.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:72.703, tt:872.436\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.06774, lr:1.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:73.196, tt:951.545\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06645, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:73.259, tt:1025.632\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.06494, lr:1.00e-02, fs:0.75096 (r=0.990,p=0.605),  time:73.175, tt:1097.620\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06500, lr:1.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:73.172, tt:1170.756\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06329, lr:1.00e-02, fs:0.76863 (r=0.990,p=0.628),  time:73.545, tt:1250.262\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.06255, lr:1.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:73.868, tt:1329.621\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06194, lr:1.00e-02, fs:0.78543 (r=0.980,p=0.655),  time:74.134, tt:1408.541\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.06071, lr:1.00e-02, fs:0.79200 (r=1.000,p=0.656),  time:74.417, tt:1488.340\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06042, lr:1.00e-02, fs:0.79675 (r=0.990,p=0.667),  time:74.591, tt:1566.409\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05925, lr:1.00e-02, fs:0.79839 (r=1.000,p=0.664),  time:74.835, tt:1646.366\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.05883, lr:1.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:74.702, tt:1718.142\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.05857, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:74.651, tt:1791.633\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.05787, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:74.553, tt:1863.814\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.05731, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:74.423, tt:1935.006\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.05650, lr:1.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:74.553, tt:2012.933\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.05678, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:74.780, tt:2093.851\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.05572, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:74.987, tt:2174.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.05621, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:75.065, tt:2251.956\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.05553, lr:1.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:75.090, tt:2327.786\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.05388, lr:1.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:75.169, tt:2405.394\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.05596, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:75.118, tt:2478.904\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.05312, lr:1.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:74.999, tt:2549.983\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.05386, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:74.932, tt:2622.628\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.05473, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:75.005, tt:2700.166\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.05244, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:75.105, tt:2778.887\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.05438, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:75.201, tt:2857.638\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.05125, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:75.313, tt:2937.226\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.05401, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:75.382, tt:3015.287\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.05232, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:75.413, tt:3091.930\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.05182, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:75.379, tt:3165.897\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05395, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:75.348, tt:3239.964\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.05166, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:75.254, tt:3311.169\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.05128, lr:1.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:75.245, tt:3386.024\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.05282, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:75.352, tt:3466.175\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.05155, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:75.452, tt:3546.267\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.05209, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:75.527, tt:3625.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.05166, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:75.619, tt:3705.310\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.05057, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:75.725, tt:3786.228\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.05227, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:75.755, tt:3863.520\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.05187, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:75.713, tt:3937.087\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.05023, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:75.650, tt:4009.450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.05093, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:75.600, tt:4082.394\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.05114, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:75.649, tt:4160.688\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.05130, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:75.710, tt:4239.751\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.05032, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:75.780, tt:4319.474\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.05142, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:75.865, tt:4400.189\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.04926, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:75.948, tt:4480.961\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.05162, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:76.009, tt:4560.552\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.05038, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:75.950, tt:4632.955\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.04935, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:75.903, tt:4705.967\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.05278, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:75.821, tt:4776.730\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.04967, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:75.819, tt:4852.441\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.05142, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:75.907, tt:4933.923\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.05067, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:76.009, tt:5016.577\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.05055, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:76.072, tt:5096.837\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.05099, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:76.130, tt:5176.821\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.05064, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:76.153, tt:5254.557\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.05041, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:76.168, tt:5331.782\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.04993, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:76.119, tt:5404.432\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.05174, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:76.062, tt:5476.478\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.05211, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:75.974, tt:5546.121\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.05136, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:75.978, tt:5622.336\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.05163, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:76.042, tt:5703.163\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.05167, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:76.075, tt:5781.713\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.05105, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:76.106, tt:5860.183\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.05302, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:76.125, tt:5937.746\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.05208, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:76.166, tt:6017.113\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.05200, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:76.123, tt:6089.864\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.05236, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:76.053, tt:6160.288\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.05072, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:76.031, tt:6234.556\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.05338, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:75.979, tt:6306.252\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.05128, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:76.024, tt:6385.980\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.05373, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:76.063, tt:6465.323\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.05197, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:76.106, tt:6545.134\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.05290, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:76.145, tt:6624.653\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.05473, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:76.180, tt:6703.875\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.05251, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:76.234, tt:6784.810\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.05463, lr:9.90e-03, fs:0.84211 (r=0.808,p=0.879),  time:76.207, tt:6858.666\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.05143, lr:9.80e-03, fs:0.87000 (r=0.879,p=0.861),  time:76.163, tt:6930.824\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.05370, lr:9.70e-03, fs:0.86294 (r=0.859,p=0.867),  time:76.140, tt:7004.919\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.05301, lr:9.61e-03, fs:0.87879 (r=0.879,p=0.879),  time:76.148, tt:7081.774\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.05229, lr:9.51e-03, fs:0.86869 (r=0.869,p=0.869),  time:76.184, tt:7161.277\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.05360, lr:9.41e-03, fs:0.87629 (r=0.859,p=0.895),  time:76.222, tt:7241.042\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.05191, lr:9.32e-03, fs:0.87437 (r=0.879,p=0.870),  time:76.252, tt:7320.149\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.05470, lr:9.23e-03, fs:0.86458 (r=0.838,p=0.892),  time:76.290, tt:7400.137\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.05140, lr:9.14e-03, fs:0.87000 (r=0.879,p=0.861),  time:76.347, tt:7481.960\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.05353, lr:9.04e-03, fs:0.87310 (r=0.869,p=0.878),  time:76.377, tt:7561.308\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.05040, lr:8.95e-03, fs:0.86139 (r=0.879,p=0.845),  time:76.343, tt:7634.294\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.05359, lr:8.86e-03, fs:0.87310 (r=0.869,p=0.878),  time:76.317, tt:7708.000\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.05323, lr:8.78e-03, fs:0.87179 (r=0.859,p=0.885),  time:76.288, tt:7781.368\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.05322, lr:8.69e-03, fs:0.88325 (r=0.879,p=0.888),  time:76.338, tt:7862.839\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.05379, lr:8.69e-03, fs:0.88205 (r=0.869,p=0.896),  time:76.396, tt:7945.159\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.05439, lr:8.69e-03, fs:0.87958 (r=0.848,p=0.913),  time:76.434, tt:8025.570\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.05357, lr:8.69e-03, fs:0.88205 (r=0.869,p=0.896),  time:76.453, tt:8104.050\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.05427, lr:8.69e-03, fs:0.87958 (r=0.848,p=0.913),  time:76.495, tt:8184.972\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.05441, lr:8.69e-03, fs:0.83871 (r=0.788,p=0.897),  time:76.539, tt:8266.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.05280, lr:8.69e-03, fs:0.87879 (r=0.879,p=0.879),  time:76.497, tt:8338.157\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.05498, lr:8.69e-03, fs:0.83696 (r=0.778,p=0.906),  time:76.459, tt:8410.506\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.05322, lr:8.69e-03, fs:0.87629 (r=0.859,p=0.895),  time:76.407, tt:8481.137\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.05363, lr:8.69e-03, fs:0.88205 (r=0.869,p=0.896),  time:76.387, tt:8555.309\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.05301, lr:8.69e-03, fs:0.88776 (r=0.879,p=0.897),  time:76.432, tt:8636.868\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.05504, lr:8.69e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.455, tt:8715.911\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.05289, lr:8.69e-03, fs:0.88325 (r=0.879,p=0.888),  time:76.491, tt:8796.463\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.05420, lr:8.69e-03, fs:0.82796 (r=0.778,p=0.885),  time:76.515, tt:8875.686\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.05372, lr:8.69e-03, fs:0.87629 (r=0.859,p=0.895),  time:76.538, tt:8954.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.05491, lr:8.69e-03, fs:0.86170 (r=0.818,p=0.910),  time:76.532, tt:9030.774\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.05446, lr:8.69e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.502, tt:9103.793\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.05498, lr:8.69e-03, fs:0.83060 (r=0.768,p=0.905),  time:76.463, tt:9175.556\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.05376, lr:8.69e-03, fs:0.82162 (r=0.768,p=0.884),  time:76.436, tt:9248.715\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09075, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:60.960, tt:60.960\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.08723, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:69.095, tt:138.190\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00035, loss_test:0.08082, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:72.799, tt:218.396\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00033, loss_test:0.07372, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:74.347, tt:297.389\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07059, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:75.226, tt:376.128\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.06839, lr:1.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:75.053, tt:450.317\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.06508, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:74.697, tt:522.878\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.06202, lr:1.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:74.543, tt:596.348\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00027, loss_test:0.05950, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:74.265, tt:668.381\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00026, loss_test:0.05786, lr:1.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:74.715, tt:747.147\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00025, loss_test:0.05600, lr:1.00e-02, fs:0.77912 (r=0.980,p=0.647),  time:75.246, tt:827.701\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00024, loss_test:0.05524, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:75.769, tt:909.229\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.05367, lr:1.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:76.084, tt:989.096\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.05264, lr:1.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:76.521, tt:1071.288\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.05168, lr:1.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:76.734, tt:1151.006\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00022, loss_test:0.05094, lr:1.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:76.385, tt:1222.156\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.05001, lr:1.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:76.111, tt:1293.886\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.04943, lr:1.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:75.847, tt:1365.239\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.04867, lr:1.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:75.850, tt:1441.143\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.04787, lr:1.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:76.037, tt:1520.741\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.04724, lr:1.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:76.326, tt:1602.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.04691, lr:1.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:76.487, tt:1682.709\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.04680, lr:1.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:76.580, tt:1761.336\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.04583, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:76.811, tt:1843.461\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.04595, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:76.829, tt:1920.732\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.04490, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:76.725, tt:1994.848\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.04473, lr:1.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:76.655, tt:2069.685\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.04415, lr:1.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:76.539, tt:2143.088\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.04362, lr:1.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:76.663, tt:2223.222\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.04374, lr:1.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:76.750, tt:2302.505\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.04250, lr:1.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:76.813, tt:2381.218\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.04379, lr:1.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:76.909, tt:2461.076\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.04139, lr:1.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:77.000, tt:2540.997\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.04176, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:77.057, tt:2619.936\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.04225, lr:1.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:76.946, tt:2693.117\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.04004, lr:1.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:76.823, tt:2765.614\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.04264, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:76.713, tt:2838.377\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.03990, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:76.590, tt:2910.425\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.04086, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:76.679, tt:2990.463\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.03992, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:76.722, tt:3068.874\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.03973, lr:1.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:76.728, tt:3145.842\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.04048, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:76.790, tt:3225.164\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.03917, lr:1.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:76.868, tt:3305.320\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.03972, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:76.865, tt:3382.043\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.03851, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:76.811, tt:3456.506\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.03963, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:76.743, tt:3530.201\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.03857, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:76.669, tt:3603.445\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.03872, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:76.824, tt:3687.560\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.03815, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:76.901, tt:3768.171\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.03796, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:76.968, tt:3848.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.03729, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:77.029, tt:3928.475\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.03943, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:77.067, tt:4007.504\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.03669, lr:1.00e-02, fs:0.89815 (r=0.980,p=0.829),  time:77.120, tt:4087.364\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.03790, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:77.043, tt:4160.335\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.03737, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.937, tt:4231.514\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.03765, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:76.864, tt:4304.364\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.03735, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:76.839, tt:4379.823\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.03667, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.840, tt:4456.695\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.03729, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.849, tt:4534.066\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.03640, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.861, tt:4611.650\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.03724, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:76.883, tt:4689.874\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.03656, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.887, tt:4766.998\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.03690, lr:1.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:76.897, tt:4844.481\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.03698, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:76.821, tt:4916.530\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.03610, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.742, tt:4988.250\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.03684, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:76.637, tt:5058.073\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.03669, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.679, tt:5137.463\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.03658, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:76.710, tt:5216.279\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.03613, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:76.739, tt:5294.983\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.03575, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:76.739, tt:5371.723\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.03653, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:76.750, tt:5449.229\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.03538, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.793, tt:5529.129\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.03705, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:76.763, tt:5603.676\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.03588, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:76.711, tt:5676.602\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.03650, lr:9.90e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.643, tt:5748.245\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.03557, lr:9.80e-03, fs:0.91866 (r=0.970,p=0.873),  time:76.628, tt:5823.755\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.03579, lr:9.70e-03, fs:0.91866 (r=0.970,p=0.873),  time:76.666, tt:5903.255\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.03553, lr:9.61e-03, fs:0.91866 (r=0.970,p=0.873),  time:76.654, tt:5979.002\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.03662, lr:9.51e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.720, tt:6060.893\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.03486, lr:9.41e-03, fs:0.91429 (r=0.970,p=0.865),  time:76.781, tt:6142.500\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.03711, lr:9.32e-03, fs:0.91787 (r=0.960,p=0.880),  time:76.816, tt:6222.095\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.03518, lr:9.23e-03, fs:0.91429 (r=0.970,p=0.865),  time:76.848, tt:6301.518\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.03611, lr:9.14e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.789, tt:6373.461\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.03551, lr:9.04e-03, fs:0.91866 (r=0.970,p=0.873),  time:76.761, tt:6447.952\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.03633, lr:8.95e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.723, tt:6521.419\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.03607, lr:8.86e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.708, tt:6596.870\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.03612, lr:8.78e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.731, tt:6675.585\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.03578, lr:8.69e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.760, tt:6754.837\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.03646, lr:8.60e-03, fs:0.91787 (r=0.960,p=0.880),  time:76.770, tt:6832.512\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.03564, lr:8.51e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.794, tt:6911.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.03603, lr:8.43e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.821, tt:6990.693\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.03552, lr:8.35e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.802, tt:7065.781\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.03620, lr:8.26e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.730, tt:7135.911\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.03504, lr:8.18e-03, fs:0.91866 (r=0.970,p=0.873),  time:76.651, tt:7205.234\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.03710, lr:8.10e-03, fs:0.91787 (r=0.960,p=0.880),  time:76.606, tt:7277.546\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.03522, lr:8.02e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.619, tt:7355.421\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.03730, lr:7.94e-03, fs:0.93137 (r=0.960,p=0.905),  time:76.623, tt:7432.451\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.03585, lr:7.94e-03, fs:0.92233 (r=0.960,p=0.888),  time:76.642, tt:7510.906\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.03615, lr:7.94e-03, fs:0.93204 (r=0.970,p=0.897),  time:76.664, tt:7589.690\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.03567, lr:7.94e-03, fs:0.92308 (r=0.970,p=0.881),  time:76.667, tt:7666.658\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.03583, lr:7.94e-03, fs:0.92233 (r=0.960,p=0.888),  time:76.657, tt:7742.404\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.03679, lr:7.94e-03, fs:0.93137 (r=0.960,p=0.905),  time:76.608, tt:7813.967\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.03604, lr:7.94e-03, fs:0.92233 (r=0.960,p=0.888),  time:76.554, tt:7885.017\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.03691, lr:7.94e-03, fs:0.93596 (r=0.960,p=0.913),  time:76.507, tt:7956.771\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.03567, lr:7.94e-03, fs:0.92683 (r=0.960,p=0.896),  time:76.531, tt:8035.791\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.03740, lr:7.94e-03, fs:0.94059 (r=0.960,p=0.922),  time:76.560, tt:8115.394\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.03554, lr:7.94e-03, fs:0.93659 (r=0.970,p=0.906),  time:76.599, tt:8196.060\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.03668, lr:7.94e-03, fs:0.93596 (r=0.960,p=0.913),  time:76.614, tt:8274.271\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.03540, lr:7.94e-03, fs:0.92233 (r=0.960,p=0.888),  time:76.642, tt:8353.983\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.03648, lr:7.94e-03, fs:0.93596 (r=0.960,p=0.913),  time:76.674, tt:8434.097\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.03569, lr:7.94e-03, fs:0.93596 (r=0.960,p=0.913),  time:76.647, tt:8507.833\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.03596, lr:7.94e-03, fs:0.93137 (r=0.960,p=0.905),  time:76.618, tt:8581.248\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.03675, lr:7.94e-03, fs:0.94527 (r=0.960,p=0.931),  time:76.609, tt:8656.795\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.03510, lr:7.94e-03, fs:0.93659 (r=0.970,p=0.906),  time:76.606, tt:8733.109\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.03621, lr:7.94e-03, fs:0.94059 (r=0.960,p=0.922),  time:76.643, tt:8813.928\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.03571, lr:7.94e-03, fs:0.93137 (r=0.960,p=0.905),  time:76.670, tt:8893.720\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.03629, lr:7.94e-03, fs:0.94059 (r=0.960,p=0.922),  time:76.688, tt:8972.552\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.03611, lr:7.94e-03, fs:0.94059 (r=0.960,p=0.922),  time:76.710, tt:9051.731\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.03554, lr:7.94e-03, fs:0.93596 (r=0.960,p=0.913),  time:76.715, tt:9129.138\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.03578, lr:7.94e-03, fs:0.93137 (r=0.960,p=0.905),  time:76.721, tt:9206.479\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.03634, lr:7.94e-03, fs:0.94527 (r=0.960,p=0.931),  time:76.683, tt:9278.642\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 12\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09357, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:64.734, tt:64.734\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09093, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:70.312, tt:140.623\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08713, lr:1.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:74.531, tt:223.593\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08545, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:76.468, tt:305.871\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08220, lr:1.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:76.988, tt:384.939\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.07939, lr:1.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:77.675, tt:466.049\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.07822, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:77.985, tt:545.896\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.07571, lr:1.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:77.976, tt:623.806\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07360, lr:1.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:77.535, tt:697.811\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07229, lr:1.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:77.414, tt:774.142\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07080, lr:1.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:77.085, tt:847.931\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06969, lr:1.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:77.306, tt:927.676\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.06882, lr:1.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:77.653, tt:1009.483\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06775, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:77.799, tt:1089.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.06672, lr:1.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:77.997, tt:1169.961\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06548, lr:1.00e-02, fs:0.75889 (r=0.970,p=0.623),  time:77.981, tt:1247.699\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06497, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:78.091, tt:1327.548\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.06455, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:77.807, tt:1400.522\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06348, lr:1.00e-02, fs:0.73640 (r=0.889,p=0.629),  time:77.623, tt:1474.832\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.06276, lr:1.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:77.451, tt:1549.019\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06235, lr:1.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:77.452, tt:1626.486\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.06147, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:77.593, tt:1707.037\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06133, lr:1.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:77.677, tt:1786.580\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.06016, lr:1.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:77.801, tt:1867.220\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.06021, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:77.877, tt:1946.913\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.05920, lr:1.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:77.895, tt:2025.281\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.05889, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:77.905, tt:2103.432\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.05800, lr:9.90e-03, fs:0.76106 (r=0.869,p=0.677),  time:77.702, tt:2175.647\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.05788, lr:9.90e-03, fs:0.75652 (r=0.879,p=0.664),  time:77.452, tt:2246.108\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.05682, lr:9.90e-03, fs:0.76786 (r=0.869,p=0.688),  time:77.286, tt:2318.587\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.05838, lr:9.90e-03, fs:0.78182 (r=0.869,p=0.711),  time:77.223, tt:2393.919\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.05603, lr:9.90e-03, fs:0.77477 (r=0.869,p=0.699),  time:77.310, tt:2473.930\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.05653, lr:9.90e-03, fs:0.78182 (r=0.869,p=0.711),  time:77.421, tt:2554.909\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.05669, lr:9.90e-03, fs:0.80000 (r=0.869,p=0.741),  time:77.549, tt:2636.681\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.05641, lr:9.90e-03, fs:0.79263 (r=0.869,p=0.729),  time:77.584, tt:2715.439\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.05584, lr:9.90e-03, fs:0.80000 (r=0.869,p=0.741),  time:77.615, tt:2794.154\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.05563, lr:9.90e-03, fs:0.79263 (r=0.869,p=0.729),  time:77.498, tt:2867.421\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.05559, lr:9.90e-03, fs:0.80952 (r=0.859,p=0.766),  time:77.424, tt:2942.107\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.05479, lr:9.90e-03, fs:0.78899 (r=0.869,p=0.723),  time:77.318, tt:3015.415\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.05491, lr:9.90e-03, fs:0.80952 (r=0.859,p=0.766),  time:77.264, tt:3090.554\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.05496, lr:9.90e-03, fs:0.82126 (r=0.859,p=0.787),  time:77.307, tt:3169.606\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.05421, lr:9.90e-03, fs:0.79070 (r=0.859,p=0.733),  time:77.271, tt:3245.381\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05488, lr:9.90e-03, fs:0.83333 (r=0.859,p=0.810),  time:77.321, tt:3324.798\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.05401, lr:9.90e-03, fs:0.79070 (r=0.859,p=0.733),  time:77.350, tt:3403.403\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.05433, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:77.374, tt:3481.822\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.05422, lr:9.90e-03, fs:0.81340 (r=0.859,p=0.773),  time:77.381, tt:3559.546\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.05472, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:77.282, tt:3632.258\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.05460, lr:9.90e-03, fs:0.83333 (r=0.859,p=0.810),  time:77.157, tt:3703.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.05316, lr:9.90e-03, fs:0.81731 (r=0.859,p=0.780),  time:77.094, tt:3777.610\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.05393, lr:9.90e-03, fs:0.82927 (r=0.859,p=0.802),  time:77.132, tt:3856.605\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.05368, lr:9.90e-03, fs:0.83333 (r=0.859,p=0.810),  time:77.209, tt:3937.646\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.05379, lr:9.90e-03, fs:0.83333 (r=0.859,p=0.810),  time:77.302, tt:4019.708\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.05376, lr:9.90e-03, fs:0.83333 (r=0.859,p=0.810),  time:77.338, tt:4098.930\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.05370, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:77.380, tt:4178.493\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.05318, lr:9.90e-03, fs:0.82524 (r=0.859,p=0.794),  time:77.412, tt:4257.680\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.05413, lr:9.90e-03, fs:0.85000 (r=0.859,p=0.842),  time:77.358, tt:4332.051\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.05353, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:77.294, tt:4405.739\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.05302, lr:9.90e-03, fs:0.83333 (r=0.859,p=0.810),  time:77.220, tt:4478.746\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.05377, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:77.237, tt:4556.993\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.05364, lr:9.90e-03, fs:0.84158 (r=0.859,p=0.825),  time:77.263, tt:4635.777\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.05289, lr:9.90e-03, fs:0.82927 (r=0.859,p=0.802),  time:77.336, tt:4717.500\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.05446, lr:9.90e-03, fs:0.85427 (r=0.859,p=0.850),  time:77.381, tt:4797.635\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.05412, lr:9.90e-03, fs:0.85000 (r=0.859,p=0.842),  time:77.425, tt:4877.781\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.05339, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:77.449, tt:4956.717\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.05403, lr:9.90e-03, fs:0.85427 (r=0.859,p=0.850),  time:77.429, tt:5032.887\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.05259, lr:9.90e-03, fs:0.84158 (r=0.859,p=0.825),  time:77.382, tt:5107.203\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.05399, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:77.289, tt:5178.330\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.05250, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:77.235, tt:5251.959\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.05322, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:77.243, tt:5329.746\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.05369, lr:9.90e-03, fs:0.84848 (r=0.848,p=0.848),  time:77.274, tt:5409.173\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.05336, lr:9.90e-03, fs:0.84000 (r=0.848,p=0.832),  time:77.292, tt:5487.761\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.05469, lr:9.90e-03, fs:0.85279 (r=0.848,p=0.857),  time:77.299, tt:5565.504\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.05352, lr:9.90e-03, fs:0.83582 (r=0.848,p=0.824),  time:77.323, tt:5644.558\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.05504, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:77.378, tt:5725.978\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.05297, lr:9.80e-03, fs:0.83582 (r=0.848,p=0.824),  time:77.350, tt:5801.234\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.05415, lr:9.80e-03, fs:0.84422 (r=0.848,p=0.840),  time:77.300, tt:5874.778\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.05333, lr:9.80e-03, fs:0.84848 (r=0.848,p=0.848),  time:77.237, tt:5947.266\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.05377, lr:9.80e-03, fs:0.84848 (r=0.848,p=0.848),  time:77.156, tt:6018.150\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.05405, lr:9.80e-03, fs:0.85279 (r=0.848,p=0.857),  time:77.195, tt:6098.397\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.05343, lr:9.80e-03, fs:0.84848 (r=0.848,p=0.848),  time:77.206, tt:6176.516\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.05341, lr:9.80e-03, fs:0.84000 (r=0.848,p=0.832),  time:77.218, tt:6254.691\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.05406, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.267, tt:6335.922\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.05316, lr:9.80e-03, fs:0.85279 (r=0.848,p=0.857),  time:77.306, tt:6416.406\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.05481, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.332, tt:6495.904\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.05337, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:77.276, tt:6568.455\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.05451, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.263, tt:6644.643\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.05374, lr:9.80e-03, fs:0.85714 (r=0.848,p=0.866),  time:77.216, tt:6717.815\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.05410, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.214, tt:6794.795\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.05548, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.238, tt:6874.202\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.05334, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:77.245, tt:6952.006\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.05429, lr:9.80e-03, fs:0.87047 (r=0.848,p=0.894),  time:77.246, tt:7029.396\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.05374, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.266, tt:7108.478\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.05506, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.312, tt:7190.008\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.05546, lr:9.80e-03, fs:0.87047 (r=0.848,p=0.894),  time:77.276, tt:7263.931\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.05421, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.243, tt:7338.062\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.05438, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.206, tt:7411.737\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.05513, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:77.152, tt:7483.740\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.05466, lr:9.80e-03, fs:0.87047 (r=0.848,p=0.894),  time:77.192, tt:7564.779\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.05494, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:77.199, tt:7642.726\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.05504, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:77.234, tt:7723.365\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.05460, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:77.247, tt:7801.940\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.05668, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:77.276, tt:7882.103\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.05549, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:77.317, tt:7963.688\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.05621, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:77.273, tt:8036.373\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.05531, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:77.217, tt:8107.760\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.05604, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:77.191, tt:8182.203\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.05677, lr:9.80e-03, fs:0.87831 (r=0.838,p=0.922),  time:77.197, tt:8260.069\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.05763, lr:9.80e-03, fs:0.88298 (r=0.838,p=0.933),  time:77.211, tt:8338.836\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.05650, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:77.235, tt:8418.593\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.05521, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:77.260, tt:8498.553\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.05703, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:77.278, tt:8577.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.05687, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:77.304, tt:8658.062\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.05749, lr:9.80e-03, fs:0.87831 (r=0.838,p=0.922),  time:77.282, tt:8732.878\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.05529, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:77.231, tt:8804.290\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.05701, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:77.181, tt:8875.781\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.05592, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:77.147, tt:8949.070\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.05602, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:77.160, tt:9027.725\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.05730, lr:9.80e-03, fs:0.87831 (r=0.838,p=0.922),  time:77.171, tt:9106.212\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.05642, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:77.166, tt:9182.803\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.05770, lr:9.80e-03, fs:0.86957 (r=0.808,p=0.941),  time:77.173, tt:9260.755\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.05705, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:77.154, tt:9335.667\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 13\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09449, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:65.529, tt:65.529\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09287, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:67.669, tt:135.339\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.09073, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:68.110, tt:204.329\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08972, lr:1.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:69.586, tt:278.344\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08723, lr:1.00e-02, fs:0.63158 (r=0.848,p=0.503),  time:71.451, tt:357.255\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.08539, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:72.590, tt:435.542\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.08246, lr:1.00e-02, fs:0.64865 (r=0.848,p=0.525),  time:73.532, tt:514.724\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00026, loss_test:0.07902, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:74.255, tt:594.039\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07639, lr:1.00e-02, fs:0.69118 (r=0.949,p=0.543),  time:74.518, tt:670.660\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07496, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:74.511, tt:745.110\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07308, lr:1.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:74.232, tt:816.556\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.07202, lr:1.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:74.188, tt:890.250\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.07036, lr:1.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:74.043, tt:962.563\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06899, lr:1.00e-02, fs:0.74104 (r=0.939,p=0.612),  time:74.305, tt:1040.270\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.06825, lr:1.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:74.672, tt:1120.087\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06726, lr:1.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:74.944, tt:1199.107\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06763, lr:1.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:75.281, tt:1279.779\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.06642, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:75.384, tt:1356.907\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06634, lr:1.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:75.438, tt:1433.318\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.06561, lr:1.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:75.217, tt:1504.334\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06477, lr:1.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:75.005, tt:1575.114\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.06473, lr:1.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:74.859, tt:1646.899\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06475, lr:1.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:74.683, tt:1717.714\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.06533, lr:1.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:74.899, tt:1797.576\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.06609, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:75.050, tt:1876.247\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.06559, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:75.216, tt:1955.622\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.06538, lr:1.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:75.398, tt:2035.737\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.06629, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:75.526, tt:2114.715\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.06608, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:75.556, tt:2191.123\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.06650, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:75.445, tt:2263.350\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.06725, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:75.325, tt:2335.066\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.06670, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:75.251, tt:2408.034\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.06691, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:75.282, tt:2484.301\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.06736, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:75.331, tt:2561.264\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.06752, lr:9.90e-03, fs:0.72195 (r=0.747,p=0.698),  time:75.423, tt:2639.807\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.06914, lr:9.80e-03, fs:0.69652 (r=0.707,p=0.686),  time:75.470, tt:2716.929\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.06639, lr:9.70e-03, fs:0.69856 (r=0.737,p=0.664),  time:75.563, tt:2795.844\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.06843, lr:9.61e-03, fs:0.70352 (r=0.707,p=0.700),  time:75.679, tt:2875.820\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.06723, lr:9.51e-03, fs:0.71220 (r=0.737,p=0.689),  time:75.650, tt:2950.336\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.06924, lr:9.41e-03, fs:0.70707 (r=0.707,p=0.707),  time:75.568, tt:3022.710\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.06687, lr:9.32e-03, fs:0.69856 (r=0.737,p=0.664),  time:75.525, tt:3096.538\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.06996, lr:9.23e-03, fs:0.72632 (r=0.697,p=0.758),  time:75.469, tt:3169.697\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.06743, lr:9.14e-03, fs:0.70647 (r=0.717,p=0.696),  time:75.575, tt:3249.704\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.07017, lr:9.04e-03, fs:0.72632 (r=0.697,p=0.758),  time:75.643, tt:3328.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.06644, lr:8.95e-03, fs:0.70647 (r=0.717,p=0.696),  time:75.695, tt:3406.294\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.07062, lr:8.86e-03, fs:0.73016 (r=0.697,p=0.767),  time:75.762, tt:3485.064\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.06622, lr:8.78e-03, fs:0.72727 (r=0.727,p=0.727),  time:75.886, tt:3566.624\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.06811, lr:8.69e-03, fs:0.71134 (r=0.697,p=0.726),  time:75.974, tt:3646.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.06722, lr:8.60e-03, fs:0.71134 (r=0.697,p=0.726),  time:75.941, tt:3721.110\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.06781, lr:8.51e-03, fs:0.71503 (r=0.697,p=0.734),  time:75.880, tt:3793.985\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.06600, lr:8.43e-03, fs:0.70769 (r=0.697,p=0.719),  time:75.815, tt:3866.541\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.06807, lr:8.35e-03, fs:0.73298 (r=0.707,p=0.761),  time:75.864, tt:3944.949\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.06544, lr:8.26e-03, fs:0.71717 (r=0.717,p=0.717),  time:75.908, tt:4023.120\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.06755, lr:8.18e-03, fs:0.71503 (r=0.697,p=0.734),  time:75.995, tt:4103.704\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.06530, lr:8.10e-03, fs:0.71066 (r=0.707,p=0.714),  time:76.109, tt:4185.987\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.06800, lr:8.02e-03, fs:0.71503 (r=0.697,p=0.734),  time:76.129, tt:4263.219\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00007, loss_test:0.06748, lr:7.94e-03, fs:0.72251 (r=0.697,p=0.750),  time:76.185, tt:4342.550\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.06664, lr:7.86e-03, fs:0.72917 (r=0.707,p=0.753),  time:76.157, tt:4417.085\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.06612, lr:7.78e-03, fs:0.71503 (r=0.697,p=0.734),  time:76.078, tt:4488.625\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.06786, lr:7.70e-03, fs:0.73016 (r=0.697,p=0.767),  time:76.017, tt:4561.012\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.06418, lr:7.62e-03, fs:0.73096 (r=0.727,p=0.735),  time:75.968, tt:4634.076\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.06906, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.037, tt:4714.279\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00006, loss_test:0.06408, lr:7.47e-03, fs:0.73196 (r=0.717,p=0.747),  time:76.085, tt:4793.353\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00006, loss_test:0.06865, lr:7.40e-03, fs:0.73913 (r=0.687,p=0.800),  time:76.145, tt:4873.280\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00006, loss_test:0.06404, lr:7.32e-03, fs:0.72539 (r=0.707,p=0.745),  time:76.205, tt:4953.300\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.06731, lr:7.25e-03, fs:0.73404 (r=0.697,p=0.775),  time:76.235, tt:5031.499\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.06494, lr:7.18e-03, fs:0.71875 (r=0.697,p=0.742),  time:76.287, tt:5111.262\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.06480, lr:7.11e-03, fs:0.73684 (r=0.707,p=0.769),  time:76.211, tt:5182.381\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.06567, lr:7.03e-03, fs:0.73016 (r=0.697,p=0.767),  time:76.166, tt:5255.464\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00005, loss_test:0.06595, lr:6.96e-03, fs:0.73016 (r=0.697,p=0.767),  time:76.137, tt:5329.587\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00005, loss_test:0.06561, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:76.136, tt:5405.634\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00005, loss_test:0.06561, lr:6.83e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.175, tt:5484.609\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00005, loss_test:0.06803, lr:6.76e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.267, tt:5567.521\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00005, loss_test:0.06625, lr:6.69e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.324, tt:5647.977\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00005, loss_test:0.06626, lr:6.62e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.348, tt:5726.075\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00005, loss_test:0.06658, lr:6.56e-03, fs:0.74194 (r=0.697,p=0.793),  time:76.384, tt:5805.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00005, loss_test:0.06485, lr:6.49e-03, fs:0.73016 (r=0.697,p=0.767),  time:76.374, tt:5880.804\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00005, loss_test:0.06703, lr:6.43e-03, fs:0.74194 (r=0.697,p=0.793),  time:76.330, tt:5953.738\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00005, loss_test:0.06538, lr:6.36e-03, fs:0.73404 (r=0.697,p=0.775),  time:76.321, tt:6029.325\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.06502, lr:6.30e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.291, tt:6103.296\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.06621, lr:6.24e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.322, tt:6182.086\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.06594, lr:6.17e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.383, tt:6263.381\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.06449, lr:6.11e-03, fs:0.75393 (r=0.727,p=0.783),  time:76.459, tt:6346.079\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00004, loss_test:0.06633, lr:6.05e-03, fs:0.74194 (r=0.697,p=0.793),  time:76.476, tt:6423.971\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00004, loss_test:0.06683, lr:5.99e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.492, tt:6501.834\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00004, loss_test:0.06684, lr:5.93e-03, fs:0.69274 (r=0.626,p=0.775),  time:76.515, tt:6580.318\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00004, loss_test:0.06662, lr:5.87e-03, fs:0.73118 (r=0.687,p=0.782),  time:76.458, tt:6651.821\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00004, loss_test:0.06556, lr:5.81e-03, fs:0.73514 (r=0.687,p=0.791),  time:76.436, tt:6726.357\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00004, loss_test:0.06685, lr:5.75e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.399, tt:6799.500\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00004, loss_test:0.06801, lr:5.70e-03, fs:0.69274 (r=0.626,p=0.775),  time:76.400, tt:6875.995\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00004, loss_test:0.06531, lr:5.64e-03, fs:0.73797 (r=0.697,p=0.784),  time:76.417, tt:6953.954\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00004, loss_test:0.06634, lr:5.58e-03, fs:0.72131 (r=0.667,p=0.786),  time:76.440, tt:7032.438\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00004, loss_test:0.06719, lr:5.53e-03, fs:0.69274 (r=0.626,p=0.775),  time:76.459, tt:7110.721\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00004, loss_test:0.06702, lr:5.47e-03, fs:0.73514 (r=0.687,p=0.791),  time:76.480, tt:7189.079\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00004, loss_test:0.06627, lr:5.42e-03, fs:0.72826 (r=0.677,p=0.788),  time:76.521, tt:7269.530\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.06635, lr:5.36e-03, fs:0.72131 (r=0.667,p=0.786),  time:76.508, tt:7344.750\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.06672, lr:5.31e-03, fs:0.67045 (r=0.596,p=0.766),  time:76.478, tt:7418.370\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.06736, lr:5.26e-03, fs:0.66286 (r=0.586,p=0.763),  time:76.454, tt:7492.540\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.06642, lr:5.20e-03, fs:0.70718 (r=0.646,p=0.780),  time:76.387, tt:7562.346\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.06703, lr:5.15e-03, fs:0.68182 (r=0.606,p=0.779),  time:76.397, tt:7639.661\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.06575, lr:5.10e-03, fs:0.74194 (r=0.697,p=0.793),  time:76.423, tt:7718.701\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00003, loss_test:0.06651, lr:5.05e-03, fs:0.67045 (r=0.596,p=0.766),  time:76.438, tt:7796.651\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00003, loss_test:0.06731, lr:5.00e-03, fs:0.67045 (r=0.596,p=0.766),  time:76.444, tt:7873.734\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00003, loss_test:0.06630, lr:4.95e-03, fs:0.66667 (r=0.586,p=0.773),  time:76.480, tt:7953.962\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00003, loss_test:0.06621, lr:4.90e-03, fs:0.72826 (r=0.677,p=0.788),  time:76.499, tt:8032.429\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00003, loss_test:0.06790, lr:4.85e-03, fs:0.66667 (r=0.586,p=0.773),  time:76.463, tt:8105.034\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00003, loss_test:0.06628, lr:4.80e-03, fs:0.66286 (r=0.586,p=0.763),  time:76.425, tt:8177.428\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00003, loss_test:0.06728, lr:4.75e-03, fs:0.68571 (r=0.606,p=0.789),  time:76.413, tt:8252.562\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00003, loss_test:0.06675, lr:4.71e-03, fs:0.67816 (r=0.596,p=0.787),  time:76.392, tt:8326.770\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00003, loss_test:0.06605, lr:4.66e-03, fs:0.72527 (r=0.667,p=0.795),  time:76.410, tt:8405.117\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00003, loss_test:0.06798, lr:4.61e-03, fs:0.66667 (r=0.576,p=0.792),  time:76.458, tt:8486.793\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00003, loss_test:0.06689, lr:4.57e-03, fs:0.67052 (r=0.586,p=0.784),  time:76.464, tt:8563.933\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00003, loss_test:0.06668, lr:4.52e-03, fs:0.67052 (r=0.586,p=0.784),  time:76.471, tt:8641.232\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00003, loss_test:0.06808, lr:4.48e-03, fs:0.66667 (r=0.576,p=0.792),  time:76.482, tt:8718.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00003, loss_test:0.06682, lr:4.43e-03, fs:0.66667 (r=0.586,p=0.773),  time:76.466, tt:8793.601\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00003, loss_test:0.06764, lr:4.39e-03, fs:0.66667 (r=0.576,p=0.792),  time:76.415, tt:8864.100\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00003, loss_test:0.06790, lr:4.34e-03, fs:0.67456 (r=0.576,p=0.814),  time:76.388, tt:8937.399\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00003, loss_test:0.06704, lr:4.30e-03, fs:0.66667 (r=0.576,p=0.792),  time:76.364, tt:9010.970\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00003, loss_test:0.06837, lr:4.26e-03, fs:0.67456 (r=0.576,p=0.814),  time:76.369, tt:9087.934\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00003, loss_test:0.06729, lr:4.21e-03, fs:0.67442 (r=0.586,p=0.795),  time:76.381, tt:9165.736\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00003, loss_test:0.06811, lr:4.17e-03, fs:0.67456 (r=0.576,p=0.814),  time:76.337, tt:9236.775\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 14\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09586, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:65.408, tt:65.408\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09349, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:71.751, tt:143.502\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08976, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:72.094, tt:216.281\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00033, loss_test:0.08606, lr:1.00e-02, fs:0.61961 (r=0.798,p=0.506),  time:71.337, tt:285.347\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08366, lr:1.00e-02, fs:0.64615 (r=0.848,p=0.522),  time:71.135, tt:355.674\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.08113, lr:1.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:70.697, tt:424.181\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.07867, lr:1.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:70.156, tt:491.090\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.07571, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:70.488, tt:563.908\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07274, lr:1.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:70.537, tt:634.833\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07173, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:70.367, tt:703.675\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.06981, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:70.214, tt:772.350\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06833, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:70.167, tt:841.999\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.06841, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:70.241, tt:913.137\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06659, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:70.276, tt:983.862\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.06660, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:70.180, tt:1052.693\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06549, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:70.149, tt:1122.378\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06576, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:70.003, tt:1190.053\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.06446, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:70.054, tt:1260.965\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06415, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:70.036, tt:1330.692\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.06350, lr:1.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:69.980, tt:1399.598\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06289, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:69.873, tt:1467.341\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.06318, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:69.834, tt:1536.340\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06234, lr:1.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:69.784, tt:1605.024\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.06252, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:69.772, tt:1674.529\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.06171, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:69.669, tt:1741.728\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.06177, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:69.752, tt:1813.559\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.06181, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:69.728, tt:1882.646\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.06103, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:69.768, tt:1953.492\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.06141, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:69.742, tt:2022.508\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.06140, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:69.707, tt:2091.215\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.06082, lr:9.90e-03, fs:0.75229 (r=0.828,p=0.689),  time:69.788, tt:2163.430\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.06138, lr:9.80e-03, fs:0.73585 (r=0.788,p=0.690),  time:69.829, tt:2234.535\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.06085, lr:9.70e-03, fs:0.74178 (r=0.798,p=0.693),  time:69.894, tt:2306.507\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.06164, lr:9.61e-03, fs:0.73585 (r=0.788,p=0.690),  time:69.923, tt:2377.387\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.06128, lr:9.51e-03, fs:0.73934 (r=0.788,p=0.696),  time:69.889, tt:2446.110\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.06102, lr:9.41e-03, fs:0.73585 (r=0.788,p=0.690),  time:69.952, tt:2518.289\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.06132, lr:9.32e-03, fs:0.72986 (r=0.778,p=0.688),  time:69.961, tt:2588.555\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.06126, lr:9.23e-03, fs:0.73684 (r=0.778,p=0.700),  time:69.933, tt:2657.439\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.06150, lr:9.14e-03, fs:0.73333 (r=0.778,p=0.694),  time:69.969, tt:2728.806\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.06164, lr:9.04e-03, fs:0.73077 (r=0.768,p=0.697),  time:69.953, tt:2798.122\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.06161, lr:8.95e-03, fs:0.74286 (r=0.788,p=0.703),  time:69.968, tt:2868.704\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.06202, lr:8.86e-03, fs:0.73786 (r=0.768,p=0.710),  time:69.979, tt:2939.127\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.06179, lr:8.78e-03, fs:0.73684 (r=0.778,p=0.700),  time:70.069, tt:3012.946\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.06192, lr:8.69e-03, fs:0.74286 (r=0.788,p=0.703),  time:70.123, tt:3085.392\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.06260, lr:8.60e-03, fs:0.75248 (r=0.768,p=0.738),  time:70.098, tt:3154.397\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.06227, lr:8.51e-03, fs:0.74396 (r=0.778,p=0.713),  time:70.138, tt:3226.327\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.06385, lr:8.43e-03, fs:0.75862 (r=0.778,p=0.740),  time:70.168, tt:3297.880\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.06291, lr:8.35e-03, fs:0.74757 (r=0.778,p=0.720),  time:70.120, tt:3365.759\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.06302, lr:8.26e-03, fs:0.75862 (r=0.778,p=0.740),  time:70.140, tt:3436.854\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.06262, lr:8.18e-03, fs:0.77228 (r=0.788,p=0.757),  time:70.109, tt:3505.445\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.06331, lr:8.18e-03, fs:0.77000 (r=0.778,p=0.762),  time:70.147, tt:3577.501\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00007, loss_test:0.06287, lr:8.18e-03, fs:0.76238 (r=0.778,p=0.748),  time:70.165, tt:3648.582\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.06335, lr:8.18e-03, fs:0.76382 (r=0.768,p=0.760),  time:70.187, tt:3719.886\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.06347, lr:8.18e-03, fs:0.76847 (r=0.788,p=0.750),  time:70.203, tt:3790.957\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.06306, lr:8.18e-03, fs:0.76238 (r=0.778,p=0.748),  time:70.208, tt:3861.461\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.06430, lr:8.18e-03, fs:0.76531 (r=0.758,p=0.773),  time:70.196, tt:3930.952\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.06492, lr:8.18e-03, fs:0.78788 (r=0.788,p=0.788),  time:70.201, tt:4001.431\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.06412, lr:8.18e-03, fs:0.74257 (r=0.758,p=0.728),  time:70.228, tt:4073.208\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.06458, lr:8.18e-03, fs:0.78392 (r=0.788,p=0.780),  time:70.202, tt:4141.912\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.06425, lr:8.18e-03, fs:0.77000 (r=0.778,p=0.762),  time:70.212, tt:4212.721\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.06477, lr:8.18e-03, fs:0.77000 (r=0.778,p=0.762),  time:70.221, tt:4283.508\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.06477, lr:8.18e-03, fs:0.78392 (r=0.788,p=0.780),  time:70.216, tt:4353.390\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.06463, lr:8.18e-03, fs:0.75758 (r=0.758,p=0.758),  time:70.255, tt:4426.034\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.06435, lr:8.18e-03, fs:0.77612 (r=0.788,p=0.765),  time:70.265, tt:4496.988\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.06451, lr:8.18e-03, fs:0.77612 (r=0.788,p=0.765),  time:70.276, tt:4567.959\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.06511, lr:8.18e-03, fs:0.75510 (r=0.747,p=0.763),  time:70.273, tt:4637.990\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.06488, lr:8.18e-03, fs:0.77551 (r=0.768,p=0.784),  time:70.236, tt:4705.781\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.06475, lr:8.18e-03, fs:0.77778 (r=0.778,p=0.778),  time:70.233, tt:4775.816\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.06431, lr:8.10e-03, fs:0.76142 (r=0.758,p=0.765),  time:70.256, tt:4847.671\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0307a213a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,121,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 70\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:0, loss:0.00062, loss_test:0.09139, lr:1.00e-02, fs:0.63004 (r=0.869,p=0.494),  time:36.576, tt:36.576\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:1, loss:0.00044, loss_test:0.10324, lr:1.00e-02, fs:0.60177 (r=0.687,p=0.535),  time:36.724, tt:73.449\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:2, loss:0.00039, loss_test:0.09467, lr:1.00e-02, fs:0.62979 (r=0.747,p=0.544),  time:36.951, tt:110.852\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:3, loss:0.00036, loss_test:0.09015, lr:1.00e-02, fs:0.63478 (r=0.737,p=0.557),  time:36.835, tt:147.341\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:4, loss:0.00034, loss_test:0.08775, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:37.007, tt:185.037\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:5, loss:0.00031, loss_test:0.08534, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:37.075, tt:222.450\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:6, loss:0.00029, loss_test:0.08241, lr:1.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:37.273, tt:260.911\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:7, loss:0.00028, loss_test:0.08655, lr:1.00e-02, fs:0.66990 (r=0.697,p=0.645),  time:38.501, tt:308.006\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:8, loss:0.00026, loss_test:0.08243, lr:1.00e-02, fs:0.65094 (r=0.697,p=0.611),  time:40.334, tt:363.010\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:9, loss:0.00025, loss_test:0.07964, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:41.865, tt:418.650\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:10, loss:0.00025, loss_test:0.08638, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:43.668, tt:480.349\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:11, loss:0.00023, loss_test:0.07828, lr:1.00e-02, fs:0.66667 (r=0.727,p=0.615),  time:44.749, tt:536.988\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:12, loss:0.00022, loss_test:0.07974, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:45.753, tt:594.791\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:13, loss:0.00020, loss_test:0.08017, lr:1.00e-02, fs:0.67662 (r=0.687,p=0.667),  time:46.745, tt:654.425\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:14, loss:0.00019, loss_test:0.07920, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:47.578, tt:713.665\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:15, loss:0.00018, loss_test:0.07784, lr:1.00e-02, fs:0.66038 (r=0.707,p=0.619),  time:48.335, tt:773.363\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:16, loss:0.00017, loss_test:0.07948, lr:1.00e-02, fs:0.69149 (r=0.657,p=0.730),  time:49.119, tt:835.026\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:17, loss:0.00017, loss_test:0.08019, lr:1.00e-02, fs:0.68783 (r=0.657,p=0.722),  time:49.635, tt:893.435\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:18, loss:0.00017, loss_test:0.07676, lr:1.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:49.878, tt:947.679\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:19, loss:0.00017, loss_test:0.08654, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:50.322, tt:1006.435\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:20, loss:0.00016, loss_test:0.07452, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:50.814, tt:1067.095\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:21, loss:0.00014, loss_test:0.07594, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:51.005, tt:1122.106\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:22, loss:0.00013, loss_test:0.07710, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:51.297, tt:1179.833\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:23, loss:0.00012, loss_test:0.07601, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:51.475, tt:1235.410\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:24, loss:0.00011, loss_test:0.07509, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:51.670, tt:1291.754\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:25, loss:0.00011, loss_test:0.07620, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:51.947, tt:1350.629\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:26, loss:0.00010, loss_test:0.07598, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:52.331, tt:1412.924\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:27, loss:0.00010, loss_test:0.07453, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:52.546, tt:1471.287\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:28, loss:0.00009, loss_test:0.07496, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:52.653, tt:1526.937\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:29, loss:0.00009, loss_test:0.07564, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:52.800, tt:1584.001\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:30, loss:0.00009, loss_test:0.07658, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:52.881, tt:1639.309\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:31, loss:0.00009, loss_test:0.07342, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:52.992, tt:1695.745\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:32, loss:0.00008, loss_test:0.07512, lr:9.90e-03, fs:0.72632 (r=0.697,p=0.758),  time:53.097, tt:1752.196\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:33, loss:0.00008, loss_test:0.07489, lr:9.80e-03, fs:0.70707 (r=0.707,p=0.707),  time:53.170, tt:1807.790\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:34, loss:0.00008, loss_test:0.07473, lr:9.70e-03, fs:0.69347 (r=0.697,p=0.690),  time:53.212, tt:1862.416\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:35, loss:0.00008, loss_test:0.07557, lr:9.61e-03, fs:0.73016 (r=0.697,p=0.767),  time:53.272, tt:1917.790\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:36, loss:0.00008, loss_test:0.07491, lr:9.51e-03, fs:0.70244 (r=0.727,p=0.679),  time:53.360, tt:1974.302\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:37, loss:0.00007, loss_test:0.07613, lr:9.41e-03, fs:0.72340 (r=0.687,p=0.764),  time:53.445, tt:2030.893\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:38, loss:0.00007, loss_test:0.07314, lr:9.32e-03, fs:0.72381 (r=0.768,p=0.685),  time:53.572, tt:2089.296\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:39, loss:0.00007, loss_test:0.07654, lr:9.23e-03, fs:0.71875 (r=0.697,p=0.742),  time:53.710, tt:2148.381\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:40, loss:0.00006, loss_test:0.07296, lr:9.14e-03, fs:0.70874 (r=0.737,p=0.682),  time:53.833, tt:2207.145\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:41, loss:0.00006, loss_test:0.07447, lr:9.04e-03, fs:0.71875 (r=0.697,p=0.742),  time:54.046, tt:2269.920\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:42, loss:0.00006, loss_test:0.07510, lr:8.95e-03, fs:0.70051 (r=0.697,p=0.704),  time:54.157, tt:2328.733\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:43, loss:0.00006, loss_test:0.07360, lr:8.86e-03, fs:0.70051 (r=0.697,p=0.704),  time:54.223, tt:2385.794\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:44, loss:0.00006, loss_test:0.07266, lr:8.78e-03, fs:0.69697 (r=0.697,p=0.697),  time:54.322, tt:2444.479\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:45, loss:0.00005, loss_test:0.07461, lr:8.69e-03, fs:0.71875 (r=0.697,p=0.742),  time:54.376, tt:2501.278\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:46, loss:0.00005, loss_test:0.07502, lr:8.60e-03, fs:0.71134 (r=0.697,p=0.726),  time:54.450, tt:2559.173\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:47, loss:0.00005, loss_test:0.07412, lr:8.51e-03, fs:0.70769 (r=0.697,p=0.719),  time:54.486, tt:2615.338\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:48, loss:0.00005, loss_test:0.07299, lr:8.43e-03, fs:0.70769 (r=0.697,p=0.719),  time:54.548, tt:2672.846\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:49, loss:0.00005, loss_test:0.07441, lr:8.35e-03, fs:0.70408 (r=0.697,p=0.711),  time:54.653, tt:2732.670\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:50, loss:0.00005, loss_test:0.07460, lr:8.26e-03, fs:0.71875 (r=0.697,p=0.742),  time:54.747, tt:2792.092\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:51, loss:0.00005, loss_test:0.07284, lr:8.18e-03, fs:0.70769 (r=0.697,p=0.719),  time:54.806, tt:2849.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:52, loss:0.00005, loss_test:0.07382, lr:8.10e-03, fs:0.72251 (r=0.697,p=0.750),  time:54.840, tt:2906.543\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:53, loss:0.00005, loss_test:0.07405, lr:8.02e-03, fs:0.71503 (r=0.697,p=0.734),  time:54.905, tt:2964.862\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:54, loss:0.00005, loss_test:0.07333, lr:7.94e-03, fs:0.71503 (r=0.697,p=0.734),  time:55.147, tt:3033.109\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:55, loss:0.00005, loss_test:0.07505, lr:7.86e-03, fs:0.72251 (r=0.697,p=0.750),  time:55.765, tt:3122.848\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:56, loss:0.00004, loss_test:0.07307, lr:7.78e-03, fs:0.70408 (r=0.697,p=0.711),  time:56.324, tt:3210.471\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:57, loss:0.00004, loss_test:0.07457, lr:7.70e-03, fs:0.72632 (r=0.697,p=0.758),  time:56.863, tt:3298.061\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:58, loss:0.00004, loss_test:0.07408, lr:7.62e-03, fs:0.71875 (r=0.697,p=0.742),  time:57.442, tt:3389.073\n",
      "1080\n",
      "1062\n",
      "1044\n",
      "1026\n",
      "1050\n",
      "66\n",
      "Ep:59, loss:0.00004, loss_test:0.07350, lr:7.55e-03, fs:0.71503 (r=0.697,p=0.734),  time:57.947, tt:3476.831\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"71-71\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 70\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:0, loss:0.00063, loss_test:0.09305, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:67.154, tt:67.154\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:1, loss:0.00058, loss_test:0.08893, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:74.445, tt:148.890\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:2, loss:0.00054, loss_test:0.08837, lr:1.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:77.596, tt:232.787\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:3, loss:0.00050, loss_test:0.08732, lr:1.00e-02, fs:0.62698 (r=0.798,p=0.516),  time:79.516, tt:318.063\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:4, loss:0.00045, loss_test:0.08557, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:80.823, tt:404.117\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:5, loss:0.00042, loss_test:0.08420, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:82.114, tt:492.682\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:6, loss:0.00039, loss_test:0.08454, lr:1.00e-02, fs:0.61728 (r=0.758,p=0.521),  time:85.945, tt:601.612\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:7, loss:0.00037, loss_test:0.08408, lr:1.00e-02, fs:0.62185 (r=0.747,p=0.532),  time:90.594, tt:724.749\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:8, loss:0.00034, loss_test:0.08365, lr:1.00e-02, fs:0.62661 (r=0.737,p=0.545),  time:93.879, tt:844.909\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:9, loss:0.00033, loss_test:0.08245, lr:1.00e-02, fs:0.62979 (r=0.747,p=0.544),  time:96.527, tt:965.272\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:10, loss:0.00031, loss_test:0.08328, lr:1.00e-02, fs:0.63755 (r=0.737,p=0.562),  time:97.771, tt:1075.476\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:11, loss:0.00029, loss_test:0.08249, lr:1.00e-02, fs:0.63478 (r=0.737,p=0.557),  time:98.088, tt:1177.059\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:12, loss:0.00029, loss_test:0.08310, lr:9.90e-03, fs:0.66359 (r=0.727,p=0.610),  time:97.460, tt:1266.982\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:13, loss:0.00027, loss_test:0.08393, lr:9.90e-03, fs:0.67290 (r=0.727,p=0.626),  time:98.985, tt:1385.792\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:14, loss:0.00025, loss_test:0.08242, lr:9.90e-03, fs:0.64865 (r=0.727,p=0.585),  time:100.639, tt:1509.579\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:15, loss:0.00024, loss_test:0.08345, lr:9.90e-03, fs:0.66355 (r=0.717,p=0.617),  time:101.347, tt:1621.550\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:16, loss:0.00022, loss_test:0.08439, lr:9.90e-03, fs:0.66667 (r=0.707,p=0.631),  time:101.552, tt:1726.385\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:17, loss:0.00021, loss_test:0.08314, lr:9.90e-03, fs:0.67299 (r=0.717,p=0.634),  time:101.935, tt:1834.826\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:18, loss:0.00020, loss_test:0.08425, lr:9.90e-03, fs:0.67619 (r=0.717,p=0.640),  time:102.178, tt:1941.391\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:19, loss:0.00019, loss_test:0.08449, lr:9.90e-03, fs:0.68246 (r=0.727,p=0.643),  time:102.230, tt:2044.594\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:20, loss:0.00018, loss_test:0.08350, lr:9.90e-03, fs:0.68932 (r=0.717,p=0.664),  time:102.455, tt:2151.563\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:21, loss:0.00017, loss_test:0.08667, lr:9.90e-03, fs:0.68342 (r=0.687,p=0.680),  time:102.704, tt:2259.491\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:22, loss:0.00016, loss_test:0.08376, lr:9.90e-03, fs:0.68342 (r=0.687,p=0.680),  time:102.873, tt:2366.078\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:23, loss:0.00015, loss_test:0.08681, lr:9.90e-03, fs:0.68687 (r=0.687,p=0.687),  time:103.047, tt:2473.123\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:24, loss:0.00015, loss_test:0.08700, lr:9.90e-03, fs:0.68687 (r=0.687,p=0.687),  time:103.196, tt:2579.894\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:25, loss:0.00014, loss_test:0.08959, lr:9.90e-03, fs:0.70213 (r=0.667,p=0.742),  time:103.318, tt:2686.262\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:26, loss:0.00013, loss_test:0.08813, lr:9.90e-03, fs:0.70466 (r=0.687,p=0.723),  time:103.463, tt:2793.502\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:27, loss:0.00013, loss_test:0.08327, lr:9.90e-03, fs:0.70297 (r=0.717,p=0.689),  time:103.508, tt:2898.236\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:28, loss:0.00013, loss_test:0.08702, lr:9.90e-03, fs:0.71498 (r=0.747,p=0.685),  time:103.718, tt:3007.826\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:29, loss:0.00013, loss_test:0.08460, lr:9.90e-03, fs:0.71287 (r=0.727,p=0.699),  time:103.898, tt:3116.939\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:30, loss:0.00012, loss_test:0.08617, lr:9.90e-03, fs:0.70833 (r=0.687,p=0.731),  time:104.121, tt:3227.738\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:31, loss:0.00011, loss_test:0.09051, lr:9.90e-03, fs:0.68852 (r=0.636,p=0.750),  time:104.176, tt:3333.645\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:32, loss:0.00010, loss_test:0.08952, lr:9.90e-03, fs:0.69565 (r=0.646,p=0.753),  time:104.317, tt:3442.468\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:33, loss:0.00009, loss_test:0.08751, lr:9.90e-03, fs:0.69945 (r=0.646,p=0.762),  time:104.601, tt:3556.437\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:34, loss:0.00009, loss_test:0.09094, lr:9.90e-03, fs:0.70330 (r=0.646,p=0.771),  time:102.852, tt:3599.803\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:35, loss:0.00009, loss_test:0.08778, lr:9.90e-03, fs:0.69430 (r=0.677,p=0.713),  time:101.200, tt:3643.191\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:36, loss:0.00008, loss_test:0.08592, lr:9.90e-03, fs:0.70103 (r=0.687,p=0.716),  time:99.639, tt:3686.637\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:37, loss:0.00008, loss_test:0.08629, lr:9.90e-03, fs:0.69841 (r=0.667,p=0.733),  time:98.139, tt:3729.268\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:38, loss:0.00008, loss_test:0.08794, lr:9.90e-03, fs:0.71658 (r=0.677,p=0.761),  time:96.723, tt:3772.195\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:39, loss:0.00008, loss_test:0.09134, lr:9.90e-03, fs:0.70391 (r=0.636,p=0.787),  time:95.452, tt:3818.089\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:40, loss:0.00007, loss_test:0.09056, lr:9.90e-03, fs:0.70000 (r=0.636,p=0.778),  time:94.177, tt:3861.251\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:41, loss:0.00007, loss_test:0.09340, lr:9.90e-03, fs:0.71264 (r=0.626,p=0.827),  time:92.962, tt:3904.399\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:42, loss:0.00006, loss_test:0.09037, lr:9.90e-03, fs:0.70455 (r=0.626,p=0.805),  time:91.802, tt:3947.470\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:43, loss:0.00006, loss_test:0.09414, lr:9.90e-03, fs:0.71264 (r=0.626,p=0.827),  time:90.707, tt:3991.102\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:44, loss:0.00006, loss_test:0.09185, lr:9.90e-03, fs:0.70455 (r=0.626,p=0.805),  time:89.651, tt:4034.273\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:45, loss:0.00006, loss_test:0.09230, lr:9.90e-03, fs:0.70455 (r=0.626,p=0.805),  time:88.647, tt:4077.748\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:46, loss:0.00006, loss_test:0.09164, lr:9.90e-03, fs:0.70056 (r=0.626,p=0.795),  time:87.691, tt:4121.468\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:47, loss:0.00006, loss_test:0.09075, lr:9.90e-03, fs:0.68889 (r=0.626,p=0.765),  time:86.750, tt:4163.986\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:48, loss:0.00006, loss_test:0.09319, lr:9.90e-03, fs:0.69274 (r=0.626,p=0.775),  time:85.856, tt:4206.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:49, loss:0.00005, loss_test:0.09206, lr:9.90e-03, fs:0.70857 (r=0.626,p=0.816),  time:85.009, tt:4250.458\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:50, loss:0.00005, loss_test:0.09246, lr:9.80e-03, fs:0.70455 (r=0.626,p=0.805),  time:84.182, tt:4293.273\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:51, loss:0.00005, loss_test:0.09518, lr:9.70e-03, fs:0.71676 (r=0.626,p=0.838),  time:83.419, tt:4337.785\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:52, loss:0.00005, loss_test:0.09695, lr:9.70e-03, fs:0.72093 (r=0.626,p=0.849),  time:82.679, tt:4381.982\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:53, loss:0.00005, loss_test:0.10037, lr:9.70e-03, fs:0.72941 (r=0.626,p=0.873),  time:81.968, tt:4426.290\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:54, loss:0.00004, loss_test:0.09859, lr:9.70e-03, fs:0.72093 (r=0.626,p=0.849),  time:81.321, tt:4472.673\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:55, loss:0.00004, loss_test:0.09806, lr:9.70e-03, fs:0.72093 (r=0.626,p=0.849),  time:80.679, tt:4518.032\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:56, loss:0.00004, loss_test:0.09810, lr:9.70e-03, fs:0.71264 (r=0.626,p=0.827),  time:80.037, tt:4562.115\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:57, loss:0.00004, loss_test:0.09675, lr:9.70e-03, fs:0.71676 (r=0.626,p=0.838),  time:79.411, tt:4605.810\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:58, loss:0.00004, loss_test:0.09498, lr:9.70e-03, fs:0.70857 (r=0.626,p=0.816),  time:78.820, tt:4650.372\n",
      "1104\n",
      "1032\n",
      "1072\n",
      "1040\n",
      "1072\n",
      "1024\n",
      "760\n",
      "Ep:59, loss:0.00004, loss_test:0.09904, lr:9.70e-03, fs:0.71264 (r=0.626,p=0.827),  time:78.236, tt:4694.160\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"71-71\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 70\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:0, loss:0.00036, loss_test:0.09485, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.090, tt:25.090\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:1, loss:0.00035, loss_test:0.09169, lr:1.00e-02, fs:0.65068 (r=0.960,p=0.492),  time:25.977, tt:51.955\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:2, loss:0.00032, loss_test:0.09094, lr:1.00e-02, fs:0.62451 (r=0.798,p=0.513),  time:26.846, tt:80.539\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:3, loss:0.00031, loss_test:0.09238, lr:1.00e-02, fs:0.61345 (r=0.737,p=0.525),  time:27.026, tt:108.105\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:4, loss:0.00029, loss_test:0.08752, lr:1.00e-02, fs:0.62454 (r=0.848,p=0.494),  time:27.642, tt:138.211\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:5, loss:0.00028, loss_test:0.08508, lr:1.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:27.830, tt:166.980\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:6, loss:0.00027, loss_test:0.08394, lr:1.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:29.120, tt:203.843\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:7, loss:0.00025, loss_test:0.08061, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:30.815, tt:246.519\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:8, loss:0.00024, loss_test:0.07889, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:32.284, tt:290.558\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:9, loss:0.00023, loss_test:0.07833, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:33.817, tt:338.174\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:10, loss:0.00022, loss_test:0.07748, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:35.322, tt:388.540\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:11, loss:0.00022, loss_test:0.07783, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:36.558, tt:438.695\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:12, loss:0.00021, loss_test:0.07749, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:37.561, tt:488.291\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:13, loss:0.00020, loss_test:0.07756, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:37.855, tt:529.968\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:14, loss:0.00019, loss_test:0.07664, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:38.148, tt:572.227\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:15, loss:0.00019, loss_test:0.07663, lr:1.00e-02, fs:0.66667 (r=0.818,p=0.562),  time:38.383, tt:614.133\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:16, loss:0.00019, loss_test:0.07641, lr:1.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:38.771, tt:659.112\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:17, loss:0.00018, loss_test:0.07526, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:39.428, tt:709.698\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:18, loss:0.00017, loss_test:0.07551, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:39.809, tt:756.373\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:19, loss:0.00017, loss_test:0.07497, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:40.363, tt:807.258\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:20, loss:0.00017, loss_test:0.07467, lr:1.00e-02, fs:0.64655 (r=0.758,p=0.564),  time:40.837, tt:857.577\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:21, loss:0.00016, loss_test:0.07501, lr:1.00e-02, fs:0.65789 (r=0.758,p=0.581),  time:40.969, tt:901.327\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:22, loss:0.00015, loss_test:0.07473, lr:1.00e-02, fs:0.64979 (r=0.778,p=0.558),  time:41.089, tt:945.048\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:23, loss:0.00015, loss_test:0.07526, lr:9.90e-03, fs:0.65728 (r=0.707,p=0.614),  time:41.097, tt:986.327\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:24, loss:0.00014, loss_test:0.07353, lr:9.80e-03, fs:0.64407 (r=0.768,p=0.555),  time:41.249, tt:1031.234\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:25, loss:0.00014, loss_test:0.07495, lr:9.70e-03, fs:0.67633 (r=0.707,p=0.648),  time:41.520, tt:1079.513\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:26, loss:0.00014, loss_test:0.07307, lr:9.61e-03, fs:0.65254 (r=0.778,p=0.562),  time:41.834, tt:1129.528\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:27, loss:0.00013, loss_test:0.07480, lr:9.51e-03, fs:0.68293 (r=0.707,p=0.660),  time:42.031, tt:1176.870\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:28, loss:0.00013, loss_test:0.07286, lr:9.41e-03, fs:0.66087 (r=0.768,p=0.580),  time:42.303, tt:1226.792\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:29, loss:0.00013, loss_test:0.07332, lr:9.32e-03, fs:0.67308 (r=0.707,p=0.642),  time:42.238, tt:1267.133\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:30, loss:0.00012, loss_test:0.07364, lr:9.23e-03, fs:0.68161 (r=0.768,p=0.613),  time:42.243, tt:1309.536\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:31, loss:0.00012, loss_test:0.07284, lr:9.14e-03, fs:0.66986 (r=0.707,p=0.636),  time:42.238, tt:1351.628\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:32, loss:0.00011, loss_test:0.07440, lr:9.04e-03, fs:0.69091 (r=0.768,p=0.628),  time:42.271, tt:1394.940\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:33, loss:0.00011, loss_test:0.07218, lr:8.95e-03, fs:0.66986 (r=0.707,p=0.636),  time:42.573, tt:1447.474\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:34, loss:0.00011, loss_test:0.07446, lr:8.86e-03, fs:0.68778 (r=0.768,p=0.623),  time:42.766, tt:1496.802\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:35, loss:0.00011, loss_test:0.07318, lr:8.78e-03, fs:0.68627 (r=0.707,p=0.667),  time:43.068, tt:1550.449\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:36, loss:0.00011, loss_test:0.07391, lr:8.69e-03, fs:0.70588 (r=0.788,p=0.639),  time:43.134, tt:1595.960\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:37, loss:0.00010, loss_test:0.07258, lr:8.69e-03, fs:0.67633 (r=0.707,p=0.648),  time:43.153, tt:1639.827\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:38, loss:0.00010, loss_test:0.07534, lr:8.69e-03, fs:0.70370 (r=0.768,p=0.650),  time:43.252, tt:1686.834\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:39, loss:0.00010, loss_test:0.07227, lr:8.69e-03, fs:0.67647 (r=0.697,p=0.657),  time:43.188, tt:1727.517\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:40, loss:0.00009, loss_test:0.07452, lr:8.69e-03, fs:0.71233 (r=0.788,p=0.650),  time:43.312, tt:1775.808\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:41, loss:0.00009, loss_test:0.07184, lr:8.69e-03, fs:0.67317 (r=0.697,p=0.651),  time:43.325, tt:1819.646\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:42, loss:0.00009, loss_test:0.07475, lr:8.69e-03, fs:0.70698 (r=0.768,p=0.655),  time:43.396, tt:1866.021\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:43, loss:0.00009, loss_test:0.07309, lr:8.69e-03, fs:0.68293 (r=0.707,p=0.660),  time:43.524, tt:1915.042\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:44, loss:0.00008, loss_test:0.07450, lr:8.69e-03, fs:0.70813 (r=0.747,p=0.673),  time:43.524, tt:1958.584\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:45, loss:0.00008, loss_test:0.07430, lr:8.69e-03, fs:0.67980 (r=0.697,p=0.663),  time:43.461, tt:1999.205\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:46, loss:0.00008, loss_test:0.07356, lr:8.69e-03, fs:0.69524 (r=0.737,p=0.658),  time:43.486, tt:2043.835\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:47, loss:0.00008, loss_test:0.07476, lr:8.69e-03, fs:0.69697 (r=0.697,p=0.697),  time:43.709, tt:2098.054\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:48, loss:0.00008, loss_test:0.07409, lr:8.69e-03, fs:0.70755 (r=0.758,p=0.664),  time:44.283, tt:2169.852\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:49, loss:0.00008, loss_test:0.07448, lr:8.69e-03, fs:0.69000 (r=0.697,p=0.683),  time:44.926, tt:2246.324\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:50, loss:0.00007, loss_test:0.07410, lr:8.69e-03, fs:0.69856 (r=0.737,p=0.664),  time:45.436, tt:2317.219\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:51, loss:0.00007, loss_test:0.07418, lr:8.69e-03, fs:0.69697 (r=0.697,p=0.697),  time:45.935, tt:2388.630\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:52, loss:0.00007, loss_test:0.07468, lr:8.60e-03, fs:0.71770 (r=0.758,p=0.682),  time:46.311, tt:2454.503\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:53, loss:0.00007, loss_test:0.07601, lr:8.60e-03, fs:0.71134 (r=0.697,p=0.726),  time:46.686, tt:2521.063\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:54, loss:0.00007, loss_test:0.07414, lr:8.60e-03, fs:0.70874 (r=0.737,p=0.682),  time:47.034, tt:2586.889\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:55, loss:0.00007, loss_test:0.07527, lr:8.60e-03, fs:0.70769 (r=0.697,p=0.719),  time:47.329, tt:2650.444\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:56, loss:0.00007, loss_test:0.07508, lr:8.60e-03, fs:0.71569 (r=0.737,p=0.695),  time:47.735, tt:2720.880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:57, loss:0.00006, loss_test:0.07387, lr:8.60e-03, fs:0.69347 (r=0.697,p=0.690),  time:48.135, tt:2791.819\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:58, loss:0.00006, loss_test:0.07572, lr:8.60e-03, fs:0.71429 (r=0.707,p=0.722),  time:48.498, tt:2861.410\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:59, loss:0.00006, loss_test:0.07488, lr:8.60e-03, fs:0.70707 (r=0.707,p=0.707),  time:48.620, tt:2917.221\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:60, loss:0.00006, loss_test:0.07510, lr:8.60e-03, fs:0.71429 (r=0.707,p=0.722),  time:48.537, tt:2960.752\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:61, loss:0.00006, loss_test:0.07483, lr:8.60e-03, fs:0.71503 (r=0.697,p=0.734),  time:48.419, tt:3002.009\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:62, loss:0.00006, loss_test:0.07649, lr:8.60e-03, fs:0.72917 (r=0.707,p=0.753),  time:48.250, tt:3039.762\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:63, loss:0.00006, loss_test:0.07494, lr:8.60e-03, fs:0.71795 (r=0.707,p=0.729),  time:48.127, tt:3080.121\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:64, loss:0.00005, loss_test:0.07804, lr:8.60e-03, fs:0.72917 (r=0.707,p=0.753),  time:48.039, tt:3122.549\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:65, loss:0.00005, loss_test:0.07475, lr:8.60e-03, fs:0.72165 (r=0.707,p=0.737),  time:48.064, tt:3172.203\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:66, loss:0.00005, loss_test:0.07772, lr:8.60e-03, fs:0.72917 (r=0.707,p=0.753),  time:48.041, tt:3218.753\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:67, loss:0.00005, loss_test:0.07436, lr:8.60e-03, fs:0.71795 (r=0.707,p=0.729),  time:48.031, tt:3266.140\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:68, loss:0.00005, loss_test:0.07812, lr:8.60e-03, fs:0.73404 (r=0.697,p=0.775),  time:48.003, tt:3312.199\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:69, loss:0.00005, loss_test:0.07467, lr:8.60e-03, fs:0.71795 (r=0.707,p=0.729),  time:47.884, tt:3351.877\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:70, loss:0.00005, loss_test:0.08005, lr:8.60e-03, fs:0.74595 (r=0.697,p=0.802),  time:47.758, tt:3390.813\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:71, loss:0.00005, loss_test:0.07539, lr:8.60e-03, fs:0.73367 (r=0.737,p=0.730),  time:47.689, tt:3433.601\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:72, loss:0.00005, loss_test:0.07875, lr:8.60e-03, fs:0.74194 (r=0.697,p=0.793),  time:47.656, tt:3478.899\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:73, loss:0.00005, loss_test:0.07890, lr:8.60e-03, fs:0.72917 (r=0.707,p=0.753),  time:47.637, tt:3525.155\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:74, loss:0.00005, loss_test:0.07483, lr:8.60e-03, fs:0.73016 (r=0.697,p=0.767),  time:47.619, tt:3571.438\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:75, loss:0.00005, loss_test:0.07951, lr:8.60e-03, fs:0.72917 (r=0.707,p=0.753),  time:47.594, tt:3617.165\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:76, loss:0.00005, loss_test:0.07437, lr:8.60e-03, fs:0.72251 (r=0.697,p=0.750),  time:47.521, tt:3659.082\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:77, loss:0.00005, loss_test:0.07924, lr:8.60e-03, fs:0.73298 (r=0.707,p=0.761),  time:47.396, tt:3696.861\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:78, loss:0.00005, loss_test:0.07774, lr:8.60e-03, fs:0.73404 (r=0.697,p=0.775),  time:47.301, tt:3736.764\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:79, loss:0.00004, loss_test:0.07780, lr:8.60e-03, fs:0.73298 (r=0.707,p=0.761),  time:47.204, tt:3776.332\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:80, loss:0.00004, loss_test:0.07873, lr:8.60e-03, fs:0.73404 (r=0.697,p=0.775),  time:47.165, tt:3820.343\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:81, loss:0.00004, loss_test:0.07695, lr:8.60e-03, fs:0.73298 (r=0.707,p=0.761),  time:47.148, tt:3866.146\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:82, loss:0.00004, loss_test:0.07836, lr:8.51e-03, fs:0.73797 (r=0.697,p=0.784),  time:47.158, tt:3914.142\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:83, loss:0.00004, loss_test:0.07800, lr:8.43e-03, fs:0.73298 (r=0.707,p=0.761),  time:47.143, tt:3959.996\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:84, loss:0.00004, loss_test:0.07696, lr:8.35e-03, fs:0.73404 (r=0.697,p=0.775),  time:47.069, tt:4000.883\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:85, loss:0.00004, loss_test:0.07937, lr:8.26e-03, fs:0.73298 (r=0.707,p=0.761),  time:46.993, tt:4041.403\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:86, loss:0.00004, loss_test:0.07887, lr:8.18e-03, fs:0.73118 (r=0.687,p=0.782),  time:46.921, tt:4082.097\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:87, loss:0.00004, loss_test:0.08104, lr:8.10e-03, fs:0.74074 (r=0.707,p=0.778),  time:46.844, tt:4122.260\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:88, loss:0.00004, loss_test:0.07677, lr:8.02e-03, fs:0.72727 (r=0.687,p=0.773),  time:46.890, tt:4173.200\n",
      "1056\n",
      "1024\n",
      "1060\n",
      "412\n",
      "Ep:89, loss:0.00004, loss_test:0.08128, lr:7.94e-03, fs:0.73684 (r=0.707,p=0.769),  time:46.910, tt:4221.883\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,90,\"71-71\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:0, loss:0.00055, loss_test:0.09155, lr:1.00e-02, fs:0.62595 (r=0.828,p=0.503),  time:45.934, tt:45.934\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:1, loss:0.00027, loss_test:0.11007, lr:1.00e-02, fs:0.60000 (r=0.576,p=0.626),  time:62.028, tt:124.056\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:2, loss:0.00023, loss_test:0.10659, lr:1.00e-02, fs:0.58065 (r=0.545,p=0.621),  time:73.188, tt:219.564\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:3, loss:0.00021, loss_test:0.09778, lr:1.00e-02, fs:0.62564 (r=0.616,p=0.635),  time:77.003, tt:308.011\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:4, loss:0.00020, loss_test:0.09789, lr:1.00e-02, fs:0.59887 (r=0.535,p=0.679),  time:79.075, tt:395.374\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:5, loss:0.00018, loss_test:0.08968, lr:1.00e-02, fs:0.62105 (r=0.596,p=0.648),  time:81.072, tt:486.433\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:6, loss:0.00017, loss_test:0.09119, lr:1.00e-02, fs:0.57647 (r=0.495,p=0.690),  time:83.469, tt:584.284\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:7, loss:0.00017, loss_test:0.08752, lr:1.00e-02, fs:0.62032 (r=0.586,p=0.659),  time:85.242, tt:681.939\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:8, loss:0.00016, loss_test:0.08512, lr:1.00e-02, fs:0.61878 (r=0.566,p=0.683),  time:86.560, tt:779.040\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:9, loss:0.00015, loss_test:0.08503, lr:1.00e-02, fs:0.60000 (r=0.515,p=0.718),  time:87.131, tt:871.311\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:10, loss:0.00015, loss_test:0.08093, lr:1.00e-02, fs:0.65934 (r=0.606,p=0.723),  time:87.194, tt:959.138\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:11, loss:0.00014, loss_test:0.08022, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:87.675, tt:1052.099\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:12, loss:0.00014, loss_test:0.08192, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:88.053, tt:1144.687\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:13, loss:0.00013, loss_test:0.07837, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:88.862, tt:1244.068\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:14, loss:0.00013, loss_test:0.08090, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:89.476, tt:1342.134\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:15, loss:0.00012, loss_test:0.07502, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:90.091, tt:1441.462\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:16, loss:0.00012, loss_test:0.07880, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:90.007, tt:1530.123\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:17, loss:0.00011, loss_test:0.07715, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:90.019, tt:1620.346\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:18, loss:0.00011, loss_test:0.07320, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:89.927, tt:1708.611\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:19, loss:0.00011, loss_test:0.07852, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:90.230, tt:1804.607\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:20, loss:0.00010, loss_test:0.07702, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:90.636, tt:1903.361\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:21, loss:0.00010, loss_test:0.07264, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:90.855, tt:1998.817\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:22, loss:0.00009, loss_test:0.07215, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:91.111, tt:2095.545\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:23, loss:0.00009, loss_test:0.07584, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:91.051, tt:2185.230\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:24, loss:0.00009, loss_test:0.07656, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:91.049, tt:2276.218\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:25, loss:0.00009, loss_test:0.06635, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:90.907, tt:2363.582\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:26, loss:0.00009, loss_test:0.07589, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:91.212, tt:2462.729\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:27, loss:0.00009, loss_test:0.07137, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:91.480, tt:2561.439\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:28, loss:0.00008, loss_test:0.07148, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:91.754, tt:2660.873\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:29, loss:0.00008, loss_test:0.07067, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:91.899, tt:2756.956\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:30, loss:0.00008, loss_test:0.07306, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:91.735, tt:2843.795\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:31, loss:0.00007, loss_test:0.06656, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:91.649, tt:2932.776\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:32, loss:0.00007, loss_test:0.07366, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:91.539, tt:3020.798\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:33, loss:0.00007, loss_test:0.06975, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:91.672, tt:3116.853\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:34, loss:0.00006, loss_test:0.06832, lr:9.90e-03, fs:0.84615 (r=0.889,p=0.807),  time:91.815, tt:3213.542\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:35, loss:0.00006, loss_test:0.06952, lr:9.90e-03, fs:0.83168 (r=0.848,p=0.816),  time:92.006, tt:3312.203\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:36, loss:0.00006, loss_test:0.06933, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:92.062, tt:3406.302\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:37, loss:0.00006, loss_test:0.06695, lr:9.90e-03, fs:0.82297 (r=0.869,p=0.782),  time:91.970, tt:3494.845\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:38, loss:0.00005, loss_test:0.07001, lr:9.90e-03, fs:0.82653 (r=0.818,p=0.835),  time:91.836, tt:3581.601\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:39, loss:0.00005, loss_test:0.06684, lr:9.90e-03, fs:0.84762 (r=0.899,p=0.802),  time:91.788, tt:3671.504\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:40, loss:0.00005, loss_test:0.06660, lr:9.90e-03, fs:0.85024 (r=0.889,p=0.815),  time:91.944, tt:3769.695\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:41, loss:0.00005, loss_test:0.06683, lr:9.90e-03, fs:0.85294 (r=0.879,p=0.829),  time:92.133, tt:3869.589\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:42, loss:0.00005, loss_test:0.06897, lr:9.90e-03, fs:0.85859 (r=0.859,p=0.859),  time:92.209, tt:3964.984\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:43, loss:0.00005, loss_test:0.06441, lr:9.90e-03, fs:0.83721 (r=0.909,p=0.776),  time:92.225, tt:4057.890\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:44, loss:0.00005, loss_test:0.07270, lr:9.90e-03, fs:0.82796 (r=0.778,p=0.885),  time:92.159, tt:4147.166\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:45, loss:0.00004, loss_test:0.06524, lr:9.90e-03, fs:0.86124 (r=0.909,p=0.818),  time:92.105, tt:4236.826\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:46, loss:0.00004, loss_test:0.06926, lr:9.90e-03, fs:0.84848 (r=0.848,p=0.848),  time:92.098, tt:4328.613\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:47, loss:0.00004, loss_test:0.06601, lr:9.90e-03, fs:0.87379 (r=0.909,p=0.841),  time:92.182, tt:4424.749\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:48, loss:0.00004, loss_test:0.06911, lr:9.90e-03, fs:0.83938 (r=0.818,p=0.862),  time:92.283, tt:4521.844\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:49, loss:0.00004, loss_test:0.06465, lr:9.90e-03, fs:0.86124 (r=0.909,p=0.818),  time:92.339, tt:4616.971\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:50, loss:0.00004, loss_test:0.07004, lr:9.90e-03, fs:0.81481 (r=0.778,p=0.856),  time:92.301, tt:4707.362\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:51, loss:0.00004, loss_test:0.06477, lr:9.90e-03, fs:0.86829 (r=0.899,p=0.840),  time:92.261, tt:4797.553\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:52, loss:0.00004, loss_test:0.06678, lr:9.90e-03, fs:0.86432 (r=0.869,p=0.860),  time:92.182, tt:4885.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:53, loss:0.00004, loss_test:0.06601, lr:9.90e-03, fs:0.86275 (r=0.889,p=0.838),  time:92.173, tt:4977.351\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:54, loss:0.00003, loss_test:0.06718, lr:9.90e-03, fs:0.87000 (r=0.879,p=0.861),  time:92.266, tt:5074.623\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:55, loss:0.00003, loss_test:0.06440, lr:9.90e-03, fs:0.86408 (r=0.899,p=0.832),  time:92.368, tt:5172.623\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:56, loss:0.00003, loss_test:0.06678, lr:9.90e-03, fs:0.86000 (r=0.869,p=0.851),  time:92.461, tt:5270.284\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:57, loss:0.00003, loss_test:0.06275, lr:9.90e-03, fs:0.86667 (r=0.919,p=0.820),  time:92.448, tt:5361.971\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:58, loss:0.00003, loss_test:0.06724, lr:9.90e-03, fs:0.85859 (r=0.859,p=0.859),  time:92.380, tt:5450.422\n",
      "1040\n",
      "1065\n",
      "1060\n",
      "1040\n",
      "235\n",
      "Ep:59, loss:0.00003, loss_test:0.06417, lr:9.80e-03, fs:0.86829 (r=0.899,p=0.840),  time:92.365, tt:5541.921\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:0, loss:0.00056, loss_test:0.07881, lr:1.00e-02, fs:0.62879 (r=0.838,p=0.503),  time:87.010, tt:87.010\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:1, loss:0.00028, loss_test:0.09100, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:85.236, tt:170.473\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:2, loss:0.00023, loss_test:0.08679, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:88.479, tt:265.436\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:3, loss:0.00021, loss_test:0.07701, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:89.770, tt:359.081\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:4, loss:0.00021, loss_test:0.08158, lr:1.00e-02, fs:0.71910 (r=0.646,p=0.810),  time:89.876, tt:449.381\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:5, loss:0.00019, loss_test:0.07638, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:89.630, tt:537.777\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:6, loss:0.00018, loss_test:0.07156, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:90.356, tt:632.495\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:7, loss:0.00017, loss_test:0.07587, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:91.023, tt:728.183\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:8, loss:0.00016, loss_test:0.06955, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:91.624, tt:824.613\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:9, loss:0.00016, loss_test:0.07231, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:92.224, tt:922.239\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:10, loss:0.00015, loss_test:0.06995, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:92.306, tt:1015.368\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:11, loss:0.00015, loss_test:0.06497, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:92.084, tt:1105.013\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:12, loss:0.00014, loss_test:0.06884, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:91.624, tt:1191.118\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:13, loss:0.00013, loss_test:0.06543, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:91.644, tt:1283.020\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:14, loss:0.00013, loss_test:0.06182, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:91.876, tt:1378.139\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:15, loss:0.00013, loss_test:0.06576, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:92.357, tt:1477.710\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:16, loss:0.00012, loss_test:0.06563, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:92.701, tt:1575.919\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:17, loss:0.00012, loss_test:0.05974, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:92.621, tt:1667.173\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:18, loss:0.00011, loss_test:0.06170, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:92.419, tt:1755.968\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:19, loss:0.00011, loss_test:0.06008, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:92.249, tt:1844.989\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:20, loss:0.00011, loss_test:0.05954, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:92.410, tt:1940.601\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:21, loss:0.00011, loss_test:0.05882, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:92.585, tt:2036.866\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:22, loss:0.00010, loss_test:0.05879, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:92.809, tt:2134.613\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:23, loss:0.00010, loss_test:0.05628, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:92.880, tt:2229.112\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:24, loss:0.00009, loss_test:0.05527, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:92.764, tt:2319.092\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:25, loss:0.00010, loss_test:0.05959, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:92.593, tt:2407.409\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:26, loss:0.00009, loss_test:0.05588, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:92.536, tt:2498.459\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:27, loss:0.00008, loss_test:0.05613, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:92.552, tt:2591.464\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:28, loss:0.00008, loss_test:0.05341, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:92.724, tt:2688.987\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:29, loss:0.00008, loss_test:0.05514, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:92.954, tt:2788.613\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:30, loss:0.00007, loss_test:0.05477, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:93.116, tt:2886.599\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:31, loss:0.00007, loss_test:0.05620, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:93.066, tt:2978.122\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:32, loss:0.00007, loss_test:0.05103, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:92.948, tt:3067.284\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:33, loss:0.00007, loss_test:0.05035, lr:1.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:92.894, tt:3158.401\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:34, loss:0.00007, loss_test:0.05319, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:93.141, tt:3259.948\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:35, loss:0.00006, loss_test:0.05472, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:93.258, tt:3357.297\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:36, loss:0.00006, loss_test:0.05244, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:93.358, tt:3454.248\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:37, loss:0.00006, loss_test:0.04769, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:93.368, tt:3547.996\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:38, loss:0.00006, loss_test:0.05347, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:93.325, tt:3639.663\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:39, loss:0.00005, loss_test:0.05212, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:93.248, tt:3729.935\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:40, loss:0.00005, loss_test:0.04600, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:93.197, tt:3821.069\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:41, loss:0.00005, loss_test:0.05628, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:93.308, tt:3918.920\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:42, loss:0.00005, loss_test:0.04737, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:93.440, tt:4017.912\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:43, loss:0.00005, loss_test:0.05044, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:93.531, tt:4115.359\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:44, loss:0.00005, loss_test:0.04851, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:93.475, tt:4206.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:45, loss:0.00004, loss_test:0.04962, lr:9.90e-03, fs:0.90909 (r=0.909,p=0.909),  time:93.367, tt:4294.889\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:46, loss:0.00004, loss_test:0.04489, lr:9.80e-03, fs:0.91866 (r=0.970,p=0.873),  time:93.242, tt:4382.392\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:47, loss:0.00004, loss_test:0.05004, lr:9.80e-03, fs:0.92308 (r=0.909,p=0.938),  time:93.206, tt:4473.881\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:48, loss:0.00004, loss_test:0.04605, lr:9.80e-03, fs:0.90732 (r=0.939,p=0.877),  time:93.299, tt:4571.641\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:49, loss:0.00004, loss_test:0.04868, lr:9.80e-03, fs:0.91000 (r=0.919,p=0.901),  time:93.347, tt:4667.333\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:50, loss:0.00004, loss_test:0.04706, lr:9.80e-03, fs:0.91542 (r=0.929,p=0.902),  time:93.400, tt:4763.424\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:51, loss:0.00004, loss_test:0.04812, lr:9.80e-03, fs:0.91837 (r=0.909,p=0.928),  time:93.280, tt:4850.551\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:52, loss:0.00004, loss_test:0.04370, lr:9.80e-03, fs:0.91429 (r=0.970,p=0.865),  time:93.177, tt:4938.354\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:53, loss:0.00004, loss_test:0.05462, lr:9.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:93.157, tt:5030.474\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:54, loss:0.00004, loss_test:0.04170, lr:9.80e-03, fs:0.92891 (r=0.990,p=0.875),  time:93.194, tt:5125.681\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:55, loss:0.00004, loss_test:0.05787, lr:9.80e-03, fs:0.84571 (r=0.747,p=0.974),  time:93.324, tt:5226.125\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:56, loss:0.00004, loss_test:0.04339, lr:9.80e-03, fs:0.94686 (r=0.990,p=0.907),  time:93.374, tt:5322.317\n",
      "##########Best model found so far##########\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:57, loss:0.00003, loss_test:0.05055, lr:9.80e-03, fs:0.88298 (r=0.838,p=0.933),  time:93.434, tt:5419.172\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:58, loss:0.00003, loss_test:0.04515, lr:9.80e-03, fs:0.92537 (r=0.939,p=0.912),  time:93.336, tt:5506.835\n",
      "1065\n",
      "1025\n",
      "1050\n",
      "1035\n",
      "265\n",
      "Ep:59, loss:0.00003, loss_test:0.04734, lr:9.80e-03, fs:0.89691 (r=0.879,p=0.916),  time:93.256, tt:5595.382\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 12\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1060\n",
      "1045\n",
      "1055\n",
      "1040\n",
      "240\n",
      "Ep:0, loss:0.00056, loss_test:0.08921, lr:1.00e-02, fs:0.60837 (r=0.808,p=0.488),  time:85.584, tt:85.584\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1045\n",
      "1055\n",
      "1040\n",
      "240\n",
      "Ep:1, loss:0.00027, loss_test:0.10780, lr:1.00e-02, fs:0.62176 (r=0.606,p=0.638),  time:83.260, tt:166.521\n",
      "##########Best model found so far##########\n",
      "1060\n",
      "1045\n",
      "1055\n",
      "1040\n",
      "240\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e897897f90e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_ran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"isolation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for CV out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;31m#         train_batch = shuffle_splits_ns(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m \u001b[0;31m#         np.random.shuffle(train_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;31m#         train_batch = np.array_split(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 10\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14116, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.102, tt:21.102\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13565, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:25.984, tt:51.969\n",
      "Ep:2, loss:0.00052, loss_test:0.12264, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:32.272, tt:96.815\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.11326, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:39.231, tt:156.925\n",
      "Ep:4, loss:0.00044, loss_test:0.11106, lr:1.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:43.279, tt:216.397\n",
      "Ep:5, loss:0.00042, loss_test:0.10639, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:45.936, tt:275.616\n",
      "Ep:6, loss:0.00039, loss_test:0.10521, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:47.772, tt:334.403\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00037, loss_test:0.10095, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:49.489, tt:395.910\n",
      "Ep:8, loss:0.00035, loss_test:0.09880, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:50.742, tt:456.678\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09717, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:51.541, tt:515.411\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.09509, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:52.254, tt:574.798\n",
      "Ep:11, loss:0.00031, loss_test:0.09513, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:52.906, tt:634.873\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.09100, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:53.553, tt:696.187\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.09193, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:54.073, tt:757.017\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.08811, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:54.471, tt:817.072\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08857, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:54.692, tt:875.068\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.08303, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:55.086, tt:936.458\n",
      "Ep:17, loss:0.00024, loss_test:0.08356, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:55.323, tt:995.810\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.08367, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:55.553, tt:1055.511\n",
      "Ep:19, loss:0.00023, loss_test:0.07870, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:55.717, tt:1114.339\n",
      "Ep:20, loss:0.00022, loss_test:0.08054, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:55.967, tt:1175.306\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.07836, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:56.199, tt:1236.376\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.07797, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:56.333, tt:1295.661\n",
      "Ep:23, loss:0.00019, loss_test:0.07711, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:56.453, tt:1354.864\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.07447, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:56.543, tt:1413.574\n",
      "Ep:25, loss:0.00017, loss_test:0.07462, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:56.695, tt:1474.073\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.07493, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:56.750, tt:1532.246\n",
      "Ep:27, loss:0.00016, loss_test:0.07193, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:56.793, tt:1590.216\n",
      "Ep:28, loss:0.00015, loss_test:0.07165, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:57.003, tt:1653.091\n",
      "Ep:29, loss:0.00014, loss_test:0.07183, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:57.157, tt:1714.710\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.06980, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:57.278, tt:1775.614\n",
      "Ep:31, loss:0.00013, loss_test:0.07088, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:57.412, tt:1837.185\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07036, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:57.499, tt:1897.466\n",
      "Ep:33, loss:0.00012, loss_test:0.06838, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:57.578, tt:1957.666\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.06747, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:57.720, tt:2020.203\n",
      "Ep:35, loss:0.00011, loss_test:0.06806, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:57.821, tt:2081.561\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.06968, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:57.871, tt:2141.215\n",
      "Ep:37, loss:0.00010, loss_test:0.06612, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:57.933, tt:2201.461\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.06620, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:58.066, tt:2264.557\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.06741, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:58.184, tt:2327.365\n",
      "Ep:40, loss:0.00009, loss_test:0.06296, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:58.327, tt:2391.416\n",
      "Ep:41, loss:0.00008, loss_test:0.06705, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:58.577, tt:2460.234\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.06722, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:58.551, tt:2517.674\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06348, lr:1.00e-02, fs:0.93264 (r=0.909,p=0.957),  time:58.462, tt:2572.332\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.06614, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:58.457, tt:2630.554\n",
      "Ep:45, loss:0.00007, loss_test:0.06687, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:58.515, tt:2691.693\n",
      "Ep:46, loss:0.00007, loss_test:0.06532, lr:1.00e-02, fs:0.93264 (r=0.909,p=0.957),  time:58.522, tt:2750.517\n",
      "Ep:47, loss:0.00006, loss_test:0.06577, lr:1.00e-02, fs:0.93264 (r=0.909,p=0.957),  time:58.479, tt:2806.980\n",
      "Ep:48, loss:0.00006, loss_test:0.06600, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:58.452, tt:2864.132\n",
      "Ep:49, loss:0.00006, loss_test:0.06568, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:58.448, tt:2922.396\n",
      "Ep:50, loss:0.00006, loss_test:0.06469, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:58.475, tt:2982.245\n",
      "Ep:51, loss:0.00006, loss_test:0.06326, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:58.517, tt:3042.892\n",
      "Ep:52, loss:0.00005, loss_test:0.06730, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:58.502, tt:3100.592\n",
      "Ep:53, loss:0.00005, loss_test:0.06682, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:58.534, tt:3160.851\n",
      "Ep:54, loss:0.00005, loss_test:0.06550, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:58.572, tt:3221.466\n",
      "Ep:55, loss:0.00005, loss_test:0.06652, lr:9.90e-03, fs:0.92708 (r=0.899,p=0.957),  time:58.573, tt:3280.069\n",
      "Ep:56, loss:0.00005, loss_test:0.06569, lr:9.80e-03, fs:0.93264 (r=0.909,p=0.957),  time:58.585, tt:3339.328\n",
      "Ep:57, loss:0.00005, loss_test:0.06471, lr:9.70e-03, fs:0.93814 (r=0.919,p=0.958),  time:58.638, tt:3400.999\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00004, loss_test:0.06688, lr:9.70e-03, fs:0.93264 (r=0.909,p=0.957),  time:58.673, tt:3461.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00004, loss_test:0.06654, lr:9.70e-03, fs:0.93264 (r=0.909,p=0.957),  time:58.690, tt:3521.414\n",
      "Ep:60, loss:0.00004, loss_test:0.06655, lr:9.70e-03, fs:0.93814 (r=0.919,p=0.958),  time:58.768, tt:3584.837\n",
      "Ep:61, loss:0.00004, loss_test:0.06489, lr:9.70e-03, fs:0.93264 (r=0.909,p=0.957),  time:58.848, tt:3648.573\n",
      "Ep:62, loss:0.00004, loss_test:0.06723, lr:9.70e-03, fs:0.91005 (r=0.869,p=0.956),  time:58.886, tt:3709.840\n",
      "Ep:63, loss:0.00004, loss_test:0.06880, lr:9.70e-03, fs:0.90426 (r=0.859,p=0.955),  time:58.924, tt:3771.151\n",
      "Ep:64, loss:0.00004, loss_test:0.06563, lr:9.70e-03, fs:0.92147 (r=0.889,p=0.957),  time:59.000, tt:3834.978\n",
      "Ep:65, loss:0.00004, loss_test:0.06460, lr:9.70e-03, fs:0.93264 (r=0.909,p=0.957),  time:59.101, tt:3900.656\n",
      "Ep:66, loss:0.00004, loss_test:0.07006, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:59.110, tt:3960.396\n",
      "Ep:67, loss:0.00003, loss_test:0.06959, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:59.106, tt:4019.192\n",
      "Ep:68, loss:0.00003, loss_test:0.06527, lr:9.70e-03, fs:0.94301 (r=0.919,p=0.968),  time:59.117, tt:4079.092\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00003, loss_test:0.06809, lr:9.70e-03, fs:0.92063 (r=0.879,p=0.967),  time:59.142, tt:4139.915\n",
      "Ep:70, loss:0.00003, loss_test:0.06899, lr:9.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:59.152, tt:4199.792\n",
      "Ep:71, loss:0.00003, loss_test:0.06679, lr:9.70e-03, fs:0.93194 (r=0.899,p=0.967),  time:59.164, tt:4259.839\n",
      "Ep:72, loss:0.00003, loss_test:0.06876, lr:9.70e-03, fs:0.89840 (r=0.848,p=0.955),  time:59.228, tt:4323.674\n",
      "Ep:73, loss:0.00003, loss_test:0.06841, lr:9.70e-03, fs:0.89730 (r=0.838,p=0.965),  time:59.226, tt:4382.738\n",
      "Ep:74, loss:0.00003, loss_test:0.06943, lr:9.70e-03, fs:0.89130 (r=0.828,p=0.965),  time:59.257, tt:4444.298\n",
      "Ep:75, loss:0.00003, loss_test:0.06896, lr:9.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:59.286, tt:4505.761\n",
      "Ep:76, loss:0.00003, loss_test:0.06722, lr:9.70e-03, fs:0.90323 (r=0.848,p=0.966),  time:59.289, tt:4565.248\n",
      "Ep:77, loss:0.00003, loss_test:0.06986, lr:9.70e-03, fs:0.90811 (r=0.848,p=0.977),  time:59.286, tt:4624.279\n",
      "Ep:78, loss:0.00003, loss_test:0.06765, lr:9.70e-03, fs:0.90323 (r=0.848,p=0.966),  time:59.304, tt:4685.006\n",
      "Ep:79, loss:0.00003, loss_test:0.06767, lr:9.70e-03, fs:0.90426 (r=0.859,p=0.955),  time:59.321, tt:4745.670\n",
      "Ep:80, loss:0.00002, loss_test:0.07003, lr:9.61e-03, fs:0.90323 (r=0.848,p=0.966),  time:59.313, tt:4804.337\n",
      "Ep:81, loss:0.00002, loss_test:0.06770, lr:9.51e-03, fs:0.90426 (r=0.859,p=0.955),  time:59.327, tt:4864.811\n",
      "Ep:82, loss:0.00002, loss_test:0.06905, lr:9.41e-03, fs:0.85876 (r=0.768,p=0.974),  time:59.331, tt:4924.446\n",
      "Ep:83, loss:0.00002, loss_test:0.07095, lr:9.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:59.358, tt:4986.102\n",
      "Ep:84, loss:0.00002, loss_test:0.06915, lr:9.23e-03, fs:0.89730 (r=0.838,p=0.965),  time:59.355, tt:5045.177\n",
      "Ep:85, loss:0.00002, loss_test:0.07038, lr:9.14e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.323, tt:5101.821\n",
      "Ep:86, loss:0.00002, loss_test:0.07275, lr:9.04e-03, fs:0.85714 (r=0.758,p=0.987),  time:59.340, tt:5162.536\n",
      "Ep:87, loss:0.00002, loss_test:0.06978, lr:8.95e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.344, tt:5222.291\n",
      "Ep:88, loss:0.00002, loss_test:0.06861, lr:8.86e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.346, tt:5281.816\n",
      "Ep:89, loss:0.00002, loss_test:0.07077, lr:8.78e-03, fs:0.83429 (r=0.737,p=0.961),  time:59.359, tt:5342.353\n",
      "Ep:90, loss:0.00002, loss_test:0.07145, lr:8.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.359, tt:5401.660\n",
      "Ep:91, loss:0.00002, loss_test:0.07066, lr:8.60e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.371, tt:5462.112\n",
      "Ep:92, loss:0.00002, loss_test:0.07008, lr:8.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.432, tt:5527.139\n",
      "Ep:93, loss:0.00002, loss_test:0.06995, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.419, tt:5585.358\n",
      "Ep:94, loss:0.00002, loss_test:0.07197, lr:8.35e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.476, tt:5650.174\n",
      "Ep:95, loss:0.00002, loss_test:0.07067, lr:8.26e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.480, tt:5710.037\n",
      "Ep:96, loss:0.00002, loss_test:0.07054, lr:8.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.465, tt:5768.110\n",
      "Ep:97, loss:0.00002, loss_test:0.07143, lr:8.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.488, tt:5829.856\n",
      "Ep:98, loss:0.00002, loss_test:0.07386, lr:8.02e-03, fs:0.82558 (r=0.717,p=0.973),  time:59.507, tt:5891.187\n",
      "Ep:99, loss:0.00002, loss_test:0.07150, lr:7.94e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.500, tt:5949.993\n",
      "Ep:100, loss:0.00002, loss_test:0.07162, lr:7.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.506, tt:6010.080\n",
      "Ep:101, loss:0.00002, loss_test:0.07228, lr:7.78e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.483, tt:6067.236\n",
      "Ep:102, loss:0.00002, loss_test:0.07309, lr:7.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.449, tt:6123.196\n",
      "Ep:103, loss:0.00002, loss_test:0.07232, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.472, tt:6185.099\n",
      "Ep:104, loss:0.00002, loss_test:0.07228, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.506, tt:6248.154\n",
      "Ep:105, loss:0.00002, loss_test:0.07252, lr:7.47e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.512, tt:6308.305\n",
      "Ep:106, loss:0.00002, loss_test:0.07225, lr:7.40e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.539, tt:6370.703\n",
      "Ep:107, loss:0.00002, loss_test:0.07302, lr:7.32e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.566, tt:6433.179\n",
      "Ep:108, loss:0.00001, loss_test:0.07436, lr:7.25e-03, fs:0.82759 (r=0.727,p=0.960),  time:59.580, tt:6494.217\n",
      "Ep:109, loss:0.00001, loss_test:0.07265, lr:7.18e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.584, tt:6554.288\n",
      "Ep:110, loss:0.00001, loss_test:0.07427, lr:7.11e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.582, tt:6613.655\n",
      "Ep:111, loss:0.00001, loss_test:0.07435, lr:7.03e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.606, tt:6675.819\n",
      "Ep:112, loss:0.00001, loss_test:0.07284, lr:6.96e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.603, tt:6735.114\n",
      "Ep:113, loss:0.00001, loss_test:0.07490, lr:6.89e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.622, tt:6796.885\n",
      "Ep:114, loss:0.00001, loss_test:0.07417, lr:6.83e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.626, tt:6857.029\n",
      "Ep:115, loss:0.00001, loss_test:0.07430, lr:6.76e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.623, tt:6916.301\n",
      "Ep:116, loss:0.00001, loss_test:0.07552, lr:6.69e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.633, tt:6977.040\n",
      "Ep:117, loss:0.00001, loss_test:0.07434, lr:6.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.633, tt:7036.709\n",
      "Ep:118, loss:0.00001, loss_test:0.07373, lr:6.56e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.653, tt:7098.696\n",
      "Ep:119, loss:0.00001, loss_test:0.07610, lr:6.49e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.685, tt:7162.143\n",
      "Ep:120, loss:0.00001, loss_test:0.07432, lr:6.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.691, tt:7222.594\n",
      "Ep:121, loss:0.00001, loss_test:0.07748, lr:6.36e-03, fs:0.82840 (r=0.707,p=1.000),  time:59.698, tt:7283.157\n",
      "Ep:122, loss:0.00001, loss_test:0.07672, lr:6.30e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.726, tt:7346.256\n",
      "Ep:123, loss:0.00001, loss_test:0.07545, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.730, tt:7406.492\n",
      "Ep:124, loss:0.00001, loss_test:0.07591, lr:6.17e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.735, tt:7466.831\n",
      "Ep:125, loss:0.00001, loss_test:0.07522, lr:6.11e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.744, tt:7527.769\n",
      "Ep:126, loss:0.00001, loss_test:0.07806, lr:6.05e-03, fs:0.82840 (r=0.707,p=1.000),  time:59.744, tt:7587.508\n",
      "Ep:127, loss:0.00001, loss_test:0.07773, lr:5.99e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.749, tt:7647.887\n",
      "Ep:128, loss:0.00001, loss_test:0.07577, lr:5.93e-03, fs:0.83237 (r=0.727,p=0.973),  time:59.767, tt:7709.898\n",
      "Ep:129, loss:0.00001, loss_test:0.07899, lr:5.87e-03, fs:0.82143 (r=0.697,p=1.000),  time:59.762, tt:7769.053\n",
      "Ep:130, loss:0.00001, loss_test:0.07695, lr:5.81e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.762, tt:7828.822\n",
      "Ep:131, loss:0.00001, loss_test:0.07707, lr:5.75e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.759, tt:7888.231\n",
      "Ep:132, loss:0.00001, loss_test:0.07698, lr:5.70e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.777, tt:7950.314\n",
      "Ep:133, loss:0.00001, loss_test:0.07799, lr:5.64e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.803, tt:8013.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.07815, lr:5.58e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.809, tt:8074.240\n",
      "Ep:135, loss:0.00001, loss_test:0.07706, lr:5.53e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.816, tt:8134.983\n",
      "Ep:136, loss:0.00001, loss_test:0.07875, lr:5.47e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.831, tt:8196.894\n",
      "Ep:137, loss:0.00001, loss_test:0.07896, lr:5.42e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.822, tt:8255.412\n",
      "Ep:138, loss:0.00001, loss_test:0.07808, lr:5.36e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.829, tt:8316.255\n",
      "Ep:139, loss:0.00001, loss_test:0.07893, lr:5.31e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.851, tt:8379.086\n",
      "Ep:140, loss:0.00001, loss_test:0.07921, lr:5.26e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.872, tt:8441.994\n",
      "Ep:141, loss:0.00001, loss_test:0.07880, lr:5.20e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.891, tt:8504.478\n",
      "Ep:142, loss:0.00001, loss_test:0.07902, lr:5.15e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.903, tt:8566.101\n",
      "Ep:143, loss:0.00001, loss_test:0.07792, lr:5.10e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.927, tt:8629.480\n",
      "Ep:144, loss:0.00001, loss_test:0.08040, lr:5.05e-03, fs:0.82840 (r=0.707,p=1.000),  time:59.944, tt:8691.891\n",
      "Ep:145, loss:0.00001, loss_test:0.07941, lr:5.00e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.962, tt:8754.430\n",
      "Ep:146, loss:0.00001, loss_test:0.07877, lr:4.95e-03, fs:0.83041 (r=0.717,p=0.986),  time:59.978, tt:8816.701\n",
      "Ep:147, loss:0.00001, loss_test:0.08083, lr:4.90e-03, fs:0.82840 (r=0.707,p=1.000),  time:59.997, tt:8879.580\n",
      "Ep:148, loss:0.00001, loss_test:0.07822, lr:4.85e-03, fs:0.83721 (r=0.727,p=0.986),  time:60.015, tt:8942.200\n",
      "Ep:149, loss:0.00001, loss_test:0.07989, lr:4.80e-03, fs:0.82840 (r=0.707,p=1.000),  time:60.037, tt:9005.507\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 11\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14674, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:54.784, tt:54.784\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.14313, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:56.169, tt:112.338\n",
      "Ep:2, loss:0.00051, loss_test:0.13519, lr:1.00e-02, fs:0.62903 (r=0.788,p=0.523),  time:56.396, tt:169.189\n",
      "Ep:3, loss:0.00046, loss_test:0.12938, lr:1.00e-02, fs:0.56716 (r=0.576,p=0.559),  time:54.892, tt:219.567\n",
      "Ep:4, loss:0.00043, loss_test:0.12506, lr:1.00e-02, fs:0.60360 (r=0.677,p=0.545),  time:56.256, tt:281.278\n",
      "Ep:5, loss:0.00041, loss_test:0.12012, lr:1.00e-02, fs:0.58291 (r=0.586,p=0.580),  time:57.929, tt:347.573\n",
      "Ep:6, loss:0.00039, loss_test:0.11658, lr:1.00e-02, fs:0.62439 (r=0.646,p=0.604),  time:58.910, tt:412.369\n",
      "Ep:7, loss:0.00037, loss_test:0.11260, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:59.675, tt:477.399\n",
      "Ep:8, loss:0.00035, loss_test:0.11160, lr:1.00e-02, fs:0.64356 (r=0.657,p=0.631),  time:60.249, tt:542.237\n",
      "Ep:9, loss:0.00034, loss_test:0.10895, lr:1.00e-02, fs:0.65000 (r=0.657,p=0.644),  time:60.576, tt:605.764\n",
      "Ep:10, loss:0.00032, loss_test:0.10689, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:60.896, tt:669.859\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.10485, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:61.039, tt:732.465\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.10330, lr:1.00e-02, fs:0.67337 (r=0.677,p=0.670),  time:61.183, tt:795.379\n",
      "Ep:13, loss:0.00029, loss_test:0.10179, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:61.250, tt:857.498\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.10031, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:61.374, tt:920.609\n",
      "Ep:15, loss:0.00026, loss_test:0.09950, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:61.541, tt:984.655\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.09915, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:61.694, tt:1048.795\n",
      "Ep:17, loss:0.00024, loss_test:0.09688, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:61.862, tt:1113.523\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.09802, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:61.979, tt:1177.592\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.09601, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:62.185, tt:1243.694\n",
      "Ep:20, loss:0.00021, loss_test:0.09751, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:62.240, tt:1307.032\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.09555, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:62.320, tt:1371.049\n",
      "Ep:22, loss:0.00019, loss_test:0.09536, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:62.381, tt:1434.760\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.09492, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:62.431, tt:1498.348\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09541, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:62.479, tt:1561.977\n",
      "Ep:25, loss:0.00016, loss_test:0.09300, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:62.402, tt:1622.456\n",
      "Ep:26, loss:0.00015, loss_test:0.09421, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:62.492, tt:1687.276\n",
      "Ep:27, loss:0.00014, loss_test:0.09314, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:62.621, tt:1753.395\n",
      "Ep:28, loss:0.00014, loss_test:0.09395, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:62.660, tt:1817.147\n",
      "Ep:29, loss:0.00013, loss_test:0.09270, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:62.679, tt:1880.379\n",
      "Ep:30, loss:0.00012, loss_test:0.09489, lr:1.00e-02, fs:0.75000 (r=0.667,p=0.857),  time:62.736, tt:1944.822\n",
      "Ep:31, loss:0.00011, loss_test:0.09286, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:62.753, tt:2008.109\n",
      "Ep:32, loss:0.00011, loss_test:0.09344, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:62.762, tt:2071.140\n",
      "Ep:33, loss:0.00010, loss_test:0.09593, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:62.798, tt:2135.124\n",
      "Ep:34, loss:0.00010, loss_test:0.09481, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:62.885, tt:2200.979\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.09385, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:62.992, tt:2267.698\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.09649, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.016, tt:2331.581\n",
      "Ep:37, loss:0.00008, loss_test:0.09688, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:63.091, tt:2397.446\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.09723, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:63.068, tt:2459.643\n",
      "Ep:39, loss:0.00008, loss_test:0.09926, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:63.144, tt:2525.746\n",
      "Ep:40, loss:0.00007, loss_test:0.09367, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:63.176, tt:2590.232\n",
      "Ep:41, loss:0.00007, loss_test:0.09603, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:63.166, tt:2652.956\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.09557, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:63.167, tt:2716.176\n",
      "Ep:43, loss:0.00007, loss_test:0.09619, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:63.176, tt:2779.760\n",
      "Ep:44, loss:0.00007, loss_test:0.09748, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:63.194, tt:2843.742\n",
      "Ep:45, loss:0.00006, loss_test:0.09795, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:63.182, tt:2906.351\n",
      "Ep:46, loss:0.00006, loss_test:0.09705, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:63.179, tt:2969.423\n",
      "Ep:47, loss:0.00006, loss_test:0.10135, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:63.277, tt:3037.310\n",
      "Ep:48, loss:0.00006, loss_test:0.09863, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.327, tt:3103.001\n",
      "Ep:49, loss:0.00005, loss_test:0.09608, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:63.402, tt:3170.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00005, loss_test:0.10084, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:63.433, tt:3235.089\n",
      "Ep:51, loss:0.00005, loss_test:0.09752, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.431, tt:3298.403\n",
      "Ep:52, loss:0.00005, loss_test:0.10112, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:63.443, tt:3362.462\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.09803, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:63.492, tt:3428.554\n",
      "Ep:54, loss:0.00004, loss_test:0.09802, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:63.500, tt:3492.490\n",
      "Ep:55, loss:0.00004, loss_test:0.10011, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:63.523, tt:3557.269\n",
      "Ep:56, loss:0.00004, loss_test:0.10027, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.514, tt:3620.320\n",
      "Ep:57, loss:0.00004, loss_test:0.10305, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:63.533, tt:3684.943\n",
      "Ep:58, loss:0.00004, loss_test:0.10097, lr:1.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:63.566, tt:3750.398\n",
      "Ep:59, loss:0.00004, loss_test:0.10154, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:63.598, tt:3815.895\n",
      "Ep:60, loss:0.00004, loss_test:0.09977, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:63.635, tt:3881.745\n",
      "Ep:61, loss:0.00004, loss_test:0.10268, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:63.639, tt:3945.600\n",
      "Ep:62, loss:0.00003, loss_test:0.10244, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:63.653, tt:4010.155\n",
      "Ep:63, loss:0.00003, loss_test:0.10177, lr:1.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:63.688, tt:4076.018\n",
      "Ep:64, loss:0.00003, loss_test:0.10518, lr:9.90e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.696, tt:4140.217\n",
      "Ep:65, loss:0.00003, loss_test:0.10217, lr:9.80e-03, fs:0.68323 (r=0.556,p=0.887),  time:63.704, tt:4204.450\n",
      "Ep:66, loss:0.00003, loss_test:0.10370, lr:9.70e-03, fs:0.72289 (r=0.606,p=0.896),  time:63.716, tt:4268.960\n",
      "Ep:67, loss:0.00003, loss_test:0.10438, lr:9.61e-03, fs:0.78613 (r=0.687,p=0.919),  time:63.736, tt:4334.066\n",
      "Ep:68, loss:0.00003, loss_test:0.10207, lr:9.51e-03, fs:0.73810 (r=0.626,p=0.899),  time:63.715, tt:4396.317\n",
      "Ep:69, loss:0.00003, loss_test:0.10403, lr:9.41e-03, fs:0.72289 (r=0.606,p=0.896),  time:63.714, tt:4460.008\n",
      "Ep:70, loss:0.00003, loss_test:0.10793, lr:9.32e-03, fs:0.67925 (r=0.545,p=0.900),  time:63.706, tt:4523.095\n",
      "Ep:71, loss:0.00003, loss_test:0.10032, lr:9.23e-03, fs:0.73054 (r=0.616,p=0.897),  time:63.709, tt:4587.031\n",
      "Ep:72, loss:0.00003, loss_test:0.10751, lr:9.14e-03, fs:0.73939 (r=0.616,p=0.924),  time:63.682, tt:4648.799\n",
      "Ep:73, loss:0.00002, loss_test:0.10440, lr:9.04e-03, fs:0.73054 (r=0.616,p=0.897),  time:63.658, tt:4710.713\n",
      "Ep:74, loss:0.00002, loss_test:0.10493, lr:8.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.657, tt:4774.268\n",
      "Ep:75, loss:0.00002, loss_test:0.10594, lr:8.86e-03, fs:0.67925 (r=0.545,p=0.900),  time:63.654, tt:4837.715\n",
      "Ep:76, loss:0.00002, loss_test:0.10680, lr:8.78e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.635, tt:4899.914\n",
      "Ep:77, loss:0.00002, loss_test:0.10337, lr:8.69e-03, fs:0.71515 (r=0.596,p=0.894),  time:63.641, tt:4964.010\n",
      "Ep:78, loss:0.00002, loss_test:0.10620, lr:8.60e-03, fs:0.69136 (r=0.566,p=0.889),  time:63.642, tt:5027.689\n",
      "Ep:79, loss:0.00002, loss_test:0.10499, lr:8.51e-03, fs:0.69136 (r=0.566,p=0.889),  time:63.617, tt:5089.400\n",
      "Ep:80, loss:0.00002, loss_test:0.10671, lr:8.43e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.637, tt:5154.574\n",
      "Ep:81, loss:0.00002, loss_test:0.10621, lr:8.35e-03, fs:0.68323 (r=0.556,p=0.887),  time:63.638, tt:5218.348\n",
      "Ep:82, loss:0.00002, loss_test:0.10690, lr:8.26e-03, fs:0.67925 (r=0.545,p=0.900),  time:63.627, tt:5281.048\n",
      "Ep:83, loss:0.00002, loss_test:0.10656, lr:8.18e-03, fs:0.67925 (r=0.545,p=0.900),  time:63.631, tt:5345.011\n",
      "Ep:84, loss:0.00002, loss_test:0.10412, lr:8.10e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.608, tt:5406.707\n",
      "Ep:85, loss:0.00002, loss_test:0.10669, lr:8.02e-03, fs:0.65823 (r=0.525,p=0.881),  time:63.593, tt:5468.957\n",
      "Ep:86, loss:0.00002, loss_test:0.10831, lr:7.94e-03, fs:0.64516 (r=0.505,p=0.893),  time:63.617, tt:5534.656\n",
      "Ep:87, loss:0.00002, loss_test:0.10631, lr:7.86e-03, fs:0.64103 (r=0.505,p=0.877),  time:63.640, tt:5600.342\n",
      "Ep:88, loss:0.00002, loss_test:0.10924, lr:7.78e-03, fs:0.65359 (r=0.505,p=0.926),  time:63.652, tt:5665.041\n",
      "Ep:89, loss:0.00002, loss_test:0.10312, lr:7.70e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.649, tt:5728.399\n",
      "Ep:90, loss:0.00002, loss_test:0.10806, lr:7.62e-03, fs:0.66234 (r=0.515,p=0.927),  time:63.657, tt:5792.798\n",
      "Ep:91, loss:0.00002, loss_test:0.10632, lr:7.55e-03, fs:0.65823 (r=0.525,p=0.881),  time:63.662, tt:5856.869\n",
      "Ep:92, loss:0.00002, loss_test:0.10634, lr:7.47e-03, fs:0.64103 (r=0.505,p=0.877),  time:63.680, tt:5922.204\n",
      "Ep:93, loss:0.00002, loss_test:0.10938, lr:7.40e-03, fs:0.65806 (r=0.515,p=0.911),  time:63.688, tt:5986.715\n",
      "Ep:94, loss:0.00001, loss_test:0.10555, lr:7.32e-03, fs:0.64516 (r=0.505,p=0.893),  time:63.667, tt:6048.390\n",
      "Ep:95, loss:0.00001, loss_test:0.10881, lr:7.25e-03, fs:0.65359 (r=0.505,p=0.926),  time:63.650, tt:6110.417\n",
      "Ep:96, loss:0.00001, loss_test:0.10554, lr:7.18e-03, fs:0.65385 (r=0.515,p=0.895),  time:63.629, tt:6172.053\n",
      "Ep:97, loss:0.00001, loss_test:0.10822, lr:7.11e-03, fs:0.65359 (r=0.505,p=0.926),  time:63.629, tt:6235.631\n",
      "Ep:98, loss:0.00001, loss_test:0.10691, lr:7.03e-03, fs:0.64516 (r=0.505,p=0.893),  time:63.624, tt:6298.734\n",
      "Ep:99, loss:0.00001, loss_test:0.10848, lr:6.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.625, tt:6362.497\n",
      "Ep:100, loss:0.00001, loss_test:0.10562, lr:6.89e-03, fs:0.64103 (r=0.505,p=0.877),  time:63.645, tt:6428.169\n",
      "Ep:101, loss:0.00001, loss_test:0.10716, lr:6.83e-03, fs:0.65806 (r=0.515,p=0.911),  time:63.661, tt:6493.401\n",
      "Ep:102, loss:0.00001, loss_test:0.10764, lr:6.76e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.668, tt:6557.801\n",
      "Ep:103, loss:0.00001, loss_test:0.10689, lr:6.69e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.650, tt:6619.560\n",
      "Ep:104, loss:0.00001, loss_test:0.10774, lr:6.62e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.660, tt:6684.301\n",
      "Ep:105, loss:0.00001, loss_test:0.10681, lr:6.56e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.665, tt:6748.468\n",
      "Ep:106, loss:0.00001, loss_test:0.10808, lr:6.49e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.687, tt:6814.472\n",
      "Ep:107, loss:0.00001, loss_test:0.10679, lr:6.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.693, tt:6878.855\n",
      "Ep:108, loss:0.00001, loss_test:0.10718, lr:6.36e-03, fs:0.65806 (r=0.515,p=0.911),  time:63.690, tt:6942.255\n",
      "Ep:109, loss:0.00001, loss_test:0.10881, lr:6.30e-03, fs:0.64052 (r=0.495,p=0.907),  time:63.659, tt:7002.438\n",
      "Ep:110, loss:0.00001, loss_test:0.10855, lr:6.24e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.622, tt:7062.049\n",
      "Ep:111, loss:0.00001, loss_test:0.10597, lr:6.17e-03, fs:0.65385 (r=0.515,p=0.895),  time:63.613, tt:7124.657\n",
      "Ep:112, loss:0.00001, loss_test:0.10753, lr:6.11e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.596, tt:7186.344\n",
      "Ep:113, loss:0.00001, loss_test:0.10743, lr:6.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.581, tt:7248.283\n",
      "Ep:114, loss:0.00001, loss_test:0.10624, lr:5.99e-03, fs:0.65806 (r=0.515,p=0.911),  time:63.577, tt:7311.310\n",
      "Ep:115, loss:0.00001, loss_test:0.10962, lr:5.93e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.547, tt:7371.405\n",
      "Ep:116, loss:0.00001, loss_test:0.10753, lr:5.87e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.539, tt:7434.031\n",
      "Ep:117, loss:0.00001, loss_test:0.10886, lr:5.81e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.518, tt:7495.107\n",
      "Ep:118, loss:0.00001, loss_test:0.10631, lr:5.75e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.495, tt:7555.882\n",
      "Ep:119, loss:0.00001, loss_test:0.10881, lr:5.70e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.486, tt:7618.357\n",
      "Ep:120, loss:0.00001, loss_test:0.10672, lr:5.64e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.480, tt:7681.019\n",
      "Ep:121, loss:0.00001, loss_test:0.10860, lr:5.58e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.462, tt:7742.374\n",
      "Ep:122, loss:0.00001, loss_test:0.10696, lr:5.53e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.459, tt:7805.420\n",
      "Ep:123, loss:0.00001, loss_test:0.10854, lr:5.47e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.454, tt:7868.340\n",
      "Ep:124, loss:0.00001, loss_test:0.10712, lr:5.42e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.445, tt:7930.572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00001, loss_test:0.10788, lr:5.36e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.414, tt:7990.107\n",
      "Ep:126, loss:0.00001, loss_test:0.10786, lr:5.31e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.382, tt:8049.479\n",
      "Ep:127, loss:0.00001, loss_test:0.10790, lr:5.26e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.361, tt:8110.198\n",
      "Ep:128, loss:0.00001, loss_test:0.10791, lr:5.20e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.336, tt:8170.361\n",
      "Ep:129, loss:0.00001, loss_test:0.10773, lr:5.15e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.322, tt:8231.848\n",
      "Ep:130, loss:0.00001, loss_test:0.10757, lr:5.10e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.307, tt:8293.247\n",
      "Ep:131, loss:0.00001, loss_test:0.10834, lr:5.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.293, tt:8354.674\n",
      "Ep:132, loss:0.00001, loss_test:0.10729, lr:5.00e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.281, tt:8416.432\n",
      "Ep:133, loss:0.00001, loss_test:0.10825, lr:4.95e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.288, tt:8480.591\n",
      "Ep:134, loss:0.00001, loss_test:0.10670, lr:4.90e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.259, tt:8539.978\n",
      "Ep:135, loss:0.00001, loss_test:0.10973, lr:4.85e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.244, tt:8601.141\n",
      "Ep:136, loss:0.00001, loss_test:0.10761, lr:4.80e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.242, tt:8664.209\n",
      "Ep:137, loss:0.00001, loss_test:0.10884, lr:4.75e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.228, tt:8725.449\n",
      "Ep:138, loss:0.00001, loss_test:0.10841, lr:4.71e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.217, tt:8787.100\n",
      "Ep:139, loss:0.00001, loss_test:0.10802, lr:4.66e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.194, tt:8847.175\n",
      "Ep:140, loss:0.00001, loss_test:0.10803, lr:4.61e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.179, tt:8908.309\n",
      "Ep:141, loss:0.00001, loss_test:0.10837, lr:4.57e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.157, tt:8968.272\n",
      "Ep:142, loss:0.00001, loss_test:0.10764, lr:4.52e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.131, tt:9027.766\n",
      "Ep:143, loss:0.00001, loss_test:0.10825, lr:4.48e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.120, tt:9089.258\n",
      "Ep:144, loss:0.00001, loss_test:0.10794, lr:4.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.111, tt:9151.045\n",
      "Ep:145, loss:0.00001, loss_test:0.10797, lr:4.39e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.097, tt:9212.145\n",
      "Ep:146, loss:0.00001, loss_test:0.10824, lr:4.34e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.067, tt:9270.788\n",
      "Ep:147, loss:0.00001, loss_test:0.10814, lr:4.30e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.062, tt:9333.135\n",
      "Ep:148, loss:0.00001, loss_test:0.10798, lr:4.26e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.031, tt:9391.642\n",
      "Ep:149, loss:0.00001, loss_test:0.10885, lr:4.21e-03, fs:0.64935 (r=0.505,p=0.909),  time:63.028, tt:9454.154\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 12\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.13979, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:61.265, tt:61.265\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13400, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:56.548, tt:113.096\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.12299, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:57.125, tt:171.375\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00048, loss_test:0.11693, lr:1.00e-02, fs:0.66341 (r=0.687,p=0.642),  time:56.789, tt:227.157\n",
      "Ep:4, loss:0.00045, loss_test:0.11458, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:55.977, tt:279.884\n",
      "Ep:5, loss:0.00043, loss_test:0.11013, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:57.438, tt:344.631\n",
      "Ep:6, loss:0.00041, loss_test:0.10701, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:58.045, tt:406.315\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.10362, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:58.549, tt:468.389\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.09987, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:59.183, tt:532.651\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.09807, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:59.332, tt:593.320\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.09563, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:59.449, tt:653.943\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.09413, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:59.761, tt:717.136\n",
      "Ep:12, loss:0.00032, loss_test:0.09218, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:59.959, tt:779.464\n",
      "Ep:13, loss:0.00030, loss_test:0.09042, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:60.315, tt:844.415\n",
      "Ep:14, loss:0.00029, loss_test:0.08848, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:60.506, tt:907.589\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.08844, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:60.668, tt:970.691\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.08745, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:60.795, tt:1033.516\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.08639, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:61.006, tt:1098.107\n",
      "Ep:18, loss:0.00025, loss_test:0.08712, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:61.125, tt:1161.378\n",
      "Ep:19, loss:0.00024, loss_test:0.08594, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:61.328, tt:1226.565\n",
      "Ep:20, loss:0.00023, loss_test:0.08748, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:61.705, tt:1295.804\n",
      "Ep:21, loss:0.00022, loss_test:0.08332, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:61.780, tt:1359.151\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.08384, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:61.914, tt:1424.029\n",
      "Ep:23, loss:0.00020, loss_test:0.08263, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:62.014, tt:1488.341\n",
      "Ep:24, loss:0.00019, loss_test:0.08291, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:62.062, tt:1551.544\n",
      "Ep:25, loss:0.00018, loss_test:0.08447, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:62.129, tt:1615.359\n",
      "Ep:26, loss:0.00017, loss_test:0.07973, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:62.083, tt:1676.244\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.08057, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:62.094, tt:1738.646\n",
      "Ep:28, loss:0.00015, loss_test:0.07902, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:62.194, tt:1803.629\n",
      "Ep:29, loss:0.00014, loss_test:0.07777, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:62.248, tt:1867.454\n",
      "Ep:30, loss:0.00013, loss_test:0.07805, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:62.333, tt:1932.332\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.07870, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:62.321, tt:1994.281\n",
      "Ep:32, loss:0.00012, loss_test:0.07750, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:62.366, tt:2058.087\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.07603, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:62.426, tt:2122.500\n",
      "Ep:34, loss:0.00011, loss_test:0.07631, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:62.451, tt:2185.769\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07537, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:62.460, tt:2248.571\n",
      "Ep:36, loss:0.00010, loss_test:0.07563, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:62.509, tt:2312.847\n",
      "Ep:37, loss:0.00009, loss_test:0.07462, lr:1.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:62.549, tt:2376.849\n",
      "Ep:38, loss:0.00009, loss_test:0.07384, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:62.680, tt:2444.517\n",
      "Ep:39, loss:0.00008, loss_test:0.07184, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:62.743, tt:2509.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00008, loss_test:0.07264, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:62.771, tt:2573.623\n",
      "Ep:41, loss:0.00008, loss_test:0.07235, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:62.850, tt:2639.694\n",
      "Ep:42, loss:0.00007, loss_test:0.07302, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:62.884, tt:2704.009\n",
      "Ep:43, loss:0.00007, loss_test:0.07346, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:62.944, tt:2769.536\n",
      "Ep:44, loss:0.00007, loss_test:0.07399, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:62.991, tt:2834.612\n",
      "Ep:45, loss:0.00006, loss_test:0.07253, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:63.066, tt:2901.026\n",
      "Ep:46, loss:0.00006, loss_test:0.07246, lr:9.90e-03, fs:0.79330 (r=0.717,p=0.887),  time:63.101, tt:2965.769\n",
      "Ep:47, loss:0.00006, loss_test:0.07344, lr:9.80e-03, fs:0.77714 (r=0.687,p=0.895),  time:63.128, tt:3030.141\n",
      "Ep:48, loss:0.00006, loss_test:0.06993, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:63.229, tt:3098.205\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00005, loss_test:0.07120, lr:9.70e-03, fs:0.79330 (r=0.717,p=0.887),  time:63.260, tt:3163.007\n",
      "Ep:50, loss:0.00005, loss_test:0.07011, lr:9.70e-03, fs:0.78453 (r=0.717,p=0.866),  time:63.222, tt:3224.345\n",
      "Ep:51, loss:0.00005, loss_test:0.07023, lr:9.70e-03, fs:0.79330 (r=0.717,p=0.887),  time:63.249, tt:3288.960\n",
      "Ep:52, loss:0.00005, loss_test:0.06991, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:63.250, tt:3352.248\n",
      "Ep:53, loss:0.00004, loss_test:0.07122, lr:9.70e-03, fs:0.78212 (r=0.707,p=0.875),  time:63.255, tt:3415.767\n",
      "Ep:54, loss:0.00004, loss_test:0.07012, lr:9.70e-03, fs:0.80000 (r=0.707,p=0.921),  time:63.319, tt:3482.545\n",
      "Ep:55, loss:0.00004, loss_test:0.07167, lr:9.70e-03, fs:0.80000 (r=0.707,p=0.921),  time:63.255, tt:3542.300\n",
      "Ep:56, loss:0.00004, loss_test:0.07564, lr:9.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:63.255, tt:3605.507\n",
      "Ep:57, loss:0.00004, loss_test:0.07000, lr:9.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:63.254, tt:3668.721\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00004, loss_test:0.06946, lr:9.70e-03, fs:0.81768 (r=0.747,p=0.902),  time:63.224, tt:3730.236\n",
      "Ep:59, loss:0.00004, loss_test:0.07134, lr:9.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:63.266, tt:3795.963\n",
      "Ep:60, loss:0.00003, loss_test:0.06992, lr:9.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:63.220, tt:3856.442\n",
      "Ep:61, loss:0.00003, loss_test:0.06994, lr:9.70e-03, fs:0.79096 (r=0.707,p=0.897),  time:63.163, tt:3916.106\n",
      "Ep:62, loss:0.00003, loss_test:0.06909, lr:9.70e-03, fs:0.79096 (r=0.707,p=0.897),  time:63.131, tt:3977.273\n",
      "Ep:63, loss:0.00003, loss_test:0.06958, lr:9.70e-03, fs:0.78212 (r=0.707,p=0.875),  time:63.120, tt:4039.708\n",
      "Ep:64, loss:0.00003, loss_test:0.06960, lr:9.70e-03, fs:0.79096 (r=0.707,p=0.897),  time:63.134, tt:4103.683\n",
      "Ep:65, loss:0.00003, loss_test:0.06995, lr:9.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:63.116, tt:4165.666\n",
      "Ep:66, loss:0.00003, loss_test:0.07292, lr:9.70e-03, fs:0.80925 (r=0.707,p=0.946),  time:63.108, tt:4228.205\n",
      "Ep:67, loss:0.00003, loss_test:0.07316, lr:9.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:63.098, tt:4290.660\n",
      "Ep:68, loss:0.00003, loss_test:0.07024, lr:9.70e-03, fs:0.80682 (r=0.717,p=0.922),  time:63.080, tt:4352.508\n",
      "Ep:69, loss:0.00002, loss_test:0.07323, lr:9.61e-03, fs:0.81609 (r=0.717,p=0.947),  time:63.073, tt:4415.088\n",
      "Ep:70, loss:0.00002, loss_test:0.07361, lr:9.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:63.059, tt:4477.179\n",
      "Ep:71, loss:0.00002, loss_test:0.07318, lr:9.41e-03, fs:0.78571 (r=0.667,p=0.957),  time:63.055, tt:4539.938\n",
      "Ep:72, loss:0.00002, loss_test:0.07193, lr:9.32e-03, fs:0.78824 (r=0.677,p=0.944),  time:63.036, tt:4601.631\n",
      "Ep:73, loss:0.00002, loss_test:0.07124, lr:9.23e-03, fs:0.79070 (r=0.687,p=0.932),  time:63.072, tt:4667.298\n",
      "Ep:74, loss:0.00002, loss_test:0.07170, lr:9.14e-03, fs:0.78363 (r=0.677,p=0.931),  time:63.061, tt:4729.545\n",
      "Ep:75, loss:0.00002, loss_test:0.07187, lr:9.04e-03, fs:0.78613 (r=0.687,p=0.919),  time:63.057, tt:4792.313\n",
      "Ep:76, loss:0.00002, loss_test:0.07345, lr:8.95e-03, fs:0.78363 (r=0.677,p=0.931),  time:63.027, tt:4853.063\n",
      "Ep:77, loss:0.00002, loss_test:0.07260, lr:8.86e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.989, tt:4913.149\n",
      "Ep:78, loss:0.00002, loss_test:0.07339, lr:8.78e-03, fs:0.78571 (r=0.667,p=0.957),  time:62.946, tt:4972.768\n",
      "Ep:79, loss:0.00002, loss_test:0.07389, lr:8.69e-03, fs:0.78571 (r=0.667,p=0.957),  time:62.933, tt:5034.654\n",
      "Ep:80, loss:0.00002, loss_test:0.07431, lr:8.60e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.932, tt:5097.506\n",
      "Ep:81, loss:0.00002, loss_test:0.07449, lr:8.51e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.935, tt:5160.654\n",
      "Ep:82, loss:0.00002, loss_test:0.07334, lr:8.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:62.914, tt:5221.882\n",
      "Ep:83, loss:0.00002, loss_test:0.07432, lr:8.35e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.895, tt:5283.222\n",
      "Ep:84, loss:0.00002, loss_test:0.07581, lr:8.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.880, tt:5344.792\n",
      "Ep:85, loss:0.00001, loss_test:0.07363, lr:8.18e-03, fs:0.78107 (r=0.667,p=0.943),  time:62.872, tt:5407.001\n",
      "Ep:86, loss:0.00001, loss_test:0.07503, lr:8.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.855, tt:5468.411\n",
      "Ep:87, loss:0.00001, loss_test:0.07701, lr:8.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.858, tt:5531.462\n",
      "Ep:88, loss:0.00001, loss_test:0.07509, lr:7.94e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.864, tt:5594.924\n",
      "Ep:89, loss:0.00001, loss_test:0.07646, lr:7.86e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.868, tt:5658.123\n",
      "Ep:90, loss:0.00001, loss_test:0.07468, lr:7.78e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.883, tt:5722.323\n",
      "Ep:91, loss:0.00001, loss_test:0.07804, lr:7.70e-03, fs:0.79762 (r=0.677,p=0.971),  time:62.892, tt:5786.055\n",
      "Ep:92, loss:0.00001, loss_test:0.07671, lr:7.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.880, tt:5847.866\n",
      "Ep:93, loss:0.00001, loss_test:0.07494, lr:7.55e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.856, tt:5908.427\n",
      "Ep:94, loss:0.00001, loss_test:0.07542, lr:7.47e-03, fs:0.77844 (r=0.657,p=0.956),  time:62.818, tt:5967.686\n",
      "Ep:95, loss:0.00001, loss_test:0.07718, lr:7.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.814, tt:6030.165\n",
      "Ep:96, loss:0.00001, loss_test:0.07522, lr:7.32e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.803, tt:6091.893\n",
      "Ep:97, loss:0.00001, loss_test:0.07647, lr:7.25e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.801, tt:6154.484\n",
      "Ep:98, loss:0.00001, loss_test:0.07607, lr:7.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.792, tt:6216.431\n",
      "Ep:99, loss:0.00001, loss_test:0.07635, lr:7.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.778, tt:6277.806\n",
      "Ep:100, loss:0.00001, loss_test:0.07597, lr:7.03e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.770, tt:6339.750\n",
      "Ep:101, loss:0.00001, loss_test:0.07561, lr:6.96e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.769, tt:6402.477\n",
      "Ep:102, loss:0.00001, loss_test:0.07575, lr:6.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.758, tt:6464.036\n",
      "Ep:103, loss:0.00001, loss_test:0.07817, lr:6.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.758, tt:6526.811\n",
      "Ep:104, loss:0.00001, loss_test:0.07710, lr:6.76e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.767, tt:6590.482\n",
      "Ep:105, loss:0.00001, loss_test:0.07619, lr:6.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.773, tt:6653.961\n",
      "Ep:106, loss:0.00001, loss_test:0.07583, lr:6.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.773, tt:6716.684\n",
      "Ep:107, loss:0.00001, loss_test:0.07697, lr:6.56e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.775, tt:6779.655\n",
      "Ep:108, loss:0.00001, loss_test:0.07577, lr:6.49e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.766, tt:6841.459\n",
      "Ep:109, loss:0.00001, loss_test:0.07637, lr:6.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.740, tt:6901.405\n",
      "Ep:110, loss:0.00001, loss_test:0.07716, lr:6.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.730, tt:6963.052\n",
      "Ep:111, loss:0.00001, loss_test:0.07669, lr:6.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.725, tt:7025.191\n",
      "Ep:112, loss:0.00001, loss_test:0.07630, lr:6.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:62.729, tt:7088.368\n",
      "Ep:113, loss:0.00001, loss_test:0.07734, lr:6.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.735, tt:7151.739\n",
      "Ep:114, loss:0.00001, loss_test:0.07595, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.739, tt:7215.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00001, loss_test:0.07694, lr:6.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.726, tt:7276.164\n",
      "Ep:116, loss:0.00001, loss_test:0.07852, lr:5.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.721, tt:7338.319\n",
      "Ep:117, loss:0.00001, loss_test:0.07640, lr:5.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.699, tt:7398.440\n",
      "Ep:118, loss:0.00001, loss_test:0.07737, lr:5.87e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.699, tt:7461.159\n",
      "Ep:119, loss:0.00001, loss_test:0.07768, lr:5.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.688, tt:7522.610\n",
      "Ep:120, loss:0.00001, loss_test:0.07674, lr:5.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.672, tt:7583.301\n",
      "Ep:121, loss:0.00001, loss_test:0.07772, lr:5.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.672, tt:7645.928\n",
      "Ep:122, loss:0.00001, loss_test:0.07653, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.663, tt:7707.527\n",
      "Ep:123, loss:0.00001, loss_test:0.07707, lr:5.58e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.668, tt:7770.794\n",
      "Ep:124, loss:0.00001, loss_test:0.07792, lr:5.53e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.670, tt:7833.793\n",
      "Ep:125, loss:0.00001, loss_test:0.07631, lr:5.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.666, tt:7895.956\n",
      "Ep:126, loss:0.00001, loss_test:0.07899, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.660, tt:7957.803\n",
      "Ep:127, loss:0.00001, loss_test:0.07744, lr:5.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.663, tt:8020.801\n",
      "Ep:128, loss:0.00001, loss_test:0.07790, lr:5.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.665, tt:8083.744\n",
      "Ep:129, loss:0.00001, loss_test:0.07685, lr:5.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.672, tt:8147.343\n",
      "Ep:130, loss:0.00001, loss_test:0.07815, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.668, tt:8209.458\n",
      "Ep:131, loss:0.00001, loss_test:0.07700, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.682, tt:8274.037\n",
      "Ep:132, loss:0.00001, loss_test:0.07727, lr:5.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.686, tt:8337.304\n",
      "Ep:133, loss:0.00001, loss_test:0.07756, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.689, tt:8400.284\n",
      "Ep:134, loss:0.00001, loss_test:0.07766, lr:5.00e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.699, tt:8464.367\n",
      "Ep:135, loss:0.00001, loss_test:0.07749, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.694, tt:8526.346\n",
      "Ep:136, loss:0.00001, loss_test:0.07751, lr:4.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.687, tt:8588.164\n",
      "Ep:137, loss:0.00001, loss_test:0.07816, lr:4.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.702, tt:8652.912\n",
      "Ep:138, loss:0.00001, loss_test:0.07700, lr:4.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.702, tt:8715.535\n",
      "Ep:139, loss:0.00001, loss_test:0.07828, lr:4.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.694, tt:8777.142\n",
      "Ep:140, loss:0.00001, loss_test:0.07768, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.718, tt:8843.233\n",
      "Ep:141, loss:0.00001, loss_test:0.07762, lr:4.66e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.747, tt:8910.107\n",
      "Ep:142, loss:0.00001, loss_test:0.07825, lr:4.61e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.771, tt:8976.263\n",
      "Ep:143, loss:0.00001, loss_test:0.07791, lr:4.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.805, tt:9043.870\n",
      "Ep:144, loss:0.00001, loss_test:0.07845, lr:4.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.834, tt:9110.953\n",
      "Ep:145, loss:0.00001, loss_test:0.07879, lr:4.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.845, tt:9175.348\n",
      "Ep:146, loss:0.00001, loss_test:0.07766, lr:4.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.855, tt:9239.711\n",
      "Ep:147, loss:0.00001, loss_test:0.07830, lr:4.39e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.880, tt:9306.259\n",
      "Ep:148, loss:0.00001, loss_test:0.07757, lr:4.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:62.905, tt:9372.833\n",
      "Ep:149, loss:0.00001, loss_test:0.07913, lr:4.30e-03, fs:0.78049 (r=0.646,p=0.985),  time:62.926, tt:9438.934\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 13\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14345, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:66.044, tt:66.044\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13874, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:65.691, tt:131.382\n",
      "Ep:2, loss:0.00051, loss_test:0.12956, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:61.824, tt:185.473\n",
      "Ep:3, loss:0.00046, loss_test:0.12365, lr:1.00e-02, fs:0.61290 (r=0.576,p=0.655),  time:59.849, tt:239.395\n",
      "Ep:4, loss:0.00043, loss_test:0.11829, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:59.978, tt:299.890\n",
      "Ep:5, loss:0.00041, loss_test:0.11640, lr:1.00e-02, fs:0.66000 (r=0.667,p=0.653),  time:59.869, tt:359.216\n",
      "Ep:6, loss:0.00039, loss_test:0.11208, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:60.644, tt:424.506\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00037, loss_test:0.11100, lr:1.00e-02, fs:0.64948 (r=0.636,p=0.663),  time:61.094, tt:488.749\n",
      "Ep:8, loss:0.00035, loss_test:0.10736, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:61.718, tt:555.465\n",
      "Ep:9, loss:0.00034, loss_test:0.10445, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:61.836, tt:618.365\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.10296, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:62.342, tt:685.763\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.10048, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:62.410, tt:748.921\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.10033, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:62.561, tt:813.299\n",
      "Ep:13, loss:0.00029, loss_test:0.09753, lr:1.00e-02, fs:0.71204 (r=0.687,p=0.739),  time:62.700, tt:877.798\n",
      "Ep:14, loss:0.00028, loss_test:0.09630, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:62.697, tt:940.449\n",
      "Ep:15, loss:0.00026, loss_test:0.09561, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:62.575, tt:1001.201\n",
      "Ep:16, loss:0.00025, loss_test:0.09421, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:62.483, tt:1062.205\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.09393, lr:1.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:62.507, tt:1125.135\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.09251, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:62.433, tt:1186.232\n",
      "Ep:19, loss:0.00022, loss_test:0.09241, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:62.298, tt:1245.968\n",
      "Ep:20, loss:0.00021, loss_test:0.09247, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:62.254, tt:1307.328\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.09153, lr:1.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:62.238, tt:1369.237\n",
      "Ep:22, loss:0.00020, loss_test:0.08954, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:62.379, tt:1434.728\n",
      "Ep:23, loss:0.00019, loss_test:0.08888, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:62.450, tt:1498.796\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.08974, lr:1.00e-02, fs:0.75000 (r=0.667,p=0.857),  time:62.555, tt:1563.868\n",
      "Ep:25, loss:0.00017, loss_test:0.08800, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:62.656, tt:1629.064\n",
      "Ep:26, loss:0.00016, loss_test:0.08642, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:62.742, tt:1694.047\n",
      "Ep:27, loss:0.00016, loss_test:0.08628, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:62.735, tt:1756.586\n",
      "Ep:28, loss:0.00015, loss_test:0.08796, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:62.861, tt:1822.969\n",
      "Ep:29, loss:0.00014, loss_test:0.08766, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:62.908, tt:1887.249\n",
      "Ep:30, loss:0.00013, loss_test:0.08415, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:63.022, tt:1953.695\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08612, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:63.134, tt:2020.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00012, loss_test:0.08878, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.266, tt:2087.766\n",
      "Ep:33, loss:0.00012, loss_test:0.09053, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.348, tt:2153.829\n",
      "Ep:34, loss:0.00011, loss_test:0.08781, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:63.411, tt:2219.368\n",
      "Ep:35, loss:0.00011, loss_test:0.08104, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:63.463, tt:2284.667\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08460, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.496, tt:2349.340\n",
      "Ep:37, loss:0.00010, loss_test:0.08677, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.478, tt:2412.175\n",
      "Ep:38, loss:0.00009, loss_test:0.08531, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.509, tt:2476.838\n",
      "Ep:39, loss:0.00009, loss_test:0.08174, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.548, tt:2541.917\n",
      "Ep:40, loss:0.00009, loss_test:0.08542, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.580, tt:2606.767\n",
      "Ep:41, loss:0.00008, loss_test:0.08920, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.629, tt:2672.423\n",
      "Ep:42, loss:0.00008, loss_test:0.09243, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.651, tt:2737.007\n",
      "Ep:43, loss:0.00008, loss_test:0.08341, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.712, tt:2803.331\n",
      "Ep:44, loss:0.00007, loss_test:0.08225, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.751, tt:2868.782\n",
      "Ep:45, loss:0.00007, loss_test:0.09098, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:63.759, tt:2932.913\n",
      "Ep:46, loss:0.00007, loss_test:0.08756, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:63.783, tt:2997.786\n",
      "Ep:47, loss:0.00007, loss_test:0.08259, lr:9.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:63.826, tt:3063.625\n",
      "Ep:48, loss:0.00006, loss_test:0.09137, lr:9.80e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.849, tt:3128.599\n",
      "Ep:49, loss:0.00006, loss_test:0.09182, lr:9.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.854, tt:3192.698\n",
      "Ep:50, loss:0.00006, loss_test:0.08531, lr:9.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:63.851, tt:3256.401\n",
      "Ep:51, loss:0.00006, loss_test:0.08663, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:63.855, tt:3320.467\n",
      "Ep:52, loss:0.00005, loss_test:0.08851, lr:9.41e-03, fs:0.76471 (r=0.657,p=0.915),  time:63.871, tt:3385.182\n",
      "Ep:53, loss:0.00005, loss_test:0.09017, lr:9.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.879, tt:3449.460\n",
      "Ep:54, loss:0.00005, loss_test:0.08673, lr:9.23e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.934, tt:3516.383\n",
      "Ep:55, loss:0.00005, loss_test:0.09380, lr:9.14e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.953, tt:3581.346\n",
      "Ep:56, loss:0.00005, loss_test:0.08811, lr:9.04e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.987, tt:3647.257\n",
      "Ep:57, loss:0.00004, loss_test:0.08988, lr:8.95e-03, fs:0.76923 (r=0.657,p=0.929),  time:63.983, tt:3711.019\n",
      "Ep:58, loss:0.00004, loss_test:0.09380, lr:8.86e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.007, tt:3776.403\n",
      "Ep:59, loss:0.00004, loss_test:0.09183, lr:8.78e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.038, tt:3842.262\n",
      "Ep:60, loss:0.00004, loss_test:0.09355, lr:8.69e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.105, tt:3910.389\n",
      "Ep:61, loss:0.00004, loss_test:0.08924, lr:8.60e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.132, tt:3976.177\n",
      "Ep:62, loss:0.00004, loss_test:0.09647, lr:8.51e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.161, tt:4042.145\n",
      "Ep:63, loss:0.00004, loss_test:0.08958, lr:8.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.192, tt:4108.281\n",
      "Ep:64, loss:0.00004, loss_test:0.09140, lr:8.35e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.222, tt:4174.440\n",
      "Ep:65, loss:0.00003, loss_test:0.09679, lr:8.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.257, tt:4240.995\n",
      "Ep:66, loss:0.00003, loss_test:0.09373, lr:8.18e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.301, tt:4308.189\n",
      "Ep:67, loss:0.00003, loss_test:0.09229, lr:8.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.361, tt:4376.536\n",
      "Ep:68, loss:0.00003, loss_test:0.09316, lr:8.02e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.359, tt:4440.771\n",
      "Ep:69, loss:0.00003, loss_test:0.09361, lr:7.94e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.383, tt:4506.806\n",
      "Ep:70, loss:0.00003, loss_test:0.09353, lr:7.86e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.418, tt:4573.676\n",
      "Ep:71, loss:0.00003, loss_test:0.09672, lr:7.78e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.425, tt:4638.620\n",
      "Ep:72, loss:0.00003, loss_test:0.09739, lr:7.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.405, tt:4701.547\n",
      "Ep:73, loss:0.00003, loss_test:0.09296, lr:7.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.426, tt:4767.502\n",
      "Ep:74, loss:0.00003, loss_test:0.09296, lr:7.55e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.430, tt:4832.229\n",
      "Ep:75, loss:0.00003, loss_test:0.09383, lr:7.47e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.408, tt:4895.027\n",
      "Ep:76, loss:0.00002, loss_test:0.09830, lr:7.40e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.414, tt:4959.906\n",
      "Ep:77, loss:0.00002, loss_test:0.09769, lr:7.32e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.436, tt:5025.977\n",
      "Ep:78, loss:0.00002, loss_test:0.09340, lr:7.25e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.463, tt:5092.588\n",
      "Ep:79, loss:0.00002, loss_test:0.09447, lr:7.18e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.488, tt:5159.017\n",
      "Ep:80, loss:0.00002, loss_test:0.09894, lr:7.11e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.504, tt:5224.816\n",
      "Ep:81, loss:0.00002, loss_test:0.09517, lr:7.03e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.524, tt:5290.995\n",
      "Ep:82, loss:0.00002, loss_test:0.09603, lr:6.96e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.515, tt:5354.758\n",
      "Ep:83, loss:0.00002, loss_test:0.09772, lr:6.89e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.523, tt:5419.939\n",
      "Ep:84, loss:0.00002, loss_test:0.09554, lr:6.83e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.545, tt:5486.299\n",
      "Ep:85, loss:0.00002, loss_test:0.09578, lr:6.76e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.549, tt:5551.187\n",
      "Ep:86, loss:0.00002, loss_test:0.09629, lr:6.69e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.536, tt:5614.674\n",
      "Ep:87, loss:0.00002, loss_test:0.09503, lr:6.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.536, tt:5679.185\n",
      "Ep:88, loss:0.00002, loss_test:0.09970, lr:6.56e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.534, tt:5743.564\n",
      "Ep:89, loss:0.00002, loss_test:0.09572, lr:6.49e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.559, tt:5810.336\n",
      "Ep:90, loss:0.00002, loss_test:0.09610, lr:6.43e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.575, tt:5876.343\n",
      "Ep:91, loss:0.00002, loss_test:0.09769, lr:6.36e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.579, tt:5941.298\n",
      "Ep:92, loss:0.00002, loss_test:0.09650, lr:6.30e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.568, tt:6004.815\n",
      "Ep:93, loss:0.00002, loss_test:0.09712, lr:6.24e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.580, tt:6070.522\n",
      "Ep:94, loss:0.00002, loss_test:0.09649, lr:6.17e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.566, tt:6133.724\n",
      "Ep:95, loss:0.00002, loss_test:0.09702, lr:6.11e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.575, tt:6199.179\n",
      "Ep:96, loss:0.00002, loss_test:0.09753, lr:6.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.573, tt:6263.563\n",
      "Ep:97, loss:0.00002, loss_test:0.09698, lr:5.99e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.565, tt:6327.414\n",
      "Ep:98, loss:0.00002, loss_test:0.09766, lr:5.93e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.541, tt:6389.572\n",
      "Ep:99, loss:0.00002, loss_test:0.09768, lr:5.87e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.533, tt:6453.282\n",
      "Ep:100, loss:0.00002, loss_test:0.09786, lr:5.81e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.553, tt:6519.816\n",
      "Ep:101, loss:0.00002, loss_test:0.09728, lr:5.75e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.534, tt:6582.495\n",
      "Ep:102, loss:0.00001, loss_test:0.09741, lr:5.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.538, tt:6647.437\n",
      "Ep:103, loss:0.00001, loss_test:0.09680, lr:5.64e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.526, tt:6710.688\n",
      "Ep:104, loss:0.00001, loss_test:0.09906, lr:5.58e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.543, tt:6777.046\n",
      "Ep:105, loss:0.00001, loss_test:0.09680, lr:5.53e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.547, tt:6841.973\n",
      "Ep:106, loss:0.00001, loss_test:0.09621, lr:5.47e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.558, tt:6907.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:107, loss:0.00001, loss_test:0.09954, lr:5.42e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.574, tt:6973.995\n",
      "Ep:108, loss:0.00001, loss_test:0.09963, lr:5.36e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.576, tt:7038.748\n",
      "Ep:109, loss:0.00001, loss_test:0.09735, lr:5.31e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.568, tt:7102.526\n",
      "Ep:110, loss:0.00001, loss_test:0.10052, lr:5.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.567, tt:7166.893\n",
      "Ep:111, loss:0.00001, loss_test:0.09717, lr:5.20e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.565, tt:7231.244\n",
      "Ep:112, loss:0.00001, loss_test:0.09812, lr:5.15e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.581, tt:7297.681\n",
      "Ep:113, loss:0.00001, loss_test:0.09844, lr:5.10e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.582, tt:7362.357\n",
      "Ep:114, loss:0.00001, loss_test:0.09864, lr:5.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.573, tt:7425.929\n",
      "Ep:115, loss:0.00001, loss_test:0.09695, lr:5.00e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.581, tt:7491.361\n",
      "Ep:116, loss:0.00001, loss_test:0.09863, lr:4.95e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.598, tt:7558.003\n",
      "Ep:117, loss:0.00001, loss_test:0.09824, lr:4.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.594, tt:7622.080\n",
      "Ep:118, loss:0.00001, loss_test:0.09838, lr:4.85e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.593, tt:7686.624\n",
      "Ep:119, loss:0.00001, loss_test:0.09839, lr:4.80e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.579, tt:7749.467\n",
      "Ep:120, loss:0.00001, loss_test:0.09844, lr:4.75e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.574, tt:7813.395\n",
      "Ep:121, loss:0.00001, loss_test:0.09960, lr:4.71e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.569, tt:7877.358\n",
      "Ep:122, loss:0.00001, loss_test:0.09828, lr:4.66e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.567, tt:7941.720\n",
      "Ep:123, loss:0.00001, loss_test:0.10002, lr:4.61e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.558, tt:8005.211\n",
      "Ep:124, loss:0.00001, loss_test:0.09798, lr:4.57e-03, fs:0.76923 (r=0.657,p=0.929),  time:64.570, tt:8071.262\n",
      "Ep:125, loss:0.00001, loss_test:0.09946, lr:4.52e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.567, tt:8135.393\n",
      "Ep:126, loss:0.00001, loss_test:0.09832, lr:4.48e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.579, tt:8201.569\n",
      "Ep:127, loss:0.00001, loss_test:0.09895, lr:4.43e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.580, tt:8266.253\n",
      "Ep:128, loss:0.00001, loss_test:0.09924, lr:4.39e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.588, tt:8331.801\n",
      "Ep:129, loss:0.00001, loss_test:0.09884, lr:4.34e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.573, tt:8394.460\n",
      "Ep:130, loss:0.00001, loss_test:0.09878, lr:4.30e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.577, tt:8459.524\n",
      "Ep:131, loss:0.00001, loss_test:0.10010, lr:4.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.578, tt:8524.336\n",
      "Ep:132, loss:0.00001, loss_test:0.09923, lr:4.21e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.576, tt:8588.631\n",
      "Ep:133, loss:0.00001, loss_test:0.09871, lr:4.17e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.564, tt:8651.630\n",
      "Ep:134, loss:0.00001, loss_test:0.09943, lr:4.13e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.567, tt:8716.564\n",
      "Ep:135, loss:0.00001, loss_test:0.10002, lr:4.09e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.557, tt:8779.699\n",
      "Ep:136, loss:0.00001, loss_test:0.09975, lr:4.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.541, tt:8842.113\n",
      "Ep:137, loss:0.00001, loss_test:0.10091, lr:4.01e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.525, tt:8904.498\n",
      "Ep:140, loss:0.00001, loss_test:0.09853, lr:3.89e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.491, tt:9093.253\n",
      "Ep:141, loss:0.00001, loss_test:0.10095, lr:3.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.494, tt:9158.111\n",
      "Ep:142, loss:0.00001, loss_test:0.09917, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.477, tt:9220.139\n",
      "Ep:143, loss:0.00001, loss_test:0.10051, lr:3.77e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.464, tt:9282.818\n",
      "Ep:144, loss:0.00001, loss_test:0.09924, lr:3.73e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.438, tt:9343.497\n",
      "Ep:145, loss:0.00001, loss_test:0.09977, lr:3.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.446, tt:9409.060\n",
      "Ep:146, loss:0.00001, loss_test:0.10034, lr:3.66e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.448, tt:9473.880\n",
      "Ep:147, loss:0.00001, loss_test:0.09968, lr:3.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.422, tt:9534.439\n",
      "Ep:148, loss:0.00001, loss_test:0.10156, lr:3.59e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.422, tt:9598.856\n",
      "Ep:149, loss:0.00001, loss_test:0.09950, lr:3.55e-03, fs:0.77381 (r=0.657,p=0.942),  time:64.411, tt:9661.592\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 14\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:1, loss:0.00054, loss_test:0.13577, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:62.592, tt:125.184\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.12416, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:60.125, tt:180.376\n",
      "Ep:3, loss:0.00046, loss_test:0.11856, lr:1.00e-02, fs:0.62000 (r=0.626,p=0.614),  time:58.856, tt:235.423\n",
      "Ep:4, loss:0.00044, loss_test:0.11484, lr:1.00e-02, fs:0.62673 (r=0.687,p=0.576),  time:58.961, tt:294.804\n",
      "Ep:5, loss:0.00042, loss_test:0.10986, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:58.689, tt:352.135\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.10667, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:58.689, tt:410.821\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.10299, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:59.162, tt:473.294\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.10060, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:59.759, tt:537.828\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09923, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:60.196, tt:601.958\n",
      "Ep:10, loss:0.00033, loss_test:0.09761, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:60.608, tt:666.690\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.09634, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:60.992, tt:731.899\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.09491, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:61.120, tt:794.560\n",
      "Ep:13, loss:0.00029, loss_test:0.09293, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:61.308, tt:858.308\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00028, loss_test:0.09253, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:61.494, tt:922.414\n",
      "Ep:15, loss:0.00027, loss_test:0.09182, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:61.501, tt:984.017\n",
      "Ep:16, loss:0.00025, loss_test:0.09146, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:61.544, tt:1046.256\n",
      "Ep:17, loss:0.00024, loss_test:0.09263, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:61.657, tt:1109.825\n",
      "Ep:18, loss:0.00023, loss_test:0.09235, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:61.745, tt:1173.155\n",
      "Ep:19, loss:0.00022, loss_test:0.09233, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:61.862, tt:1237.237\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.09200, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:61.896, tt:1299.826\n",
      "Ep:21, loss:0.00020, loss_test:0.09220, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:61.915, tt:1362.129\n",
      "Ep:22, loss:0.00019, loss_test:0.09221, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:61.964, tt:1425.163\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.09134, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:62.035, tt:1488.845\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09383, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:62.040, tt:1550.990\n",
      "Ep:25, loss:0.00016, loss_test:0.09524, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:62.182, tt:1616.723\n",
      "Ep:26, loss:0.00015, loss_test:0.09648, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:62.191, tt:1679.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00014, loss_test:0.09629, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:62.283, tt:1743.937\n",
      "Ep:28, loss:0.00013, loss_test:0.09603, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:62.298, tt:1806.649\n",
      "Ep:29, loss:0.00013, loss_test:0.09487, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:62.311, tt:1869.341\n",
      "Ep:30, loss:0.00012, loss_test:0.09541, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:62.298, tt:1931.234\n",
      "Ep:31, loss:0.00011, loss_test:0.09665, lr:1.00e-02, fs:0.79042 (r=0.667,p=0.971),  time:62.343, tt:1994.989\n",
      "Ep:32, loss:0.00011, loss_test:0.09745, lr:1.00e-02, fs:0.77576 (r=0.646,p=0.970),  time:62.287, tt:2055.459\n",
      "Ep:33, loss:0.00010, loss_test:0.09693, lr:1.00e-02, fs:0.81176 (r=0.697,p=0.972),  time:62.316, tt:2118.746\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.10342, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:62.363, tt:2182.690\n",
      "Ep:35, loss:0.00009, loss_test:0.10494, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:62.427, tt:2247.381\n",
      "Ep:36, loss:0.00009, loss_test:0.10048, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:62.473, tt:2311.504\n",
      "Ep:37, loss:0.00008, loss_test:0.10100, lr:1.00e-02, fs:0.77576 (r=0.646,p=0.970),  time:62.542, tt:2376.583\n",
      "Ep:38, loss:0.00008, loss_test:0.10004, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:62.532, tt:2438.730\n",
      "Ep:39, loss:0.00007, loss_test:0.10244, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:62.566, tt:2502.638\n",
      "Ep:40, loss:0.00007, loss_test:0.10393, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:62.659, tt:2569.006\n",
      "Ep:41, loss:0.00007, loss_test:0.10279, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:62.656, tt:2631.553\n",
      "Ep:42, loss:0.00006, loss_test:0.10335, lr:1.00e-02, fs:0.74074 (r=0.606,p=0.952),  time:62.672, tt:2694.916\n",
      "Ep:43, loss:0.00006, loss_test:0.10819, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:62.723, tt:2759.819\n",
      "Ep:44, loss:0.00006, loss_test:0.10399, lr:1.00e-02, fs:0.72840 (r=0.596,p=0.937),  time:62.714, tt:2822.122\n",
      "Ep:45, loss:0.00005, loss_test:0.10703, lr:9.90e-03, fs:0.71698 (r=0.576,p=0.950),  time:62.721, tt:2885.158\n",
      "Ep:46, loss:0.00005, loss_test:0.10517, lr:9.80e-03, fs:0.73171 (r=0.606,p=0.923),  time:62.750, tt:2949.238\n",
      "Ep:47, loss:0.00005, loss_test:0.10388, lr:9.70e-03, fs:0.72393 (r=0.596,p=0.922),  time:62.724, tt:3010.729\n",
      "Ep:48, loss:0.00005, loss_test:0.10127, lr:9.61e-03, fs:0.72393 (r=0.596,p=0.922),  time:62.729, tt:3073.713\n",
      "Ep:49, loss:0.00005, loss_test:0.10517, lr:9.51e-03, fs:0.69182 (r=0.556,p=0.917),  time:62.738, tt:3136.876\n",
      "Ep:50, loss:0.00004, loss_test:0.10896, lr:9.41e-03, fs:0.70440 (r=0.566,p=0.933),  time:62.695, tt:3197.447\n",
      "Ep:51, loss:0.00004, loss_test:0.10811, lr:9.32e-03, fs:0.70064 (r=0.556,p=0.948),  time:62.712, tt:3261.033\n",
      "Ep:52, loss:0.00004, loss_test:0.10429, lr:9.23e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.706, tt:3323.444\n",
      "Ep:53, loss:0.00004, loss_test:0.10625, lr:9.14e-03, fs:0.68790 (r=0.545,p=0.931),  time:62.694, tt:3385.483\n",
      "Ep:54, loss:0.00004, loss_test:0.11046, lr:9.04e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.693, tt:3448.106\n",
      "Ep:55, loss:0.00004, loss_test:0.10835, lr:8.95e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.660, tt:3508.985\n",
      "Ep:56, loss:0.00003, loss_test:0.10563, lr:8.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.647, tt:3570.876\n",
      "Ep:57, loss:0.00003, loss_test:0.10532, lr:8.78e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.631, tt:3632.607\n",
      "Ep:58, loss:0.00003, loss_test:0.11487, lr:8.69e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.660, tt:3696.913\n",
      "Ep:59, loss:0.00003, loss_test:0.11037, lr:8.60e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.646, tt:3758.758\n",
      "Ep:60, loss:0.00003, loss_test:0.11078, lr:8.51e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.650, tt:3821.636\n",
      "Ep:61, loss:0.00003, loss_test:0.11032, lr:8.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.661, tt:3884.987\n",
      "Ep:62, loss:0.00003, loss_test:0.11322, lr:8.35e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.677, tt:3948.679\n",
      "Ep:63, loss:0.00003, loss_test:0.11279, lr:8.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.685, tt:4011.839\n",
      "Ep:64, loss:0.00003, loss_test:0.11064, lr:8.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:62.679, tt:4074.110\n",
      "Ep:65, loss:0.00003, loss_test:0.11390, lr:8.10e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.695, tt:4137.902\n",
      "Ep:66, loss:0.00002, loss_test:0.11357, lr:8.02e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.713, tt:4201.793\n",
      "Ep:67, loss:0.00002, loss_test:0.11516, lr:7.94e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.713, tt:4264.516\n",
      "Ep:68, loss:0.00002, loss_test:0.11350, lr:7.86e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.718, tt:4327.519\n",
      "Ep:69, loss:0.00002, loss_test:0.11362, lr:7.78e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.715, tt:4390.046\n",
      "Ep:70, loss:0.00002, loss_test:0.11536, lr:7.70e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.735, tt:4454.197\n",
      "Ep:71, loss:0.00002, loss_test:0.11414, lr:7.62e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.746, tt:4517.680\n",
      "Ep:72, loss:0.00002, loss_test:0.11384, lr:7.55e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.765, tt:4581.866\n",
      "Ep:73, loss:0.00002, loss_test:0.11665, lr:7.47e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.781, tt:4645.790\n",
      "Ep:74, loss:0.00002, loss_test:0.11263, lr:7.40e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.809, tt:4710.640\n",
      "Ep:75, loss:0.00002, loss_test:0.11595, lr:7.32e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.824, tt:4774.615\n",
      "Ep:76, loss:0.00002, loss_test:0.11686, lr:7.25e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.902, tt:4843.462\n",
      "Ep:77, loss:0.00002, loss_test:0.11681, lr:7.18e-03, fs:0.69677 (r=0.545,p=0.964),  time:62.960, tt:4910.865\n",
      "Ep:78, loss:0.00002, loss_test:0.11616, lr:7.11e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.034, tt:4979.725\n",
      "Ep:79, loss:0.00002, loss_test:0.11656, lr:7.03e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.083, tt:5046.653\n",
      "Ep:80, loss:0.00002, loss_test:0.11428, lr:6.96e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.159, tt:5115.851\n",
      "Ep:81, loss:0.00002, loss_test:0.11824, lr:6.89e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.231, tt:5184.902\n",
      "Ep:82, loss:0.00002, loss_test:0.11501, lr:6.83e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.266, tt:5251.077\n",
      "Ep:83, loss:0.00002, loss_test:0.11674, lr:6.76e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.352, tt:5321.550\n",
      "Ep:84, loss:0.00001, loss_test:0.11582, lr:6.69e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.414, tt:5390.190\n",
      "Ep:85, loss:0.00001, loss_test:0.11855, lr:6.62e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.459, tt:5457.464\n",
      "Ep:86, loss:0.00001, loss_test:0.11575, lr:6.56e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.507, tt:5525.123\n",
      "Ep:87, loss:0.00001, loss_test:0.11807, lr:6.49e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.555, tt:5592.846\n",
      "Ep:88, loss:0.00001, loss_test:0.12050, lr:6.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.593, tt:5659.788\n",
      "Ep:89, loss:0.00001, loss_test:0.11699, lr:6.36e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.645, tt:5728.016\n",
      "Ep:90, loss:0.00001, loss_test:0.11744, lr:6.30e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.707, tt:5797.371\n",
      "Ep:91, loss:0.00001, loss_test:0.11854, lr:6.24e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.738, tt:5863.905\n",
      "Ep:92, loss:0.00001, loss_test:0.11801, lr:6.17e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.786, tt:5932.140\n",
      "Ep:93, loss:0.00001, loss_test:0.11800, lr:6.11e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.823, tt:5999.348\n",
      "Ep:94, loss:0.00001, loss_test:0.11753, lr:6.05e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.893, tt:6069.868\n",
      "Ep:95, loss:0.00001, loss_test:0.11829, lr:5.99e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.933, tt:6137.551\n",
      "Ep:96, loss:0.00001, loss_test:0.11909, lr:5.93e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.977, tt:6205.749\n",
      "Ep:97, loss:0.00001, loss_test:0.11965, lr:5.87e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.992, tt:6271.170\n",
      "Ep:98, loss:0.00001, loss_test:0.11847, lr:5.81e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.041, tt:6340.063\n",
      "Ep:99, loss:0.00001, loss_test:0.12060, lr:5.75e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.075, tt:6407.490\n",
      "Ep:100, loss:0.00001, loss_test:0.11899, lr:5.70e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.101, tt:6474.192\n",
      "Ep:101, loss:0.00001, loss_test:0.12041, lr:5.64e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.159, tt:6544.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:102, loss:0.00001, loss_test:0.11862, lr:5.58e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.202, tt:6612.760\n",
      "Ep:103, loss:0.00001, loss_test:0.12043, lr:5.53e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.254, tt:6682.435\n",
      "Ep:104, loss:0.00001, loss_test:0.11825, lr:5.47e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.296, tt:6751.102\n",
      "Ep:105, loss:0.00001, loss_test:0.11976, lr:5.42e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.358, tt:6821.901\n",
      "Ep:106, loss:0.00001, loss_test:0.11874, lr:5.36e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.408, tt:6891.694\n",
      "Ep:107, loss:0.00001, loss_test:0.12068, lr:5.31e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.453, tt:6960.929\n",
      "Ep:108, loss:0.00001, loss_test:0.11977, lr:5.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.482, tt:7028.542\n",
      "Ep:109, loss:0.00001, loss_test:0.12016, lr:5.20e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.512, tt:7096.370\n",
      "Ep:110, loss:0.00001, loss_test:0.12024, lr:5.15e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.547, tt:7164.712\n",
      "Ep:111, loss:0.00001, loss_test:0.11941, lr:5.10e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.562, tt:7230.924\n",
      "Ep:112, loss:0.00001, loss_test:0.12163, lr:5.05e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.587, tt:7298.355\n",
      "Ep:113, loss:0.00001, loss_test:0.12070, lr:5.00e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.621, tt:7366.749\n",
      "Ep:114, loss:0.00001, loss_test:0.12217, lr:4.95e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.645, tt:7434.119\n",
      "Ep:115, loss:0.00001, loss_test:0.11981, lr:4.90e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.672, tt:7501.901\n",
      "Ep:116, loss:0.00001, loss_test:0.12136, lr:4.85e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.707, tt:7570.736\n",
      "Ep:117, loss:0.00001, loss_test:0.12021, lr:4.80e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.733, tt:7638.444\n",
      "Ep:118, loss:0.00001, loss_test:0.12115, lr:4.75e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.776, tt:7708.346\n",
      "Ep:119, loss:0.00001, loss_test:0.12034, lr:4.71e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.790, tt:7774.777\n",
      "Ep:120, loss:0.00001, loss_test:0.12151, lr:4.66e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.815, tt:7842.652\n",
      "Ep:121, loss:0.00001, loss_test:0.12109, lr:4.61e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.834, tt:7909.779\n",
      "Ep:122, loss:0.00001, loss_test:0.12164, lr:4.57e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.859, tt:7977.673\n",
      "Ep:123, loss:0.00001, loss_test:0.12173, lr:4.52e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.877, tt:8044.696\n",
      "Ep:124, loss:0.00001, loss_test:0.12064, lr:4.48e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.905, tt:8113.091\n",
      "Ep:125, loss:0.00001, loss_test:0.12143, lr:4.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.921, tt:8180.042\n",
      "Ep:126, loss:0.00001, loss_test:0.12276, lr:4.39e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.957, tt:8249.544\n",
      "Ep:127, loss:0.00001, loss_test:0.12094, lr:4.34e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.958, tt:8314.663\n",
      "Ep:128, loss:0.00001, loss_test:0.12271, lr:4.30e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.951, tt:8378.634\n",
      "Ep:129, loss:0.00001, loss_test:0.12150, lr:4.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.973, tt:8446.532\n",
      "Ep:130, loss:0.00001, loss_test:0.12201, lr:4.21e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.989, tt:8513.615\n",
      "Ep:131, loss:0.00001, loss_test:0.12203, lr:4.17e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.031, tt:8584.064\n",
      "Ep:132, loss:0.00001, loss_test:0.12163, lr:4.13e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.072, tt:8654.566\n",
      "Ep:133, loss:0.00001, loss_test:0.12355, lr:4.09e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.097, tt:8723.048\n",
      "Ep:134, loss:0.00001, loss_test:0.12319, lr:4.05e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.125, tt:8791.826\n",
      "Ep:135, loss:0.00001, loss_test:0.12287, lr:4.01e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.160, tt:8861.743\n",
      "Ep:136, loss:0.00001, loss_test:0.12286, lr:3.97e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.205, tt:8933.048\n",
      "Ep:137, loss:0.00001, loss_test:0.12254, lr:3.93e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.246, tt:9003.986\n",
      "Ep:138, loss:0.00001, loss_test:0.12268, lr:3.89e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.280, tt:9073.985\n",
      "Ep:139, loss:0.00001, loss_test:0.12348, lr:3.85e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.334, tt:9146.753\n",
      "Ep:140, loss:0.00001, loss_test:0.12288, lr:3.81e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.349, tt:9214.276\n",
      "Ep:141, loss:0.00001, loss_test:0.12345, lr:3.77e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.384, tt:9284.572\n",
      "Ep:142, loss:0.00001, loss_test:0.12326, lr:3.73e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.400, tt:9352.207\n",
      "Ep:144, loss:0.00001, loss_test:0.12314, lr:3.66e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.457, tt:9491.212\n",
      "Ep:145, loss:0.00001, loss_test:0.12416, lr:3.62e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.493, tt:9562.021\n",
      "Ep:146, loss:0.00001, loss_test:0.12355, lr:3.59e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.513, tt:9630.436\n",
      "Ep:147, loss:0.00001, loss_test:0.12482, lr:3.55e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.543, tt:9700.342\n",
      "Ep:148, loss:0.00001, loss_test:0.12367, lr:3.52e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.565, tt:9769.154\n",
      "Ep:149, loss:0.00001, loss_test:0.12475, lr:3.48e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.591, tt:9838.662\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 15\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14278, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:70.977, tt:70.977\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13834, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:70.988, tt:141.975\n",
      "Ep:2, loss:0.00052, loss_test:0.12814, lr:1.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:70.571, tt:211.714\n",
      "Ep:3, loss:0.00048, loss_test:0.11736, lr:1.00e-02, fs:0.64151 (r=0.687,p=0.602),  time:68.150, tt:272.601\n",
      "Ep:4, loss:0.00044, loss_test:0.11515, lr:1.00e-02, fs:0.66957 (r=0.778,p=0.588),  time:64.869, tt:324.347\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.11103, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:64.815, tt:388.888\n",
      "Ep:6, loss:0.00040, loss_test:0.10853, lr:1.00e-02, fs:0.64220 (r=0.707,p=0.588),  time:63.516, tt:444.612\n",
      "Ep:7, loss:0.00038, loss_test:0.10426, lr:1.00e-02, fs:0.66341 (r=0.687,p=0.642),  time:63.124, tt:504.992\n",
      "Ep:8, loss:0.00037, loss_test:0.10377, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:62.715, tt:564.434\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.10078, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:62.775, tt:627.748\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.09905, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:62.891, tt:691.801\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.09733, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:62.993, tt:755.917\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.09563, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:63.036, tt:819.465\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.09399, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:63.129, tt:883.806\n",
      "Ep:14, loss:0.00029, loss_test:0.09217, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:63.251, tt:948.765\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.09046, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:63.334, tt:1013.337\n",
      "Ep:16, loss:0.00027, loss_test:0.08939, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:63.291, tt:1075.953\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.08950, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:63.181, tt:1137.250\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.08630, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:63.113, tt:1199.141\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.08944, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:63.119, tt:1262.382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00023, loss_test:0.08281, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:63.119, tt:1325.505\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.08421, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:63.250, tt:1391.507\n",
      "Ep:22, loss:0.00021, loss_test:0.08423, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:63.267, tt:1455.138\n",
      "Ep:23, loss:0.00020, loss_test:0.08039, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:63.495, tt:1523.878\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.08208, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:63.694, tt:1592.361\n",
      "Ep:25, loss:0.00018, loss_test:0.07986, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:63.637, tt:1654.558\n",
      "Ep:26, loss:0.00017, loss_test:0.07865, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:63.671, tt:1719.113\n",
      "Ep:27, loss:0.00016, loss_test:0.07800, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:63.615, tt:1781.225\n",
      "Ep:28, loss:0.00015, loss_test:0.07900, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:63.648, tt:1845.806\n",
      "Ep:29, loss:0.00014, loss_test:0.07990, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:63.308, tt:1899.253\n",
      "Ep:30, loss:0.00014, loss_test:0.08063, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:62.956, tt:1951.648\n",
      "Ep:31, loss:0.00013, loss_test:0.07858, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:62.658, tt:2005.066\n",
      "Ep:32, loss:0.00012, loss_test:0.07755, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:62.313, tt:2056.325\n",
      "Ep:33, loss:0.00012, loss_test:0.07699, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:62.101, tt:2111.440\n",
      "Ep:34, loss:0.00011, loss_test:0.07944, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:61.900, tt:2166.514\n",
      "Ep:35, loss:0.00011, loss_test:0.07965, lr:9.90e-03, fs:0.75556 (r=0.687,p=0.840),  time:61.816, tt:2225.381\n",
      "Ep:36, loss:0.00010, loss_test:0.07447, lr:9.80e-03, fs:0.84694 (r=0.838,p=0.856),  time:61.711, tt:2283.297\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07409, lr:9.80e-03, fs:0.84694 (r=0.838,p=0.856),  time:61.638, tt:2342.257\n",
      "Ep:38, loss:0.00009, loss_test:0.07796, lr:9.80e-03, fs:0.76404 (r=0.687,p=0.861),  time:61.591, tt:2402.031\n",
      "Ep:39, loss:0.00009, loss_test:0.07730, lr:9.80e-03, fs:0.78453 (r=0.717,p=0.866),  time:61.491, tt:2459.648\n",
      "Ep:40, loss:0.00008, loss_test:0.07407, lr:9.80e-03, fs:0.81915 (r=0.778,p=0.865),  time:61.434, tt:2518.775\n",
      "Ep:41, loss:0.00008, loss_test:0.07460, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:61.299, tt:2574.562\n",
      "Ep:42, loss:0.00008, loss_test:0.07634, lr:9.80e-03, fs:0.77778 (r=0.707,p=0.864),  time:61.187, tt:2631.042\n",
      "Ep:43, loss:0.00007, loss_test:0.07197, lr:9.80e-03, fs:0.85128 (r=0.838,p=0.865),  time:61.141, tt:2690.200\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.07129, lr:9.80e-03, fs:0.85128 (r=0.838,p=0.865),  time:61.072, tt:2748.236\n",
      "Ep:45, loss:0.00007, loss_test:0.07359, lr:9.80e-03, fs:0.80874 (r=0.747,p=0.881),  time:61.010, tt:2806.459\n",
      "Ep:46, loss:0.00007, loss_test:0.07350, lr:9.80e-03, fs:0.80874 (r=0.747,p=0.881),  time:60.941, tt:2864.247\n",
      "Ep:47, loss:0.00006, loss_test:0.07274, lr:9.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:60.914, tt:2923.879\n",
      "Ep:48, loss:0.00006, loss_test:0.07141, lr:9.80e-03, fs:0.84375 (r=0.818,p=0.871),  time:60.862, tt:2982.218\n",
      "Ep:49, loss:0.00006, loss_test:0.07252, lr:9.80e-03, fs:0.83598 (r=0.798,p=0.878),  time:60.827, tt:3041.365\n",
      "Ep:50, loss:0.00006, loss_test:0.07244, lr:9.80e-03, fs:0.79558 (r=0.727,p=0.878),  time:60.743, tt:3097.888\n",
      "Ep:51, loss:0.00005, loss_test:0.07345, lr:9.80e-03, fs:0.79121 (r=0.727,p=0.867),  time:60.708, tt:3156.799\n",
      "Ep:52, loss:0.00005, loss_test:0.07085, lr:9.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:60.687, tt:3216.430\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06993, lr:9.80e-03, fs:0.84974 (r=0.828,p=0.872),  time:60.648, tt:3275.014\n",
      "Ep:54, loss:0.00005, loss_test:0.07022, lr:9.80e-03, fs:0.85417 (r=0.828,p=0.882),  time:60.610, tt:3333.568\n",
      "Ep:55, loss:0.00005, loss_test:0.07009, lr:9.80e-03, fs:0.85263 (r=0.818,p=0.890),  time:60.576, tt:3392.251\n",
      "Ep:56, loss:0.00004, loss_test:0.07203, lr:9.80e-03, fs:0.79558 (r=0.727,p=0.878),  time:60.537, tt:3450.629\n",
      "Ep:57, loss:0.00004, loss_test:0.06989, lr:9.80e-03, fs:0.84043 (r=0.798,p=0.888),  time:60.521, tt:3510.195\n",
      "Ep:58, loss:0.00004, loss_test:0.07064, lr:9.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:60.473, tt:3567.883\n",
      "Ep:59, loss:0.00004, loss_test:0.06979, lr:9.80e-03, fs:0.82540 (r=0.788,p=0.867),  time:60.475, tt:3628.502\n",
      "Ep:60, loss:0.00004, loss_test:0.07225, lr:9.80e-03, fs:0.78889 (r=0.717,p=0.877),  time:60.447, tt:3687.241\n",
      "Ep:61, loss:0.00004, loss_test:0.07197, lr:9.80e-03, fs:0.78453 (r=0.717,p=0.866),  time:60.427, tt:3746.492\n",
      "Ep:62, loss:0.00004, loss_test:0.07087, lr:9.80e-03, fs:0.77095 (r=0.697,p=0.863),  time:60.426, tt:3806.851\n",
      "Ep:63, loss:0.00003, loss_test:0.07048, lr:9.80e-03, fs:0.76667 (r=0.697,p=0.852),  time:60.398, tt:3865.467\n",
      "Ep:64, loss:0.00003, loss_test:0.07033, lr:9.70e-03, fs:0.84043 (r=0.798,p=0.888),  time:60.381, tt:3924.768\n",
      "Ep:65, loss:0.00003, loss_test:0.07310, lr:9.61e-03, fs:0.77966 (r=0.697,p=0.885),  time:60.344, tt:3982.691\n",
      "Ep:66, loss:0.00003, loss_test:0.07252, lr:9.51e-03, fs:0.77528 (r=0.697,p=0.873),  time:60.311, tt:4040.850\n",
      "Ep:67, loss:0.00003, loss_test:0.07355, lr:9.41e-03, fs:0.75145 (r=0.657,p=0.878),  time:60.306, tt:4100.809\n",
      "Ep:68, loss:0.00003, loss_test:0.07263, lr:9.32e-03, fs:0.79545 (r=0.707,p=0.909),  time:60.270, tt:4158.628\n",
      "Ep:69, loss:0.00003, loss_test:0.07351, lr:9.23e-03, fs:0.76301 (r=0.667,p=0.892),  time:60.202, tt:4214.135\n",
      "Ep:70, loss:0.00003, loss_test:0.07380, lr:9.14e-03, fs:0.77457 (r=0.677,p=0.905),  time:60.166, tt:4271.758\n",
      "Ep:71, loss:0.00003, loss_test:0.07273, lr:9.04e-03, fs:0.79532 (r=0.687,p=0.944),  time:60.124, tt:4328.964\n",
      "Ep:72, loss:0.00003, loss_test:0.07099, lr:8.95e-03, fs:0.80000 (r=0.707,p=0.921),  time:60.088, tt:4386.427\n",
      "Ep:73, loss:0.00003, loss_test:0.07180, lr:8.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:60.056, tt:4444.134\n",
      "Ep:74, loss:0.00002, loss_test:0.07344, lr:8.78e-03, fs:0.77844 (r=0.657,p=0.956),  time:60.047, tt:4503.541\n",
      "Ep:75, loss:0.00002, loss_test:0.07842, lr:8.69e-03, fs:0.75449 (r=0.636,p=0.926),  time:60.011, tt:4560.836\n",
      "Ep:76, loss:0.00002, loss_test:0.07456, lr:8.60e-03, fs:0.76364 (r=0.636,p=0.955),  time:59.962, tt:4617.098\n",
      "Ep:77, loss:0.00002, loss_test:0.07372, lr:8.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.947, tt:4675.850\n",
      "Ep:78, loss:0.00002, loss_test:0.07322, lr:8.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.925, tt:4734.048\n",
      "Ep:79, loss:0.00002, loss_test:0.07178, lr:8.35e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.859, tt:4788.683\n",
      "Ep:80, loss:0.00002, loss_test:0.07146, lr:8.26e-03, fs:0.77844 (r=0.657,p=0.956),  time:59.829, tt:4846.187\n",
      "Ep:81, loss:0.00002, loss_test:0.07388, lr:8.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.825, tt:4905.609\n",
      "Ep:82, loss:0.00002, loss_test:0.07240, lr:8.10e-03, fs:0.77844 (r=0.657,p=0.956),  time:59.798, tt:4963.264\n",
      "Ep:83, loss:0.00002, loss_test:0.07443, lr:8.02e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.746, tt:5018.668\n",
      "Ep:84, loss:0.00002, loss_test:0.07507, lr:7.94e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.758, tt:5079.459\n",
      "Ep:85, loss:0.00002, loss_test:0.07554, lr:7.86e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.751, tt:5138.594\n",
      "Ep:86, loss:0.00002, loss_test:0.07041, lr:7.78e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.743, tt:5197.613\n",
      "Ep:87, loss:0.00002, loss_test:0.07116, lr:7.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.733, tt:5256.526\n",
      "Ep:88, loss:0.00002, loss_test:0.07492, lr:7.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.684, tt:5311.838\n",
      "Ep:89, loss:0.00002, loss_test:0.07328, lr:7.55e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.692, tt:5372.237\n",
      "Ep:90, loss:0.00002, loss_test:0.07658, lr:7.47e-03, fs:0.76364 (r=0.636,p=0.955),  time:59.670, tt:5429.992\n",
      "Ep:91, loss:0.00001, loss_test:0.07253, lr:7.40e-03, fs:0.79268 (r=0.657,p=1.000),  time:59.676, tt:5490.147\n",
      "Ep:92, loss:0.00001, loss_test:0.07294, lr:7.32e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.647, tt:5547.186\n",
      "Ep:93, loss:0.00001, loss_test:0.07269, lr:7.25e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.640, tt:5606.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:94, loss:0.00001, loss_test:0.07274, lr:7.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.652, tt:5666.985\n",
      "Ep:95, loss:0.00001, loss_test:0.07411, lr:7.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.626, tt:5724.120\n",
      "Ep:96, loss:0.00001, loss_test:0.07419, lr:7.03e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.607, tt:5781.918\n",
      "Ep:97, loss:0.00001, loss_test:0.07468, lr:6.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.581, tt:5838.910\n",
      "Ep:98, loss:0.00001, loss_test:0.07466, lr:6.89e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.549, tt:5895.397\n",
      "Ep:99, loss:0.00001, loss_test:0.07530, lr:6.83e-03, fs:0.78528 (r=0.646,p=1.000),  time:59.550, tt:5954.968\n",
      "Ep:100, loss:0.00001, loss_test:0.07415, lr:6.76e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.531, tt:6012.628\n",
      "Ep:101, loss:0.00001, loss_test:0.07342, lr:6.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.517, tt:6070.701\n",
      "Ep:102, loss:0.00001, loss_test:0.07332, lr:6.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.510, tt:6129.480\n",
      "Ep:103, loss:0.00001, loss_test:0.07541, lr:6.56e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.511, tt:6189.164\n",
      "Ep:104, loss:0.00001, loss_test:0.07448, lr:6.49e-03, fs:0.76364 (r=0.636,p=0.955),  time:59.478, tt:6245.213\n",
      "Ep:105, loss:0.00001, loss_test:0.07586, lr:6.43e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.460, tt:6302.792\n",
      "Ep:106, loss:0.00001, loss_test:0.07385, lr:6.36e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.470, tt:6363.260\n",
      "Ep:107, loss:0.00001, loss_test:0.07397, lr:6.30e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.453, tt:6420.895\n",
      "Ep:108, loss:0.00001, loss_test:0.07273, lr:6.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.467, tt:6481.909\n",
      "Ep:109, loss:0.00001, loss_test:0.07388, lr:6.17e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.459, tt:6540.529\n",
      "Ep:110, loss:0.00001, loss_test:0.07564, lr:6.11e-03, fs:0.77019 (r=0.626,p=1.000),  time:59.434, tt:6597.212\n",
      "Ep:111, loss:0.00001, loss_test:0.07342, lr:6.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.393, tt:6652.030\n",
      "Ep:112, loss:0.00001, loss_test:0.07366, lr:5.99e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.389, tt:6710.981\n",
      "Ep:113, loss:0.00001, loss_test:0.07431, lr:5.93e-03, fs:0.77778 (r=0.636,p=1.000),  time:59.395, tt:6771.088\n",
      "Ep:114, loss:0.00001, loss_test:0.07596, lr:5.87e-03, fs:0.77778 (r=0.636,p=1.000),  time:59.395, tt:6830.442\n",
      "Ep:115, loss:0.00001, loss_test:0.07446, lr:5.81e-03, fs:0.77778 (r=0.636,p=1.000),  time:59.392, tt:6889.442\n",
      "Ep:116, loss:0.00001, loss_test:0.07329, lr:5.75e-03, fs:0.78788 (r=0.657,p=0.985),  time:59.381, tt:6947.617\n",
      "Ep:117, loss:0.00001, loss_test:0.07412, lr:5.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:59.390, tt:7007.979\n",
      "Ep:118, loss:0.00001, loss_test:0.07711, lr:5.64e-03, fs:0.77019 (r=0.626,p=1.000),  time:59.391, tt:7067.574\n",
      "Ep:119, loss:0.00001, loss_test:0.07444, lr:5.58e-03, fs:0.77778 (r=0.636,p=1.000),  time:59.381, tt:7125.769\n",
      "Ep:120, loss:0.00001, loss_test:0.07316, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.367, tt:7183.379\n",
      "Ep:121, loss:0.00001, loss_test:0.07484, lr:5.47e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.344, tt:7239.930\n",
      "Ep:122, loss:0.00001, loss_test:0.07600, lr:5.42e-03, fs:0.77778 (r=0.636,p=1.000),  time:59.350, tt:7299.993\n",
      "Ep:123, loss:0.00001, loss_test:0.07473, lr:5.36e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.353, tt:7359.812\n",
      "Ep:124, loss:0.00001, loss_test:0.07306, lr:5.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.361, tt:7420.066\n",
      "Ep:125, loss:0.00001, loss_test:0.07414, lr:5.26e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.336, tt:7476.309\n",
      "Ep:126, loss:0.00001, loss_test:0.07718, lr:5.20e-03, fs:0.76250 (r=0.616,p=1.000),  time:59.322, tt:7533.928\n",
      "Ep:127, loss:0.00001, loss_test:0.07458, lr:5.15e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.307, tt:7591.315\n",
      "Ep:128, loss:0.00001, loss_test:0.07353, lr:5.10e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.299, tt:7649.567\n",
      "Ep:129, loss:0.00001, loss_test:0.07507, lr:5.05e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.294, tt:7708.166\n",
      "Ep:130, loss:0.00001, loss_test:0.07520, lr:5.00e-03, fs:0.76543 (r=0.626,p=0.984),  time:59.269, tt:7764.232\n",
      "Ep:131, loss:0.00001, loss_test:0.07399, lr:4.95e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.284, tt:7825.500\n",
      "Ep:132, loss:0.00001, loss_test:0.07412, lr:4.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.278, tt:7884.011\n",
      "Ep:133, loss:0.00001, loss_test:0.07521, lr:4.85e-03, fs:0.75776 (r=0.616,p=0.984),  time:59.270, tt:7942.211\n",
      "Ep:134, loss:0.00001, loss_test:0.07456, lr:4.80e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.239, tt:7997.224\n",
      "Ep:135, loss:0.00001, loss_test:0.07503, lr:4.75e-03, fs:0.75776 (r=0.616,p=0.984),  time:59.230, tt:8055.335\n",
      "Ep:136, loss:0.00001, loss_test:0.07490, lr:4.71e-03, fs:0.76543 (r=0.626,p=0.984),  time:59.224, tt:8113.657\n",
      "Ep:137, loss:0.00001, loss_test:0.07417, lr:4.66e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.219, tt:8172.173\n",
      "Ep:138, loss:0.00001, loss_test:0.07447, lr:4.61e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.207, tt:8229.763\n",
      "Ep:139, loss:0.00001, loss_test:0.07553, lr:4.57e-03, fs:0.75776 (r=0.616,p=0.984),  time:59.186, tt:8286.099\n",
      "Ep:140, loss:0.00001, loss_test:0.07495, lr:4.52e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.201, tt:8347.401\n",
      "Ep:141, loss:0.00001, loss_test:0.07359, lr:4.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.197, tt:8405.907\n",
      "Ep:142, loss:0.00001, loss_test:0.07499, lr:4.43e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.183, tt:8463.150\n",
      "Ep:143, loss:0.00001, loss_test:0.07547, lr:4.39e-03, fs:0.75776 (r=0.616,p=0.984),  time:59.164, tt:8519.565\n",
      "Ep:144, loss:0.00001, loss_test:0.07442, lr:4.34e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.139, tt:8575.120\n",
      "Ep:145, loss:0.00001, loss_test:0.07383, lr:4.30e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.126, tt:8632.428\n",
      "Ep:146, loss:0.00001, loss_test:0.07613, lr:4.26e-03, fs:0.75776 (r=0.616,p=0.984),  time:59.106, tt:8688.548\n",
      "Ep:147, loss:0.00001, loss_test:0.07327, lr:4.21e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.097, tt:8746.398\n",
      "Ep:148, loss:0.00001, loss_test:0.07472, lr:4.17e-03, fs:0.76543 (r=0.626,p=0.984),  time:59.097, tt:8805.461\n",
      "Ep:149, loss:0.00001, loss_test:0.07510, lr:4.13e-03, fs:0.75776 (r=0.616,p=0.984),  time:59.092, tt:8863.838\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 16\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14202, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.671, tt:57.671\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13686, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:57.635, tt:115.269\n",
      "Ep:2, loss:0.00052, loss_test:0.12622, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:57.620, tt:172.861\n",
      "Ep:3, loss:0.00047, loss_test:0.11500, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:57.533, tt:230.132\n",
      "Ep:4, loss:0.00045, loss_test:0.10884, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:56.442, tt:282.211\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00042, loss_test:0.10371, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:55.182, tt:331.095\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.10080, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:55.434, tt:388.040\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09688, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:54.550, tt:436.398\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.09338, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:55.143, tt:496.286\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09036, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:55.200, tt:551.999\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.08982, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:55.500, tt:610.500\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.08726, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:55.587, tt:667.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00030, loss_test:0.08488, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:55.646, tt:723.401\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.08458, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:55.856, tt:781.982\n",
      "Ep:14, loss:0.00028, loss_test:0.08193, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:55.834, tt:837.506\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08167, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:55.928, tt:894.851\n",
      "Ep:16, loss:0.00025, loss_test:0.07899, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:55.973, tt:951.534\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.07814, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:56.146, tt:1010.636\n",
      "Ep:18, loss:0.00023, loss_test:0.07640, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:56.266, tt:1069.051\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.07429, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:56.231, tt:1124.623\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.07723, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:56.329, tt:1182.919\n",
      "Ep:21, loss:0.00020, loss_test:0.07305, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:56.432, tt:1241.502\n",
      "Ep:22, loss:0.00019, loss_test:0.07253, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:56.483, tt:1299.101\n",
      "Ep:23, loss:0.00018, loss_test:0.07195, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:56.622, tt:1358.932\n",
      "Ep:24, loss:0.00018, loss_test:0.07162, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:56.655, tt:1416.387\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.06835, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:56.670, tt:1473.422\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.06855, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:56.719, tt:1531.409\n",
      "Ep:27, loss:0.00015, loss_test:0.06723, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:56.785, tt:1589.984\n",
      "Ep:28, loss:0.00014, loss_test:0.06913, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:56.864, tt:1649.054\n",
      "Ep:29, loss:0.00014, loss_test:0.06862, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:56.882, tt:1706.461\n",
      "Ep:30, loss:0.00013, loss_test:0.06562, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:56.872, tt:1763.044\n",
      "Ep:31, loss:0.00012, loss_test:0.06405, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:56.916, tt:1821.300\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.06390, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:56.944, tt:1879.145\n",
      "Ep:33, loss:0.00011, loss_test:0.06134, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:56.976, tt:1937.192\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.06424, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:56.984, tt:1994.438\n",
      "Ep:35, loss:0.00010, loss_test:0.06475, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:56.956, tt:2050.429\n",
      "Ep:36, loss:0.00009, loss_test:0.06477, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:56.932, tt:2106.468\n",
      "Ep:37, loss:0.00009, loss_test:0.06712, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:56.966, tt:2164.709\n",
      "Ep:38, loss:0.00009, loss_test:0.06695, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:56.986, tt:2222.460\n",
      "Ep:39, loss:0.00009, loss_test:0.06361, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:57.010, tt:2280.404\n",
      "Ep:40, loss:0.00008, loss_test:0.06609, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:57.052, tt:2339.123\n",
      "Ep:41, loss:0.00008, loss_test:0.06546, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:57.043, tt:2395.799\n",
      "Ep:42, loss:0.00007, loss_test:0.06648, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:57.065, tt:2453.813\n",
      "Ep:43, loss:0.00007, loss_test:0.06430, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:57.121, tt:2513.331\n",
      "Ep:44, loss:0.00007, loss_test:0.06231, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:57.144, tt:2571.470\n",
      "Ep:45, loss:0.00006, loss_test:0.06490, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:57.194, tt:2630.917\n",
      "Ep:46, loss:0.00006, loss_test:0.05928, lr:9.80e-03, fs:0.84324 (r=0.788,p=0.907),  time:57.231, tt:2689.851\n",
      "Ep:47, loss:0.00006, loss_test:0.06046, lr:9.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:57.331, tt:2751.867\n",
      "Ep:48, loss:0.00006, loss_test:0.05896, lr:9.61e-03, fs:0.85246 (r=0.788,p=0.929),  time:57.354, tt:2810.363\n",
      "Ep:49, loss:0.00005, loss_test:0.05839, lr:9.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:57.392, tt:2869.590\n",
      "Ep:50, loss:0.00005, loss_test:0.06246, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:57.455, tt:2930.226\n",
      "Ep:51, loss:0.00005, loss_test:0.06306, lr:9.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:57.438, tt:2986.793\n",
      "Ep:52, loss:0.00005, loss_test:0.06268, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:57.439, tt:3044.244\n",
      "Ep:53, loss:0.00005, loss_test:0.06414, lr:9.14e-03, fs:0.81356 (r=0.727,p=0.923),  time:57.415, tt:3100.391\n",
      "Ep:54, loss:0.00005, loss_test:0.06029, lr:9.04e-03, fs:0.83333 (r=0.758,p=0.926),  time:57.405, tt:3157.272\n",
      "Ep:55, loss:0.00004, loss_test:0.05909, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:57.424, tt:3215.743\n",
      "Ep:56, loss:0.00004, loss_test:0.05922, lr:8.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:57.440, tt:3274.100\n",
      "Ep:57, loss:0.00004, loss_test:0.06106, lr:8.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.431, tt:3330.987\n",
      "Ep:58, loss:0.00004, loss_test:0.06175, lr:8.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.427, tt:3388.169\n",
      "Ep:59, loss:0.00004, loss_test:0.06093, lr:8.60e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.441, tt:3446.468\n",
      "Ep:60, loss:0.00003, loss_test:0.06047, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.436, tt:3503.574\n",
      "Ep:61, loss:0.00003, loss_test:0.06142, lr:8.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.449, tt:3561.845\n",
      "Ep:62, loss:0.00003, loss_test:0.06031, lr:8.35e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.456, tt:3619.753\n",
      "Ep:63, loss:0.00003, loss_test:0.06224, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:57.459, tt:3677.400\n",
      "Ep:64, loss:0.00003, loss_test:0.06118, lr:8.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.450, tt:3734.244\n",
      "Ep:65, loss:0.00003, loss_test:0.06149, lr:8.10e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.468, tt:3792.903\n",
      "Ep:66, loss:0.00003, loss_test:0.06240, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.495, tt:3852.162\n",
      "Ep:67, loss:0.00003, loss_test:0.06110, lr:7.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.515, tt:3910.995\n",
      "Ep:68, loss:0.00003, loss_test:0.06185, lr:7.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.491, tt:3966.905\n",
      "Ep:69, loss:0.00003, loss_test:0.06459, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.501, tt:4025.092\n",
      "Ep:70, loss:0.00003, loss_test:0.06242, lr:7.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.500, tt:4082.491\n",
      "Ep:71, loss:0.00002, loss_test:0.06488, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.515, tt:4141.101\n",
      "Ep:72, loss:0.00002, loss_test:0.06159, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.530, tt:4199.680\n",
      "Ep:73, loss:0.00002, loss_test:0.06218, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.546, tt:4258.435\n",
      "Ep:74, loss:0.00002, loss_test:0.06366, lr:7.40e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.588, tt:4319.122\n",
      "Ep:75, loss:0.00002, loss_test:0.06429, lr:7.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.565, tt:4374.929\n",
      "Ep:76, loss:0.00002, loss_test:0.06391, lr:7.25e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.539, tt:4430.524\n",
      "Ep:77, loss:0.00002, loss_test:0.06388, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.528, tt:4487.164\n",
      "Ep:78, loss:0.00002, loss_test:0.06446, lr:7.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.523, tt:4544.278\n",
      "Ep:79, loss:0.00002, loss_test:0.06540, lr:7.03e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.552, tt:4604.174\n",
      "Ep:80, loss:0.00002, loss_test:0.06311, lr:6.96e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.560, tt:4662.384\n",
      "Ep:81, loss:0.00002, loss_test:0.06466, lr:6.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.578, tt:4721.384\n",
      "Ep:82, loss:0.00002, loss_test:0.06343, lr:6.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.557, tt:4777.251\n",
      "Ep:83, loss:0.00002, loss_test:0.06594, lr:6.76e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.536, tt:4833.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:84, loss:0.00002, loss_test:0.06614, lr:6.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.550, tt:4891.762\n",
      "Ep:85, loss:0.00002, loss_test:0.06453, lr:6.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.506, tt:4945.545\n",
      "Ep:86, loss:0.00002, loss_test:0.06587, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.488, tt:5001.473\n",
      "Ep:87, loss:0.00002, loss_test:0.06343, lr:6.49e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.478, tt:5058.068\n",
      "Ep:88, loss:0.00002, loss_test:0.06679, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.478, tt:5115.556\n",
      "Ep:89, loss:0.00002, loss_test:0.06568, lr:6.36e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.482, tt:5173.368\n",
      "Ep:90, loss:0.00002, loss_test:0.06633, lr:6.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.506, tt:5233.035\n",
      "Ep:91, loss:0.00002, loss_test:0.06726, lr:6.24e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.544, tt:5294.087\n",
      "Ep:92, loss:0.00001, loss_test:0.06641, lr:6.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.556, tt:5352.672\n",
      "Ep:93, loss:0.00001, loss_test:0.06728, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.546, tt:5409.307\n",
      "Ep:94, loss:0.00001, loss_test:0.06782, lr:6.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.555, tt:5467.752\n",
      "Ep:95, loss:0.00001, loss_test:0.06678, lr:5.99e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.536, tt:5523.463\n",
      "Ep:96, loss:0.00001, loss_test:0.06517, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.532, tt:5580.647\n",
      "Ep:97, loss:0.00001, loss_test:0.06906, lr:5.87e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.521, tt:5637.038\n",
      "Ep:98, loss:0.00001, loss_test:0.06712, lr:5.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.549, tt:5697.338\n",
      "Ep:99, loss:0.00001, loss_test:0.06690, lr:5.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.567, tt:5756.749\n",
      "Ep:100, loss:0.00001, loss_test:0.06532, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.574, tt:5814.984\n",
      "Ep:101, loss:0.00001, loss_test:0.06772, lr:5.64e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.602, tt:5875.439\n",
      "Ep:102, loss:0.00001, loss_test:0.06959, lr:5.58e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.645, tt:5937.469\n",
      "Ep:103, loss:0.00001, loss_test:0.06613, lr:5.53e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.662, tt:5996.865\n",
      "Ep:104, loss:0.00001, loss_test:0.06732, lr:5.47e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.672, tt:6055.528\n",
      "Ep:105, loss:0.00001, loss_test:0.06873, lr:5.42e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.682, tt:6114.252\n",
      "Ep:106, loss:0.00001, loss_test:0.06746, lr:5.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.709, tt:6174.851\n",
      "Ep:107, loss:0.00001, loss_test:0.06676, lr:5.31e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.727, tt:6234.462\n",
      "Ep:108, loss:0.00001, loss_test:0.06839, lr:5.26e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.749, tt:6294.689\n",
      "Ep:109, loss:0.00001, loss_test:0.06958, lr:5.20e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.761, tt:6353.677\n",
      "Ep:110, loss:0.00001, loss_test:0.06636, lr:5.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.736, tt:6408.688\n",
      "Ep:111, loss:0.00001, loss_test:0.06801, lr:5.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.749, tt:6467.923\n",
      "Ep:112, loss:0.00001, loss_test:0.07100, lr:5.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.757, tt:6526.506\n",
      "Ep:113, loss:0.00001, loss_test:0.06731, lr:5.00e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.758, tt:6584.460\n",
      "Ep:114, loss:0.00001, loss_test:0.06820, lr:4.95e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.738, tt:6639.875\n",
      "Ep:115, loss:0.00001, loss_test:0.06879, lr:4.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.744, tt:6698.356\n",
      "Ep:116, loss:0.00001, loss_test:0.06917, lr:4.85e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.739, tt:6755.487\n",
      "Ep:117, loss:0.00001, loss_test:0.06739, lr:4.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.746, tt:6813.982\n",
      "Ep:118, loss:0.00001, loss_test:0.07026, lr:4.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.745, tt:6871.640\n",
      "Ep:119, loss:0.00001, loss_test:0.06866, lr:4.71e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.721, tt:6926.468\n",
      "Ep:120, loss:0.00001, loss_test:0.06729, lr:4.66e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.725, tt:6984.680\n",
      "Ep:121, loss:0.00001, loss_test:0.07036, lr:4.61e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.733, tt:7043.435\n",
      "Ep:122, loss:0.00001, loss_test:0.06803, lr:4.57e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.734, tt:7101.319\n",
      "Ep:123, loss:0.00001, loss_test:0.06927, lr:4.52e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.729, tt:7158.385\n",
      "Ep:124, loss:0.00001, loss_test:0.07033, lr:4.48e-03, fs:0.83237 (r=0.727,p=0.973),  time:57.733, tt:7216.568\n",
      "Ep:125, loss:0.00001, loss_test:0.06791, lr:4.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:57.734, tt:7274.511\n",
      "Ep:126, loss:0.00001, loss_test:0.06901, lr:4.39e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.708, tt:7328.946\n",
      "Ep:127, loss:0.00001, loss_test:0.06928, lr:4.34e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.716, tt:7387.609\n",
      "Ep:128, loss:0.00001, loss_test:0.06888, lr:4.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.721, tt:7446.040\n",
      "Ep:129, loss:0.00001, loss_test:0.07032, lr:4.26e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.723, tt:7504.002\n",
      "Ep:130, loss:0.00001, loss_test:0.06882, lr:4.21e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.729, tt:7562.558\n",
      "Ep:131, loss:0.00001, loss_test:0.06923, lr:4.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.719, tt:7618.933\n",
      "Ep:132, loss:0.00001, loss_test:0.06834, lr:4.13e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.710, tt:7675.492\n",
      "Ep:133, loss:0.00001, loss_test:0.06920, lr:4.09e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.714, tt:7733.664\n",
      "Ep:134, loss:0.00001, loss_test:0.06890, lr:4.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.724, tt:7792.679\n",
      "Ep:135, loss:0.00001, loss_test:0.06875, lr:4.01e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.725, tt:7850.635\n",
      "Ep:136, loss:0.00001, loss_test:0.06967, lr:3.97e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.714, tt:7906.861\n",
      "Ep:137, loss:0.00001, loss_test:0.06845, lr:3.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.711, tt:7964.163\n",
      "Ep:138, loss:0.00001, loss_test:0.06968, lr:3.89e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.706, tt:8021.155\n",
      "Ep:139, loss:0.00001, loss_test:0.06838, lr:3.85e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.687, tt:8076.198\n",
      "Ep:140, loss:0.00001, loss_test:0.06960, lr:3.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.683, tt:8133.294\n",
      "Ep:141, loss:0.00001, loss_test:0.06968, lr:3.77e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.679, tt:8190.419\n",
      "Ep:142, loss:0.00001, loss_test:0.06897, lr:3.73e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.687, tt:8249.253\n",
      "Ep:143, loss:0.00001, loss_test:0.06999, lr:3.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.689, tt:8307.157\n",
      "Ep:144, loss:0.00001, loss_test:0.06940, lr:3.66e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.687, tt:8364.669\n",
      "Ep:145, loss:0.00001, loss_test:0.06898, lr:3.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.700, tt:8424.236\n",
      "Ep:146, loss:0.00001, loss_test:0.06948, lr:3.59e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.687, tt:8480.006\n",
      "Ep:147, loss:0.00001, loss_test:0.06927, lr:3.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.679, tt:8536.439\n",
      "Ep:148, loss:0.00001, loss_test:0.06956, lr:3.52e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.678, tt:8594.035\n",
      "Ep:149, loss:0.00001, loss_test:0.07025, lr:3.48e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.681, tt:8652.096\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 17\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14022, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.392, tt:58.392\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13393, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:59.589, tt:119.179\n",
      "Ep:2, loss:0.00051, loss_test:0.12233, lr:1.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:59.937, tt:179.810\n",
      "Ep:3, loss:0.00047, loss_test:0.11606, lr:1.00e-02, fs:0.64948 (r=0.636,p=0.663),  time:58.902, tt:235.610\n",
      "Ep:4, loss:0.00044, loss_test:0.10944, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:57.831, tt:289.153\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00042, loss_test:0.10496, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:56.418, tt:338.507\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.10031, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:56.423, tt:394.959\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09588, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:56.626, tt:453.012\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.09210, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:56.216, tt:505.947\n",
      "Ep:9, loss:0.00035, loss_test:0.08895, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:56.277, tt:562.773\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.08604, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:56.641, tt:623.046\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.08429, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:56.676, tt:680.113\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.08354, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:56.905, tt:739.767\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.08171, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:56.829, tt:795.609\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00028, loss_test:0.08079, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:56.891, tt:853.362\n",
      "Ep:15, loss:0.00027, loss_test:0.07856, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:56.927, tt:910.838\n",
      "Ep:16, loss:0.00026, loss_test:0.07813, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:57.042, tt:969.710\n",
      "Ep:17, loss:0.00025, loss_test:0.07762, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:57.175, tt:1029.153\n",
      "Ep:18, loss:0.00024, loss_test:0.07637, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:57.310, tt:1088.897\n",
      "Ep:19, loss:0.00023, loss_test:0.07669, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:57.430, tt:1148.599\n",
      "Ep:20, loss:0.00021, loss_test:0.07768, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:57.484, tt:1207.165\n",
      "Ep:21, loss:0.00020, loss_test:0.07899, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:57.656, tt:1268.428\n",
      "Ep:22, loss:0.00019, loss_test:0.07720, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:57.764, tt:1328.571\n",
      "Ep:23, loss:0.00019, loss_test:0.07731, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:57.912, tt:1389.896\n",
      "Ep:24, loss:0.00018, loss_test:0.08037, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:57.995, tt:1449.871\n",
      "Ep:25, loss:0.00017, loss_test:0.07815, lr:9.90e-03, fs:0.77457 (r=0.677,p=0.905),  time:57.994, tt:1507.835\n",
      "Ep:26, loss:0.00016, loss_test:0.07656, lr:9.80e-03, fs:0.76744 (r=0.667,p=0.904),  time:58.162, tt:1570.385\n",
      "Ep:27, loss:0.00015, loss_test:0.08017, lr:9.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:58.154, tt:1628.317\n",
      "Ep:28, loss:0.00014, loss_test:0.08116, lr:9.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:58.156, tt:1686.519\n",
      "Ep:29, loss:0.00014, loss_test:0.07999, lr:9.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:58.206, tt:1746.166\n",
      "Ep:30, loss:0.00013, loss_test:0.08283, lr:9.41e-03, fs:0.77108 (r=0.646,p=0.955),  time:58.175, tt:1803.418\n",
      "Ep:31, loss:0.00012, loss_test:0.07866, lr:9.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:58.197, tt:1862.301\n",
      "Ep:32, loss:0.00012, loss_test:0.07947, lr:9.23e-03, fs:0.77108 (r=0.646,p=0.955),  time:58.193, tt:1920.356\n",
      "Ep:33, loss:0.00011, loss_test:0.07988, lr:9.14e-03, fs:0.77108 (r=0.646,p=0.955),  time:58.130, tt:1976.424\n",
      "Ep:34, loss:0.00011, loss_test:0.08517, lr:9.04e-03, fs:0.77108 (r=0.646,p=0.955),  time:58.097, tt:2033.391\n",
      "Ep:35, loss:0.00010, loss_test:0.08151, lr:8.95e-03, fs:0.77108 (r=0.646,p=0.955),  time:58.084, tt:2091.030\n",
      "Ep:36, loss:0.00010, loss_test:0.07864, lr:8.86e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.941, tt:2143.834\n",
      "Ep:37, loss:0.00009, loss_test:0.07813, lr:8.78e-03, fs:0.77381 (r=0.657,p=0.942),  time:57.937, tt:2201.605\n",
      "Ep:38, loss:0.00009, loss_test:0.08136, lr:8.69e-03, fs:0.77381 (r=0.657,p=0.942),  time:57.865, tt:2256.743\n",
      "Ep:39, loss:0.00008, loss_test:0.08717, lr:8.60e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.848, tt:2313.925\n",
      "Ep:40, loss:0.00008, loss_test:0.08229, lr:8.51e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.817, tt:2370.481\n",
      "Ep:41, loss:0.00008, loss_test:0.07989, lr:8.43e-03, fs:0.77381 (r=0.657,p=0.942),  time:57.825, tt:2428.641\n",
      "Ep:42, loss:0.00008, loss_test:0.08315, lr:8.35e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.815, tt:2486.035\n",
      "Ep:43, loss:0.00007, loss_test:0.08565, lr:8.26e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.714, tt:2539.399\n",
      "Ep:44, loss:0.00007, loss_test:0.08017, lr:8.18e-03, fs:0.77381 (r=0.657,p=0.942),  time:57.665, tt:2594.931\n",
      "Ep:45, loss:0.00007, loss_test:0.08486, lr:8.10e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.675, tt:2653.070\n",
      "Ep:46, loss:0.00006, loss_test:0.08384, lr:8.02e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.649, tt:2709.505\n",
      "Ep:47, loss:0.00006, loss_test:0.08459, lr:7.94e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.635, tt:2766.477\n",
      "Ep:48, loss:0.00006, loss_test:0.08252, lr:7.86e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.585, tt:2821.652\n",
      "Ep:49, loss:0.00006, loss_test:0.08293, lr:7.78e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.580, tt:2878.990\n",
      "Ep:50, loss:0.00006, loss_test:0.08219, lr:7.70e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.551, tt:2935.089\n",
      "Ep:51, loss:0.00005, loss_test:0.08860, lr:7.62e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.550, tt:2992.588\n",
      "Ep:52, loss:0.00005, loss_test:0.08870, lr:7.55e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.548, tt:3050.039\n",
      "Ep:53, loss:0.00005, loss_test:0.08276, lr:7.47e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.521, tt:3106.113\n",
      "Ep:54, loss:0.00005, loss_test:0.08631, lr:7.40e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.556, tt:3165.595\n",
      "Ep:55, loss:0.00005, loss_test:0.08974, lr:7.32e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.516, tt:3220.877\n",
      "Ep:56, loss:0.00005, loss_test:0.08736, lr:7.25e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.465, tt:3275.532\n",
      "Ep:57, loss:0.00005, loss_test:0.08252, lr:7.18e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.472, tt:3333.355\n",
      "Ep:58, loss:0.00004, loss_test:0.08925, lr:7.11e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.424, tt:3388.002\n",
      "Ep:59, loss:0.00004, loss_test:0.08711, lr:7.03e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.440, tt:3446.426\n",
      "Ep:60, loss:0.00004, loss_test:0.08905, lr:6.96e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.398, tt:3501.274\n",
      "Ep:61, loss:0.00004, loss_test:0.08980, lr:6.89e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.374, tt:3557.214\n",
      "Ep:62, loss:0.00004, loss_test:0.08554, lr:6.83e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.340, tt:3612.418\n",
      "Ep:63, loss:0.00004, loss_test:0.08892, lr:6.76e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.346, tt:3670.122\n",
      "Ep:64, loss:0.00004, loss_test:0.08872, lr:6.69e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.297, tt:3724.313\n",
      "Ep:65, loss:0.00004, loss_test:0.08834, lr:6.62e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.304, tt:3782.056\n",
      "Ep:66, loss:0.00003, loss_test:0.09092, lr:6.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.312, tt:3839.891\n",
      "Ep:67, loss:0.00003, loss_test:0.09108, lr:6.49e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.262, tt:3893.822\n",
      "Ep:68, loss:0.00003, loss_test:0.08781, lr:6.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.270, tt:3951.641\n",
      "Ep:69, loss:0.00003, loss_test:0.08886, lr:6.36e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.254, tt:4007.812\n",
      "Ep:70, loss:0.00003, loss_test:0.09438, lr:6.30e-03, fs:0.78788 (r=0.657,p=0.985),  time:57.228, tt:4063.208\n",
      "Ep:71, loss:0.00003, loss_test:0.08834, lr:6.24e-03, fs:0.77844 (r=0.657,p=0.956),  time:57.230, tt:4120.539\n",
      "Ep:72, loss:0.00003, loss_test:0.09028, lr:6.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.212, tt:4176.446\n",
      "Ep:73, loss:0.00003, loss_test:0.09067, lr:6.11e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.174, tt:4230.902\n",
      "Ep:74, loss:0.00003, loss_test:0.09205, lr:6.05e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.176, tt:4288.173\n",
      "Ep:75, loss:0.00003, loss_test:0.08759, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.146, tt:4343.107\n",
      "Ep:76, loss:0.00003, loss_test:0.08961, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.157, tt:4401.073\n",
      "Ep:77, loss:0.00003, loss_test:0.09179, lr:5.87e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.133, tt:4456.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00003, loss_test:0.09130, lr:5.81e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.108, tt:4511.572\n",
      "Ep:79, loss:0.00002, loss_test:0.08907, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.092, tt:4567.394\n",
      "Ep:80, loss:0.00002, loss_test:0.09131, lr:5.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.085, tt:4623.898\n",
      "Ep:81, loss:0.00002, loss_test:0.09323, lr:5.64e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.087, tt:4681.166\n",
      "Ep:82, loss:0.00002, loss_test:0.08822, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.070, tt:4736.793\n",
      "Ep:83, loss:0.00002, loss_test:0.09096, lr:5.53e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.049, tt:4792.093\n",
      "Ep:84, loss:0.00002, loss_test:0.09305, lr:5.47e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.036, tt:4848.089\n",
      "Ep:85, loss:0.00002, loss_test:0.09060, lr:5.42e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.040, tt:4905.401\n",
      "Ep:86, loss:0.00002, loss_test:0.08918, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.053, tt:4963.641\n",
      "Ep:87, loss:0.00002, loss_test:0.09069, lr:5.31e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.059, tt:5021.188\n",
      "Ep:88, loss:0.00002, loss_test:0.09207, lr:5.26e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.056, tt:5077.956\n",
      "Ep:89, loss:0.00002, loss_test:0.08901, lr:5.20e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.071, tt:5136.399\n",
      "Ep:90, loss:0.00002, loss_test:0.09062, lr:5.15e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.075, tt:5193.814\n",
      "Ep:91, loss:0.00002, loss_test:0.09344, lr:5.10e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.083, tt:5251.673\n",
      "Ep:92, loss:0.00002, loss_test:0.08980, lr:5.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:57.087, tt:5309.108\n",
      "Ep:93, loss:0.00002, loss_test:0.09051, lr:5.00e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.093, tt:5366.721\n",
      "Ep:94, loss:0.00002, loss_test:0.09075, lr:4.95e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.102, tt:5424.643\n",
      "Ep:95, loss:0.00002, loss_test:0.09093, lr:4.90e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.096, tt:5481.195\n",
      "Ep:96, loss:0.00002, loss_test:0.08981, lr:4.85e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.089, tt:5537.641\n",
      "Ep:97, loss:0.00002, loss_test:0.09122, lr:4.80e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.076, tt:5593.460\n",
      "Ep:98, loss:0.00002, loss_test:0.09151, lr:4.75e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.089, tt:5651.840\n",
      "Ep:99, loss:0.00002, loss_test:0.08910, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:57.113, tt:5711.255\n",
      "Ep:100, loss:0.00002, loss_test:0.09263, lr:4.66e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.114, tt:5768.522\n",
      "Ep:101, loss:0.00002, loss_test:0.09119, lr:4.61e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.119, tt:5826.117\n",
      "Ep:102, loss:0.00002, loss_test:0.09043, lr:4.57e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.127, tt:5884.060\n",
      "Ep:103, loss:0.00002, loss_test:0.09043, lr:4.52e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.137, tt:5942.223\n",
      "Ep:104, loss:0.00002, loss_test:0.09116, lr:4.48e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.141, tt:5999.834\n",
      "Ep:105, loss:0.00002, loss_test:0.09148, lr:4.43e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.152, tt:6058.148\n",
      "Ep:106, loss:0.00002, loss_test:0.09092, lr:4.39e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.152, tt:6115.223\n",
      "Ep:107, loss:0.00001, loss_test:0.09140, lr:4.34e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.136, tt:6170.642\n",
      "Ep:108, loss:0.00001, loss_test:0.09178, lr:4.30e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.147, tt:6229.005\n",
      "Ep:109, loss:0.00001, loss_test:0.09039, lr:4.26e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.158, tt:6287.368\n",
      "Ep:110, loss:0.00001, loss_test:0.09063, lr:4.21e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.150, tt:6343.670\n",
      "Ep:111, loss:0.00001, loss_test:0.09165, lr:4.17e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.141, tt:6399.769\n",
      "Ep:112, loss:0.00001, loss_test:0.08976, lr:4.13e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.124, tt:6454.960\n",
      "Ep:113, loss:0.00001, loss_test:0.09167, lr:4.09e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.110, tt:6510.540\n",
      "Ep:114, loss:0.00001, loss_test:0.09071, lr:4.05e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.126, tt:6569.451\n",
      "Ep:115, loss:0.00001, loss_test:0.09188, lr:4.01e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.138, tt:6628.006\n",
      "Ep:116, loss:0.00001, loss_test:0.09241, lr:3.97e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.148, tt:6686.299\n",
      "Ep:117, loss:0.00001, loss_test:0.09026, lr:3.93e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.178, tt:6746.955\n",
      "Ep:118, loss:0.00001, loss_test:0.09095, lr:3.89e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.189, tt:6805.450\n",
      "Ep:119, loss:0.00001, loss_test:0.09162, lr:3.85e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.193, tt:6863.126\n",
      "Ep:120, loss:0.00001, loss_test:0.09091, lr:3.81e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.219, tt:6923.517\n",
      "Ep:121, loss:0.00001, loss_test:0.09048, lr:3.77e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.202, tt:6978.688\n",
      "Ep:122, loss:0.00001, loss_test:0.09127, lr:3.73e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.204, tt:7036.107\n",
      "Ep:123, loss:0.00001, loss_test:0.09056, lr:3.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.233, tt:7096.890\n",
      "Ep:124, loss:0.00001, loss_test:0.09252, lr:3.66e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.225, tt:7153.186\n",
      "Ep:125, loss:0.00001, loss_test:0.09095, lr:3.62e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.239, tt:7212.101\n",
      "Ep:126, loss:0.00001, loss_test:0.09204, lr:3.59e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.234, tt:7268.740\n",
      "Ep:127, loss:0.00001, loss_test:0.09034, lr:3.55e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.249, tt:7327.927\n",
      "Ep:128, loss:0.00001, loss_test:0.09259, lr:3.52e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.278, tt:7388.906\n",
      "Ep:129, loss:0.00001, loss_test:0.09112, lr:3.48e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.291, tt:7447.782\n",
      "Ep:130, loss:0.00001, loss_test:0.09129, lr:3.45e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.297, tt:7505.969\n",
      "Ep:131, loss:0.00001, loss_test:0.09156, lr:3.41e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.312, tt:7565.249\n",
      "Ep:132, loss:0.00001, loss_test:0.09141, lr:3.38e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.314, tt:7622.701\n",
      "Ep:133, loss:0.00001, loss_test:0.09103, lr:3.34e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.322, tt:7681.168\n",
      "Ep:134, loss:0.00001, loss_test:0.09095, lr:3.31e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.333, tt:7740.012\n",
      "Ep:135, loss:0.00001, loss_test:0.09135, lr:3.28e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.361, tt:7801.091\n",
      "Ep:136, loss:0.00001, loss_test:0.09105, lr:3.24e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.355, tt:7857.699\n",
      "Ep:137, loss:0.00001, loss_test:0.09163, lr:3.21e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.369, tt:7916.914\n",
      "Ep:138, loss:0.00001, loss_test:0.09135, lr:3.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.370, tt:7974.409\n",
      "Ep:139, loss:0.00001, loss_test:0.09082, lr:3.15e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.382, tt:8033.504\n",
      "Ep:140, loss:0.00001, loss_test:0.09153, lr:3.12e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.402, tt:8093.748\n",
      "Ep:141, loss:0.00001, loss_test:0.09157, lr:3.09e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.425, tt:8154.283\n",
      "Ep:142, loss:0.00001, loss_test:0.09128, lr:3.05e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.417, tt:8210.678\n",
      "Ep:143, loss:0.00001, loss_test:0.09161, lr:3.02e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.447, tt:8272.309\n",
      "Ep:144, loss:0.00001, loss_test:0.09150, lr:2.99e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.433, tt:8327.803\n",
      "Ep:145, loss:0.00001, loss_test:0.09173, lr:2.96e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.446, tt:8387.060\n",
      "Ep:146, loss:0.00001, loss_test:0.09107, lr:2.93e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.458, tt:8446.316\n",
      "Ep:147, loss:0.00001, loss_test:0.09155, lr:2.90e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.465, tt:8504.798\n",
      "Ep:148, loss:0.00001, loss_test:0.09086, lr:2.88e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.476, tt:8563.973\n",
      "Ep:149, loss:0.00001, loss_test:0.09166, lr:2.85e-03, fs:0.79268 (r=0.657,p=1.000),  time:57.478, tt:8621.646\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 18\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14563, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.879, tt:56.879\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.14262, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:59.466, tt:118.933\n",
      "Ep:2, loss:0.00049, loss_test:0.14122, lr:1.00e-02, fs:0.57014 (r=0.636,p=0.516),  time:58.060, tt:174.181\n",
      "Ep:3, loss:0.00044, loss_test:0.14514, lr:1.00e-02, fs:0.53535 (r=0.535,p=0.535),  time:57.941, tt:231.763\n",
      "Ep:4, loss:0.00042, loss_test:0.14048, lr:1.00e-02, fs:0.55769 (r=0.586,p=0.532),  time:57.411, tt:287.055\n",
      "Ep:5, loss:0.00040, loss_test:0.14604, lr:1.00e-02, fs:0.54639 (r=0.535,p=0.558),  time:55.922, tt:335.533\n",
      "Ep:6, loss:0.00037, loss_test:0.14107, lr:1.00e-02, fs:0.57426 (r=0.586,p=0.563),  time:55.311, tt:387.179\n",
      "Ep:7, loss:0.00036, loss_test:0.13818, lr:1.00e-02, fs:0.56701 (r=0.556,p=0.579),  time:55.609, tt:444.871\n",
      "Ep:8, loss:0.00034, loss_test:0.13604, lr:1.00e-02, fs:0.58333 (r=0.566,p=0.602),  time:55.551, tt:499.963\n",
      "Ep:9, loss:0.00032, loss_test:0.13267, lr:1.00e-02, fs:0.58163 (r=0.576,p=0.588),  time:55.373, tt:553.730\n",
      "Ep:10, loss:0.00031, loss_test:0.12839, lr:1.00e-02, fs:0.60825 (r=0.596,p=0.621),  time:55.762, tt:613.377\n",
      "Ep:11, loss:0.00030, loss_test:0.12658, lr:1.00e-02, fs:0.64975 (r=0.646,p=0.653),  time:56.214, tt:674.563\n",
      "Ep:12, loss:0.00028, loss_test:0.12614, lr:9.90e-03, fs:0.68085 (r=0.646,p=0.719),  time:56.855, tt:739.118\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00027, loss_test:0.12354, lr:9.90e-03, fs:0.66667 (r=0.646,p=0.688),  time:57.043, tt:798.602\n",
      "Ep:14, loss:0.00026, loss_test:0.12209, lr:9.90e-03, fs:0.67016 (r=0.646,p=0.696),  time:56.933, tt:853.989\n",
      "Ep:15, loss:0.00025, loss_test:0.11999, lr:9.90e-03, fs:0.69474 (r=0.667,p=0.725),  time:57.116, tt:913.853\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.11880, lr:9.90e-03, fs:0.69841 (r=0.667,p=0.733),  time:57.239, tt:973.066\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.11772, lr:9.90e-03, fs:0.69565 (r=0.646,p=0.753),  time:57.298, tt:1031.370\n",
      "Ep:18, loss:0.00022, loss_test:0.11782, lr:9.90e-03, fs:0.67403 (r=0.616,p=0.744),  time:57.351, tt:1089.672\n",
      "Ep:19, loss:0.00022, loss_test:0.11441, lr:9.90e-03, fs:0.68817 (r=0.646,p=0.736),  time:57.375, tt:1147.507\n",
      "Ep:20, loss:0.00021, loss_test:0.11671, lr:9.90e-03, fs:0.67742 (r=0.636,p=0.724),  time:57.431, tt:1206.058\n",
      "Ep:21, loss:0.00020, loss_test:0.11326, lr:9.90e-03, fs:0.69149 (r=0.657,p=0.730),  time:57.480, tt:1264.565\n",
      "Ep:22, loss:0.00019, loss_test:0.11459, lr:9.90e-03, fs:0.70391 (r=0.636,p=0.787),  time:57.521, tt:1322.992\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.11437, lr:9.90e-03, fs:0.70000 (r=0.636,p=0.778),  time:57.607, tt:1382.574\n",
      "Ep:24, loss:0.00018, loss_test:0.11465, lr:9.90e-03, fs:0.70391 (r=0.636,p=0.787),  time:57.649, tt:1441.229\n",
      "Ep:25, loss:0.00017, loss_test:0.11380, lr:9.90e-03, fs:0.70455 (r=0.626,p=0.805),  time:57.701, tt:1500.224\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.11678, lr:9.90e-03, fs:0.67816 (r=0.596,p=0.787),  time:57.725, tt:1558.569\n",
      "Ep:27, loss:0.00016, loss_test:0.10984, lr:9.90e-03, fs:0.70270 (r=0.657,p=0.756),  time:57.643, tt:1614.016\n",
      "Ep:28, loss:0.00015, loss_test:0.11533, lr:9.90e-03, fs:0.63905 (r=0.545,p=0.771),  time:57.781, tt:1675.635\n",
      "Ep:29, loss:0.00015, loss_test:0.11295, lr:9.90e-03, fs:0.68927 (r=0.616,p=0.782),  time:57.761, tt:1732.828\n",
      "Ep:30, loss:0.00014, loss_test:0.11589, lr:9.90e-03, fs:0.63905 (r=0.545,p=0.771),  time:57.802, tt:1791.874\n",
      "Ep:31, loss:0.00014, loss_test:0.10974, lr:9.90e-03, fs:0.69565 (r=0.646,p=0.753),  time:57.691, tt:1846.116\n",
      "Ep:32, loss:0.00013, loss_test:0.11559, lr:9.90e-03, fs:0.63473 (r=0.535,p=0.779),  time:57.746, tt:1905.622\n",
      "Ep:33, loss:0.00012, loss_test:0.11221, lr:9.90e-03, fs:0.65497 (r=0.566,p=0.778),  time:57.711, tt:1962.179\n",
      "Ep:34, loss:0.00012, loss_test:0.11487, lr:9.90e-03, fs:0.64242 (r=0.535,p=0.803),  time:57.706, tt:2019.694\n",
      "Ep:35, loss:0.00011, loss_test:0.11311, lr:9.90e-03, fs:0.64242 (r=0.535,p=0.803),  time:57.782, tt:2080.156\n",
      "Ep:36, loss:0.00011, loss_test:0.11332, lr:9.90e-03, fs:0.65839 (r=0.535,p=0.855),  time:57.817, tt:2139.244\n",
      "Ep:37, loss:0.00010, loss_test:0.11310, lr:9.80e-03, fs:0.65432 (r=0.535,p=0.841),  time:57.805, tt:2196.603\n",
      "Ep:38, loss:0.00010, loss_test:0.11199, lr:9.70e-03, fs:0.66250 (r=0.535,p=0.869),  time:57.817, tt:2254.865\n",
      "Ep:39, loss:0.00010, loss_test:0.11135, lr:9.61e-03, fs:0.65839 (r=0.535,p=0.855),  time:57.900, tt:2316.000\n",
      "Ep:40, loss:0.00009, loss_test:0.10990, lr:9.51e-03, fs:0.65432 (r=0.535,p=0.841),  time:57.984, tt:2377.357\n",
      "Ep:41, loss:0.00009, loss_test:0.11348, lr:9.41e-03, fs:0.65432 (r=0.535,p=0.841),  time:58.023, tt:2436.968\n",
      "Ep:42, loss:0.00009, loss_test:0.10940, lr:9.32e-03, fs:0.65839 (r=0.535,p=0.855),  time:58.061, tt:2496.644\n",
      "Ep:43, loss:0.00008, loss_test:0.11033, lr:9.23e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.051, tt:2554.224\n",
      "Ep:44, loss:0.00008, loss_test:0.11314, lr:9.14e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.044, tt:2611.991\n",
      "Ep:45, loss:0.00008, loss_test:0.11532, lr:9.04e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.096, tt:2672.418\n",
      "Ep:46, loss:0.00007, loss_test:0.10431, lr:8.95e-03, fs:0.65432 (r=0.535,p=0.841),  time:58.122, tt:2731.741\n",
      "Ep:47, loss:0.00007, loss_test:0.11354, lr:8.86e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.109, tt:2789.229\n",
      "Ep:48, loss:0.00007, loss_test:0.11386, lr:8.78e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.136, tt:2848.668\n",
      "Ep:49, loss:0.00007, loss_test:0.10823, lr:8.69e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.189, tt:2909.433\n",
      "Ep:50, loss:0.00006, loss_test:0.10847, lr:8.60e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.310, tt:2973.821\n",
      "Ep:51, loss:0.00006, loss_test:0.10712, lr:8.51e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.380, tt:3035.764\n",
      "Ep:52, loss:0.00006, loss_test:0.11515, lr:8.43e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.403, tt:3095.347\n",
      "Ep:53, loss:0.00006, loss_test:0.11115, lr:8.35e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.379, tt:3152.482\n",
      "Ep:54, loss:0.00006, loss_test:0.10657, lr:8.26e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.424, tt:3213.333\n",
      "Ep:55, loss:0.00005, loss_test:0.11093, lr:8.18e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.463, tt:3273.941\n",
      "Ep:56, loss:0.00005, loss_test:0.11437, lr:8.10e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.476, tt:3333.130\n",
      "Ep:57, loss:0.00005, loss_test:0.10853, lr:8.02e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.443, tt:3389.681\n",
      "Ep:58, loss:0.00005, loss_test:0.11302, lr:7.94e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.436, tt:3447.724\n",
      "Ep:59, loss:0.00005, loss_test:0.10914, lr:7.86e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.436, tt:3506.187\n",
      "Ep:60, loss:0.00005, loss_test:0.11086, lr:7.78e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.478, tt:3567.137\n",
      "Ep:61, loss:0.00005, loss_test:0.11164, lr:7.70e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.513, tt:3627.790\n",
      "Ep:62, loss:0.00004, loss_test:0.10940, lr:7.62e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.592, tt:3691.265\n",
      "Ep:63, loss:0.00004, loss_test:0.11270, lr:7.55e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.639, tt:3752.867\n",
      "Ep:64, loss:0.00004, loss_test:0.11140, lr:7.47e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.627, tt:3810.746\n",
      "Ep:65, loss:0.00004, loss_test:0.10748, lr:7.40e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.673, tt:3872.438\n",
      "Ep:66, loss:0.00004, loss_test:0.11131, lr:7.32e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.660, tt:3930.213\n",
      "Ep:67, loss:0.00004, loss_test:0.11193, lr:7.25e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.671, tt:3989.596\n",
      "Ep:68, loss:0.00004, loss_test:0.11291, lr:7.18e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.680, tt:4048.892\n",
      "Ep:69, loss:0.00004, loss_test:0.10729, lr:7.11e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.693, tt:4108.507\n",
      "Ep:70, loss:0.00004, loss_test:0.11217, lr:7.03e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.704, tt:4167.998\n",
      "Ep:71, loss:0.00004, loss_test:0.11187, lr:6.96e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.669, tt:4224.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00004, loss_test:0.10877, lr:6.89e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.681, tt:4283.737\n",
      "Ep:73, loss:0.00004, loss_test:0.10997, lr:6.83e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.693, tt:4343.296\n",
      "Ep:74, loss:0.00003, loss_test:0.11193, lr:6.76e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.735, tt:4405.104\n",
      "Ep:75, loss:0.00003, loss_test:0.11069, lr:6.69e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.755, tt:4465.371\n",
      "Ep:76, loss:0.00003, loss_test:0.10862, lr:6.62e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.800, tt:4527.608\n",
      "Ep:77, loss:0.00003, loss_test:0.11383, lr:6.56e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.856, tt:4590.803\n",
      "Ep:78, loss:0.00003, loss_test:0.11015, lr:6.49e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.840, tt:4648.370\n",
      "Ep:79, loss:0.00003, loss_test:0.11107, lr:6.43e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.868, tt:4709.464\n",
      "Ep:80, loss:0.00003, loss_test:0.11087, lr:6.36e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.874, tt:4768.771\n",
      "Ep:81, loss:0.00003, loss_test:0.10908, lr:6.30e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.880, tt:4828.141\n",
      "Ep:82, loss:0.00003, loss_test:0.11086, lr:6.24e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.888, tt:4887.717\n",
      "Ep:83, loss:0.00003, loss_test:0.11044, lr:6.17e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.959, tt:4952.588\n",
      "Ep:84, loss:0.00003, loss_test:0.10770, lr:6.11e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.967, tt:5012.159\n",
      "Ep:85, loss:0.00003, loss_test:0.11303, lr:6.05e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.950, tt:5069.722\n",
      "Ep:86, loss:0.00003, loss_test:0.10972, lr:5.99e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.962, tt:5129.673\n",
      "Ep:87, loss:0.00003, loss_test:0.10787, lr:5.93e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.977, tt:5189.941\n",
      "Ep:88, loss:0.00003, loss_test:0.10990, lr:5.87e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.955, tt:5247.028\n",
      "Ep:89, loss:0.00003, loss_test:0.11217, lr:5.81e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.956, tt:5305.999\n",
      "Ep:90, loss:0.00003, loss_test:0.10710, lr:5.75e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.952, tt:5364.626\n",
      "Ep:91, loss:0.00003, loss_test:0.10979, lr:5.70e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.958, tt:5424.169\n",
      "Ep:92, loss:0.00003, loss_test:0.11149, lr:5.64e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.941, tt:5481.532\n",
      "Ep:93, loss:0.00003, loss_test:0.10976, lr:5.58e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.944, tt:5540.730\n",
      "Ep:94, loss:0.00003, loss_test:0.10951, lr:5.53e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.925, tt:5597.877\n",
      "Ep:95, loss:0.00002, loss_test:0.11113, lr:5.47e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.954, tt:5659.620\n",
      "Ep:96, loss:0.00002, loss_test:0.10869, lr:5.42e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.922, tt:5715.422\n",
      "Ep:97, loss:0.00002, loss_test:0.11069, lr:5.36e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.913, tt:5773.520\n",
      "Ep:98, loss:0.00002, loss_test:0.10957, lr:5.31e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.931, tt:5834.199\n",
      "Ep:99, loss:0.00002, loss_test:0.11088, lr:5.26e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.915, tt:5891.483\n",
      "Ep:100, loss:0.00002, loss_test:0.10939, lr:5.20e-03, fs:0.66667 (r=0.535,p=0.883),  time:58.907, tt:5949.617\n",
      "Ep:101, loss:0.00002, loss_test:0.10992, lr:5.15e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.885, tt:6006.279\n",
      "Ep:102, loss:0.00002, loss_test:0.10886, lr:5.10e-03, fs:0.67516 (r=0.535,p=0.914),  time:58.895, tt:6066.145\n",
      "Ep:103, loss:0.00002, loss_test:0.11248, lr:5.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.887, tt:6124.212\n",
      "Ep:104, loss:0.00002, loss_test:0.11088, lr:5.00e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.864, tt:6180.740\n",
      "Ep:105, loss:0.00002, loss_test:0.11074, lr:4.95e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.846, tt:6237.719\n",
      "Ep:106, loss:0.00002, loss_test:0.10992, lr:4.90e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.823, tt:6294.042\n",
      "Ep:107, loss:0.00002, loss_test:0.11139, lr:4.85e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.807, tt:6351.121\n",
      "Ep:108, loss:0.00002, loss_test:0.11006, lr:4.80e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.774, tt:6406.356\n",
      "Ep:109, loss:0.00002, loss_test:0.10996, lr:4.75e-03, fs:0.67949 (r=0.535,p=0.930),  time:58.783, tt:6466.078\n",
      "Ep:110, loss:0.00002, loss_test:0.11231, lr:4.71e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.757, tt:6521.973\n",
      "Ep:111, loss:0.00002, loss_test:0.10954, lr:4.66e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.742, tt:6579.071\n",
      "Ep:112, loss:0.00002, loss_test:0.11193, lr:4.61e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.733, tt:6636.814\n",
      "Ep:113, loss:0.00002, loss_test:0.11018, lr:4.57e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.738, tt:6696.148\n",
      "Ep:114, loss:0.00002, loss_test:0.11029, lr:4.52e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.742, tt:6755.287\n",
      "Ep:115, loss:0.00002, loss_test:0.11226, lr:4.48e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.753, tt:6815.359\n",
      "Ep:116, loss:0.00002, loss_test:0.11079, lr:4.43e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.740, tt:6872.594\n",
      "Ep:117, loss:0.00002, loss_test:0.11189, lr:4.39e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.737, tt:6930.934\n",
      "Ep:118, loss:0.00002, loss_test:0.11032, lr:4.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.717, tt:6987.288\n",
      "Ep:119, loss:0.00002, loss_test:0.11138, lr:4.30e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.764, tt:7051.659\n",
      "Ep:120, loss:0.00002, loss_test:0.11053, lr:4.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:58.795, tt:7114.190\n",
      "Ep:121, loss:0.00002, loss_test:0.11104, lr:4.21e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.818, tt:7175.828\n",
      "Ep:122, loss:0.00002, loss_test:0.11131, lr:4.17e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.876, tt:7241.775\n",
      "Ep:123, loss:0.00002, loss_test:0.11111, lr:4.13e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.927, tt:7306.898\n",
      "Ep:124, loss:0.00002, loss_test:0.11162, lr:4.09e-03, fs:0.68831 (r=0.535,p=0.964),  time:58.982, tt:7372.797\n",
      "Ep:125, loss:0.00002, loss_test:0.11019, lr:4.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.021, tt:7436.616\n",
      "Ep:126, loss:0.00002, loss_test:0.11273, lr:4.01e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.089, tt:7504.311\n",
      "Ep:127, loss:0.00002, loss_test:0.10993, lr:3.97e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.137, tt:7569.513\n",
      "Ep:128, loss:0.00002, loss_test:0.11203, lr:3.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.173, tt:7633.348\n",
      "Ep:129, loss:0.00002, loss_test:0.11145, lr:3.89e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.198, tt:7695.714\n",
      "Ep:130, loss:0.00002, loss_test:0.11198, lr:3.85e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.230, tt:7759.073\n",
      "Ep:131, loss:0.00002, loss_test:0.11125, lr:3.81e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.269, tt:7823.504\n",
      "Ep:132, loss:0.00002, loss_test:0.11220, lr:3.77e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.308, tt:7887.920\n",
      "Ep:133, loss:0.00002, loss_test:0.11053, lr:3.73e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.291, tt:7944.975\n",
      "Ep:134, loss:0.00002, loss_test:0.11229, lr:3.70e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.296, tt:8004.962\n",
      "Ep:135, loss:0.00002, loss_test:0.11151, lr:3.66e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.330, tt:8068.941\n",
      "Ep:136, loss:0.00002, loss_test:0.11142, lr:3.62e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.386, tt:8135.869\n",
      "Ep:137, loss:0.00002, loss_test:0.11212, lr:3.59e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.426, tt:8200.836\n",
      "Ep:138, loss:0.00002, loss_test:0.11046, lr:3.55e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.467, tt:8265.887\n",
      "Ep:139, loss:0.00001, loss_test:0.11248, lr:3.52e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.497, tt:8329.636\n",
      "Ep:140, loss:0.00001, loss_test:0.11009, lr:3.48e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.512, tt:8391.244\n",
      "Ep:141, loss:0.00001, loss_test:0.11253, lr:3.45e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.548, tt:8455.800\n",
      "Ep:142, loss:0.00001, loss_test:0.11032, lr:3.41e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.595, tt:8522.114\n",
      "Ep:143, loss:0.00001, loss_test:0.11226, lr:3.38e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.620, tt:8585.337\n",
      "Ep:144, loss:0.00001, loss_test:0.11073, lr:3.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.646, tt:8648.741\n",
      "Ep:145, loss:0.00001, loss_test:0.11142, lr:3.31e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.678, tt:8712.995\n",
      "Ep:146, loss:0.00001, loss_test:0.11120, lr:3.28e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.708, tt:8777.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.11162, lr:3.24e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.746, tt:8842.420\n",
      "Ep:148, loss:0.00001, loss_test:0.11094, lr:3.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.797, tt:8909.813\n",
      "Ep:149, loss:0.00001, loss_test:0.11256, lr:3.18e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.822, tt:8973.244\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 19\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14064, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:65.859, tt:65.859\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13531, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:66.257, tt:132.513\n",
      "Ep:2, loss:0.00052, loss_test:0.12343, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:65.539, tt:196.617\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.11222, lr:1.00e-02, fs:0.65072 (r=0.687,p=0.618),  time:65.518, tt:262.071\n",
      "Ep:4, loss:0.00044, loss_test:0.11022, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:64.654, tt:323.269\n",
      "Ep:5, loss:0.00042, loss_test:0.10555, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:64.280, tt:385.680\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.10377, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:63.676, tt:445.731\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.10113, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:63.018, tt:504.140\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.09859, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:63.029, tt:567.265\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.09751, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:63.069, tt:630.686\n",
      "Ep:10, loss:0.00033, loss_test:0.09563, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:62.532, tt:687.853\n",
      "Ep:11, loss:0.00032, loss_test:0.09415, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:62.556, tt:750.673\n",
      "Ep:12, loss:0.00031, loss_test:0.09305, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:62.872, tt:817.341\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.09178, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:62.997, tt:881.962\n",
      "Ep:14, loss:0.00028, loss_test:0.09227, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:63.195, tt:947.929\n",
      "Ep:15, loss:0.00027, loss_test:0.08979, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:63.254, tt:1012.064\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.08864, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:63.272, tt:1075.625\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.08833, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:63.321, tt:1139.782\n",
      "Ep:18, loss:0.00024, loss_test:0.08594, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:63.349, tt:1203.632\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.08543, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:63.493, tt:1269.850\n",
      "Ep:20, loss:0.00021, loss_test:0.08442, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:63.464, tt:1332.753\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.08386, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:63.566, tt:1398.449\n",
      "Ep:22, loss:0.00019, loss_test:0.08245, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:63.662, tt:1464.233\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.08344, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:63.663, tt:1527.914\n",
      "Ep:24, loss:0.00018, loss_test:0.08123, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:63.787, tt:1594.666\n",
      "Ep:25, loss:0.00017, loss_test:0.08107, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:63.864, tt:1660.453\n",
      "Ep:26, loss:0.00016, loss_test:0.07989, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:63.946, tt:1726.553\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.07801, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:64.037, tt:1793.038\n",
      "Ep:28, loss:0.00014, loss_test:0.08088, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:64.217, tt:1862.295\n",
      "Ep:29, loss:0.00013, loss_test:0.07841, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:64.207, tt:1926.214\n",
      "Ep:30, loss:0.00013, loss_test:0.07723, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:64.254, tt:1991.873\n",
      "Ep:31, loss:0.00012, loss_test:0.07827, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:64.320, tt:2058.244\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07609, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:64.322, tt:2122.634\n",
      "Ep:33, loss:0.00011, loss_test:0.07719, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:64.333, tt:2187.321\n",
      "Ep:34, loss:0.00010, loss_test:0.07722, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:64.409, tt:2254.316\n",
      "Ep:35, loss:0.00010, loss_test:0.07733, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:64.445, tt:2320.010\n",
      "Ep:36, loss:0.00009, loss_test:0.07670, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:64.488, tt:2386.053\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07580, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:64.557, tt:2453.152\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07491, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:64.604, tt:2519.547\n",
      "Ep:39, loss:0.00008, loss_test:0.07646, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:64.674, tt:2586.971\n",
      "Ep:40, loss:0.00008, loss_test:0.07507, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:64.706, tt:2652.959\n",
      "Ep:41, loss:0.00008, loss_test:0.07496, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:64.753, tt:2719.616\n",
      "Ep:42, loss:0.00007, loss_test:0.07522, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:64.769, tt:2785.072\n",
      "Ep:43, loss:0.00007, loss_test:0.07542, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:64.838, tt:2852.866\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.07393, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:64.793, tt:2915.683\n",
      "Ep:45, loss:0.00006, loss_test:0.07467, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:64.766, tt:2979.254\n",
      "Ep:46, loss:0.00006, loss_test:0.07407, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:64.805, tt:3045.846\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.07403, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:64.807, tt:3110.734\n",
      "Ep:48, loss:0.00006, loss_test:0.07335, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:64.828, tt:3176.560\n",
      "Ep:49, loss:0.00005, loss_test:0.07424, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:64.863, tt:3243.151\n",
      "Ep:50, loss:0.00005, loss_test:0.07460, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:64.883, tt:3309.023\n",
      "Ep:51, loss:0.00005, loss_test:0.07289, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:64.902, tt:3374.906\n",
      "Ep:52, loss:0.00005, loss_test:0.07374, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:64.906, tt:3439.993\n",
      "Ep:53, loss:0.00005, loss_test:0.07312, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:64.927, tt:3506.060\n",
      "Ep:54, loss:0.00005, loss_test:0.07290, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:64.939, tt:3571.656\n",
      "Ep:55, loss:0.00004, loss_test:0.07264, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:64.977, tt:3638.711\n",
      "Ep:56, loss:0.00004, loss_test:0.07235, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:64.978, tt:3703.725\n",
      "Ep:57, loss:0.00004, loss_test:0.07236, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:65.000, tt:3770.017\n",
      "Ep:58, loss:0.00004, loss_test:0.07198, lr:9.90e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.973, tt:3833.381\n",
      "Ep:59, loss:0.00004, loss_test:0.07250, lr:9.80e-03, fs:0.80000 (r=0.707,p=0.921),  time:64.988, tt:3899.270\n",
      "Ep:60, loss:0.00004, loss_test:0.07341, lr:9.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:65.022, tt:3966.334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00004, loss_test:0.07286, lr:9.61e-03, fs:0.80000 (r=0.707,p=0.921),  time:65.021, tt:4031.317\n",
      "Ep:62, loss:0.00004, loss_test:0.07237, lr:9.51e-03, fs:0.79310 (r=0.697,p=0.920),  time:65.039, tt:4097.476\n",
      "Ep:63, loss:0.00003, loss_test:0.07393, lr:9.41e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.022, tt:4161.378\n",
      "Ep:64, loss:0.00003, loss_test:0.07525, lr:9.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:65.032, tt:4227.058\n",
      "Ep:65, loss:0.00003, loss_test:0.07292, lr:9.23e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.025, tt:4291.669\n",
      "Ep:66, loss:0.00003, loss_test:0.07486, lr:9.14e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.054, tt:4358.616\n",
      "Ep:67, loss:0.00003, loss_test:0.07473, lr:9.04e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.024, tt:4421.648\n",
      "Ep:68, loss:0.00003, loss_test:0.07464, lr:8.95e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.028, tt:4486.955\n",
      "Ep:69, loss:0.00003, loss_test:0.07570, lr:8.86e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.005, tt:4550.376\n",
      "Ep:70, loss:0.00003, loss_test:0.07352, lr:8.78e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.009, tt:4615.639\n",
      "Ep:71, loss:0.00003, loss_test:0.07371, lr:8.69e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.992, tt:4679.456\n",
      "Ep:72, loss:0.00003, loss_test:0.07555, lr:8.60e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.997, tt:4744.811\n",
      "Ep:73, loss:0.00003, loss_test:0.07584, lr:8.51e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.007, tt:4810.494\n",
      "Ep:74, loss:0.00002, loss_test:0.07484, lr:8.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.995, tt:4874.610\n",
      "Ep:75, loss:0.00002, loss_test:0.07537, lr:8.35e-03, fs:0.80702 (r=0.697,p=0.958),  time:65.017, tt:4941.287\n",
      "Ep:76, loss:0.00002, loss_test:0.07516, lr:8.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.042, tt:5008.210\n",
      "Ep:77, loss:0.00002, loss_test:0.07480, lr:8.18e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.055, tt:5074.312\n",
      "Ep:78, loss:0.00002, loss_test:0.07601, lr:8.10e-03, fs:0.80702 (r=0.697,p=0.958),  time:65.046, tt:5138.651\n",
      "Ep:79, loss:0.00002, loss_test:0.07491, lr:8.02e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.051, tt:5204.053\n",
      "Ep:80, loss:0.00002, loss_test:0.07399, lr:7.94e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.033, tt:5267.688\n",
      "Ep:81, loss:0.00002, loss_test:0.07493, lr:7.86e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.039, tt:5333.187\n",
      "Ep:82, loss:0.00002, loss_test:0.07643, lr:7.78e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.047, tt:5398.890\n",
      "Ep:83, loss:0.00002, loss_test:0.07644, lr:7.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.044, tt:5463.672\n",
      "Ep:84, loss:0.00002, loss_test:0.07625, lr:7.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:65.035, tt:5527.996\n",
      "Ep:85, loss:0.00002, loss_test:0.07548, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.999, tt:5589.942\n",
      "Ep:86, loss:0.00002, loss_test:0.07708, lr:7.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.966, tt:5652.049\n",
      "Ep:87, loss:0.00002, loss_test:0.07736, lr:7.40e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.888, tt:5710.156\n",
      "Ep:88, loss:0.00002, loss_test:0.07657, lr:7.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.799, tt:5767.128\n",
      "Ep:89, loss:0.00002, loss_test:0.07678, lr:7.25e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.691, tt:5822.215\n",
      "Ep:90, loss:0.00002, loss_test:0.07600, lr:7.18e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.601, tt:5878.730\n",
      "Ep:91, loss:0.00002, loss_test:0.07873, lr:7.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.553, tt:5938.853\n",
      "Ep:92, loss:0.00002, loss_test:0.07781, lr:7.03e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.470, tt:5995.686\n",
      "Ep:93, loss:0.00002, loss_test:0.07625, lr:6.96e-03, fs:0.79769 (r=0.697,p=0.932),  time:64.377, tt:6051.421\n",
      "Ep:94, loss:0.00002, loss_test:0.07759, lr:6.89e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.341, tt:6112.400\n",
      "Ep:95, loss:0.00002, loss_test:0.07864, lr:6.83e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.284, tt:6171.232\n",
      "Ep:96, loss:0.00002, loss_test:0.07793, lr:6.76e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.221, tt:6229.471\n",
      "Ep:97, loss:0.00002, loss_test:0.07713, lr:6.69e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.158, tt:6287.522\n",
      "Ep:98, loss:0.00002, loss_test:0.07806, lr:6.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.073, tt:6343.272\n",
      "Ep:99, loss:0.00002, loss_test:0.07864, lr:6.56e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.027, tt:6402.657\n",
      "Ep:100, loss:0.00002, loss_test:0.07852, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:63.957, tt:6459.685\n",
      "Ep:101, loss:0.00001, loss_test:0.07775, lr:6.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:63.897, tt:6517.517\n",
      "Ep:102, loss:0.00001, loss_test:0.07788, lr:6.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.841, tt:6575.649\n",
      "Ep:103, loss:0.00001, loss_test:0.07900, lr:6.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:63.796, tt:6634.795\n",
      "Ep:104, loss:0.00001, loss_test:0.07783, lr:6.24e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.746, tt:6693.322\n",
      "Ep:105, loss:0.00001, loss_test:0.07835, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.687, tt:6750.769\n",
      "Ep:106, loss:0.00001, loss_test:0.07883, lr:6.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.629, tt:6808.256\n",
      "Ep:107, loss:0.00001, loss_test:0.07805, lr:6.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.577, tt:6866.359\n",
      "Ep:108, loss:0.00001, loss_test:0.07816, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:63.529, tt:6924.617\n",
      "Ep:109, loss:0.00001, loss_test:0.07875, lr:5.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.496, tt:6984.604\n",
      "Ep:110, loss:0.00001, loss_test:0.07878, lr:5.87e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.462, tt:7044.236\n",
      "Ep:111, loss:0.00001, loss_test:0.07810, lr:5.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.403, tt:7101.135\n",
      "Ep:112, loss:0.00001, loss_test:0.07876, lr:5.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:63.347, tt:7158.254\n",
      "Ep:113, loss:0.00001, loss_test:0.07873, lr:5.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.283, tt:7214.261\n",
      "Ep:114, loss:0.00001, loss_test:0.07976, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.231, tt:7271.516\n",
      "Ep:115, loss:0.00001, loss_test:0.07843, lr:5.58e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.165, tt:7327.143\n",
      "Ep:116, loss:0.00001, loss_test:0.07909, lr:5.53e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.105, tt:7383.302\n",
      "Ep:117, loss:0.00001, loss_test:0.07971, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.070, tt:7442.316\n",
      "Ep:118, loss:0.00001, loss_test:0.07917, lr:5.42e-03, fs:0.80233 (r=0.697,p=0.945),  time:63.019, tt:7499.291\n",
      "Ep:119, loss:0.00001, loss_test:0.07883, lr:5.36e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.985, tt:7558.227\n",
      "Ep:120, loss:0.00001, loss_test:0.07910, lr:5.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.963, tt:7618.533\n",
      "Ep:121, loss:0.00001, loss_test:0.08020, lr:5.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.924, tt:7676.775\n",
      "Ep:122, loss:0.00001, loss_test:0.07869, lr:5.20e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.874, tt:7733.541\n",
      "Ep:123, loss:0.00001, loss_test:0.07889, lr:5.15e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.852, tt:7793.644\n",
      "Ep:124, loss:0.00001, loss_test:0.07958, lr:5.10e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.800, tt:7850.030\n",
      "Ep:125, loss:0.00001, loss_test:0.07891, lr:5.05e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.757, tt:7907.409\n",
      "Ep:126, loss:0.00001, loss_test:0.07934, lr:5.00e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.723, tt:7965.819\n",
      "Ep:127, loss:0.00001, loss_test:0.07945, lr:4.95e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.683, tt:8023.457\n",
      "Ep:128, loss:0.00001, loss_test:0.07923, lr:4.90e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.662, tt:8083.427\n",
      "Ep:129, loss:0.00001, loss_test:0.08038, lr:4.85e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.653, tt:8144.894\n",
      "Ep:130, loss:0.00001, loss_test:0.07943, lr:4.80e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.618, tt:8202.983\n",
      "Ep:131, loss:0.00001, loss_test:0.07961, lr:4.75e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.593, tt:8262.313\n",
      "Ep:132, loss:0.00001, loss_test:0.07962, lr:4.71e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.557, tt:8320.137\n",
      "Ep:133, loss:0.00001, loss_test:0.08002, lr:4.66e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.535, tt:8379.636\n",
      "Ep:134, loss:0.00001, loss_test:0.07977, lr:4.61e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.512, tt:8439.162\n",
      "Ep:135, loss:0.00001, loss_test:0.08062, lr:4.57e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.484, tt:8497.768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00001, loss_test:0.07961, lr:4.52e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.454, tt:8556.243\n",
      "Ep:137, loss:0.00001, loss_test:0.07975, lr:4.48e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.427, tt:8614.923\n",
      "Ep:138, loss:0.00001, loss_test:0.07980, lr:4.43e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.383, tt:8671.254\n",
      "Ep:139, loss:0.00001, loss_test:0.08009, lr:4.39e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.345, tt:8728.293\n",
      "Ep:140, loss:0.00001, loss_test:0.08075, lr:4.34e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.318, tt:8786.900\n",
      "Ep:141, loss:0.00001, loss_test:0.07994, lr:4.30e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.297, tt:8846.174\n",
      "Ep:142, loss:0.00001, loss_test:0.08047, lr:4.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.255, tt:8902.465\n",
      "Ep:143, loss:0.00001, loss_test:0.08009, lr:4.21e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.229, tt:8960.984\n",
      "Ep:144, loss:0.00001, loss_test:0.08076, lr:4.17e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.206, tt:9019.860\n",
      "Ep:145, loss:0.00001, loss_test:0.08047, lr:4.13e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.178, tt:9077.975\n",
      "Ep:146, loss:0.00001, loss_test:0.08048, lr:4.09e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.154, tt:9136.601\n",
      "Ep:147, loss:0.00001, loss_test:0.08036, lr:4.05e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.134, tt:9195.821\n",
      "Ep:148, loss:0.00001, loss_test:0.08127, lr:4.01e-03, fs:0.80233 (r=0.697,p=0.945),  time:62.115, tt:9255.068\n",
      "Ep:149, loss:0.00001, loss_test:0.08073, lr:3.97e-03, fs:0.79769 (r=0.697,p=0.932),  time:62.087, tt:9313.074\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14991, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:5.411, tt:5.411\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14983, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:5.705, tt:11.411\n",
      "Ep:2, loss:0.00000, loss_test:0.14970, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:6.075, tt:18.226\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00000, loss_test:0.14953, lr:1.00e-02, fs:0.64138 (r=0.939,p=0.487),  time:6.732, tt:26.929\n",
      "Ep:4, loss:0.00000, loss_test:0.14926, lr:1.00e-02, fs:0.64138 (r=0.939,p=0.487),  time:7.709, tt:38.544\n",
      "Ep:5, loss:0.00000, loss_test:0.14893, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:8.758, tt:52.547\n",
      "Ep:6, loss:0.00000, loss_test:0.14850, lr:1.00e-02, fs:0.64111 (r=0.929,p=0.489),  time:9.655, tt:67.586\n",
      "Ep:7, loss:0.00000, loss_test:0.14788, lr:1.00e-02, fs:0.63636 (r=0.919,p=0.487),  time:10.572, tt:84.578\n",
      "Ep:8, loss:0.00000, loss_test:0.14702, lr:1.00e-02, fs:0.62191 (r=0.889,p=0.478),  time:11.194, tt:100.743\n",
      "Ep:9, loss:0.00000, loss_test:0.14593, lr:1.00e-02, fs:0.60364 (r=0.838,p=0.472),  time:11.787, tt:117.870\n",
      "Ep:10, loss:0.00000, loss_test:0.14450, lr:1.00e-02, fs:0.59779 (r=0.818,p=0.471),  time:12.278, tt:135.057\n",
      "Ep:11, loss:0.00000, loss_test:0.14254, lr:1.00e-02, fs:0.60769 (r=0.798,p=0.491),  time:12.705, tt:152.464\n",
      "Ep:12, loss:0.00000, loss_test:0.14018, lr:1.00e-02, fs:0.61475 (r=0.758,p=0.517),  time:12.978, tt:168.719\n",
      "Ep:13, loss:0.00000, loss_test:0.13777, lr:1.00e-02, fs:0.60426 (r=0.717,p=0.522),  time:13.313, tt:186.382\n",
      "Ep:14, loss:0.00000, loss_test:0.13652, lr:9.90e-03, fs:0.59716 (r=0.636,p=0.562),  time:13.583, tt:203.743\n",
      "Ep:15, loss:0.00000, loss_test:0.13609, lr:9.80e-03, fs:0.60204 (r=0.596,p=0.608),  time:13.762, tt:220.195\n",
      "Ep:16, loss:0.00000, loss_test:0.13597, lr:9.70e-03, fs:0.59259 (r=0.566,p=0.622),  time:13.948, tt:237.117\n",
      "Ep:17, loss:0.00000, loss_test:0.13561, lr:9.61e-03, fs:0.58511 (r=0.556,p=0.618),  time:14.073, tt:253.315\n",
      "Ep:18, loss:0.00000, loss_test:0.13463, lr:9.51e-03, fs:0.60417 (r=0.586,p=0.624),  time:14.212, tt:270.035\n",
      "Ep:19, loss:0.00000, loss_test:0.13324, lr:9.41e-03, fs:0.61929 (r=0.616,p=0.622),  time:14.352, tt:287.039\n",
      "Ep:20, loss:0.00000, loss_test:0.13218, lr:9.32e-03, fs:0.62745 (r=0.646,p=0.610),  time:14.468, tt:303.823\n",
      "Ep:21, loss:0.00000, loss_test:0.13156, lr:9.23e-03, fs:0.61682 (r=0.667,p=0.574),  time:14.556, tt:320.232\n",
      "Ep:22, loss:0.00000, loss_test:0.13080, lr:9.14e-03, fs:0.61972 (r=0.667,p=0.579),  time:14.653, tt:337.030\n",
      "Ep:23, loss:0.00000, loss_test:0.12983, lr:9.04e-03, fs:0.62559 (r=0.667,p=0.589),  time:14.719, tt:353.262\n",
      "Ep:24, loss:0.00000, loss_test:0.12902, lr:8.95e-03, fs:0.63054 (r=0.646,p=0.615),  time:14.809, tt:370.237\n",
      "Ep:25, loss:0.00000, loss_test:0.12828, lr:8.86e-03, fs:0.62312 (r=0.626,p=0.620),  time:14.868, tt:386.578\n",
      "Ep:26, loss:0.00000, loss_test:0.12772, lr:8.78e-03, fs:0.63212 (r=0.616,p=0.649),  time:14.966, tt:404.086\n",
      "Ep:27, loss:0.00000, loss_test:0.12703, lr:8.69e-03, fs:0.64550 (r=0.616,p=0.678),  time:15.020, tt:420.561\n",
      "Ep:28, loss:0.00000, loss_test:0.12594, lr:8.60e-03, fs:0.64550 (r=0.616,p=0.678),  time:15.074, tt:437.141\n",
      "Ep:29, loss:0.00000, loss_test:0.12464, lr:8.51e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.153, tt:454.590\n",
      "Ep:30, loss:0.00000, loss_test:0.12337, lr:8.43e-03, fs:0.64583 (r=0.626,p=0.667),  time:15.210, tt:471.501\n",
      "Ep:31, loss:0.00000, loss_test:0.12223, lr:8.35e-03, fs:0.64948 (r=0.636,p=0.663),  time:15.273, tt:488.752\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.12123, lr:8.35e-03, fs:0.64615 (r=0.636,p=0.656),  time:15.357, tt:506.774\n",
      "Ep:33, loss:0.00000, loss_test:0.12025, lr:8.35e-03, fs:0.65306 (r=0.646,p=0.660),  time:15.407, tt:523.838\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.11924, lr:8.35e-03, fs:0.65285 (r=0.636,p=0.670),  time:15.499, tt:542.467\n",
      "Ep:35, loss:0.00000, loss_test:0.11846, lr:8.35e-03, fs:0.64583 (r=0.626,p=0.667),  time:15.555, tt:559.986\n",
      "Ep:36, loss:0.00000, loss_test:0.11786, lr:8.35e-03, fs:0.63492 (r=0.606,p=0.667),  time:15.602, tt:577.273\n",
      "Ep:37, loss:0.00000, loss_test:0.11728, lr:8.35e-03, fs:0.62703 (r=0.586,p=0.674),  time:15.646, tt:594.536\n",
      "Ep:38, loss:0.00000, loss_test:0.11656, lr:8.35e-03, fs:0.63043 (r=0.586,p=0.682),  time:15.697, tt:612.179\n",
      "Ep:39, loss:0.00000, loss_test:0.11562, lr:8.35e-03, fs:0.63043 (r=0.586,p=0.682),  time:15.737, tt:629.466\n",
      "Ep:40, loss:0.00000, loss_test:0.11478, lr:8.35e-03, fs:0.63441 (r=0.596,p=0.678),  time:15.771, tt:646.599\n",
      "Ep:41, loss:0.00000, loss_test:0.11405, lr:8.35e-03, fs:0.65625 (r=0.636,p=0.677),  time:15.810, tt:664.026\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00000, loss_test:0.11342, lr:8.35e-03, fs:0.65969 (r=0.636,p=0.685),  time:15.857, tt:681.846\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.11278, lr:8.35e-03, fs:0.66667 (r=0.636,p=0.700),  time:15.889, tt:699.096\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00000, loss_test:0.11209, lr:8.35e-03, fs:0.65591 (r=0.616,p=0.701),  time:15.927, tt:716.732\n",
      "Ep:45, loss:0.00000, loss_test:0.11133, lr:8.35e-03, fs:0.65591 (r=0.616,p=0.701),  time:15.961, tt:734.192\n",
      "Ep:46, loss:0.00000, loss_test:0.11035, lr:8.35e-03, fs:0.66304 (r=0.616,p=0.718),  time:15.995, tt:751.767\n",
      "Ep:47, loss:0.00000, loss_test:0.10921, lr:8.35e-03, fs:0.66304 (r=0.616,p=0.718),  time:16.025, tt:769.182\n",
      "Ep:48, loss:0.00000, loss_test:0.10804, lr:8.35e-03, fs:0.66304 (r=0.616,p=0.718),  time:16.063, tt:787.081\n",
      "Ep:49, loss:0.00000, loss_test:0.10697, lr:8.35e-03, fs:0.67725 (r=0.646,p=0.711),  time:16.087, tt:804.349\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00000, loss_test:0.10597, lr:8.35e-03, fs:0.67725 (r=0.646,p=0.711),  time:16.100, tt:821.111\n",
      "Ep:51, loss:0.00000, loss_test:0.10497, lr:8.35e-03, fs:0.68817 (r=0.646,p=0.736),  time:16.126, tt:838.563\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00000, loss_test:0.10405, lr:8.35e-03, fs:0.69565 (r=0.646,p=0.753),  time:16.173, tt:857.174\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00000, loss_test:0.10325, lr:8.35e-03, fs:0.69565 (r=0.646,p=0.753),  time:16.203, tt:874.981\n",
      "Ep:54, loss:0.00000, loss_test:0.10243, lr:8.35e-03, fs:0.74074 (r=0.707,p=0.778),  time:16.234, tt:892.857\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00000, loss_test:0.10167, lr:8.35e-03, fs:0.75000 (r=0.727,p=0.774),  time:16.257, tt:910.369\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00000, loss_test:0.10106, lr:8.35e-03, fs:0.75000 (r=0.727,p=0.774),  time:16.286, tt:928.320\n",
      "Ep:57, loss:0.00000, loss_test:0.10054, lr:8.35e-03, fs:0.75000 (r=0.727,p=0.774),  time:16.328, tt:947.028\n",
      "Ep:58, loss:0.00000, loss_test:0.10004, lr:8.35e-03, fs:0.74346 (r=0.717,p=0.772),  time:16.346, tt:964.427\n",
      "Ep:59, loss:0.00000, loss_test:0.09955, lr:8.35e-03, fs:0.74346 (r=0.717,p=0.772),  time:16.368, tt:982.057\n",
      "Ep:60, loss:0.00000, loss_test:0.09901, lr:8.35e-03, fs:0.74346 (r=0.717,p=0.772),  time:16.393, tt:999.950\n",
      "Ep:61, loss:0.00000, loss_test:0.09840, lr:8.35e-03, fs:0.74346 (r=0.717,p=0.772),  time:16.404, tt:1017.078\n",
      "Ep:62, loss:0.00000, loss_test:0.09780, lr:8.35e-03, fs:0.75132 (r=0.717,p=0.789),  time:16.418, tt:1034.350\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00000, loss_test:0.09719, lr:8.35e-03, fs:0.76440 (r=0.737,p=0.793),  time:16.438, tt:1052.000\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.09659, lr:8.35e-03, fs:0.76440 (r=0.737,p=0.793),  time:16.452, tt:1069.411\n",
      "Ep:65, loss:0.00000, loss_test:0.09604, lr:8.35e-03, fs:0.77249 (r=0.737,p=0.811),  time:16.477, tt:1087.454\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00000, loss_test:0.09554, lr:8.35e-03, fs:0.77249 (r=0.737,p=0.811),  time:16.500, tt:1105.487\n",
      "Ep:67, loss:0.00000, loss_test:0.09499, lr:8.35e-03, fs:0.77660 (r=0.737,p=0.820),  time:16.519, tt:1123.275\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00000, loss_test:0.09440, lr:8.35e-03, fs:0.78307 (r=0.747,p=0.822),  time:16.538, tt:1141.118\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00000, loss_test:0.09384, lr:8.35e-03, fs:0.80208 (r=0.778,p=0.828),  time:16.561, tt:1159.237\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00000, loss_test:0.09338, lr:8.35e-03, fs:0.80208 (r=0.778,p=0.828),  time:16.586, tt:1177.630\n",
      "Ep:71, loss:0.00000, loss_test:0.09298, lr:8.35e-03, fs:0.79581 (r=0.768,p=0.826),  time:16.597, tt:1195.004\n",
      "Ep:72, loss:0.00000, loss_test:0.09258, lr:8.35e-03, fs:0.79365 (r=0.758,p=0.833),  time:16.604, tt:1212.128\n",
      "Ep:73, loss:0.00000, loss_test:0.09211, lr:8.35e-03, fs:0.78947 (r=0.758,p=0.824),  time:16.609, tt:1229.072\n",
      "Ep:74, loss:0.00000, loss_test:0.09160, lr:8.35e-03, fs:0.79365 (r=0.758,p=0.833),  time:16.624, tt:1246.791\n",
      "Ep:75, loss:0.00000, loss_test:0.09104, lr:8.35e-03, fs:0.79365 (r=0.758,p=0.833),  time:16.634, tt:1264.221\n",
      "Ep:76, loss:0.00000, loss_test:0.09048, lr:8.35e-03, fs:0.80000 (r=0.768,p=0.835),  time:16.646, tt:1281.737\n",
      "Ep:77, loss:0.00000, loss_test:0.08991, lr:8.35e-03, fs:0.80000 (r=0.768,p=0.835),  time:16.672, tt:1300.410\n",
      "Ep:78, loss:0.00000, loss_test:0.08942, lr:8.35e-03, fs:0.80423 (r=0.768,p=0.844),  time:16.673, tt:1317.201\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00000, loss_test:0.08892, lr:8.35e-03, fs:0.80851 (r=0.768,p=0.854),  time:16.682, tt:1334.587\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00000, loss_test:0.08844, lr:8.35e-03, fs:0.80851 (r=0.768,p=0.854),  time:16.690, tt:1351.911\n",
      "Ep:81, loss:0.00000, loss_test:0.08793, lr:8.35e-03, fs:0.81481 (r=0.778,p=0.856),  time:16.696, tt:1369.086\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00000, loss_test:0.08741, lr:8.35e-03, fs:0.81481 (r=0.778,p=0.856),  time:16.705, tt:1386.541\n",
      "Ep:83, loss:0.00000, loss_test:0.08691, lr:8.35e-03, fs:0.81481 (r=0.778,p=0.856),  time:16.725, tt:1404.896\n",
      "Ep:84, loss:0.00000, loss_test:0.08640, lr:8.35e-03, fs:0.81481 (r=0.778,p=0.856),  time:16.730, tt:1422.029\n",
      "Ep:85, loss:0.00000, loss_test:0.08586, lr:8.35e-03, fs:0.81481 (r=0.778,p=0.856),  time:16.737, tt:1439.404\n",
      "Ep:86, loss:0.00000, loss_test:0.08537, lr:8.35e-03, fs:0.81481 (r=0.778,p=0.856),  time:16.744, tt:1456.747\n",
      "Ep:87, loss:0.00000, loss_test:0.08493, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:16.750, tt:1473.966\n",
      "Ep:88, loss:0.00000, loss_test:0.08454, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:16.761, tt:1491.757\n",
      "Ep:89, loss:0.00000, loss_test:0.08405, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:16.776, tt:1509.855\n",
      "Ep:90, loss:0.00000, loss_test:0.08349, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:16.781, tt:1527.113\n",
      "Ep:91, loss:0.00000, loss_test:0.08292, lr:8.35e-03, fs:0.80851 (r=0.768,p=0.854),  time:16.787, tt:1544.366\n",
      "Ep:92, loss:0.00000, loss_test:0.08237, lr:8.35e-03, fs:0.81720 (r=0.768,p=0.874),  time:16.792, tt:1561.702\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00000, loss_test:0.08184, lr:8.35e-03, fs:0.81720 (r=0.768,p=0.874),  time:16.795, tt:1578.729\n",
      "Ep:94, loss:0.00000, loss_test:0.08135, lr:8.35e-03, fs:0.81081 (r=0.758,p=0.872),  time:16.809, tt:1596.836\n",
      "Ep:95, loss:0.00000, loss_test:0.08087, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.813, tt:1614.060\n",
      "Ep:96, loss:0.00000, loss_test:0.08042, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.827, tt:1632.187\n",
      "Ep:97, loss:0.00000, loss_test:0.08006, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.834, tt:1649.770\n",
      "Ep:98, loss:0.00000, loss_test:0.07973, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.844, tt:1667.601\n",
      "Ep:99, loss:0.00000, loss_test:0.07933, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.848, tt:1684.849\n",
      "Ep:100, loss:0.00000, loss_test:0.07886, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.849, tt:1701.780\n",
      "Ep:101, loss:0.00000, loss_test:0.07843, lr:8.35e-03, fs:0.82162 (r=0.768,p=0.884),  time:16.844, tt:1718.043\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00000, loss_test:0.07808, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.848, tt:1735.357\n",
      "Ep:103, loss:0.00000, loss_test:0.07779, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.850, tt:1752.432\n",
      "Ep:104, loss:0.00000, loss_test:0.07752, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:16.852, tt:1769.412\n",
      "Ep:105, loss:0.00000, loss_test:0.07723, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:16.853, tt:1786.395\n",
      "Ep:106, loss:0.00000, loss_test:0.07693, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:16.854, tt:1803.386\n",
      "Ep:107, loss:0.00000, loss_test:0.07663, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:16.855, tt:1820.297\n",
      "Ep:108, loss:0.00000, loss_test:0.07628, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:16.858, tt:1837.576\n",
      "Ep:109, loss:0.00000, loss_test:0.07588, lr:8.35e-03, fs:0.82418 (r=0.758,p=0.904),  time:16.861, tt:1854.679\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.07546, lr:8.35e-03, fs:0.82418 (r=0.758,p=0.904),  time:16.867, tt:1872.243\n",
      "Ep:111, loss:0.00000, loss_test:0.07512, lr:8.35e-03, fs:0.82418 (r=0.758,p=0.904),  time:16.881, tt:1890.674\n",
      "Ep:112, loss:0.00000, loss_test:0.07481, lr:8.35e-03, fs:0.82418 (r=0.758,p=0.904),  time:16.890, tt:1908.601\n",
      "Ep:113, loss:0.00000, loss_test:0.07442, lr:8.35e-03, fs:0.82873 (r=0.758,p=0.915),  time:16.897, tt:1926.204\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00000, loss_test:0.07396, lr:8.35e-03, fs:0.84153 (r=0.778,p=0.917),  time:16.896, tt:1943.002\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00000, loss_test:0.07362, lr:8.35e-03, fs:0.84783 (r=0.788,p=0.918),  time:16.897, tt:1960.082\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00000, loss_test:0.07346, lr:8.35e-03, fs:0.84153 (r=0.778,p=0.917),  time:16.910, tt:1978.413\n",
      "Ep:117, loss:0.00000, loss_test:0.07321, lr:8.35e-03, fs:0.84153 (r=0.778,p=0.917),  time:16.920, tt:1996.543\n",
      "Ep:118, loss:0.00000, loss_test:0.07285, lr:8.35e-03, fs:0.85870 (r=0.798,p=0.929),  time:16.922, tt:2013.711\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00000, loss_test:0.07251, lr:8.35e-03, fs:0.86339 (r=0.798,p=0.940),  time:16.933, tt:2032.016\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00000, loss_test:0.07227, lr:8.35e-03, fs:0.86339 (r=0.798,p=0.940),  time:16.938, tt:2049.489\n",
      "Ep:121, loss:0.00000, loss_test:0.07203, lr:8.35e-03, fs:0.86339 (r=0.798,p=0.940),  time:16.940, tt:2066.717\n",
      "Ep:122, loss:0.00000, loss_test:0.07175, lr:8.35e-03, fs:0.86339 (r=0.798,p=0.940),  time:16.950, tt:2084.897\n",
      "Ep:123, loss:0.00000, loss_test:0.07145, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:16.953, tt:2102.139\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00000, loss_test:0.07122, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:16.958, tt:2119.729\n",
      "Ep:125, loss:0.00000, loss_test:0.07097, lr:8.35e-03, fs:0.87568 (r=0.818,p=0.942),  time:16.968, tt:2138.000\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.07077, lr:8.35e-03, fs:0.87568 (r=0.818,p=0.942),  time:16.975, tt:2155.801\n",
      "Ep:127, loss:0.00000, loss_test:0.07075, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:16.978, tt:2173.148\n",
      "Ep:128, loss:0.00000, loss_test:0.07077, lr:8.35e-03, fs:0.86339 (r=0.798,p=0.940),  time:16.986, tt:2191.152\n",
      "Ep:129, loss:0.00000, loss_test:0.07064, lr:8.35e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.000, tt:2209.968\n",
      "Ep:130, loss:0.00000, loss_test:0.07032, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.003, tt:2227.418\n",
      "Ep:131, loss:0.00000, loss_test:0.07008, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.009, tt:2245.210\n",
      "Ep:132, loss:0.00000, loss_test:0.06999, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.013, tt:2262.701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.06986, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.015, tt:2280.021\n",
      "Ep:134, loss:0.00000, loss_test:0.06960, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.022, tt:2297.904\n",
      "Ep:135, loss:0.00000, loss_test:0.06938, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.024, tt:2315.264\n",
      "Ep:136, loss:0.00000, loss_test:0.06948, lr:8.35e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.027, tt:2332.687\n",
      "Ep:137, loss:0.00000, loss_test:0.06952, lr:8.26e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.025, tt:2349.479\n",
      "Ep:138, loss:0.00000, loss_test:0.06939, lr:8.18e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.023, tt:2366.262\n",
      "Ep:139, loss:0.00000, loss_test:0.06921, lr:8.10e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.016, tt:2382.294\n",
      "Ep:140, loss:0.00000, loss_test:0.06924, lr:8.02e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.016, tt:2399.196\n",
      "Ep:141, loss:0.00000, loss_test:0.06932, lr:7.94e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.012, tt:2415.731\n",
      "Ep:142, loss:0.00000, loss_test:0.06922, lr:7.86e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.013, tt:2432.814\n",
      "Ep:143, loss:0.00000, loss_test:0.06905, lr:7.78e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.009, tt:2449.225\n",
      "Ep:144, loss:0.00000, loss_test:0.06900, lr:7.70e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.003, tt:2465.479\n",
      "Ep:145, loss:0.00000, loss_test:0.06913, lr:7.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.003, tt:2482.426\n",
      "Ep:146, loss:0.00000, loss_test:0.06910, lr:7.55e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.004, tt:2499.649\n",
      "Ep:147, loss:0.00000, loss_test:0.06897, lr:7.47e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.008, tt:2517.184\n",
      "Ep:148, loss:0.00000, loss_test:0.06885, lr:7.40e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.005, tt:2533.671\n",
      "Ep:149, loss:0.00000, loss_test:0.06885, lr:7.32e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.005, tt:2550.729\n",
      "Ep:150, loss:0.00000, loss_test:0.06886, lr:7.25e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.007, tt:2568.003\n",
      "Ep:151, loss:0.00000, loss_test:0.06889, lr:7.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.006, tt:2584.915\n",
      "Ep:152, loss:0.00000, loss_test:0.06883, lr:7.11e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.014, tt:2603.074\n",
      "Ep:153, loss:0.00000, loss_test:0.06874, lr:7.03e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.017, tt:2620.553\n",
      "Ep:154, loss:0.00000, loss_test:0.06867, lr:6.96e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.015, tt:2637.400\n",
      "Ep:155, loss:0.00000, loss_test:0.06869, lr:6.89e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.015, tt:2654.327\n",
      "Ep:156, loss:0.00000, loss_test:0.06876, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:17.017, tt:2671.658\n",
      "Ep:157, loss:0.00000, loss_test:0.06868, lr:6.76e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.015, tt:2688.417\n",
      "Ep:158, loss:0.00000, loss_test:0.06859, lr:6.69e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.016, tt:2705.570\n",
      "Ep:159, loss:0.00000, loss_test:0.06859, lr:6.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.019, tt:2723.066\n",
      "Ep:160, loss:0.00000, loss_test:0.06863, lr:6.56e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.014, tt:2739.272\n",
      "Ep:161, loss:0.00000, loss_test:0.06861, lr:6.49e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.016, tt:2756.644\n",
      "Ep:162, loss:0.00000, loss_test:0.06847, lr:6.43e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.018, tt:2773.927\n",
      "Ep:163, loss:0.00000, loss_test:0.06846, lr:6.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.021, tt:2791.468\n",
      "Ep:164, loss:0.00000, loss_test:0.06854, lr:6.30e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.027, tt:2809.407\n",
      "Ep:165, loss:0.00000, loss_test:0.06850, lr:6.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.031, tt:2827.186\n",
      "Ep:166, loss:0.00000, loss_test:0.06843, lr:6.17e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.036, tt:2844.977\n",
      "Ep:167, loss:0.00000, loss_test:0.06836, lr:6.11e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.038, tt:2862.413\n",
      "Ep:168, loss:0.00000, loss_test:0.06826, lr:6.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.042, tt:2880.073\n",
      "Ep:169, loss:0.00000, loss_test:0.06821, lr:5.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.050, tt:2898.510\n",
      "Ep:170, loss:0.00000, loss_test:0.06816, lr:5.93e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.051, tt:2915.669\n",
      "Ep:171, loss:0.00000, loss_test:0.06816, lr:5.87e-03, fs:0.85714 (r=0.788,p=0.940),  time:17.052, tt:2932.952\n",
      "Ep:172, loss:0.00000, loss_test:0.06818, lr:5.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:17.055, tt:2950.575\n",
      "Ep:173, loss:0.00000, loss_test:0.06814, lr:5.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:17.059, tt:2968.193\n",
      "Ep:174, loss:0.00000, loss_test:0.06806, lr:5.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:17.062, tt:2985.896\n",
      "Ep:175, loss:0.00000, loss_test:0.06796, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.066, tt:3003.695\n",
      "Ep:176, loss:0.00000, loss_test:0.06789, lr:5.58e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.076, tt:3022.406\n",
      "Ep:177, loss:0.00000, loss_test:0.06786, lr:5.53e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.079, tt:3040.073\n",
      "Ep:178, loss:0.00000, loss_test:0.06778, lr:5.47e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.085, tt:3058.181\n",
      "Ep:179, loss:0.00000, loss_test:0.06769, lr:5.42e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.092, tt:3076.564\n",
      "Ep:180, loss:0.00000, loss_test:0.06764, lr:5.36e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.093, tt:3093.811\n",
      "Ep:181, loss:0.00000, loss_test:0.06763, lr:5.31e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.099, tt:3111.945\n",
      "Ep:182, loss:0.00000, loss_test:0.06760, lr:5.26e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.101, tt:3129.544\n",
      "Ep:183, loss:0.00000, loss_test:0.06755, lr:5.20e-03, fs:0.86667 (r=0.788,p=0.963),  time:17.104, tt:3147.215\n",
      "Ep:184, loss:0.00000, loss_test:0.06748, lr:5.15e-03, fs:0.86188 (r=0.788,p=0.951),  time:17.113, tt:3165.883\n",
      "Ep:185, loss:0.00000, loss_test:0.06746, lr:5.10e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.123, tt:3184.930\n",
      "Ep:186, loss:0.00000, loss_test:0.06746, lr:5.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:17.127, tt:3202.689\n",
      "Ep:187, loss:0.00000, loss_test:0.06746, lr:5.00e-03, fs:0.86517 (r=0.778,p=0.975),  time:17.131, tt:3220.564\n",
      "Ep:188, loss:0.00000, loss_test:0.06736, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:17.134, tt:3238.391\n",
      "Ep:189, loss:0.00000, loss_test:0.06731, lr:4.90e-03, fs:0.86517 (r=0.778,p=0.975),  time:17.139, tt:3256.468\n",
      "Ep:190, loss:0.00000, loss_test:0.06733, lr:4.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:17.142, tt:3274.189\n",
      "Ep:191, loss:0.00000, loss_test:0.06735, lr:4.80e-03, fs:0.86517 (r=0.778,p=0.975),  time:17.147, tt:3292.311\n",
      "Ep:192, loss:0.00000, loss_test:0.06730, lr:4.75e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.149, tt:3309.847\n",
      "Ep:193, loss:0.00000, loss_test:0.06723, lr:4.71e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.151, tt:3327.379\n",
      "Ep:194, loss:0.00000, loss_test:0.06719, lr:4.66e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.155, tt:3345.306\n",
      "Ep:195, loss:0.00000, loss_test:0.06720, lr:4.61e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.161, tt:3363.473\n",
      "Ep:196, loss:0.00000, loss_test:0.06718, lr:4.57e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.166, tt:3381.780\n",
      "Ep:197, loss:0.00000, loss_test:0.06708, lr:4.52e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.169, tt:3399.493\n",
      "Ep:198, loss:0.00000, loss_test:0.06701, lr:4.48e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.174, tt:3417.706\n",
      "Ep:199, loss:0.00000, loss_test:0.06699, lr:4.43e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.177, tt:3435.434\n",
      "Ep:200, loss:0.00000, loss_test:0.06695, lr:4.39e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.180, tt:3453.212\n",
      "Ep:201, loss:0.00000, loss_test:0.06689, lr:4.34e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.183, tt:3470.955\n",
      "Ep:202, loss:0.00000, loss_test:0.06685, lr:4.30e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.185, tt:3488.466\n",
      "Ep:203, loss:0.00000, loss_test:0.06685, lr:4.26e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.185, tt:3505.745\n",
      "Ep:204, loss:0.00000, loss_test:0.06687, lr:4.21e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.185, tt:3522.910\n",
      "Ep:205, loss:0.00000, loss_test:0.06690, lr:4.17e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.185, tt:3540.021\n",
      "Ep:206, loss:0.00000, loss_test:0.06686, lr:4.13e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.183, tt:3556.779\n",
      "Ep:207, loss:0.00000, loss_test:0.06680, lr:4.09e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.185, tt:3574.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.06681, lr:4.05e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.184, tt:3591.520\n",
      "Ep:209, loss:0.00000, loss_test:0.06683, lr:4.01e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.183, tt:3608.479\n",
      "Ep:210, loss:0.00000, loss_test:0.06684, lr:3.97e-03, fs:0.87006 (r=0.778,p=0.987),  time:17.187, tt:3626.354\n",
      "Ep:211, loss:0.00000, loss_test:0.06685, lr:3.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.183, tt:3642.853\n",
      "Ep:212, loss:0.00000, loss_test:0.06685, lr:3.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.184, tt:3660.297\n",
      "Ep:213, loss:0.00000, loss_test:0.06685, lr:3.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.184, tt:3677.438\n",
      "Ep:214, loss:0.00000, loss_test:0.06683, lr:3.81e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.187, tt:3695.261\n",
      "Ep:215, loss:0.00000, loss_test:0.06678, lr:3.77e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.188, tt:3712.691\n",
      "Ep:216, loss:0.00000, loss_test:0.06677, lr:3.73e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.190, tt:3730.198\n",
      "Ep:217, loss:0.00000, loss_test:0.06676, lr:3.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.191, tt:3747.723\n",
      "Ep:218, loss:0.00000, loss_test:0.06679, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.198, tt:3766.309\n",
      "Ep:219, loss:0.00000, loss_test:0.06681, lr:3.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.198, tt:3783.569\n",
      "Ep:220, loss:0.00000, loss_test:0.06683, lr:3.59e-03, fs:0.86364 (r=0.768,p=0.987),  time:17.196, tt:3800.261\n",
      "Ep:221, loss:0.00000, loss_test:0.06685, lr:3.55e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.194, tt:3817.114\n",
      "Ep:222, loss:0.00000, loss_test:0.06690, lr:3.52e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.196, tt:3834.733\n",
      "Ep:223, loss:0.00000, loss_test:0.06692, lr:3.48e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.197, tt:3852.148\n",
      "Ep:224, loss:0.00000, loss_test:0.06691, lr:3.45e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.197, tt:3869.212\n",
      "Ep:225, loss:0.00000, loss_test:0.06689, lr:3.41e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.198, tt:3886.831\n",
      "Ep:226, loss:0.00000, loss_test:0.06688, lr:3.38e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.199, tt:3904.253\n",
      "Ep:227, loss:0.00000, loss_test:0.06688, lr:3.34e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.204, tt:3922.440\n",
      "Ep:228, loss:0.00000, loss_test:0.06686, lr:3.31e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.206, tt:3940.210\n",
      "Ep:229, loss:0.00000, loss_test:0.06684, lr:3.28e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.211, tt:3958.555\n",
      "Ep:230, loss:0.00000, loss_test:0.06680, lr:3.24e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.213, tt:3976.271\n",
      "Ep:231, loss:0.00000, loss_test:0.06678, lr:3.21e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.219, tt:3994.842\n",
      "Ep:232, loss:0.00000, loss_test:0.06678, lr:3.18e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.221, tt:4012.446\n",
      "Ep:233, loss:0.00000, loss_test:0.06678, lr:3.15e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.222, tt:4029.913\n",
      "Ep:234, loss:0.00000, loss_test:0.06678, lr:3.12e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.220, tt:4046.604\n",
      "Ep:235, loss:0.00000, loss_test:0.06679, lr:3.09e-03, fs:0.85057 (r=0.747,p=0.987),  time:17.222, tt:4064.376\n",
      "Ep:236, loss:0.00000, loss_test:0.06678, lr:3.05e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.227, tt:4082.715\n",
      "Ep:237, loss:0.00000, loss_test:0.06675, lr:3.02e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.229, tt:4100.478\n",
      "Ep:238, loss:0.00000, loss_test:0.06674, lr:2.99e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.231, tt:4118.139\n",
      "Ep:239, loss:0.00000, loss_test:0.06674, lr:2.96e-03, fs:0.85714 (r=0.758,p=0.987),  time:17.234, tt:4136.159\n",
      "Ep:240, loss:0.00000, loss_test:0.06679, lr:2.93e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.236, tt:4153.938\n",
      "Ep:241, loss:0.00000, loss_test:0.06683, lr:2.90e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.236, tt:4171.196\n",
      "Ep:242, loss:0.00000, loss_test:0.06682, lr:2.88e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.239, tt:4188.979\n",
      "Ep:243, loss:0.00000, loss_test:0.06683, lr:2.85e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.242, tt:4206.935\n",
      "Ep:244, loss:0.00000, loss_test:0.06684, lr:2.82e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.245, tt:4224.938\n",
      "Ep:245, loss:0.00000, loss_test:0.06687, lr:2.79e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.246, tt:4242.637\n",
      "Ep:246, loss:0.00000, loss_test:0.06689, lr:2.76e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.247, tt:4260.089\n",
      "Ep:247, loss:0.00000, loss_test:0.06689, lr:2.73e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.245, tt:4276.821\n",
      "Ep:248, loss:0.00000, loss_test:0.06688, lr:2.71e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.246, tt:4294.208\n",
      "Ep:249, loss:0.00000, loss_test:0.06689, lr:2.68e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.249, tt:4312.348\n",
      "Ep:250, loss:0.00000, loss_test:0.06690, lr:2.65e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.254, tt:4330.877\n",
      "Ep:251, loss:0.00000, loss_test:0.06689, lr:2.63e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.256, tt:4348.496\n",
      "Ep:252, loss:0.00000, loss_test:0.06687, lr:2.60e-03, fs:0.84393 (r=0.737,p=0.986),  time:17.260, tt:4366.731\n",
      "Ep:253, loss:0.00000, loss_test:0.06686, lr:2.57e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.261, tt:4384.239\n",
      "Ep:254, loss:0.00000, loss_test:0.06684, lr:2.55e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.266, tt:4402.935\n",
      "Ep:255, loss:0.00000, loss_test:0.06683, lr:2.52e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.269, tt:4420.911\n",
      "Ep:256, loss:0.00000, loss_test:0.06680, lr:2.50e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.270, tt:4438.439\n",
      "Ep:257, loss:0.00000, loss_test:0.06679, lr:2.47e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.276, tt:4457.179\n",
      "Ep:258, loss:0.00000, loss_test:0.06678, lr:2.45e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.280, tt:4475.474\n",
      "Ep:259, loss:0.00000, loss_test:0.06679, lr:2.42e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.285, tt:4493.991\n",
      "Ep:260, loss:0.00000, loss_test:0.06680, lr:2.40e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.290, tt:4512.746\n",
      "Ep:261, loss:0.00000, loss_test:0.06681, lr:2.38e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.297, tt:4531.725\n",
      "Ep:262, loss:0.00000, loss_test:0.06680, lr:2.35e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.304, tt:4550.892\n",
      "Ep:263, loss:0.00000, loss_test:0.06679, lr:2.33e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.307, tt:4569.003\n",
      "Ep:264, loss:0.00000, loss_test:0.06679, lr:2.31e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.309, tt:4586.934\n",
      "Ep:265, loss:0.00000, loss_test:0.06680, lr:2.28e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.313, tt:4605.385\n",
      "Ep:266, loss:0.00000, loss_test:0.06681, lr:2.26e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.317, tt:4623.648\n",
      "Ep:267, loss:0.00000, loss_test:0.06684, lr:2.24e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.320, tt:4641.683\n",
      "Ep:268, loss:0.00000, loss_test:0.06685, lr:2.21e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.323, tt:4659.895\n",
      "Ep:269, loss:0.00000, loss_test:0.06686, lr:2.19e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.328, tt:4678.634\n",
      "Ep:270, loss:0.00000, loss_test:0.06687, lr:2.17e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.335, tt:4697.837\n",
      "Ep:271, loss:0.00000, loss_test:0.06688, lr:2.15e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.339, tt:4716.281\n",
      "Ep:272, loss:0.00000, loss_test:0.06688, lr:2.13e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.342, tt:4734.248\n",
      "Ep:273, loss:0.00000, loss_test:0.06688, lr:2.11e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.347, tt:4753.150\n",
      "Ep:274, loss:0.00000, loss_test:0.06688, lr:2.08e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.351, tt:4771.417\n",
      "Ep:275, loss:0.00000, loss_test:0.06686, lr:2.06e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.353, tt:4789.333\n",
      "Ep:276, loss:0.00000, loss_test:0.06685, lr:2.04e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.358, tt:4808.177\n",
      "Ep:277, loss:0.00000, loss_test:0.06684, lr:2.02e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.364, tt:4827.065\n",
      "Ep:278, loss:0.00000, loss_test:0.06683, lr:2.00e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.364, tt:4844.508\n",
      "Ep:279, loss:0.00000, loss_test:0.06682, lr:1.98e-03, fs:0.83041 (r=0.717,p=0.986),  time:17.361, tt:4861.164\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14642, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.701, tt:15.701\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14626, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.538, tt:31.076\n",
      "Ep:2, loss:0.00000, loss_test:0.14602, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.494, tt:46.482\n",
      "Ep:3, loss:0.00000, loss_test:0.14570, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.288, tt:61.153\n",
      "Ep:4, loss:0.00000, loss_test:0.14527, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.887, tt:74.433\n",
      "Ep:5, loss:0.00000, loss_test:0.14474, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:14.995, tt:89.968\n",
      "Ep:6, loss:0.00000, loss_test:0.14407, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:14.803, tt:103.623\n",
      "Ep:7, loss:0.00000, loss_test:0.14320, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:15.212, tt:121.698\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00000, loss_test:0.14209, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:15.637, tt:140.732\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00000, loss_test:0.14068, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:15.947, tt:159.465\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00000, loss_test:0.13898, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:16.181, tt:177.990\n",
      "Ep:11, loss:0.00000, loss_test:0.13704, lr:1.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:16.361, tt:196.333\n",
      "Ep:12, loss:0.00000, loss_test:0.13508, lr:1.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:16.591, tt:215.689\n",
      "Ep:13, loss:0.00000, loss_test:0.13317, lr:1.00e-02, fs:0.62857 (r=0.778,p=0.527),  time:16.768, tt:234.754\n",
      "Ep:14, loss:0.00000, loss_test:0.13157, lr:1.00e-02, fs:0.59633 (r=0.657,p=0.546),  time:16.897, tt:253.461\n",
      "Ep:15, loss:0.00000, loss_test:0.13138, lr:1.00e-02, fs:0.58937 (r=0.616,p=0.565),  time:17.045, tt:272.724\n",
      "Ep:16, loss:0.00000, loss_test:0.13187, lr:1.00e-02, fs:0.58883 (r=0.586,p=0.592),  time:17.255, tt:293.343\n",
      "Ep:17, loss:0.00000, loss_test:0.13217, lr:1.00e-02, fs:0.57895 (r=0.556,p=0.604),  time:17.371, tt:312.681\n",
      "Ep:18, loss:0.00000, loss_test:0.13127, lr:1.00e-02, fs:0.58639 (r=0.566,p=0.609),  time:17.475, tt:332.024\n",
      "Ep:19, loss:0.00000, loss_test:0.12965, lr:1.00e-02, fs:0.61307 (r=0.616,p=0.610),  time:17.579, tt:351.583\n",
      "Ep:20, loss:0.00000, loss_test:0.12835, lr:1.00e-02, fs:0.60488 (r=0.626,p=0.585),  time:17.640, tt:370.442\n",
      "Ep:21, loss:0.00000, loss_test:0.12746, lr:9.90e-03, fs:0.60377 (r=0.646,p=0.566),  time:17.704, tt:389.485\n",
      "Ep:22, loss:0.00000, loss_test:0.12665, lr:9.80e-03, fs:0.60377 (r=0.646,p=0.566),  time:17.725, tt:407.668\n",
      "Ep:23, loss:0.00000, loss_test:0.12574, lr:9.70e-03, fs:0.60664 (r=0.646,p=0.571),  time:17.779, tt:426.708\n",
      "Ep:24, loss:0.00000, loss_test:0.12478, lr:9.61e-03, fs:0.61538 (r=0.646,p=0.587),  time:17.850, tt:446.255\n",
      "Ep:25, loss:0.00000, loss_test:0.12406, lr:9.51e-03, fs:0.63054 (r=0.646,p=0.615),  time:17.887, tt:465.070\n",
      "Ep:26, loss:0.00000, loss_test:0.12390, lr:9.41e-03, fs:0.63590 (r=0.626,p=0.646),  time:17.922, tt:483.901\n",
      "Ep:27, loss:0.00000, loss_test:0.12343, lr:9.32e-03, fs:0.64583 (r=0.626,p=0.667),  time:17.936, tt:502.204\n",
      "Ep:28, loss:0.00000, loss_test:0.12221, lr:9.23e-03, fs:0.65285 (r=0.636,p=0.670),  time:17.945, tt:520.397\n",
      "Ep:29, loss:0.00000, loss_test:0.12044, lr:9.14e-03, fs:0.64646 (r=0.646,p=0.646),  time:17.968, tt:539.044\n",
      "Ep:30, loss:0.00000, loss_test:0.11875, lr:9.04e-03, fs:0.65000 (r=0.657,p=0.644),  time:17.985, tt:557.535\n",
      "Ep:31, loss:0.00000, loss_test:0.11736, lr:8.95e-03, fs:0.66341 (r=0.687,p=0.642),  time:17.991, tt:575.715\n",
      "Ep:32, loss:0.00000, loss_test:0.11622, lr:8.86e-03, fs:0.66019 (r=0.687,p=0.636),  time:18.036, tt:595.173\n",
      "Ep:33, loss:0.00000, loss_test:0.11532, lr:8.78e-03, fs:0.66995 (r=0.687,p=0.654),  time:18.046, tt:613.548\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.11473, lr:8.78e-03, fs:0.67662 (r=0.687,p=0.667),  time:18.071, tt:632.501\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00000, loss_test:0.11435, lr:8.78e-03, fs:0.68687 (r=0.687,p=0.687),  time:18.096, tt:651.466\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00000, loss_test:0.11390, lr:8.78e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.081, tt:668.998\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.11313, lr:8.78e-03, fs:0.68063 (r=0.657,p=0.707),  time:18.123, tt:688.655\n",
      "Ep:38, loss:0.00000, loss_test:0.11214, lr:8.78e-03, fs:0.68750 (r=0.667,p=0.710),  time:18.123, tt:706.798\n",
      "Ep:39, loss:0.00000, loss_test:0.11100, lr:8.78e-03, fs:0.69430 (r=0.677,p=0.713),  time:18.119, tt:724.759\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.10984, lr:8.78e-03, fs:0.69744 (r=0.687,p=0.708),  time:18.134, tt:743.481\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00000, loss_test:0.10892, lr:8.78e-03, fs:0.68718 (r=0.677,p=0.698),  time:18.119, tt:761.003\n",
      "Ep:42, loss:0.00000, loss_test:0.10830, lr:8.78e-03, fs:0.69430 (r=0.677,p=0.713),  time:18.137, tt:779.874\n",
      "Ep:43, loss:0.00000, loss_test:0.10803, lr:8.78e-03, fs:0.69474 (r=0.667,p=0.725),  time:18.123, tt:797.429\n",
      "Ep:44, loss:0.00000, loss_test:0.10790, lr:8.78e-03, fs:0.69474 (r=0.667,p=0.725),  time:18.117, tt:815.248\n",
      "Ep:45, loss:0.00000, loss_test:0.10761, lr:8.78e-03, fs:0.70588 (r=0.667,p=0.750),  time:18.135, tt:834.208\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00000, loss_test:0.10693, lr:8.78e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.151, tt:853.096\n",
      "Ep:47, loss:0.00000, loss_test:0.10593, lr:8.78e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.168, tt:872.048\n",
      "Ep:48, loss:0.00000, loss_test:0.10494, lr:8.78e-03, fs:0.69841 (r=0.667,p=0.733),  time:18.152, tt:889.460\n",
      "Ep:49, loss:0.00000, loss_test:0.10429, lr:8.78e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.158, tt:907.916\n",
      "Ep:50, loss:0.00000, loss_test:0.10400, lr:8.78e-03, fs:0.70270 (r=0.657,p=0.756),  time:18.165, tt:926.406\n",
      "Ep:51, loss:0.00000, loss_test:0.10380, lr:8.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:18.158, tt:944.216\n",
      "Ep:52, loss:0.00000, loss_test:0.10338, lr:8.78e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.146, tt:961.751\n",
      "Ep:53, loss:0.00000, loss_test:0.10271, lr:8.78e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.153, tt:980.274\n",
      "Ep:54, loss:0.00000, loss_test:0.10202, lr:8.78e-03, fs:0.70652 (r=0.657,p=0.765),  time:18.161, tt:998.842\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00000, loss_test:0.10150, lr:8.78e-03, fs:0.70652 (r=0.657,p=0.765),  time:18.162, tt:1017.075\n",
      "Ep:56, loss:0.00000, loss_test:0.10116, lr:8.78e-03, fs:0.70652 (r=0.657,p=0.765),  time:18.152, tt:1034.659\n",
      "Ep:57, loss:0.00000, loss_test:0.10095, lr:8.78e-03, fs:0.71429 (r=0.657,p=0.783),  time:18.160, tt:1053.259\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00000, loss_test:0.10075, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.164, tt:1071.698\n",
      "Ep:59, loss:0.00000, loss_test:0.10043, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.151, tt:1089.082\n",
      "Ep:60, loss:0.00000, loss_test:0.10001, lr:8.78e-03, fs:0.71429 (r=0.657,p=0.783),  time:18.161, tt:1107.810\n",
      "Ep:61, loss:0.00000, loss_test:0.09975, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.162, tt:1126.021\n",
      "Ep:62, loss:0.00000, loss_test:0.09970, lr:8.78e-03, fs:0.71429 (r=0.657,p=0.783),  time:18.157, tt:1143.895\n",
      "Ep:63, loss:0.00000, loss_test:0.09972, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.163, tt:1162.455\n",
      "Ep:64, loss:0.00000, loss_test:0.09964, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.157, tt:1180.226\n",
      "Ep:65, loss:0.00000, loss_test:0.09929, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.160, tt:1198.549\n",
      "Ep:66, loss:0.00000, loss_test:0.09883, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.159, tt:1216.656\n",
      "Ep:67, loss:0.00000, loss_test:0.09845, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.154, tt:1234.439\n",
      "Ep:68, loss:0.00000, loss_test:0.09829, lr:8.78e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.147, tt:1252.119\n",
      "Ep:69, loss:0.00000, loss_test:0.09827, lr:8.69e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.154, tt:1270.762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00000, loss_test:0.09825, lr:8.60e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.128, tt:1287.108\n",
      "Ep:71, loss:0.00000, loss_test:0.09808, lr:8.51e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.116, tt:1304.338\n",
      "Ep:72, loss:0.00000, loss_test:0.09775, lr:8.43e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.102, tt:1321.413\n",
      "Ep:73, loss:0.00000, loss_test:0.09738, lr:8.35e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.077, tt:1337.709\n",
      "Ep:74, loss:0.00000, loss_test:0.09708, lr:8.26e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.084, tt:1356.324\n",
      "Ep:75, loss:0.00000, loss_test:0.09695, lr:8.18e-03, fs:0.70056 (r=0.626,p=0.795),  time:18.079, tt:1374.016\n",
      "Ep:76, loss:0.00000, loss_test:0.09686, lr:8.10e-03, fs:0.70056 (r=0.626,p=0.795),  time:18.075, tt:1391.800\n",
      "Ep:77, loss:0.00000, loss_test:0.09667, lr:8.02e-03, fs:0.70056 (r=0.626,p=0.795),  time:18.090, tt:1411.003\n",
      "Ep:78, loss:0.00000, loss_test:0.09640, lr:7.94e-03, fs:0.70056 (r=0.626,p=0.795),  time:18.094, tt:1429.444\n",
      "Ep:79, loss:0.00000, loss_test:0.09613, lr:7.86e-03, fs:0.70056 (r=0.626,p=0.795),  time:18.089, tt:1447.095\n",
      "Ep:80, loss:0.00000, loss_test:0.09594, lr:7.78e-03, fs:0.69714 (r=0.616,p=0.803),  time:18.073, tt:1463.880\n",
      "Ep:81, loss:0.00000, loss_test:0.09584, lr:7.70e-03, fs:0.69714 (r=0.616,p=0.803),  time:18.058, tt:1480.776\n",
      "Ep:82, loss:0.00000, loss_test:0.09577, lr:7.62e-03, fs:0.70115 (r=0.616,p=0.813),  time:18.035, tt:1496.897\n",
      "Ep:83, loss:0.00000, loss_test:0.09569, lr:7.55e-03, fs:0.70115 (r=0.616,p=0.813),  time:18.022, tt:1513.820\n",
      "Ep:84, loss:0.00000, loss_test:0.09555, lr:7.47e-03, fs:0.70115 (r=0.616,p=0.813),  time:18.015, tt:1531.276\n",
      "Ep:85, loss:0.00000, loss_test:0.09541, lr:7.40e-03, fs:0.70930 (r=0.616,p=0.836),  time:18.007, tt:1548.563\n",
      "Ep:86, loss:0.00000, loss_test:0.09527, lr:7.32e-03, fs:0.70930 (r=0.616,p=0.836),  time:17.993, tt:1565.426\n",
      "Ep:87, loss:0.00000, loss_test:0.09514, lr:7.25e-03, fs:0.71676 (r=0.626,p=0.838),  time:17.971, tt:1581.441\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00000, loss_test:0.09502, lr:7.25e-03, fs:0.72414 (r=0.636,p=0.840),  time:17.954, tt:1597.870\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00000, loss_test:0.09492, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.936, tt:1614.231\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00000, loss_test:0.09485, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.933, tt:1631.901\n",
      "Ep:91, loss:0.00000, loss_test:0.09477, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.905, tt:1647.286\n",
      "Ep:92, loss:0.00000, loss_test:0.09464, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.881, tt:1662.890\n",
      "Ep:93, loss:0.00000, loss_test:0.09454, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.861, tt:1678.906\n",
      "Ep:94, loss:0.00000, loss_test:0.09450, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.838, tt:1694.621\n",
      "Ep:95, loss:0.00000, loss_test:0.09447, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.823, tt:1711.056\n",
      "Ep:96, loss:0.00000, loss_test:0.09444, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.806, tt:1727.148\n",
      "Ep:97, loss:0.00000, loss_test:0.09439, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.804, tt:1744.815\n",
      "Ep:98, loss:0.00000, loss_test:0.09432, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.786, tt:1760.780\n",
      "Ep:99, loss:0.00000, loss_test:0.09424, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:17.769, tt:1776.858\n",
      "Ep:100, loss:0.00000, loss_test:0.09421, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.752, tt:1792.953\n",
      "Ep:101, loss:0.00000, loss_test:0.09423, lr:7.18e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.735, tt:1809.010\n",
      "Ep:102, loss:0.00000, loss_test:0.09421, lr:7.11e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.722, tt:1825.323\n",
      "Ep:103, loss:0.00000, loss_test:0.09413, lr:7.03e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.715, tt:1842.405\n",
      "Ep:104, loss:0.00000, loss_test:0.09404, lr:6.96e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.703, tt:1858.836\n",
      "Ep:105, loss:0.00000, loss_test:0.09401, lr:6.89e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.687, tt:1874.779\n",
      "Ep:106, loss:0.00000, loss_test:0.09403, lr:6.83e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.677, tt:1891.402\n",
      "Ep:107, loss:0.00000, loss_test:0.09404, lr:6.76e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.677, tt:1909.076\n",
      "Ep:108, loss:0.00000, loss_test:0.09402, lr:6.69e-03, fs:0.72093 (r=0.626,p=0.849),  time:17.672, tt:1926.240\n",
      "Ep:109, loss:0.00000, loss_test:0.09396, lr:6.62e-03, fs:0.72515 (r=0.626,p=0.861),  time:17.658, tt:1942.399\n",
      "Ep:110, loss:0.00000, loss_test:0.09389, lr:6.56e-03, fs:0.72941 (r=0.626,p=0.873),  time:17.653, tt:1959.531\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.09387, lr:6.56e-03, fs:0.72941 (r=0.626,p=0.873),  time:17.645, tt:1976.240\n",
      "Ep:112, loss:0.00000, loss_test:0.09386, lr:6.56e-03, fs:0.73373 (r=0.626,p=0.886),  time:17.652, tt:1994.626\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.09390, lr:6.56e-03, fs:0.73373 (r=0.626,p=0.886),  time:17.651, tt:2012.197\n",
      "Ep:114, loss:0.00000, loss_test:0.09397, lr:6.56e-03, fs:0.73373 (r=0.626,p=0.886),  time:17.652, tt:2029.926\n",
      "Ep:115, loss:0.00000, loss_test:0.09404, lr:6.56e-03, fs:0.73373 (r=0.626,p=0.886),  time:17.645, tt:2046.822\n",
      "Ep:116, loss:0.00000, loss_test:0.09409, lr:6.56e-03, fs:0.73810 (r=0.626,p=0.899),  time:17.646, tt:2064.566\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00000, loss_test:0.09410, lr:6.56e-03, fs:0.73810 (r=0.626,p=0.899),  time:17.635, tt:2080.918\n",
      "Ep:118, loss:0.00000, loss_test:0.09407, lr:6.56e-03, fs:0.73810 (r=0.626,p=0.899),  time:17.629, tt:2097.909\n",
      "Ep:119, loss:0.00000, loss_test:0.09411, lr:6.56e-03, fs:0.73810 (r=0.626,p=0.899),  time:17.627, tt:2115.276\n",
      "Ep:120, loss:0.00000, loss_test:0.09426, lr:6.56e-03, fs:0.73810 (r=0.626,p=0.899),  time:17.620, tt:2131.968\n",
      "Ep:121, loss:0.00000, loss_test:0.09440, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.605, tt:2147.859\n",
      "Ep:122, loss:0.00000, loss_test:0.09438, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.605, tt:2165.356\n",
      "Ep:123, loss:0.00000, loss_test:0.09433, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.611, tt:2183.751\n",
      "Ep:124, loss:0.00000, loss_test:0.09443, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.618, tt:2202.226\n",
      "Ep:125, loss:0.00000, loss_test:0.09462, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.631, tt:2221.525\n",
      "Ep:126, loss:0.00000, loss_test:0.09460, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.634, tt:2239.456\n",
      "Ep:127, loss:0.00000, loss_test:0.09450, lr:6.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.642, tt:2258.219\n",
      "Ep:128, loss:0.00000, loss_test:0.09451, lr:6.49e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.653, tt:2277.174\n",
      "Ep:129, loss:0.00000, loss_test:0.09464, lr:6.43e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.651, tt:2294.665\n",
      "Ep:130, loss:0.00000, loss_test:0.09482, lr:6.36e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.652, tt:2312.456\n",
      "Ep:131, loss:0.00000, loss_test:0.09496, lr:6.30e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.646, tt:2329.247\n",
      "Ep:132, loss:0.00000, loss_test:0.09494, lr:6.24e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.643, tt:2346.510\n",
      "Ep:133, loss:0.00000, loss_test:0.09488, lr:6.17e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.647, tt:2364.706\n",
      "Ep:134, loss:0.00000, loss_test:0.09498, lr:6.11e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.650, tt:2382.689\n",
      "Ep:135, loss:0.00000, loss_test:0.09519, lr:6.05e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.658, tt:2401.440\n",
      "Ep:136, loss:0.00000, loss_test:0.09535, lr:5.99e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.667, tt:2420.440\n",
      "Ep:137, loss:0.00000, loss_test:0.09535, lr:5.93e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.673, tt:2438.846\n",
      "Ep:138, loss:0.00000, loss_test:0.09531, lr:5.87e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.671, tt:2456.263\n",
      "Ep:139, loss:0.00000, loss_test:0.09537, lr:5.81e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.678, tt:2474.956\n",
      "Ep:140, loss:0.00000, loss_test:0.09540, lr:5.75e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.679, tt:2492.699\n",
      "Ep:141, loss:0.00000, loss_test:0.09553, lr:5.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.684, tt:2511.126\n",
      "Ep:142, loss:0.00000, loss_test:0.09572, lr:5.64e-03, fs:0.73054 (r=0.616,p=0.897),  time:17.686, tt:2529.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.09585, lr:5.58e-03, fs:0.72289 (r=0.606,p=0.896),  time:17.683, tt:2546.372\n",
      "Ep:144, loss:0.00000, loss_test:0.09595, lr:5.53e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.685, tt:2564.380\n",
      "Ep:145, loss:0.00000, loss_test:0.09603, lr:5.47e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.687, tt:2582.327\n",
      "Ep:146, loss:0.00000, loss_test:0.09607, lr:5.42e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.691, tt:2600.570\n",
      "Ep:147, loss:0.00000, loss_test:0.09613, lr:5.36e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.689, tt:2618.030\n",
      "Ep:148, loss:0.00000, loss_test:0.09623, lr:5.31e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.695, tt:2636.629\n",
      "Ep:149, loss:0.00000, loss_test:0.09636, lr:5.26e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.698, tt:2654.683\n",
      "Ep:150, loss:0.00000, loss_test:0.09645, lr:5.20e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.701, tt:2672.791\n",
      "Ep:151, loss:0.00000, loss_test:0.09656, lr:5.15e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.711, tt:2692.134\n",
      "Ep:152, loss:0.00000, loss_test:0.09671, lr:5.10e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.720, tt:2711.150\n",
      "Ep:153, loss:0.00000, loss_test:0.09690, lr:5.05e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.729, tt:2730.337\n",
      "Ep:154, loss:0.00000, loss_test:0.09704, lr:5.00e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.738, tt:2749.352\n",
      "Ep:155, loss:0.00000, loss_test:0.09713, lr:4.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.742, tt:2767.693\n",
      "Ep:156, loss:0.00000, loss_test:0.09715, lr:4.90e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.753, tt:2787.200\n",
      "Ep:157, loss:0.00000, loss_test:0.09717, lr:4.85e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.764, tt:2806.783\n",
      "Ep:158, loss:0.00000, loss_test:0.09718, lr:4.80e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.776, tt:2826.354\n",
      "Ep:159, loss:0.00000, loss_test:0.09726, lr:4.75e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.779, tt:2844.563\n",
      "Ep:160, loss:0.00000, loss_test:0.09737, lr:4.71e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.783, tt:2863.099\n",
      "Ep:161, loss:0.00000, loss_test:0.09745, lr:4.66e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.787, tt:2881.518\n",
      "Ep:162, loss:0.00000, loss_test:0.09750, lr:4.61e-03, fs:0.71515 (r=0.596,p=0.894),  time:17.787, tt:2899.254\n",
      "Ep:163, loss:0.00000, loss_test:0.09751, lr:4.57e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.790, tt:2917.513\n",
      "Ep:164, loss:0.00000, loss_test:0.09753, lr:4.52e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.790, tt:2935.295\n",
      "Ep:165, loss:0.00000, loss_test:0.09756, lr:4.48e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.793, tt:2953.691\n",
      "Ep:166, loss:0.00000, loss_test:0.09758, lr:4.43e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.801, tt:2972.822\n",
      "Ep:167, loss:0.00000, loss_test:0.09764, lr:4.39e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.808, tt:2991.829\n",
      "Ep:168, loss:0.00000, loss_test:0.09776, lr:4.34e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.823, tt:3012.160\n",
      "Ep:169, loss:0.00000, loss_test:0.09787, lr:4.30e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.828, tt:3030.724\n",
      "Ep:170, loss:0.00000, loss_test:0.09794, lr:4.26e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.829, tt:3048.738\n",
      "Ep:171, loss:0.00000, loss_test:0.09799, lr:4.21e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.840, tt:3068.489\n",
      "Ep:172, loss:0.00000, loss_test:0.09799, lr:4.17e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.844, tt:3086.972\n",
      "Ep:173, loss:0.00000, loss_test:0.09798, lr:4.13e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.848, tt:3105.543\n",
      "Ep:174, loss:0.00000, loss_test:0.09803, lr:4.09e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.851, tt:3123.990\n",
      "Ep:175, loss:0.00000, loss_test:0.09816, lr:4.05e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.861, tt:3143.485\n",
      "Ep:176, loss:0.00000, loss_test:0.09831, lr:4.01e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.866, tt:3162.345\n",
      "Ep:177, loss:0.00000, loss_test:0.09841, lr:3.97e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.874, tt:3181.505\n",
      "Ep:178, loss:0.00000, loss_test:0.09841, lr:3.93e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.882, tt:3200.912\n",
      "Ep:179, loss:0.00000, loss_test:0.09840, lr:3.89e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.886, tt:3219.555\n",
      "Ep:180, loss:0.00000, loss_test:0.09841, lr:3.85e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.895, tt:3239.046\n",
      "Ep:181, loss:0.00000, loss_test:0.09849, lr:3.81e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.903, tt:3258.316\n",
      "Ep:182, loss:0.00000, loss_test:0.09861, lr:3.77e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.907, tt:3276.928\n",
      "Ep:183, loss:0.00000, loss_test:0.09870, lr:3.73e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.911, tt:3295.595\n",
      "Ep:184, loss:0.00000, loss_test:0.09878, lr:3.70e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.915, tt:3314.266\n",
      "Ep:185, loss:0.00000, loss_test:0.09888, lr:3.66e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.920, tt:3333.055\n",
      "Ep:186, loss:0.00000, loss_test:0.09894, lr:3.62e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.922, tt:3351.501\n",
      "Ep:187, loss:0.00000, loss_test:0.09899, lr:3.59e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.929, tt:3370.577\n",
      "Ep:188, loss:0.00000, loss_test:0.09906, lr:3.55e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.933, tt:3389.311\n",
      "Ep:189, loss:0.00000, loss_test:0.09916, lr:3.52e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.941, tt:3408.717\n",
      "Ep:190, loss:0.00000, loss_test:0.09928, lr:3.48e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.945, tt:3427.467\n",
      "Ep:191, loss:0.00000, loss_test:0.09936, lr:3.45e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.952, tt:3446.815\n",
      "Ep:192, loss:0.00000, loss_test:0.09937, lr:3.41e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.954, tt:3465.158\n",
      "Ep:193, loss:0.00000, loss_test:0.09936, lr:3.38e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.958, tt:3483.869\n",
      "Ep:194, loss:0.00000, loss_test:0.09939, lr:3.34e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.962, tt:3502.561\n",
      "Ep:195, loss:0.00000, loss_test:0.09946, lr:3.31e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.969, tt:3521.931\n",
      "Ep:196, loss:0.00000, loss_test:0.09953, lr:3.28e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.971, tt:3540.208\n",
      "Ep:197, loss:0.00000, loss_test:0.09961, lr:3.24e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.976, tt:3559.303\n",
      "Ep:198, loss:0.00000, loss_test:0.09971, lr:3.21e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.983, tt:3578.623\n",
      "Ep:199, loss:0.00000, loss_test:0.09980, lr:3.18e-03, fs:0.71951 (r=0.596,p=0.908),  time:17.987, tt:3597.414\n",
      "Ep:200, loss:0.00000, loss_test:0.09991, lr:3.15e-03, fs:0.71515 (r=0.596,p=0.894),  time:17.996, tt:3617.285\n",
      "Ep:201, loss:0.00000, loss_test:0.10001, lr:3.12e-03, fs:0.71515 (r=0.596,p=0.894),  time:17.998, tt:3635.648\n",
      "Ep:202, loss:0.00000, loss_test:0.10008, lr:3.09e-03, fs:0.71515 (r=0.596,p=0.894),  time:18.002, tt:3654.375\n",
      "Ep:203, loss:0.00000, loss_test:0.10013, lr:3.05e-03, fs:0.71515 (r=0.596,p=0.894),  time:18.004, tt:3672.777\n",
      "Ep:204, loss:0.00000, loss_test:0.10019, lr:3.02e-03, fs:0.70732 (r=0.586,p=0.892),  time:18.012, tt:3692.513\n",
      "Ep:205, loss:0.00000, loss_test:0.10028, lr:2.99e-03, fs:0.70732 (r=0.586,p=0.892),  time:18.018, tt:3711.617\n",
      "Ep:206, loss:0.00000, loss_test:0.10043, lr:2.96e-03, fs:0.70732 (r=0.586,p=0.892),  time:18.023, tt:3730.840\n",
      "Ep:207, loss:0.00000, loss_test:0.10055, lr:2.93e-03, fs:0.70732 (r=0.586,p=0.892),  time:18.029, tt:3750.127\n",
      "Ep:208, loss:0.00000, loss_test:0.10062, lr:2.90e-03, fs:0.70732 (r=0.586,p=0.892),  time:18.035, tt:3769.406\n",
      "Ep:209, loss:0.00000, loss_test:0.10068, lr:2.88e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.037, tt:3787.673\n",
      "Ep:210, loss:0.00000, loss_test:0.10072, lr:2.85e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.042, tt:3806.936\n",
      "Ep:211, loss:0.00000, loss_test:0.10078, lr:2.82e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.048, tt:3826.160\n",
      "Ep:212, loss:0.00000, loss_test:0.10086, lr:2.79e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.052, tt:3845.008\n",
      "Ep:213, loss:0.00000, loss_test:0.10097, lr:2.76e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.061, tt:3865.081\n",
      "Ep:214, loss:0.00000, loss_test:0.10107, lr:2.73e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.066, tt:3884.188\n",
      "Ep:215, loss:0.00000, loss_test:0.10117, lr:2.71e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.069, tt:3902.841\n",
      "Ep:216, loss:0.00000, loss_test:0.10126, lr:2.68e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.074, tt:3922.128\n",
      "Ep:217, loss:0.00000, loss_test:0.10136, lr:2.65e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.079, tt:3941.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:218, loss:0.00000, loss_test:0.10145, lr:2.63e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.084, tt:3960.295\n",
      "Ep:219, loss:0.00000, loss_test:0.10151, lr:2.60e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.093, tt:3980.354\n",
      "Ep:220, loss:0.00000, loss_test:0.10158, lr:2.57e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.101, tt:4000.379\n",
      "Ep:221, loss:0.00000, loss_test:0.10163, lr:2.55e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.110, tt:4020.334\n",
      "Ep:222, loss:0.00000, loss_test:0.10172, lr:2.52e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.119, tt:4040.441\n",
      "Ep:223, loss:0.00000, loss_test:0.10180, lr:2.50e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.126, tt:4060.140\n",
      "Ep:224, loss:0.00000, loss_test:0.10184, lr:2.47e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.132, tt:4079.707\n",
      "Ep:225, loss:0.00000, loss_test:0.10191, lr:2.45e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.137, tt:4099.034\n",
      "Ep:226, loss:0.00000, loss_test:0.10201, lr:2.42e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.144, tt:4118.770\n",
      "Ep:227, loss:0.00000, loss_test:0.10212, lr:2.40e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.153, tt:4138.809\n",
      "Ep:228, loss:0.00000, loss_test:0.10223, lr:2.38e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.161, tt:4158.896\n",
      "Ep:229, loss:0.00000, loss_test:0.10231, lr:2.35e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.166, tt:4178.180\n",
      "Ep:230, loss:0.00000, loss_test:0.10236, lr:2.33e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.169, tt:4196.996\n",
      "Ep:231, loss:0.00000, loss_test:0.10240, lr:2.31e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.173, tt:4216.160\n",
      "Ep:232, loss:0.00000, loss_test:0.10247, lr:2.28e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.182, tt:4236.478\n",
      "Ep:233, loss:0.00000, loss_test:0.10257, lr:2.26e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.187, tt:4255.709\n",
      "Ep:234, loss:0.00000, loss_test:0.10266, lr:2.24e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.184, tt:4273.289\n",
      "Ep:235, loss:0.00000, loss_test:0.10271, lr:2.21e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.187, tt:4292.160\n",
      "Ep:236, loss:0.00000, loss_test:0.10275, lr:2.19e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.190, tt:4311.047\n",
      "Ep:237, loss:0.00000, loss_test:0.10279, lr:2.17e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.193, tt:4329.957\n",
      "Ep:238, loss:0.00000, loss_test:0.10285, lr:2.15e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.196, tt:4348.873\n",
      "Ep:239, loss:0.00000, loss_test:0.10289, lr:2.13e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.202, tt:4368.437\n",
      "Ep:240, loss:0.00000, loss_test:0.10290, lr:2.11e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.201, tt:4386.360\n",
      "Ep:241, loss:0.00000, loss_test:0.10292, lr:2.08e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.202, tt:4404.775\n",
      "Ep:242, loss:0.00000, loss_test:0.10294, lr:2.06e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.200, tt:4422.537\n",
      "Ep:243, loss:0.00000, loss_test:0.10299, lr:2.04e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.194, tt:4439.328\n",
      "Ep:244, loss:0.00000, loss_test:0.10303, lr:2.02e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.189, tt:4456.332\n",
      "Ep:245, loss:0.00000, loss_test:0.10309, lr:2.00e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.183, tt:4472.909\n",
      "Ep:246, loss:0.00000, loss_test:0.10313, lr:1.98e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.175, tt:4489.178\n",
      "Ep:247, loss:0.00000, loss_test:0.10317, lr:1.96e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.169, tt:4505.821\n",
      "Ep:248, loss:0.00000, loss_test:0.10325, lr:1.94e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.163, tt:4522.642\n",
      "Ep:249, loss:0.00000, loss_test:0.10330, lr:1.92e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.158, tt:4539.584\n",
      "Ep:250, loss:0.00000, loss_test:0.10335, lr:1.90e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.152, tt:4556.104\n",
      "Ep:251, loss:0.00000, loss_test:0.10341, lr:1.89e-03, fs:0.67925 (r=0.545,p=0.900),  time:18.145, tt:4572.471\n",
      "Ep:252, loss:0.00000, loss_test:0.10347, lr:1.87e-03, fs:0.67925 (r=0.545,p=0.900),  time:18.137, tt:4588.673\n",
      "Ep:253, loss:0.00000, loss_test:0.10352, lr:1.85e-03, fs:0.67925 (r=0.545,p=0.900),  time:18.128, tt:4604.480\n",
      "Ep:254, loss:0.00000, loss_test:0.10358, lr:1.83e-03, fs:0.67089 (r=0.535,p=0.898),  time:18.119, tt:4620.455\n",
      "Ep:255, loss:0.00000, loss_test:0.10360, lr:1.81e-03, fs:0.67089 (r=0.535,p=0.898),  time:18.113, tt:4636.963\n",
      "Ep:256, loss:0.00000, loss_test:0.10360, lr:1.79e-03, fs:0.66242 (r=0.525,p=0.897),  time:18.111, tt:4654.526\n",
      "Ep:257, loss:0.00000, loss_test:0.10363, lr:1.78e-03, fs:0.66242 (r=0.525,p=0.897),  time:18.105, tt:4671.084\n",
      "Ep:258, loss:0.00000, loss_test:0.10368, lr:1.76e-03, fs:0.66242 (r=0.525,p=0.897),  time:18.098, tt:4687.323\n",
      "Ep:259, loss:0.00000, loss_test:0.10377, lr:1.74e-03, fs:0.66242 (r=0.525,p=0.897),  time:18.089, tt:4703.178\n",
      "Ep:260, loss:0.00000, loss_test:0.10383, lr:1.72e-03, fs:0.66242 (r=0.525,p=0.897),  time:18.080, tt:4718.995\n",
      "Ep:261, loss:0.00000, loss_test:0.10386, lr:1.71e-03, fs:0.66242 (r=0.525,p=0.897),  time:18.074, tt:4735.406\n",
      "Ep:262, loss:0.00000, loss_test:0.10388, lr:1.69e-03, fs:0.65385 (r=0.515,p=0.895),  time:18.065, tt:4751.193\n",
      "Ep:263, loss:0.00000, loss_test:0.10390, lr:1.67e-03, fs:0.65385 (r=0.515,p=0.895),  time:18.057, tt:4767.113\n",
      "Ep:264, loss:0.00000, loss_test:0.10393, lr:1.65e-03, fs:0.65385 (r=0.515,p=0.895),  time:18.049, tt:4783.001\n",
      "Ep:265, loss:0.00000, loss_test:0.10397, lr:1.64e-03, fs:0.65385 (r=0.515,p=0.895),  time:18.038, tt:4798.184\n",
      "Ep:266, loss:0.00000, loss_test:0.10401, lr:1.62e-03, fs:0.65385 (r=0.515,p=0.895),  time:18.031, tt:4814.236\n",
      "Ep:267, loss:0.00000, loss_test:0.10404, lr:1.61e-03, fs:0.65385 (r=0.515,p=0.895),  time:18.024, tt:4830.454\n",
      "Ep:268, loss:0.00000, loss_test:0.10407, lr:1.59e-03, fs:0.64516 (r=0.505,p=0.893),  time:18.015, tt:4845.928\n",
      "Ep:269, loss:0.00000, loss_test:0.10412, lr:1.57e-03, fs:0.64516 (r=0.505,p=0.893),  time:18.008, tt:4862.055\n",
      "Ep:270, loss:0.00000, loss_test:0.10417, lr:1.56e-03, fs:0.64516 (r=0.505,p=0.893),  time:18.003, tt:4878.794\n",
      "Ep:271, loss:0.00000, loss_test:0.10423, lr:1.54e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.995, tt:4894.770\n",
      "Ep:272, loss:0.00000, loss_test:0.10428, lr:1.53e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.989, tt:4911.085\n",
      "Ep:273, loss:0.00000, loss_test:0.10432, lr:1.51e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.988, tt:4928.712\n",
      "Ep:274, loss:0.00000, loss_test:0.10434, lr:1.50e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.985, tt:4945.880\n",
      "Ep:275, loss:0.00000, loss_test:0.10437, lr:1.48e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.986, tt:4964.140\n",
      "Ep:276, loss:0.00000, loss_test:0.10441, lr:1.47e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.985, tt:4981.923\n",
      "Ep:277, loss:0.00000, loss_test:0.10448, lr:1.45e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.980, tt:4998.338\n",
      "Ep:278, loss:0.00000, loss_test:0.10451, lr:1.44e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.974, tt:5014.837\n",
      "Ep:279, loss:0.00000, loss_test:0.10453, lr:1.42e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.971, tt:5031.804\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"3-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=40000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,280,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 512: \n",
      "Ep:0, loss:0.00113, loss_test:0.15046, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:18.742, tt:18.742\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00112, loss_test:0.15046, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:20.485, tt:40.969\n",
      "Ep:2, loss:0.00112, loss_test:0.15051, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:21.071, tt:63.212\n",
      "Ep:3, loss:0.00110, loss_test:0.15059, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:21.226, tt:84.902\n",
      "Ep:4, loss:0.00108, loss_test:0.15071, lr:4.00e-03, fs:0.65052 (r=0.949,p=0.495),  time:21.459, tt:107.294\n",
      "Ep:5, loss:0.00105, loss_test:0.15077, lr:4.00e-03, fs:0.64085 (r=0.919,p=0.492),  time:21.458, tt:128.746\n",
      "Ep:6, loss:0.00100, loss_test:0.15121, lr:4.00e-03, fs:0.56917 (r=0.727,p=0.468),  time:21.618, tt:151.328\n",
      "Ep:7, loss:0.00094, loss_test:0.15403, lr:4.00e-03, fs:0.53704 (r=0.586,p=0.496),  time:21.740, tt:173.923\n",
      "Ep:8, loss:0.00090, loss_test:0.15842, lr:4.00e-03, fs:0.50256 (r=0.495,p=0.510),  time:21.894, tt:197.046\n",
      "Ep:9, loss:0.00087, loss_test:0.15759, lr:4.00e-03, fs:0.50000 (r=0.495,p=0.505),  time:21.881, tt:218.808\n",
      "Ep:10, loss:0.00084, loss_test:0.15461, lr:4.00e-03, fs:0.50246 (r=0.515,p=0.490),  time:21.998, tt:241.982\n",
      "Ep:11, loss:0.00082, loss_test:0.15353, lr:4.00e-03, fs:0.52174 (r=0.545,p=0.500),  time:22.050, tt:264.604\n",
      "Ep:12, loss:0.00079, loss_test:0.15323, lr:3.96e-03, fs:0.51741 (r=0.525,p=0.510),  time:22.104, tt:287.348\n",
      "Ep:13, loss:0.00077, loss_test:0.15298, lr:3.92e-03, fs:0.52525 (r=0.525,p=0.525),  time:22.159, tt:310.228\n",
      "Ep:14, loss:0.00075, loss_test:0.14995, lr:3.88e-03, fs:0.52261 (r=0.525,p=0.520),  time:22.298, tt:334.463\n",
      "Ep:15, loss:0.00073, loss_test:0.14748, lr:3.84e-03, fs:0.52000 (r=0.525,p=0.515),  time:22.301, tt:356.811\n",
      "Ep:16, loss:0.00071, loss_test:0.14676, lr:3.80e-03, fs:0.53266 (r=0.535,p=0.530),  time:22.268, tt:378.559\n",
      "Ep:17, loss:0.00069, loss_test:0.14548, lr:3.77e-03, fs:0.53535 (r=0.535,p=0.535),  time:22.299, tt:401.375\n",
      "Ep:18, loss:0.00068, loss_test:0.14439, lr:3.73e-03, fs:0.54455 (r=0.556,p=0.534),  time:22.353, tt:424.706\n",
      "Ep:19, loss:0.00066, loss_test:0.14320, lr:3.69e-03, fs:0.55172 (r=0.566,p=0.538),  time:22.375, tt:447.500\n",
      "Ep:20, loss:0.00065, loss_test:0.14220, lr:3.65e-03, fs:0.56158 (r=0.576,p=0.548),  time:22.380, tt:469.971\n",
      "Ep:21, loss:0.00064, loss_test:0.14149, lr:3.62e-03, fs:0.55882 (r=0.576,p=0.543),  time:22.393, tt:492.655\n",
      "Ep:22, loss:0.00063, loss_test:0.14012, lr:3.58e-03, fs:0.56863 (r=0.586,p=0.552),  time:22.415, tt:515.534\n",
      "Ep:23, loss:0.00062, loss_test:0.13947, lr:3.55e-03, fs:0.56863 (r=0.586,p=0.552),  time:22.434, tt:538.410\n",
      "Ep:24, loss:0.00061, loss_test:0.13822, lr:3.51e-03, fs:0.56436 (r=0.576,p=0.553),  time:22.428, tt:560.696\n",
      "Ep:25, loss:0.00060, loss_test:0.13745, lr:3.47e-03, fs:0.57143 (r=0.586,p=0.558),  time:22.418, tt:582.865\n",
      "Ep:26, loss:0.00059, loss_test:0.13661, lr:3.44e-03, fs:0.57143 (r=0.586,p=0.558),  time:22.402, tt:604.860\n",
      "Ep:27, loss:0.00058, loss_test:0.13597, lr:3.41e-03, fs:0.57426 (r=0.586,p=0.563),  time:22.393, tt:627.012\n",
      "Ep:28, loss:0.00057, loss_test:0.13511, lr:3.37e-03, fs:0.58128 (r=0.596,p=0.567),  time:22.397, tt:649.509\n",
      "Ep:29, loss:0.00056, loss_test:0.13403, lr:3.34e-03, fs:0.58537 (r=0.606,p=0.566),  time:22.417, tt:672.500\n",
      "Ep:30, loss:0.00056, loss_test:0.13435, lr:3.30e-03, fs:0.58000 (r=0.586,p=0.574),  time:22.396, tt:694.266\n",
      "Ep:31, loss:0.00055, loss_test:0.13305, lr:3.27e-03, fs:0.59596 (r=0.596,p=0.596),  time:22.414, tt:717.244\n",
      "Ep:32, loss:0.00054, loss_test:0.13262, lr:3.24e-03, fs:0.61307 (r=0.616,p=0.610),  time:22.436, tt:740.403\n",
      "Ep:33, loss:0.00053, loss_test:0.13134, lr:3.21e-03, fs:0.61692 (r=0.626,p=0.608),  time:22.434, tt:762.762\n",
      "Ep:34, loss:0.00053, loss_test:0.13138, lr:3.17e-03, fs:0.61000 (r=0.616,p=0.604),  time:22.427, tt:784.948\n",
      "Ep:35, loss:0.00052, loss_test:0.13040, lr:3.14e-03, fs:0.61616 (r=0.616,p=0.616),  time:22.449, tt:808.168\n",
      "Ep:36, loss:0.00051, loss_test:0.12987, lr:3.11e-03, fs:0.62626 (r=0.626,p=0.626),  time:22.449, tt:830.608\n",
      "Ep:37, loss:0.00051, loss_test:0.12843, lr:3.08e-03, fs:0.62245 (r=0.616,p=0.629),  time:22.468, tt:853.788\n",
      "Ep:38, loss:0.00050, loss_test:0.12879, lr:3.05e-03, fs:0.63265 (r=0.626,p=0.639),  time:22.476, tt:876.567\n",
      "Ep:39, loss:0.00049, loss_test:0.12833, lr:3.02e-03, fs:0.63918 (r=0.626,p=0.653),  time:22.480, tt:899.218\n",
      "Ep:40, loss:0.00049, loss_test:0.12666, lr:2.99e-03, fs:0.66667 (r=0.657,p=0.677),  time:22.477, tt:921.573\n",
      "Ep:41, loss:0.00048, loss_test:0.12579, lr:2.96e-03, fs:0.65657 (r=0.657,p=0.657),  time:22.492, tt:944.660\n",
      "Ep:42, loss:0.00047, loss_test:0.12471, lr:2.93e-03, fs:0.65990 (r=0.657,p=0.663),  time:22.497, tt:967.357\n",
      "Ep:43, loss:0.00047, loss_test:0.12450, lr:2.90e-03, fs:0.66667 (r=0.657,p=0.677),  time:22.493, tt:989.708\n",
      "Ep:44, loss:0.00046, loss_test:0.12343, lr:2.87e-03, fs:0.66327 (r=0.657,p=0.670),  time:22.499, tt:1012.454\n",
      "Ep:45, loss:0.00045, loss_test:0.12341, lr:2.84e-03, fs:0.65979 (r=0.646,p=0.674),  time:22.502, tt:1035.108\n",
      "Ep:46, loss:0.00045, loss_test:0.12253, lr:2.81e-03, fs:0.67016 (r=0.646,p=0.696),  time:22.504, tt:1057.692\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00045, loss_test:0.12157, lr:2.81e-03, fs:0.66667 (r=0.646,p=0.688),  time:22.516, tt:1080.788\n",
      "Ep:48, loss:0.00044, loss_test:0.12202, lr:2.81e-03, fs:0.68367 (r=0.677,p=0.691),  time:22.517, tt:1103.343\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00043, loss_test:0.12089, lr:2.81e-03, fs:0.67358 (r=0.657,p=0.691),  time:22.517, tt:1125.856\n",
      "Ep:50, loss:0.00043, loss_test:0.12096, lr:2.81e-03, fs:0.68421 (r=0.657,p=0.714),  time:22.517, tt:1148.380\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00042, loss_test:0.12044, lr:2.81e-03, fs:0.68394 (r=0.667,p=0.702),  time:22.518, tt:1170.941\n",
      "Ep:52, loss:0.00041, loss_test:0.11922, lr:2.81e-03, fs:0.67358 (r=0.657,p=0.691),  time:22.526, tt:1193.878\n",
      "Ep:53, loss:0.00041, loss_test:0.11984, lr:2.81e-03, fs:0.69110 (r=0.667,p=0.717),  time:22.528, tt:1216.494\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00040, loss_test:0.11916, lr:2.81e-03, fs:0.68783 (r=0.657,p=0.722),  time:22.526, tt:1238.925\n",
      "Ep:55, loss:0.00040, loss_test:0.11860, lr:2.81e-03, fs:0.68421 (r=0.657,p=0.714),  time:22.525, tt:1261.405\n",
      "Ep:56, loss:0.00039, loss_test:0.11834, lr:2.81e-03, fs:0.68063 (r=0.657,p=0.707),  time:22.511, tt:1283.111\n",
      "Ep:57, loss:0.00039, loss_test:0.11824, lr:2.81e-03, fs:0.68108 (r=0.636,p=0.733),  time:22.510, tt:1305.585\n",
      "Ep:58, loss:0.00038, loss_test:0.11794, lr:2.81e-03, fs:0.68108 (r=0.636,p=0.733),  time:22.518, tt:1328.579\n",
      "Ep:59, loss:0.00038, loss_test:0.11735, lr:2.81e-03, fs:0.68085 (r=0.646,p=0.719),  time:22.512, tt:1350.746\n",
      "Ep:60, loss:0.00037, loss_test:0.11832, lr:2.81e-03, fs:0.68852 (r=0.636,p=0.750),  time:22.510, tt:1373.087\n",
      "Ep:61, loss:0.00037, loss_test:0.11716, lr:2.81e-03, fs:0.68108 (r=0.636,p=0.733),  time:22.502, tt:1395.149\n",
      "Ep:62, loss:0.00036, loss_test:0.11706, lr:2.81e-03, fs:0.68852 (r=0.636,p=0.750),  time:22.509, tt:1418.052\n",
      "Ep:63, loss:0.00036, loss_test:0.11690, lr:2.81e-03, fs:0.68478 (r=0.636,p=0.741),  time:22.526, tt:1441.652\n",
      "Ep:64, loss:0.00035, loss_test:0.11533, lr:2.81e-03, fs:0.68108 (r=0.636,p=0.733),  time:22.535, tt:1464.795\n",
      "Ep:65, loss:0.00035, loss_test:0.11650, lr:2.79e-03, fs:0.68132 (r=0.626,p=0.747),  time:22.535, tt:1487.341\n",
      "Ep:66, loss:0.00034, loss_test:0.11494, lr:2.76e-03, fs:0.68852 (r=0.636,p=0.750),  time:22.527, tt:1509.315\n",
      "Ep:67, loss:0.00034, loss_test:0.11612, lr:2.73e-03, fs:0.68539 (r=0.616,p=0.772),  time:22.529, tt:1531.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00033, loss_test:0.11502, lr:2.70e-03, fs:0.68508 (r=0.626,p=0.756),  time:22.526, tt:1554.277\n",
      "Ep:69, loss:0.00033, loss_test:0.11547, lr:2.68e-03, fs:0.68156 (r=0.616,p=0.762),  time:22.520, tt:1576.377\n",
      "Ep:70, loss:0.00032, loss_test:0.11434, lr:2.65e-03, fs:0.69274 (r=0.626,p=0.775),  time:22.515, tt:1598.587\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00032, loss_test:0.11529, lr:2.65e-03, fs:0.67416 (r=0.606,p=0.759),  time:22.519, tt:1621.402\n",
      "Ep:72, loss:0.00031, loss_test:0.11393, lr:2.65e-03, fs:0.68927 (r=0.616,p=0.782),  time:22.516, tt:1643.660\n",
      "Ep:73, loss:0.00031, loss_test:0.11500, lr:2.65e-03, fs:0.66292 (r=0.596,p=0.747),  time:22.520, tt:1666.473\n",
      "Ep:74, loss:0.00031, loss_test:0.11381, lr:2.65e-03, fs:0.68182 (r=0.606,p=0.779),  time:22.531, tt:1689.805\n",
      "Ep:75, loss:0.00030, loss_test:0.11482, lr:2.65e-03, fs:0.65517 (r=0.576,p=0.760),  time:22.542, tt:1713.174\n",
      "Ep:76, loss:0.00030, loss_test:0.11331, lr:2.65e-03, fs:0.66286 (r=0.586,p=0.763),  time:22.533, tt:1735.043\n",
      "Ep:77, loss:0.00029, loss_test:0.11427, lr:2.65e-03, fs:0.65517 (r=0.576,p=0.760),  time:22.532, tt:1757.535\n",
      "Ep:78, loss:0.00029, loss_test:0.11332, lr:2.65e-03, fs:0.66667 (r=0.586,p=0.773),  time:22.542, tt:1780.839\n",
      "Ep:79, loss:0.00028, loss_test:0.11335, lr:2.65e-03, fs:0.65143 (r=0.576,p=0.750),  time:22.546, tt:1803.696\n",
      "Ep:80, loss:0.00028, loss_test:0.11332, lr:2.65e-03, fs:0.67052 (r=0.586,p=0.784),  time:22.547, tt:1826.334\n",
      "Ep:81, loss:0.00028, loss_test:0.11316, lr:2.65e-03, fs:0.66667 (r=0.586,p=0.773),  time:22.543, tt:1848.512\n",
      "Ep:82, loss:0.00027, loss_test:0.11251, lr:2.62e-03, fs:0.66667 (r=0.586,p=0.773),  time:22.543, tt:1871.028\n",
      "Ep:83, loss:0.00027, loss_test:0.11330, lr:2.60e-03, fs:0.67456 (r=0.576,p=0.814),  time:22.555, tt:1894.585\n",
      "Ep:84, loss:0.00026, loss_test:0.11189, lr:2.57e-03, fs:0.66667 (r=0.586,p=0.773),  time:22.568, tt:1918.276\n",
      "Ep:85, loss:0.00026, loss_test:0.11237, lr:2.54e-03, fs:0.68235 (r=0.586,p=0.817),  time:22.572, tt:1941.231\n",
      "Ep:86, loss:0.00026, loss_test:0.11197, lr:2.52e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.574, tt:1963.902\n",
      "Ep:87, loss:0.00025, loss_test:0.11234, lr:2.49e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.572, tt:1986.340\n",
      "Ep:88, loss:0.00025, loss_test:0.11144, lr:2.47e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.576, tt:2009.300\n",
      "Ep:89, loss:0.00024, loss_test:0.11207, lr:2.44e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.580, tt:2032.242\n",
      "Ep:90, loss:0.00024, loss_test:0.11091, lr:2.42e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.588, tt:2055.523\n",
      "Ep:91, loss:0.00024, loss_test:0.11059, lr:2.40e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.592, tt:2078.496\n",
      "Ep:92, loss:0.00024, loss_test:0.11203, lr:2.37e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.595, tt:2101.368\n",
      "Ep:93, loss:0.00023, loss_test:0.11021, lr:2.35e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.611, tt:2125.389\n",
      "Ep:94, loss:0.00023, loss_test:0.11180, lr:2.32e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.625, tt:2149.406\n",
      "Ep:95, loss:0.00023, loss_test:0.11017, lr:2.30e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.632, tt:2172.658\n",
      "Ep:96, loss:0.00022, loss_test:0.11106, lr:2.28e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.635, tt:2195.638\n",
      "Ep:97, loss:0.00022, loss_test:0.11037, lr:2.26e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.642, tt:2218.933\n",
      "Ep:98, loss:0.00022, loss_test:0.11025, lr:2.23e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.644, tt:2241.781\n",
      "Ep:99, loss:0.00021, loss_test:0.10981, lr:2.21e-03, fs:0.67442 (r=0.586,p=0.795),  time:22.618, tt:2261.791\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=512 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14980, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:8.877, tt:8.877\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14976, lr:8.00e-03, fs:0.64384 (r=0.949,p=0.487),  time:9.794, tt:19.587\n",
      "Ep:2, loss:0.00027, loss_test:0.14977, lr:8.00e-03, fs:0.64360 (r=0.939,p=0.489),  time:10.321, tt:30.962\n",
      "Ep:3, loss:0.00026, loss_test:0.14977, lr:8.00e-03, fs:0.63158 (r=0.909,p=0.484),  time:10.412, tt:41.648\n",
      "Ep:4, loss:0.00026, loss_test:0.14975, lr:8.00e-03, fs:0.61481 (r=0.838,p=0.485),  time:10.574, tt:52.869\n",
      "Ep:5, loss:0.00024, loss_test:0.15036, lr:8.00e-03, fs:0.55967 (r=0.687,p=0.472),  time:10.682, tt:64.093\n",
      "Ep:6, loss:0.00023, loss_test:0.15317, lr:8.00e-03, fs:0.52778 (r=0.576,p=0.487),  time:10.713, tt:74.994\n",
      "Ep:7, loss:0.00022, loss_test:0.15745, lr:8.00e-03, fs:0.49505 (r=0.505,p=0.485),  time:10.758, tt:86.063\n",
      "Ep:8, loss:0.00022, loss_test:0.16017, lr:8.00e-03, fs:0.50256 (r=0.495,p=0.510),  time:10.758, tt:96.822\n",
      "Ep:9, loss:0.00021, loss_test:0.15832, lr:8.00e-03, fs:0.49751 (r=0.505,p=0.490),  time:10.836, tt:108.358\n",
      "Ep:10, loss:0.00021, loss_test:0.15580, lr:8.00e-03, fs:0.49756 (r=0.515,p=0.481),  time:10.863, tt:119.497\n",
      "Ep:11, loss:0.00021, loss_test:0.15450, lr:8.00e-03, fs:0.50242 (r=0.525,p=0.481),  time:10.941, tt:131.288\n",
      "Ep:12, loss:0.00020, loss_test:0.15507, lr:7.92e-03, fs:0.50485 (r=0.525,p=0.486),  time:11.037, tt:143.479\n",
      "Ep:13, loss:0.00020, loss_test:0.15682, lr:7.84e-03, fs:0.51000 (r=0.515,p=0.505),  time:11.233, tt:157.264\n",
      "Ep:14, loss:0.00019, loss_test:0.15730, lr:7.76e-03, fs:0.51000 (r=0.515,p=0.505),  time:11.443, tt:171.649\n",
      "Ep:15, loss:0.00019, loss_test:0.15661, lr:7.68e-03, fs:0.52000 (r=0.525,p=0.515),  time:12.012, tt:192.192\n",
      "Ep:16, loss:0.00019, loss_test:0.15473, lr:7.61e-03, fs:0.52941 (r=0.545,p=0.514),  time:12.513, tt:212.720\n",
      "Ep:17, loss:0.00018, loss_test:0.15318, lr:7.53e-03, fs:0.55502 (r=0.586,p=0.527),  time:13.034, tt:234.611\n",
      "Ep:18, loss:0.00018, loss_test:0.15199, lr:7.46e-03, fs:0.56459 (r=0.596,p=0.536),  time:13.490, tt:256.306\n",
      "Ep:19, loss:0.00018, loss_test:0.15163, lr:7.38e-03, fs:0.57005 (r=0.596,p=0.546),  time:13.916, tt:278.329\n",
      "Ep:20, loss:0.00017, loss_test:0.15142, lr:7.31e-03, fs:0.56311 (r=0.586,p=0.542),  time:14.374, tt:301.852\n",
      "Ep:21, loss:0.00017, loss_test:0.15053, lr:7.24e-03, fs:0.56039 (r=0.586,p=0.537),  time:14.871, tt:327.156\n",
      "Ep:22, loss:0.00017, loss_test:0.14883, lr:7.16e-03, fs:0.56190 (r=0.596,p=0.532),  time:15.270, tt:351.208\n",
      "Ep:23, loss:0.00017, loss_test:0.14783, lr:7.09e-03, fs:0.56731 (r=0.596,p=0.541),  time:15.830, tt:379.925\n",
      "Ep:24, loss:0.00016, loss_test:0.14761, lr:7.02e-03, fs:0.56158 (r=0.576,p=0.548),  time:16.300, tt:407.503\n",
      "Ep:25, loss:0.00016, loss_test:0.14702, lr:6.95e-03, fs:0.56436 (r=0.576,p=0.553),  time:16.764, tt:435.870\n",
      "Ep:26, loss:0.00016, loss_test:0.14604, lr:6.88e-03, fs:0.55882 (r=0.576,p=0.543),  time:17.191, tt:464.169\n",
      "Ep:27, loss:0.00016, loss_test:0.14545, lr:6.81e-03, fs:0.55340 (r=0.576,p=0.533),  time:17.567, tt:491.885\n",
      "Ep:28, loss:0.00015, loss_test:0.14533, lr:6.74e-03, fs:0.55172 (r=0.566,p=0.538),  time:17.969, tt:521.107\n",
      "Ep:29, loss:0.00015, loss_test:0.14497, lr:6.68e-03, fs:0.55721 (r=0.566,p=0.549),  time:18.312, tt:549.370\n",
      "Ep:30, loss:0.00015, loss_test:0.14452, lr:6.61e-03, fs:0.54000 (r=0.545,p=0.535),  time:18.692, tt:579.446\n",
      "Ep:31, loss:0.00015, loss_test:0.14391, lr:6.54e-03, fs:0.54726 (r=0.556,p=0.539),  time:18.995, tt:607.853\n",
      "Ep:32, loss:0.00015, loss_test:0.14325, lr:6.48e-03, fs:0.55446 (r=0.566,p=0.544),  time:19.276, tt:636.093\n",
      "Ep:33, loss:0.00015, loss_test:0.14268, lr:6.41e-03, fs:0.55556 (r=0.556,p=0.556),  time:19.491, tt:662.699\n",
      "Ep:34, loss:0.00014, loss_test:0.14172, lr:6.35e-03, fs:0.56281 (r=0.566,p=0.560),  time:19.748, tt:691.190\n",
      "Ep:35, loss:0.00014, loss_test:0.14058, lr:6.29e-03, fs:0.56716 (r=0.576,p=0.559),  time:19.988, tt:719.558\n",
      "Ep:36, loss:0.00014, loss_test:0.13998, lr:6.22e-03, fs:0.56853 (r=0.566,p=0.571),  time:20.224, tt:748.285\n",
      "Ep:37, loss:0.00014, loss_test:0.13974, lr:6.16e-03, fs:0.56853 (r=0.566,p=0.571),  time:20.433, tt:776.465\n",
      "Ep:38, loss:0.00014, loss_test:0.13869, lr:6.10e-03, fs:0.56853 (r=0.566,p=0.571),  time:20.602, tt:803.473\n",
      "Ep:39, loss:0.00014, loss_test:0.13744, lr:6.04e-03, fs:0.58291 (r=0.586,p=0.580),  time:20.787, tt:831.492\n",
      "Ep:40, loss:0.00013, loss_test:0.13708, lr:5.98e-03, fs:0.59596 (r=0.596,p=0.596),  time:20.964, tt:859.532\n",
      "Ep:41, loss:0.00013, loss_test:0.13658, lr:5.92e-03, fs:0.61000 (r=0.616,p=0.604),  time:21.145, tt:888.083\n",
      "Ep:42, loss:0.00013, loss_test:0.13575, lr:5.86e-03, fs:0.62069 (r=0.636,p=0.606),  time:21.312, tt:916.414\n",
      "Ep:43, loss:0.00013, loss_test:0.13461, lr:5.80e-03, fs:0.62069 (r=0.636,p=0.606),  time:21.466, tt:944.517\n",
      "Ep:44, loss:0.00013, loss_test:0.13398, lr:5.74e-03, fs:0.62376 (r=0.636,p=0.612),  time:21.632, tt:973.432\n",
      "Ep:45, loss:0.00013, loss_test:0.13399, lr:5.68e-03, fs:0.60606 (r=0.606,p=0.606),  time:21.794, tt:1002.504\n",
      "Ep:46, loss:0.00013, loss_test:0.13376, lr:5.63e-03, fs:0.60914 (r=0.606,p=0.612),  time:21.933, tt:1030.836\n",
      "Ep:47, loss:0.00012, loss_test:0.13298, lr:5.57e-03, fs:0.61224 (r=0.606,p=0.619),  time:22.071, tt:1059.386\n",
      "Ep:48, loss:0.00012, loss_test:0.13224, lr:5.52e-03, fs:0.61224 (r=0.606,p=0.619),  time:22.210, tt:1088.272\n",
      "Ep:49, loss:0.00012, loss_test:0.13181, lr:5.46e-03, fs:0.60914 (r=0.606,p=0.612),  time:22.349, tt:1117.428\n",
      "Ep:50, loss:0.00012, loss_test:0.13115, lr:5.41e-03, fs:0.61224 (r=0.606,p=0.619),  time:22.465, tt:1145.723\n",
      "Ep:51, loss:0.00012, loss_test:0.13051, lr:5.35e-03, fs:0.61538 (r=0.606,p=0.625),  time:22.594, tt:1174.912\n",
      "Ep:52, loss:0.00012, loss_test:0.13039, lr:5.30e-03, fs:0.63212 (r=0.616,p=0.649),  time:22.691, tt:1202.635\n",
      "Ep:53, loss:0.00012, loss_test:0.13032, lr:5.25e-03, fs:0.63158 (r=0.606,p=0.659),  time:22.790, tt:1230.649\n",
      "Ep:54, loss:0.00011, loss_test:0.12962, lr:5.19e-03, fs:0.62564 (r=0.616,p=0.635),  time:22.873, tt:1258.040\n",
      "Ep:55, loss:0.00011, loss_test:0.12877, lr:5.14e-03, fs:0.63542 (r=0.616,p=0.656),  time:22.947, tt:1285.039\n",
      "Ep:56, loss:0.00011, loss_test:0.12822, lr:5.09e-03, fs:0.63542 (r=0.616,p=0.656),  time:22.997, tt:1310.809\n",
      "Ep:57, loss:0.00011, loss_test:0.12775, lr:5.04e-03, fs:0.63542 (r=0.616,p=0.656),  time:23.092, tt:1339.312\n",
      "Ep:58, loss:0.00011, loss_test:0.12774, lr:4.99e-03, fs:0.63212 (r=0.616,p=0.649),  time:23.198, tt:1368.672\n",
      "Ep:59, loss:0.00011, loss_test:0.12701, lr:4.94e-03, fs:0.63542 (r=0.616,p=0.656),  time:23.286, tt:1397.155\n",
      "Ep:60, loss:0.00011, loss_test:0.12648, lr:4.89e-03, fs:0.63542 (r=0.616,p=0.656),  time:23.378, tt:1426.070\n",
      "Ep:61, loss:0.00011, loss_test:0.12671, lr:4.84e-03, fs:0.63212 (r=0.616,p=0.649),  time:23.476, tt:1455.514\n",
      "Ep:62, loss:0.00010, loss_test:0.12689, lr:4.79e-03, fs:0.63212 (r=0.616,p=0.649),  time:23.566, tt:1484.645\n",
      "Ep:63, loss:0.00010, loss_test:0.12630, lr:4.74e-03, fs:0.63542 (r=0.616,p=0.656),  time:23.658, tt:1514.081\n",
      "Ep:64, loss:0.00010, loss_test:0.12600, lr:4.70e-03, fs:0.63542 (r=0.616,p=0.656),  time:23.748, tt:1543.640\n",
      "Ep:65, loss:0.00010, loss_test:0.12583, lr:4.65e-03, fs:0.63590 (r=0.626,p=0.646),  time:23.855, tt:1574.404\n",
      "Ep:66, loss:0.00010, loss_test:0.12587, lr:4.60e-03, fs:0.63542 (r=0.616,p=0.656),  time:23.921, tt:1602.697\n",
      "Ep:67, loss:0.00010, loss_test:0.12524, lr:4.56e-03, fs:0.63918 (r=0.626,p=0.653),  time:24.016, tt:1633.068\n",
      "Ep:68, loss:0.00010, loss_test:0.12536, lr:4.51e-03, fs:0.64583 (r=0.626,p=0.667),  time:24.076, tt:1661.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00010, loss_test:0.12522, lr:4.47e-03, fs:0.63874 (r=0.616,p=0.663),  time:24.156, tt:1690.946\n",
      "Ep:70, loss:0.00010, loss_test:0.12504, lr:4.42e-03, fs:0.63542 (r=0.616,p=0.656),  time:24.211, tt:1718.956\n",
      "Ep:71, loss:0.00009, loss_test:0.12495, lr:4.38e-03, fs:0.64211 (r=0.616,p=0.670),  time:24.275, tt:1747.800\n",
      "Ep:72, loss:0.00009, loss_test:0.12490, lr:4.33e-03, fs:0.64211 (r=0.616,p=0.670),  time:24.313, tt:1774.859\n",
      "Ep:73, loss:0.00009, loss_test:0.12463, lr:4.29e-03, fs:0.63874 (r=0.616,p=0.663),  time:24.366, tt:1803.078\n",
      "Ep:74, loss:0.00009, loss_test:0.12499, lr:4.25e-03, fs:0.64211 (r=0.616,p=0.670),  time:24.443, tt:1833.246\n",
      "Ep:75, loss:0.00009, loss_test:0.12488, lr:4.20e-03, fs:0.63874 (r=0.616,p=0.663),  time:24.504, tt:1862.296\n",
      "Ep:76, loss:0.00009, loss_test:0.12489, lr:4.16e-03, fs:0.63874 (r=0.616,p=0.663),  time:24.588, tt:1893.293\n",
      "Ep:77, loss:0.00009, loss_test:0.12465, lr:4.12e-03, fs:0.63542 (r=0.616,p=0.656),  time:24.606, tt:1919.285\n",
      "Ep:78, loss:0.00009, loss_test:0.12511, lr:4.08e-03, fs:0.63542 (r=0.616,p=0.656),  time:24.668, tt:1948.736\n",
      "Ep:79, loss:0.00009, loss_test:0.12482, lr:4.04e-03, fs:0.63874 (r=0.616,p=0.663),  time:24.708, tt:1976.603\n",
      "Ep:80, loss:0.00009, loss_test:0.12409, lr:4.00e-03, fs:0.63542 (r=0.616,p=0.656),  time:24.754, tt:2005.043\n",
      "Ep:81, loss:0.00009, loss_test:0.12451, lr:3.96e-03, fs:0.63830 (r=0.606,p=0.674),  time:24.823, tt:2035.451\n",
      "Ep:82, loss:0.00009, loss_test:0.12458, lr:3.92e-03, fs:0.64171 (r=0.606,p=0.682),  time:24.858, tt:2063.226\n",
      "Ep:83, loss:0.00008, loss_test:0.12449, lr:3.88e-03, fs:0.63830 (r=0.606,p=0.674),  time:24.882, tt:2090.107\n",
      "Ep:84, loss:0.00008, loss_test:0.12406, lr:3.84e-03, fs:0.63830 (r=0.606,p=0.674),  time:24.936, tt:2119.559\n",
      "Ep:85, loss:0.00008, loss_test:0.12404, lr:3.80e-03, fs:0.64171 (r=0.606,p=0.682),  time:24.983, tt:2148.537\n",
      "Ep:86, loss:0.00008, loss_test:0.12432, lr:3.76e-03, fs:0.64171 (r=0.606,p=0.682),  time:25.037, tt:2178.220\n",
      "Ep:87, loss:0.00008, loss_test:0.12421, lr:3.73e-03, fs:0.63830 (r=0.606,p=0.674),  time:25.070, tt:2206.151\n",
      "Ep:88, loss:0.00008, loss_test:0.12330, lr:3.69e-03, fs:0.63492 (r=0.606,p=0.667),  time:25.100, tt:2233.861\n",
      "Ep:89, loss:0.00008, loss_test:0.12418, lr:3.65e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.139, tt:2262.492\n",
      "Ep:90, loss:0.00008, loss_test:0.12484, lr:3.62e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.176, tt:2291.039\n",
      "Ep:91, loss:0.00008, loss_test:0.12418, lr:3.58e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.226, tt:2320.806\n",
      "Ep:92, loss:0.00008, loss_test:0.12388, lr:3.54e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.268, tt:2349.969\n",
      "Ep:93, loss:0.00008, loss_test:0.12421, lr:3.51e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.276, tt:2375.977\n",
      "Ep:94, loss:0.00008, loss_test:0.12405, lr:3.47e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.316, tt:2405.004\n",
      "Ep:95, loss:0.00008, loss_test:0.12325, lr:3.44e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.356, tt:2434.156\n",
      "Ep:96, loss:0.00008, loss_test:0.12340, lr:3.40e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.406, tt:2464.399\n",
      "Ep:97, loss:0.00007, loss_test:0.12376, lr:3.37e-03, fs:0.65217 (r=0.606,p=0.706),  time:25.438, tt:2492.914\n",
      "Ep:98, loss:0.00007, loss_test:0.12366, lr:3.34e-03, fs:0.65217 (r=0.606,p=0.706),  time:25.465, tt:2521.002\n",
      "Ep:99, loss:0.00007, loss_test:0.12328, lr:3.30e-03, fs:0.64865 (r=0.606,p=0.698),  time:25.499, tt:2549.928\n",
      "Ep:100, loss:0.00007, loss_test:0.12385, lr:3.27e-03, fs:0.64481 (r=0.596,p=0.702),  time:25.539, tt:2579.427\n",
      "Ep:101, loss:0.00007, loss_test:0.12337, lr:3.24e-03, fs:0.64481 (r=0.596,p=0.702),  time:25.574, tt:2608.557\n",
      "Ep:102, loss:0.00007, loss_test:0.12283, lr:3.21e-03, fs:0.65217 (r=0.606,p=0.706),  time:25.608, tt:2637.665\n",
      "Ep:103, loss:0.00007, loss_test:0.12310, lr:3.17e-03, fs:0.64481 (r=0.596,p=0.702),  time:25.624, tt:2664.925\n",
      "Ep:104, loss:0.00007, loss_test:0.12335, lr:3.14e-03, fs:0.64835 (r=0.596,p=0.711),  time:25.659, tt:2694.184\n",
      "Ep:105, loss:0.00007, loss_test:0.12298, lr:3.11e-03, fs:0.64481 (r=0.596,p=0.702),  time:25.683, tt:2722.435\n",
      "Ep:106, loss:0.00007, loss_test:0.12306, lr:3.08e-03, fs:0.65217 (r=0.606,p=0.706),  time:25.707, tt:2750.654\n",
      "Ep:107, loss:0.00007, loss_test:0.12332, lr:3.05e-03, fs:0.64835 (r=0.596,p=0.711),  time:25.741, tt:2780.046\n",
      "Ep:108, loss:0.00007, loss_test:0.12325, lr:3.02e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.760, tt:2807.886\n",
      "Ep:109, loss:0.00007, loss_test:0.12253, lr:2.99e-03, fs:0.65934 (r=0.606,p=0.723),  time:25.780, tt:2835.837\n",
      "Ep:110, loss:0.00007, loss_test:0.12340, lr:2.96e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.807, tt:2864.537\n",
      "Ep:111, loss:0.00007, loss_test:0.12360, lr:2.93e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.840, tt:2894.100\n",
      "Ep:112, loss:0.00007, loss_test:0.12299, lr:2.90e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.876, tt:2924.035\n",
      "Ep:113, loss:0.00007, loss_test:0.12353, lr:2.87e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.903, tt:2952.961\n",
      "Ep:114, loss:0.00007, loss_test:0.12395, lr:2.84e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.914, tt:2980.054\n",
      "Ep:115, loss:0.00007, loss_test:0.12350, lr:2.81e-03, fs:0.65934 (r=0.606,p=0.723),  time:25.937, tt:3008.742\n",
      "Ep:116, loss:0.00007, loss_test:0.12389, lr:2.78e-03, fs:0.65193 (r=0.596,p=0.720),  time:25.968, tt:3038.210\n",
      "Ep:117, loss:0.00006, loss_test:0.12392, lr:2.76e-03, fs:0.65193 (r=0.596,p=0.720),  time:26.005, tt:3068.581\n",
      "Ep:118, loss:0.00006, loss_test:0.12354, lr:2.73e-03, fs:0.65934 (r=0.606,p=0.723),  time:26.024, tt:3096.903\n",
      "Ep:119, loss:0.00006, loss_test:0.12381, lr:2.70e-03, fs:0.65193 (r=0.596,p=0.720),  time:26.042, tt:3125.066\n",
      "Ep:120, loss:0.00006, loss_test:0.12384, lr:2.68e-03, fs:0.65193 (r=0.596,p=0.720),  time:26.070, tt:3154.466\n",
      "Ep:121, loss:0.00006, loss_test:0.12373, lr:2.65e-03, fs:0.65934 (r=0.606,p=0.723),  time:26.090, tt:3182.989\n",
      "Ep:122, loss:0.00006, loss_test:0.12405, lr:2.62e-03, fs:0.65193 (r=0.596,p=0.720),  time:26.120, tt:3212.796\n",
      "Ep:123, loss:0.00006, loss_test:0.12396, lr:2.60e-03, fs:0.65193 (r=0.596,p=0.720),  time:26.144, tt:3241.850\n",
      "Ep:124, loss:0.00006, loss_test:0.12365, lr:2.57e-03, fs:0.65934 (r=0.606,p=0.723),  time:26.167, tt:3270.814\n",
      "Ep:125, loss:0.00006, loss_test:0.12366, lr:2.54e-03, fs:0.66298 (r=0.606,p=0.732),  time:26.189, tt:3299.869\n",
      "Ep:126, loss:0.00006, loss_test:0.12370, lr:2.52e-03, fs:0.66298 (r=0.606,p=0.732),  time:26.229, tt:3331.060\n",
      "Ep:127, loss:0.00006, loss_test:0.12435, lr:2.49e-03, fs:0.65922 (r=0.596,p=0.738),  time:26.264, tt:3361.755\n",
      "Ep:128, loss:0.00006, loss_test:0.12428, lr:2.47e-03, fs:0.66667 (r=0.606,p=0.741),  time:26.293, tt:3391.790\n",
      "Ep:129, loss:0.00006, loss_test:0.12431, lr:2.44e-03, fs:0.67033 (r=0.616,p=0.735),  time:26.302, tt:3419.258\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00006, loss_test:0.12406, lr:2.44e-03, fs:0.67033 (r=0.616,p=0.735),  time:26.316, tt:3447.384\n",
      "Ep:131, loss:0.00006, loss_test:0.12445, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.339, tt:3476.743\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00006, loss_test:0.12502, lr:2.44e-03, fs:0.65922 (r=0.596,p=0.738),  time:26.365, tt:3506.494\n",
      "Ep:133, loss:0.00006, loss_test:0.12423, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.386, tt:3535.688\n",
      "Ep:134, loss:0.00006, loss_test:0.12438, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.402, tt:3564.330\n",
      "Ep:135, loss:0.00006, loss_test:0.12445, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.405, tt:3591.093\n",
      "Ep:136, loss:0.00006, loss_test:0.12486, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.425, tt:3620.265\n",
      "Ep:137, loss:0.00006, loss_test:0.12404, lr:2.44e-03, fs:0.67033 (r=0.616,p=0.735),  time:26.447, tt:3649.664\n",
      "Ep:138, loss:0.00006, loss_test:0.12460, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.465, tt:3678.691\n",
      "Ep:139, loss:0.00006, loss_test:0.12508, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.482, tt:3707.514\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00006, loss_test:0.12462, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.497, tt:3736.051\n",
      "Ep:141, loss:0.00005, loss_test:0.12468, lr:2.44e-03, fs:0.67403 (r=0.616,p=0.744),  time:26.517, tt:3765.394\n",
      "Ep:142, loss:0.00005, loss_test:0.12479, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.532, tt:3794.040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00005, loss_test:0.12464, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.539, tt:3821.616\n",
      "Ep:144, loss:0.00005, loss_test:0.12498, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.557, tt:3850.751\n",
      "Ep:145, loss:0.00005, loss_test:0.12486, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.568, tt:3878.886\n",
      "Ep:146, loss:0.00005, loss_test:0.12505, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.598, tt:3909.895\n",
      "Ep:147, loss:0.00005, loss_test:0.12519, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.617, tt:3939.293\n",
      "Ep:148, loss:0.00005, loss_test:0.12469, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.635, tt:3968.544\n",
      "Ep:149, loss:0.00005, loss_test:0.12525, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.654, tt:3998.083\n",
      "Ep:150, loss:0.00005, loss_test:0.12558, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.675, tt:4027.865\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00005, loss_test:0.12505, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.686, tt:4056.278\n",
      "Ep:152, loss:0.00005, loss_test:0.12548, lr:2.44e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.713, tt:4087.063\n",
      "Ep:153, loss:0.00005, loss_test:0.12551, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.721, tt:4114.976\n",
      "Ep:154, loss:0.00005, loss_test:0.12582, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.740, tt:4144.687\n",
      "Ep:155, loss:0.00005, loss_test:0.12542, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.757, tt:4174.140\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00005, loss_test:0.12497, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.776, tt:4203.815\n",
      "Ep:157, loss:0.00005, loss_test:0.12548, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.791, tt:4233.038\n",
      "Ep:158, loss:0.00005, loss_test:0.12581, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.806, tt:4262.106\n",
      "Ep:159, loss:0.00005, loss_test:0.12493, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.811, tt:4289.725\n",
      "Ep:160, loss:0.00005, loss_test:0.12560, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.826, tt:4318.988\n",
      "Ep:161, loss:0.00005, loss_test:0.12596, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.852, tt:4349.979\n",
      "Ep:162, loss:0.00005, loss_test:0.12582, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.869, tt:4379.662\n",
      "Ep:163, loss:0.00005, loss_test:0.12514, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.894, tt:4410.545\n",
      "Ep:164, loss:0.00005, loss_test:0.12578, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.901, tt:4438.696\n",
      "Ep:165, loss:0.00005, loss_test:0.12527, lr:2.44e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.920, tt:4468.711\n",
      "Ep:166, loss:0.00005, loss_test:0.12563, lr:2.44e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.939, tt:4498.848\n",
      "Ep:167, loss:0.00005, loss_test:0.12603, lr:2.42e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.957, tt:4528.827\n",
      "Ep:168, loss:0.00005, loss_test:0.12547, lr:2.40e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.976, tt:4558.954\n",
      "Ep:169, loss:0.00005, loss_test:0.12552, lr:2.37e-03, fs:0.68539 (r=0.616,p=0.772),  time:26.990, tt:4588.274\n",
      "Ep:170, loss:0.00005, loss_test:0.12630, lr:2.35e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.005, tt:4617.857\n",
      "Ep:171, loss:0.00005, loss_test:0.12586, lr:2.32e-03, fs:0.68156 (r=0.616,p=0.762),  time:27.024, tt:4648.160\n",
      "Ep:172, loss:0.00005, loss_test:0.12555, lr:2.30e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.041, tt:4678.035\n",
      "Ep:173, loss:0.00004, loss_test:0.12568, lr:2.28e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.064, tt:4709.134\n",
      "Ep:174, loss:0.00004, loss_test:0.12518, lr:2.25e-03, fs:0.68156 (r=0.616,p=0.762),  time:27.082, tt:4739.317\n",
      "Ep:175, loss:0.00004, loss_test:0.12553, lr:2.23e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.093, tt:4768.375\n",
      "Ep:176, loss:0.00004, loss_test:0.12622, lr:2.21e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.104, tt:4797.459\n",
      "Ep:177, loss:0.00004, loss_test:0.12600, lr:2.19e-03, fs:0.68156 (r=0.616,p=0.762),  time:27.117, tt:4826.805\n",
      "Ep:178, loss:0.00004, loss_test:0.12539, lr:2.17e-03, fs:0.68156 (r=0.616,p=0.762),  time:27.125, tt:4855.428\n",
      "Ep:179, loss:0.00004, loss_test:0.12562, lr:2.14e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.140, tt:4885.136\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"9-9\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14463, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.685, tt:10.685\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14393, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:12.135, tt:24.269\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.14273, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.589, tt:43.767\n",
      "Ep:3, loss:0.00027, loss_test:0.14087, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:16.657, tt:66.626\n",
      "Ep:4, loss:0.00027, loss_test:0.13817, lr:1.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:18.904, tt:94.518\n",
      "Ep:5, loss:0.00026, loss_test:0.13405, lr:1.00e-02, fs:0.64311 (r=0.919,p=0.495),  time:20.867, tt:125.205\n",
      "Ep:6, loss:0.00025, loss_test:0.12830, lr:1.00e-02, fs:0.65370 (r=0.848,p=0.532),  time:22.159, tt:155.113\n",
      "Ep:7, loss:0.00024, loss_test:0.12198, lr:1.00e-02, fs:0.65236 (r=0.768,p=0.567),  time:23.277, tt:186.218\n",
      "Ep:8, loss:0.00023, loss_test:0.11933, lr:1.00e-02, fs:0.65116 (r=0.707,p=0.603),  time:24.045, tt:216.408\n",
      "Ep:9, loss:0.00023, loss_test:0.11680, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:24.860, tt:248.600\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11476, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:25.461, tt:280.071\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.11287, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:25.835, tt:310.024\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10998, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:26.033, tt:338.434\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10759, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:26.405, tt:369.664\n",
      "Ep:14, loss:0.00020, loss_test:0.10579, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:26.748, tt:401.216\n",
      "Ep:15, loss:0.00019, loss_test:0.10415, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:27.010, tt:432.155\n",
      "Ep:16, loss:0.00019, loss_test:0.10230, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:27.224, tt:462.806\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10039, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:27.367, tt:492.607\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09890, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:27.545, tt:523.353\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09836, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:27.624, tt:552.478\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09806, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:27.793, tt:583.655\n",
      "Ep:21, loss:0.00017, loss_test:0.09695, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:27.929, tt:614.433\n",
      "Ep:22, loss:0.00016, loss_test:0.09619, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:28.014, tt:644.328\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09544, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:28.081, tt:673.954\n",
      "Ep:24, loss:0.00016, loss_test:0.09554, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:28.163, tt:704.081\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09461, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:28.299, tt:735.783\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.09382, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:28.354, tt:765.568\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09357, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:28.451, tt:796.624\n",
      "Ep:28, loss:0.00015, loss_test:0.09275, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:28.481, tt:825.942\n",
      "Ep:29, loss:0.00014, loss_test:0.09167, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:28.571, tt:857.121\n",
      "Ep:30, loss:0.00014, loss_test:0.09116, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:28.680, tt:889.072\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09091, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:28.655, tt:916.962\n",
      "Ep:32, loss:0.00013, loss_test:0.09032, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:28.697, tt:946.993\n",
      "Ep:33, loss:0.00013, loss_test:0.08966, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:28.738, tt:977.097\n",
      "Ep:34, loss:0.00013, loss_test:0.09020, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:28.776, tt:1007.172\n",
      "Ep:35, loss:0.00012, loss_test:0.08920, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:28.821, tt:1037.543\n",
      "Ep:36, loss:0.00012, loss_test:0.08820, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:28.878, tt:1068.485\n",
      "Ep:37, loss:0.00012, loss_test:0.08832, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:28.850, tt:1096.285\n",
      "Ep:38, loss:0.00012, loss_test:0.08892, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:28.875, tt:1126.140\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08693, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:28.944, tt:1157.749\n",
      "Ep:40, loss:0.00011, loss_test:0.08755, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:29.000, tt:1188.985\n",
      "Ep:41, loss:0.00011, loss_test:0.08806, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:29.068, tt:1220.864\n",
      "Ep:42, loss:0.00011, loss_test:0.08651, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:29.090, tt:1250.860\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.08678, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:29.088, tt:1279.887\n",
      "Ep:44, loss:0.00010, loss_test:0.08769, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:29.089, tt:1309.006\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.08653, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:29.108, tt:1338.960\n",
      "Ep:46, loss:0.00009, loss_test:0.08708, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:29.151, tt:1370.091\n",
      "Ep:47, loss:0.00009, loss_test:0.08602, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:29.187, tt:1400.970\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.08664, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:29.221, tt:1431.830\n",
      "Ep:49, loss:0.00009, loss_test:0.08656, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:29.260, tt:1463.018\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.08611, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:29.288, tt:1493.671\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.08594, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:29.310, tt:1524.095\n",
      "Ep:52, loss:0.00008, loss_test:0.08660, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:29.348, tt:1555.419\n",
      "Ep:53, loss:0.00008, loss_test:0.08570, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:29.343, tt:1584.534\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.08657, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:29.336, tt:1613.475\n",
      "Ep:55, loss:0.00007, loss_test:0.08588, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:29.369, tt:1644.662\n",
      "Ep:56, loss:0.00007, loss_test:0.08644, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:29.398, tt:1675.692\n",
      "Ep:57, loss:0.00007, loss_test:0.08605, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:29.460, tt:1708.708\n",
      "Ep:58, loss:0.00007, loss_test:0.08547, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:29.512, tt:1741.209\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00007, loss_test:0.08602, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:29.525, tt:1771.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00006, loss_test:0.08489, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:29.586, tt:1804.717\n",
      "Ep:61, loss:0.00006, loss_test:0.08636, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.611, tt:1835.893\n",
      "Ep:62, loss:0.00006, loss_test:0.08332, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.651, tt:1868.036\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.08615, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:29.699, tt:1900.726\n",
      "Ep:64, loss:0.00006, loss_test:0.08461, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:29.727, tt:1932.278\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.08485, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:29.743, tt:1963.010\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.08530, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:29.769, tt:1994.506\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.08347, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:29.804, tt:2026.654\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.08441, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:29.827, tt:2058.043\n",
      "Ep:69, loss:0.00005, loss_test:0.08294, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:29.844, tt:2089.070\n",
      "Ep:70, loss:0.00005, loss_test:0.08460, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:29.866, tt:2120.514\n",
      "Ep:71, loss:0.00005, loss_test:0.08341, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.901, tt:2152.878\n",
      "Ep:72, loss:0.00005, loss_test:0.08505, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:29.937, tt:2185.373\n",
      "Ep:73, loss:0.00004, loss_test:0.08284, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.977, tt:2218.291\n",
      "Ep:74, loss:0.00004, loss_test:0.08541, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:29.983, tt:2248.688\n",
      "Ep:75, loss:0.00004, loss_test:0.08234, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.009, tt:2280.679\n",
      "Ep:76, loss:0.00004, loss_test:0.08430, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:30.022, tt:2311.663\n",
      "Ep:77, loss:0.00004, loss_test:0.08392, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.042, tt:2343.242\n",
      "Ep:78, loss:0.00004, loss_test:0.08219, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.082, tt:2376.453\n",
      "Ep:79, loss:0.00004, loss_test:0.08468, lr:9.90e-03, fs:0.78723 (r=0.747,p=0.831),  time:30.104, tt:2408.320\n",
      "Ep:80, loss:0.00004, loss_test:0.08325, lr:9.80e-03, fs:0.79787 (r=0.758,p=0.843),  time:30.128, tt:2440.406\n",
      "Ep:81, loss:0.00004, loss_test:0.08317, lr:9.70e-03, fs:0.78756 (r=0.768,p=0.809),  time:30.128, tt:2470.469\n",
      "Ep:82, loss:0.00004, loss_test:0.08479, lr:9.61e-03, fs:0.76667 (r=0.697,p=0.852),  time:30.133, tt:2501.006\n",
      "Ep:83, loss:0.00003, loss_test:0.08326, lr:9.51e-03, fs:0.76684 (r=0.747,p=0.787),  time:30.135, tt:2531.353\n",
      "Ep:84, loss:0.00003, loss_test:0.08462, lr:9.41e-03, fs:0.77596 (r=0.717,p=0.845),  time:30.145, tt:2562.311\n",
      "Ep:85, loss:0.00003, loss_test:0.08409, lr:9.32e-03, fs:0.75824 (r=0.697,p=0.831),  time:30.168, tt:2594.430\n",
      "Ep:86, loss:0.00003, loss_test:0.08366, lr:9.23e-03, fs:0.77005 (r=0.727,p=0.818),  time:30.164, tt:2624.265\n",
      "Ep:87, loss:0.00003, loss_test:0.08479, lr:9.14e-03, fs:0.75978 (r=0.687,p=0.850),  time:30.181, tt:2655.964\n",
      "Ep:88, loss:0.00003, loss_test:0.08321, lr:9.04e-03, fs:0.76842 (r=0.737,p=0.802),  time:30.196, tt:2687.439\n",
      "Ep:89, loss:0.00003, loss_test:0.08374, lr:8.95e-03, fs:0.75676 (r=0.707,p=0.814),  time:30.210, tt:2718.910\n",
      "Ep:90, loss:0.00003, loss_test:0.08400, lr:8.86e-03, fs:0.77083 (r=0.747,p=0.796),  time:30.198, tt:2748.058\n",
      "Ep:91, loss:0.00003, loss_test:0.08416, lr:8.78e-03, fs:0.75000 (r=0.697,p=0.812),  time:30.210, tt:2779.330\n",
      "Ep:92, loss:0.00003, loss_test:0.08358, lr:8.69e-03, fs:0.78125 (r=0.758,p=0.806),  time:30.215, tt:2809.993\n",
      "Ep:93, loss:0.00003, loss_test:0.08379, lr:8.60e-03, fs:0.76344 (r=0.717,p=0.816),  time:30.216, tt:2840.285\n",
      "Ep:94, loss:0.00003, loss_test:0.08384, lr:8.51e-03, fs:0.73626 (r=0.677,p=0.807),  time:30.240, tt:2872.800\n",
      "Ep:95, loss:0.00003, loss_test:0.08391, lr:8.43e-03, fs:0.74595 (r=0.697,p=0.802),  time:30.257, tt:2904.668\n",
      "Ep:96, loss:0.00003, loss_test:0.08406, lr:8.35e-03, fs:0.75556 (r=0.687,p=0.840),  time:30.258, tt:2935.003\n",
      "Ep:97, loss:0.00003, loss_test:0.08359, lr:8.26e-03, fs:0.74468 (r=0.707,p=0.787),  time:30.249, tt:2964.443\n",
      "Ep:98, loss:0.00003, loss_test:0.08438, lr:8.18e-03, fs:0.74157 (r=0.667,p=0.835),  time:30.267, tt:2996.479\n",
      "Ep:99, loss:0.00003, loss_test:0.08289, lr:8.10e-03, fs:0.78756 (r=0.768,p=0.809),  time:30.283, tt:3028.346\n",
      "Ep:100, loss:0.00002, loss_test:0.08432, lr:8.02e-03, fs:0.73743 (r=0.667,p=0.825),  time:30.293, tt:3059.546\n",
      "Ep:101, loss:0.00002, loss_test:0.08330, lr:7.94e-03, fs:0.76596 (r=0.727,p=0.809),  time:30.324, tt:3093.017\n",
      "Ep:102, loss:0.00002, loss_test:0.08378, lr:7.86e-03, fs:0.73743 (r=0.667,p=0.825),  time:30.336, tt:3124.630\n",
      "Ep:103, loss:0.00002, loss_test:0.08281, lr:7.78e-03, fs:0.74866 (r=0.707,p=0.795),  time:30.351, tt:3156.469\n",
      "Ep:104, loss:0.00002, loss_test:0.08486, lr:7.70e-03, fs:0.70520 (r=0.616,p=0.824),  time:30.354, tt:3187.129\n",
      "Ep:105, loss:0.00002, loss_test:0.08336, lr:7.62e-03, fs:0.73626 (r=0.677,p=0.807),  time:30.355, tt:3217.615\n",
      "Ep:106, loss:0.00002, loss_test:0.08475, lr:7.55e-03, fs:0.70930 (r=0.616,p=0.836),  time:30.369, tt:3249.466\n",
      "Ep:107, loss:0.00002, loss_test:0.08492, lr:7.47e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.374, tt:3280.374\n",
      "Ep:108, loss:0.00002, loss_test:0.08336, lr:7.40e-03, fs:0.71111 (r=0.646,p=0.790),  time:30.379, tt:3311.293\n",
      "Ep:109, loss:0.00002, loss_test:0.08444, lr:7.32e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.386, tt:3342.465\n",
      "Ep:110, loss:0.00002, loss_test:0.08232, lr:7.25e-03, fs:0.72928 (r=0.667,p=0.805),  time:30.404, tt:3374.881\n",
      "Ep:111, loss:0.00002, loss_test:0.08424, lr:7.18e-03, fs:0.70520 (r=0.616,p=0.824),  time:30.428, tt:3407.947\n",
      "Ep:112, loss:0.00002, loss_test:0.08409, lr:7.11e-03, fs:0.70930 (r=0.616,p=0.836),  time:30.429, tt:3438.508\n",
      "Ep:113, loss:0.00002, loss_test:0.08259, lr:7.03e-03, fs:0.72626 (r=0.657,p=0.812),  time:30.436, tt:3469.759\n",
      "Ep:114, loss:0.00002, loss_test:0.08413, lr:6.96e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.450, tt:3501.735\n",
      "Ep:115, loss:0.00002, loss_test:0.08278, lr:6.89e-03, fs:0.72727 (r=0.646,p=0.831),  time:30.458, tt:3533.091\n",
      "Ep:116, loss:0.00002, loss_test:0.08342, lr:6.83e-03, fs:0.71591 (r=0.636,p=0.818),  time:30.450, tt:3562.690\n",
      "Ep:117, loss:0.00002, loss_test:0.08339, lr:6.76e-03, fs:0.72316 (r=0.646,p=0.821),  time:30.465, tt:3594.838\n",
      "Ep:118, loss:0.00002, loss_test:0.08396, lr:6.69e-03, fs:0.69767 (r=0.606,p=0.822),  time:30.481, tt:3627.192\n",
      "Ep:119, loss:0.00002, loss_test:0.08315, lr:6.62e-03, fs:0.69364 (r=0.606,p=0.811),  time:30.499, tt:3659.860\n",
      "Ep:120, loss:0.00002, loss_test:0.08319, lr:6.56e-03, fs:0.72832 (r=0.636,p=0.851),  time:30.519, tt:3692.832\n",
      "Ep:121, loss:0.00002, loss_test:0.08372, lr:6.49e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.535, tt:3725.279\n",
      "Ep:122, loss:0.00002, loss_test:0.08316, lr:6.43e-03, fs:0.71264 (r=0.626,p=0.827),  time:30.556, tt:3758.418\n",
      "Ep:123, loss:0.00002, loss_test:0.08391, lr:6.36e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.556, tt:3788.929\n",
      "Ep:124, loss:0.00002, loss_test:0.08334, lr:6.30e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.563, tt:3820.393\n",
      "Ep:125, loss:0.00002, loss_test:0.08289, lr:6.24e-03, fs:0.70930 (r=0.616,p=0.836),  time:30.575, tt:3852.451\n",
      "Ep:126, loss:0.00002, loss_test:0.08336, lr:6.17e-03, fs:0.71264 (r=0.626,p=0.827),  time:30.585, tt:3884.330\n",
      "Ep:127, loss:0.00002, loss_test:0.08371, lr:6.11e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.582, tt:3914.492\n",
      "Ep:128, loss:0.00002, loss_test:0.08329, lr:6.05e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.588, tt:3945.801\n",
      "Ep:129, loss:0.00002, loss_test:0.08365, lr:5.99e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.593, tt:3977.029\n",
      "Ep:130, loss:0.00002, loss_test:0.08320, lr:5.93e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.602, tt:4008.837\n",
      "Ep:131, loss:0.00002, loss_test:0.08332, lr:5.87e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.621, tt:4042.009\n",
      "Ep:132, loss:0.00002, loss_test:0.08324, lr:5.81e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.630, tt:4073.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00002, loss_test:0.08342, lr:5.75e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.635, tt:4105.065\n",
      "Ep:134, loss:0.00002, loss_test:0.08291, lr:5.70e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.635, tt:4135.680\n",
      "Ep:135, loss:0.00002, loss_test:0.08398, lr:5.64e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.650, tt:4168.404\n",
      "Ep:136, loss:0.00002, loss_test:0.08332, lr:5.58e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.664, tt:4201.031\n",
      "Ep:137, loss:0.00002, loss_test:0.08311, lr:5.53e-03, fs:0.70930 (r=0.616,p=0.836),  time:30.673, tt:4232.862\n",
      "Ep:138, loss:0.00002, loss_test:0.08411, lr:5.47e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.672, tt:4263.373\n",
      "Ep:139, loss:0.00002, loss_test:0.08326, lr:5.42e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.680, tt:4295.144\n",
      "Ep:140, loss:0.00002, loss_test:0.08369, lr:5.36e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.689, tt:4327.125\n",
      "Ep:141, loss:0.00002, loss_test:0.08337, lr:5.31e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.696, tt:4358.872\n",
      "Ep:142, loss:0.00002, loss_test:0.08322, lr:5.26e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.714, tt:4392.141\n",
      "Ep:143, loss:0.00002, loss_test:0.08316, lr:5.20e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.713, tt:4422.672\n",
      "Ep:144, loss:0.00001, loss_test:0.08378, lr:5.15e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.734, tt:4456.377\n",
      "Ep:145, loss:0.00001, loss_test:0.08363, lr:5.10e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.744, tt:4488.579\n",
      "Ep:146, loss:0.00001, loss_test:0.08299, lr:5.05e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.743, tt:4519.255\n",
      "Ep:147, loss:0.00001, loss_test:0.08367, lr:5.00e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.757, tt:4551.978\n",
      "Ep:148, loss:0.00001, loss_test:0.08335, lr:4.95e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.770, tt:4584.752\n",
      "Ep:149, loss:0.00001, loss_test:0.08358, lr:4.90e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.771, tt:4615.593\n",
      "Ep:150, loss:0.00001, loss_test:0.08263, lr:4.85e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.778, tt:4647.542\n",
      "Ep:151, loss:0.00001, loss_test:0.08391, lr:4.80e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.786, tt:4679.410\n",
      "Ep:152, loss:0.00001, loss_test:0.08239, lr:4.75e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.793, tt:4711.270\n",
      "Ep:153, loss:0.00001, loss_test:0.08391, lr:4.71e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.799, tt:4743.069\n",
      "Ep:154, loss:0.00001, loss_test:0.08400, lr:4.66e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.804, tt:4774.584\n",
      "Ep:155, loss:0.00001, loss_test:0.08227, lr:4.61e-03, fs:0.72414 (r=0.636,p=0.840),  time:30.798, tt:4804.540\n",
      "Ep:156, loss:0.00001, loss_test:0.08354, lr:4.57e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.799, tt:4835.474\n",
      "Ep:157, loss:0.00001, loss_test:0.08382, lr:4.52e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.796, tt:4865.838\n",
      "Ep:158, loss:0.00001, loss_test:0.08250, lr:4.48e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.791, tt:4895.745\n",
      "Ep:159, loss:0.00001, loss_test:0.08361, lr:4.43e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.793, tt:4926.849\n",
      "Ep:160, loss:0.00001, loss_test:0.08321, lr:4.39e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.800, tt:4958.824\n",
      "Ep:161, loss:0.00001, loss_test:0.08240, lr:4.34e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.805, tt:4990.399\n",
      "Ep:162, loss:0.00001, loss_test:0.08417, lr:4.30e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.811, tt:5022.246\n",
      "Ep:163, loss:0.00001, loss_test:0.08299, lr:4.26e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.814, tt:5053.453\n",
      "Ep:164, loss:0.00001, loss_test:0.08338, lr:4.21e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.826, tt:5086.276\n",
      "Ep:165, loss:0.00001, loss_test:0.08408, lr:4.17e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.825, tt:5116.941\n",
      "Ep:166, loss:0.00001, loss_test:0.08259, lr:4.13e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.821, tt:5147.047\n",
      "Ep:167, loss:0.00001, loss_test:0.08345, lr:4.09e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.833, tt:5179.871\n",
      "Ep:168, loss:0.00001, loss_test:0.08434, lr:4.05e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.838, tt:5211.592\n",
      "Ep:169, loss:0.00001, loss_test:0.08284, lr:4.01e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.842, tt:5243.195\n",
      "Ep:170, loss:0.00001, loss_test:0.08326, lr:3.97e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.853, tt:5275.935\n",
      "Ep:171, loss:0.00001, loss_test:0.08374, lr:3.93e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.864, tt:5308.610\n",
      "Ep:172, loss:0.00001, loss_test:0.08297, lr:3.89e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.872, tt:5340.790\n",
      "Ep:173, loss:0.00001, loss_test:0.08335, lr:3.85e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.869, tt:5371.173\n",
      "Ep:174, loss:0.00001, loss_test:0.08377, lr:3.81e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.879, tt:5403.774\n",
      "Ep:175, loss:0.00001, loss_test:0.08303, lr:3.77e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.883, tt:5435.458\n",
      "Ep:176, loss:0.00001, loss_test:0.08277, lr:3.73e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.879, tt:5465.613\n",
      "Ep:177, loss:0.00001, loss_test:0.08349, lr:3.70e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.879, tt:5496.376\n",
      "Ep:178, loss:0.00001, loss_test:0.08312, lr:3.66e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.872, tt:5526.079\n",
      "Ep:179, loss:0.00001, loss_test:0.08285, lr:3.62e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.877, tt:5557.777\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14196, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:27.992, tt:27.992\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14100, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.343, tt:56.686\n",
      "Ep:2, loss:0.00028, loss_test:0.13936, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.657, tt:79.970\n",
      "Ep:3, loss:0.00027, loss_test:0.13689, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:27.174, tt:108.697\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13357, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:28.004, tt:140.021\n",
      "Ep:5, loss:0.00026, loss_test:0.12913, lr:1.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:28.576, tt:171.457\n",
      "Ep:6, loss:0.00025, loss_test:0.12498, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:29.106, tt:203.742\n",
      "Ep:7, loss:0.00024, loss_test:0.12205, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:29.418, tt:235.345\n",
      "Ep:8, loss:0.00023, loss_test:0.12151, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:29.837, tt:268.537\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11963, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:30.160, tt:301.598\n",
      "Ep:10, loss:0.00022, loss_test:0.11667, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:30.229, tt:332.522\n",
      "Ep:11, loss:0.00022, loss_test:0.11439, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:30.321, tt:363.851\n",
      "Ep:12, loss:0.00021, loss_test:0.11200, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:30.305, tt:393.963\n",
      "Ep:13, loss:0.00020, loss_test:0.10980, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:30.409, tt:425.731\n",
      "Ep:14, loss:0.00020, loss_test:0.10719, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:30.415, tt:456.230\n",
      "Ep:15, loss:0.00019, loss_test:0.10433, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:30.494, tt:487.908\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10152, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:30.627, tt:520.666\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09975, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:30.701, tt:552.616\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09805, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:30.803, tt:585.260\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09624, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:30.863, tt:617.254\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09431, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:30.918, tt:649.271\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00017, loss_test:0.09239, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:30.976, tt:681.483\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.09081, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:31.004, tt:713.088\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08995, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:31.042, tt:745.013\n",
      "Ep:24, loss:0.00016, loss_test:0.08835, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:31.011, tt:775.286\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.08687, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:30.986, tt:805.648\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08540, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:31.033, tt:837.897\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.08392, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:31.137, tt:871.836\n",
      "Ep:28, loss:0.00015, loss_test:0.08282, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:31.161, tt:903.656\n",
      "Ep:29, loss:0.00014, loss_test:0.08156, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:31.143, tt:934.302\n",
      "Ep:30, loss:0.00014, loss_test:0.08033, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:31.171, tt:966.314\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.07926, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:31.204, tt:998.532\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.07862, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:31.195, tt:1029.425\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07775, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:31.188, tt:1060.402\n",
      "Ep:34, loss:0.00013, loss_test:0.07689, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:31.197, tt:1091.902\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.07622, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:31.207, tt:1123.460\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.07538, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:31.248, tt:1156.172\n",
      "Ep:37, loss:0.00012, loss_test:0.07460, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:31.217, tt:1186.259\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.07341, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:31.211, tt:1217.227\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.07303, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:31.213, tt:1248.520\n",
      "Ep:40, loss:0.00012, loss_test:0.07305, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:31.213, tt:1279.720\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.07170, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:31.203, tt:1310.510\n",
      "Ep:42, loss:0.00011, loss_test:0.07123, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:31.205, tt:1341.830\n",
      "Ep:43, loss:0.00011, loss_test:0.07057, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:31.207, tt:1373.088\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00011, loss_test:0.07021, lr:1.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:31.252, tt:1406.342\n",
      "Ep:45, loss:0.00010, loss_test:0.06933, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:31.247, tt:1437.354\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.06900, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:31.271, tt:1469.731\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.06860, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:31.282, tt:1501.560\n",
      "Ep:48, loss:0.00010, loss_test:0.06747, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:31.241, tt:1530.800\n",
      "Ep:49, loss:0.00009, loss_test:0.06775, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:31.244, tt:1562.219\n",
      "Ep:50, loss:0.00009, loss_test:0.06719, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:31.255, tt:1594.022\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.06573, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:31.282, tt:1626.655\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00009, loss_test:0.06625, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:31.290, tt:1658.368\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.06519, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:31.313, tt:1690.916\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.06513, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:31.300, tt:1721.515\n",
      "Ep:55, loss:0.00008, loss_test:0.06502, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:31.290, tt:1752.222\n",
      "Ep:56, loss:0.00008, loss_test:0.06361, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:31.304, tt:1784.313\n",
      "Ep:57, loss:0.00007, loss_test:0.06427, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:31.301, tt:1815.448\n",
      "Ep:58, loss:0.00007, loss_test:0.06255, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:31.278, tt:1845.383\n",
      "Ep:59, loss:0.00007, loss_test:0.06319, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:31.281, tt:1876.858\n",
      "Ep:60, loss:0.00007, loss_test:0.06193, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:31.281, tt:1908.137\n",
      "Ep:61, loss:0.00007, loss_test:0.06200, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:31.284, tt:1939.599\n",
      "Ep:62, loss:0.00006, loss_test:0.06200, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:31.278, tt:1970.542\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.06111, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:31.286, tt:2002.277\n",
      "Ep:64, loss:0.00006, loss_test:0.06198, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.293, tt:2034.037\n",
      "Ep:65, loss:0.00006, loss_test:0.06063, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:31.288, tt:2065.036\n",
      "Ep:66, loss:0.00006, loss_test:0.06100, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:31.318, tt:2098.301\n",
      "Ep:67, loss:0.00006, loss_test:0.06072, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.323, tt:2129.936\n",
      "Ep:68, loss:0.00005, loss_test:0.06048, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.340, tt:2162.486\n",
      "Ep:69, loss:0.00005, loss_test:0.06080, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.355, tt:2194.873\n",
      "Ep:70, loss:0.00005, loss_test:0.05986, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:31.364, tt:2226.816\n",
      "Ep:71, loss:0.00005, loss_test:0.06153, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:31.376, tt:2259.084\n",
      "Ep:72, loss:0.00005, loss_test:0.05932, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:31.383, tt:2290.935\n",
      "Ep:73, loss:0.00005, loss_test:0.06081, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:31.390, tt:2322.854\n",
      "Ep:74, loss:0.00005, loss_test:0.05996, lr:9.90e-03, fs:0.90196 (r=0.929,p=0.876),  time:31.397, tt:2354.747\n",
      "Ep:75, loss:0.00005, loss_test:0.06010, lr:9.80e-03, fs:0.90640 (r=0.929,p=0.885),  time:31.398, tt:2386.238\n",
      "Ep:76, loss:0.00005, loss_test:0.06068, lr:9.70e-03, fs:0.89000 (r=0.899,p=0.881),  time:31.384, tt:2416.597\n",
      "Ep:77, loss:0.00004, loss_test:0.05839, lr:9.61e-03, fs:0.90385 (r=0.949,p=0.862),  time:31.363, tt:2446.292\n",
      "Ep:78, loss:0.00004, loss_test:0.06048, lr:9.51e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.361, tt:2477.503\n",
      "Ep:79, loss:0.00004, loss_test:0.05838, lr:9.41e-03, fs:0.90732 (r=0.939,p=0.877),  time:31.392, tt:2511.361\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00004, loss_test:0.05861, lr:9.41e-03, fs:0.90099 (r=0.919,p=0.883),  time:31.408, tt:2544.028\n",
      "Ep:81, loss:0.00004, loss_test:0.06036, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:31.412, tt:2575.820\n",
      "Ep:82, loss:0.00004, loss_test:0.05790, lr:9.41e-03, fs:0.90385 (r=0.949,p=0.862),  time:31.390, tt:2605.343\n",
      "Ep:83, loss:0.00004, loss_test:0.06053, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:31.390, tt:2636.784\n",
      "Ep:84, loss:0.00004, loss_test:0.05747, lr:9.41e-03, fs:0.91176 (r=0.939,p=0.886),  time:31.375, tt:2666.853\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.05908, lr:9.41e-03, fs:0.89447 (r=0.899,p=0.890),  time:31.373, tt:2698.101\n",
      "Ep:86, loss:0.00003, loss_test:0.05884, lr:9.41e-03, fs:0.89000 (r=0.899,p=0.881),  time:31.369, tt:2729.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:87, loss:0.00003, loss_test:0.05849, lr:9.41e-03, fs:0.89447 (r=0.899,p=0.890),  time:31.369, tt:2760.486\n",
      "Ep:88, loss:0.00003, loss_test:0.05843, lr:9.41e-03, fs:0.89447 (r=0.899,p=0.890),  time:31.377, tt:2792.569\n",
      "Ep:89, loss:0.00003, loss_test:0.05733, lr:9.41e-03, fs:0.90640 (r=0.929,p=0.885),  time:31.380, tt:2824.212\n",
      "Ep:90, loss:0.00003, loss_test:0.05896, lr:9.41e-03, fs:0.89340 (r=0.889,p=0.898),  time:31.374, tt:2855.051\n",
      "Ep:91, loss:0.00003, loss_test:0.05786, lr:9.41e-03, fs:0.89552 (r=0.909,p=0.882),  time:31.370, tt:2886.069\n",
      "Ep:92, loss:0.00003, loss_test:0.05730, lr:9.41e-03, fs:0.89552 (r=0.909,p=0.882),  time:31.372, tt:2917.552\n",
      "Ep:93, loss:0.00003, loss_test:0.05845, lr:9.41e-03, fs:0.88889 (r=0.889,p=0.889),  time:31.378, tt:2949.563\n",
      "Ep:94, loss:0.00003, loss_test:0.05796, lr:9.41e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.381, tt:2981.195\n",
      "Ep:95, loss:0.00003, loss_test:0.05689, lr:9.41e-03, fs:0.90099 (r=0.919,p=0.883),  time:31.389, tt:3013.374\n",
      "Ep:96, loss:0.00003, loss_test:0.05882, lr:9.32e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.393, tt:3045.123\n",
      "Ep:97, loss:0.00003, loss_test:0.05703, lr:9.23e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.392, tt:3076.411\n",
      "Ep:98, loss:0.00003, loss_test:0.05822, lr:9.14e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.401, tt:3108.654\n",
      "Ep:99, loss:0.00002, loss_test:0.05784, lr:9.04e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.403, tt:3140.330\n",
      "Ep:100, loss:0.00002, loss_test:0.05790, lr:8.95e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.404, tt:3171.791\n",
      "Ep:101, loss:0.00002, loss_test:0.05789, lr:8.86e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.413, tt:3204.091\n",
      "Ep:102, loss:0.00002, loss_test:0.05680, lr:8.78e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.403, tt:3234.542\n",
      "Ep:103, loss:0.00002, loss_test:0.05743, lr:8.69e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.414, tt:3267.061\n",
      "Ep:104, loss:0.00002, loss_test:0.05703, lr:8.60e-03, fs:0.89216 (r=0.919,p=0.867),  time:31.397, tt:3296.668\n",
      "Ep:105, loss:0.00002, loss_test:0.05881, lr:8.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:31.403, tt:3328.680\n",
      "Ep:106, loss:0.00002, loss_test:0.05741, lr:8.43e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.397, tt:3359.455\n",
      "Ep:107, loss:0.00002, loss_test:0.05825, lr:8.35e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.380, tt:3389.055\n",
      "Ep:108, loss:0.00002, loss_test:0.05814, lr:8.26e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.362, tt:3418.490\n",
      "Ep:109, loss:0.00002, loss_test:0.05755, lr:8.18e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.349, tt:3448.342\n",
      "Ep:110, loss:0.00002, loss_test:0.05745, lr:8.10e-03, fs:0.89552 (r=0.909,p=0.882),  time:31.340, tt:3478.739\n",
      "Ep:111, loss:0.00002, loss_test:0.05843, lr:8.02e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.335, tt:3509.543\n",
      "Ep:112, loss:0.00002, loss_test:0.05749, lr:7.94e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.329, tt:3540.130\n",
      "Ep:113, loss:0.00002, loss_test:0.05817, lr:7.86e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.336, tt:3572.350\n",
      "Ep:114, loss:0.00002, loss_test:0.05763, lr:7.78e-03, fs:0.89109 (r=0.909,p=0.874),  time:31.346, tt:3604.806\n",
      "Ep:115, loss:0.00002, loss_test:0.05808, lr:7.70e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.349, tt:3636.530\n",
      "Ep:116, loss:0.00002, loss_test:0.05846, lr:7.62e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.361, tt:3669.274\n",
      "Ep:117, loss:0.00002, loss_test:0.05758, lr:7.55e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.361, tt:3700.611\n",
      "Ep:118, loss:0.00002, loss_test:0.05801, lr:7.47e-03, fs:0.87562 (r=0.889,p=0.863),  time:31.355, tt:3731.231\n",
      "Ep:119, loss:0.00002, loss_test:0.05768, lr:7.40e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.365, tt:3763.767\n",
      "Ep:120, loss:0.00002, loss_test:0.05770, lr:7.32e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.353, tt:3793.738\n",
      "Ep:121, loss:0.00002, loss_test:0.05838, lr:7.25e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.349, tt:3824.622\n",
      "Ep:122, loss:0.00002, loss_test:0.05642, lr:7.18e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.348, tt:3855.748\n",
      "Ep:123, loss:0.00002, loss_test:0.05917, lr:7.11e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.349, tt:3887.317\n",
      "Ep:124, loss:0.00002, loss_test:0.05652, lr:7.03e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.338, tt:3917.237\n",
      "Ep:125, loss:0.00002, loss_test:0.05881, lr:6.96e-03, fs:0.88889 (r=0.889,p=0.889),  time:31.342, tt:3949.036\n",
      "Ep:126, loss:0.00002, loss_test:0.05782, lr:6.89e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.337, tt:3979.740\n",
      "Ep:127, loss:0.00002, loss_test:0.05703, lr:6.83e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.321, tt:4009.131\n",
      "Ep:128, loss:0.00002, loss_test:0.05905, lr:6.76e-03, fs:0.88205 (r=0.869,p=0.896),  time:31.321, tt:4040.442\n",
      "Ep:129, loss:0.00001, loss_test:0.05660, lr:6.69e-03, fs:0.91787 (r=0.960,p=0.880),  time:31.317, tt:4071.150\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00001, loss_test:0.05935, lr:6.69e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.298, tt:4100.019\n",
      "Ep:131, loss:0.00001, loss_test:0.05802, lr:6.69e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.305, tt:4132.214\n",
      "Ep:132, loss:0.00001, loss_test:0.05627, lr:6.69e-03, fs:0.91787 (r=0.960,p=0.880),  time:31.298, tt:4162.649\n",
      "Ep:133, loss:0.00001, loss_test:0.06001, lr:6.69e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.290, tt:4192.876\n",
      "Ep:134, loss:0.00001, loss_test:0.05667, lr:6.69e-03, fs:0.90099 (r=0.919,p=0.883),  time:31.299, tt:4225.316\n",
      "Ep:135, loss:0.00001, loss_test:0.05750, lr:6.69e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.305, tt:4257.491\n",
      "Ep:136, loss:0.00001, loss_test:0.05774, lr:6.69e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.314, tt:4290.018\n",
      "Ep:137, loss:0.00001, loss_test:0.05686, lr:6.69e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.315, tt:4321.414\n",
      "Ep:138, loss:0.00001, loss_test:0.05882, lr:6.69e-03, fs:0.88889 (r=0.889,p=0.889),  time:31.304, tt:4351.222\n",
      "Ep:139, loss:0.00001, loss_test:0.05646, lr:6.69e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.290, tt:4380.585\n",
      "Ep:140, loss:0.00001, loss_test:0.05787, lr:6.69e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.285, tt:4411.176\n",
      "Ep:141, loss:0.00001, loss_test:0.05811, lr:6.62e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.283, tt:4442.132\n",
      "Ep:142, loss:0.00001, loss_test:0.05694, lr:6.56e-03, fs:0.89109 (r=0.909,p=0.874),  time:31.270, tt:4471.616\n",
      "Ep:143, loss:0.00001, loss_test:0.05898, lr:6.49e-03, fs:0.87879 (r=0.879,p=0.879),  time:31.251, tt:4500.176\n",
      "Ep:144, loss:0.00001, loss_test:0.05697, lr:6.43e-03, fs:0.89655 (r=0.919,p=0.875),  time:31.241, tt:4529.989\n",
      "Ep:145, loss:0.00001, loss_test:0.05749, lr:6.36e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.241, tt:4561.256\n",
      "Ep:146, loss:0.00001, loss_test:0.05874, lr:6.30e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.242, tt:4592.584\n",
      "Ep:147, loss:0.00001, loss_test:0.05720, lr:6.24e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.235, tt:4622.759\n",
      "Ep:148, loss:0.00001, loss_test:0.05725, lr:6.17e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.233, tt:4653.656\n",
      "Ep:149, loss:0.00001, loss_test:0.05787, lr:6.11e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.245, tt:4686.720\n",
      "Ep:150, loss:0.00001, loss_test:0.05804, lr:6.05e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.236, tt:4716.691\n",
      "Ep:151, loss:0.00001, loss_test:0.05749, lr:5.99e-03, fs:0.89109 (r=0.909,p=0.874),  time:31.247, tt:4749.566\n",
      "Ep:152, loss:0.00001, loss_test:0.05774, lr:5.93e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.246, tt:4780.617\n",
      "Ep:153, loss:0.00001, loss_test:0.05796, lr:5.87e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.253, tt:4813.012\n",
      "Ep:154, loss:0.00001, loss_test:0.05776, lr:5.81e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.258, tt:4844.954\n",
      "Ep:155, loss:0.00001, loss_test:0.05786, lr:5.75e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.254, tt:4875.649\n",
      "Ep:156, loss:0.00001, loss_test:0.05792, lr:5.70e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.251, tt:4906.444\n",
      "Ep:157, loss:0.00001, loss_test:0.05799, lr:5.64e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.244, tt:4936.503\n",
      "Ep:158, loss:0.00001, loss_test:0.05815, lr:5.58e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.237, tt:4966.721\n",
      "Ep:159, loss:0.00001, loss_test:0.05785, lr:5.53e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.234, tt:4997.376\n",
      "Ep:160, loss:0.00001, loss_test:0.05832, lr:5.47e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.232, tt:5028.407\n",
      "Ep:161, loss:0.00001, loss_test:0.05803, lr:5.42e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.235, tt:5060.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:162, loss:0.00001, loss_test:0.05787, lr:5.36e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.231, tt:5090.727\n",
      "Ep:163, loss:0.00001, loss_test:0.05871, lr:5.31e-03, fs:0.86294 (r=0.859,p=0.867),  time:31.232, tt:5122.071\n",
      "Ep:164, loss:0.00001, loss_test:0.05824, lr:5.26e-03, fs:0.85567 (r=0.838,p=0.874),  time:31.216, tt:5150.591\n",
      "Ep:165, loss:0.00001, loss_test:0.05830, lr:5.20e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.213, tt:5181.382\n",
      "Ep:166, loss:0.00001, loss_test:0.05831, lr:5.15e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.215, tt:5212.845\n",
      "Ep:167, loss:0.00001, loss_test:0.05829, lr:5.10e-03, fs:0.85417 (r=0.828,p=0.882),  time:31.214, tt:5243.980\n",
      "Ep:168, loss:0.00001, loss_test:0.05821, lr:5.05e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.205, tt:5273.587\n",
      "Ep:169, loss:0.00001, loss_test:0.05849, lr:5.00e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.206, tt:5305.009\n",
      "Ep:170, loss:0.00001, loss_test:0.05804, lr:4.95e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.201, tt:5335.440\n",
      "Ep:171, loss:0.00001, loss_test:0.05838, lr:4.90e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.205, tt:5367.186\n",
      "Ep:172, loss:0.00001, loss_test:0.05874, lr:4.85e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.214, tt:5400.050\n",
      "Ep:173, loss:0.00001, loss_test:0.05823, lr:4.80e-03, fs:0.85567 (r=0.838,p=0.874),  time:31.213, tt:5431.117\n",
      "Ep:174, loss:0.00001, loss_test:0.05871, lr:4.75e-03, fs:0.85417 (r=0.828,p=0.882),  time:31.219, tt:5463.364\n",
      "Ep:175, loss:0.00001, loss_test:0.05868, lr:4.71e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.224, tt:5495.436\n",
      "Ep:176, loss:0.00001, loss_test:0.05854, lr:4.66e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.226, tt:5526.967\n",
      "Ep:177, loss:0.00001, loss_test:0.05826, lr:4.61e-03, fs:0.85567 (r=0.838,p=0.874),  time:31.212, tt:5555.710\n",
      "Ep:178, loss:0.00001, loss_test:0.05868, lr:4.57e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.209, tt:5586.479\n",
      "Ep:179, loss:0.00001, loss_test:0.05900, lr:4.52e-03, fs:0.81720 (r=0.768,p=0.874),  time:31.201, tt:5616.090\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14384, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:54.291, tt:54.291\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14084, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:54.893, tt:109.786\n",
      "Ep:2, loss:0.00054, loss_test:0.13411, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:57.328, tt:171.985\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.12528, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:58.357, tt:233.427\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.12502, lr:1.00e-02, fs:0.60417 (r=0.586,p=0.624),  time:59.275, tt:296.373\n",
      "Ep:5, loss:0.00043, loss_test:0.11942, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:60.081, tt:360.485\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00041, loss_test:0.11825, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:60.556, tt:423.895\n",
      "Ep:7, loss:0.00039, loss_test:0.11488, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:61.039, tt:488.315\n",
      "Ep:8, loss:0.00038, loss_test:0.11161, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:61.370, tt:552.334\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.10801, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:61.730, tt:617.296\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.10562, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:61.920, tt:681.123\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.10444, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:62.118, tt:745.421\n",
      "Ep:12, loss:0.00032, loss_test:0.10269, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:62.227, tt:808.953\n",
      "Ep:13, loss:0.00030, loss_test:0.10156, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:62.423, tt:873.924\n",
      "Ep:14, loss:0.00029, loss_test:0.10009, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:62.533, tt:937.996\n",
      "Ep:15, loss:0.00028, loss_test:0.09887, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:62.328, tt:997.246\n",
      "Ep:16, loss:0.00027, loss_test:0.09794, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:62.510, tt:1062.665\n",
      "Ep:17, loss:0.00026, loss_test:0.09659, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:62.677, tt:1128.188\n",
      "Ep:18, loss:0.00025, loss_test:0.09505, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:62.851, tt:1194.163\n",
      "Ep:19, loss:0.00024, loss_test:0.09395, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:63.029, tt:1260.570\n",
      "Ep:20, loss:0.00023, loss_test:0.09301, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:63.138, tt:1325.898\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.09445, lr:1.00e-02, fs:0.75281 (r=0.677,p=0.848),  time:63.188, tt:1390.136\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.09192, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:63.315, tt:1456.237\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.09239, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:63.407, tt:1521.770\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.09417, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:63.471, tt:1586.786\n",
      "Ep:25, loss:0.00018, loss_test:0.09021, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:63.473, tt:1650.305\n",
      "Ep:26, loss:0.00017, loss_test:0.09080, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:63.505, tt:1714.644\n",
      "Ep:27, loss:0.00016, loss_test:0.09115, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:63.467, tt:1777.067\n",
      "Ep:28, loss:0.00016, loss_test:0.08810, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:63.475, tt:1840.783\n",
      "Ep:29, loss:0.00015, loss_test:0.08775, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:63.554, tt:1906.634\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.08825, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:63.588, tt:1971.224\n",
      "Ep:31, loss:0.00013, loss_test:0.08654, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:63.631, tt:2036.179\n",
      "Ep:32, loss:0.00013, loss_test:0.08551, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:63.682, tt:2101.494\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08796, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:63.709, tt:2166.108\n",
      "Ep:34, loss:0.00011, loss_test:0.08399, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:63.666, tt:2228.308\n",
      "Ep:35, loss:0.00011, loss_test:0.08593, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:63.675, tt:2292.316\n",
      "Ep:36, loss:0.00010, loss_test:0.08524, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:63.680, tt:2356.155\n",
      "Ep:37, loss:0.00010, loss_test:0.08794, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:63.670, tt:2419.466\n",
      "Ep:38, loss:0.00009, loss_test:0.08206, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:63.652, tt:2482.421\n",
      "Ep:39, loss:0.00009, loss_test:0.08748, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:63.588, tt:2543.516\n",
      "Ep:40, loss:0.00008, loss_test:0.08676, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:63.595, tt:2607.378\n",
      "Ep:41, loss:0.00008, loss_test:0.08354, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:63.631, tt:2672.494\n",
      "Ep:42, loss:0.00007, loss_test:0.08611, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:63.547, tt:2732.509\n",
      "Ep:43, loss:0.00007, loss_test:0.08474, lr:1.00e-02, fs:0.70000 (r=0.566,p=0.918),  time:63.574, tt:2797.269\n",
      "Ep:44, loss:0.00007, loss_test:0.08923, lr:9.90e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.618, tt:2862.821\n",
      "Ep:45, loss:0.00007, loss_test:0.08739, lr:9.80e-03, fs:0.70064 (r=0.556,p=0.948),  time:63.684, tt:2929.452\n",
      "Ep:46, loss:0.00006, loss_test:0.08590, lr:9.70e-03, fs:0.70000 (r=0.566,p=0.918),  time:63.735, tt:2995.552\n",
      "Ep:47, loss:0.00006, loss_test:0.08798, lr:9.61e-03, fs:0.67974 (r=0.525,p=0.963),  time:63.728, tt:3058.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00005, loss_test:0.08427, lr:9.51e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.749, tt:3123.694\n",
      "Ep:49, loss:0.00005, loss_test:0.08547, lr:9.41e-03, fs:0.65823 (r=0.525,p=0.881),  time:63.743, tt:3187.165\n",
      "Ep:50, loss:0.00005, loss_test:0.08822, lr:9.32e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.744, tt:3250.945\n",
      "Ep:51, loss:0.00005, loss_test:0.08876, lr:9.23e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.764, tt:3315.715\n",
      "Ep:52, loss:0.00005, loss_test:0.08482, lr:9.14e-03, fs:0.65823 (r=0.525,p=0.881),  time:63.743, tt:3378.378\n",
      "Ep:53, loss:0.00004, loss_test:0.08555, lr:9.04e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.765, tt:3443.322\n",
      "Ep:54, loss:0.00004, loss_test:0.08913, lr:8.95e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.776, tt:3507.689\n",
      "Ep:55, loss:0.00004, loss_test:0.08755, lr:8.86e-03, fs:0.67097 (r=0.525,p=0.929),  time:63.803, tt:3572.968\n",
      "Ep:56, loss:0.00004, loss_test:0.08591, lr:8.78e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.826, tt:3638.096\n",
      "Ep:57, loss:0.00004, loss_test:0.08580, lr:8.69e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.855, tt:3703.608\n",
      "Ep:58, loss:0.00004, loss_test:0.08713, lr:8.60e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.839, tt:3766.479\n",
      "Ep:59, loss:0.00003, loss_test:0.08765, lr:8.51e-03, fs:0.66242 (r=0.525,p=0.897),  time:63.858, tt:3831.450\n",
      "Ep:60, loss:0.00003, loss_test:0.08854, lr:8.43e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.878, tt:3896.585\n",
      "Ep:61, loss:0.00003, loss_test:0.08852, lr:8.35e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.924, tt:3963.285\n",
      "Ep:62, loss:0.00003, loss_test:0.08743, lr:8.26e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.967, tt:4029.936\n",
      "Ep:63, loss:0.00003, loss_test:0.08667, lr:8.18e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.978, tt:4094.584\n",
      "Ep:64, loss:0.00003, loss_test:0.08988, lr:8.10e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.013, tt:4160.851\n",
      "Ep:65, loss:0.00003, loss_test:0.08837, lr:8.02e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.015, tt:4225.010\n",
      "Ep:66, loss:0.00003, loss_test:0.08938, lr:7.94e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.020, tt:4289.342\n",
      "Ep:67, loss:0.00003, loss_test:0.09029, lr:7.86e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.997, tt:4351.821\n",
      "Ep:68, loss:0.00003, loss_test:0.08934, lr:7.78e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.021, tt:4417.440\n",
      "Ep:69, loss:0.00003, loss_test:0.09125, lr:7.70e-03, fs:0.67974 (r=0.525,p=0.963),  time:64.059, tt:4484.159\n",
      "Ep:70, loss:0.00003, loss_test:0.08886, lr:7.62e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.070, tt:4549.006\n",
      "Ep:71, loss:0.00002, loss_test:0.08824, lr:7.55e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.079, tt:4613.689\n",
      "Ep:72, loss:0.00002, loss_test:0.08948, lr:7.47e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.074, tt:4677.420\n",
      "Ep:73, loss:0.00002, loss_test:0.08895, lr:7.40e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.076, tt:4741.602\n",
      "Ep:74, loss:0.00002, loss_test:0.08822, lr:7.32e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.092, tt:4806.917\n",
      "Ep:75, loss:0.00002, loss_test:0.09060, lr:7.25e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.091, tt:4870.904\n",
      "Ep:76, loss:0.00002, loss_test:0.08925, lr:7.18e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.127, tt:4937.759\n",
      "Ep:77, loss:0.00002, loss_test:0.08983, lr:7.11e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.134, tt:5002.483\n",
      "Ep:78, loss:0.00002, loss_test:0.09180, lr:7.03e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.129, tt:5066.199\n",
      "Ep:79, loss:0.00002, loss_test:0.09106, lr:6.96e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.130, tt:5130.374\n",
      "Ep:80, loss:0.00002, loss_test:0.09067, lr:6.89e-03, fs:0.67974 (r=0.525,p=0.963),  time:64.122, tt:5193.849\n",
      "Ep:81, loss:0.00002, loss_test:0.09061, lr:6.83e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.109, tt:5256.957\n",
      "Ep:82, loss:0.00002, loss_test:0.08923, lr:6.76e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.117, tt:5321.748\n",
      "Ep:83, loss:0.00002, loss_test:0.09133, lr:6.69e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.088, tt:5383.364\n",
      "Ep:84, loss:0.00002, loss_test:0.08955, lr:6.62e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.089, tt:5447.562\n",
      "Ep:85, loss:0.00002, loss_test:0.08970, lr:6.56e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.097, tt:5512.321\n",
      "Ep:86, loss:0.00002, loss_test:0.09129, lr:6.49e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.084, tt:5575.280\n",
      "Ep:87, loss:0.00002, loss_test:0.09069, lr:6.43e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.103, tt:5641.100\n",
      "Ep:88, loss:0.00002, loss_test:0.09059, lr:6.36e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.125, tt:5707.100\n",
      "Ep:89, loss:0.00002, loss_test:0.09028, lr:6.30e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.144, tt:5772.967\n",
      "Ep:90, loss:0.00002, loss_test:0.09063, lr:6.24e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.165, tt:5839.027\n",
      "Ep:91, loss:0.00002, loss_test:0.09195, lr:6.17e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.182, tt:5904.702\n",
      "Ep:92, loss:0.00002, loss_test:0.09085, lr:6.11e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.197, tt:5970.338\n",
      "Ep:93, loss:0.00002, loss_test:0.09227, lr:6.05e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.198, tt:6034.577\n",
      "Ep:94, loss:0.00002, loss_test:0.09158, lr:5.99e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.214, tt:6100.296\n",
      "Ep:95, loss:0.00002, loss_test:0.09061, lr:5.93e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.226, tt:6165.695\n",
      "Ep:96, loss:0.00002, loss_test:0.09176, lr:5.87e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.194, tt:6226.855\n",
      "Ep:97, loss:0.00002, loss_test:0.09181, lr:5.81e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.195, tt:6291.123\n",
      "Ep:98, loss:0.00002, loss_test:0.09261, lr:5.75e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.206, tt:6356.366\n",
      "Ep:99, loss:0.00001, loss_test:0.09109, lr:5.70e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.218, tt:6421.817\n",
      "Ep:100, loss:0.00001, loss_test:0.09328, lr:5.64e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.221, tt:6486.288\n",
      "Ep:101, loss:0.00001, loss_test:0.09335, lr:5.58e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.218, tt:6550.215\n",
      "Ep:102, loss:0.00001, loss_test:0.09150, lr:5.53e-03, fs:0.66667 (r=0.525,p=0.912),  time:64.201, tt:6612.731\n",
      "Ep:103, loss:0.00001, loss_test:0.09305, lr:5.47e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.202, tt:6677.011\n",
      "Ep:104, loss:0.00001, loss_test:0.09260, lr:5.42e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.182, tt:6739.116\n",
      "Ep:105, loss:0.00001, loss_test:0.09186, lr:5.36e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.195, tt:6804.704\n",
      "Ep:106, loss:0.00001, loss_test:0.09303, lr:5.31e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.195, tt:6868.848\n",
      "Ep:107, loss:0.00001, loss_test:0.09311, lr:5.26e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.194, tt:6932.956\n",
      "Ep:108, loss:0.00001, loss_test:0.09201, lr:5.20e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.206, tt:6998.507\n",
      "Ep:109, loss:0.00001, loss_test:0.09343, lr:5.15e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.224, tt:7064.627\n",
      "Ep:110, loss:0.00001, loss_test:0.09215, lr:5.10e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.245, tt:7131.146\n",
      "Ep:111, loss:0.00001, loss_test:0.09379, lr:5.05e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.257, tt:7196.737\n",
      "Ep:112, loss:0.00001, loss_test:0.09229, lr:5.00e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.265, tt:7261.956\n",
      "Ep:113, loss:0.00001, loss_test:0.09319, lr:4.95e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.279, tt:7327.796\n",
      "Ep:114, loss:0.00001, loss_test:0.09334, lr:4.90e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.277, tt:7391.869\n",
      "Ep:115, loss:0.00001, loss_test:0.09381, lr:4.85e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.298, tt:7458.563\n",
      "Ep:116, loss:0.00001, loss_test:0.09355, lr:4.80e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.298, tt:7522.855\n",
      "Ep:117, loss:0.00001, loss_test:0.09469, lr:4.75e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.297, tt:7587.086\n",
      "Ep:118, loss:0.00001, loss_test:0.09383, lr:4.71e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.288, tt:7650.303\n",
      "Ep:119, loss:0.00001, loss_test:0.09334, lr:4.66e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.248, tt:7709.711\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14639, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.810, tt:52.810\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14428, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:55.294, tt:110.588\n",
      "Ep:2, loss:0.00053, loss_test:0.13982, lr:1.00e-02, fs:0.62454 (r=0.848,p=0.494),  time:58.712, tt:176.136\n",
      "Ep:3, loss:0.00048, loss_test:0.13737, lr:1.00e-02, fs:0.63107 (r=0.657,p=0.607),  time:60.293, tt:241.171\n",
      "Ep:4, loss:0.00044, loss_test:0.13873, lr:1.00e-02, fs:0.63590 (r=0.626,p=0.646),  time:61.161, tt:305.807\n",
      "Ep:5, loss:0.00043, loss_test:0.13191, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:61.556, tt:369.334\n",
      "Ep:6, loss:0.00040, loss_test:0.13406, lr:1.00e-02, fs:0.57609 (r=0.535,p=0.624),  time:62.091, tt:434.638\n",
      "Ep:7, loss:0.00038, loss_test:0.12657, lr:1.00e-02, fs:0.64706 (r=0.667,p=0.629),  time:62.353, tt:498.822\n",
      "Ep:8, loss:0.00037, loss_test:0.12530, lr:1.00e-02, fs:0.55866 (r=0.505,p=0.625),  time:62.213, tt:559.913\n",
      "Ep:9, loss:0.00035, loss_test:0.12154, lr:1.00e-02, fs:0.58564 (r=0.535,p=0.646),  time:62.366, tt:623.656\n",
      "Ep:10, loss:0.00033, loss_test:0.12024, lr:1.00e-02, fs:0.57303 (r=0.515,p=0.646),  time:62.617, tt:688.791\n",
      "Ep:11, loss:0.00032, loss_test:0.11761, lr:1.00e-02, fs:0.63102 (r=0.596,p=0.670),  time:62.688, tt:752.259\n",
      "Ep:12, loss:0.00031, loss_test:0.11825, lr:9.90e-03, fs:0.59669 (r=0.545,p=0.659),  time:62.888, tt:817.547\n",
      "Ep:13, loss:0.00029, loss_test:0.11798, lr:9.80e-03, fs:0.61538 (r=0.566,p=0.675),  time:62.956, tt:881.383\n",
      "Ep:14, loss:0.00028, loss_test:0.11775, lr:9.70e-03, fs:0.60440 (r=0.556,p=0.663),  time:63.081, tt:946.222\n",
      "Ep:15, loss:0.00027, loss_test:0.11905, lr:9.61e-03, fs:0.62222 (r=0.566,p=0.691),  time:63.043, tt:1008.685\n",
      "Ep:16, loss:0.00026, loss_test:0.11841, lr:9.51e-03, fs:0.62983 (r=0.576,p=0.695),  time:63.133, tt:1073.261\n",
      "Ep:17, loss:0.00024, loss_test:0.11916, lr:9.41e-03, fs:0.62983 (r=0.576,p=0.695),  time:63.130, tt:1136.332\n",
      "Ep:18, loss:0.00023, loss_test:0.11844, lr:9.32e-03, fs:0.63333 (r=0.576,p=0.704),  time:63.196, tt:1200.720\n",
      "Ep:19, loss:0.00022, loss_test:0.12021, lr:9.23e-03, fs:0.64045 (r=0.576,p=0.722),  time:63.164, tt:1263.279\n",
      "Ep:20, loss:0.00021, loss_test:0.12090, lr:9.14e-03, fs:0.61988 (r=0.535,p=0.736),  time:63.276, tt:1328.800\n",
      "Ep:21, loss:0.00020, loss_test:0.11789, lr:9.04e-03, fs:0.65169 (r=0.586,p=0.734),  time:63.382, tt:1394.396\n",
      "Ep:22, loss:0.00019, loss_test:0.12195, lr:8.95e-03, fs:0.62275 (r=0.525,p=0.765),  time:63.420, tt:1458.651\n",
      "Ep:23, loss:0.00018, loss_test:0.12319, lr:8.86e-03, fs:0.62195 (r=0.515,p=0.785),  time:63.458, tt:1522.988\n",
      "Ep:24, loss:0.00017, loss_test:0.12439, lr:8.78e-03, fs:0.61728 (r=0.505,p=0.794),  time:63.503, tt:1587.573\n",
      "Ep:25, loss:0.00017, loss_test:0.12539, lr:8.69e-03, fs:0.60000 (r=0.485,p=0.787),  time:63.496, tt:1650.888\n",
      "Ep:26, loss:0.00016, loss_test:0.12251, lr:8.60e-03, fs:0.61728 (r=0.505,p=0.794),  time:63.505, tt:1714.623\n",
      "Ep:27, loss:0.00015, loss_test:0.12652, lr:8.51e-03, fs:0.58228 (r=0.465,p=0.780),  time:63.534, tt:1778.958\n",
      "Ep:28, loss:0.00014, loss_test:0.12681, lr:8.43e-03, fs:0.58228 (r=0.465,p=0.780),  time:63.560, tt:1843.229\n",
      "Ep:29, loss:0.00013, loss_test:0.12579, lr:8.35e-03, fs:0.58228 (r=0.465,p=0.780),  time:63.618, tt:1908.535\n",
      "Ep:30, loss:0.00013, loss_test:0.12606, lr:8.26e-03, fs:0.59119 (r=0.475,p=0.783),  time:63.578, tt:1970.934\n",
      "Ep:31, loss:0.00012, loss_test:0.12877, lr:8.18e-03, fs:0.58228 (r=0.465,p=0.780),  time:63.645, tt:2036.649\n",
      "Ep:32, loss:0.00012, loss_test:0.12741, lr:8.10e-03, fs:0.58599 (r=0.465,p=0.793),  time:63.684, tt:2101.572\n",
      "Ep:33, loss:0.00011, loss_test:0.12946, lr:8.02e-03, fs:0.57516 (r=0.444,p=0.815),  time:63.671, tt:2164.815\n",
      "Ep:34, loss:0.00011, loss_test:0.12880, lr:7.94e-03, fs:0.59355 (r=0.465,p=0.821),  time:63.690, tt:2229.135\n",
      "Ep:35, loss:0.00010, loss_test:0.12766, lr:7.86e-03, fs:0.58599 (r=0.465,p=0.793),  time:63.745, tt:2294.830\n",
      "Ep:36, loss:0.00010, loss_test:0.13070, lr:7.78e-03, fs:0.56579 (r=0.434,p=0.811),  time:63.791, tt:2360.280\n",
      "Ep:37, loss:0.00009, loss_test:0.13154, lr:7.70e-03, fs:0.56579 (r=0.434,p=0.811),  time:63.814, tt:2424.940\n",
      "Ep:38, loss:0.00009, loss_test:0.13203, lr:7.62e-03, fs:0.56579 (r=0.434,p=0.811),  time:63.844, tt:2489.930\n",
      "Ep:39, loss:0.00009, loss_test:0.13297, lr:7.55e-03, fs:0.56954 (r=0.434,p=0.827),  time:63.863, tt:2554.525\n",
      "Ep:40, loss:0.00008, loss_test:0.13323, lr:7.47e-03, fs:0.56579 (r=0.434,p=0.811),  time:63.870, tt:2618.664\n",
      "Ep:41, loss:0.00008, loss_test:0.13312, lr:7.40e-03, fs:0.56209 (r=0.434,p=0.796),  time:63.886, tt:2683.200\n",
      "Ep:42, loss:0.00008, loss_test:0.13292, lr:7.32e-03, fs:0.56209 (r=0.434,p=0.796),  time:63.938, tt:2749.319\n",
      "Ep:43, loss:0.00007, loss_test:0.13291, lr:7.25e-03, fs:0.56579 (r=0.434,p=0.811),  time:63.976, tt:2814.958\n",
      "Ep:44, loss:0.00007, loss_test:0.13712, lr:7.18e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.053, tt:2882.382\n",
      "Ep:45, loss:0.00007, loss_test:0.13374, lr:7.11e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.031, tt:2945.414\n",
      "Ep:46, loss:0.00007, loss_test:0.13810, lr:7.03e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.036, tt:3009.676\n",
      "Ep:47, loss:0.00006, loss_test:0.13601, lr:6.96e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.050, tt:3074.415\n",
      "Ep:48, loss:0.00006, loss_test:0.13665, lr:6.89e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.095, tt:3140.638\n",
      "Ep:49, loss:0.00006, loss_test:0.13443, lr:6.83e-03, fs:0.56954 (r=0.434,p=0.827),  time:64.128, tt:3206.417\n",
      "Ep:50, loss:0.00006, loss_test:0.13539, lr:6.76e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.134, tt:3270.822\n",
      "Ep:51, loss:0.00006, loss_test:0.13678, lr:6.69e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.137, tt:3335.109\n",
      "Ep:52, loss:0.00005, loss_test:0.13579, lr:6.62e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.146, tt:3399.745\n",
      "Ep:53, loss:0.00005, loss_test:0.13731, lr:6.56e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.148, tt:3463.989\n",
      "Ep:54, loss:0.00005, loss_test:0.13467, lr:6.49e-03, fs:0.56954 (r=0.434,p=0.827),  time:64.139, tt:3527.641\n",
      "Ep:55, loss:0.00005, loss_test:0.13797, lr:6.43e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.144, tt:3592.060\n",
      "Ep:56, loss:0.00005, loss_test:0.13651, lr:6.36e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.143, tt:3656.136\n",
      "Ep:57, loss:0.00005, loss_test:0.13693, lr:6.30e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.167, tt:3721.668\n",
      "Ep:58, loss:0.00005, loss_test:0.13703, lr:6.24e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.200, tt:3787.780\n",
      "Ep:59, loss:0.00004, loss_test:0.13521, lr:6.17e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.198, tt:3851.891\n",
      "Ep:60, loss:0.00004, loss_test:0.13884, lr:6.11e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.223, tt:3917.578\n",
      "Ep:61, loss:0.00004, loss_test:0.13490, lr:6.05e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.214, tt:3981.238\n",
      "Ep:62, loss:0.00004, loss_test:0.13875, lr:5.99e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.181, tt:4043.417\n",
      "Ep:63, loss:0.00004, loss_test:0.13545, lr:5.93e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.157, tt:4106.072\n",
      "Ep:64, loss:0.00004, loss_test:0.13749, lr:5.87e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.153, tt:4169.959\n",
      "Ep:65, loss:0.00004, loss_test:0.13766, lr:5.81e-03, fs:0.57333 (r=0.434,p=0.843),  time:64.131, tt:4232.663\n",
      "Ep:66, loss:0.00004, loss_test:0.13546, lr:5.75e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.118, tt:4295.895\n",
      "Ep:67, loss:0.00004, loss_test:0.14009, lr:5.70e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.101, tt:4358.863\n",
      "Ep:68, loss:0.00004, loss_test:0.13635, lr:5.64e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.097, tt:4422.702\n",
      "Ep:69, loss:0.00004, loss_test:0.13849, lr:5.58e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.119, tt:4488.302\n",
      "Ep:70, loss:0.00004, loss_test:0.13827, lr:5.53e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.150, tt:4554.662\n",
      "Ep:71, loss:0.00003, loss_test:0.13884, lr:5.47e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.169, tt:4620.146\n",
      "Ep:72, loss:0.00003, loss_test:0.13725, lr:5.42e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.174, tt:4684.699\n",
      "Ep:73, loss:0.00003, loss_test:0.14016, lr:5.36e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.157, tt:4747.642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00003, loss_test:0.13736, lr:5.31e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.125, tt:4809.382\n",
      "Ep:75, loss:0.00003, loss_test:0.14061, lr:5.26e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.142, tt:4874.764\n",
      "Ep:76, loss:0.00003, loss_test:0.13828, lr:5.20e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.145, tt:4939.173\n",
      "Ep:77, loss:0.00003, loss_test:0.14237, lr:5.15e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.117, tt:5001.152\n",
      "Ep:78, loss:0.00003, loss_test:0.13951, lr:5.10e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.121, tt:5065.570\n",
      "Ep:79, loss:0.00003, loss_test:0.14096, lr:5.05e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.133, tt:5130.609\n",
      "Ep:80, loss:0.00003, loss_test:0.14111, lr:5.00e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.126, tt:5194.241\n",
      "Ep:81, loss:0.00003, loss_test:0.13921, lr:4.95e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.136, tt:5259.164\n",
      "Ep:82, loss:0.00003, loss_test:0.14072, lr:4.90e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.115, tt:5321.528\n",
      "Ep:83, loss:0.00003, loss_test:0.13937, lr:4.85e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.121, tt:5386.142\n",
      "Ep:84, loss:0.00003, loss_test:0.14000, lr:4.80e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.107, tt:5449.127\n",
      "Ep:85, loss:0.00003, loss_test:0.14072, lr:4.75e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.103, tt:5512.856\n",
      "Ep:86, loss:0.00003, loss_test:0.14070, lr:4.71e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.087, tt:5575.547\n",
      "Ep:87, loss:0.00003, loss_test:0.14033, lr:4.66e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.097, tt:5640.550\n",
      "Ep:88, loss:0.00003, loss_test:0.13925, lr:4.61e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.072, tt:5702.447\n",
      "Ep:89, loss:0.00003, loss_test:0.14163, lr:4.57e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.057, tt:5765.126\n",
      "Ep:90, loss:0.00003, loss_test:0.14073, lr:4.52e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.042, tt:5827.843\n",
      "Ep:91, loss:0.00002, loss_test:0.14181, lr:4.48e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.022, tt:5890.034\n",
      "Ep:92, loss:0.00002, loss_test:0.14109, lr:4.43e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.024, tt:5954.213\n",
      "Ep:93, loss:0.00002, loss_test:0.14144, lr:4.39e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.029, tt:6018.721\n",
      "Ep:94, loss:0.00002, loss_test:0.14207, lr:4.34e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.059, tt:6085.580\n",
      "Ep:95, loss:0.00002, loss_test:0.14047, lr:4.30e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.071, tt:6150.811\n",
      "Ep:96, loss:0.00002, loss_test:0.14188, lr:4.26e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.077, tt:6215.435\n",
      "Ep:97, loss:0.00002, loss_test:0.14127, lr:4.21e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.073, tt:6279.170\n",
      "Ep:98, loss:0.00002, loss_test:0.14213, lr:4.17e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.079, tt:6343.821\n",
      "Ep:99, loss:0.00002, loss_test:0.14199, lr:4.13e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.070, tt:6407.045\n",
      "Ep:100, loss:0.00002, loss_test:0.14204, lr:4.09e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.067, tt:6470.772\n",
      "Ep:101, loss:0.00002, loss_test:0.14286, lr:4.05e-03, fs:0.57718 (r=0.434,p=0.860),  time:64.073, tt:6535.435\n",
      "Ep:102, loss:0.00002, loss_test:0.14180, lr:4.01e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.068, tt:6599.018\n",
      "Ep:103, loss:0.00002, loss_test:0.14240, lr:3.97e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.068, tt:6663.044\n",
      "Ep:104, loss:0.00002, loss_test:0.14157, lr:3.93e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.073, tt:6727.616\n",
      "Ep:105, loss:0.00002, loss_test:0.14293, lr:3.89e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.078, tt:6792.295\n",
      "Ep:106, loss:0.00002, loss_test:0.14366, lr:3.85e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.102, tt:6858.930\n",
      "Ep:107, loss:0.00002, loss_test:0.14173, lr:3.81e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.087, tt:6921.350\n",
      "Ep:108, loss:0.00002, loss_test:0.14374, lr:3.77e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.091, tt:6985.902\n",
      "Ep:109, loss:0.00002, loss_test:0.14145, lr:3.73e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.110, tt:7052.074\n",
      "Ep:110, loss:0.00002, loss_test:0.14376, lr:3.70e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.103, tt:7115.429\n",
      "Ep:111, loss:0.00002, loss_test:0.14227, lr:3.66e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.118, tt:7181.184\n",
      "Ep:112, loss:0.00002, loss_test:0.14417, lr:3.62e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.109, tt:7244.340\n",
      "Ep:113, loss:0.00002, loss_test:0.14249, lr:3.59e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.131, tt:7310.895\n",
      "Ep:114, loss:0.00002, loss_test:0.14307, lr:3.55e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.130, tt:7375.006\n",
      "Ep:115, loss:0.00002, loss_test:0.14296, lr:3.52e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.148, tt:7441.190\n",
      "Ep:116, loss:0.00002, loss_test:0.14336, lr:3.48e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.174, tt:7508.401\n",
      "Ep:117, loss:0.00002, loss_test:0.14359, lr:3.45e-03, fs:0.58108 (r=0.434,p=0.878),  time:64.140, tt:7568.483\n",
      "Ep:118, loss:0.00002, loss_test:0.14391, lr:3.41e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.137, tt:7632.355\n",
      "Ep:119, loss:0.00002, loss_test:0.14497, lr:3.38e-03, fs:0.58503 (r=0.434,p=0.896),  time:64.121, tt:7694.525\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.14124, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:81.679, tt:81.679\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00081, loss_test:0.13253, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:87.361, tt:174.722\n",
      "Ep:2, loss:0.00073, loss_test:0.12014, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:90.361, tt:271.082\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00067, loss_test:0.11791, lr:1.00e-02, fs:0.69912 (r=0.798,p=0.622),  time:92.756, tt:371.024\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00062, loss_test:0.11320, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:94.349, tt:471.745\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00057, loss_test:0.10895, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:95.641, tt:573.848\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00054, loss_test:0.10621, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:96.072, tt:672.501\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00050, loss_test:0.10371, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:96.540, tt:772.319\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00048, loss_test:0.10236, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:97.248, tt:875.230\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00045, loss_test:0.10142, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:97.414, tt:974.140\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.09754, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:97.616, tt:1073.775\n",
      "Ep:11, loss:0.00040, loss_test:0.09823, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:97.568, tt:1170.822\n",
      "Ep:12, loss:0.00038, loss_test:0.09692, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:97.795, tt:1271.341\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00036, loss_test:0.09426, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:98.175, tt:1374.444\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00033, loss_test:0.09426, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:98.106, tt:1471.589\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00031, loss_test:0.09345, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:98.236, tt:1571.784\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00029, loss_test:0.09337, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:98.220, tt:1669.738\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00027, loss_test:0.09127, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:98.102, tt:1765.843\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.09065, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:98.347, tt:1868.600\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00023, loss_test:0.08918, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:98.107, tt:1962.143\n",
      "Ep:20, loss:0.00021, loss_test:0.08845, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:98.021, tt:2058.438\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.08901, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:98.050, tt:2157.104\n",
      "Ep:22, loss:0.00018, loss_test:0.08587, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:98.117, tt:2256.696\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08573, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:98.083, tt:2353.988\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.08365, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:98.169, tt:2454.221\n",
      "Ep:25, loss:0.00015, loss_test:0.08350, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:98.198, tt:2553.158\n",
      "Ep:26, loss:0.00013, loss_test:0.08013, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:98.252, tt:2652.805\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08001, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:98.315, tt:2752.807\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.08084, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:98.347, tt:2852.050\n",
      "Ep:29, loss:0.00010, loss_test:0.07902, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:98.433, tt:2952.978\n",
      "Ep:30, loss:0.00009, loss_test:0.07911, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.396, tt:3050.291\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07890, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.404, tt:3148.930\n",
      "Ep:32, loss:0.00008, loss_test:0.07972, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.358, tt:3245.813\n",
      "Ep:33, loss:0.00008, loss_test:0.08035, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.342, tt:3343.624\n",
      "Ep:34, loss:0.00007, loss_test:0.07746, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.322, tt:3441.284\n",
      "Ep:35, loss:0.00007, loss_test:0.07687, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.313, tt:3539.260\n",
      "Ep:36, loss:0.00006, loss_test:0.07766, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:98.315, tt:3637.663\n",
      "Ep:37, loss:0.00006, loss_test:0.07905, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.226, tt:3732.592\n",
      "Ep:38, loss:0.00005, loss_test:0.07807, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:98.161, tt:3828.285\n",
      "Ep:39, loss:0.00005, loss_test:0.07808, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:98.197, tt:3927.861\n",
      "Ep:40, loss:0.00005, loss_test:0.07991, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.234, tt:4027.596\n",
      "Ep:41, loss:0.00004, loss_test:0.07908, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:98.246, tt:4126.311\n",
      "Ep:42, loss:0.00004, loss_test:0.07838, lr:9.90e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.250, tt:4224.750\n",
      "Ep:43, loss:0.00004, loss_test:0.07851, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.260, tt:4323.429\n",
      "Ep:44, loss:0.00004, loss_test:0.08077, lr:9.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.350, tt:4425.765\n",
      "Ep:45, loss:0.00004, loss_test:0.07971, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.355, tt:4524.344\n",
      "Ep:46, loss:0.00003, loss_test:0.08086, lr:9.51e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.383, tt:4623.995\n",
      "Ep:47, loss:0.00003, loss_test:0.08361, lr:9.41e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.364, tt:4721.454\n",
      "Ep:48, loss:0.00003, loss_test:0.08382, lr:9.32e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.401, tt:4821.661\n",
      "Ep:49, loss:0.00003, loss_test:0.08334, lr:9.23e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.378, tt:4918.889\n",
      "Ep:50, loss:0.00003, loss_test:0.08420, lr:9.14e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.364, tt:5016.568\n",
      "Ep:51, loss:0.00003, loss_test:0.08228, lr:9.04e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.336, tt:5113.467\n",
      "Ep:52, loss:0.00002, loss_test:0.08448, lr:8.95e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.327, tt:5211.319\n",
      "Ep:53, loss:0.00002, loss_test:0.08442, lr:8.86e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.275, tt:5306.852\n",
      "Ep:54, loss:0.00002, loss_test:0.08523, lr:8.78e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.272, tt:5404.985\n",
      "Ep:55, loss:0.00002, loss_test:0.08336, lr:8.69e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.243, tt:5501.604\n",
      "Ep:56, loss:0.00002, loss_test:0.08548, lr:8.60e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.267, tt:5601.212\n",
      "Ep:57, loss:0.00002, loss_test:0.08563, lr:8.51e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.293, tt:5700.966\n",
      "Ep:58, loss:0.00002, loss_test:0.08679, lr:8.43e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.274, tt:5798.181\n",
      "Ep:59, loss:0.00002, loss_test:0.08568, lr:8.35e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.263, tt:5895.757\n",
      "Ep:60, loss:0.00002, loss_test:0.08684, lr:8.26e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.268, tt:5994.344\n",
      "Ep:61, loss:0.00002, loss_test:0.08498, lr:8.18e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.285, tt:6093.643\n",
      "Ep:62, loss:0.00002, loss_test:0.08616, lr:8.10e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.255, tt:6190.051\n",
      "Ep:63, loss:0.00002, loss_test:0.08634, lr:8.02e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.268, tt:6289.182\n",
      "Ep:64, loss:0.00001, loss_test:0.08757, lr:7.94e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.263, tt:6387.108\n",
      "Ep:65, loss:0.00001, loss_test:0.08623, lr:7.86e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.256, tt:6484.903\n",
      "Ep:66, loss:0.00001, loss_test:0.08820, lr:7.78e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.212, tt:6580.202\n",
      "Ep:67, loss:0.00001, loss_test:0.08753, lr:7.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.241, tt:6680.366\n",
      "Ep:68, loss:0.00001, loss_test:0.08733, lr:7.62e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.262, tt:6780.097\n",
      "Ep:69, loss:0.00001, loss_test:0.08838, lr:7.55e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.283, tt:6879.842\n",
      "Ep:70, loss:0.00001, loss_test:0.08732, lr:7.47e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.247, tt:6975.557\n",
      "Ep:71, loss:0.00001, loss_test:0.08790, lr:7.40e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.209, tt:7071.072\n",
      "Ep:72, loss:0.00001, loss_test:0.08842, lr:7.32e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.197, tt:7168.347\n",
      "Ep:73, loss:0.00001, loss_test:0.08808, lr:7.25e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.206, tt:7267.229\n",
      "Ep:74, loss:0.00001, loss_test:0.08693, lr:7.18e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.201, tt:7365.054\n",
      "Ep:75, loss:0.00001, loss_test:0.08853, lr:7.11e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.204, tt:7463.534\n",
      "Ep:76, loss:0.00001, loss_test:0.08948, lr:7.03e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.180, tt:7559.883\n",
      "Ep:77, loss:0.00001, loss_test:0.08753, lr:6.96e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.187, tt:7658.602\n",
      "Ep:78, loss:0.00001, loss_test:0.08814, lr:6.89e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.188, tt:7756.818\n",
      "Ep:79, loss:0.00001, loss_test:0.08819, lr:6.83e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.168, tt:7853.470\n",
      "Ep:80, loss:0.00001, loss_test:0.08868, lr:6.76e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.176, tt:7952.250\n",
      "Ep:81, loss:0.00001, loss_test:0.08817, lr:6.69e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.142, tt:8047.626\n",
      "Ep:82, loss:0.00001, loss_test:0.08811, lr:6.62e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.135, tt:8145.189\n",
      "Ep:83, loss:0.00001, loss_test:0.08830, lr:6.56e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.125, tt:8242.472\n",
      "Ep:84, loss:0.00001, loss_test:0.08839, lr:6.49e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.131, tt:8341.127\n",
      "Ep:85, loss:0.00001, loss_test:0.08830, lr:6.43e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.164, tt:8442.127\n",
      "Ep:86, loss:0.00001, loss_test:0.08860, lr:6.36e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.186, tt:8542.162\n",
      "Ep:87, loss:0.00001, loss_test:0.08875, lr:6.30e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.194, tt:8641.071\n",
      "Ep:88, loss:0.00001, loss_test:0.08743, lr:6.24e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.154, tt:8735.743\n",
      "Ep:89, loss:0.00001, loss_test:0.08833, lr:6.17e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.146, tt:8833.118\n",
      "Ep:90, loss:0.00001, loss_test:0.08847, lr:6.11e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.144, tt:8931.113\n",
      "Ep:91, loss:0.00001, loss_test:0.08822, lr:6.05e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.136, tt:9028.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:92, loss:0.00001, loss_test:0.08863, lr:5.99e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.138, tt:9126.831\n",
      "Ep:93, loss:0.00001, loss_test:0.08813, lr:5.93e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.141, tt:9225.294\n",
      "Ep:94, loss:0.00001, loss_test:0.08864, lr:5.87e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.150, tt:9324.281\n",
      "Ep:95, loss:0.00001, loss_test:0.08912, lr:5.81e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.174, tt:9424.740\n",
      "Ep:96, loss:0.00001, loss_test:0.08847, lr:5.75e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.182, tt:9523.615\n",
      "Ep:97, loss:0.00001, loss_test:0.08861, lr:5.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.132, tt:9616.968\n",
      "Ep:98, loss:0.00001, loss_test:0.08870, lr:5.64e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.134, tt:9715.255\n",
      "Ep:99, loss:0.00001, loss_test:0.08819, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:98.100, tt:9809.994\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.14285, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:83.170, tt:83.170\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00082, loss_test:0.13570, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:89.934, tt:179.868\n",
      "Ep:2, loss:0.00074, loss_test:0.12178, lr:1.00e-02, fs:0.65049 (r=0.677,p=0.626),  time:92.933, tt:278.799\n",
      "Ep:3, loss:0.00066, loss_test:0.11944, lr:1.00e-02, fs:0.65385 (r=0.687,p=0.624),  time:94.461, tt:377.843\n",
      "Ep:4, loss:0.00061, loss_test:0.11477, lr:1.00e-02, fs:0.66000 (r=0.667,p=0.653),  time:94.635, tt:473.175\n",
      "Ep:5, loss:0.00057, loss_test:0.10919, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:95.442, tt:572.649\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00053, loss_test:0.10711, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:95.818, tt:670.727\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00050, loss_test:0.10177, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:96.114, tt:768.913\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00047, loss_test:0.09919, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:96.250, tt:866.252\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.09800, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:96.772, tt:967.722\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.09662, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:96.753, tt:1064.280\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.09414, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:96.735, tt:1160.818\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00037, loss_test:0.09153, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:97.024, tt:1261.311\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00035, loss_test:0.09061, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:97.022, tt:1358.308\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00032, loss_test:0.09098, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:97.196, tt:1457.941\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.09087, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:97.378, tt:1558.043\n",
      "Ep:16, loss:0.00028, loss_test:0.08684, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:97.533, tt:1658.054\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.09052, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:97.596, tt:1756.732\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.08919, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:97.458, tt:1851.704\n",
      "Ep:19, loss:0.00021, loss_test:0.08852, lr:1.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:97.559, tt:1951.175\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.08628, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:97.617, tt:2049.950\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.08560, lr:1.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:97.632, tt:2147.915\n",
      "Ep:22, loss:0.00016, loss_test:0.08611, lr:1.00e-02, fs:0.83041 (r=0.717,p=0.986),  time:97.757, tt:2248.407\n",
      "Ep:23, loss:0.00015, loss_test:0.08747, lr:1.00e-02, fs:0.82353 (r=0.707,p=0.986),  time:97.794, tt:2347.055\n",
      "Ep:24, loss:0.00014, loss_test:0.08678, lr:1.00e-02, fs:0.82353 (r=0.707,p=0.986),  time:97.800, tt:2445.002\n",
      "Ep:25, loss:0.00013, loss_test:0.08802, lr:1.00e-02, fs:0.82840 (r=0.707,p=1.000),  time:97.783, tt:2542.348\n",
      "Ep:26, loss:0.00012, loss_test:0.08896, lr:1.00e-02, fs:0.82840 (r=0.707,p=1.000),  time:97.750, tt:2639.259\n",
      "Ep:27, loss:0.00011, loss_test:0.08803, lr:1.00e-02, fs:0.83041 (r=0.717,p=0.986),  time:97.787, tt:2738.038\n",
      "Ep:28, loss:0.00011, loss_test:0.08626, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:97.729, tt:2834.141\n",
      "Ep:29, loss:0.00010, loss_test:0.08710, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:97.744, tt:2932.312\n",
      "Ep:30, loss:0.00009, loss_test:0.08694, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:97.731, tt:3029.666\n",
      "Ep:31, loss:0.00008, loss_test:0.08772, lr:1.00e-02, fs:0.83529 (r=0.717,p=1.000),  time:97.747, tt:3127.893\n",
      "Ep:32, loss:0.00008, loss_test:0.08798, lr:9.90e-03, fs:0.83529 (r=0.717,p=1.000),  time:97.795, tt:3227.228\n",
      "Ep:33, loss:0.00007, loss_test:0.08711, lr:9.80e-03, fs:0.83529 (r=0.717,p=1.000),  time:97.744, tt:3323.313\n",
      "Ep:34, loss:0.00007, loss_test:0.09031, lr:9.70e-03, fs:0.83529 (r=0.717,p=1.000),  time:97.790, tt:3422.654\n",
      "Ep:35, loss:0.00006, loss_test:0.09171, lr:9.61e-03, fs:0.82143 (r=0.697,p=1.000),  time:97.784, tt:3520.237\n",
      "Ep:36, loss:0.00006, loss_test:0.09127, lr:9.51e-03, fs:0.83529 (r=0.717,p=1.000),  time:97.707, tt:3615.168\n",
      "Ep:37, loss:0.00006, loss_test:0.09118, lr:9.41e-03, fs:0.83529 (r=0.717,p=1.000),  time:97.799, tt:3716.344\n",
      "Ep:38, loss:0.00005, loss_test:0.09274, lr:9.32e-03, fs:0.83529 (r=0.717,p=1.000),  time:97.873, tt:3817.063\n",
      "Ep:39, loss:0.00005, loss_test:0.09160, lr:9.23e-03, fs:0.82143 (r=0.697,p=1.000),  time:97.957, tt:3918.286\n",
      "Ep:40, loss:0.00005, loss_test:0.09106, lr:9.14e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.006, tt:4018.245\n",
      "Ep:41, loss:0.00005, loss_test:0.09402, lr:9.04e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.943, tt:4113.616\n",
      "Ep:42, loss:0.00004, loss_test:0.09319, lr:8.95e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.937, tt:4211.271\n",
      "Ep:43, loss:0.00004, loss_test:0.09392, lr:8.86e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.941, tt:4309.407\n",
      "Ep:44, loss:0.00004, loss_test:0.09592, lr:8.78e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.981, tt:4409.146\n",
      "Ep:45, loss:0.00004, loss_test:0.09356, lr:8.69e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.985, tt:4507.330\n",
      "Ep:46, loss:0.00004, loss_test:0.09541, lr:8.60e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.069, tt:4609.254\n",
      "Ep:47, loss:0.00003, loss_test:0.09718, lr:8.51e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.048, tt:4706.319\n",
      "Ep:48, loss:0.00003, loss_test:0.09735, lr:8.43e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.060, tt:4804.938\n",
      "Ep:49, loss:0.00003, loss_test:0.09879, lr:8.35e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.094, tt:4904.702\n",
      "Ep:50, loss:0.00003, loss_test:0.10149, lr:8.26e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.130, tt:5004.637\n",
      "Ep:51, loss:0.00003, loss_test:0.10059, lr:8.18e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.136, tt:5103.076\n",
      "Ep:52, loss:0.00003, loss_test:0.09953, lr:8.10e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.146, tt:5201.728\n",
      "Ep:53, loss:0.00003, loss_test:0.10113, lr:8.02e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.111, tt:5298.020\n",
      "Ep:54, loss:0.00002, loss_test:0.10085, lr:7.94e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.087, tt:5394.812\n",
      "Ep:55, loss:0.00002, loss_test:0.10248, lr:7.86e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.065, tt:5491.628\n",
      "Ep:56, loss:0.00002, loss_test:0.09971, lr:7.78e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.085, tt:5590.823\n",
      "Ep:57, loss:0.00002, loss_test:0.10181, lr:7.70e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.079, tt:5688.598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00002, loss_test:0.10107, lr:7.62e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.077, tt:5786.542\n",
      "Ep:59, loss:0.00002, loss_test:0.10176, lr:7.55e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.085, tt:5885.113\n",
      "Ep:60, loss:0.00002, loss_test:0.10278, lr:7.47e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.101, tt:5984.159\n",
      "Ep:61, loss:0.00002, loss_test:0.10314, lr:7.40e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.097, tt:6082.026\n",
      "Ep:62, loss:0.00002, loss_test:0.10080, lr:7.32e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.108, tt:6180.777\n",
      "Ep:63, loss:0.00002, loss_test:0.10053, lr:7.25e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.136, tt:6280.728\n",
      "Ep:64, loss:0.00002, loss_test:0.10185, lr:7.18e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.137, tt:6378.895\n",
      "Ep:65, loss:0.00002, loss_test:0.10237, lr:7.11e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.106, tt:6475.027\n",
      "Ep:66, loss:0.00002, loss_test:0.10177, lr:7.03e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.110, tt:6573.394\n",
      "Ep:67, loss:0.00002, loss_test:0.10091, lr:6.96e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.090, tt:6670.125\n",
      "Ep:68, loss:0.00002, loss_test:0.10204, lr:6.89e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.095, tt:6768.560\n",
      "Ep:69, loss:0.00001, loss_test:0.10195, lr:6.83e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.104, tt:6867.296\n",
      "Ep:70, loss:0.00001, loss_test:0.10220, lr:6.76e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.091, tt:6964.475\n",
      "Ep:71, loss:0.00001, loss_test:0.10121, lr:6.69e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.060, tt:7060.350\n",
      "Ep:72, loss:0.00001, loss_test:0.10180, lr:6.62e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.038, tt:7156.770\n",
      "Ep:73, loss:0.00001, loss_test:0.10265, lr:6.56e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.016, tt:7253.211\n",
      "Ep:74, loss:0.00001, loss_test:0.10120, lr:6.49e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.028, tt:7352.131\n",
      "Ep:75, loss:0.00001, loss_test:0.10252, lr:6.43e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.023, tt:7449.741\n",
      "Ep:76, loss:0.00001, loss_test:0.10202, lr:6.36e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.033, tt:7548.541\n",
      "Ep:77, loss:0.00001, loss_test:0.10222, lr:6.30e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.056, tt:7648.337\n",
      "Ep:78, loss:0.00001, loss_test:0.10227, lr:6.24e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.038, tt:7744.989\n",
      "Ep:79, loss:0.00001, loss_test:0.10172, lr:6.17e-03, fs:0.77778 (r=0.636,p=1.000),  time:98.020, tt:7841.583\n",
      "Ep:80, loss:0.00001, loss_test:0.10257, lr:6.11e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.976, tt:7936.091\n",
      "Ep:81, loss:0.00001, loss_test:0.10287, lr:6.05e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.973, tt:8033.746\n",
      "Ep:82, loss:0.00001, loss_test:0.10260, lr:5.99e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.986, tt:8132.810\n",
      "Ep:83, loss:0.00001, loss_test:0.10258, lr:5.93e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.958, tt:8228.457\n",
      "Ep:84, loss:0.00001, loss_test:0.10154, lr:5.87e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.937, tt:8324.681\n",
      "Ep:85, loss:0.00001, loss_test:0.10286, lr:5.81e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.908, tt:8420.088\n",
      "Ep:86, loss:0.00001, loss_test:0.10142, lr:5.75e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.908, tt:8518.028\n",
      "Ep:87, loss:0.00001, loss_test:0.10178, lr:5.70e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.906, tt:8615.734\n",
      "Ep:88, loss:0.00001, loss_test:0.10204, lr:5.64e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.906, tt:8713.670\n",
      "Ep:89, loss:0.00001, loss_test:0.10257, lr:5.58e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.905, tt:8811.432\n",
      "Ep:90, loss:0.00001, loss_test:0.10182, lr:5.53e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.911, tt:8909.928\n",
      "Ep:91, loss:0.00001, loss_test:0.10241, lr:5.47e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.907, tt:9007.470\n",
      "Ep:92, loss:0.00001, loss_test:0.10283, lr:5.42e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.910, tt:9105.642\n",
      "Ep:93, loss:0.00001, loss_test:0.10219, lr:5.36e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.897, tt:9202.293\n",
      "Ep:94, loss:0.00001, loss_test:0.10239, lr:5.31e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.904, tt:9300.924\n",
      "Ep:95, loss:0.00001, loss_test:0.10167, lr:5.26e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.883, tt:9396.811\n",
      "Ep:96, loss:0.00001, loss_test:0.10102, lr:5.20e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.881, tt:9494.476\n",
      "Ep:97, loss:0.00001, loss_test:0.10212, lr:5.15e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.852, tt:9589.456\n",
      "Ep:98, loss:0.00001, loss_test:0.10270, lr:5.10e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.851, tt:9687.219\n",
      "Ep:99, loss:0.00001, loss_test:0.10164, lr:5.05e-03, fs:0.77778 (r=0.636,p=1.000),  time:97.886, tt:9788.573\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.14473, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:100.610, tt:100.610\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00088, loss_test:0.13084, lr:1.00e-02, fs:0.60748 (r=0.657,p=0.565),  time:106.459, tt:212.917\n",
      "Ep:2, loss:0.00078, loss_test:0.12264, lr:1.00e-02, fs:0.62500 (r=0.707,p=0.560),  time:110.269, tt:330.808\n",
      "Ep:3, loss:0.00071, loss_test:0.11457, lr:1.00e-02, fs:0.64948 (r=0.636,p=0.663),  time:112.321, tt:449.284\n",
      "Ep:4, loss:0.00065, loss_test:0.10846, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:112.647, tt:563.235\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00059, loss_test:0.10326, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:113.122, tt:678.733\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00055, loss_test:0.10006, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:113.552, tt:794.863\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00051, loss_test:0.09872, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:113.462, tt:907.697\n",
      "Ep:8, loss:0.00047, loss_test:0.09520, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:113.358, tt:1020.224\n",
      "Ep:9, loss:0.00043, loss_test:0.09436, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:113.555, tt:1135.551\n",
      "Ep:10, loss:0.00040, loss_test:0.09326, lr:1.00e-02, fs:0.70391 (r=0.636,p=0.787),  time:113.669, tt:1250.356\n",
      "Ep:11, loss:0.00036, loss_test:0.09141, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:113.836, tt:1366.028\n",
      "Ep:12, loss:0.00033, loss_test:0.09240, lr:1.00e-02, fs:0.70115 (r=0.616,p=0.813),  time:113.890, tt:1480.564\n",
      "Ep:13, loss:0.00030, loss_test:0.09057, lr:1.00e-02, fs:0.72414 (r=0.636,p=0.840),  time:114.090, tt:1597.267\n",
      "Ep:14, loss:0.00028, loss_test:0.09003, lr:1.00e-02, fs:0.73143 (r=0.646,p=0.842),  time:114.028, tt:1710.422\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.08994, lr:1.00e-02, fs:0.72000 (r=0.636,p=0.829),  time:114.038, tt:1824.612\n",
      "Ep:16, loss:0.00023, loss_test:0.08687, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:114.082, tt:1939.388\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.08951, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:114.227, tt:2056.089\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.09488, lr:1.00e-02, fs:0.74556 (r=0.636,p=0.900),  time:114.131, tt:2168.495\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.08976, lr:1.00e-02, fs:0.74419 (r=0.646,p=0.877),  time:114.371, tt:2287.412\n",
      "Ep:20, loss:0.00017, loss_test:0.09219, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:114.404, tt:2402.491\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08828, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:114.558, tt:2520.285\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.09146, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:114.547, tt:2634.591\n",
      "Ep:23, loss:0.00013, loss_test:0.08984, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:114.496, tt:2747.901\n",
      "Ep:24, loss:0.00012, loss_test:0.09226, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:114.517, tt:2862.916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00011, loss_test:0.09461, lr:1.00e-02, fs:0.71166 (r=0.586,p=0.906),  time:114.516, tt:2977.411\n",
      "Ep:26, loss:0.00010, loss_test:0.08929, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:114.565, tt:3093.254\n",
      "Ep:27, loss:0.00010, loss_test:0.09295, lr:1.00e-02, fs:0.68750 (r=0.556,p=0.902),  time:114.590, tt:3208.510\n",
      "Ep:28, loss:0.00009, loss_test:0.09255, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:114.580, tt:3322.820\n",
      "Ep:29, loss:0.00008, loss_test:0.09292, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:114.555, tt:3436.651\n",
      "Ep:30, loss:0.00008, loss_test:0.09935, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:114.491, tt:3549.226\n",
      "Ep:31, loss:0.00007, loss_test:0.09350, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:114.538, tt:3665.221\n",
      "Ep:32, loss:0.00007, loss_test:0.09751, lr:1.00e-02, fs:0.70513 (r=0.556,p=0.965),  time:114.602, tt:3781.864\n",
      "Ep:33, loss:0.00007, loss_test:0.09503, lr:9.90e-03, fs:0.74847 (r=0.616,p=0.953),  time:114.640, tt:3897.748\n",
      "Ep:34, loss:0.00006, loss_test:0.09469, lr:9.80e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.760, tt:4016.595\n",
      "Ep:35, loss:0.00006, loss_test:0.09294, lr:9.70e-03, fs:0.75449 (r=0.636,p=0.926),  time:114.777, tt:4131.969\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00005, loss_test:0.09634, lr:9.70e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.760, tt:4246.123\n",
      "Ep:37, loss:0.00005, loss_test:0.09904, lr:9.70e-03, fs:0.71338 (r=0.566,p=0.966),  time:114.778, tt:4361.558\n",
      "Ep:38, loss:0.00005, loss_test:0.09947, lr:9.70e-03, fs:0.68387 (r=0.535,p=0.946),  time:114.786, tt:4476.658\n",
      "Ep:39, loss:0.00005, loss_test:0.10201, lr:9.70e-03, fs:0.65789 (r=0.505,p=0.943),  time:114.761, tt:4590.449\n",
      "Ep:40, loss:0.00004, loss_test:0.10310, lr:9.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.728, tt:4703.840\n",
      "Ep:41, loss:0.00004, loss_test:0.09905, lr:9.70e-03, fs:0.67105 (r=0.515,p=0.962),  time:114.699, tt:4817.351\n",
      "Ep:42, loss:0.00004, loss_test:0.09864, lr:9.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.650, tt:4929.959\n",
      "Ep:43, loss:0.00004, loss_test:0.10603, lr:9.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.692, tt:5046.438\n",
      "Ep:44, loss:0.00003, loss_test:0.10465, lr:9.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.665, tt:5159.926\n",
      "Ep:45, loss:0.00003, loss_test:0.10321, lr:9.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.598, tt:5271.529\n",
      "Ep:46, loss:0.00003, loss_test:0.10151, lr:9.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.560, tt:5384.297\n",
      "Ep:47, loss:0.00003, loss_test:0.10355, lr:9.61e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.633, tt:5502.389\n",
      "Ep:48, loss:0.00003, loss_test:0.10442, lr:9.51e-03, fs:0.66225 (r=0.505,p=0.962),  time:114.614, tt:5616.101\n",
      "Ep:49, loss:0.00003, loss_test:0.10822, lr:9.41e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.567, tt:5728.350\n",
      "Ep:50, loss:0.00003, loss_test:0.10700, lr:9.32e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.559, tt:5842.497\n",
      "Ep:51, loss:0.00003, loss_test:0.10684, lr:9.23e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.600, tt:5959.205\n",
      "Ep:52, loss:0.00002, loss_test:0.10460, lr:9.14e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.572, tt:6072.326\n",
      "Ep:53, loss:0.00002, loss_test:0.10574, lr:9.04e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.524, tt:6184.313\n",
      "Ep:54, loss:0.00002, loss_test:0.10372, lr:8.95e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.551, tt:6300.300\n",
      "Ep:55, loss:0.00002, loss_test:0.10418, lr:8.86e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.513, tt:6412.736\n",
      "Ep:56, loss:0.00002, loss_test:0.10675, lr:8.78e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.514, tt:6527.272\n",
      "Ep:57, loss:0.00002, loss_test:0.10638, lr:8.69e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.514, tt:6641.828\n",
      "Ep:58, loss:0.00002, loss_test:0.10766, lr:8.60e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.498, tt:6755.360\n",
      "Ep:59, loss:0.00002, loss_test:0.10845, lr:8.51e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.482, tt:6868.907\n",
      "Ep:60, loss:0.00002, loss_test:0.10741, lr:8.43e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.471, tt:6982.710\n",
      "Ep:61, loss:0.00002, loss_test:0.10783, lr:8.35e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.477, tt:7097.562\n",
      "Ep:62, loss:0.00002, loss_test:0.10786, lr:8.26e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.507, tt:7213.952\n",
      "Ep:63, loss:0.00002, loss_test:0.11056, lr:8.18e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.528, tt:7329.796\n",
      "Ep:64, loss:0.00002, loss_test:0.10901, lr:8.10e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.524, tt:7444.092\n",
      "Ep:65, loss:0.00001, loss_test:0.10789, lr:8.02e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.513, tt:7557.878\n",
      "Ep:66, loss:0.00001, loss_test:0.10902, lr:7.94e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.519, tt:7672.781\n",
      "Ep:67, loss:0.00001, loss_test:0.11014, lr:7.86e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.530, tt:7788.020\n",
      "Ep:68, loss:0.00001, loss_test:0.10865, lr:7.78e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.529, tt:7902.492\n",
      "Ep:69, loss:0.00001, loss_test:0.11268, lr:7.70e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.528, tt:8016.971\n",
      "Ep:70, loss:0.00001, loss_test:0.11305, lr:7.62e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.526, tt:8131.363\n",
      "Ep:71, loss:0.00001, loss_test:0.10990, lr:7.55e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.533, tt:8246.389\n",
      "Ep:72, loss:0.00001, loss_test:0.11334, lr:7.47e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.574, tt:8363.884\n",
      "Ep:73, loss:0.00001, loss_test:0.11075, lr:7.40e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.581, tt:8479.016\n",
      "Ep:74, loss:0.00001, loss_test:0.11058, lr:7.32e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.560, tt:8592.027\n",
      "Ep:75, loss:0.00001, loss_test:0.11160, lr:7.25e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.537, tt:8704.807\n",
      "Ep:76, loss:0.00001, loss_test:0.11043, lr:7.18e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.544, tt:8819.878\n",
      "Ep:77, loss:0.00001, loss_test:0.10956, lr:7.11e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.558, tt:8935.533\n",
      "Ep:78, loss:0.00001, loss_test:0.11022, lr:7.03e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.553, tt:9049.676\n",
      "Ep:79, loss:0.00001, loss_test:0.10995, lr:6.96e-03, fs:0.66667 (r=0.505,p=0.980),  time:114.550, tt:9163.999\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.13406, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:94.395, tt:94.395\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00090, loss_test:0.10598, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:101.136, tt:202.273\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00080, loss_test:0.09701, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:107.132, tt:321.395\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00073, loss_test:0.08927, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:109.805, tt:439.221\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00067, loss_test:0.08305, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:110.637, tt:553.187\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00061, loss_test:0.07956, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:110.998, tt:665.989\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00057, loss_test:0.07623, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:111.715, tt:782.004\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00053, loss_test:0.07276, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:112.234, tt:897.872\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00049, loss_test:0.07014, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:112.260, tt:1010.342\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00046, loss_test:0.06747, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:112.482, tt:1124.823\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00043, loss_test:0.06648, lr:1.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:112.889, tt:1241.777\n",
      "Ep:11, loss:0.00039, loss_test:0.06331, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:112.979, tt:1355.745\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00036, loss_test:0.06032, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:113.080, tt:1470.046\n",
      "Ep:13, loss:0.00033, loss_test:0.05892, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:113.264, tt:1585.693\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.05743, lr:1.00e-02, fs:0.95050 (r=0.970,p=0.932),  time:113.503, tt:1702.538\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.05620, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:113.809, tt:1820.940\n",
      "Ep:16, loss:0.00025, loss_test:0.05513, lr:1.00e-02, fs:0.96000 (r=0.970,p=0.950),  time:113.776, tt:1934.187\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.05502, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.851, tt:2049.316\n",
      "Ep:18, loss:0.00021, loss_test:0.05340, lr:1.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:113.852, tt:2163.179\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.05256, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:113.996, tt:2279.912\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.05229, lr:1.00e-02, fs:0.97000 (r=0.980,p=0.960),  time:114.090, tt:2395.881\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.05380, lr:1.00e-02, fs:0.91489 (r=0.869,p=0.966),  time:113.994, tt:2507.867\n",
      "Ep:22, loss:0.00014, loss_test:0.05205, lr:1.00e-02, fs:0.95385 (r=0.939,p=0.969),  time:114.086, tt:2623.979\n",
      "Ep:23, loss:0.00013, loss_test:0.05327, lr:1.00e-02, fs:0.93684 (r=0.899,p=0.978),  time:114.067, tt:2737.602\n",
      "Ep:24, loss:0.00012, loss_test:0.05436, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:114.013, tt:2850.329\n",
      "Ep:25, loss:0.00011, loss_test:0.05304, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:113.930, tt:2962.184\n",
      "Ep:26, loss:0.00011, loss_test:0.05030, lr:1.00e-02, fs:0.93750 (r=0.909,p=0.968),  time:113.923, tt:3075.908\n",
      "Ep:27, loss:0.00010, loss_test:0.05438, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:113.981, tt:3191.474\n",
      "Ep:28, loss:0.00009, loss_test:0.05670, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:113.923, tt:3303.758\n",
      "Ep:29, loss:0.00009, loss_test:0.05004, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:113.885, tt:3416.547\n",
      "Ep:30, loss:0.00008, loss_test:0.05358, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:113.917, tt:3531.435\n",
      "Ep:31, loss:0.00008, loss_test:0.05440, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:113.982, tt:3647.423\n",
      "Ep:32, loss:0.00007, loss_test:0.05465, lr:9.90e-03, fs:0.88889 (r=0.808,p=0.988),  time:114.046, tt:3763.518\n",
      "Ep:33, loss:0.00007, loss_test:0.05577, lr:9.80e-03, fs:0.87640 (r=0.788,p=0.987),  time:114.063, tt:3878.148\n",
      "Ep:34, loss:0.00006, loss_test:0.05432, lr:9.70e-03, fs:0.90710 (r=0.838,p=0.988),  time:114.120, tt:3994.203\n",
      "Ep:35, loss:0.00006, loss_test:0.05517, lr:9.61e-03, fs:0.87500 (r=0.778,p=1.000),  time:114.136, tt:4108.910\n",
      "Ep:36, loss:0.00005, loss_test:0.05700, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.135, tt:4222.977\n",
      "Ep:37, loss:0.00005, loss_test:0.05624, lr:9.41e-03, fs:0.88136 (r=0.788,p=1.000),  time:114.148, tt:4337.608\n",
      "Ep:38, loss:0.00005, loss_test:0.05567, lr:9.32e-03, fs:0.88764 (r=0.798,p=1.000),  time:114.080, tt:4449.131\n",
      "Ep:39, loss:0.00004, loss_test:0.05592, lr:9.23e-03, fs:0.89385 (r=0.808,p=1.000),  time:114.165, tt:4566.586\n",
      "Ep:40, loss:0.00004, loss_test:0.05648, lr:9.14e-03, fs:0.88136 (r=0.788,p=1.000),  time:114.204, tt:4682.381\n",
      "Ep:41, loss:0.00004, loss_test:0.05728, lr:9.04e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.250, tt:4798.497\n",
      "Ep:42, loss:0.00004, loss_test:0.05849, lr:8.95e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.323, tt:4915.892\n",
      "Ep:43, loss:0.00004, loss_test:0.05923, lr:8.86e-03, fs:0.86207 (r=0.758,p=1.000),  time:114.378, tt:5032.631\n",
      "Ep:44, loss:0.00003, loss_test:0.05755, lr:8.78e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.429, tt:5149.298\n",
      "Ep:45, loss:0.00003, loss_test:0.05792, lr:8.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.430, tt:5263.789\n",
      "Ep:46, loss:0.00003, loss_test:0.05892, lr:8.60e-03, fs:0.83529 (r=0.717,p=1.000),  time:114.464, tt:5379.820\n",
      "Ep:47, loss:0.00003, loss_test:0.05878, lr:8.51e-03, fs:0.84884 (r=0.737,p=1.000),  time:114.495, tt:5495.779\n",
      "Ep:48, loss:0.00003, loss_test:0.05716, lr:8.43e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.526, tt:5611.767\n",
      "Ep:49, loss:0.00003, loss_test:0.05948, lr:8.35e-03, fs:0.80723 (r=0.677,p=1.000),  time:114.531, tt:5726.550\n",
      "Ep:50, loss:0.00003, loss_test:0.05712, lr:8.26e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.609, tt:5845.051\n",
      "Ep:51, loss:0.00002, loss_test:0.06012, lr:8.18e-03, fs:0.80723 (r=0.677,p=1.000),  time:114.594, tt:5958.906\n",
      "Ep:52, loss:0.00002, loss_test:0.05750, lr:8.10e-03, fs:0.80723 (r=0.677,p=1.000),  time:114.523, tt:6069.722\n",
      "Ep:53, loss:0.00002, loss_test:0.05941, lr:8.02e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.520, tt:6184.090\n",
      "Ep:54, loss:0.00002, loss_test:0.05968, lr:7.94e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.541, tt:6299.760\n",
      "Ep:55, loss:0.00002, loss_test:0.05993, lr:7.86e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.586, tt:6416.837\n",
      "Ep:56, loss:0.00002, loss_test:0.05903, lr:7.78e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.540, tt:6528.753\n",
      "Ep:57, loss:0.00002, loss_test:0.05980, lr:7.70e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.541, tt:6643.376\n",
      "Ep:58, loss:0.00002, loss_test:0.06029, lr:7.62e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.506, tt:6755.849\n",
      "Ep:59, loss:0.00002, loss_test:0.05941, lr:7.55e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.459, tt:6867.523\n",
      "Ep:60, loss:0.00002, loss_test:0.05948, lr:7.47e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.432, tt:6980.339\n",
      "Ep:61, loss:0.00002, loss_test:0.06054, lr:7.40e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.389, tt:7092.105\n",
      "Ep:62, loss:0.00002, loss_test:0.06021, lr:7.32e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.345, tt:7203.741\n",
      "Ep:63, loss:0.00002, loss_test:0.06124, lr:7.25e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.361, tt:7319.132\n",
      "Ep:64, loss:0.00001, loss_test:0.05991, lr:7.18e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.347, tt:7432.583\n",
      "Ep:65, loss:0.00001, loss_test:0.06106, lr:7.11e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.334, tt:7546.049\n",
      "Ep:66, loss:0.00001, loss_test:0.05993, lr:7.03e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.381, tt:7663.540\n",
      "Ep:67, loss:0.00001, loss_test:0.06010, lr:6.96e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.409, tt:7779.837\n",
      "Ep:68, loss:0.00001, loss_test:0.06052, lr:6.89e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.398, tt:7893.485\n",
      "Ep:69, loss:0.00001, loss_test:0.06028, lr:6.83e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.394, tt:8007.585\n",
      "Ep:70, loss:0.00001, loss_test:0.06060, lr:6.76e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.382, tt:8121.152\n",
      "Ep:71, loss:0.00001, loss_test:0.06024, lr:6.69e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.390, tt:8236.056\n",
      "Ep:72, loss:0.00001, loss_test:0.06129, lr:6.62e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.417, tt:8352.444\n",
      "Ep:73, loss:0.00001, loss_test:0.06101, lr:6.56e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.418, tt:8466.927\n",
      "Ep:74, loss:0.00001, loss_test:0.06086, lr:6.49e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.465, tt:8584.911\n",
      "Ep:75, loss:0.00001, loss_test:0.06111, lr:6.43e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.506, tt:8702.479\n",
      "Ep:76, loss:0.00001, loss_test:0.06164, lr:6.36e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.536, tt:8819.266\n",
      "Ep:77, loss:0.00001, loss_test:0.06074, lr:6.30e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.571, tt:8936.571\n",
      "Ep:78, loss:0.00001, loss_test:0.06198, lr:6.24e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.603, tt:9053.675\n",
      "Ep:79, loss:0.00001, loss_test:0.06209, lr:6.17e-03, fs:0.80000 (r=0.667,p=1.000),  time:114.560, tt:9164.806\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00120, loss_test:0.13759, lr:1.00e-02, fs:0.61176 (r=0.788,p=0.500),  time:129.148, tt:129.148\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00101, loss_test:0.13314, lr:1.00e-02, fs:0.55769 (r=0.586,p=0.532),  time:138.209, tt:276.419\n",
      "Ep:2, loss:0.00090, loss_test:0.12699, lr:1.00e-02, fs:0.60606 (r=0.606,p=0.606),  time:142.018, tt:426.054\n",
      "Ep:3, loss:0.00081, loss_test:0.11925, lr:1.00e-02, fs:0.62827 (r=0.606,p=0.652),  time:144.281, tt:577.125\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00074, loss_test:0.11190, lr:1.00e-02, fs:0.62366 (r=0.586,p=0.667),  time:145.693, tt:728.463\n",
      "Ep:5, loss:0.00067, loss_test:0.11132, lr:1.00e-02, fs:0.65922 (r=0.596,p=0.738),  time:146.527, tt:879.159\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00061, loss_test:0.10791, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:146.369, tt:1024.585\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00056, loss_test:0.11045, lr:1.00e-02, fs:0.68182 (r=0.606,p=0.779),  time:146.664, tt:1173.311\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00051, loss_test:0.10993, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:147.134, tt:1324.205\n",
      "Ep:9, loss:0.00045, loss_test:0.10835, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:147.194, tt:1471.940\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00041, loss_test:0.11239, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:147.558, tt:1623.134\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00036, loss_test:0.11419, lr:1.00e-02, fs:0.70238 (r=0.596,p=0.855),  time:147.743, tt:1772.920\n",
      "Ep:12, loss:0.00033, loss_test:0.11024, lr:1.00e-02, fs:0.70175 (r=0.606,p=0.833),  time:147.744, tt:1920.676\n",
      "Ep:13, loss:0.00029, loss_test:0.11483, lr:1.00e-02, fs:0.69461 (r=0.586,p=0.853),  time:148.017, tt:2072.243\n",
      "Ep:14, loss:0.00026, loss_test:0.11641, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:148.132, tt:2221.978\n",
      "Ep:15, loss:0.00023, loss_test:0.11305, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:148.295, tt:2372.713\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.11566, lr:1.00e-02, fs:0.71515 (r=0.596,p=0.894),  time:148.455, tt:2523.731\n",
      "Ep:17, loss:0.00018, loss_test:0.11553, lr:1.00e-02, fs:0.71856 (r=0.606,p=0.882),  time:148.549, tt:2673.877\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.11162, lr:1.00e-02, fs:0.73373 (r=0.626,p=0.886),  time:148.306, tt:2817.821\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.11614, lr:1.00e-02, fs:0.73939 (r=0.616,p=0.924),  time:147.910, tt:2958.195\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.11410, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:147.738, tt:3102.493\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.12061, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:147.530, tt:3245.662\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00010, loss_test:0.11567, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:147.479, tt:3392.012\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.12061, lr:1.00e-02, fs:0.76543 (r=0.626,p=0.984),  time:147.468, tt:3539.222\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00008, loss_test:0.12086, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:147.653, tt:3691.328\n",
      "Ep:25, loss:0.00007, loss_test:0.12050, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:147.649, tt:3838.872\n",
      "Ep:26, loss:0.00007, loss_test:0.12609, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:147.593, tt:3985.008\n",
      "Ep:27, loss:0.00006, loss_test:0.12260, lr:1.00e-02, fs:0.76829 (r=0.636,p=0.969),  time:147.558, tt:4131.623\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00006, loss_test:0.12644, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:147.489, tt:4277.188\n",
      "Ep:29, loss:0.00005, loss_test:0.12300, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:147.454, tt:4423.610\n",
      "Ep:30, loss:0.00005, loss_test:0.13090, lr:1.00e-02, fs:0.75000 (r=0.606,p=0.984),  time:147.453, tt:4571.029\n",
      "Ep:31, loss:0.00004, loss_test:0.12669, lr:1.00e-02, fs:0.76543 (r=0.626,p=0.984),  time:147.467, tt:4718.936\n",
      "Ep:32, loss:0.00004, loss_test:0.12779, lr:1.00e-02, fs:0.74214 (r=0.596,p=0.983),  time:147.598, tt:4870.740\n",
      "Ep:33, loss:0.00004, loss_test:0.13095, lr:1.00e-02, fs:0.71795 (r=0.566,p=0.982),  time:147.630, tt:5019.412\n",
      "Ep:34, loss:0.00003, loss_test:0.12728, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:147.679, tt:5168.780\n",
      "Ep:35, loss:0.00003, loss_test:0.13022, lr:1.00e-02, fs:0.76543 (r=0.626,p=0.984),  time:147.699, tt:5317.171\n",
      "Ep:36, loss:0.00003, loss_test:0.12963, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:147.617, tt:5461.815\n",
      "Ep:37, loss:0.00003, loss_test:0.13004, lr:1.00e-02, fs:0.71795 (r=0.566,p=0.982),  time:147.666, tt:5611.294\n",
      "Ep:38, loss:0.00002, loss_test:0.12905, lr:1.00e-02, fs:0.76543 (r=0.626,p=0.984),  time:147.642, tt:5758.046\n",
      "Ep:39, loss:0.00002, loss_test:0.13109, lr:9.90e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.564, tt:5902.552\n",
      "Ep:40, loss:0.00002, loss_test:0.13035, lr:9.80e-03, fs:0.72611 (r=0.576,p=0.983),  time:147.668, tt:6054.400\n",
      "Ep:41, loss:0.00002, loss_test:0.13214, lr:9.70e-03, fs:0.73418 (r=0.586,p=0.983),  time:147.660, tt:6201.711\n",
      "Ep:42, loss:0.00002, loss_test:0.13123, lr:9.61e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.626, tt:6347.928\n",
      "Ep:43, loss:0.00002, loss_test:0.13045, lr:9.51e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.618, tt:6495.171\n",
      "Ep:44, loss:0.00002, loss_test:0.13095, lr:9.41e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.599, tt:6641.946\n",
      "Ep:45, loss:0.00002, loss_test:0.13175, lr:9.32e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.659, tt:6792.310\n",
      "Ep:46, loss:0.00002, loss_test:0.13120, lr:9.23e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.667, tt:6940.369\n",
      "Ep:47, loss:0.00001, loss_test:0.13088, lr:9.14e-03, fs:0.70968 (r=0.556,p=0.982),  time:147.684, tt:7088.816\n",
      "Ep:48, loss:0.00001, loss_test:0.13079, lr:9.04e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.680, tt:7236.303\n",
      "Ep:49, loss:0.00001, loss_test:0.13152, lr:8.95e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.643, tt:7382.154\n",
      "Ep:50, loss:0.00001, loss_test:0.13046, lr:8.86e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.613, tt:7528.274\n",
      "Ep:51, loss:0.00001, loss_test:0.13194, lr:8.78e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.615, tt:7675.955\n",
      "Ep:52, loss:0.00001, loss_test:0.13124, lr:8.69e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.550, tt:7820.139\n",
      "Ep:53, loss:0.00001, loss_test:0.13156, lr:8.60e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.548, tt:7967.606\n",
      "Ep:54, loss:0.00001, loss_test:0.13045, lr:8.51e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.646, tt:8120.538\n",
      "Ep:55, loss:0.00001, loss_test:0.13127, lr:8.43e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.681, tt:8270.149\n",
      "Ep:56, loss:0.00001, loss_test:0.13169, lr:8.35e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.685, tt:8418.053\n",
      "Ep:57, loss:0.00001, loss_test:0.13179, lr:8.26e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.696, tt:8566.340\n",
      "Ep:58, loss:0.00001, loss_test:0.13085, lr:8.18e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.620, tt:8709.576\n",
      "Ep:59, loss:0.00001, loss_test:0.13199, lr:8.10e-03, fs:0.71795 (r=0.566,p=0.982),  time:147.561, tt:8853.647\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00120, loss_test:0.12422, lr:1.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:127.005, tt:127.005\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00103, loss_test:0.11259, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:136.982, tt:273.964\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00092, loss_test:0.10502, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:141.390, tt:424.170\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00083, loss_test:0.10023, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:143.378, tt:573.511\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00075, loss_test:0.09562, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:144.417, tt:722.085\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00068, loss_test:0.09204, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:144.845, tt:869.068\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00061, loss_test:0.08987, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:145.354, tt:1017.477\n",
      "Ep:7, loss:0.00055, loss_test:0.08888, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:146.115, tt:1168.919\n",
      "Ep:8, loss:0.00050, loss_test:0.08779, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:146.352, tt:1317.166\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00045, loss_test:0.08238, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:146.190, tt:1461.903\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00039, loss_test:0.08516, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:146.721, tt:1613.933\n",
      "Ep:11, loss:0.00034, loss_test:0.08449, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:146.811, tt:1761.729\n",
      "Ep:12, loss:0.00029, loss_test:0.08047, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:147.116, tt:1912.509\n",
      "Ep:13, loss:0.00026, loss_test:0.08072, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:147.182, tt:2060.543\n",
      "Ep:14, loss:0.00023, loss_test:0.08176, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:147.355, tt:2210.330\n",
      "Ep:15, loss:0.00020, loss_test:0.07844, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:147.302, tt:2356.825\n",
      "Ep:16, loss:0.00017, loss_test:0.08117, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:147.099, tt:2500.691\n",
      "Ep:17, loss:0.00015, loss_test:0.08209, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:147.070, tt:2647.254\n",
      "Ep:18, loss:0.00013, loss_test:0.08274, lr:1.00e-02, fs:0.72840 (r=0.596,p=0.937),  time:147.160, tt:2796.031\n",
      "Ep:19, loss:0.00012, loss_test:0.08530, lr:1.00e-02, fs:0.72152 (r=0.576,p=0.966),  time:147.282, tt:2945.646\n",
      "Ep:20, loss:0.00011, loss_test:0.08941, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:147.305, tt:3093.409\n",
      "Ep:21, loss:0.00010, loss_test:0.08236, lr:9.90e-03, fs:0.75610 (r=0.626,p=0.954),  time:147.297, tt:3240.540\n",
      "Ep:22, loss:0.00008, loss_test:0.08410, lr:9.80e-03, fs:0.79290 (r=0.677,p=0.957),  time:147.228, tt:3386.247\n",
      "Ep:23, loss:0.00007, loss_test:0.08771, lr:9.70e-03, fs:0.78824 (r=0.677,p=0.944),  time:147.075, tt:3529.802\n",
      "Ep:24, loss:0.00006, loss_test:0.08945, lr:9.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:146.994, tt:3674.862\n",
      "Ep:25, loss:0.00006, loss_test:0.08925, lr:9.51e-03, fs:0.79042 (r=0.667,p=0.971),  time:146.949, tt:3820.669\n",
      "Ep:26, loss:0.00005, loss_test:0.09224, lr:9.41e-03, fs:0.76829 (r=0.636,p=0.969),  time:147.019, tt:3969.510\n",
      "Ep:27, loss:0.00005, loss_test:0.09347, lr:9.32e-03, fs:0.78571 (r=0.667,p=0.957),  time:147.024, tt:4116.662\n",
      "Ep:28, loss:0.00004, loss_test:0.09262, lr:9.23e-03, fs:0.79762 (r=0.677,p=0.971),  time:147.058, tt:4264.686\n",
      "Ep:29, loss:0.00004, loss_test:0.09702, lr:9.14e-03, fs:0.78571 (r=0.667,p=0.957),  time:147.074, tt:4412.209\n",
      "Ep:30, loss:0.00004, loss_test:0.09476, lr:9.04e-03, fs:0.75309 (r=0.616,p=0.968),  time:147.012, tt:4557.364\n",
      "Ep:31, loss:0.00003, loss_test:0.09486, lr:8.95e-03, fs:0.79762 (r=0.677,p=0.971),  time:146.992, tt:4703.733\n",
      "Ep:32, loss:0.00003, loss_test:0.09546, lr:8.86e-03, fs:0.79762 (r=0.677,p=0.971),  time:147.046, tt:4852.512\n",
      "Ep:33, loss:0.00003, loss_test:0.09711, lr:8.78e-03, fs:0.79762 (r=0.677,p=0.971),  time:147.079, tt:5000.671\n",
      "Ep:34, loss:0.00003, loss_test:0.09810, lr:8.69e-03, fs:0.79762 (r=0.677,p=0.971),  time:147.155, tt:5150.410\n",
      "Ep:35, loss:0.00003, loss_test:0.09943, lr:8.60e-03, fs:0.77301 (r=0.636,p=0.984),  time:147.212, tt:5299.625\n",
      "Ep:36, loss:0.00002, loss_test:0.09815, lr:8.51e-03, fs:0.79762 (r=0.677,p=0.971),  time:147.200, tt:5446.396\n",
      "Ep:37, loss:0.00002, loss_test:0.10125, lr:8.43e-03, fs:0.76543 (r=0.626,p=0.984),  time:147.210, tt:5593.975\n",
      "Ep:38, loss:0.00002, loss_test:0.10189, lr:8.35e-03, fs:0.74074 (r=0.606,p=0.952),  time:147.196, tt:5740.626\n",
      "Ep:39, loss:0.00002, loss_test:0.10036, lr:8.26e-03, fs:0.74534 (r=0.606,p=0.968),  time:147.252, tt:5890.070\n",
      "Ep:40, loss:0.00002, loss_test:0.10099, lr:8.18e-03, fs:0.79290 (r=0.677,p=0.957),  time:147.241, tt:6036.868\n",
      "Ep:41, loss:0.00002, loss_test:0.10314, lr:8.10e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.249, tt:6184.456\n",
      "Ep:42, loss:0.00002, loss_test:0.10258, lr:8.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:147.198, tt:6329.534\n",
      "Ep:43, loss:0.00002, loss_test:0.10347, lr:7.94e-03, fs:0.76543 (r=0.626,p=0.984),  time:147.166, tt:6475.308\n",
      "Ep:44, loss:0.00002, loss_test:0.10401, lr:7.86e-03, fs:0.75309 (r=0.616,p=0.968),  time:147.124, tt:6620.575\n",
      "Ep:45, loss:0.00001, loss_test:0.10344, lr:7.78e-03, fs:0.74534 (r=0.606,p=0.968),  time:147.191, tt:6770.786\n",
      "Ep:46, loss:0.00001, loss_test:0.10451, lr:7.70e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.197, tt:6918.237\n",
      "Ep:47, loss:0.00001, loss_test:0.10458, lr:7.62e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.231, tt:7067.110\n",
      "Ep:48, loss:0.00001, loss_test:0.10480, lr:7.55e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.303, tt:7217.866\n",
      "Ep:49, loss:0.00001, loss_test:0.10452, lr:7.47e-03, fs:0.74534 (r=0.606,p=0.968),  time:147.320, tt:7366.021\n",
      "Ep:50, loss:0.00001, loss_test:0.10551, lr:7.40e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.372, tt:7515.996\n",
      "Ep:51, loss:0.00001, loss_test:0.10492, lr:7.32e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.434, tt:7666.571\n",
      "Ep:52, loss:0.00001, loss_test:0.10650, lr:7.25e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.414, tt:7812.951\n",
      "Ep:53, loss:0.00001, loss_test:0.10728, lr:7.18e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.494, tt:7964.702\n",
      "Ep:54, loss:0.00001, loss_test:0.10650, lr:7.11e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.548, tt:8115.117\n",
      "Ep:55, loss:0.00001, loss_test:0.10740, lr:7.03e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.557, tt:8263.208\n",
      "Ep:56, loss:0.00001, loss_test:0.10694, lr:6.96e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.634, tt:8415.115\n",
      "Ep:57, loss:0.00001, loss_test:0.10612, lr:6.89e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.565, tt:8558.782\n",
      "Ep:58, loss:0.00001, loss_test:0.10729, lr:6.83e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.525, tt:8703.957\n",
      "Ep:59, loss:0.00001, loss_test:0.10589, lr:6.76e-03, fs:0.75000 (r=0.606,p=0.984),  time:147.496, tt:8849.753\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00408, loss_test:0.12037, lr:1.00e-02, fs:0.64390 (r=0.667,p=0.623),  time:542.911, tt:542.911\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00259, loss_test:0.09277, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:550.485, tt:1100.970\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00180, loss_test:0.07921, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:555.241, tt:1665.724\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00123, loss_test:0.07674, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:557.405, tt:2229.622\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00085, loss_test:0.07268, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:559.839, tt:2799.193\n",
      "Ep:5, loss:0.00058, loss_test:0.07789, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:560.618, tt:3363.705\n",
      "Ep:6, loss:0.00039, loss_test:0.08338, lr:1.00e-02, fs:0.77576 (r=0.646,p=0.970),  time:560.038, tt:3920.269\n",
      "Ep:7, loss:0.00028, loss_test:0.08834, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:560.033, tt:4480.260\n",
      "Ep:8, loss:0.00020, loss_test:0.08520, lr:1.00e-02, fs:0.77778 (r=0.636,p=1.000),  time:560.486, tt:5044.371\n",
      "Ep:9, loss:0.00015, loss_test:0.09223, lr:1.00e-02, fs:0.77778 (r=0.636,p=1.000),  time:560.871, tt:5608.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00011, loss_test:0.09368, lr:1.00e-02, fs:0.77778 (r=0.636,p=1.000),  time:560.576, tt:6166.331\n",
      "Ep:11, loss:0.00007, loss_test:0.09259, lr:1.00e-02, fs:0.77778 (r=0.636,p=1.000),  time:561.171, tt:6734.053\n",
      "Ep:12, loss:0.00005, loss_test:0.09251, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:560.656, tt:7288.524\n",
      "Ep:13, loss:0.00004, loss_test:0.09178, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:560.925, tt:7852.948\n",
      "Ep:14, loss:0.00003, loss_test:0.09452, lr:1.00e-02, fs:0.73885 (r=0.586,p=1.000),  time:561.195, tt:8417.924\n",
      "Ep:15, loss:0.00003, loss_test:0.09223, lr:9.90e-03, fs:0.73885 (r=0.586,p=1.000),  time:561.208, tt:8979.336\n",
      "Ep:16, loss:0.00002, loss_test:0.09133, lr:9.80e-03, fs:0.73885 (r=0.586,p=1.000),  time:561.040, tt:9537.676\n",
      "Ep:17, loss:0.00002, loss_test:0.09101, lr:9.70e-03, fs:0.73885 (r=0.586,p=1.000),  time:560.347, tt:10086.244\n",
      "Ep:18, loss:0.00002, loss_test:0.09169, lr:9.61e-03, fs:0.73885 (r=0.586,p=1.000),  time:560.162, tt:10643.083\n",
      "Ep:19, loss:0.00002, loss_test:0.09097, lr:9.51e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.697, tt:11193.935\n",
      "Ep:20, loss:0.00002, loss_test:0.09228, lr:9.41e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.785, tt:11755.488\n",
      "Ep:21, loss:0.00001, loss_test:0.09142, lr:9.32e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.806, tt:12315.723\n",
      "Ep:22, loss:0.00001, loss_test:0.09170, lr:9.23e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.607, tt:12870.950\n",
      "Ep:23, loss:0.00001, loss_test:0.09207, lr:9.14e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.731, tt:13433.546\n",
      "Ep:24, loss:0.00001, loss_test:0.09258, lr:9.04e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.718, tt:13992.944\n",
      "Ep:25, loss:0.00001, loss_test:0.09115, lr:8.95e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.584, tt:14549.172\n",
      "Ep:26, loss:0.00001, loss_test:0.09230, lr:8.86e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.266, tt:15100.170\n",
      "Ep:27, loss:0.00001, loss_test:0.09247, lr:8.78e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.916, tt:15649.637\n",
      "Ep:28, loss:0.00001, loss_test:0.09224, lr:8.69e-03, fs:0.73885 (r=0.586,p=1.000),  time:559.147, tt:16215.260\n",
      "Ep:29, loss:0.00001, loss_test:0.09230, lr:8.60e-03, fs:0.73885 (r=0.586,p=1.000),  time:558.390, tt:16751.703\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00416, loss_test:0.11293, lr:1.00e-02, fs:0.65241 (r=0.616,p=0.693),  time:539.228, tt:539.228\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00259, loss_test:0.09401, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:552.208, tt:1104.416\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00171, loss_test:0.09571, lr:1.00e-02, fs:0.70303 (r=0.586,p=0.879),  time:554.553, tt:1663.658\n",
      "Ep:3, loss:0.00114, loss_test:0.09457, lr:1.00e-02, fs:0.70000 (r=0.566,p=0.918),  time:552.311, tt:2209.246\n",
      "Ep:4, loss:0.00076, loss_test:0.09634, lr:1.00e-02, fs:0.70000 (r=0.566,p=0.918),  time:554.050, tt:2770.249\n",
      "Ep:5, loss:0.00053, loss_test:0.09631, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:555.502, tt:3333.012\n",
      "Ep:6, loss:0.00036, loss_test:0.10869, lr:1.00e-02, fs:0.72152 (r=0.576,p=0.966),  time:555.869, tt:3891.083\n",
      "Ep:7, loss:0.00026, loss_test:0.11303, lr:1.00e-02, fs:0.64865 (r=0.485,p=0.980),  time:554.793, tt:4438.343\n",
      "Ep:8, loss:0.00020, loss_test:0.11437, lr:1.00e-02, fs:0.62069 (r=0.455,p=0.978),  time:554.376, tt:4989.383\n",
      "Ep:9, loss:0.00015, loss_test:0.11812, lr:1.00e-02, fs:0.62069 (r=0.455,p=0.978),  time:554.177, tt:5541.770\n",
      "Ep:10, loss:0.00011, loss_test:0.11721, lr:1.00e-02, fs:0.62069 (r=0.455,p=0.978),  time:553.785, tt:6091.635\n",
      "Ep:11, loss:0.00009, loss_test:0.11911, lr:1.00e-02, fs:0.62500 (r=0.455,p=1.000),  time:553.064, tt:6636.767\n",
      "Ep:12, loss:0.00007, loss_test:0.12212, lr:1.00e-02, fs:0.62500 (r=0.455,p=1.000),  time:552.472, tt:7182.134\n",
      "Ep:13, loss:0.00005, loss_test:0.12250, lr:9.90e-03, fs:0.62500 (r=0.455,p=1.000),  time:552.273, tt:7731.826\n",
      "Ep:14, loss:0.00004, loss_test:0.11968, lr:9.80e-03, fs:0.62500 (r=0.455,p=1.000),  time:552.306, tt:8284.596\n",
      "Ep:15, loss:0.00004, loss_test:0.12059, lr:9.70e-03, fs:0.62500 (r=0.455,p=1.000),  time:551.774, tt:8828.379\n",
      "Ep:16, loss:0.00003, loss_test:0.12152, lr:9.61e-03, fs:0.62500 (r=0.455,p=1.000),  time:551.716, tt:9379.170\n",
      "Ep:17, loss:0.00003, loss_test:0.12035, lr:9.51e-03, fs:0.62500 (r=0.455,p=1.000),  time:552.021, tt:9936.385\n",
      "Ep:18, loss:0.00002, loss_test:0.12231, lr:9.41e-03, fs:0.62500 (r=0.455,p=1.000),  time:551.604, tt:10480.469\n",
      "Ep:19, loss:0.00002, loss_test:0.12170, lr:9.32e-03, fs:0.62500 (r=0.455,p=1.000),  time:551.508, tt:11030.168\n",
      "Ep:20, loss:0.00002, loss_test:0.12135, lr:9.23e-03, fs:0.62500 (r=0.455,p=1.000),  time:551.083, tt:11572.751\n",
      "Ep:21, loss:0.00002, loss_test:0.12263, lr:9.14e-03, fs:0.62500 (r=0.455,p=1.000),  time:550.806, tt:12117.742\n",
      "Ep:22, loss:0.00002, loss_test:0.12205, lr:9.04e-03, fs:0.62500 (r=0.455,p=1.000),  time:550.284, tt:12656.542\n",
      "Ep:23, loss:0.00002, loss_test:0.12162, lr:8.95e-03, fs:0.62500 (r=0.455,p=1.000),  time:550.137, tt:13203.298\n",
      "Ep:24, loss:0.00001, loss_test:0.12247, lr:8.86e-03, fs:0.62500 (r=0.455,p=1.000),  time:550.260, tt:13756.489\n",
      "Ep:25, loss:0.00001, loss_test:0.12140, lr:8.78e-03, fs:0.62500 (r=0.455,p=1.000),  time:550.226, tt:14305.872\n",
      "Ep:26, loss:0.00001, loss_test:0.12034, lr:8.69e-03, fs:0.62500 (r=0.455,p=1.000),  time:549.879, tt:14846.726\n",
      "Ep:27, loss:0.00001, loss_test:0.11971, lr:8.60e-03, fs:0.62500 (r=0.455,p=1.000),  time:549.692, tt:15391.369\n",
      "Ep:28, loss:0.00001, loss_test:0.11990, lr:8.51e-03, fs:0.62500 (r=0.455,p=1.000),  time:549.736, tt:15942.333\n",
      "Ep:29, loss:0.00001, loss_test:0.11937, lr:8.43e-03, fs:0.62500 (r=0.455,p=1.000),  time:546.997, tt:16409.911\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,6,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,80,cv_number,8,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,10,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,0,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14334, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.524, tt:10.524\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14256, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.746, tt:23.492\n",
      "Ep:2, loss:0.00028, loss_test:0.14126, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:12.199, tt:36.596\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13930, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:12.912, tt:51.648\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13632, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:13.920, tt:69.598\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.13240, lr:1.00e-02, fs:0.68551 (r=0.980,p=0.527),  time:15.607, tt:93.642\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12793, lr:1.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:17.116, tt:119.812\n",
      "Ep:7, loss:0.00024, loss_test:0.12524, lr:1.00e-02, fs:0.63850 (r=0.687,p=0.596),  time:18.428, tt:147.427\n",
      "Ep:8, loss:0.00023, loss_test:0.12537, lr:1.00e-02, fs:0.58201 (r=0.556,p=0.611),  time:19.465, tt:175.181\n",
      "Ep:9, loss:0.00022, loss_test:0.12396, lr:1.00e-02, fs:0.59893 (r=0.566,p=0.636),  time:20.257, tt:202.573\n",
      "Ep:10, loss:0.00022, loss_test:0.12239, lr:1.00e-02, fs:0.61616 (r=0.616,p=0.616),  time:21.092, tt:232.009\n",
      "Ep:11, loss:0.00021, loss_test:0.12135, lr:1.00e-02, fs:0.64356 (r=0.657,p=0.631),  time:21.528, tt:258.339\n",
      "Ep:12, loss:0.00020, loss_test:0.11999, lr:1.00e-02, fs:0.60870 (r=0.566,p=0.659),  time:22.138, tt:287.798\n",
      "Ep:13, loss:0.00020, loss_test:0.11853, lr:1.00e-02, fs:0.59218 (r=0.535,p=0.662),  time:22.563, tt:315.878\n",
      "Ep:14, loss:0.00019, loss_test:0.11645, lr:1.00e-02, fs:0.62703 (r=0.586,p=0.674),  time:22.921, tt:343.813\n",
      "Ep:15, loss:0.00019, loss_test:0.11542, lr:1.00e-02, fs:0.64550 (r=0.616,p=0.678),  time:23.198, tt:371.176\n",
      "Ep:16, loss:0.00018, loss_test:0.11558, lr:1.00e-02, fs:0.64130 (r=0.596,p=0.694),  time:23.574, tt:400.752\n",
      "Ep:17, loss:0.00018, loss_test:0.11537, lr:9.90e-03, fs:0.67725 (r=0.646,p=0.711),  time:23.829, tt:428.922\n",
      "Ep:18, loss:0.00017, loss_test:0.11401, lr:9.80e-03, fs:0.69072 (r=0.677,p=0.705),  time:24.082, tt:457.553\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.11325, lr:9.80e-03, fs:0.68750 (r=0.667,p=0.710),  time:24.401, tt:488.015\n",
      "Ep:20, loss:0.00016, loss_test:0.11315, lr:9.80e-03, fs:0.68817 (r=0.646,p=0.736),  time:24.731, tt:519.349\n",
      "Ep:21, loss:0.00016, loss_test:0.11271, lr:9.80e-03, fs:0.68783 (r=0.657,p=0.722),  time:24.999, tt:549.985\n",
      "Ep:22, loss:0.00015, loss_test:0.11153, lr:9.80e-03, fs:0.71134 (r=0.697,p=0.726),  time:25.107, tt:577.456\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.11142, lr:9.80e-03, fs:0.71134 (r=0.697,p=0.726),  time:25.340, tt:608.149\n",
      "Ep:24, loss:0.00015, loss_test:0.11153, lr:9.80e-03, fs:0.68449 (r=0.646,p=0.727),  time:25.440, tt:636.000\n",
      "Ep:25, loss:0.00014, loss_test:0.11124, lr:9.80e-03, fs:0.69149 (r=0.657,p=0.730),  time:25.631, tt:666.403\n",
      "Ep:26, loss:0.00014, loss_test:0.11062, lr:9.80e-03, fs:0.70157 (r=0.677,p=0.728),  time:25.709, tt:694.141\n",
      "Ep:27, loss:0.00014, loss_test:0.11103, lr:9.80e-03, fs:0.68817 (r=0.646,p=0.736),  time:25.830, tt:723.247\n",
      "Ep:28, loss:0.00013, loss_test:0.10981, lr:9.80e-03, fs:0.70899 (r=0.677,p=0.744),  time:25.934, tt:752.086\n",
      "Ep:29, loss:0.00013, loss_test:0.10879, lr:9.80e-03, fs:0.73469 (r=0.727,p=0.742),  time:26.077, tt:782.318\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.10920, lr:9.80e-03, fs:0.69892 (r=0.657,p=0.747),  time:26.171, tt:811.286\n",
      "Ep:31, loss:0.00013, loss_test:0.10870, lr:9.80e-03, fs:0.70270 (r=0.657,p=0.756),  time:26.254, tt:840.113\n",
      "Ep:32, loss:0.00012, loss_test:0.10834, lr:9.80e-03, fs:0.71958 (r=0.687,p=0.756),  time:26.346, tt:869.433\n",
      "Ep:33, loss:0.00012, loss_test:0.10890, lr:9.80e-03, fs:0.69565 (r=0.646,p=0.753),  time:26.419, tt:898.260\n",
      "Ep:34, loss:0.00012, loss_test:0.10809, lr:9.80e-03, fs:0.72340 (r=0.687,p=0.764),  time:26.515, tt:928.019\n",
      "Ep:35, loss:0.00012, loss_test:0.10819, lr:9.80e-03, fs:0.71351 (r=0.667,p=0.767),  time:26.585, tt:957.071\n",
      "Ep:36, loss:0.00011, loss_test:0.10882, lr:9.80e-03, fs:0.68508 (r=0.626,p=0.756),  time:26.667, tt:986.683\n",
      "Ep:37, loss:0.00011, loss_test:0.10727, lr:9.80e-03, fs:0.70213 (r=0.667,p=0.742),  time:26.729, tt:1015.702\n",
      "Ep:38, loss:0.00011, loss_test:0.10832, lr:9.80e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.773, tt:1044.166\n",
      "Ep:39, loss:0.00011, loss_test:0.10659, lr:9.80e-03, fs:0.70968 (r=0.667,p=0.759),  time:26.805, tt:1072.189\n",
      "Ep:40, loss:0.00010, loss_test:0.10746, lr:9.80e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.840, tt:1100.460\n",
      "Ep:41, loss:0.00010, loss_test:0.10672, lr:9.70e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.901, tt:1129.850\n",
      "Ep:42, loss:0.00010, loss_test:0.10691, lr:9.61e-03, fs:0.68156 (r=0.616,p=0.762),  time:26.915, tt:1157.325\n",
      "Ep:43, loss:0.00010, loss_test:0.10650, lr:9.51e-03, fs:0.67778 (r=0.616,p=0.753),  time:26.912, tt:1184.148\n",
      "Ep:44, loss:0.00009, loss_test:0.10763, lr:9.41e-03, fs:0.67045 (r=0.596,p=0.766),  time:26.930, tt:1211.843\n",
      "Ep:45, loss:0.00009, loss_test:0.10559, lr:9.32e-03, fs:0.69613 (r=0.636,p=0.768),  time:26.989, tt:1241.483\n",
      "Ep:46, loss:0.00009, loss_test:0.10724, lr:9.23e-03, fs:0.67045 (r=0.596,p=0.766),  time:27.015, tt:1269.709\n",
      "Ep:47, loss:0.00009, loss_test:0.10496, lr:9.14e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.042, tt:1298.002\n",
      "Ep:48, loss:0.00009, loss_test:0.10739, lr:9.04e-03, fs:0.67429 (r=0.596,p=0.776),  time:27.059, tt:1325.881\n",
      "Ep:49, loss:0.00009, loss_test:0.10621, lr:8.95e-03, fs:0.67429 (r=0.596,p=0.776),  time:27.060, tt:1353.021\n",
      "Ep:50, loss:0.00008, loss_test:0.10450, lr:8.86e-03, fs:0.67797 (r=0.606,p=0.769),  time:27.092, tt:1381.716\n",
      "Ep:51, loss:0.00008, loss_test:0.10710, lr:8.78e-03, fs:0.65896 (r=0.576,p=0.770),  time:27.125, tt:1410.495\n",
      "Ep:52, loss:0.00008, loss_test:0.10482, lr:8.69e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.142, tt:1438.549\n",
      "Ep:53, loss:0.00008, loss_test:0.10778, lr:8.60e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.157, tt:1466.468\n",
      "Ep:54, loss:0.00008, loss_test:0.10470, lr:8.51e-03, fs:0.68539 (r=0.616,p=0.772),  time:27.197, tt:1495.811\n",
      "Ep:55, loss:0.00008, loss_test:0.10672, lr:8.43e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.191, tt:1522.690\n",
      "Ep:56, loss:0.00007, loss_test:0.10691, lr:8.35e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.191, tt:1549.893\n",
      "Ep:57, loss:0.00007, loss_test:0.10600, lr:8.26e-03, fs:0.65896 (r=0.576,p=0.770),  time:27.217, tt:1578.593\n",
      "Ep:58, loss:0.00007, loss_test:0.10823, lr:8.18e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.253, tt:1607.900\n",
      "Ep:59, loss:0.00007, loss_test:0.10557, lr:8.10e-03, fs:0.65896 (r=0.576,p=0.770),  time:27.225, tt:1633.495\n",
      "Ep:60, loss:0.00007, loss_test:0.10641, lr:8.02e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.228, tt:1660.902\n",
      "Ep:61, loss:0.00007, loss_test:0.10510, lr:7.94e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.246, tt:1689.237\n",
      "Ep:62, loss:0.00007, loss_test:0.10777, lr:7.86e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.251, tt:1716.825\n",
      "Ep:63, loss:0.00007, loss_test:0.10565, lr:7.78e-03, fs:0.65896 (r=0.576,p=0.770),  time:27.272, tt:1745.412\n",
      "Ep:64, loss:0.00006, loss_test:0.10757, lr:7.70e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.288, tt:1773.739\n",
      "Ep:65, loss:0.00006, loss_test:0.10464, lr:7.62e-03, fs:0.66667 (r=0.586,p=0.773),  time:27.331, tt:1803.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00006, loss_test:0.10835, lr:7.55e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.318, tt:1830.311\n",
      "Ep:67, loss:0.00006, loss_test:0.10528, lr:7.47e-03, fs:0.67052 (r=0.586,p=0.784),  time:27.342, tt:1859.253\n",
      "Ep:68, loss:0.00006, loss_test:0.10658, lr:7.40e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.380, tt:1889.229\n",
      "Ep:69, loss:0.00006, loss_test:0.10567, lr:7.32e-03, fs:0.65896 (r=0.576,p=0.770),  time:27.400, tt:1918.000\n",
      "Ep:70, loss:0.00006, loss_test:0.10900, lr:7.25e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.411, tt:1946.191\n",
      "Ep:71, loss:0.00006, loss_test:0.10601, lr:7.18e-03, fs:0.67052 (r=0.586,p=0.784),  time:27.432, tt:1975.139\n",
      "Ep:72, loss:0.00006, loss_test:0.10682, lr:7.11e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.448, tt:2003.711\n",
      "Ep:73, loss:0.00006, loss_test:0.10767, lr:7.03e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.484, tt:2033.811\n",
      "Ep:74, loss:0.00006, loss_test:0.10594, lr:6.96e-03, fs:0.67052 (r=0.586,p=0.784),  time:27.470, tt:2060.278\n",
      "Ep:75, loss:0.00005, loss_test:0.10982, lr:6.89e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.477, tt:2088.277\n",
      "Ep:76, loss:0.00005, loss_test:0.10413, lr:6.83e-03, fs:0.66667 (r=0.586,p=0.773),  time:27.473, tt:2115.440\n",
      "Ep:77, loss:0.00005, loss_test:0.11207, lr:6.76e-03, fs:0.64706 (r=0.556,p=0.775),  time:27.485, tt:2143.803\n",
      "Ep:78, loss:0.00005, loss_test:0.10592, lr:6.69e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.479, tt:2170.870\n",
      "Ep:79, loss:0.00005, loss_test:0.10805, lr:6.62e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.489, tt:2199.101\n",
      "Ep:80, loss:0.00005, loss_test:0.11043, lr:6.56e-03, fs:0.65089 (r=0.556,p=0.786),  time:27.515, tt:2228.696\n",
      "Ep:81, loss:0.00005, loss_test:0.10493, lr:6.49e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.511, tt:2255.933\n",
      "Ep:82, loss:0.00005, loss_test:0.11220, lr:6.43e-03, fs:0.65497 (r=0.566,p=0.778),  time:27.514, tt:2283.664\n",
      "Ep:83, loss:0.00005, loss_test:0.10423, lr:6.36e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.526, tt:2312.143\n",
      "Ep:84, loss:0.00005, loss_test:0.10991, lr:6.30e-03, fs:0.66279 (r=0.576,p=0.781),  time:27.544, tt:2341.254\n",
      "Ep:85, loss:0.00005, loss_test:0.10680, lr:6.24e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.566, tt:2370.686\n",
      "Ep:86, loss:0.00005, loss_test:0.10724, lr:6.17e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.590, tt:2400.352\n",
      "Ep:87, loss:0.00005, loss_test:0.10932, lr:6.11e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.603, tt:2429.028\n",
      "Ep:88, loss:0.00005, loss_test:0.10607, lr:6.05e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.606, tt:2456.911\n",
      "Ep:89, loss:0.00004, loss_test:0.10931, lr:5.99e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.614, tt:2485.271\n",
      "Ep:90, loss:0.00004, loss_test:0.10657, lr:5.93e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.622, tt:2513.638\n",
      "Ep:91, loss:0.00004, loss_test:0.10848, lr:5.87e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.636, tt:2542.497\n",
      "Ep:92, loss:0.00004, loss_test:0.10903, lr:5.81e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.650, tt:2571.460\n",
      "Ep:93, loss:0.00004, loss_test:0.10773, lr:5.75e-03, fs:0.66667 (r=0.576,p=0.792),  time:27.659, tt:2599.983\n",
      "Ep:94, loss:0.00004, loss_test:0.11003, lr:5.70e-03, fs:0.67059 (r=0.576,p=0.803),  time:27.652, tt:2626.895\n",
      "Ep:95, loss:0.00004, loss_test:0.10965, lr:5.64e-03, fs:0.67059 (r=0.576,p=0.803),  time:27.646, tt:2653.970\n",
      "Ep:96, loss:0.00004, loss_test:0.11054, lr:5.58e-03, fs:0.67857 (r=0.576,p=0.826),  time:27.649, tt:2681.957\n",
      "Ep:97, loss:0.00004, loss_test:0.10869, lr:5.53e-03, fs:0.67456 (r=0.576,p=0.814),  time:27.653, tt:2710.004\n",
      "Ep:98, loss:0.00004, loss_test:0.10895, lr:5.47e-03, fs:0.67857 (r=0.576,p=0.826),  time:27.670, tt:2739.369\n",
      "Ep:99, loss:0.00004, loss_test:0.11158, lr:5.42e-03, fs:0.67857 (r=0.576,p=0.826),  time:27.690, tt:2769.019\n",
      "Ep:100, loss:0.00004, loss_test:0.10871, lr:5.36e-03, fs:0.67857 (r=0.576,p=0.826),  time:27.708, tt:2798.499\n",
      "Ep:101, loss:0.00004, loss_test:0.11291, lr:5.31e-03, fs:0.68675 (r=0.576,p=0.851),  time:27.725, tt:2827.983\n",
      "Ep:102, loss:0.00004, loss_test:0.10727, lr:5.26e-03, fs:0.67857 (r=0.576,p=0.826),  time:27.735, tt:2856.756\n",
      "Ep:103, loss:0.00004, loss_test:0.11409, lr:5.20e-03, fs:0.68675 (r=0.576,p=0.851),  time:27.741, tt:2885.092\n",
      "Ep:104, loss:0.00004, loss_test:0.10950, lr:5.15e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.751, tt:2913.827\n",
      "Ep:105, loss:0.00004, loss_test:0.11192, lr:5.10e-03, fs:0.68675 (r=0.576,p=0.851),  time:27.758, tt:2942.335\n",
      "Ep:106, loss:0.00004, loss_test:0.11123, lr:5.05e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.751, tt:2969.330\n",
      "Ep:107, loss:0.00004, loss_test:0.10791, lr:5.00e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.750, tt:2997.031\n",
      "Ep:108, loss:0.00004, loss_test:0.11467, lr:4.95e-03, fs:0.68675 (r=0.576,p=0.851),  time:27.763, tt:3026.196\n",
      "Ep:109, loss:0.00003, loss_test:0.10858, lr:4.90e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.767, tt:3054.359\n",
      "Ep:110, loss:0.00003, loss_test:0.11263, lr:4.85e-03, fs:0.68675 (r=0.576,p=0.851),  time:27.748, tt:3080.070\n",
      "Ep:111, loss:0.00003, loss_test:0.11283, lr:4.80e-03, fs:0.68675 (r=0.576,p=0.851),  time:27.734, tt:3106.261\n",
      "Ep:112, loss:0.00003, loss_test:0.10912, lr:4.75e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.726, tt:3133.008\n",
      "Ep:113, loss:0.00003, loss_test:0.11446, lr:4.71e-03, fs:0.69091 (r=0.576,p=0.864),  time:27.711, tt:3159.084\n",
      "Ep:114, loss:0.00003, loss_test:0.10780, lr:4.66e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.713, tt:3186.986\n",
      "Ep:115, loss:0.00003, loss_test:0.11494, lr:4.61e-03, fs:0.69091 (r=0.576,p=0.864),  time:27.726, tt:3216.266\n",
      "Ep:116, loss:0.00003, loss_test:0.11511, lr:4.57e-03, fs:0.69512 (r=0.576,p=0.877),  time:27.740, tt:3245.625\n",
      "Ep:117, loss:0.00003, loss_test:0.10743, lr:4.52e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.758, tt:3275.471\n",
      "Ep:118, loss:0.00003, loss_test:0.11530, lr:4.48e-03, fs:0.69091 (r=0.576,p=0.864),  time:27.782, tt:3306.031\n",
      "Ep:119, loss:0.00003, loss_test:0.11388, lr:4.43e-03, fs:0.69512 (r=0.576,p=0.877),  time:27.795, tt:3335.391\n",
      "Ep:120, loss:0.00003, loss_test:0.10787, lr:4.39e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.808, tt:3364.762\n",
      "Ep:121, loss:0.00003, loss_test:0.11441, lr:4.34e-03, fs:0.69091 (r=0.576,p=0.864),  time:27.844, tt:3396.961\n",
      "Ep:122, loss:0.00003, loss_test:0.11412, lr:4.30e-03, fs:0.69091 (r=0.576,p=0.864),  time:27.884, tt:3429.724\n",
      "Ep:123, loss:0.00003, loss_test:0.10882, lr:4.26e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.901, tt:3459.739\n",
      "Ep:124, loss:0.00003, loss_test:0.11438, lr:4.21e-03, fs:0.69512 (r=0.576,p=0.877),  time:27.927, tt:3490.850\n",
      "Ep:125, loss:0.00003, loss_test:0.11463, lr:4.17e-03, fs:0.69512 (r=0.576,p=0.877),  time:27.965, tt:3523.611\n",
      "Ep:126, loss:0.00003, loss_test:0.10825, lr:4.13e-03, fs:0.68263 (r=0.576,p=0.838),  time:27.991, tt:3554.833\n",
      "Ep:127, loss:0.00003, loss_test:0.11633, lr:4.09e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.015, tt:3585.909\n",
      "Ep:128, loss:0.00003, loss_test:0.11320, lr:4.05e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.024, tt:3615.040\n",
      "Ep:129, loss:0.00003, loss_test:0.10970, lr:4.01e-03, fs:0.69091 (r=0.576,p=0.864),  time:28.044, tt:3645.739\n",
      "Ep:130, loss:0.00003, loss_test:0.11484, lr:3.97e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.068, tt:3676.846\n",
      "Ep:131, loss:0.00003, loss_test:0.11388, lr:3.93e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.088, tt:3707.598\n",
      "Ep:132, loss:0.00003, loss_test:0.11009, lr:3.89e-03, fs:0.69091 (r=0.576,p=0.864),  time:28.111, tt:3738.769\n",
      "Ep:133, loss:0.00003, loss_test:0.11470, lr:3.85e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.116, tt:3767.576\n",
      "Ep:134, loss:0.00003, loss_test:0.11517, lr:3.81e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.137, tt:3798.487\n",
      "Ep:135, loss:0.00003, loss_test:0.11002, lr:3.77e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.161, tt:3829.931\n",
      "Ep:136, loss:0.00003, loss_test:0.11328, lr:3.73e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.187, tt:3861.647\n",
      "Ep:137, loss:0.00003, loss_test:0.11377, lr:3.70e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.193, tt:3890.567\n",
      "Ep:138, loss:0.00003, loss_test:0.11122, lr:3.66e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.211, tt:3921.340\n",
      "Ep:139, loss:0.00003, loss_test:0.11316, lr:3.62e-03, fs:0.69512 (r=0.576,p=0.877),  time:28.232, tt:3952.487\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14630, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:28.426, tt:28.426\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14559, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:29.214, tt:58.428\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.14428, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:29.950, tt:89.850\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.14210, lr:1.00e-02, fs:0.64336 (r=0.929,p=0.492),  time:29.364, tt:117.455\n",
      "Ep:4, loss:0.00026, loss_test:0.13901, lr:1.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:28.334, tt:141.671\n",
      "Ep:5, loss:0.00025, loss_test:0.13458, lr:1.00e-02, fs:0.61111 (r=0.778,p=0.503),  time:28.450, tt:170.700\n",
      "Ep:6, loss:0.00024, loss_test:0.13035, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:28.936, tt:202.550\n",
      "Ep:7, loss:0.00023, loss_test:0.12905, lr:1.00e-02, fs:0.65049 (r=0.677,p=0.626),  time:29.155, tt:233.237\n",
      "Ep:8, loss:0.00023, loss_test:0.12750, lr:1.00e-02, fs:0.65700 (r=0.687,p=0.630),  time:29.398, tt:264.584\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.12644, lr:1.00e-02, fs:0.65741 (r=0.717,p=0.607),  time:29.640, tt:296.403\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.12466, lr:1.00e-02, fs:0.64455 (r=0.687,p=0.607),  time:29.597, tt:325.564\n",
      "Ep:11, loss:0.00021, loss_test:0.12235, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:29.681, tt:356.171\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.12015, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:29.666, tt:385.652\n",
      "Ep:13, loss:0.00020, loss_test:0.11785, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:29.671, tt:415.391\n",
      "Ep:14, loss:0.00019, loss_test:0.11580, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:29.747, tt:446.208\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11410, lr:1.00e-02, fs:0.64550 (r=0.616,p=0.678),  time:29.798, tt:476.765\n",
      "Ep:16, loss:0.00018, loss_test:0.11274, lr:1.00e-02, fs:0.64481 (r=0.596,p=0.702),  time:29.923, tt:508.689\n",
      "Ep:17, loss:0.00018, loss_test:0.11136, lr:1.00e-02, fs:0.65217 (r=0.606,p=0.706),  time:29.913, tt:538.440\n",
      "Ep:18, loss:0.00017, loss_test:0.10986, lr:1.00e-02, fs:0.65957 (r=0.626,p=0.697),  time:29.959, tt:569.214\n",
      "Ep:19, loss:0.00017, loss_test:0.10849, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:30.024, tt:600.478\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10762, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:29.963, tt:629.214\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.10632, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:29.958, tt:659.084\n",
      "Ep:22, loss:0.00016, loss_test:0.10556, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:29.991, tt:689.800\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.10533, lr:1.00e-02, fs:0.70000 (r=0.636,p=0.778),  time:30.025, tt:720.592\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.10345, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:29.993, tt:749.829\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.10282, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:30.007, tt:780.183\n",
      "Ep:26, loss:0.00014, loss_test:0.10318, lr:1.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:30.020, tt:810.546\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.10115, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:30.047, tt:841.307\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.10165, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:30.105, tt:873.036\n",
      "Ep:29, loss:0.00013, loss_test:0.10104, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:30.125, tt:903.735\n",
      "Ep:30, loss:0.00013, loss_test:0.09911, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:30.129, tt:933.994\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.10034, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:30.166, tt:965.318\n",
      "Ep:32, loss:0.00012, loss_test:0.09840, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:30.215, tt:997.093\n",
      "Ep:33, loss:0.00012, loss_test:0.09859, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:30.210, tt:1027.135\n",
      "Ep:34, loss:0.00012, loss_test:0.09898, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:30.224, tt:1057.837\n",
      "Ep:35, loss:0.00011, loss_test:0.09781, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:30.258, tt:1089.284\n",
      "Ep:36, loss:0.00011, loss_test:0.09926, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:30.284, tt:1120.523\n",
      "Ep:37, loss:0.00011, loss_test:0.09877, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:30.388, tt:1154.750\n",
      "Ep:38, loss:0.00011, loss_test:0.09741, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:30.398, tt:1185.506\n",
      "Ep:39, loss:0.00010, loss_test:0.10147, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.412, tt:1216.470\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.09686, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:30.466, tt:1249.117\n",
      "Ep:41, loss:0.00010, loss_test:0.10100, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:30.480, tt:1280.176\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.09812, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.518, tt:1312.264\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.10121, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.502, tt:1342.108\n",
      "Ep:44, loss:0.00009, loss_test:0.09938, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.515, tt:1373.174\n",
      "Ep:45, loss:0.00009, loss_test:0.10020, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:30.530, tt:1404.369\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.10055, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.520, tt:1434.430\n",
      "Ep:47, loss:0.00009, loss_test:0.10052, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:30.519, tt:1464.933\n",
      "Ep:48, loss:0.00008, loss_test:0.10133, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:30.515, tt:1495.232\n",
      "Ep:49, loss:0.00008, loss_test:0.10117, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:30.538, tt:1526.896\n",
      "Ep:50, loss:0.00008, loss_test:0.10028, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:30.545, tt:1557.807\n",
      "Ep:51, loss:0.00008, loss_test:0.09959, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:30.551, tt:1588.658\n",
      "Ep:52, loss:0.00008, loss_test:0.10111, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:30.580, tt:1620.747\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.10032, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:30.605, tt:1652.655\n",
      "Ep:54, loss:0.00007, loss_test:0.10076, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:30.612, tt:1683.682\n",
      "Ep:55, loss:0.00007, loss_test:0.10010, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:30.598, tt:1713.461\n",
      "Ep:56, loss:0.00007, loss_test:0.10466, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:30.627, tt:1745.716\n",
      "Ep:57, loss:0.00007, loss_test:0.09885, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.636, tt:1776.911\n",
      "Ep:58, loss:0.00007, loss_test:0.10387, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.675, tt:1809.815\n",
      "Ep:59, loss:0.00007, loss_test:0.09984, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:30.693, tt:1841.554\n",
      "Ep:60, loss:0.00007, loss_test:0.10404, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.708, tt:1873.161\n",
      "Ep:61, loss:0.00006, loss_test:0.10088, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.698, tt:1903.269\n",
      "Ep:62, loss:0.00006, loss_test:0.10355, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.719, tt:1935.292\n",
      "Ep:63, loss:0.00006, loss_test:0.10289, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.721, tt:1966.167\n",
      "Ep:64, loss:0.00006, loss_test:0.09949, lr:9.90e-03, fs:0.75556 (r=0.687,p=0.840),  time:30.727, tt:1997.278\n",
      "Ep:65, loss:0.00006, loss_test:0.10553, lr:9.80e-03, fs:0.76301 (r=0.667,p=0.892),  time:30.711, tt:2026.920\n",
      "Ep:66, loss:0.00006, loss_test:0.10014, lr:9.70e-03, fs:0.75556 (r=0.687,p=0.840),  time:30.696, tt:2056.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00006, loss_test:0.10648, lr:9.61e-03, fs:0.76301 (r=0.667,p=0.892),  time:30.684, tt:2086.513\n",
      "Ep:68, loss:0.00006, loss_test:0.10053, lr:9.51e-03, fs:0.75556 (r=0.687,p=0.840),  time:30.674, tt:2116.504\n",
      "Ep:69, loss:0.00005, loss_test:0.10531, lr:9.41e-03, fs:0.76301 (r=0.667,p=0.892),  time:30.674, tt:2147.160\n",
      "Ep:70, loss:0.00005, loss_test:0.10168, lr:9.32e-03, fs:0.75000 (r=0.667,p=0.857),  time:30.708, tt:2180.260\n",
      "Ep:71, loss:0.00005, loss_test:0.10613, lr:9.23e-03, fs:0.75581 (r=0.657,p=0.890),  time:30.689, tt:2209.587\n",
      "Ep:72, loss:0.00005, loss_test:0.10148, lr:9.14e-03, fs:0.75429 (r=0.667,p=0.868),  time:30.687, tt:2240.186\n",
      "Ep:73, loss:0.00005, loss_test:0.10538, lr:9.04e-03, fs:0.75581 (r=0.657,p=0.890),  time:30.716, tt:2272.961\n",
      "Ep:74, loss:0.00005, loss_test:0.10166, lr:8.95e-03, fs:0.75000 (r=0.667,p=0.857),  time:30.727, tt:2304.496\n",
      "Ep:75, loss:0.00005, loss_test:0.10504, lr:8.86e-03, fs:0.74854 (r=0.646,p=0.889),  time:30.715, tt:2334.327\n",
      "Ep:76, loss:0.00005, loss_test:0.10311, lr:8.78e-03, fs:0.75000 (r=0.667,p=0.857),  time:30.732, tt:2366.401\n",
      "Ep:77, loss:0.00005, loss_test:0.10412, lr:8.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:30.741, tt:2397.792\n",
      "Ep:78, loss:0.00005, loss_test:0.10389, lr:8.60e-03, fs:0.75581 (r=0.657,p=0.890),  time:30.728, tt:2427.527\n",
      "Ep:79, loss:0.00004, loss_test:0.10511, lr:8.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:30.721, tt:2457.667\n",
      "Ep:80, loss:0.00004, loss_test:0.10168, lr:8.43e-03, fs:0.75145 (r=0.657,p=0.878),  time:30.749, tt:2490.686\n",
      "Ep:81, loss:0.00004, loss_test:0.10610, lr:8.35e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.761, tt:2522.416\n",
      "Ep:82, loss:0.00004, loss_test:0.10494, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:30.773, tt:2554.173\n",
      "Ep:83, loss:0.00004, loss_test:0.10443, lr:8.18e-03, fs:0.75294 (r=0.646,p=0.901),  time:30.786, tt:2586.039\n",
      "Ep:84, loss:0.00004, loss_test:0.10381, lr:8.10e-03, fs:0.75581 (r=0.657,p=0.890),  time:30.796, tt:2617.699\n",
      "Ep:85, loss:0.00004, loss_test:0.10431, lr:8.02e-03, fs:0.75294 (r=0.646,p=0.901),  time:30.805, tt:2649.248\n",
      "Ep:86, loss:0.00004, loss_test:0.10322, lr:7.94e-03, fs:0.75294 (r=0.646,p=0.901),  time:30.829, tt:2682.148\n",
      "Ep:87, loss:0.00004, loss_test:0.10536, lr:7.86e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.851, tt:2714.851\n",
      "Ep:88, loss:0.00004, loss_test:0.10305, lr:7.78e-03, fs:0.75581 (r=0.657,p=0.890),  time:30.853, tt:2745.894\n",
      "Ep:89, loss:0.00004, loss_test:0.10640, lr:7.70e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.858, tt:2777.181\n",
      "Ep:90, loss:0.00004, loss_test:0.10400, lr:7.62e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.875, tt:2809.581\n",
      "Ep:91, loss:0.00004, loss_test:0.10486, lr:7.55e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.888, tt:2841.659\n",
      "Ep:92, loss:0.00004, loss_test:0.10468, lr:7.47e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.893, tt:2873.059\n",
      "Ep:93, loss:0.00003, loss_test:0.10377, lr:7.40e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.894, tt:2904.066\n",
      "Ep:94, loss:0.00003, loss_test:0.10430, lr:7.32e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.905, tt:2936.001\n",
      "Ep:95, loss:0.00003, loss_test:0.10466, lr:7.25e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.903, tt:2966.664\n",
      "Ep:96, loss:0.00003, loss_test:0.10325, lr:7.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.910, tt:2998.284\n",
      "Ep:97, loss:0.00003, loss_test:0.10673, lr:7.11e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.925, tt:3030.628\n",
      "Ep:98, loss:0.00003, loss_test:0.10495, lr:7.03e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.894, tt:3058.515\n",
      "Ep:99, loss:0.00003, loss_test:0.10425, lr:6.96e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.906, tt:3090.572\n",
      "Ep:100, loss:0.00003, loss_test:0.10596, lr:6.89e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.905, tt:3121.427\n",
      "Ep:101, loss:0.00003, loss_test:0.10223, lr:6.83e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.906, tt:3152.443\n",
      "Ep:102, loss:0.00003, loss_test:0.10825, lr:6.76e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.905, tt:3183.193\n",
      "Ep:103, loss:0.00003, loss_test:0.10452, lr:6.69e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.926, tt:3216.284\n",
      "Ep:104, loss:0.00003, loss_test:0.10395, lr:6.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.947, tt:3249.391\n",
      "Ep:105, loss:0.00003, loss_test:0.10737, lr:6.56e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.963, tt:3282.101\n",
      "Ep:106, loss:0.00003, loss_test:0.10141, lr:6.49e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.959, tt:3312.576\n",
      "Ep:107, loss:0.00003, loss_test:0.10840, lr:6.43e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.954, tt:3342.999\n",
      "Ep:108, loss:0.00003, loss_test:0.10431, lr:6.36e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.967, tt:3375.439\n",
      "Ep:109, loss:0.00003, loss_test:0.10436, lr:6.30e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.969, tt:3406.555\n",
      "Ep:110, loss:0.00003, loss_test:0.10865, lr:6.24e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.969, tt:3437.597\n",
      "Ep:111, loss:0.00003, loss_test:0.10143, lr:6.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.985, tt:3470.336\n",
      "Ep:112, loss:0.00003, loss_test:0.10737, lr:6.11e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.976, tt:3500.313\n",
      "Ep:113, loss:0.00003, loss_test:0.10534, lr:6.05e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.982, tt:3531.937\n",
      "Ep:114, loss:0.00003, loss_test:0.10304, lr:5.99e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.985, tt:3563.224\n",
      "Ep:115, loss:0.00003, loss_test:0.10568, lr:5.93e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.968, tt:3592.346\n",
      "Ep:116, loss:0.00003, loss_test:0.10374, lr:5.87e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.939, tt:3619.889\n",
      "Ep:117, loss:0.00003, loss_test:0.10433, lr:5.81e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.947, tt:3651.804\n",
      "Ep:118, loss:0.00003, loss_test:0.10427, lr:5.75e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.945, tt:3682.487\n",
      "Ep:119, loss:0.00002, loss_test:0.10415, lr:5.70e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.947, tt:3713.686\n",
      "Ep:120, loss:0.00002, loss_test:0.10339, lr:5.64e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.938, tt:3743.517\n",
      "Ep:121, loss:0.00002, loss_test:0.10504, lr:5.58e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.930, tt:3773.439\n",
      "Ep:122, loss:0.00002, loss_test:0.10443, lr:5.53e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.909, tt:3801.786\n",
      "Ep:123, loss:0.00002, loss_test:0.10412, lr:5.47e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.914, tt:3833.373\n",
      "Ep:124, loss:0.00002, loss_test:0.10415, lr:5.42e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.907, tt:3863.333\n",
      "Ep:125, loss:0.00002, loss_test:0.10469, lr:5.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.903, tt:3893.745\n",
      "Ep:126, loss:0.00002, loss_test:0.10347, lr:5.31e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.917, tt:3926.412\n",
      "Ep:127, loss:0.00002, loss_test:0.10566, lr:5.26e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.922, tt:3958.048\n",
      "Ep:128, loss:0.00002, loss_test:0.10364, lr:5.20e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.925, tt:3989.299\n",
      "Ep:129, loss:0.00002, loss_test:0.10410, lr:5.15e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.924, tt:4020.126\n",
      "Ep:130, loss:0.00002, loss_test:0.10537, lr:5.10e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.911, tt:4049.353\n",
      "Ep:131, loss:0.00002, loss_test:0.10554, lr:5.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.914, tt:4080.709\n",
      "Ep:132, loss:0.00002, loss_test:0.10303, lr:5.00e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.922, tt:4112.657\n",
      "Ep:133, loss:0.00002, loss_test:0.10484, lr:4.95e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.930, tt:4144.632\n",
      "Ep:134, loss:0.00002, loss_test:0.10397, lr:4.90e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.924, tt:4174.804\n",
      "Ep:135, loss:0.00002, loss_test:0.10380, lr:4.85e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.925, tt:4205.843\n",
      "Ep:136, loss:0.00002, loss_test:0.10434, lr:4.80e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.924, tt:4236.619\n",
      "Ep:137, loss:0.00002, loss_test:0.10506, lr:4.75e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.920, tt:4266.965\n",
      "Ep:138, loss:0.00002, loss_test:0.10265, lr:4.71e-03, fs:0.75449 (r=0.636,p=0.926),  time:30.888, tt:4293.413\n",
      "Ep:139, loss:0.00002, loss_test:0.10598, lr:4.66e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.854, tt:4319.541\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"3-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,140,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00182, loss_test:0.12957, lr:1.00e-02, fs:0.62201 (r=0.657,p=0.591),  time:173.255, tt:173.255\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00150, loss_test:0.11528, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:204.971, tt:409.941\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00128, loss_test:0.10040, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:217.753, tt:653.259\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00112, loss_test:0.09426, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:222.739, tt:890.955\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00098, loss_test:0.08930, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:224.774, tt:1123.870\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00085, loss_test:0.08664, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:226.495, tt:1358.968\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00072, loss_test:0.08350, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:227.840, tt:1594.878\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00062, loss_test:0.08213, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:229.017, tt:1832.136\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00052, loss_test:0.08478, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:229.828, tt:2068.454\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.08802, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:230.476, tt:2304.764\n",
      "Ep:10, loss:0.00037, loss_test:0.08214, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:230.970, tt:2540.670\n",
      "Ep:11, loss:0.00032, loss_test:0.08577, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:231.573, tt:2778.878\n",
      "Ep:12, loss:0.00027, loss_test:0.08599, lr:1.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:232.292, tt:3019.793\n",
      "Ep:13, loss:0.00024, loss_test:0.08818, lr:1.00e-02, fs:0.75000 (r=0.606,p=0.984),  time:232.603, tt:3256.440\n",
      "Ep:14, loss:0.00021, loss_test:0.08838, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:232.645, tt:3489.674\n",
      "Ep:15, loss:0.00018, loss_test:0.09168, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:233.058, tt:3728.928\n",
      "Ep:16, loss:0.00016, loss_test:0.09492, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:233.148, tt:3963.521\n",
      "Ep:17, loss:0.00014, loss_test:0.09522, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:233.258, tt:4198.652\n",
      "Ep:18, loss:0.00013, loss_test:0.09566, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:233.391, tt:4434.431\n",
      "Ep:19, loss:0.00011, loss_test:0.09342, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:231.971, tt:4639.419\n",
      "Ep:20, loss:0.00010, loss_test:0.09834, lr:9.90e-03, fs:0.72611 (r=0.576,p=0.983),  time:231.082, tt:4852.712\n",
      "Ep:21, loss:0.00009, loss_test:0.10020, lr:9.80e-03, fs:0.73077 (r=0.576,p=1.000),  time:230.033, tt:5060.728\n",
      "Ep:22, loss:0.00008, loss_test:0.09952, lr:9.70e-03, fs:0.73077 (r=0.576,p=1.000),  time:229.327, tt:5274.512\n",
      "Ep:23, loss:0.00008, loss_test:0.10133, lr:9.61e-03, fs:0.73077 (r=0.576,p=1.000),  time:228.568, tt:5485.624\n",
      "Ep:24, loss:0.00007, loss_test:0.10107, lr:9.51e-03, fs:0.73077 (r=0.576,p=1.000),  time:227.957, tt:5698.926\n",
      "Ep:25, loss:0.00007, loss_test:0.10202, lr:9.41e-03, fs:0.73077 (r=0.576,p=1.000),  time:227.384, tt:5911.990\n",
      "Ep:26, loss:0.00006, loss_test:0.09833, lr:9.32e-03, fs:0.73077 (r=0.576,p=1.000),  time:226.673, tt:6120.170\n",
      "Ep:27, loss:0.00006, loss_test:0.10652, lr:9.23e-03, fs:0.73077 (r=0.576,p=1.000),  time:225.976, tt:6327.329\n",
      "Ep:28, loss:0.00005, loss_test:0.10334, lr:9.14e-03, fs:0.73077 (r=0.576,p=1.000),  time:225.507, tt:6539.696\n",
      "Ep:29, loss:0.00005, loss_test:0.10197, lr:9.04e-03, fs:0.73077 (r=0.576,p=1.000),  time:224.900, tt:6746.995\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=16,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,16,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.13784, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:79.894, tt:79.894\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00092, loss_test:0.11707, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:98.080, tt:196.160\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00082, loss_test:0.09975, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:103.793, tt:311.378\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00075, loss_test:0.09333, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:106.503, tt:426.012\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00068, loss_test:0.08804, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:108.312, tt:541.560\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00062, loss_test:0.08387, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:109.529, tt:657.174\n",
      "Ep:6, loss:0.00057, loss_test:0.08030, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:110.586, tt:774.105\n",
      "Ep:7, loss:0.00053, loss_test:0.07697, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:111.473, tt:891.787\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00049, loss_test:0.07426, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:112.064, tt:1008.579\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00045, loss_test:0.07184, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:112.675, tt:1126.746\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.06990, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:113.326, tt:1246.590\n",
      "Ep:11, loss:0.00038, loss_test:0.06873, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:113.724, tt:1364.682\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00035, loss_test:0.06715, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:114.140, tt:1483.824\n",
      "Ep:13, loss:0.00032, loss_test:0.06583, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:114.411, tt:1601.751\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.06482, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:114.608, tt:1719.116\n",
      "Ep:15, loss:0.00026, loss_test:0.06425, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:115.015, tt:1840.232\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.06224, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:115.320, tt:1960.433\n",
      "Ep:17, loss:0.00021, loss_test:0.06158, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:115.311, tt:2075.605\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.05991, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:115.600, tt:2196.409\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.05837, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:115.741, tt:2314.824\n",
      "Ep:20, loss:0.00016, loss_test:0.05858, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:115.689, tt:2429.479\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.05642, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:115.803, tt:2547.677\n",
      "Ep:22, loss:0.00014, loss_test:0.05773, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:115.822, tt:2663.900\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.05552, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:115.840, tt:2780.149\n",
      "Ep:24, loss:0.00012, loss_test:0.05648, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:115.932, tt:2898.300\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.05798, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:115.999, tt:3015.965\n",
      "Ep:26, loss:0.00010, loss_test:0.05561, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:115.917, tt:3129.757\n",
      "Ep:27, loss:0.00010, loss_test:0.05519, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:115.947, tt:3246.516\n",
      "Ep:28, loss:0.00009, loss_test:0.05750, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:116.051, tt:3365.491\n",
      "Ep:29, loss:0.00008, loss_test:0.05601, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:116.052, tt:3481.554\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.05769, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:116.036, tt:3597.105\n",
      "Ep:31, loss:0.00007, loss_test:0.05695, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:115.964, tt:3710.845\n",
      "Ep:32, loss:0.00007, loss_test:0.05795, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:115.937, tt:3825.928\n",
      "Ep:33, loss:0.00007, loss_test:0.05593, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:115.996, tt:3943.849\n",
      "Ep:34, loss:0.00006, loss_test:0.05688, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:115.929, tt:4057.501\n",
      "Ep:35, loss:0.00006, loss_test:0.05921, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:115.930, tt:4173.471\n",
      "Ep:36, loss:0.00006, loss_test:0.05746, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:115.998, tt:4291.923\n",
      "Ep:37, loss:0.00005, loss_test:0.05733, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:116.078, tt:4410.978\n",
      "Ep:38, loss:0.00005, loss_test:0.05852, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:116.094, tt:4527.678\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.05894, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:116.117, tt:4644.662\n",
      "Ep:40, loss:0.00004, loss_test:0.05971, lr:1.00e-02, fs:0.90909 (r=0.859,p=0.966),  time:116.147, tt:4762.035\n",
      "Ep:41, loss:0.00004, loss_test:0.05947, lr:1.00e-02, fs:0.91979 (r=0.869,p=0.977),  time:116.118, tt:4876.942\n",
      "Ep:43, loss:0.00004, loss_test:0.05965, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:116.025, tt:5105.100\n",
      "Ep:44, loss:0.00004, loss_test:0.06032, lr:1.00e-02, fs:0.91979 (r=0.869,p=0.977),  time:116.110, tt:5224.939\n",
      "Ep:45, loss:0.00003, loss_test:0.05929, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:116.079, tt:5339.637\n",
      "Ep:46, loss:0.00003, loss_test:0.06006, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:116.126, tt:5457.914\n",
      "Ep:47, loss:0.00003, loss_test:0.06282, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:116.151, tt:5575.245\n",
      "Ep:48, loss:0.00003, loss_test:0.06036, lr:1.00e-02, fs:0.91304 (r=0.848,p=0.988),  time:116.129, tt:5690.336\n",
      "Ep:49, loss:0.00003, loss_test:0.06287, lr:1.00e-02, fs:0.90000 (r=0.818,p=1.000),  time:116.180, tt:5809.023\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 4096: \n",
      "Ep:0, loss:0.00007, loss_test:0.14105, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.222, tt:11.222\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.14005, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.595, tt:31.190\n",
      "Ep:2, loss:0.00007, loss_test:0.13837, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:17.723, tt:53.168\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00007, loss_test:0.13574, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:20.550, tt:82.199\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00007, loss_test:0.13161, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:22.945, tt:114.725\n",
      "Ep:5, loss:0.00007, loss_test:0.12591, lr:1.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:24.659, tt:147.952\n",
      "Ep:6, loss:0.00006, loss_test:0.11775, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:26.464, tt:185.247\n",
      "Ep:7, loss:0.00006, loss_test:0.10793, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:27.105, tt:216.843\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00006, loss_test:0.10283, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:27.509, tt:247.583\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00006, loss_test:0.10142, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:28.127, tt:281.265\n",
      "Ep:10, loss:0.00006, loss_test:0.09983, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:28.511, tt:313.624\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00005, loss_test:0.09836, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:28.811, tt:345.730\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.09617, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:29.077, tt:377.996\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00005, loss_test:0.09420, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:29.202, tt:408.833\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00005, loss_test:0.09245, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:29.331, tt:439.959\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00005, loss_test:0.09084, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:29.449, tt:471.179\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00005, loss_test:0.08946, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:29.560, tt:502.516\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00005, loss_test:0.08850, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:29.720, tt:534.961\n",
      "Ep:18, loss:0.00005, loss_test:0.08732, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.839, tt:566.942\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.08567, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.790, tt:595.807\n",
      "Ep:20, loss:0.00004, loss_test:0.08427, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.821, tt:626.243\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.08338, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:29.909, tt:657.995\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.08243, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.041, tt:690.937\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.08138, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.129, tt:723.095\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.08043, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.215, tt:755.365\n",
      "Ep:25, loss:0.00004, loss_test:0.07978, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.311, tt:788.076\n",
      "Ep:26, loss:0.00004, loss_test:0.07882, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.304, tt:818.215\n",
      "Ep:27, loss:0.00004, loss_test:0.07769, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.399, tt:851.179\n",
      "Ep:28, loss:0.00004, loss_test:0.07693, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.499, tt:884.470\n",
      "Ep:29, loss:0.00004, loss_test:0.07632, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:30.515, tt:915.462\n",
      "Ep:30, loss:0.00004, loss_test:0.07559, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:30.585, tt:948.149\n",
      "Ep:31, loss:0.00003, loss_test:0.07476, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.535, tt:977.112\n",
      "Ep:32, loss:0.00003, loss_test:0.07457, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.442, tt:1004.583\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.07397, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.362, tt:1032.307\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.07319, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:30.331, tt:1061.585\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.07258, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.251, tt:1089.020\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.07199, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.184, tt:1116.803\n",
      "Ep:37, loss:0.00003, loss_test:0.07145, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:30.153, tt:1145.827\n",
      "Ep:38, loss:0.00003, loss_test:0.07100, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:30.086, tt:1173.366\n",
      "Ep:39, loss:0.00003, loss_test:0.07031, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.045, tt:1201.781\n",
      "Ep:40, loss:0.00003, loss_test:0.06985, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:29.975, tt:1228.964\n",
      "Ep:41, loss:0.00003, loss_test:0.06946, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:29.931, tt:1257.088\n",
      "Ep:42, loss:0.00003, loss_test:0.06891, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:29.842, tt:1283.216\n",
      "Ep:43, loss:0.00003, loss_test:0.06876, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.821, tt:1312.107\n",
      "Ep:44, loss:0.00003, loss_test:0.06836, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.796, tt:1340.814\n",
      "Ep:45, loss:0.00003, loss_test:0.06782, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.780, tt:1369.877\n",
      "Ep:46, loss:0.00003, loss_test:0.06769, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.674, tt:1394.697\n",
      "Ep:47, loss:0.00002, loss_test:0.06705, lr:9.90e-03, fs:0.83333 (r=0.808,p=0.860),  time:29.640, tt:1422.702\n",
      "Ep:48, loss:0.00002, loss_test:0.06705, lr:9.80e-03, fs:0.83333 (r=0.808,p=0.860),  time:29.638, tt:1452.271\n",
      "Ep:49, loss:0.00002, loss_test:0.06667, lr:9.70e-03, fs:0.83333 (r=0.808,p=0.860),  time:29.600, tt:1480.007\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=4096 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14438, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.966, tt:14.966\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14374, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.528, tt:35.056\n",
      "Ep:2, loss:0.00014, loss_test:0.14273, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.397, tt:64.192\n",
      "Ep:3, loss:0.00014, loss_test:0.14114, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:23.703, tt:94.811\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00014, loss_test:0.13871, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:25.336, tt:126.681\n",
      "Ep:5, loss:0.00013, loss_test:0.13523, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:26.567, tt:159.404\n",
      "Ep:6, loss:0.00013, loss_test:0.13075, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:27.080, tt:189.559\n",
      "Ep:7, loss:0.00012, loss_test:0.12550, lr:1.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:27.577, tt:220.619\n",
      "Ep:8, loss:0.00012, loss_test:0.12460, lr:1.00e-02, fs:0.62626 (r=0.626,p=0.626),  time:28.014, tt:252.130\n",
      "Ep:9, loss:0.00011, loss_test:0.12331, lr:1.00e-02, fs:0.65657 (r=0.657,p=0.657),  time:28.303, tt:283.025\n",
      "Ep:10, loss:0.00011, loss_test:0.12117, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:28.523, tt:313.752\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00011, loss_test:0.11896, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:28.788, tt:345.455\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00011, loss_test:0.11626, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:29.038, tt:377.493\n",
      "Ep:13, loss:0.00010, loss_test:0.11567, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:29.173, tt:408.424\n",
      "Ep:14, loss:0.00010, loss_test:0.11321, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:29.373, tt:440.599\n",
      "Ep:15, loss:0.00010, loss_test:0.11169, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:29.590, tt:473.446\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00009, loss_test:0.11161, lr:1.00e-02, fs:0.66310 (r=0.626,p=0.705),  time:29.734, tt:505.470\n",
      "Ep:17, loss:0.00009, loss_test:0.11153, lr:1.00e-02, fs:0.66298 (r=0.606,p=0.732),  time:29.752, tt:535.529\n",
      "Ep:18, loss:0.00009, loss_test:0.11017, lr:1.00e-02, fs:0.71204 (r=0.687,p=0.739),  time:29.853, tt:567.201\n",
      "Ep:19, loss:0.00009, loss_test:0.10908, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:29.883, tt:597.659\n",
      "Ep:20, loss:0.00008, loss_test:0.10827, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:30.033, tt:630.685\n",
      "Ep:21, loss:0.00008, loss_test:0.10758, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:30.061, tt:661.345\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.10702, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:30.110, tt:692.519\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00008, loss_test:0.10688, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:30.143, tt:723.436\n",
      "Ep:24, loss:0.00007, loss_test:0.10644, lr:1.00e-02, fs:0.69189 (r=0.646,p=0.744),  time:30.168, tt:754.195\n",
      "Ep:25, loss:0.00007, loss_test:0.10634, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:30.251, tt:786.534\n",
      "Ep:26, loss:0.00007, loss_test:0.10571, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:30.330, tt:818.922\n",
      "Ep:27, loss:0.00007, loss_test:0.10520, lr:1.00e-02, fs:0.69613 (r=0.636,p=0.768),  time:30.353, tt:849.888\n",
      "Ep:28, loss:0.00007, loss_test:0.10516, lr:1.00e-02, fs:0.68889 (r=0.626,p=0.765),  time:30.398, tt:881.555\n",
      "Ep:29, loss:0.00007, loss_test:0.10496, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:30.500, tt:915.010\n",
      "Ep:30, loss:0.00006, loss_test:0.10404, lr:1.00e-02, fs:0.69274 (r=0.626,p=0.775),  time:30.585, tt:948.135\n",
      "Ep:31, loss:0.00006, loss_test:0.10466, lr:1.00e-02, fs:0.69364 (r=0.606,p=0.811),  time:30.621, tt:979.883\n",
      "Ep:32, loss:0.00006, loss_test:0.10429, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:30.686, tt:1012.634\n",
      "Ep:33, loss:0.00006, loss_test:0.10401, lr:1.00e-02, fs:0.70520 (r=0.616,p=0.824),  time:30.708, tt:1044.077\n",
      "Ep:34, loss:0.00006, loss_test:0.10429, lr:9.90e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.727, tt:1075.448\n",
      "Ep:35, loss:0.00006, loss_test:0.10387, lr:9.80e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.717, tt:1105.796\n",
      "Ep:36, loss:0.00006, loss_test:0.10444, lr:9.70e-03, fs:0.69880 (r=0.586,p=0.866),  time:30.718, tt:1136.552\n",
      "Ep:37, loss:0.00005, loss_test:0.10314, lr:9.61e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.744, tt:1168.263\n",
      "Ep:38, loss:0.00005, loss_test:0.10369, lr:9.51e-03, fs:0.70659 (r=0.596,p=0.868),  time:30.767, tt:1199.893\n",
      "Ep:39, loss:0.00005, loss_test:0.10357, lr:9.41e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.790, tt:1231.608\n",
      "Ep:40, loss:0.00005, loss_test:0.10284, lr:9.32e-03, fs:0.71765 (r=0.616,p=0.859),  time:30.817, tt:1263.480\n",
      "Ep:41, loss:0.00005, loss_test:0.10388, lr:9.23e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.850, tt:1295.700\n",
      "Ep:42, loss:0.00005, loss_test:0.10411, lr:9.14e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.889, tt:1328.207\n",
      "Ep:43, loss:0.00005, loss_test:0.10369, lr:9.04e-03, fs:0.69512 (r=0.576,p=0.877),  time:30.920, tt:1360.468\n",
      "Ep:44, loss:0.00005, loss_test:0.10351, lr:8.95e-03, fs:0.70303 (r=0.586,p=0.879),  time:30.901, tt:1390.524\n",
      "Ep:45, loss:0.00004, loss_test:0.10512, lr:8.86e-03, fs:0.68354 (r=0.545,p=0.915),  time:30.904, tt:1421.580\n",
      "Ep:46, loss:0.00004, loss_test:0.10197, lr:8.78e-03, fs:0.69880 (r=0.586,p=0.866),  time:30.943, tt:1454.299\n",
      "Ep:47, loss:0.00004, loss_test:0.10558, lr:8.69e-03, fs:0.68790 (r=0.545,p=0.931),  time:30.939, tt:1485.066\n",
      "Ep:48, loss:0.00004, loss_test:0.10365, lr:8.60e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.948, tt:1516.438\n",
      "Ep:49, loss:0.00004, loss_test:0.10421, lr:8.51e-03, fs:0.70000 (r=0.566,p=0.918),  time:30.941, tt:1547.066\n",
      "Ep:50, loss:0.00004, loss_test:0.10400, lr:8.43e-03, fs:0.70000 (r=0.566,p=0.918),  time:30.931, tt:1577.479\n",
      "Ep:51, loss:0.00004, loss_test:0.10407, lr:8.35e-03, fs:0.70000 (r=0.566,p=0.918),  time:30.938, tt:1608.759\n",
      "Ep:52, loss:0.00004, loss_test:0.10503, lr:8.26e-03, fs:0.70886 (r=0.566,p=0.949),  time:30.939, tt:1639.774\n",
      "Ep:53, loss:0.00004, loss_test:0.10450, lr:8.18e-03, fs:0.70440 (r=0.566,p=0.933),  time:30.932, tt:1670.324\n",
      "Ep:54, loss:0.00004, loss_test:0.10472, lr:8.10e-03, fs:0.70886 (r=0.566,p=0.949),  time:30.957, tt:1702.615\n",
      "Ep:55, loss:0.00004, loss_test:0.10508, lr:8.02e-03, fs:0.70886 (r=0.566,p=0.949),  time:30.990, tt:1735.461\n",
      "Ep:56, loss:0.00004, loss_test:0.10313, lr:7.94e-03, fs:0.69565 (r=0.566,p=0.903),  time:31.014, tt:1767.777\n",
      "Ep:57, loss:0.00003, loss_test:0.10683, lr:7.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:31.032, tt:1799.865\n",
      "Ep:58, loss:0.00003, loss_test:0.10342, lr:7.78e-03, fs:0.70440 (r=0.566,p=0.933),  time:31.050, tt:1831.965\n",
      "Ep:59, loss:0.00003, loss_test:0.10580, lr:7.70e-03, fs:0.70886 (r=0.566,p=0.949),  time:31.082, tt:1864.896\n",
      "Ep:60, loss:0.00003, loss_test:0.10459, lr:7.62e-03, fs:0.70886 (r=0.566,p=0.949),  time:31.116, tt:1898.072\n",
      "Ep:61, loss:0.00003, loss_test:0.10354, lr:7.55e-03, fs:0.70440 (r=0.566,p=0.933),  time:31.116, tt:1929.168\n",
      "Ep:62, loss:0.00003, loss_test:0.10747, lr:7.47e-03, fs:0.70513 (r=0.556,p=0.965),  time:31.146, tt:1962.203\n",
      "Ep:63, loss:0.00003, loss_test:0.10310, lr:7.40e-03, fs:0.70440 (r=0.566,p=0.933),  time:31.167, tt:1994.690\n",
      "Ep:64, loss:0.00003, loss_test:0.10658, lr:7.32e-03, fs:0.71338 (r=0.566,p=0.966),  time:31.170, tt:2026.045\n",
      "Ep:65, loss:0.00003, loss_test:0.10522, lr:7.25e-03, fs:0.70886 (r=0.566,p=0.949),  time:31.171, tt:2057.291\n",
      "Ep:66, loss:0.00003, loss_test:0.10303, lr:7.18e-03, fs:0.70807 (r=0.576,p=0.919),  time:31.198, tt:2090.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00003, loss_test:0.10621, lr:7.11e-03, fs:0.69231 (r=0.545,p=0.947),  time:31.220, tt:2122.973\n",
      "Ep:68, loss:0.00003, loss_test:0.10284, lr:7.03e-03, fs:0.71250 (r=0.576,p=0.934),  time:31.247, tt:2156.056\n",
      "Ep:69, loss:0.00003, loss_test:0.10767, lr:6.96e-03, fs:0.70130 (r=0.545,p=0.982),  time:31.280, tt:2189.615\n",
      "Ep:70, loss:0.00003, loss_test:0.10502, lr:6.89e-03, fs:0.70064 (r=0.556,p=0.948),  time:31.313, tt:2223.205\n",
      "Ep:71, loss:0.00003, loss_test:0.10350, lr:6.83e-03, fs:0.71698 (r=0.576,p=0.950),  time:31.311, tt:2254.361\n",
      "Ep:72, loss:0.00003, loss_test:0.10824, lr:6.76e-03, fs:0.68421 (r=0.525,p=0.981),  time:31.339, tt:2287.716\n",
      "Ep:73, loss:0.00003, loss_test:0.10241, lr:6.69e-03, fs:0.71250 (r=0.576,p=0.934),  time:31.356, tt:2320.348\n",
      "Ep:74, loss:0.00003, loss_test:0.10675, lr:6.62e-03, fs:0.67974 (r=0.525,p=0.963),  time:31.375, tt:2353.111\n",
      "Ep:75, loss:0.00002, loss_test:0.10575, lr:6.56e-03, fs:0.68387 (r=0.535,p=0.946),  time:31.408, tt:2387.029\n",
      "Ep:76, loss:0.00002, loss_test:0.10411, lr:6.49e-03, fs:0.70886 (r=0.566,p=0.949),  time:31.459, tt:2422.381\n",
      "Ep:77, loss:0.00002, loss_test:0.10777, lr:6.43e-03, fs:0.68421 (r=0.525,p=0.981),  time:31.488, tt:2456.027\n",
      "Ep:78, loss:0.00002, loss_test:0.10408, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:31.505, tt:2488.897\n",
      "Ep:79, loss:0.00002, loss_test:0.10705, lr:6.30e-03, fs:0.68421 (r=0.525,p=0.981),  time:31.545, tt:2523.568\n",
      "Ep:80, loss:0.00002, loss_test:0.10517, lr:6.24e-03, fs:0.68831 (r=0.535,p=0.964),  time:31.552, tt:2555.699\n",
      "Ep:81, loss:0.00002, loss_test:0.10703, lr:6.17e-03, fs:0.69281 (r=0.535,p=0.981),  time:31.576, tt:2589.246\n",
      "Ep:82, loss:0.00002, loss_test:0.10591, lr:6.11e-03, fs:0.68831 (r=0.535,p=0.964),  time:31.591, tt:2622.077\n",
      "Ep:83, loss:0.00002, loss_test:0.10527, lr:6.05e-03, fs:0.68831 (r=0.535,p=0.964),  time:31.618, tt:2655.933\n",
      "Ep:84, loss:0.00002, loss_test:0.10785, lr:5.99e-03, fs:0.69737 (r=0.535,p=1.000),  time:31.624, tt:2688.076\n",
      "Ep:85, loss:0.00002, loss_test:0.10546, lr:5.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:31.632, tt:2720.393\n",
      "Ep:86, loss:0.00002, loss_test:0.10780, lr:5.87e-03, fs:0.68874 (r=0.525,p=1.000),  time:31.640, tt:2752.664\n",
      "Ep:87, loss:0.00002, loss_test:0.10768, lr:5.81e-03, fs:0.69281 (r=0.535,p=0.981),  time:31.651, tt:2785.276\n",
      "Ep:88, loss:0.00002, loss_test:0.10625, lr:5.75e-03, fs:0.68831 (r=0.535,p=0.964),  time:31.666, tt:2818.291\n",
      "Ep:89, loss:0.00002, loss_test:0.10799, lr:5.70e-03, fs:0.68874 (r=0.525,p=1.000),  time:31.673, tt:2850.551\n",
      "Ep:90, loss:0.00002, loss_test:0.10646, lr:5.64e-03, fs:0.69281 (r=0.535,p=0.981),  time:31.688, tt:2883.610\n",
      "Ep:91, loss:0.00002, loss_test:0.10818, lr:5.58e-03, fs:0.68000 (r=0.515,p=1.000),  time:31.714, tt:2917.718\n",
      "Ep:92, loss:0.00002, loss_test:0.10547, lr:5.53e-03, fs:0.69281 (r=0.535,p=0.981),  time:31.720, tt:2949.916\n",
      "Ep:93, loss:0.00002, loss_test:0.10677, lr:5.47e-03, fs:0.68421 (r=0.525,p=0.981),  time:31.737, tt:2983.283\n",
      "Ep:94, loss:0.00002, loss_test:0.10678, lr:5.42e-03, fs:0.68874 (r=0.525,p=1.000),  time:31.753, tt:3016.512\n",
      "Ep:95, loss:0.00002, loss_test:0.10692, lr:5.36e-03, fs:0.68874 (r=0.525,p=1.000),  time:31.770, tt:3049.966\n",
      "Ep:96, loss:0.00002, loss_test:0.10772, lr:5.31e-03, fs:0.68000 (r=0.515,p=1.000),  time:31.776, tt:3082.254\n",
      "Ep:97, loss:0.00002, loss_test:0.10618, lr:5.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:31.789, tt:3115.361\n",
      "Ep:98, loss:0.00002, loss_test:0.10889, lr:5.20e-03, fs:0.68000 (r=0.515,p=1.000),  time:31.811, tt:3149.256\n",
      "Ep:99, loss:0.00002, loss_test:0.10614, lr:5.15e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.830, tt:3183.015\n",
      "Ep:100, loss:0.00002, loss_test:0.10732, lr:5.10e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.850, tt:3216.846\n",
      "Ep:101, loss:0.00002, loss_test:0.10768, lr:5.05e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.863, tt:3249.998\n",
      "Ep:102, loss:0.00002, loss_test:0.10637, lr:5.00e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.881, tt:3283.713\n",
      "Ep:103, loss:0.00002, loss_test:0.10805, lr:4.95e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.885, tt:3316.008\n",
      "Ep:104, loss:0.00002, loss_test:0.10663, lr:4.90e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.883, tt:3347.724\n",
      "Ep:105, loss:0.00002, loss_test:0.10809, lr:4.85e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.901, tt:3381.516\n",
      "Ep:106, loss:0.00002, loss_test:0.10568, lr:4.80e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.909, tt:3414.244\n",
      "Ep:107, loss:0.00002, loss_test:0.10910, lr:4.75e-03, fs:0.66667 (r=0.505,p=0.980),  time:31.925, tt:3447.928\n",
      "Ep:108, loss:0.00002, loss_test:0.10804, lr:4.71e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.921, tt:3479.361\n",
      "Ep:109, loss:0.00002, loss_test:0.10500, lr:4.66e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.926, tt:3511.892\n",
      "Ep:110, loss:0.00001, loss_test:0.10908, lr:4.61e-03, fs:0.66667 (r=0.505,p=0.980),  time:31.939, tt:3545.200\n",
      "Ep:111, loss:0.00001, loss_test:0.10494, lr:4.57e-03, fs:0.67105 (r=0.515,p=0.962),  time:31.955, tt:3578.917\n",
      "Ep:112, loss:0.00001, loss_test:0.10854, lr:4.52e-03, fs:0.66667 (r=0.505,p=0.980),  time:31.961, tt:3611.616\n",
      "Ep:113, loss:0.00001, loss_test:0.10658, lr:4.48e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.971, tt:3644.671\n",
      "Ep:114, loss:0.00001, loss_test:0.10590, lr:4.43e-03, fs:0.67550 (r=0.515,p=0.981),  time:31.980, tt:3677.682\n",
      "Ep:115, loss:0.00001, loss_test:0.10980, lr:4.39e-03, fs:0.66667 (r=0.505,p=0.980),  time:31.990, tt:3710.836\n",
      "Ep:116, loss:0.00001, loss_test:0.10304, lr:4.34e-03, fs:0.67105 (r=0.515,p=0.962),  time:32.002, tt:3744.262\n",
      "Ep:117, loss:0.00001, loss_test:0.10947, lr:4.30e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.040, tt:3780.733\n",
      "Ep:118, loss:0.00001, loss_test:0.10743, lr:4.26e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.061, tt:3815.280\n",
      "Ep:119, loss:0.00001, loss_test:0.10475, lr:4.21e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.063, tt:3847.600\n",
      "Ep:120, loss:0.00001, loss_test:0.10926, lr:4.17e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.065, tt:3879.874\n",
      "Ep:121, loss:0.00001, loss_test:0.10525, lr:4.13e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.071, tt:3912.662\n",
      "Ep:122, loss:0.00001, loss_test:0.10683, lr:4.09e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.074, tt:3945.073\n",
      "Ep:123, loss:0.00001, loss_test:0.10978, lr:4.05e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.080, tt:3977.880\n",
      "Ep:124, loss:0.00001, loss_test:0.10429, lr:4.01e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.099, tt:4012.339\n",
      "Ep:125, loss:0.00001, loss_test:0.10786, lr:3.97e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.115, tt:4046.474\n",
      "Ep:126, loss:0.00001, loss_test:0.10702, lr:3.93e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.118, tt:4078.945\n",
      "Ep:127, loss:0.00001, loss_test:0.10477, lr:3.89e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.123, tt:4111.788\n",
      "Ep:128, loss:0.00001, loss_test:0.10862, lr:3.85e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.129, tt:4144.603\n",
      "Ep:129, loss:0.00001, loss_test:0.10460, lr:3.81e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.139, tt:4178.058\n",
      "Ep:130, loss:0.00001, loss_test:0.10633, lr:3.77e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.154, tt:4212.120\n",
      "Ep:131, loss:0.00001, loss_test:0.10779, lr:3.73e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.165, tt:4245.775\n",
      "Ep:132, loss:0.00001, loss_test:0.10528, lr:3.70e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.166, tt:4278.019\n",
      "Ep:133, loss:0.00001, loss_test:0.10725, lr:3.66e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.178, tt:4311.901\n",
      "Ep:134, loss:0.00001, loss_test:0.10475, lr:3.62e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.188, tt:4345.360\n",
      "Ep:135, loss:0.00001, loss_test:0.10725, lr:3.59e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.186, tt:4377.311\n",
      "Ep:136, loss:0.00001, loss_test:0.10720, lr:3.55e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.195, tt:4410.663\n",
      "Ep:137, loss:0.00001, loss_test:0.10420, lr:3.52e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.200, tt:4443.539\n",
      "Ep:138, loss:0.00001, loss_test:0.10770, lr:3.48e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.223, tt:4478.934\n",
      "Ep:139, loss:0.00001, loss_test:0.10641, lr:3.45e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.222, tt:4511.109\n",
      "Ep:140, loss:0.00001, loss_test:0.10534, lr:3.41e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.222, tt:4543.328\n",
      "Ep:141, loss:0.00001, loss_test:0.10674, lr:3.38e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.233, tt:4577.051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.10494, lr:3.34e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.231, tt:4609.019\n",
      "Ep:143, loss:0.00001, loss_test:0.10572, lr:3.31e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.227, tt:4640.667\n",
      "Ep:144, loss:0.00001, loss_test:0.10597, lr:3.28e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.234, tt:4673.886\n",
      "Ep:145, loss:0.00001, loss_test:0.10550, lr:3.24e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.245, tt:4707.719\n",
      "Ep:146, loss:0.00001, loss_test:0.10619, lr:3.21e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.253, tt:4741.238\n",
      "Ep:147, loss:0.00001, loss_test:0.10639, lr:3.18e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.266, tt:4775.405\n",
      "Ep:148, loss:0.00001, loss_test:0.10458, lr:3.15e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.270, tt:4808.249\n",
      "Ep:149, loss:0.00001, loss_test:0.10688, lr:3.12e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.277, tt:4841.571\n",
      "Ep:150, loss:0.00001, loss_test:0.10522, lr:3.09e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.280, tt:4874.322\n",
      "Ep:151, loss:0.00001, loss_test:0.10610, lr:3.05e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.285, tt:4907.328\n",
      "Ep:152, loss:0.00001, loss_test:0.10641, lr:3.02e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.296, tt:4941.303\n",
      "Ep:153, loss:0.00001, loss_test:0.10529, lr:2.99e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.293, tt:4973.081\n",
      "Ep:154, loss:0.00001, loss_test:0.10630, lr:2.96e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.294, tt:5005.593\n",
      "Ep:155, loss:0.00001, loss_test:0.10609, lr:2.93e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.303, tt:5039.296\n",
      "Ep:156, loss:0.00001, loss_test:0.10537, lr:2.90e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.306, tt:5072.040\n",
      "Ep:157, loss:0.00001, loss_test:0.10674, lr:2.88e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.314, tt:5105.651\n",
      "Ep:158, loss:0.00001, loss_test:0.10520, lr:2.85e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.319, tt:5138.691\n",
      "Ep:159, loss:0.00001, loss_test:0.10589, lr:2.82e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.332, tt:5173.095\n",
      "Ep:160, loss:0.00001, loss_test:0.10587, lr:2.79e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.324, tt:5204.206\n",
      "Ep:161, loss:0.00001, loss_test:0.10543, lr:2.76e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.333, tt:5237.906\n",
      "Ep:162, loss:0.00001, loss_test:0.10601, lr:2.73e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.335, tt:5270.641\n",
      "Ep:163, loss:0.00001, loss_test:0.10569, lr:2.71e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.342, tt:5304.164\n",
      "Ep:164, loss:0.00001, loss_test:0.10551, lr:2.68e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.344, tt:5336.787\n",
      "Ep:165, loss:0.00001, loss_test:0.10578, lr:2.65e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.341, tt:5368.591\n",
      "Ep:166, loss:0.00001, loss_test:0.10617, lr:2.63e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.348, tt:5402.061\n",
      "Ep:167, loss:0.00001, loss_test:0.10541, lr:2.60e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.358, tt:5436.159\n",
      "Ep:168, loss:0.00001, loss_test:0.10610, lr:2.57e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.370, tt:5470.497\n",
      "Ep:169, loss:0.00001, loss_test:0.10538, lr:2.55e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.366, tt:5502.225\n",
      "Ep:170, loss:0.00001, loss_test:0.10530, lr:2.52e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.361, tt:5533.780\n",
      "Ep:171, loss:0.00001, loss_test:0.10616, lr:2.50e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.365, tt:5566.802\n",
      "Ep:172, loss:0.00001, loss_test:0.10498, lr:2.47e-03, fs:0.67550 (r=0.515,p=0.981),  time:32.367, tt:5599.505\n",
      "Ep:173, loss:0.00001, loss_test:0.10598, lr:2.45e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.374, tt:5633.080\n",
      "Ep:174, loss:0.00001, loss_test:0.10604, lr:2.42e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.398, tt:5669.671\n",
      "Ep:175, loss:0.00001, loss_test:0.10539, lr:2.40e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.405, tt:5703.195\n",
      "Ep:176, loss:0.00001, loss_test:0.10589, lr:2.38e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.396, tt:5734.091\n",
      "Ep:177, loss:0.00001, loss_test:0.10611, lr:2.35e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.391, tt:5765.554\n",
      "Ep:178, loss:0.00001, loss_test:0.10603, lr:2.33e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.391, tt:5798.062\n",
      "Ep:179, loss:0.00001, loss_test:0.10539, lr:2.31e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.388, tt:5829.843\n",
      "Ep:180, loss:0.00001, loss_test:0.10590, lr:2.28e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.389, tt:5862.494\n",
      "Ep:181, loss:0.00001, loss_test:0.10586, lr:2.26e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.388, tt:5894.636\n",
      "Ep:182, loss:0.00001, loss_test:0.10606, lr:2.24e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.389, tt:5927.267\n",
      "Ep:183, loss:0.00001, loss_test:0.10573, lr:2.21e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.388, tt:5959.477\n",
      "Ep:184, loss:0.00001, loss_test:0.10558, lr:2.19e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.389, tt:5992.047\n",
      "Ep:185, loss:0.00001, loss_test:0.10596, lr:2.17e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.393, tt:6025.013\n",
      "Ep:186, loss:0.00001, loss_test:0.10608, lr:2.15e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.389, tt:6056.668\n",
      "Ep:187, loss:0.00001, loss_test:0.10578, lr:2.13e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.396, tt:6090.356\n",
      "Ep:188, loss:0.00001, loss_test:0.10608, lr:2.11e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.396, tt:6122.783\n",
      "Ep:189, loss:0.00001, loss_test:0.10626, lr:2.08e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.396, tt:6155.185\n",
      "Ep:190, loss:0.00001, loss_test:0.10591, lr:2.06e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.395, tt:6187.356\n",
      "Ep:191, loss:0.00001, loss_test:0.10629, lr:2.04e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.389, tt:6218.647\n",
      "Ep:192, loss:0.00001, loss_test:0.10637, lr:2.02e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.380, tt:6249.434\n",
      "Ep:193, loss:0.00001, loss_test:0.10573, lr:2.00e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.387, tt:6282.998\n",
      "Ep:194, loss:0.00001, loss_test:0.10664, lr:1.98e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.376, tt:6313.325\n",
      "Ep:195, loss:0.00001, loss_test:0.10625, lr:1.96e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.388, tt:6348.048\n",
      "Ep:196, loss:0.00001, loss_test:0.10603, lr:1.94e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.385, tt:6379.883\n",
      "Ep:197, loss:0.00001, loss_test:0.10623, lr:1.92e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.383, tt:6411.850\n",
      "Ep:198, loss:0.00001, loss_test:0.10647, lr:1.90e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.383, tt:6444.127\n",
      "Ep:199, loss:0.00001, loss_test:0.10595, lr:1.89e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.378, tt:6475.594\n",
      "Ep:200, loss:0.00001, loss_test:0.10692, lr:1.87e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.373, tt:6506.945\n",
      "Ep:201, loss:0.00001, loss_test:0.10678, lr:1.85e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.372, tt:6539.228\n",
      "Ep:202, loss:0.00001, loss_test:0.10602, lr:1.83e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.371, tt:6571.267\n",
      "Ep:203, loss:0.00001, loss_test:0.10674, lr:1.81e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.347, tt:6598.861\n",
      "Ep:204, loss:0.00001, loss_test:0.10706, lr:1.79e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.323, tt:6626.251\n",
      "Ep:205, loss:0.00001, loss_test:0.10587, lr:1.78e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.303, tt:6654.319\n",
      "Ep:206, loss:0.00001, loss_test:0.10636, lr:1.76e-03, fs:0.66667 (r=0.505,p=0.980),  time:32.286, tt:6683.239\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14356, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.151, tt:17.151\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14277, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.830, tt:47.660\n",
      "Ep:2, loss:0.00014, loss_test:0.14140, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.542, tt:79.625\n",
      "Ep:3, loss:0.00014, loss_test:0.13926, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:27.456, tt:109.825\n",
      "Ep:4, loss:0.00013, loss_test:0.13593, lr:1.00e-02, fs:0.63860 (r=0.919,p=0.489),  time:28.290, tt:141.448\n",
      "Ep:5, loss:0.00013, loss_test:0.13090, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:28.633, tt:171.799\n",
      "Ep:6, loss:0.00012, loss_test:0.12439, lr:1.00e-02, fs:0.63519 (r=0.747,p=0.552),  time:29.081, tt:203.566\n",
      "Ep:7, loss:0.00011, loss_test:0.12176, lr:1.00e-02, fs:0.61765 (r=0.636,p=0.600),  time:29.507, tt:236.056\n",
      "Ep:8, loss:0.00011, loss_test:0.12135, lr:1.00e-02, fs:0.62766 (r=0.596,p=0.663),  time:29.717, tt:267.457\n",
      "Ep:9, loss:0.00011, loss_test:0.11920, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:29.902, tt:299.015\n",
      "Ep:10, loss:0.00010, loss_test:0.11859, lr:1.00e-02, fs:0.62673 (r=0.687,p=0.576),  time:30.034, tt:330.370\n",
      "Ep:11, loss:0.00010, loss_test:0.11644, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:30.174, tt:362.086\n",
      "Ep:12, loss:0.00010, loss_test:0.11534, lr:9.90e-03, fs:0.65625 (r=0.636,p=0.677),  time:30.203, tt:392.644\n",
      "Ep:13, loss:0.00009, loss_test:0.11411, lr:9.80e-03, fs:0.65979 (r=0.646,p=0.674),  time:30.268, tt:423.747\n",
      "Ep:14, loss:0.00009, loss_test:0.11346, lr:9.70e-03, fs:0.65686 (r=0.677,p=0.638),  time:30.385, tt:455.770\n",
      "Ep:15, loss:0.00009, loss_test:0.11232, lr:9.61e-03, fs:0.66019 (r=0.687,p=0.636),  time:30.516, tt:488.253\n",
      "Ep:16, loss:0.00009, loss_test:0.11125, lr:9.51e-03, fs:0.68718 (r=0.677,p=0.698),  time:30.565, tt:519.600\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.11077, lr:9.51e-03, fs:0.68394 (r=0.667,p=0.702),  time:30.666, tt:551.994\n",
      "Ep:18, loss:0.00008, loss_test:0.11010, lr:9.51e-03, fs:0.69036 (r=0.687,p=0.694),  time:30.648, tt:582.305\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.10903, lr:9.51e-03, fs:0.68687 (r=0.687,p=0.687),  time:30.707, tt:614.134\n",
      "Ep:20, loss:0.00008, loss_test:0.10791, lr:9.51e-03, fs:0.70769 (r=0.697,p=0.719),  time:30.722, tt:645.161\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.10667, lr:9.51e-03, fs:0.70103 (r=0.687,p=0.716),  time:30.854, tt:678.781\n",
      "Ep:22, loss:0.00007, loss_test:0.10553, lr:9.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:30.914, tt:711.032\n",
      "Ep:23, loss:0.00007, loss_test:0.10466, lr:9.51e-03, fs:0.70707 (r=0.707,p=0.707),  time:30.991, tt:743.789\n",
      "Ep:24, loss:0.00007, loss_test:0.10332, lr:9.51e-03, fs:0.71066 (r=0.707,p=0.714),  time:31.054, tt:776.344\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.10220, lr:9.51e-03, fs:0.71429 (r=0.707,p=0.722),  time:31.108, tt:808.802\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.10129, lr:9.51e-03, fs:0.71642 (r=0.727,p=0.706),  time:31.138, tt:840.717\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.10032, lr:9.51e-03, fs:0.71717 (r=0.717,p=0.717),  time:31.275, tt:875.710\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.09954, lr:9.51e-03, fs:0.72821 (r=0.717,p=0.740),  time:31.366, tt:909.600\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00006, loss_test:0.09869, lr:9.51e-03, fs:0.71357 (r=0.717,p=0.710),  time:31.403, tt:942.085\n",
      "Ep:30, loss:0.00006, loss_test:0.09827, lr:9.51e-03, fs:0.72727 (r=0.727,p=0.727),  time:31.453, tt:975.052\n",
      "Ep:31, loss:0.00006, loss_test:0.09770, lr:9.51e-03, fs:0.74227 (r=0.727,p=0.758),  time:31.485, tt:1007.527\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.09693, lr:9.51e-03, fs:0.74490 (r=0.737,p=0.753),  time:31.493, tt:1039.261\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.09647, lr:9.51e-03, fs:0.75622 (r=0.768,p=0.745),  time:31.530, tt:1072.004\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.09555, lr:9.51e-03, fs:0.75510 (r=0.747,p=0.763),  time:31.549, tt:1104.222\n",
      "Ep:35, loss:0.00006, loss_test:0.09478, lr:9.51e-03, fs:0.76768 (r=0.768,p=0.768),  time:31.551, tt:1135.845\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00005, loss_test:0.09441, lr:9.51e-03, fs:0.77157 (r=0.768,p=0.776),  time:31.547, tt:1167.257\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.09369, lr:9.51e-03, fs:0.77551 (r=0.768,p=0.784),  time:31.561, tt:1199.310\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.09259, lr:9.51e-03, fs:0.78173 (r=0.778,p=0.786),  time:31.611, tt:1232.842\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.09250, lr:9.51e-03, fs:0.78173 (r=0.778,p=0.786),  time:31.642, tt:1265.690\n",
      "Ep:40, loss:0.00005, loss_test:0.09174, lr:9.51e-03, fs:0.79188 (r=0.788,p=0.796),  time:31.690, tt:1299.277\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.09059, lr:9.51e-03, fs:0.79188 (r=0.788,p=0.796),  time:31.705, tt:1331.610\n",
      "Ep:42, loss:0.00005, loss_test:0.09042, lr:9.51e-03, fs:0.80000 (r=0.788,p=0.812),  time:31.722, tt:1364.037\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.08947, lr:9.51e-03, fs:0.80000 (r=0.788,p=0.812),  time:31.749, tt:1396.943\n",
      "Ep:44, loss:0.00005, loss_test:0.08886, lr:9.51e-03, fs:0.80612 (r=0.798,p=0.814),  time:31.787, tt:1430.422\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.08813, lr:9.51e-03, fs:0.80829 (r=0.788,p=0.830),  time:31.791, tt:1462.395\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.08790, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.798, tt:1494.512\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.08701, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.830, tt:1527.851\n",
      "Ep:48, loss:0.00004, loss_test:0.08647, lr:9.51e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.861, tt:1561.202\n",
      "Ep:49, loss:0.00004, loss_test:0.08586, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.891, tt:1594.561\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.08459, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.925, tt:1628.159\n",
      "Ep:51, loss:0.00004, loss_test:0.08461, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.958, tt:1661.836\n",
      "Ep:52, loss:0.00004, loss_test:0.08349, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.997, tt:1695.821\n",
      "Ep:53, loss:0.00004, loss_test:0.08341, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:32.033, tt:1729.765\n",
      "Ep:54, loss:0.00004, loss_test:0.08222, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:32.046, tt:1762.508\n",
      "Ep:55, loss:0.00004, loss_test:0.08224, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:32.041, tt:1794.288\n",
      "Ep:56, loss:0.00003, loss_test:0.08168, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:32.050, tt:1826.831\n",
      "Ep:57, loss:0.00003, loss_test:0.08104, lr:9.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:32.055, tt:1859.174\n",
      "Ep:58, loss:0.00003, loss_test:0.08054, lr:9.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:32.056, tt:1891.327\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.08063, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:32.062, tt:1923.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.07935, lr:9.51e-03, fs:0.82979 (r=0.788,p=0.876),  time:32.073, tt:1956.458\n",
      "Ep:61, loss:0.00003, loss_test:0.08071, lr:9.51e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.085, tt:1989.260\n",
      "Ep:62, loss:0.00003, loss_test:0.07884, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:32.102, tt:2022.451\n",
      "Ep:63, loss:0.00003, loss_test:0.07964, lr:9.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.132, tt:2056.462\n",
      "Ep:64, loss:0.00003, loss_test:0.07865, lr:9.51e-03, fs:0.82796 (r=0.778,p=0.885),  time:32.141, tt:2089.174\n",
      "Ep:65, loss:0.00003, loss_test:0.07911, lr:9.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.123, tt:2120.101\n",
      "Ep:66, loss:0.00003, loss_test:0.07855, lr:9.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.149, tt:2153.960\n",
      "Ep:67, loss:0.00003, loss_test:0.07985, lr:9.51e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.159, tt:2186.832\n",
      "Ep:68, loss:0.00003, loss_test:0.07850, lr:9.51e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.196, tt:2221.542\n",
      "Ep:69, loss:0.00003, loss_test:0.07907, lr:9.51e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.206, tt:2254.449\n",
      "Ep:70, loss:0.00003, loss_test:0.07844, lr:9.41e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.199, tt:2286.140\n",
      "Ep:71, loss:0.00002, loss_test:0.07850, lr:9.32e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.203, tt:2318.612\n",
      "Ep:72, loss:0.00002, loss_test:0.07846, lr:9.23e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.215, tt:2351.715\n",
      "Ep:73, loss:0.00002, loss_test:0.07781, lr:9.14e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.221, tt:2384.322\n",
      "Ep:74, loss:0.00002, loss_test:0.07779, lr:9.04e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.227, tt:2416.997\n",
      "Ep:75, loss:0.00002, loss_test:0.07820, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.235, tt:2449.853\n",
      "Ep:76, loss:0.00002, loss_test:0.07729, lr:8.86e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.233, tt:2481.938\n",
      "Ep:77, loss:0.00002, loss_test:0.07702, lr:8.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.245, tt:2515.134\n",
      "Ep:78, loss:0.00002, loss_test:0.07720, lr:8.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.253, tt:2547.981\n",
      "Ep:79, loss:0.00002, loss_test:0.07667, lr:8.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.259, tt:2580.681\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.07672, lr:8.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.268, tt:2613.703\n",
      "Ep:81, loss:0.00002, loss_test:0.07639, lr:8.60e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.292, tt:2647.958\n",
      "Ep:82, loss:0.00002, loss_test:0.07643, lr:8.60e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.303, tt:2681.133\n",
      "Ep:83, loss:0.00002, loss_test:0.07561, lr:8.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.317, tt:2714.653\n",
      "Ep:84, loss:0.00002, loss_test:0.07631, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.304, tt:2745.853\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.07536, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.328, tt:2780.206\n",
      "Ep:86, loss:0.00002, loss_test:0.07518, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.338, tt:2813.405\n",
      "Ep:87, loss:0.00002, loss_test:0.07474, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.334, tt:2845.349\n",
      "Ep:88, loss:0.00002, loss_test:0.07538, lr:8.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.337, tt:2877.984\n",
      "Ep:89, loss:0.00002, loss_test:0.07403, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.371, tt:2913.364\n",
      "Ep:90, loss:0.00002, loss_test:0.07511, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.381, tt:2946.703\n",
      "Ep:91, loss:0.00002, loss_test:0.07436, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.375, tt:2978.510\n",
      "Ep:92, loss:0.00002, loss_test:0.07362, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.371, tt:3010.505\n",
      "Ep:93, loss:0.00002, loss_test:0.07419, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.369, tt:3042.732\n",
      "Ep:94, loss:0.00002, loss_test:0.07330, lr:8.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.383, tt:3076.375\n",
      "Ep:95, loss:0.00002, loss_test:0.07386, lr:8.60e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.393, tt:3109.714\n",
      "Ep:96, loss:0.00001, loss_test:0.07366, lr:8.51e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.387, tt:3141.521\n",
      "Ep:97, loss:0.00001, loss_test:0.07347, lr:8.43e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.404, tt:3175.640\n",
      "Ep:98, loss:0.00001, loss_test:0.07269, lr:8.35e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.406, tt:3208.167\n",
      "Ep:99, loss:0.00001, loss_test:0.07395, lr:8.26e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.421, tt:3242.067\n",
      "Ep:100, loss:0.00001, loss_test:0.07267, lr:8.18e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.410, tt:3273.372\n",
      "Ep:101, loss:0.00001, loss_test:0.07310, lr:8.10e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.419, tt:3306.711\n",
      "Ep:102, loss:0.00001, loss_test:0.07260, lr:8.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.421, tt:3339.338\n",
      "Ep:103, loss:0.00001, loss_test:0.07300, lr:7.94e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.415, tt:3371.205\n",
      "Ep:104, loss:0.00001, loss_test:0.07249, lr:7.86e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.416, tt:3403.716\n",
      "Ep:105, loss:0.00001, loss_test:0.07253, lr:7.78e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.416, tt:3436.091\n",
      "Ep:106, loss:0.00001, loss_test:0.07291, lr:7.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.414, tt:3468.250\n",
      "Ep:107, loss:0.00001, loss_test:0.07212, lr:7.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.407, tt:3499.974\n",
      "Ep:108, loss:0.00001, loss_test:0.07241, lr:7.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.394, tt:3530.926\n",
      "Ep:109, loss:0.00001, loss_test:0.07226, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.398, tt:3563.795\n",
      "Ep:110, loss:0.00001, loss_test:0.07192, lr:7.40e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.396, tt:3595.902\n",
      "Ep:111, loss:0.00001, loss_test:0.07213, lr:7.32e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.407, tt:3629.625\n",
      "Ep:112, loss:0.00001, loss_test:0.07211, lr:7.25e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.411, tt:3662.436\n",
      "Ep:113, loss:0.00001, loss_test:0.07203, lr:7.18e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.406, tt:3694.337\n",
      "Ep:114, loss:0.00001, loss_test:0.07178, lr:7.11e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.417, tt:3727.992\n",
      "Ep:115, loss:0.00001, loss_test:0.07206, lr:7.03e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.419, tt:3760.596\n",
      "Ep:116, loss:0.00001, loss_test:0.07238, lr:6.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.428, tt:3794.054\n",
      "Ep:117, loss:0.00001, loss_test:0.07207, lr:6.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.435, tt:3827.314\n",
      "Ep:118, loss:0.00001, loss_test:0.07184, lr:6.83e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.439, tt:3860.281\n",
      "Ep:119, loss:0.00001, loss_test:0.07152, lr:6.76e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.432, tt:3891.815\n",
      "Ep:120, loss:0.00001, loss_test:0.07178, lr:6.69e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.435, tt:3924.668\n",
      "Ep:121, loss:0.00001, loss_test:0.07207, lr:6.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.440, tt:3957.704\n",
      "Ep:122, loss:0.00001, loss_test:0.07122, lr:6.56e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.437, tt:3989.692\n",
      "Ep:123, loss:0.00001, loss_test:0.07213, lr:6.49e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.436, tt:4022.031\n",
      "Ep:124, loss:0.00001, loss_test:0.07158, lr:6.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.435, tt:4054.395\n",
      "Ep:125, loss:0.00001, loss_test:0.07193, lr:6.36e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.434, tt:4086.702\n",
      "Ep:126, loss:0.00001, loss_test:0.07219, lr:6.30e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.443, tt:4120.290\n",
      "Ep:127, loss:0.00001, loss_test:0.07199, lr:6.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.437, tt:4151.943\n",
      "Ep:128, loss:0.00001, loss_test:0.07127, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.438, tt:4184.559\n",
      "Ep:129, loss:0.00001, loss_test:0.07198, lr:6.11e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.439, tt:4217.046\n",
      "Ep:130, loss:0.00001, loss_test:0.07131, lr:6.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.442, tt:4249.876\n",
      "Ep:131, loss:0.00001, loss_test:0.07172, lr:5.99e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.443, tt:4282.427\n",
      "Ep:132, loss:0.00001, loss_test:0.07141, lr:5.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.436, tt:4313.929\n",
      "Ep:133, loss:0.00001, loss_test:0.07142, lr:5.87e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.433, tt:4346.047\n",
      "Ep:134, loss:0.00001, loss_test:0.07153, lr:5.81e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.427, tt:4377.689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.07189, lr:5.75e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.411, tt:4407.913\n",
      "Ep:136, loss:0.00001, loss_test:0.07104, lr:5.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.408, tt:4439.956\n",
      "Ep:137, loss:0.00001, loss_test:0.07135, lr:5.64e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.406, tt:4471.961\n",
      "Ep:138, loss:0.00001, loss_test:0.07170, lr:5.58e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.398, tt:4503.267\n",
      "Ep:139, loss:0.00001, loss_test:0.07183, lr:5.53e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.396, tt:4535.495\n",
      "Ep:140, loss:0.00001, loss_test:0.07109, lr:5.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.391, tt:4567.151\n",
      "Ep:141, loss:0.00001, loss_test:0.07185, lr:5.42e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.391, tt:4599.590\n",
      "Ep:142, loss:0.00001, loss_test:0.07192, lr:5.36e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.384, tt:4630.905\n",
      "Ep:143, loss:0.00001, loss_test:0.07068, lr:5.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.381, tt:4662.872\n",
      "Ep:144, loss:0.00001, loss_test:0.07251, lr:5.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.366, tt:4693.074\n",
      "Ep:145, loss:0.00001, loss_test:0.07152, lr:5.20e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.361, tt:4724.745\n",
      "Ep:146, loss:0.00001, loss_test:0.07091, lr:5.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.341, tt:4754.123\n",
      "Ep:147, loss:0.00001, loss_test:0.07235, lr:5.10e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.337, tt:4785.942\n",
      "Ep:148, loss:0.00001, loss_test:0.07095, lr:5.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.337, tt:4818.185\n",
      "Ep:149, loss:0.00001, loss_test:0.07144, lr:5.00e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.335, tt:4850.201\n",
      "Ep:150, loss:0.00001, loss_test:0.07198, lr:4.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.316, tt:4879.699\n",
      "Ep:151, loss:0.00001, loss_test:0.07086, lr:4.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.332, tt:4914.447\n",
      "Ep:152, loss:0.00001, loss_test:0.07177, lr:4.85e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.316, tt:4944.284\n",
      "Ep:153, loss:0.00001, loss_test:0.07215, lr:4.80e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.301, tt:4974.431\n",
      "Ep:154, loss:0.00001, loss_test:0.07068, lr:4.75e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.290, tt:5004.886\n",
      "Ep:155, loss:0.00001, loss_test:0.07175, lr:4.71e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.282, tt:5036.030\n",
      "Ep:156, loss:0.00001, loss_test:0.07210, lr:4.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.270, tt:5066.409\n",
      "Ep:157, loss:0.00001, loss_test:0.07083, lr:4.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.267, tt:5098.244\n",
      "Ep:158, loss:0.00001, loss_test:0.07156, lr:4.57e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.258, tt:5129.006\n",
      "Ep:159, loss:0.00001, loss_test:0.07200, lr:4.52e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.245, tt:5159.211\n",
      "Ep:160, loss:0.00001, loss_test:0.07099, lr:4.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.234, tt:5189.629\n",
      "Ep:161, loss:0.00001, loss_test:0.07174, lr:4.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.221, tt:5219.864\n",
      "Ep:162, loss:0.00001, loss_test:0.07163, lr:4.39e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.214, tt:5250.853\n",
      "Ep:163, loss:0.00001, loss_test:0.07116, lr:4.34e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.208, tt:5282.057\n",
      "Ep:164, loss:0.00001, loss_test:0.07169, lr:4.30e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.205, tt:5313.824\n",
      "Ep:165, loss:0.00001, loss_test:0.07172, lr:4.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.193, tt:5343.959\n",
      "Ep:166, loss:0.00001, loss_test:0.07097, lr:4.21e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.180, tt:5374.054\n",
      "Ep:167, loss:0.00001, loss_test:0.07169, lr:4.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.167, tt:5404.012\n",
      "Ep:168, loss:0.00001, loss_test:0.07203, lr:4.13e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.162, tt:5435.323\n",
      "Ep:169, loss:0.00001, loss_test:0.07103, lr:4.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.156, tt:5466.582\n",
      "Ep:170, loss:0.00001, loss_test:0.07172, lr:4.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.155, tt:5498.589\n",
      "Ep:171, loss:0.00001, loss_test:0.07128, lr:4.01e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.157, tt:5530.936\n",
      "Ep:172, loss:0.00001, loss_test:0.07129, lr:3.97e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.175, tt:5566.251\n",
      "Ep:173, loss:0.00001, loss_test:0.07165, lr:3.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.163, tt:5596.419\n",
      "Ep:174, loss:0.00001, loss_test:0.07147, lr:3.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.161, tt:5628.108\n",
      "Ep:175, loss:0.00001, loss_test:0.07119, lr:3.85e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.151, tt:5658.579\n",
      "Ep:176, loss:0.00001, loss_test:0.07151, lr:3.81e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.145, tt:5689.605\n",
      "Ep:177, loss:0.00001, loss_test:0.07126, lr:3.77e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.146, tt:5721.929\n",
      "Ep:178, loss:0.00001, loss_test:0.07134, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.141, tt:5753.284\n",
      "Ep:179, loss:0.00001, loss_test:0.07133, lr:3.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.132, tt:5783.724\n",
      "Ep:180, loss:0.00001, loss_test:0.07129, lr:3.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.127, tt:5814.958\n",
      "Ep:181, loss:0.00001, loss_test:0.07141, lr:3.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.121, tt:5846.074\n",
      "Ep:182, loss:0.00001, loss_test:0.07129, lr:3.59e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.110, tt:5876.129\n",
      "Ep:183, loss:0.00001, loss_test:0.07140, lr:3.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.113, tt:5908.777\n",
      "Ep:184, loss:0.00001, loss_test:0.07126, lr:3.52e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.111, tt:5940.525\n",
      "Ep:185, loss:0.00001, loss_test:0.07134, lr:3.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.109, tt:5972.228\n",
      "Ep:186, loss:0.00001, loss_test:0.07150, lr:3.45e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.105, tt:6003.711\n",
      "Ep:187, loss:0.00001, loss_test:0.07133, lr:3.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.104, tt:6035.500\n",
      "Ep:188, loss:0.00001, loss_test:0.07137, lr:3.38e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.103, tt:6067.514\n",
      "Ep:189, loss:0.00001, loss_test:0.07152, lr:3.34e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.102, tt:6099.329\n",
      "Ep:190, loss:0.00001, loss_test:0.07139, lr:3.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.097, tt:6130.465\n",
      "Ep:191, loss:0.00001, loss_test:0.07150, lr:3.28e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.092, tt:6161.647\n",
      "Ep:192, loss:0.00001, loss_test:0.07158, lr:3.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.084, tt:6192.230\n",
      "Ep:193, loss:0.00001, loss_test:0.07124, lr:3.21e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.078, tt:6223.081\n",
      "Ep:194, loss:0.00001, loss_test:0.07157, lr:3.18e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.072, tt:6254.113\n",
      "Ep:195, loss:0.00001, loss_test:0.07163, lr:3.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.067, tt:6285.079\n",
      "Ep:196, loss:0.00001, loss_test:0.07124, lr:3.12e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.060, tt:6315.874\n",
      "Ep:197, loss:0.00001, loss_test:0.07122, lr:3.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.050, tt:6345.839\n",
      "Ep:198, loss:0.00001, loss_test:0.07141, lr:3.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.054, tt:6378.689\n",
      "Ep:199, loss:0.00001, loss_test:0.07152, lr:3.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.048, tt:6409.700\n",
      "Ep:200, loss:0.00001, loss_test:0.07117, lr:2.99e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.044, tt:6440.759\n",
      "Ep:201, loss:0.00001, loss_test:0.07137, lr:2.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.037, tt:6471.563\n",
      "Ep:202, loss:0.00001, loss_test:0.07144, lr:2.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.039, tt:6503.858\n",
      "Ep:203, loss:0.00001, loss_test:0.07161, lr:2.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.032, tt:6534.544\n",
      "Ep:204, loss:0.00001, loss_test:0.07116, lr:2.88e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.029, tt:6565.951\n",
      "Ep:205, loss:0.00001, loss_test:0.07148, lr:2.85e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.020, tt:6596.042\n",
      "Ep:206, loss:0.00001, loss_test:0.07158, lr:2.82e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.983, tt:6620.578\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14397, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.639, tt:58.639\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14159, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:63.799, tt:127.597\n",
      "Ep:2, loss:0.00053, loss_test:0.13610, lr:1.00e-02, fs:0.64286 (r=0.909,p=0.497),  time:65.416, tt:196.249\n",
      "Ep:3, loss:0.00049, loss_test:0.12673, lr:1.00e-02, fs:0.61062 (r=0.697,p=0.543),  time:66.409, tt:265.636\n",
      "Ep:4, loss:0.00045, loss_test:0.12334, lr:1.00e-02, fs:0.61538 (r=0.606,p=0.625),  time:66.552, tt:332.759\n",
      "Ep:5, loss:0.00043, loss_test:0.11742, lr:1.00e-02, fs:0.64455 (r=0.687,p=0.607),  time:66.566, tt:399.394\n",
      "Ep:6, loss:0.00041, loss_test:0.11419, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:66.563, tt:465.944\n",
      "Ep:7, loss:0.00038, loss_test:0.11150, lr:1.00e-02, fs:0.66038 (r=0.707,p=0.619),  time:66.492, tt:531.935\n",
      "Ep:8, loss:0.00036, loss_test:0.10924, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:66.758, tt:600.823\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.10703, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:66.676, tt:666.765\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.10556, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:66.617, tt:732.787\n",
      "Ep:11, loss:0.00031, loss_test:0.10482, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:66.422, tt:797.066\n",
      "Ep:12, loss:0.00030, loss_test:0.10361, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:66.512, tt:864.653\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.10146, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:66.630, tt:932.818\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.10143, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:66.788, tt:1001.818\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.09886, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:66.624, tt:1065.982\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.09859, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:66.671, tt:1133.404\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.09569, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:66.634, tt:1199.409\n",
      "Ep:18, loss:0.00023, loss_test:0.09472, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:66.684, tt:1267.004\n",
      "Ep:19, loss:0.00022, loss_test:0.09321, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:66.824, tt:1336.487\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.09115, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:66.913, tt:1405.165\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.09092, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:66.870, tt:1471.129\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.08957, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:66.870, tt:1538.013\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.08702, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:66.864, tt:1604.741\n",
      "Ep:24, loss:0.00018, loss_test:0.08695, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:66.946, tt:1673.660\n",
      "Ep:25, loss:0.00017, loss_test:0.08981, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:66.918, tt:1739.864\n",
      "Ep:26, loss:0.00017, loss_test:0.08558, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:66.872, tt:1805.556\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.08293, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:66.953, tt:1874.690\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.08357, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:66.895, tt:1939.941\n",
      "Ep:29, loss:0.00015, loss_test:0.08457, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:66.937, tt:2008.121\n",
      "Ep:30, loss:0.00014, loss_test:0.08100, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:66.890, tt:2073.587\n",
      "Ep:31, loss:0.00013, loss_test:0.08101, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:66.829, tt:2138.528\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08057, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:66.811, tt:2204.778\n",
      "Ep:33, loss:0.00012, loss_test:0.07985, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:66.836, tt:2272.436\n",
      "Ep:34, loss:0.00012, loss_test:0.08311, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:66.833, tt:2339.155\n",
      "Ep:35, loss:0.00012, loss_test:0.08321, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:66.890, tt:2408.056\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.07763, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:66.885, tt:2474.752\n",
      "Ep:37, loss:0.00011, loss_test:0.07792, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:66.847, tt:2540.167\n",
      "Ep:38, loss:0.00011, loss_test:0.08067, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:66.840, tt:2606.747\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07768, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:66.786, tt:2671.447\n",
      "Ep:40, loss:0.00010, loss_test:0.07709, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:66.776, tt:2737.830\n",
      "Ep:41, loss:0.00009, loss_test:0.07705, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:66.762, tt:2804.013\n",
      "Ep:42, loss:0.00009, loss_test:0.07615, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:66.753, tt:2870.376\n",
      "Ep:43, loss:0.00009, loss_test:0.07590, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:66.733, tt:2936.231\n",
      "Ep:44, loss:0.00008, loss_test:0.07884, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:66.695, tt:3001.275\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.07833, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:66.672, tt:3066.901\n",
      "Ep:46, loss:0.00008, loss_test:0.07653, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:66.688, tt:3134.328\n",
      "Ep:47, loss:0.00007, loss_test:0.07850, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:66.767, tt:3204.839\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.07838, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:66.755, tt:3270.979\n",
      "Ep:49, loss:0.00007, loss_test:0.07757, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:66.749, tt:3337.474\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.07897, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:66.708, tt:3402.094\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.07820, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:66.710, tt:3468.909\n",
      "Ep:52, loss:0.00006, loss_test:0.07876, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:66.703, tt:3535.276\n",
      "Ep:53, loss:0.00006, loss_test:0.07831, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:66.737, tt:3603.791\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.07927, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:66.700, tt:3668.527\n",
      "Ep:55, loss:0.00005, loss_test:0.07772, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:66.633, tt:3731.421\n",
      "Ep:56, loss:0.00005, loss_test:0.08047, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:66.608, tt:3796.628\n",
      "Ep:57, loss:0.00005, loss_test:0.08285, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:66.546, tt:3859.655\n",
      "Ep:58, loss:0.00005, loss_test:0.07827, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:66.572, tt:3927.758\n",
      "Ep:59, loss:0.00004, loss_test:0.08300, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:66.643, tt:3998.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00004, loss_test:0.07985, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:66.652, tt:4065.800\n",
      "Ep:61, loss:0.00004, loss_test:0.07958, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:66.641, tt:4131.743\n",
      "Ep:62, loss:0.00004, loss_test:0.08115, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:66.657, tt:4199.409\n",
      "Ep:63, loss:0.00004, loss_test:0.08124, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:66.663, tt:4266.464\n",
      "Ep:64, loss:0.00004, loss_test:0.08084, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:66.616, tt:4330.047\n",
      "Ep:65, loss:0.00003, loss_test:0.08061, lr:9.90e-03, fs:0.84946 (r=0.798,p=0.908),  time:66.613, tt:4396.474\n",
      "Ep:66, loss:0.00003, loss_test:0.08074, lr:9.80e-03, fs:0.84783 (r=0.788,p=0.918),  time:66.592, tt:4461.693\n",
      "Ep:67, loss:0.00003, loss_test:0.08266, lr:9.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:66.628, tt:4530.736\n",
      "Ep:68, loss:0.00003, loss_test:0.08119, lr:9.61e-03, fs:0.83978 (r=0.768,p=0.927),  time:66.621, tt:4596.815\n",
      "Ep:69, loss:0.00003, loss_test:0.08299, lr:9.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.620, tt:4663.418\n",
      "Ep:70, loss:0.00003, loss_test:0.08120, lr:9.41e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.599, tt:4728.495\n",
      "Ep:71, loss:0.00003, loss_test:0.08167, lr:9.32e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.585, tt:4794.102\n",
      "Ep:72, loss:0.00003, loss_test:0.08229, lr:9.23e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.602, tt:4861.923\n",
      "Ep:73, loss:0.00002, loss_test:0.08264, lr:9.14e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.630, tt:4930.594\n",
      "Ep:74, loss:0.00002, loss_test:0.08212, lr:9.04e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.613, tt:4995.973\n",
      "Ep:75, loss:0.00002, loss_test:0.08203, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:66.630, tt:5063.851\n",
      "Ep:76, loss:0.00002, loss_test:0.08226, lr:8.86e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.637, tt:5131.082\n",
      "Ep:77, loss:0.00002, loss_test:0.08363, lr:8.78e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.611, tt:5195.692\n",
      "Ep:78, loss:0.00002, loss_test:0.08228, lr:8.69e-03, fs:0.83799 (r=0.758,p=0.938),  time:66.587, tt:5260.359\n",
      "Ep:79, loss:0.00002, loss_test:0.08236, lr:8.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:66.563, tt:5325.054\n",
      "Ep:80, loss:0.00002, loss_test:0.08301, lr:8.51e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.575, tt:5392.614\n",
      "Ep:81, loss:0.00002, loss_test:0.08249, lr:8.43e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.602, tt:5461.377\n",
      "Ep:82, loss:0.00002, loss_test:0.08407, lr:8.35e-03, fs:0.84746 (r=0.758,p=0.962),  time:66.633, tt:5530.509\n",
      "Ep:83, loss:0.00002, loss_test:0.08255, lr:8.26e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.620, tt:5596.098\n",
      "Ep:84, loss:0.00002, loss_test:0.08297, lr:8.18e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.603, tt:5661.213\n",
      "Ep:85, loss:0.00002, loss_test:0.08216, lr:8.10e-03, fs:0.83799 (r=0.758,p=0.938),  time:66.588, tt:5726.552\n",
      "Ep:86, loss:0.00002, loss_test:0.08298, lr:8.02e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.598, tt:5794.059\n",
      "Ep:87, loss:0.00002, loss_test:0.08332, lr:7.94e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.581, tt:5859.125\n",
      "Ep:88, loss:0.00002, loss_test:0.08225, lr:7.86e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.579, tt:5925.529\n",
      "Ep:89, loss:0.00001, loss_test:0.08311, lr:7.78e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.579, tt:5992.108\n",
      "Ep:90, loss:0.00001, loss_test:0.08278, lr:7.70e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.586, tt:6059.335\n",
      "Ep:91, loss:0.00001, loss_test:0.08251, lr:7.62e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.593, tt:6126.510\n",
      "Ep:92, loss:0.00001, loss_test:0.08388, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:66.591, tt:6192.968\n",
      "Ep:93, loss:0.00001, loss_test:0.08231, lr:7.47e-03, fs:0.84746 (r=0.758,p=0.962),  time:66.583, tt:6258.760\n",
      "Ep:94, loss:0.00001, loss_test:0.08326, lr:7.40e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.591, tt:6326.155\n",
      "Ep:95, loss:0.00001, loss_test:0.08329, lr:7.32e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.577, tt:6391.421\n",
      "Ep:96, loss:0.00001, loss_test:0.08283, lr:7.25e-03, fs:0.84746 (r=0.758,p=0.962),  time:66.579, tt:6458.188\n",
      "Ep:97, loss:0.00001, loss_test:0.08275, lr:7.18e-03, fs:0.84746 (r=0.758,p=0.962),  time:66.595, tt:6526.339\n",
      "Ep:98, loss:0.00001, loss_test:0.08356, lr:7.11e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.591, tt:6592.513\n",
      "Ep:99, loss:0.00001, loss_test:0.08328, lr:7.03e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.569, tt:6656.916\n",
      "Ep:100, loss:0.00001, loss_test:0.08265, lr:6.96e-03, fs:0.84746 (r=0.758,p=0.962),  time:66.566, tt:6723.186\n",
      "Ep:101, loss:0.00001, loss_test:0.08358, lr:6.89e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.561, tt:6789.202\n",
      "Ep:102, loss:0.00001, loss_test:0.08309, lr:6.83e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.563, tt:6856.024\n",
      "Ep:103, loss:0.00001, loss_test:0.08345, lr:6.76e-03, fs:0.84746 (r=0.758,p=0.962),  time:66.555, tt:6921.711\n",
      "Ep:104, loss:0.00001, loss_test:0.08330, lr:6.69e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.546, tt:6987.382\n",
      "Ep:105, loss:0.00001, loss_test:0.08358, lr:6.62e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.529, tt:7052.113\n",
      "Ep:106, loss:0.00001, loss_test:0.08268, lr:6.56e-03, fs:0.85227 (r=0.758,p=0.974),  time:66.438, tt:7108.916\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14469, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.068, tt:7.068\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14437, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:7.312, tt:14.624\n",
      "Ep:2, loss:0.00014, loss_test:0.14387, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:8.249, tt:24.748\n",
      "Ep:3, loss:0.00014, loss_test:0.14318, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:10.171, tt:40.683\n",
      "Ep:4, loss:0.00014, loss_test:0.14229, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:11.121, tt:55.607\n",
      "Ep:5, loss:0.00013, loss_test:0.14112, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:11.844, tt:71.064\n",
      "Ep:6, loss:0.00013, loss_test:0.13963, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:12.359, tt:86.515\n",
      "Ep:7, loss:0.00013, loss_test:0.13774, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:12.573, tt:100.583\n",
      "Ep:8, loss:0.00013, loss_test:0.13528, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:12.835, tt:115.514\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00012, loss_test:0.13252, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:13.144, tt:131.436\n",
      "Ep:10, loss:0.00012, loss_test:0.12942, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:13.431, tt:147.739\n",
      "Ep:11, loss:0.00012, loss_test:0.12705, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:13.667, tt:163.998\n",
      "Ep:12, loss:0.00011, loss_test:0.12549, lr:1.00e-02, fs:0.64979 (r=0.778,p=0.558),  time:13.798, tt:179.378\n",
      "Ep:13, loss:0.00011, loss_test:0.12465, lr:1.00e-02, fs:0.63636 (r=0.707,p=0.579),  time:13.884, tt:194.377\n",
      "Ep:14, loss:0.00011, loss_test:0.12368, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:14.219, tt:213.284\n",
      "Ep:15, loss:0.00011, loss_test:0.12276, lr:1.00e-02, fs:0.65138 (r=0.717,p=0.597),  time:14.291, tt:228.652\n",
      "Ep:16, loss:0.00011, loss_test:0.12202, lr:1.00e-02, fs:0.64253 (r=0.717,p=0.582),  time:14.380, tt:244.454\n",
      "Ep:17, loss:0.00010, loss_test:0.12159, lr:1.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:14.430, tt:259.746\n",
      "Ep:18, loss:0.00010, loss_test:0.12110, lr:1.00e-02, fs:0.64912 (r=0.747,p=0.574),  time:14.457, tt:274.687\n",
      "Ep:19, loss:0.00010, loss_test:0.12000, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:14.496, tt:289.923\n",
      "Ep:20, loss:0.00010, loss_test:0.11849, lr:9.90e-03, fs:0.66368 (r=0.747,p=0.597),  time:14.504, tt:304.574\n",
      "Ep:21, loss:0.00010, loss_test:0.11710, lr:9.80e-03, fs:0.68203 (r=0.747,p=0.627),  time:14.480, tt:318.558\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00010, loss_test:0.11582, lr:9.80e-03, fs:0.67299 (r=0.717,p=0.634),  time:14.546, tt:334.551\n",
      "Ep:23, loss:0.00010, loss_test:0.11510, lr:9.80e-03, fs:0.66981 (r=0.717,p=0.628),  time:14.584, tt:350.007\n",
      "Ep:24, loss:0.00009, loss_test:0.11481, lr:9.80e-03, fs:0.67290 (r=0.727,p=0.626),  time:14.574, tt:364.350\n",
      "Ep:25, loss:0.00009, loss_test:0.11463, lr:9.80e-03, fs:0.67593 (r=0.737,p=0.624),  time:14.606, tt:379.767\n",
      "Ep:26, loss:0.00009, loss_test:0.11434, lr:9.80e-03, fs:0.68203 (r=0.747,p=0.627),  time:14.643, tt:395.350\n",
      "Ep:27, loss:0.00009, loss_test:0.11397, lr:9.80e-03, fs:0.66977 (r=0.727,p=0.621),  time:14.698, tt:411.549\n",
      "Ep:28, loss:0.00009, loss_test:0.11340, lr:9.80e-03, fs:0.67907 (r=0.737,p=0.629),  time:14.742, tt:427.521\n",
      "Ep:29, loss:0.00009, loss_test:0.11265, lr:9.80e-03, fs:0.67925 (r=0.727,p=0.637),  time:14.756, tt:442.691\n",
      "Ep:30, loss:0.00009, loss_test:0.11200, lr:9.80e-03, fs:0.67943 (r=0.717,p=0.645),  time:14.771, tt:457.890\n",
      "Ep:31, loss:0.00009, loss_test:0.11155, lr:9.80e-03, fs:0.68293 (r=0.707,p=0.660),  time:14.796, tt:473.456\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.11128, lr:9.80e-03, fs:0.68293 (r=0.707,p=0.660),  time:14.816, tt:488.917\n",
      "Ep:33, loss:0.00008, loss_test:0.11108, lr:9.80e-03, fs:0.68627 (r=0.707,p=0.667),  time:14.864, tt:505.384\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.11100, lr:9.80e-03, fs:0.68627 (r=0.707,p=0.667),  time:14.919, tt:522.149\n",
      "Ep:35, loss:0.00008, loss_test:0.11098, lr:9.80e-03, fs:0.69903 (r=0.727,p=0.673),  time:14.938, tt:537.756\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.11075, lr:9.80e-03, fs:0.69608 (r=0.717,p=0.676),  time:14.957, tt:553.426\n",
      "Ep:37, loss:0.00008, loss_test:0.11043, lr:9.80e-03, fs:0.70297 (r=0.717,p=0.689),  time:14.996, tt:569.856\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.11003, lr:9.80e-03, fs:0.70297 (r=0.717,p=0.689),  time:15.001, tt:585.053\n",
      "Ep:39, loss:0.00008, loss_test:0.10960, lr:9.80e-03, fs:0.70297 (r=0.717,p=0.689),  time:14.989, tt:599.540\n",
      "Ep:40, loss:0.00008, loss_test:0.10921, lr:9.80e-03, fs:0.70297 (r=0.717,p=0.689),  time:15.024, tt:615.995\n",
      "Ep:41, loss:0.00007, loss_test:0.10878, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:15.024, tt:630.994\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.10824, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:15.022, tt:645.967\n",
      "Ep:43, loss:0.00007, loss_test:0.10764, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:15.012, tt:660.510\n",
      "Ep:44, loss:0.00007, loss_test:0.10713, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:15.023, tt:676.024\n",
      "Ep:45, loss:0.00007, loss_test:0.10673, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:15.023, tt:691.054\n",
      "Ep:46, loss:0.00007, loss_test:0.10651, lr:9.80e-03, fs:0.70647 (r=0.717,p=0.696),  time:15.024, tt:706.113\n",
      "Ep:47, loss:0.00007, loss_test:0.10627, lr:9.80e-03, fs:0.71287 (r=0.727,p=0.699),  time:15.036, tt:721.712\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.10597, lr:9.80e-03, fs:0.71642 (r=0.727,p=0.706),  time:15.015, tt:735.745\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.10558, lr:9.80e-03, fs:0.71642 (r=0.727,p=0.706),  time:14.981, tt:749.031\n",
      "Ep:50, loss:0.00007, loss_test:0.10523, lr:9.80e-03, fs:0.71642 (r=0.727,p=0.706),  time:14.953, tt:762.621\n",
      "Ep:51, loss:0.00007, loss_test:0.10488, lr:9.80e-03, fs:0.71287 (r=0.727,p=0.699),  time:14.947, tt:777.252\n",
      "Ep:52, loss:0.00006, loss_test:0.10455, lr:9.80e-03, fs:0.71287 (r=0.727,p=0.699),  time:14.935, tt:791.543\n",
      "Ep:53, loss:0.00006, loss_test:0.10412, lr:9.80e-03, fs:0.71287 (r=0.727,p=0.699),  time:14.949, tt:807.238\n",
      "Ep:54, loss:0.00006, loss_test:0.10363, lr:9.80e-03, fs:0.70000 (r=0.707,p=0.693),  time:14.949, tt:822.221\n",
      "Ep:55, loss:0.00006, loss_test:0.10342, lr:9.80e-03, fs:0.69347 (r=0.697,p=0.690),  time:14.924, tt:835.736\n",
      "Ep:56, loss:0.00006, loss_test:0.10316, lr:9.80e-03, fs:0.69388 (r=0.687,p=0.701),  time:14.914, tt:850.087\n",
      "Ep:57, loss:0.00006, loss_test:0.10273, lr:9.80e-03, fs:0.69388 (r=0.687,p=0.701),  time:14.917, tt:865.166\n",
      "Ep:58, loss:0.00006, loss_test:0.10242, lr:9.80e-03, fs:0.70051 (r=0.697,p=0.704),  time:14.895, tt:878.805\n",
      "Ep:59, loss:0.00006, loss_test:0.10203, lr:9.80e-03, fs:0.70051 (r=0.697,p=0.704),  time:14.889, tt:893.360\n",
      "Ep:60, loss:0.00006, loss_test:0.10185, lr:9.70e-03, fs:0.70051 (r=0.697,p=0.704),  time:14.893, tt:908.444\n",
      "Ep:61, loss:0.00006, loss_test:0.10166, lr:9.61e-03, fs:0.68041 (r=0.667,p=0.695),  time:14.907, tt:924.255\n",
      "Ep:62, loss:0.00006, loss_test:0.10141, lr:9.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:14.907, tt:939.148\n",
      "Ep:63, loss:0.00006, loss_test:0.10117, lr:9.41e-03, fs:0.70051 (r=0.697,p=0.704),  time:14.901, tt:953.647\n",
      "Ep:64, loss:0.00006, loss_test:0.10089, lr:9.32e-03, fs:0.67358 (r=0.657,p=0.691),  time:14.898, tt:968.391\n",
      "Ep:65, loss:0.00006, loss_test:0.10031, lr:9.23e-03, fs:0.70051 (r=0.697,p=0.704),  time:14.899, tt:983.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00006, loss_test:0.09987, lr:9.14e-03, fs:0.70707 (r=0.707,p=0.707),  time:14.927, tt:1000.121\n",
      "Ep:67, loss:0.00005, loss_test:0.09960, lr:9.04e-03, fs:0.68718 (r=0.677,p=0.698),  time:14.930, tt:1015.268\n",
      "Ep:68, loss:0.00005, loss_test:0.09944, lr:8.95e-03, fs:0.68718 (r=0.677,p=0.698),  time:14.931, tt:1030.215\n",
      "Ep:69, loss:0.00005, loss_test:0.09915, lr:8.86e-03, fs:0.68718 (r=0.677,p=0.698),  time:14.940, tt:1045.766\n",
      "Ep:70, loss:0.00005, loss_test:0.09878, lr:8.78e-03, fs:0.69072 (r=0.677,p=0.705),  time:14.914, tt:1058.877\n",
      "Ep:71, loss:0.00005, loss_test:0.09859, lr:8.69e-03, fs:0.69072 (r=0.677,p=0.705),  time:14.919, tt:1074.173\n",
      "Ep:72, loss:0.00005, loss_test:0.09834, lr:8.60e-03, fs:0.69744 (r=0.687,p=0.708),  time:14.953, tt:1091.590\n",
      "Ep:73, loss:0.00005, loss_test:0.09792, lr:8.51e-03, fs:0.69744 (r=0.687,p=0.708),  time:14.969, tt:1107.713\n",
      "Ep:74, loss:0.00005, loss_test:0.09752, lr:8.43e-03, fs:0.69744 (r=0.687,p=0.708),  time:14.970, tt:1122.760\n",
      "Ep:75, loss:0.00005, loss_test:0.09743, lr:8.35e-03, fs:0.69744 (r=0.687,p=0.708),  time:14.984, tt:1138.815\n",
      "Ep:76, loss:0.00005, loss_test:0.09681, lr:8.26e-03, fs:0.69430 (r=0.677,p=0.713),  time:14.990, tt:1154.194\n",
      "Ep:77, loss:0.00005, loss_test:0.09641, lr:8.18e-03, fs:0.70103 (r=0.687,p=0.716),  time:15.004, tt:1170.297\n",
      "Ep:78, loss:0.00005, loss_test:0.09607, lr:8.10e-03, fs:0.70408 (r=0.697,p=0.711),  time:14.999, tt:1184.929\n",
      "Ep:79, loss:0.00005, loss_test:0.09557, lr:8.02e-03, fs:0.70103 (r=0.687,p=0.716),  time:14.977, tt:1198.172\n",
      "Ep:80, loss:0.00005, loss_test:0.09528, lr:7.94e-03, fs:0.70103 (r=0.687,p=0.716),  time:14.982, tt:1213.558\n",
      "Ep:81, loss:0.00005, loss_test:0.09513, lr:7.86e-03, fs:0.71357 (r=0.717,p=0.710),  time:14.986, tt:1228.833\n",
      "Ep:82, loss:0.00005, loss_test:0.09477, lr:7.78e-03, fs:0.71642 (r=0.727,p=0.706),  time:14.991, tt:1244.220\n",
      "Ep:83, loss:0.00005, loss_test:0.09423, lr:7.70e-03, fs:0.71717 (r=0.717,p=0.717),  time:14.978, tt:1258.120\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00005, loss_test:0.09397, lr:7.70e-03, fs:0.71717 (r=0.717,p=0.717),  time:14.965, tt:1272.061\n",
      "Ep:85, loss:0.00005, loss_test:0.09395, lr:7.70e-03, fs:0.72277 (r=0.737,p=0.709),  time:14.972, tt:1287.629\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00005, loss_test:0.09366, lr:7.70e-03, fs:0.72637 (r=0.737,p=0.716),  time:14.965, tt:1301.937\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00004, loss_test:0.09323, lr:7.70e-03, fs:0.73000 (r=0.737,p=0.723),  time:14.954, tt:1315.918\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00004, loss_test:0.09296, lr:7.70e-03, fs:0.72277 (r=0.737,p=0.709),  time:14.944, tt:1330.025\n",
      "Ep:89, loss:0.00004, loss_test:0.09268, lr:7.70e-03, fs:0.72277 (r=0.737,p=0.709),  time:14.947, tt:1345.239\n",
      "Ep:90, loss:0.00004, loss_test:0.09242, lr:7.70e-03, fs:0.73000 (r=0.737,p=0.723),  time:14.926, tt:1358.278\n",
      "Ep:91, loss:0.00004, loss_test:0.09225, lr:7.70e-03, fs:0.73000 (r=0.737,p=0.723),  time:14.927, tt:1373.329\n",
      "Ep:92, loss:0.00004, loss_test:0.09180, lr:7.70e-03, fs:0.73632 (r=0.747,p=0.725),  time:14.925, tt:1387.987\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00004, loss_test:0.09142, lr:7.70e-03, fs:0.74000 (r=0.747,p=0.733),  time:14.931, tt:1403.473\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00004, loss_test:0.09138, lr:7.70e-03, fs:0.74627 (r=0.758,p=0.735),  time:14.929, tt:1418.211\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00004, loss_test:0.09116, lr:7.70e-03, fs:0.74627 (r=0.758,p=0.735),  time:14.932, tt:1433.486\n",
      "Ep:96, loss:0.00004, loss_test:0.09087, lr:7.70e-03, fs:0.76000 (r=0.768,p=0.752),  time:14.919, tt:1447.189\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00004, loss_test:0.09054, lr:7.70e-03, fs:0.76000 (r=0.768,p=0.752),  time:14.922, tt:1462.320\n",
      "Ep:98, loss:0.00004, loss_test:0.09023, lr:7.70e-03, fs:0.76000 (r=0.768,p=0.752),  time:14.913, tt:1476.367\n",
      "Ep:99, loss:0.00004, loss_test:0.08987, lr:7.70e-03, fs:0.76000 (r=0.768,p=0.752),  time:14.899, tt:1489.942\n",
      "Ep:100, loss:0.00004, loss_test:0.08972, lr:7.70e-03, fs:0.76000 (r=0.768,p=0.752),  time:14.885, tt:1503.397\n",
      "Ep:101, loss:0.00004, loss_test:0.08937, lr:7.70e-03, fs:0.76382 (r=0.768,p=0.760),  time:14.886, tt:1518.360\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00004, loss_test:0.08917, lr:7.70e-03, fs:0.76382 (r=0.768,p=0.760),  time:14.875, tt:1532.142\n",
      "Ep:103, loss:0.00004, loss_test:0.08896, lr:7.70e-03, fs:0.75622 (r=0.768,p=0.745),  time:14.884, tt:1547.957\n",
      "Ep:104, loss:0.00004, loss_test:0.08853, lr:7.70e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.876, tt:1561.948\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00004, loss_test:0.08847, lr:7.70e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.882, tt:1577.533\n",
      "Ep:106, loss:0.00004, loss_test:0.08857, lr:7.70e-03, fs:0.76000 (r=0.768,p=0.752),  time:14.884, tt:1592.617\n",
      "Ep:107, loss:0.00004, loss_test:0.08799, lr:7.70e-03, fs:0.76768 (r=0.768,p=0.768),  time:14.883, tt:1607.416\n",
      "Ep:108, loss:0.00004, loss_test:0.08751, lr:7.70e-03, fs:0.77320 (r=0.758,p=0.789),  time:14.889, tt:1622.860\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00004, loss_test:0.08748, lr:7.70e-03, fs:0.76768 (r=0.768,p=0.768),  time:14.886, tt:1637.514\n",
      "Ep:110, loss:0.00004, loss_test:0.08758, lr:7.70e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.889, tt:1652.633\n",
      "Ep:111, loss:0.00004, loss_test:0.08743, lr:7.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.882, tt:1666.810\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00004, loss_test:0.08718, lr:7.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.880, tt:1681.448\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00003, loss_test:0.08685, lr:7.70e-03, fs:0.77551 (r=0.768,p=0.784),  time:14.880, tt:1696.310\n",
      "Ep:114, loss:0.00003, loss_test:0.08657, lr:7.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.877, tt:1710.869\n",
      "Ep:115, loss:0.00003, loss_test:0.08664, lr:7.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.888, tt:1726.999\n",
      "Ep:116, loss:0.00003, loss_test:0.08677, lr:7.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.878, tt:1740.743\n",
      "Ep:117, loss:0.00003, loss_test:0.08659, lr:7.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.891, tt:1757.146\n",
      "Ep:118, loss:0.00003, loss_test:0.08629, lr:7.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.898, tt:1772.913\n",
      "Ep:119, loss:0.00003, loss_test:0.08626, lr:7.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.897, tt:1787.624\n",
      "Ep:120, loss:0.00003, loss_test:0.08637, lr:7.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.908, tt:1803.868\n",
      "Ep:121, loss:0.00003, loss_test:0.08618, lr:7.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.928, tt:1821.187\n",
      "Ep:122, loss:0.00003, loss_test:0.08593, lr:7.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.937, tt:1837.286\n",
      "Ep:123, loss:0.00003, loss_test:0.08579, lr:7.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.944, tt:1853.033\n",
      "Ep:124, loss:0.00003, loss_test:0.08579, lr:7.62e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.949, tt:1868.590\n",
      "Ep:125, loss:0.00003, loss_test:0.08587, lr:7.55e-03, fs:0.76923 (r=0.758,p=0.781),  time:14.948, tt:1883.406\n",
      "Ep:126, loss:0.00003, loss_test:0.08570, lr:7.47e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.952, tt:1898.953\n",
      "Ep:127, loss:0.00003, loss_test:0.08554, lr:7.40e-03, fs:0.77487 (r=0.747,p=0.804),  time:14.957, tt:1914.459\n",
      "Ep:128, loss:0.00003, loss_test:0.08542, lr:7.32e-03, fs:0.77551 (r=0.768,p=0.784),  time:14.956, tt:1929.300\n",
      "Ep:129, loss:0.00003, loss_test:0.08548, lr:7.25e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.958, tt:1944.548\n",
      "Ep:130, loss:0.00003, loss_test:0.08552, lr:7.18e-03, fs:0.77487 (r=0.747,p=0.804),  time:14.962, tt:1960.048\n",
      "Ep:131, loss:0.00003, loss_test:0.08534, lr:7.11e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.964, tt:1975.244\n",
      "Ep:132, loss:0.00003, loss_test:0.08515, lr:7.03e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.967, tt:1990.560\n",
      "Ep:133, loss:0.00003, loss_test:0.08486, lr:6.96e-03, fs:0.77487 (r=0.747,p=0.804),  time:14.965, tt:2005.311\n",
      "Ep:134, loss:0.00003, loss_test:0.08476, lr:6.89e-03, fs:0.76842 (r=0.737,p=0.802),  time:14.969, tt:2020.867\n",
      "Ep:135, loss:0.00003, loss_test:0.08460, lr:6.83e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.976, tt:2036.736\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00003, loss_test:0.08458, lr:6.83e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.969, tt:2050.819\n",
      "Ep:137, loss:0.00003, loss_test:0.08469, lr:6.83e-03, fs:0.76190 (r=0.727,p=0.800),  time:14.971, tt:2066.034\n",
      "Ep:138, loss:0.00003, loss_test:0.08446, lr:6.83e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.965, tt:2080.069\n",
      "Ep:139, loss:0.00003, loss_test:0.08434, lr:6.83e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.959, tt:2094.225\n",
      "Ep:140, loss:0.00003, loss_test:0.08452, lr:6.83e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.956, tt:2108.788\n",
      "Ep:141, loss:0.00003, loss_test:0.08445, lr:6.83e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.953, tt:2123.276\n",
      "Ep:142, loss:0.00003, loss_test:0.08418, lr:6.83e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.951, tt:2137.999\n",
      "Ep:143, loss:0.00003, loss_test:0.08405, lr:6.83e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.946, tt:2152.244\n",
      "Ep:144, loss:0.00003, loss_test:0.08401, lr:6.83e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.943, tt:2166.795\n",
      "Ep:145, loss:0.00002, loss_test:0.08393, lr:6.83e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.938, tt:2180.957\n",
      "Ep:146, loss:0.00002, loss_test:0.08385, lr:6.83e-03, fs:0.77487 (r=0.747,p=0.804),  time:14.988, tt:2203.172\n",
      "Ep:147, loss:0.00002, loss_test:0.08385, lr:6.76e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.984, tt:2217.683\n",
      "Ep:148, loss:0.00002, loss_test:0.08364, lr:6.69e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.988, tt:2233.182\n",
      "Ep:149, loss:0.00002, loss_test:0.08373, lr:6.62e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.987, tt:2248.009\n",
      "Ep:150, loss:0.00002, loss_test:0.08375, lr:6.56e-03, fs:0.77895 (r=0.747,p=0.813),  time:14.986, tt:2262.843\n",
      "Ep:151, loss:0.00002, loss_test:0.08351, lr:6.49e-03, fs:0.77320 (r=0.758,p=0.789),  time:14.981, tt:2277.134\n",
      "Ep:152, loss:0.00002, loss_test:0.08349, lr:6.43e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.972, tt:2290.764\n",
      "Ep:153, loss:0.00002, loss_test:0.08345, lr:6.36e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.953, tt:2302.790\n",
      "Ep:154, loss:0.00002, loss_test:0.08325, lr:6.30e-03, fs:0.77320 (r=0.758,p=0.789),  time:14.945, tt:2316.429\n",
      "Ep:155, loss:0.00002, loss_test:0.08338, lr:6.24e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.937, tt:2330.161\n",
      "Ep:156, loss:0.00002, loss_test:0.08322, lr:6.17e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.927, tt:2343.564\n",
      "Ep:157, loss:0.00002, loss_test:0.08308, lr:6.11e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.922, tt:2357.620\n",
      "Ep:158, loss:0.00002, loss_test:0.08336, lr:6.05e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.916, tt:2371.688\n",
      "Ep:159, loss:0.00002, loss_test:0.08328, lr:5.99e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.915, tt:2386.419\n",
      "Ep:160, loss:0.00002, loss_test:0.08288, lr:5.93e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.910, tt:2400.546\n",
      "Ep:161, loss:0.00002, loss_test:0.08279, lr:5.87e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.910, tt:2415.361\n",
      "Ep:162, loss:0.00002, loss_test:0.08286, lr:5.81e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.900, tt:2428.653\n",
      "Ep:163, loss:0.00002, loss_test:0.08272, lr:5.75e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.890, tt:2441.884\n",
      "Ep:164, loss:0.00002, loss_test:0.08257, lr:5.70e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.879, tt:2455.044\n",
      "Ep:165, loss:0.00002, loss_test:0.08295, lr:5.64e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.865, tt:2467.622\n",
      "Ep:166, loss:0.00002, loss_test:0.08278, lr:5.58e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.850, tt:2479.905\n",
      "Ep:167, loss:0.00002, loss_test:0.08231, lr:5.53e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.836, tt:2492.511\n",
      "Ep:168, loss:0.00002, loss_test:0.08252, lr:5.47e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.830, tt:2506.294\n",
      "Ep:169, loss:0.00002, loss_test:0.08267, lr:5.42e-03, fs:0.79365 (r=0.758,p=0.833),  time:14.824, tt:2520.140\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00002, loss_test:0.08241, lr:5.42e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.814, tt:2533.168\n",
      "Ep:171, loss:0.00002, loss_test:0.08212, lr:5.42e-03, fs:0.78351 (r=0.768,p=0.800),  time:14.805, tt:2546.420\n",
      "Ep:172, loss:0.00002, loss_test:0.08250, lr:5.42e-03, fs:0.79365 (r=0.758,p=0.833),  time:14.789, tt:2558.479\n",
      "Ep:173, loss:0.00002, loss_test:0.08237, lr:5.42e-03, fs:0.79365 (r=0.758,p=0.833),  time:14.783, tt:2572.271\n",
      "Ep:174, loss:0.00002, loss_test:0.08179, lr:5.42e-03, fs:0.78351 (r=0.768,p=0.800),  time:14.769, tt:2584.522\n",
      "Ep:175, loss:0.00002, loss_test:0.08195, lr:5.42e-03, fs:0.77720 (r=0.758,p=0.798),  time:14.758, tt:2597.417\n",
      "Ep:176, loss:0.00002, loss_test:0.08216, lr:5.42e-03, fs:0.79365 (r=0.758,p=0.833),  time:14.750, tt:2610.787\n",
      "Ep:177, loss:0.00002, loss_test:0.08196, lr:5.42e-03, fs:0.78534 (r=0.758,p=0.815),  time:14.739, tt:2623.538\n",
      "Ep:178, loss:0.00002, loss_test:0.08180, lr:5.42e-03, fs:0.78125 (r=0.758,p=0.806),  time:14.725, tt:2635.848\n",
      "Ep:179, loss:0.00002, loss_test:0.08204, lr:5.42e-03, fs:0.79787 (r=0.758,p=0.843),  time:14.722, tt:2650.032\n",
      "##########Best model found so far##########\n",
      "Ep:180, loss:0.00002, loss_test:0.08190, lr:5.42e-03, fs:0.78947 (r=0.758,p=0.824),  time:14.714, tt:2663.213\n",
      "Ep:181, loss:0.00002, loss_test:0.08159, lr:5.42e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.706, tt:2676.569\n",
      "Ep:182, loss:0.00002, loss_test:0.08186, lr:5.42e-03, fs:0.78723 (r=0.747,p=0.831),  time:14.699, tt:2689.828\n",
      "Ep:183, loss:0.00002, loss_test:0.08167, lr:5.42e-03, fs:0.78723 (r=0.747,p=0.831),  time:14.693, tt:2703.539\n",
      "Ep:184, loss:0.00002, loss_test:0.08127, lr:5.42e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.675, tt:2714.968\n",
      "Ep:185, loss:0.00002, loss_test:0.08171, lr:5.42e-03, fs:0.79787 (r=0.758,p=0.843),  time:14.654, tt:2725.634\n",
      "Ep:186, loss:0.00002, loss_test:0.08186, lr:5.42e-03, fs:0.79787 (r=0.758,p=0.843),  time:14.646, tt:2738.864\n",
      "Ep:187, loss:0.00002, loss_test:0.08155, lr:5.42e-03, fs:0.78947 (r=0.758,p=0.824),  time:14.636, tt:2751.568\n",
      "Ep:188, loss:0.00002, loss_test:0.08134, lr:5.42e-03, fs:0.78534 (r=0.758,p=0.815),  time:14.629, tt:2764.918\n",
      "Ep:189, loss:0.00002, loss_test:0.08156, lr:5.42e-03, fs:0.79144 (r=0.747,p=0.841),  time:14.616, tt:2777.029\n",
      "Ep:190, loss:0.00002, loss_test:0.08140, lr:5.42e-03, fs:0.79365 (r=0.758,p=0.833),  time:14.614, tt:2791.321\n",
      "Ep:191, loss:0.00002, loss_test:0.08103, lr:5.36e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.608, tt:2804.752\n",
      "Ep:192, loss:0.00002, loss_test:0.08127, lr:5.31e-03, fs:0.79144 (r=0.747,p=0.841),  time:14.619, tt:2821.515\n",
      "Ep:193, loss:0.00002, loss_test:0.08117, lr:5.26e-03, fs:0.79144 (r=0.747,p=0.841),  time:14.611, tt:2834.463\n",
      "Ep:194, loss:0.00002, loss_test:0.08083, lr:5.20e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.606, tt:2848.138\n",
      "Ep:195, loss:0.00002, loss_test:0.08131, lr:5.15e-03, fs:0.78947 (r=0.758,p=0.824),  time:14.591, tt:2859.780\n",
      "Ep:196, loss:0.00002, loss_test:0.08155, lr:5.10e-03, fs:0.79144 (r=0.747,p=0.841),  time:14.578, tt:2871.775\n",
      "Ep:197, loss:0.00002, loss_test:0.08140, lr:5.05e-03, fs:0.79144 (r=0.747,p=0.841),  time:14.561, tt:2883.030\n",
      "Ep:198, loss:0.00002, loss_test:0.08088, lr:5.00e-03, fs:0.78947 (r=0.758,p=0.824),  time:14.549, tt:2895.340\n",
      "Ep:199, loss:0.00002, loss_test:0.08106, lr:4.95e-03, fs:0.78307 (r=0.747,p=0.822),  time:14.535, tt:2907.080\n",
      "Ep:200, loss:0.00002, loss_test:0.08124, lr:4.90e-03, fs:0.78723 (r=0.747,p=0.831),  time:14.526, tt:2919.751\n",
      "Ep:201, loss:0.00002, loss_test:0.08113, lr:4.85e-03, fs:0.78723 (r=0.747,p=0.831),  time:14.512, tt:2931.357\n",
      "Ep:202, loss:0.00002, loss_test:0.08083, lr:4.80e-03, fs:0.78947 (r=0.758,p=0.824),  time:14.502, tt:2943.852\n",
      "Ep:203, loss:0.00002, loss_test:0.08084, lr:4.75e-03, fs:0.78307 (r=0.747,p=0.822),  time:14.492, tt:2956.357\n",
      "Ep:204, loss:0.00002, loss_test:0.08091, lr:4.71e-03, fs:0.78307 (r=0.747,p=0.822),  time:14.484, tt:2969.260\n",
      "Ep:205, loss:0.00002, loss_test:0.08092, lr:4.66e-03, fs:0.78947 (r=0.758,p=0.824),  time:14.474, tt:2981.715\n",
      "Ep:206, loss:0.00002, loss_test:0.08104, lr:4.61e-03, fs:0.78723 (r=0.747,p=0.831),  time:14.462, tt:2993.634\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14600, lr:1.00e-02, fs:0.65854 (r=0.982,p=0.495),  time:25.515, tt:25.515\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14541, lr:1.00e-02, fs:0.65854 (r=0.982,p=0.495),  time:28.743, tt:57.485\n",
      "Ep:2, loss:0.00028, loss_test:0.14433, lr:1.00e-02, fs:0.65854 (r=0.982,p=0.495),  time:30.040, tt:90.121\n",
      "Ep:3, loss:0.00028, loss_test:0.14260, lr:1.00e-02, fs:0.66258 (r=0.982,p=0.500),  time:30.466, tt:121.864\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.14024, lr:1.00e-02, fs:0.65432 (r=0.964,p=0.495),  time:30.999, tt:154.995\n",
      "Ep:5, loss:0.00026, loss_test:0.13660, lr:1.00e-02, fs:0.65359 (r=0.909,p=0.510),  time:31.352, tt:188.110\n",
      "Ep:6, loss:0.00025, loss_test:0.13144, lr:1.00e-02, fs:0.64748 (r=0.818,p=0.536),  time:31.390, tt:219.733\n",
      "Ep:7, loss:0.00024, loss_test:0.12745, lr:1.00e-02, fs:0.58065 (r=0.655,p=0.522),  time:31.654, tt:253.232\n",
      "Ep:8, loss:0.00023, loss_test:0.12675, lr:1.00e-02, fs:0.56604 (r=0.545,p=0.588),  time:31.766, tt:285.891\n",
      "Ep:9, loss:0.00022, loss_test:0.12469, lr:1.00e-02, fs:0.57944 (r=0.564,p=0.596),  time:31.875, tt:318.754\n",
      "Ep:10, loss:0.00022, loss_test:0.12129, lr:1.00e-02, fs:0.58182 (r=0.582,p=0.582),  time:31.994, tt:351.933\n",
      "Ep:11, loss:0.00021, loss_test:0.11920, lr:1.00e-02, fs:0.62609 (r=0.655,p=0.600),  time:32.098, tt:385.174\n",
      "Ep:12, loss:0.00021, loss_test:0.11666, lr:1.00e-02, fs:0.63636 (r=0.636,p=0.636),  time:32.090, tt:417.166\n",
      "Ep:13, loss:0.00020, loss_test:0.11526, lr:1.00e-02, fs:0.63462 (r=0.600,p=0.673),  time:32.226, tt:451.161\n",
      "Ep:14, loss:0.00020, loss_test:0.11241, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:32.263, tt:483.948\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10960, lr:1.00e-02, fs:0.67257 (r=0.691,p=0.655),  time:32.265, tt:516.234\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10705, lr:1.00e-02, fs:0.69725 (r=0.691,p=0.704),  time:32.224, tt:547.811\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10562, lr:1.00e-02, fs:0.68571 (r=0.655,p=0.720),  time:32.202, tt:579.628\n",
      "Ep:18, loss:0.00017, loss_test:0.10318, lr:1.00e-02, fs:0.68571 (r=0.655,p=0.720),  time:32.203, tt:611.855\n",
      "Ep:19, loss:0.00017, loss_test:0.10053, lr:1.00e-02, fs:0.73874 (r=0.745,p=0.732),  time:32.158, tt:643.158\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09850, lr:1.00e-02, fs:0.72222 (r=0.709,p=0.736),  time:32.186, tt:675.904\n",
      "Ep:21, loss:0.00016, loss_test:0.09709, lr:1.00e-02, fs:0.72222 (r=0.709,p=0.736),  time:32.170, tt:707.748\n",
      "Ep:22, loss:0.00016, loss_test:0.09529, lr:1.00e-02, fs:0.73394 (r=0.727,p=0.741),  time:32.197, tt:740.523\n",
      "Ep:23, loss:0.00015, loss_test:0.09389, lr:1.00e-02, fs:0.75676 (r=0.764,p=0.750),  time:32.272, tt:774.538\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09273, lr:1.00e-02, fs:0.75676 (r=0.764,p=0.750),  time:32.336, tt:808.392\n",
      "Ep:25, loss:0.00015, loss_test:0.09085, lr:1.00e-02, fs:0.77876 (r=0.800,p=0.759),  time:32.377, tt:841.803\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08911, lr:1.00e-02, fs:0.78947 (r=0.818,p=0.763),  time:32.384, tt:874.368\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08772, lr:1.00e-02, fs:0.78947 (r=0.818,p=0.763),  time:32.349, tt:905.768\n",
      "Ep:28, loss:0.00014, loss_test:0.08641, lr:1.00e-02, fs:0.81034 (r=0.855,p=0.770),  time:32.405, tt:939.756\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08515, lr:1.00e-02, fs:0.80342 (r=0.855,p=0.758),  time:32.410, tt:972.288\n",
      "Ep:30, loss:0.00013, loss_test:0.08409, lr:1.00e-02, fs:0.81034 (r=0.855,p=0.770),  time:32.386, tt:1003.955\n",
      "Ep:31, loss:0.00013, loss_test:0.08262, lr:1.00e-02, fs:0.81739 (r=0.855,p=0.783),  time:32.361, tt:1035.536\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08116, lr:1.00e-02, fs:0.81034 (r=0.855,p=0.770),  time:32.362, tt:1067.951\n",
      "Ep:33, loss:0.00012, loss_test:0.07981, lr:1.00e-02, fs:0.81739 (r=0.855,p=0.783),  time:32.338, tt:1099.496\n",
      "Ep:34, loss:0.00012, loss_test:0.07815, lr:1.00e-02, fs:0.81739 (r=0.855,p=0.783),  time:32.359, tt:1132.575\n",
      "Ep:35, loss:0.00012, loss_test:0.07704, lr:1.00e-02, fs:0.82456 (r=0.855,p=0.797),  time:32.364, tt:1165.107\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07577, lr:1.00e-02, fs:0.83929 (r=0.855,p=0.825),  time:32.352, tt:1197.016\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07466, lr:1.00e-02, fs:0.83186 (r=0.855,p=0.810),  time:32.291, tt:1227.061\n",
      "Ep:38, loss:0.00011, loss_test:0.07385, lr:1.00e-02, fs:0.82569 (r=0.818,p=0.833),  time:32.258, tt:1258.065\n",
      "Ep:39, loss:0.00011, loss_test:0.07292, lr:1.00e-02, fs:0.81081 (r=0.818,p=0.804),  time:32.259, tt:1290.371\n",
      "Ep:40, loss:0.00010, loss_test:0.07212, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:32.256, tt:1322.506\n",
      "Ep:41, loss:0.00010, loss_test:0.07063, lr:1.00e-02, fs:0.82883 (r=0.836,p=0.821),  time:32.276, tt:1355.608\n",
      "Ep:42, loss:0.00010, loss_test:0.06958, lr:1.00e-02, fs:0.82883 (r=0.836,p=0.821),  time:32.291, tt:1388.515\n",
      "Ep:43, loss:0.00010, loss_test:0.06866, lr:1.00e-02, fs:0.83636 (r=0.836,p=0.836),  time:32.259, tt:1419.410\n",
      "Ep:44, loss:0.00010, loss_test:0.06756, lr:1.00e-02, fs:0.86207 (r=0.909,p=0.820),  time:32.260, tt:1451.690\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.06716, lr:1.00e-02, fs:0.84685 (r=0.855,p=0.839),  time:32.254, tt:1483.698\n",
      "Ep:46, loss:0.00009, loss_test:0.06586, lr:1.00e-02, fs:0.86726 (r=0.891,p=0.845),  time:32.246, tt:1515.541\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.06493, lr:1.00e-02, fs:0.86726 (r=0.891,p=0.845),  time:32.290, tt:1549.934\n",
      "Ep:48, loss:0.00009, loss_test:0.06444, lr:1.00e-02, fs:0.85714 (r=0.873,p=0.842),  time:32.287, tt:1582.045\n",
      "Ep:49, loss:0.00009, loss_test:0.06331, lr:1.00e-02, fs:0.85965 (r=0.891,p=0.831),  time:32.304, tt:1615.224\n",
      "Ep:50, loss:0.00008, loss_test:0.06306, lr:1.00e-02, fs:0.85714 (r=0.873,p=0.842),  time:32.292, tt:1646.881\n",
      "Ep:51, loss:0.00008, loss_test:0.06189, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:32.291, tt:1679.132\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.06175, lr:1.00e-02, fs:0.85714 (r=0.873,p=0.842),  time:32.286, tt:1711.182\n",
      "Ep:53, loss:0.00008, loss_test:0.06068, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:32.284, tt:1743.312\n",
      "Ep:54, loss:0.00008, loss_test:0.05995, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:32.285, tt:1775.685\n",
      "Ep:55, loss:0.00008, loss_test:0.05911, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:32.270, tt:1807.112\n",
      "Ep:56, loss:0.00007, loss_test:0.05839, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:32.271, tt:1839.475\n",
      "Ep:57, loss:0.00007, loss_test:0.05822, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:32.263, tt:1871.262\n",
      "Ep:58, loss:0.00007, loss_test:0.05749, lr:1.00e-02, fs:0.85714 (r=0.873,p=0.842),  time:32.250, tt:1902.729\n",
      "Ep:59, loss:0.00007, loss_test:0.05699, lr:1.00e-02, fs:0.85714 (r=0.873,p=0.842),  time:32.229, tt:1933.745\n",
      "Ep:60, loss:0.00007, loss_test:0.05653, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:32.207, tt:1964.652\n",
      "Ep:61, loss:0.00007, loss_test:0.05579, lr:1.00e-02, fs:0.86486 (r=0.873,p=0.857),  time:32.225, tt:1997.939\n",
      "Ep:62, loss:0.00007, loss_test:0.05526, lr:1.00e-02, fs:0.86726 (r=0.891,p=0.845),  time:32.208, tt:2029.130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.05505, lr:9.90e-03, fs:0.87037 (r=0.855,p=0.887),  time:32.188, tt:2060.011\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.05431, lr:9.90e-03, fs:0.86486 (r=0.873,p=0.857),  time:32.186, tt:2092.097\n",
      "Ep:65, loss:0.00006, loss_test:0.05415, lr:9.90e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.185, tt:2124.228\n",
      "Ep:66, loss:0.00006, loss_test:0.05355, lr:9.90e-03, fs:0.85714 (r=0.873,p=0.842),  time:32.175, tt:2155.721\n",
      "Ep:67, loss:0.00006, loss_test:0.05309, lr:9.90e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.177, tt:2188.024\n",
      "Ep:68, loss:0.00006, loss_test:0.05244, lr:9.90e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.172, tt:2219.885\n",
      "Ep:69, loss:0.00006, loss_test:0.05226, lr:9.90e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.158, tt:2251.080\n",
      "Ep:70, loss:0.00006, loss_test:0.05188, lr:9.90e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.147, tt:2282.435\n",
      "Ep:71, loss:0.00005, loss_test:0.05134, lr:9.90e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.144, tt:2314.336\n",
      "Ep:72, loss:0.00005, loss_test:0.05063, lr:9.90e-03, fs:0.83929 (r=0.855,p=0.825),  time:32.139, tt:2346.156\n",
      "Ep:73, loss:0.00005, loss_test:0.05014, lr:9.90e-03, fs:0.83929 (r=0.855,p=0.825),  time:32.144, tt:2378.631\n",
      "Ep:74, loss:0.00005, loss_test:0.04979, lr:9.90e-03, fs:0.84685 (r=0.855,p=0.839),  time:32.129, tt:2409.701\n",
      "Ep:75, loss:0.00005, loss_test:0.04939, lr:9.80e-03, fs:0.85455 (r=0.855,p=0.855),  time:32.171, tt:2444.979\n",
      "Ep:76, loss:0.00005, loss_test:0.04884, lr:9.70e-03, fs:0.84685 (r=0.855,p=0.839),  time:32.162, tt:2476.470\n",
      "Ep:77, loss:0.00005, loss_test:0.04888, lr:9.61e-03, fs:0.83929 (r=0.855,p=0.825),  time:32.178, tt:2509.901\n",
      "Ep:78, loss:0.00005, loss_test:0.04833, lr:9.51e-03, fs:0.86239 (r=0.855,p=0.870),  time:32.160, tt:2540.620\n",
      "Ep:79, loss:0.00005, loss_test:0.04791, lr:9.41e-03, fs:0.84956 (r=0.873,p=0.828),  time:32.157, tt:2572.563\n",
      "Ep:80, loss:0.00005, loss_test:0.04761, lr:9.32e-03, fs:0.87037 (r=0.855,p=0.887),  time:32.151, tt:2604.234\n",
      "Ep:81, loss:0.00005, loss_test:0.04716, lr:9.23e-03, fs:0.85714 (r=0.873,p=0.842),  time:32.154, tt:2636.610\n",
      "Ep:82, loss:0.00004, loss_test:0.04701, lr:9.14e-03, fs:0.87037 (r=0.855,p=0.887),  time:32.165, tt:2669.708\n",
      "Ep:83, loss:0.00004, loss_test:0.04639, lr:9.04e-03, fs:0.85714 (r=0.873,p=0.842),  time:32.186, tt:2703.596\n",
      "Ep:84, loss:0.00004, loss_test:0.04640, lr:8.95e-03, fs:0.87037 (r=0.855,p=0.887),  time:32.196, tt:2736.670\n",
      "Ep:85, loss:0.00004, loss_test:0.04605, lr:8.86e-03, fs:0.87273 (r=0.873,p=0.873),  time:32.200, tt:2769.190\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00004, loss_test:0.04543, lr:8.86e-03, fs:0.88073 (r=0.873,p=0.889),  time:32.218, tt:2802.952\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00004, loss_test:0.04545, lr:8.86e-03, fs:0.87850 (r=0.855,p=0.904),  time:32.237, tt:2836.890\n",
      "Ep:88, loss:0.00004, loss_test:0.04498, lr:8.86e-03, fs:0.86486 (r=0.873,p=0.857),  time:32.254, tt:2870.573\n",
      "Ep:89, loss:0.00004, loss_test:0.04459, lr:8.86e-03, fs:0.87037 (r=0.855,p=0.887),  time:32.260, tt:2903.416\n",
      "Ep:90, loss:0.00004, loss_test:0.04464, lr:8.86e-03, fs:0.87273 (r=0.873,p=0.873),  time:32.273, tt:2936.806\n",
      "Ep:91, loss:0.00004, loss_test:0.04405, lr:8.86e-03, fs:0.88073 (r=0.873,p=0.889),  time:32.291, tt:2970.818\n",
      "Ep:92, loss:0.00004, loss_test:0.04426, lr:8.86e-03, fs:0.87037 (r=0.855,p=0.887),  time:32.312, tt:3004.969\n",
      "Ep:93, loss:0.00004, loss_test:0.04341, lr:8.86e-03, fs:0.88073 (r=0.873,p=0.889),  time:32.316, tt:3037.724\n",
      "Ep:94, loss:0.00004, loss_test:0.04362, lr:8.86e-03, fs:0.88073 (r=0.873,p=0.889),  time:32.328, tt:3071.183\n",
      "Ep:95, loss:0.00004, loss_test:0.04284, lr:8.86e-03, fs:0.87850 (r=0.855,p=0.904),  time:32.353, tt:3105.866\n",
      "Ep:96, loss:0.00004, loss_test:0.04249, lr:8.86e-03, fs:0.87273 (r=0.873,p=0.873),  time:32.405, tt:3143.313\n",
      "Ep:97, loss:0.00004, loss_test:0.04314, lr:8.86e-03, fs:0.89286 (r=0.909,p=0.877),  time:32.430, tt:3178.156\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00004, loss_test:0.04220, lr:8.86e-03, fs:0.88073 (r=0.873,p=0.889),  time:32.445, tt:3212.011\n",
      "Ep:99, loss:0.00004, loss_test:0.04292, lr:8.86e-03, fs:0.89286 (r=0.909,p=0.877),  time:32.452, tt:3245.209\n",
      "Ep:100, loss:0.00003, loss_test:0.04118, lr:8.86e-03, fs:0.88889 (r=0.873,p=0.906),  time:32.476, tt:3280.064\n",
      "Ep:101, loss:0.00003, loss_test:0.04141, lr:8.86e-03, fs:0.89091 (r=0.891,p=0.891),  time:32.502, tt:3315.202\n",
      "Ep:102, loss:0.00003, loss_test:0.04120, lr:8.86e-03, fs:0.89091 (r=0.891,p=0.891),  time:32.506, tt:3348.094\n",
      "Ep:103, loss:0.00003, loss_test:0.04020, lr:8.86e-03, fs:0.89908 (r=0.891,p=0.907),  time:32.507, tt:3380.679\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00003, loss_test:0.04028, lr:8.86e-03, fs:0.90090 (r=0.909,p=0.893),  time:32.517, tt:3414.334\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00003, loss_test:0.03979, lr:8.86e-03, fs:0.89908 (r=0.891,p=0.907),  time:32.525, tt:3447.604\n",
      "Ep:106, loss:0.00003, loss_test:0.04007, lr:8.86e-03, fs:0.90090 (r=0.909,p=0.893),  time:32.536, tt:3481.399\n",
      "Ep:107, loss:0.00003, loss_test:0.03889, lr:8.86e-03, fs:0.90909 (r=0.909,p=0.909),  time:32.545, tt:3514.834\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00003, loss_test:0.03902, lr:8.86e-03, fs:0.91071 (r=0.927,p=0.895),  time:32.553, tt:3548.309\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00003, loss_test:0.03852, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:32.536, tt:3578.924\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00003, loss_test:0.03847, lr:8.86e-03, fs:0.90909 (r=0.909,p=0.909),  time:32.531, tt:3610.929\n",
      "Ep:111, loss:0.00003, loss_test:0.03785, lr:8.86e-03, fs:0.90909 (r=0.909,p=0.909),  time:32.551, tt:3645.711\n",
      "Ep:112, loss:0.00003, loss_test:0.03759, lr:8.86e-03, fs:0.91743 (r=0.909,p=0.926),  time:32.549, tt:3678.070\n",
      "Ep:113, loss:0.00003, loss_test:0.03801, lr:8.86e-03, fs:0.91071 (r=0.927,p=0.895),  time:32.556, tt:3711.329\n",
      "Ep:114, loss:0.00003, loss_test:0.03732, lr:8.86e-03, fs:0.91743 (r=0.909,p=0.926),  time:32.571, tt:3745.656\n",
      "Ep:115, loss:0.00003, loss_test:0.03691, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:32.580, tt:3779.223\n",
      "Ep:116, loss:0.00003, loss_test:0.03662, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:32.579, tt:3811.695\n",
      "Ep:117, loss:0.00003, loss_test:0.03612, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.583, tt:3844.757\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00003, loss_test:0.03620, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:32.574, tt:3876.274\n",
      "Ep:119, loss:0.00002, loss_test:0.03604, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.571, tt:3908.482\n",
      "Ep:120, loss:0.00002, loss_test:0.03561, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:32.566, tt:3940.509\n",
      "Ep:121, loss:0.00002, loss_test:0.03547, lr:8.86e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.574, tt:3974.048\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00002, loss_test:0.03492, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.568, tt:4005.903\n",
      "Ep:123, loss:0.00002, loss_test:0.03537, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:32.566, tt:4038.129\n",
      "Ep:124, loss:0.00002, loss_test:0.03468, lr:8.86e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.565, tt:4070.653\n",
      "Ep:125, loss:0.00002, loss_test:0.03474, lr:8.86e-03, fs:0.91071 (r=0.927,p=0.895),  time:32.568, tt:4103.511\n",
      "Ep:126, loss:0.00002, loss_test:0.03469, lr:8.86e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.565, tt:4135.733\n",
      "Ep:127, loss:0.00002, loss_test:0.03420, lr:8.86e-03, fs:0.91071 (r=0.927,p=0.895),  time:32.560, tt:4167.656\n",
      "Ep:128, loss:0.00002, loss_test:0.03422, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.559, tt:4200.132\n",
      "Ep:129, loss:0.00002, loss_test:0.03347, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.560, tt:4232.818\n",
      "Ep:130, loss:0.00002, loss_test:0.03372, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.556, tt:4264.805\n",
      "Ep:131, loss:0.00002, loss_test:0.03300, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.564, tt:4298.400\n",
      "Ep:132, loss:0.00002, loss_test:0.03276, lr:8.86e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.569, tt:4331.620\n",
      "Ep:133, loss:0.00002, loss_test:0.03327, lr:8.78e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.566, tt:4363.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.03277, lr:8.69e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.567, tt:4396.586\n",
      "Ep:135, loss:0.00002, loss_test:0.03249, lr:8.60e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.578, tt:4430.562\n",
      "Ep:136, loss:0.00002, loss_test:0.03230, lr:8.51e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.576, tt:4462.919\n",
      "Ep:137, loss:0.00002, loss_test:0.03196, lr:8.43e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.584, tt:4496.627\n",
      "Ep:138, loss:0.00002, loss_test:0.03205, lr:8.35e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.590, tt:4530.024\n",
      "Ep:139, loss:0.00002, loss_test:0.03171, lr:8.26e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.580, tt:4561.159\n",
      "Ep:140, loss:0.00002, loss_test:0.03146, lr:8.18e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.572, tt:4592.672\n",
      "Ep:141, loss:0.00002, loss_test:0.03114, lr:8.10e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.571, tt:4625.151\n",
      "Ep:142, loss:0.00002, loss_test:0.03104, lr:8.02e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.574, tt:4658.118\n",
      "Ep:143, loss:0.00002, loss_test:0.03114, lr:7.94e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.574, tt:4690.646\n",
      "Ep:144, loss:0.00002, loss_test:0.03094, lr:7.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.575, tt:4723.320\n",
      "Ep:145, loss:0.00002, loss_test:0.03108, lr:7.78e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.575, tt:4755.923\n",
      "Ep:146, loss:0.00002, loss_test:0.03049, lr:7.70e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.584, tt:4789.834\n",
      "Ep:147, loss:0.00002, loss_test:0.03033, lr:7.62e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.588, tt:4823.052\n",
      "Ep:148, loss:0.00002, loss_test:0.03047, lr:7.55e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.588, tt:4855.621\n",
      "Ep:149, loss:0.00002, loss_test:0.03011, lr:7.47e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.584, tt:4887.527\n",
      "Ep:150, loss:0.00002, loss_test:0.03013, lr:7.40e-03, fs:0.93578 (r=0.927,p=0.944),  time:32.574, tt:4918.618\n",
      "Ep:151, loss:0.00002, loss_test:0.03002, lr:7.32e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.565, tt:4949.866\n",
      "Ep:152, loss:0.00002, loss_test:0.02958, lr:7.25e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.562, tt:4982.048\n",
      "Ep:153, loss:0.00002, loss_test:0.02968, lr:7.18e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.560, tt:5014.260\n",
      "Ep:154, loss:0.00002, loss_test:0.02956, lr:7.11e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.553, tt:5045.667\n",
      "Ep:155, loss:0.00001, loss_test:0.02951, lr:7.03e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.546, tt:5077.148\n",
      "Ep:156, loss:0.00001, loss_test:0.02918, lr:6.96e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.546, tt:5109.715\n",
      "Ep:157, loss:0.00001, loss_test:0.02915, lr:6.89e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.539, tt:5141.106\n",
      "Ep:158, loss:0.00001, loss_test:0.02882, lr:6.83e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.562, tt:5177.421\n",
      "Ep:159, loss:0.00001, loss_test:0.02872, lr:6.76e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.559, tt:5209.393\n",
      "Ep:160, loss:0.00001, loss_test:0.02875, lr:6.69e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.550, tt:5240.545\n",
      "Ep:161, loss:0.00001, loss_test:0.02873, lr:6.62e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.550, tt:5273.160\n",
      "Ep:162, loss:0.00001, loss_test:0.02890, lr:6.56e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.544, tt:5304.714\n",
      "Ep:163, loss:0.00001, loss_test:0.02846, lr:6.49e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.545, tt:5337.353\n",
      "Ep:164, loss:0.00001, loss_test:0.02861, lr:6.43e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.544, tt:5369.772\n",
      "Ep:165, loss:0.00001, loss_test:0.02827, lr:6.36e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.535, tt:5400.775\n",
      "Ep:166, loss:0.00001, loss_test:0.02829, lr:6.30e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.530, tt:5432.554\n",
      "Ep:167, loss:0.00001, loss_test:0.02807, lr:6.24e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.519, tt:5463.216\n",
      "Ep:168, loss:0.00001, loss_test:0.02798, lr:6.17e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.507, tt:5493.676\n",
      "Ep:169, loss:0.00001, loss_test:0.02803, lr:6.11e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.499, tt:5524.779\n",
      "Ep:170, loss:0.00001, loss_test:0.02785, lr:6.05e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.494, tt:5556.473\n",
      "Ep:171, loss:0.00001, loss_test:0.02776, lr:5.99e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.494, tt:5588.936\n",
      "Ep:172, loss:0.00001, loss_test:0.02779, lr:5.93e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.486, tt:5620.151\n",
      "Ep:173, loss:0.00001, loss_test:0.02768, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.472, tt:5650.204\n",
      "Ep:174, loss:0.00001, loss_test:0.02738, lr:5.81e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.462, tt:5680.935\n",
      "Ep:175, loss:0.00001, loss_test:0.02731, lr:5.75e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.453, tt:5711.769\n",
      "Ep:176, loss:0.00001, loss_test:0.02735, lr:5.70e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.448, tt:5743.265\n",
      "Ep:177, loss:0.00001, loss_test:0.02732, lr:5.64e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.438, tt:5774.048\n",
      "Ep:178, loss:0.00001, loss_test:0.02721, lr:5.58e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.436, tt:5806.108\n",
      "Ep:179, loss:0.00001, loss_test:0.02715, lr:5.53e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.428, tt:5837.044\n",
      "Ep:180, loss:0.00001, loss_test:0.02715, lr:5.47e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.418, tt:5867.607\n",
      "Ep:181, loss:0.00001, loss_test:0.02711, lr:5.42e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.414, tt:5899.427\n",
      "Ep:182, loss:0.00001, loss_test:0.02687, lr:5.36e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.415, tt:5931.910\n",
      "Ep:183, loss:0.00001, loss_test:0.02674, lr:5.31e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.402, tt:5962.003\n",
      "Ep:184, loss:0.00001, loss_test:0.02684, lr:5.26e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.408, tt:5995.535\n",
      "Ep:185, loss:0.00001, loss_test:0.02674, lr:5.20e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.405, tt:6027.397\n",
      "Ep:186, loss:0.00001, loss_test:0.02682, lr:5.15e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.401, tt:6058.997\n",
      "Ep:187, loss:0.00001, loss_test:0.02662, lr:5.10e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.395, tt:6090.344\n",
      "Ep:188, loss:0.00001, loss_test:0.02664, lr:5.05e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.388, tt:6121.311\n",
      "Ep:189, loss:0.00001, loss_test:0.02653, lr:5.00e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.382, tt:6152.541\n",
      "Ep:190, loss:0.00001, loss_test:0.02659, lr:4.95e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.388, tt:6186.159\n",
      "Ep:191, loss:0.00001, loss_test:0.02655, lr:4.90e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.383, tt:6217.602\n",
      "Ep:192, loss:0.00001, loss_test:0.02638, lr:4.85e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.380, tt:6249.346\n",
      "Ep:193, loss:0.00001, loss_test:0.02650, lr:4.80e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.376, tt:6280.893\n",
      "Ep:194, loss:0.00001, loss_test:0.02636, lr:4.75e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.366, tt:6311.368\n",
      "Ep:195, loss:0.00001, loss_test:0.02637, lr:4.71e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.359, tt:6342.311\n",
      "Ep:196, loss:0.00001, loss_test:0.02620, lr:4.66e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.358, tt:6374.590\n",
      "Ep:197, loss:0.00001, loss_test:0.02622, lr:4.61e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.354, tt:6406.149\n",
      "Ep:198, loss:0.00001, loss_test:0.02605, lr:4.57e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.349, tt:6437.445\n",
      "Ep:199, loss:0.00001, loss_test:0.02593, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.347, tt:6469.440\n",
      "Ep:200, loss:0.00001, loss_test:0.02608, lr:4.48e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.342, tt:6500.709\n",
      "Ep:201, loss:0.00001, loss_test:0.02599, lr:4.43e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.330, tt:6530.640\n",
      "Ep:202, loss:0.00001, loss_test:0.02600, lr:4.39e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.324, tt:6561.754\n",
      "Ep:203, loss:0.00001, loss_test:0.02593, lr:4.34e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.309, tt:6590.943\n",
      "Ep:204, loss:0.00001, loss_test:0.02576, lr:4.30e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.299, tt:6621.338\n",
      "Ep:205, loss:0.00001, loss_test:0.02580, lr:4.26e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.309, tt:6655.755\n",
      "Ep:206, loss:0.00001, loss_test:0.02584, lr:4.21e-03, fs:0.92727 (r=0.927,p=0.927),  time:32.285, tt:6682.961\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14529, lr:1.00e-02, fs:0.66250 (r=0.964,p=0.505),  time:20.357, tt:20.357\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14362, lr:1.00e-02, fs:0.64103 (r=0.909,p=0.495),  time:23.853, tt:47.707\n",
      "Ep:2, loss:0.00027, loss_test:0.14100, lr:1.00e-02, fs:0.62162 (r=0.836,p=0.495),  time:27.460, tt:82.381\n",
      "Ep:3, loss:0.00026, loss_test:0.13869, lr:1.00e-02, fs:0.62774 (r=0.782,p=0.524),  time:29.389, tt:117.557\n",
      "Ep:4, loss:0.00025, loss_test:0.13659, lr:1.00e-02, fs:0.60606 (r=0.727,p=0.519),  time:31.094, tt:155.472\n",
      "Ep:5, loss:0.00025, loss_test:0.13518, lr:1.00e-02, fs:0.61417 (r=0.709,p=0.542),  time:32.153, tt:192.919\n",
      "Ep:6, loss:0.00024, loss_test:0.13366, lr:1.00e-02, fs:0.60800 (r=0.691,p=0.543),  time:32.729, tt:229.103\n",
      "Ep:7, loss:0.00023, loss_test:0.13129, lr:1.00e-02, fs:0.60163 (r=0.673,p=0.544),  time:33.406, tt:267.251\n",
      "Ep:8, loss:0.00023, loss_test:0.12958, lr:1.00e-02, fs:0.60656 (r=0.673,p=0.552),  time:33.579, tt:302.214\n",
      "Ep:9, loss:0.00022, loss_test:0.12766, lr:1.00e-02, fs:0.61667 (r=0.673,p=0.569),  time:34.154, tt:341.544\n",
      "Ep:10, loss:0.00021, loss_test:0.12586, lr:1.00e-02, fs:0.60504 (r=0.655,p=0.562),  time:34.469, tt:379.155\n",
      "Ep:11, loss:0.00021, loss_test:0.12359, lr:1.00e-02, fs:0.61017 (r=0.655,p=0.571),  time:34.666, tt:415.997\n",
      "Ep:12, loss:0.00020, loss_test:0.12068, lr:9.90e-03, fs:0.59829 (r=0.636,p=0.565),  time:34.685, tt:450.900\n",
      "Ep:13, loss:0.00020, loss_test:0.11818, lr:9.80e-03, fs:0.63248 (r=0.673,p=0.597),  time:34.704, tt:485.852\n",
      "Ep:14, loss:0.00019, loss_test:0.11602, lr:9.70e-03, fs:0.66102 (r=0.709,p=0.619),  time:34.730, tt:520.947\n",
      "Ep:15, loss:0.00019, loss_test:0.11332, lr:9.61e-03, fs:0.64407 (r=0.691,p=0.603),  time:34.891, tt:558.262\n",
      "Ep:16, loss:0.00018, loss_test:0.11088, lr:9.51e-03, fs:0.64407 (r=0.691,p=0.603),  time:34.941, tt:593.990\n",
      "Ep:17, loss:0.00018, loss_test:0.10855, lr:9.41e-03, fs:0.67227 (r=0.727,p=0.625),  time:34.923, tt:628.618\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10657, lr:9.41e-03, fs:0.65546 (r=0.709,p=0.609),  time:35.030, tt:665.575\n",
      "Ep:19, loss:0.00017, loss_test:0.10463, lr:9.41e-03, fs:0.66102 (r=0.709,p=0.619),  time:35.138, tt:702.754\n",
      "Ep:20, loss:0.00016, loss_test:0.10202, lr:9.41e-03, fs:0.69027 (r=0.709,p=0.672),  time:35.164, tt:738.450\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09967, lr:9.41e-03, fs:0.70085 (r=0.745,p=0.661),  time:35.171, tt:773.758\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09751, lr:9.41e-03, fs:0.70085 (r=0.745,p=0.661),  time:35.190, tt:809.372\n",
      "Ep:23, loss:0.00015, loss_test:0.09499, lr:9.41e-03, fs:0.71186 (r=0.764,p=0.667),  time:35.273, tt:846.554\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09331, lr:9.41e-03, fs:0.72414 (r=0.764,p=0.689),  time:35.342, tt:883.554\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09099, lr:9.41e-03, fs:0.71186 (r=0.764,p=0.667),  time:35.469, tt:922.202\n",
      "Ep:26, loss:0.00013, loss_test:0.08797, lr:9.41e-03, fs:0.77586 (r=0.818,p=0.738),  time:35.539, tt:959.550\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08662, lr:9.41e-03, fs:0.76923 (r=0.818,p=0.726),  time:35.604, tt:996.900\n",
      "Ep:28, loss:0.00013, loss_test:0.08455, lr:9.41e-03, fs:0.79310 (r=0.836,p=0.754),  time:35.666, tt:1034.318\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08252, lr:9.41e-03, fs:0.78632 (r=0.836,p=0.742),  time:35.706, tt:1071.178\n",
      "Ep:30, loss:0.00012, loss_test:0.08116, lr:9.41e-03, fs:0.78261 (r=0.818,p=0.750),  time:35.756, tt:1108.438\n",
      "Ep:31, loss:0.00011, loss_test:0.07872, lr:9.41e-03, fs:0.82645 (r=0.909,p=0.758),  time:35.792, tt:1145.353\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07758, lr:9.41e-03, fs:0.82051 (r=0.873,p=0.774),  time:35.786, tt:1180.950\n",
      "Ep:33, loss:0.00011, loss_test:0.07667, lr:9.41e-03, fs:0.83607 (r=0.927,p=0.761),  time:35.828, tt:1218.164\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.07504, lr:9.41e-03, fs:0.84746 (r=0.909,p=0.794),  time:35.849, tt:1254.717\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07408, lr:9.41e-03, fs:0.83607 (r=0.927,p=0.761),  time:35.886, tt:1291.881\n",
      "Ep:36, loss:0.00010, loss_test:0.07294, lr:9.41e-03, fs:0.85000 (r=0.927,p=0.785),  time:35.922, tt:1329.113\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07133, lr:9.41e-03, fs:0.86885 (r=0.964,p=0.791),  time:35.927, tt:1365.213\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.06928, lr:9.41e-03, fs:0.85714 (r=0.927,p=0.797),  time:35.937, tt:1401.550\n",
      "Ep:39, loss:0.00009, loss_test:0.06923, lr:9.41e-03, fs:0.86885 (r=0.964,p=0.791),  time:35.980, tt:1439.180\n",
      "Ep:40, loss:0.00009, loss_test:0.06735, lr:9.41e-03, fs:0.85000 (r=0.927,p=0.785),  time:36.002, tt:1476.088\n",
      "Ep:41, loss:0.00009, loss_test:0.06706, lr:9.41e-03, fs:0.86885 (r=0.964,p=0.791),  time:36.048, tt:1514.032\n",
      "Ep:42, loss:0.00008, loss_test:0.06469, lr:9.41e-03, fs:0.88525 (r=0.982,p=0.806),  time:36.046, tt:1549.995\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06407, lr:9.41e-03, fs:0.87395 (r=0.945,p=0.812),  time:36.073, tt:1587.231\n",
      "Ep:44, loss:0.00008, loss_test:0.06282, lr:9.41e-03, fs:0.89256 (r=0.982,p=0.818),  time:36.095, tt:1624.262\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06181, lr:9.41e-03, fs:0.88525 (r=0.982,p=0.806),  time:36.146, tt:1662.738\n",
      "Ep:46, loss:0.00007, loss_test:0.06173, lr:9.41e-03, fs:0.88333 (r=0.964,p=0.815),  time:36.225, tt:1702.566\n",
      "Ep:47, loss:0.00007, loss_test:0.06049, lr:9.41e-03, fs:0.87603 (r=0.964,p=0.803),  time:36.206, tt:1737.889\n",
      "Ep:48, loss:0.00007, loss_test:0.06100, lr:9.41e-03, fs:0.87603 (r=0.964,p=0.803),  time:36.203, tt:1773.957\n",
      "Ep:49, loss:0.00007, loss_test:0.05885, lr:9.41e-03, fs:0.88525 (r=0.982,p=0.806),  time:36.205, tt:1810.272\n",
      "Ep:50, loss:0.00007, loss_test:0.05868, lr:9.41e-03, fs:0.89076 (r=0.964,p=0.828),  time:36.225, tt:1847.472\n",
      "Ep:51, loss:0.00007, loss_test:0.05678, lr:9.41e-03, fs:0.88333 (r=0.964,p=0.815),  time:36.238, tt:1884.395\n",
      "Ep:52, loss:0.00006, loss_test:0.05709, lr:9.41e-03, fs:0.88333 (r=0.964,p=0.815),  time:36.264, tt:1921.990\n",
      "Ep:53, loss:0.00006, loss_test:0.05645, lr:9.41e-03, fs:0.89831 (r=0.964,p=0.841),  time:36.220, tt:1955.901\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.05808, lr:9.41e-03, fs:0.85714 (r=0.927,p=0.797),  time:36.259, tt:1994.232\n",
      "Ep:55, loss:0.00006, loss_test:0.05486, lr:9.41e-03, fs:0.89831 (r=0.964,p=0.841),  time:36.268, tt:2031.027\n",
      "Ep:56, loss:0.00006, loss_test:0.05509, lr:9.41e-03, fs:0.87931 (r=0.927,p=0.836),  time:36.284, tt:2068.191\n",
      "Ep:57, loss:0.00006, loss_test:0.05230, lr:9.41e-03, fs:0.89076 (r=0.964,p=0.828),  time:36.297, tt:2105.218\n",
      "Ep:58, loss:0.00006, loss_test:0.05343, lr:9.41e-03, fs:0.86207 (r=0.909,p=0.820),  time:36.296, tt:2141.445\n",
      "Ep:62, loss:0.00005, loss_test:0.05287, lr:9.41e-03, fs:0.85470 (r=0.909,p=0.806),  time:36.272, tt:2285.153\n",
      "Ep:63, loss:0.00005, loss_test:0.04823, lr:9.41e-03, fs:0.88889 (r=0.945,p=0.839),  time:36.258, tt:2320.526\n",
      "Ep:64, loss:0.00005, loss_test:0.04896, lr:9.41e-03, fs:0.86207 (r=0.909,p=0.820),  time:36.258, tt:2356.774\n",
      "Ep:65, loss:0.00005, loss_test:0.04681, lr:9.32e-03, fs:0.88889 (r=0.945,p=0.839),  time:36.243, tt:2392.040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00005, loss_test:0.04832, lr:9.23e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.250, tt:2428.731\n",
      "Ep:67, loss:0.00005, loss_test:0.04570, lr:9.14e-03, fs:0.86957 (r=0.909,p=0.833),  time:36.247, tt:2464.778\n",
      "Ep:68, loss:0.00004, loss_test:0.04590, lr:9.04e-03, fs:0.86957 (r=0.909,p=0.833),  time:36.231, tt:2499.917\n",
      "Ep:69, loss:0.00004, loss_test:0.04608, lr:8.95e-03, fs:0.87719 (r=0.909,p=0.847),  time:36.224, tt:2535.704\n",
      "Ep:70, loss:0.00004, loss_test:0.04457, lr:8.86e-03, fs:0.87719 (r=0.909,p=0.847),  time:36.213, tt:2571.096\n",
      "Ep:71, loss:0.00004, loss_test:0.04414, lr:8.78e-03, fs:0.87719 (r=0.909,p=0.847),  time:36.219, tt:2607.799\n",
      "Ep:72, loss:0.00004, loss_test:0.04305, lr:8.69e-03, fs:0.87719 (r=0.909,p=0.847),  time:36.230, tt:2644.823\n",
      "Ep:73, loss:0.00004, loss_test:0.04558, lr:8.60e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.246, tt:2682.186\n",
      "Ep:74, loss:0.00004, loss_test:0.04177, lr:8.51e-03, fs:0.90435 (r=0.945,p=0.867),  time:36.275, tt:2720.610\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.04413, lr:8.51e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.271, tt:2756.598\n",
      "Ep:76, loss:0.00004, loss_test:0.04106, lr:8.51e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.267, tt:2792.541\n",
      "Ep:77, loss:0.00004, loss_test:0.04217, lr:8.51e-03, fs:0.87719 (r=0.909,p=0.847),  time:36.255, tt:2827.884\n",
      "Ep:78, loss:0.00004, loss_test:0.04053, lr:8.51e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.258, tt:2864.350\n",
      "Ep:79, loss:0.00004, loss_test:0.04057, lr:8.51e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.256, tt:2900.456\n",
      "Ep:80, loss:0.00003, loss_test:0.04115, lr:8.51e-03, fs:0.87719 (r=0.909,p=0.847),  time:36.256, tt:2936.755\n",
      "Ep:81, loss:0.00003, loss_test:0.04185, lr:8.51e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.239, tt:2971.591\n",
      "Ep:82, loss:0.00003, loss_test:0.03952, lr:8.51e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.238, tt:3007.774\n",
      "Ep:83, loss:0.00003, loss_test:0.04105, lr:8.51e-03, fs:0.86957 (r=0.909,p=0.833),  time:36.220, tt:3042.473\n",
      "Ep:84, loss:0.00003, loss_test:0.04034, lr:8.51e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.212, tt:3078.045\n",
      "Ep:85, loss:0.00003, loss_test:0.03882, lr:8.51e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.185, tt:3111.874\n",
      "Ep:86, loss:0.00003, loss_test:0.03986, lr:8.43e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.181, tt:3147.710\n",
      "Ep:87, loss:0.00003, loss_test:0.03821, lr:8.35e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.174, tt:3183.329\n",
      "Ep:88, loss:0.00003, loss_test:0.04156, lr:8.26e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.165, tt:3218.693\n",
      "Ep:89, loss:0.00003, loss_test:0.03906, lr:8.18e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.151, tt:3253.632\n",
      "Ep:90, loss:0.00003, loss_test:0.03962, lr:8.10e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.143, tt:3288.971\n",
      "Ep:91, loss:0.00003, loss_test:0.03802, lr:8.02e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.132, tt:3324.166\n",
      "Ep:92, loss:0.00003, loss_test:0.04061, lr:7.94e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.104, tt:3357.702\n",
      "Ep:93, loss:0.00003, loss_test:0.03826, lr:7.86e-03, fs:0.89474 (r=0.927,p=0.864),  time:36.091, tt:3392.593\n",
      "Ep:94, loss:0.00003, loss_test:0.03991, lr:7.78e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.084, tt:3428.021\n",
      "Ep:95, loss:0.00003, loss_test:0.03783, lr:7.70e-03, fs:0.88496 (r=0.909,p=0.862),  time:36.087, tt:3464.341\n",
      "Ep:96, loss:0.00003, loss_test:0.03914, lr:7.62e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.086, tt:3500.315\n",
      "Ep:97, loss:0.00003, loss_test:0.03662, lr:7.55e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.085, tt:3536.346\n",
      "Ep:98, loss:0.00003, loss_test:0.03971, lr:7.47e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.082, tt:3572.146\n",
      "Ep:99, loss:0.00003, loss_test:0.03663, lr:7.40e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.083, tt:3608.313\n",
      "Ep:100, loss:0.00003, loss_test:0.03866, lr:7.32e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.068, tt:3642.824\n",
      "Ep:101, loss:0.00003, loss_test:0.03620, lr:7.25e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.059, tt:3677.982\n",
      "Ep:102, loss:0.00003, loss_test:0.03707, lr:7.18e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.046, tt:3712.753\n",
      "Ep:103, loss:0.00003, loss_test:0.03639, lr:7.11e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.041, tt:3748.237\n",
      "Ep:104, loss:0.00002, loss_test:0.03579, lr:7.03e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.028, tt:3782.896\n",
      "Ep:105, loss:0.00002, loss_test:0.03759, lr:6.96e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.031, tt:3819.288\n",
      "Ep:106, loss:0.00002, loss_test:0.03561, lr:6.89e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.043, tt:3856.611\n",
      "Ep:107, loss:0.00002, loss_test:0.03751, lr:6.83e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.038, tt:3892.086\n",
      "Ep:108, loss:0.00002, loss_test:0.03534, lr:6.76e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.031, tt:3927.361\n",
      "Ep:109, loss:0.00002, loss_test:0.03513, lr:6.69e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.042, tt:3964.660\n",
      "Ep:110, loss:0.00002, loss_test:0.03621, lr:6.62e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.032, tt:3999.535\n",
      "Ep:111, loss:0.00002, loss_test:0.03430, lr:6.56e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.022, tt:4034.495\n",
      "Ep:112, loss:0.00002, loss_test:0.03672, lr:6.49e-03, fs:0.89286 (r=0.909,p=0.877),  time:36.006, tt:4068.642\n",
      "Ep:113, loss:0.00002, loss_test:0.03481, lr:6.43e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.008, tt:4104.922\n",
      "Ep:114, loss:0.00002, loss_test:0.03467, lr:6.36e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.017, tt:4141.977\n",
      "Ep:115, loss:0.00002, loss_test:0.03525, lr:6.30e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.008, tt:4176.980\n",
      "Ep:116, loss:0.00002, loss_test:0.03354, lr:6.24e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.002, tt:4212.236\n",
      "Ep:117, loss:0.00002, loss_test:0.03486, lr:6.17e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.017, tt:4249.976\n",
      "Ep:118, loss:0.00002, loss_test:0.03383, lr:6.11e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.006, tt:4284.663\n",
      "Ep:119, loss:0.00002, loss_test:0.03426, lr:6.05e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.013, tt:4321.535\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00002, loss_test:0.03477, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.009, tt:4357.099\n",
      "Ep:121, loss:0.00002, loss_test:0.03347, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.011, tt:4393.369\n",
      "Ep:122, loss:0.00002, loss_test:0.03393, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.001, tt:4428.146\n",
      "Ep:123, loss:0.00002, loss_test:0.03352, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.006, tt:4464.785\n",
      "Ep:124, loss:0.00002, loss_test:0.03321, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.002, tt:4500.311\n",
      "Ep:125, loss:0.00002, loss_test:0.03316, lr:6.05e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.017, tt:4538.106\n",
      "Ep:126, loss:0.00002, loss_test:0.03340, lr:6.05e-03, fs:0.91071 (r=0.927,p=0.895),  time:36.017, tt:4574.204\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.03267, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.014, tt:4609.802\n",
      "Ep:128, loss:0.00002, loss_test:0.03352, lr:6.05e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.016, tt:4646.121\n",
      "Ep:129, loss:0.00002, loss_test:0.03264, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:36.002, tt:4680.224\n",
      "Ep:130, loss:0.00002, loss_test:0.03270, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:35.999, tt:4715.807\n",
      "Ep:131, loss:0.00002, loss_test:0.03373, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:35.999, tt:4751.903\n",
      "Ep:132, loss:0.00002, loss_test:0.03227, lr:6.05e-03, fs:0.91071 (r=0.927,p=0.895),  time:36.002, tt:4788.226\n",
      "Ep:133, loss:0.00002, loss_test:0.03249, lr:6.05e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.003, tt:4824.377\n",
      "Ep:134, loss:0.00002, loss_test:0.03222, lr:6.05e-03, fs:0.90265 (r=0.927,p=0.879),  time:36.001, tt:4860.180\n",
      "Ep:135, loss:0.00002, loss_test:0.03282, lr:6.05e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.005, tt:4896.706\n",
      "Ep:136, loss:0.00002, loss_test:0.03226, lr:6.05e-03, fs:0.90265 (r=0.927,p=0.879),  time:35.991, tt:4930.773\n",
      "Ep:137, loss:0.00002, loss_test:0.03213, lr:6.05e-03, fs:0.90090 (r=0.909,p=0.893),  time:35.989, tt:4966.529\n",
      "Ep:138, loss:0.00002, loss_test:0.03143, lr:5.99e-03, fs:0.91071 (r=0.927,p=0.895),  time:35.993, tt:5003.086\n",
      "Ep:139, loss:0.00001, loss_test:0.03204, lr:5.93e-03, fs:0.91071 (r=0.927,p=0.895),  time:36.026, tt:5043.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.03187, lr:5.87e-03, fs:0.91892 (r=0.927,p=0.911),  time:36.011, tt:5077.620\n",
      "##########Best model found so far##########\n",
      "Ep:141, loss:0.00002, loss_test:0.03216, lr:5.87e-03, fs:0.91071 (r=0.927,p=0.895),  time:36.012, tt:5113.711\n",
      "Ep:142, loss:0.00001, loss_test:0.03250, lr:5.87e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.011, tt:5149.622\n",
      "Ep:143, loss:0.00001, loss_test:0.03102, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.010, tt:5185.505\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00001, loss_test:0.03325, lr:5.87e-03, fs:0.91892 (r=0.927,p=0.911),  time:36.010, tt:5221.470\n",
      "Ep:145, loss:0.00001, loss_test:0.03073, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.007, tt:5257.053\n",
      "Ep:146, loss:0.00001, loss_test:0.03252, lr:5.87e-03, fs:0.91071 (r=0.927,p=0.895),  time:35.995, tt:5291.273\n",
      "Ep:147, loss:0.00001, loss_test:0.03103, lr:5.87e-03, fs:0.91892 (r=0.927,p=0.911),  time:35.987, tt:5326.078\n",
      "Ep:148, loss:0.00001, loss_test:0.03125, lr:5.87e-03, fs:0.91892 (r=0.927,p=0.911),  time:35.978, tt:5360.749\n",
      "Ep:149, loss:0.00001, loss_test:0.03146, lr:5.87e-03, fs:0.91892 (r=0.927,p=0.911),  time:35.955, tt:5393.216\n",
      "Ep:150, loss:0.00001, loss_test:0.03034, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.937, tt:5426.516\n",
      "Ep:151, loss:0.00001, loss_test:0.03265, lr:5.87e-03, fs:0.91071 (r=0.927,p=0.895),  time:35.947, tt:5463.943\n",
      "Ep:152, loss:0.00001, loss_test:0.03035, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.942, tt:5499.138\n",
      "Ep:153, loss:0.00001, loss_test:0.03109, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.939, tt:5534.665\n",
      "Ep:154, loss:0.00001, loss_test:0.03111, lr:5.87e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.938, tt:5570.429\n",
      "Ep:155, loss:0.00001, loss_test:0.03036, lr:5.81e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.943, tt:5607.048\n",
      "Ep:156, loss:0.00001, loss_test:0.03175, lr:5.75e-03, fs:0.91892 (r=0.927,p=0.911),  time:35.949, tt:5644.046\n",
      "Ep:157, loss:0.00001, loss_test:0.03045, lr:5.70e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.950, tt:5680.165\n",
      "Ep:158, loss:0.00001, loss_test:0.03129, lr:5.64e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.974, tt:5719.788\n",
      "Ep:159, loss:0.00001, loss_test:0.03102, lr:5.58e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.987, tt:5757.843\n",
      "Ep:160, loss:0.00001, loss_test:0.03044, lr:5.53e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.990, tt:5794.405\n",
      "Ep:161, loss:0.00001, loss_test:0.03074, lr:5.47e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.994, tt:5830.970\n",
      "Ep:162, loss:0.00001, loss_test:0.03075, lr:5.42e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.988, tt:5866.004\n",
      "Ep:163, loss:0.00001, loss_test:0.03024, lr:5.36e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.982, tt:5901.096\n",
      "Ep:164, loss:0.00001, loss_test:0.03064, lr:5.31e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.983, tt:5937.267\n",
      "Ep:165, loss:0.00001, loss_test:0.03000, lr:5.26e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.983, tt:5973.235\n",
      "Ep:166, loss:0.00001, loss_test:0.03062, lr:5.20e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.987, tt:6009.752\n",
      "Ep:167, loss:0.00001, loss_test:0.03014, lr:5.15e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.983, tt:6045.211\n",
      "Ep:168, loss:0.00001, loss_test:0.02997, lr:5.10e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.985, tt:6081.461\n",
      "Ep:169, loss:0.00001, loss_test:0.03050, lr:5.05e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.983, tt:6117.056\n",
      "Ep:170, loss:0.00001, loss_test:0.02968, lr:5.00e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.985, tt:6153.430\n",
      "Ep:171, loss:0.00001, loss_test:0.03068, lr:4.95e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.985, tt:6189.394\n",
      "Ep:172, loss:0.00001, loss_test:0.02980, lr:4.90e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.992, tt:6226.665\n",
      "Ep:173, loss:0.00001, loss_test:0.03050, lr:4.85e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.993, tt:6262.770\n",
      "Ep:174, loss:0.00001, loss_test:0.02975, lr:4.80e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.986, tt:6297.532\n",
      "Ep:175, loss:0.00001, loss_test:0.02999, lr:4.75e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.983, tt:6332.983\n",
      "Ep:176, loss:0.00001, loss_test:0.02975, lr:4.71e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.989, tt:6370.026\n",
      "Ep:177, loss:0.00001, loss_test:0.02985, lr:4.66e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.993, tt:6406.666\n",
      "Ep:178, loss:0.00001, loss_test:0.03008, lr:4.61e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.995, tt:6443.087\n",
      "Ep:179, loss:0.00001, loss_test:0.02944, lr:4.57e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.999, tt:6479.882\n",
      "Ep:180, loss:0.00001, loss_test:0.02988, lr:4.52e-03, fs:0.93578 (r=0.927,p=0.944),  time:35.996, tt:6515.313\n",
      "##########Best model found so far##########\n",
      "Ep:181, loss:0.00001, loss_test:0.02950, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.997, tt:6551.512\n",
      "Ep:182, loss:0.00001, loss_test:0.02992, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.004, tt:6588.723\n",
      "Ep:183, loss:0.00001, loss_test:0.02921, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.010, tt:6625.767\n",
      "Ep:184, loss:0.00001, loss_test:0.02980, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.015, tt:6662.789\n",
      "Ep:185, loss:0.00001, loss_test:0.02926, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.020, tt:6699.653\n",
      "Ep:186, loss:0.00001, loss_test:0.02934, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.038, tt:6739.163\n",
      "Ep:187, loss:0.00001, loss_test:0.03027, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.043, tt:6776.018\n",
      "Ep:188, loss:0.00001, loss_test:0.02876, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.051, tt:6813.600\n",
      "Ep:189, loss:0.00001, loss_test:0.02986, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.063, tt:6851.919\n",
      "Ep:190, loss:0.00001, loss_test:0.02910, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.076, tt:6890.598\n",
      "Ep:191, loss:0.00001, loss_test:0.02905, lr:4.52e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.073, tt:6925.998\n",
      "Ep:192, loss:0.00001, loss_test:0.03029, lr:4.48e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.071, tt:6961.622\n",
      "Ep:193, loss:0.00001, loss_test:0.02853, lr:4.43e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.082, tt:6999.813\n",
      "Ep:194, loss:0.00001, loss_test:0.02939, lr:4.39e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.084, tt:7036.312\n",
      "Ep:195, loss:0.00001, loss_test:0.02921, lr:4.34e-03, fs:0.93578 (r=0.927,p=0.944),  time:36.091, tt:7073.867\n",
      "Ep:196, loss:0.00001, loss_test:0.02839, lr:4.30e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.105, tt:7112.758\n",
      "Ep:197, loss:0.00001, loss_test:0.02966, lr:4.26e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.109, tt:7149.514\n",
      "Ep:198, loss:0.00001, loss_test:0.02872, lr:4.21e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.113, tt:7186.565\n",
      "Ep:199, loss:0.00001, loss_test:0.02884, lr:4.17e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.128, tt:7225.648\n",
      "Ep:200, loss:0.00001, loss_test:0.02929, lr:4.13e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.140, tt:7264.235\n",
      "Ep:201, loss:0.00001, loss_test:0.02865, lr:4.09e-03, fs:0.93578 (r=0.927,p=0.944),  time:36.150, tt:7302.330\n",
      "Ep:202, loss:0.00001, loss_test:0.02896, lr:4.05e-03, fs:0.93578 (r=0.927,p=0.944),  time:36.165, tt:7341.569\n",
      "Ep:203, loss:0.00001, loss_test:0.02886, lr:4.01e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.177, tt:7380.184\n",
      "Ep:204, loss:0.00001, loss_test:0.02873, lr:3.97e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.187, tt:7418.256\n",
      "Ep:205, loss:0.00001, loss_test:0.02889, lr:3.93e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.191, tt:7455.384\n",
      "Ep:206, loss:0.00001, loss_test:0.02876, lr:3.89e-03, fs:0.92727 (r=0.927,p=0.927),  time:36.189, tt:7491.182\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03046, lr:6.00e-02, fs:0.62400 (r=0.709,p=0.557),  time:30.692, tt:30.692\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02570, lr:6.00e-02, fs:0.63087 (r=0.855,p=0.500),  time:31.285, tt:62.569\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02644, lr:6.00e-02, fs:0.65000 (r=0.945,p=0.495),  time:32.263, tt:96.788\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02671, lr:6.00e-02, fs:0.64516 (r=0.909,p=0.500),  time:33.007, tt:132.029\n",
      "Ep:4, loss:0.00005, loss_test:0.02708, lr:6.00e-02, fs:0.63576 (r=0.873,p=0.500),  time:33.217, tt:166.085\n",
      "Ep:5, loss:0.00005, loss_test:0.02725, lr:6.00e-02, fs:0.59722 (r=0.782,p=0.483),  time:33.454, tt:200.725\n",
      "Ep:6, loss:0.00005, loss_test:0.02732, lr:6.00e-02, fs:0.60432 (r=0.764,p=0.500),  time:33.591, tt:235.139\n",
      "Ep:7, loss:0.00005, loss_test:0.02713, lr:6.00e-02, fs:0.61314 (r=0.764,p=0.512),  time:33.810, tt:270.482\n",
      "Ep:8, loss:0.00005, loss_test:0.02650, lr:6.00e-02, fs:0.62774 (r=0.782,p=0.524),  time:34.003, tt:306.027\n",
      "Ep:9, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.61871 (r=0.782,p=0.512),  time:34.181, tt:341.806\n",
      "Ep:10, loss:0.00004, loss_test:0.02559, lr:6.00e-02, fs:0.61538 (r=0.800,p=0.500),  time:34.103, tt:375.129\n",
      "Ep:11, loss:0.00004, loss_test:0.02549, lr:6.00e-02, fs:0.61314 (r=0.764,p=0.512),  time:34.064, tt:408.767\n",
      "Ep:12, loss:0.00004, loss_test:0.02566, lr:6.00e-02, fs:0.61654 (r=0.745,p=0.526),  time:34.175, tt:444.280\n",
      "Ep:13, loss:0.00004, loss_test:0.02559, lr:6.00e-02, fs:0.59542 (r=0.709,p=0.513),  time:34.186, tt:478.608\n",
      "Ep:14, loss:0.00004, loss_test:0.02496, lr:5.94e-02, fs:0.60294 (r=0.745,p=0.506),  time:34.242, tt:513.631\n",
      "Ep:15, loss:0.00004, loss_test:0.02442, lr:5.88e-02, fs:0.59574 (r=0.764,p=0.488),  time:34.478, tt:551.651\n",
      "Ep:16, loss:0.00004, loss_test:0.02401, lr:5.82e-02, fs:0.60140 (r=0.782,p=0.489),  time:34.508, tt:586.636\n",
      "Ep:17, loss:0.00004, loss_test:0.02382, lr:5.76e-02, fs:0.59259 (r=0.727,p=0.500),  time:34.581, tt:622.458\n",
      "Ep:18, loss:0.00004, loss_test:0.02364, lr:5.71e-02, fs:0.58647 (r=0.709,p=0.500),  time:34.573, tt:656.889\n",
      "Ep:19, loss:0.00004, loss_test:0.02314, lr:5.65e-02, fs:0.59259 (r=0.727,p=0.500),  time:34.592, tt:691.839\n",
      "Ep:20, loss:0.00003, loss_test:0.02254, lr:5.59e-02, fs:0.60432 (r=0.764,p=0.500),  time:34.573, tt:726.037\n",
      "Ep:21, loss:0.00003, loss_test:0.02205, lr:5.54e-02, fs:0.62937 (r=0.818,p=0.511),  time:34.562, tt:760.365\n",
      "Ep:22, loss:0.00003, loss_test:0.02179, lr:5.48e-02, fs:0.61314 (r=0.764,p=0.512),  time:34.573, tt:795.170\n",
      "Ep:23, loss:0.00003, loss_test:0.02150, lr:5.43e-02, fs:0.61765 (r=0.764,p=0.519),  time:34.555, tt:829.324\n",
      "Ep:24, loss:0.00003, loss_test:0.02097, lr:5.37e-02, fs:0.63235 (r=0.782,p=0.531),  time:34.591, tt:864.783\n",
      "Ep:25, loss:0.00003, loss_test:0.02044, lr:5.32e-02, fs:0.65693 (r=0.818,p=0.549),  time:34.593, tt:899.431\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.02002, lr:5.32e-02, fs:0.66176 (r=0.818,p=0.556),  time:34.617, tt:934.650\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01964, lr:5.32e-02, fs:0.66176 (r=0.818,p=0.556),  time:34.642, tt:969.967\n",
      "Ep:28, loss:0.00003, loss_test:0.01920, lr:5.32e-02, fs:0.67647 (r=0.836,p=0.568),  time:34.688, tt:1005.949\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01881, lr:5.32e-02, fs:0.66667 (r=0.818,p=0.562),  time:34.722, tt:1041.668\n",
      "Ep:30, loss:0.00003, loss_test:0.01826, lr:5.32e-02, fs:0.69173 (r=0.836,p=0.590),  time:34.752, tt:1077.299\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01768, lr:5.32e-02, fs:0.70149 (r=0.855,p=0.595),  time:34.748, tt:1111.937\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01717, lr:5.32e-02, fs:0.72180 (r=0.873,p=0.615),  time:34.706, tt:1145.306\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01662, lr:5.32e-02, fs:0.71642 (r=0.873,p=0.608),  time:34.714, tt:1180.262\n",
      "Ep:34, loss:0.00002, loss_test:0.01607, lr:5.32e-02, fs:0.71642 (r=0.873,p=0.608),  time:34.730, tt:1215.533\n",
      "Ep:35, loss:0.00002, loss_test:0.01575, lr:5.32e-02, fs:0.73282 (r=0.873,p=0.632),  time:34.742, tt:1250.712\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01524, lr:5.32e-02, fs:0.74419 (r=0.873,p=0.649),  time:34.711, tt:1284.322\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01480, lr:5.32e-02, fs:0.75758 (r=0.909,p=0.649),  time:34.670, tt:1317.465\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01456, lr:5.32e-02, fs:0.76336 (r=0.909,p=0.658),  time:34.636, tt:1350.818\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01418, lr:5.32e-02, fs:0.76923 (r=0.909,p=0.667),  time:34.670, tt:1386.810\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01379, lr:5.32e-02, fs:0.77273 (r=0.927,p=0.662),  time:34.730, tt:1423.930\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01344, lr:5.32e-02, fs:0.78788 (r=0.945,p=0.675),  time:34.742, tt:1459.146\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01303, lr:5.32e-02, fs:0.80000 (r=0.945,p=0.693),  time:34.756, tt:1494.505\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01282, lr:5.32e-02, fs:0.80000 (r=0.945,p=0.693),  time:34.797, tt:1531.060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02092, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:14.060, tt:14.060\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02609, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.911, tt:31.822\n",
      "Ep:2, loss:0.00005, loss_test:0.02769, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:18.238, tt:54.715\n",
      "Ep:3, loss:0.00006, loss_test:0.02771, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:21.134, tt:84.536\n",
      "Ep:4, loss:0.00006, loss_test:0.02704, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:23.188, tt:115.938\n",
      "Ep:5, loss:0.00005, loss_test:0.02639, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:24.294, tt:145.762\n",
      "Ep:6, loss:0.00005, loss_test:0.02540, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:25.095, tt:175.666\n",
      "Ep:7, loss:0.00005, loss_test:0.02435, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:25.796, tt:206.368\n",
      "Ep:8, loss:0.00005, loss_test:0.02362, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:26.266, tt:236.398\n",
      "Ep:9, loss:0.00005, loss_test:0.02296, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:26.560, tt:265.600\n",
      "Ep:10, loss:0.00005, loss_test:0.02225, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:26.926, tt:296.184\n",
      "Ep:11, loss:0.00005, loss_test:0.02157, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:27.194, tt:326.324\n",
      "Ep:12, loss:0.00005, loss_test:0.02107, lr:5.94e-02, fs:0.67407 (r=0.919,p=0.532),  time:27.454, tt:356.904\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00005, loss_test:0.02040, lr:5.94e-02, fs:0.66917 (r=0.899,p=0.533),  time:27.682, tt:387.551\n",
      "Ep:14, loss:0.00005, loss_test:0.01962, lr:5.94e-02, fs:0.67424 (r=0.899,p=0.539),  time:27.881, tt:418.221\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01888, lr:5.94e-02, fs:0.68462 (r=0.899,p=0.553),  time:28.047, tt:448.753\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01838, lr:5.94e-02, fs:0.68775 (r=0.879,p=0.565),  time:28.233, tt:479.956\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01812, lr:5.94e-02, fs:0.69841 (r=0.889,p=0.575),  time:28.417, tt:511.503\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01797, lr:5.94e-02, fs:0.69804 (r=0.899,p=0.571),  time:28.537, tt:542.211\n",
      "Ep:19, loss:0.00004, loss_test:0.01779, lr:5.94e-02, fs:0.70079 (r=0.899,p=0.574),  time:28.621, tt:572.419\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01754, lr:5.94e-02, fs:0.70079 (r=0.899,p=0.574),  time:28.675, tt:602.183\n",
      "Ep:21, loss:0.00004, loss_test:0.01724, lr:5.94e-02, fs:0.70079 (r=0.899,p=0.574),  time:28.754, tt:632.579\n",
      "Ep:22, loss:0.00004, loss_test:0.01698, lr:5.94e-02, fs:0.70356 (r=0.899,p=0.578),  time:28.811, tt:662.653\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01673, lr:5.94e-02, fs:0.69600 (r=0.879,p=0.576),  time:28.851, tt:692.425\n",
      "Ep:24, loss:0.00004, loss_test:0.01655, lr:5.94e-02, fs:0.69600 (r=0.879,p=0.576),  time:28.917, tt:722.916\n",
      "Ep:25, loss:0.00004, loss_test:0.01633, lr:5.94e-02, fs:0.69880 (r=0.879,p=0.580),  time:29.031, tt:754.816\n",
      "Ep:26, loss:0.00004, loss_test:0.01611, lr:5.94e-02, fs:0.69880 (r=0.879,p=0.580),  time:29.134, tt:786.619\n",
      "Ep:27, loss:0.00004, loss_test:0.01590, lr:5.94e-02, fs:0.71255 (r=0.889,p=0.595),  time:29.299, tt:820.370\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01571, lr:5.94e-02, fs:0.71311 (r=0.879,p=0.600),  time:29.399, tt:852.569\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01555, lr:5.94e-02, fs:0.72428 (r=0.889,p=0.611),  time:29.450, tt:883.501\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.01544, lr:5.94e-02, fs:0.74074 (r=0.909,p=0.625),  time:29.528, tt:915.373\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.01532, lr:5.94e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.578, tt:946.488\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00004, loss_test:0.01524, lr:5.94e-02, fs:0.74074 (r=0.909,p=0.625),  time:29.610, tt:977.120\n",
      "Ep:33, loss:0.00004, loss_test:0.01519, lr:5.94e-02, fs:0.74590 (r=0.919,p=0.628),  time:29.630, tt:1007.413\n",
      "Ep:34, loss:0.00003, loss_test:0.01511, lr:5.94e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.664, tt:1038.241\n",
      "Ep:35, loss:0.00003, loss_test:0.01507, lr:5.94e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.682, tt:1068.550\n",
      "Ep:36, loss:0.00003, loss_test:0.01502, lr:5.94e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.699, tt:1098.856\n",
      "Ep:37, loss:0.00003, loss_test:0.01501, lr:5.94e-02, fs:0.75410 (r=0.929,p=0.634),  time:29.767, tt:1131.130\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01498, lr:5.94e-02, fs:0.76230 (r=0.939,p=0.641),  time:29.796, tt:1162.026\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01496, lr:5.94e-02, fs:0.76230 (r=0.939,p=0.641),  time:29.829, tt:1193.175\n",
      "Ep:40, loss:0.00003, loss_test:0.01496, lr:5.94e-02, fs:0.76349 (r=0.929,p=0.648),  time:29.860, tt:1224.244\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01490, lr:5.94e-02, fs:0.76987 (r=0.929,p=0.657),  time:29.920, tt:1256.646\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01481, lr:5.94e-02, fs:0.75304 (r=0.939,p=0.628),  time:29.968, tt:1288.645\n",
      "Ep:43, loss:0.00003, loss_test:0.01474, lr:5.94e-02, fs:0.76860 (r=0.939,p=0.650),  time:30.033, tt:1321.442\n",
      "Ep:44, loss:0.00003, loss_test:0.01467, lr:5.94e-02, fs:0.76987 (r=0.929,p=0.657),  time:30.049, tt:1352.191\n",
      "Ep:45, loss:0.00003, loss_test:0.01462, lr:5.94e-02, fs:0.76543 (r=0.939,p=0.646),  time:30.070, tt:1383.222\n",
      "Ep:46, loss:0.00003, loss_test:0.01456, lr:5.94e-02, fs:0.77966 (r=0.929,p=0.672),  time:30.098, tt:1414.618\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01453, lr:5.94e-02, fs:0.77049 (r=0.949,p=0.648),  time:30.107, tt:1445.137\n",
      "Ep:48, loss:0.00003, loss_test:0.01461, lr:5.94e-02, fs:0.78481 (r=0.939,p=0.674),  time:30.136, tt:1476.678\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01468, lr:5.94e-02, fs:0.78151 (r=0.939,p=0.669),  time:30.169, tt:1508.440\n",
      "Ep:50, loss:0.00003, loss_test:0.01471, lr:5.94e-02, fs:0.77586 (r=0.909,p=0.677),  time:30.207, tt:1540.545\n",
      "Ep:51, loss:0.00003, loss_test:0.01471, lr:5.94e-02, fs:0.76991 (r=0.879,p=0.685),  time:30.264, tt:1573.722\n",
      "Ep:52, loss:0.00002, loss_test:0.01484, lr:5.94e-02, fs:0.76190 (r=0.889,p=0.667),  time:30.311, tt:1606.494\n",
      "Ep:53, loss:0.00002, loss_test:0.01499, lr:5.94e-02, fs:0.76190 (r=0.889,p=0.667),  time:30.327, tt:1637.633\n",
      "Ep:54, loss:0.00002, loss_test:0.01503, lr:5.94e-02, fs:0.76444 (r=0.869,p=0.683),  time:30.358, tt:1669.708\n",
      "Ep:55, loss:0.00002, loss_test:0.01514, lr:5.94e-02, fs:0.76577 (r=0.859,p=0.691),  time:30.394, tt:1702.055\n",
      "Ep:56, loss:0.00002, loss_test:0.01519, lr:5.94e-02, fs:0.78788 (r=0.919,p=0.689),  time:30.412, tt:1733.512\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01600, lr:5.94e-02, fs:0.76852 (r=0.838,p=0.709),  time:30.424, tt:1764.611\n",
      "Ep:58, loss:0.00002, loss_test:0.01528, lr:5.94e-02, fs:0.77679 (r=0.879,p=0.696),  time:30.444, tt:1796.211\n",
      "Ep:59, loss:0.00002, loss_test:0.01567, lr:5.94e-02, fs:0.78761 (r=0.899,p=0.701),  time:30.441, tt:1826.480\n",
      "Ep:60, loss:0.00002, loss_test:0.01559, lr:5.94e-02, fs:0.76316 (r=0.879,p=0.674),  time:30.456, tt:1857.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00002, loss_test:0.01528, lr:5.94e-02, fs:0.76995 (r=0.828,p=0.719),  time:30.470, tt:1889.157\n",
      "Ep:62, loss:0.00002, loss_test:0.01584, lr:5.94e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.481, tt:1920.290\n",
      "Ep:63, loss:0.00002, loss_test:0.01572, lr:5.94e-02, fs:0.75455 (r=0.838,p=0.686),  time:30.489, tt:1951.289\n",
      "Ep:64, loss:0.00002, loss_test:0.01567, lr:5.94e-02, fs:0.78846 (r=0.828,p=0.752),  time:30.505, tt:1982.821\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01677, lr:5.94e-02, fs:0.77295 (r=0.808,p=0.741),  time:30.522, tt:2014.469\n",
      "Ep:66, loss:0.00002, loss_test:0.01694, lr:5.94e-02, fs:0.73529 (r=0.758,p=0.714),  time:30.529, tt:2045.425\n",
      "Ep:67, loss:0.00002, loss_test:0.01564, lr:5.94e-02, fs:0.78261 (r=0.818,p=0.750),  time:30.516, tt:2075.076\n",
      "Ep:68, loss:0.00001, loss_test:0.01601, lr:5.94e-02, fs:0.77885 (r=0.818,p=0.743),  time:30.559, tt:2108.588\n",
      "Ep:69, loss:0.00001, loss_test:0.01626, lr:5.94e-02, fs:0.79208 (r=0.808,p=0.777),  time:30.553, tt:2138.694\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01706, lr:5.94e-02, fs:0.73469 (r=0.727,p=0.742),  time:30.560, tt:2169.731\n",
      "Ep:71, loss:0.00001, loss_test:0.01698, lr:5.94e-02, fs:0.74490 (r=0.737,p=0.753),  time:30.585, tt:2202.105\n",
      "Ep:72, loss:0.00001, loss_test:0.01519, lr:5.94e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.596, tt:2233.543\n",
      "Ep:73, loss:0.00001, loss_test:0.01505, lr:5.94e-02, fs:0.79024 (r=0.818,p=0.764),  time:30.599, tt:2264.360\n",
      "Ep:74, loss:0.00001, loss_test:0.01472, lr:5.94e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.601, tt:2295.054\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01554, lr:5.94e-02, fs:0.78641 (r=0.818,p=0.757),  time:30.604, tt:2325.928\n",
      "Ep:76, loss:0.00001, loss_test:0.01650, lr:5.94e-02, fs:0.73846 (r=0.727,p=0.750),  time:30.593, tt:2355.680\n",
      "Ep:77, loss:0.00001, loss_test:0.01890, lr:5.94e-02, fs:0.71351 (r=0.667,p=0.767),  time:30.597, tt:2386.590\n",
      "Ep:78, loss:0.00002, loss_test:0.01498, lr:5.94e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.604, tt:2417.682\n",
      "Ep:79, loss:0.00001, loss_test:0.01352, lr:5.94e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.603, tt:2448.202\n",
      "Ep:80, loss:0.00001, loss_test:0.01523, lr:5.94e-02, fs:0.76617 (r=0.778,p=0.755),  time:30.597, tt:2478.371\n",
      "Ep:81, loss:0.00001, loss_test:0.01346, lr:5.94e-02, fs:0.80193 (r=0.838,p=0.769),  time:30.598, tt:2509.035\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01472, lr:5.94e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.626, tt:2541.992\n",
      "Ep:83, loss:0.00001, loss_test:0.01529, lr:5.94e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.638, tt:2573.619\n",
      "Ep:84, loss:0.00001, loss_test:0.01511, lr:5.94e-02, fs:0.80208 (r=0.778,p=0.828),  time:30.626, tt:2603.238\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01660, lr:5.94e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.635, tt:2634.587\n",
      "Ep:86, loss:0.00001, loss_test:0.01444, lr:5.94e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.627, tt:2664.558\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01575, lr:5.94e-02, fs:0.75532 (r=0.717,p=0.798),  time:30.628, tt:2695.252\n",
      "Ep:88, loss:0.00001, loss_test:0.01718, lr:5.94e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.635, tt:2726.551\n",
      "Ep:89, loss:0.00001, loss_test:0.01571, lr:5.94e-02, fs:0.80203 (r=0.798,p=0.806),  time:30.652, tt:2758.710\n",
      "Ep:90, loss:0.00001, loss_test:0.01654, lr:5.94e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.648, tt:2788.962\n",
      "Ep:91, loss:0.00001, loss_test:0.01611, lr:5.94e-02, fs:0.73224 (r=0.677,p=0.798),  time:30.662, tt:2820.896\n",
      "Ep:92, loss:0.00001, loss_test:0.01667, lr:5.94e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.658, tt:2851.171\n",
      "Ep:93, loss:0.00001, loss_test:0.01566, lr:5.94e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.657, tt:2881.774\n",
      "Ep:94, loss:0.00001, loss_test:0.01732, lr:5.94e-02, fs:0.72826 (r=0.677,p=0.788),  time:30.654, tt:2912.169\n",
      "Ep:95, loss:0.00001, loss_test:0.01816, lr:5.94e-02, fs:0.73034 (r=0.657,p=0.823),  time:30.652, tt:2942.622\n",
      "Ep:96, loss:0.00001, loss_test:0.01675, lr:5.94e-02, fs:0.73034 (r=0.657,p=0.823),  time:30.654, tt:2973.427\n",
      "Ep:97, loss:0.00001, loss_test:0.01688, lr:5.94e-02, fs:0.75936 (r=0.717,p=0.807),  time:30.655, tt:3004.148\n",
      "Ep:98, loss:0.00001, loss_test:0.01645, lr:5.88e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.647, tt:3034.092\n",
      "Ep:99, loss:0.00001, loss_test:0.01954, lr:5.82e-02, fs:0.74033 (r=0.677,p=0.817),  time:30.632, tt:3063.227\n",
      "Ep:100, loss:0.00001, loss_test:0.01630, lr:5.76e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.630, tt:3093.591\n",
      "Ep:101, loss:0.00001, loss_test:0.01751, lr:5.71e-02, fs:0.72222 (r=0.657,p=0.802),  time:30.600, tt:3121.242\n",
      "Ep:102, loss:0.00001, loss_test:0.01673, lr:5.65e-02, fs:0.75978 (r=0.687,p=0.850),  time:30.593, tt:3151.091\n",
      "Ep:103, loss:0.00001, loss_test:0.01648, lr:5.59e-02, fs:0.76596 (r=0.727,p=0.809),  time:30.579, tt:3180.199\n",
      "Ep:104, loss:0.00001, loss_test:0.01703, lr:5.54e-02, fs:0.75581 (r=0.657,p=0.890),  time:30.581, tt:3210.981\n",
      "Ep:105, loss:0.00001, loss_test:0.01809, lr:5.48e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.570, tt:3240.441\n",
      "Ep:106, loss:0.00001, loss_test:0.01770, lr:5.43e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.560, tt:3269.892\n",
      "Ep:107, loss:0.00001, loss_test:0.01699, lr:5.37e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.560, tt:3300.496\n",
      "Ep:108, loss:0.00001, loss_test:0.01838, lr:5.32e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.573, tt:3332.424\n",
      "Ep:109, loss:0.00000, loss_test:0.01759, lr:5.27e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.574, tt:3363.154\n",
      "Ep:110, loss:0.00000, loss_test:0.01919, lr:5.21e-02, fs:0.74713 (r=0.657,p=0.867),  time:30.590, tt:3395.506\n",
      "Ep:111, loss:0.00001, loss_test:0.01889, lr:5.16e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.597, tt:3426.902\n",
      "Ep:112, loss:0.00001, loss_test:0.01657, lr:5.11e-02, fs:0.77095 (r=0.697,p=0.863),  time:30.599, tt:3457.678\n",
      "Ep:113, loss:0.00001, loss_test:0.01651, lr:5.06e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.605, tt:3488.948\n",
      "Ep:114, loss:0.00000, loss_test:0.01692, lr:5.01e-02, fs:0.77528 (r=0.697,p=0.873),  time:30.612, tt:3520.376\n",
      "Ep:115, loss:0.00000, loss_test:0.01780, lr:4.96e-02, fs:0.77778 (r=0.707,p=0.864),  time:30.613, tt:3551.077\n",
      "Ep:116, loss:0.00000, loss_test:0.01828, lr:4.91e-02, fs:0.73684 (r=0.636,p=0.875),  time:30.623, tt:3582.941\n",
      "Ep:117, loss:0.00000, loss_test:0.01895, lr:4.86e-02, fs:0.76301 (r=0.667,p=0.892),  time:30.640, tt:3615.485\n",
      "Ep:118, loss:0.00000, loss_test:0.01819, lr:4.81e-02, fs:0.78212 (r=0.707,p=0.875),  time:30.633, tt:3645.303\n",
      "Ep:119, loss:0.00000, loss_test:0.01861, lr:4.76e-02, fs:0.77273 (r=0.687,p=0.883),  time:30.631, tt:3675.736\n",
      "Ep:120, loss:0.00000, loss_test:0.01842, lr:4.71e-02, fs:0.76301 (r=0.667,p=0.892),  time:30.644, tt:3707.953\n",
      "Ep:121, loss:0.00000, loss_test:0.01895, lr:4.67e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.652, tt:3739.525\n",
      "Ep:122, loss:0.00000, loss_test:0.01802, lr:4.62e-02, fs:0.77273 (r=0.687,p=0.883),  time:30.656, tt:3770.672\n",
      "Ep:123, loss:0.00000, loss_test:0.01905, lr:4.57e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.656, tt:3801.283\n",
      "Ep:124, loss:0.00000, loss_test:0.01820, lr:4.53e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.654, tt:3831.731\n",
      "Ep:125, loss:0.00000, loss_test:0.01976, lr:4.48e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.644, tt:3861.128\n",
      "Ep:126, loss:0.00000, loss_test:0.01864, lr:4.44e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.637, tt:3890.946\n",
      "Ep:127, loss:0.00000, loss_test:0.01859, lr:4.39e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.640, tt:3921.940\n",
      "Ep:128, loss:0.00000, loss_test:0.01925, lr:4.35e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.641, tt:3952.689\n",
      "Ep:129, loss:0.00000, loss_test:0.01845, lr:4.31e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.641, tt:3983.313\n",
      "Ep:130, loss:0.00000, loss_test:0.01992, lr:4.26e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.644, tt:4014.321\n",
      "Ep:131, loss:0.00000, loss_test:0.01866, lr:4.22e-02, fs:0.79775 (r=0.717,p=0.899),  time:30.642, tt:4044.727\n",
      "Ep:132, loss:0.00000, loss_test:0.01930, lr:4.18e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.636, tt:4074.654\n",
      "Ep:133, loss:0.00000, loss_test:0.01923, lr:4.14e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.625, tt:4103.790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01926, lr:4.10e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.621, tt:4133.840\n",
      "Ep:135, loss:0.00000, loss_test:0.01989, lr:4.05e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.615, tt:4163.620\n",
      "Ep:136, loss:0.00000, loss_test:0.01924, lr:4.01e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.598, tt:4191.902\n",
      "Ep:137, loss:0.00000, loss_test:0.01930, lr:3.97e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.593, tt:4221.868\n",
      "Ep:138, loss:0.00000, loss_test:0.02028, lr:3.93e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.595, tt:4252.688\n",
      "Ep:139, loss:0.00000, loss_test:0.02000, lr:3.89e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.575, tt:4280.486\n",
      "Ep:140, loss:0.00000, loss_test:0.02021, lr:3.86e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.574, tt:4310.939\n",
      "Ep:141, loss:0.00000, loss_test:0.01942, lr:3.82e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.576, tt:4341.810\n",
      "Ep:142, loss:0.00000, loss_test:0.02106, lr:3.78e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.566, tt:4370.884\n",
      "Ep:143, loss:0.00000, loss_test:0.01962, lr:3.74e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.561, tt:4400.777\n",
      "Ep:144, loss:0.00000, loss_test:0.02101, lr:3.70e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.551, tt:4429.853\n",
      "Ep:145, loss:0.00000, loss_test:0.01947, lr:3.67e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.545, tt:4459.568\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00000, loss_test:0.02140, lr:3.67e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.531, tt:4488.093\n",
      "Ep:147, loss:0.00000, loss_test:0.01982, lr:3.67e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.520, tt:4516.909\n",
      "Ep:148, loss:0.00000, loss_test:0.02203, lr:3.67e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.524, tt:4548.064\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00000, loss_test:0.02004, lr:3.67e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.527, tt:4579.052\n",
      "Ep:150, loss:0.00000, loss_test:0.02172, lr:3.67e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.524, tt:4609.155\n",
      "Ep:151, loss:0.00000, loss_test:0.02059, lr:3.67e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.520, tt:4638.997\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00000, loss_test:0.02134, lr:3.67e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.527, tt:4670.570\n",
      "Ep:153, loss:0.00000, loss_test:0.02075, lr:3.67e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.528, tt:4701.270\n",
      "Ep:154, loss:0.00000, loss_test:0.02167, lr:3.67e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.546, tt:4734.571\n",
      "Ep:155, loss:0.00000, loss_test:0.02119, lr:3.67e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.555, tt:4766.577\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00000, loss_test:0.02149, lr:3.67e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.567, tt:4799.016\n",
      "Ep:157, loss:0.00000, loss_test:0.02171, lr:3.67e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.570, tt:4830.012\n",
      "Ep:158, loss:0.00000, loss_test:0.02159, lr:3.67e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.575, tt:4861.424\n",
      "Ep:159, loss:0.00000, loss_test:0.02218, lr:3.67e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.575, tt:4892.059\n",
      "Ep:160, loss:0.00000, loss_test:0.02165, lr:3.67e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.576, tt:4922.715\n",
      "Ep:161, loss:0.00000, loss_test:0.02231, lr:3.67e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.578, tt:4953.641\n",
      "Ep:162, loss:0.00000, loss_test:0.02158, lr:3.67e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.577, tt:4984.122\n",
      "Ep:163, loss:0.00000, loss_test:0.02264, lr:3.67e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.582, tt:5015.474\n",
      "Ep:164, loss:0.00000, loss_test:0.02113, lr:3.67e-02, fs:0.80702 (r=0.697,p=0.958),  time:30.590, tt:5047.432\n",
      "Ep:165, loss:0.00000, loss_test:0.02214, lr:3.67e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.595, tt:5078.767\n",
      "Ep:166, loss:0.00000, loss_test:0.02118, lr:3.67e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.603, tt:5110.678\n",
      "Ep:167, loss:0.00000, loss_test:0.02174, lr:3.63e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.608, tt:5142.202\n",
      "Ep:168, loss:0.00000, loss_test:0.02004, lr:3.59e-02, fs:0.84091 (r=0.747,p=0.961),  time:30.614, tt:5173.780\n",
      "##########Best model found so far##########\n",
      "Ep:169, loss:0.00000, loss_test:0.02223, lr:3.59e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.621, tt:5205.488\n",
      "Ep:170, loss:0.00000, loss_test:0.02049, lr:3.59e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.629, tt:5237.628\n",
      "Ep:171, loss:0.00000, loss_test:0.02207, lr:3.59e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.622, tt:5267.069\n",
      "Ep:172, loss:0.00000, loss_test:0.02078, lr:3.59e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.628, tt:5298.688\n",
      "Ep:173, loss:0.00000, loss_test:0.02235, lr:3.59e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.633, tt:5330.163\n",
      "Ep:174, loss:0.00000, loss_test:0.02035, lr:3.59e-02, fs:0.84091 (r=0.747,p=0.961),  time:30.642, tt:5362.311\n",
      "Ep:175, loss:0.00000, loss_test:0.02174, lr:3.59e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.644, tt:5393.307\n",
      "Ep:176, loss:0.00000, loss_test:0.02197, lr:3.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.640, tt:5423.200\n",
      "Ep:177, loss:0.00000, loss_test:0.02142, lr:3.59e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.646, tt:5455.041\n",
      "Ep:178, loss:0.00000, loss_test:0.02198, lr:3.59e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.650, tt:5486.431\n",
      "Ep:179, loss:0.00000, loss_test:0.02181, lr:3.59e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.655, tt:5517.882\n",
      "Ep:180, loss:0.00000, loss_test:0.02268, lr:3.56e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.655, tt:5548.644\n",
      "Ep:181, loss:0.00000, loss_test:0.02211, lr:3.52e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.664, tt:5580.759\n",
      "Ep:182, loss:0.00000, loss_test:0.02263, lr:3.49e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.667, tt:5612.150\n",
      "Ep:183, loss:0.00000, loss_test:0.02246, lr:3.45e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.667, tt:5642.804\n",
      "Ep:184, loss:0.00000, loss_test:0.02285, lr:3.42e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.664, tt:5672.800\n",
      "Ep:185, loss:0.00000, loss_test:0.02249, lr:3.38e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.666, tt:5703.836\n",
      "Ep:186, loss:0.00000, loss_test:0.02304, lr:3.35e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.662, tt:5733.746\n",
      "Ep:187, loss:0.00000, loss_test:0.02303, lr:3.32e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.656, tt:5763.251\n",
      "Ep:188, loss:0.00000, loss_test:0.02309, lr:3.28e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.647, tt:5792.364\n",
      "Ep:189, loss:0.00000, loss_test:0.02266, lr:3.25e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.650, tt:5823.581\n",
      "Ep:190, loss:0.00000, loss_test:0.02341, lr:3.22e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.650, tt:5854.168\n",
      "Ep:191, loss:0.00000, loss_test:0.02315, lr:3.19e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.643, tt:5883.465\n",
      "Ep:192, loss:0.00000, loss_test:0.02384, lr:3.15e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.640, tt:5913.505\n",
      "Ep:193, loss:0.00000, loss_test:0.02295, lr:3.12e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.636, tt:5943.330\n",
      "Ep:194, loss:0.00000, loss_test:0.02450, lr:3.09e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.631, tt:5973.035\n",
      "Ep:195, loss:0.00000, loss_test:0.02337, lr:3.06e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.627, tt:6002.913\n",
      "Ep:196, loss:0.00000, loss_test:0.02355, lr:3.03e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.620, tt:6032.230\n",
      "Ep:197, loss:0.00000, loss_test:0.02342, lr:3.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.631, tt:6064.988\n",
      "Ep:198, loss:0.00000, loss_test:0.02411, lr:2.97e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.631, tt:6095.524\n",
      "Ep:199, loss:0.00000, loss_test:0.02391, lr:2.94e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.631, tt:6126.230\n",
      "Ep:200, loss:0.00000, loss_test:0.02386, lr:2.91e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.635, tt:6157.710\n",
      "Ep:201, loss:0.00000, loss_test:0.02401, lr:2.88e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.638, tt:6188.854\n",
      "Ep:202, loss:0.00000, loss_test:0.02422, lr:2.85e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.637, tt:6219.257\n",
      "Ep:203, loss:0.00000, loss_test:0.02417, lr:2.82e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.637, tt:6249.984\n",
      "Ep:204, loss:0.00000, loss_test:0.02421, lr:2.80e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.644, tt:6282.101\n",
      "Ep:205, loss:0.00000, loss_test:0.02446, lr:2.77e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.647, tt:6313.317\n",
      "Ep:206, loss:0.00000, loss_test:0.02461, lr:2.74e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.647, tt:6343.999\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.11813, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:29.120, tt:29.120\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.11636, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:30.319, tt:60.639\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11424, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:26.614, tt:79.842\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11303, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:27.272, tt:109.089\n",
      "Ep:4, loss:0.00026, loss_test:0.11176, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:27.549, tt:137.746\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.11080, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:27.794, tt:166.767\n",
      "Ep:6, loss:0.00026, loss_test:0.10969, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:28.485, tt:199.395\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.10869, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:28.934, tt:231.471\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.10749, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:29.354, tt:264.185\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.10637, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:29.652, tt:296.517\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.10527, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:29.835, tt:328.191\n",
      "Ep:11, loss:0.00024, loss_test:0.10400, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:30.044, tt:360.529\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10168, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:30.238, tt:393.094\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.09825, lr:1.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:30.381, tt:425.327\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.09526, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:30.459, tt:456.893\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.09213, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:30.570, tt:489.124\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.08977, lr:1.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:30.730, tt:522.406\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.08643, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:30.861, tt:555.504\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.08517, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:30.831, tt:585.792\n",
      "Ep:19, loss:0.00020, loss_test:0.08518, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:30.923, tt:618.461\n",
      "Ep:20, loss:0.00019, loss_test:0.08336, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:30.869, tt:648.256\n",
      "Ep:21, loss:0.00018, loss_test:0.08593, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.936, tt:680.593\n",
      "Ep:22, loss:0.00017, loss_test:0.08305, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.983, tt:712.603\n",
      "Ep:23, loss:0.00017, loss_test:0.08775, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:31.004, tt:744.094\n",
      "Ep:24, loss:0.00016, loss_test:0.08292, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:31.051, tt:776.274\n",
      "Ep:25, loss:0.00015, loss_test:0.08600, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:31.105, tt:808.727\n",
      "Ep:26, loss:0.00015, loss_test:0.08225, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:31.101, tt:839.719\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08262, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.165, tt:872.623\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08058, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.172, tt:903.974\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08500, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:31.165, tt:934.942\n",
      "Ep:30, loss:0.00013, loss_test:0.08578, lr:1.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:31.188, tt:966.834\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08315, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:31.151, tt:996.830\n",
      "Ep:32, loss:0.00012, loss_test:0.07857, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:31.190, tt:1029.274\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08608, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.202, tt:1060.865\n",
      "Ep:34, loss:0.00011, loss_test:0.08142, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.095, tt:1088.311\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08157, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.103, tt:1119.718\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07912, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:31.125, tt:1151.629\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07549, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:31.174, tt:1184.605\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07919, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:31.228, tt:1217.893\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.08217, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:31.238, tt:1249.508\n",
      "Ep:40, loss:0.00008, loss_test:0.07600, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.223, tt:1280.142\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.07279, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:31.237, tt:1311.958\n",
      "Ep:42, loss:0.00009, loss_test:0.06818, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:31.264, tt:1344.350\n",
      "Ep:43, loss:0.00009, loss_test:0.07655, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:31.280, tt:1376.334\n",
      "Ep:44, loss:0.00008, loss_test:0.08023, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.290, tt:1408.038\n",
      "Ep:45, loss:0.00008, loss_test:0.07284, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:31.311, tt:1440.312\n",
      "Ep:46, loss:0.00008, loss_test:0.07380, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:31.306, tt:1471.394\n",
      "Ep:47, loss:0.00007, loss_test:0.07728, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:31.324, tt:1503.548\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.06698, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:31.301, tt:1533.740\n",
      "Ep:49, loss:0.00006, loss_test:0.07243, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.291, tt:1564.530\n",
      "Ep:50, loss:0.00006, loss_test:0.06931, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:31.293, tt:1595.926\n",
      "Ep:51, loss:0.00006, loss_test:0.07093, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:31.312, tt:1628.213\n",
      "Ep:52, loss:0.00005, loss_test:0.06660, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:31.313, tt:1659.573\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06466, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:31.305, tt:1690.496\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.06911, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:31.329, tt:1723.111\n",
      "Ep:55, loss:0.00005, loss_test:0.06747, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:31.344, tt:1755.286\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.06739, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:31.332, tt:1785.906\n",
      "Ep:57, loss:0.00004, loss_test:0.06761, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:31.320, tt:1816.531\n",
      "Ep:58, loss:0.00004, loss_test:0.06142, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:31.337, tt:1848.861\n",
      "Ep:59, loss:0.00004, loss_test:0.06695, lr:1.00e-02, fs:0.92462 (r=0.929,p=0.920),  time:31.350, tt:1881.017\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00004, loss_test:0.06698, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.360, tt:1912.959\n",
      "Ep:61, loss:0.00004, loss_test:0.06259, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:31.376, tt:1945.317\n",
      "Ep:62, loss:0.00003, loss_test:0.05857, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:31.397, tt:1978.027\n",
      "Ep:63, loss:0.00003, loss_test:0.05842, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:31.409, tt:2010.155\n",
      "Ep:64, loss:0.00003, loss_test:0.05665, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:31.436, tt:2043.368\n",
      "Ep:65, loss:0.00003, loss_test:0.06198, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:31.447, tt:2075.531\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00003, loss_test:0.06026, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:31.431, tt:2105.857\n",
      "Ep:67, loss:0.00002, loss_test:0.06294, lr:1.00e-02, fs:0.92929 (r=0.929,p=0.929),  time:31.439, tt:2137.843\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.05930, lr:1.00e-02, fs:0.92632 (r=0.889,p=0.967),  time:31.455, tt:2170.399\n",
      "Ep:69, loss:0.00003, loss_test:0.06009, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:31.465, tt:2202.578\n",
      "Ep:70, loss:0.00003, loss_test:0.07203, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:31.497, tt:2236.302\n",
      "Ep:71, loss:0.00003, loss_test:0.06175, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:31.500, tt:2268.023\n",
      "Ep:72, loss:0.00003, loss_test:0.06137, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:31.500, tt:2299.505\n",
      "Ep:73, loss:0.00003, loss_test:0.06523, lr:1.00e-02, fs:0.89503 (r=0.818,p=0.988),  time:31.514, tt:2332.007\n",
      "Ep:74, loss:0.00002, loss_test:0.05287, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:31.531, tt:2364.851\n",
      "Ep:75, loss:0.00002, loss_test:0.06538, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:31.547, tt:2397.561\n",
      "Ep:76, loss:0.00002, loss_test:0.06174, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:31.552, tt:2429.491\n",
      "Ep:77, loss:0.00002, loss_test:0.07377, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.561, tt:2461.747\n",
      "Ep:78, loss:0.00002, loss_test:0.06061, lr:1.00e-02, fs:0.91304 (r=0.848,p=0.988),  time:31.574, tt:2494.315\n",
      "Ep:79, loss:0.00002, loss_test:0.06736, lr:9.90e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.598, tt:2527.804\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.06367, lr:9.90e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.611, tt:2560.480\n",
      "Ep:81, loss:0.00001, loss_test:0.06087, lr:9.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.629, tt:2593.540\n",
      "Ep:82, loss:0.00001, loss_test:0.06135, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.630, tt:2625.304\n",
      "Ep:83, loss:0.00001, loss_test:0.06277, lr:9.90e-03, fs:0.90811 (r=0.848,p=0.977),  time:31.629, tt:2656.798\n",
      "Ep:84, loss:0.00001, loss_test:0.06666, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.620, tt:2687.695\n",
      "Ep:85, loss:0.00001, loss_test:0.06142, lr:9.90e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.646, tt:2721.585\n",
      "Ep:86, loss:0.00001, loss_test:0.06205, lr:9.90e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.666, tt:2754.974\n",
      "Ep:87, loss:0.00001, loss_test:0.06696, lr:9.90e-03, fs:0.92632 (r=0.889,p=0.967),  time:31.678, tt:2787.670\n",
      "Ep:88, loss:0.00001, loss_test:0.06348, lr:9.90e-03, fs:0.91892 (r=0.859,p=0.988),  time:31.689, tt:2820.318\n",
      "Ep:89, loss:0.00001, loss_test:0.06581, lr:9.90e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.702, tt:2853.173\n",
      "Ep:90, loss:0.00001, loss_test:0.06217, lr:9.90e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.726, tt:2887.081\n",
      "Ep:91, loss:0.00001, loss_test:0.06038, lr:9.80e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.747, tt:2920.740\n",
      "Ep:92, loss:0.00001, loss_test:0.06772, lr:9.70e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.786, tt:2956.052\n",
      "Ep:93, loss:0.00001, loss_test:0.06310, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:31.845, tt:2993.459\n",
      "Ep:94, loss:0.00001, loss_test:0.06702, lr:9.51e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.886, tt:3029.187\n",
      "Ep:95, loss:0.00001, loss_test:0.07017, lr:9.41e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.921, tt:3064.375\n",
      "Ep:96, loss:0.00001, loss_test:0.06342, lr:9.32e-03, fs:0.93122 (r=0.889,p=0.978),  time:31.972, tt:3101.331\n",
      "Ep:97, loss:0.00001, loss_test:0.05999, lr:9.23e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.022, tt:3138.111\n",
      "Ep:98, loss:0.00001, loss_test:0.07386, lr:9.14e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.068, tt:3174.749\n",
      "Ep:99, loss:0.00001, loss_test:0.06816, lr:9.04e-03, fs:0.89503 (r=0.818,p=0.988),  time:32.096, tt:3209.586\n",
      "Ep:100, loss:0.00001, loss_test:0.06620, lr:8.95e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.123, tt:3244.410\n",
      "Ep:101, loss:0.00001, loss_test:0.06574, lr:8.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.144, tt:3278.725\n",
      "Ep:102, loss:0.00001, loss_test:0.06882, lr:8.78e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.177, tt:3314.186\n",
      "Ep:103, loss:0.00001, loss_test:0.06701, lr:8.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.212, tt:3350.086\n",
      "Ep:104, loss:0.00001, loss_test:0.07138, lr:8.60e-03, fs:0.90323 (r=0.848,p=0.966),  time:32.229, tt:3384.017\n",
      "Ep:105, loss:0.00001, loss_test:0.06477, lr:8.51e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.252, tt:3418.760\n",
      "Ep:106, loss:0.00001, loss_test:0.06502, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.257, tt:3451.528\n",
      "Ep:107, loss:0.00002, loss_test:0.07555, lr:8.35e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.278, tt:3486.074\n",
      "Ep:108, loss:0.00002, loss_test:0.05974, lr:8.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.309, tt:3521.716\n",
      "Ep:109, loss:0.00002, loss_test:0.05955, lr:8.18e-03, fs:0.89796 (r=0.889,p=0.907),  time:32.333, tt:3556.617\n",
      "Ep:110, loss:0.00001, loss_test:0.07445, lr:8.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.364, tt:3592.350\n",
      "Ep:111, loss:0.00001, loss_test:0.07296, lr:8.02e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.389, tt:3627.615\n",
      "Ep:112, loss:0.00001, loss_test:0.06144, lr:7.94e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.422, tt:3663.743\n",
      "Ep:113, loss:0.00001, loss_test:0.06137, lr:7.86e-03, fs:0.89130 (r=0.828,p=0.965),  time:32.443, tt:3698.554\n",
      "Ep:114, loss:0.00001, loss_test:0.07120, lr:7.78e-03, fs:0.90323 (r=0.848,p=0.966),  time:32.470, tt:3734.036\n",
      "Ep:115, loss:0.00001, loss_test:0.06028, lr:7.70e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.505, tt:3770.547\n",
      "Ep:116, loss:0.00001, loss_test:0.05973, lr:7.62e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.529, tt:3805.948\n",
      "Ep:117, loss:0.00001, loss_test:0.06241, lr:7.55e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.554, tt:3841.319\n",
      "Ep:118, loss:0.00001, loss_test:0.06345, lr:7.47e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.564, tt:3875.115\n",
      "Ep:119, loss:0.00001, loss_test:0.05688, lr:7.40e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.599, tt:3911.845\n",
      "Ep:120, loss:0.00000, loss_test:0.05667, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:32.629, tt:3948.081\n",
      "Ep:121, loss:0.00000, loss_test:0.05973, lr:7.25e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.653, tt:3983.698\n",
      "Ep:122, loss:0.00000, loss_test:0.05896, lr:7.18e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.672, tt:4018.673\n",
      "Ep:123, loss:0.00000, loss_test:0.05867, lr:7.11e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.691, tt:4053.655\n",
      "Ep:124, loss:0.00000, loss_test:0.05926, lr:7.03e-03, fs:0.91979 (r=0.869,p=0.977),  time:32.717, tt:4089.625\n",
      "Ep:125, loss:0.00000, loss_test:0.06019, lr:6.96e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.742, tt:4125.511\n",
      "Ep:126, loss:0.00000, loss_test:0.06149, lr:6.89e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.761, tt:4160.583\n",
      "Ep:127, loss:0.00000, loss_test:0.06165, lr:6.83e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.773, tt:4194.943\n",
      "Ep:128, loss:0.00000, loss_test:0.06082, lr:6.76e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.795, tt:4230.614\n",
      "Ep:129, loss:0.00000, loss_test:0.06068, lr:6.69e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.809, tt:4265.170\n",
      "Ep:130, loss:0.00000, loss_test:0.06096, lr:6.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.821, tt:4299.564\n",
      "Ep:131, loss:0.00000, loss_test:0.06068, lr:6.56e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.838, tt:4334.563\n",
      "Ep:132, loss:0.00000, loss_test:0.06144, lr:6.49e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.854, tt:4369.548\n",
      "Ep:133, loss:0.00000, loss_test:0.06071, lr:6.43e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.863, tt:4403.707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.06003, lr:6.36e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.879, tt:4438.712\n",
      "Ep:135, loss:0.00000, loss_test:0.06090, lr:6.30e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.887, tt:4472.665\n",
      "Ep:136, loss:0.00000, loss_test:0.06136, lr:6.24e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.903, tt:4507.714\n",
      "Ep:137, loss:0.00000, loss_test:0.06167, lr:6.17e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.919, tt:4542.811\n",
      "Ep:138, loss:0.00000, loss_test:0.06168, lr:6.11e-03, fs:0.90811 (r=0.848,p=0.977),  time:32.934, tt:4577.798\n",
      "Ep:139, loss:0.00000, loss_test:0.06177, lr:6.05e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.942, tt:4611.845\n",
      "Ep:140, loss:0.00000, loss_test:0.06192, lr:5.99e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.947, tt:4645.521\n",
      "Ep:141, loss:0.00000, loss_test:0.06149, lr:5.93e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.959, tt:4680.181\n",
      "Ep:142, loss:0.00000, loss_test:0.06114, lr:5.87e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.978, tt:4715.784\n",
      "Ep:143, loss:0.00000, loss_test:0.06170, lr:5.81e-03, fs:0.93122 (r=0.889,p=0.978),  time:32.987, tt:4750.060\n",
      "Ep:144, loss:0.00000, loss_test:0.06166, lr:5.75e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.001, tt:4785.201\n",
      "Ep:145, loss:0.00000, loss_test:0.06234, lr:5.70e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.020, tt:4820.984\n",
      "Ep:146, loss:0.00000, loss_test:0.06351, lr:5.64e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.027, tt:4854.925\n",
      "Ep:147, loss:0.00000, loss_test:0.06290, lr:5.58e-03, fs:0.91489 (r=0.869,p=0.966),  time:33.030, tt:4888.490\n",
      "Ep:148, loss:0.00000, loss_test:0.06262, lr:5.53e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.045, tt:4923.718\n",
      "Ep:149, loss:0.00000, loss_test:0.06263, lr:5.47e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.067, tt:4960.066\n",
      "Ep:150, loss:0.00000, loss_test:0.06268, lr:5.42e-03, fs:0.91489 (r=0.869,p=0.966),  time:33.082, tt:4995.338\n",
      "Ep:151, loss:0.00000, loss_test:0.06310, lr:5.36e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.105, tt:5031.984\n",
      "Ep:152, loss:0.00000, loss_test:0.06347, lr:5.31e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.115, tt:5066.595\n",
      "Ep:153, loss:0.00000, loss_test:0.06273, lr:5.26e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.122, tt:5100.831\n",
      "Ep:154, loss:0.00000, loss_test:0.06235, lr:5.20e-03, fs:0.92553 (r=0.879,p=0.978),  time:33.135, tt:5135.923\n",
      "Ep:155, loss:0.00000, loss_test:0.06338, lr:5.15e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.149, tt:5171.197\n",
      "Ep:156, loss:0.00000, loss_test:0.06331, lr:5.10e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.156, tt:5205.485\n",
      "Ep:157, loss:0.00000, loss_test:0.06293, lr:5.05e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.165, tt:5240.085\n",
      "Ep:158, loss:0.00000, loss_test:0.06307, lr:5.00e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.180, tt:5275.684\n",
      "Ep:159, loss:0.00000, loss_test:0.06340, lr:4.95e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.201, tt:5312.128\n",
      "Ep:160, loss:0.00000, loss_test:0.06377, lr:4.90e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.208, tt:5346.501\n",
      "Ep:161, loss:0.00000, loss_test:0.06379, lr:4.85e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.212, tt:5380.409\n",
      "Ep:162, loss:0.00000, loss_test:0.06335, lr:4.80e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.222, tt:5415.265\n",
      "Ep:163, loss:0.00000, loss_test:0.06284, lr:4.75e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.244, tt:5451.972\n",
      "Ep:164, loss:0.00000, loss_test:0.06328, lr:4.71e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.249, tt:5486.135\n",
      "Ep:165, loss:0.00000, loss_test:0.06371, lr:4.66e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.255, tt:5520.254\n",
      "Ep:166, loss:0.00000, loss_test:0.06358, lr:4.61e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.256, tt:5553.670\n",
      "Ep:167, loss:0.00000, loss_test:0.06382, lr:4.57e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.261, tt:5587.830\n",
      "Ep:168, loss:0.00000, loss_test:0.06406, lr:4.52e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.268, tt:5622.312\n",
      "Ep:169, loss:0.00000, loss_test:0.06425, lr:4.48e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.273, tt:5656.328\n",
      "Ep:170, loss:0.00000, loss_test:0.06439, lr:4.43e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.280, tt:5690.817\n",
      "Ep:171, loss:0.00000, loss_test:0.06407, lr:4.39e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.294, tt:5726.604\n",
      "Ep:172, loss:0.00000, loss_test:0.06390, lr:4.34e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.303, tt:5761.399\n",
      "Ep:173, loss:0.00000, loss_test:0.06425, lr:4.30e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.321, tt:5797.904\n",
      "Ep:174, loss:0.00000, loss_test:0.06455, lr:4.26e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.331, tt:5832.990\n",
      "Ep:175, loss:0.00000, loss_test:0.06466, lr:4.21e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.338, tt:5867.402\n",
      "Ep:176, loss:0.00000, loss_test:0.06451, lr:4.17e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.351, tt:5903.059\n",
      "Ep:177, loss:0.00000, loss_test:0.06456, lr:4.13e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.374, tt:5940.542\n",
      "Ep:178, loss:0.00000, loss_test:0.06499, lr:4.09e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.393, tt:5977.401\n",
      "Ep:179, loss:0.00000, loss_test:0.06500, lr:4.05e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.416, tt:6014.941\n",
      "Ep:180, loss:0.00000, loss_test:0.06497, lr:4.01e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.425, tt:6049.909\n",
      "Ep:181, loss:0.00000, loss_test:0.06530, lr:3.97e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.442, tt:6086.462\n",
      "Ep:182, loss:0.00000, loss_test:0.06547, lr:3.93e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.464, tt:6123.931\n",
      "Ep:183, loss:0.00000, loss_test:0.06541, lr:3.89e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.482, tt:6160.712\n",
      "Ep:184, loss:0.00000, loss_test:0.06557, lr:3.85e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.500, tt:6197.426\n",
      "Ep:185, loss:0.00000, loss_test:0.06561, lr:3.81e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.519, tt:6234.567\n",
      "Ep:186, loss:0.00000, loss_test:0.06548, lr:3.77e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.546, tt:6273.164\n",
      "Ep:187, loss:0.00000, loss_test:0.06581, lr:3.73e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.555, tt:6308.321\n",
      "Ep:188, loss:0.00000, loss_test:0.06572, lr:3.70e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.572, tt:6345.125\n",
      "Ep:189, loss:0.00000, loss_test:0.06549, lr:3.66e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.577, tt:6379.590\n",
      "Ep:190, loss:0.00000, loss_test:0.06567, lr:3.62e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.585, tt:6414.661\n",
      "Ep:191, loss:0.00000, loss_test:0.06561, lr:3.59e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.596, tt:6450.493\n",
      "Ep:192, loss:0.00000, loss_test:0.06590, lr:3.55e-03, fs:0.92632 (r=0.889,p=0.967),  time:33.612, tt:6487.151\n",
      "Ep:193, loss:0.00000, loss_test:0.06630, lr:3.52e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.628, tt:6523.829\n",
      "Ep:194, loss:0.00000, loss_test:0.06608, lr:3.48e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.649, tt:6561.564\n",
      "Ep:195, loss:0.00000, loss_test:0.06616, lr:3.45e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.662, tt:6597.830\n",
      "Ep:196, loss:0.00000, loss_test:0.06646, lr:3.41e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.678, tt:6634.628\n",
      "Ep:197, loss:0.00000, loss_test:0.06625, lr:3.38e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.697, tt:6672.000\n",
      "Ep:198, loss:0.00000, loss_test:0.06599, lr:3.34e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.714, tt:6709.183\n",
      "Ep:199, loss:0.00000, loss_test:0.06627, lr:3.31e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.725, tt:6745.061\n",
      "Ep:200, loss:0.00000, loss_test:0.06660, lr:3.28e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.741, tt:6781.845\n",
      "Ep:201, loss:0.00000, loss_test:0.06647, lr:3.24e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.757, tt:6818.844\n",
      "Ep:202, loss:0.00000, loss_test:0.06676, lr:3.21e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.767, tt:6854.610\n",
      "Ep:203, loss:0.00000, loss_test:0.06702, lr:3.18e-03, fs:0.91979 (r=0.869,p=0.977),  time:33.779, tt:6890.837\n",
      "Ep:204, loss:0.00000, loss_test:0.06701, lr:3.15e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.787, tt:6926.274\n",
      "Ep:205, loss:0.00000, loss_test:0.06698, lr:3.12e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.804, tt:6963.548\n",
      "Ep:206, loss:0.00000, loss_test:0.06736, lr:3.09e-03, fs:0.93122 (r=0.889,p=0.978),  time:33.791, tt:6994.736\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02125, lr:6.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:28.475, tt:28.475\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02258, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:26.935, tt:53.870\n",
      "Ep:2, loss:0.00005, loss_test:0.02440, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:27.279, tt:81.838\n",
      "Ep:3, loss:0.00005, loss_test:0.02436, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:28.859, tt:115.438\n",
      "Ep:4, loss:0.00005, loss_test:0.02367, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:29.860, tt:149.299\n",
      "Ep:5, loss:0.00005, loss_test:0.02261, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:30.605, tt:183.630\n",
      "Ep:6, loss:0.00005, loss_test:0.02158, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:31.040, tt:217.281\n",
      "Ep:7, loss:0.00005, loss_test:0.02067, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:31.539, tt:252.315\n",
      "Ep:8, loss:0.00005, loss_test:0.01986, lr:6.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:31.957, tt:287.611\n",
      "Ep:9, loss:0.00005, loss_test:0.01924, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:32.260, tt:322.605\n",
      "Ep:10, loss:0.00004, loss_test:0.01878, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:32.398, tt:356.377\n",
      "Ep:11, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:32.594, tt:391.122\n",
      "Ep:12, loss:0.00004, loss_test:0.01783, lr:5.94e-02, fs:0.70000 (r=0.919,p=0.565),  time:32.696, tt:425.047\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01760, lr:5.94e-02, fs:0.69498 (r=0.909,p=0.562),  time:32.851, tt:459.912\n",
      "Ep:14, loss:0.00004, loss_test:0.01748, lr:5.94e-02, fs:0.69466 (r=0.919,p=0.558),  time:32.966, tt:494.496\n",
      "Ep:15, loss:0.00004, loss_test:0.01744, lr:5.94e-02, fs:0.69962 (r=0.929,p=0.561),  time:33.172, tt:530.760\n",
      "Ep:16, loss:0.00004, loss_test:0.01735, lr:5.94e-02, fs:0.69663 (r=0.939,p=0.554),  time:33.280, tt:565.768\n",
      "Ep:17, loss:0.00004, loss_test:0.01724, lr:5.94e-02, fs:0.70149 (r=0.949,p=0.556),  time:33.320, tt:599.764\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01699, lr:5.94e-02, fs:0.70455 (r=0.939,p=0.564),  time:33.609, tt:638.565\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01695, lr:5.94e-02, fs:0.70229 (r=0.929,p=0.564),  time:33.654, tt:673.081\n",
      "Ep:20, loss:0.00003, loss_test:0.01717, lr:5.94e-02, fs:0.69732 (r=0.919,p=0.562),  time:33.740, tt:708.550\n",
      "Ep:21, loss:0.00003, loss_test:0.01733, lr:5.94e-02, fs:0.69767 (r=0.909,p=0.566),  time:33.785, tt:743.273\n",
      "Ep:22, loss:0.00003, loss_test:0.01750, lr:5.94e-02, fs:0.70079 (r=0.899,p=0.574),  time:33.836, tt:778.227\n",
      "Ep:23, loss:0.00003, loss_test:0.01770, lr:5.94e-02, fs:0.69841 (r=0.889,p=0.575),  time:33.910, tt:813.831\n",
      "Ep:24, loss:0.00003, loss_test:0.01790, lr:5.94e-02, fs:0.70968 (r=0.889,p=0.591),  time:33.866, tt:846.645\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01807, lr:5.94e-02, fs:0.69106 (r=0.859,p=0.578),  time:33.928, tt:882.133\n",
      "Ep:26, loss:0.00003, loss_test:0.01809, lr:5.94e-02, fs:0.69672 (r=0.859,p=0.586),  time:33.957, tt:916.835\n",
      "Ep:27, loss:0.00003, loss_test:0.01809, lr:5.94e-02, fs:0.70000 (r=0.848,p=0.596),  time:33.940, tt:950.306\n",
      "Ep:28, loss:0.00003, loss_test:0.01820, lr:5.94e-02, fs:0.68354 (r=0.818,p=0.587),  time:33.957, tt:984.758\n",
      "Ep:29, loss:0.00002, loss_test:0.01819, lr:5.94e-02, fs:0.68085 (r=0.808,p=0.588),  time:33.942, tt:1018.274\n",
      "Ep:30, loss:0.00002, loss_test:0.01825, lr:5.94e-02, fs:0.68376 (r=0.808,p=0.593),  time:33.875, tt:1050.122\n",
      "Ep:31, loss:0.00002, loss_test:0.01840, lr:5.94e-02, fs:0.68376 (r=0.808,p=0.593),  time:33.894, tt:1084.623\n",
      "Ep:32, loss:0.00002, loss_test:0.01865, lr:5.94e-02, fs:0.68696 (r=0.798,p=0.603),  time:33.941, tt:1120.062\n",
      "Ep:33, loss:0.00002, loss_test:0.01898, lr:5.94e-02, fs:0.69955 (r=0.788,p=0.629),  time:33.919, tt:1153.246\n",
      "Ep:34, loss:0.00002, loss_test:0.01914, lr:5.94e-02, fs:0.69333 (r=0.788,p=0.619),  time:33.952, tt:1188.333\n",
      "Ep:35, loss:0.00002, loss_test:0.01918, lr:5.94e-02, fs:0.70222 (r=0.798,p=0.627),  time:33.991, tt:1223.665\n",
      "Ep:36, loss:0.00002, loss_test:0.01921, lr:5.88e-02, fs:0.70270 (r=0.788,p=0.634),  time:34.035, tt:1259.307\n",
      "Ep:37, loss:0.00002, loss_test:0.01931, lr:5.82e-02, fs:0.71171 (r=0.798,p=0.642),  time:34.052, tt:1293.964\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01941, lr:5.82e-02, fs:0.70909 (r=0.788,p=0.645),  time:34.126, tt:1330.929\n",
      "Ep:39, loss:0.00002, loss_test:0.01963, lr:5.82e-02, fs:0.70909 (r=0.788,p=0.645),  time:34.147, tt:1365.865\n",
      "Ep:40, loss:0.00002, loss_test:0.01976, lr:5.82e-02, fs:0.73059 (r=0.808,p=0.667),  time:34.151, tt:1400.182\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01966, lr:5.82e-02, fs:0.72222 (r=0.788,p=0.667),  time:34.171, tt:1435.199\n",
      "Ep:42, loss:0.00002, loss_test:0.01991, lr:5.82e-02, fs:0.73585 (r=0.788,p=0.690),  time:34.195, tt:1470.391\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.02026, lr:5.82e-02, fs:0.75117 (r=0.808,p=0.702),  time:34.217, tt:1505.544\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.02014, lr:5.82e-02, fs:0.72642 (r=0.778,p=0.681),  time:34.230, tt:1540.370\n",
      "Ep:45, loss:0.00002, loss_test:0.02031, lr:5.82e-02, fs:0.72727 (r=0.768,p=0.691),  time:34.247, tt:1575.377\n",
      "Ep:46, loss:0.00001, loss_test:0.02089, lr:5.82e-02, fs:0.76923 (r=0.808,p=0.734),  time:34.274, tt:1610.867\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.02035, lr:5.82e-02, fs:0.75472 (r=0.808,p=0.708),  time:34.271, tt:1645.017\n",
      "Ep:48, loss:0.00001, loss_test:0.02073, lr:5.82e-02, fs:0.74286 (r=0.788,p=0.703),  time:34.281, tt:1679.785\n",
      "Ep:49, loss:0.00001, loss_test:0.02102, lr:5.82e-02, fs:0.76329 (r=0.798,p=0.731),  time:34.263, tt:1713.127\n",
      "Ep:50, loss:0.00001, loss_test:0.02237, lr:5.82e-02, fs:0.78431 (r=0.808,p=0.762),  time:34.272, tt:1747.873\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.02088, lr:5.82e-02, fs:0.75122 (r=0.778,p=0.726),  time:34.266, tt:1781.843\n",
      "Ep:52, loss:0.00001, loss_test:0.02072, lr:5.82e-02, fs:0.76329 (r=0.798,p=0.731),  time:34.287, tt:1817.195\n",
      "Ep:53, loss:0.00001, loss_test:0.02186, lr:5.82e-02, fs:0.76555 (r=0.808,p=0.727),  time:34.301, tt:1852.239\n",
      "Ep:54, loss:0.00001, loss_test:0.02103, lr:5.82e-02, fs:0.75862 (r=0.778,p=0.740),  time:34.311, tt:1887.079\n",
      "Ep:55, loss:0.00001, loss_test:0.02118, lr:5.82e-02, fs:0.77295 (r=0.808,p=0.741),  time:34.302, tt:1920.910\n",
      "Ep:56, loss:0.00001, loss_test:0.02034, lr:5.82e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.298, tt:1955.013\n",
      "Ep:57, loss:0.00001, loss_test:0.02108, lr:5.82e-02, fs:0.77295 (r=0.808,p=0.741),  time:34.286, tt:1988.594\n",
      "Ep:58, loss:0.00001, loss_test:0.02123, lr:5.82e-02, fs:0.77073 (r=0.798,p=0.745),  time:34.302, tt:2023.794\n",
      "Ep:59, loss:0.00001, loss_test:0.02180, lr:5.82e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.286, tt:2057.147\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.02253, lr:5.82e-02, fs:0.77387 (r=0.778,p=0.770),  time:34.269, tt:2090.421\n",
      "Ep:61, loss:0.00001, loss_test:0.02285, lr:5.82e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.261, tt:2124.170\n",
      "Ep:62, loss:0.00001, loss_test:0.02247, lr:5.82e-02, fs:0.79024 (r=0.818,p=0.764),  time:34.279, tt:2159.604\n",
      "Ep:63, loss:0.00001, loss_test:0.02291, lr:5.82e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.284, tt:2194.146\n",
      "Ep:64, loss:0.00001, loss_test:0.02334, lr:5.82e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.297, tt:2229.319\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.02423, lr:5.82e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.317, tt:2264.909\n",
      "Ep:66, loss:0.00001, loss_test:0.02422, lr:5.82e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.296, tt:2297.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.02410, lr:5.82e-02, fs:0.80597 (r=0.818,p=0.794),  time:34.297, tt:2332.173\n",
      "Ep:68, loss:0.00001, loss_test:0.02452, lr:5.82e-02, fs:0.80402 (r=0.808,p=0.800),  time:34.279, tt:2365.282\n",
      "Ep:69, loss:0.00001, loss_test:0.02534, lr:5.82e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.275, tt:2399.270\n",
      "Ep:70, loss:0.00001, loss_test:0.02567, lr:5.82e-02, fs:0.77720 (r=0.758,p=0.798),  time:34.277, tt:2433.638\n",
      "Ep:71, loss:0.00001, loss_test:0.02581, lr:5.82e-02, fs:0.78974 (r=0.778,p=0.802),  time:34.264, tt:2466.991\n",
      "Ep:72, loss:0.00001, loss_test:0.02593, lr:5.82e-02, fs:0.81633 (r=0.808,p=0.825),  time:34.274, tt:2502.027\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.02624, lr:5.82e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.298, tt:2538.050\n",
      "Ep:74, loss:0.00001, loss_test:0.02637, lr:5.82e-02, fs:0.80412 (r=0.788,p=0.821),  time:34.277, tt:2570.775\n",
      "Ep:75, loss:0.00001, loss_test:0.02746, lr:5.82e-02, fs:0.79144 (r=0.747,p=0.841),  time:34.291, tt:2606.131\n",
      "Ep:76, loss:0.00001, loss_test:0.02766, lr:5.82e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.307, tt:2641.642\n",
      "Ep:77, loss:0.00001, loss_test:0.02844, lr:5.82e-02, fs:0.77596 (r=0.717,p=0.845),  time:34.339, tt:2678.464\n",
      "Ep:78, loss:0.00001, loss_test:0.02904, lr:5.82e-02, fs:0.77174 (r=0.717,p=0.835),  time:34.344, tt:2713.189\n",
      "Ep:79, loss:0.00000, loss_test:0.02922, lr:5.82e-02, fs:0.76087 (r=0.707,p=0.824),  time:34.346, tt:2747.677\n",
      "Ep:80, loss:0.00000, loss_test:0.02960, lr:5.82e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.339, tt:2781.458\n",
      "Ep:81, loss:0.00000, loss_test:0.02963, lr:5.82e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.351, tt:2816.808\n",
      "Ep:82, loss:0.00000, loss_test:0.03051, lr:5.82e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.363, tt:2852.136\n",
      "Ep:83, loss:0.00001, loss_test:0.02970, lr:5.82e-02, fs:0.77005 (r=0.727,p=0.818),  time:34.355, tt:2885.841\n",
      "Ep:84, loss:0.00001, loss_test:0.02959, lr:5.76e-02, fs:0.79592 (r=0.788,p=0.804),  time:34.356, tt:2920.294\n",
      "Ep:85, loss:0.00001, loss_test:0.03043, lr:5.71e-02, fs:0.75393 (r=0.727,p=0.783),  time:34.330, tt:2952.352\n",
      "Ep:86, loss:0.00001, loss_test:0.02789, lr:5.65e-02, fs:0.81865 (r=0.798,p=0.840),  time:34.317, tt:2985.560\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.02865, lr:5.65e-02, fs:0.76142 (r=0.758,p=0.765),  time:34.349, tt:3022.726\n",
      "Ep:88, loss:0.00001, loss_test:0.02715, lr:5.65e-02, fs:0.80000 (r=0.788,p=0.812),  time:34.348, tt:3056.938\n",
      "Ep:89, loss:0.00001, loss_test:0.02949, lr:5.65e-02, fs:0.75648 (r=0.737,p=0.777),  time:34.335, tt:3090.158\n",
      "Ep:90, loss:0.00001, loss_test:0.02869, lr:5.65e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.321, tt:3123.216\n",
      "Ep:91, loss:0.00001, loss_test:0.03076, lr:5.65e-02, fs:0.75789 (r=0.727,p=0.791),  time:34.323, tt:3157.702\n",
      "Ep:92, loss:0.00000, loss_test:0.03128, lr:5.65e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.333, tt:3192.962\n",
      "Ep:93, loss:0.00000, loss_test:0.03209, lr:5.65e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.329, tt:3226.958\n",
      "Ep:94, loss:0.00000, loss_test:0.03247, lr:5.65e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.350, tt:3263.226\n",
      "Ep:95, loss:0.00000, loss_test:0.03415, lr:5.65e-02, fs:0.76667 (r=0.697,p=0.852),  time:34.363, tt:3298.811\n",
      "Ep:96, loss:0.00000, loss_test:0.03473, lr:5.65e-02, fs:0.76757 (r=0.717,p=0.826),  time:34.365, tt:3333.406\n",
      "Ep:97, loss:0.00000, loss_test:0.03302, lr:5.65e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.378, tt:3369.073\n",
      "Ep:98, loss:0.00000, loss_test:0.03426, lr:5.59e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.391, tt:3404.725\n",
      "Ep:99, loss:0.00000, loss_test:0.03517, lr:5.54e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.410, tt:3441.042\n",
      "Ep:100, loss:0.00000, loss_test:0.03488, lr:5.48e-02, fs:0.76503 (r=0.707,p=0.833),  time:34.423, tt:3476.770\n",
      "Ep:101, loss:0.00000, loss_test:0.03437, lr:5.43e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.421, tt:3510.926\n",
      "Ep:102, loss:0.00000, loss_test:0.03557, lr:5.37e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.462, tt:3549.597\n",
      "Ep:103, loss:0.00000, loss_test:0.03725, lr:5.32e-02, fs:0.77174 (r=0.717,p=0.835),  time:34.464, tt:3584.303\n",
      "Ep:104, loss:0.00000, loss_test:0.03551, lr:5.27e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.477, tt:3620.077\n",
      "Ep:105, loss:0.00000, loss_test:0.03670, lr:5.21e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.481, tt:3655.023\n",
      "Ep:106, loss:0.00000, loss_test:0.03784, lr:5.16e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.482, tt:3689.569\n",
      "Ep:107, loss:0.00000, loss_test:0.03877, lr:5.11e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.482, tt:3724.069\n",
      "Ep:108, loss:0.00000, loss_test:0.03666, lr:5.06e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.478, tt:3758.117\n",
      "Ep:109, loss:0.00000, loss_test:0.03854, lr:5.01e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.482, tt:3793.073\n",
      "Ep:110, loss:0.00000, loss_test:0.03933, lr:4.96e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.475, tt:3826.772\n",
      "Ep:111, loss:0.00000, loss_test:0.03917, lr:4.91e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.470, tt:3860.588\n",
      "Ep:112, loss:0.00000, loss_test:0.03763, lr:4.86e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.465, tt:3894.520\n",
      "Ep:113, loss:0.00000, loss_test:0.03915, lr:4.81e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.463, tt:3928.771\n",
      "Ep:114, loss:0.00000, loss_test:0.03980, lr:4.76e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.464, tt:3963.412\n",
      "Ep:115, loss:0.00000, loss_test:0.03893, lr:4.71e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.464, tt:3997.876\n",
      "Ep:116, loss:0.00000, loss_test:0.03855, lr:4.67e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.469, tt:4032.829\n",
      "Ep:117, loss:0.00000, loss_test:0.04043, lr:4.62e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.463, tt:4066.637\n",
      "Ep:118, loss:0.00000, loss_test:0.03895, lr:4.57e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.465, tt:4101.317\n",
      "Ep:119, loss:0.00000, loss_test:0.03877, lr:4.53e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.453, tt:4134.368\n",
      "Ep:120, loss:0.00000, loss_test:0.03952, lr:4.48e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.447, tt:4168.064\n",
      "Ep:121, loss:0.00000, loss_test:0.03923, lr:4.44e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.440, tt:4201.688\n",
      "Ep:122, loss:0.00000, loss_test:0.03904, lr:4.39e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.435, tt:4235.468\n",
      "Ep:123, loss:0.00000, loss_test:0.04057, lr:4.35e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.416, tt:4267.589\n",
      "Ep:124, loss:0.00000, loss_test:0.03892, lr:4.31e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.426, tt:4303.246\n",
      "Ep:125, loss:0.00000, loss_test:0.03980, lr:4.26e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.423, tt:4337.348\n",
      "Ep:126, loss:0.00000, loss_test:0.04009, lr:4.22e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.427, tt:4372.184\n",
      "Ep:127, loss:0.00000, loss_test:0.03960, lr:4.18e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.418, tt:4405.505\n",
      "Ep:128, loss:0.00000, loss_test:0.04056, lr:4.14e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.421, tt:4440.291\n",
      "Ep:129, loss:0.00000, loss_test:0.04077, lr:4.10e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.420, tt:4474.621\n",
      "Ep:130, loss:0.00000, loss_test:0.04014, lr:4.05e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.410, tt:4507.726\n",
      "Ep:131, loss:0.00000, loss_test:0.04057, lr:4.01e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.406, tt:4541.558\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00000, loss_test:0.04039, lr:4.01e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.403, tt:4575.641\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00000, loss_test:0.04108, lr:4.01e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.409, tt:4610.784\n",
      "Ep:134, loss:0.00000, loss_test:0.04105, lr:4.01e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.413, tt:4645.694\n",
      "Ep:135, loss:0.00000, loss_test:0.04105, lr:4.01e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.410, tt:4679.754\n",
      "Ep:136, loss:0.00000, loss_test:0.04083, lr:4.01e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.419, tt:4715.347\n",
      "Ep:137, loss:0.00000, loss_test:0.04162, lr:4.01e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.412, tt:4748.815\n",
      "Ep:138, loss:0.00000, loss_test:0.04100, lr:4.01e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.403, tt:4782.079\n",
      "Ep:139, loss:0.00000, loss_test:0.04167, lr:4.01e-02, fs:0.81395 (r=0.707,p=0.959),  time:34.401, tt:4816.176\n",
      "Ep:140, loss:0.00000, loss_test:0.04069, lr:4.01e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.386, tt:4848.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.04131, lr:4.01e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.378, tt:4881.653\n",
      "Ep:142, loss:0.00000, loss_test:0.04172, lr:4.01e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.371, tt:4915.096\n",
      "Ep:143, loss:0.00000, loss_test:0.04122, lr:4.01e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.358, tt:4947.482\n",
      "Ep:144, loss:0.00000, loss_test:0.04134, lr:3.97e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.349, tt:4980.609\n",
      "Ep:145, loss:0.00000, loss_test:0.04158, lr:3.93e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.351, tt:5015.310\n",
      "Ep:146, loss:0.00000, loss_test:0.04182, lr:3.89e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.347, tt:5049.000\n",
      "Ep:147, loss:0.00000, loss_test:0.04170, lr:3.86e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.339, tt:5082.138\n",
      "Ep:148, loss:0.00000, loss_test:0.04174, lr:3.82e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.338, tt:5116.402\n",
      "Ep:149, loss:0.00000, loss_test:0.04151, lr:3.78e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.330, tt:5149.566\n",
      "Ep:150, loss:0.00000, loss_test:0.04166, lr:3.74e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.330, tt:5183.764\n",
      "Ep:151, loss:0.00000, loss_test:0.04214, lr:3.70e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.324, tt:5217.186\n",
      "Ep:152, loss:0.00000, loss_test:0.04209, lr:3.67e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.316, tt:5250.381\n",
      "Ep:153, loss:0.00000, loss_test:0.04215, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.308, tt:5283.467\n",
      "Ep:154, loss:0.00000, loss_test:0.04215, lr:3.59e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.309, tt:5317.839\n",
      "Ep:155, loss:0.00000, loss_test:0.04255, lr:3.56e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.299, tt:5350.697\n",
      "Ep:156, loss:0.00000, loss_test:0.04219, lr:3.52e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.309, tt:5386.520\n",
      "Ep:157, loss:0.00000, loss_test:0.04246, lr:3.49e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.310, tt:5420.938\n",
      "Ep:158, loss:0.00000, loss_test:0.04263, lr:3.45e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.301, tt:5453.819\n",
      "Ep:159, loss:0.00000, loss_test:0.04253, lr:3.42e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.300, tt:5488.075\n",
      "Ep:160, loss:0.00000, loss_test:0.04251, lr:3.38e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.306, tt:5523.294\n",
      "Ep:161, loss:0.00000, loss_test:0.04269, lr:3.35e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.315, tt:5558.957\n",
      "Ep:162, loss:0.00000, loss_test:0.04281, lr:3.32e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.322, tt:5594.541\n",
      "Ep:163, loss:0.00000, loss_test:0.04280, lr:3.28e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.327, tt:5629.565\n",
      "Ep:164, loss:0.00000, loss_test:0.04274, lr:3.25e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.332, tt:5664.812\n",
      "Ep:165, loss:0.00000, loss_test:0.04293, lr:3.22e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.343, tt:5700.913\n",
      "Ep:166, loss:0.00000, loss_test:0.04293, lr:3.19e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.342, tt:5735.142\n",
      "Ep:167, loss:0.00000, loss_test:0.04288, lr:3.15e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.353, tt:5771.310\n",
      "Ep:168, loss:0.00000, loss_test:0.04297, lr:3.12e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.366, tt:5807.929\n",
      "Ep:169, loss:0.00000, loss_test:0.04284, lr:3.09e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.375, tt:5843.833\n",
      "Ep:170, loss:0.00000, loss_test:0.04305, lr:3.06e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.376, tt:5878.319\n",
      "Ep:171, loss:0.00000, loss_test:0.04300, lr:3.03e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.376, tt:5912.652\n",
      "Ep:172, loss:0.00000, loss_test:0.04320, lr:3.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.383, tt:5948.224\n",
      "Ep:173, loss:0.00000, loss_test:0.04322, lr:2.97e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.392, tt:5984.153\n",
      "Ep:174, loss:0.00000, loss_test:0.04307, lr:2.94e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.384, tt:6017.261\n",
      "Ep:175, loss:0.00000, loss_test:0.04320, lr:2.91e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.390, tt:6052.691\n",
      "Ep:176, loss:0.00000, loss_test:0.04326, lr:2.88e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.393, tt:6087.594\n",
      "Ep:177, loss:0.00000, loss_test:0.04323, lr:2.85e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.394, tt:6122.081\n",
      "Ep:178, loss:0.00000, loss_test:0.04350, lr:2.82e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.398, tt:6157.298\n",
      "Ep:179, loss:0.00000, loss_test:0.04325, lr:2.80e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.406, tt:6193.051\n",
      "Ep:180, loss:0.00000, loss_test:0.04354, lr:2.77e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.414, tt:6228.983\n",
      "Ep:181, loss:0.00000, loss_test:0.04344, lr:2.74e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.423, tt:6264.910\n",
      "Ep:182, loss:0.00000, loss_test:0.04363, lr:2.71e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.424, tt:6299.531\n",
      "Ep:183, loss:0.00000, loss_test:0.04339, lr:2.69e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.432, tt:6335.478\n",
      "Ep:184, loss:0.00000, loss_test:0.04372, lr:2.66e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.439, tt:6371.131\n",
      "Ep:185, loss:0.00000, loss_test:0.04341, lr:2.63e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.452, tt:6407.983\n",
      "Ep:186, loss:0.00000, loss_test:0.04386, lr:2.61e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.460, tt:6444.078\n",
      "Ep:187, loss:0.00000, loss_test:0.04339, lr:2.58e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.466, tt:6479.649\n",
      "Ep:188, loss:0.00000, loss_test:0.04395, lr:2.55e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.476, tt:6515.920\n",
      "Ep:189, loss:0.00000, loss_test:0.04360, lr:2.53e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.481, tt:6551.324\n",
      "Ep:190, loss:0.00000, loss_test:0.04394, lr:2.50e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.484, tt:6586.389\n",
      "Ep:191, loss:0.00000, loss_test:0.04373, lr:2.48e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.481, tt:6620.429\n",
      "Ep:192, loss:0.00000, loss_test:0.04392, lr:2.45e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.482, tt:6654.934\n",
      "Ep:193, loss:0.00000, loss_test:0.04377, lr:2.43e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.486, tt:6690.215\n",
      "Ep:194, loss:0.00000, loss_test:0.04396, lr:2.40e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.486, tt:6724.837\n",
      "Ep:195, loss:0.00000, loss_test:0.04380, lr:2.38e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.485, tt:6759.036\n",
      "Ep:196, loss:0.00000, loss_test:0.04408, lr:2.36e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.486, tt:6793.782\n",
      "Ep:197, loss:0.00000, loss_test:0.04390, lr:2.33e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.488, tt:6828.590\n",
      "Ep:198, loss:0.00000, loss_test:0.04414, lr:2.31e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.494, tt:6864.295\n",
      "Ep:199, loss:0.00000, loss_test:0.04405, lr:2.29e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.497, tt:6899.435\n",
      "Ep:200, loss:0.00000, loss_test:0.04401, lr:2.26e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.510, tt:6936.469\n",
      "Ep:201, loss:0.00000, loss_test:0.04405, lr:2.24e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.516, tt:6972.249\n",
      "Ep:202, loss:0.00000, loss_test:0.04407, lr:2.22e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.522, tt:7007.868\n",
      "Ep:203, loss:0.00000, loss_test:0.04417, lr:2.20e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.523, tt:7042.640\n",
      "Ep:204, loss:0.00000, loss_test:0.04414, lr:2.17e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.527, tt:7078.035\n",
      "Ep:205, loss:0.00000, loss_test:0.04423, lr:2.15e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.528, tt:7112.665\n",
      "Ep:206, loss:0.00000, loss_test:0.04410, lr:2.13e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.535, tt:7148.647\n",
      "Ep:207, loss:0.00000, loss_test:0.04428, lr:2.11e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.541, tt:7184.619\n",
      "Ep:208, loss:0.00000, loss_test:0.04430, lr:2.09e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.539, tt:7218.697\n",
      "Ep:209, loss:0.00000, loss_test:0.04418, lr:2.07e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.543, tt:7253.977\n",
      "Ep:210, loss:0.00000, loss_test:0.04431, lr:2.05e-02, fs:0.82081 (r=0.717,p=0.959),  time:34.524, tt:7284.630\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.11450, lr:1.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:30.724, tt:30.724\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00027, loss_test:0.11490, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:31.112, tt:62.224\n",
      "Ep:2, loss:0.00027, loss_test:0.11544, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:30.853, tt:92.559\n",
      "Ep:3, loss:0.00026, loss_test:0.11501, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:32.334, tt:129.335\n",
      "Ep:4, loss:0.00026, loss_test:0.11400, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:33.251, tt:166.256\n",
      "Ep:5, loss:0.00026, loss_test:0.11287, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:33.695, tt:202.172\n",
      "Ep:6, loss:0.00026, loss_test:0.11174, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:34.162, tt:239.136\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.11093, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:34.500, tt:276.001\n",
      "Ep:8, loss:0.00026, loss_test:0.11052, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:34.999, tt:314.989\n",
      "Ep:9, loss:0.00026, loss_test:0.11028, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:35.235, tt:352.354\n",
      "Ep:10, loss:0.00025, loss_test:0.10961, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:35.346, tt:388.804\n",
      "Ep:11, loss:0.00025, loss_test:0.10822, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:35.400, tt:424.801\n",
      "Ep:12, loss:0.00025, loss_test:0.10683, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:35.429, tt:460.575\n",
      "Ep:13, loss:0.00025, loss_test:0.10630, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:35.456, tt:496.384\n",
      "Ep:14, loss:0.00025, loss_test:0.10557, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:35.397, tt:530.962\n",
      "Ep:15, loss:0.00024, loss_test:0.10503, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:35.423, tt:566.760\n",
      "Ep:16, loss:0.00024, loss_test:0.10367, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:35.370, tt:601.289\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.10175, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:35.479, tt:638.626\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.10124, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:35.507, tt:674.630\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.10078, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:35.577, tt:711.535\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.09837, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:35.625, tt:748.120\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.09741, lr:1.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:35.678, tt:784.924\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.09661, lr:1.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:35.731, tt:821.804\n",
      "Ep:23, loss:0.00022, loss_test:0.09402, lr:1.00e-02, fs:0.73640 (r=0.889,p=0.629),  time:35.791, tt:858.996\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.09389, lr:1.00e-02, fs:0.74380 (r=0.909,p=0.629),  time:35.807, tt:895.187\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.09114, lr:1.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:35.846, tt:931.999\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00020, loss_test:0.09034, lr:1.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:35.870, tt:968.490\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.08623, lr:1.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:35.872, tt:1004.406\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.08814, lr:1.00e-02, fs:0.76596 (r=0.909,p=0.662),  time:35.908, tt:1041.339\n",
      "Ep:29, loss:0.00018, loss_test:0.08364, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:35.919, tt:1077.571\n",
      "Ep:30, loss:0.00018, loss_test:0.08469, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:35.921, tt:1113.540\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.08357, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:35.957, tt:1150.616\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00017, loss_test:0.08099, lr:1.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:35.967, tt:1186.923\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00016, loss_test:0.07973, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:35.988, tt:1223.601\n",
      "Ep:34, loss:0.00015, loss_test:0.07790, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:35.984, tt:1259.441\n",
      "Ep:35, loss:0.00015, loss_test:0.07868, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:36.025, tt:1296.901\n",
      "Ep:36, loss:0.00014, loss_test:0.08863, lr:1.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:36.048, tt:1333.792\n",
      "Ep:37, loss:0.00014, loss_test:0.07419, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:36.081, tt:1371.059\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00015, loss_test:0.08331, lr:1.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:36.094, tt:1407.663\n",
      "Ep:39, loss:0.00013, loss_test:0.06897, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:36.086, tt:1443.439\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.07878, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:36.135, tt:1481.537\n",
      "Ep:41, loss:0.00012, loss_test:0.07037, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:36.150, tt:1518.289\n",
      "Ep:42, loss:0.00012, loss_test:0.07826, lr:1.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:36.125, tt:1553.384\n",
      "Ep:43, loss:0.00011, loss_test:0.06311, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:36.129, tt:1589.672\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.07108, lr:1.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:36.130, tt:1625.869\n",
      "Ep:45, loss:0.00011, loss_test:0.06172, lr:1.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:36.110, tt:1661.061\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.06136, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:36.079, tt:1695.695\n",
      "Ep:47, loss:0.00009, loss_test:0.07039, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:36.083, tt:1731.970\n",
      "Ep:48, loss:0.00009, loss_test:0.06669, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:36.034, tt:1765.653\n",
      "Ep:49, loss:0.00009, loss_test:0.06836, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:36.024, tt:1801.206\n",
      "Ep:50, loss:0.00009, loss_test:0.06183, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:35.998, tt:1835.901\n",
      "Ep:51, loss:0.00008, loss_test:0.06450, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.963, tt:1870.053\n",
      "Ep:52, loss:0.00007, loss_test:0.05956, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.991, tt:1907.503\n",
      "Ep:53, loss:0.00007, loss_test:0.06102, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:36.026, tt:1945.409\n",
      "Ep:54, loss:0.00007, loss_test:0.05951, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:36.006, tt:1980.350\n",
      "Ep:55, loss:0.00006, loss_test:0.05590, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.021, tt:2017.181\n",
      "Ep:56, loss:0.00007, loss_test:0.05870, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:35.994, tt:2051.637\n",
      "Ep:57, loss:0.00006, loss_test:0.05568, lr:9.90e-03, fs:0.84324 (r=0.788,p=0.907),  time:35.973, tt:2086.446\n",
      "Ep:58, loss:0.00006, loss_test:0.05583, lr:9.80e-03, fs:0.86735 (r=0.859,p=0.876),  time:35.992, tt:2123.526\n",
      "Ep:59, loss:0.00005, loss_test:0.05559, lr:9.70e-03, fs:0.88205 (r=0.869,p=0.896),  time:36.007, tt:2160.444\n",
      "Ep:60, loss:0.00006, loss_test:0.06401, lr:9.61e-03, fs:0.84158 (r=0.859,p=0.825),  time:35.998, tt:2195.878\n",
      "Ep:61, loss:0.00007, loss_test:0.05417, lr:9.51e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.996, tt:2231.772\n",
      "Ep:62, loss:0.00006, loss_test:0.05964, lr:9.41e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.007, tt:2268.453\n",
      "Ep:63, loss:0.00006, loss_test:0.05756, lr:9.32e-03, fs:0.82105 (r=0.788,p=0.857),  time:36.027, tt:2305.735\n",
      "Ep:64, loss:0.00005, loss_test:0.05954, lr:9.23e-03, fs:0.86772 (r=0.828,p=0.911),  time:36.019, tt:2341.214\n",
      "Ep:65, loss:0.00005, loss_test:0.05146, lr:9.14e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.005, tt:2376.302\n",
      "Ep:66, loss:0.00005, loss_test:0.05204, lr:9.04e-03, fs:0.87755 (r=0.869,p=0.887),  time:36.009, tt:2412.619\n",
      "Ep:67, loss:0.00004, loss_test:0.05576, lr:8.95e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.009, tt:2448.615\n",
      "Ep:68, loss:0.00004, loss_test:0.05525, lr:8.86e-03, fs:0.88205 (r=0.869,p=0.896),  time:36.030, tt:2486.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00004, loss_test:0.05015, lr:8.78e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.050, tt:2523.506\n",
      "Ep:70, loss:0.00004, loss_test:0.05093, lr:8.69e-03, fs:0.84946 (r=0.798,p=0.908),  time:36.054, tt:2559.859\n",
      "Ep:71, loss:0.00004, loss_test:0.05362, lr:8.60e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.093, tt:2598.708\n",
      "Ep:72, loss:0.00003, loss_test:0.05141, lr:8.51e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.110, tt:2636.038\n",
      "Ep:73, loss:0.00003, loss_test:0.05155, lr:8.43e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.104, tt:2671.731\n",
      "Ep:74, loss:0.00003, loss_test:0.05405, lr:8.35e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.114, tt:2708.563\n",
      "Ep:75, loss:0.00003, loss_test:0.05603, lr:8.26e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.104, tt:2743.886\n",
      "Ep:76, loss:0.00004, loss_test:0.05495, lr:8.18e-03, fs:0.87629 (r=0.859,p=0.895),  time:36.105, tt:2780.051\n",
      "Ep:77, loss:0.00003, loss_test:0.05679, lr:8.10e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.094, tt:2815.300\n",
      "Ep:78, loss:0.00003, loss_test:0.05030, lr:8.02e-03, fs:0.90052 (r=0.869,p=0.935),  time:36.085, tt:2850.690\n",
      "Ep:79, loss:0.00003, loss_test:0.05285, lr:7.94e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.081, tt:2886.471\n",
      "Ep:80, loss:0.00003, loss_test:0.04925, lr:7.86e-03, fs:0.88325 (r=0.879,p=0.888),  time:36.089, tt:2923.181\n",
      "Ep:81, loss:0.00003, loss_test:0.05292, lr:7.78e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.109, tt:2960.918\n",
      "Ep:82, loss:0.00003, loss_test:0.04969, lr:7.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:36.112, tt:2997.303\n",
      "Ep:83, loss:0.00003, loss_test:0.05353, lr:7.62e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.127, tt:3034.693\n",
      "Ep:84, loss:0.00003, loss_test:0.05007, lr:7.55e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.108, tt:3069.185\n",
      "Ep:85, loss:0.00003, loss_test:0.05394, lr:7.47e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.103, tt:3104.861\n",
      "Ep:86, loss:0.00003, loss_test:0.05370, lr:7.40e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.100, tt:3140.663\n",
      "Ep:87, loss:0.00003, loss_test:0.05371, lr:7.32e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.089, tt:3175.844\n",
      "Ep:88, loss:0.00003, loss_test:0.05343, lr:7.25e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.102, tt:3213.049\n",
      "Ep:89, loss:0.00003, loss_test:0.05178, lr:7.18e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.073, tt:3246.541\n",
      "Ep:90, loss:0.00002, loss_test:0.05283, lr:7.11e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.058, tt:3281.246\n",
      "Ep:91, loss:0.00003, loss_test:0.05037, lr:7.03e-03, fs:0.88421 (r=0.848,p=0.923),  time:36.049, tt:3316.499\n",
      "Ep:92, loss:0.00002, loss_test:0.05426, lr:6.96e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.053, tt:3352.935\n",
      "Ep:93, loss:0.00002, loss_test:0.05432, lr:6.89e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.048, tt:3388.534\n",
      "Ep:94, loss:0.00002, loss_test:0.05241, lr:6.83e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.053, tt:3425.063\n",
      "Ep:95, loss:0.00002, loss_test:0.04864, lr:6.76e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.088, tt:3464.477\n",
      "Ep:96, loss:0.00002, loss_test:0.05084, lr:6.69e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.107, tt:3502.389\n",
      "Ep:97, loss:0.00002, loss_test:0.05219, lr:6.62e-03, fs:0.87234 (r=0.828,p=0.921),  time:36.106, tt:3538.431\n",
      "Ep:98, loss:0.00002, loss_test:0.05197, lr:6.56e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.122, tt:3576.031\n",
      "Ep:99, loss:0.00002, loss_test:0.04991, lr:6.49e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.134, tt:3613.363\n",
      "Ep:100, loss:0.00002, loss_test:0.04967, lr:6.43e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.153, tt:3651.483\n",
      "Ep:101, loss:0.00002, loss_test:0.05084, lr:6.36e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.162, tt:3688.553\n",
      "Ep:102, loss:0.00002, loss_test:0.05206, lr:6.30e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.165, tt:3725.010\n",
      "Ep:103, loss:0.00002, loss_test:0.04795, lr:6.24e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.171, tt:3761.747\n",
      "Ep:104, loss:0.00002, loss_test:0.04988, lr:6.17e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.173, tt:3798.125\n",
      "Ep:105, loss:0.00001, loss_test:0.04945, lr:6.11e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.170, tt:3834.023\n",
      "Ep:106, loss:0.00001, loss_test:0.05236, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.166, tt:3869.726\n",
      "Ep:107, loss:0.00001, loss_test:0.04834, lr:5.99e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.162, tt:3905.463\n",
      "Ep:108, loss:0.00001, loss_test:0.05067, lr:5.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.178, tt:3943.453\n",
      "Ep:109, loss:0.00001, loss_test:0.04890, lr:5.87e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.165, tt:3978.124\n",
      "Ep:110, loss:0.00001, loss_test:0.05161, lr:5.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.166, tt:4014.456\n",
      "Ep:111, loss:0.00001, loss_test:0.04950, lr:5.75e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.177, tt:4051.814\n",
      "Ep:112, loss:0.00001, loss_test:0.05271, lr:5.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.169, tt:4087.050\n",
      "Ep:113, loss:0.00001, loss_test:0.04883, lr:5.64e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.167, tt:4123.020\n",
      "Ep:114, loss:0.00001, loss_test:0.04702, lr:5.58e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.159, tt:4158.323\n",
      "Ep:115, loss:0.00001, loss_test:0.05296, lr:5.53e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.161, tt:4194.644\n",
      "Ep:116, loss:0.00001, loss_test:0.04877, lr:5.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.160, tt:4230.720\n",
      "Ep:117, loss:0.00001, loss_test:0.05179, lr:5.42e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.158, tt:4266.653\n",
      "Ep:118, loss:0.00001, loss_test:0.04889, lr:5.36e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.151, tt:4301.946\n",
      "Ep:119, loss:0.00001, loss_test:0.05033, lr:5.31e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.154, tt:4338.462\n",
      "Ep:120, loss:0.00001, loss_test:0.04850, lr:5.26e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.146, tt:4373.675\n",
      "Ep:121, loss:0.00001, loss_test:0.04909, lr:5.20e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.154, tt:4410.787\n",
      "Ep:122, loss:0.00001, loss_test:0.04883, lr:5.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.146, tt:4445.951\n",
      "Ep:123, loss:0.00001, loss_test:0.04886, lr:5.10e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.137, tt:4481.012\n",
      "Ep:124, loss:0.00001, loss_test:0.04904, lr:5.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.135, tt:4516.874\n",
      "Ep:125, loss:0.00001, loss_test:0.04703, lr:5.00e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.141, tt:4553.727\n",
      "Ep:126, loss:0.00001, loss_test:0.04944, lr:4.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.131, tt:4588.642\n",
      "Ep:127, loss:0.00001, loss_test:0.04640, lr:4.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.125, tt:4623.947\n",
      "Ep:128, loss:0.00001, loss_test:0.04881, lr:4.85e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.119, tt:4659.396\n",
      "Ep:129, loss:0.00001, loss_test:0.04889, lr:4.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.126, tt:4696.392\n",
      "Ep:130, loss:0.00001, loss_test:0.04703, lr:4.75e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.119, tt:4731.524\n",
      "Ep:131, loss:0.00001, loss_test:0.04829, lr:4.71e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.118, tt:4767.563\n",
      "Ep:132, loss:0.00001, loss_test:0.04792, lr:4.66e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.115, tt:4803.284\n",
      "Ep:133, loss:0.00001, loss_test:0.04879, lr:4.61e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.122, tt:4840.315\n",
      "Ep:134, loss:0.00001, loss_test:0.04784, lr:4.57e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.112, tt:4875.172\n",
      "Ep:135, loss:0.00001, loss_test:0.04689, lr:4.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.105, tt:4910.343\n",
      "Ep:136, loss:0.00001, loss_test:0.04781, lr:4.48e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.112, tt:4947.337\n",
      "Ep:137, loss:0.00001, loss_test:0.04961, lr:4.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.134, tt:4986.505\n",
      "Ep:138, loss:0.00001, loss_test:0.04803, lr:4.39e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.142, tt:5023.694\n",
      "Ep:139, loss:0.00001, loss_test:0.05075, lr:4.34e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.156, tt:5061.810\n",
      "Ep:140, loss:0.00001, loss_test:0.04816, lr:4.30e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.159, tt:5098.469\n",
      "Ep:141, loss:0.00001, loss_test:0.04999, lr:4.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.161, tt:5134.842\n",
      "Ep:142, loss:0.00001, loss_test:0.04747, lr:4.21e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.157, tt:5170.425\n",
      "Ep:143, loss:0.00001, loss_test:0.04965, lr:4.17e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.161, tt:5207.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.04688, lr:4.13e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.173, tt:5245.098\n",
      "Ep:145, loss:0.00001, loss_test:0.04973, lr:4.09e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.182, tt:5282.586\n",
      "Ep:146, loss:0.00001, loss_test:0.04613, lr:4.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.198, tt:5321.070\n",
      "Ep:147, loss:0.00001, loss_test:0.04861, lr:4.01e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.201, tt:5357.789\n",
      "Ep:148, loss:0.00001, loss_test:0.04757, lr:3.97e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.204, tt:5394.435\n",
      "Ep:149, loss:0.00001, loss_test:0.04716, lr:3.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.201, tt:5430.135\n",
      "Ep:150, loss:0.00001, loss_test:0.04860, lr:3.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.195, tt:5465.502\n",
      "Ep:151, loss:0.00001, loss_test:0.04651, lr:3.85e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.198, tt:5502.050\n",
      "Ep:152, loss:0.00001, loss_test:0.04782, lr:3.81e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.193, tt:5537.508\n",
      "Ep:153, loss:0.00001, loss_test:0.04773, lr:3.77e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.193, tt:5573.735\n",
      "Ep:154, loss:0.00001, loss_test:0.04697, lr:3.73e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.199, tt:5610.859\n",
      "Ep:155, loss:0.00001, loss_test:0.04661, lr:3.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.205, tt:5648.053\n",
      "Ep:156, loss:0.00001, loss_test:0.04683, lr:3.66e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.207, tt:5684.463\n",
      "Ep:157, loss:0.00001, loss_test:0.04778, lr:3.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.210, tt:5721.211\n",
      "Ep:158, loss:0.00001, loss_test:0.04711, lr:3.59e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.207, tt:5756.958\n",
      "Ep:159, loss:0.00001, loss_test:0.04679, lr:3.55e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.209, tt:5793.385\n",
      "Ep:160, loss:0.00001, loss_test:0.04739, lr:3.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.214, tt:5830.384\n",
      "Ep:161, loss:0.00001, loss_test:0.04676, lr:3.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.208, tt:5865.676\n",
      "Ep:162, loss:0.00001, loss_test:0.04714, lr:3.45e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.203, tt:5901.114\n",
      "Ep:163, loss:0.00001, loss_test:0.04690, lr:3.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.210, tt:5938.384\n",
      "Ep:164, loss:0.00001, loss_test:0.04704, lr:3.38e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.205, tt:5973.854\n",
      "Ep:165, loss:0.00001, loss_test:0.04636, lr:3.34e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.203, tt:6009.721\n",
      "Ep:166, loss:0.00001, loss_test:0.04773, lr:3.31e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.205, tt:6046.300\n",
      "Ep:167, loss:0.00001, loss_test:0.04667, lr:3.28e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.206, tt:6082.658\n",
      "Ep:168, loss:0.00001, loss_test:0.04824, lr:3.24e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.205, tt:6118.681\n",
      "Ep:169, loss:0.00001, loss_test:0.04745, lr:3.21e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.201, tt:6154.209\n",
      "Ep:170, loss:0.00001, loss_test:0.04916, lr:3.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.207, tt:6191.409\n",
      "Ep:171, loss:0.00001, loss_test:0.04667, lr:3.15e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.200, tt:6226.433\n",
      "Ep:172, loss:0.00001, loss_test:0.04978, lr:3.12e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.199, tt:6262.345\n",
      "Ep:173, loss:0.00001, loss_test:0.04794, lr:3.09e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.192, tt:6297.460\n",
      "Ep:174, loss:0.00001, loss_test:0.04936, lr:3.05e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.207, tt:6336.199\n",
      "Ep:175, loss:0.00001, loss_test:0.04736, lr:3.02e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.207, tt:6372.415\n",
      "Ep:176, loss:0.00001, loss_test:0.04793, lr:2.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.205, tt:6408.200\n",
      "Ep:177, loss:0.00001, loss_test:0.04752, lr:2.96e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.202, tt:6443.895\n",
      "Ep:178, loss:0.00001, loss_test:0.04726, lr:2.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.204, tt:6480.505\n",
      "Ep:179, loss:0.00001, loss_test:0.04853, lr:2.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.205, tt:6516.908\n",
      "Ep:180, loss:0.00001, loss_test:0.04616, lr:2.88e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.202, tt:6552.576\n",
      "Ep:181, loss:0.00001, loss_test:0.04870, lr:2.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.204, tt:6589.047\n",
      "Ep:182, loss:0.00001, loss_test:0.04685, lr:2.82e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.202, tt:6625.003\n",
      "Ep:183, loss:0.00001, loss_test:0.04730, lr:2.79e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.206, tt:6661.851\n",
      "Ep:184, loss:0.00001, loss_test:0.04755, lr:2.76e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.211, tt:6698.967\n",
      "Ep:185, loss:0.00001, loss_test:0.04812, lr:2.73e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.218, tt:6736.456\n",
      "Ep:186, loss:0.00001, loss_test:0.04696, lr:2.71e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.217, tt:6772.561\n",
      "Ep:187, loss:0.00001, loss_test:0.04860, lr:2.68e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.236, tt:6812.451\n",
      "Ep:188, loss:0.00001, loss_test:0.04817, lr:2.65e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.239, tt:6849.165\n",
      "Ep:189, loss:0.00001, loss_test:0.04716, lr:2.63e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.242, tt:6886.060\n",
      "Ep:190, loss:0.00001, loss_test:0.04892, lr:2.60e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.242, tt:6922.300\n",
      "Ep:191, loss:0.00001, loss_test:0.04717, lr:2.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.243, tt:6958.725\n",
      "Ep:192, loss:0.00001, loss_test:0.04863, lr:2.55e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.244, tt:6995.085\n",
      "Ep:193, loss:0.00001, loss_test:0.04803, lr:2.52e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.244, tt:7031.372\n",
      "Ep:194, loss:0.00001, loss_test:0.04797, lr:2.50e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.243, tt:7067.406\n",
      "Ep:195, loss:0.00000, loss_test:0.04837, lr:2.47e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.247, tt:7104.462\n",
      "Ep:196, loss:0.00001, loss_test:0.04721, lr:2.45e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.246, tt:7140.523\n",
      "Ep:197, loss:0.00000, loss_test:0.04902, lr:2.42e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.243, tt:7176.090\n",
      "Ep:198, loss:0.00000, loss_test:0.04780, lr:2.40e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.245, tt:7212.800\n",
      "Ep:199, loss:0.00000, loss_test:0.04741, lr:2.38e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.239, tt:7247.856\n",
      "Ep:200, loss:0.00000, loss_test:0.04840, lr:2.35e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.240, tt:7284.303\n",
      "Ep:201, loss:0.00000, loss_test:0.04747, lr:2.33e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.244, tt:7321.226\n",
      "Ep:202, loss:0.00000, loss_test:0.04710, lr:2.31e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.245, tt:7357.809\n",
      "Ep:203, loss:0.00000, loss_test:0.04741, lr:2.28e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.246, tt:7394.217\n",
      "Ep:204, loss:0.00000, loss_test:0.04757, lr:2.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.242, tt:7429.673\n",
      "Ep:205, loss:0.00000, loss_test:0.04762, lr:2.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.238, tt:7465.086\n",
      "Ep:206, loss:0.00000, loss_test:0.04794, lr:2.21e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.239, tt:7501.403\n",
      "Ep:207, loss:0.00000, loss_test:0.04798, lr:2.19e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.240, tt:7537.854\n",
      "Ep:208, loss:0.00000, loss_test:0.04778, lr:2.17e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.237, tt:7573.562\n",
      "Ep:209, loss:0.00000, loss_test:0.04793, lr:2.15e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.239, tt:7610.274\n",
      "Ep:210, loss:0.00000, loss_test:0.04705, lr:2.13e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.210, tt:7640.249\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02283, lr:6.00e-02, fs:0.70130 (r=0.818,p=0.614),  time:27.689, tt:27.689\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00005, loss_test:0.02411, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:28.461, tt:56.922\n",
      "Ep:2, loss:0.00005, loss_test:0.02628, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.873, tt:86.619\n",
      "Ep:3, loss:0.00005, loss_test:0.02537, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:29.909, tt:119.635\n",
      "Ep:4, loss:0.00005, loss_test:0.02493, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:30.996, tt:154.979\n",
      "Ep:5, loss:0.00005, loss_test:0.02430, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:31.669, tt:190.012\n",
      "Ep:6, loss:0.00005, loss_test:0.02380, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:32.004, tt:224.026\n",
      "Ep:7, loss:0.00005, loss_test:0.02354, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:32.367, tt:258.934\n",
      "Ep:8, loss:0.00005, loss_test:0.02331, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:32.631, tt:293.683\n",
      "Ep:9, loss:0.00005, loss_test:0.02310, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:32.984, tt:329.836\n",
      "Ep:10, loss:0.00005, loss_test:0.02291, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:33.164, tt:364.799\n",
      "Ep:11, loss:0.00005, loss_test:0.02271, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:33.300, tt:399.603\n",
      "Ep:12, loss:0.00005, loss_test:0.02241, lr:5.94e-02, fs:0.66418 (r=0.899,p=0.527),  time:33.409, tt:434.313\n",
      "Ep:13, loss:0.00005, loss_test:0.02183, lr:5.88e-02, fs:0.66418 (r=0.899,p=0.527),  time:33.426, tt:467.958\n",
      "Ep:14, loss:0.00005, loss_test:0.02121, lr:5.82e-02, fs:0.67170 (r=0.899,p=0.536),  time:33.547, tt:503.206\n",
      "Ep:15, loss:0.00005, loss_test:0.02062, lr:5.76e-02, fs:0.67170 (r=0.899,p=0.536),  time:33.711, tt:539.378\n",
      "Ep:16, loss:0.00005, loss_test:0.02010, lr:5.71e-02, fs:0.67170 (r=0.899,p=0.536),  time:33.768, tt:574.050\n",
      "Ep:17, loss:0.00005, loss_test:0.01959, lr:5.65e-02, fs:0.67424 (r=0.899,p=0.539),  time:33.856, tt:609.401\n",
      "Ep:18, loss:0.00005, loss_test:0.01912, lr:5.59e-02, fs:0.67176 (r=0.889,p=0.540),  time:33.877, tt:643.669\n",
      "Ep:19, loss:0.00004, loss_test:0.01867, lr:5.54e-02, fs:0.68182 (r=0.909,p=0.545),  time:33.969, tt:679.377\n",
      "Ep:20, loss:0.00004, loss_test:0.01824, lr:5.48e-02, fs:0.69498 (r=0.909,p=0.562),  time:34.007, tt:714.137\n",
      "Ep:21, loss:0.00004, loss_test:0.01792, lr:5.43e-02, fs:0.69231 (r=0.909,p=0.559),  time:33.995, tt:747.888\n",
      "Ep:22, loss:0.00004, loss_test:0.01770, lr:5.37e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.015, tt:782.338\n",
      "Ep:23, loss:0.00004, loss_test:0.01761, lr:5.32e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.074, tt:817.774\n",
      "Ep:24, loss:0.00004, loss_test:0.01749, lr:5.27e-02, fs:0.68726 (r=0.899,p=0.556),  time:34.214, tt:855.356\n",
      "Ep:25, loss:0.00004, loss_test:0.01724, lr:5.21e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.274, tt:891.132\n",
      "Ep:26, loss:0.00004, loss_test:0.01692, lr:5.16e-02, fs:0.70312 (r=0.909,p=0.573),  time:34.306, tt:926.252\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01660, lr:5.16e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.306, tt:960.578\n",
      "Ep:28, loss:0.00004, loss_test:0.01627, lr:5.16e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.354, tt:996.279\n",
      "Ep:29, loss:0.00004, loss_test:0.01606, lr:5.16e-02, fs:0.70817 (r=0.919,p=0.576),  time:34.377, tt:1031.309\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.01589, lr:5.16e-02, fs:0.70817 (r=0.919,p=0.576),  time:34.407, tt:1066.612\n",
      "Ep:31, loss:0.00003, loss_test:0.01561, lr:5.16e-02, fs:0.71373 (r=0.919,p=0.583),  time:34.420, tt:1101.436\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01548, lr:5.16e-02, fs:0.71654 (r=0.919,p=0.587),  time:34.430, tt:1136.189\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01538, lr:5.16e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.457, tt:1171.533\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01537, lr:5.16e-02, fs:0.73930 (r=0.960,p=0.601),  time:34.529, tt:1208.498\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01531, lr:5.16e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.533, tt:1243.199\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01530, lr:5.16e-02, fs:0.74104 (r=0.939,p=0.612),  time:34.504, tt:1276.643\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01534, lr:5.16e-02, fs:0.74803 (r=0.960,p=0.613),  time:34.514, tt:1311.515\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01544, lr:5.16e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.509, tt:1345.864\n",
      "Ep:39, loss:0.00003, loss_test:0.01545, lr:5.16e-02, fs:0.75102 (r=0.929,p=0.630),  time:34.636, tt:1385.457\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01552, lr:5.16e-02, fs:0.73984 (r=0.919,p=0.619),  time:34.654, tt:1420.807\n",
      "Ep:41, loss:0.00003, loss_test:0.01546, lr:5.16e-02, fs:0.72574 (r=0.869,p=0.623),  time:34.658, tt:1455.616\n",
      "Ep:42, loss:0.00003, loss_test:0.01541, lr:5.16e-02, fs:0.72961 (r=0.859,p=0.634),  time:34.651, tt:1489.983\n",
      "Ep:43, loss:0.00003, loss_test:0.01535, lr:5.16e-02, fs:0.73913 (r=0.859,p=0.649),  time:34.637, tt:1524.007\n",
      "Ep:44, loss:0.00003, loss_test:0.01528, lr:5.16e-02, fs:0.73913 (r=0.859,p=0.649),  time:34.639, tt:1558.755\n",
      "Ep:45, loss:0.00002, loss_test:0.01529, lr:5.16e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.652, tt:1594.000\n",
      "Ep:46, loss:0.00002, loss_test:0.01528, lr:5.16e-02, fs:0.73874 (r=0.828,p=0.667),  time:34.657, tt:1628.898\n",
      "Ep:47, loss:0.00002, loss_test:0.01539, lr:5.16e-02, fs:0.74208 (r=0.828,p=0.672),  time:34.663, tt:1663.832\n",
      "Ep:48, loss:0.00002, loss_test:0.01555, lr:5.16e-02, fs:0.72727 (r=0.808,p=0.661),  time:34.693, tt:1699.948\n",
      "Ep:49, loss:0.00002, loss_test:0.01563, lr:5.16e-02, fs:0.73148 (r=0.798,p=0.675),  time:34.692, tt:1734.595\n",
      "Ep:50, loss:0.00002, loss_test:0.01557, lr:5.16e-02, fs:0.74178 (r=0.798,p=0.693),  time:34.688, tt:1769.068\n",
      "Ep:51, loss:0.00002, loss_test:0.01560, lr:5.11e-02, fs:0.74528 (r=0.798,p=0.699),  time:34.712, tt:1805.035\n",
      "Ep:52, loss:0.00002, loss_test:0.01585, lr:5.06e-02, fs:0.73488 (r=0.798,p=0.681),  time:34.736, tt:1841.033\n",
      "Ep:53, loss:0.00002, loss_test:0.01619, lr:5.01e-02, fs:0.73585 (r=0.788,p=0.690),  time:34.721, tt:1874.917\n",
      "Ep:54, loss:0.00002, loss_test:0.01606, lr:4.96e-02, fs:0.75000 (r=0.788,p=0.716),  time:34.732, tt:1910.280\n",
      "Ep:55, loss:0.00002, loss_test:0.01731, lr:4.91e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.726, tt:1944.668\n",
      "Ep:56, loss:0.00002, loss_test:0.01628, lr:4.86e-02, fs:0.74757 (r=0.778,p=0.720),  time:34.731, tt:1979.686\n",
      "Ep:57, loss:0.00002, loss_test:0.01758, lr:4.81e-02, fs:0.72321 (r=0.818,p=0.648),  time:34.721, tt:2013.813\n",
      "Ep:58, loss:0.00002, loss_test:0.01630, lr:4.76e-02, fs:0.75728 (r=0.788,p=0.729),  time:34.751, tt:2050.319\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01751, lr:4.76e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.769, tt:2086.150\n",
      "Ep:60, loss:0.00002, loss_test:0.01703, lr:4.76e-02, fs:0.74882 (r=0.798,p=0.705),  time:34.767, tt:2120.761\n",
      "Ep:61, loss:0.00002, loss_test:0.01693, lr:4.76e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.753, tt:2154.706\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01810, lr:4.76e-02, fs:0.75598 (r=0.798,p=0.718),  time:34.758, tt:2189.740\n",
      "Ep:63, loss:0.00002, loss_test:0.01704, lr:4.76e-02, fs:0.76847 (r=0.788,p=0.750),  time:34.777, tt:2225.722\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.01787, lr:4.76e-02, fs:0.75472 (r=0.808,p=0.708),  time:34.781, tt:2260.765\n",
      "Ep:65, loss:0.00001, loss_test:0.01770, lr:4.76e-02, fs:0.77228 (r=0.788,p=0.757),  time:34.773, tt:2295.004\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01744, lr:4.76e-02, fs:0.77228 (r=0.788,p=0.757),  time:34.782, tt:2330.379\n",
      "Ep:67, loss:0.00001, loss_test:0.01862, lr:4.76e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.770, tt:2364.383\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01841, lr:4.76e-02, fs:0.76923 (r=0.758,p=0.781),  time:34.756, tt:2398.198\n",
      "Ep:69, loss:0.00001, loss_test:0.01787, lr:4.76e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.748, tt:2432.372\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01830, lr:4.76e-02, fs:0.77157 (r=0.768,p=0.776),  time:34.751, tt:2467.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.01860, lr:4.76e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.746, tt:2501.684\n",
      "Ep:72, loss:0.00001, loss_test:0.01821, lr:4.76e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.733, tt:2535.525\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01877, lr:4.76e-02, fs:0.77320 (r=0.758,p=0.789),  time:34.716, tt:2568.998\n",
      "Ep:74, loss:0.00001, loss_test:0.01930, lr:4.76e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.717, tt:2603.752\n",
      "Ep:75, loss:0.00001, loss_test:0.02049, lr:4.76e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.710, tt:2637.992\n",
      "Ep:76, loss:0.00001, loss_test:0.01935, lr:4.76e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.705, tt:2672.300\n",
      "Ep:77, loss:0.00001, loss_test:0.01824, lr:4.76e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.697, tt:2706.389\n",
      "Ep:78, loss:0.00001, loss_test:0.02079, lr:4.76e-02, fs:0.77387 (r=0.778,p=0.770),  time:34.694, tt:2740.791\n",
      "Ep:79, loss:0.00001, loss_test:0.01973, lr:4.76e-02, fs:0.77157 (r=0.768,p=0.776),  time:34.703, tt:2776.212\n",
      "Ep:80, loss:0.00001, loss_test:0.01857, lr:4.76e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.697, tt:2810.496\n",
      "Ep:81, loss:0.00001, loss_test:0.02071, lr:4.76e-02, fs:0.78049 (r=0.808,p=0.755),  time:34.712, tt:2846.400\n",
      "Ep:82, loss:0.00001, loss_test:0.01936, lr:4.76e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.722, tt:2881.922\n",
      "Ep:83, loss:0.00001, loss_test:0.01860, lr:4.76e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.726, tt:2917.000\n",
      "Ep:84, loss:0.00001, loss_test:0.02094, lr:4.71e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.713, tt:2950.645\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01959, lr:4.71e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.719, tt:2985.821\n",
      "Ep:86, loss:0.00001, loss_test:0.02028, lr:4.71e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.736, tt:3022.069\n",
      "Ep:87, loss:0.00001, loss_test:0.02120, lr:4.71e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.704, tt:3053.952\n",
      "Ep:88, loss:0.00001, loss_test:0.02025, lr:4.71e-02, fs:0.79581 (r=0.768,p=0.826),  time:34.690, tt:3087.370\n",
      "Ep:89, loss:0.00001, loss_test:0.01944, lr:4.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:34.689, tt:3122.005\n",
      "Ep:90, loss:0.00001, loss_test:0.02047, lr:4.71e-02, fs:0.80412 (r=0.788,p=0.821),  time:34.696, tt:3157.379\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.02267, lr:4.71e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.704, tt:3192.733\n",
      "Ep:92, loss:0.00001, loss_test:0.02012, lr:4.71e-02, fs:0.79167 (r=0.768,p=0.817),  time:34.703, tt:3227.339\n",
      "Ep:93, loss:0.00001, loss_test:0.01994, lr:4.71e-02, fs:0.80000 (r=0.768,p=0.835),  time:34.699, tt:3261.722\n",
      "Ep:94, loss:0.00001, loss_test:0.02184, lr:4.71e-02, fs:0.80208 (r=0.778,p=0.828),  time:34.705, tt:3296.987\n",
      "Ep:95, loss:0.00001, loss_test:0.02248, lr:4.71e-02, fs:0.79793 (r=0.778,p=0.819),  time:34.702, tt:3331.430\n",
      "Ep:96, loss:0.00001, loss_test:0.02103, lr:4.71e-02, fs:0.80000 (r=0.768,p=0.835),  time:34.717, tt:3367.530\n",
      "Ep:97, loss:0.00001, loss_test:0.02110, lr:4.71e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.735, tt:3404.042\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.02193, lr:4.71e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.732, tt:3438.464\n",
      "Ep:99, loss:0.00001, loss_test:0.02369, lr:4.71e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.752, tt:3475.244\n",
      "Ep:100, loss:0.00001, loss_test:0.02285, lr:4.71e-02, fs:0.81053 (r=0.778,p=0.846),  time:34.756, tt:3510.372\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.02165, lr:4.71e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.765, tt:3546.042\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.02079, lr:4.71e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.770, tt:3581.349\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.02185, lr:4.71e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.770, tt:3616.078\n",
      "Ep:104, loss:0.00001, loss_test:0.02268, lr:4.71e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.777, tt:3651.534\n",
      "Ep:105, loss:0.00001, loss_test:0.02448, lr:4.71e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.784, tt:3687.071\n",
      "Ep:106, loss:0.00001, loss_test:0.02328, lr:4.71e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.794, tt:3722.938\n",
      "Ep:107, loss:0.00001, loss_test:0.02120, lr:4.71e-02, fs:0.81053 (r=0.778,p=0.846),  time:34.796, tt:3757.991\n",
      "Ep:108, loss:0.00001, loss_test:0.02040, lr:4.71e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.812, tt:3794.496\n",
      "Ep:109, loss:0.00001, loss_test:0.02332, lr:4.71e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.825, tt:3830.782\n",
      "Ep:110, loss:0.00001, loss_test:0.02202, lr:4.71e-02, fs:0.80208 (r=0.778,p=0.828),  time:34.837, tt:3866.950\n",
      "Ep:111, loss:0.00001, loss_test:0.02161, lr:4.71e-02, fs:0.81053 (r=0.778,p=0.846),  time:34.854, tt:3903.612\n",
      "Ep:112, loss:0.00000, loss_test:0.02404, lr:4.71e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.874, tt:3940.725\n",
      "Ep:113, loss:0.00001, loss_test:0.02409, lr:4.71e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.881, tt:3976.443\n",
      "Ep:114, loss:0.00000, loss_test:0.02248, lr:4.67e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.895, tt:4012.871\n",
      "Ep:115, loss:0.00000, loss_test:0.02383, lr:4.62e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.913, tt:4049.859\n",
      "Ep:116, loss:0.00000, loss_test:0.02495, lr:4.57e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.917, tt:4085.238\n",
      "Ep:117, loss:0.00000, loss_test:0.02424, lr:4.53e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.919, tt:4120.408\n",
      "Ep:118, loss:0.00000, loss_test:0.02424, lr:4.48e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.946, tt:4158.626\n",
      "Ep:119, loss:0.00000, loss_test:0.02420, lr:4.44e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.958, tt:4194.924\n",
      "Ep:120, loss:0.00000, loss_test:0.02445, lr:4.39e-02, fs:0.80214 (r=0.758,p=0.852),  time:34.967, tt:4231.036\n",
      "Ep:121, loss:0.00000, loss_test:0.02598, lr:4.35e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.974, tt:4266.877\n",
      "Ep:122, loss:0.00000, loss_test:0.02657, lr:4.31e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.985, tt:4303.196\n",
      "Ep:123, loss:0.00000, loss_test:0.02491, lr:4.26e-02, fs:0.80423 (r=0.768,p=0.844),  time:35.022, tt:4342.715\n",
      "Ep:124, loss:0.00000, loss_test:0.02374, lr:4.22e-02, fs:0.80851 (r=0.768,p=0.854),  time:35.031, tt:4378.869\n",
      "Ep:125, loss:0.00000, loss_test:0.02676, lr:4.18e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.043, tt:4415.401\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.02581, lr:4.18e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.039, tt:4449.999\n",
      "Ep:127, loss:0.00000, loss_test:0.02448, lr:4.18e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.055, tt:4486.987\n",
      "Ep:128, loss:0.00000, loss_test:0.02574, lr:4.18e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.068, tt:4523.834\n",
      "Ep:129, loss:0.00000, loss_test:0.02624, lr:4.18e-02, fs:0.80214 (r=0.758,p=0.852),  time:35.070, tt:4559.069\n",
      "Ep:130, loss:0.00000, loss_test:0.02505, lr:4.18e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.079, tt:4595.410\n",
      "Ep:131, loss:0.00000, loss_test:0.02554, lr:4.18e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.069, tt:4629.095\n",
      "Ep:132, loss:0.00000, loss_test:0.02751, lr:4.18e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.073, tt:4664.746\n",
      "Ep:133, loss:0.00000, loss_test:0.02731, lr:4.18e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.069, tt:4699.285\n",
      "Ep:134, loss:0.00000, loss_test:0.02635, lr:4.18e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.071, tt:4734.529\n",
      "Ep:135, loss:0.00000, loss_test:0.02517, lr:4.18e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.075, tt:4770.156\n",
      "Ep:136, loss:0.00000, loss_test:0.02684, lr:4.18e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.078, tt:4805.649\n",
      "Ep:137, loss:0.00000, loss_test:0.02831, lr:4.14e-02, fs:0.80851 (r=0.768,p=0.854),  time:35.087, tt:4842.047\n",
      "Ep:138, loss:0.00000, loss_test:0.02720, lr:4.10e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.106, tt:4879.704\n",
      "Ep:139, loss:0.00000, loss_test:0.02587, lr:4.05e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.118, tt:4916.468\n",
      "Ep:140, loss:0.00000, loss_test:0.02642, lr:4.01e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.131, tt:4953.459\n",
      "Ep:141, loss:0.00000, loss_test:0.02897, lr:3.97e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.144, tt:4990.455\n",
      "Ep:142, loss:0.00000, loss_test:0.02768, lr:3.93e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.163, tt:5028.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.02636, lr:3.89e-02, fs:0.80851 (r=0.768,p=0.854),  time:35.184, tt:5066.508\n",
      "Ep:144, loss:0.00000, loss_test:0.02754, lr:3.86e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.185, tt:5101.803\n",
      "Ep:145, loss:0.00000, loss_test:0.02877, lr:3.82e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.180, tt:5136.337\n",
      "Ep:146, loss:0.00000, loss_test:0.02756, lr:3.78e-02, fs:0.80851 (r=0.768,p=0.854),  time:35.188, tt:5172.594\n",
      "Ep:147, loss:0.00000, loss_test:0.02690, lr:3.74e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.190, tt:5208.062\n",
      "Ep:148, loss:0.00000, loss_test:0.02795, lr:3.70e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.194, tt:5243.862\n",
      "Ep:149, loss:0.00000, loss_test:0.02906, lr:3.67e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.196, tt:5279.436\n",
      "Ep:150, loss:0.00000, loss_test:0.02744, lr:3.63e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.195, tt:5314.438\n",
      "Ep:151, loss:0.00000, loss_test:0.02743, lr:3.59e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.202, tt:5350.679\n",
      "Ep:152, loss:0.00000, loss_test:0.02913, lr:3.56e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.197, tt:5385.139\n",
      "Ep:153, loss:0.00000, loss_test:0.02843, lr:3.52e-02, fs:0.79570 (r=0.747,p=0.851),  time:35.207, tt:5421.824\n",
      "Ep:154, loss:0.00000, loss_test:0.02881, lr:3.49e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.210, tt:5457.537\n",
      "Ep:155, loss:0.00000, loss_test:0.02891, lr:3.45e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.219, tt:5494.177\n",
      "Ep:156, loss:0.00000, loss_test:0.02947, lr:3.42e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.233, tt:5531.571\n",
      "Ep:157, loss:0.00000, loss_test:0.02926, lr:3.38e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.252, tt:5569.771\n",
      "Ep:158, loss:0.00000, loss_test:0.02862, lr:3.35e-02, fs:0.80214 (r=0.758,p=0.852),  time:35.257, tt:5605.790\n",
      "Ep:159, loss:0.00000, loss_test:0.03026, lr:3.32e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.271, tt:5643.283\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00000, loss_test:0.02940, lr:3.32e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.284, tt:5680.797\n",
      "Ep:161, loss:0.00000, loss_test:0.02857, lr:3.32e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.281, tt:5715.477\n",
      "Ep:162, loss:0.00000, loss_test:0.02954, lr:3.32e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.287, tt:5751.780\n",
      "Ep:163, loss:0.00000, loss_test:0.02991, lr:3.32e-02, fs:0.81081 (r=0.758,p=0.872),  time:35.291, tt:5787.803\n",
      "Ep:164, loss:0.00000, loss_test:0.02965, lr:3.32e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.301, tt:5824.671\n",
      "Ep:165, loss:0.00000, loss_test:0.02901, lr:3.32e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.307, tt:5861.033\n",
      "Ep:166, loss:0.00000, loss_test:0.03110, lr:3.32e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.313, tt:5897.337\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00000, loss_test:0.03054, lr:3.32e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.325, tt:5934.683\n",
      "Ep:168, loss:0.00000, loss_test:0.02785, lr:3.32e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.326, tt:5970.173\n",
      "Ep:169, loss:0.00000, loss_test:0.03033, lr:3.32e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.334, tt:6006.709\n",
      "Ep:170, loss:0.00000, loss_test:0.03116, lr:3.32e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.344, tt:6043.824\n",
      "Ep:171, loss:0.00000, loss_test:0.03021, lr:3.32e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.354, tt:6080.823\n",
      "Ep:172, loss:0.00000, loss_test:0.03033, lr:3.32e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.356, tt:6116.587\n",
      "Ep:173, loss:0.00000, loss_test:0.03144, lr:3.32e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.366, tt:6153.662\n",
      "Ep:174, loss:0.00000, loss_test:0.03160, lr:3.32e-02, fs:0.81319 (r=0.747,p=0.892),  time:35.377, tt:6190.939\n",
      "Ep:175, loss:0.00000, loss_test:0.03036, lr:3.32e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.388, tt:6228.311\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00000, loss_test:0.03000, lr:3.32e-02, fs:0.81319 (r=0.747,p=0.892),  time:35.384, tt:6262.945\n",
      "Ep:177, loss:0.00000, loss_test:0.03095, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.393, tt:6300.015\n",
      "Ep:178, loss:0.00000, loss_test:0.03194, lr:3.32e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.391, tt:6334.927\n",
      "Ep:179, loss:0.00000, loss_test:0.03201, lr:3.32e-02, fs:0.73684 (r=0.636,p=0.875),  time:35.386, tt:6369.515\n",
      "Ep:180, loss:0.00000, loss_test:0.03101, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.383, tt:6404.342\n",
      "Ep:181, loss:0.00000, loss_test:0.03172, lr:3.32e-02, fs:0.81356 (r=0.727,p=0.923),  time:35.380, tt:6439.180\n",
      "Ep:182, loss:0.00000, loss_test:0.03182, lr:3.32e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.377, tt:6473.979\n",
      "Ep:183, loss:0.00000, loss_test:0.03243, lr:3.32e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.380, tt:6509.925\n",
      "Ep:184, loss:0.00000, loss_test:0.03200, lr:3.32e-02, fs:0.74118 (r=0.636,p=0.887),  time:35.387, tt:6546.568\n",
      "Ep:185, loss:0.00000, loss_test:0.03174, lr:3.32e-02, fs:0.79545 (r=0.707,p=0.909),  time:35.387, tt:6581.936\n",
      "Ep:186, loss:0.00000, loss_test:0.03177, lr:3.32e-02, fs:0.80226 (r=0.717,p=0.910),  time:35.390, tt:6617.921\n",
      "Ep:187, loss:0.00000, loss_test:0.03186, lr:3.28e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.392, tt:6653.610\n",
      "Ep:188, loss:0.00000, loss_test:0.03307, lr:3.25e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.394, tt:6689.522\n",
      "Ep:189, loss:0.00000, loss_test:0.03253, lr:3.22e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.393, tt:6724.630\n",
      "Ep:190, loss:0.00000, loss_test:0.03229, lr:3.19e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.391, tt:6759.680\n",
      "Ep:191, loss:0.00000, loss_test:0.03228, lr:3.15e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.383, tt:6793.556\n",
      "Ep:192, loss:0.00000, loss_test:0.03172, lr:3.12e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.379, tt:6828.136\n",
      "Ep:193, loss:0.00000, loss_test:0.03168, lr:3.09e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.371, tt:6861.957\n",
      "Ep:194, loss:0.00000, loss_test:0.03171, lr:3.06e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.374, tt:6897.923\n",
      "Ep:195, loss:0.00000, loss_test:0.03338, lr:3.03e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.372, tt:6933.004\n",
      "Ep:196, loss:0.00000, loss_test:0.03333, lr:3.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:35.373, tt:6968.392\n",
      "Ep:197, loss:0.00000, loss_test:0.03177, lr:2.97e-02, fs:0.79545 (r=0.707,p=0.909),  time:35.372, tt:7003.707\n",
      "Ep:198, loss:0.00000, loss_test:0.03318, lr:2.94e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.371, tt:7038.828\n",
      "Ep:199, loss:0.00000, loss_test:0.03320, lr:2.91e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.374, tt:7074.716\n",
      "Ep:200, loss:0.00000, loss_test:0.03242, lr:2.88e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.374, tt:7110.109\n",
      "Ep:201, loss:0.00000, loss_test:0.03334, lr:2.85e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.381, tt:7146.900\n",
      "Ep:202, loss:0.00000, loss_test:0.03416, lr:2.82e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.385, tt:7183.150\n",
      "Ep:203, loss:0.00000, loss_test:0.03224, lr:2.80e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.389, tt:7219.304\n",
      "Ep:204, loss:0.00000, loss_test:0.03288, lr:2.77e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.389, tt:7254.711\n",
      "Ep:205, loss:0.00000, loss_test:0.03387, lr:2.74e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.380, tt:7288.307\n",
      "Ep:206, loss:0.00000, loss_test:0.03302, lr:2.71e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.377, tt:7323.008\n",
      "Ep:207, loss:0.00000, loss_test:0.03267, lr:2.69e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.376, tt:7358.132\n",
      "Ep:208, loss:0.00000, loss_test:0.03382, lr:2.66e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.374, tt:7393.129\n",
      "Ep:209, loss:0.00000, loss_test:0.03371, lr:2.63e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.363, tt:7426.288\n",
      "Ep:210, loss:0.00000, loss_test:0.03236, lr:2.61e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.360, tt:7461.017\n",
      "Ep:211, loss:0.00000, loss_test:0.03412, lr:2.58e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.331, tt:7490.201\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00027, loss_test:0.11522, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:31.416, tt:31.416\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.11555, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:30.512, tt:61.024\n",
      "Ep:2, loss:0.00027, loss_test:0.11592, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:29.836, tt:89.509\n",
      "Ep:3, loss:0.00026, loss_test:0.11598, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:30.485, tt:121.942\n",
      "Ep:4, loss:0.00026, loss_test:0.11569, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:30.905, tt:154.526\n",
      "Ep:5, loss:0.00026, loss_test:0.11495, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:31.699, tt:190.193\n",
      "Ep:6, loss:0.00026, loss_test:0.11391, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:32.220, tt:225.541\n",
      "Ep:7, loss:0.00026, loss_test:0.11294, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:32.578, tt:260.625\n",
      "Ep:8, loss:0.00026, loss_test:0.11229, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:32.847, tt:295.623\n",
      "Ep:9, loss:0.00026, loss_test:0.11196, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:33.192, tt:331.919\n",
      "Ep:10, loss:0.00025, loss_test:0.11128, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:33.441, tt:367.854\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.11047, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:33.623, tt:403.479\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.10918, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:33.676, tt:437.794\n",
      "Ep:13, loss:0.00025, loss_test:0.10795, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:33.823, tt:473.522\n",
      "Ep:14, loss:0.00025, loss_test:0.10735, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:33.928, tt:508.928\n",
      "Ep:15, loss:0.00025, loss_test:0.10691, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:34.068, tt:545.086\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.10625, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:34.212, tt:581.598\n",
      "Ep:17, loss:0.00024, loss_test:0.10545, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:34.296, tt:617.323\n",
      "Ep:18, loss:0.00024, loss_test:0.10456, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:34.386, tt:653.333\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.10384, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:34.466, tt:689.329\n",
      "Ep:20, loss:0.00023, loss_test:0.10344, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:34.597, tt:726.546\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.10207, lr:1.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:34.672, tt:762.774\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.10222, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:34.793, tt:800.231\n",
      "Ep:23, loss:0.00023, loss_test:0.10007, lr:1.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:34.865, tt:836.755\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00022, loss_test:0.09937, lr:1.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:34.929, tt:873.219\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00022, loss_test:0.09897, lr:1.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:34.975, tt:909.361\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00022, loss_test:0.09678, lr:1.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:35.041, tt:946.118\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00022, loss_test:0.09680, lr:1.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:35.117, tt:983.280\n",
      "Ep:28, loss:0.00021, loss_test:0.09582, lr:1.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:35.158, tt:1019.595\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00021, loss_test:0.09386, lr:1.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:35.193, tt:1055.801\n",
      "Ep:30, loss:0.00021, loss_test:0.09660, lr:1.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:35.239, tt:1092.397\n",
      "Ep:31, loss:0.00020, loss_test:0.09156, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:35.241, tt:1127.699\n",
      "Ep:32, loss:0.00020, loss_test:0.09135, lr:1.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:35.301, tt:1164.923\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00020, loss_test:0.09195, lr:1.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:35.321, tt:1200.926\n",
      "Ep:34, loss:0.00019, loss_test:0.08785, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:35.384, tt:1238.426\n",
      "Ep:35, loss:0.00019, loss_test:0.10324, lr:1.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:35.425, tt:1275.283\n",
      "Ep:36, loss:0.00019, loss_test:0.08564, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:35.445, tt:1311.460\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00019, loss_test:0.09379, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:35.502, tt:1349.084\n",
      "Ep:38, loss:0.00018, loss_test:0.08284, lr:1.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:35.523, tt:1385.416\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00017, loss_test:0.08466, lr:1.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:35.549, tt:1421.958\n",
      "Ep:40, loss:0.00018, loss_test:0.10609, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.557, tt:1457.822\n",
      "Ep:41, loss:0.00018, loss_test:0.07928, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:35.584, tt:1494.511\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00018, loss_test:0.08396, lr:1.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:35.598, tt:1530.704\n",
      "Ep:43, loss:0.00017, loss_test:0.09854, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:35.629, tt:1567.696\n",
      "Ep:44, loss:0.00016, loss_test:0.08091, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:35.656, tt:1604.536\n",
      "Ep:45, loss:0.00015, loss_test:0.09224, lr:1.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:35.668, tt:1640.747\n",
      "Ep:46, loss:0.00015, loss_test:0.07857, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:35.704, tt:1678.110\n",
      "Ep:47, loss:0.00014, loss_test:0.08790, lr:1.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:35.762, tt:1716.574\n",
      "Ep:48, loss:0.00014, loss_test:0.08133, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:35.774, tt:1752.914\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00013, loss_test:0.08697, lr:1.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:35.781, tt:1789.049\n",
      "Ep:50, loss:0.00013, loss_test:0.07823, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.797, tt:1825.636\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00012, loss_test:0.08040, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:35.801, tt:1861.630\n",
      "Ep:52, loss:0.00011, loss_test:0.07847, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:35.806, tt:1897.733\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00011, loss_test:0.07950, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:35.812, tt:1933.842\n",
      "Ep:54, loss:0.00011, loss_test:0.07037, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.811, tt:1969.597\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00010, loss_test:0.07494, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:35.823, tt:2006.098\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00010, loss_test:0.07657, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:35.838, tt:2042.764\n",
      "Ep:57, loss:0.00009, loss_test:0.07706, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.838, tt:2078.583\n",
      "Ep:58, loss:0.00009, loss_test:0.07744, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:35.823, tt:2113.575\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00009, loss_test:0.07025, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:35.815, tt:2148.888\n",
      "Ep:60, loss:0.00009, loss_test:0.08676, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:35.830, tt:2185.656\n",
      "Ep:61, loss:0.00009, loss_test:0.07761, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:35.830, tt:2221.464\n",
      "Ep:62, loss:0.00009, loss_test:0.08022, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:35.846, tt:2258.328\n",
      "Ep:63, loss:0.00009, loss_test:0.08445, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:35.870, tt:2295.665\n",
      "Ep:64, loss:0.00009, loss_test:0.07751, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.892, tt:2332.953\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00008, loss_test:0.07492, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:35.879, tt:2368.043\n",
      "Ep:66, loss:0.00008, loss_test:0.07675, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.888, tt:2404.470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00007, loss_test:0.07028, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:35.916, tt:2442.306\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.07048, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.930, tt:2479.161\n",
      "Ep:69, loss:0.00006, loss_test:0.06937, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.949, tt:2516.455\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.07220, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.947, tt:2552.213\n",
      "Ep:71, loss:0.00005, loss_test:0.07010, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:35.950, tt:2588.387\n",
      "Ep:72, loss:0.00006, loss_test:0.07603, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.958, tt:2624.961\n",
      "Ep:73, loss:0.00005, loss_test:0.06899, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.953, tt:2660.541\n",
      "Ep:74, loss:0.00005, loss_test:0.06762, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.950, tt:2696.230\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.07140, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.947, tt:2731.946\n",
      "Ep:76, loss:0.00005, loss_test:0.06883, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.989, tt:2771.171\n",
      "Ep:77, loss:0.00005, loss_test:0.06769, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.992, tt:2807.363\n",
      "Ep:78, loss:0.00004, loss_test:0.06956, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:36.002, tt:2844.148\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.06949, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:36.011, tt:2880.878\n",
      "Ep:80, loss:0.00004, loss_test:0.06969, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:36.007, tt:2916.586\n",
      "Ep:81, loss:0.00003, loss_test:0.06842, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.018, tt:2953.470\n",
      "Ep:82, loss:0.00003, loss_test:0.06748, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:36.016, tt:2989.346\n",
      "Ep:83, loss:0.00003, loss_test:0.06488, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:36.021, tt:3025.758\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00003, loss_test:0.06980, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:36.021, tt:3061.750\n",
      "Ep:85, loss:0.00003, loss_test:0.06519, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:36.024, tt:3098.049\n",
      "Ep:86, loss:0.00003, loss_test:0.06518, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:36.035, tt:3135.085\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00003, loss_test:0.07013, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:36.047, tt:3172.159\n",
      "Ep:88, loss:0.00003, loss_test:0.06305, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:36.052, tt:3208.635\n",
      "Ep:89, loss:0.00003, loss_test:0.06816, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:36.063, tt:3245.686\n",
      "Ep:90, loss:0.00003, loss_test:0.06688, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:36.048, tt:3280.334\n",
      "Ep:91, loss:0.00003, loss_test:0.06427, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.037, tt:3315.403\n",
      "Ep:92, loss:0.00003, loss_test:0.06599, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:36.020, tt:3349.901\n",
      "Ep:93, loss:0.00002, loss_test:0.06316, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.004, tt:3384.344\n",
      "Ep:94, loss:0.00002, loss_test:0.06700, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:36.005, tt:3420.495\n",
      "Ep:95, loss:0.00002, loss_test:0.06461, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.024, tt:3458.303\n",
      "Ep:96, loss:0.00003, loss_test:0.06972, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.029, tt:3494.820\n",
      "Ep:97, loss:0.00003, loss_test:0.06661, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:36.023, tt:3530.275\n",
      "Ep:98, loss:0.00004, loss_test:0.07841, lr:9.90e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.028, tt:3566.799\n",
      "Ep:99, loss:0.00003, loss_test:0.06097, lr:9.80e-03, fs:0.84492 (r=0.798,p=0.898),  time:36.041, tt:3604.073\n",
      "Ep:100, loss:0.00003, loss_test:0.08358, lr:9.70e-03, fs:0.84492 (r=0.798,p=0.898),  time:36.044, tt:3640.440\n",
      "Ep:101, loss:0.00003, loss_test:0.06481, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:36.039, tt:3675.941\n",
      "Ep:102, loss:0.00003, loss_test:0.06663, lr:9.51e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.037, tt:3711.764\n",
      "Ep:103, loss:0.00003, loss_test:0.07276, lr:9.41e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.035, tt:3747.620\n",
      "Ep:104, loss:0.00003, loss_test:0.07089, lr:9.32e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.049, tt:3785.169\n",
      "Ep:105, loss:0.00002, loss_test:0.06475, lr:9.23e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.063, tt:3822.729\n",
      "Ep:106, loss:0.00002, loss_test:0.07685, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.075, tt:3860.032\n",
      "Ep:107, loss:0.00002, loss_test:0.06601, lr:9.04e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.083, tt:3896.947\n",
      "Ep:108, loss:0.00002, loss_test:0.06931, lr:8.95e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.080, tt:3932.764\n",
      "Ep:109, loss:0.00002, loss_test:0.07470, lr:8.86e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.070, tt:3967.715\n",
      "Ep:110, loss:0.00002, loss_test:0.07156, lr:8.78e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.063, tt:4003.040\n",
      "Ep:111, loss:0.00002, loss_test:0.07247, lr:8.69e-03, fs:0.84946 (r=0.798,p=0.908),  time:36.064, tt:4039.190\n",
      "Ep:112, loss:0.00002, loss_test:0.07381, lr:8.60e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.070, tt:4075.860\n",
      "Ep:113, loss:0.00001, loss_test:0.07445, lr:8.51e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.077, tt:4112.829\n",
      "Ep:114, loss:0.00001, loss_test:0.07631, lr:8.43e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.074, tt:4148.533\n",
      "Ep:115, loss:0.00001, loss_test:0.07381, lr:8.35e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.095, tt:4187.055\n",
      "Ep:116, loss:0.00001, loss_test:0.07329, lr:8.26e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.087, tt:4222.141\n",
      "Ep:117, loss:0.00001, loss_test:0.07804, lr:8.18e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.077, tt:4257.101\n",
      "Ep:118, loss:0.00001, loss_test:0.07350, lr:8.10e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.082, tt:4293.774\n",
      "Ep:119, loss:0.00001, loss_test:0.07412, lr:8.02e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.086, tt:4330.322\n",
      "Ep:120, loss:0.00001, loss_test:0.07528, lr:7.94e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.096, tt:4367.610\n",
      "Ep:121, loss:0.00001, loss_test:0.07434, lr:7.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.105, tt:4404.862\n",
      "Ep:122, loss:0.00001, loss_test:0.07514, lr:7.78e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.110, tt:4441.529\n",
      "Ep:123, loss:0.00001, loss_test:0.07824, lr:7.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.112, tt:4477.927\n",
      "Ep:124, loss:0.00001, loss_test:0.07923, lr:7.62e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.108, tt:4513.446\n",
      "Ep:125, loss:0.00001, loss_test:0.07532, lr:7.55e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.097, tt:4548.214\n",
      "Ep:126, loss:0.00001, loss_test:0.07844, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.093, tt:4583.873\n",
      "Ep:127, loss:0.00001, loss_test:0.07786, lr:7.40e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.096, tt:4620.262\n",
      "Ep:128, loss:0.00001, loss_test:0.07694, lr:7.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.095, tt:4656.275\n",
      "Ep:129, loss:0.00001, loss_test:0.07898, lr:7.25e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.089, tt:4691.558\n",
      "Ep:130, loss:0.00001, loss_test:0.07531, lr:7.18e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.081, tt:4726.633\n",
      "Ep:131, loss:0.00001, loss_test:0.07959, lr:7.11e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.090, tt:4763.947\n",
      "Ep:132, loss:0.00001, loss_test:0.07444, lr:7.03e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.079, tt:4798.514\n",
      "Ep:133, loss:0.00001, loss_test:0.08011, lr:6.96e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.085, tt:4835.365\n",
      "Ep:134, loss:0.00001, loss_test:0.07666, lr:6.89e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.091, tt:4872.298\n",
      "Ep:135, loss:0.00001, loss_test:0.08004, lr:6.83e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.095, tt:4908.878\n",
      "Ep:136, loss:0.00001, loss_test:0.07669, lr:6.76e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.101, tt:4945.869\n",
      "Ep:137, loss:0.00001, loss_test:0.07956, lr:6.69e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.100, tt:4981.779\n",
      "Ep:138, loss:0.00001, loss_test:0.07592, lr:6.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.094, tt:5017.107\n",
      "Ep:139, loss:0.00001, loss_test:0.08042, lr:6.56e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.102, tt:5054.217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.07744, lr:6.49e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.107, tt:5091.042\n",
      "Ep:141, loss:0.00001, loss_test:0.07994, lr:6.43e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.091, tt:5124.860\n",
      "Ep:142, loss:0.00001, loss_test:0.07857, lr:6.36e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.095, tt:5161.648\n",
      "Ep:143, loss:0.00001, loss_test:0.07853, lr:6.30e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.099, tt:5198.196\n",
      "Ep:144, loss:0.00001, loss_test:0.07849, lr:6.24e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.096, tt:5233.959\n",
      "Ep:145, loss:0.00000, loss_test:0.07791, lr:6.17e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.091, tt:5269.241\n",
      "Ep:146, loss:0.00000, loss_test:0.07721, lr:6.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.089, tt:5305.063\n",
      "Ep:147, loss:0.00000, loss_test:0.08179, lr:6.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.092, tt:5341.558\n",
      "Ep:148, loss:0.00000, loss_test:0.07774, lr:5.99e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.093, tt:5377.928\n",
      "Ep:149, loss:0.00000, loss_test:0.08196, lr:5.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.083, tt:5412.471\n",
      "Ep:150, loss:0.00000, loss_test:0.07886, lr:5.87e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.080, tt:5448.103\n",
      "Ep:151, loss:0.00000, loss_test:0.07945, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.067, tt:5482.166\n",
      "Ep:152, loss:0.00000, loss_test:0.07818, lr:5.75e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.065, tt:5517.969\n",
      "Ep:153, loss:0.00000, loss_test:0.07951, lr:5.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.068, tt:5554.460\n",
      "Ep:154, loss:0.00000, loss_test:0.08047, lr:5.64e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.080, tt:5592.368\n",
      "Ep:155, loss:0.00000, loss_test:0.08008, lr:5.58e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.082, tt:5628.772\n",
      "Ep:156, loss:0.00000, loss_test:0.07812, lr:5.53e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.080, tt:5664.535\n",
      "Ep:157, loss:0.00000, loss_test:0.08026, lr:5.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.084, tt:5701.324\n",
      "Ep:158, loss:0.00000, loss_test:0.07923, lr:5.42e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.091, tt:5738.435\n",
      "Ep:159, loss:0.00000, loss_test:0.08020, lr:5.36e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.087, tt:5773.911\n",
      "Ep:160, loss:0.00000, loss_test:0.07874, lr:5.31e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.091, tt:5810.583\n",
      "Ep:161, loss:0.00000, loss_test:0.08104, lr:5.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.090, tt:5846.572\n",
      "Ep:162, loss:0.00000, loss_test:0.07915, lr:5.20e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.090, tt:5882.592\n",
      "Ep:163, loss:0.00000, loss_test:0.07905, lr:5.15e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.097, tt:5919.840\n",
      "Ep:164, loss:0.00000, loss_test:0.08060, lr:5.10e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.096, tt:5955.815\n",
      "Ep:165, loss:0.00000, loss_test:0.07857, lr:5.05e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.095, tt:5991.763\n",
      "Ep:166, loss:0.00000, loss_test:0.08027, lr:5.00e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.091, tt:6027.153\n",
      "Ep:167, loss:0.00000, loss_test:0.08009, lr:4.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.094, tt:6063.873\n",
      "Ep:168, loss:0.00000, loss_test:0.08007, lr:4.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.098, tt:6100.589\n",
      "Ep:169, loss:0.00000, loss_test:0.08019, lr:4.85e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.101, tt:6137.254\n",
      "Ep:170, loss:0.00000, loss_test:0.07992, lr:4.80e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.101, tt:6173.190\n",
      "Ep:171, loss:0.00000, loss_test:0.07999, lr:4.75e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.104, tt:6209.880\n",
      "Ep:172, loss:0.00000, loss_test:0.07926, lr:4.71e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.109, tt:6246.927\n",
      "Ep:173, loss:0.00000, loss_test:0.08008, lr:4.66e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.120, tt:6284.919\n",
      "Ep:174, loss:0.00000, loss_test:0.07903, lr:4.61e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.129, tt:6322.507\n",
      "Ep:175, loss:0.00000, loss_test:0.08031, lr:4.57e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.135, tt:6359.843\n",
      "Ep:176, loss:0.00000, loss_test:0.07977, lr:4.52e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.138, tt:6396.414\n",
      "Ep:177, loss:0.00000, loss_test:0.08041, lr:4.48e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.146, tt:6434.006\n",
      "Ep:178, loss:0.00000, loss_test:0.07903, lr:4.43e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.144, tt:6469.817\n",
      "Ep:179, loss:0.00000, loss_test:0.08045, lr:4.39e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.148, tt:6506.701\n",
      "Ep:180, loss:0.00000, loss_test:0.07977, lr:4.34e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.157, tt:6544.507\n",
      "Ep:181, loss:0.00000, loss_test:0.07965, lr:4.30e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.165, tt:6582.083\n",
      "Ep:182, loss:0.00000, loss_test:0.07992, lr:4.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.173, tt:6619.695\n",
      "Ep:183, loss:0.00000, loss_test:0.08009, lr:4.21e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.172, tt:6655.578\n",
      "Ep:184, loss:0.00000, loss_test:0.08123, lr:4.17e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.174, tt:6692.168\n",
      "Ep:185, loss:0.00000, loss_test:0.07913, lr:4.13e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.180, tt:6729.428\n",
      "Ep:186, loss:0.00000, loss_test:0.08196, lr:4.09e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.178, tt:6765.291\n",
      "Ep:187, loss:0.00000, loss_test:0.07991, lr:4.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.175, tt:6800.952\n",
      "Ep:188, loss:0.00000, loss_test:0.08150, lr:4.01e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.173, tt:6836.622\n",
      "Ep:189, loss:0.00000, loss_test:0.07944, lr:3.97e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.177, tt:6873.633\n",
      "Ep:190, loss:0.00000, loss_test:0.08081, lr:3.93e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.178, tt:6909.986\n",
      "Ep:191, loss:0.00000, loss_test:0.07951, lr:3.89e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.179, tt:6946.389\n",
      "Ep:192, loss:0.00000, loss_test:0.08166, lr:3.85e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.187, tt:6984.169\n",
      "Ep:193, loss:0.00000, loss_test:0.08038, lr:3.81e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.194, tt:7021.548\n",
      "Ep:194, loss:0.00000, loss_test:0.08096, lr:3.77e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.192, tt:7057.405\n",
      "Ep:195, loss:0.00000, loss_test:0.08113, lr:3.73e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.185, tt:7092.197\n",
      "Ep:196, loss:0.00000, loss_test:0.08068, lr:3.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.183, tt:7128.060\n",
      "Ep:197, loss:0.00000, loss_test:0.07947, lr:3.66e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.183, tt:7164.214\n",
      "Ep:198, loss:0.00000, loss_test:0.08029, lr:3.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.183, tt:7200.412\n",
      "Ep:199, loss:0.00000, loss_test:0.08061, lr:3.59e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.183, tt:7236.676\n",
      "Ep:200, loss:0.00000, loss_test:0.08005, lr:3.55e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.183, tt:7272.824\n",
      "Ep:201, loss:0.00000, loss_test:0.08090, lr:3.52e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.179, tt:7308.149\n",
      "Ep:202, loss:0.00000, loss_test:0.08031, lr:3.48e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.183, tt:7345.231\n",
      "Ep:203, loss:0.00000, loss_test:0.08089, lr:3.45e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.183, tt:7381.425\n",
      "Ep:204, loss:0.00000, loss_test:0.07942, lr:3.41e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.182, tt:7417.318\n",
      "Ep:205, loss:0.00000, loss_test:0.08279, lr:3.38e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.183, tt:7453.726\n",
      "Ep:206, loss:0.00000, loss_test:0.08119, lr:3.34e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.181, tt:7489.367\n",
      "Ep:207, loss:0.00000, loss_test:0.08168, lr:3.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.184, tt:7526.186\n",
      "Ep:208, loss:0.00000, loss_test:0.08068, lr:3.28e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.184, tt:7562.484\n",
      "Ep:209, loss:0.00000, loss_test:0.08062, lr:3.24e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.185, tt:7598.884\n",
      "Ep:210, loss:0.00000, loss_test:0.08024, lr:3.21e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.187, tt:7635.408\n",
      "Ep:211, loss:0.00000, loss_test:0.08186, lr:3.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.169, tt:7667.808\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02602, lr:6.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:26.975, tt:26.975\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02306, lr:6.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:26.067, tt:52.133\n",
      "Ep:2, loss:0.00005, loss_test:0.02536, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:26.399, tt:79.196\n",
      "Ep:3, loss:0.00005, loss_test:0.02461, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:27.516, tt:110.065\n",
      "Ep:4, loss:0.00005, loss_test:0.02312, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:28.606, tt:143.032\n",
      "Ep:5, loss:0.00005, loss_test:0.02251, lr:6.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:29.814, tt:178.887\n",
      "Ep:6, loss:0.00005, loss_test:0.02243, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:30.574, tt:214.018\n",
      "Ep:7, loss:0.00005, loss_test:0.02245, lr:6.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:31.095, tt:248.761\n",
      "Ep:8, loss:0.00005, loss_test:0.02249, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:31.628, tt:284.653\n",
      "Ep:9, loss:0.00005, loss_test:0.02257, lr:6.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:31.939, tt:319.385\n",
      "Ep:10, loss:0.00005, loss_test:0.02257, lr:6.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:32.185, tt:354.037\n",
      "Ep:11, loss:0.00005, loss_test:0.02225, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:32.457, tt:389.484\n",
      "Ep:12, loss:0.00005, loss_test:0.02161, lr:5.94e-02, fs:0.67416 (r=0.909,p=0.536),  time:32.661, tt:424.592\n",
      "Ep:13, loss:0.00005, loss_test:0.02096, lr:5.88e-02, fs:0.67170 (r=0.899,p=0.536),  time:32.818, tt:459.445\n",
      "Ep:14, loss:0.00005, loss_test:0.02043, lr:5.82e-02, fs:0.67681 (r=0.899,p=0.543),  time:32.902, tt:493.527\n",
      "Ep:15, loss:0.00005, loss_test:0.01999, lr:5.76e-02, fs:0.67939 (r=0.899,p=0.546),  time:32.987, tt:527.789\n",
      "Ep:16, loss:0.00005, loss_test:0.01960, lr:5.71e-02, fs:0.68441 (r=0.909,p=0.549),  time:33.089, tt:562.509\n",
      "Ep:17, loss:0.00005, loss_test:0.01919, lr:5.65e-02, fs:0.67954 (r=0.889,p=0.550),  time:33.195, tt:597.506\n",
      "Ep:18, loss:0.00004, loss_test:0.01873, lr:5.59e-02, fs:0.68726 (r=0.899,p=0.556),  time:33.272, tt:632.172\n",
      "Ep:19, loss:0.00004, loss_test:0.01828, lr:5.54e-02, fs:0.68992 (r=0.899,p=0.560),  time:33.307, tt:666.136\n",
      "Ep:20, loss:0.00004, loss_test:0.01797, lr:5.48e-02, fs:0.69048 (r=0.879,p=0.569),  time:33.395, tt:701.298\n",
      "Ep:21, loss:0.00004, loss_test:0.01777, lr:5.43e-02, fs:0.69636 (r=0.869,p=0.581),  time:33.538, tt:737.830\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01766, lr:5.43e-02, fs:0.69919 (r=0.869,p=0.585),  time:33.629, tt:773.468\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01755, lr:5.43e-02, fs:0.69919 (r=0.869,p=0.585),  time:33.678, tt:808.267\n",
      "Ep:24, loss:0.00004, loss_test:0.01739, lr:5.43e-02, fs:0.69919 (r=0.869,p=0.585),  time:33.742, tt:843.561\n",
      "Ep:25, loss:0.00004, loss_test:0.01720, lr:5.43e-02, fs:0.70445 (r=0.879,p=0.588),  time:33.772, tt:878.077\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01693, lr:5.43e-02, fs:0.71311 (r=0.879,p=0.600),  time:33.797, tt:912.528\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01663, lr:5.43e-02, fs:0.72131 (r=0.889,p=0.607),  time:33.852, tt:947.846\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01629, lr:5.43e-02, fs:0.72500 (r=0.879,p=0.617),  time:33.891, tt:982.840\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01595, lr:5.43e-02, fs:0.73950 (r=0.889,p=0.633),  time:33.953, tt:1018.580\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01560, lr:5.43e-02, fs:0.75630 (r=0.909,p=0.647),  time:34.013, tt:1054.412\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01528, lr:5.43e-02, fs:0.75105 (r=0.899,p=0.645),  time:34.029, tt:1088.939\n",
      "Ep:32, loss:0.00003, loss_test:0.01497, lr:5.43e-02, fs:0.75424 (r=0.899,p=0.650),  time:34.068, tt:1124.241\n",
      "Ep:33, loss:0.00003, loss_test:0.01463, lr:5.43e-02, fs:0.75630 (r=0.909,p=0.647),  time:34.139, tt:1160.720\n",
      "Ep:34, loss:0.00003, loss_test:0.01432, lr:5.43e-02, fs:0.75630 (r=0.909,p=0.647),  time:34.163, tt:1195.700\n",
      "Ep:35, loss:0.00003, loss_test:0.01408, lr:5.43e-02, fs:0.76271 (r=0.909,p=0.657),  time:34.150, tt:1229.392\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01383, lr:5.43e-02, fs:0.77778 (r=0.919,p=0.674),  time:34.189, tt:1265.009\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01360, lr:5.43e-02, fs:0.78603 (r=0.909,p=0.692),  time:34.236, tt:1300.952\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01343, lr:5.43e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.239, tt:1335.310\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01315, lr:5.43e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.264, tt:1370.549\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01293, lr:5.43e-02, fs:0.82819 (r=0.949,p=0.734),  time:34.289, tt:1405.862\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01265, lr:5.43e-02, fs:0.83843 (r=0.970,p=0.738),  time:34.277, tt:1439.616\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01244, lr:5.43e-02, fs:0.84071 (r=0.960,p=0.748),  time:34.302, tt:1474.967\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01230, lr:5.43e-02, fs:0.84444 (r=0.960,p=0.754),  time:34.328, tt:1510.447\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01211, lr:5.43e-02, fs:0.83784 (r=0.939,p=0.756),  time:34.361, tt:1546.249\n",
      "Ep:45, loss:0.00002, loss_test:0.01179, lr:5.43e-02, fs:0.82353 (r=0.919,p=0.746),  time:34.385, tt:1581.712\n",
      "Ep:46, loss:0.00002, loss_test:0.01166, lr:5.43e-02, fs:0.83636 (r=0.929,p=0.760),  time:34.390, tt:1616.315\n",
      "Ep:47, loss:0.00001, loss_test:0.01174, lr:5.43e-02, fs:0.82028 (r=0.899,p=0.754),  time:34.404, tt:1651.389\n",
      "Ep:48, loss:0.00001, loss_test:0.01160, lr:5.43e-02, fs:0.82791 (r=0.899,p=0.767),  time:34.429, tt:1687.021\n",
      "Ep:49, loss:0.00001, loss_test:0.01140, lr:5.43e-02, fs:0.84906 (r=0.909,p=0.796),  time:34.456, tt:1722.816\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01151, lr:5.43e-02, fs:0.85577 (r=0.899,p=0.817),  time:34.479, tt:1758.439\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01154, lr:5.43e-02, fs:0.86957 (r=0.909,p=0.833),  time:34.496, tt:1793.803\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01139, lr:5.43e-02, fs:0.85437 (r=0.889,p=0.822),  time:34.524, tt:1829.791\n",
      "Ep:53, loss:0.00001, loss_test:0.01163, lr:5.43e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.526, tt:1864.429\n",
      "Ep:54, loss:0.00001, loss_test:0.01127, lr:5.43e-02, fs:0.87255 (r=0.899,p=0.848),  time:34.526, tt:1898.919\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01161, lr:5.43e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.524, tt:1933.317\n",
      "Ep:56, loss:0.00001, loss_test:0.01119, lr:5.43e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.543, tt:1968.929\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01143, lr:5.43e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.554, tt:2004.124\n",
      "Ep:58, loss:0.00001, loss_test:0.01129, lr:5.43e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.561, tt:2039.076\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01156, lr:5.43e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.571, tt:2074.244\n",
      "Ep:60, loss:0.00001, loss_test:0.01142, lr:5.43e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.555, tt:2107.844\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01212, lr:5.43e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.546, tt:2141.858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01172, lr:5.43e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.585, tt:2178.877\n",
      "Ep:63, loss:0.00001, loss_test:0.01213, lr:5.43e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.590, tt:2213.733\n",
      "Ep:64, loss:0.00001, loss_test:0.01251, lr:5.43e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.595, tt:2248.669\n",
      "Ep:65, loss:0.00001, loss_test:0.01229, lr:5.43e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.600, tt:2283.595\n",
      "Ep:66, loss:0.00001, loss_test:0.01268, lr:5.43e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.623, tt:2319.722\n",
      "Ep:67, loss:0.00001, loss_test:0.01290, lr:5.43e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.624, tt:2354.435\n",
      "Ep:68, loss:0.00001, loss_test:0.01257, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.614, tt:2388.370\n",
      "Ep:69, loss:0.00001, loss_test:0.01347, lr:5.43e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.616, tt:2423.097\n",
      "Ep:70, loss:0.00001, loss_test:0.01309, lr:5.43e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.636, tt:2459.133\n",
      "Ep:71, loss:0.00001, loss_test:0.01301, lr:5.43e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.636, tt:2493.781\n",
      "Ep:72, loss:0.00000, loss_test:0.01372, lr:5.37e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.621, tt:2527.357\n",
      "Ep:73, loss:0.00000, loss_test:0.01370, lr:5.32e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.644, tt:2563.675\n",
      "Ep:74, loss:0.00000, loss_test:0.01402, lr:5.27e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.663, tt:2599.762\n",
      "Ep:75, loss:0.00000, loss_test:0.01447, lr:5.21e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.655, tt:2633.788\n",
      "Ep:76, loss:0.00000, loss_test:0.01425, lr:5.16e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.663, tt:2669.063\n",
      "Ep:77, loss:0.00000, loss_test:0.01526, lr:5.11e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.676, tt:2704.699\n",
      "Ep:78, loss:0.00000, loss_test:0.01481, lr:5.06e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.660, tt:2738.121\n",
      "Ep:79, loss:0.00000, loss_test:0.01505, lr:5.01e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.651, tt:2772.114\n",
      "Ep:80, loss:0.00000, loss_test:0.01599, lr:4.96e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.637, tt:2805.574\n",
      "Ep:81, loss:0.00000, loss_test:0.01512, lr:4.91e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.628, tt:2839.521\n",
      "Ep:82, loss:0.00000, loss_test:0.01598, lr:4.86e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.623, tt:2873.692\n",
      "Ep:83, loss:0.00000, loss_test:0.01622, lr:4.81e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.628, tt:2908.788\n",
      "Ep:84, loss:0.00000, loss_test:0.01633, lr:4.76e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.633, tt:2943.807\n",
      "Ep:85, loss:0.00000, loss_test:0.01588, lr:4.71e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.641, tt:2979.118\n",
      "Ep:86, loss:0.00000, loss_test:0.01663, lr:4.67e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.625, tt:3012.383\n",
      "Ep:87, loss:0.00000, loss_test:0.01684, lr:4.62e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.635, tt:3047.875\n",
      "Ep:88, loss:0.00000, loss_test:0.01663, lr:4.57e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.652, tt:3084.037\n",
      "Ep:89, loss:0.00000, loss_test:0.01719, lr:4.53e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.665, tt:3119.862\n",
      "Ep:90, loss:0.00000, loss_test:0.01748, lr:4.48e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.676, tt:3155.473\n",
      "Ep:91, loss:0.00000, loss_test:0.01754, lr:4.44e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.686, tt:3191.086\n",
      "Ep:92, loss:0.00000, loss_test:0.01737, lr:4.39e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.720, tt:3228.916\n",
      "Ep:93, loss:0.00000, loss_test:0.01801, lr:4.35e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.735, tt:3265.068\n",
      "Ep:94, loss:0.00000, loss_test:0.01785, lr:4.31e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.746, tt:3300.892\n",
      "Ep:95, loss:0.00000, loss_test:0.01825, lr:4.26e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.738, tt:3334.830\n",
      "Ep:96, loss:0.00000, loss_test:0.01851, lr:4.22e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.756, tt:3371.331\n",
      "Ep:97, loss:0.00000, loss_test:0.01836, lr:4.18e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.769, tt:3407.350\n",
      "Ep:98, loss:0.00000, loss_test:0.01893, lr:4.14e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.768, tt:3441.996\n",
      "Ep:99, loss:0.00000, loss_test:0.01862, lr:4.10e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.780, tt:3477.964\n",
      "Ep:100, loss:0.00000, loss_test:0.01905, lr:4.05e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.789, tt:3513.670\n",
      "Ep:101, loss:0.00000, loss_test:0.01905, lr:4.01e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.806, tt:3550.162\n",
      "Ep:102, loss:0.00000, loss_test:0.01902, lr:3.97e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.819, tt:3586.321\n",
      "Ep:103, loss:0.00000, loss_test:0.01996, lr:3.93e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.836, tt:3622.933\n",
      "Ep:104, loss:0.00000, loss_test:0.01911, lr:3.89e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.841, tt:3658.326\n",
      "Ep:105, loss:0.00000, loss_test:0.01971, lr:3.86e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.840, tt:3693.024\n",
      "Ep:106, loss:0.00000, loss_test:0.02005, lr:3.82e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.846, tt:3728.499\n",
      "Ep:107, loss:0.00000, loss_test:0.01971, lr:3.78e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.850, tt:3763.766\n",
      "Ep:108, loss:0.00000, loss_test:0.02026, lr:3.74e-02, fs:0.67901 (r=0.556,p=0.873),  time:34.855, tt:3799.192\n",
      "Ep:109, loss:0.00000, loss_test:0.02037, lr:3.70e-02, fs:0.67081 (r=0.545,p=0.871),  time:34.882, tt:3837.059\n",
      "Ep:110, loss:0.00000, loss_test:0.02029, lr:3.67e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.896, tt:3873.465\n",
      "Ep:111, loss:0.00000, loss_test:0.02056, lr:3.63e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.905, tt:3909.349\n",
      "Ep:112, loss:0.00000, loss_test:0.02077, lr:3.59e-02, fs:0.67081 (r=0.545,p=0.871),  time:34.909, tt:3944.680\n",
      "Ep:113, loss:0.00000, loss_test:0.02064, lr:3.56e-02, fs:0.67081 (r=0.545,p=0.871),  time:34.917, tt:3980.491\n",
      "Ep:114, loss:0.00000, loss_test:0.02088, lr:3.52e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.912, tt:4014.855\n",
      "Ep:115, loss:0.00000, loss_test:0.02088, lr:3.49e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.910, tt:4049.517\n",
      "Ep:116, loss:0.00000, loss_test:0.02115, lr:3.45e-02, fs:0.67081 (r=0.545,p=0.871),  time:34.914, tt:4084.889\n",
      "Ep:117, loss:0.00000, loss_test:0.02123, lr:3.42e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.922, tt:4120.783\n",
      "Ep:118, loss:0.00000, loss_test:0.02118, lr:3.38e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.928, tt:4156.394\n",
      "Ep:119, loss:0.00000, loss_test:0.02150, lr:3.35e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.927, tt:4191.226\n",
      "Ep:120, loss:0.00000, loss_test:0.02134, lr:3.32e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.935, tt:4227.171\n",
      "Ep:121, loss:0.00000, loss_test:0.02149, lr:3.28e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.933, tt:4261.843\n",
      "Ep:122, loss:0.00000, loss_test:0.02176, lr:3.25e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.943, tt:4297.946\n",
      "Ep:123, loss:0.00000, loss_test:0.02144, lr:3.22e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.954, tt:4334.294\n",
      "Ep:124, loss:0.00000, loss_test:0.02197, lr:3.19e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.953, tt:4369.142\n",
      "Ep:125, loss:0.00000, loss_test:0.02160, lr:3.15e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.955, tt:4404.366\n",
      "Ep:126, loss:0.00000, loss_test:0.02239, lr:3.12e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.960, tt:4439.925\n",
      "Ep:127, loss:0.00000, loss_test:0.02174, lr:3.09e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.971, tt:4476.309\n",
      "Ep:128, loss:0.00000, loss_test:0.02245, lr:3.06e-02, fs:0.63694 (r=0.505,p=0.862),  time:34.971, tt:4511.297\n",
      "Ep:129, loss:0.00000, loss_test:0.02196, lr:3.03e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.969, tt:4545.977\n",
      "Ep:130, loss:0.00000, loss_test:0.02242, lr:3.00e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.975, tt:4581.667\n",
      "Ep:131, loss:0.00000, loss_test:0.02234, lr:2.97e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.984, tt:4617.937\n",
      "Ep:132, loss:0.00000, loss_test:0.02240, lr:2.94e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.990, tt:4653.610\n",
      "Ep:133, loss:0.00000, loss_test:0.02249, lr:2.91e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.993, tt:4689.008\n",
      "Ep:134, loss:0.00000, loss_test:0.02245, lr:2.88e-02, fs:0.63694 (r=0.505,p=0.862),  time:34.996, tt:4724.473\n",
      "Ep:135, loss:0.00000, loss_test:0.02270, lr:2.85e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.998, tt:4759.691\n",
      "Ep:136, loss:0.00000, loss_test:0.02255, lr:2.82e-02, fs:0.63694 (r=0.505,p=0.862),  time:34.995, tt:4794.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02302, lr:2.80e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.999, tt:4829.799\n",
      "Ep:138, loss:0.00000, loss_test:0.02253, lr:2.77e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.002, tt:4865.308\n",
      "Ep:139, loss:0.00000, loss_test:0.02300, lr:2.74e-02, fs:0.64557 (r=0.515,p=0.864),  time:35.007, tt:4901.028\n",
      "Ep:140, loss:0.00000, loss_test:0.02295, lr:2.71e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.012, tt:4936.751\n",
      "Ep:141, loss:0.00000, loss_test:0.02304, lr:2.69e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.017, tt:4972.400\n",
      "Ep:142, loss:0.00000, loss_test:0.02316, lr:2.66e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.023, tt:5008.226\n",
      "Ep:143, loss:0.00000, loss_test:0.02303, lr:2.63e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.024, tt:5043.513\n",
      "Ep:144, loss:0.00000, loss_test:0.02333, lr:2.61e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.034, tt:5079.890\n",
      "Ep:145, loss:0.00000, loss_test:0.02307, lr:2.58e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.030, tt:5114.414\n",
      "Ep:146, loss:0.00000, loss_test:0.02350, lr:2.55e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.032, tt:5149.729\n",
      "Ep:147, loss:0.00000, loss_test:0.02329, lr:2.53e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.035, tt:5185.203\n",
      "Ep:148, loss:0.00000, loss_test:0.02350, lr:2.50e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.037, tt:5220.487\n",
      "Ep:149, loss:0.00000, loss_test:0.02339, lr:2.48e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.037, tt:5255.560\n",
      "Ep:150, loss:0.00000, loss_test:0.02368, lr:2.45e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.036, tt:5290.476\n",
      "Ep:151, loss:0.00000, loss_test:0.02343, lr:2.43e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.055, tt:5328.328\n",
      "Ep:152, loss:0.00000, loss_test:0.02389, lr:2.40e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.064, tt:5364.731\n",
      "Ep:153, loss:0.00000, loss_test:0.02348, lr:2.38e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.068, tt:5400.532\n",
      "Ep:154, loss:0.00000, loss_test:0.02386, lr:2.36e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.065, tt:5435.110\n",
      "Ep:155, loss:0.00000, loss_test:0.02377, lr:2.33e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.054, tt:5468.446\n",
      "Ep:156, loss:0.00000, loss_test:0.02399, lr:2.31e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.051, tt:5502.976\n",
      "Ep:157, loss:0.00000, loss_test:0.02381, lr:2.29e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.054, tt:5538.464\n",
      "Ep:158, loss:0.00000, loss_test:0.02401, lr:2.26e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.052, tt:5573.283\n",
      "Ep:159, loss:0.00000, loss_test:0.02417, lr:2.24e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.056, tt:5608.888\n",
      "Ep:160, loss:0.00000, loss_test:0.02385, lr:2.22e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.048, tt:5642.780\n",
      "Ep:161, loss:0.00000, loss_test:0.02406, lr:2.20e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.039, tt:5676.388\n",
      "Ep:162, loss:0.00000, loss_test:0.02412, lr:2.17e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.042, tt:5711.890\n",
      "Ep:163, loss:0.00000, loss_test:0.02433, lr:2.15e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.037, tt:5746.000\n",
      "Ep:164, loss:0.00000, loss_test:0.02399, lr:2.13e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.027, tt:5779.521\n",
      "Ep:165, loss:0.00000, loss_test:0.02449, lr:2.11e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.021, tt:5813.490\n",
      "Ep:166, loss:0.00000, loss_test:0.02422, lr:2.09e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.018, tt:5848.073\n",
      "Ep:167, loss:0.00000, loss_test:0.02443, lr:2.07e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.019, tt:5883.108\n",
      "Ep:168, loss:0.00000, loss_test:0.02423, lr:2.05e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.011, tt:5916.927\n",
      "Ep:169, loss:0.00000, loss_test:0.02452, lr:2.03e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.006, tt:5951.078\n",
      "Ep:170, loss:0.00000, loss_test:0.02453, lr:2.01e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.992, tt:5983.567\n",
      "Ep:171, loss:0.00000, loss_test:0.02443, lr:1.99e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.987, tt:6017.802\n",
      "Ep:172, loss:0.00000, loss_test:0.02467, lr:1.97e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.982, tt:6051.960\n",
      "Ep:173, loss:0.00000, loss_test:0.02450, lr:1.95e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.981, tt:6086.687\n",
      "Ep:174, loss:0.00000, loss_test:0.02483, lr:1.93e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.979, tt:6121.400\n",
      "Ep:175, loss:0.00000, loss_test:0.02457, lr:1.91e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.972, tt:6155.135\n",
      "Ep:176, loss:0.00000, loss_test:0.02479, lr:1.89e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.965, tt:6188.891\n",
      "Ep:177, loss:0.00000, loss_test:0.02478, lr:1.87e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.963, tt:6223.463\n",
      "Ep:178, loss:0.00000, loss_test:0.02475, lr:1.85e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.963, tt:6258.399\n",
      "Ep:179, loss:0.00000, loss_test:0.02491, lr:1.83e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.962, tt:6293.226\n",
      "Ep:180, loss:0.00000, loss_test:0.02474, lr:1.81e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.967, tt:6329.060\n",
      "Ep:181, loss:0.00000, loss_test:0.02499, lr:1.80e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.965, tt:6363.551\n",
      "Ep:182, loss:0.00000, loss_test:0.02489, lr:1.78e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.964, tt:6398.327\n",
      "Ep:183, loss:0.00000, loss_test:0.02493, lr:1.76e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.962, tt:6433.058\n",
      "Ep:184, loss:0.00000, loss_test:0.02503, lr:1.74e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.958, tt:6467.302\n",
      "Ep:185, loss:0.00000, loss_test:0.02494, lr:1.73e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.964, tt:6503.269\n",
      "Ep:186, loss:0.00000, loss_test:0.02507, lr:1.71e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.960, tt:6537.546\n",
      "Ep:187, loss:0.00000, loss_test:0.02511, lr:1.69e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.962, tt:6572.790\n",
      "Ep:188, loss:0.00000, loss_test:0.02508, lr:1.67e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.954, tt:6606.293\n",
      "Ep:189, loss:0.00000, loss_test:0.02507, lr:1.66e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.966, tt:6643.477\n",
      "Ep:190, loss:0.00000, loss_test:0.02515, lr:1.64e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.977, tt:6680.574\n",
      "Ep:191, loss:0.00000, loss_test:0.02522, lr:1.62e-02, fs:0.61039 (r=0.475,p=0.855),  time:34.997, tt:6719.409\n",
      "Ep:192, loss:0.00000, loss_test:0.02524, lr:1.61e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.011, tt:6757.185\n",
      "Ep:193, loss:0.00000, loss_test:0.02509, lr:1.59e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.024, tt:6794.688\n",
      "Ep:194, loss:0.00000, loss_test:0.02526, lr:1.58e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.030, tt:6830.867\n",
      "Ep:195, loss:0.00000, loss_test:0.02519, lr:1.56e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.028, tt:6865.420\n",
      "Ep:196, loss:0.00000, loss_test:0.02520, lr:1.54e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.026, tt:6900.134\n",
      "Ep:197, loss:0.00000, loss_test:0.02535, lr:1.53e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.020, tt:6933.877\n",
      "Ep:198, loss:0.00000, loss_test:0.02524, lr:1.51e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.013, tt:6967.544\n",
      "Ep:199, loss:0.00000, loss_test:0.02535, lr:1.50e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.013, tt:7002.659\n",
      "Ep:200, loss:0.00000, loss_test:0.02535, lr:1.48e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.010, tt:7037.077\n",
      "Ep:201, loss:0.00000, loss_test:0.02537, lr:1.47e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.002, tt:7070.310\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00029, loss_test:0.13067, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:30.620, tt:30.620\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.12910, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:32.628, tt:65.256\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.12772, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:31.384, tt:94.152\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00028, loss_test:0.12659, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:31.290, tt:125.161\n",
      "Ep:4, loss:0.00027, loss_test:0.12506, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:31.582, tt:157.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00027, loss_test:0.12324, lr:1.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:32.470, tt:194.820\n",
      "Ep:6, loss:0.00027, loss_test:0.12105, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:32.939, tt:230.576\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00027, loss_test:0.11867, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:33.401, tt:267.208\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00027, loss_test:0.11653, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:33.683, tt:303.145\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.11478, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:33.901, tt:339.014\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00026, loss_test:0.11361, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.060, tt:374.662\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.11301, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.276, tt:411.311\n",
      "Ep:12, loss:0.00026, loss_test:0.11291, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.346, tt:446.495\n",
      "Ep:13, loss:0.00026, loss_test:0.11263, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.395, tt:481.526\n",
      "Ep:14, loss:0.00026, loss_test:0.11212, lr:1.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:34.379, tt:515.678\n",
      "Ep:15, loss:0.00025, loss_test:0.11095, lr:1.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.366, tt:549.850\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.10963, lr:1.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:34.553, tt:587.409\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.10853, lr:1.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:34.609, tt:622.959\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.10757, lr:1.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:34.619, tt:657.760\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.10693, lr:1.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:34.639, tt:692.782\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.10634, lr:1.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:34.666, tt:727.991\n",
      "Ep:21, loss:0.00024, loss_test:0.10515, lr:1.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:34.646, tt:762.204\n",
      "Ep:22, loss:0.00024, loss_test:0.10366, lr:1.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:34.619, tt:796.248\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00023, loss_test:0.10164, lr:1.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:34.609, tt:830.627\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00023, loss_test:0.09964, lr:1.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:34.604, tt:865.095\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00023, loss_test:0.09761, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:34.637, tt:900.571\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00022, loss_test:0.09542, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:34.583, tt:933.731\n",
      "Ep:27, loss:0.00022, loss_test:0.09326, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:34.592, tt:968.588\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00021, loss_test:0.09189, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:34.622, tt:1004.046\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00020, loss_test:0.09046, lr:1.00e-02, fs:0.75536 (r=0.889,p=0.657),  time:34.605, tt:1038.138\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00020, loss_test:0.08741, lr:1.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:34.583, tt:1072.079\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00019, loss_test:0.08585, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:34.588, tt:1106.816\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00018, loss_test:0.08470, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:34.633, tt:1142.876\n",
      "Ep:33, loss:0.00018, loss_test:0.08197, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:34.651, tt:1178.126\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00016, loss_test:0.08033, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:34.677, tt:1213.681\n",
      "Ep:35, loss:0.00015, loss_test:0.07771, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:34.658, tt:1247.703\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.07538, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:34.678, tt:1283.104\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00013, loss_test:0.07389, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:34.677, tt:1317.744\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.07490, lr:1.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:34.732, tt:1354.544\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.07037, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.734, tt:1389.363\n",
      "Ep:40, loss:0.00011, loss_test:0.06857, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.714, tt:1423.287\n",
      "Ep:41, loss:0.00011, loss_test:0.07262, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.748, tt:1459.417\n",
      "Ep:42, loss:0.00011, loss_test:0.06708, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.785, tt:1495.745\n",
      "Ep:43, loss:0.00010, loss_test:0.06261, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.825, tt:1532.292\n",
      "Ep:44, loss:0.00009, loss_test:0.06231, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.866, tt:1568.989\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06299, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.894, tt:1605.106\n",
      "Ep:46, loss:0.00008, loss_test:0.06137, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.898, tt:1640.187\n",
      "Ep:47, loss:0.00007, loss_test:0.06005, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.900, tt:1675.187\n",
      "Ep:48, loss:0.00007, loss_test:0.06149, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.929, tt:1711.523\n",
      "Ep:49, loss:0.00006, loss_test:0.05825, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.928, tt:1746.392\n",
      "Ep:50, loss:0.00006, loss_test:0.05863, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.923, tt:1781.088\n",
      "Ep:51, loss:0.00005, loss_test:0.05824, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.918, tt:1815.717\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.05866, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.957, tt:1852.738\n",
      "Ep:53, loss:0.00005, loss_test:0.05489, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.988, tt:1889.375\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.05661, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.009, tt:1925.515\n",
      "Ep:55, loss:0.00004, loss_test:0.05732, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.014, tt:1960.812\n",
      "Ep:56, loss:0.00004, loss_test:0.06546, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:35.010, tt:1995.552\n",
      "Ep:57, loss:0.00004, loss_test:0.05671, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.012, tt:2030.683\n",
      "Ep:58, loss:0.00004, loss_test:0.05732, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.026, tt:2066.518\n",
      "Ep:59, loss:0.00004, loss_test:0.06431, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.042, tt:2102.526\n",
      "Ep:60, loss:0.00003, loss_test:0.05475, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:35.067, tt:2139.061\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.05474, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.075, tt:2174.650\n",
      "Ep:62, loss:0.00003, loss_test:0.06151, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.100, tt:2211.279\n",
      "Ep:63, loss:0.00003, loss_test:0.05471, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.118, tt:2247.551\n",
      "Ep:64, loss:0.00003, loss_test:0.05451, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.118, tt:2282.695\n",
      "Ep:65, loss:0.00003, loss_test:0.05312, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:35.129, tt:2318.507\n",
      "Ep:66, loss:0.00003, loss_test:0.05589, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.138, tt:2354.264\n",
      "Ep:67, loss:0.00002, loss_test:0.05254, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:35.149, tt:2390.161\n",
      "Ep:68, loss:0.00002, loss_test:0.05754, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.154, tt:2425.632\n",
      "Ep:69, loss:0.00002, loss_test:0.05692, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.165, tt:2461.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00002, loss_test:0.05556, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.173, tt:2497.270\n",
      "Ep:71, loss:0.00002, loss_test:0.05625, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:35.160, tt:2531.550\n",
      "Ep:72, loss:0.00002, loss_test:0.05076, lr:9.90e-03, fs:0.90426 (r=0.859,p=0.955),  time:35.176, tt:2567.846\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.06086, lr:9.90e-03, fs:0.82418 (r=0.758,p=0.904),  time:35.183, tt:2603.560\n",
      "Ep:74, loss:0.00002, loss_test:0.05939, lr:9.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.188, tt:2639.092\n",
      "Ep:75, loss:0.00002, loss_test:0.05477, lr:9.90e-03, fs:0.85870 (r=0.798,p=0.929),  time:35.182, tt:2673.833\n",
      "Ep:76, loss:0.00002, loss_test:0.06718, lr:9.90e-03, fs:0.75449 (r=0.636,p=0.926),  time:35.189, tt:2709.583\n",
      "Ep:77, loss:0.00002, loss_test:0.05799, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.193, tt:2745.047\n",
      "Ep:78, loss:0.00002, loss_test:0.06111, lr:9.90e-03, fs:0.81564 (r=0.737,p=0.912),  time:35.204, tt:2781.127\n",
      "Ep:79, loss:0.00002, loss_test:0.05187, lr:9.90e-03, fs:0.88172 (r=0.828,p=0.943),  time:35.222, tt:2817.723\n",
      "Ep:80, loss:0.00002, loss_test:0.05965, lr:9.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.239, tt:2854.383\n",
      "Ep:81, loss:0.00001, loss_test:0.05778, lr:9.90e-03, fs:0.82222 (r=0.747,p=0.914),  time:35.231, tt:2888.983\n",
      "Ep:82, loss:0.00001, loss_test:0.05503, lr:9.90e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.239, tt:2924.827\n",
      "Ep:83, loss:0.00001, loss_test:0.06129, lr:9.90e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.243, tt:2960.435\n",
      "Ep:84, loss:0.00001, loss_test:0.05504, lr:9.80e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.253, tt:2996.518\n",
      "Ep:85, loss:0.00001, loss_test:0.05537, lr:9.70e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.262, tt:3032.497\n",
      "Ep:86, loss:0.00001, loss_test:0.05724, lr:9.61e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.249, tt:3066.698\n",
      "Ep:87, loss:0.00001, loss_test:0.05665, lr:9.51e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.243, tt:3101.418\n",
      "Ep:88, loss:0.00001, loss_test:0.05585, lr:9.41e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.249, tt:3137.157\n",
      "Ep:89, loss:0.00001, loss_test:0.05705, lr:9.32e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.243, tt:3171.891\n",
      "Ep:90, loss:0.00001, loss_test:0.05538, lr:9.23e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.245, tt:3207.285\n",
      "Ep:91, loss:0.00001, loss_test:0.05980, lr:9.14e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.253, tt:3243.304\n",
      "Ep:92, loss:0.00001, loss_test:0.05512, lr:9.04e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.260, tt:3279.195\n",
      "Ep:93, loss:0.00001, loss_test:0.05942, lr:8.95e-03, fs:0.76829 (r=0.636,p=0.969),  time:35.301, tt:3318.329\n",
      "Ep:94, loss:0.00001, loss_test:0.05666, lr:8.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.342, tt:3357.465\n",
      "Ep:95, loss:0.00001, loss_test:0.05996, lr:8.78e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.385, tt:3396.936\n",
      "Ep:96, loss:0.00001, loss_test:0.05567, lr:8.69e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.418, tt:3435.540\n",
      "Ep:97, loss:0.00001, loss_test:0.05599, lr:8.60e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.460, tt:3475.104\n",
      "Ep:98, loss:0.00001, loss_test:0.05643, lr:8.51e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.454, tt:3509.987\n",
      "Ep:99, loss:0.00001, loss_test:0.05686, lr:8.43e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.459, tt:3545.883\n",
      "Ep:100, loss:0.00001, loss_test:0.05821, lr:8.35e-03, fs:0.83908 (r=0.737,p=0.973),  time:35.475, tt:3582.953\n",
      "Ep:101, loss:0.00001, loss_test:0.05606, lr:8.26e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.494, tt:3620.390\n",
      "Ep:102, loss:0.00001, loss_test:0.05693, lr:8.18e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.538, tt:3660.442\n",
      "Ep:103, loss:0.00001, loss_test:0.05511, lr:8.10e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.558, tt:3697.985\n",
      "Ep:104, loss:0.00001, loss_test:0.05603, lr:8.02e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.587, tt:3736.623\n",
      "Ep:105, loss:0.00001, loss_test:0.05546, lr:7.94e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.618, tt:3775.520\n",
      "Ep:106, loss:0.00001, loss_test:0.05634, lr:7.86e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.641, tt:3813.617\n",
      "Ep:107, loss:0.00000, loss_test:0.05537, lr:7.78e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.668, tt:3852.181\n",
      "Ep:108, loss:0.00000, loss_test:0.05528, lr:7.70e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.690, tt:3890.191\n",
      "Ep:109, loss:0.00000, loss_test:0.05497, lr:7.62e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.703, tt:3927.291\n",
      "Ep:110, loss:0.00000, loss_test:0.05485, lr:7.55e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.707, tt:3963.427\n",
      "Ep:111, loss:0.00000, loss_test:0.05419, lr:7.47e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.712, tt:3999.688\n",
      "Ep:112, loss:0.00000, loss_test:0.05464, lr:7.40e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.727, tt:4037.201\n",
      "Ep:113, loss:0.00000, loss_test:0.05587, lr:7.32e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.735, tt:4073.741\n",
      "Ep:114, loss:0.00000, loss_test:0.05484, lr:7.25e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.730, tt:4108.938\n",
      "Ep:115, loss:0.00000, loss_test:0.05535, lr:7.18e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.732, tt:4144.885\n",
      "Ep:116, loss:0.00000, loss_test:0.05463, lr:7.11e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.735, tt:4180.988\n",
      "Ep:117, loss:0.00000, loss_test:0.05403, lr:7.03e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.729, tt:4216.005\n",
      "Ep:118, loss:0.00000, loss_test:0.05350, lr:6.96e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.733, tt:4252.205\n",
      "Ep:119, loss:0.00000, loss_test:0.05453, lr:6.89e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.729, tt:4287.475\n",
      "Ep:120, loss:0.00000, loss_test:0.05536, lr:6.83e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.727, tt:4322.940\n",
      "Ep:121, loss:0.00000, loss_test:0.05583, lr:6.76e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.734, tt:4359.591\n",
      "Ep:122, loss:0.00000, loss_test:0.05452, lr:6.69e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.739, tt:4395.849\n",
      "Ep:123, loss:0.00000, loss_test:0.05453, lr:6.62e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.743, tt:4432.116\n",
      "Ep:124, loss:0.00000, loss_test:0.05394, lr:6.56e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.742, tt:4467.798\n",
      "Ep:125, loss:0.00000, loss_test:0.05437, lr:6.49e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.740, tt:4503.214\n",
      "Ep:126, loss:0.00000, loss_test:0.05445, lr:6.43e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.749, tt:4540.107\n",
      "Ep:127, loss:0.00000, loss_test:0.05337, lr:6.36e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.752, tt:4576.242\n",
      "Ep:128, loss:0.00000, loss_test:0.05477, lr:6.30e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.771, tt:4614.448\n",
      "Ep:129, loss:0.00000, loss_test:0.05455, lr:6.24e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.768, tt:4649.856\n",
      "Ep:130, loss:0.00000, loss_test:0.05651, lr:6.17e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.782, tt:4687.418\n",
      "Ep:131, loss:0.00000, loss_test:0.05609, lr:6.11e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.776, tt:4722.399\n",
      "Ep:132, loss:0.00000, loss_test:0.05433, lr:6.05e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.782, tt:4758.993\n",
      "Ep:133, loss:0.00000, loss_test:0.05551, lr:5.99e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.781, tt:4794.652\n",
      "Ep:134, loss:0.00000, loss_test:0.05350, lr:5.93e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.785, tt:4830.972\n",
      "Ep:135, loss:0.00000, loss_test:0.05574, lr:5.87e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.808, tt:4869.831\n",
      "Ep:136, loss:0.00000, loss_test:0.05620, lr:5.81e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.809, tt:4905.788\n",
      "Ep:137, loss:0.00000, loss_test:0.05427, lr:5.75e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.812, tt:4942.118\n",
      "Ep:138, loss:0.00000, loss_test:0.05416, lr:5.70e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.828, tt:4980.063\n",
      "Ep:139, loss:0.00000, loss_test:0.05376, lr:5.64e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.833, tt:5016.635\n",
      "Ep:140, loss:0.00000, loss_test:0.05550, lr:5.58e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.840, tt:5053.483\n",
      "Ep:141, loss:0.00000, loss_test:0.05526, lr:5.53e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.848, tt:5090.368\n",
      "Ep:142, loss:0.00000, loss_test:0.05417, lr:5.47e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.845, tt:5125.874\n",
      "Ep:143, loss:0.00000, loss_test:0.05418, lr:5.42e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.855, tt:5163.105\n",
      "Ep:144, loss:0.00000, loss_test:0.05318, lr:5.36e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.849, tt:5198.080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.05392, lr:5.31e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.846, tt:5233.461\n",
      "Ep:146, loss:0.00000, loss_test:0.05448, lr:5.26e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.852, tt:5270.212\n",
      "Ep:147, loss:0.00000, loss_test:0.05325, lr:5.20e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.851, tt:5305.907\n",
      "Ep:148, loss:0.00000, loss_test:0.05344, lr:5.15e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.847, tt:5341.244\n",
      "Ep:149, loss:0.00000, loss_test:0.05336, lr:5.10e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.858, tt:5378.746\n",
      "Ep:150, loss:0.00000, loss_test:0.05364, lr:5.05e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.866, tt:5415.830\n",
      "Ep:151, loss:0.00000, loss_test:0.05346, lr:5.00e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.877, tt:5453.302\n",
      "Ep:152, loss:0.00000, loss_test:0.05315, lr:4.95e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.869, tt:5487.954\n",
      "Ep:155, loss:0.00000, loss_test:0.05284, lr:4.80e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.870, tt:5595.737\n",
      "Ep:156, loss:0.00000, loss_test:0.05309, lr:4.75e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.879, tt:5632.952\n",
      "Ep:157, loss:0.00000, loss_test:0.05282, lr:4.71e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.880, tt:5669.012\n",
      "Ep:158, loss:0.00000, loss_test:0.05291, lr:4.66e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.868, tt:5703.066\n",
      "Ep:159, loss:0.00000, loss_test:0.05313, lr:4.61e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.895, tt:5743.237\n",
      "Ep:160, loss:0.00000, loss_test:0.05324, lr:4.57e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.890, tt:5778.264\n",
      "Ep:161, loss:0.00000, loss_test:0.05284, lr:4.52e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.889, tt:5813.978\n",
      "Ep:162, loss:0.00000, loss_test:0.05280, lr:4.48e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.889, tt:5849.893\n",
      "Ep:163, loss:0.00000, loss_test:0.05315, lr:4.43e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.893, tt:5886.455\n",
      "Ep:164, loss:0.00000, loss_test:0.05325, lr:4.39e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.891, tt:5922.022\n",
      "Ep:165, loss:0.00000, loss_test:0.05332, lr:4.34e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.892, tt:5958.034\n",
      "Ep:166, loss:0.00000, loss_test:0.05266, lr:4.30e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.896, tt:5994.581\n",
      "Ep:167, loss:0.00000, loss_test:0.05258, lr:4.26e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.895, tt:6030.425\n",
      "Ep:168, loss:0.00000, loss_test:0.05357, lr:4.21e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.898, tt:6066.806\n",
      "Ep:169, loss:0.00000, loss_test:0.05286, lr:4.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.904, tt:6103.743\n",
      "Ep:170, loss:0.00000, loss_test:0.05280, lr:4.13e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.899, tt:6138.718\n",
      "Ep:171, loss:0.00000, loss_test:0.05305, lr:4.09e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.900, tt:6174.828\n",
      "Ep:172, loss:0.00000, loss_test:0.05298, lr:4.05e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.897, tt:6210.147\n",
      "Ep:173, loss:0.00000, loss_test:0.05316, lr:4.01e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.893, tt:6245.458\n",
      "Ep:174, loss:0.00000, loss_test:0.05286, lr:3.97e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.899, tt:6282.254\n",
      "Ep:175, loss:0.00000, loss_test:0.05253, lr:3.93e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.892, tt:6316.967\n",
      "Ep:176, loss:0.00000, loss_test:0.05253, lr:3.89e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.880, tt:6350.723\n",
      "Ep:177, loss:0.00000, loss_test:0.05206, lr:3.85e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.871, tt:6385.048\n",
      "Ep:178, loss:0.00000, loss_test:0.05220, lr:3.81e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.871, tt:6420.901\n",
      "Ep:179, loss:0.00000, loss_test:0.05251, lr:3.77e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.872, tt:6457.038\n",
      "Ep:180, loss:0.00000, loss_test:0.05263, lr:3.73e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.875, tt:6493.435\n",
      "Ep:181, loss:0.00000, loss_test:0.05201, lr:3.70e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.867, tt:6527.874\n",
      "Ep:182, loss:0.00000, loss_test:0.05218, lr:3.66e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.865, tt:6563.305\n",
      "Ep:183, loss:0.00000, loss_test:0.05313, lr:3.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.883, tt:6602.457\n",
      "Ep:184, loss:0.00000, loss_test:0.05247, lr:3.59e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.877, tt:6637.226\n",
      "Ep:185, loss:0.00000, loss_test:0.05189, lr:3.55e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.862, tt:6670.372\n",
      "Ep:186, loss:0.00000, loss_test:0.05251, lr:3.52e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.857, tt:6705.216\n",
      "Ep:187, loss:0.00000, loss_test:0.05286, lr:3.48e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.852, tt:6740.241\n",
      "Ep:188, loss:0.00000, loss_test:0.05215, lr:3.45e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.848, tt:6775.224\n",
      "Ep:189, loss:0.00000, loss_test:0.05216, lr:3.41e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.841, tt:6809.798\n",
      "Ep:190, loss:0.00000, loss_test:0.05251, lr:3.38e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.837, tt:6844.926\n",
      "Ep:191, loss:0.00000, loss_test:0.05219, lr:3.34e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.830, tt:6879.414\n",
      "Ep:192, loss:0.00000, loss_test:0.05196, lr:3.31e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.825, tt:6914.267\n",
      "Ep:193, loss:0.00000, loss_test:0.05249, lr:3.28e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.821, tt:6949.267\n",
      "Ep:194, loss:0.00000, loss_test:0.05268, lr:3.24e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.810, tt:6982.914\n",
      "Ep:195, loss:0.00000, loss_test:0.05237, lr:3.21e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.802, tt:7017.154\n",
      "Ep:196, loss:0.00000, loss_test:0.05269, lr:3.18e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.798, tt:7052.113\n",
      "Ep:197, loss:0.00000, loss_test:0.05263, lr:3.15e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.786, tt:7085.625\n",
      "Ep:198, loss:0.00000, loss_test:0.05253, lr:3.12e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.779, tt:7119.937\n",
      "Ep:199, loss:0.00000, loss_test:0.05229, lr:3.09e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.772, tt:7154.306\n",
      "Ep:200, loss:0.00000, loss_test:0.05177, lr:3.05e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.763, tt:7188.354\n",
      "Ep:201, loss:0.00000, loss_test:0.05176, lr:3.02e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.746, tt:7220.738\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02463, lr:6.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:24.328, tt:24.328\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02205, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:23.699, tt:47.398\n",
      "Ep:2, loss:0.00005, loss_test:0.02420, lr:6.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:23.408, tt:70.224\n",
      "Ep:3, loss:0.00005, loss_test:0.02428, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:23.468, tt:93.871\n",
      "Ep:4, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:23.661, tt:118.306\n",
      "Ep:5, loss:0.00005, loss_test:0.02343, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:24.827, tt:148.960\n",
      "Ep:6, loss:0.00005, loss_test:0.02312, lr:6.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:25.421, tt:177.947\n",
      "Ep:7, loss:0.00005, loss_test:0.02283, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:25.965, tt:207.721\n",
      "Ep:8, loss:0.00005, loss_test:0.02248, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:26.504, tt:238.534\n",
      "Ep:9, loss:0.00005, loss_test:0.02210, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:26.854, tt:268.536\n",
      "Ep:10, loss:0.00005, loss_test:0.02169, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:27.139, tt:298.528\n",
      "Ep:11, loss:0.00005, loss_test:0.02115, lr:6.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:27.343, tt:328.114\n",
      "Ep:12, loss:0.00005, loss_test:0.02045, lr:5.94e-02, fs:0.67164 (r=0.909,p=0.533),  time:27.418, tt:356.434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00005, loss_test:0.01966, lr:5.88e-02, fs:0.67433 (r=0.889,p=0.543),  time:27.622, tt:386.704\n",
      "Ep:14, loss:0.00004, loss_test:0.01896, lr:5.82e-02, fs:0.68750 (r=0.889,p=0.561),  time:27.799, tt:416.986\n",
      "Ep:15, loss:0.00004, loss_test:0.01854, lr:5.76e-02, fs:0.69636 (r=0.869,p=0.581),  time:27.941, tt:447.062\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01835, lr:5.76e-02, fs:0.69421 (r=0.848,p=0.587),  time:28.132, tt:478.250\n",
      "Ep:17, loss:0.00004, loss_test:0.01828, lr:5.76e-02, fs:0.69421 (r=0.848,p=0.587),  time:28.196, tt:507.534\n",
      "Ep:18, loss:0.00004, loss_test:0.01819, lr:5.76e-02, fs:0.69136 (r=0.848,p=0.583),  time:28.237, tt:536.498\n",
      "Ep:19, loss:0.00004, loss_test:0.01809, lr:5.76e-02, fs:0.68852 (r=0.848,p=0.579),  time:28.347, tt:566.931\n",
      "Ep:20, loss:0.00004, loss_test:0.01802, lr:5.76e-02, fs:0.69919 (r=0.869,p=0.585),  time:28.410, tt:596.603\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01790, lr:5.76e-02, fs:0.70492 (r=0.869,p=0.593),  time:28.442, tt:625.714\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01780, lr:5.76e-02, fs:0.70492 (r=0.869,p=0.593),  time:28.481, tt:655.066\n",
      "Ep:23, loss:0.00004, loss_test:0.01763, lr:5.76e-02, fs:0.70492 (r=0.869,p=0.593),  time:28.487, tt:683.699\n",
      "Ep:24, loss:0.00004, loss_test:0.01747, lr:5.76e-02, fs:0.70445 (r=0.879,p=0.588),  time:28.503, tt:712.568\n",
      "Ep:25, loss:0.00004, loss_test:0.01732, lr:5.76e-02, fs:0.70161 (r=0.879,p=0.584),  time:28.561, tt:742.596\n",
      "Ep:26, loss:0.00004, loss_test:0.01714, lr:5.76e-02, fs:0.70161 (r=0.879,p=0.584),  time:28.609, tt:772.437\n",
      "Ep:27, loss:0.00004, loss_test:0.01699, lr:5.76e-02, fs:0.70445 (r=0.879,p=0.588),  time:28.643, tt:802.009\n",
      "Ep:28, loss:0.00004, loss_test:0.01688, lr:5.76e-02, fs:0.71311 (r=0.879,p=0.600),  time:28.689, tt:831.980\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01673, lr:5.76e-02, fs:0.71837 (r=0.889,p=0.603),  time:28.704, tt:861.128\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01662, lr:5.76e-02, fs:0.72428 (r=0.889,p=0.611),  time:28.746, tt:891.127\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01644, lr:5.76e-02, fs:0.72428 (r=0.889,p=0.611),  time:28.792, tt:921.342\n",
      "Ep:32, loss:0.00003, loss_test:0.01627, lr:5.76e-02, fs:0.71901 (r=0.879,p=0.608),  time:28.838, tt:951.658\n",
      "Ep:33, loss:0.00003, loss_test:0.01608, lr:5.76e-02, fs:0.72500 (r=0.879,p=0.617),  time:28.896, tt:982.450\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01586, lr:5.76e-02, fs:0.72727 (r=0.889,p=0.615),  time:28.934, tt:1012.692\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01567, lr:5.76e-02, fs:0.73333 (r=0.889,p=0.624),  time:28.963, tt:1042.663\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01547, lr:5.76e-02, fs:0.73950 (r=0.889,p=0.633),  time:28.989, tt:1072.596\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01513, lr:5.76e-02, fs:0.73333 (r=0.889,p=0.624),  time:29.038, tt:1103.425\n",
      "Ep:38, loss:0.00003, loss_test:0.01504, lr:5.76e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.063, tt:1133.456\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01480, lr:5.76e-02, fs:0.76395 (r=0.899,p=0.664),  time:29.102, tt:1164.067\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01458, lr:5.76e-02, fs:0.77253 (r=0.909,p=0.672),  time:29.125, tt:1194.131\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01450, lr:5.76e-02, fs:0.76856 (r=0.889,p=0.677),  time:29.150, tt:1224.280\n",
      "Ep:42, loss:0.00002, loss_test:0.01434, lr:5.76e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.196, tt:1255.407\n",
      "Ep:43, loss:0.00002, loss_test:0.01422, lr:5.76e-02, fs:0.75113 (r=0.838,p=0.680),  time:29.260, tt:1287.450\n",
      "Ep:44, loss:0.00002, loss_test:0.01415, lr:5.76e-02, fs:0.75676 (r=0.848,p=0.683),  time:29.306, tt:1318.759\n",
      "Ep:45, loss:0.00002, loss_test:0.01418, lr:5.76e-02, fs:0.77064 (r=0.848,p=0.706),  time:29.319, tt:1348.668\n",
      "Ep:46, loss:0.00002, loss_test:0.01383, lr:5.76e-02, fs:0.78899 (r=0.869,p=0.723),  time:29.356, tt:1379.747\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01424, lr:5.76e-02, fs:0.78140 (r=0.848,p=0.724),  time:29.376, tt:1410.053\n",
      "Ep:48, loss:0.00002, loss_test:0.01413, lr:5.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:29.393, tt:1440.250\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01408, lr:5.76e-02, fs:0.80374 (r=0.869,p=0.748),  time:29.392, tt:1469.577\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01413, lr:5.76e-02, fs:0.78873 (r=0.848,p=0.737),  time:29.405, tt:1499.637\n",
      "Ep:51, loss:0.00002, loss_test:0.01400, lr:5.76e-02, fs:0.80383 (r=0.848,p=0.764),  time:29.444, tt:1531.073\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01422, lr:5.76e-02, fs:0.80976 (r=0.838,p=0.783),  time:29.479, tt:1562.374\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01403, lr:5.76e-02, fs:0.82759 (r=0.848,p=0.808),  time:29.490, tt:1592.437\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01396, lr:5.76e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.517, tt:1623.438\n",
      "Ep:55, loss:0.00001, loss_test:0.01385, lr:5.76e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.513, tt:1652.721\n",
      "Ep:56, loss:0.00001, loss_test:0.01399, lr:5.76e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.535, tt:1683.504\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01401, lr:5.76e-02, fs:0.83582 (r=0.848,p=0.824),  time:29.547, tt:1713.722\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01425, lr:5.76e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.567, tt:1744.480\n",
      "Ep:59, loss:0.00001, loss_test:0.01457, lr:5.76e-02, fs:0.83077 (r=0.818,p=0.844),  time:29.580, tt:1774.802\n",
      "Ep:60, loss:0.00001, loss_test:0.01484, lr:5.76e-02, fs:0.82828 (r=0.828,p=0.828),  time:29.599, tt:1805.533\n",
      "Ep:61, loss:0.00001, loss_test:0.01498, lr:5.76e-02, fs:0.82474 (r=0.808,p=0.842),  time:29.613, tt:1836.011\n",
      "Ep:62, loss:0.00001, loss_test:0.01484, lr:5.76e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.626, tt:1866.466\n",
      "Ep:63, loss:0.00001, loss_test:0.01514, lr:5.76e-02, fs:0.81865 (r=0.798,p=0.840),  time:29.609, tt:1894.983\n",
      "Ep:64, loss:0.00001, loss_test:0.01529, lr:5.76e-02, fs:0.82051 (r=0.808,p=0.833),  time:29.611, tt:1924.731\n",
      "Ep:65, loss:0.00001, loss_test:0.01551, lr:5.76e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.615, tt:1954.597\n",
      "Ep:66, loss:0.00001, loss_test:0.01502, lr:5.76e-02, fs:0.84422 (r=0.848,p=0.840),  time:29.626, tt:1984.961\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01702, lr:5.76e-02, fs:0.82105 (r=0.788,p=0.857),  time:29.637, tt:2015.315\n",
      "Ep:68, loss:0.00001, loss_test:0.01538, lr:5.76e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.653, tt:2046.075\n",
      "Ep:69, loss:0.00001, loss_test:0.01603, lr:5.76e-02, fs:0.80628 (r=0.778,p=0.837),  time:29.661, tt:2076.243\n",
      "Ep:70, loss:0.00001, loss_test:0.01645, lr:5.76e-02, fs:0.80628 (r=0.778,p=0.837),  time:29.658, tt:2105.688\n",
      "Ep:71, loss:0.00001, loss_test:0.01519, lr:5.76e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.655, tt:2135.132\n",
      "Ep:72, loss:0.00001, loss_test:0.01763, lr:5.76e-02, fs:0.81675 (r=0.788,p=0.848),  time:29.665, tt:2165.561\n",
      "Ep:73, loss:0.00001, loss_test:0.01538, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:29.694, tt:2197.326\n",
      "Ep:74, loss:0.00001, loss_test:0.01787, lr:5.76e-02, fs:0.81250 (r=0.788,p=0.839),  time:29.705, tt:2227.872\n",
      "Ep:75, loss:0.00001, loss_test:0.01585, lr:5.76e-02, fs:0.82105 (r=0.788,p=0.857),  time:29.716, tt:2258.413\n",
      "Ep:76, loss:0.00001, loss_test:0.01880, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:29.716, tt:2288.131\n",
      "Ep:77, loss:0.00001, loss_test:0.01606, lr:5.76e-02, fs:0.81481 (r=0.778,p=0.856),  time:29.720, tt:2318.179\n",
      "Ep:78, loss:0.00001, loss_test:0.01800, lr:5.71e-02, fs:0.81283 (r=0.768,p=0.864),  time:29.726, tt:2348.369\n",
      "Ep:79, loss:0.00001, loss_test:0.01730, lr:5.65e-02, fs:0.81915 (r=0.778,p=0.865),  time:29.738, tt:2379.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00001, loss_test:0.01820, lr:5.59e-02, fs:0.81319 (r=0.747,p=0.892),  time:29.760, tt:2410.557\n",
      "Ep:81, loss:0.00001, loss_test:0.01739, lr:5.54e-02, fs:0.81283 (r=0.768,p=0.864),  time:29.782, tt:2442.165\n",
      "Ep:82, loss:0.00000, loss_test:0.01961, lr:5.48e-02, fs:0.79330 (r=0.717,p=0.887),  time:29.798, tt:2473.249\n",
      "Ep:83, loss:0.00000, loss_test:0.01810, lr:5.43e-02, fs:0.83243 (r=0.778,p=0.895),  time:29.796, tt:2502.903\n",
      "Ep:84, loss:0.00000, loss_test:0.01979, lr:5.37e-02, fs:0.79096 (r=0.707,p=0.897),  time:29.784, tt:2531.652\n",
      "Ep:85, loss:0.00000, loss_test:0.01751, lr:5.32e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.801, tt:2562.868\n",
      "Ep:86, loss:0.00001, loss_test:0.01831, lr:5.27e-02, fs:0.76667 (r=0.697,p=0.852),  time:29.814, tt:2593.816\n",
      "Ep:87, loss:0.00000, loss_test:0.01897, lr:5.21e-02, fs:0.83060 (r=0.768,p=0.905),  time:29.825, tt:2624.643\n",
      "Ep:88, loss:0.00001, loss_test:0.02044, lr:5.16e-02, fs:0.78409 (r=0.697,p=0.896),  time:29.829, tt:2654.820\n",
      "Ep:89, loss:0.00000, loss_test:0.01660, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.839, tt:2685.552\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00000, loss_test:0.01977, lr:5.11e-02, fs:0.78212 (r=0.707,p=0.875),  time:29.859, tt:2717.141\n",
      "Ep:91, loss:0.00000, loss_test:0.01735, lr:5.11e-02, fs:0.82162 (r=0.768,p=0.884),  time:29.861, tt:2747.190\n",
      "Ep:92, loss:0.00000, loss_test:0.01936, lr:5.11e-02, fs:0.75824 (r=0.697,p=0.831),  time:29.862, tt:2777.184\n",
      "Ep:93, loss:0.00000, loss_test:0.01832, lr:5.11e-02, fs:0.81768 (r=0.747,p=0.902),  time:29.878, tt:2808.543\n",
      "Ep:94, loss:0.00000, loss_test:0.01889, lr:5.11e-02, fs:0.77528 (r=0.697,p=0.873),  time:29.875, tt:2838.170\n",
      "Ep:95, loss:0.00000, loss_test:0.01746, lr:5.11e-02, fs:0.80874 (r=0.747,p=0.881),  time:29.880, tt:2868.450\n",
      "Ep:96, loss:0.00000, loss_test:0.02031, lr:5.11e-02, fs:0.78409 (r=0.697,p=0.896),  time:29.893, tt:2899.632\n",
      "Ep:97, loss:0.00000, loss_test:0.01792, lr:5.11e-02, fs:0.77528 (r=0.697,p=0.873),  time:29.901, tt:2930.278\n",
      "Ep:98, loss:0.00000, loss_test:0.01987, lr:5.11e-02, fs:0.78409 (r=0.697,p=0.896),  time:29.914, tt:2961.444\n",
      "Ep:99, loss:0.00000, loss_test:0.01890, lr:5.11e-02, fs:0.77095 (r=0.697,p=0.863),  time:29.926, tt:2992.611\n",
      "Ep:100, loss:0.00000, loss_test:0.01997, lr:5.11e-02, fs:0.78409 (r=0.697,p=0.896),  time:29.947, tt:3024.660\n",
      "Ep:101, loss:0.00000, loss_test:0.01958, lr:5.06e-02, fs:0.78857 (r=0.697,p=0.908),  time:29.962, tt:3056.080\n",
      "Ep:102, loss:0.00000, loss_test:0.02022, lr:5.01e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.983, tt:3088.286\n",
      "Ep:103, loss:0.00000, loss_test:0.02011, lr:4.96e-02, fs:0.78857 (r=0.697,p=0.908),  time:29.988, tt:3118.704\n",
      "Ep:104, loss:0.00000, loss_test:0.02049, lr:4.91e-02, fs:0.78409 (r=0.697,p=0.896),  time:29.999, tt:3149.874\n",
      "Ep:105, loss:0.00000, loss_test:0.01937, lr:4.86e-02, fs:0.77528 (r=0.697,p=0.873),  time:30.011, tt:3181.194\n",
      "Ep:106, loss:0.00000, loss_test:0.02075, lr:4.81e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.017, tt:3211.830\n",
      "Ep:107, loss:0.00000, loss_test:0.02027, lr:4.76e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.029, tt:3243.163\n",
      "Ep:108, loss:0.00000, loss_test:0.02014, lr:4.71e-02, fs:0.76836 (r=0.687,p=0.872),  time:30.053, tt:3275.792\n",
      "Ep:109, loss:0.00000, loss_test:0.02124, lr:4.67e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.062, tt:3306.830\n",
      "Ep:110, loss:0.00000, loss_test:0.02045, lr:4.62e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.062, tt:3336.832\n",
      "Ep:111, loss:0.00000, loss_test:0.02024, lr:4.57e-02, fs:0.77528 (r=0.697,p=0.873),  time:30.067, tt:3367.524\n",
      "Ep:112, loss:0.00000, loss_test:0.02085, lr:4.53e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.074, tt:3398.398\n",
      "Ep:113, loss:0.00000, loss_test:0.02006, lr:4.48e-02, fs:0.77528 (r=0.697,p=0.873),  time:30.064, tt:3427.290\n",
      "Ep:114, loss:0.00000, loss_test:0.02041, lr:4.44e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.076, tt:3458.789\n",
      "Ep:115, loss:0.00000, loss_test:0.02092, lr:4.39e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.085, tt:3489.905\n",
      "Ep:116, loss:0.00000, loss_test:0.01966, lr:4.35e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.092, tt:3520.706\n",
      "Ep:117, loss:0.00000, loss_test:0.02172, lr:4.31e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.102, tt:3552.046\n",
      "Ep:118, loss:0.00000, loss_test:0.01993, lr:4.26e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.108, tt:3582.901\n",
      "Ep:119, loss:0.00000, loss_test:0.02127, lr:4.22e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.122, tt:3614.636\n",
      "Ep:120, loss:0.00000, loss_test:0.02095, lr:4.18e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.118, tt:3644.263\n",
      "Ep:121, loss:0.00000, loss_test:0.02115, lr:4.14e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.125, tt:3675.190\n",
      "Ep:122, loss:0.00000, loss_test:0.02105, lr:4.10e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.137, tt:3706.906\n",
      "Ep:123, loss:0.00000, loss_test:0.02114, lr:4.05e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.145, tt:3737.925\n",
      "Ep:124, loss:0.00000, loss_test:0.02112, lr:4.01e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.152, tt:3768.949\n",
      "Ep:125, loss:0.00000, loss_test:0.02167, lr:3.97e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.162, tt:3800.444\n",
      "Ep:126, loss:0.00000, loss_test:0.02048, lr:3.93e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.174, tt:3832.075\n",
      "Ep:127, loss:0.00000, loss_test:0.02179, lr:3.89e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.181, tt:3863.190\n",
      "Ep:128, loss:0.00000, loss_test:0.02086, lr:3.86e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.189, tt:3894.412\n",
      "Ep:129, loss:0.00000, loss_test:0.02229, lr:3.82e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.192, tt:3924.980\n",
      "Ep:130, loss:0.00000, loss_test:0.02079, lr:3.78e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.204, tt:3956.699\n",
      "Ep:131, loss:0.00000, loss_test:0.02225, lr:3.74e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.212, tt:3987.926\n",
      "Ep:132, loss:0.00000, loss_test:0.02140, lr:3.70e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.221, tt:4019.342\n",
      "Ep:133, loss:0.00000, loss_test:0.02181, lr:3.67e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.222, tt:4049.812\n",
      "Ep:134, loss:0.00000, loss_test:0.02226, lr:3.63e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.232, tt:4081.289\n",
      "Ep:135, loss:0.00000, loss_test:0.02131, lr:3.59e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.244, tt:4113.118\n",
      "Ep:136, loss:0.00000, loss_test:0.02251, lr:3.56e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.257, tt:4145.214\n",
      "Ep:137, loss:0.00000, loss_test:0.02135, lr:3.52e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.262, tt:4176.114\n",
      "Ep:138, loss:0.00000, loss_test:0.02288, lr:3.49e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.264, tt:4206.627\n",
      "Ep:139, loss:0.00000, loss_test:0.02156, lr:3.45e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.268, tt:4237.556\n",
      "Ep:140, loss:0.00000, loss_test:0.02246, lr:3.42e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.279, tt:4269.377\n",
      "Ep:141, loss:0.00000, loss_test:0.02211, lr:3.38e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.292, tt:4301.496\n",
      "Ep:142, loss:0.00000, loss_test:0.02210, lr:3.35e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.298, tt:4332.632\n",
      "Ep:143, loss:0.00000, loss_test:0.02270, lr:3.32e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.305, tt:4363.876\n",
      "Ep:144, loss:0.00000, loss_test:0.02176, lr:3.28e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.310, tt:4395.012\n",
      "Ep:145, loss:0.00000, loss_test:0.02274, lr:3.25e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.321, tt:4426.902\n",
      "Ep:146, loss:0.00000, loss_test:0.02204, lr:3.22e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.334, tt:4459.114\n",
      "Ep:147, loss:0.00000, loss_test:0.02278, lr:3.19e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.361, tt:4493.397\n",
      "Ep:148, loss:0.00000, loss_test:0.02236, lr:3.15e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.381, tt:4526.765\n",
      "Ep:149, loss:0.00000, loss_test:0.02236, lr:3.12e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.389, tt:4558.405\n",
      "Ep:150, loss:0.00000, loss_test:0.02266, lr:3.09e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.406, tt:4591.290\n",
      "Ep:151, loss:0.00000, loss_test:0.02247, lr:3.06e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.406, tt:4621.718\n",
      "Ep:152, loss:0.00000, loss_test:0.02274, lr:3.03e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.398, tt:4650.964\n",
      "Ep:153, loss:0.00000, loss_test:0.02267, lr:3.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.404, tt:4682.223\n",
      "Ep:154, loss:0.00000, loss_test:0.02276, lr:2.97e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.409, tt:4713.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.02282, lr:2.94e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.411, tt:4744.043\n",
      "Ep:156, loss:0.00000, loss_test:0.02265, lr:2.91e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.404, tt:4773.488\n",
      "Ep:157, loss:0.00000, loss_test:0.02312, lr:2.88e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.402, tt:4803.474\n",
      "Ep:158, loss:0.00000, loss_test:0.02270, lr:2.85e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.396, tt:4832.957\n",
      "Ep:159, loss:0.00000, loss_test:0.02312, lr:2.82e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.396, tt:4863.300\n",
      "Ep:160, loss:0.00000, loss_test:0.02285, lr:2.80e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.403, tt:4894.887\n",
      "Ep:161, loss:0.00000, loss_test:0.02311, lr:2.77e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.397, tt:4924.273\n",
      "Ep:162, loss:0.00000, loss_test:0.02303, lr:2.74e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.401, tt:4955.310\n",
      "Ep:163, loss:0.00000, loss_test:0.02305, lr:2.71e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.401, tt:4985.769\n",
      "Ep:164, loss:0.00000, loss_test:0.02302, lr:2.69e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.406, tt:5016.922\n",
      "Ep:165, loss:0.00000, loss_test:0.02324, lr:2.66e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.404, tt:5047.142\n",
      "Ep:166, loss:0.00000, loss_test:0.02322, lr:2.63e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.408, tt:5078.122\n",
      "Ep:167, loss:0.00000, loss_test:0.02322, lr:2.61e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.411, tt:5109.000\n",
      "Ep:168, loss:0.00000, loss_test:0.02326, lr:2.58e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.408, tt:5138.996\n",
      "Ep:169, loss:0.00000, loss_test:0.02323, lr:2.55e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.405, tt:5168.885\n",
      "Ep:170, loss:0.00000, loss_test:0.02341, lr:2.53e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.403, tt:5198.985\n",
      "Ep:171, loss:0.00000, loss_test:0.02322, lr:2.50e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.403, tt:5229.235\n",
      "Ep:172, loss:0.00000, loss_test:0.02344, lr:2.48e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.410, tt:5260.935\n",
      "Ep:173, loss:0.00000, loss_test:0.02345, lr:2.45e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.416, tt:5292.397\n",
      "Ep:174, loss:0.00000, loss_test:0.02337, lr:2.43e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.417, tt:5322.992\n",
      "Ep:175, loss:0.00000, loss_test:0.02352, lr:2.40e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.415, tt:5353.017\n",
      "Ep:176, loss:0.00000, loss_test:0.02348, lr:2.38e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.431, tt:5386.303\n",
      "Ep:177, loss:0.00000, loss_test:0.02344, lr:2.36e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.434, tt:5417.294\n",
      "Ep:178, loss:0.00000, loss_test:0.02366, lr:2.33e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.437, tt:5448.302\n",
      "Ep:179, loss:0.00000, loss_test:0.02349, lr:2.31e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.444, tt:5479.832\n",
      "Ep:180, loss:0.00000, loss_test:0.02368, lr:2.29e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.443, tt:5510.227\n",
      "Ep:181, loss:0.00000, loss_test:0.02361, lr:2.26e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.440, tt:5540.095\n",
      "Ep:182, loss:0.00000, loss_test:0.02364, lr:2.24e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.442, tt:5570.959\n",
      "Ep:183, loss:0.00000, loss_test:0.02376, lr:2.22e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.444, tt:5601.645\n",
      "Ep:184, loss:0.00000, loss_test:0.02354, lr:2.20e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.448, tt:5632.805\n",
      "Ep:185, loss:0.00000, loss_test:0.02381, lr:2.17e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.452, tt:5664.153\n",
      "Ep:186, loss:0.00000, loss_test:0.02374, lr:2.15e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.453, tt:5694.641\n",
      "Ep:187, loss:0.00000, loss_test:0.02367, lr:2.13e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.458, tt:5726.065\n",
      "Ep:188, loss:0.00000, loss_test:0.02382, lr:2.11e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.458, tt:5756.525\n",
      "Ep:189, loss:0.00000, loss_test:0.02373, lr:2.09e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.460, tt:5787.337\n",
      "Ep:190, loss:0.00000, loss_test:0.02385, lr:2.07e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.462, tt:5818.308\n",
      "Ep:191, loss:0.00000, loss_test:0.02381, lr:2.05e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.465, tt:5849.264\n",
      "Ep:192, loss:0.00000, loss_test:0.02380, lr:2.03e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.468, tt:5880.419\n",
      "Ep:193, loss:0.00000, loss_test:0.02395, lr:2.01e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.461, tt:5909.475\n",
      "Ep:194, loss:0.00000, loss_test:0.02391, lr:1.99e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.463, tt:5940.366\n",
      "Ep:195, loss:0.00000, loss_test:0.02391, lr:1.97e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.460, tt:5970.203\n",
      "Ep:196, loss:0.00000, loss_test:0.02392, lr:1.95e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.461, tt:6000.797\n",
      "Ep:197, loss:0.00000, loss_test:0.02393, lr:1.93e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.460, tt:6031.043\n",
      "Ep:198, loss:0.00000, loss_test:0.02399, lr:1.91e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.453, tt:6060.223\n",
      "Ep:199, loss:0.00000, loss_test:0.02400, lr:1.89e-02, fs:0.79769 (r=0.697,p=0.932),  time:30.440, tt:6088.080\n",
      "Ep:200, loss:0.00000, loss_test:0.02399, lr:1.87e-02, fs:0.79310 (r=0.697,p=0.920),  time:30.433, tt:6117.016\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.12098, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:24.620, tt:24.620\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.11892, lr:1.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:26.243, tt:52.485\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.11733, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:25.674, tt:77.021\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.11703, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:25.972, tt:103.888\n",
      "Ep:4, loss:0.00027, loss_test:0.11660, lr:1.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:26.727, tt:133.636\n",
      "Ep:5, loss:0.00026, loss_test:0.11544, lr:1.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:27.411, tt:164.464\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.11325, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:27.939, tt:195.575\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.11141, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:28.315, tt:226.521\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.10935, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:28.977, tt:260.795\n",
      "Ep:9, loss:0.00026, loss_test:0.10783, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:29.059, tt:290.591\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.10682, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:29.137, tt:320.509\n",
      "Ep:11, loss:0.00025, loss_test:0.10627, lr:1.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:29.178, tt:350.141\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.10612, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:29.364, tt:381.726\n",
      "Ep:13, loss:0.00025, loss_test:0.10522, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:29.426, tt:411.959\n",
      "Ep:14, loss:0.00024, loss_test:0.10325, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:29.516, tt:442.742\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.10181, lr:1.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:29.644, tt:474.301\n",
      "Ep:16, loss:0.00023, loss_test:0.09993, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:29.760, tt:505.923\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.09805, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:29.816, tt:536.686\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.09658, lr:1.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:29.869, tt:567.510\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.09446, lr:1.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.926, tt:598.527\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00022, loss_test:0.09272, lr:1.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:29.964, tt:629.249\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.08982, lr:1.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:30.038, tt:660.843\n",
      "Ep:22, loss:0.00021, loss_test:0.08748, lr:1.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:30.181, tt:694.153\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.08568, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:30.243, tt:725.822\n",
      "Ep:24, loss:0.00020, loss_test:0.08513, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:30.221, tt:755.525\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00020, loss_test:0.08261, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:30.293, tt:787.619\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00020, loss_test:0.08126, lr:1.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:30.301, tt:818.124\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.08104, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.289, tt:848.094\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.07924, lr:1.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.334, tt:879.694\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00018, loss_test:0.07781, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.356, tt:910.686\n",
      "Ep:30, loss:0.00018, loss_test:0.07856, lr:1.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:30.409, tt:942.682\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.07722, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:30.411, tt:973.155\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00017, loss_test:0.07484, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:30.386, tt:1002.734\n",
      "Ep:33, loss:0.00016, loss_test:0.07890, lr:1.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:30.404, tt:1033.749\n",
      "Ep:34, loss:0.00015, loss_test:0.07525, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:30.434, tt:1065.176\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00015, loss_test:0.08112, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:30.473, tt:1097.041\n",
      "Ep:36, loss:0.00014, loss_test:0.07454, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:30.536, tt:1129.825\n",
      "Ep:37, loss:0.00014, loss_test:0.08537, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:30.536, tt:1160.380\n",
      "Ep:38, loss:0.00013, loss_test:0.07314, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.563, tt:1191.949\n",
      "Ep:39, loss:0.00013, loss_test:0.07495, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:30.603, tt:1224.109\n",
      "Ep:40, loss:0.00012, loss_test:0.09203, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:30.616, tt:1255.269\n",
      "Ep:41, loss:0.00012, loss_test:0.06985, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.622, tt:1286.141\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.06911, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.640, tt:1317.510\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.08610, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:30.644, tt:1348.334\n",
      "Ep:44, loss:0.00010, loss_test:0.08018, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.674, tt:1380.312\n",
      "Ep:45, loss:0.00009, loss_test:0.07820, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:30.653, tt:1410.049\n",
      "Ep:46, loss:0.00009, loss_test:0.08041, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.676, tt:1441.773\n",
      "Ep:47, loss:0.00008, loss_test:0.07448, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.650, tt:1471.188\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.07139, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.647, tt:1501.724\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.07729, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:30.672, tt:1533.625\n",
      "Ep:50, loss:0.00007, loss_test:0.07876, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.694, tt:1565.399\n",
      "Ep:51, loss:0.00008, loss_test:0.09536, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:30.692, tt:1595.997\n",
      "Ep:52, loss:0.00009, loss_test:0.07598, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.694, tt:1626.782\n",
      "Ep:53, loss:0.00007, loss_test:0.08308, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.703, tt:1657.981\n",
      "Ep:54, loss:0.00006, loss_test:0.07225, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.724, tt:1689.802\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.08206, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.756, tt:1722.310\n",
      "Ep:56, loss:0.00006, loss_test:0.07607, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.742, tt:1752.322\n",
      "Ep:57, loss:0.00006, loss_test:0.09348, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.753, tt:1783.701\n",
      "Ep:58, loss:0.00007, loss_test:0.07684, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.756, tt:1814.600\n",
      "Ep:59, loss:0.00006, loss_test:0.08110, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:30.739, tt:1844.311\n",
      "Ep:60, loss:0.00006, loss_test:0.08336, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.734, tt:1874.744\n",
      "Ep:61, loss:0.00006, loss_test:0.07495, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.738, tt:1905.757\n",
      "Ep:62, loss:0.00005, loss_test:0.08240, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:30.744, tt:1936.848\n",
      "Ep:63, loss:0.00005, loss_test:0.08086, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.718, tt:1965.940\n",
      "Ep:64, loss:0.00005, loss_test:0.07817, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.712, tt:1996.286\n",
      "Ep:65, loss:0.00004, loss_test:0.07780, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.711, tt:2026.910\n",
      "Ep:66, loss:0.00004, loss_test:0.08378, lr:9.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:30.719, tt:2058.195\n",
      "Ep:67, loss:0.00004, loss_test:0.07533, lr:9.80e-03, fs:0.85106 (r=0.808,p=0.899),  time:30.725, tt:2089.326\n",
      "Ep:68, loss:0.00003, loss_test:0.07757, lr:9.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:30.738, tt:2120.922\n",
      "Ep:69, loss:0.00003, loss_test:0.08125, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.760, tt:2153.202\n",
      "Ep:70, loss:0.00003, loss_test:0.08187, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:30.769, tt:2184.608\n",
      "Ep:71, loss:0.00003, loss_test:0.08355, lr:9.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.770, tt:2215.414\n",
      "Ep:72, loss:0.00003, loss_test:0.07861, lr:9.32e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.778, tt:2246.800\n",
      "Ep:73, loss:0.00003, loss_test:0.08477, lr:9.23e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.793, tt:2278.678\n",
      "Ep:74, loss:0.00003, loss_test:0.08267, lr:9.14e-03, fs:0.78161 (r=0.687,p=0.907),  time:30.800, tt:2309.966\n",
      "Ep:75, loss:0.00002, loss_test:0.08848, lr:9.04e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.833, tt:2343.291\n",
      "Ep:76, loss:0.00002, loss_test:0.07893, lr:8.95e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.836, tt:2374.349\n",
      "Ep:77, loss:0.00002, loss_test:0.08331, lr:8.86e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.831, tt:2404.848\n",
      "Ep:78, loss:0.00002, loss_test:0.08158, lr:8.78e-03, fs:0.78161 (r=0.687,p=0.907),  time:30.814, tt:2434.331\n",
      "Ep:79, loss:0.00002, loss_test:0.08325, lr:8.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.817, tt:2465.393\n",
      "Ep:80, loss:0.00002, loss_test:0.08279, lr:8.60e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.828, tt:2497.088\n",
      "Ep:81, loss:0.00002, loss_test:0.08204, lr:8.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:30.829, tt:2527.948\n",
      "Ep:82, loss:0.00002, loss_test:0.08474, lr:8.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.836, tt:2559.419\n",
      "Ep:83, loss:0.00002, loss_test:0.08112, lr:8.35e-03, fs:0.76471 (r=0.657,p=0.915),  time:30.831, tt:2589.818\n",
      "Ep:84, loss:0.00002, loss_test:0.08946, lr:8.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.817, tt:2619.488\n",
      "Ep:85, loss:0.00002, loss_test:0.08439, lr:8.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:30.811, tt:2649.747\n",
      "Ep:86, loss:0.00002, loss_test:0.08340, lr:8.10e-03, fs:0.77907 (r=0.677,p=0.918),  time:30.823, tt:2681.631\n",
      "Ep:87, loss:0.00001, loss_test:0.08469, lr:8.02e-03, fs:0.76471 (r=0.657,p=0.915),  time:30.848, tt:2714.649\n",
      "Ep:88, loss:0.00001, loss_test:0.08510, lr:7.94e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.858, tt:2746.320\n",
      "Ep:89, loss:0.00001, loss_test:0.08017, lr:7.86e-03, fs:0.76471 (r=0.657,p=0.915),  time:30.857, tt:2777.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.08711, lr:7.78e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.864, tt:2808.606\n",
      "Ep:91, loss:0.00001, loss_test:0.07925, lr:7.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:30.864, tt:2839.446\n",
      "Ep:92, loss:0.00001, loss_test:0.08513, lr:7.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:30.877, tt:2871.543\n",
      "Ep:93, loss:0.00001, loss_test:0.08359, lr:7.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:30.875, tt:2902.281\n",
      "Ep:94, loss:0.00001, loss_test:0.07913, lr:7.47e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.883, tt:2933.907\n",
      "Ep:95, loss:0.00001, loss_test:0.08467, lr:7.40e-03, fs:0.76923 (r=0.657,p=0.929),  time:30.892, tt:2965.658\n",
      "Ep:96, loss:0.00001, loss_test:0.08638, lr:7.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:30.891, tt:2996.433\n",
      "Ep:97, loss:0.00001, loss_test:0.08421, lr:7.25e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.892, tt:3027.417\n",
      "Ep:98, loss:0.00001, loss_test:0.08387, lr:7.18e-03, fs:0.78824 (r=0.677,p=0.944),  time:30.901, tt:3059.204\n",
      "Ep:99, loss:0.00001, loss_test:0.08480, lr:7.11e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.900, tt:3089.957\n",
      "Ep:100, loss:0.00001, loss_test:0.08204, lr:7.03e-03, fs:0.79070 (r=0.687,p=0.932),  time:30.912, tt:3122.120\n",
      "Ep:101, loss:0.00001, loss_test:0.08436, lr:6.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.907, tt:3152.483\n",
      "Ep:102, loss:0.00001, loss_test:0.08336, lr:6.89e-03, fs:0.78107 (r=0.667,p=0.943),  time:30.922, tt:3184.952\n",
      "Ep:103, loss:0.00001, loss_test:0.08366, lr:6.83e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.949, tt:3218.666\n",
      "Ep:104, loss:0.00001, loss_test:0.08101, lr:6.76e-03, fs:0.75294 (r=0.646,p=0.901),  time:30.942, tt:3248.879\n",
      "Ep:105, loss:0.00001, loss_test:0.08489, lr:6.69e-03, fs:0.75449 (r=0.636,p=0.926),  time:30.938, tt:3279.415\n",
      "Ep:106, loss:0.00001, loss_test:0.08403, lr:6.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.938, tt:3310.405\n",
      "Ep:107, loss:0.00001, loss_test:0.08284, lr:6.56e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.943, tt:3341.862\n",
      "Ep:108, loss:0.00001, loss_test:0.08409, lr:6.49e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.932, tt:3371.592\n",
      "Ep:109, loss:0.00001, loss_test:0.08551, lr:6.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.931, tt:3402.421\n",
      "Ep:110, loss:0.00001, loss_test:0.08522, lr:6.36e-03, fs:0.76364 (r=0.636,p=0.955),  time:30.934, tt:3433.665\n",
      "Ep:111, loss:0.00001, loss_test:0.08354, lr:6.30e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.928, tt:3463.901\n",
      "Ep:112, loss:0.00001, loss_test:0.08586, lr:6.24e-03, fs:0.75610 (r=0.626,p=0.954),  time:30.942, tt:3496.421\n",
      "Ep:113, loss:0.00001, loss_test:0.08668, lr:6.17e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.947, tt:3527.990\n",
      "Ep:114, loss:0.00001, loss_test:0.08545, lr:6.11e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.950, tt:3559.250\n",
      "Ep:115, loss:0.00001, loss_test:0.08491, lr:6.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.956, tt:3590.906\n",
      "Ep:116, loss:0.00001, loss_test:0.08553, lr:5.99e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.953, tt:3621.556\n",
      "Ep:117, loss:0.00001, loss_test:0.08466, lr:5.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.960, tt:3653.241\n",
      "Ep:118, loss:0.00001, loss_test:0.08412, lr:5.87e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.957, tt:3683.845\n",
      "Ep:119, loss:0.00001, loss_test:0.08664, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:30.953, tt:3714.319\n",
      "Ep:120, loss:0.00001, loss_test:0.08686, lr:5.75e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.953, tt:3745.335\n",
      "Ep:121, loss:0.00001, loss_test:0.08549, lr:5.70e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.950, tt:3775.955\n",
      "Ep:122, loss:0.00001, loss_test:0.08486, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:30.960, tt:3808.090\n",
      "Ep:123, loss:0.00001, loss_test:0.08618, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.956, tt:3838.594\n",
      "Ep:124, loss:0.00001, loss_test:0.08678, lr:5.53e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.962, tt:3870.266\n",
      "Ep:125, loss:0.00001, loss_test:0.08681, lr:5.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:30.955, tt:3900.331\n",
      "Ep:126, loss:0.00001, loss_test:0.08571, lr:5.42e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.957, tt:3931.582\n",
      "Ep:127, loss:0.00001, loss_test:0.08541, lr:5.36e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.960, tt:3962.917\n",
      "Ep:128, loss:0.00001, loss_test:0.08606, lr:5.31e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.967, tt:3994.684\n",
      "Ep:129, loss:0.00001, loss_test:0.08616, lr:5.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.967, tt:4025.719\n",
      "Ep:130, loss:0.00001, loss_test:0.08636, lr:5.20e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.970, tt:4057.084\n",
      "Ep:131, loss:0.00001, loss_test:0.08723, lr:5.15e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.979, tt:4089.278\n",
      "Ep:132, loss:0.00001, loss_test:0.08465, lr:5.10e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.995, tt:4122.285\n",
      "Ep:133, loss:0.00001, loss_test:0.08722, lr:5.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.000, tt:4154.009\n",
      "Ep:134, loss:0.00001, loss_test:0.08676, lr:5.00e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.005, tt:4185.654\n",
      "Ep:135, loss:0.00001, loss_test:0.08752, lr:4.95e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.020, tt:4218.658\n",
      "Ep:136, loss:0.00001, loss_test:0.08569, lr:4.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.034, tt:4251.625\n",
      "Ep:137, loss:0.00001, loss_test:0.08556, lr:4.85e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.029, tt:4281.968\n",
      "Ep:138, loss:0.00001, loss_test:0.08809, lr:4.80e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.037, tt:4314.191\n",
      "Ep:139, loss:0.00001, loss_test:0.08726, lr:4.75e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.046, tt:4346.452\n",
      "Ep:140, loss:0.00001, loss_test:0.08619, lr:4.71e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.048, tt:4377.761\n",
      "Ep:141, loss:0.00001, loss_test:0.08500, lr:4.66e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.055, tt:4409.765\n",
      "Ep:142, loss:0.00001, loss_test:0.08731, lr:4.61e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.060, tt:4441.584\n",
      "Ep:143, loss:0.00001, loss_test:0.08829, lr:4.57e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.054, tt:4471.805\n",
      "Ep:144, loss:0.00001, loss_test:0.08631, lr:4.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.059, tt:4503.518\n",
      "Ep:145, loss:0.00000, loss_test:0.08596, lr:4.48e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.071, tt:4536.370\n",
      "Ep:146, loss:0.00000, loss_test:0.08680, lr:4.43e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.077, tt:4568.384\n",
      "Ep:147, loss:0.00000, loss_test:0.08667, lr:4.39e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.071, tt:4598.560\n",
      "Ep:148, loss:0.00000, loss_test:0.08643, lr:4.34e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.088, tt:4632.174\n",
      "Ep:149, loss:0.00000, loss_test:0.08699, lr:4.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.085, tt:4662.729\n",
      "Ep:150, loss:0.00000, loss_test:0.08817, lr:4.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.092, tt:4694.851\n",
      "Ep:151, loss:0.00000, loss_test:0.08809, lr:4.21e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.088, tt:4725.378\n",
      "Ep:152, loss:0.00000, loss_test:0.08910, lr:4.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.079, tt:4755.054\n",
      "Ep:153, loss:0.00000, loss_test:0.08757, lr:4.13e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.073, tt:4785.311\n",
      "Ep:154, loss:0.00000, loss_test:0.08838, lr:4.09e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.077, tt:4816.937\n",
      "Ep:155, loss:0.00000, loss_test:0.08757, lr:4.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.080, tt:4848.540\n",
      "Ep:156, loss:0.00000, loss_test:0.08709, lr:4.01e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.075, tt:4878.782\n",
      "Ep:157, loss:0.00000, loss_test:0.08954, lr:3.97e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.076, tt:4910.039\n",
      "Ep:158, loss:0.00000, loss_test:0.08861, lr:3.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.082, tt:4942.095\n",
      "Ep:159, loss:0.00000, loss_test:0.08888, lr:3.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.093, tt:4974.942\n",
      "Ep:160, loss:0.00000, loss_test:0.08790, lr:3.85e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.103, tt:5007.575\n",
      "Ep:161, loss:0.00000, loss_test:0.08927, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.109, tt:5039.727\n",
      "Ep:162, loss:0.00000, loss_test:0.08856, lr:3.77e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.117, tt:5072.025\n",
      "Ep:163, loss:0.00000, loss_test:0.08899, lr:3.73e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.121, tt:5103.860\n",
      "Ep:164, loss:0.00000, loss_test:0.08753, lr:3.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.115, tt:5133.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:165, loss:0.00000, loss_test:0.08784, lr:3.66e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.103, tt:5163.126\n",
      "Ep:166, loss:0.00000, loss_test:0.08776, lr:3.62e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.099, tt:5193.483\n",
      "Ep:167, loss:0.00000, loss_test:0.08900, lr:3.59e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.101, tt:5224.890\n",
      "Ep:168, loss:0.00000, loss_test:0.08932, lr:3.55e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.101, tt:5256.061\n",
      "Ep:169, loss:0.00000, loss_test:0.08777, lr:3.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.094, tt:5285.961\n",
      "Ep:170, loss:0.00000, loss_test:0.08901, lr:3.48e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.106, tt:5319.154\n",
      "Ep:171, loss:0.00000, loss_test:0.08825, lr:3.45e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.105, tt:5350.056\n",
      "Ep:172, loss:0.00000, loss_test:0.08791, lr:3.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.105, tt:5381.180\n",
      "Ep:173, loss:0.00000, loss_test:0.08834, lr:3.38e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.103, tt:5411.859\n",
      "Ep:174, loss:0.00000, loss_test:0.08789, lr:3.34e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.104, tt:5443.186\n",
      "Ep:175, loss:0.00000, loss_test:0.08779, lr:3.31e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.105, tt:5474.466\n",
      "Ep:176, loss:0.00000, loss_test:0.08695, lr:3.28e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.102, tt:5505.002\n",
      "Ep:177, loss:0.00000, loss_test:0.08703, lr:3.24e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.099, tt:5535.644\n",
      "Ep:178, loss:0.00000, loss_test:0.08653, lr:3.21e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.095, tt:5565.920\n",
      "Ep:179, loss:0.00000, loss_test:0.08779, lr:3.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.098, tt:5597.655\n",
      "Ep:180, loss:0.00000, loss_test:0.08818, lr:3.15e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.089, tt:5627.031\n",
      "Ep:181, loss:0.00000, loss_test:0.08820, lr:3.12e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.089, tt:5658.143\n",
      "Ep:182, loss:0.00000, loss_test:0.08760, lr:3.09e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.083, tt:5688.103\n",
      "Ep:183, loss:0.00000, loss_test:0.08729, lr:3.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.079, tt:5718.620\n",
      "Ep:184, loss:0.00000, loss_test:0.08730, lr:3.02e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.075, tt:5748.803\n",
      "Ep:185, loss:0.00000, loss_test:0.08687, lr:2.99e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.076, tt:5780.204\n",
      "Ep:186, loss:0.00000, loss_test:0.08697, lr:2.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.075, tt:5810.939\n",
      "Ep:187, loss:0.00000, loss_test:0.08691, lr:2.93e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.075, tt:5842.023\n",
      "Ep:188, loss:0.00000, loss_test:0.08825, lr:2.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.076, tt:5873.293\n",
      "Ep:189, loss:0.00000, loss_test:0.08763, lr:2.88e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.072, tt:5903.752\n",
      "Ep:190, loss:0.00000, loss_test:0.08816, lr:2.85e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.064, tt:5933.211\n",
      "Ep:191, loss:0.00000, loss_test:0.08762, lr:2.82e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.064, tt:5964.199\n",
      "Ep:192, loss:0.00000, loss_test:0.08632, lr:2.79e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.052, tt:5992.955\n",
      "Ep:193, loss:0.00000, loss_test:0.08734, lr:2.76e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.049, tt:6023.459\n",
      "Ep:194, loss:0.00000, loss_test:0.08678, lr:2.73e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.042, tt:6053.258\n",
      "Ep:195, loss:0.00000, loss_test:0.08722, lr:2.71e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.043, tt:6084.394\n",
      "Ep:196, loss:0.00000, loss_test:0.08652, lr:2.68e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.040, tt:6114.870\n",
      "Ep:197, loss:0.00000, loss_test:0.08740, lr:2.65e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.032, tt:6144.425\n",
      "Ep:198, loss:0.00000, loss_test:0.08726, lr:2.63e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.039, tt:6176.670\n",
      "Ep:199, loss:0.00000, loss_test:0.08597, lr:2.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.013, tt:6202.576\n",
      "Ep:200, loss:0.00000, loss_test:0.08702, lr:2.57e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.990, tt:6228.973\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02043, lr:6.00e-02, fs:0.62447 (r=0.747,p=0.536),  time:24.666, tt:24.666\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02059, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:23.873, tt:47.746\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.677, tt:74.032\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02200, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.007, tt:104.026\n",
      "Ep:4, loss:0.00004, loss_test:0.02119, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.063, tt:135.316\n",
      "Ep:5, loss:0.00004, loss_test:0.02002, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:27.740, tt:166.438\n",
      "Ep:6, loss:0.00004, loss_test:0.01871, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:28.225, tt:197.573\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:28.640, tt:229.118\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01716, lr:6.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:29.062, tt:261.555\n",
      "Ep:9, loss:0.00004, loss_test:0.01710, lr:6.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:29.250, tt:292.498\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:29.272, tt:321.987\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:29.324, tt:351.893\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:29.535, tt:383.959\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01674, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:29.601, tt:414.409\n",
      "Ep:14, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:29.731, tt:445.972\n",
      "Ep:15, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:29.859, tt:477.747\n",
      "Ep:16, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:29.820, tt:506.939\n",
      "Ep:17, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:29.888, tt:537.982\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:30.064, tt:571.224\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:30.082, tt:601.638\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:30.119, tt:632.490\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:30.257, tt:665.649\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:30.325, tt:697.467\n",
      "Ep:23, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:30.375, tt:728.991\n",
      "Ep:24, loss:0.00003, loss_test:0.01654, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:30.435, tt:760.874\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:30.463, tt:792.029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:30.526, tt:824.212\n",
      "Ep:27, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:30.554, tt:855.523\n",
      "Ep:28, loss:0.00002, loss_test:0.01669, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:30.555, tt:886.089\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:30.531, tt:915.919\n",
      "Ep:30, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:30.601, tt:948.638\n",
      "Ep:31, loss:0.00002, loss_test:0.01671, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:30.629, tt:980.121\n",
      "Ep:32, loss:0.00002, loss_test:0.01671, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:30.654, tt:1011.596\n",
      "Ep:33, loss:0.00002, loss_test:0.01672, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:30.670, tt:1042.792\n",
      "Ep:34, loss:0.00002, loss_test:0.01675, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:30.778, tt:1077.222\n",
      "Ep:35, loss:0.00002, loss_test:0.01679, lr:6.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:30.772, tt:1107.800\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01677, lr:6.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:30.799, tt:1139.557\n",
      "Ep:37, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.844, tt:1172.067\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01675, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.831, tt:1202.411\n",
      "Ep:39, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.819, tt:1232.773\n",
      "Ep:40, loss:0.00002, loss_test:0.01678, lr:6.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:30.815, tt:1263.424\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01677, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:30.847, tt:1295.575\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01680, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.822, tt:1325.351\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01681, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.841, tt:1357.003\n",
      "Ep:44, loss:0.00002, loss_test:0.01682, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.833, tt:1387.494\n",
      "Ep:45, loss:0.00002, loss_test:0.01682, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.817, tt:1417.584\n",
      "Ep:46, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.795, tt:1447.372\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01687, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.784, tt:1477.613\n",
      "Ep:48, loss:0.00002, loss_test:0.01685, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.804, tt:1509.387\n",
      "Ep:49, loss:0.00002, loss_test:0.01689, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.807, tt:1540.366\n",
      "Ep:50, loss:0.00002, loss_test:0.01691, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.792, tt:1570.413\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01692, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.813, tt:1602.266\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01692, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.794, tt:1632.067\n",
      "Ep:53, loss:0.00002, loss_test:0.01695, lr:6.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:30.753, tt:1660.650\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01696, lr:6.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:30.752, tt:1691.370\n",
      "Ep:55, loss:0.00002, loss_test:0.01694, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:30.736, tt:1721.212\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01694, lr:6.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:30.726, tt:1751.356\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01696, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.701, tt:1780.660\n",
      "Ep:58, loss:0.00002, loss_test:0.01701, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.691, tt:1810.782\n",
      "Ep:59, loss:0.00002, loss_test:0.01703, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.692, tt:1841.546\n",
      "Ep:60, loss:0.00002, loss_test:0.01700, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.672, tt:1871.017\n",
      "Ep:61, loss:0.00002, loss_test:0.01705, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.652, tt:1900.395\n",
      "Ep:62, loss:0.00002, loss_test:0.01707, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.656, tt:1931.337\n",
      "Ep:63, loss:0.00001, loss_test:0.01708, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.665, tt:1962.561\n",
      "Ep:64, loss:0.00001, loss_test:0.01709, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.653, tt:1992.476\n",
      "Ep:65, loss:0.00001, loss_test:0.01710, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.643, tt:2022.467\n",
      "Ep:66, loss:0.00001, loss_test:0.01716, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.637, tt:2052.702\n",
      "Ep:67, loss:0.00001, loss_test:0.01718, lr:6.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.628, tt:2082.711\n",
      "Ep:68, loss:0.00001, loss_test:0.01716, lr:5.94e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.628, tt:2113.358\n",
      "Ep:69, loss:0.00001, loss_test:0.01717, lr:5.88e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.637, tt:2144.597\n",
      "Ep:70, loss:0.00001, loss_test:0.01718, lr:5.82e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.620, tt:2174.002\n",
      "Ep:71, loss:0.00001, loss_test:0.01720, lr:5.76e-02, fs:0.82234 (r=0.818,p=0.827),  time:30.601, tt:2203.266\n",
      "Ep:72, loss:0.00001, loss_test:0.01724, lr:5.71e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.597, tt:2233.564\n",
      "Ep:73, loss:0.00001, loss_test:0.01728, lr:5.65e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.603, tt:2264.591\n",
      "Ep:74, loss:0.00001, loss_test:0.01730, lr:5.59e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.603, tt:2295.222\n",
      "Ep:75, loss:0.00001, loss_test:0.01729, lr:5.54e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.601, tt:2325.685\n",
      "Ep:76, loss:0.00001, loss_test:0.01732, lr:5.48e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.597, tt:2355.979\n",
      "Ep:77, loss:0.00001, loss_test:0.01736, lr:5.43e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.622, tt:2388.538\n",
      "Ep:78, loss:0.00001, loss_test:0.01733, lr:5.37e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.620, tt:2418.970\n",
      "Ep:79, loss:0.00001, loss_test:0.01738, lr:5.32e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.603, tt:2448.250\n",
      "Ep:80, loss:0.00001, loss_test:0.01738, lr:5.27e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.603, tt:2478.877\n",
      "Ep:81, loss:0.00001, loss_test:0.01741, lr:5.21e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.610, tt:2509.984\n",
      "Ep:82, loss:0.00001, loss_test:0.01743, lr:5.16e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.610, tt:2540.660\n",
      "Ep:83, loss:0.00001, loss_test:0.01745, lr:5.11e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.625, tt:2572.483\n",
      "Ep:84, loss:0.00001, loss_test:0.01750, lr:5.06e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.611, tt:2601.954\n",
      "Ep:85, loss:0.00001, loss_test:0.01750, lr:5.01e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.592, tt:2630.902\n",
      "Ep:86, loss:0.00001, loss_test:0.01753, lr:4.96e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.567, tt:2659.329\n",
      "Ep:87, loss:0.00001, loss_test:0.01758, lr:4.91e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.562, tt:2689.464\n",
      "Ep:88, loss:0.00001, loss_test:0.01760, lr:4.86e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.556, tt:2719.467\n",
      "Ep:89, loss:0.00001, loss_test:0.01761, lr:4.81e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.556, tt:2750.001\n",
      "Ep:90, loss:0.00001, loss_test:0.01764, lr:4.76e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.553, tt:2780.365\n",
      "Ep:91, loss:0.00001, loss_test:0.01763, lr:4.71e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.539, tt:2809.599\n",
      "Ep:92, loss:0.00001, loss_test:0.01766, lr:4.67e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.546, tt:2840.790\n",
      "Ep:93, loss:0.00001, loss_test:0.01768, lr:4.62e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.576, tt:2874.129\n",
      "Ep:94, loss:0.00001, loss_test:0.01774, lr:4.57e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.584, tt:2905.512\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01770, lr:4.57e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.579, tt:2935.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00001, loss_test:0.01772, lr:4.57e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.577, tt:2965.985\n",
      "Ep:97, loss:0.00001, loss_test:0.01776, lr:4.57e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.587, tt:2997.507\n",
      "Ep:98, loss:0.00001, loss_test:0.01780, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.576, tt:3027.034\n",
      "Ep:99, loss:0.00001, loss_test:0.01782, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.574, tt:3057.358\n",
      "Ep:100, loss:0.00001, loss_test:0.01783, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.562, tt:3086.797\n",
      "Ep:101, loss:0.00001, loss_test:0.01787, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.551, tt:3116.164\n",
      "Ep:102, loss:0.00001, loss_test:0.01791, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.558, tt:3147.444\n",
      "Ep:103, loss:0.00001, loss_test:0.01792, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.553, tt:3177.475\n",
      "Ep:104, loss:0.00001, loss_test:0.01792, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.546, tt:3207.346\n",
      "Ep:105, loss:0.00001, loss_test:0.01796, lr:4.57e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.534, tt:3236.629\n",
      "Ep:106, loss:0.00001, loss_test:0.01798, lr:4.53e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.531, tt:3266.803\n",
      "Ep:107, loss:0.00001, loss_test:0.01800, lr:4.48e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.524, tt:3296.566\n",
      "Ep:108, loss:0.00001, loss_test:0.01801, lr:4.44e-02, fs:0.81283 (r=0.768,p=0.864),  time:30.523, tt:3327.021\n",
      "Ep:109, loss:0.00001, loss_test:0.01804, lr:4.39e-02, fs:0.80645 (r=0.758,p=0.862),  time:30.506, tt:3355.657\n",
      "Ep:110, loss:0.00001, loss_test:0.01808, lr:4.35e-02, fs:0.80645 (r=0.758,p=0.862),  time:30.494, tt:3384.801\n",
      "Ep:111, loss:0.00001, loss_test:0.01811, lr:4.31e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.483, tt:3414.140\n",
      "Ep:112, loss:0.00001, loss_test:0.01812, lr:4.26e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.481, tt:3444.343\n",
      "Ep:113, loss:0.00001, loss_test:0.01814, lr:4.22e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.466, tt:3473.112\n",
      "Ep:114, loss:0.00001, loss_test:0.01816, lr:4.18e-02, fs:0.78689 (r=0.727,p=0.857),  time:30.462, tt:3503.147\n",
      "Ep:115, loss:0.00001, loss_test:0.01820, lr:4.14e-02, fs:0.77778 (r=0.707,p=0.864),  time:30.470, tt:3534.520\n",
      "Ep:116, loss:0.00001, loss_test:0.01824, lr:4.10e-02, fs:0.77778 (r=0.707,p=0.864),  time:30.470, tt:3565.022\n",
      "Ep:117, loss:0.00001, loss_test:0.01824, lr:4.05e-02, fs:0.77348 (r=0.707,p=0.854),  time:30.470, tt:3595.493\n",
      "Ep:118, loss:0.00001, loss_test:0.01823, lr:4.01e-02, fs:0.77348 (r=0.707,p=0.854),  time:30.475, tt:3626.568\n",
      "Ep:119, loss:0.00001, loss_test:0.01827, lr:3.97e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.469, tt:3656.307\n",
      "Ep:120, loss:0.00001, loss_test:0.01832, lr:3.93e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.455, tt:3685.022\n",
      "Ep:121, loss:0.00001, loss_test:0.01833, lr:3.89e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.448, tt:3714.644\n",
      "Ep:122, loss:0.00001, loss_test:0.01834, lr:3.86e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.437, tt:3743.767\n",
      "Ep:123, loss:0.00001, loss_test:0.01838, lr:3.82e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.437, tt:3774.234\n",
      "Ep:124, loss:0.00001, loss_test:0.01840, lr:3.78e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.448, tt:3806.041\n",
      "Ep:125, loss:0.00001, loss_test:0.01839, lr:3.74e-02, fs:0.76667 (r=0.697,p=0.852),  time:30.454, tt:3837.207\n",
      "Ep:126, loss:0.00001, loss_test:0.01839, lr:3.70e-02, fs:0.75978 (r=0.687,p=0.850),  time:30.456, tt:3867.858\n",
      "Ep:127, loss:0.00001, loss_test:0.01845, lr:3.67e-02, fs:0.75978 (r=0.687,p=0.850),  time:30.451, tt:3897.769\n",
      "Ep:128, loss:0.00001, loss_test:0.01847, lr:3.63e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.450, tt:3928.044\n",
      "Ep:129, loss:0.00001, loss_test:0.01847, lr:3.59e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.457, tt:3959.436\n",
      "Ep:130, loss:0.00001, loss_test:0.01849, lr:3.56e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.461, tt:3990.333\n",
      "Ep:131, loss:0.00001, loss_test:0.01854, lr:3.52e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.467, tt:4021.644\n",
      "Ep:132, loss:0.00001, loss_test:0.01857, lr:3.49e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.458, tt:4050.931\n",
      "Ep:133, loss:0.00001, loss_test:0.01862, lr:3.45e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.444, tt:4079.435\n",
      "Ep:134, loss:0.00001, loss_test:0.01860, lr:3.42e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.435, tt:4108.717\n",
      "Ep:135, loss:0.00001, loss_test:0.01862, lr:3.38e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.414, tt:4136.252\n",
      "Ep:136, loss:0.00001, loss_test:0.01864, lr:3.35e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.445, tt:4170.999\n",
      "Ep:137, loss:0.00001, loss_test:0.01866, lr:3.32e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.429, tt:4199.200\n",
      "Ep:138, loss:0.00001, loss_test:0.01871, lr:3.28e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.422, tt:4228.615\n",
      "Ep:139, loss:0.00001, loss_test:0.01871, lr:3.25e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.415, tt:4258.129\n",
      "Ep:140, loss:0.00001, loss_test:0.01874, lr:3.22e-02, fs:0.73143 (r=0.646,p=0.842),  time:30.406, tt:4287.232\n",
      "Ep:141, loss:0.00001, loss_test:0.01876, lr:3.19e-02, fs:0.73143 (r=0.646,p=0.842),  time:30.402, tt:4317.102\n",
      "Ep:142, loss:0.00001, loss_test:0.01880, lr:3.15e-02, fs:0.73143 (r=0.646,p=0.842),  time:30.405, tt:4347.878\n",
      "Ep:143, loss:0.00001, loss_test:0.01882, lr:3.12e-02, fs:0.72414 (r=0.636,p=0.840),  time:30.412, tt:4379.273\n",
      "Ep:144, loss:0.00001, loss_test:0.01881, lr:3.09e-02, fs:0.72414 (r=0.636,p=0.840),  time:30.410, tt:4409.475\n",
      "Ep:145, loss:0.00001, loss_test:0.01885, lr:3.06e-02, fs:0.72414 (r=0.636,p=0.840),  time:30.413, tt:4440.242\n",
      "Ep:146, loss:0.00001, loss_test:0.01888, lr:3.03e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.422, tt:4472.033\n",
      "Ep:147, loss:0.00001, loss_test:0.01888, lr:3.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.426, tt:4503.012\n",
      "Ep:148, loss:0.00001, loss_test:0.01889, lr:2.97e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.420, tt:4532.598\n",
      "Ep:149, loss:0.00001, loss_test:0.01891, lr:2.94e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.426, tt:4563.915\n",
      "Ep:150, loss:0.00001, loss_test:0.01893, lr:2.91e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.423, tt:4593.851\n",
      "Ep:151, loss:0.00001, loss_test:0.01895, lr:2.88e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.422, tt:4624.169\n",
      "Ep:152, loss:0.00001, loss_test:0.01897, lr:2.85e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.420, tt:4654.328\n",
      "Ep:153, loss:0.00001, loss_test:0.01899, lr:2.82e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.403, tt:4682.086\n",
      "Ep:154, loss:0.00001, loss_test:0.01899, lr:2.80e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.404, tt:4712.552\n",
      "Ep:155, loss:0.00001, loss_test:0.01903, lr:2.77e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.407, tt:4743.504\n",
      "Ep:156, loss:0.00001, loss_test:0.01903, lr:2.74e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.403, tt:4773.259\n",
      "Ep:157, loss:0.00001, loss_test:0.01907, lr:2.71e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.393, tt:4802.101\n",
      "Ep:158, loss:0.00001, loss_test:0.01910, lr:2.69e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.382, tt:4830.804\n",
      "Ep:159, loss:0.00001, loss_test:0.01912, lr:2.66e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.385, tt:4861.603\n",
      "Ep:160, loss:0.00001, loss_test:0.01912, lr:2.63e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.383, tt:4891.602\n",
      "Ep:161, loss:0.00001, loss_test:0.01914, lr:2.61e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.382, tt:4921.893\n",
      "Ep:162, loss:0.00001, loss_test:0.01917, lr:2.58e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.371, tt:4950.535\n",
      "Ep:163, loss:0.00001, loss_test:0.01919, lr:2.55e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.373, tt:4981.250\n",
      "Ep:164, loss:0.00001, loss_test:0.01920, lr:2.53e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.384, tt:5013.281\n",
      "Ep:165, loss:0.00001, loss_test:0.01919, lr:2.50e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.379, tt:5042.973\n",
      "Ep:166, loss:0.00001, loss_test:0.01921, lr:2.48e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.376, tt:5072.837\n",
      "Ep:167, loss:0.00001, loss_test:0.01924, lr:2.45e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.369, tt:5101.908\n",
      "Ep:168, loss:0.00001, loss_test:0.01925, lr:2.43e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.364, tt:5131.556\n",
      "Ep:169, loss:0.00001, loss_test:0.01928, lr:2.40e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.357, tt:5160.768\n",
      "Ep:170, loss:0.00001, loss_test:0.01929, lr:2.38e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.356, tt:5190.864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:171, loss:0.00001, loss_test:0.01931, lr:2.36e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.353, tt:5220.699\n",
      "Ep:172, loss:0.00001, loss_test:0.01932, lr:2.33e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.359, tt:5252.118\n",
      "Ep:173, loss:0.00001, loss_test:0.01935, lr:2.31e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.355, tt:5281.744\n",
      "Ep:174, loss:0.00001, loss_test:0.01936, lr:2.29e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.375, tt:5315.589\n",
      "Ep:175, loss:0.00001, loss_test:0.01937, lr:2.26e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.375, tt:5346.083\n",
      "Ep:176, loss:0.00001, loss_test:0.01938, lr:2.24e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.374, tt:5376.150\n",
      "Ep:177, loss:0.00001, loss_test:0.01939, lr:2.22e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.373, tt:5406.306\n",
      "Ep:178, loss:0.00001, loss_test:0.01940, lr:2.20e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.375, tt:5437.126\n",
      "Ep:179, loss:0.00001, loss_test:0.01941, lr:2.17e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.379, tt:5468.240\n",
      "Ep:180, loss:0.00001, loss_test:0.01943, lr:2.15e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.380, tt:5498.828\n",
      "Ep:181, loss:0.00001, loss_test:0.01944, lr:2.13e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.380, tt:5529.210\n",
      "Ep:182, loss:0.00001, loss_test:0.01945, lr:2.11e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.374, tt:5558.408\n",
      "Ep:183, loss:0.00001, loss_test:0.01945, lr:2.09e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.376, tt:5589.128\n",
      "Ep:184, loss:0.00001, loss_test:0.01947, lr:2.07e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.375, tt:5619.399\n",
      "Ep:185, loss:0.00001, loss_test:0.01949, lr:2.05e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.373, tt:5649.394\n",
      "Ep:186, loss:0.00001, loss_test:0.01950, lr:2.03e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.369, tt:5679.056\n",
      "Ep:187, loss:0.00001, loss_test:0.01953, lr:2.01e-02, fs:0.70238 (r=0.596,p=0.855),  time:30.371, tt:5709.657\n",
      "Ep:188, loss:0.00001, loss_test:0.01953, lr:1.99e-02, fs:0.70238 (r=0.596,p=0.855),  time:30.367, tt:5739.424\n",
      "Ep:189, loss:0.00001, loss_test:0.01955, lr:1.97e-02, fs:0.70238 (r=0.596,p=0.855),  time:30.369, tt:5770.092\n",
      "Ep:190, loss:0.00001, loss_test:0.01957, lr:1.95e-02, fs:0.70238 (r=0.596,p=0.855),  time:30.371, tt:5800.851\n",
      "Ep:191, loss:0.00001, loss_test:0.01958, lr:1.93e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.370, tt:5831.029\n",
      "Ep:192, loss:0.00001, loss_test:0.01960, lr:1.91e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.372, tt:5861.724\n",
      "Ep:193, loss:0.00001, loss_test:0.01961, lr:1.89e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.371, tt:5891.915\n",
      "Ep:194, loss:0.00001, loss_test:0.01962, lr:1.87e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.367, tt:5921.562\n",
      "Ep:195, loss:0.00001, loss_test:0.01964, lr:1.85e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.369, tt:5952.248\n",
      "Ep:196, loss:0.00001, loss_test:0.01967, lr:1.83e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.362, tt:5981.251\n",
      "Ep:197, loss:0.00001, loss_test:0.01967, lr:1.81e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.370, tt:6013.290\n",
      "Ep:198, loss:0.00001, loss_test:0.01967, lr:1.80e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.372, tt:6043.929\n",
      "Ep:199, loss:0.00001, loss_test:0.01967, lr:1.78e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.366, tt:6073.288\n",
      "Ep:200, loss:0.00001, loss_test:0.01969, lr:1.76e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.363, tt:6103.062\n",
      "Ep:201, loss:0.00001, loss_test:0.01970, lr:1.74e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.363, tt:6133.287\n",
      "Ep:202, loss:0.00001, loss_test:0.01971, lr:1.73e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.365, tt:6164.002\n",
      "Ep:203, loss:0.00001, loss_test:0.01972, lr:1.71e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.359, tt:6193.265\n",
      "Ep:204, loss:0.00001, loss_test:0.01973, lr:1.69e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.347, tt:6221.112\n",
      "Ep:205, loss:0.00001, loss_test:0.01975, lr:1.67e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.342, tt:6250.403\n",
      "Ep:206, loss:0.00001, loss_test:0.01977, lr:1.66e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.356, tt:6283.641\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13794, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:24.393, tt:24.393\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13620, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:26.009, tt:52.019\n",
      "Ep:2, loss:0.00027, loss_test:0.13316, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:27.590, tt:82.771\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12808, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:28.823, tt:115.293\n",
      "Ep:4, loss:0.00026, loss_test:0.12055, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:28.888, tt:144.440\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11073, lr:1.00e-02, fs:0.67521 (r=0.798,p=0.585),  time:29.652, tt:177.910\n",
      "Ep:6, loss:0.00024, loss_test:0.10544, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:30.022, tt:210.153\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10369, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:30.195, tt:241.559\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10363, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:30.322, tt:272.900\n",
      "Ep:9, loss:0.00022, loss_test:0.10280, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:30.593, tt:305.928\n",
      "Ep:10, loss:0.00021, loss_test:0.09867, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:30.817, tt:338.991\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09676, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:30.835, tt:370.024\n",
      "Ep:12, loss:0.00020, loss_test:0.09634, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:30.821, tt:400.675\n",
      "Ep:13, loss:0.00019, loss_test:0.09631, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:30.887, tt:432.411\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09566, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:30.935, tt:464.021\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09445, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:31.061, tt:496.975\n",
      "Ep:16, loss:0.00018, loss_test:0.09416, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:31.193, tt:530.286\n",
      "Ep:17, loss:0.00017, loss_test:0.09385, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:31.285, tt:563.133\n",
      "Ep:18, loss:0.00017, loss_test:0.09272, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:31.352, tt:595.688\n",
      "Ep:19, loss:0.00016, loss_test:0.09209, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:31.418, tt:628.351\n",
      "Ep:20, loss:0.00016, loss_test:0.09057, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:31.493, tt:661.350\n",
      "Ep:21, loss:0.00015, loss_test:0.08896, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:31.566, tt:694.462\n",
      "Ep:22, loss:0.00015, loss_test:0.08848, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:31.656, tt:728.077\n",
      "Ep:23, loss:0.00014, loss_test:0.08757, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:31.639, tt:759.336\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08646, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:31.799, tt:794.964\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08623, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:31.832, tt:827.632\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08590, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:31.863, tt:860.305\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08415, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:31.873, tt:892.439\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08298, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:31.903, tt:925.189\n",
      "Ep:29, loss:0.00012, loss_test:0.08320, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:31.902, tt:957.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00012, loss_test:0.08279, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:31.879, tt:988.237\n",
      "Ep:31, loss:0.00012, loss_test:0.08155, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:31.911, tt:1021.156\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08086, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:31.876, tt:1051.892\n",
      "Ep:33, loss:0.00011, loss_test:0.08085, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:31.894, tt:1084.383\n",
      "Ep:34, loss:0.00011, loss_test:0.07914, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.871, tt:1115.494\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07910, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.917, tt:1149.020\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.07859, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.903, tt:1180.401\n",
      "Ep:37, loss:0.00010, loss_test:0.07689, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.906, tt:1212.428\n",
      "Ep:38, loss:0.00010, loss_test:0.07726, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:31.893, tt:1243.839\n",
      "Ep:42, loss:0.00009, loss_test:0.07387, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.881, tt:1370.869\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.07395, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.918, tt:1404.403\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.07345, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:31.925, tt:1436.628\n",
      "Ep:45, loss:0.00008, loss_test:0.07317, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.945, tt:1469.459\n",
      "Ep:46, loss:0.00008, loss_test:0.07261, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.974, tt:1502.801\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07294, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:31.964, tt:1534.282\n",
      "Ep:48, loss:0.00007, loss_test:0.07152, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:31.951, tt:1565.585\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.07319, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.975, tt:1598.761\n",
      "Ep:50, loss:0.00007, loss_test:0.07167, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.987, tt:1631.331\n",
      "Ep:51, loss:0.00007, loss_test:0.07141, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.984, tt:1663.166\n",
      "Ep:52, loss:0.00007, loss_test:0.07113, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.999, tt:1695.965\n",
      "Ep:53, loss:0.00007, loss_test:0.07057, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:32.014, tt:1728.752\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.07001, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.986, tt:1759.235\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.07047, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:31.994, tt:1791.659\n",
      "Ep:56, loss:0.00006, loss_test:0.07027, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:32.012, tt:1824.691\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.07147, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:32.038, tt:1858.187\n",
      "Ep:58, loss:0.00006, loss_test:0.07027, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:32.061, tt:1891.610\n",
      "Ep:59, loss:0.00006, loss_test:0.07129, lr:1.00e-02, fs:0.86188 (r=0.788,p=0.951),  time:32.053, tt:1923.155\n",
      "Ep:60, loss:0.00005, loss_test:0.06948, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:32.054, tt:1955.314\n",
      "Ep:61, loss:0.00005, loss_test:0.06908, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:32.052, tt:1987.248\n",
      "Ep:62, loss:0.00005, loss_test:0.06968, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:32.068, tt:2020.256\n",
      "Ep:63, loss:0.00005, loss_test:0.06865, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:32.097, tt:2054.187\n",
      "Ep:64, loss:0.00005, loss_test:0.07020, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:32.089, tt:2085.766\n",
      "Ep:65, loss:0.00005, loss_test:0.06922, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:32.114, tt:2119.525\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.06942, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:32.091, tt:2150.117\n",
      "Ep:67, loss:0.00005, loss_test:0.06939, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:32.092, tt:2182.268\n",
      "Ep:68, loss:0.00004, loss_test:0.06936, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:32.071, tt:2212.893\n",
      "Ep:69, loss:0.00004, loss_test:0.06886, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:32.086, tt:2246.004\n",
      "Ep:70, loss:0.00004, loss_test:0.06994, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:32.087, tt:2278.167\n",
      "Ep:71, loss:0.00004, loss_test:0.06819, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:32.052, tt:2307.779\n",
      "Ep:72, loss:0.00004, loss_test:0.07073, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:32.074, tt:2341.374\n",
      "Ep:73, loss:0.00004, loss_test:0.06742, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:32.068, tt:2373.034\n",
      "Ep:74, loss:0.00004, loss_test:0.07083, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:32.049, tt:2403.692\n",
      "Ep:75, loss:0.00004, loss_test:0.06825, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:32.055, tt:2436.202\n",
      "Ep:76, loss:0.00004, loss_test:0.06922, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:32.071, tt:2469.469\n",
      "Ep:77, loss:0.00004, loss_test:0.06957, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:32.045, tt:2499.512\n",
      "Ep:78, loss:0.00004, loss_test:0.06810, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.021, tt:2529.651\n",
      "Ep:79, loss:0.00004, loss_test:0.07011, lr:9.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.005, tt:2560.433\n",
      "Ep:80, loss:0.00003, loss_test:0.06985, lr:9.61e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.011, tt:2592.888\n",
      "Ep:81, loss:0.00003, loss_test:0.06799, lr:9.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.989, tt:2623.079\n",
      "Ep:82, loss:0.00003, loss_test:0.07016, lr:9.41e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.998, tt:2655.824\n",
      "Ep:83, loss:0.00003, loss_test:0.06908, lr:9.32e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.013, tt:2689.100\n",
      "Ep:84, loss:0.00003, loss_test:0.06785, lr:9.23e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.000, tt:2719.988\n",
      "Ep:85, loss:0.00003, loss_test:0.07044, lr:9.14e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.984, tt:2750.623\n",
      "Ep:86, loss:0.00003, loss_test:0.06719, lr:9.04e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.975, tt:2781.822\n",
      "Ep:87, loss:0.00003, loss_test:0.06929, lr:8.95e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.971, tt:2813.413\n",
      "Ep:88, loss:0.00003, loss_test:0.06913, lr:8.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.975, tt:2845.755\n",
      "Ep:89, loss:0.00003, loss_test:0.06757, lr:8.78e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.969, tt:2877.214\n",
      "Ep:90, loss:0.00003, loss_test:0.06836, lr:8.69e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.982, tt:2910.357\n",
      "Ep:91, loss:0.00003, loss_test:0.06928, lr:8.60e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.976, tt:2941.808\n",
      "Ep:92, loss:0.00003, loss_test:0.06848, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.985, tt:2974.615\n",
      "Ep:93, loss:0.00003, loss_test:0.06829, lr:8.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.980, tt:3006.116\n",
      "Ep:94, loss:0.00003, loss_test:0.07032, lr:8.35e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.978, tt:3037.867\n",
      "Ep:95, loss:0.00003, loss_test:0.06852, lr:8.26e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.987, tt:3070.733\n",
      "Ep:96, loss:0.00003, loss_test:0.06870, lr:8.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.984, tt:3102.444\n",
      "Ep:97, loss:0.00003, loss_test:0.06811, lr:8.10e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.993, tt:3135.335\n",
      "Ep:98, loss:0.00003, loss_test:0.06850, lr:8.02e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.012, tt:3169.236\n",
      "Ep:99, loss:0.00002, loss_test:0.06985, lr:7.94e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.018, tt:3201.807\n",
      "Ep:100, loss:0.00002, loss_test:0.06820, lr:7.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.023, tt:3234.301\n",
      "Ep:101, loss:0.00002, loss_test:0.06823, lr:7.78e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.021, tt:3266.115\n",
      "Ep:102, loss:0.00002, loss_test:0.06876, lr:7.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.031, tt:3299.155\n",
      "Ep:103, loss:0.00002, loss_test:0.06834, lr:7.62e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.032, tt:3331.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00002, loss_test:0.06808, lr:7.55e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.020, tt:3362.145\n",
      "Ep:105, loss:0.00002, loss_test:0.06800, lr:7.47e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.018, tt:3393.903\n",
      "Ep:106, loss:0.00002, loss_test:0.06833, lr:7.40e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.017, tt:3425.803\n",
      "Ep:107, loss:0.00002, loss_test:0.06818, lr:7.32e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.054, tt:3461.834\n",
      "Ep:108, loss:0.00002, loss_test:0.06765, lr:7.25e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.058, tt:3494.289\n",
      "Ep:109, loss:0.00002, loss_test:0.06856, lr:7.18e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.056, tt:3526.171\n",
      "Ep:110, loss:0.00002, loss_test:0.06806, lr:7.11e-03, fs:0.89130 (r=0.828,p=0.965),  time:32.058, tt:3558.485\n",
      "Ep:111, loss:0.00002, loss_test:0.06741, lr:7.03e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.033, tt:3587.654\n",
      "Ep:112, loss:0.00002, loss_test:0.06848, lr:6.96e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.020, tt:3618.307\n",
      "Ep:113, loss:0.00002, loss_test:0.06769, lr:6.89e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.018, tt:3650.018\n",
      "Ep:114, loss:0.00002, loss_test:0.06760, lr:6.83e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.017, tt:3681.998\n",
      "Ep:115, loss:0.00002, loss_test:0.06817, lr:6.76e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.016, tt:3713.881\n",
      "Ep:116, loss:0.00002, loss_test:0.06794, lr:6.69e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.002, tt:3744.221\n",
      "Ep:117, loss:0.00002, loss_test:0.06743, lr:6.62e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.010, tt:3777.156\n",
      "Ep:118, loss:0.00002, loss_test:0.06785, lr:6.56e-03, fs:0.88525 (r=0.818,p=0.964),  time:32.004, tt:3808.501\n",
      "Ep:119, loss:0.00002, loss_test:0.06844, lr:6.49e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.992, tt:3839.063\n",
      "Ep:120, loss:0.00002, loss_test:0.06739, lr:6.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.989, tt:3870.622\n",
      "Ep:121, loss:0.00002, loss_test:0.06801, lr:6.36e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.968, tt:3900.141\n",
      "Ep:122, loss:0.00002, loss_test:0.06807, lr:6.30e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.953, tt:3930.216\n",
      "Ep:123, loss:0.00002, loss_test:0.06696, lr:6.24e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.933, tt:3959.703\n",
      "Ep:124, loss:0.00002, loss_test:0.06766, lr:6.17e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.929, tt:3991.093\n",
      "Ep:125, loss:0.00002, loss_test:0.06806, lr:6.11e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.913, tt:4021.010\n",
      "Ep:126, loss:0.00002, loss_test:0.06762, lr:6.05e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.918, tt:4053.630\n",
      "Ep:127, loss:0.00002, loss_test:0.06747, lr:5.99e-03, fs:0.89130 (r=0.828,p=0.965),  time:31.907, tt:4084.141\n",
      "Ep:128, loss:0.00002, loss_test:0.06735, lr:5.93e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.914, tt:4116.911\n",
      "Ep:129, loss:0.00002, loss_test:0.06753, lr:5.87e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.908, tt:4148.014\n",
      "Ep:130, loss:0.00002, loss_test:0.06755, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.904, tt:4179.398\n",
      "Ep:131, loss:0.00002, loss_test:0.06769, lr:5.75e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.910, tt:4212.133\n",
      "Ep:132, loss:0.00002, loss_test:0.06786, lr:5.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.913, tt:4244.428\n",
      "Ep:133, loss:0.00002, loss_test:0.06810, lr:5.64e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.907, tt:4275.572\n",
      "Ep:134, loss:0.00001, loss_test:0.06775, lr:5.58e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.910, tt:4307.792\n",
      "Ep:135, loss:0.00001, loss_test:0.06765, lr:5.53e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.912, tt:4339.995\n",
      "Ep:136, loss:0.00001, loss_test:0.06815, lr:5.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.905, tt:4371.050\n",
      "Ep:137, loss:0.00001, loss_test:0.06777, lr:5.42e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.902, tt:4402.476\n",
      "Ep:138, loss:0.00001, loss_test:0.06757, lr:5.36e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.897, tt:4433.693\n",
      "Ep:139, loss:0.00001, loss_test:0.06840, lr:5.31e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.907, tt:4466.964\n",
      "Ep:140, loss:0.00001, loss_test:0.06831, lr:5.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.912, tt:4499.566\n",
      "Ep:141, loss:0.00001, loss_test:0.06755, lr:5.20e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.919, tt:4532.449\n",
      "Ep:142, loss:0.00001, loss_test:0.06863, lr:5.15e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.922, tt:4564.780\n",
      "Ep:143, loss:0.00001, loss_test:0.06862, lr:5.10e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.913, tt:4595.487\n",
      "Ep:144, loss:0.00001, loss_test:0.06796, lr:5.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.911, tt:4627.114\n",
      "Ep:145, loss:0.00001, loss_test:0.06787, lr:5.00e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.899, tt:4657.285\n",
      "Ep:146, loss:0.00001, loss_test:0.06848, lr:4.95e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.906, tt:4690.181\n",
      "Ep:147, loss:0.00001, loss_test:0.06806, lr:4.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.909, tt:4722.568\n",
      "Ep:148, loss:0.00001, loss_test:0.06807, lr:4.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.906, tt:4753.942\n",
      "Ep:149, loss:0.00001, loss_test:0.06830, lr:4.80e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.912, tt:4786.753\n",
      "Ep:150, loss:0.00001, loss_test:0.06825, lr:4.75e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.917, tt:4819.420\n",
      "Ep:151, loss:0.00001, loss_test:0.06804, lr:4.71e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.923, tt:4852.319\n",
      "Ep:152, loss:0.00001, loss_test:0.06815, lr:4.66e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.931, tt:4885.425\n",
      "Ep:153, loss:0.00001, loss_test:0.06871, lr:4.61e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.936, tt:4918.209\n",
      "Ep:154, loss:0.00001, loss_test:0.06851, lr:4.57e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.944, tt:4951.260\n",
      "Ep:155, loss:0.00001, loss_test:0.06832, lr:4.52e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.945, tt:4983.447\n",
      "Ep:156, loss:0.00001, loss_test:0.06859, lr:4.48e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.950, tt:5016.134\n",
      "Ep:157, loss:0.00001, loss_test:0.06867, lr:4.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.953, tt:5048.533\n",
      "Ep:158, loss:0.00001, loss_test:0.06849, lr:4.39e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.959, tt:5081.496\n",
      "Ep:159, loss:0.00001, loss_test:0.06890, lr:4.34e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.966, tt:5114.619\n",
      "Ep:160, loss:0.00001, loss_test:0.06913, lr:4.30e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.972, tt:5147.458\n",
      "Ep:161, loss:0.00001, loss_test:0.06866, lr:4.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.968, tt:5178.877\n",
      "Ep:162, loss:0.00001, loss_test:0.06848, lr:4.21e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.966, tt:5210.515\n",
      "Ep:163, loss:0.00001, loss_test:0.06951, lr:4.17e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.967, tt:5242.640\n",
      "Ep:164, loss:0.00001, loss_test:0.06929, lr:4.13e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.973, tt:5275.615\n",
      "Ep:165, loss:0.00001, loss_test:0.06854, lr:4.09e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.970, tt:5307.058\n",
      "Ep:166, loss:0.00001, loss_test:0.06918, lr:4.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.973, tt:5339.525\n",
      "Ep:167, loss:0.00001, loss_test:0.06939, lr:4.01e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.979, tt:5372.422\n",
      "Ep:168, loss:0.00001, loss_test:0.06892, lr:3.97e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.975, tt:5403.800\n",
      "Ep:169, loss:0.00001, loss_test:0.06843, lr:3.93e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.992, tt:5438.667\n",
      "Ep:170, loss:0.00001, loss_test:0.06898, lr:3.89e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.985, tt:5469.509\n",
      "Ep:171, loss:0.00001, loss_test:0.06902, lr:3.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.990, tt:5502.281\n",
      "Ep:172, loss:0.00001, loss_test:0.06850, lr:3.81e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.988, tt:5533.989\n",
      "Ep:173, loss:0.00001, loss_test:0.06869, lr:3.77e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.979, tt:5564.347\n",
      "Ep:174, loss:0.00001, loss_test:0.06879, lr:3.73e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.991, tt:5598.434\n",
      "Ep:175, loss:0.00001, loss_test:0.06853, lr:3.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.000, tt:5632.041\n",
      "Ep:176, loss:0.00001, loss_test:0.06863, lr:3.66e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.999, tt:5663.868\n",
      "Ep:177, loss:0.00001, loss_test:0.06862, lr:3.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.999, tt:5695.893\n",
      "Ep:178, loss:0.00001, loss_test:0.06856, lr:3.59e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.003, tt:5728.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:179, loss:0.00001, loss_test:0.06889, lr:3.55e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.011, tt:5761.896\n",
      "Ep:180, loss:0.00001, loss_test:0.06894, lr:3.52e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.014, tt:5794.446\n",
      "Ep:181, loss:0.00001, loss_test:0.06858, lr:3.48e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.019, tt:5827.388\n",
      "Ep:182, loss:0.00001, loss_test:0.06864, lr:3.45e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.012, tt:5858.107\n",
      "Ep:183, loss:0.00001, loss_test:0.06876, lr:3.41e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.006, tt:5889.022\n",
      "Ep:184, loss:0.00001, loss_test:0.06886, lr:3.38e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.013, tt:5922.452\n",
      "Ep:185, loss:0.00001, loss_test:0.06877, lr:3.34e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.013, tt:5954.443\n",
      "Ep:186, loss:0.00001, loss_test:0.06881, lr:3.31e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.016, tt:5986.971\n",
      "Ep:187, loss:0.00001, loss_test:0.06883, lr:3.28e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.015, tt:6018.779\n",
      "Ep:188, loss:0.00001, loss_test:0.06899, lr:3.24e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.007, tt:6049.339\n",
      "Ep:189, loss:0.00001, loss_test:0.06890, lr:3.21e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.006, tt:6081.116\n",
      "Ep:190, loss:0.00001, loss_test:0.06891, lr:3.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.022, tt:6116.218\n",
      "Ep:191, loss:0.00001, loss_test:0.06906, lr:3.15e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.015, tt:6146.802\n",
      "Ep:192, loss:0.00001, loss_test:0.06914, lr:3.12e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.015, tt:6178.804\n",
      "Ep:193, loss:0.00001, loss_test:0.06891, lr:3.09e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.017, tt:6211.395\n",
      "Ep:194, loss:0.00001, loss_test:0.06867, lr:3.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.013, tt:6242.622\n",
      "Ep:195, loss:0.00001, loss_test:0.06929, lr:3.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.022, tt:6276.294\n",
      "Ep:196, loss:0.00001, loss_test:0.06934, lr:2.99e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.020, tt:6307.960\n",
      "Ep:197, loss:0.00001, loss_test:0.06877, lr:2.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.016, tt:6339.071\n",
      "Ep:198, loss:0.00001, loss_test:0.06896, lr:2.93e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.020, tt:6371.982\n",
      "Ep:199, loss:0.00001, loss_test:0.06913, lr:2.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.028, tt:6405.528\n",
      "Ep:200, loss:0.00001, loss_test:0.06921, lr:2.88e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.033, tt:6438.715\n",
      "Ep:201, loss:0.00001, loss_test:0.06870, lr:2.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.035, tt:6471.062\n",
      "Ep:202, loss:0.00001, loss_test:0.06895, lr:2.82e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.033, tt:6502.708\n",
      "Ep:203, loss:0.00001, loss_test:0.06946, lr:2.79e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.025, tt:6533.144\n",
      "Ep:204, loss:0.00001, loss_test:0.06914, lr:2.76e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.999, tt:6559.748\n",
      "Ep:205, loss:0.00001, loss_test:0.06861, lr:2.73e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.986, tt:6589.111\n",
      "Ep:206, loss:0.00001, loss_test:0.06910, lr:2.71e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.971, tt:6617.918\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01919, lr:6.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:21.822, tt:21.822\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02040, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:23.726, tt:47.452\n",
      "Ep:2, loss:0.00004, loss_test:0.02197, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.882, tt:74.647\n",
      "Ep:3, loss:0.00004, loss_test:0.02193, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.088, tt:104.354\n",
      "Ep:4, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.189, tt:135.946\n",
      "Ep:5, loss:0.00004, loss_test:0.01976, lr:6.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:27.646, tt:165.873\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.69065 (r=0.970,p=0.536),  time:28.098, tt:196.686\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01799, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:28.177, tt:225.416\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01763, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:28.305, tt:254.747\n",
      "Ep:9, loss:0.00004, loss_test:0.01740, lr:6.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:28.490, tt:284.898\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01715, lr:6.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:28.581, tt:314.396\n",
      "Ep:11, loss:0.00004, loss_test:0.01702, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:28.607, tt:343.287\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01694, lr:6.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:28.616, tt:372.012\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01684, lr:6.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:28.765, tt:402.706\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01664, lr:6.00e-02, fs:0.72727 (r=0.970,p=0.582),  time:29.053, tt:435.800\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.74131 (r=0.970,p=0.600),  time:29.165, tt:466.637\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:29.318, tt:498.401\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:29.325, tt:527.842\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:29.409, tt:558.767\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:29.434, tt:588.672\n",
      "Ep:20, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:29.497, tt:619.442\n",
      "Ep:21, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:29.548, tt:650.057\n",
      "Ep:22, loss:0.00003, loss_test:0.01560, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:29.617, tt:681.196\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:29.691, tt:712.573\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01542, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:29.754, tt:743.852\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:29.815, tt:775.181\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01534, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:29.853, tt:806.033\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:29.830, tt:835.230\n",
      "Ep:28, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:29.842, tt:865.413\n",
      "Ep:29, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:29.817, tt:894.521\n",
      "Ep:30, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:29.811, tt:924.131\n",
      "Ep:31, loss:0.00002, loss_test:0.01525, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:29.850, tt:955.213\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:29.861, tt:985.407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:29.904, tt:1016.750\n",
      "Ep:34, loss:0.00002, loss_test:0.01525, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:29.968, tt:1048.868\n",
      "Ep:35, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:30.050, tt:1081.814\n",
      "Ep:36, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:30.092, tt:1113.401\n",
      "Ep:37, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:30.094, tt:1143.577\n",
      "Ep:38, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:30.117, tt:1174.567\n",
      "Ep:39, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:30.153, tt:1206.118\n",
      "Ep:40, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.174, tt:1237.121\n",
      "Ep:41, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.205, tt:1268.600\n",
      "Ep:42, loss:0.00002, loss_test:0.01534, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.200, tt:1298.591\n",
      "Ep:43, loss:0.00002, loss_test:0.01536, lr:5.94e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.232, tt:1330.193\n",
      "Ep:44, loss:0.00002, loss_test:0.01535, lr:5.88e-02, fs:0.77725 (r=0.828,p=0.732),  time:30.258, tt:1361.631\n",
      "Ep:45, loss:0.00002, loss_test:0.01535, lr:5.82e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.252, tt:1391.574\n",
      "Ep:46, loss:0.00002, loss_test:0.01537, lr:5.76e-02, fs:0.78469 (r=0.828,p=0.745),  time:30.319, tt:1424.969\n",
      "Ep:47, loss:0.00002, loss_test:0.01538, lr:5.71e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.329, tt:1455.812\n",
      "Ep:48, loss:0.00002, loss_test:0.01540, lr:5.65e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.365, tt:1487.864\n",
      "Ep:49, loss:0.00002, loss_test:0.01542, lr:5.59e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.371, tt:1518.527\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01542, lr:5.59e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.368, tt:1548.777\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01543, lr:5.59e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.390, tt:1580.267\n",
      "Ep:52, loss:0.00002, loss_test:0.01543, lr:5.59e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.386, tt:1610.479\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01547, lr:5.59e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.389, tt:1641.025\n",
      "Ep:54, loss:0.00002, loss_test:0.01548, lr:5.59e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.390, tt:1671.432\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01550, lr:5.59e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.400, tt:1702.406\n",
      "Ep:56, loss:0.00002, loss_test:0.01550, lr:5.59e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.406, tt:1733.121\n",
      "Ep:57, loss:0.00002, loss_test:0.01549, lr:5.59e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.403, tt:1763.380\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01551, lr:5.59e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.408, tt:1794.051\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01549, lr:5.59e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.410, tt:1824.620\n",
      "Ep:60, loss:0.00002, loss_test:0.01549, lr:5.59e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.412, tt:1855.119\n",
      "Ep:61, loss:0.00002, loss_test:0.01553, lr:5.59e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.429, tt:1886.583\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01556, lr:5.59e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.429, tt:1916.999\n",
      "Ep:63, loss:0.00001, loss_test:0.01559, lr:5.59e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.405, tt:1945.911\n",
      "Ep:64, loss:0.00001, loss_test:0.01563, lr:5.59e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.418, tt:1977.164\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01566, lr:5.59e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.410, tt:2007.091\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01566, lr:5.59e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.408, tt:2037.360\n",
      "Ep:67, loss:0.00001, loss_test:0.01566, lr:5.59e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.415, tt:2068.211\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01572, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.429, tt:2099.595\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01570, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.439, tt:2130.707\n",
      "Ep:70, loss:0.00001, loss_test:0.01572, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.451, tt:2161.987\n",
      "Ep:71, loss:0.00001, loss_test:0.01574, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.461, tt:2193.226\n",
      "Ep:72, loss:0.00001, loss_test:0.01577, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.461, tt:2223.685\n",
      "Ep:73, loss:0.00001, loss_test:0.01580, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.469, tt:2254.716\n",
      "Ep:74, loss:0.00001, loss_test:0.01582, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.487, tt:2286.515\n",
      "Ep:75, loss:0.00001, loss_test:0.01581, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.497, tt:2317.774\n",
      "Ep:76, loss:0.00001, loss_test:0.01582, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.513, tt:2349.505\n",
      "Ep:77, loss:0.00001, loss_test:0.01583, lr:5.59e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.531, tt:2381.417\n",
      "Ep:78, loss:0.00001, loss_test:0.01589, lr:5.59e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.532, tt:2412.007\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01593, lr:5.59e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.524, tt:2441.909\n",
      "Ep:80, loss:0.00001, loss_test:0.01596, lr:5.59e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.511, tt:2471.407\n",
      "Ep:81, loss:0.00001, loss_test:0.01593, lr:5.59e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.501, tt:2501.086\n",
      "Ep:82, loss:0.00001, loss_test:0.01599, lr:5.59e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.510, tt:2532.306\n",
      "Ep:83, loss:0.00001, loss_test:0.01600, lr:5.59e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.511, tt:2562.949\n",
      "Ep:84, loss:0.00001, loss_test:0.01600, lr:5.59e-02, fs:0.86294 (r=0.859,p=0.867),  time:30.536, tt:2595.539\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01600, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.531, tt:2625.673\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01604, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.559, tt:2658.672\n",
      "Ep:87, loss:0.00001, loss_test:0.01608, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.551, tt:2688.451\n",
      "Ep:88, loss:0.00001, loss_test:0.01613, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.560, tt:2719.814\n",
      "Ep:89, loss:0.00001, loss_test:0.01622, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.570, tt:2751.297\n",
      "Ep:90, loss:0.00001, loss_test:0.01623, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.574, tt:2782.224\n",
      "Ep:91, loss:0.00001, loss_test:0.01620, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.574, tt:2812.846\n",
      "Ep:92, loss:0.00001, loss_test:0.01623, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.585, tt:2844.385\n",
      "Ep:93, loss:0.00001, loss_test:0.01632, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.585, tt:2875.032\n",
      "Ep:94, loss:0.00001, loss_test:0.01636, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.607, tt:2907.626\n",
      "Ep:95, loss:0.00001, loss_test:0.01634, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.618, tt:2939.365\n",
      "Ep:96, loss:0.00001, loss_test:0.01639, lr:5.59e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.623, tt:2970.409\n",
      "Ep:97, loss:0.00001, loss_test:0.01650, lr:5.54e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.636, tt:3002.363\n",
      "Ep:98, loss:0.00001, loss_test:0.01655, lr:5.48e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.642, tt:3033.546\n",
      "Ep:99, loss:0.00001, loss_test:0.01655, lr:5.43e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.633, tt:3063.285\n",
      "Ep:100, loss:0.00001, loss_test:0.01656, lr:5.37e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.633, tt:3093.928\n",
      "Ep:101, loss:0.00001, loss_test:0.01664, lr:5.32e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.630, tt:3124.215\n",
      "Ep:102, loss:0.00001, loss_test:0.01667, lr:5.27e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.630, tt:3154.869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:103, loss:0.00001, loss_test:0.01669, lr:5.21e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.637, tt:3186.196\n",
      "Ep:104, loss:0.00001, loss_test:0.01668, lr:5.16e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.631, tt:3216.240\n",
      "Ep:105, loss:0.00001, loss_test:0.01670, lr:5.11e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.632, tt:3246.991\n",
      "Ep:106, loss:0.00001, loss_test:0.01674, lr:5.06e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.644, tt:3278.855\n",
      "Ep:107, loss:0.00001, loss_test:0.01682, lr:5.01e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.643, tt:3309.454\n",
      "Ep:108, loss:0.00001, loss_test:0.01685, lr:4.96e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.627, tt:3338.362\n",
      "Ep:109, loss:0.00001, loss_test:0.01684, lr:4.91e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.602, tt:3366.229\n",
      "Ep:110, loss:0.00001, loss_test:0.01687, lr:4.86e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.603, tt:3396.921\n",
      "Ep:111, loss:0.00001, loss_test:0.01693, lr:4.81e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.604, tt:3427.607\n",
      "Ep:112, loss:0.00001, loss_test:0.01699, lr:4.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.610, tt:3458.882\n",
      "Ep:113, loss:0.00001, loss_test:0.01698, lr:4.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.605, tt:3488.957\n",
      "Ep:114, loss:0.00001, loss_test:0.01700, lr:4.67e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.607, tt:3519.845\n",
      "Ep:115, loss:0.00001, loss_test:0.01704, lr:4.62e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.605, tt:3550.192\n",
      "Ep:116, loss:0.00001, loss_test:0.01703, lr:4.57e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.603, tt:3580.494\n",
      "Ep:117, loss:0.00001, loss_test:0.01703, lr:4.53e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.594, tt:3610.066\n",
      "Ep:118, loss:0.00001, loss_test:0.01707, lr:4.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.591, tt:3640.342\n",
      "Ep:119, loss:0.00001, loss_test:0.01713, lr:4.44e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.598, tt:3671.713\n",
      "Ep:120, loss:0.00001, loss_test:0.01714, lr:4.39e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.599, tt:3702.488\n",
      "Ep:121, loss:0.00001, loss_test:0.01718, lr:4.35e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.594, tt:3732.485\n",
      "Ep:122, loss:0.00001, loss_test:0.01720, lr:4.31e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.600, tt:3763.855\n",
      "Ep:123, loss:0.00001, loss_test:0.01721, lr:4.26e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.617, tt:3796.495\n",
      "Ep:124, loss:0.00001, loss_test:0.01724, lr:4.22e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.619, tt:3827.314\n",
      "Ep:125, loss:0.00001, loss_test:0.01728, lr:4.18e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.628, tt:3859.097\n",
      "Ep:126, loss:0.00001, loss_test:0.01732, lr:4.14e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.638, tt:3891.077\n",
      "Ep:127, loss:0.00001, loss_test:0.01736, lr:4.10e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.648, tt:3922.907\n",
      "Ep:128, loss:0.00001, loss_test:0.01739, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.649, tt:3953.694\n",
      "Ep:129, loss:0.00001, loss_test:0.01742, lr:4.01e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.649, tt:3984.417\n",
      "Ep:130, loss:0.00001, loss_test:0.01743, lr:3.97e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.656, tt:4015.893\n",
      "Ep:131, loss:0.00001, loss_test:0.01742, lr:3.93e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.660, tt:4047.133\n",
      "Ep:132, loss:0.00001, loss_test:0.01743, lr:3.89e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.655, tt:4077.165\n",
      "Ep:133, loss:0.00001, loss_test:0.01744, lr:3.86e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.654, tt:4107.645\n",
      "Ep:134, loss:0.00001, loss_test:0.01748, lr:3.82e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.650, tt:4137.780\n",
      "Ep:135, loss:0.00001, loss_test:0.01752, lr:3.78e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.657, tt:4169.355\n",
      "Ep:136, loss:0.00001, loss_test:0.01756, lr:3.74e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.655, tt:4199.679\n",
      "Ep:137, loss:0.00001, loss_test:0.01756, lr:3.70e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.659, tt:4230.950\n",
      "Ep:138, loss:0.00001, loss_test:0.01759, lr:3.67e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.663, tt:4262.161\n",
      "Ep:139, loss:0.00001, loss_test:0.01765, lr:3.63e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.679, tt:4295.019\n",
      "Ep:140, loss:0.00001, loss_test:0.01766, lr:3.59e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.694, tt:4327.798\n",
      "Ep:141, loss:0.00001, loss_test:0.01767, lr:3.56e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.706, tt:4360.260\n",
      "Ep:142, loss:0.00001, loss_test:0.01769, lr:3.52e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.703, tt:4390.583\n",
      "Ep:143, loss:0.00001, loss_test:0.01770, lr:3.49e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.711, tt:4422.320\n",
      "Ep:144, loss:0.00001, loss_test:0.01771, lr:3.45e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.710, tt:4452.956\n",
      "Ep:145, loss:0.00001, loss_test:0.01773, lr:3.42e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.706, tt:4483.008\n",
      "Ep:146, loss:0.00001, loss_test:0.01779, lr:3.38e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.722, tt:4516.166\n",
      "Ep:147, loss:0.00001, loss_test:0.01784, lr:3.35e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.727, tt:4547.626\n",
      "Ep:148, loss:0.00001, loss_test:0.01785, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.728, tt:4578.517\n",
      "Ep:149, loss:0.00001, loss_test:0.01784, lr:3.28e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.728, tt:4609.232\n",
      "Ep:150, loss:0.00001, loss_test:0.01789, lr:3.25e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.736, tt:4641.159\n",
      "Ep:151, loss:0.00001, loss_test:0.01793, lr:3.22e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.732, tt:4671.245\n",
      "Ep:152, loss:0.00001, loss_test:0.01790, lr:3.19e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.736, tt:4702.640\n",
      "Ep:153, loss:0.00001, loss_test:0.01792, lr:3.15e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.734, tt:4733.083\n",
      "Ep:154, loss:0.00001, loss_test:0.01794, lr:3.12e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.737, tt:4764.286\n",
      "Ep:155, loss:0.00001, loss_test:0.01796, lr:3.09e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.755, tt:4797.761\n",
      "Ep:156, loss:0.00001, loss_test:0.01799, lr:3.06e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.748, tt:4827.452\n",
      "Ep:157, loss:0.00001, loss_test:0.01798, lr:3.03e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.739, tt:4856.815\n",
      "Ep:158, loss:0.00001, loss_test:0.01803, lr:3.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.738, tt:4887.277\n",
      "Ep:159, loss:0.00001, loss_test:0.01804, lr:2.97e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.741, tt:4918.537\n",
      "Ep:160, loss:0.00001, loss_test:0.01806, lr:2.94e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.729, tt:4947.321\n",
      "Ep:161, loss:0.00001, loss_test:0.01807, lr:2.91e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.726, tt:4977.688\n",
      "Ep:162, loss:0.00001, loss_test:0.01812, lr:2.88e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.720, tt:5007.308\n",
      "Ep:163, loss:0.00001, loss_test:0.01815, lr:2.85e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.719, tt:5037.894\n",
      "Ep:164, loss:0.00001, loss_test:0.01816, lr:2.82e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.718, tt:5068.513\n",
      "Ep:165, loss:0.00001, loss_test:0.01816, lr:2.80e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.716, tt:5098.849\n",
      "Ep:166, loss:0.00001, loss_test:0.01819, lr:2.77e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.714, tt:5129.253\n",
      "Ep:167, loss:0.00001, loss_test:0.01821, lr:2.74e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.718, tt:5160.552\n",
      "Ep:168, loss:0.00001, loss_test:0.01822, lr:2.71e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.720, tt:5191.710\n",
      "Ep:169, loss:0.00001, loss_test:0.01823, lr:2.69e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.717, tt:5221.869\n",
      "Ep:170, loss:0.00001, loss_test:0.01824, lr:2.66e-02, fs:0.79545 (r=0.707,p=0.909),  time:30.716, tt:5252.400\n",
      "Ep:171, loss:0.00001, loss_test:0.01826, lr:2.63e-02, fs:0.79545 (r=0.707,p=0.909),  time:30.718, tt:5283.519\n",
      "Ep:172, loss:0.00001, loss_test:0.01830, lr:2.61e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.701, tt:5311.326\n",
      "Ep:173, loss:0.00001, loss_test:0.01830, lr:2.58e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.702, tt:5342.145\n",
      "Ep:174, loss:0.00001, loss_test:0.01831, lr:2.55e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.696, tt:5371.882\n",
      "Ep:175, loss:0.00001, loss_test:0.01834, lr:2.53e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.697, tt:5402.652\n",
      "Ep:176, loss:0.00000, loss_test:0.01838, lr:2.50e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.699, tt:5433.763\n",
      "Ep:177, loss:0.00000, loss_test:0.01838, lr:2.48e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.699, tt:5464.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:178, loss:0.00000, loss_test:0.01841, lr:2.45e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.698, tt:5494.924\n",
      "Ep:179, loss:0.00000, loss_test:0.01842, lr:2.43e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.696, tt:5525.299\n",
      "Ep:180, loss:0.00000, loss_test:0.01843, lr:2.40e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.700, tt:5556.718\n",
      "Ep:181, loss:0.00000, loss_test:0.01846, lr:2.38e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.703, tt:5588.024\n",
      "Ep:182, loss:0.00000, loss_test:0.01847, lr:2.36e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.708, tt:5619.554\n",
      "Ep:183, loss:0.00000, loss_test:0.01847, lr:2.33e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.709, tt:5650.416\n",
      "Ep:184, loss:0.00000, loss_test:0.01846, lr:2.31e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.702, tt:5679.923\n",
      "Ep:185, loss:0.00000, loss_test:0.01849, lr:2.29e-02, fs:0.76471 (r=0.657,p=0.915),  time:30.703, tt:5710.810\n",
      "Ep:186, loss:0.00000, loss_test:0.01853, lr:2.26e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.704, tt:5741.597\n",
      "Ep:187, loss:0.00000, loss_test:0.01857, lr:2.24e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.708, tt:5773.072\n",
      "Ep:188, loss:0.00000, loss_test:0.01858, lr:2.22e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.713, tt:5804.771\n",
      "Ep:189, loss:0.00000, loss_test:0.01858, lr:2.20e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.718, tt:5836.457\n",
      "Ep:190, loss:0.00000, loss_test:0.01858, lr:2.17e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.725, tt:5868.399\n",
      "Ep:191, loss:0.00000, loss_test:0.01858, lr:2.15e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.728, tt:5899.722\n",
      "Ep:192, loss:0.00000, loss_test:0.01860, lr:2.13e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.728, tt:5930.420\n",
      "Ep:193, loss:0.00000, loss_test:0.01862, lr:2.11e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.728, tt:5961.304\n",
      "Ep:194, loss:0.00000, loss_test:0.01864, lr:2.09e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.724, tt:5991.106\n",
      "Ep:195, loss:0.00000, loss_test:0.01866, lr:2.07e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.726, tt:6022.225\n",
      "Ep:196, loss:0.00000, loss_test:0.01867, lr:2.05e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.733, tt:6054.352\n",
      "Ep:197, loss:0.00000, loss_test:0.01869, lr:2.03e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.726, tt:6083.658\n",
      "Ep:198, loss:0.00000, loss_test:0.01872, lr:2.01e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.729, tt:6115.112\n",
      "Ep:199, loss:0.00000, loss_test:0.01871, lr:1.99e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.726, tt:6145.239\n",
      "Ep:200, loss:0.00000, loss_test:0.01873, lr:1.97e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.725, tt:6175.735\n",
      "Ep:201, loss:0.00000, loss_test:0.01874, lr:1.95e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.717, tt:6204.806\n",
      "Ep:202, loss:0.00000, loss_test:0.01875, lr:1.93e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.716, tt:6235.309\n",
      "Ep:203, loss:0.00000, loss_test:0.01877, lr:1.91e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.735, tt:6269.993\n",
      "Ep:204, loss:0.00000, loss_test:0.01877, lr:1.89e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.736, tt:6300.792\n",
      "Ep:205, loss:0.00000, loss_test:0.01880, lr:1.87e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.728, tt:6329.923\n",
      "Ep:206, loss:0.00000, loss_test:0.01880, lr:1.85e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.723, tt:6359.647\n",
      "Ep:207, loss:0.00000, loss_test:0.01881, lr:1.83e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.714, tt:6388.550\n",
      "Ep:208, loss:0.00000, loss_test:0.01883, lr:1.81e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.709, tt:6418.286\n",
      "Ep:209, loss:0.00000, loss_test:0.01884, lr:1.80e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.693, tt:6445.565\n",
      "Ep:210, loss:0.00000, loss_test:0.01886, lr:1.78e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.662, tt:6469.764\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13938, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.714, tt:27.714\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13815, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.576, tt:59.152\n",
      "Ep:2, loss:0.00028, loss_test:0.13619, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.446, tt:91.337\n",
      "Ep:3, loss:0.00028, loss_test:0.13338, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.437, tt:121.749\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12940, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:30.975, tt:154.875\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12403, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:31.573, tt:189.438\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.11683, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:31.823, tt:222.759\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.10978, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:31.931, tt:255.445\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.10571, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:32.035, tt:288.316\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10343, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:32.190, tt:321.901\n",
      "Ep:10, loss:0.00023, loss_test:0.10230, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:32.313, tt:355.441\n",
      "Ep:11, loss:0.00022, loss_test:0.10173, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:32.451, tt:389.412\n",
      "Ep:12, loss:0.00021, loss_test:0.09992, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:32.527, tt:422.855\n",
      "Ep:13, loss:0.00021, loss_test:0.09720, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:32.726, tt:458.158\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09520, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:32.755, tt:491.324\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09456, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:32.700, tt:523.203\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09338, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:32.784, tt:557.334\n",
      "Ep:17, loss:0.00019, loss_test:0.09292, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:32.858, tt:591.453\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09271, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:32.835, tt:623.866\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09128, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:32.848, tt:656.964\n",
      "Ep:20, loss:0.00017, loss_test:0.09087, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:32.918, tt:691.273\n",
      "Ep:21, loss:0.00017, loss_test:0.09184, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:32.916, tt:724.148\n",
      "Ep:22, loss:0.00016, loss_test:0.09140, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:32.944, tt:757.703\n",
      "Ep:23, loss:0.00016, loss_test:0.09041, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:32.976, tt:791.432\n",
      "Ep:24, loss:0.00015, loss_test:0.08857, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:32.979, tt:824.479\n",
      "Ep:25, loss:0.00015, loss_test:0.08742, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:32.938, tt:856.395\n",
      "Ep:26, loss:0.00014, loss_test:0.08778, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:32.939, tt:889.361\n",
      "Ep:27, loss:0.00014, loss_test:0.08514, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.883, tt:920.732\n",
      "Ep:28, loss:0.00014, loss_test:0.08561, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:32.881, tt:953.547\n",
      "Ep:29, loss:0.00013, loss_test:0.08286, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:32.896, tt:986.892\n",
      "Ep:30, loss:0.00013, loss_test:0.08126, lr:9.90e-03, fs:0.78723 (r=0.747,p=0.831),  time:32.866, tt:1018.843\n",
      "Ep:31, loss:0.00013, loss_test:0.08238, lr:9.80e-03, fs:0.79188 (r=0.788,p=0.796),  time:32.811, tt:1049.954\n",
      "Ep:32, loss:0.00012, loss_test:0.07983, lr:9.70e-03, fs:0.81283 (r=0.768,p=0.864),  time:32.810, tt:1082.733\n",
      "Ep:33, loss:0.00012, loss_test:0.08129, lr:9.61e-03, fs:0.79592 (r=0.788,p=0.804),  time:32.813, tt:1115.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00012, loss_test:0.07824, lr:9.51e-03, fs:0.80423 (r=0.768,p=0.844),  time:32.796, tt:1147.846\n",
      "Ep:35, loss:0.00012, loss_test:0.07818, lr:9.41e-03, fs:0.80628 (r=0.778,p=0.837),  time:32.770, tt:1179.713\n",
      "Ep:36, loss:0.00011, loss_test:0.07802, lr:9.32e-03, fs:0.80851 (r=0.768,p=0.854),  time:32.796, tt:1213.440\n",
      "Ep:37, loss:0.00011, loss_test:0.07695, lr:9.23e-03, fs:0.80645 (r=0.758,p=0.862),  time:32.791, tt:1246.039\n",
      "Ep:38, loss:0.00011, loss_test:0.07724, lr:9.14e-03, fs:0.80423 (r=0.768,p=0.844),  time:32.770, tt:1278.038\n",
      "Ep:39, loss:0.00011, loss_test:0.07659, lr:9.04e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.754, tt:1310.177\n",
      "Ep:40, loss:0.00010, loss_test:0.07594, lr:8.95e-03, fs:0.83417 (r=0.838,p=0.830),  time:32.764, tt:1343.308\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.07522, lr:8.95e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.767, tt:1376.229\n",
      "Ep:42, loss:0.00010, loss_test:0.07636, lr:8.95e-03, fs:0.81915 (r=0.778,p=0.865),  time:32.779, tt:1409.485\n",
      "Ep:43, loss:0.00010, loss_test:0.07327, lr:8.95e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.772, tt:1441.964\n",
      "Ep:44, loss:0.00010, loss_test:0.07314, lr:8.95e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.790, tt:1475.555\n",
      "Ep:45, loss:0.00009, loss_test:0.07478, lr:8.95e-03, fs:0.84656 (r=0.808,p=0.889),  time:32.793, tt:1508.478\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.07085, lr:8.95e-03, fs:0.83060 (r=0.768,p=0.905),  time:32.781, tt:1540.690\n",
      "Ep:47, loss:0.00009, loss_test:0.07409, lr:8.95e-03, fs:0.84974 (r=0.828,p=0.872),  time:32.780, tt:1573.417\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.07290, lr:8.95e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.780, tt:1606.232\n",
      "Ep:49, loss:0.00009, loss_test:0.07142, lr:8.95e-03, fs:0.84656 (r=0.808,p=0.889),  time:32.732, tt:1636.622\n",
      "Ep:50, loss:0.00008, loss_test:0.07056, lr:8.95e-03, fs:0.83060 (r=0.768,p=0.905),  time:32.717, tt:1668.573\n",
      "Ep:51, loss:0.00008, loss_test:0.07149, lr:8.95e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.701, tt:1700.476\n",
      "Ep:52, loss:0.00008, loss_test:0.06953, lr:8.95e-03, fs:0.83243 (r=0.778,p=0.895),  time:32.700, tt:1733.091\n",
      "Ep:53, loss:0.00008, loss_test:0.06907, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.707, tt:1766.190\n",
      "Ep:54, loss:0.00008, loss_test:0.06972, lr:8.95e-03, fs:0.85714 (r=0.818,p=0.900),  time:32.706, tt:1798.830\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.06983, lr:8.95e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.704, tt:1831.406\n",
      "Ep:56, loss:0.00007, loss_test:0.06821, lr:8.95e-03, fs:0.83243 (r=0.778,p=0.895),  time:32.687, tt:1863.173\n",
      "Ep:57, loss:0.00007, loss_test:0.06854, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.652, tt:1893.813\n",
      "Ep:58, loss:0.00007, loss_test:0.06947, lr:8.95e-03, fs:0.84324 (r=0.788,p=0.907),  time:32.624, tt:1924.801\n",
      "Ep:59, loss:0.00007, loss_test:0.06711, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.609, tt:1956.512\n",
      "Ep:60, loss:0.00007, loss_test:0.06820, lr:8.95e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.613, tt:1989.391\n",
      "Ep:61, loss:0.00007, loss_test:0.06675, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.612, tt:2021.935\n",
      "Ep:62, loss:0.00006, loss_test:0.06733, lr:8.95e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.606, tt:2054.186\n",
      "Ep:63, loss:0.00006, loss_test:0.06664, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.593, tt:2085.949\n",
      "Ep:64, loss:0.00006, loss_test:0.06687, lr:8.95e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.580, tt:2117.732\n",
      "Ep:65, loss:0.00006, loss_test:0.06630, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.575, tt:2149.944\n",
      "Ep:66, loss:0.00006, loss_test:0.06671, lr:8.86e-03, fs:0.84946 (r=0.798,p=0.908),  time:32.569, tt:2182.099\n",
      "Ep:67, loss:0.00006, loss_test:0.06616, lr:8.78e-03, fs:0.84324 (r=0.788,p=0.907),  time:32.561, tt:2214.123\n",
      "Ep:68, loss:0.00006, loss_test:0.06576, lr:8.69e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.564, tt:2246.934\n",
      "Ep:69, loss:0.00006, loss_test:0.06570, lr:8.60e-03, fs:0.84324 (r=0.788,p=0.907),  time:32.564, tt:2279.491\n",
      "Ep:70, loss:0.00005, loss_test:0.06466, lr:8.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:32.561, tt:2311.797\n",
      "Ep:71, loss:0.00005, loss_test:0.06579, lr:8.43e-03, fs:0.84783 (r=0.788,p=0.918),  time:32.559, tt:2344.244\n",
      "Ep:72, loss:0.00005, loss_test:0.06460, lr:8.35e-03, fs:0.84615 (r=0.778,p=0.928),  time:32.561, tt:2376.923\n",
      "Ep:73, loss:0.00005, loss_test:0.06496, lr:8.26e-03, fs:0.84324 (r=0.788,p=0.907),  time:32.549, tt:2408.590\n",
      "Ep:74, loss:0.00005, loss_test:0.06566, lr:8.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.560, tt:2442.009\n",
      "Ep:75, loss:0.00005, loss_test:0.06491, lr:8.10e-03, fs:0.84324 (r=0.788,p=0.907),  time:32.569, tt:2475.247\n",
      "Ep:76, loss:0.00005, loss_test:0.06404, lr:8.02e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.548, tt:2506.187\n",
      "Ep:77, loss:0.00005, loss_test:0.06426, lr:7.94e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.525, tt:2536.950\n",
      "Ep:78, loss:0.00005, loss_test:0.06562, lr:7.86e-03, fs:0.86170 (r=0.818,p=0.910),  time:32.514, tt:2568.598\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00005, loss_test:0.06430, lr:7.86e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.498, tt:2599.863\n",
      "Ep:80, loss:0.00005, loss_test:0.06630, lr:7.86e-03, fs:0.86316 (r=0.828,p=0.901),  time:32.489, tt:2631.633\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.06362, lr:7.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.493, tt:2664.440\n",
      "Ep:82, loss:0.00005, loss_test:0.06853, lr:7.86e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.474, tt:2695.323\n",
      "Ep:83, loss:0.00005, loss_test:0.06176, lr:7.86e-03, fs:0.79775 (r=0.717,p=0.899),  time:32.468, tt:2727.354\n",
      "Ep:84, loss:0.00005, loss_test:0.07115, lr:7.86e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.459, tt:2759.042\n",
      "Ep:85, loss:0.00005, loss_test:0.06162, lr:7.86e-03, fs:0.80226 (r=0.717,p=0.910),  time:32.434, tt:2789.367\n",
      "Ep:86, loss:0.00004, loss_test:0.06500, lr:7.86e-03, fs:0.84783 (r=0.788,p=0.918),  time:32.415, tt:2820.118\n",
      "Ep:87, loss:0.00004, loss_test:0.06351, lr:7.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.413, tt:2852.340\n",
      "Ep:88, loss:0.00004, loss_test:0.06274, lr:7.86e-03, fs:0.86911 (r=0.838,p=0.902),  time:32.408, tt:2884.280\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.06423, lr:7.86e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.399, tt:2915.911\n",
      "Ep:90, loss:0.00004, loss_test:0.06089, lr:7.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.395, tt:2947.982\n",
      "Ep:91, loss:0.00004, loss_test:0.06360, lr:7.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.402, tt:2980.973\n",
      "Ep:92, loss:0.00004, loss_test:0.06042, lr:7.86e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.391, tt:3012.359\n",
      "Ep:93, loss:0.00004, loss_test:0.06189, lr:7.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.388, tt:3044.458\n",
      "Ep:94, loss:0.00004, loss_test:0.06210, lr:7.86e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.403, tt:3078.309\n",
      "Ep:95, loss:0.00004, loss_test:0.06055, lr:7.86e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.411, tt:3111.463\n",
      "Ep:96, loss:0.00003, loss_test:0.06281, lr:7.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.410, tt:3143.761\n",
      "Ep:97, loss:0.00003, loss_test:0.05941, lr:7.86e-03, fs:0.86631 (r=0.818,p=0.920),  time:32.418, tt:3176.924\n",
      "Ep:98, loss:0.00003, loss_test:0.06235, lr:7.86e-03, fs:0.80000 (r=0.707,p=0.921),  time:32.412, tt:3208.775\n",
      "Ep:99, loss:0.00003, loss_test:0.05942, lr:7.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.397, tt:3239.706\n",
      "Ep:100, loss:0.00003, loss_test:0.06300, lr:7.78e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.401, tt:3272.474\n",
      "Ep:101, loss:0.00003, loss_test:0.06044, lr:7.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.396, tt:3304.401\n",
      "Ep:102, loss:0.00003, loss_test:0.06003, lr:7.62e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.389, tt:3336.045\n",
      "Ep:103, loss:0.00003, loss_test:0.06151, lr:7.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.389, tt:3368.405\n",
      "Ep:104, loss:0.00003, loss_test:0.05910, lr:7.47e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.376, tt:3399.485\n",
      "Ep:105, loss:0.00003, loss_test:0.06180, lr:7.40e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.374, tt:3431.608\n",
      "Ep:106, loss:0.00003, loss_test:0.05922, lr:7.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:32.355, tt:3461.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:107, loss:0.00003, loss_test:0.06016, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.351, tt:3493.894\n",
      "Ep:108, loss:0.00003, loss_test:0.06133, lr:7.18e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.350, tt:3526.145\n",
      "Ep:109, loss:0.00003, loss_test:0.05825, lr:7.11e-03, fs:0.81564 (r=0.737,p=0.912),  time:32.348, tt:3558.304\n",
      "Ep:110, loss:0.00003, loss_test:0.06196, lr:7.03e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.353, tt:3591.178\n",
      "Ep:111, loss:0.00003, loss_test:0.05897, lr:6.96e-03, fs:0.79545 (r=0.707,p=0.909),  time:32.338, tt:3621.828\n",
      "Ep:112, loss:0.00003, loss_test:0.06025, lr:6.89e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.309, tt:3650.871\n",
      "Ep:113, loss:0.00003, loss_test:0.06159, lr:6.83e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.291, tt:3681.205\n",
      "Ep:114, loss:0.00003, loss_test:0.05773, lr:6.76e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.286, tt:3712.876\n",
      "Ep:115, loss:0.00003, loss_test:0.06018, lr:6.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.286, tt:3745.216\n",
      "Ep:116, loss:0.00003, loss_test:0.05954, lr:6.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.289, tt:3777.808\n",
      "Ep:117, loss:0.00003, loss_test:0.05887, lr:6.56e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.281, tt:3809.203\n",
      "Ep:118, loss:0.00002, loss_test:0.05969, lr:6.49e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.290, tt:3842.510\n",
      "Ep:119, loss:0.00002, loss_test:0.05835, lr:6.43e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.297, tt:3875.625\n",
      "Ep:120, loss:0.00002, loss_test:0.05943, lr:6.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.293, tt:3907.509\n",
      "Ep:121, loss:0.00002, loss_test:0.05934, lr:6.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.285, tt:3938.747\n",
      "Ep:122, loss:0.00002, loss_test:0.05836, lr:6.24e-03, fs:0.80000 (r=0.707,p=0.921),  time:32.291, tt:3971.842\n",
      "Ep:123, loss:0.00002, loss_test:0.06007, lr:6.17e-03, fs:0.84615 (r=0.778,p=0.928),  time:32.307, tt:4006.073\n",
      "Ep:124, loss:0.00002, loss_test:0.05826, lr:6.11e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.313, tt:4039.068\n",
      "Ep:125, loss:0.00002, loss_test:0.05991, lr:6.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:32.307, tt:4070.692\n",
      "Ep:126, loss:0.00002, loss_test:0.05936, lr:5.99e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.308, tt:4103.126\n",
      "Ep:127, loss:0.00002, loss_test:0.05958, lr:5.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.323, tt:4137.301\n",
      "Ep:128, loss:0.00002, loss_test:0.05931, lr:5.87e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.323, tt:4169.605\n",
      "Ep:129, loss:0.00002, loss_test:0.05908, lr:5.81e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.325, tt:4202.200\n",
      "Ep:130, loss:0.00002, loss_test:0.05929, lr:5.75e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.325, tt:4234.574\n",
      "Ep:131, loss:0.00002, loss_test:0.05906, lr:5.70e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.331, tt:4267.701\n",
      "Ep:132, loss:0.00002, loss_test:0.05842, lr:5.64e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.342, tt:4301.434\n",
      "Ep:133, loss:0.00002, loss_test:0.05886, lr:5.58e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.346, tt:4334.405\n",
      "Ep:134, loss:0.00002, loss_test:0.05923, lr:5.53e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.343, tt:4366.265\n",
      "Ep:135, loss:0.00002, loss_test:0.05894, lr:5.47e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.336, tt:4397.681\n",
      "Ep:136, loss:0.00002, loss_test:0.05766, lr:5.42e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.328, tt:4428.916\n",
      "Ep:137, loss:0.00002, loss_test:0.05990, lr:5.36e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.319, tt:4460.084\n",
      "Ep:138, loss:0.00002, loss_test:0.05885, lr:5.31e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.317, tt:4492.054\n",
      "Ep:139, loss:0.00002, loss_test:0.05937, lr:5.26e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.314, tt:4524.005\n",
      "Ep:140, loss:0.00002, loss_test:0.06035, lr:5.20e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.325, tt:4557.827\n",
      "Ep:141, loss:0.00002, loss_test:0.05929, lr:5.15e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.327, tt:4590.390\n",
      "Ep:142, loss:0.00002, loss_test:0.05928, lr:5.10e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.322, tt:4622.058\n",
      "Ep:143, loss:0.00002, loss_test:0.05961, lr:5.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:32.315, tt:4653.333\n",
      "Ep:144, loss:0.00002, loss_test:0.05870, lr:5.00e-03, fs:0.84153 (r=0.778,p=0.917),  time:32.312, tt:4685.208\n",
      "Ep:145, loss:0.00002, loss_test:0.05925, lr:4.95e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.316, tt:4718.131\n",
      "Ep:146, loss:0.00002, loss_test:0.06057, lr:4.90e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.320, tt:4751.069\n",
      "Ep:147, loss:0.00002, loss_test:0.05760, lr:4.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.330, tt:4784.871\n",
      "Ep:148, loss:0.00002, loss_test:0.05978, lr:4.80e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.354, tt:4820.746\n",
      "Ep:149, loss:0.00002, loss_test:0.05898, lr:4.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.348, tt:4852.235\n",
      "Ep:150, loss:0.00002, loss_test:0.05835, lr:4.71e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.350, tt:4884.889\n",
      "Ep:151, loss:0.00002, loss_test:0.05886, lr:4.66e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.356, tt:4918.051\n",
      "Ep:152, loss:0.00002, loss_test:0.05819, lr:4.61e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.361, tt:4951.201\n",
      "Ep:153, loss:0.00002, loss_test:0.05842, lr:4.57e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.365, tt:4984.148\n",
      "Ep:154, loss:0.00002, loss_test:0.05876, lr:4.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.361, tt:5015.902\n",
      "Ep:155, loss:0.00002, loss_test:0.05879, lr:4.48e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.364, tt:5048.714\n",
      "Ep:156, loss:0.00002, loss_test:0.05829, lr:4.43e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.350, tt:5078.958\n",
      "Ep:157, loss:0.00002, loss_test:0.05889, lr:4.39e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.342, tt:5110.093\n",
      "Ep:158, loss:0.00002, loss_test:0.05850, lr:4.34e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.341, tt:5142.288\n",
      "Ep:159, loss:0.00002, loss_test:0.05855, lr:4.30e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.335, tt:5173.611\n",
      "Ep:160, loss:0.00002, loss_test:0.05866, lr:4.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.338, tt:5206.374\n",
      "Ep:161, loss:0.00002, loss_test:0.05870, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.338, tt:5238.789\n",
      "Ep:162, loss:0.00002, loss_test:0.05836, lr:4.17e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.335, tt:5270.664\n",
      "Ep:163, loss:0.00002, loss_test:0.05914, lr:4.13e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.336, tt:5303.111\n",
      "Ep:164, loss:0.00002, loss_test:0.05884, lr:4.09e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.333, tt:5334.930\n",
      "Ep:165, loss:0.00002, loss_test:0.05847, lr:4.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.336, tt:5367.809\n",
      "Ep:166, loss:0.00002, loss_test:0.05903, lr:4.01e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.334, tt:5399.755\n",
      "Ep:167, loss:0.00002, loss_test:0.05867, lr:3.97e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.331, tt:5431.620\n",
      "Ep:168, loss:0.00002, loss_test:0.05841, lr:3.93e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.329, tt:5463.554\n",
      "Ep:169, loss:0.00002, loss_test:0.05888, lr:3.89e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.327, tt:5495.621\n",
      "Ep:170, loss:0.00002, loss_test:0.05902, lr:3.85e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.321, tt:5526.944\n",
      "Ep:171, loss:0.00002, loss_test:0.05848, lr:3.81e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.315, tt:5558.114\n",
      "Ep:172, loss:0.00002, loss_test:0.05872, lr:3.77e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.311, tt:5589.885\n",
      "Ep:173, loss:0.00002, loss_test:0.05862, lr:3.73e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.307, tt:5621.469\n",
      "Ep:174, loss:0.00002, loss_test:0.05839, lr:3.70e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.290, tt:5650.723\n",
      "Ep:175, loss:0.00002, loss_test:0.05882, lr:3.66e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.287, tt:5682.488\n",
      "Ep:176, loss:0.00002, loss_test:0.05910, lr:3.62e-03, fs:0.82022 (r=0.737,p=0.924),  time:32.290, tt:5715.407\n",
      "Ep:177, loss:0.00002, loss_test:0.05854, lr:3.59e-03, fs:0.80000 (r=0.707,p=0.921),  time:32.294, tt:5748.282\n",
      "Ep:178, loss:0.00002, loss_test:0.05900, lr:3.55e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.286, tt:5779.162\n",
      "Ep:179, loss:0.00002, loss_test:0.05848, lr:3.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.272, tt:5808.887\n",
      "Ep:180, loss:0.00002, loss_test:0.05905, lr:3.48e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.270, tt:5840.906\n",
      "Ep:181, loss:0.00002, loss_test:0.05956, lr:3.45e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.275, tt:5874.115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:182, loss:0.00002, loss_test:0.05873, lr:3.41e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.268, tt:5905.029\n",
      "Ep:183, loss:0.00002, loss_test:0.05881, lr:3.38e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.269, tt:5937.428\n",
      "Ep:184, loss:0.00001, loss_test:0.05872, lr:3.34e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.258, tt:5967.743\n",
      "Ep:185, loss:0.00001, loss_test:0.05931, lr:3.31e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.259, tt:6000.176\n",
      "Ep:186, loss:0.00001, loss_test:0.05885, lr:3.28e-03, fs:0.79310 (r=0.697,p=0.920),  time:32.261, tt:6032.723\n",
      "Ep:187, loss:0.00001, loss_test:0.05903, lr:3.24e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.254, tt:6063.757\n",
      "Ep:188, loss:0.00001, loss_test:0.05979, lr:3.21e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.243, tt:6094.012\n",
      "Ep:189, loss:0.00001, loss_test:0.05881, lr:3.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.236, tt:6124.903\n",
      "Ep:190, loss:0.00001, loss_test:0.05881, lr:3.15e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.230, tt:6155.886\n",
      "Ep:191, loss:0.00001, loss_test:0.05952, lr:3.12e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.228, tt:6187.757\n",
      "Ep:192, loss:0.00001, loss_test:0.05918, lr:3.09e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.224, tt:6219.324\n",
      "Ep:193, loss:0.00001, loss_test:0.05868, lr:3.05e-03, fs:0.80000 (r=0.707,p=0.921),  time:32.222, tt:6251.121\n",
      "Ep:194, loss:0.00001, loss_test:0.05926, lr:3.02e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.218, tt:6282.453\n",
      "Ep:195, loss:0.00001, loss_test:0.05946, lr:2.99e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.218, tt:6314.784\n",
      "Ep:196, loss:0.00001, loss_test:0.05910, lr:2.96e-03, fs:0.80000 (r=0.707,p=0.921),  time:32.210, tt:6345.377\n",
      "Ep:197, loss:0.00001, loss_test:0.05898, lr:2.93e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.209, tt:6377.324\n",
      "Ep:198, loss:0.00001, loss_test:0.05959, lr:2.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.206, tt:6408.938\n",
      "Ep:199, loss:0.00001, loss_test:0.05945, lr:2.88e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.201, tt:6440.172\n",
      "Ep:200, loss:0.00001, loss_test:0.05869, lr:2.85e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.196, tt:6471.421\n",
      "Ep:201, loss:0.00001, loss_test:0.05944, lr:2.82e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.193, tt:6502.977\n",
      "Ep:202, loss:0.00001, loss_test:0.05947, lr:2.79e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.185, tt:6533.568\n",
      "Ep:203, loss:0.00001, loss_test:0.05908, lr:2.76e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.171, tt:6562.976\n",
      "Ep:204, loss:0.00001, loss_test:0.05941, lr:2.73e-03, fs:0.80000 (r=0.707,p=0.921),  time:32.165, tt:6593.911\n",
      "Ep:205, loss:0.00001, loss_test:0.05946, lr:2.71e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.152, tt:6623.371\n",
      "Ep:206, loss:0.00001, loss_test:0.05937, lr:2.68e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.145, tt:6653.951\n",
      "Ep:207, loss:0.00001, loss_test:0.05999, lr:2.65e-03, fs:0.81143 (r=0.717,p=0.934),  time:32.124, tt:6681.853\n",
      "Ep:208, loss:0.00001, loss_test:0.05912, lr:2.63e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.103, tt:6709.620\n",
      "Ep:209, loss:0.00001, loss_test:0.05962, lr:2.60e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.072, tt:6735.198\n",
      "Ep:210, loss:0.00001, loss_test:0.06003, lr:2.57e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.038, tt:6760.090\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01927, lr:6.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:28.919, tt:28.919\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02067, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.706, tt:59.412\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02235, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.615, tt:85.844\n",
      "Ep:3, loss:0.00004, loss_test:0.02245, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.363, tt:113.452\n",
      "Ep:4, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.329, tt:141.643\n",
      "Ep:5, loss:0.00004, loss_test:0.02029, lr:6.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:28.523, tt:171.138\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01905, lr:6.00e-02, fs:0.69065 (r=0.970,p=0.536),  time:28.826, tt:201.779\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:29.022, tt:232.177\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01769, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:29.152, tt:262.371\n",
      "Ep:9, loss:0.00004, loss_test:0.01738, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:29.227, tt:292.274\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01714, lr:6.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:29.325, tt:322.580\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01702, lr:6.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:29.389, tt:352.669\n",
      "Ep:12, loss:0.00003, loss_test:0.01695, lr:6.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:29.530, tt:383.895\n",
      "Ep:13, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:29.608, tt:414.518\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:29.652, tt:444.775\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:29.761, tt:476.168\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:29.719, tt:505.221\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01602, lr:6.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:29.798, tt:536.357\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:29.862, tt:567.385\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01589, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:29.900, tt:597.996\n",
      "Ep:20, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:29.934, tt:628.612\n",
      "Ep:21, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:30.011, tt:660.252\n",
      "Ep:22, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:30.033, tt:690.756\n",
      "Ep:23, loss:0.00003, loss_test:0.01578, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:30.029, tt:720.695\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01578, lr:6.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:30.042, tt:751.058\n",
      "Ep:25, loss:0.00003, loss_test:0.01579, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:30.083, tt:782.169\n",
      "Ep:26, loss:0.00003, loss_test:0.01581, lr:6.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:30.177, tt:814.787\n",
      "Ep:27, loss:0.00003, loss_test:0.01583, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:30.163, tt:844.570\n",
      "Ep:28, loss:0.00002, loss_test:0.01586, lr:6.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:30.165, tt:874.792\n",
      "Ep:29, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:30.162, tt:904.863\n",
      "Ep:30, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:30.168, tt:935.197\n",
      "Ep:31, loss:0.00002, loss_test:0.01593, lr:6.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:30.117, tt:963.744\n",
      "Ep:32, loss:0.00002, loss_test:0.01597, lr:6.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:30.122, tt:994.011\n",
      "Ep:33, loss:0.00002, loss_test:0.01601, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:30.137, tt:1024.642\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00002, loss_test:0.01603, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:30.137, tt:1054.801\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.152, tt:1085.458\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.196, tt:1117.241\n",
      "Ep:37, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:30.169, tt:1146.409\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01611, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:30.182, tt:1177.089\n",
      "Ep:39, loss:0.00002, loss_test:0.01612, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:30.192, tt:1207.682\n",
      "Ep:40, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.219, tt:1238.992\n",
      "Ep:41, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.285, tt:1271.959\n",
      "Ep:42, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.285, tt:1302.248\n",
      "Ep:43, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:30.246, tt:1330.804\n",
      "Ep:44, loss:0.00002, loss_test:0.01623, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:30.265, tt:1361.920\n",
      "Ep:45, loss:0.00002, loss_test:0.01626, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:30.237, tt:1390.918\n",
      "Ep:46, loss:0.00002, loss_test:0.01630, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:30.218, tt:1420.231\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01631, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:30.256, tt:1452.277\n",
      "Ep:48, loss:0.00002, loss_test:0.01635, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.265, tt:1482.988\n",
      "Ep:49, loss:0.00002, loss_test:0.01638, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.242, tt:1512.083\n",
      "Ep:50, loss:0.00002, loss_test:0.01643, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.230, tt:1541.722\n",
      "Ep:51, loss:0.00002, loss_test:0.01647, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:30.232, tt:1572.041\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01650, lr:6.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.219, tt:1601.589\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01657, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.211, tt:1631.380\n",
      "Ep:54, loss:0.00002, loss_test:0.01663, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.187, tt:1660.283\n",
      "Ep:55, loss:0.00002, loss_test:0.01668, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:30.183, tt:1690.270\n",
      "Ep:56, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.189, tt:1720.793\n",
      "Ep:57, loss:0.00002, loss_test:0.01680, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:30.191, tt:1751.088\n",
      "Ep:58, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:30.199, tt:1781.731\n",
      "Ep:59, loss:0.00002, loss_test:0.01688, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.211, tt:1812.682\n",
      "Ep:60, loss:0.00002, loss_test:0.01692, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.215, tt:1843.105\n",
      "Ep:61, loss:0.00002, loss_test:0.01695, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:30.219, tt:1873.553\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01699, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.203, tt:1902.813\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01705, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.198, tt:1932.689\n",
      "Ep:64, loss:0.00001, loss_test:0.01712, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.208, tt:1963.511\n",
      "Ep:65, loss:0.00001, loss_test:0.01713, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.199, tt:1993.118\n",
      "Ep:66, loss:0.00001, loss_test:0.01723, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.177, tt:2021.872\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01724, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.183, tt:2052.456\n",
      "Ep:68, loss:0.00001, loss_test:0.01727, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.159, tt:2080.947\n",
      "Ep:69, loss:0.00001, loss_test:0.01734, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.137, tt:2109.568\n",
      "Ep:70, loss:0.00001, loss_test:0.01739, lr:6.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.153, tt:2140.828\n",
      "Ep:71, loss:0.00001, loss_test:0.01745, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.132, tt:2169.475\n",
      "Ep:72, loss:0.00001, loss_test:0.01744, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.145, tt:2200.618\n",
      "Ep:73, loss:0.00001, loss_test:0.01749, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.147, tt:2230.861\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01753, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.152, tt:2261.429\n",
      "Ep:75, loss:0.00001, loss_test:0.01758, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.144, tt:2290.972\n",
      "Ep:76, loss:0.00001, loss_test:0.01756, lr:6.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:30.149, tt:2321.512\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01761, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.169, tt:2353.147\n",
      "Ep:78, loss:0.00001, loss_test:0.01771, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.160, tt:2382.664\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01768, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.171, tt:2413.684\n",
      "Ep:80, loss:0.00001, loss_test:0.01771, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.194, tt:2445.695\n",
      "Ep:81, loss:0.00001, loss_test:0.01778, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.208, tt:2477.073\n",
      "Ep:82, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.207, tt:2507.156\n",
      "Ep:83, loss:0.00001, loss_test:0.01789, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.217, tt:2538.190\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01796, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.214, tt:2568.195\n",
      "Ep:85, loss:0.00001, loss_test:0.01802, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.216, tt:2598.591\n",
      "Ep:86, loss:0.00001, loss_test:0.01804, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.222, tt:2629.318\n",
      "Ep:87, loss:0.00001, loss_test:0.01809, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.224, tt:2659.679\n",
      "Ep:88, loss:0.00001, loss_test:0.01817, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.227, tt:2690.196\n",
      "Ep:89, loss:0.00001, loss_test:0.01819, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.231, tt:2720.825\n",
      "Ep:90, loss:0.00001, loss_test:0.01829, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.247, tt:2752.451\n",
      "Ep:91, loss:0.00001, loss_test:0.01830, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.255, tt:2783.455\n",
      "Ep:92, loss:0.00001, loss_test:0.01828, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.271, tt:2815.182\n",
      "Ep:93, loss:0.00001, loss_test:0.01834, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.287, tt:2846.945\n",
      "Ep:94, loss:0.00001, loss_test:0.01843, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.291, tt:2877.687\n",
      "Ep:95, loss:0.00001, loss_test:0.01845, lr:5.94e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.298, tt:2908.642\n",
      "Ep:96, loss:0.00001, loss_test:0.01845, lr:5.88e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.309, tt:2939.987\n",
      "Ep:97, loss:0.00001, loss_test:0.01845, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.306, tt:2970.034\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01853, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.315, tt:3001.208\n",
      "Ep:99, loss:0.00001, loss_test:0.01855, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.320, tt:3032.031\n",
      "Ep:100, loss:0.00001, loss_test:0.01862, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.325, tt:3062.795\n",
      "Ep:101, loss:0.00001, loss_test:0.01865, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.335, tt:3094.125\n",
      "Ep:102, loss:0.00001, loss_test:0.01877, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.352, tt:3126.211\n",
      "Ep:103, loss:0.00001, loss_test:0.01873, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.356, tt:3157.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00001, loss_test:0.01872, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.355, tt:3187.237\n",
      "Ep:105, loss:0.00001, loss_test:0.01880, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.351, tt:3217.212\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.01885, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.352, tt:3247.713\n",
      "Ep:107, loss:0.00001, loss_test:0.01887, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.326, tt:3275.217\n",
      "Ep:108, loss:0.00001, loss_test:0.01889, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.314, tt:3304.280\n",
      "Ep:109, loss:0.00001, loss_test:0.01892, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.296, tt:3332.547\n",
      "Ep:110, loss:0.00001, loss_test:0.01895, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.304, tt:3363.790\n",
      "Ep:111, loss:0.00001, loss_test:0.01903, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.316, tt:3395.391\n",
      "Ep:112, loss:0.00001, loss_test:0.01899, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.314, tt:3425.469\n",
      "Ep:113, loss:0.00001, loss_test:0.01906, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.322, tt:3456.683\n",
      "Ep:114, loss:0.00001, loss_test:0.01921, lr:5.82e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.324, tt:3487.258\n",
      "Ep:115, loss:0.00001, loss_test:0.01922, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.320, tt:3517.129\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.01922, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.333, tt:3548.955\n",
      "Ep:117, loss:0.00001, loss_test:0.01926, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.335, tt:3579.550\n",
      "Ep:118, loss:0.00001, loss_test:0.01926, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.339, tt:3610.333\n",
      "Ep:119, loss:0.00001, loss_test:0.01935, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.340, tt:3640.801\n",
      "Ep:120, loss:0.00001, loss_test:0.01942, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.337, tt:3670.736\n",
      "Ep:121, loss:0.00001, loss_test:0.01946, lr:5.82e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.332, tt:3700.463\n",
      "Ep:122, loss:0.00001, loss_test:0.01950, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.324, tt:3729.854\n",
      "Ep:123, loss:0.00001, loss_test:0.01951, lr:5.82e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.322, tt:3759.889\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.01958, lr:5.82e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.332, tt:3791.447\n",
      "Ep:125, loss:0.00001, loss_test:0.01962, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.328, tt:3821.366\n",
      "Ep:126, loss:0.00001, loss_test:0.01964, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.328, tt:3851.717\n",
      "Ep:127, loss:0.00001, loss_test:0.01972, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.325, tt:3881.632\n",
      "Ep:128, loss:0.00001, loss_test:0.01979, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.332, tt:3912.783\n",
      "Ep:129, loss:0.00001, loss_test:0.01977, lr:5.82e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.327, tt:3942.573\n",
      "Ep:130, loss:0.00001, loss_test:0.01984, lr:5.82e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.329, tt:3973.128\n",
      "Ep:131, loss:0.00001, loss_test:0.01988, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.334, tt:4004.055\n",
      "Ep:132, loss:0.00001, loss_test:0.01994, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.350, tt:4036.510\n",
      "Ep:133, loss:0.00001, loss_test:0.02000, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.353, tt:4067.361\n",
      "Ep:134, loss:0.00001, loss_test:0.02002, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.361, tt:4098.700\n",
      "Ep:135, loss:0.00001, loss_test:0.02005, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.370, tt:4130.311\n",
      "Ep:136, loss:0.00001, loss_test:0.02017, lr:5.71e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.379, tt:4161.971\n",
      "Ep:137, loss:0.00001, loss_test:0.02019, lr:5.65e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.373, tt:4191.427\n",
      "Ep:138, loss:0.00001, loss_test:0.02016, lr:5.59e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.383, tt:4223.228\n",
      "Ep:139, loss:0.00001, loss_test:0.02024, lr:5.54e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.393, tt:4254.954\n",
      "Ep:140, loss:0.00001, loss_test:0.02027, lr:5.48e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.410, tt:4287.881\n",
      "Ep:141, loss:0.00001, loss_test:0.02029, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.412, tt:4318.512\n",
      "Ep:142, loss:0.00001, loss_test:0.02037, lr:5.37e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.422, tt:4350.412\n",
      "Ep:143, loss:0.00001, loss_test:0.02039, lr:5.32e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.429, tt:4381.823\n",
      "Ep:144, loss:0.00001, loss_test:0.02037, lr:5.27e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.436, tt:4413.158\n",
      "Ep:145, loss:0.00001, loss_test:0.02043, lr:5.21e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.452, tt:4445.921\n",
      "Ep:146, loss:0.00001, loss_test:0.02058, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.458, tt:4477.394\n",
      "Ep:147, loss:0.00001, loss_test:0.02059, lr:5.11e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.465, tt:4508.783\n",
      "Ep:148, loss:0.00001, loss_test:0.02061, lr:5.06e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.459, tt:4538.398\n",
      "Ep:149, loss:0.00001, loss_test:0.02072, lr:5.01e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.460, tt:4568.944\n",
      "Ep:150, loss:0.00001, loss_test:0.02072, lr:4.96e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.474, tt:4601.520\n",
      "Ep:151, loss:0.00001, loss_test:0.02069, lr:4.91e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.472, tt:4631.746\n",
      "Ep:152, loss:0.00001, loss_test:0.02079, lr:4.86e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.470, tt:4661.884\n",
      "Ep:153, loss:0.00001, loss_test:0.02079, lr:4.81e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.470, tt:4692.399\n",
      "Ep:154, loss:0.00001, loss_test:0.02080, lr:4.76e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.471, tt:4723.009\n",
      "Ep:155, loss:0.00001, loss_test:0.02088, lr:4.71e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.461, tt:4751.972\n",
      "Ep:156, loss:0.00000, loss_test:0.02092, lr:4.67e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.456, tt:4781.658\n",
      "Ep:157, loss:0.00000, loss_test:0.02091, lr:4.62e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.458, tt:4812.389\n",
      "Ep:158, loss:0.00000, loss_test:0.02100, lr:4.57e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.462, tt:4843.497\n",
      "Ep:159, loss:0.00000, loss_test:0.02108, lr:4.53e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.456, tt:4872.882\n",
      "Ep:160, loss:0.00000, loss_test:0.02107, lr:4.48e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.448, tt:4902.144\n",
      "Ep:161, loss:0.00000, loss_test:0.02106, lr:4.44e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.443, tt:4931.744\n",
      "Ep:162, loss:0.00000, loss_test:0.02110, lr:4.39e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.445, tt:4962.527\n",
      "Ep:163, loss:0.00000, loss_test:0.02110, lr:4.35e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.447, tt:4993.274\n",
      "Ep:164, loss:0.00000, loss_test:0.02115, lr:4.31e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.453, tt:5024.805\n",
      "Ep:165, loss:0.00000, loss_test:0.02127, lr:4.26e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.455, tt:5055.583\n",
      "Ep:166, loss:0.00000, loss_test:0.02131, lr:4.22e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.459, tt:5086.578\n",
      "Ep:167, loss:0.00000, loss_test:0.02131, lr:4.18e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.456, tt:5116.562\n",
      "Ep:168, loss:0.00000, loss_test:0.02136, lr:4.14e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.455, tt:5146.853\n",
      "Ep:169, loss:0.00000, loss_test:0.02136, lr:4.10e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.453, tt:5177.061\n",
      "Ep:170, loss:0.00000, loss_test:0.02137, lr:4.05e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.456, tt:5207.909\n",
      "Ep:171, loss:0.00000, loss_test:0.02144, lr:4.01e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.468, tt:5240.491\n",
      "Ep:172, loss:0.00000, loss_test:0.02143, lr:3.97e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.455, tt:5268.630\n",
      "Ep:173, loss:0.00000, loss_test:0.02147, lr:3.93e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.460, tt:5299.988\n",
      "Ep:174, loss:0.00000, loss_test:0.02154, lr:3.89e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.458, tt:5330.235\n",
      "Ep:175, loss:0.00000, loss_test:0.02156, lr:3.86e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.449, tt:5359.062\n",
      "Ep:176, loss:0.00000, loss_test:0.02158, lr:3.82e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.446, tt:5388.861\n",
      "Ep:177, loss:0.00000, loss_test:0.02164, lr:3.78e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.437, tt:5417.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:178, loss:0.00000, loss_test:0.02169, lr:3.74e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.436, tt:5447.966\n",
      "Ep:179, loss:0.00000, loss_test:0.02173, lr:3.70e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.434, tt:5478.185\n",
      "Ep:180, loss:0.00000, loss_test:0.02172, lr:3.67e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.428, tt:5507.436\n",
      "Ep:181, loss:0.00000, loss_test:0.02175, lr:3.63e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.421, tt:5536.535\n",
      "Ep:182, loss:0.00000, loss_test:0.02176, lr:3.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.424, tt:5567.682\n",
      "Ep:183, loss:0.00000, loss_test:0.02182, lr:3.56e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.430, tt:5599.118\n",
      "Ep:184, loss:0.00000, loss_test:0.02187, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.431, tt:5629.656\n",
      "Ep:185, loss:0.00000, loss_test:0.02190, lr:3.49e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.427, tt:5659.471\n",
      "Ep:186, loss:0.00000, loss_test:0.02191, lr:3.45e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.430, tt:5690.455\n",
      "Ep:187, loss:0.00000, loss_test:0.02191, lr:3.42e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.437, tt:5722.194\n",
      "Ep:188, loss:0.00000, loss_test:0.02192, lr:3.38e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.454, tt:5755.733\n",
      "Ep:189, loss:0.00000, loss_test:0.02197, lr:3.35e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.464, tt:5788.164\n",
      "Ep:190, loss:0.00000, loss_test:0.02203, lr:3.32e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.467, tt:5819.138\n",
      "Ep:191, loss:0.00000, loss_test:0.02204, lr:3.28e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.468, tt:5849.817\n",
      "Ep:192, loss:0.00000, loss_test:0.02206, lr:3.25e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.474, tt:5881.484\n",
      "Ep:193, loss:0.00000, loss_test:0.02210, lr:3.22e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.472, tt:5911.592\n",
      "Ep:194, loss:0.00000, loss_test:0.02214, lr:3.19e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.478, tt:5943.131\n",
      "Ep:195, loss:0.00000, loss_test:0.02217, lr:3.15e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.479, tt:5973.898\n",
      "Ep:196, loss:0.00000, loss_test:0.02220, lr:3.12e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.476, tt:6003.725\n",
      "Ep:197, loss:0.00000, loss_test:0.02223, lr:3.09e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.478, tt:6034.688\n",
      "Ep:198, loss:0.00000, loss_test:0.02228, lr:3.06e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.488, tt:6067.025\n",
      "Ep:199, loss:0.00000, loss_test:0.02229, lr:3.03e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.496, tt:6099.236\n",
      "Ep:200, loss:0.00000, loss_test:0.02229, lr:3.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.496, tt:6129.783\n",
      "Ep:201, loss:0.00000, loss_test:0.02230, lr:2.97e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.502, tt:6161.322\n",
      "Ep:202, loss:0.00000, loss_test:0.02235, lr:2.94e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.503, tt:6192.115\n",
      "Ep:203, loss:0.00000, loss_test:0.02237, lr:2.91e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.504, tt:6222.789\n",
      "Ep:204, loss:0.00000, loss_test:0.02238, lr:2.88e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.510, tt:6254.576\n",
      "Ep:205, loss:0.00000, loss_test:0.02240, lr:2.85e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.493, tt:6281.547\n",
      "Ep:206, loss:0.00000, loss_test:0.02243, lr:2.82e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.502, tt:6313.895\n",
      "Ep:207, loss:0.00000, loss_test:0.02244, lr:2.80e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.492, tt:6342.298\n",
      "Ep:208, loss:0.00000, loss_test:0.02247, lr:2.77e-02, fs:0.76471 (r=0.657,p=0.915),  time:30.474, tt:6369.100\n",
      "Ep:209, loss:0.00000, loss_test:0.02249, lr:2.74e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.469, tt:6398.530\n",
      "Ep:210, loss:0.00000, loss_test:0.02253, lr:2.71e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.437, tt:6422.255\n",
      "Ep:211, loss:0.00000, loss_test:0.02251, lr:2.69e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.428, tt:6450.765\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13900, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.327, tt:31.327\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13732, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.473, tt:62.946\n",
      "Ep:2, loss:0.00027, loss_test:0.13436, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:31.419, tt:94.257\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12965, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:31.083, tt:124.331\n",
      "Ep:6, loss:0.00024, loss_test:0.10962, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:31.785, tt:222.492\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10602, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:32.070, tt:256.562\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10430, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:32.164, tt:289.475\n",
      "Ep:9, loss:0.00023, loss_test:0.10354, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:32.217, tt:322.170\n",
      "Ep:10, loss:0.00022, loss_test:0.10304, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:32.285, tt:355.133\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10202, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:32.370, tt:388.435\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09931, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:32.481, tt:422.249\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.09740, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:32.509, tt:455.130\n",
      "Ep:14, loss:0.00020, loss_test:0.09675, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:32.489, tt:487.337\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09556, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:32.420, tt:518.722\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09483, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:32.352, tt:549.987\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09433, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:32.409, tt:583.357\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09365, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:32.396, tt:615.518\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09299, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:32.306, tt:646.118\n",
      "Ep:20, loss:0.00017, loss_test:0.09281, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:32.324, tt:678.809\n",
      "Ep:21, loss:0.00016, loss_test:0.09271, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:32.262, tt:709.761\n",
      "Ep:22, loss:0.00016, loss_test:0.09121, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:32.280, tt:742.448\n",
      "Ep:23, loss:0.00016, loss_test:0.09050, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:32.279, tt:774.689\n",
      "Ep:24, loss:0.00015, loss_test:0.08920, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:32.304, tt:807.597\n",
      "Ep:25, loss:0.00015, loss_test:0.08820, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:32.296, tt:839.692\n",
      "Ep:26, loss:0.00014, loss_test:0.08918, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:32.288, tt:871.778\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08849, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:32.207, tt:901.808\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08732, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:32.179, tt:933.200\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08844, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:32.157, tt:964.709\n",
      "Ep:30, loss:0.00013, loss_test:0.08647, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:32.145, tt:996.491\n",
      "Ep:31, loss:0.00012, loss_test:0.08655, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:32.149, tt:1028.770\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.08605, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.154, tt:1061.097\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00012, loss_test:0.08403, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:32.152, tt:1093.157\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.08586, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.146, tt:1125.116\n",
      "Ep:35, loss:0.00011, loss_test:0.08380, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:32.137, tt:1156.919\n",
      "Ep:36, loss:0.00011, loss_test:0.08342, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.102, tt:1187.787\n",
      "Ep:37, loss:0.00011, loss_test:0.08414, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.066, tt:1218.511\n",
      "Ep:38, loss:0.00010, loss_test:0.08180, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:32.060, tt:1250.322\n",
      "Ep:39, loss:0.00010, loss_test:0.08218, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:32.011, tt:1280.458\n",
      "Ep:40, loss:0.00010, loss_test:0.08167, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.992, tt:1311.674\n",
      "Ep:41, loss:0.00010, loss_test:0.08055, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:31.993, tt:1343.687\n",
      "Ep:42, loss:0.00009, loss_test:0.08001, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:32.009, tt:1376.382\n",
      "Ep:43, loss:0.00009, loss_test:0.07958, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.976, tt:1406.933\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.07943, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.939, tt:1437.261\n",
      "Ep:45, loss:0.00009, loss_test:0.07930, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.940, tt:1469.252\n",
      "Ep:46, loss:0.00008, loss_test:0.07867, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:31.925, tt:1500.491\n",
      "Ep:47, loss:0.00008, loss_test:0.08025, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:31.915, tt:1531.914\n",
      "Ep:48, loss:0.00008, loss_test:0.07688, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.916, tt:1563.890\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.07759, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:31.967, tt:1598.330\n",
      "Ep:50, loss:0.00008, loss_test:0.07542, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.952, tt:1629.534\n",
      "Ep:51, loss:0.00007, loss_test:0.07791, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.956, tt:1661.724\n",
      "Ep:52, loss:0.00007, loss_test:0.07504, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.946, tt:1693.136\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.07502, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:31.935, tt:1724.516\n",
      "Ep:54, loss:0.00007, loss_test:0.07655, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.916, tt:1755.392\n",
      "Ep:55, loss:0.00007, loss_test:0.07401, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.903, tt:1786.579\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.07429, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.900, tt:1818.275\n",
      "Ep:57, loss:0.00006, loss_test:0.07344, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.864, tt:1848.110\n",
      "Ep:58, loss:0.00006, loss_test:0.07585, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.842, tt:1878.677\n",
      "Ep:59, loss:0.00006, loss_test:0.07303, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:31.840, tt:1910.428\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.07579, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.835, tt:1941.932\n",
      "Ep:61, loss:0.00006, loss_test:0.07325, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:31.834, tt:1973.692\n",
      "Ep:62, loss:0.00006, loss_test:0.07343, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.828, tt:2005.154\n",
      "Ep:63, loss:0.00006, loss_test:0.07242, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.827, tt:2036.910\n",
      "Ep:64, loss:0.00006, loss_test:0.07126, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:31.791, tt:2066.404\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.07349, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.780, tt:2097.501\n",
      "Ep:66, loss:0.00005, loss_test:0.07219, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.779, tt:2129.216\n",
      "Ep:67, loss:0.00005, loss_test:0.07209, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.761, tt:2159.716\n",
      "Ep:68, loss:0.00005, loss_test:0.07052, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.742, tt:2190.199\n",
      "Ep:69, loss:0.00005, loss_test:0.07223, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:31.739, tt:2221.759\n",
      "Ep:70, loss:0.00005, loss_test:0.07069, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.729, tt:2252.793\n",
      "Ep:71, loss:0.00005, loss_test:0.07154, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.730, tt:2284.541\n",
      "Ep:72, loss:0.00004, loss_test:0.07020, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.724, tt:2315.846\n",
      "Ep:73, loss:0.00004, loss_test:0.06948, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.721, tt:2347.349\n",
      "Ep:74, loss:0.00004, loss_test:0.06985, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:31.719, tt:2378.902\n",
      "Ep:75, loss:0.00004, loss_test:0.06974, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.692, tt:2408.629\n",
      "Ep:76, loss:0.00004, loss_test:0.07113, lr:9.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.692, tt:2440.248\n",
      "Ep:77, loss:0.00004, loss_test:0.06898, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.686, tt:2471.547\n",
      "Ep:78, loss:0.00004, loss_test:0.06926, lr:9.70e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.668, tt:2501.750\n",
      "Ep:79, loss:0.00004, loss_test:0.06811, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.646, tt:2531.697\n",
      "Ep:80, loss:0.00004, loss_test:0.07551, lr:9.51e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.655, tt:2564.076\n",
      "Ep:81, loss:0.00004, loss_test:0.06838, lr:9.41e-03, fs:0.88542 (r=0.859,p=0.914),  time:31.640, tt:2594.446\n",
      "Ep:82, loss:0.00004, loss_test:0.07481, lr:9.32e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.630, tt:2625.265\n",
      "Ep:83, loss:0.00004, loss_test:0.06950, lr:9.23e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.628, tt:2656.773\n",
      "Ep:84, loss:0.00004, loss_test:0.07527, lr:9.14e-03, fs:0.83429 (r=0.737,p=0.961),  time:31.627, tt:2688.279\n",
      "Ep:85, loss:0.00004, loss_test:0.07090, lr:9.04e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.626, tt:2719.794\n",
      "Ep:86, loss:0.00004, loss_test:0.07012, lr:8.95e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.613, tt:2750.295\n",
      "Ep:87, loss:0.00004, loss_test:0.07069, lr:8.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.594, tt:2780.255\n",
      "Ep:88, loss:0.00004, loss_test:0.07084, lr:8.78e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.602, tt:2812.543\n",
      "Ep:89, loss:0.00003, loss_test:0.06787, lr:8.69e-03, fs:0.90256 (r=0.889,p=0.917),  time:31.598, tt:2843.842\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00003, loss_test:0.07232, lr:8.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.591, tt:2874.768\n",
      "Ep:91, loss:0.00003, loss_test:0.06795, lr:8.69e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.588, tt:2906.135\n",
      "Ep:92, loss:0.00003, loss_test:0.06852, lr:8.69e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.588, tt:2937.666\n",
      "Ep:93, loss:0.00003, loss_test:0.06882, lr:8.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.587, tt:2969.203\n",
      "Ep:94, loss:0.00003, loss_test:0.06698, lr:8.69e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.582, tt:3000.322\n",
      "Ep:95, loss:0.00003, loss_test:0.06874, lr:8.69e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.572, tt:3030.913\n",
      "Ep:96, loss:0.00003, loss_test:0.06824, lr:8.69e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.589, tt:3064.176\n",
      "Ep:97, loss:0.00003, loss_test:0.06624, lr:8.69e-03, fs:0.89005 (r=0.859,p=0.924),  time:31.580, tt:3094.859\n",
      "Ep:98, loss:0.00003, loss_test:0.07049, lr:8.69e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.582, tt:3126.586\n",
      "Ep:99, loss:0.00003, loss_test:0.06620, lr:8.69e-03, fs:0.89691 (r=0.879,p=0.916),  time:31.576, tt:3157.606\n",
      "Ep:100, loss:0.00003, loss_test:0.07107, lr:8.69e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.584, tt:3189.958\n",
      "Ep:101, loss:0.00002, loss_test:0.06602, lr:8.60e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.579, tt:3221.108\n",
      "Ep:102, loss:0.00002, loss_test:0.06815, lr:8.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.579, tt:3252.664\n",
      "Ep:103, loss:0.00002, loss_test:0.06605, lr:8.43e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.563, tt:3282.576\n",
      "Ep:104, loss:0.00002, loss_test:0.06780, lr:8.35e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.570, tt:3314.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00002, loss_test:0.06655, lr:8.26e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.562, tt:3345.622\n",
      "Ep:106, loss:0.00002, loss_test:0.06558, lr:8.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.576, tt:3378.636\n",
      "Ep:107, loss:0.00002, loss_test:0.06874, lr:8.10e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.576, tt:3410.168\n",
      "Ep:108, loss:0.00002, loss_test:0.06529, lr:8.02e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.576, tt:3441.807\n",
      "Ep:109, loss:0.00002, loss_test:0.06719, lr:7.94e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.555, tt:3471.056\n",
      "Ep:110, loss:0.00002, loss_test:0.06469, lr:7.86e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.518, tt:3498.460\n",
      "Ep:111, loss:0.00002, loss_test:0.06786, lr:7.78e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.525, tt:3530.815\n",
      "Ep:112, loss:0.00002, loss_test:0.06457, lr:7.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.510, tt:3560.678\n",
      "Ep:113, loss:0.00002, loss_test:0.06642, lr:7.62e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.516, tt:3592.853\n",
      "Ep:114, loss:0.00002, loss_test:0.06604, lr:7.55e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.512, tt:3623.884\n",
      "Ep:115, loss:0.00002, loss_test:0.06494, lr:7.47e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.515, tt:3655.763\n",
      "Ep:116, loss:0.00002, loss_test:0.06676, lr:7.40e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.497, tt:3685.118\n",
      "Ep:117, loss:0.00002, loss_test:0.06536, lr:7.32e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.501, tt:3717.065\n",
      "Ep:118, loss:0.00002, loss_test:0.06501, lr:7.25e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.496, tt:3748.019\n",
      "Ep:119, loss:0.00002, loss_test:0.06544, lr:7.18e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.489, tt:3778.698\n",
      "Ep:120, loss:0.00002, loss_test:0.06540, lr:7.11e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.493, tt:3810.636\n",
      "Ep:121, loss:0.00002, loss_test:0.06512, lr:7.03e-03, fs:0.87912 (r=0.808,p=0.964),  time:31.489, tt:3841.607\n",
      "Ep:122, loss:0.00002, loss_test:0.06551, lr:6.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.484, tt:3872.563\n",
      "Ep:123, loss:0.00002, loss_test:0.06478, lr:6.89e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.474, tt:3902.730\n",
      "Ep:124, loss:0.00002, loss_test:0.06535, lr:6.83e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.475, tt:3934.335\n",
      "Ep:125, loss:0.00002, loss_test:0.06419, lr:6.76e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.485, tt:3967.098\n",
      "Ep:126, loss:0.00002, loss_test:0.06524, lr:6.69e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.487, tt:3998.857\n",
      "Ep:127, loss:0.00002, loss_test:0.06592, lr:6.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.501, tt:4032.130\n",
      "Ep:128, loss:0.00002, loss_test:0.06674, lr:6.56e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.500, tt:4063.478\n",
      "Ep:129, loss:0.00001, loss_test:0.06358, lr:6.49e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.507, tt:4095.960\n",
      "Ep:130, loss:0.00001, loss_test:0.06714, lr:6.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.500, tt:4126.453\n",
      "Ep:131, loss:0.00001, loss_test:0.06462, lr:6.36e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.514, tt:4159.884\n",
      "Ep:132, loss:0.00001, loss_test:0.06694, lr:6.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.514, tt:4191.314\n",
      "Ep:133, loss:0.00001, loss_test:0.06615, lr:6.24e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.506, tt:4221.805\n",
      "Ep:134, loss:0.00001, loss_test:0.06406, lr:6.17e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.510, tt:4253.839\n",
      "Ep:135, loss:0.00001, loss_test:0.06603, lr:6.11e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.513, tt:4285.745\n",
      "Ep:136, loss:0.00001, loss_test:0.06449, lr:6.05e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.525, tt:4318.984\n",
      "Ep:137, loss:0.00001, loss_test:0.06449, lr:5.99e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.522, tt:4349.968\n",
      "Ep:138, loss:0.00001, loss_test:0.06380, lr:5.93e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.510, tt:4379.928\n",
      "Ep:139, loss:0.00001, loss_test:0.06571, lr:5.87e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.516, tt:4412.303\n",
      "Ep:140, loss:0.00001, loss_test:0.06374, lr:5.81e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.505, tt:4442.139\n",
      "Ep:141, loss:0.00001, loss_test:0.06642, lr:5.75e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.502, tt:4473.338\n",
      "Ep:142, loss:0.00001, loss_test:0.06505, lr:5.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.505, tt:4505.197\n",
      "Ep:143, loss:0.00001, loss_test:0.06376, lr:5.64e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.498, tt:4535.732\n",
      "Ep:144, loss:0.00001, loss_test:0.06552, lr:5.58e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.494, tt:4566.582\n",
      "Ep:145, loss:0.00001, loss_test:0.06371, lr:5.53e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.500, tt:4598.938\n",
      "Ep:146, loss:0.00001, loss_test:0.06469, lr:5.47e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.497, tt:4630.108\n",
      "Ep:147, loss:0.00001, loss_test:0.06523, lr:5.42e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.491, tt:4660.653\n",
      "Ep:148, loss:0.00001, loss_test:0.06361, lr:5.36e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.480, tt:4690.491\n",
      "Ep:149, loss:0.00001, loss_test:0.06449, lr:5.31e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.475, tt:4721.307\n",
      "Ep:150, loss:0.00001, loss_test:0.06430, lr:5.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.474, tt:4752.617\n",
      "Ep:151, loss:0.00001, loss_test:0.06337, lr:5.20e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.472, tt:4783.696\n",
      "Ep:152, loss:0.00001, loss_test:0.06377, lr:5.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.481, tt:4816.635\n",
      "Ep:153, loss:0.00001, loss_test:0.06431, lr:5.10e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.486, tt:4848.867\n",
      "Ep:154, loss:0.00001, loss_test:0.06377, lr:5.05e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.493, tt:4881.351\n",
      "Ep:155, loss:0.00001, loss_test:0.06417, lr:5.00e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.504, tt:4914.654\n",
      "Ep:156, loss:0.00001, loss_test:0.06410, lr:4.95e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.517, tt:4948.105\n",
      "Ep:157, loss:0.00001, loss_test:0.06347, lr:4.90e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.516, tt:4979.592\n",
      "Ep:158, loss:0.00001, loss_test:0.06567, lr:4.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.504, tt:5009.078\n",
      "Ep:159, loss:0.00001, loss_test:0.06584, lr:4.80e-03, fs:0.84091 (r=0.747,p=0.961),  time:31.496, tt:5039.337\n",
      "Ep:160, loss:0.00001, loss_test:0.06340, lr:4.75e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.496, tt:5070.876\n",
      "Ep:161, loss:0.00001, loss_test:0.06472, lr:4.71e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.490, tt:5101.443\n",
      "Ep:162, loss:0.00001, loss_test:0.06438, lr:4.66e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.490, tt:5132.913\n",
      "Ep:163, loss:0.00001, loss_test:0.06317, lr:4.61e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.478, tt:5162.356\n",
      "Ep:164, loss:0.00001, loss_test:0.06434, lr:4.57e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.469, tt:5192.346\n",
      "Ep:165, loss:0.00001, loss_test:0.06382, lr:4.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.469, tt:5223.850\n",
      "Ep:166, loss:0.00001, loss_test:0.06362, lr:4.48e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.468, tt:5255.180\n",
      "Ep:167, loss:0.00001, loss_test:0.06333, lr:4.43e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.470, tt:5286.973\n",
      "Ep:168, loss:0.00001, loss_test:0.06426, lr:4.39e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.466, tt:5317.676\n",
      "Ep:169, loss:0.00001, loss_test:0.06379, lr:4.34e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.457, tt:5347.746\n",
      "Ep:170, loss:0.00001, loss_test:0.06398, lr:4.30e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.464, tt:5380.331\n",
      "Ep:171, loss:0.00001, loss_test:0.06424, lr:4.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.471, tt:5412.957\n",
      "Ep:172, loss:0.00001, loss_test:0.06352, lr:4.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.469, tt:5444.092\n",
      "Ep:173, loss:0.00001, loss_test:0.06423, lr:4.17e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.465, tt:5474.888\n",
      "Ep:174, loss:0.00001, loss_test:0.06388, lr:4.13e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.464, tt:5506.186\n",
      "Ep:175, loss:0.00001, loss_test:0.06408, lr:4.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.468, tt:5538.288\n",
      "Ep:176, loss:0.00001, loss_test:0.06421, lr:4.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.460, tt:5568.475\n",
      "Ep:177, loss:0.00001, loss_test:0.06432, lr:4.01e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.466, tt:5600.994\n",
      "Ep:178, loss:0.00001, loss_test:0.06431, lr:3.97e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.471, tt:5633.229\n",
      "Ep:179, loss:0.00001, loss_test:0.06366, lr:3.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.465, tt:5663.652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00001, loss_test:0.06492, lr:3.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.465, tt:5695.230\n",
      "Ep:181, loss:0.00001, loss_test:0.06407, lr:3.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.471, tt:5727.658\n",
      "Ep:182, loss:0.00001, loss_test:0.06460, lr:3.81e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.476, tt:5760.080\n",
      "Ep:183, loss:0.00001, loss_test:0.06515, lr:3.77e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.468, tt:5790.111\n",
      "Ep:184, loss:0.00001, loss_test:0.06352, lr:3.73e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.469, tt:5821.759\n",
      "Ep:185, loss:0.00001, loss_test:0.06423, lr:3.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.464, tt:5852.230\n",
      "Ep:186, loss:0.00001, loss_test:0.06491, lr:3.66e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.460, tt:5882.969\n",
      "Ep:187, loss:0.00001, loss_test:0.06368, lr:3.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.464, tt:5915.177\n",
      "Ep:188, loss:0.00001, loss_test:0.06445, lr:3.59e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.453, tt:5944.559\n",
      "Ep:189, loss:0.00001, loss_test:0.06464, lr:3.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.452, tt:5975.874\n",
      "Ep:190, loss:0.00001, loss_test:0.06319, lr:3.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.459, tt:6008.585\n",
      "Ep:191, loss:0.00001, loss_test:0.06439, lr:3.48e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.452, tt:6038.844\n",
      "Ep:192, loss:0.00001, loss_test:0.06489, lr:3.45e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.448, tt:6069.403\n",
      "Ep:193, loss:0.00001, loss_test:0.06365, lr:3.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.447, tt:6100.798\n",
      "Ep:194, loss:0.00001, loss_test:0.06429, lr:3.38e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.452, tt:6133.141\n",
      "Ep:195, loss:0.00001, loss_test:0.06483, lr:3.34e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.455, tt:6165.172\n",
      "Ep:196, loss:0.00001, loss_test:0.06385, lr:3.31e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.452, tt:6196.091\n",
      "Ep:197, loss:0.00001, loss_test:0.06405, lr:3.28e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.451, tt:6227.283\n",
      "Ep:198, loss:0.00001, loss_test:0.06466, lr:3.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.450, tt:6258.605\n",
      "Ep:199, loss:0.00001, loss_test:0.06368, lr:3.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.456, tt:6291.301\n",
      "Ep:200, loss:0.00001, loss_test:0.06492, lr:3.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.452, tt:6321.860\n",
      "Ep:201, loss:0.00001, loss_test:0.06483, lr:3.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.462, tt:6355.363\n",
      "Ep:202, loss:0.00001, loss_test:0.06371, lr:3.12e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.457, tt:6385.711\n",
      "Ep:203, loss:0.00001, loss_test:0.06387, lr:3.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.459, tt:6417.552\n",
      "Ep:204, loss:0.00001, loss_test:0.06391, lr:3.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.443, tt:6445.823\n",
      "Ep:205, loss:0.00001, loss_test:0.06342, lr:3.02e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.432, tt:6475.066\n",
      "Ep:206, loss:0.00001, loss_test:0.06408, lr:2.99e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.424, tt:6504.721\n",
      "Ep:207, loss:0.00001, loss_test:0.06448, lr:2.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.414, tt:6534.153\n",
      "Ep:208, loss:0.00001, loss_test:0.06380, lr:2.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.400, tt:6562.628\n",
      "Ep:209, loss:0.00001, loss_test:0.06377, lr:2.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.352, tt:6583.919\n",
      "Ep:210, loss:0.00001, loss_test:0.06430, lr:2.88e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.310, tt:6606.387\n",
      "Ep:211, loss:0.00001, loss_test:0.06375, lr:2.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.276, tt:6630.534\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02032, lr:6.00e-02, fs:0.63158 (r=0.667,p=0.600),  time:30.418, tt:30.418\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02080, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.454, tt:58.908\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02346, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.326, tt:87.978\n",
      "Ep:3, loss:0.00005, loss_test:0.02476, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.950, tt:115.799\n",
      "Ep:4, loss:0.00005, loss_test:0.02508, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.081, tt:145.404\n",
      "Ep:5, loss:0.00005, loss_test:0.02467, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.141, tt:174.848\n",
      "Ep:6, loss:0.00005, loss_test:0.02376, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.357, tt:205.499\n",
      "Ep:7, loss:0.00005, loss_test:0.02244, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.425, tt:235.402\n",
      "Ep:8, loss:0.00004, loss_test:0.02080, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.397, tt:264.569\n",
      "Ep:9, loss:0.00004, loss_test:0.01910, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:29.378, tt:293.777\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01768, lr:6.00e-02, fs:0.68327 (r=0.970,p=0.527),  time:29.437, tt:323.807\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01693, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:29.467, tt:353.608\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01696, lr:6.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:29.489, tt:383.356\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:29.558, tt:413.817\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01731, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:29.758, tt:446.367\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01696, lr:6.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:29.888, tt:478.209\n",
      "Ep:16, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:29.876, tt:507.895\n",
      "Ep:17, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:29.902, tt:538.238\n",
      "Ep:18, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:29.908, tt:568.260\n",
      "Ep:19, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:29.926, tt:598.526\n",
      "Ep:20, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:29.884, tt:627.557\n",
      "Ep:21, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:29.807, tt:655.765\n",
      "Ep:22, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:29.774, tt:684.799\n",
      "Ep:23, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:29.805, tt:715.326\n",
      "Ep:24, loss:0.00003, loss_test:0.01628, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:29.829, tt:745.721\n",
      "Ep:25, loss:0.00003, loss_test:0.01623, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.815, tt:775.177\n",
      "Ep:26, loss:0.00003, loss_test:0.01612, lr:5.94e-02, fs:0.75455 (r=0.838,p=0.686),  time:29.859, tt:806.204\n",
      "Ep:27, loss:0.00002, loss_test:0.01598, lr:5.88e-02, fs:0.75113 (r=0.838,p=0.680),  time:29.880, tt:836.638\n",
      "Ep:28, loss:0.00002, loss_test:0.01584, lr:5.82e-02, fs:0.75113 (r=0.838,p=0.680),  time:29.855, tt:865.809\n",
      "Ep:29, loss:0.00002, loss_test:0.01575, lr:5.76e-02, fs:0.75113 (r=0.838,p=0.680),  time:29.784, tt:893.528\n",
      "Ep:30, loss:0.00002, loss_test:0.01569, lr:5.71e-02, fs:0.75799 (r=0.838,p=0.692),  time:29.818, tt:924.367\n",
      "Ep:31, loss:0.00002, loss_test:0.01567, lr:5.65e-02, fs:0.76147 (r=0.838,p=0.697),  time:29.841, tt:954.911\n",
      "Ep:32, loss:0.00002, loss_test:0.01569, lr:5.59e-02, fs:0.76498 (r=0.838,p=0.703),  time:29.875, tt:985.866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00002, loss_test:0.01569, lr:5.54e-02, fs:0.77209 (r=0.838,p=0.716),  time:29.873, tt:1015.673\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01569, lr:5.54e-02, fs:0.77570 (r=0.838,p=0.722),  time:29.854, tt:1044.901\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01568, lr:5.54e-02, fs:0.77570 (r=0.838,p=0.722),  time:29.869, tt:1075.282\n",
      "Ep:36, loss:0.00002, loss_test:0.01564, lr:5.54e-02, fs:0.77570 (r=0.838,p=0.722),  time:29.869, tt:1105.150\n",
      "Ep:37, loss:0.00002, loss_test:0.01559, lr:5.54e-02, fs:0.78505 (r=0.848,p=0.730),  time:29.891, tt:1135.870\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01554, lr:5.54e-02, fs:0.79070 (r=0.859,p=0.733),  time:29.945, tt:1167.857\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01550, lr:5.54e-02, fs:0.79070 (r=0.859,p=0.733),  time:29.945, tt:1197.809\n",
      "Ep:40, loss:0.00002, loss_test:0.01548, lr:5.54e-02, fs:0.80189 (r=0.859,p=0.752),  time:29.951, tt:1227.984\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01547, lr:5.54e-02, fs:0.80569 (r=0.859,p=0.759),  time:29.970, tt:1258.746\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01548, lr:5.54e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.954, tt:1288.020\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01548, lr:5.54e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.953, tt:1317.931\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01546, lr:5.54e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.967, tt:1348.498\n",
      "Ep:45, loss:0.00002, loss_test:0.01544, lr:5.54e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.971, tt:1378.662\n",
      "Ep:46, loss:0.00002, loss_test:0.01541, lr:5.54e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.003, tt:1410.154\n",
      "Ep:47, loss:0.00002, loss_test:0.01538, lr:5.54e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.020, tt:1440.968\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01537, lr:5.54e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.042, tt:1472.051\n",
      "Ep:49, loss:0.00002, loss_test:0.01536, lr:5.54e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.026, tt:1501.283\n",
      "Ep:50, loss:0.00002, loss_test:0.01536, lr:5.54e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.051, tt:1532.613\n",
      "Ep:51, loss:0.00002, loss_test:0.01535, lr:5.54e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.063, tt:1563.252\n",
      "Ep:52, loss:0.00002, loss_test:0.01534, lr:5.54e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.085, tt:1594.488\n",
      "Ep:53, loss:0.00002, loss_test:0.01534, lr:5.54e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.115, tt:1626.235\n",
      "Ep:54, loss:0.00001, loss_test:0.01533, lr:5.54e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.118, tt:1656.465\n",
      "Ep:55, loss:0.00001, loss_test:0.01533, lr:5.54e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.139, tt:1687.800\n",
      "Ep:56, loss:0.00001, loss_test:0.01532, lr:5.54e-02, fs:0.81000 (r=0.818,p=0.802),  time:30.139, tt:1717.923\n",
      "Ep:57, loss:0.00001, loss_test:0.01532, lr:5.54e-02, fs:0.80402 (r=0.808,p=0.800),  time:30.144, tt:1748.374\n",
      "Ep:58, loss:0.00001, loss_test:0.01533, lr:5.54e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.173, tt:1780.233\n",
      "Ep:59, loss:0.00001, loss_test:0.01533, lr:5.48e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.186, tt:1811.162\n",
      "Ep:60, loss:0.00001, loss_test:0.01533, lr:5.43e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.166, tt:1840.096\n",
      "Ep:61, loss:0.00001, loss_test:0.01534, lr:5.37e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.162, tt:1870.072\n",
      "Ep:62, loss:0.00001, loss_test:0.01533, lr:5.32e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.154, tt:1899.724\n",
      "Ep:63, loss:0.00001, loss_test:0.01533, lr:5.27e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.189, tt:1932.091\n",
      "Ep:64, loss:0.00001, loss_test:0.01533, lr:5.21e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.175, tt:1961.385\n",
      "Ep:65, loss:0.00001, loss_test:0.01533, lr:5.16e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.181, tt:1991.948\n",
      "Ep:66, loss:0.00001, loss_test:0.01534, lr:5.11e-02, fs:0.74595 (r=0.697,p=0.802),  time:30.188, tt:2022.562\n",
      "Ep:67, loss:0.00001, loss_test:0.01534, lr:5.06e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.176, tt:2051.961\n",
      "Ep:68, loss:0.00001, loss_test:0.01537, lr:5.01e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.186, tt:2082.819\n",
      "Ep:69, loss:0.00001, loss_test:0.01539, lr:4.96e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.183, tt:2112.790\n",
      "Ep:70, loss:0.00001, loss_test:0.01539, lr:4.91e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.213, tt:2145.126\n",
      "Ep:71, loss:0.00001, loss_test:0.01539, lr:4.86e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.230, tt:2176.557\n",
      "Ep:72, loss:0.00001, loss_test:0.01540, lr:4.81e-02, fs:0.73626 (r=0.677,p=0.807),  time:30.232, tt:2206.920\n",
      "Ep:73, loss:0.00001, loss_test:0.01539, lr:4.76e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.230, tt:2237.030\n",
      "Ep:74, loss:0.00001, loss_test:0.01539, lr:4.71e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.227, tt:2267.037\n",
      "Ep:75, loss:0.00001, loss_test:0.01538, lr:4.67e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.227, tt:2297.271\n",
      "Ep:76, loss:0.00001, loss_test:0.01539, lr:4.62e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.220, tt:2326.918\n",
      "Ep:77, loss:0.00001, loss_test:0.01543, lr:4.57e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.201, tt:2355.646\n",
      "Ep:78, loss:0.00001, loss_test:0.01544, lr:4.53e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.203, tt:2386.065\n",
      "Ep:79, loss:0.00001, loss_test:0.01545, lr:4.48e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.210, tt:2416.774\n",
      "Ep:80, loss:0.00001, loss_test:0.01547, lr:4.44e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.207, tt:2446.732\n",
      "Ep:81, loss:0.00001, loss_test:0.01548, lr:4.39e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.215, tt:2477.591\n",
      "Ep:82, loss:0.00001, loss_test:0.01550, lr:4.35e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.212, tt:2507.630\n",
      "Ep:83, loss:0.00001, loss_test:0.01553, lr:4.31e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.233, tt:2539.532\n",
      "Ep:84, loss:0.00001, loss_test:0.01554, lr:4.26e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.246, tt:2570.883\n",
      "Ep:85, loss:0.00001, loss_test:0.01555, lr:4.22e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.252, tt:2601.661\n",
      "Ep:86, loss:0.00001, loss_test:0.01554, lr:4.18e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.264, tt:2632.965\n",
      "Ep:87, loss:0.00001, loss_test:0.01556, lr:4.14e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.283, tt:2664.935\n",
      "Ep:88, loss:0.00001, loss_test:0.01557, lr:4.10e-02, fs:0.74713 (r=0.657,p=0.867),  time:30.285, tt:2695.366\n",
      "Ep:89, loss:0.00001, loss_test:0.01558, lr:4.05e-02, fs:0.74713 (r=0.657,p=0.867),  time:30.281, tt:2725.321\n",
      "Ep:90, loss:0.00001, loss_test:0.01558, lr:4.01e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.282, tt:2755.708\n",
      "Ep:91, loss:0.00001, loss_test:0.01560, lr:3.97e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.277, tt:2785.492\n",
      "Ep:92, loss:0.00001, loss_test:0.01562, lr:3.93e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.265, tt:2814.691\n",
      "Ep:93, loss:0.00001, loss_test:0.01563, lr:3.89e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.275, tt:2845.850\n",
      "Ep:94, loss:0.00001, loss_test:0.01564, lr:3.86e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.266, tt:2875.256\n",
      "Ep:95, loss:0.00001, loss_test:0.01565, lr:3.82e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.263, tt:2905.227\n",
      "Ep:96, loss:0.00001, loss_test:0.01566, lr:3.78e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.260, tt:2935.259\n",
      "Ep:97, loss:0.00001, loss_test:0.01568, lr:3.74e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.263, tt:2965.794\n",
      "Ep:98, loss:0.00001, loss_test:0.01569, lr:3.70e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.252, tt:2994.929\n",
      "Ep:99, loss:0.00001, loss_test:0.01571, lr:3.67e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.251, tt:3025.107\n",
      "Ep:100, loss:0.00001, loss_test:0.01572, lr:3.63e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.251, tt:3055.386\n",
      "Ep:101, loss:0.00001, loss_test:0.01573, lr:3.59e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.261, tt:3086.648\n",
      "Ep:102, loss:0.00001, loss_test:0.01573, lr:3.56e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.254, tt:3116.152\n",
      "Ep:103, loss:0.00001, loss_test:0.01574, lr:3.52e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.241, tt:3145.084\n",
      "Ep:104, loss:0.00001, loss_test:0.01576, lr:3.49e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.214, tt:3172.440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00001, loss_test:0.01578, lr:3.45e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.211, tt:3202.345\n",
      "Ep:106, loss:0.00001, loss_test:0.01580, lr:3.42e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.211, tt:3232.572\n",
      "Ep:107, loss:0.00001, loss_test:0.01581, lr:3.38e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.214, tt:3263.159\n",
      "Ep:108, loss:0.00001, loss_test:0.01581, lr:3.35e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.221, tt:3294.134\n",
      "Ep:109, loss:0.00001, loss_test:0.01583, lr:3.32e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.232, tt:3325.524\n",
      "Ep:110, loss:0.00001, loss_test:0.01584, lr:3.28e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.244, tt:3357.088\n",
      "Ep:111, loss:0.00001, loss_test:0.01587, lr:3.25e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.252, tt:3388.223\n",
      "Ep:112, loss:0.00001, loss_test:0.01589, lr:3.22e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.257, tt:3419.094\n",
      "Ep:113, loss:0.00001, loss_test:0.01591, lr:3.19e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.257, tt:3449.245\n",
      "Ep:114, loss:0.00001, loss_test:0.01591, lr:3.15e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.254, tt:3479.156\n",
      "Ep:115, loss:0.00001, loss_test:0.01591, lr:3.12e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.262, tt:3510.352\n",
      "Ep:116, loss:0.00001, loss_test:0.01593, lr:3.09e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.262, tt:3540.666\n",
      "Ep:117, loss:0.00001, loss_test:0.01595, lr:3.06e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.284, tt:3573.550\n",
      "Ep:118, loss:0.00001, loss_test:0.01597, lr:3.03e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.275, tt:3602.758\n",
      "Ep:119, loss:0.00001, loss_test:0.01598, lr:3.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.273, tt:3632.788\n",
      "Ep:120, loss:0.00001, loss_test:0.01599, lr:2.97e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.278, tt:3663.610\n",
      "Ep:121, loss:0.00001, loss_test:0.01599, lr:2.94e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.290, tt:3695.353\n",
      "Ep:122, loss:0.00001, loss_test:0.01600, lr:2.91e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.284, tt:3724.888\n",
      "Ep:123, loss:0.00001, loss_test:0.01601, lr:2.88e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.274, tt:3754.027\n",
      "Ep:124, loss:0.00001, loss_test:0.01603, lr:2.85e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.279, tt:3784.878\n",
      "Ep:125, loss:0.00001, loss_test:0.01606, lr:2.82e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.281, tt:3815.368\n",
      "Ep:126, loss:0.00001, loss_test:0.01608, lr:2.80e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.278, tt:3845.260\n",
      "Ep:127, loss:0.00001, loss_test:0.01608, lr:2.77e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.280, tt:3875.822\n",
      "Ep:128, loss:0.00001, loss_test:0.01609, lr:2.74e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.269, tt:3904.714\n",
      "Ep:129, loss:0.00001, loss_test:0.01610, lr:2.71e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.263, tt:3934.227\n",
      "Ep:130, loss:0.00001, loss_test:0.01612, lr:2.69e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.255, tt:3963.422\n",
      "Ep:131, loss:0.00001, loss_test:0.01614, lr:2.66e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.257, tt:3993.881\n",
      "Ep:132, loss:0.00001, loss_test:0.01616, lr:2.63e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.247, tt:4022.880\n",
      "Ep:133, loss:0.00001, loss_test:0.01617, lr:2.61e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.249, tt:4053.332\n",
      "Ep:134, loss:0.00001, loss_test:0.01619, lr:2.58e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.254, tt:4084.311\n",
      "Ep:135, loss:0.00001, loss_test:0.01621, lr:2.55e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.247, tt:4113.586\n",
      "Ep:136, loss:0.00001, loss_test:0.01622, lr:2.53e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.245, tt:4143.601\n",
      "Ep:137, loss:0.00001, loss_test:0.01622, lr:2.50e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.244, tt:4173.732\n",
      "Ep:138, loss:0.00001, loss_test:0.01623, lr:2.48e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.248, tt:4204.468\n",
      "Ep:139, loss:0.00001, loss_test:0.01624, lr:2.45e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.270, tt:4237.851\n",
      "Ep:140, loss:0.00001, loss_test:0.01627, lr:2.43e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.273, tt:4268.481\n",
      "Ep:141, loss:0.00001, loss_test:0.01628, lr:2.40e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.266, tt:4297.740\n",
      "Ep:142, loss:0.00001, loss_test:0.01630, lr:2.38e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.263, tt:4327.668\n",
      "Ep:143, loss:0.00001, loss_test:0.01632, lr:2.36e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.265, tt:4358.139\n",
      "Ep:144, loss:0.00001, loss_test:0.01633, lr:2.33e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.258, tt:4387.378\n",
      "Ep:145, loss:0.00001, loss_test:0.01634, lr:2.31e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.254, tt:4417.074\n",
      "Ep:146, loss:0.00001, loss_test:0.01635, lr:2.29e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.243, tt:4445.750\n",
      "Ep:147, loss:0.00001, loss_test:0.01635, lr:2.26e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.246, tt:4476.477\n",
      "Ep:148, loss:0.00001, loss_test:0.01636, lr:2.24e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.246, tt:4506.637\n",
      "Ep:149, loss:0.00001, loss_test:0.01637, lr:2.22e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.248, tt:4537.200\n",
      "Ep:150, loss:0.00001, loss_test:0.01638, lr:2.20e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.244, tt:4566.803\n",
      "Ep:151, loss:0.00001, loss_test:0.01638, lr:2.17e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.242, tt:4596.827\n",
      "Ep:152, loss:0.00001, loss_test:0.01639, lr:2.15e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.244, tt:4627.385\n",
      "Ep:153, loss:0.00001, loss_test:0.01641, lr:2.13e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.246, tt:4657.896\n",
      "Ep:154, loss:0.00001, loss_test:0.01642, lr:2.11e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.246, tt:4688.074\n",
      "Ep:155, loss:0.00001, loss_test:0.01643, lr:2.09e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.242, tt:4717.826\n",
      "Ep:156, loss:0.00001, loss_test:0.01644, lr:2.07e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.240, tt:4747.660\n",
      "Ep:157, loss:0.00001, loss_test:0.01645, lr:2.05e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.230, tt:4776.328\n",
      "Ep:158, loss:0.00001, loss_test:0.01646, lr:2.03e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.232, tt:4806.855\n",
      "Ep:159, loss:0.00001, loss_test:0.01648, lr:2.01e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.227, tt:4836.277\n",
      "Ep:160, loss:0.00001, loss_test:0.01649, lr:1.99e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.225, tt:4866.268\n",
      "Ep:161, loss:0.00001, loss_test:0.01650, lr:1.97e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.223, tt:4896.117\n",
      "Ep:162, loss:0.00001, loss_test:0.01651, lr:1.95e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.227, tt:4926.963\n",
      "Ep:163, loss:0.00001, loss_test:0.01652, lr:1.93e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.226, tt:4957.091\n",
      "Ep:164, loss:0.00001, loss_test:0.01653, lr:1.91e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.226, tt:4987.222\n",
      "Ep:165, loss:0.00001, loss_test:0.01654, lr:1.89e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.229, tt:5018.041\n",
      "Ep:166, loss:0.00001, loss_test:0.01655, lr:1.87e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.220, tt:5046.703\n",
      "Ep:167, loss:0.00001, loss_test:0.01657, lr:1.85e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.223, tt:5077.430\n",
      "Ep:168, loss:0.00001, loss_test:0.01658, lr:1.83e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.225, tt:5108.092\n",
      "Ep:169, loss:0.00001, loss_test:0.01660, lr:1.81e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.226, tt:5138.495\n",
      "Ep:170, loss:0.00001, loss_test:0.01660, lr:1.80e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.233, tt:5169.859\n",
      "Ep:171, loss:0.00001, loss_test:0.01662, lr:1.78e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.238, tt:5200.979\n",
      "Ep:172, loss:0.00001, loss_test:0.01664, lr:1.76e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.245, tt:5232.302\n",
      "Ep:173, loss:0.00001, loss_test:0.01665, lr:1.74e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.250, tt:5263.429\n",
      "Ep:174, loss:0.00001, loss_test:0.01666, lr:1.73e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.259, tt:5295.335\n",
      "Ep:175, loss:0.00001, loss_test:0.01668, lr:1.71e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.260, tt:5325.765\n",
      "Ep:176, loss:0.00001, loss_test:0.01668, lr:1.69e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.264, tt:5356.796\n",
      "Ep:177, loss:0.00001, loss_test:0.01669, lr:1.67e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.291, tt:5391.727\n",
      "Ep:178, loss:0.00001, loss_test:0.01670, lr:1.66e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.287, tt:5421.397\n",
      "Ep:179, loss:0.00001, loss_test:0.01672, lr:1.64e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.289, tt:5452.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00001, loss_test:0.01673, lr:1.62e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.284, tt:5481.349\n",
      "Ep:181, loss:0.00001, loss_test:0.01674, lr:1.61e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.276, tt:5510.170\n",
      "Ep:182, loss:0.00001, loss_test:0.01675, lr:1.59e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.280, tt:5541.266\n",
      "Ep:183, loss:0.00001, loss_test:0.01675, lr:1.58e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.280, tt:5571.440\n",
      "Ep:184, loss:0.00001, loss_test:0.01676, lr:1.56e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.279, tt:5601.527\n",
      "Ep:185, loss:0.00001, loss_test:0.01677, lr:1.54e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.274, tt:5631.053\n",
      "Ep:186, loss:0.00001, loss_test:0.01678, lr:1.53e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.270, tt:5660.459\n",
      "Ep:187, loss:0.00001, loss_test:0.01680, lr:1.51e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.267, tt:5690.290\n",
      "Ep:188, loss:0.00001, loss_test:0.01681, lr:1.50e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.261, tt:5719.385\n",
      "Ep:189, loss:0.00001, loss_test:0.01681, lr:1.48e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.262, tt:5749.860\n",
      "Ep:190, loss:0.00001, loss_test:0.01682, lr:1.47e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.267, tt:5780.996\n",
      "Ep:191, loss:0.00001, loss_test:0.01683, lr:1.45e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.272, tt:5812.162\n",
      "Ep:192, loss:0.00001, loss_test:0.01684, lr:1.44e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.276, tt:5843.297\n",
      "Ep:193, loss:0.00001, loss_test:0.01685, lr:1.43e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.267, tt:5871.768\n",
      "Ep:194, loss:0.00001, loss_test:0.01686, lr:1.41e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.255, tt:5899.807\n",
      "Ep:195, loss:0.00001, loss_test:0.01686, lr:1.40e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.256, tt:5930.244\n",
      "Ep:196, loss:0.00001, loss_test:0.01688, lr:1.38e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.245, tt:5958.362\n",
      "Ep:197, loss:0.00001, loss_test:0.01688, lr:1.37e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.221, tt:5983.753\n",
      "Ep:198, loss:0.00001, loss_test:0.01689, lr:1.36e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.199, tt:6009.680\n",
      "Ep:199, loss:0.00000, loss_test:0.01689, lr:1.34e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.177, tt:6035.423\n",
      "Ep:200, loss:0.00000, loss_test:0.01690, lr:1.33e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.164, tt:6062.970\n",
      "Ep:201, loss:0.00000, loss_test:0.01692, lr:1.32e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.156, tt:6091.541\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13956, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.491, tt:32.491\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13843, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.259, tt:68.518\n",
      "Ep:2, loss:0.00028, loss_test:0.13660, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.485, tt:100.456\n",
      "Ep:3, loss:0.00027, loss_test:0.13384, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.212, tt:128.847\n",
      "Ep:4, loss:0.00027, loss_test:0.12986, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:32.118, tt:160.589\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12412, lr:1.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:31.932, tt:191.591\n",
      "Ep:6, loss:0.00025, loss_test:0.11705, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:32.104, tt:224.730\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11165, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:32.127, tt:257.020\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11090, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:31.981, tt:287.830\n",
      "Ep:9, loss:0.00023, loss_test:0.11024, lr:1.00e-02, fs:0.65217 (r=0.606,p=0.706),  time:31.992, tt:319.924\n",
      "Ep:10, loss:0.00022, loss_test:0.10842, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:32.018, tt:352.194\n",
      "Ep:11, loss:0.00021, loss_test:0.10768, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:32.094, tt:385.126\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10694, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:32.065, tt:416.851\n",
      "Ep:13, loss:0.00020, loss_test:0.10718, lr:1.00e-02, fs:0.63043 (r=0.586,p=0.682),  time:32.074, tt:449.034\n",
      "Ep:14, loss:0.00019, loss_test:0.10676, lr:1.00e-02, fs:0.63388 (r=0.586,p=0.690),  time:32.066, tt:480.990\n",
      "Ep:15, loss:0.00019, loss_test:0.10555, lr:1.00e-02, fs:0.64921 (r=0.626,p=0.674),  time:32.169, tt:514.697\n",
      "Ep:16, loss:0.00018, loss_test:0.10451, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:32.093, tt:545.576\n",
      "Ep:17, loss:0.00017, loss_test:0.10408, lr:1.00e-02, fs:0.65263 (r=0.626,p=0.681),  time:32.045, tt:576.809\n",
      "Ep:18, loss:0.00017, loss_test:0.10360, lr:1.00e-02, fs:0.66667 (r=0.616,p=0.726),  time:31.988, tt:607.779\n",
      "Ep:19, loss:0.00016, loss_test:0.10198, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:31.922, tt:638.430\n",
      "Ep:20, loss:0.00016, loss_test:0.10076, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:31.976, tt:671.486\n",
      "Ep:21, loss:0.00015, loss_test:0.09999, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:32.027, tt:704.585\n",
      "Ep:22, loss:0.00015, loss_test:0.09901, lr:1.00e-02, fs:0.69663 (r=0.626,p=0.785),  time:32.064, tt:737.467\n",
      "Ep:23, loss:0.00014, loss_test:0.09747, lr:9.90e-03, fs:0.71429 (r=0.657,p=0.783),  time:32.054, tt:769.294\n",
      "Ep:24, loss:0.00013, loss_test:0.09682, lr:9.80e-03, fs:0.70718 (r=0.646,p=0.780),  time:32.030, tt:800.761\n",
      "Ep:25, loss:0.00013, loss_test:0.09647, lr:9.70e-03, fs:0.71186 (r=0.636,p=0.808),  time:32.027, tt:832.691\n",
      "Ep:26, loss:0.00013, loss_test:0.09558, lr:9.61e-03, fs:0.72316 (r=0.646,p=0.821),  time:31.993, tt:863.803\n",
      "Ep:27, loss:0.00012, loss_test:0.09453, lr:9.51e-03, fs:0.71508 (r=0.646,p=0.800),  time:32.037, tt:897.047\n",
      "Ep:28, loss:0.00012, loss_test:0.09385, lr:9.41e-03, fs:0.72316 (r=0.646,p=0.821),  time:32.021, tt:928.602\n",
      "Ep:29, loss:0.00011, loss_test:0.09287, lr:9.32e-03, fs:0.72316 (r=0.646,p=0.821),  time:32.003, tt:960.088\n",
      "Ep:30, loss:0.00011, loss_test:0.09197, lr:9.23e-03, fs:0.72316 (r=0.646,p=0.821),  time:31.959, tt:990.735\n",
      "Ep:31, loss:0.00011, loss_test:0.09109, lr:9.14e-03, fs:0.73743 (r=0.667,p=0.825),  time:31.920, tt:1021.453\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.09048, lr:9.14e-03, fs:0.74860 (r=0.677,p=0.838),  time:31.887, tt:1052.271\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.08992, lr:9.14e-03, fs:0.73446 (r=0.657,p=0.833),  time:31.947, tt:1086.193\n",
      "Ep:34, loss:0.00010, loss_test:0.08918, lr:9.14e-03, fs:0.74860 (r=0.677,p=0.838),  time:31.944, tt:1118.049\n",
      "Ep:35, loss:0.00009, loss_test:0.08863, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.936, tt:1149.697\n",
      "Ep:36, loss:0.00009, loss_test:0.08815, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.951, tt:1182.191\n",
      "Ep:37, loss:0.00009, loss_test:0.08780, lr:9.14e-03, fs:0.72727 (r=0.646,p=0.831),  time:31.940, tt:1213.725\n",
      "Ep:38, loss:0.00009, loss_test:0.08745, lr:9.14e-03, fs:0.73563 (r=0.646,p=0.853),  time:31.937, tt:1245.548\n",
      "Ep:39, loss:0.00008, loss_test:0.08652, lr:9.14e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.913, tt:1276.512\n",
      "Ep:40, loss:0.00008, loss_test:0.08636, lr:9.14e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.944, tt:1309.724\n",
      "Ep:41, loss:0.00008, loss_test:0.08610, lr:9.14e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.945, tt:1341.708\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.08573, lr:9.14e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.944, tt:1373.589\n",
      "Ep:43, loss:0.00007, loss_test:0.08528, lr:9.14e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.953, tt:1405.945\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.08516, lr:9.14e-03, fs:0.75581 (r=0.657,p=0.890),  time:31.935, tt:1437.094\n",
      "Ep:45, loss:0.00007, loss_test:0.08470, lr:9.14e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.944, tt:1469.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00007, loss_test:0.08434, lr:9.14e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.926, tt:1500.527\n",
      "Ep:47, loss:0.00007, loss_test:0.08407, lr:9.14e-03, fs:0.75145 (r=0.657,p=0.878),  time:31.930, tt:1532.663\n",
      "Ep:48, loss:0.00007, loss_test:0.08376, lr:9.14e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.938, tt:1564.942\n",
      "Ep:49, loss:0.00006, loss_test:0.08334, lr:9.14e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.908, tt:1595.389\n",
      "Ep:50, loss:0.00006, loss_test:0.08306, lr:9.14e-03, fs:0.75145 (r=0.657,p=0.878),  time:31.913, tt:1627.541\n",
      "Ep:51, loss:0.00006, loss_test:0.08255, lr:9.14e-03, fs:0.74713 (r=0.657,p=0.867),  time:31.928, tt:1660.240\n",
      "Ep:52, loss:0.00006, loss_test:0.08205, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.922, tt:1691.860\n",
      "Ep:53, loss:0.00006, loss_test:0.08234, lr:9.14e-03, fs:0.74419 (r=0.646,p=0.877),  time:31.896, tt:1722.390\n",
      "Ep:54, loss:0.00006, loss_test:0.08160, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.866, tt:1752.614\n",
      "Ep:55, loss:0.00006, loss_test:0.08143, lr:9.04e-03, fs:0.74713 (r=0.657,p=0.867),  time:31.868, tt:1784.633\n",
      "Ep:56, loss:0.00005, loss_test:0.08178, lr:8.95e-03, fs:0.74419 (r=0.646,p=0.877),  time:31.863, tt:1816.168\n",
      "Ep:57, loss:0.00005, loss_test:0.08098, lr:8.86e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.871, tt:1848.520\n",
      "Ep:58, loss:0.00005, loss_test:0.08133, lr:8.78e-03, fs:0.75145 (r=0.657,p=0.878),  time:31.888, tt:1881.383\n",
      "Ep:59, loss:0.00005, loss_test:0.08144, lr:8.69e-03, fs:0.74118 (r=0.636,p=0.887),  time:31.866, tt:1911.937\n",
      "Ep:60, loss:0.00005, loss_test:0.08037, lr:8.60e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.868, tt:1943.952\n",
      "Ep:61, loss:0.00005, loss_test:0.08050, lr:8.51e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.871, tt:1975.976\n",
      "Ep:62, loss:0.00005, loss_test:0.08104, lr:8.43e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.870, tt:2007.794\n",
      "Ep:63, loss:0.00005, loss_test:0.08008, lr:8.35e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.872, tt:2039.840\n",
      "Ep:64, loss:0.00005, loss_test:0.08073, lr:8.26e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.916, tt:2074.563\n",
      "Ep:65, loss:0.00004, loss_test:0.08034, lr:8.18e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.905, tt:2105.721\n",
      "Ep:66, loss:0.00004, loss_test:0.07943, lr:8.10e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.912, tt:2138.128\n",
      "Ep:67, loss:0.00004, loss_test:0.08056, lr:8.02e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.903, tt:2169.405\n",
      "Ep:68, loss:0.00004, loss_test:0.07957, lr:7.94e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.913, tt:2202.016\n",
      "Ep:69, loss:0.00004, loss_test:0.07997, lr:7.86e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.925, tt:2234.763\n",
      "Ep:70, loss:0.00004, loss_test:0.08041, lr:7.78e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.930, tt:2267.056\n",
      "Ep:71, loss:0.00004, loss_test:0.07897, lr:7.70e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.942, tt:2299.835\n",
      "Ep:72, loss:0.00004, loss_test:0.07957, lr:7.62e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.931, tt:2330.981\n",
      "Ep:73, loss:0.00004, loss_test:0.07998, lr:7.55e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.900, tt:2360.602\n",
      "Ep:74, loss:0.00004, loss_test:0.07939, lr:7.47e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.893, tt:2391.965\n",
      "Ep:75, loss:0.00004, loss_test:0.07934, lr:7.40e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.905, tt:2424.815\n",
      "Ep:76, loss:0.00004, loss_test:0.07955, lr:7.32e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.907, tt:2456.850\n",
      "Ep:77, loss:0.00004, loss_test:0.07908, lr:7.25e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.901, tt:2488.264\n",
      "Ep:78, loss:0.00004, loss_test:0.07919, lr:7.18e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.892, tt:2519.467\n",
      "Ep:79, loss:0.00004, loss_test:0.07943, lr:7.11e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.894, tt:2551.521\n",
      "Ep:80, loss:0.00003, loss_test:0.07883, lr:7.03e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.909, tt:2584.608\n",
      "Ep:81, loss:0.00003, loss_test:0.07898, lr:6.96e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.897, tt:2615.525\n",
      "Ep:82, loss:0.00003, loss_test:0.07918, lr:6.89e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.880, tt:2646.035\n",
      "Ep:83, loss:0.00003, loss_test:0.07887, lr:6.83e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.877, tt:2677.674\n",
      "Ep:84, loss:0.00003, loss_test:0.07932, lr:6.76e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.880, tt:2709.805\n",
      "Ep:85, loss:0.00003, loss_test:0.07882, lr:6.69e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.898, tt:2743.216\n",
      "Ep:86, loss:0.00003, loss_test:0.07863, lr:6.62e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.896, tt:2774.919\n",
      "Ep:87, loss:0.00003, loss_test:0.07918, lr:6.56e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.905, tt:2807.678\n",
      "Ep:88, loss:0.00003, loss_test:0.07886, lr:6.49e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.913, tt:2840.270\n",
      "Ep:89, loss:0.00003, loss_test:0.07841, lr:6.43e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.922, tt:2872.954\n",
      "Ep:90, loss:0.00003, loss_test:0.07923, lr:6.36e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.916, tt:2904.359\n",
      "Ep:91, loss:0.00003, loss_test:0.07892, lr:6.30e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.913, tt:2935.958\n",
      "Ep:92, loss:0.00003, loss_test:0.07818, lr:6.24e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.900, tt:2966.677\n",
      "Ep:93, loss:0.00003, loss_test:0.07913, lr:6.17e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.915, tt:3000.044\n",
      "Ep:94, loss:0.00003, loss_test:0.07887, lr:6.11e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.927, tt:3033.109\n",
      "Ep:95, loss:0.00003, loss_test:0.07850, lr:6.05e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.915, tt:3063.848\n",
      "Ep:96, loss:0.00003, loss_test:0.07946, lr:5.99e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.923, tt:3096.535\n",
      "Ep:97, loss:0.00003, loss_test:0.07858, lr:5.93e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.919, tt:3128.062\n",
      "Ep:98, loss:0.00003, loss_test:0.07787, lr:5.87e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.914, tt:3159.517\n",
      "Ep:99, loss:0.00003, loss_test:0.07921, lr:5.81e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.898, tt:3189.757\n",
      "Ep:100, loss:0.00003, loss_test:0.07937, lr:5.75e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.901, tt:3221.988\n",
      "Ep:101, loss:0.00003, loss_test:0.07812, lr:5.70e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.908, tt:3254.604\n",
      "Ep:102, loss:0.00003, loss_test:0.07823, lr:5.64e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.911, tt:3286.864\n",
      "Ep:103, loss:0.00003, loss_test:0.07948, lr:5.58e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.907, tt:3318.278\n",
      "Ep:104, loss:0.00003, loss_test:0.07941, lr:5.53e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.918, tt:3351.357\n",
      "Ep:105, loss:0.00003, loss_test:0.07806, lr:5.47e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.918, tt:3383.345\n",
      "Ep:106, loss:0.00003, loss_test:0.07860, lr:5.42e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.927, tt:3416.227\n",
      "Ep:107, loss:0.00002, loss_test:0.07899, lr:5.36e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.920, tt:3447.374\n",
      "Ep:108, loss:0.00002, loss_test:0.07844, lr:5.31e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.908, tt:3478.001\n",
      "Ep:109, loss:0.00002, loss_test:0.07827, lr:5.26e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.909, tt:3509.964\n",
      "Ep:110, loss:0.00002, loss_test:0.07833, lr:5.20e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.909, tt:3541.896\n",
      "Ep:111, loss:0.00002, loss_test:0.07809, lr:5.15e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.904, tt:3573.259\n",
      "Ep:112, loss:0.00002, loss_test:0.07809, lr:5.10e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.907, tt:3605.506\n",
      "Ep:113, loss:0.00002, loss_test:0.07884, lr:5.05e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.892, tt:3635.717\n",
      "Ep:114, loss:0.00002, loss_test:0.07809, lr:5.00e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.892, tt:3667.533\n",
      "Ep:115, loss:0.00002, loss_test:0.07749, lr:4.95e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.898, tt:3700.136\n",
      "Ep:116, loss:0.00002, loss_test:0.07844, lr:4.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.890, tt:3731.095\n",
      "Ep:117, loss:0.00002, loss_test:0.07847, lr:4.85e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.864, tt:3759.911\n",
      "Ep:118, loss:0.00002, loss_test:0.07752, lr:4.80e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.841, tt:3789.042\n",
      "Ep:119, loss:0.00002, loss_test:0.07796, lr:4.75e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.833, tt:3820.018\n",
      "Ep:120, loss:0.00002, loss_test:0.07891, lr:4.71e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.835, tt:3852.074\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00002, loss_test:0.07834, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.841, tt:3884.624\n",
      "Ep:122, loss:0.00002, loss_test:0.07737, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.844, tt:3916.839\n",
      "Ep:123, loss:0.00002, loss_test:0.07793, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.858, tt:3950.415\n",
      "Ep:124, loss:0.00002, loss_test:0.07878, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.858, tt:3982.222\n",
      "Ep:125, loss:0.00002, loss_test:0.07802, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.847, tt:4012.713\n",
      "Ep:126, loss:0.00002, loss_test:0.07729, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.847, tt:4044.525\n",
      "Ep:127, loss:0.00002, loss_test:0.07802, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.842, tt:4075.728\n",
      "Ep:128, loss:0.00002, loss_test:0.07828, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.840, tt:4107.400\n",
      "Ep:129, loss:0.00002, loss_test:0.07790, lr:4.71e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.829, tt:4137.787\n",
      "Ep:130, loss:0.00002, loss_test:0.07711, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.834, tt:4170.207\n",
      "Ep:131, loss:0.00002, loss_test:0.07750, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.834, tt:4202.070\n",
      "Ep:132, loss:0.00002, loss_test:0.07820, lr:4.66e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.816, tt:4231.577\n",
      "Ep:133, loss:0.00002, loss_test:0.07762, lr:4.61e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.811, tt:4262.701\n",
      "Ep:134, loss:0.00002, loss_test:0.07719, lr:4.57e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.803, tt:4293.416\n",
      "Ep:135, loss:0.00002, loss_test:0.07790, lr:4.52e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.797, tt:4324.432\n",
      "Ep:136, loss:0.00002, loss_test:0.07743, lr:4.48e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.785, tt:4354.524\n",
      "Ep:137, loss:0.00002, loss_test:0.07722, lr:4.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.792, tt:4387.343\n",
      "Ep:138, loss:0.00002, loss_test:0.07772, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.791, tt:4418.906\n",
      "Ep:139, loss:0.00002, loss_test:0.07729, lr:4.34e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.782, tt:4449.490\n",
      "Ep:140, loss:0.00002, loss_test:0.07748, lr:4.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.784, tt:4481.489\n",
      "Ep:141, loss:0.00002, loss_test:0.07776, lr:4.26e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.782, tt:4513.072\n",
      "Ep:142, loss:0.00002, loss_test:0.07751, lr:4.21e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.781, tt:4544.680\n",
      "Ep:143, loss:0.00002, loss_test:0.07711, lr:4.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.786, tt:4577.155\n",
      "Ep:144, loss:0.00002, loss_test:0.07723, lr:4.13e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.793, tt:4609.938\n",
      "Ep:145, loss:0.00002, loss_test:0.07729, lr:4.09e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.781, tt:4640.078\n",
      "Ep:146, loss:0.00002, loss_test:0.07697, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.780, tt:4671.681\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00002, loss_test:0.07684, lr:4.05e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.787, tt:4704.535\n",
      "Ep:148, loss:0.00002, loss_test:0.07693, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.787, tt:4736.323\n",
      "Ep:149, loss:0.00002, loss_test:0.07691, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.777, tt:4766.537\n",
      "Ep:150, loss:0.00002, loss_test:0.07694, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.781, tt:4798.948\n",
      "Ep:151, loss:0.00002, loss_test:0.07689, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.784, tt:4831.106\n",
      "Ep:152, loss:0.00002, loss_test:0.07665, lr:4.05e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.794, tt:4864.416\n",
      "Ep:153, loss:0.00002, loss_test:0.07682, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.788, tt:4895.391\n",
      "Ep:154, loss:0.00002, loss_test:0.07683, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.784, tt:4926.566\n",
      "Ep:155, loss:0.00002, loss_test:0.07678, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.784, tt:4958.366\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00002, loss_test:0.07669, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.785, tt:4990.233\n",
      "Ep:157, loss:0.00002, loss_test:0.07658, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.789, tt:5022.616\n",
      "Ep:158, loss:0.00002, loss_test:0.07654, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.786, tt:5053.900\n",
      "Ep:159, loss:0.00002, loss_test:0.07654, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.790, tt:5086.320\n",
      "Ep:160, loss:0.00002, loss_test:0.07664, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.793, tt:5118.670\n",
      "Ep:161, loss:0.00002, loss_test:0.07657, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.789, tt:5149.830\n",
      "Ep:162, loss:0.00002, loss_test:0.07649, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.779, tt:5180.014\n",
      "Ep:163, loss:0.00002, loss_test:0.07648, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.780, tt:5211.889\n",
      "Ep:164, loss:0.00002, loss_test:0.07670, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.782, tt:5244.023\n",
      "Ep:165, loss:0.00002, loss_test:0.07631, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.774, tt:5274.502\n",
      "Ep:166, loss:0.00002, loss_test:0.07644, lr:4.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.777, tt:5306.720\n",
      "Ep:167, loss:0.00002, loss_test:0.07660, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.764, tt:5336.276\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00001, loss_test:0.07612, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.758, tt:5367.161\n",
      "Ep:169, loss:0.00001, loss_test:0.07668, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.756, tt:5398.566\n",
      "Ep:170, loss:0.00001, loss_test:0.07620, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.757, tt:5430.529\n",
      "Ep:171, loss:0.00001, loss_test:0.07632, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.741, tt:5459.456\n",
      "Ep:172, loss:0.00001, loss_test:0.07676, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.728, tt:5488.882\n",
      "Ep:173, loss:0.00001, loss_test:0.07653, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.719, tt:5519.081\n",
      "Ep:174, loss:0.00001, loss_test:0.07600, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.732, tt:5553.172\n",
      "Ep:175, loss:0.00001, loss_test:0.07635, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.730, tt:5584.520\n",
      "Ep:176, loss:0.00001, loss_test:0.07648, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.722, tt:5614.727\n",
      "Ep:177, loss:0.00001, loss_test:0.07594, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.712, tt:5644.721\n",
      "Ep:178, loss:0.00001, loss_test:0.07640, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.713, tt:5676.617\n",
      "Ep:179, loss:0.00001, loss_test:0.07679, lr:3.97e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.721, tt:5709.728\n",
      "Ep:180, loss:0.00001, loss_test:0.07618, lr:3.93e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.731, tt:5743.342\n",
      "Ep:181, loss:0.00001, loss_test:0.07615, lr:3.89e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.725, tt:5773.969\n",
      "Ep:182, loss:0.00001, loss_test:0.07614, lr:3.85e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.723, tt:5805.364\n",
      "Ep:183, loss:0.00001, loss_test:0.07655, lr:3.81e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.714, tt:5835.352\n",
      "Ep:184, loss:0.00001, loss_test:0.07599, lr:3.77e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.717, tt:5867.663\n",
      "Ep:185, loss:0.00001, loss_test:0.07573, lr:3.73e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.720, tt:5899.894\n",
      "Ep:186, loss:0.00001, loss_test:0.07612, lr:3.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.713, tt:5930.307\n",
      "Ep:187, loss:0.00001, loss_test:0.07640, lr:3.66e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.704, tt:5960.362\n",
      "Ep:188, loss:0.00001, loss_test:0.07592, lr:3.62e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.699, tt:5991.174\n",
      "Ep:189, loss:0.00001, loss_test:0.07600, lr:3.59e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.691, tt:6021.333\n",
      "Ep:190, loss:0.00001, loss_test:0.07621, lr:3.55e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.692, tt:6053.084\n",
      "Ep:191, loss:0.00001, loss_test:0.07603, lr:3.52e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.696, tt:6085.612\n",
      "Ep:192, loss:0.00001, loss_test:0.07554, lr:3.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.699, tt:6117.967\n",
      "Ep:193, loss:0.00001, loss_test:0.07581, lr:3.45e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.690, tt:6147.918\n",
      "Ep:194, loss:0.00001, loss_test:0.07636, lr:3.41e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.680, tt:6177.581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00001, loss_test:0.07568, lr:3.38e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.661, tt:6205.620\n",
      "Ep:196, loss:0.00001, loss_test:0.07557, lr:3.34e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.637, tt:6232.447\n",
      "Ep:197, loss:0.00001, loss_test:0.07644, lr:3.31e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.614, tt:6259.630\n",
      "Ep:198, loss:0.00001, loss_test:0.07596, lr:3.28e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.581, tt:6284.689\n",
      "Ep:199, loss:0.00001, loss_test:0.07560, lr:3.24e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.565, tt:6312.956\n",
      "Ep:200, loss:0.00001, loss_test:0.07555, lr:3.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.531, tt:6337.655\n",
      "Ep:201, loss:0.00001, loss_test:0.07594, lr:3.18e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.512, tt:6365.382\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02037, lr:6.00e-02, fs:0.66667 (r=0.768,p=0.589),  time:26.362, tt:26.362\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02149, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:26.310, tt:52.621\n",
      "Ep:2, loss:0.00004, loss_test:0.02395, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.748, tt:77.243\n",
      "Ep:3, loss:0.00005, loss_test:0.02489, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.298, tt:101.193\n",
      "Ep:4, loss:0.00005, loss_test:0.02469, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.154, tt:125.769\n",
      "Ep:5, loss:0.00005, loss_test:0.02374, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.082, tt:150.493\n",
      "Ep:6, loss:0.00005, loss_test:0.02222, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:25.069, tt:175.483\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02055, lr:6.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:25.220, tt:201.762\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01919, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:25.212, tt:226.904\n",
      "Ep:9, loss:0.00004, loss_test:0.01847, lr:6.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:25.321, tt:253.211\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01833, lr:6.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:25.382, tt:279.206\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01831, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:25.475, tt:305.705\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01817, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:25.425, tt:330.527\n",
      "Ep:13, loss:0.00004, loss_test:0.01799, lr:6.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:25.527, tt:357.378\n",
      "Ep:14, loss:0.00003, loss_test:0.01790, lr:6.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:25.583, tt:383.749\n",
      "Ep:15, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:25.686, tt:410.969\n",
      "Ep:16, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:25.708, tt:437.034\n",
      "Ep:17, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:25.725, tt:463.058\n",
      "Ep:18, loss:0.00003, loss_test:0.01782, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:25.761, tt:489.461\n",
      "Ep:19, loss:0.00003, loss_test:0.01779, lr:6.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:25.815, tt:516.301\n",
      "Ep:20, loss:0.00003, loss_test:0.01775, lr:6.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:25.769, tt:541.152\n",
      "Ep:21, loss:0.00003, loss_test:0.01771, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:25.772, tt:566.988\n",
      "Ep:22, loss:0.00003, loss_test:0.01761, lr:6.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:25.791, tt:593.199\n",
      "Ep:23, loss:0.00003, loss_test:0.01753, lr:5.94e-02, fs:0.69198 (r=0.828,p=0.594),  time:25.809, tt:619.424\n",
      "Ep:24, loss:0.00003, loss_test:0.01746, lr:5.88e-02, fs:0.69198 (r=0.828,p=0.594),  time:25.789, tt:644.731\n",
      "Ep:25, loss:0.00003, loss_test:0.01741, lr:5.82e-02, fs:0.70293 (r=0.848,p=0.600),  time:25.768, tt:669.963\n",
      "Ep:26, loss:0.00003, loss_test:0.01739, lr:5.76e-02, fs:0.70293 (r=0.848,p=0.600),  time:25.753, tt:695.326\n",
      "Ep:27, loss:0.00003, loss_test:0.01740, lr:5.71e-02, fs:0.70293 (r=0.848,p=0.600),  time:25.715, tt:720.007\n",
      "Ep:28, loss:0.00003, loss_test:0.01742, lr:5.65e-02, fs:0.71489 (r=0.848,p=0.618),  time:25.667, tt:744.343\n",
      "Ep:29, loss:0.00003, loss_test:0.01747, lr:5.59e-02, fs:0.71489 (r=0.848,p=0.618),  time:25.634, tt:769.011\n",
      "Ep:30, loss:0.00003, loss_test:0.01752, lr:5.54e-02, fs:0.73276 (r=0.859,p=0.639),  time:25.624, tt:794.338\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01753, lr:5.54e-02, fs:0.73593 (r=0.859,p=0.644),  time:25.607, tt:819.417\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01751, lr:5.54e-02, fs:0.73913 (r=0.859,p=0.649),  time:25.639, tt:846.096\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01744, lr:5.54e-02, fs:0.73913 (r=0.859,p=0.649),  time:25.670, tt:872.785\n",
      "Ep:34, loss:0.00002, loss_test:0.01735, lr:5.54e-02, fs:0.74783 (r=0.869,p=0.656),  time:25.678, tt:898.720\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01725, lr:5.54e-02, fs:0.75109 (r=0.869,p=0.662),  time:25.697, tt:925.106\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01715, lr:5.54e-02, fs:0.75771 (r=0.869,p=0.672),  time:25.731, tt:952.039\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01705, lr:5.54e-02, fs:0.76444 (r=0.869,p=0.683),  time:25.712, tt:977.046\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01696, lr:5.54e-02, fs:0.76786 (r=0.869,p=0.688),  time:25.678, tt:1001.455\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01688, lr:5.54e-02, fs:0.77130 (r=0.869,p=0.694),  time:25.693, tt:1027.711\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01682, lr:5.54e-02, fs:0.77130 (r=0.869,p=0.694),  time:25.685, tt:1053.091\n",
      "Ep:41, loss:0.00002, loss_test:0.01677, lr:5.54e-02, fs:0.77477 (r=0.869,p=0.699),  time:25.704, tt:1079.559\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01672, lr:5.54e-02, fs:0.78027 (r=0.879,p=0.702),  time:25.746, tt:1107.098\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01669, lr:5.54e-02, fs:0.78378 (r=0.879,p=0.707),  time:25.725, tt:1131.881\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01666, lr:5.54e-02, fs:0.78378 (r=0.879,p=0.707),  time:25.697, tt:1156.365\n",
      "Ep:45, loss:0.00002, loss_test:0.01663, lr:5.54e-02, fs:0.78378 (r=0.879,p=0.707),  time:25.693, tt:1181.877\n",
      "Ep:46, loss:0.00002, loss_test:0.01657, lr:5.54e-02, fs:0.78378 (r=0.879,p=0.707),  time:25.678, tt:1206.845\n",
      "Ep:47, loss:0.00002, loss_test:0.01653, lr:5.54e-02, fs:0.79279 (r=0.889,p=0.715),  time:25.713, tt:1234.240\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01648, lr:5.54e-02, fs:0.79638 (r=0.889,p=0.721),  time:25.764, tt:1262.448\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01645, lr:5.54e-02, fs:0.79638 (r=0.889,p=0.721),  time:25.769, tt:1288.461\n",
      "Ep:50, loss:0.00002, loss_test:0.01641, lr:5.54e-02, fs:0.79638 (r=0.889,p=0.721),  time:25.744, tt:1312.940\n",
      "Ep:51, loss:0.00002, loss_test:0.01637, lr:5.54e-02, fs:0.80000 (r=0.889,p=0.727),  time:25.736, tt:1338.252\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01631, lr:5.54e-02, fs:0.80000 (r=0.889,p=0.727),  time:25.754, tt:1364.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00002, loss_test:0.01625, lr:5.54e-02, fs:0.80000 (r=0.889,p=0.727),  time:25.771, tt:1391.614\n",
      "Ep:54, loss:0.00002, loss_test:0.01620, lr:5.54e-02, fs:0.80365 (r=0.889,p=0.733),  time:25.798, tt:1418.894\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01613, lr:5.54e-02, fs:0.81279 (r=0.899,p=0.742),  time:25.802, tt:1444.918\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01609, lr:5.54e-02, fs:0.81651 (r=0.899,p=0.748),  time:25.788, tt:1469.936\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01606, lr:5.54e-02, fs:0.81651 (r=0.899,p=0.748),  time:25.811, tt:1497.057\n",
      "Ep:58, loss:0.00002, loss_test:0.01602, lr:5.54e-02, fs:0.81651 (r=0.899,p=0.748),  time:25.820, tt:1523.380\n",
      "Ep:59, loss:0.00002, loss_test:0.01596, lr:5.54e-02, fs:0.82407 (r=0.899,p=0.761),  time:25.828, tt:1549.660\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01594, lr:5.54e-02, fs:0.82791 (r=0.899,p=0.767),  time:25.823, tt:1575.173\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01593, lr:5.54e-02, fs:0.82791 (r=0.899,p=0.767),  time:25.830, tt:1601.433\n",
      "Ep:62, loss:0.00001, loss_test:0.01589, lr:5.54e-02, fs:0.82791 (r=0.899,p=0.767),  time:25.832, tt:1627.428\n",
      "Ep:63, loss:0.00001, loss_test:0.01585, lr:5.54e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.808, tt:1651.683\n",
      "Ep:64, loss:0.00001, loss_test:0.01583, lr:5.54e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.810, tt:1677.670\n",
      "Ep:65, loss:0.00001, loss_test:0.01577, lr:5.54e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.809, tt:1703.401\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01572, lr:5.54e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.799, tt:1728.506\n",
      "Ep:67, loss:0.00001, loss_test:0.01571, lr:5.54e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.802, tt:1754.539\n",
      "Ep:68, loss:0.00001, loss_test:0.01568, lr:5.54e-02, fs:0.83412 (r=0.889,p=0.786),  time:25.809, tt:1780.846\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01565, lr:5.54e-02, fs:0.83412 (r=0.889,p=0.786),  time:25.791, tt:1805.362\n",
      "Ep:70, loss:0.00001, loss_test:0.01563, lr:5.54e-02, fs:0.83962 (r=0.899,p=0.788),  time:25.786, tt:1830.782\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01562, lr:5.54e-02, fs:0.84360 (r=0.899,p=0.795),  time:25.763, tt:1854.927\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01560, lr:5.54e-02, fs:0.84360 (r=0.899,p=0.795),  time:25.766, tt:1880.894\n",
      "Ep:73, loss:0.00001, loss_test:0.01557, lr:5.54e-02, fs:0.83810 (r=0.889,p=0.793),  time:25.767, tt:1906.722\n",
      "Ep:74, loss:0.00001, loss_test:0.01556, lr:5.54e-02, fs:0.84211 (r=0.889,p=0.800),  time:25.793, tt:1934.460\n",
      "Ep:75, loss:0.00001, loss_test:0.01554, lr:5.54e-02, fs:0.85024 (r=0.889,p=0.815),  time:25.784, tt:1959.562\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01552, lr:5.54e-02, fs:0.85024 (r=0.889,p=0.815),  time:25.777, tt:1984.859\n",
      "Ep:77, loss:0.00001, loss_test:0.01548, lr:5.54e-02, fs:0.85437 (r=0.889,p=0.822),  time:25.767, tt:2009.830\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01544, lr:5.54e-02, fs:0.85437 (r=0.889,p=0.822),  time:25.760, tt:2035.014\n",
      "Ep:79, loss:0.00001, loss_test:0.01541, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.765, tt:2061.161\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01540, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.758, tt:2086.433\n",
      "Ep:81, loss:0.00001, loss_test:0.01540, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.762, tt:2112.512\n",
      "Ep:82, loss:0.00001, loss_test:0.01537, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.764, tt:2138.381\n",
      "Ep:83, loss:0.00001, loss_test:0.01535, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.764, tt:2164.189\n",
      "Ep:84, loss:0.00001, loss_test:0.01534, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.765, tt:2189.983\n",
      "Ep:85, loss:0.00001, loss_test:0.01533, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.770, tt:2216.218\n",
      "Ep:86, loss:0.00001, loss_test:0.01531, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:25.777, tt:2242.605\n",
      "Ep:87, loss:0.00001, loss_test:0.01530, lr:5.54e-02, fs:0.86700 (r=0.889,p=0.846),  time:25.768, tt:2267.552\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01532, lr:5.54e-02, fs:0.86700 (r=0.889,p=0.846),  time:25.775, tt:2293.942\n",
      "Ep:89, loss:0.00001, loss_test:0.01531, lr:5.54e-02, fs:0.86139 (r=0.879,p=0.845),  time:25.773, tt:2319.561\n",
      "Ep:90, loss:0.00001, loss_test:0.01529, lr:5.54e-02, fs:0.86139 (r=0.879,p=0.845),  time:25.769, tt:2344.941\n",
      "Ep:91, loss:0.00001, loss_test:0.01524, lr:5.54e-02, fs:0.86700 (r=0.889,p=0.846),  time:25.764, tt:2370.328\n",
      "Ep:92, loss:0.00001, loss_test:0.01522, lr:5.54e-02, fs:0.86139 (r=0.879,p=0.845),  time:25.772, tt:2396.774\n",
      "Ep:93, loss:0.00001, loss_test:0.01525, lr:5.54e-02, fs:0.86432 (r=0.869,p=0.860),  time:25.768, tt:2422.202\n",
      "Ep:94, loss:0.00001, loss_test:0.01523, lr:5.54e-02, fs:0.86000 (r=0.869,p=0.851),  time:25.758, tt:2446.965\n",
      "Ep:95, loss:0.00001, loss_test:0.01520, lr:5.54e-02, fs:0.86000 (r=0.869,p=0.851),  time:25.753, tt:2472.324\n",
      "Ep:96, loss:0.00001, loss_test:0.01520, lr:5.54e-02, fs:0.86432 (r=0.869,p=0.860),  time:25.759, tt:2498.647\n",
      "Ep:97, loss:0.00001, loss_test:0.01522, lr:5.54e-02, fs:0.86869 (r=0.869,p=0.869),  time:25.766, tt:2525.037\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01520, lr:5.54e-02, fs:0.86294 (r=0.859,p=0.867),  time:25.762, tt:2550.404\n",
      "Ep:99, loss:0.00001, loss_test:0.01520, lr:5.54e-02, fs:0.85714 (r=0.848,p=0.866),  time:25.762, tt:2576.187\n",
      "Ep:100, loss:0.00001, loss_test:0.01522, lr:5.54e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.745, tt:2600.258\n",
      "Ep:101, loss:0.00001, loss_test:0.01524, lr:5.54e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.719, tt:2623.377\n",
      "Ep:102, loss:0.00001, loss_test:0.01524, lr:5.54e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.710, tt:2648.181\n",
      "Ep:103, loss:0.00001, loss_test:0.01524, lr:5.54e-02, fs:0.86735 (r=0.859,p=0.876),  time:25.703, tt:2673.065\n",
      "Ep:104, loss:0.00001, loss_test:0.01524, lr:5.54e-02, fs:0.86735 (r=0.859,p=0.876),  time:25.685, tt:2696.953\n",
      "Ep:105, loss:0.00001, loss_test:0.01524, lr:5.54e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.683, tt:2722.384\n",
      "Ep:106, loss:0.00001, loss_test:0.01527, lr:5.54e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.656, tt:2745.173\n",
      "Ep:107, loss:0.00001, loss_test:0.01531, lr:5.54e-02, fs:0.86598 (r=0.848,p=0.884),  time:25.650, tt:2770.167\n",
      "Ep:108, loss:0.00001, loss_test:0.01534, lr:5.54e-02, fs:0.86598 (r=0.848,p=0.884),  time:25.635, tt:2794.206\n",
      "Ep:109, loss:0.00001, loss_test:0.01532, lr:5.48e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.634, tt:2819.719\n",
      "Ep:110, loss:0.00001, loss_test:0.01529, lr:5.43e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.625, tt:2844.328\n",
      "Ep:111, loss:0.00001, loss_test:0.01531, lr:5.37e-02, fs:0.86154 (r=0.848,p=0.875),  time:25.627, tt:2870.207\n",
      "Ep:112, loss:0.00001, loss_test:0.01534, lr:5.32e-02, fs:0.86598 (r=0.848,p=0.884),  time:25.620, tt:2895.057\n",
      "Ep:113, loss:0.00001, loss_test:0.01536, lr:5.27e-02, fs:0.86458 (r=0.838,p=0.892),  time:25.614, tt:2919.957\n",
      "Ep:114, loss:0.00001, loss_test:0.01539, lr:5.21e-02, fs:0.86458 (r=0.838,p=0.892),  time:25.619, tt:2946.151\n",
      "Ep:115, loss:0.00001, loss_test:0.01540, lr:5.16e-02, fs:0.86458 (r=0.838,p=0.892),  time:25.613, tt:2971.119\n",
      "Ep:116, loss:0.00001, loss_test:0.01541, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:25.610, tt:2996.334\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01543, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:25.614, tt:3022.475\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.01546, lr:5.11e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.607, tt:3047.268\n",
      "Ep:119, loss:0.00001, loss_test:0.01546, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:25.616, tt:3073.967\n",
      "Ep:120, loss:0.00001, loss_test:0.01547, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:25.621, tt:3100.114\n",
      "Ep:121, loss:0.00001, loss_test:0.01548, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:25.629, tt:3126.793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00001, loss_test:0.01548, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:25.630, tt:3152.537\n",
      "Ep:123, loss:0.00001, loss_test:0.01550, lr:5.11e-02, fs:0.86458 (r=0.838,p=0.892),  time:25.634, tt:3178.660\n",
      "Ep:124, loss:0.00001, loss_test:0.01551, lr:5.11e-02, fs:0.86458 (r=0.838,p=0.892),  time:25.633, tt:3204.179\n",
      "Ep:125, loss:0.00001, loss_test:0.01552, lr:5.11e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.649, tt:3231.814\n",
      "Ep:126, loss:0.00001, loss_test:0.01555, lr:5.11e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.657, tt:3258.456\n",
      "Ep:127, loss:0.00001, loss_test:0.01555, lr:5.11e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.661, tt:3284.567\n",
      "Ep:128, loss:0.00001, loss_test:0.01556, lr:5.11e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.658, tt:3309.876\n",
      "Ep:129, loss:0.00001, loss_test:0.01558, lr:5.06e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.663, tt:3336.135\n",
      "Ep:130, loss:0.00001, loss_test:0.01560, lr:5.01e-02, fs:0.86772 (r=0.828,p=0.911),  time:25.664, tt:3362.001\n",
      "Ep:131, loss:0.00001, loss_test:0.01560, lr:4.96e-02, fs:0.86772 (r=0.828,p=0.911),  time:25.665, tt:3387.836\n",
      "Ep:132, loss:0.00001, loss_test:0.01560, lr:4.91e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.670, tt:3414.067\n",
      "Ep:133, loss:0.00001, loss_test:0.01562, lr:4.86e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.671, tt:3439.850\n",
      "Ep:134, loss:0.00001, loss_test:0.01566, lr:4.81e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.657, tt:3463.692\n",
      "Ep:135, loss:0.00001, loss_test:0.01569, lr:4.76e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.657, tt:3489.374\n",
      "Ep:136, loss:0.00001, loss_test:0.01568, lr:4.71e-02, fs:0.86022 (r=0.808,p=0.920),  time:25.648, tt:3513.835\n",
      "Ep:137, loss:0.00001, loss_test:0.01568, lr:4.67e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.648, tt:3539.490\n",
      "Ep:138, loss:0.00001, loss_test:0.01571, lr:4.62e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.651, tt:3565.494\n",
      "Ep:139, loss:0.00001, loss_test:0.01572, lr:4.57e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.655, tt:3591.682\n",
      "Ep:140, loss:0.00001, loss_test:0.01574, lr:4.53e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.657, tt:3617.642\n",
      "Ep:141, loss:0.00001, loss_test:0.01575, lr:4.48e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.648, tt:3642.032\n",
      "Ep:142, loss:0.00001, loss_test:0.01576, lr:4.44e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.649, tt:3667.763\n",
      "Ep:143, loss:0.00001, loss_test:0.01579, lr:4.39e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.653, tt:3693.975\n",
      "Ep:144, loss:0.00001, loss_test:0.01581, lr:4.35e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.659, tt:3720.573\n",
      "Ep:145, loss:0.00001, loss_test:0.01583, lr:4.31e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.658, tt:3746.133\n",
      "Ep:146, loss:0.00001, loss_test:0.01582, lr:4.26e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.663, tt:3772.473\n",
      "Ep:147, loss:0.00001, loss_test:0.01582, lr:4.22e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.666, tt:3798.568\n",
      "Ep:148, loss:0.00000, loss_test:0.01580, lr:4.18e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.670, tt:3824.827\n",
      "Ep:149, loss:0.00000, loss_test:0.01581, lr:4.14e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.682, tt:3852.374\n",
      "Ep:150, loss:0.00000, loss_test:0.01581, lr:4.10e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.685, tt:3878.365\n",
      "Ep:151, loss:0.00000, loss_test:0.01582, lr:4.05e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.706, tt:3907.289\n",
      "Ep:152, loss:0.00000, loss_test:0.01585, lr:4.01e-02, fs:0.85405 (r=0.798,p=0.919),  time:25.705, tt:3932.840\n",
      "Ep:153, loss:0.00000, loss_test:0.01587, lr:3.97e-02, fs:0.84783 (r=0.788,p=0.918),  time:25.706, tt:3958.667\n",
      "Ep:154, loss:0.00000, loss_test:0.01591, lr:3.93e-02, fs:0.84783 (r=0.788,p=0.918),  time:25.708, tt:3984.683\n",
      "Ep:155, loss:0.00000, loss_test:0.01593, lr:3.89e-02, fs:0.85246 (r=0.788,p=0.929),  time:25.701, tt:4009.399\n",
      "Ep:156, loss:0.00000, loss_test:0.01596, lr:3.86e-02, fs:0.85246 (r=0.788,p=0.929),  time:25.703, tt:4035.394\n",
      "Ep:157, loss:0.00000, loss_test:0.01597, lr:3.82e-02, fs:0.85246 (r=0.788,p=0.929),  time:25.703, tt:4061.081\n",
      "Ep:158, loss:0.00000, loss_test:0.01598, lr:3.78e-02, fs:0.85246 (r=0.788,p=0.929),  time:25.703, tt:4086.811\n",
      "Ep:159, loss:0.00000, loss_test:0.01600, lr:3.74e-02, fs:0.85246 (r=0.788,p=0.929),  time:25.692, tt:4110.678\n",
      "Ep:160, loss:0.00000, loss_test:0.01600, lr:3.70e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.692, tt:4136.338\n",
      "Ep:161, loss:0.00000, loss_test:0.01601, lr:3.67e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.701, tt:4163.589\n",
      "Ep:162, loss:0.00000, loss_test:0.01604, lr:3.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.696, tt:4188.417\n",
      "Ep:163, loss:0.00000, loss_test:0.01605, lr:3.59e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.690, tt:4213.128\n",
      "Ep:164, loss:0.00000, loss_test:0.01609, lr:3.56e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.688, tt:4238.471\n",
      "Ep:165, loss:0.00000, loss_test:0.01608, lr:3.52e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.686, tt:4263.942\n",
      "Ep:166, loss:0.00000, loss_test:0.01609, lr:3.49e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.690, tt:4290.161\n",
      "Ep:167, loss:0.00000, loss_test:0.01609, lr:3.45e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.685, tt:4315.003\n",
      "Ep:168, loss:0.00000, loss_test:0.01613, lr:3.42e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.678, tt:4339.565\n",
      "Ep:169, loss:0.00000, loss_test:0.01614, lr:3.38e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.680, tt:4365.628\n",
      "Ep:170, loss:0.00000, loss_test:0.01615, lr:3.35e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.681, tt:4391.395\n",
      "Ep:171, loss:0.00000, loss_test:0.01618, lr:3.32e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.683, tt:4417.514\n",
      "Ep:172, loss:0.00000, loss_test:0.01619, lr:3.28e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.685, tt:4443.553\n",
      "Ep:173, loss:0.00000, loss_test:0.01620, lr:3.25e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.681, tt:4468.518\n",
      "Ep:174, loss:0.00000, loss_test:0.01620, lr:3.22e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.680, tt:4494.001\n",
      "Ep:175, loss:0.00000, loss_test:0.01622, lr:3.19e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.677, tt:4519.185\n",
      "Ep:176, loss:0.00000, loss_test:0.01625, lr:3.15e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.677, tt:4544.876\n",
      "Ep:177, loss:0.00000, loss_test:0.01626, lr:3.12e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.696, tt:4573.819\n",
      "Ep:178, loss:0.00000, loss_test:0.01628, lr:3.09e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.691, tt:4598.699\n",
      "Ep:179, loss:0.00000, loss_test:0.01629, lr:3.06e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.691, tt:4624.404\n",
      "Ep:180, loss:0.00000, loss_test:0.01632, lr:3.03e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.689, tt:4649.743\n",
      "Ep:181, loss:0.00000, loss_test:0.01633, lr:3.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.693, tt:4676.059\n",
      "Ep:182, loss:0.00000, loss_test:0.01635, lr:2.97e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.698, tt:4702.770\n",
      "Ep:183, loss:0.00000, loss_test:0.01636, lr:2.94e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.701, tt:4728.946\n",
      "Ep:184, loss:0.00000, loss_test:0.01636, lr:2.91e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.700, tt:4754.461\n",
      "Ep:185, loss:0.00000, loss_test:0.01639, lr:2.88e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.698, tt:4779.871\n",
      "Ep:186, loss:0.00000, loss_test:0.01641, lr:2.85e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.702, tt:4806.354\n",
      "Ep:187, loss:0.00000, loss_test:0.01642, lr:2.82e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.701, tt:4831.856\n",
      "Ep:188, loss:0.00000, loss_test:0.01642, lr:2.80e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.700, tt:4857.292\n",
      "Ep:189, loss:0.00000, loss_test:0.01643, lr:2.77e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.701, tt:4883.095\n",
      "Ep:190, loss:0.00000, loss_test:0.01645, lr:2.74e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.687, tt:4906.182\n",
      "Ep:191, loss:0.00000, loss_test:0.01645, lr:2.71e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.677, tt:4929.902\n",
      "Ep:192, loss:0.00000, loss_test:0.01646, lr:2.69e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.678, tt:4955.809\n",
      "Ep:193, loss:0.00000, loss_test:0.01648, lr:2.66e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.661, tt:4978.209\n",
      "Ep:194, loss:0.00000, loss_test:0.01650, lr:2.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.652, tt:5002.129\n",
      "Ep:195, loss:0.00000, loss_test:0.01652, lr:2.61e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.646, tt:5026.623\n",
      "Ep:196, loss:0.00000, loss_test:0.01653, lr:2.58e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.639, tt:5050.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.01653, lr:2.55e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.623, tt:5073.314\n",
      "Ep:198, loss:0.00000, loss_test:0.01653, lr:2.53e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.615, tt:5097.341\n",
      "Ep:199, loss:0.00000, loss_test:0.01654, lr:2.50e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.601, tt:5120.270\n",
      "Ep:200, loss:0.00000, loss_test:0.01656, lr:2.48e-02, fs:0.85714 (r=0.788,p=0.940),  time:25.599, tt:5145.483\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13950, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.776, tt:25.776\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13810, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.863, tt:55.726\n",
      "Ep:2, loss:0.00028, loss_test:0.13569, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:27.775, tt:83.325\n",
      "Ep:3, loss:0.00027, loss_test:0.13199, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:27.518, tt:110.073\n",
      "Ep:4, loss:0.00027, loss_test:0.12618, lr:1.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:27.150, tt:135.752\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.11791, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:27.190, tt:163.141\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10987, lr:1.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:27.466, tt:192.265\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10596, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:27.345, tt:218.759\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10509, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:27.430, tt:246.871\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10312, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:27.501, tt:275.014\n",
      "Ep:10, loss:0.00022, loss_test:0.10239, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:27.474, tt:302.214\n",
      "Ep:11, loss:0.00021, loss_test:0.10126, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:27.492, tt:329.905\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10080, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:27.409, tt:356.312\n",
      "Ep:13, loss:0.00020, loss_test:0.10022, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:27.459, tt:384.427\n",
      "Ep:14, loss:0.00019, loss_test:0.09922, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:27.421, tt:411.322\n",
      "Ep:15, loss:0.00019, loss_test:0.09910, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:27.443, tt:439.086\n",
      "Ep:16, loss:0.00018, loss_test:0.09944, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:27.378, tt:465.430\n",
      "Ep:17, loss:0.00018, loss_test:0.09887, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:27.329, tt:491.930\n",
      "Ep:18, loss:0.00017, loss_test:0.09772, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:27.302, tt:518.729\n",
      "Ep:19, loss:0.00017, loss_test:0.09660, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:27.248, tt:544.964\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09552, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:27.200, tt:571.194\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09453, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:27.209, tt:598.609\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09357, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:27.263, tt:627.047\n",
      "Ep:23, loss:0.00015, loss_test:0.09212, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:27.291, tt:654.994\n",
      "Ep:24, loss:0.00014, loss_test:0.09093, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:27.247, tt:681.174\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08983, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:27.203, tt:707.276\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08867, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:27.207, tt:734.589\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08765, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:27.174, tt:760.859\n",
      "Ep:28, loss:0.00013, loss_test:0.08590, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:27.203, tt:788.875\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08560, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:27.185, tt:815.542\n",
      "Ep:30, loss:0.00012, loss_test:0.08396, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:27.184, tt:842.717\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08281, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:27.213, tt:870.805\n",
      "Ep:32, loss:0.00011, loss_test:0.08185, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:27.165, tt:896.458\n",
      "Ep:33, loss:0.00011, loss_test:0.08101, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:27.158, tt:923.361\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08103, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:27.203, tt:952.114\n",
      "Ep:35, loss:0.00010, loss_test:0.08025, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:27.215, tt:979.724\n",
      "Ep:36, loss:0.00010, loss_test:0.07893, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.216, tt:1007.000\n",
      "Ep:37, loss:0.00009, loss_test:0.07897, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:27.209, tt:1033.947\n",
      "Ep:38, loss:0.00009, loss_test:0.07771, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.174, tt:1059.804\n",
      "Ep:39, loss:0.00009, loss_test:0.07772, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:27.199, tt:1087.963\n",
      "Ep:40, loss:0.00008, loss_test:0.07638, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:27.179, tt:1114.359\n",
      "Ep:41, loss:0.00008, loss_test:0.07480, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:27.170, tt:1141.134\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07504, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:27.162, tt:1167.980\n",
      "Ep:43, loss:0.00008, loss_test:0.07390, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:27.173, tt:1195.613\n",
      "Ep:44, loss:0.00007, loss_test:0.07429, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:27.161, tt:1222.247\n",
      "Ep:45, loss:0.00007, loss_test:0.07233, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.149, tt:1248.850\n",
      "Ep:46, loss:0.00007, loss_test:0.07255, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:27.133, tt:1275.270\n",
      "Ep:47, loss:0.00007, loss_test:0.07156, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.151, tt:1303.258\n",
      "Ep:48, loss:0.00007, loss_test:0.07079, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:27.170, tt:1331.325\n",
      "Ep:49, loss:0.00006, loss_test:0.07070, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.160, tt:1357.976\n",
      "Ep:50, loss:0.00006, loss_test:0.06922, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:27.151, tt:1384.691\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.06966, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:27.160, tt:1412.321\n",
      "Ep:52, loss:0.00006, loss_test:0.06858, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:27.173, tt:1440.169\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.06908, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:27.185, tt:1467.968\n",
      "Ep:54, loss:0.00006, loss_test:0.06810, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:27.166, tt:1494.133\n",
      "Ep:55, loss:0.00005, loss_test:0.06807, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:27.160, tt:1520.932\n",
      "Ep:56, loss:0.00005, loss_test:0.06747, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:27.160, tt:1548.123\n",
      "Ep:57, loss:0.00005, loss_test:0.06608, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:27.132, tt:1573.671\n",
      "Ep:58, loss:0.00005, loss_test:0.06741, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.122, tt:1600.171\n",
      "Ep:59, loss:0.00005, loss_test:0.06635, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:27.118, tt:1627.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.06733, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:27.093, tt:1652.647\n",
      "Ep:61, loss:0.00005, loss_test:0.06597, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:27.094, tt:1679.858\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00005, loss_test:0.06764, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.090, tt:1706.658\n",
      "Ep:63, loss:0.00005, loss_test:0.06497, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:27.072, tt:1732.634\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.06672, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.067, tt:1759.342\n",
      "Ep:65, loss:0.00005, loss_test:0.06432, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:27.053, tt:1785.523\n",
      "Ep:66, loss:0.00004, loss_test:0.06605, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:27.035, tt:1811.370\n",
      "Ep:67, loss:0.00004, loss_test:0.06422, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:27.045, tt:1839.069\n",
      "Ep:68, loss:0.00004, loss_test:0.06419, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:27.072, tt:1867.975\n",
      "Ep:69, loss:0.00004, loss_test:0.06403, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:27.080, tt:1895.582\n",
      "Ep:70, loss:0.00004, loss_test:0.06256, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:27.088, tt:1923.242\n",
      "Ep:71, loss:0.00004, loss_test:0.06265, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:27.096, tt:1950.934\n",
      "Ep:72, loss:0.00004, loss_test:0.06208, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:27.117, tt:1979.542\n",
      "Ep:73, loss:0.00004, loss_test:0.06205, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:27.132, tt:2007.794\n",
      "Ep:74, loss:0.00004, loss_test:0.06150, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:27.137, tt:2035.290\n",
      "Ep:75, loss:0.00004, loss_test:0.06201, lr:9.90e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.143, tt:2062.843\n",
      "Ep:76, loss:0.00003, loss_test:0.06076, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:27.145, tt:2090.157\n",
      "Ep:77, loss:0.00003, loss_test:0.06161, lr:9.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.131, tt:2116.184\n",
      "Ep:78, loss:0.00003, loss_test:0.05995, lr:9.61e-03, fs:0.89947 (r=0.859,p=0.944),  time:27.119, tt:2142.435\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00003, loss_test:0.06113, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.135, tt:2170.790\n",
      "Ep:80, loss:0.00003, loss_test:0.05972, lr:9.61e-03, fs:0.90526 (r=0.869,p=0.945),  time:27.158, tt:2199.763\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00003, loss_test:0.06133, lr:9.61e-03, fs:0.86957 (r=0.808,p=0.941),  time:27.179, tt:2228.702\n",
      "Ep:82, loss:0.00003, loss_test:0.05978, lr:9.61e-03, fs:0.89947 (r=0.859,p=0.944),  time:27.185, tt:2256.349\n",
      "Ep:83, loss:0.00003, loss_test:0.06177, lr:9.61e-03, fs:0.86957 (r=0.808,p=0.941),  time:27.182, tt:2283.262\n",
      "Ep:84, loss:0.00003, loss_test:0.06063, lr:9.61e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.185, tt:2310.722\n",
      "Ep:85, loss:0.00003, loss_test:0.06133, lr:9.61e-03, fs:0.86957 (r=0.808,p=0.941),  time:27.183, tt:2337.701\n",
      "Ep:86, loss:0.00003, loss_test:0.06157, lr:9.61e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.204, tt:2366.737\n",
      "Ep:87, loss:0.00003, loss_test:0.06005, lr:9.61e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.205, tt:2394.069\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.06261, lr:9.61e-03, fs:0.85083 (r=0.778,p=0.939),  time:27.203, tt:2421.034\n",
      "Ep:89, loss:0.00003, loss_test:0.05939, lr:9.61e-03, fs:0.91667 (r=0.889,p=0.946),  time:27.212, tt:2449.090\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00003, loss_test:0.06319, lr:9.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.195, tt:2474.768\n",
      "Ep:91, loss:0.00003, loss_test:0.05867, lr:9.61e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.217, tt:2503.919\n",
      "Ep:92, loss:0.00003, loss_test:0.06103, lr:9.61e-03, fs:0.86339 (r=0.798,p=0.940),  time:27.212, tt:2530.711\n",
      "Ep:93, loss:0.00003, loss_test:0.06136, lr:9.61e-03, fs:0.85714 (r=0.788,p=0.940),  time:27.223, tt:2558.990\n",
      "Ep:94, loss:0.00003, loss_test:0.05831, lr:9.61e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.236, tt:2587.388\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00003, loss_test:0.06150, lr:9.61e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.250, tt:2616.042\n",
      "Ep:96, loss:0.00003, loss_test:0.05930, lr:9.61e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.255, tt:2643.764\n",
      "Ep:97, loss:0.00003, loss_test:0.05839, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.259, tt:2671.407\n",
      "Ep:98, loss:0.00003, loss_test:0.05919, lr:9.61e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.269, tt:2699.592\n",
      "Ep:99, loss:0.00002, loss_test:0.05882, lr:9.61e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.268, tt:2726.789\n",
      "Ep:100, loss:0.00002, loss_test:0.05814, lr:9.61e-03, fs:0.86957 (r=0.808,p=0.941),  time:27.268, tt:2754.055\n",
      "Ep:101, loss:0.00002, loss_test:0.05715, lr:9.61e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.281, tt:2782.619\n",
      "Ep:102, loss:0.00002, loss_test:0.05834, lr:9.61e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.275, tt:2809.287\n",
      "Ep:103, loss:0.00002, loss_test:0.05736, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.276, tt:2836.689\n",
      "Ep:104, loss:0.00002, loss_test:0.05671, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:27.280, tt:2864.372\n",
      "Ep:105, loss:0.00002, loss_test:0.05657, lr:9.61e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.277, tt:2891.376\n",
      "Ep:106, loss:0.00002, loss_test:0.05636, lr:9.51e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.279, tt:2918.883\n",
      "Ep:107, loss:0.00002, loss_test:0.05540, lr:9.41e-03, fs:0.91667 (r=0.889,p=0.946),  time:27.288, tt:2947.114\n",
      "Ep:108, loss:0.00002, loss_test:0.05720, lr:9.32e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.307, tt:2976.425\n",
      "Ep:109, loss:0.00002, loss_test:0.05547, lr:9.23e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.315, tt:3004.599\n",
      "Ep:110, loss:0.00002, loss_test:0.05576, lr:9.14e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.315, tt:3032.002\n",
      "Ep:111, loss:0.00002, loss_test:0.05582, lr:9.04e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.318, tt:3059.641\n",
      "Ep:112, loss:0.00002, loss_test:0.05552, lr:8.95e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.306, tt:3085.613\n",
      "Ep:113, loss:0.00002, loss_test:0.05481, lr:8.86e-03, fs:0.91667 (r=0.889,p=0.946),  time:27.312, tt:3113.580\n",
      "Ep:114, loss:0.00002, loss_test:0.05567, lr:8.78e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.315, tt:3141.194\n",
      "Ep:115, loss:0.00002, loss_test:0.05513, lr:8.69e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.319, tt:3169.061\n",
      "Ep:116, loss:0.00002, loss_test:0.05472, lr:8.60e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.311, tt:3195.436\n",
      "Ep:117, loss:0.00002, loss_test:0.05453, lr:8.51e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.302, tt:3221.594\n",
      "Ep:118, loss:0.00002, loss_test:0.05583, lr:8.43e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.296, tt:3248.175\n",
      "Ep:119, loss:0.00002, loss_test:0.05451, lr:8.35e-03, fs:0.91005 (r=0.869,p=0.956),  time:27.301, tt:3276.121\n",
      "Ep:120, loss:0.00002, loss_test:0.05458, lr:8.26e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.302, tt:3303.521\n",
      "Ep:121, loss:0.00002, loss_test:0.05540, lr:8.18e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.325, tt:3333.693\n",
      "Ep:122, loss:0.00002, loss_test:0.05408, lr:8.10e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.342, tt:3363.033\n",
      "Ep:123, loss:0.00002, loss_test:0.05573, lr:8.02e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.336, tt:3389.648\n",
      "Ep:124, loss:0.00002, loss_test:0.05356, lr:7.94e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.363, tt:3420.363\n",
      "Ep:125, loss:0.00002, loss_test:0.05568, lr:7.86e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.365, tt:3447.997\n",
      "Ep:126, loss:0.00002, loss_test:0.05396, lr:7.78e-03, fs:0.91667 (r=0.889,p=0.946),  time:27.367, tt:3475.623\n",
      "Ep:127, loss:0.00002, loss_test:0.05384, lr:7.70e-03, fs:0.91099 (r=0.879,p=0.946),  time:27.354, tt:3501.255\n",
      "Ep:128, loss:0.00002, loss_test:0.05469, lr:7.62e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.364, tt:3530.014\n",
      "Ep:129, loss:0.00002, loss_test:0.05342, lr:7.55e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.359, tt:3556.731\n",
      "Ep:130, loss:0.00002, loss_test:0.05448, lr:7.47e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.344, tt:3582.039\n",
      "Ep:131, loss:0.00002, loss_test:0.05366, lr:7.40e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.355, tt:3610.794\n",
      "Ep:132, loss:0.00002, loss_test:0.05371, lr:7.32e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.365, tt:3639.587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00002, loss_test:0.05369, lr:7.25e-03, fs:0.89362 (r=0.848,p=0.944),  time:27.364, tt:3666.733\n",
      "Ep:134, loss:0.00002, loss_test:0.05300, lr:7.18e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.370, tt:3694.920\n",
      "Ep:135, loss:0.00002, loss_test:0.05363, lr:7.11e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.369, tt:3722.126\n",
      "Ep:136, loss:0.00002, loss_test:0.05340, lr:7.03e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.373, tt:3750.041\n",
      "Ep:137, loss:0.00002, loss_test:0.05352, lr:6.96e-03, fs:0.89947 (r=0.859,p=0.944),  time:27.390, tt:3779.771\n",
      "Ep:138, loss:0.00002, loss_test:0.05277, lr:6.89e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.407, tt:3809.548\n",
      "Ep:139, loss:0.00002, loss_test:0.05408, lr:6.83e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.401, tt:3836.163\n",
      "Ep:140, loss:0.00002, loss_test:0.05365, lr:6.76e-03, fs:0.90426 (r=0.859,p=0.955),  time:27.407, tt:3864.390\n",
      "Ep:141, loss:0.00001, loss_test:0.05369, lr:6.69e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.397, tt:3890.406\n",
      "Ep:142, loss:0.00001, loss_test:0.05450, lr:6.62e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.384, tt:3915.902\n",
      "Ep:143, loss:0.00001, loss_test:0.05270, lr:6.56e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.380, tt:3942.788\n",
      "Ep:144, loss:0.00001, loss_test:0.05360, lr:6.49e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.385, tt:3970.830\n",
      "Ep:145, loss:0.00001, loss_test:0.05378, lr:6.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.391, tt:3999.021\n",
      "Ep:146, loss:0.00001, loss_test:0.05315, lr:6.36e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.380, tt:4024.927\n",
      "Ep:147, loss:0.00001, loss_test:0.05402, lr:6.30e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.376, tt:4051.602\n",
      "Ep:148, loss:0.00001, loss_test:0.05241, lr:6.24e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.375, tt:4078.947\n",
      "Ep:149, loss:0.00001, loss_test:0.05359, lr:6.17e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.385, tt:4107.699\n",
      "Ep:150, loss:0.00001, loss_test:0.05332, lr:6.11e-03, fs:0.90426 (r=0.859,p=0.955),  time:27.394, tt:4136.426\n",
      "Ep:151, loss:0.00001, loss_test:0.05247, lr:6.05e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.393, tt:4163.668\n",
      "Ep:152, loss:0.00001, loss_test:0.05326, lr:5.99e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.395, tt:4191.459\n",
      "Ep:153, loss:0.00001, loss_test:0.05326, lr:5.93e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.394, tt:4218.742\n",
      "Ep:154, loss:0.00001, loss_test:0.05241, lr:5.87e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.393, tt:4245.953\n",
      "Ep:155, loss:0.00001, loss_test:0.05313, lr:5.81e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.390, tt:4272.884\n",
      "Ep:156, loss:0.00001, loss_test:0.05242, lr:5.75e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.395, tt:4301.047\n",
      "Ep:157, loss:0.00001, loss_test:0.05270, lr:5.70e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.395, tt:4328.426\n",
      "Ep:158, loss:0.00001, loss_test:0.05342, lr:5.64e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.395, tt:4355.881\n",
      "Ep:159, loss:0.00001, loss_test:0.05228, lr:5.58e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.397, tt:4383.464\n",
      "Ep:160, loss:0.00001, loss_test:0.05301, lr:5.53e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.395, tt:4410.667\n",
      "Ep:161, loss:0.00001, loss_test:0.05318, lr:5.47e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.400, tt:4438.803\n",
      "Ep:162, loss:0.00001, loss_test:0.05189, lr:5.42e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.411, tt:4468.030\n",
      "Ep:163, loss:0.00001, loss_test:0.05256, lr:5.36e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.410, tt:4495.166\n",
      "Ep:164, loss:0.00001, loss_test:0.05279, lr:5.31e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.410, tt:4522.633\n",
      "Ep:165, loss:0.00001, loss_test:0.05209, lr:5.26e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.418, tt:4551.328\n",
      "Ep:166, loss:0.00001, loss_test:0.05227, lr:5.20e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.415, tt:4578.305\n",
      "Ep:167, loss:0.00001, loss_test:0.05259, lr:5.15e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.417, tt:4606.064\n",
      "Ep:168, loss:0.00001, loss_test:0.05220, lr:5.10e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.417, tt:4633.395\n",
      "Ep:169, loss:0.00001, loss_test:0.05234, lr:5.05e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.413, tt:4660.182\n",
      "Ep:170, loss:0.00001, loss_test:0.05274, lr:5.00e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.411, tt:4687.337\n",
      "Ep:171, loss:0.00001, loss_test:0.05198, lr:4.95e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.420, tt:4716.208\n",
      "Ep:172, loss:0.00001, loss_test:0.05287, lr:4.90e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.416, tt:4742.955\n",
      "Ep:173, loss:0.00001, loss_test:0.05316, lr:4.85e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.420, tt:4771.119\n",
      "Ep:174, loss:0.00001, loss_test:0.05187, lr:4.80e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.409, tt:4796.514\n",
      "Ep:175, loss:0.00001, loss_test:0.05242, lr:4.75e-03, fs:0.90426 (r=0.859,p=0.955),  time:27.387, tt:4820.074\n",
      "Ep:176, loss:0.00001, loss_test:0.05294, lr:4.71e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.379, tt:4846.051\n",
      "Ep:177, loss:0.00001, loss_test:0.05214, lr:4.66e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.374, tt:4872.487\n",
      "Ep:178, loss:0.00001, loss_test:0.05174, lr:4.61e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.377, tt:4900.416\n",
      "Ep:179, loss:0.00001, loss_test:0.05238, lr:4.57e-03, fs:0.91579 (r=0.879,p=0.956),  time:27.364, tt:4925.464\n",
      "Ep:180, loss:0.00001, loss_test:0.05232, lr:4.52e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.359, tt:4952.063\n",
      "Ep:181, loss:0.00001, loss_test:0.05206, lr:4.48e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.360, tt:4979.573\n",
      "Ep:182, loss:0.00001, loss_test:0.05217, lr:4.43e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.355, tt:5006.044\n",
      "Ep:183, loss:0.00001, loss_test:0.05251, lr:4.39e-03, fs:0.90426 (r=0.859,p=0.955),  time:27.356, tt:5033.524\n",
      "Ep:184, loss:0.00001, loss_test:0.05201, lr:4.34e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.353, tt:5060.396\n",
      "Ep:185, loss:0.00001, loss_test:0.05181, lr:4.30e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.352, tt:5087.458\n",
      "Ep:186, loss:0.00001, loss_test:0.05206, lr:4.26e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.356, tt:5115.538\n",
      "Ep:187, loss:0.00001, loss_test:0.05183, lr:4.21e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.347, tt:5141.296\n",
      "Ep:188, loss:0.00001, loss_test:0.05202, lr:4.17e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.351, tt:5169.419\n",
      "Ep:189, loss:0.00001, loss_test:0.05193, lr:4.13e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.341, tt:5194.824\n",
      "Ep:190, loss:0.00001, loss_test:0.05198, lr:4.09e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.330, tt:5220.062\n",
      "Ep:191, loss:0.00001, loss_test:0.05226, lr:4.05e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.317, tt:5244.905\n",
      "Ep:192, loss:0.00001, loss_test:0.05171, lr:4.01e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.309, tt:5270.623\n",
      "Ep:193, loss:0.00001, loss_test:0.05184, lr:3.97e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.294, tt:5295.066\n",
      "Ep:194, loss:0.00001, loss_test:0.05253, lr:3.93e-03, fs:0.88649 (r=0.828,p=0.953),  time:27.270, tt:5317.638\n",
      "Ep:195, loss:0.00001, loss_test:0.05189, lr:3.89e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.249, tt:5340.882\n",
      "Ep:196, loss:0.00001, loss_test:0.05144, lr:3.85e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.230, tt:5364.284\n",
      "Ep:197, loss:0.00001, loss_test:0.05231, lr:3.81e-03, fs:0.89840 (r=0.848,p=0.955),  time:27.209, tt:5387.459\n",
      "Ep:198, loss:0.00001, loss_test:0.05242, lr:3.77e-03, fs:0.89247 (r=0.838,p=0.954),  time:27.174, tt:5407.606\n",
      "Ep:199, loss:0.00001, loss_test:0.05160, lr:3.73e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.134, tt:5426.701\n",
      "Ep:200, loss:0.00001, loss_test:0.05194, lr:3.70e-03, fs:0.92147 (r=0.889,p=0.957),  time:27.121, tt:5451.277\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02054, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:30.605, tt:30.605\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02251, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:30.802, tt:61.604\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02390, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.988, tt:92.965\n",
      "Ep:3, loss:0.00005, loss_test:0.02364, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:32.119, tt:128.477\n",
      "Ep:4, loss:0.00005, loss_test:0.02215, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:32.567, tt:162.837\n",
      "Ep:5, loss:0.00004, loss_test:0.02032, lr:6.00e-02, fs:0.68100 (r=0.960,p=0.528),  time:33.169, tt:199.012\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01887, lr:6.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:33.896, tt:237.274\n",
      "Ep:7, loss:0.00004, loss_test:0.01786, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:33.914, tt:271.308\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01698, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:33.945, tt:305.507\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01646, lr:6.00e-02, fs:0.71318 (r=0.929,p=0.579),  time:33.988, tt:339.881\n",
      "Ep:10, loss:0.00004, loss_test:0.01622, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:34.204, tt:376.247\n",
      "Ep:11, loss:0.00004, loss_test:0.01587, lr:6.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:34.201, tt:410.418\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01553, lr:6.00e-02, fs:0.73518 (r=0.939,p=0.604),  time:34.158, tt:444.060\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:34.228, tt:479.189\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01508, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:34.222, tt:513.328\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.234, tt:547.750\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01477, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:34.239, tt:582.066\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.249, tt:616.487\n",
      "Ep:18, loss:0.00003, loss_test:0.01452, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.255, tt:650.851\n",
      "Ep:19, loss:0.00003, loss_test:0.01449, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:34.324, tt:686.487\n",
      "Ep:20, loss:0.00003, loss_test:0.01450, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:34.347, tt:721.290\n",
      "Ep:21, loss:0.00003, loss_test:0.01447, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:34.378, tt:756.314\n",
      "Ep:22, loss:0.00003, loss_test:0.01442, lr:6.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:34.386, tt:790.881\n",
      "Ep:23, loss:0.00003, loss_test:0.01434, lr:6.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:34.352, tt:824.437\n",
      "Ep:24, loss:0.00002, loss_test:0.01427, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:34.353, tt:858.819\n",
      "Ep:25, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:34.365, tt:893.482\n",
      "Ep:26, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:34.358, tt:927.661\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01409, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:34.324, tt:961.068\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:34.356, tt:996.328\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:34.387, tt:1031.602\n",
      "Ep:30, loss:0.00002, loss_test:0.01409, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:34.377, tt:1065.676\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01409, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:34.382, tt:1100.214\n",
      "Ep:32, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:34.368, tt:1134.137\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:34.358, tt:1168.163\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:34.400, tt:1203.991\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:34.462, tt:1240.622\n",
      "Ep:36, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:34.514, tt:1277.033\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:34.533, tt:1312.258\n",
      "Ep:38, loss:0.00002, loss_test:0.01387, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:34.576, tt:1348.462\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:34.573, tt:1382.906\n",
      "Ep:40, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:34.585, tt:1418.004\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:34.606, tt:1453.464\n",
      "Ep:42, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:34.586, tt:1487.218\n",
      "Ep:43, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:34.591, tt:1521.987\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01431, lr:6.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:34.603, tt:1557.127\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01433, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.585, tt:1590.901\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01435, lr:6.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.581, tt:1625.309\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01451, lr:6.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:34.585, tt:1660.070\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01452, lr:6.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:34.572, tt:1694.038\n",
      "Ep:49, loss:0.00001, loss_test:0.01454, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.552, tt:1727.586\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01463, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.526, tt:1760.852\n",
      "Ep:51, loss:0.00001, loss_test:0.01468, lr:6.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:34.534, tt:1795.771\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01470, lr:6.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:34.516, tt:1829.351\n",
      "Ep:53, loss:0.00001, loss_test:0.01484, lr:6.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:34.516, tt:1863.854\n",
      "Ep:54, loss:0.00001, loss_test:0.01496, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.535, tt:1899.415\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01514, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.532, tt:1933.801\n",
      "Ep:56, loss:0.00001, loss_test:0.01521, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.517, tt:1967.484\n",
      "Ep:57, loss:0.00001, loss_test:0.01526, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.529, tt:2002.687\n",
      "Ep:58, loss:0.00001, loss_test:0.01534, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.512, tt:2036.223\n",
      "Ep:59, loss:0.00001, loss_test:0.01543, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.511, tt:2070.685\n",
      "Ep:60, loss:0.00001, loss_test:0.01560, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.507, tt:2104.932\n",
      "Ep:61, loss:0.00001, loss_test:0.01558, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.513, tt:2139.812\n",
      "Ep:62, loss:0.00001, loss_test:0.01570, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.527, tt:2175.198\n",
      "Ep:63, loss:0.00001, loss_test:0.01579, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.529, tt:2209.868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01602, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.565, tt:2246.714\n",
      "Ep:65, loss:0.00001, loss_test:0.01602, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.567, tt:2281.407\n",
      "Ep:66, loss:0.00001, loss_test:0.01622, lr:5.94e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.582, tt:2316.967\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01613, lr:5.94e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.601, tt:2352.877\n",
      "Ep:68, loss:0.00001, loss_test:0.01628, lr:5.94e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.610, tt:2388.084\n",
      "Ep:69, loss:0.00001, loss_test:0.01635, lr:5.94e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.639, tt:2424.739\n",
      "Ep:70, loss:0.00001, loss_test:0.01647, lr:5.94e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.653, tt:2460.382\n",
      "Ep:71, loss:0.00001, loss_test:0.01636, lr:5.94e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.686, tt:2497.393\n",
      "Ep:72, loss:0.00001, loss_test:0.01679, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.680, tt:2531.676\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01639, lr:5.94e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.693, tt:2567.266\n",
      "Ep:74, loss:0.00001, loss_test:0.01673, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.701, tt:2602.558\n",
      "Ep:75, loss:0.00001, loss_test:0.01682, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.737, tt:2639.997\n",
      "Ep:76, loss:0.00001, loss_test:0.01671, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.766, tt:2676.975\n",
      "Ep:77, loss:0.00001, loss_test:0.01696, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.800, tt:2714.374\n",
      "Ep:78, loss:0.00001, loss_test:0.01698, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.800, tt:2749.177\n",
      "Ep:79, loss:0.00001, loss_test:0.01723, lr:5.94e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.829, tt:2786.280\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01707, lr:5.94e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.824, tt:2820.751\n",
      "Ep:81, loss:0.00001, loss_test:0.01747, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.832, tt:2856.214\n",
      "Ep:82, loss:0.00001, loss_test:0.01733, lr:5.94e-02, fs:0.89796 (r=0.889,p=0.907),  time:34.844, tt:2892.077\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01746, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.869, tt:2928.979\n",
      "Ep:84, loss:0.00001, loss_test:0.01767, lr:5.94e-02, fs:0.89796 (r=0.889,p=0.907),  time:34.895, tt:2966.065\n",
      "Ep:85, loss:0.00001, loss_test:0.01762, lr:5.94e-02, fs:0.89796 (r=0.889,p=0.907),  time:34.907, tt:3002.045\n",
      "Ep:86, loss:0.00001, loss_test:0.01806, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.921, tt:3038.102\n",
      "Ep:87, loss:0.00001, loss_test:0.01770, lr:5.94e-02, fs:0.89691 (r=0.879,p=0.916),  time:34.943, tt:3074.993\n",
      "Ep:88, loss:0.00001, loss_test:0.01816, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.958, tt:3111.276\n",
      "Ep:89, loss:0.00001, loss_test:0.01784, lr:5.94e-02, fs:0.90625 (r=0.879,p=0.935),  time:34.957, tt:3146.096\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01860, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.950, tt:3180.473\n",
      "Ep:91, loss:0.00001, loss_test:0.01799, lr:5.94e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.958, tt:3216.132\n",
      "Ep:92, loss:0.00001, loss_test:0.01869, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.976, tt:3252.735\n",
      "Ep:93, loss:0.00001, loss_test:0.01820, lr:5.94e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.993, tt:3289.350\n",
      "Ep:94, loss:0.00001, loss_test:0.01899, lr:5.94e-02, fs:0.89340 (r=0.889,p=0.898),  time:35.007, tt:3325.661\n",
      "Ep:95, loss:0.00001, loss_test:0.01850, lr:5.94e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.017, tt:3361.604\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00000, loss_test:0.01862, lr:5.94e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.020, tt:3396.946\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00000, loss_test:0.01917, lr:5.94e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.043, tt:3434.255\n",
      "Ep:98, loss:0.00000, loss_test:0.01874, lr:5.94e-02, fs:0.90625 (r=0.879,p=0.935),  time:35.069, tt:3471.819\n",
      "Ep:99, loss:0.00000, loss_test:0.01916, lr:5.94e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.085, tt:3508.462\n",
      "Ep:100, loss:0.00000, loss_test:0.01917, lr:5.94e-02, fs:0.90625 (r=0.879,p=0.935),  time:35.087, tt:3543.785\n",
      "Ep:101, loss:0.00000, loss_test:0.01960, lr:5.94e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.083, tt:3578.478\n",
      "Ep:102, loss:0.00000, loss_test:0.01969, lr:5.94e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.099, tt:3615.153\n",
      "Ep:103, loss:0.00000, loss_test:0.01928, lr:5.94e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.100, tt:3650.372\n",
      "Ep:104, loss:0.00000, loss_test:0.01999, lr:5.94e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.099, tt:3685.425\n",
      "Ep:105, loss:0.00000, loss_test:0.01964, lr:5.94e-02, fs:0.90625 (r=0.879,p=0.935),  time:35.106, tt:3721.255\n",
      "Ep:106, loss:0.00000, loss_test:0.01966, lr:5.94e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.114, tt:3757.159\n",
      "Ep:107, loss:0.00000, loss_test:0.02058, lr:5.94e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.114, tt:3792.334\n",
      "Ep:108, loss:0.00000, loss_test:0.02019, lr:5.88e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.125, tt:3828.668\n",
      "Ep:109, loss:0.00000, loss_test:0.02033, lr:5.82e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.132, tt:3864.503\n",
      "Ep:110, loss:0.00000, loss_test:0.02088, lr:5.76e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.135, tt:3899.994\n",
      "Ep:111, loss:0.00000, loss_test:0.02036, lr:5.71e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.139, tt:3935.552\n",
      "Ep:112, loss:0.00000, loss_test:0.02096, lr:5.65e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.147, tt:3971.605\n",
      "Ep:113, loss:0.00000, loss_test:0.02104, lr:5.59e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.146, tt:4006.605\n",
      "Ep:114, loss:0.00000, loss_test:0.02084, lr:5.54e-02, fs:0.90625 (r=0.879,p=0.935),  time:35.155, tt:4042.860\n",
      "Ep:115, loss:0.00000, loss_test:0.02143, lr:5.48e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.169, tt:4079.640\n",
      "Ep:116, loss:0.00000, loss_test:0.02142, lr:5.43e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.190, tt:4117.229\n",
      "Ep:117, loss:0.00000, loss_test:0.02118, lr:5.37e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.202, tt:4153.830\n",
      "Ep:118, loss:0.00000, loss_test:0.02178, lr:5.32e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.209, tt:4189.861\n",
      "Ep:119, loss:0.00000, loss_test:0.02152, lr:5.27e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.199, tt:4223.901\n",
      "Ep:120, loss:0.00000, loss_test:0.02173, lr:5.21e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.198, tt:4258.952\n",
      "Ep:121, loss:0.00000, loss_test:0.02206, lr:5.16e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.203, tt:4294.795\n",
      "Ep:122, loss:0.00000, loss_test:0.02205, lr:5.11e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.209, tt:4330.683\n",
      "Ep:123, loss:0.00000, loss_test:0.02241, lr:5.06e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.207, tt:4365.658\n",
      "Ep:124, loss:0.00000, loss_test:0.02213, lr:5.01e-02, fs:0.90625 (r=0.879,p=0.935),  time:35.219, tt:4402.345\n",
      "Ep:125, loss:0.00000, loss_test:0.02271, lr:4.96e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.214, tt:4436.907\n",
      "Ep:126, loss:0.00000, loss_test:0.02224, lr:4.91e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.239, tt:4475.398\n",
      "Ep:127, loss:0.00000, loss_test:0.02239, lr:4.86e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.248, tt:4511.806\n",
      "Ep:128, loss:0.00000, loss_test:0.02312, lr:4.81e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.250, tt:4547.279\n",
      "Ep:129, loss:0.00000, loss_test:0.02206, lr:4.76e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.245, tt:4581.811\n",
      "Ep:130, loss:0.00000, loss_test:0.02338, lr:4.71e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.244, tt:4617.002\n",
      "Ep:131, loss:0.00000, loss_test:0.02257, lr:4.67e-02, fs:0.91192 (r=0.889,p=0.936),  time:35.249, tt:4652.825\n",
      "Ep:132, loss:0.00000, loss_test:0.02232, lr:4.62e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.244, tt:4687.392\n",
      "Ep:133, loss:0.00000, loss_test:0.02329, lr:4.57e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.243, tt:4722.607\n",
      "Ep:134, loss:0.00000, loss_test:0.02253, lr:4.53e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.237, tt:4756.995\n",
      "Ep:135, loss:0.00000, loss_test:0.02350, lr:4.48e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.248, tt:4793.763\n",
      "Ep:136, loss:0.00000, loss_test:0.02262, lr:4.44e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.249, tt:4829.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02382, lr:4.39e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.252, tt:4864.815\n",
      "Ep:138, loss:0.00000, loss_test:0.02289, lr:4.35e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.255, tt:4900.446\n",
      "Ep:139, loss:0.00000, loss_test:0.02371, lr:4.31e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.261, tt:4936.577\n",
      "Ep:140, loss:0.00000, loss_test:0.02311, lr:4.26e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.261, tt:4971.816\n",
      "Ep:141, loss:0.00000, loss_test:0.02386, lr:4.22e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.257, tt:5006.459\n",
      "Ep:142, loss:0.00000, loss_test:0.02353, lr:4.18e-02, fs:0.91099 (r=0.879,p=0.946),  time:35.263, tt:5042.614\n",
      "Ep:143, loss:0.00000, loss_test:0.02365, lr:4.14e-02, fs:0.90526 (r=0.869,p=0.945),  time:35.272, tt:5079.122\n",
      "Ep:144, loss:0.00000, loss_test:0.02406, lr:4.10e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.267, tt:5113.737\n",
      "Ep:145, loss:0.00000, loss_test:0.02381, lr:4.05e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.276, tt:5150.229\n",
      "Ep:146, loss:0.00000, loss_test:0.02445, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.276, tt:5185.501\n",
      "Ep:147, loss:0.00000, loss_test:0.02406, lr:3.97e-02, fs:0.88770 (r=0.838,p=0.943),  time:35.278, tt:5221.184\n",
      "Ep:148, loss:0.00000, loss_test:0.02441, lr:3.93e-02, fs:0.89947 (r=0.859,p=0.944),  time:35.274, tt:5255.778\n",
      "Ep:149, loss:0.00000, loss_test:0.02438, lr:3.89e-02, fs:0.88770 (r=0.838,p=0.943),  time:35.261, tt:5289.105\n",
      "Ep:150, loss:0.00000, loss_test:0.02461, lr:3.86e-02, fs:0.89474 (r=0.859,p=0.934),  time:35.254, tt:5323.409\n",
      "Ep:151, loss:0.00000, loss_test:0.02446, lr:3.82e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.249, tt:5357.896\n",
      "Ep:152, loss:0.00000, loss_test:0.02498, lr:3.78e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.237, tt:5391.239\n",
      "Ep:153, loss:0.00000, loss_test:0.02457, lr:3.74e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.228, tt:5425.158\n",
      "Ep:154, loss:0.00000, loss_test:0.02498, lr:3.70e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.232, tt:5460.938\n",
      "Ep:155, loss:0.00000, loss_test:0.02467, lr:3.67e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.233, tt:5496.360\n",
      "Ep:156, loss:0.00000, loss_test:0.02501, lr:3.63e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.221, tt:5529.752\n",
      "Ep:157, loss:0.00000, loss_test:0.02490, lr:3.59e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.218, tt:5564.511\n",
      "Ep:158, loss:0.00000, loss_test:0.02510, lr:3.56e-02, fs:0.88770 (r=0.838,p=0.943),  time:35.224, tt:5600.601\n",
      "Ep:159, loss:0.00000, loss_test:0.02498, lr:3.52e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.230, tt:5636.775\n",
      "Ep:160, loss:0.00000, loss_test:0.02548, lr:3.49e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.235, tt:5672.762\n",
      "Ep:161, loss:0.00000, loss_test:0.02506, lr:3.45e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.234, tt:5707.888\n",
      "Ep:162, loss:0.00000, loss_test:0.02539, lr:3.42e-02, fs:0.87568 (r=0.818,p=0.942),  time:35.244, tt:5744.744\n",
      "Ep:163, loss:0.00000, loss_test:0.02536, lr:3.38e-02, fs:0.87701 (r=0.828,p=0.932),  time:35.247, tt:5780.511\n",
      "Ep:164, loss:0.00000, loss_test:0.02532, lr:3.35e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.252, tt:5816.546\n",
      "Ep:165, loss:0.00000, loss_test:0.02544, lr:3.32e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.261, tt:5853.361\n",
      "Ep:166, loss:0.00000, loss_test:0.02557, lr:3.28e-02, fs:0.87568 (r=0.818,p=0.942),  time:35.267, tt:5889.520\n",
      "Ep:167, loss:0.00000, loss_test:0.02553, lr:3.25e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.263, tt:5924.262\n",
      "Ep:168, loss:0.00000, loss_test:0.02572, lr:3.22e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.265, tt:5959.794\n",
      "Ep:169, loss:0.00000, loss_test:0.02558, lr:3.19e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.267, tt:5995.316\n",
      "Ep:170, loss:0.00000, loss_test:0.02579, lr:3.15e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.265, tt:6030.313\n",
      "Ep:171, loss:0.00000, loss_test:0.02596, lr:3.12e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.261, tt:6064.879\n",
      "Ep:172, loss:0.00000, loss_test:0.02557, lr:3.09e-02, fs:0.83799 (r=0.758,p=0.938),  time:35.261, tt:6100.078\n",
      "Ep:173, loss:0.00000, loss_test:0.02605, lr:3.06e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.260, tt:6135.269\n",
      "Ep:174, loss:0.00000, loss_test:0.02559, lr:3.03e-02, fs:0.83799 (r=0.758,p=0.938),  time:35.263, tt:6171.030\n",
      "Ep:175, loss:0.00000, loss_test:0.02613, lr:3.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.246, tt:6203.234\n",
      "Ep:176, loss:0.00000, loss_test:0.02589, lr:2.97e-02, fs:0.83799 (r=0.758,p=0.938),  time:35.241, tt:6237.570\n",
      "Ep:177, loss:0.00000, loss_test:0.02620, lr:2.94e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.239, tt:6272.529\n",
      "Ep:178, loss:0.00000, loss_test:0.02588, lr:2.91e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.231, tt:6306.412\n",
      "Ep:179, loss:0.00000, loss_test:0.02620, lr:2.88e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.233, tt:6341.920\n",
      "Ep:180, loss:0.00000, loss_test:0.02608, lr:2.85e-02, fs:0.83333 (r=0.758,p=0.926),  time:35.237, tt:6377.940\n",
      "Ep:181, loss:0.00000, loss_test:0.02643, lr:2.82e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.231, tt:6412.018\n",
      "Ep:182, loss:0.00000, loss_test:0.02615, lr:2.80e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.228, tt:6446.748\n",
      "Ep:183, loss:0.00000, loss_test:0.02638, lr:2.77e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.240, tt:6484.237\n",
      "Ep:184, loss:0.00000, loss_test:0.02624, lr:2.74e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.248, tt:6520.908\n",
      "Ep:185, loss:0.00000, loss_test:0.02646, lr:2.71e-02, fs:0.83333 (r=0.758,p=0.926),  time:35.249, tt:6556.320\n",
      "Ep:186, loss:0.00000, loss_test:0.02633, lr:2.69e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.247, tt:6591.146\n",
      "Ep:187, loss:0.00000, loss_test:0.02647, lr:2.66e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.254, tt:6627.730\n",
      "Ep:188, loss:0.00000, loss_test:0.02659, lr:2.63e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.258, tt:6663.742\n",
      "Ep:189, loss:0.00000, loss_test:0.02650, lr:2.61e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.265, tt:6700.361\n",
      "Ep:190, loss:0.00000, loss_test:0.02673, lr:2.58e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.274, tt:6737.392\n",
      "Ep:191, loss:0.00000, loss_test:0.02654, lr:2.55e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.277, tt:6773.236\n",
      "Ep:192, loss:0.00000, loss_test:0.02673, lr:2.53e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.277, tt:6808.415\n",
      "Ep:193, loss:0.00000, loss_test:0.02665, lr:2.50e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.279, tt:6844.110\n",
      "Ep:194, loss:0.00000, loss_test:0.02664, lr:2.48e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.286, tt:6880.859\n",
      "Ep:195, loss:0.00000, loss_test:0.02682, lr:2.45e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.275, tt:6913.843\n",
      "Ep:196, loss:0.00000, loss_test:0.02669, lr:2.43e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.282, tt:6950.474\n",
      "Ep:197, loss:0.00000, loss_test:0.02684, lr:2.40e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.274, tt:6984.273\n",
      "Ep:198, loss:0.00000, loss_test:0.02684, lr:2.38e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.268, tt:7018.319\n",
      "Ep:199, loss:0.00000, loss_test:0.02690, lr:2.36e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.267, tt:7053.370\n",
      "Ep:200, loss:0.00000, loss_test:0.02693, lr:2.33e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.239, tt:7083.106\n",
      "Ep:201, loss:0.00000, loss_test:0.02699, lr:2.31e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.240, tt:7118.425\n",
      "Ep:202, loss:0.00000, loss_test:0.02692, lr:2.29e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.229, tt:7151.552\n",
      "Ep:203, loss:0.00000, loss_test:0.02703, lr:2.26e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.228, tt:7186.443\n",
      "Ep:204, loss:0.00000, loss_test:0.02700, lr:2.24e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.215, tt:7219.114\n",
      "Ep:205, loss:0.00000, loss_test:0.02704, lr:2.22e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.187, tt:7248.540\n",
      "Ep:206, loss:0.00000, loss_test:0.02712, lr:2.20e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.176, tt:7281.425\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12365, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:32.792, tt:32.792\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00026, loss_test:0.11773, lr:1.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:33.893, tt:67.785\n",
      "Ep:2, loss:0.00026, loss_test:0.11140, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:35.386, tt:106.157\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.10622, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:35.751, tt:143.006\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.10308, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:35.635, tt:178.177\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10081, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:35.618, tt:213.707\n",
      "Ep:6, loss:0.00024, loss_test:0.09828, lr:1.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:35.858, tt:251.005\n",
      "Ep:7, loss:0.00023, loss_test:0.09432, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:35.684, tt:285.473\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.09082, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:35.668, tt:321.010\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.08902, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:35.577, tt:355.766\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.08737, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:35.492, tt:390.413\n",
      "Ep:11, loss:0.00020, loss_test:0.08535, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:35.376, tt:424.512\n",
      "Ep:12, loss:0.00020, loss_test:0.08350, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:35.334, tt:459.347\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.08278, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:35.252, tt:493.527\n",
      "Ep:14, loss:0.00019, loss_test:0.08219, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:35.265, tt:528.975\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08124, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:35.255, tt:564.085\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08026, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:35.372, tt:601.330\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.07955, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:35.355, tt:636.389\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.07880, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:35.406, tt:672.708\n",
      "Ep:19, loss:0.00016, loss_test:0.07791, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.459, tt:709.171\n",
      "Ep:20, loss:0.00016, loss_test:0.07720, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.476, tt:744.986\n",
      "Ep:21, loss:0.00015, loss_test:0.07722, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.517, tt:781.378\n",
      "Ep:22, loss:0.00015, loss_test:0.07669, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:35.566, tt:818.014\n",
      "Ep:23, loss:0.00014, loss_test:0.07566, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.573, tt:853.741\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07504, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.593, tt:889.822\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07406, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.599, tt:925.573\n",
      "Ep:26, loss:0.00013, loss_test:0.07321, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.630, tt:962.008\n",
      "Ep:27, loss:0.00012, loss_test:0.07262, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.656, tt:998.356\n",
      "Ep:28, loss:0.00012, loss_test:0.07164, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.664, tt:1034.262\n",
      "Ep:29, loss:0.00012, loss_test:0.07161, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.687, tt:1070.610\n",
      "Ep:30, loss:0.00011, loss_test:0.07085, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.714, tt:1107.149\n",
      "Ep:31, loss:0.00011, loss_test:0.07086, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.723, tt:1143.148\n",
      "Ep:32, loss:0.00010, loss_test:0.07039, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.746, tt:1179.618\n",
      "Ep:33, loss:0.00010, loss_test:0.06942, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.733, tt:1214.906\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06976, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.720, tt:1250.213\n",
      "Ep:35, loss:0.00009, loss_test:0.06880, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.728, tt:1286.217\n",
      "Ep:36, loss:0.00009, loss_test:0.06846, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.745, tt:1322.547\n",
      "Ep:37, loss:0.00009, loss_test:0.06845, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.754, tt:1358.636\n",
      "Ep:38, loss:0.00008, loss_test:0.06747, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.756, tt:1394.483\n",
      "Ep:39, loss:0.00008, loss_test:0.06916, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.740, tt:1429.589\n",
      "Ep:40, loss:0.00008, loss_test:0.06641, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.767, tt:1466.447\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.06922, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.800, tt:1503.596\n",
      "Ep:42, loss:0.00007, loss_test:0.06677, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.821, tt:1540.314\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.06941, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.839, tt:1576.930\n",
      "Ep:44, loss:0.00007, loss_test:0.06725, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.827, tt:1612.237\n",
      "Ep:45, loss:0.00007, loss_test:0.06550, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.844, tt:1648.841\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.06839, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.860, tt:1685.435\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.06686, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.868, tt:1721.646\n",
      "Ep:48, loss:0.00006, loss_test:0.06598, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.858, tt:1757.045\n",
      "Ep:49, loss:0.00006, loss_test:0.06868, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.861, tt:1793.029\n",
      "Ep:50, loss:0.00006, loss_test:0.06643, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:35.884, tt:1830.104\n",
      "Ep:51, loss:0.00006, loss_test:0.07044, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:35.879, tt:1865.691\n",
      "Ep:52, loss:0.00006, loss_test:0.06896, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.881, tt:1901.684\n",
      "Ep:53, loss:0.00005, loss_test:0.06501, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.909, tt:1939.112\n",
      "Ep:54, loss:0.00005, loss_test:0.06916, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.909, tt:1975.003\n",
      "Ep:55, loss:0.00005, loss_test:0.06632, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.953, tt:2013.367\n",
      "Ep:56, loss:0.00005, loss_test:0.06411, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.957, tt:2049.542\n",
      "Ep:57, loss:0.00005, loss_test:0.06776, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:35.960, tt:2085.681\n",
      "Ep:58, loss:0.00004, loss_test:0.06523, lr:9.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:35.970, tt:2122.228\n",
      "Ep:59, loss:0.00004, loss_test:0.06646, lr:9.80e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.993, tt:2159.560\n",
      "Ep:60, loss:0.00004, loss_test:0.06864, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.009, tt:2196.559\n",
      "Ep:61, loss:0.00004, loss_test:0.06679, lr:9.61e-03, fs:0.87958 (r=0.848,p=0.913),  time:35.999, tt:2231.937\n",
      "Ep:62, loss:0.00004, loss_test:0.06904, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:35.994, tt:2267.631\n",
      "Ep:63, loss:0.00004, loss_test:0.06424, lr:9.41e-03, fs:0.86772 (r=0.828,p=0.911),  time:36.012, tt:2304.774\n",
      "Ep:64, loss:0.00004, loss_test:0.06905, lr:9.32e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.010, tt:2340.654\n",
      "Ep:65, loss:0.00004, loss_test:0.06862, lr:9.23e-03, fs:0.87958 (r=0.848,p=0.913),  time:36.032, tt:2378.125\n",
      "Ep:66, loss:0.00004, loss_test:0.06318, lr:9.14e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.061, tt:2416.103\n",
      "Ep:67, loss:0.00004, loss_test:0.07508, lr:9.04e-03, fs:0.86294 (r=0.859,p=0.867),  time:36.081, tt:2453.502\n",
      "Ep:68, loss:0.00005, loss_test:0.06111, lr:8.95e-03, fs:0.82955 (r=0.737,p=0.948),  time:36.091, tt:2490.293\n",
      "Ep:69, loss:0.00004, loss_test:0.06694, lr:8.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.097, tt:2526.825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00004, loss_test:0.06667, lr:8.78e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.115, tt:2564.137\n",
      "Ep:71, loss:0.00004, loss_test:0.06354, lr:8.69e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.125, tt:2601.015\n",
      "Ep:72, loss:0.00003, loss_test:0.06613, lr:8.60e-03, fs:0.86316 (r=0.828,p=0.901),  time:36.134, tt:2637.776\n",
      "Ep:73, loss:0.00003, loss_test:0.06554, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.152, tt:2675.227\n",
      "Ep:74, loss:0.00003, loss_test:0.06441, lr:8.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.186, tt:2713.984\n",
      "Ep:75, loss:0.00003, loss_test:0.06698, lr:8.35e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.186, tt:2750.116\n",
      "Ep:76, loss:0.00003, loss_test:0.06639, lr:8.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.178, tt:2785.682\n",
      "Ep:77, loss:0.00003, loss_test:0.06524, lr:8.18e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.181, tt:2822.105\n",
      "Ep:78, loss:0.00003, loss_test:0.06534, lr:8.10e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.194, tt:2859.347\n",
      "Ep:79, loss:0.00003, loss_test:0.06456, lr:8.02e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.202, tt:2896.190\n",
      "Ep:80, loss:0.00003, loss_test:0.06510, lr:7.94e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.199, tt:2932.139\n",
      "Ep:81, loss:0.00003, loss_test:0.06688, lr:7.86e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.203, tt:2968.658\n",
      "Ep:82, loss:0.00003, loss_test:0.06450, lr:7.78e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.174, tt:3002.453\n",
      "Ep:83, loss:0.00003, loss_test:0.06452, lr:7.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.154, tt:3036.952\n",
      "Ep:84, loss:0.00003, loss_test:0.06505, lr:7.62e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.163, tt:3073.824\n",
      "Ep:85, loss:0.00003, loss_test:0.06546, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.163, tt:3109.990\n",
      "Ep:86, loss:0.00003, loss_test:0.06546, lr:7.47e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.184, tt:3148.009\n",
      "Ep:87, loss:0.00003, loss_test:0.06605, lr:7.40e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.203, tt:3185.876\n",
      "Ep:88, loss:0.00003, loss_test:0.06400, lr:7.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.238, tt:3225.148\n",
      "Ep:89, loss:0.00003, loss_test:0.06699, lr:7.25e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.244, tt:3261.991\n",
      "Ep:90, loss:0.00002, loss_test:0.06639, lr:7.18e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.251, tt:3298.806\n",
      "Ep:91, loss:0.00002, loss_test:0.06492, lr:7.11e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.239, tt:3334.034\n",
      "Ep:92, loss:0.00002, loss_test:0.06638, lr:7.03e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.252, tt:3371.417\n",
      "Ep:93, loss:0.00002, loss_test:0.06433, lr:6.96e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.270, tt:3409.347\n",
      "Ep:94, loss:0.00002, loss_test:0.06558, lr:6.89e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.268, tt:3445.445\n",
      "Ep:95, loss:0.00002, loss_test:0.06450, lr:6.83e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.258, tt:3480.797\n",
      "Ep:96, loss:0.00002, loss_test:0.06767, lr:6.76e-03, fs:0.82222 (r=0.747,p=0.914),  time:36.275, tt:3518.682\n",
      "Ep:97, loss:0.00002, loss_test:0.06525, lr:6.69e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.287, tt:3556.117\n",
      "Ep:98, loss:0.00002, loss_test:0.06498, lr:6.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.308, tt:3594.472\n",
      "Ep:99, loss:0.00002, loss_test:0.06593, lr:6.56e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.325, tt:3632.519\n",
      "Ep:100, loss:0.00002, loss_test:0.06577, lr:6.49e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.317, tt:3668.033\n",
      "Ep:101, loss:0.00002, loss_test:0.06564, lr:6.43e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.321, tt:3704.772\n",
      "Ep:102, loss:0.00002, loss_test:0.06606, lr:6.36e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.338, tt:3742.799\n",
      "Ep:103, loss:0.00002, loss_test:0.06627, lr:6.30e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.344, tt:3779.726\n",
      "Ep:104, loss:0.00002, loss_test:0.06441, lr:6.24e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.338, tt:3815.525\n",
      "Ep:105, loss:0.00002, loss_test:0.06512, lr:6.17e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.330, tt:3850.968\n",
      "Ep:106, loss:0.00002, loss_test:0.06619, lr:6.11e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.332, tt:3887.577\n",
      "Ep:107, loss:0.00002, loss_test:0.06399, lr:6.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.328, tt:3923.475\n",
      "Ep:108, loss:0.00002, loss_test:0.06746, lr:5.99e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.327, tt:3959.638\n",
      "Ep:109, loss:0.00002, loss_test:0.06504, lr:5.93e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.330, tt:3996.324\n",
      "Ep:110, loss:0.00002, loss_test:0.06678, lr:5.87e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.331, tt:4032.791\n",
      "Ep:111, loss:0.00002, loss_test:0.06602, lr:5.81e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.329, tt:4068.814\n",
      "Ep:112, loss:0.00002, loss_test:0.06614, lr:5.75e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.342, tt:4106.605\n",
      "Ep:113, loss:0.00002, loss_test:0.06704, lr:5.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.346, tt:4143.422\n",
      "Ep:114, loss:0.00002, loss_test:0.06442, lr:5.64e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.346, tt:4179.748\n",
      "Ep:115, loss:0.00002, loss_test:0.06588, lr:5.58e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.356, tt:4217.252\n",
      "Ep:116, loss:0.00002, loss_test:0.06681, lr:5.53e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.353, tt:4253.316\n",
      "Ep:117, loss:0.00002, loss_test:0.06587, lr:5.47e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.337, tt:4287.780\n",
      "Ep:118, loss:0.00002, loss_test:0.06564, lr:5.42e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.332, tt:4323.461\n",
      "Ep:119, loss:0.00002, loss_test:0.06575, lr:5.36e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.327, tt:4359.264\n",
      "Ep:120, loss:0.00002, loss_test:0.06560, lr:5.31e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.335, tt:4396.551\n",
      "Ep:121, loss:0.00002, loss_test:0.06675, lr:5.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.341, tt:4433.625\n",
      "Ep:122, loss:0.00002, loss_test:0.06572, lr:5.20e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.337, tt:4469.402\n",
      "Ep:123, loss:0.00002, loss_test:0.06724, lr:5.15e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.343, tt:4506.490\n",
      "Ep:124, loss:0.00002, loss_test:0.06441, lr:5.10e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.342, tt:4542.729\n",
      "Ep:125, loss:0.00002, loss_test:0.06702, lr:5.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.334, tt:4578.088\n",
      "Ep:126, loss:0.00002, loss_test:0.06544, lr:5.00e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.344, tt:4615.668\n",
      "Ep:127, loss:0.00002, loss_test:0.06624, lr:4.95e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.356, tt:4653.570\n",
      "Ep:128, loss:0.00002, loss_test:0.06645, lr:4.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.365, tt:4691.136\n",
      "Ep:129, loss:0.00002, loss_test:0.06653, lr:4.85e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.368, tt:4727.780\n",
      "Ep:130, loss:0.00002, loss_test:0.06610, lr:4.80e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.376, tt:4765.304\n",
      "Ep:131, loss:0.00002, loss_test:0.06664, lr:4.75e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.369, tt:4800.695\n",
      "Ep:132, loss:0.00002, loss_test:0.06557, lr:4.71e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.362, tt:4836.150\n",
      "Ep:133, loss:0.00002, loss_test:0.06675, lr:4.66e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.365, tt:4872.904\n",
      "Ep:134, loss:0.00002, loss_test:0.06692, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.362, tt:4908.872\n",
      "Ep:135, loss:0.00002, loss_test:0.06538, lr:4.57e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.360, tt:4944.944\n",
      "Ep:136, loss:0.00002, loss_test:0.06607, lr:4.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.366, tt:4982.107\n",
      "Ep:137, loss:0.00002, loss_test:0.06719, lr:4.48e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.367, tt:5018.614\n",
      "Ep:138, loss:0.00001, loss_test:0.06510, lr:4.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.369, tt:5055.225\n",
      "Ep:139, loss:0.00002, loss_test:0.06812, lr:4.39e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.364, tt:5090.912\n",
      "Ep:140, loss:0.00002, loss_test:0.06675, lr:4.34e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.355, tt:5126.027\n",
      "Ep:141, loss:0.00001, loss_test:0.06765, lr:4.30e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.356, tt:5162.544\n",
      "Ep:142, loss:0.00002, loss_test:0.06663, lr:4.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.355, tt:5198.739\n",
      "Ep:143, loss:0.00001, loss_test:0.06771, lr:4.21e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.354, tt:5235.046\n",
      "Ep:144, loss:0.00001, loss_test:0.06813, lr:4.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.354, tt:5271.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.06676, lr:4.13e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.342, tt:5305.958\n",
      "Ep:146, loss:0.00001, loss_test:0.06629, lr:4.09e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.331, tt:5340.696\n",
      "Ep:147, loss:0.00001, loss_test:0.06770, lr:4.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.323, tt:5375.735\n",
      "Ep:148, loss:0.00001, loss_test:0.06672, lr:4.01e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.326, tt:5412.565\n",
      "Ep:149, loss:0.00001, loss_test:0.06728, lr:3.97e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.334, tt:5450.128\n",
      "Ep:150, loss:0.00001, loss_test:0.06623, lr:3.93e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.335, tt:5486.630\n",
      "Ep:151, loss:0.00001, loss_test:0.06719, lr:3.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.339, tt:5523.476\n",
      "Ep:152, loss:0.00001, loss_test:0.06630, lr:3.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.343, tt:5560.481\n",
      "Ep:153, loss:0.00001, loss_test:0.06713, lr:3.81e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.339, tt:5596.248\n",
      "Ep:154, loss:0.00001, loss_test:0.06788, lr:3.77e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.336, tt:5632.026\n",
      "Ep:155, loss:0.00001, loss_test:0.06776, lr:3.73e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.336, tt:5668.441\n",
      "Ep:156, loss:0.00001, loss_test:0.06756, lr:3.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.333, tt:5704.213\n",
      "Ep:157, loss:0.00001, loss_test:0.06620, lr:3.66e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.337, tt:5741.195\n",
      "Ep:158, loss:0.00001, loss_test:0.06844, lr:3.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.347, tt:5779.219\n",
      "Ep:159, loss:0.00001, loss_test:0.06769, lr:3.59e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.355, tt:5816.848\n",
      "Ep:160, loss:0.00001, loss_test:0.06763, lr:3.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.361, tt:5854.139\n",
      "Ep:161, loss:0.00001, loss_test:0.06739, lr:3.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.367, tt:5891.442\n",
      "Ep:162, loss:0.00001, loss_test:0.06771, lr:3.48e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.370, tt:5928.333\n",
      "Ep:163, loss:0.00001, loss_test:0.06839, lr:3.45e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.378, tt:5965.924\n",
      "Ep:164, loss:0.00001, loss_test:0.06879, lr:3.41e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.391, tt:6004.550\n",
      "Ep:165, loss:0.00001, loss_test:0.06806, lr:3.38e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.400, tt:6042.372\n",
      "Ep:166, loss:0.00001, loss_test:0.06709, lr:3.34e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.404, tt:6079.492\n",
      "Ep:167, loss:0.00001, loss_test:0.06860, lr:3.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.401, tt:6115.339\n",
      "Ep:168, loss:0.00001, loss_test:0.06734, lr:3.28e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.398, tt:6151.246\n",
      "Ep:169, loss:0.00001, loss_test:0.06789, lr:3.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.396, tt:6187.337\n",
      "Ep:170, loss:0.00001, loss_test:0.06735, lr:3.21e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.402, tt:6224.748\n",
      "Ep:171, loss:0.00001, loss_test:0.06724, lr:3.18e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.401, tt:6260.951\n",
      "Ep:172, loss:0.00001, loss_test:0.06918, lr:3.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.400, tt:6297.244\n",
      "Ep:173, loss:0.00001, loss_test:0.06757, lr:3.12e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.411, tt:6335.495\n",
      "Ep:174, loss:0.00001, loss_test:0.06784, lr:3.09e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.417, tt:6372.949\n",
      "Ep:175, loss:0.00001, loss_test:0.06855, lr:3.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.419, tt:6409.656\n",
      "Ep:176, loss:0.00001, loss_test:0.06874, lr:3.02e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.413, tt:6445.140\n",
      "Ep:177, loss:0.00001, loss_test:0.06843, lr:2.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.411, tt:6481.110\n",
      "Ep:178, loss:0.00001, loss_test:0.06746, lr:2.96e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.404, tt:6516.367\n",
      "Ep:179, loss:0.00001, loss_test:0.06845, lr:2.93e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.402, tt:6552.362\n",
      "Ep:180, loss:0.00001, loss_test:0.06850, lr:2.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.406, tt:6589.395\n",
      "Ep:181, loss:0.00001, loss_test:0.06813, lr:2.88e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.404, tt:6625.515\n",
      "Ep:182, loss:0.00001, loss_test:0.06878, lr:2.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.395, tt:6660.203\n",
      "Ep:183, loss:0.00001, loss_test:0.06812, lr:2.82e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.397, tt:6696.986\n",
      "Ep:184, loss:0.00001, loss_test:0.06917, lr:2.79e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.401, tt:6734.209\n",
      "Ep:185, loss:0.00001, loss_test:0.06884, lr:2.76e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.403, tt:6770.960\n",
      "Ep:186, loss:0.00001, loss_test:0.06827, lr:2.73e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.407, tt:6808.122\n",
      "Ep:187, loss:0.00001, loss_test:0.06935, lr:2.71e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.425, tt:6847.808\n",
      "Ep:188, loss:0.00001, loss_test:0.06787, lr:2.68e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.433, tt:6885.839\n",
      "Ep:189, loss:0.00001, loss_test:0.06824, lr:2.65e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.441, tt:6923.769\n",
      "Ep:190, loss:0.00001, loss_test:0.06932, lr:2.63e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.439, tt:6959.839\n",
      "Ep:191, loss:0.00001, loss_test:0.06888, lr:2.60e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.441, tt:6996.725\n",
      "Ep:192, loss:0.00001, loss_test:0.06816, lr:2.57e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.442, tt:7033.356\n",
      "Ep:193, loss:0.00001, loss_test:0.06894, lr:2.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.450, tt:7071.387\n",
      "Ep:194, loss:0.00001, loss_test:0.06931, lr:2.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.455, tt:7108.765\n",
      "Ep:195, loss:0.00001, loss_test:0.06883, lr:2.50e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.460, tt:7146.109\n",
      "Ep:196, loss:0.00001, loss_test:0.06841, lr:2.47e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.453, tt:7181.273\n",
      "Ep:197, loss:0.00001, loss_test:0.06907, lr:2.45e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.459, tt:7218.956\n",
      "Ep:198, loss:0.00001, loss_test:0.06972, lr:2.42e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.445, tt:7252.528\n",
      "Ep:199, loss:0.00001, loss_test:0.06953, lr:2.40e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.421, tt:7284.260\n",
      "Ep:200, loss:0.00001, loss_test:0.06912, lr:2.38e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.410, tt:7318.393\n",
      "Ep:201, loss:0.00001, loss_test:0.06923, lr:2.35e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.385, tt:7349.750\n",
      "Ep:202, loss:0.00001, loss_test:0.06942, lr:2.33e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.364, tt:7381.877\n",
      "Ep:203, loss:0.00001, loss_test:0.06888, lr:2.31e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.325, tt:7410.229\n",
      "Ep:204, loss:0.00001, loss_test:0.06903, lr:2.28e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.282, tt:7437.844\n",
      "Ep:205, loss:0.00001, loss_test:0.06907, lr:2.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.256, tt:7468.698\n",
      "Ep:206, loss:0.00001, loss_test:0.06893, lr:2.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.250, tt:7503.669\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.01990, lr:6.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:31.415, tt:31.415\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02265, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:32.113, tt:64.225\n",
      "Ep:2, loss:0.00005, loss_test:0.02538, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.757, tt:98.272\n",
      "Ep:3, loss:0.00005, loss_test:0.02596, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.321, tt:133.284\n",
      "Ep:4, loss:0.00005, loss_test:0.02522, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:33.636, tt:168.179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00005, loss_test:0.02364, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:34.064, tt:204.386\n",
      "Ep:6, loss:0.00005, loss_test:0.02169, lr:6.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:34.356, tt:240.489\n",
      "Ep:7, loss:0.00005, loss_test:0.02015, lr:6.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:34.745, tt:277.959\n",
      "Ep:8, loss:0.00004, loss_test:0.01904, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:34.676, tt:312.082\n",
      "Ep:9, loss:0.00004, loss_test:0.01810, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:34.730, tt:347.300\n",
      "Ep:10, loss:0.00004, loss_test:0.01765, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:34.898, tt:383.879\n",
      "Ep:11, loss:0.00004, loss_test:0.01767, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:35.070, tt:420.844\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01759, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:35.091, tt:456.184\n",
      "Ep:13, loss:0.00004, loss_test:0.01728, lr:6.00e-02, fs:0.70769 (r=0.929,p=0.571),  time:35.207, tt:492.891\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01698, lr:6.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:35.329, tt:529.932\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01676, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:35.496, tt:567.937\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01651, lr:6.00e-02, fs:0.73518 (r=0.939,p=0.604),  time:35.577, tt:604.809\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01623, lr:6.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:35.577, tt:640.385\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01597, lr:6.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:35.532, tt:675.110\n",
      "Ep:19, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:35.538, tt:710.764\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:35.545, tt:746.440\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:35.560, tt:782.319\n",
      "Ep:22, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:35.575, tt:818.219\n",
      "Ep:23, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:35.541, tt:852.990\n",
      "Ep:24, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:35.513, tt:887.833\n",
      "Ep:25, loss:0.00003, loss_test:0.01570, lr:6.00e-02, fs:0.75314 (r=0.909,p=0.643),  time:35.555, tt:924.440\n",
      "Ep:26, loss:0.00003, loss_test:0.01573, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:35.554, tt:959.952\n",
      "Ep:27, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:35.554, tt:995.513\n",
      "Ep:28, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:35.616, tt:1032.864\n",
      "Ep:29, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:35.607, tt:1068.220\n",
      "Ep:30, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:35.627, tt:1104.428\n",
      "Ep:31, loss:0.00002, loss_test:0.01592, lr:6.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:35.656, tt:1140.999\n",
      "Ep:32, loss:0.00002, loss_test:0.01594, lr:5.94e-02, fs:0.74667 (r=0.848,p=0.667),  time:35.649, tt:1176.406\n",
      "Ep:33, loss:0.00002, loss_test:0.01599, lr:5.88e-02, fs:0.74439 (r=0.838,p=0.669),  time:35.642, tt:1211.825\n",
      "Ep:34, loss:0.00002, loss_test:0.01606, lr:5.82e-02, fs:0.73543 (r=0.828,p=0.661),  time:35.638, tt:1247.333\n",
      "Ep:35, loss:0.00002, loss_test:0.01615, lr:5.76e-02, fs:0.73214 (r=0.828,p=0.656),  time:35.621, tt:1282.374\n",
      "Ep:36, loss:0.00002, loss_test:0.01629, lr:5.71e-02, fs:0.74886 (r=0.828,p=0.683),  time:35.581, tt:1316.489\n",
      "Ep:37, loss:0.00002, loss_test:0.01640, lr:5.65e-02, fs:0.74545 (r=0.828,p=0.678),  time:35.579, tt:1352.020\n",
      "Ep:38, loss:0.00002, loss_test:0.01651, lr:5.59e-02, fs:0.74545 (r=0.828,p=0.678),  time:35.576, tt:1387.459\n",
      "Ep:39, loss:0.00002, loss_test:0.01649, lr:5.54e-02, fs:0.75229 (r=0.828,p=0.689),  time:35.567, tt:1422.683\n",
      "Ep:40, loss:0.00002, loss_test:0.01649, lr:5.48e-02, fs:0.76852 (r=0.838,p=0.709),  time:35.596, tt:1459.418\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01649, lr:5.48e-02, fs:0.77209 (r=0.838,p=0.716),  time:35.558, tt:1493.443\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01663, lr:5.48e-02, fs:0.77209 (r=0.838,p=0.716),  time:35.551, tt:1528.690\n",
      "Ep:43, loss:0.00002, loss_test:0.01678, lr:5.48e-02, fs:0.77570 (r=0.838,p=0.722),  time:35.545, tt:1563.961\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01683, lr:5.48e-02, fs:0.77570 (r=0.838,p=0.722),  time:35.536, tt:1599.132\n",
      "Ep:45, loss:0.00002, loss_test:0.01683, lr:5.48e-02, fs:0.77570 (r=0.838,p=0.722),  time:35.536, tt:1634.670\n",
      "Ep:46, loss:0.00002, loss_test:0.01681, lr:5.48e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.535, tt:1670.133\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01679, lr:5.48e-02, fs:0.78673 (r=0.838,p=0.741),  time:35.534, tt:1705.649\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01683, lr:5.48e-02, fs:0.78302 (r=0.838,p=0.735),  time:35.513, tt:1740.131\n",
      "Ep:49, loss:0.00001, loss_test:0.01694, lr:5.48e-02, fs:0.79426 (r=0.838,p=0.755),  time:35.524, tt:1776.181\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01698, lr:5.48e-02, fs:0.79048 (r=0.838,p=0.748),  time:35.530, tt:1812.009\n",
      "Ep:51, loss:0.00001, loss_test:0.01699, lr:5.48e-02, fs:0.79048 (r=0.838,p=0.748),  time:35.558, tt:1849.024\n",
      "Ep:52, loss:0.00001, loss_test:0.01704, lr:5.48e-02, fs:0.79808 (r=0.838,p=0.761),  time:35.583, tt:1885.907\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01707, lr:5.48e-02, fs:0.79426 (r=0.838,p=0.755),  time:35.587, tt:1921.703\n",
      "Ep:54, loss:0.00001, loss_test:0.01726, lr:5.48e-02, fs:0.80583 (r=0.838,p=0.776),  time:35.598, tt:1957.911\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01708, lr:5.48e-02, fs:0.79412 (r=0.818,p=0.771),  time:35.608, tt:1994.070\n",
      "Ep:56, loss:0.00001, loss_test:0.01734, lr:5.48e-02, fs:0.80000 (r=0.828,p=0.774),  time:35.594, tt:2028.836\n",
      "Ep:57, loss:0.00001, loss_test:0.01724, lr:5.48e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.613, tt:2065.547\n",
      "Ep:58, loss:0.00001, loss_test:0.01744, lr:5.48e-02, fs:0.80788 (r=0.828,p=0.788),  time:35.629, tt:2102.121\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01749, lr:5.48e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.659, tt:2139.537\n",
      "Ep:60, loss:0.00001, loss_test:0.01751, lr:5.48e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.668, tt:2175.755\n",
      "Ep:61, loss:0.00001, loss_test:0.01776, lr:5.48e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.696, tt:2213.135\n",
      "Ep:62, loss:0.00001, loss_test:0.01771, lr:5.48e-02, fs:0.81188 (r=0.828,p=0.796),  time:35.703, tt:2249.302\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01798, lr:5.48e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.697, tt:2284.592\n",
      "Ep:64, loss:0.00001, loss_test:0.01784, lr:5.48e-02, fs:0.80788 (r=0.828,p=0.788),  time:35.723, tt:2322.007\n",
      "Ep:65, loss:0.00001, loss_test:0.01808, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:35.723, tt:2357.751\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01803, lr:5.48e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.710, tt:2392.601\n",
      "Ep:67, loss:0.00001, loss_test:0.01844, lr:5.48e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.718, tt:2428.824\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01809, lr:5.48e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.726, tt:2465.083\n",
      "Ep:69, loss:0.00001, loss_test:0.01861, lr:5.48e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.729, tt:2501.011\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01837, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.724, tt:2536.382\n",
      "Ep:71, loss:0.00001, loss_test:0.01855, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.765, tt:2575.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.01865, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.769, tt:2611.124\n",
      "Ep:73, loss:0.00001, loss_test:0.01869, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.774, tt:2647.297\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01881, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.782, tt:2683.674\n",
      "Ep:75, loss:0.00001, loss_test:0.01922, lr:5.48e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.786, tt:2719.733\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01907, lr:5.48e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.781, tt:2755.172\n",
      "Ep:77, loss:0.00001, loss_test:0.01936, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.793, tt:2791.820\n",
      "Ep:78, loss:0.00001, loss_test:0.01940, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.765, tt:2825.417\n",
      "Ep:79, loss:0.00001, loss_test:0.01925, lr:5.48e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.744, tt:2859.481\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01982, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.739, tt:2894.848\n",
      "Ep:81, loss:0.00001, loss_test:0.01953, lr:5.48e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.730, tt:2929.899\n",
      "Ep:82, loss:0.00001, loss_test:0.01984, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.740, tt:2966.421\n",
      "Ep:83, loss:0.00001, loss_test:0.02021, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.738, tt:3001.961\n",
      "Ep:84, loss:0.00001, loss_test:0.01980, lr:5.48e-02, fs:0.83249 (r=0.828,p=0.837),  time:35.726, tt:3036.683\n",
      "Ep:85, loss:0.00001, loss_test:0.02054, lr:5.48e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.703, tt:3070.474\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.02031, lr:5.48e-02, fs:0.83673 (r=0.828,p=0.845),  time:35.706, tt:3106.397\n",
      "Ep:87, loss:0.00001, loss_test:0.02011, lr:5.48e-02, fs:0.81633 (r=0.808,p=0.825),  time:35.721, tt:3143.432\n",
      "Ep:88, loss:0.00001, loss_test:0.02103, lr:5.48e-02, fs:0.83673 (r=0.828,p=0.845),  time:35.730, tt:3180.007\n",
      "Ep:89, loss:0.00001, loss_test:0.02062, lr:5.48e-02, fs:0.83673 (r=0.828,p=0.845),  time:35.727, tt:3215.442\n",
      "Ep:90, loss:0.00001, loss_test:0.02086, lr:5.48e-02, fs:0.83673 (r=0.828,p=0.845),  time:35.747, tt:3252.949\n",
      "Ep:91, loss:0.00001, loss_test:0.02151, lr:5.48e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.745, tt:3288.516\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.02048, lr:5.48e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.739, tt:3323.682\n",
      "Ep:93, loss:0.00001, loss_test:0.02154, lr:5.48e-02, fs:0.83077 (r=0.818,p=0.844),  time:35.723, tt:3357.925\n",
      "Ep:94, loss:0.00001, loss_test:0.02077, lr:5.48e-02, fs:0.83249 (r=0.828,p=0.837),  time:35.719, tt:3393.269\n",
      "Ep:95, loss:0.00001, loss_test:0.02152, lr:5.48e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.713, tt:3428.493\n",
      "Ep:96, loss:0.00001, loss_test:0.02165, lr:5.48e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.705, tt:3463.364\n",
      "Ep:97, loss:0.00001, loss_test:0.02144, lr:5.48e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.696, tt:3498.171\n",
      "Ep:98, loss:0.00001, loss_test:0.02227, lr:5.48e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.687, tt:3533.007\n",
      "Ep:99, loss:0.00001, loss_test:0.02193, lr:5.48e-02, fs:0.81250 (r=0.788,p=0.839),  time:35.668, tt:3566.753\n",
      "Ep:100, loss:0.00001, loss_test:0.02238, lr:5.48e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.654, tt:3601.076\n",
      "Ep:101, loss:0.00001, loss_test:0.02284, lr:5.48e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.648, tt:3636.099\n",
      "Ep:102, loss:0.00001, loss_test:0.02198, lr:5.48e-02, fs:0.78723 (r=0.747,p=0.831),  time:35.623, tt:3669.162\n",
      "Ep:103, loss:0.00001, loss_test:0.02329, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.604, tt:3702.854\n",
      "Ep:104, loss:0.00001, loss_test:0.02278, lr:5.37e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.588, tt:3736.757\n",
      "Ep:105, loss:0.00001, loss_test:0.02240, lr:5.32e-02, fs:0.78495 (r=0.737,p=0.839),  time:35.589, tt:3772.423\n",
      "Ep:106, loss:0.00001, loss_test:0.02338, lr:5.27e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.567, tt:3805.658\n",
      "Ep:107, loss:0.00001, loss_test:0.02243, lr:5.21e-02, fs:0.78495 (r=0.737,p=0.839),  time:35.542, tt:3838.538\n",
      "Ep:108, loss:0.00001, loss_test:0.02354, lr:5.16e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.540, tt:3873.829\n",
      "Ep:109, loss:0.00001, loss_test:0.02289, lr:5.11e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.531, tt:3908.398\n",
      "Ep:110, loss:0.00001, loss_test:0.02358, lr:5.06e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.545, tt:3945.505\n",
      "Ep:111, loss:0.00000, loss_test:0.02400, lr:5.01e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.547, tt:3981.269\n",
      "Ep:112, loss:0.00000, loss_test:0.02340, lr:4.96e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.539, tt:4015.880\n",
      "Ep:113, loss:0.00000, loss_test:0.02430, lr:4.91e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.520, tt:4049.291\n",
      "Ep:114, loss:0.00000, loss_test:0.02390, lr:4.86e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.513, tt:4083.982\n",
      "Ep:115, loss:0.00000, loss_test:0.02452, lr:4.81e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.505, tt:4118.597\n",
      "Ep:116, loss:0.00000, loss_test:0.02466, lr:4.76e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.496, tt:4153.012\n",
      "Ep:117, loss:0.00000, loss_test:0.02450, lr:4.71e-02, fs:0.77348 (r=0.707,p=0.854),  time:35.487, tt:4187.499\n",
      "Ep:118, loss:0.00000, loss_test:0.02538, lr:4.67e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.478, tt:4221.898\n",
      "Ep:119, loss:0.00000, loss_test:0.02476, lr:4.62e-02, fs:0.77348 (r=0.707,p=0.854),  time:35.467, tt:4256.025\n",
      "Ep:120, loss:0.00000, loss_test:0.02523, lr:4.57e-02, fs:0.77348 (r=0.707,p=0.854),  time:35.456, tt:4290.174\n",
      "Ep:121, loss:0.00000, loss_test:0.02544, lr:4.53e-02, fs:0.76667 (r=0.697,p=0.852),  time:35.450, tt:4324.877\n",
      "Ep:122, loss:0.00000, loss_test:0.02540, lr:4.48e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.437, tt:4358.691\n",
      "Ep:123, loss:0.00000, loss_test:0.02578, lr:4.44e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.432, tt:4393.531\n",
      "Ep:124, loss:0.00000, loss_test:0.02591, lr:4.39e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.416, tt:4427.043\n",
      "Ep:125, loss:0.00000, loss_test:0.02595, lr:4.35e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.409, tt:4461.546\n",
      "Ep:126, loss:0.00000, loss_test:0.02613, lr:4.31e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.403, tt:4496.173\n",
      "Ep:127, loss:0.00000, loss_test:0.02648, lr:4.26e-02, fs:0.77348 (r=0.707,p=0.854),  time:35.401, tt:4531.340\n",
      "Ep:128, loss:0.00000, loss_test:0.02648, lr:4.22e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.387, tt:4564.911\n",
      "Ep:129, loss:0.00000, loss_test:0.02675, lr:4.18e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.392, tt:4600.983\n",
      "Ep:130, loss:0.00000, loss_test:0.02691, lr:4.14e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.384, tt:4635.339\n",
      "Ep:131, loss:0.00000, loss_test:0.02685, lr:4.10e-02, fs:0.75281 (r=0.677,p=0.848),  time:35.372, tt:4669.122\n",
      "Ep:132, loss:0.00000, loss_test:0.02714, lr:4.05e-02, fs:0.76667 (r=0.697,p=0.852),  time:35.377, tt:4705.129\n",
      "Ep:133, loss:0.00000, loss_test:0.02702, lr:4.01e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.378, tt:4740.640\n",
      "Ep:134, loss:0.00000, loss_test:0.02736, lr:3.97e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.372, tt:4775.169\n",
      "Ep:135, loss:0.00000, loss_test:0.02741, lr:3.93e-02, fs:0.75706 (r=0.677,p=0.859),  time:35.364, tt:4809.512\n",
      "Ep:136, loss:0.00000, loss_test:0.02758, lr:3.89e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.358, tt:4844.021\n",
      "Ep:137, loss:0.00000, loss_test:0.02765, lr:3.86e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.356, tt:4879.089\n",
      "Ep:138, loss:0.00000, loss_test:0.02786, lr:3.82e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.347, tt:4913.251\n",
      "Ep:139, loss:0.00000, loss_test:0.02790, lr:3.78e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.348, tt:4948.726\n",
      "Ep:140, loss:0.00000, loss_test:0.02806, lr:3.74e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.352, tt:4984.685\n",
      "Ep:141, loss:0.00000, loss_test:0.02821, lr:3.70e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.346, tt:5019.123\n",
      "Ep:142, loss:0.00000, loss_test:0.02840, lr:3.67e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.345, tt:5054.375\n",
      "Ep:143, loss:0.00000, loss_test:0.02849, lr:3.63e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.352, tt:5090.618\n",
      "Ep:144, loss:0.00000, loss_test:0.02839, lr:3.59e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.347, tt:5125.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.02866, lr:3.56e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.341, tt:5159.756\n",
      "Ep:146, loss:0.00000, loss_test:0.02884, lr:3.52e-02, fs:0.73563 (r=0.646,p=0.853),  time:35.355, tt:5197.164\n",
      "Ep:147, loss:0.00000, loss_test:0.02888, lr:3.49e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.360, tt:5233.223\n",
      "Ep:148, loss:0.00000, loss_test:0.02898, lr:3.45e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.359, tt:5268.550\n",
      "Ep:149, loss:0.00000, loss_test:0.02904, lr:3.42e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.360, tt:5303.944\n",
      "Ep:150, loss:0.00000, loss_test:0.02921, lr:3.38e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.364, tt:5340.010\n",
      "Ep:151, loss:0.00000, loss_test:0.02938, lr:3.35e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.363, tt:5375.118\n",
      "Ep:152, loss:0.00000, loss_test:0.02933, lr:3.32e-02, fs:0.72832 (r=0.636,p=0.851),  time:35.355, tt:5409.382\n",
      "Ep:153, loss:0.00000, loss_test:0.02948, lr:3.28e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.360, tt:5445.477\n",
      "Ep:154, loss:0.00000, loss_test:0.02966, lr:3.25e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.375, tt:5483.052\n",
      "Ep:155, loss:0.00000, loss_test:0.02986, lr:3.22e-02, fs:0.72832 (r=0.636,p=0.851),  time:35.379, tt:5519.085\n",
      "Ep:156, loss:0.00000, loss_test:0.02964, lr:3.19e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.382, tt:5554.914\n",
      "Ep:157, loss:0.00000, loss_test:0.02998, lr:3.15e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.385, tt:5590.793\n",
      "Ep:158, loss:0.00000, loss_test:0.03005, lr:3.12e-02, fs:0.73563 (r=0.646,p=0.853),  time:35.386, tt:5626.391\n",
      "Ep:159, loss:0.00000, loss_test:0.03010, lr:3.09e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.384, tt:5661.390\n",
      "Ep:160, loss:0.00000, loss_test:0.03034, lr:3.06e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.391, tt:5697.994\n",
      "Ep:161, loss:0.00000, loss_test:0.03019, lr:3.03e-02, fs:0.72093 (r=0.626,p=0.849),  time:35.398, tt:5734.522\n",
      "Ep:162, loss:0.00000, loss_test:0.03055, lr:3.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.397, tt:5769.742\n",
      "Ep:163, loss:0.00000, loss_test:0.03042, lr:2.97e-02, fs:0.72832 (r=0.636,p=0.851),  time:35.398, tt:5805.306\n",
      "Ep:164, loss:0.00000, loss_test:0.03054, lr:2.94e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.401, tt:5841.240\n",
      "Ep:165, loss:0.00000, loss_test:0.03063, lr:2.91e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.419, tt:5879.531\n",
      "Ep:166, loss:0.00000, loss_test:0.03081, lr:2.88e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.426, tt:5916.173\n",
      "Ep:167, loss:0.00000, loss_test:0.03095, lr:2.85e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.428, tt:5951.856\n",
      "Ep:168, loss:0.00000, loss_test:0.03093, lr:2.82e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.432, tt:5987.943\n",
      "Ep:169, loss:0.00000, loss_test:0.03121, lr:2.80e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.426, tt:6022.466\n",
      "Ep:170, loss:0.00000, loss_test:0.03090, lr:2.77e-02, fs:0.72515 (r=0.626,p=0.861),  time:35.430, tt:6058.451\n",
      "Ep:171, loss:0.00000, loss_test:0.03140, lr:2.74e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.429, tt:6093.754\n",
      "Ep:172, loss:0.00000, loss_test:0.03115, lr:2.71e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.439, tt:6130.986\n",
      "Ep:173, loss:0.00000, loss_test:0.03144, lr:2.69e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.438, tt:6166.170\n",
      "Ep:174, loss:0.00000, loss_test:0.03154, lr:2.66e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.437, tt:6201.520\n",
      "Ep:175, loss:0.00000, loss_test:0.03152, lr:2.63e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.432, tt:6236.106\n",
      "Ep:176, loss:0.00000, loss_test:0.03168, lr:2.61e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.429, tt:6271.022\n",
      "Ep:177, loss:0.00000, loss_test:0.03147, lr:2.58e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.427, tt:6305.970\n",
      "Ep:178, loss:0.00000, loss_test:0.03207, lr:2.55e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.428, tt:6341.663\n",
      "Ep:179, loss:0.00000, loss_test:0.03161, lr:2.53e-02, fs:0.72515 (r=0.626,p=0.861),  time:35.427, tt:6376.887\n",
      "Ep:180, loss:0.00000, loss_test:0.03211, lr:2.50e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.433, tt:6413.390\n",
      "Ep:181, loss:0.00000, loss_test:0.03174, lr:2.48e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.429, tt:6448.082\n",
      "Ep:182, loss:0.00000, loss_test:0.03229, lr:2.45e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.428, tt:6483.322\n",
      "Ep:183, loss:0.00000, loss_test:0.03197, lr:2.43e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.425, tt:6518.182\n",
      "Ep:184, loss:0.00000, loss_test:0.03237, lr:2.40e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.417, tt:6552.101\n",
      "Ep:185, loss:0.00000, loss_test:0.03216, lr:2.38e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.417, tt:6587.640\n",
      "Ep:186, loss:0.00000, loss_test:0.03239, lr:2.36e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.416, tt:6622.709\n",
      "Ep:187, loss:0.00000, loss_test:0.03240, lr:2.33e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.416, tt:6658.287\n",
      "Ep:188, loss:0.00000, loss_test:0.03247, lr:2.31e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.409, tt:6692.250\n",
      "Ep:189, loss:0.00000, loss_test:0.03264, lr:2.29e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.407, tt:6727.333\n",
      "Ep:190, loss:0.00000, loss_test:0.03268, lr:2.26e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.403, tt:6761.907\n",
      "Ep:191, loss:0.00000, loss_test:0.03274, lr:2.24e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.395, tt:6795.935\n",
      "Ep:192, loss:0.00000, loss_test:0.03278, lr:2.22e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.388, tt:6829.870\n",
      "Ep:193, loss:0.00000, loss_test:0.03298, lr:2.20e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.389, tt:6865.389\n",
      "Ep:194, loss:0.00000, loss_test:0.03290, lr:2.17e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.392, tt:6901.416\n",
      "Ep:195, loss:0.00000, loss_test:0.03298, lr:2.15e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.391, tt:6936.662\n",
      "Ep:196, loss:0.00000, loss_test:0.03304, lr:2.13e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.387, tt:6971.256\n",
      "Ep:197, loss:0.00000, loss_test:0.03320, lr:2.11e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.386, tt:7006.344\n",
      "Ep:198, loss:0.00000, loss_test:0.03316, lr:2.09e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.387, tt:7042.058\n",
      "Ep:199, loss:0.00000, loss_test:0.03334, lr:2.07e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.380, tt:7075.922\n",
      "Ep:200, loss:0.00000, loss_test:0.03327, lr:2.05e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.362, tt:7107.732\n",
      "Ep:201, loss:0.00000, loss_test:0.03341, lr:2.03e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.365, tt:7143.674\n",
      "Ep:202, loss:0.00000, loss_test:0.03349, lr:2.01e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.360, tt:7178.122\n",
      "Ep:203, loss:0.00000, loss_test:0.03342, lr:1.99e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.341, tt:7209.630\n",
      "Ep:204, loss:0.00000, loss_test:0.03361, lr:1.97e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.329, tt:7242.390\n",
      "Ep:205, loss:0.00000, loss_test:0.03355, lr:1.95e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.320, tt:7275.840\n",
      "Ep:206, loss:0.00000, loss_test:0.03368, lr:1.93e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.320, tt:7311.273\n",
      "Ep:207, loss:0.00000, loss_test:0.03378, lr:1.91e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.313, tt:7345.183\n",
      "Ep:208, loss:0.00000, loss_test:0.03379, lr:1.89e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.291, tt:7375.917\n",
      "Ep:209, loss:0.00000, loss_test:0.03380, lr:1.87e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.273, tt:7407.375\n",
      "Ep:210, loss:0.00000, loss_test:0.03396, lr:1.85e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.276, tt:7443.304\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13146, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:34.948, tt:34.948\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12723, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:34.643, tt:69.286\n",
      "Ep:2, loss:0.00026, loss_test:0.12093, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:34.839, tt:104.518\n",
      "Ep:3, loss:0.00026, loss_test:0.11511, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:35.235, tt:140.941\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00025, loss_test:0.11025, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:35.500, tt:177.498\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.10627, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:35.832, tt:214.991\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10375, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:36.118, tt:252.828\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10269, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:36.418, tt:291.341\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10133, lr:1.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:36.390, tt:327.509\n",
      "Ep:9, loss:0.00023, loss_test:0.09970, lr:1.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:36.465, tt:364.650\n",
      "Ep:10, loss:0.00022, loss_test:0.09762, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:36.554, tt:402.096\n",
      "Ep:11, loss:0.00021, loss_test:0.09508, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:36.555, tt:438.666\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09353, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:36.549, tt:475.142\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09228, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:36.684, tt:513.579\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09044, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:36.715, tt:550.728\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.08886, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:36.740, tt:587.848\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08753, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:36.748, tt:624.721\n",
      "Ep:17, loss:0.00017, loss_test:0.08608, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:36.820, tt:662.768\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08506, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:36.840, tt:699.957\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08370, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:36.951, tt:739.029\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08291, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:36.983, tt:776.647\n",
      "Ep:21, loss:0.00015, loss_test:0.08263, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:36.937, tt:812.615\n",
      "Ep:22, loss:0.00015, loss_test:0.08166, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:37.017, tt:851.389\n",
      "Ep:23, loss:0.00014, loss_test:0.08099, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:37.008, tt:888.188\n",
      "Ep:24, loss:0.00014, loss_test:0.08007, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:37.006, tt:925.154\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07997, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:37.003, tt:962.074\n",
      "Ep:26, loss:0.00013, loss_test:0.07839, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:37.029, tt:999.770\n",
      "Ep:27, loss:0.00012, loss_test:0.07835, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:37.049, tt:1037.365\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07829, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:37.035, tt:1074.013\n",
      "Ep:29, loss:0.00011, loss_test:0.07771, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:37.026, tt:1110.785\n",
      "Ep:30, loss:0.00011, loss_test:0.07644, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:37.030, tt:1147.939\n",
      "Ep:31, loss:0.00011, loss_test:0.07580, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:37.000, tt:1184.000\n",
      "Ep:32, loss:0.00010, loss_test:0.07515, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:37.057, tt:1222.891\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07348, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:37.129, tt:1262.399\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07304, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:37.146, tt:1300.094\n",
      "Ep:35, loss:0.00009, loss_test:0.07419, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:37.158, tt:1337.689\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07128, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:37.128, tt:1373.745\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07320, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:37.155, tt:1411.887\n",
      "Ep:38, loss:0.00008, loss_test:0.07207, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:37.153, tt:1448.967\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.07217, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.166, tt:1486.633\n",
      "Ep:40, loss:0.00008, loss_test:0.07152, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:37.199, tt:1525.155\n",
      "Ep:41, loss:0.00008, loss_test:0.07164, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:37.224, tt:1563.397\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.07203, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:37.257, tt:1602.037\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.07204, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:37.252, tt:1639.106\n",
      "Ep:44, loss:0.00007, loss_test:0.06948, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:37.257, tt:1676.560\n",
      "Ep:45, loss:0.00007, loss_test:0.06993, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:37.270, tt:1714.423\n",
      "Ep:46, loss:0.00007, loss_test:0.07189, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:37.270, tt:1751.682\n",
      "Ep:47, loss:0.00007, loss_test:0.06821, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.310, tt:1790.886\n",
      "Ep:48, loss:0.00006, loss_test:0.06845, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:37.320, tt:1828.694\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.06701, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:37.326, tt:1866.285\n",
      "Ep:50, loss:0.00006, loss_test:0.06721, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:37.327, tt:1903.696\n",
      "Ep:51, loss:0.00006, loss_test:0.06512, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:37.343, tt:1941.822\n",
      "Ep:52, loss:0.00006, loss_test:0.06519, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:37.377, tt:1980.985\n",
      "Ep:53, loss:0.00005, loss_test:0.06552, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:37.370, tt:2017.987\n",
      "Ep:54, loss:0.00005, loss_test:0.06518, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:37.371, tt:2055.418\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.06289, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:37.387, tt:2093.650\n",
      "Ep:56, loss:0.00005, loss_test:0.06393, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:37.390, tt:2131.252\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.06206, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:37.378, tt:2167.948\n",
      "Ep:58, loss:0.00005, loss_test:0.06363, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:37.387, tt:2205.838\n",
      "Ep:59, loss:0.00005, loss_test:0.06128, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:37.410, tt:2244.607\n",
      "Ep:60, loss:0.00004, loss_test:0.06216, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:37.405, tt:2281.687\n",
      "Ep:61, loss:0.00005, loss_test:0.06027, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:37.389, tt:2318.141\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.06283, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:37.366, tt:2354.035\n",
      "Ep:63, loss:0.00004, loss_test:0.06009, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:37.330, tt:2389.101\n",
      "Ep:64, loss:0.00004, loss_test:0.06094, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:37.303, tt:2424.705\n",
      "Ep:65, loss:0.00004, loss_test:0.06027, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:37.288, tt:2461.033\n",
      "Ep:66, loss:0.00004, loss_test:0.06493, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:37.260, tt:2496.429\n",
      "Ep:67, loss:0.00004, loss_test:0.06111, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:37.267, tt:2534.148\n",
      "Ep:68, loss:0.00005, loss_test:0.06163, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:37.257, tt:2570.747\n",
      "Ep:69, loss:0.00005, loss_test:0.07102, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:37.257, tt:2608.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00006, loss_test:0.07056, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:37.247, tt:2644.522\n",
      "Ep:71, loss:0.00005, loss_test:0.07057, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:37.256, tt:2682.416\n",
      "Ep:72, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:37.260, tt:2719.983\n",
      "Ep:73, loss:0.00005, loss_test:0.06797, lr:9.90e-03, fs:0.89796 (r=0.889,p=0.907),  time:37.243, tt:2755.967\n",
      "Ep:74, loss:0.00004, loss_test:0.06227, lr:9.80e-03, fs:0.88776 (r=0.879,p=0.897),  time:37.242, tt:2793.117\n",
      "Ep:75, loss:0.00004, loss_test:0.06945, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.241, tt:2830.336\n",
      "Ep:76, loss:0.00004, loss_test:0.06131, lr:9.61e-03, fs:0.92386 (r=0.919,p=0.929),  time:37.221, tt:2865.996\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.06148, lr:9.61e-03, fs:0.86339 (r=0.798,p=0.940),  time:37.200, tt:2901.595\n",
      "Ep:78, loss:0.00003, loss_test:0.06576, lr:9.61e-03, fs:0.86188 (r=0.788,p=0.951),  time:37.186, tt:2937.689\n",
      "Ep:79, loss:0.00003, loss_test:0.05862, lr:9.61e-03, fs:0.92228 (r=0.899,p=0.947),  time:37.179, tt:2974.324\n",
      "Ep:80, loss:0.00003, loss_test:0.06035, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:37.168, tt:3010.580\n",
      "Ep:81, loss:0.00003, loss_test:0.06155, lr:9.61e-03, fs:0.86339 (r=0.798,p=0.940),  time:37.177, tt:3048.496\n",
      "Ep:82, loss:0.00003, loss_test:0.05718, lr:9.61e-03, fs:0.91753 (r=0.899,p=0.937),  time:37.185, tt:3086.359\n",
      "Ep:83, loss:0.00003, loss_test:0.05927, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:37.152, tt:3120.795\n",
      "Ep:84, loss:0.00003, loss_test:0.06036, lr:9.61e-03, fs:0.86339 (r=0.798,p=0.940),  time:37.110, tt:3154.353\n",
      "Ep:85, loss:0.00003, loss_test:0.05613, lr:9.61e-03, fs:0.91282 (r=0.899,p=0.927),  time:37.079, tt:3188.814\n",
      "Ep:86, loss:0.00003, loss_test:0.05786, lr:9.61e-03, fs:0.91667 (r=0.889,p=0.946),  time:37.061, tt:3224.272\n",
      "Ep:87, loss:0.00002, loss_test:0.05817, lr:9.61e-03, fs:0.88889 (r=0.848,p=0.933),  time:37.046, tt:3260.018\n",
      "Ep:88, loss:0.00002, loss_test:0.05632, lr:9.51e-03, fs:0.91753 (r=0.899,p=0.937),  time:37.057, tt:3298.043\n",
      "Ep:89, loss:0.00002, loss_test:0.05752, lr:9.41e-03, fs:0.89947 (r=0.859,p=0.944),  time:37.053, tt:3334.803\n",
      "Ep:90, loss:0.00002, loss_test:0.05765, lr:9.32e-03, fs:0.90625 (r=0.879,p=0.935),  time:37.036, tt:3370.278\n",
      "Ep:91, loss:0.00002, loss_test:0.05707, lr:9.23e-03, fs:0.91192 (r=0.889,p=0.936),  time:37.031, tt:3406.845\n",
      "Ep:92, loss:0.00002, loss_test:0.05780, lr:9.14e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.024, tt:3443.246\n",
      "Ep:93, loss:0.00002, loss_test:0.05757, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:37.019, tt:3479.785\n",
      "Ep:94, loss:0.00002, loss_test:0.05802, lr:8.95e-03, fs:0.88889 (r=0.848,p=0.933),  time:37.021, tt:3517.016\n",
      "Ep:95, loss:0.00002, loss_test:0.05734, lr:8.86e-03, fs:0.90052 (r=0.869,p=0.935),  time:36.986, tt:3550.702\n",
      "Ep:96, loss:0.00002, loss_test:0.05648, lr:8.78e-03, fs:0.90625 (r=0.879,p=0.935),  time:37.000, tt:3589.041\n",
      "Ep:97, loss:0.00002, loss_test:0.05884, lr:8.69e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.987, tt:3624.697\n",
      "Ep:98, loss:0.00002, loss_test:0.05642, lr:8.60e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.981, tt:3661.127\n",
      "Ep:99, loss:0.00002, loss_test:0.05856, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.988, tt:3698.755\n",
      "Ep:100, loss:0.00002, loss_test:0.05791, lr:8.43e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.985, tt:3735.470\n",
      "Ep:101, loss:0.00002, loss_test:0.05738, lr:8.35e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.982, tt:3772.204\n",
      "Ep:102, loss:0.00002, loss_test:0.05852, lr:8.26e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.985, tt:3809.418\n",
      "Ep:103, loss:0.00002, loss_test:0.05741, lr:8.18e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.991, tt:3847.089\n",
      "Ep:104, loss:0.00002, loss_test:0.05660, lr:8.10e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.975, tt:3882.328\n",
      "Ep:105, loss:0.00002, loss_test:0.05728, lr:8.02e-03, fs:0.89947 (r=0.859,p=0.944),  time:36.963, tt:3918.128\n",
      "Ep:106, loss:0.00002, loss_test:0.05636, lr:7.94e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.957, tt:3954.443\n",
      "Ep:107, loss:0.00002, loss_test:0.05818, lr:7.86e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.944, tt:3989.897\n",
      "Ep:108, loss:0.00002, loss_test:0.05701, lr:7.78e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.949, tt:4027.400\n",
      "Ep:109, loss:0.00002, loss_test:0.05710, lr:7.70e-03, fs:0.91099 (r=0.879,p=0.946),  time:36.945, tt:4063.913\n",
      "Ep:110, loss:0.00002, loss_test:0.05720, lr:7.62e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.923, tt:4098.503\n",
      "Ep:111, loss:0.00002, loss_test:0.05761, lr:7.55e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.909, tt:4133.769\n",
      "Ep:112, loss:0.00002, loss_test:0.05693, lr:7.47e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.908, tt:4170.562\n",
      "Ep:113, loss:0.00002, loss_test:0.05759, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.895, tt:4205.990\n",
      "Ep:114, loss:0.00002, loss_test:0.05588, lr:7.32e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.877, tt:4240.894\n",
      "Ep:115, loss:0.00001, loss_test:0.05814, lr:7.25e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.873, tt:4277.239\n",
      "Ep:116, loss:0.00001, loss_test:0.05721, lr:7.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.882, tt:4315.137\n",
      "Ep:117, loss:0.00001, loss_test:0.05668, lr:7.11e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.877, tt:4351.532\n",
      "Ep:118, loss:0.00001, loss_test:0.05793, lr:7.03e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.862, tt:4386.575\n",
      "Ep:119, loss:0.00001, loss_test:0.05686, lr:6.96e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.859, tt:4423.067\n",
      "Ep:120, loss:0.00001, loss_test:0.05787, lr:6.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.862, tt:4460.290\n",
      "Ep:121, loss:0.00001, loss_test:0.05737, lr:6.83e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.854, tt:4496.170\n",
      "Ep:122, loss:0.00001, loss_test:0.05756, lr:6.76e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.859, tt:4533.693\n",
      "Ep:123, loss:0.00001, loss_test:0.05765, lr:6.69e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.847, tt:4568.973\n",
      "Ep:124, loss:0.00001, loss_test:0.05773, lr:6.62e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.837, tt:4604.617\n",
      "Ep:125, loss:0.00001, loss_test:0.05733, lr:6.56e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.838, tt:4641.570\n",
      "Ep:126, loss:0.00001, loss_test:0.05856, lr:6.49e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.833, tt:4677.764\n",
      "Ep:127, loss:0.00001, loss_test:0.05715, lr:6.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.826, tt:4713.697\n",
      "Ep:128, loss:0.00001, loss_test:0.05941, lr:6.36e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.836, tt:4751.780\n",
      "Ep:129, loss:0.00001, loss_test:0.05780, lr:6.30e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.822, tt:4786.919\n",
      "Ep:130, loss:0.00001, loss_test:0.05882, lr:6.24e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.818, tt:4823.222\n",
      "Ep:131, loss:0.00001, loss_test:0.05801, lr:6.17e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.816, tt:4859.758\n",
      "Ep:132, loss:0.00001, loss_test:0.05887, lr:6.11e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.813, tt:4896.137\n",
      "Ep:133, loss:0.00001, loss_test:0.05902, lr:6.05e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.813, tt:4932.880\n",
      "Ep:134, loss:0.00001, loss_test:0.05724, lr:5.99e-03, fs:0.90426 (r=0.859,p=0.955),  time:36.806, tt:4968.866\n",
      "Ep:135, loss:0.00001, loss_test:0.06047, lr:5.93e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.811, tt:5006.254\n",
      "Ep:136, loss:0.00001, loss_test:0.05726, lr:5.87e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.807, tt:5042.624\n",
      "Ep:137, loss:0.00001, loss_test:0.05941, lr:5.81e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.803, tt:5078.799\n",
      "Ep:138, loss:0.00001, loss_test:0.05850, lr:5.75e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.806, tt:5116.058\n",
      "Ep:139, loss:0.00001, loss_test:0.05830, lr:5.70e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.798, tt:5151.677\n",
      "Ep:140, loss:0.00001, loss_test:0.05884, lr:5.64e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.791, tt:5187.569\n",
      "Ep:141, loss:0.00001, loss_test:0.05873, lr:5.58e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.793, tt:5224.580\n",
      "Ep:142, loss:0.00001, loss_test:0.05826, lr:5.53e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.796, tt:5261.814\n",
      "Ep:143, loss:0.00001, loss_test:0.05863, lr:5.47e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.796, tt:5298.692\n",
      "Ep:144, loss:0.00001, loss_test:0.05881, lr:5.42e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.790, tt:5334.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.05815, lr:5.36e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.803, tt:5373.256\n",
      "Ep:146, loss:0.00001, loss_test:0.05894, lr:5.31e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.834, tt:5414.531\n",
      "Ep:147, loss:0.00001, loss_test:0.05801, lr:5.26e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.833, tt:5451.246\n",
      "Ep:148, loss:0.00001, loss_test:0.05914, lr:5.20e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.830, tt:5487.701\n",
      "Ep:149, loss:0.00001, loss_test:0.05850, lr:5.15e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.831, tt:5524.648\n",
      "Ep:150, loss:0.00001, loss_test:0.05877, lr:5.10e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.837, tt:5562.327\n",
      "Ep:151, loss:0.00001, loss_test:0.05821, lr:5.05e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.842, tt:5599.961\n",
      "Ep:152, loss:0.00001, loss_test:0.05858, lr:5.00e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.846, tt:5637.376\n",
      "Ep:153, loss:0.00001, loss_test:0.05870, lr:4.95e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.847, tt:5674.487\n",
      "Ep:154, loss:0.00001, loss_test:0.05933, lr:4.90e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.848, tt:5711.378\n",
      "Ep:155, loss:0.00001, loss_test:0.05854, lr:4.85e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.859, tt:5750.077\n",
      "Ep:156, loss:0.00001, loss_test:0.05815, lr:4.80e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.855, tt:5786.257\n",
      "Ep:157, loss:0.00001, loss_test:0.05890, lr:4.75e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.855, tt:5823.022\n",
      "Ep:158, loss:0.00001, loss_test:0.05871, lr:4.71e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.850, tt:5859.185\n",
      "Ep:159, loss:0.00001, loss_test:0.05836, lr:4.66e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.854, tt:5896.564\n",
      "Ep:160, loss:0.00001, loss_test:0.05985, lr:4.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.851, tt:5932.951\n",
      "Ep:161, loss:0.00001, loss_test:0.05789, lr:4.57e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.837, tt:5967.531\n",
      "Ep:162, loss:0.00001, loss_test:0.05969, lr:4.52e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.839, tt:6004.801\n",
      "Ep:163, loss:0.00001, loss_test:0.05854, lr:4.48e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.831, tt:6040.255\n",
      "Ep:164, loss:0.00001, loss_test:0.05891, lr:4.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.833, tt:6077.416\n",
      "Ep:165, loss:0.00001, loss_test:0.05956, lr:4.39e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.821, tt:6112.264\n",
      "Ep:166, loss:0.00001, loss_test:0.05886, lr:4.34e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.812, tt:6147.633\n",
      "Ep:167, loss:0.00001, loss_test:0.05938, lr:4.30e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.804, tt:6182.994\n",
      "Ep:168, loss:0.00001, loss_test:0.05863, lr:4.26e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.803, tt:6219.701\n",
      "Ep:169, loss:0.00001, loss_test:0.05886, lr:4.21e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.795, tt:6255.071\n",
      "Ep:170, loss:0.00001, loss_test:0.05859, lr:4.17e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.793, tt:6291.683\n",
      "Ep:171, loss:0.00001, loss_test:0.05910, lr:4.13e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.796, tt:6328.831\n",
      "Ep:172, loss:0.00001, loss_test:0.05925, lr:4.09e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.791, tt:6364.762\n",
      "Ep:173, loss:0.00001, loss_test:0.05881, lr:4.05e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.781, tt:6399.830\n",
      "Ep:174, loss:0.00001, loss_test:0.05919, lr:4.01e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.776, tt:6435.877\n",
      "Ep:175, loss:0.00001, loss_test:0.05912, lr:3.97e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.766, tt:6470.856\n",
      "Ep:176, loss:0.00001, loss_test:0.05849, lr:3.93e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.759, tt:6506.415\n",
      "Ep:177, loss:0.00001, loss_test:0.05990, lr:3.89e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.754, tt:6542.297\n",
      "Ep:178, loss:0.00001, loss_test:0.05874, lr:3.85e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.760, tt:6580.008\n",
      "Ep:179, loss:0.00001, loss_test:0.05955, lr:3.81e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.761, tt:6616.975\n",
      "Ep:180, loss:0.00001, loss_test:0.05932, lr:3.77e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.765, tt:6654.514\n",
      "Ep:181, loss:0.00001, loss_test:0.05834, lr:3.73e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.761, tt:6690.556\n",
      "Ep:182, loss:0.00001, loss_test:0.05972, lr:3.70e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.758, tt:6726.761\n",
      "Ep:183, loss:0.00001, loss_test:0.05874, lr:3.66e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.770, tt:6765.692\n",
      "Ep:184, loss:0.00001, loss_test:0.05949, lr:3.62e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.762, tt:6800.962\n",
      "Ep:185, loss:0.00001, loss_test:0.05942, lr:3.59e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.755, tt:6836.338\n",
      "Ep:186, loss:0.00001, loss_test:0.05845, lr:3.55e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.748, tt:6871.880\n",
      "Ep:187, loss:0.00001, loss_test:0.05961, lr:3.52e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.739, tt:6906.935\n",
      "Ep:188, loss:0.00001, loss_test:0.05864, lr:3.48e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.740, tt:6943.770\n",
      "Ep:189, loss:0.00001, loss_test:0.05858, lr:3.45e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.743, tt:6981.114\n",
      "Ep:190, loss:0.00001, loss_test:0.05939, lr:3.41e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.740, tt:7017.402\n",
      "Ep:191, loss:0.00001, loss_test:0.05875, lr:3.38e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.742, tt:7054.449\n",
      "Ep:192, loss:0.00001, loss_test:0.05901, lr:3.34e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.749, tt:7092.583\n",
      "Ep:193, loss:0.00001, loss_test:0.05900, lr:3.31e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.738, tt:7127.241\n",
      "Ep:194, loss:0.00001, loss_test:0.05865, lr:3.28e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.738, tt:7163.823\n",
      "Ep:195, loss:0.00001, loss_test:0.05922, lr:3.24e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.742, tt:7201.378\n",
      "Ep:196, loss:0.00001, loss_test:0.05895, lr:3.21e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.736, tt:7236.992\n",
      "Ep:197, loss:0.00001, loss_test:0.05883, lr:3.18e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.729, tt:7272.404\n",
      "Ep:198, loss:0.00001, loss_test:0.05874, lr:3.15e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.729, tt:7309.060\n",
      "Ep:199, loss:0.00001, loss_test:0.05861, lr:3.12e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.724, tt:7344.774\n",
      "Ep:200, loss:0.00001, loss_test:0.05919, lr:3.09e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.705, tt:7377.785\n",
      "Ep:201, loss:0.00001, loss_test:0.05862, lr:3.05e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.695, tt:7412.460\n",
      "Ep:202, loss:0.00001, loss_test:0.05947, lr:3.02e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.684, tt:7446.920\n",
      "Ep:203, loss:0.00001, loss_test:0.05890, lr:2.99e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.656, tt:7477.847\n",
      "Ep:204, loss:0.00001, loss_test:0.05899, lr:2.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.636, tt:7510.473\n",
      "Ep:205, loss:0.00001, loss_test:0.05934, lr:2.93e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.612, tt:7542.096\n",
      "Ep:206, loss:0.00001, loss_test:0.05869, lr:2.90e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.599, tt:7575.903\n",
      "Ep:207, loss:0.00001, loss_test:0.05937, lr:2.88e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.565, tt:7605.602\n",
      "Ep:208, loss:0.00001, loss_test:0.05926, lr:2.85e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.518, tt:7632.349\n",
      "Ep:209, loss:0.00001, loss_test:0.05876, lr:2.82e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.490, tt:7662.968\n",
      "Ep:210, loss:0.00001, loss_test:0.05907, lr:2.79e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.484, tt:7698.211\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.01898, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:32.520, tt:32.520\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00004, loss_test:0.02261, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:33.356, tt:66.713\n",
      "Ep:2, loss:0.00005, loss_test:0.02452, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.803, tt:101.408\n",
      "Ep:3, loss:0.00005, loss_test:0.02426, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.051, tt:136.206\n",
      "Ep:4, loss:0.00005, loss_test:0.02300, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:34.740, tt:173.698\n",
      "Ep:5, loss:0.00005, loss_test:0.02121, lr:6.00e-02, fs:0.67832 (r=0.980,p=0.519),  time:34.727, tt:208.361\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.01961, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:34.805, tt:243.633\n",
      "Ep:7, loss:0.00004, loss_test:0.01843, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:34.841, tt:278.725\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01745, lr:6.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:34.977, tt:314.790\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01696, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:34.951, tt:349.507\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01684, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:35.013, tt:385.143\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01659, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:34.930, tt:419.163\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01624, lr:6.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:34.739, tt:451.612\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01585, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:34.653, tt:485.136\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01552, lr:6.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:34.700, tt:520.493\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01528, lr:6.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:34.541, tt:552.658\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01508, lr:6.00e-02, fs:0.76078 (r=0.980,p=0.622),  time:34.583, tt:587.918\n",
      "Ep:17, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.75889 (r=0.970,p=0.623),  time:34.450, tt:620.092\n",
      "Ep:18, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:34.504, tt:655.579\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01465, lr:6.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:34.522, tt:690.448\n",
      "Ep:20, loss:0.00003, loss_test:0.01449, lr:6.00e-02, fs:0.77419 (r=0.970,p=0.644),  time:34.539, tt:725.311\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01441, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:34.574, tt:760.631\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01437, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:34.569, tt:795.098\n",
      "Ep:23, loss:0.00003, loss_test:0.01434, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:34.587, tt:830.085\n",
      "Ep:24, loss:0.00003, loss_test:0.01430, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:34.639, tt:865.973\n",
      "Ep:25, loss:0.00003, loss_test:0.01429, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.687, tt:901.864\n",
      "Ep:26, loss:0.00003, loss_test:0.01432, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:34.698, tt:936.859\n",
      "Ep:27, loss:0.00003, loss_test:0.01438, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:34.727, tt:972.359\n",
      "Ep:28, loss:0.00003, loss_test:0.01444, lr:6.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.710, tt:1006.592\n",
      "Ep:29, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:34.683, tt:1040.483\n",
      "Ep:30, loss:0.00002, loss_test:0.01439, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:34.664, tt:1074.587\n",
      "Ep:31, loss:0.00002, loss_test:0.01439, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:34.648, tt:1108.724\n",
      "Ep:32, loss:0.00002, loss_test:0.01447, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:34.626, tt:1142.644\n",
      "Ep:33, loss:0.00002, loss_test:0.01452, lr:5.94e-02, fs:0.74312 (r=0.818,p=0.681),  time:34.612, tt:1176.810\n",
      "Ep:34, loss:0.00002, loss_test:0.01453, lr:5.88e-02, fs:0.75000 (r=0.818,p=0.692),  time:34.637, tt:1212.298\n",
      "Ep:35, loss:0.00002, loss_test:0.01456, lr:5.82e-02, fs:0.75117 (r=0.808,p=0.702),  time:34.614, tt:1246.101\n",
      "Ep:36, loss:0.00002, loss_test:0.01457, lr:5.76e-02, fs:0.75117 (r=0.808,p=0.702),  time:34.621, tt:1280.983\n",
      "Ep:37, loss:0.00002, loss_test:0.01450, lr:5.71e-02, fs:0.76056 (r=0.818,p=0.711),  time:34.605, tt:1314.999\n",
      "Ep:38, loss:0.00002, loss_test:0.01442, lr:5.65e-02, fs:0.76056 (r=0.818,p=0.711),  time:34.621, tt:1350.238\n",
      "Ep:39, loss:0.00002, loss_test:0.01435, lr:5.59e-02, fs:0.78302 (r=0.838,p=0.735),  time:34.620, tt:1384.805\n",
      "Ep:40, loss:0.00002, loss_test:0.01432, lr:5.54e-02, fs:0.78873 (r=0.848,p=0.737),  time:34.612, tt:1419.076\n",
      "Ep:41, loss:0.00002, loss_test:0.01429, lr:5.48e-02, fs:0.79439 (r=0.859,p=0.739),  time:34.605, tt:1453.430\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01432, lr:5.48e-02, fs:0.80189 (r=0.859,p=0.752),  time:34.633, tt:1489.220\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01434, lr:5.48e-02, fs:0.80569 (r=0.859,p=0.759),  time:34.645, tt:1524.390\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01440, lr:5.48e-02, fs:0.80569 (r=0.859,p=0.759),  time:34.615, tt:1557.667\n",
      "Ep:45, loss:0.00002, loss_test:0.01438, lr:5.48e-02, fs:0.80952 (r=0.859,p=0.766),  time:34.598, tt:1591.503\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01442, lr:5.48e-02, fs:0.80952 (r=0.859,p=0.766),  time:34.568, tt:1624.709\n",
      "Ep:47, loss:0.00002, loss_test:0.01439, lr:5.48e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.537, tt:1657.792\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01439, lr:5.48e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.530, tt:1691.949\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01442, lr:5.48e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.557, tt:1727.862\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01437, lr:5.48e-02, fs:0.82524 (r=0.859,p=0.794),  time:34.544, tt:1761.724\n",
      "Ep:51, loss:0.00001, loss_test:0.01434, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.540, tt:1796.062\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01434, lr:5.48e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.519, tt:1829.505\n",
      "Ep:53, loss:0.00001, loss_test:0.01433, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.499, tt:1862.931\n",
      "Ep:54, loss:0.00001, loss_test:0.01445, lr:5.48e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.465, tt:1895.578\n",
      "Ep:55, loss:0.00001, loss_test:0.01436, lr:5.48e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.457, tt:1929.565\n",
      "Ep:56, loss:0.00001, loss_test:0.01444, lr:5.48e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.445, tt:1963.376\n",
      "Ep:57, loss:0.00001, loss_test:0.01449, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:34.449, tt:1998.059\n",
      "Ep:58, loss:0.00001, loss_test:0.01448, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.459, tt:2033.075\n",
      "Ep:59, loss:0.00001, loss_test:0.01460, lr:5.48e-02, fs:0.83000 (r=0.838,p=0.822),  time:34.464, tt:2067.814\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01447, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.453, tt:2101.611\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01451, lr:5.48e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.428, tt:2134.511\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01446, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.427, tt:2168.895\n",
      "Ep:63, loss:0.00001, loss_test:0.01446, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.417, tt:2202.661\n",
      "Ep:64, loss:0.00001, loss_test:0.01462, lr:5.48e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.452, tt:2239.392\n",
      "Ep:65, loss:0.00001, loss_test:0.01461, lr:5.48e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.467, tt:2274.844\n",
      "Ep:66, loss:0.00001, loss_test:0.01456, lr:5.48e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.472, tt:2309.627\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.01463, lr:5.48e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.478, tt:2344.475\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01446, lr:5.48e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.475, tt:2378.804\n",
      "Ep:69, loss:0.00001, loss_test:0.01469, lr:5.48e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.504, tt:2415.309\n",
      "Ep:70, loss:0.00001, loss_test:0.01466, lr:5.48e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.516, tt:2450.645\n",
      "Ep:71, loss:0.00001, loss_test:0.01453, lr:5.48e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.508, tt:2484.603\n",
      "Ep:72, loss:0.00001, loss_test:0.01477, lr:5.48e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.518, tt:2519.846\n",
      "Ep:73, loss:0.00001, loss_test:0.01463, lr:5.48e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.533, tt:2555.477\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01487, lr:5.48e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.551, tt:2591.335\n",
      "Ep:75, loss:0.00001, loss_test:0.01472, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.541, tt:2625.088\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01481, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.537, tt:2659.386\n",
      "Ep:77, loss:0.00001, loss_test:0.01494, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.545, tt:2694.543\n",
      "Ep:78, loss:0.00001, loss_test:0.01488, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.536, tt:2728.314\n",
      "Ep:79, loss:0.00001, loss_test:0.01491, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.506, tt:2760.512\n",
      "Ep:80, loss:0.00001, loss_test:0.01499, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.515, tt:2795.704\n",
      "Ep:81, loss:0.00001, loss_test:0.01507, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.514, tt:2830.167\n",
      "Ep:82, loss:0.00001, loss_test:0.01487, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.525, tt:2865.585\n",
      "Ep:83, loss:0.00001, loss_test:0.01502, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.515, tt:2899.279\n",
      "Ep:84, loss:0.00001, loss_test:0.01512, lr:5.48e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.498, tt:2932.298\n",
      "Ep:85, loss:0.00001, loss_test:0.01509, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.518, tt:2968.525\n",
      "Ep:86, loss:0.00001, loss_test:0.01512, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.514, tt:3002.677\n",
      "Ep:87, loss:0.00001, loss_test:0.01508, lr:5.43e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.508, tt:3036.697\n",
      "Ep:88, loss:0.00001, loss_test:0.01526, lr:5.37e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.510, tt:3071.389\n",
      "Ep:89, loss:0.00001, loss_test:0.01524, lr:5.32e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.505, tt:3105.414\n",
      "Ep:90, loss:0.00001, loss_test:0.01523, lr:5.27e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.490, tt:3138.633\n",
      "Ep:91, loss:0.00001, loss_test:0.01533, lr:5.21e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.491, tt:3173.145\n",
      "Ep:92, loss:0.00001, loss_test:0.01532, lr:5.16e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.491, tt:3207.672\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01529, lr:5.16e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.490, tt:3242.045\n",
      "Ep:94, loss:0.00001, loss_test:0.01559, lr:5.16e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.496, tt:3277.104\n",
      "Ep:95, loss:0.00001, loss_test:0.01537, lr:5.16e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.510, tt:3312.932\n",
      "Ep:96, loss:0.00001, loss_test:0.01575, lr:5.16e-02, fs:0.85279 (r=0.848,p=0.857),  time:34.508, tt:3347.302\n",
      "Ep:97, loss:0.00001, loss_test:0.01545, lr:5.16e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.495, tt:3380.537\n",
      "Ep:98, loss:0.00001, loss_test:0.01571, lr:5.16e-02, fs:0.85279 (r=0.848,p=0.857),  time:34.500, tt:3415.468\n",
      "Ep:99, loss:0.00001, loss_test:0.01576, lr:5.16e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.508, tt:3450.832\n",
      "Ep:100, loss:0.00001, loss_test:0.01568, lr:5.16e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.483, tt:3482.794\n",
      "Ep:101, loss:0.00000, loss_test:0.01597, lr:5.16e-02, fs:0.85279 (r=0.848,p=0.857),  time:34.478, tt:3516.781\n",
      "Ep:102, loss:0.00001, loss_test:0.01596, lr:5.16e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.467, tt:3550.055\n",
      "Ep:103, loss:0.00000, loss_test:0.01595, lr:5.16e-02, fs:0.85279 (r=0.848,p=0.857),  time:34.481, tt:3586.070\n",
      "Ep:104, loss:0.00000, loss_test:0.01608, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.475, tt:3619.865\n",
      "Ep:105, loss:0.00000, loss_test:0.01597, lr:5.06e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.454, tt:3652.157\n",
      "Ep:106, loss:0.00000, loss_test:0.01607, lr:5.01e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.451, tt:3686.248\n",
      "Ep:107, loss:0.00000, loss_test:0.01626, lr:4.96e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.458, tt:3721.515\n",
      "Ep:108, loss:0.00000, loss_test:0.01608, lr:4.91e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.470, tt:3757.246\n",
      "Ep:109, loss:0.00000, loss_test:0.01639, lr:4.86e-02, fs:0.84694 (r=0.838,p=0.856),  time:34.470, tt:3791.746\n",
      "Ep:110, loss:0.00000, loss_test:0.01629, lr:4.81e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.481, tt:3827.430\n",
      "Ep:111, loss:0.00000, loss_test:0.01632, lr:4.76e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.467, tt:3860.313\n",
      "Ep:112, loss:0.00000, loss_test:0.01649, lr:4.71e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.481, tt:3896.352\n",
      "Ep:113, loss:0.00000, loss_test:0.01642, lr:4.67e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.482, tt:3930.898\n",
      "Ep:114, loss:0.00000, loss_test:0.01654, lr:4.62e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.490, tt:3966.313\n",
      "Ep:115, loss:0.00000, loss_test:0.01665, lr:4.57e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.506, tt:4002.653\n",
      "Ep:116, loss:0.00000, loss_test:0.01662, lr:4.53e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.509, tt:4037.532\n",
      "Ep:117, loss:0.00000, loss_test:0.01669, lr:4.48e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.509, tt:4072.055\n",
      "Ep:118, loss:0.00000, loss_test:0.01672, lr:4.44e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.527, tt:4108.717\n",
      "Ep:119, loss:0.00000, loss_test:0.01682, lr:4.39e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.551, tt:4146.121\n",
      "Ep:120, loss:0.00000, loss_test:0.01699, lr:4.35e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.548, tt:4180.275\n",
      "Ep:121, loss:0.00000, loss_test:0.01689, lr:4.31e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.548, tt:4214.807\n",
      "Ep:122, loss:0.00000, loss_test:0.01692, lr:4.26e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.543, tt:4248.778\n",
      "Ep:123, loss:0.00000, loss_test:0.01705, lr:4.22e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.544, tt:4283.469\n",
      "Ep:124, loss:0.00000, loss_test:0.01699, lr:4.18e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.548, tt:4318.552\n",
      "Ep:125, loss:0.00000, loss_test:0.01697, lr:4.14e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.563, tt:4354.876\n",
      "Ep:126, loss:0.00000, loss_test:0.01715, lr:4.10e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.557, tt:4388.711\n",
      "Ep:127, loss:0.00000, loss_test:0.01717, lr:4.05e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.554, tt:4422.942\n",
      "Ep:128, loss:0.00000, loss_test:0.01722, lr:4.01e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.557, tt:4457.861\n",
      "Ep:129, loss:0.00000, loss_test:0.01733, lr:3.97e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.547, tt:4491.076\n",
      "Ep:130, loss:0.00000, loss_test:0.01728, lr:3.93e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.539, tt:4524.663\n",
      "Ep:131, loss:0.00000, loss_test:0.01745, lr:3.89e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.538, tt:4559.014\n",
      "Ep:132, loss:0.00000, loss_test:0.01747, lr:3.86e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.530, tt:4592.470\n",
      "Ep:133, loss:0.00000, loss_test:0.01736, lr:3.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.527, tt:4626.555\n",
      "Ep:134, loss:0.00000, loss_test:0.01761, lr:3.78e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.520, tt:4660.141\n",
      "Ep:135, loss:0.00000, loss_test:0.01745, lr:3.74e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.512, tt:4693.635\n",
      "Ep:136, loss:0.00000, loss_test:0.01768, lr:3.70e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.506, tt:4727.374\n",
      "Ep:137, loss:0.00000, loss_test:0.01764, lr:3.67e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.493, tt:4760.054\n",
      "Ep:138, loss:0.00000, loss_test:0.01764, lr:3.63e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.500, tt:4795.493\n",
      "Ep:139, loss:0.00000, loss_test:0.01785, lr:3.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.505, tt:4830.748\n",
      "Ep:140, loss:0.00000, loss_test:0.01766, lr:3.56e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.505, tt:4865.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.01794, lr:3.52e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.498, tt:4898.769\n",
      "Ep:142, loss:0.00000, loss_test:0.01773, lr:3.49e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.498, tt:4933.152\n",
      "Ep:143, loss:0.00000, loss_test:0.01794, lr:3.45e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.487, tt:4966.075\n",
      "Ep:144, loss:0.00000, loss_test:0.01787, lr:3.42e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.485, tt:5000.366\n",
      "Ep:145, loss:0.00000, loss_test:0.01797, lr:3.38e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.482, tt:5034.318\n",
      "Ep:146, loss:0.00000, loss_test:0.01807, lr:3.35e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.472, tt:5067.377\n",
      "Ep:147, loss:0.00000, loss_test:0.01805, lr:3.32e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.479, tt:5102.833\n",
      "Ep:148, loss:0.00000, loss_test:0.01811, lr:3.28e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.478, tt:5137.292\n",
      "Ep:149, loss:0.00000, loss_test:0.01805, lr:3.25e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.481, tt:5172.136\n",
      "Ep:150, loss:0.00000, loss_test:0.01822, lr:3.22e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.477, tt:5206.037\n",
      "Ep:151, loss:0.00000, loss_test:0.01823, lr:3.19e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.480, tt:5240.896\n",
      "Ep:152, loss:0.00000, loss_test:0.01821, lr:3.15e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.476, tt:5274.863\n",
      "Ep:153, loss:0.00000, loss_test:0.01836, lr:3.12e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.474, tt:5308.983\n",
      "Ep:154, loss:0.00000, loss_test:0.01833, lr:3.09e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.479, tt:5344.207\n",
      "Ep:155, loss:0.00000, loss_test:0.01845, lr:3.06e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.490, tt:5380.470\n",
      "Ep:156, loss:0.00000, loss_test:0.01839, lr:3.03e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.486, tt:5414.267\n",
      "Ep:157, loss:0.00000, loss_test:0.01864, lr:3.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.489, tt:5449.298\n",
      "Ep:158, loss:0.00000, loss_test:0.01839, lr:2.97e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.495, tt:5484.635\n",
      "Ep:159, loss:0.00000, loss_test:0.01873, lr:2.94e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.500, tt:5519.946\n",
      "Ep:160, loss:0.00000, loss_test:0.01846, lr:2.91e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.504, tt:5555.132\n",
      "Ep:161, loss:0.00000, loss_test:0.01878, lr:2.88e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.507, tt:5590.166\n",
      "Ep:162, loss:0.00000, loss_test:0.01852, lr:2.85e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.508, tt:5624.814\n",
      "Ep:163, loss:0.00000, loss_test:0.01876, lr:2.82e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.509, tt:5659.481\n",
      "Ep:164, loss:0.00000, loss_test:0.01866, lr:2.80e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.511, tt:5694.372\n",
      "Ep:165, loss:0.00000, loss_test:0.01872, lr:2.77e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.511, tt:5728.874\n",
      "Ep:166, loss:0.00000, loss_test:0.01878, lr:2.74e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.508, tt:5762.829\n",
      "Ep:167, loss:0.00000, loss_test:0.01882, lr:2.71e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.506, tt:5797.087\n",
      "Ep:168, loss:0.00000, loss_test:0.01883, lr:2.69e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.508, tt:5831.779\n",
      "Ep:169, loss:0.00000, loss_test:0.01900, lr:2.66e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.506, tt:5866.038\n",
      "Ep:170, loss:0.00000, loss_test:0.01886, lr:2.63e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.512, tt:5901.580\n",
      "Ep:171, loss:0.00000, loss_test:0.01893, lr:2.61e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.519, tt:5937.251\n",
      "Ep:172, loss:0.00000, loss_test:0.01903, lr:2.58e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.526, tt:5973.055\n",
      "Ep:173, loss:0.00000, loss_test:0.01903, lr:2.55e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.534, tt:6008.994\n",
      "Ep:174, loss:0.00000, loss_test:0.01905, lr:2.53e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.553, tt:6046.782\n",
      "Ep:175, loss:0.00000, loss_test:0.01912, lr:2.50e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.564, tt:6083.197\n",
      "Ep:176, loss:0.00000, loss_test:0.01916, lr:2.48e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.563, tt:6117.721\n",
      "Ep:177, loss:0.00000, loss_test:0.01914, lr:2.45e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.572, tt:6153.787\n",
      "Ep:178, loss:0.00000, loss_test:0.01923, lr:2.43e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.574, tt:6188.816\n",
      "Ep:179, loss:0.00000, loss_test:0.01925, lr:2.40e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.578, tt:6223.979\n",
      "Ep:180, loss:0.00000, loss_test:0.01926, lr:2.38e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.585, tt:6259.897\n",
      "Ep:181, loss:0.00000, loss_test:0.01932, lr:2.36e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.604, tt:6297.840\n",
      "Ep:182, loss:0.00000, loss_test:0.01928, lr:2.33e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.598, tt:6331.489\n",
      "Ep:183, loss:0.00000, loss_test:0.01935, lr:2.31e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.600, tt:6366.404\n",
      "Ep:184, loss:0.00000, loss_test:0.01943, lr:2.29e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.601, tt:6401.109\n",
      "Ep:185, loss:0.00000, loss_test:0.01931, lr:2.26e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.595, tt:6434.637\n",
      "Ep:186, loss:0.00000, loss_test:0.01948, lr:2.24e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.593, tt:6468.799\n",
      "Ep:187, loss:0.00000, loss_test:0.01955, lr:2.22e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.603, tt:6505.455\n",
      "Ep:188, loss:0.00000, loss_test:0.01944, lr:2.20e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.609, tt:6541.117\n",
      "Ep:189, loss:0.00000, loss_test:0.01949, lr:2.17e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.623, tt:6578.448\n",
      "Ep:190, loss:0.00000, loss_test:0.01961, lr:2.15e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.631, tt:6614.459\n",
      "Ep:191, loss:0.00000, loss_test:0.01954, lr:2.13e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.636, tt:6650.150\n",
      "Ep:192, loss:0.00000, loss_test:0.01961, lr:2.11e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.634, tt:6684.283\n",
      "Ep:193, loss:0.00000, loss_test:0.01969, lr:2.09e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.636, tt:6719.358\n",
      "Ep:194, loss:0.00000, loss_test:0.01960, lr:2.07e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.638, tt:6754.338\n",
      "Ep:195, loss:0.00000, loss_test:0.01973, lr:2.05e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.647, tt:6790.764\n",
      "Ep:196, loss:0.00000, loss_test:0.01964, lr:2.03e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.654, tt:6826.759\n",
      "Ep:197, loss:0.00000, loss_test:0.01974, lr:2.01e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.654, tt:6861.583\n",
      "Ep:198, loss:0.00000, loss_test:0.01974, lr:1.99e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.653, tt:6895.983\n",
      "Ep:199, loss:0.00000, loss_test:0.01979, lr:1.97e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.660, tt:6932.005\n",
      "Ep:200, loss:0.00000, loss_test:0.01979, lr:1.95e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.655, tt:6965.749\n",
      "Ep:201, loss:0.00000, loss_test:0.01981, lr:1.93e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.650, tt:6999.361\n",
      "Ep:202, loss:0.00000, loss_test:0.01991, lr:1.91e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.647, tt:7033.275\n",
      "Ep:203, loss:0.00000, loss_test:0.01983, lr:1.89e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.635, tt:7065.553\n",
      "Ep:204, loss:0.00000, loss_test:0.02000, lr:1.87e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.623, tt:7097.740\n",
      "Ep:205, loss:0.00000, loss_test:0.01995, lr:1.85e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.606, tt:7128.863\n",
      "Ep:206, loss:0.00000, loss_test:0.01995, lr:1.83e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.592, tt:7160.544\n",
      "Ep:207, loss:0.00000, loss_test:0.01996, lr:1.81e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.571, tt:7190.862\n",
      "Ep:208, loss:0.00000, loss_test:0.01999, lr:1.80e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.550, tt:7221.037\n",
      "Ep:209, loss:0.00000, loss_test:0.02004, lr:1.78e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.559, tt:7257.375\n",
      "Ep:210, loss:0.00000, loss_test:0.02003, lr:1.76e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.567, tt:7293.619\n",
      "Ep:211, loss:0.00000, loss_test:0.02014, lr:1.74e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.572, tt:7329.250\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13308, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:32.310, tt:32.310\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12930, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:35.140, tt:70.279\n",
      "Ep:2, loss:0.00027, loss_test:0.12321, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:35.014, tt:105.043\n",
      "Ep:3, loss:0.00026, loss_test:0.11650, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:35.258, tt:141.034\n",
      "Ep:4, loss:0.00026, loss_test:0.11135, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:35.644, tt:178.220\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.10856, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:35.727, tt:214.364\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.10838, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:35.720, tt:250.038\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10837, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:36.020, tt:288.158\n",
      "Ep:8, loss:0.00024, loss_test:0.10584, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:36.206, tt:325.853\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10196, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:36.146, tt:361.464\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.09981, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:36.176, tt:397.937\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.09861, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:36.129, tt:433.547\n",
      "Ep:12, loss:0.00022, loss_test:0.09790, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:36.045, tt:468.589\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.09688, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:36.173, tt:506.417\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09564, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:36.323, tt:544.845\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09447, lr:1.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:36.413, tt:582.615\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09272, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:36.392, tt:618.664\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09197, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:36.413, tt:655.425\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09149, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:36.423, tt:692.038\n",
      "Ep:19, loss:0.00018, loss_test:0.09129, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:36.417, tt:728.336\n",
      "Ep:20, loss:0.00017, loss_test:0.08869, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:36.491, tt:766.311\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.08864, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:36.535, tt:803.763\n",
      "Ep:22, loss:0.00016, loss_test:0.08823, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:36.587, tt:841.498\n",
      "Ep:23, loss:0.00016, loss_test:0.08676, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:36.567, tt:877.616\n",
      "Ep:24, loss:0.00015, loss_test:0.08777, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:36.588, tt:914.699\n",
      "Ep:25, loss:0.00015, loss_test:0.08583, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:36.658, tt:953.114\n",
      "Ep:26, loss:0.00014, loss_test:0.08526, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:36.691, tt:990.666\n",
      "Ep:27, loss:0.00014, loss_test:0.08571, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:36.725, tt:1028.314\n",
      "Ep:28, loss:0.00014, loss_test:0.08424, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:36.728, tt:1065.122\n",
      "Ep:29, loss:0.00013, loss_test:0.08525, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:36.758, tt:1102.725\n",
      "Ep:30, loss:0.00013, loss_test:0.08392, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:36.800, tt:1140.788\n",
      "Ep:31, loss:0.00012, loss_test:0.08368, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.838, tt:1178.828\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.08405, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:36.833, tt:1215.500\n",
      "Ep:33, loss:0.00011, loss_test:0.08306, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:36.860, tt:1253.253\n",
      "Ep:34, loss:0.00011, loss_test:0.08531, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:36.848, tt:1289.680\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.08350, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:36.823, tt:1325.630\n",
      "Ep:36, loss:0.00011, loss_test:0.08391, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:36.827, tt:1362.606\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08309, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:36.817, tt:1399.063\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.08289, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.812, tt:1435.679\n",
      "Ep:39, loss:0.00010, loss_test:0.08357, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.769, tt:1470.763\n",
      "Ep:40, loss:0.00010, loss_test:0.08174, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:36.793, tt:1508.522\n",
      "Ep:41, loss:0.00009, loss_test:0.08276, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:36.779, tt:1544.717\n",
      "Ep:42, loss:0.00009, loss_test:0.08225, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:36.774, tt:1581.293\n",
      "Ep:43, loss:0.00009, loss_test:0.08450, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.754, tt:1617.185\n",
      "Ep:44, loss:0.00008, loss_test:0.08141, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.757, tt:1654.072\n",
      "Ep:45, loss:0.00008, loss_test:0.08401, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:36.770, tt:1691.405\n",
      "Ep:46, loss:0.00008, loss_test:0.07671, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:36.746, tt:1727.079\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.08248, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:36.736, tt:1763.330\n",
      "Ep:48, loss:0.00007, loss_test:0.07948, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:36.714, tt:1799.007\n",
      "Ep:49, loss:0.00007, loss_test:0.08537, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:36.712, tt:1835.599\n",
      "Ep:50, loss:0.00007, loss_test:0.08089, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:36.713, tt:1872.370\n",
      "Ep:51, loss:0.00007, loss_test:0.08153, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:36.714, tt:1909.145\n",
      "Ep:52, loss:0.00006, loss_test:0.07717, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:36.717, tt:1945.997\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.08383, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:36.689, tt:1981.220\n",
      "Ep:54, loss:0.00006, loss_test:0.07928, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:36.687, tt:2017.779\n",
      "Ep:55, loss:0.00006, loss_test:0.08158, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:36.688, tt:2054.554\n",
      "Ep:56, loss:0.00006, loss_test:0.08096, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.706, tt:2092.225\n",
      "Ep:57, loss:0.00005, loss_test:0.08069, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.686, tt:2127.769\n",
      "Ep:58, loss:0.00006, loss_test:0.08306, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:36.681, tt:2164.155\n",
      "Ep:59, loss:0.00005, loss_test:0.08125, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:36.669, tt:2200.161\n",
      "Ep:60, loss:0.00005, loss_test:0.08463, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:36.663, tt:2236.416\n",
      "Ep:61, loss:0.00005, loss_test:0.08133, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:36.656, tt:2272.673\n",
      "Ep:62, loss:0.00005, loss_test:0.08018, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.678, tt:2310.715\n",
      "Ep:63, loss:0.00006, loss_test:0.08165, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.654, tt:2345.854\n",
      "Ep:64, loss:0.00005, loss_test:0.08070, lr:9.90e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.642, tt:2381.761\n",
      "Ep:65, loss:0.00005, loss_test:0.07947, lr:9.80e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.642, tt:2418.344\n",
      "Ep:66, loss:0.00005, loss_test:0.08264, lr:9.70e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.630, tt:2454.207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00005, loss_test:0.08033, lr:9.61e-03, fs:0.81319 (r=0.747,p=0.892),  time:36.634, tt:2491.139\n",
      "Ep:68, loss:0.00005, loss_test:0.08409, lr:9.51e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.633, tt:2527.696\n",
      "Ep:69, loss:0.00004, loss_test:0.08044, lr:9.41e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.623, tt:2563.594\n",
      "Ep:70, loss:0.00004, loss_test:0.08484, lr:9.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.639, tt:2601.405\n",
      "Ep:71, loss:0.00004, loss_test:0.08204, lr:9.23e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.650, tt:2638.805\n",
      "Ep:72, loss:0.00004, loss_test:0.08051, lr:9.14e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.646, tt:2675.174\n",
      "Ep:73, loss:0.00004, loss_test:0.08797, lr:9.04e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.642, tt:2711.509\n",
      "Ep:74, loss:0.00004, loss_test:0.08181, lr:8.95e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.642, tt:2748.140\n",
      "Ep:75, loss:0.00003, loss_test:0.08505, lr:8.86e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.644, tt:2784.916\n",
      "Ep:76, loss:0.00003, loss_test:0.08290, lr:8.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.629, tt:2820.411\n",
      "Ep:77, loss:0.00003, loss_test:0.08191, lr:8.69e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.613, tt:2855.803\n",
      "Ep:78, loss:0.00003, loss_test:0.08468, lr:8.60e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.610, tt:2892.211\n",
      "Ep:79, loss:0.00003, loss_test:0.08257, lr:8.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.603, tt:2928.278\n",
      "Ep:80, loss:0.00003, loss_test:0.08415, lr:8.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.599, tt:2964.545\n",
      "Ep:81, loss:0.00003, loss_test:0.08337, lr:8.35e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.555, tt:2997.550\n",
      "Ep:82, loss:0.00003, loss_test:0.08289, lr:8.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.518, tt:3030.954\n",
      "Ep:83, loss:0.00003, loss_test:0.08242, lr:8.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.513, tt:3067.060\n",
      "Ep:84, loss:0.00003, loss_test:0.08355, lr:8.10e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.499, tt:3102.416\n",
      "Ep:85, loss:0.00003, loss_test:0.08337, lr:8.02e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.491, tt:3138.251\n",
      "Ep:86, loss:0.00003, loss_test:0.08252, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.473, tt:3173.111\n",
      "Ep:87, loss:0.00003, loss_test:0.08433, lr:7.86e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.473, tt:3209.646\n",
      "Ep:88, loss:0.00003, loss_test:0.08380, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.473, tt:3246.061\n",
      "Ep:89, loss:0.00003, loss_test:0.08245, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.459, tt:3281.312\n",
      "Ep:90, loss:0.00003, loss_test:0.08393, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.449, tt:3316.859\n",
      "Ep:91, loss:0.00002, loss_test:0.08373, lr:7.55e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.439, tt:3352.390\n",
      "Ep:92, loss:0.00003, loss_test:0.08411, lr:7.47e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.446, tt:3389.461\n",
      "Ep:93, loss:0.00002, loss_test:0.08500, lr:7.40e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.437, tt:3425.116\n",
      "Ep:94, loss:0.00002, loss_test:0.08329, lr:7.32e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.423, tt:3460.172\n",
      "Ep:95, loss:0.00002, loss_test:0.08387, lr:7.25e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.412, tt:3495.579\n",
      "Ep:96, loss:0.00002, loss_test:0.08372, lr:7.18e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.399, tt:3530.670\n",
      "Ep:97, loss:0.00002, loss_test:0.08605, lr:7.11e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.383, tt:3565.541\n",
      "Ep:98, loss:0.00002, loss_test:0.08244, lr:7.03e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.392, tt:3602.762\n",
      "Ep:99, loss:0.00003, loss_test:0.08686, lr:6.96e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.363, tt:3636.258\n",
      "Ep:100, loss:0.00002, loss_test:0.08436, lr:6.89e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.349, tt:3671.213\n",
      "Ep:101, loss:0.00002, loss_test:0.08316, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.350, tt:3707.736\n",
      "Ep:102, loss:0.00002, loss_test:0.08598, lr:6.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.337, tt:3742.690\n",
      "Ep:103, loss:0.00002, loss_test:0.08605, lr:6.69e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.333, tt:3778.647\n",
      "Ep:104, loss:0.00002, loss_test:0.08461, lr:6.62e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.309, tt:3812.393\n",
      "Ep:105, loss:0.00002, loss_test:0.08720, lr:6.56e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.312, tt:3849.080\n",
      "Ep:106, loss:0.00002, loss_test:0.08543, lr:6.49e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.302, tt:3884.358\n",
      "Ep:107, loss:0.00002, loss_test:0.08497, lr:6.43e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.302, tt:3920.606\n",
      "Ep:108, loss:0.00002, loss_test:0.08501, lr:6.36e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.301, tt:3956.821\n",
      "Ep:109, loss:0.00002, loss_test:0.08543, lr:6.30e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.304, tt:3993.445\n",
      "Ep:110, loss:0.00002, loss_test:0.08488, lr:6.24e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.319, tt:4031.424\n",
      "Ep:111, loss:0.00002, loss_test:0.08629, lr:6.17e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.341, tt:4070.219\n",
      "Ep:112, loss:0.00002, loss_test:0.08590, lr:6.11e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.362, tt:4108.923\n",
      "Ep:113, loss:0.00002, loss_test:0.08490, lr:6.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.374, tt:4146.666\n",
      "Ep:114, loss:0.00002, loss_test:0.08652, lr:5.99e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.371, tt:4182.633\n",
      "Ep:115, loss:0.00002, loss_test:0.08571, lr:5.93e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.386, tt:4220.760\n",
      "Ep:116, loss:0.00002, loss_test:0.08555, lr:5.87e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.397, tt:4258.461\n",
      "Ep:117, loss:0.00002, loss_test:0.08495, lr:5.81e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.401, tt:4295.292\n",
      "Ep:118, loss:0.00002, loss_test:0.08623, lr:5.75e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.398, tt:4331.408\n",
      "Ep:119, loss:0.00002, loss_test:0.08531, lr:5.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.391, tt:4366.935\n",
      "Ep:120, loss:0.00002, loss_test:0.08612, lr:5.64e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.399, tt:4404.238\n",
      "Ep:121, loss:0.00002, loss_test:0.08632, lr:5.58e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.410, tt:4441.965\n",
      "Ep:122, loss:0.00002, loss_test:0.08460, lr:5.53e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.414, tt:4478.978\n",
      "Ep:123, loss:0.00002, loss_test:0.08711, lr:5.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.420, tt:4516.031\n",
      "Ep:124, loss:0.00002, loss_test:0.08563, lr:5.42e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.419, tt:4552.344\n",
      "Ep:125, loss:0.00002, loss_test:0.08529, lr:5.36e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.425, tt:4589.498\n",
      "Ep:126, loss:0.00002, loss_test:0.08599, lr:5.31e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.432, tt:4626.872\n",
      "Ep:127, loss:0.00002, loss_test:0.08657, lr:5.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.433, tt:4663.472\n",
      "Ep:128, loss:0.00002, loss_test:0.08509, lr:5.20e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.439, tt:4700.614\n",
      "Ep:129, loss:0.00002, loss_test:0.08621, lr:5.15e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.458, tt:4739.476\n",
      "Ep:130, loss:0.00002, loss_test:0.08677, lr:5.10e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.469, tt:4777.447\n",
      "Ep:131, loss:0.00002, loss_test:0.08478, lr:5.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.465, tt:4813.340\n",
      "Ep:132, loss:0.00002, loss_test:0.08702, lr:5.00e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.460, tt:4849.215\n",
      "Ep:133, loss:0.00002, loss_test:0.08677, lr:4.95e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.466, tt:4886.438\n",
      "Ep:134, loss:0.00002, loss_test:0.08570, lr:4.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.471, tt:4923.561\n",
      "Ep:135, loss:0.00002, loss_test:0.08538, lr:4.85e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.469, tt:4959.768\n",
      "Ep:136, loss:0.00002, loss_test:0.08745, lr:4.80e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.470, tt:4996.428\n",
      "Ep:137, loss:0.00002, loss_test:0.08681, lr:4.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.479, tt:5034.162\n",
      "Ep:138, loss:0.00002, loss_test:0.08722, lr:4.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.472, tt:5069.589\n",
      "Ep:139, loss:0.00002, loss_test:0.08643, lr:4.66e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.476, tt:5106.605\n",
      "Ep:140, loss:0.00002, loss_test:0.08569, lr:4.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.501, tt:5146.577\n",
      "Ep:141, loss:0.00002, loss_test:0.08802, lr:4.57e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.510, tt:5184.354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00002, loss_test:0.08646, lr:4.52e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.509, tt:5220.729\n",
      "Ep:143, loss:0.00002, loss_test:0.08625, lr:4.48e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.515, tt:5258.097\n",
      "Ep:144, loss:0.00002, loss_test:0.08669, lr:4.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.534, tt:5297.396\n",
      "Ep:145, loss:0.00002, loss_test:0.08600, lr:4.39e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.531, tt:5333.466\n",
      "Ep:146, loss:0.00002, loss_test:0.08620, lr:4.34e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.536, tt:5370.812\n",
      "Ep:147, loss:0.00001, loss_test:0.08594, lr:4.30e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.542, tt:5408.178\n",
      "Ep:148, loss:0.00001, loss_test:0.08686, lr:4.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.548, tt:5445.694\n",
      "Ep:149, loss:0.00001, loss_test:0.08586, lr:4.21e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.551, tt:5482.685\n",
      "Ep:150, loss:0.00001, loss_test:0.08563, lr:4.17e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.559, tt:5520.466\n",
      "Ep:151, loss:0.00001, loss_test:0.08741, lr:4.13e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.579, tt:5559.952\n",
      "Ep:152, loss:0.00001, loss_test:0.08616, lr:4.09e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.579, tt:5596.552\n",
      "Ep:153, loss:0.00001, loss_test:0.08559, lr:4.05e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.582, tt:5633.644\n",
      "Ep:154, loss:0.00001, loss_test:0.08724, lr:4.01e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.591, tt:5671.620\n",
      "Ep:155, loss:0.00001, loss_test:0.08640, lr:3.97e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.606, tt:5710.527\n",
      "Ep:156, loss:0.00001, loss_test:0.08682, lr:3.93e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.620, tt:5749.418\n",
      "Ep:157, loss:0.00001, loss_test:0.08576, lr:3.89e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.628, tt:5787.164\n",
      "Ep:158, loss:0.00001, loss_test:0.08639, lr:3.85e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.628, tt:5823.811\n",
      "Ep:159, loss:0.00001, loss_test:0.08803, lr:3.81e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.652, tt:5864.362\n",
      "Ep:160, loss:0.00001, loss_test:0.08543, lr:3.77e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.661, tt:5902.440\n",
      "Ep:161, loss:0.00001, loss_test:0.08636, lr:3.73e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.667, tt:5940.070\n",
      "Ep:162, loss:0.00001, loss_test:0.08743, lr:3.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.676, tt:5978.247\n",
      "Ep:163, loss:0.00001, loss_test:0.08639, lr:3.66e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.686, tt:6016.548\n",
      "Ep:164, loss:0.00001, loss_test:0.08632, lr:3.62e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.692, tt:6054.104\n",
      "Ep:165, loss:0.00001, loss_test:0.08630, lr:3.59e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.708, tt:6093.532\n",
      "Ep:166, loss:0.00001, loss_test:0.08686, lr:3.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.714, tt:6131.241\n",
      "Ep:167, loss:0.00001, loss_test:0.08629, lr:3.52e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.726, tt:6169.908\n",
      "Ep:168, loss:0.00001, loss_test:0.08572, lr:3.48e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.732, tt:6207.689\n",
      "Ep:169, loss:0.00001, loss_test:0.08675, lr:3.45e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.734, tt:6244.749\n",
      "Ep:170, loss:0.00001, loss_test:0.08622, lr:3.41e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.748, tt:6283.928\n",
      "Ep:171, loss:0.00001, loss_test:0.08592, lr:3.38e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.747, tt:6320.542\n",
      "Ep:172, loss:0.00001, loss_test:0.08622, lr:3.34e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.748, tt:6357.402\n",
      "Ep:173, loss:0.00001, loss_test:0.08554, lr:3.31e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.749, tt:6394.397\n",
      "Ep:174, loss:0.00001, loss_test:0.08655, lr:3.28e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.754, tt:6431.873\n",
      "Ep:175, loss:0.00001, loss_test:0.08594, lr:3.24e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.756, tt:6468.984\n",
      "Ep:176, loss:0.00001, loss_test:0.08516, lr:3.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.753, tt:6505.272\n",
      "Ep:177, loss:0.00001, loss_test:0.08654, lr:3.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.751, tt:6541.591\n",
      "Ep:178, loss:0.00001, loss_test:0.08582, lr:3.15e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.747, tt:6577.639\n",
      "Ep:179, loss:0.00001, loss_test:0.08531, lr:3.12e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.757, tt:6616.197\n",
      "Ep:180, loss:0.00001, loss_test:0.08586, lr:3.09e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.752, tt:6652.187\n",
      "Ep:181, loss:0.00001, loss_test:0.08502, lr:3.05e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.742, tt:6687.054\n",
      "Ep:182, loss:0.00001, loss_test:0.08611, lr:3.02e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.742, tt:6723.709\n",
      "Ep:183, loss:0.00001, loss_test:0.08530, lr:2.99e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.736, tt:6759.361\n",
      "Ep:184, loss:0.00001, loss_test:0.08512, lr:2.96e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.728, tt:6794.685\n",
      "Ep:185, loss:0.00001, loss_test:0.08592, lr:2.93e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.725, tt:6830.940\n",
      "Ep:186, loss:0.00001, loss_test:0.08495, lr:2.90e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.735, tt:6869.375\n",
      "Ep:187, loss:0.00001, loss_test:0.08572, lr:2.88e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.735, tt:6906.245\n",
      "Ep:188, loss:0.00001, loss_test:0.08541, lr:2.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.728, tt:6941.677\n",
      "Ep:189, loss:0.00001, loss_test:0.08542, lr:2.82e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.733, tt:6979.272\n",
      "Ep:190, loss:0.00001, loss_test:0.08605, lr:2.79e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.733, tt:7015.942\n",
      "Ep:191, loss:0.00001, loss_test:0.08542, lr:2.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.731, tt:7052.430\n",
      "Ep:192, loss:0.00001, loss_test:0.08582, lr:2.73e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.723, tt:7087.541\n",
      "Ep:193, loss:0.00001, loss_test:0.08583, lr:2.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.720, tt:7123.752\n",
      "Ep:194, loss:0.00001, loss_test:0.08530, lr:2.68e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.712, tt:7158.892\n",
      "Ep:195, loss:0.00001, loss_test:0.08588, lr:2.65e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.707, tt:7194.540\n",
      "Ep:196, loss:0.00001, loss_test:0.08590, lr:2.63e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.698, tt:7229.603\n",
      "Ep:197, loss:0.00001, loss_test:0.08528, lr:2.60e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.700, tt:7266.511\n",
      "Ep:198, loss:0.00001, loss_test:0.08482, lr:2.57e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.696, tt:7302.598\n",
      "Ep:199, loss:0.00001, loss_test:0.08550, lr:2.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.695, tt:7339.081\n",
      "Ep:200, loss:0.00001, loss_test:0.08513, lr:2.52e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.706, tt:7377.903\n",
      "Ep:201, loss:0.00001, loss_test:0.08499, lr:2.50e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.694, tt:7412.150\n",
      "Ep:202, loss:0.00001, loss_test:0.08557, lr:2.47e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.669, tt:7443.712\n",
      "Ep:203, loss:0.00001, loss_test:0.08536, lr:2.45e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.654, tt:7477.403\n",
      "Ep:204, loss:0.00001, loss_test:0.08480, lr:2.42e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.644, tt:7511.922\n",
      "Ep:205, loss:0.00001, loss_test:0.08498, lr:2.40e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.635, tt:7546.906\n",
      "Ep:206, loss:0.00001, loss_test:0.08495, lr:2.38e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.598, tt:7575.837\n",
      "Ep:207, loss:0.00001, loss_test:0.08524, lr:2.35e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.560, tt:7604.444\n",
      "Ep:208, loss:0.00001, loss_test:0.08515, lr:2.33e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.534, tt:7635.517\n",
      "Ep:209, loss:0.00001, loss_test:0.08499, lr:2.31e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.533, tt:7671.837\n",
      "Ep:210, loss:0.00001, loss_test:0.08488, lr:2.28e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.533, tt:7708.359\n",
      "Ep:211, loss:0.00001, loss_test:0.08468, lr:2.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.529, tt:7744.150\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02173, lr:6.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:31.924, tt:31.924\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02152, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:32.923, tt:65.846\n",
      "Ep:2, loss:0.00005, loss_test:0.02557, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.229, tt:99.687\n",
      "Ep:3, loss:0.00005, loss_test:0.02753, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.491, tt:133.963\n",
      "Ep:4, loss:0.00006, loss_test:0.02797, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.396, tt:166.982\n",
      "Ep:5, loss:0.00006, loss_test:0.02730, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.573, tt:201.441\n",
      "Ep:6, loss:0.00006, loss_test:0.02592, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.604, tt:235.228\n",
      "Ep:7, loss:0.00005, loss_test:0.02401, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:33.730, tt:269.842\n",
      "Ep:8, loss:0.00005, loss_test:0.02209, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:33.577, tt:302.194\n",
      "Ep:9, loss:0.00005, loss_test:0.02062, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:33.577, tt:335.770\n",
      "Ep:10, loss:0.00005, loss_test:0.01983, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:33.606, tt:369.669\n",
      "Ep:11, loss:0.00005, loss_test:0.01944, lr:6.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:33.592, tt:403.110\n",
      "Ep:12, loss:0.00004, loss_test:0.01902, lr:5.94e-02, fs:0.68293 (r=0.848,p=0.571),  time:33.618, tt:437.028\n",
      "Ep:13, loss:0.00004, loss_test:0.01850, lr:5.88e-02, fs:0.67742 (r=0.848,p=0.564),  time:33.588, tt:470.227\n",
      "Ep:14, loss:0.00004, loss_test:0.01809, lr:5.82e-02, fs:0.68482 (r=0.889,p=0.557),  time:33.691, tt:505.367\n",
      "Ep:15, loss:0.00004, loss_test:0.01776, lr:5.76e-02, fs:0.68914 (r=0.929,p=0.548),  time:33.696, tt:539.135\n",
      "Ep:16, loss:0.00004, loss_test:0.01739, lr:5.71e-02, fs:0.69202 (r=0.919,p=0.555),  time:33.582, tt:570.898\n",
      "Ep:17, loss:0.00004, loss_test:0.01699, lr:5.65e-02, fs:0.70817 (r=0.919,p=0.576),  time:33.681, tt:606.264\n",
      "Ep:18, loss:0.00004, loss_test:0.01671, lr:5.59e-02, fs:0.71713 (r=0.909,p=0.592),  time:33.742, tt:641.100\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01659, lr:5.59e-02, fs:0.72653 (r=0.899,p=0.610),  time:33.778, tt:675.553\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01655, lr:5.59e-02, fs:0.72653 (r=0.899,p=0.610),  time:33.828, tt:710.383\n",
      "Ep:21, loss:0.00003, loss_test:0.01648, lr:5.59e-02, fs:0.73469 (r=0.909,p=0.616),  time:33.884, tt:745.441\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01636, lr:5.59e-02, fs:0.74699 (r=0.939,p=0.620),  time:33.934, tt:780.478\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01621, lr:5.59e-02, fs:0.74699 (r=0.939,p=0.620),  time:34.094, tt:818.264\n",
      "Ep:24, loss:0.00003, loss_test:0.01608, lr:5.59e-02, fs:0.76000 (r=0.960,p=0.629),  time:34.136, tt:853.393\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01594, lr:5.59e-02, fs:0.77236 (r=0.960,p=0.646),  time:34.167, tt:888.335\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01581, lr:5.59e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.204, tt:923.510\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01566, lr:5.59e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.283, tt:959.919\n",
      "Ep:28, loss:0.00003, loss_test:0.01552, lr:5.59e-02, fs:0.78008 (r=0.949,p=0.662),  time:34.327, tt:995.491\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01546, lr:5.59e-02, fs:0.76151 (r=0.919,p=0.650),  time:34.346, tt:1030.388\n",
      "Ep:30, loss:0.00003, loss_test:0.01540, lr:5.59e-02, fs:0.75424 (r=0.899,p=0.650),  time:34.360, tt:1065.167\n",
      "Ep:31, loss:0.00002, loss_test:0.01534, lr:5.59e-02, fs:0.76923 (r=0.909,p=0.667),  time:34.422, tt:1101.504\n",
      "Ep:32, loss:0.00002, loss_test:0.01525, lr:5.59e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.483, tt:1137.930\n",
      "Ep:33, loss:0.00002, loss_test:0.01512, lr:5.59e-02, fs:0.77922 (r=0.909,p=0.682),  time:34.525, tt:1173.849\n",
      "Ep:34, loss:0.00002, loss_test:0.01501, lr:5.59e-02, fs:0.79130 (r=0.919,p=0.695),  time:34.523, tt:1208.320\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01495, lr:5.59e-02, fs:0.78571 (r=0.889,p=0.704),  time:34.531, tt:1243.105\n",
      "Ep:36, loss:0.00002, loss_test:0.01488, lr:5.59e-02, fs:0.79279 (r=0.889,p=0.715),  time:34.550, tt:1278.350\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01475, lr:5.59e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.555, tt:1313.080\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01464, lr:5.59e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.565, tt:1348.020\n",
      "Ep:39, loss:0.00002, loss_test:0.01458, lr:5.59e-02, fs:0.80000 (r=0.889,p=0.727),  time:34.598, tt:1383.931\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01448, lr:5.59e-02, fs:0.80365 (r=0.889,p=0.733),  time:34.594, tt:1418.366\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01432, lr:5.59e-02, fs:0.80365 (r=0.889,p=0.733),  time:34.669, tt:1456.101\n",
      "Ep:42, loss:0.00002, loss_test:0.01418, lr:5.59e-02, fs:0.80734 (r=0.889,p=0.739),  time:34.719, tt:1492.904\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01411, lr:5.59e-02, fs:0.80734 (r=0.889,p=0.739),  time:34.727, tt:1527.984\n",
      "Ep:44, loss:0.00001, loss_test:0.01404, lr:5.59e-02, fs:0.80184 (r=0.879,p=0.737),  time:34.785, tt:1565.340\n",
      "Ep:45, loss:0.00001, loss_test:0.01392, lr:5.59e-02, fs:0.80930 (r=0.879,p=0.750),  time:34.798, tt:1600.731\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01387, lr:5.59e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.798, tt:1635.507\n",
      "Ep:47, loss:0.00001, loss_test:0.01384, lr:5.59e-02, fs:0.80930 (r=0.879,p=0.750),  time:34.804, tt:1670.586\n",
      "Ep:48, loss:0.00001, loss_test:0.01372, lr:5.59e-02, fs:0.80930 (r=0.879,p=0.750),  time:34.849, tt:1707.589\n",
      "Ep:49, loss:0.00001, loss_test:0.01364, lr:5.59e-02, fs:0.81308 (r=0.879,p=0.757),  time:34.874, tt:1743.717\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01357, lr:5.59e-02, fs:0.81690 (r=0.879,p=0.763),  time:34.905, tt:1780.161\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01352, lr:5.59e-02, fs:0.81517 (r=0.869,p=0.768),  time:34.916, tt:1815.613\n",
      "Ep:52, loss:0.00001, loss_test:0.01346, lr:5.59e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.954, tt:1852.576\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01342, lr:5.59e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.977, tt:1888.736\n",
      "Ep:54, loss:0.00001, loss_test:0.01346, lr:5.59e-02, fs:0.81731 (r=0.859,p=0.780),  time:34.951, tt:1922.331\n",
      "Ep:55, loss:0.00001, loss_test:0.01348, lr:5.59e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.946, tt:1956.951\n",
      "Ep:56, loss:0.00001, loss_test:0.01344, lr:5.59e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.948, tt:1992.050\n",
      "Ep:57, loss:0.00001, loss_test:0.01349, lr:5.59e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.946, tt:2026.850\n",
      "Ep:58, loss:0.00001, loss_test:0.01349, lr:5.59e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.945, tt:2061.761\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01349, lr:5.59e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.984, tt:2099.068\n",
      "Ep:60, loss:0.00001, loss_test:0.01352, lr:5.59e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.991, tt:2134.474\n",
      "Ep:61, loss:0.00001, loss_test:0.01358, lr:5.59e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.005, tt:2170.285\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01363, lr:5.59e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.019, tt:2206.228\n",
      "Ep:63, loss:0.00001, loss_test:0.01367, lr:5.59e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.037, tt:2242.367\n",
      "Ep:64, loss:0.00001, loss_test:0.01368, lr:5.59e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.041, tt:2277.694\n",
      "Ep:65, loss:0.00001, loss_test:0.01370, lr:5.59e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.043, tt:2312.837\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00001, loss_test:0.01375, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.047, tt:2348.124\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01386, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.071, tt:2384.842\n",
      "Ep:68, loss:0.00001, loss_test:0.01391, lr:5.59e-02, fs:0.84264 (r=0.838,p=0.847),  time:35.086, tt:2420.965\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01397, lr:5.59e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.083, tt:2455.822\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01402, lr:5.59e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.099, tt:2492.051\n",
      "Ep:71, loss:0.00001, loss_test:0.01405, lr:5.59e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.102, tt:2527.342\n",
      "Ep:72, loss:0.00001, loss_test:0.01410, lr:5.59e-02, fs:0.83505 (r=0.818,p=0.853),  time:35.108, tt:2562.893\n",
      "Ep:73, loss:0.00001, loss_test:0.01423, lr:5.59e-02, fs:0.81675 (r=0.788,p=0.848),  time:35.113, tt:2598.348\n",
      "Ep:74, loss:0.00001, loss_test:0.01420, lr:5.59e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.105, tt:2632.859\n",
      "Ep:75, loss:0.00001, loss_test:0.01429, lr:5.59e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.102, tt:2667.723\n",
      "Ep:76, loss:0.00001, loss_test:0.01446, lr:5.59e-02, fs:0.78495 (r=0.737,p=0.839),  time:35.081, tt:2701.203\n",
      "Ep:77, loss:0.00001, loss_test:0.01439, lr:5.59e-02, fs:0.78723 (r=0.747,p=0.831),  time:35.079, tt:2736.146\n",
      "Ep:78, loss:0.00001, loss_test:0.01449, lr:5.59e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.097, tt:2772.636\n",
      "Ep:79, loss:0.00001, loss_test:0.01469, lr:5.59e-02, fs:0.76087 (r=0.707,p=0.824),  time:35.075, tt:2805.991\n",
      "Ep:80, loss:0.00001, loss_test:0.01464, lr:5.59e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.062, tt:2840.007\n",
      "Ep:81, loss:0.00001, loss_test:0.01479, lr:5.54e-02, fs:0.75410 (r=0.697,p=0.821),  time:35.058, tt:2874.756\n",
      "Ep:82, loss:0.00001, loss_test:0.01483, lr:5.48e-02, fs:0.75410 (r=0.697,p=0.821),  time:35.056, tt:2909.617\n",
      "Ep:83, loss:0.00001, loss_test:0.01489, lr:5.43e-02, fs:0.75410 (r=0.697,p=0.821),  time:35.046, tt:2943.859\n",
      "Ep:84, loss:0.00000, loss_test:0.01500, lr:5.37e-02, fs:0.75138 (r=0.687,p=0.829),  time:35.046, tt:2978.899\n",
      "Ep:85, loss:0.00000, loss_test:0.01509, lr:5.32e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.046, tt:3013.940\n",
      "Ep:86, loss:0.00000, loss_test:0.01514, lr:5.27e-02, fs:0.74157 (r=0.667,p=0.835),  time:35.045, tt:3048.892\n",
      "Ep:87, loss:0.00000, loss_test:0.01527, lr:5.21e-02, fs:0.73864 (r=0.657,p=0.844),  time:35.056, tt:3084.927\n",
      "Ep:88, loss:0.00000, loss_test:0.01535, lr:5.16e-02, fs:0.73446 (r=0.657,p=0.833),  time:35.065, tt:3120.773\n",
      "Ep:89, loss:0.00000, loss_test:0.01544, lr:5.11e-02, fs:0.72727 (r=0.646,p=0.831),  time:35.065, tt:3155.876\n",
      "Ep:90, loss:0.00000, loss_test:0.01556, lr:5.06e-02, fs:0.72414 (r=0.636,p=0.840),  time:35.067, tt:3191.103\n",
      "Ep:91, loss:0.00000, loss_test:0.01561, lr:5.01e-02, fs:0.73256 (r=0.636,p=0.863),  time:35.057, tt:3225.271\n",
      "Ep:92, loss:0.00000, loss_test:0.01575, lr:4.96e-02, fs:0.72515 (r=0.626,p=0.861),  time:35.053, tt:3259.974\n",
      "Ep:93, loss:0.00000, loss_test:0.01581, lr:4.91e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.051, tt:3294.754\n",
      "Ep:94, loss:0.00000, loss_test:0.01585, lr:4.86e-02, fs:0.72189 (r=0.616,p=0.871),  time:35.060, tt:3330.678\n",
      "Ep:95, loss:0.00000, loss_test:0.01603, lr:4.81e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.065, tt:3366.193\n",
      "Ep:96, loss:0.00000, loss_test:0.01604, lr:4.76e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.075, tt:3402.301\n",
      "Ep:97, loss:0.00000, loss_test:0.01616, lr:4.71e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.090, tt:3438.832\n",
      "Ep:98, loss:0.00000, loss_test:0.01627, lr:4.67e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.087, tt:3473.582\n",
      "Ep:99, loss:0.00000, loss_test:0.01624, lr:4.62e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.079, tt:3507.868\n",
      "Ep:100, loss:0.00000, loss_test:0.01645, lr:4.57e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.084, tt:3543.454\n",
      "Ep:101, loss:0.00000, loss_test:0.01647, lr:4.53e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.096, tt:3579.841\n",
      "Ep:102, loss:0.00000, loss_test:0.01651, lr:4.48e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.112, tt:3616.536\n",
      "Ep:103, loss:0.00000, loss_test:0.01667, lr:4.44e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.127, tt:3653.233\n",
      "Ep:104, loss:0.00000, loss_test:0.01666, lr:4.39e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.137, tt:3689.365\n",
      "Ep:105, loss:0.00000, loss_test:0.01680, lr:4.35e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.152, tt:3726.104\n",
      "Ep:106, loss:0.00000, loss_test:0.01686, lr:4.31e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.162, tt:3762.327\n",
      "Ep:107, loss:0.00000, loss_test:0.01684, lr:4.26e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.179, tt:3799.351\n",
      "Ep:108, loss:0.00000, loss_test:0.01706, lr:4.22e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.173, tt:3833.908\n",
      "Ep:109, loss:0.00000, loss_test:0.01709, lr:4.18e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.177, tt:3869.503\n",
      "Ep:110, loss:0.00000, loss_test:0.01709, lr:4.14e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.188, tt:3905.876\n",
      "Ep:111, loss:0.00000, loss_test:0.01728, lr:4.10e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.209, tt:3943.371\n",
      "Ep:112, loss:0.00000, loss_test:0.01726, lr:4.05e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.218, tt:3979.651\n",
      "Ep:113, loss:0.00000, loss_test:0.01736, lr:4.01e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.212, tt:4014.147\n",
      "Ep:114, loss:0.00000, loss_test:0.01750, lr:3.97e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.225, tt:4050.917\n",
      "Ep:115, loss:0.00000, loss_test:0.01741, lr:3.93e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.241, tt:4087.933\n",
      "Ep:116, loss:0.00000, loss_test:0.01760, lr:3.89e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.247, tt:4123.894\n",
      "Ep:117, loss:0.00000, loss_test:0.01765, lr:3.86e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.256, tt:4160.252\n",
      "Ep:118, loss:0.00000, loss_test:0.01773, lr:3.82e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.264, tt:4196.466\n",
      "Ep:119, loss:0.00000, loss_test:0.01785, lr:3.78e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.275, tt:4233.010\n",
      "Ep:120, loss:0.00000, loss_test:0.01788, lr:3.74e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.280, tt:4268.923\n",
      "Ep:121, loss:0.00000, loss_test:0.01786, lr:3.70e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.279, tt:4304.065\n",
      "Ep:122, loss:0.00000, loss_test:0.01801, lr:3.67e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.278, tt:4339.166\n",
      "Ep:123, loss:0.00000, loss_test:0.01809, lr:3.63e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.278, tt:4374.533\n",
      "Ep:124, loss:0.00000, loss_test:0.01811, lr:3.59e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.268, tt:4408.468\n",
      "Ep:125, loss:0.00000, loss_test:0.01815, lr:3.56e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.280, tt:4445.231\n",
      "Ep:126, loss:0.00000, loss_test:0.01827, lr:3.52e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.274, tt:4479.789\n",
      "Ep:127, loss:0.00000, loss_test:0.01829, lr:3.49e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.273, tt:4514.973\n",
      "Ep:128, loss:0.00000, loss_test:0.01835, lr:3.45e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.269, tt:4549.667\n",
      "Ep:129, loss:0.00000, loss_test:0.01842, lr:3.42e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.272, tt:4585.384\n",
      "Ep:130, loss:0.00000, loss_test:0.01850, lr:3.38e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.271, tt:4620.511\n",
      "Ep:131, loss:0.00000, loss_test:0.01851, lr:3.35e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.273, tt:4656.094\n",
      "Ep:132, loss:0.00000, loss_test:0.01860, lr:3.32e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.279, tt:4692.120\n",
      "Ep:133, loss:0.00000, loss_test:0.01869, lr:3.28e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.279, tt:4727.426\n",
      "Ep:134, loss:0.00000, loss_test:0.01865, lr:3.25e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.274, tt:4761.931\n",
      "Ep:135, loss:0.00000, loss_test:0.01868, lr:3.22e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.270, tt:4796.694\n",
      "Ep:136, loss:0.00000, loss_test:0.01887, lr:3.19e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.261, tt:4830.794\n",
      "Ep:137, loss:0.00000, loss_test:0.01885, lr:3.15e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.254, tt:4865.085\n",
      "Ep:138, loss:0.00000, loss_test:0.01883, lr:3.12e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.250, tt:4899.816\n",
      "Ep:139, loss:0.00000, loss_test:0.01898, lr:3.09e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.244, tt:4934.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.01901, lr:3.06e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.235, tt:4968.162\n",
      "Ep:141, loss:0.00000, loss_test:0.01896, lr:3.03e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.222, tt:5001.454\n",
      "Ep:142, loss:0.00000, loss_test:0.01913, lr:3.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.219, tt:5036.253\n",
      "Ep:143, loss:0.00000, loss_test:0.01913, lr:2.97e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.219, tt:5071.572\n",
      "Ep:144, loss:0.00000, loss_test:0.01912, lr:2.94e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.216, tt:5106.290\n",
      "Ep:145, loss:0.00000, loss_test:0.01921, lr:2.91e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.219, tt:5141.971\n",
      "Ep:146, loss:0.00000, loss_test:0.01923, lr:2.88e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.217, tt:5176.841\n",
      "Ep:147, loss:0.00000, loss_test:0.01925, lr:2.85e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.216, tt:5212.026\n",
      "Ep:148, loss:0.00000, loss_test:0.01933, lr:2.82e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.216, tt:5247.133\n",
      "Ep:149, loss:0.00000, loss_test:0.01938, lr:2.80e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.219, tt:5282.877\n",
      "Ep:150, loss:0.00000, loss_test:0.01937, lr:2.77e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.221, tt:5318.415\n",
      "Ep:151, loss:0.00000, loss_test:0.01945, lr:2.74e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.222, tt:5353.706\n",
      "Ep:152, loss:0.00000, loss_test:0.01951, lr:2.71e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.225, tt:5389.425\n",
      "Ep:153, loss:0.00000, loss_test:0.01950, lr:2.69e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.233, tt:5425.884\n",
      "Ep:154, loss:0.00000, loss_test:0.01954, lr:2.66e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.248, tt:5463.507\n",
      "Ep:155, loss:0.00000, loss_test:0.01961, lr:2.63e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.245, tt:5498.265\n",
      "Ep:156, loss:0.00000, loss_test:0.01966, lr:2.61e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.255, tt:5535.064\n",
      "Ep:157, loss:0.00000, loss_test:0.01965, lr:2.58e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.267, tt:5572.185\n",
      "Ep:158, loss:0.00000, loss_test:0.01972, lr:2.55e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.268, tt:5607.544\n",
      "Ep:159, loss:0.00000, loss_test:0.01978, lr:2.53e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.275, tt:5644.064\n",
      "Ep:160, loss:0.00000, loss_test:0.01978, lr:2.50e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.278, tt:5679.678\n",
      "Ep:161, loss:0.00000, loss_test:0.01976, lr:2.48e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.281, tt:5715.510\n",
      "Ep:162, loss:0.00000, loss_test:0.01987, lr:2.45e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.285, tt:5751.399\n",
      "Ep:163, loss:0.00000, loss_test:0.01990, lr:2.43e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.283, tt:5786.438\n",
      "Ep:164, loss:0.00000, loss_test:0.01985, lr:2.40e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.300, tt:5824.417\n",
      "Ep:165, loss:0.00000, loss_test:0.01991, lr:2.38e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.300, tt:5859.824\n",
      "Ep:166, loss:0.00000, loss_test:0.02000, lr:2.36e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.308, tt:5896.374\n",
      "Ep:167, loss:0.00000, loss_test:0.01999, lr:2.33e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.310, tt:5932.053\n",
      "Ep:168, loss:0.00000, loss_test:0.02001, lr:2.31e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.311, tt:5967.590\n",
      "Ep:169, loss:0.00000, loss_test:0.02005, lr:2.29e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.311, tt:6002.851\n",
      "Ep:170, loss:0.00000, loss_test:0.02011, lr:2.26e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.312, tt:6038.317\n",
      "Ep:171, loss:0.00000, loss_test:0.02009, lr:2.24e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.324, tt:6075.722\n",
      "Ep:172, loss:0.00000, loss_test:0.02015, lr:2.22e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.326, tt:6111.450\n",
      "Ep:173, loss:0.00000, loss_test:0.02018, lr:2.20e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.334, tt:6148.173\n",
      "Ep:174, loss:0.00000, loss_test:0.02019, lr:2.17e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.331, tt:6182.920\n",
      "Ep:175, loss:0.00000, loss_test:0.02020, lr:2.15e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.326, tt:6217.331\n",
      "Ep:176, loss:0.00000, loss_test:0.02023, lr:2.13e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.325, tt:6252.490\n",
      "Ep:177, loss:0.00000, loss_test:0.02030, lr:2.11e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.324, tt:6287.616\n",
      "Ep:178, loss:0.00000, loss_test:0.02031, lr:2.09e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.313, tt:6321.000\n",
      "Ep:179, loss:0.00000, loss_test:0.02029, lr:2.07e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.312, tt:6356.096\n",
      "Ep:180, loss:0.00000, loss_test:0.02033, lr:2.05e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.312, tt:6391.523\n",
      "Ep:181, loss:0.00000, loss_test:0.02039, lr:2.03e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.314, tt:6427.181\n",
      "Ep:182, loss:0.00000, loss_test:0.02039, lr:2.01e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.308, tt:6461.424\n",
      "Ep:183, loss:0.00000, loss_test:0.02040, lr:1.99e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.307, tt:6496.492\n",
      "Ep:184, loss:0.00000, loss_test:0.02042, lr:1.97e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.315, tt:6533.303\n",
      "Ep:185, loss:0.00000, loss_test:0.02044, lr:1.95e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.318, tt:6569.226\n",
      "Ep:186, loss:0.00000, loss_test:0.02049, lr:1.93e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.326, tt:6606.021\n",
      "Ep:187, loss:0.00000, loss_test:0.02051, lr:1.91e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.330, tt:6642.024\n",
      "Ep:188, loss:0.00000, loss_test:0.02051, lr:1.89e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.328, tt:6677.039\n",
      "Ep:189, loss:0.00000, loss_test:0.02056, lr:1.87e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.325, tt:6711.738\n",
      "Ep:190, loss:0.00000, loss_test:0.02055, lr:1.85e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.333, tt:6748.516\n",
      "Ep:191, loss:0.00000, loss_test:0.02062, lr:1.83e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.319, tt:6781.187\n",
      "Ep:192, loss:0.00000, loss_test:0.02060, lr:1.81e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.325, tt:6817.628\n",
      "Ep:193, loss:0.00000, loss_test:0.02063, lr:1.80e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.317, tt:6851.484\n",
      "Ep:194, loss:0.00000, loss_test:0.02066, lr:1.78e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.309, tt:6885.171\n",
      "Ep:195, loss:0.00000, loss_test:0.02069, lr:1.76e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.297, tt:6918.163\n",
      "Ep:196, loss:0.00000, loss_test:0.02069, lr:1.74e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.275, tt:6949.086\n",
      "Ep:197, loss:0.00000, loss_test:0.02070, lr:1.73e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.257, tt:6980.816\n",
      "Ep:198, loss:0.00000, loss_test:0.02076, lr:1.71e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.253, tt:7015.303\n",
      "Ep:199, loss:0.00000, loss_test:0.02078, lr:1.69e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.250, tt:7049.998\n",
      "Ep:200, loss:0.00000, loss_test:0.02074, lr:1.67e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.246, tt:7084.412\n",
      "Ep:201, loss:0.00000, loss_test:0.02077, lr:1.66e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.239, tt:7118.283\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.11914, lr:1.00e-02, fs:0.67925 (r=0.909,p=0.542),  time:33.460, tt:33.460\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.11705, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:34.469, tt:68.937\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.11541, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:35.129, tt:105.387\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11397, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.976, tt:139.903\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11297, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:35.021, tt:175.104\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.11184, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:35.360, tt:212.162\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00025, loss_test:0.11082, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:35.395, tt:247.763\n",
      "Ep:7, loss:0.00025, loss_test:0.10932, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:35.489, tt:283.908\n",
      "Ep:8, loss:0.00025, loss_test:0.10748, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:35.533, tt:319.794\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.10534, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:35.495, tt:354.946\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.10294, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:35.572, tt:391.294\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.10111, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:35.599, tt:427.184\n",
      "Ep:12, loss:0.00023, loss_test:0.09913, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:35.582, tt:462.566\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.09680, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:35.609, tt:498.525\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.09418, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:35.891, tt:538.368\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.09310, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:36.034, tt:576.539\n",
      "Ep:16, loss:0.00020, loss_test:0.09227, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:36.303, tt:617.154\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.09147, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:36.513, tt:657.235\n",
      "Ep:18, loss:0.00019, loss_test:0.09028, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:36.593, tt:695.258\n",
      "Ep:19, loss:0.00018, loss_test:0.08982, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:36.675, tt:733.495\n",
      "Ep:20, loss:0.00018, loss_test:0.08868, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:36.756, tt:771.882\n",
      "Ep:21, loss:0.00017, loss_test:0.08827, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:36.784, tt:809.258\n",
      "Ep:22, loss:0.00016, loss_test:0.08787, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:36.918, tt:849.114\n",
      "Ep:23, loss:0.00015, loss_test:0.08569, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:36.981, tt:887.532\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08427, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:37.039, tt:925.970\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08469, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:37.079, tt:964.059\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08229, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:37.126, tt:1002.407\n",
      "Ep:27, loss:0.00013, loss_test:0.08289, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:37.211, tt:1041.913\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.08153, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:37.211, tt:1079.133\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08012, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:37.153, tt:1114.596\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08018, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:37.207, tt:1153.422\n",
      "Ep:31, loss:0.00010, loss_test:0.08082, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:37.256, tt:1192.193\n",
      "Ep:32, loss:0.00010, loss_test:0.07891, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:37.234, tt:1228.732\n",
      "Ep:33, loss:0.00009, loss_test:0.07827, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:37.274, tt:1267.332\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.07904, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:37.265, tt:1304.277\n",
      "Ep:35, loss:0.00009, loss_test:0.07718, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:37.232, tt:1340.370\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.07771, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.209, tt:1376.718\n",
      "Ep:37, loss:0.00008, loss_test:0.07805, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:37.210, tt:1413.995\n",
      "Ep:38, loss:0.00008, loss_test:0.07571, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:37.216, tt:1451.427\n",
      "Ep:39, loss:0.00007, loss_test:0.07682, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:37.191, tt:1487.626\n",
      "Ep:40, loss:0.00007, loss_test:0.07350, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:37.199, tt:1525.149\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.07610, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:37.194, tt:1562.164\n",
      "Ep:42, loss:0.00006, loss_test:0.07391, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:37.194, tt:1599.347\n",
      "Ep:43, loss:0.00006, loss_test:0.07185, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:37.184, tt:1636.079\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.07402, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:37.182, tt:1673.208\n",
      "Ep:45, loss:0.00006, loss_test:0.07108, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:37.170, tt:1709.831\n",
      "Ep:46, loss:0.00005, loss_test:0.07293, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:37.149, tt:1746.023\n",
      "Ep:47, loss:0.00005, loss_test:0.07059, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:37.133, tt:1782.386\n",
      "Ep:48, loss:0.00005, loss_test:0.07086, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:37.102, tt:1818.002\n",
      "Ep:49, loss:0.00005, loss_test:0.07160, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:37.098, tt:1854.902\n",
      "Ep:50, loss:0.00004, loss_test:0.07096, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:37.081, tt:1891.141\n",
      "Ep:51, loss:0.00004, loss_test:0.07000, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:37.042, tt:1926.168\n",
      "Ep:52, loss:0.00004, loss_test:0.06891, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:37.004, tt:1961.186\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.07042, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:36.953, tt:1995.481\n",
      "Ep:54, loss:0.00004, loss_test:0.06763, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:36.932, tt:2031.237\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.06933, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:36.915, tt:2067.213\n",
      "Ep:56, loss:0.00004, loss_test:0.06797, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:36.885, tt:2102.470\n",
      "Ep:57, loss:0.00003, loss_test:0.06819, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.860, tt:2137.873\n",
      "Ep:58, loss:0.00003, loss_test:0.06599, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.868, tt:2175.189\n",
      "Ep:59, loss:0.00003, loss_test:0.06842, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:36.829, tt:2209.748\n",
      "Ep:60, loss:0.00003, loss_test:0.06774, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:36.808, tt:2245.258\n",
      "Ep:61, loss:0.00003, loss_test:0.06372, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:36.788, tt:2280.829\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00003, loss_test:0.07062, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:36.774, tt:2316.792\n",
      "Ep:63, loss:0.00003, loss_test:0.06187, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:36.770, tt:2353.259\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.06864, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:36.732, tt:2387.595\n",
      "Ep:65, loss:0.00003, loss_test:0.06649, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:36.687, tt:2421.355\n",
      "Ep:66, loss:0.00003, loss_test:0.06214, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:36.673, tt:2457.058\n",
      "Ep:67, loss:0.00003, loss_test:0.07050, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:36.644, tt:2491.773\n",
      "Ep:68, loss:0.00003, loss_test:0.06218, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:36.612, tt:2526.228\n",
      "Ep:69, loss:0.00002, loss_test:0.06656, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:36.585, tt:2560.932\n",
      "Ep:70, loss:0.00002, loss_test:0.06538, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:36.577, tt:2596.955\n",
      "Ep:71, loss:0.00002, loss_test:0.06398, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:36.555, tt:2631.986\n",
      "Ep:72, loss:0.00002, loss_test:0.06607, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:36.543, tt:2667.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00002, loss_test:0.06278, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:36.533, tt:2703.461\n",
      "Ep:74, loss:0.00002, loss_test:0.07134, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:36.503, tt:2737.700\n",
      "Ep:75, loss:0.00002, loss_test:0.06094, lr:9.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:36.511, tt:2774.858\n",
      "Ep:76, loss:0.00002, loss_test:0.07024, lr:9.80e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.493, tt:2809.957\n",
      "Ep:77, loss:0.00002, loss_test:0.06179, lr:9.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.479, tt:2845.333\n",
      "Ep:78, loss:0.00002, loss_test:0.06718, lr:9.61e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.506, tt:2883.972\n",
      "Ep:79, loss:0.00002, loss_test:0.06258, lr:9.51e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.495, tt:2919.638\n",
      "Ep:80, loss:0.00002, loss_test:0.06885, lr:9.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.479, tt:2954.820\n",
      "Ep:81, loss:0.00002, loss_test:0.06250, lr:9.32e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.489, tt:2992.086\n",
      "Ep:82, loss:0.00002, loss_test:0.06652, lr:9.23e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.499, tt:3029.447\n",
      "Ep:83, loss:0.00002, loss_test:0.06365, lr:9.14e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.505, tt:3066.440\n",
      "Ep:84, loss:0.00002, loss_test:0.06646, lr:9.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.503, tt:3102.759\n",
      "Ep:85, loss:0.00002, loss_test:0.06456, lr:8.95e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.487, tt:3137.909\n",
      "Ep:86, loss:0.00002, loss_test:0.06333, lr:8.86e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.487, tt:3174.365\n",
      "Ep:87, loss:0.00002, loss_test:0.06814, lr:8.78e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.491, tt:3211.248\n",
      "Ep:88, loss:0.00002, loss_test:0.06137, lr:8.69e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.478, tt:3246.551\n",
      "Ep:89, loss:0.00002, loss_test:0.06784, lr:8.60e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.438, tt:3279.407\n",
      "Ep:90, loss:0.00001, loss_test:0.06301, lr:8.51e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.402, tt:3312.569\n",
      "Ep:91, loss:0.00001, loss_test:0.06571, lr:8.43e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.397, tt:3348.553\n",
      "Ep:92, loss:0.00001, loss_test:0.06224, lr:8.35e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.381, tt:3383.421\n",
      "Ep:93, loss:0.00001, loss_test:0.06440, lr:8.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.387, tt:3420.392\n",
      "Ep:94, loss:0.00001, loss_test:0.06710, lr:8.18e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.371, tt:3455.250\n",
      "Ep:95, loss:0.00001, loss_test:0.06218, lr:8.10e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.375, tt:3492.032\n",
      "Ep:96, loss:0.00001, loss_test:0.06735, lr:8.02e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.376, tt:3528.491\n",
      "Ep:97, loss:0.00001, loss_test:0.06234, lr:7.94e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.379, tt:3565.115\n",
      "Ep:98, loss:0.00001, loss_test:0.06556, lr:7.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.391, tt:3602.730\n",
      "Ep:99, loss:0.00001, loss_test:0.06712, lr:7.78e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.392, tt:3639.213\n",
      "Ep:100, loss:0.00001, loss_test:0.06147, lr:7.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.393, tt:3675.723\n",
      "Ep:101, loss:0.00001, loss_test:0.06825, lr:7.62e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.413, tt:3714.118\n",
      "Ep:102, loss:0.00001, loss_test:0.06226, lr:7.55e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.400, tt:3749.157\n",
      "Ep:103, loss:0.00001, loss_test:0.06410, lr:7.47e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.392, tt:3784.740\n",
      "Ep:104, loss:0.00001, loss_test:0.06525, lr:7.40e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.384, tt:3820.292\n",
      "Ep:105, loss:0.00001, loss_test:0.06302, lr:7.32e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.386, tt:3856.890\n",
      "Ep:106, loss:0.00001, loss_test:0.06623, lr:7.25e-03, fs:0.74699 (r=0.626,p=0.925),  time:36.394, tt:3894.123\n",
      "Ep:107, loss:0.00001, loss_test:0.06388, lr:7.18e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.396, tt:3930.723\n",
      "Ep:108, loss:0.00001, loss_test:0.06390, lr:7.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.393, tt:3966.885\n",
      "Ep:109, loss:0.00001, loss_test:0.06512, lr:7.03e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.407, tt:4004.762\n",
      "Ep:110, loss:0.00001, loss_test:0.06329, lr:6.96e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.421, tt:4042.681\n",
      "Ep:111, loss:0.00001, loss_test:0.06453, lr:6.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.407, tt:4077.636\n",
      "Ep:112, loss:0.00001, loss_test:0.06452, lr:6.83e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.389, tt:4111.955\n",
      "Ep:113, loss:0.00001, loss_test:0.06351, lr:6.76e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.398, tt:4149.397\n",
      "Ep:114, loss:0.00001, loss_test:0.06478, lr:6.69e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.398, tt:4185.823\n",
      "Ep:115, loss:0.00001, loss_test:0.06347, lr:6.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.397, tt:4222.062\n",
      "Ep:116, loss:0.00001, loss_test:0.06455, lr:6.56e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.390, tt:4257.607\n",
      "Ep:117, loss:0.00001, loss_test:0.06429, lr:6.49e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.399, tt:4295.117\n",
      "Ep:118, loss:0.00001, loss_test:0.06372, lr:6.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.412, tt:4332.980\n",
      "Ep:119, loss:0.00001, loss_test:0.06406, lr:6.36e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.403, tt:4368.340\n",
      "Ep:120, loss:0.00001, loss_test:0.06365, lr:6.30e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.398, tt:4404.114\n",
      "Ep:121, loss:0.00001, loss_test:0.06488, lr:6.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.396, tt:4440.269\n",
      "Ep:122, loss:0.00001, loss_test:0.06382, lr:6.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.395, tt:4476.644\n",
      "Ep:123, loss:0.00001, loss_test:0.06405, lr:6.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.402, tt:4513.887\n",
      "Ep:124, loss:0.00001, loss_test:0.06393, lr:6.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.405, tt:4550.643\n",
      "Ep:125, loss:0.00001, loss_test:0.06382, lr:5.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.403, tt:4586.827\n",
      "Ep:126, loss:0.00001, loss_test:0.06457, lr:5.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.412, tt:4624.358\n",
      "Ep:127, loss:0.00001, loss_test:0.06358, lr:5.87e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.426, tt:4662.561\n",
      "Ep:128, loss:0.00001, loss_test:0.06383, lr:5.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.426, tt:4698.908\n",
      "Ep:129, loss:0.00001, loss_test:0.06491, lr:5.75e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.431, tt:4735.999\n",
      "Ep:130, loss:0.00001, loss_test:0.06355, lr:5.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.434, tt:4772.798\n",
      "Ep:131, loss:0.00001, loss_test:0.06454, lr:5.64e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.431, tt:4808.905\n",
      "Ep:132, loss:0.00001, loss_test:0.06393, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.430, tt:4845.252\n",
      "Ep:133, loss:0.00001, loss_test:0.06427, lr:5.53e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.424, tt:4880.851\n",
      "Ep:134, loss:0.00001, loss_test:0.06387, lr:5.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.424, tt:4917.198\n",
      "Ep:135, loss:0.00001, loss_test:0.06397, lr:5.42e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.412, tt:4952.006\n",
      "Ep:136, loss:0.00001, loss_test:0.06496, lr:5.36e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.416, tt:4988.986\n",
      "Ep:137, loss:0.00001, loss_test:0.06410, lr:5.31e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.419, tt:5025.761\n",
      "Ep:138, loss:0.00001, loss_test:0.06408, lr:5.26e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.420, tt:5062.363\n",
      "Ep:139, loss:0.00001, loss_test:0.06436, lr:5.20e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.409, tt:5097.203\n",
      "Ep:140, loss:0.00001, loss_test:0.06381, lr:5.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.403, tt:5132.802\n",
      "Ep:141, loss:0.00001, loss_test:0.06422, lr:5.10e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.407, tt:5169.808\n",
      "Ep:142, loss:0.00001, loss_test:0.06418, lr:5.05e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.420, tt:5208.063\n",
      "Ep:143, loss:0.00001, loss_test:0.06502, lr:5.00e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.432, tt:5246.253\n",
      "Ep:144, loss:0.00001, loss_test:0.06369, lr:4.95e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.434, tt:5282.987\n",
      "Ep:145, loss:0.00001, loss_test:0.06481, lr:4.90e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.439, tt:5320.045\n",
      "Ep:146, loss:0.00001, loss_test:0.06378, lr:4.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.447, tt:5357.645\n",
      "Ep:147, loss:0.00001, loss_test:0.06446, lr:4.80e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.454, tt:5395.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00001, loss_test:0.06529, lr:4.75e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.454, tt:5431.706\n",
      "Ep:149, loss:0.00001, loss_test:0.06341, lr:4.71e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.447, tt:5467.086\n",
      "Ep:150, loss:0.00001, loss_test:0.06511, lr:4.66e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.450, tt:5503.980\n",
      "Ep:151, loss:0.00001, loss_test:0.06527, lr:4.61e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.451, tt:5540.503\n",
      "Ep:152, loss:0.00001, loss_test:0.06355, lr:4.57e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.457, tt:5577.906\n",
      "Ep:153, loss:0.00001, loss_test:0.06462, lr:4.52e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.459, tt:5614.646\n",
      "Ep:154, loss:0.00001, loss_test:0.06558, lr:4.48e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.450, tt:5649.741\n",
      "Ep:155, loss:0.00001, loss_test:0.06416, lr:4.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.441, tt:5684.767\n",
      "Ep:156, loss:0.00001, loss_test:0.06486, lr:4.39e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.455, tt:5723.381\n",
      "Ep:157, loss:0.00001, loss_test:0.06591, lr:4.34e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.447, tt:5758.634\n",
      "Ep:158, loss:0.00001, loss_test:0.06439, lr:4.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.443, tt:5794.510\n",
      "Ep:159, loss:0.00001, loss_test:0.06443, lr:4.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.451, tt:5832.200\n",
      "Ep:160, loss:0.00001, loss_test:0.06537, lr:4.21e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.442, tt:5867.128\n",
      "Ep:161, loss:0.00001, loss_test:0.06458, lr:4.17e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.437, tt:5902.776\n",
      "Ep:162, loss:0.00001, loss_test:0.06481, lr:4.13e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.439, tt:5939.607\n",
      "Ep:163, loss:0.00001, loss_test:0.06489, lr:4.09e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.430, tt:5974.571\n",
      "Ep:164, loss:0.00001, loss_test:0.06412, lr:4.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.423, tt:6009.810\n",
      "Ep:165, loss:0.00001, loss_test:0.06583, lr:4.01e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.427, tt:6046.900\n",
      "Ep:166, loss:0.00001, loss_test:0.06555, lr:3.97e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.421, tt:6082.322\n",
      "Ep:167, loss:0.00001, loss_test:0.06454, lr:3.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.417, tt:6118.130\n",
      "Ep:168, loss:0.00001, loss_test:0.06523, lr:3.89e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.409, tt:6153.193\n",
      "Ep:169, loss:0.00001, loss_test:0.06529, lr:3.85e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.405, tt:6188.801\n",
      "Ep:170, loss:0.00001, loss_test:0.06463, lr:3.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.406, tt:6225.491\n",
      "Ep:171, loss:0.00001, loss_test:0.06553, lr:3.77e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.399, tt:6260.669\n",
      "Ep:172, loss:0.00001, loss_test:0.06548, lr:3.73e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.384, tt:6294.476\n",
      "Ep:173, loss:0.00001, loss_test:0.06454, lr:3.70e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.378, tt:6329.850\n",
      "Ep:174, loss:0.00001, loss_test:0.06540, lr:3.66e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.380, tt:6366.441\n",
      "Ep:175, loss:0.00001, loss_test:0.06506, lr:3.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.380, tt:6402.951\n",
      "Ep:176, loss:0.00001, loss_test:0.06534, lr:3.59e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.379, tt:6439.162\n",
      "Ep:177, loss:0.00001, loss_test:0.06541, lr:3.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.380, tt:6475.662\n",
      "Ep:178, loss:0.00001, loss_test:0.06525, lr:3.52e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.376, tt:6511.373\n",
      "Ep:179, loss:0.00001, loss_test:0.06540, lr:3.48e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.369, tt:6546.444\n",
      "Ep:180, loss:0.00001, loss_test:0.06527, lr:3.45e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.372, tt:6583.375\n",
      "Ep:181, loss:0.00001, loss_test:0.06516, lr:3.41e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.367, tt:6618.802\n",
      "Ep:182, loss:0.00001, loss_test:0.06560, lr:3.38e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.369, tt:6655.460\n",
      "Ep:183, loss:0.00001, loss_test:0.06520, lr:3.34e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.372, tt:6692.528\n",
      "Ep:184, loss:0.00001, loss_test:0.06522, lr:3.31e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.397, tt:6733.446\n",
      "Ep:185, loss:0.00001, loss_test:0.06543, lr:3.28e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.401, tt:6770.666\n",
      "Ep:186, loss:0.00001, loss_test:0.06507, lr:3.24e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.396, tt:6806.081\n",
      "Ep:187, loss:0.00001, loss_test:0.06534, lr:3.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.396, tt:6842.528\n",
      "Ep:188, loss:0.00001, loss_test:0.06527, lr:3.18e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.397, tt:6878.996\n",
      "Ep:189, loss:0.00001, loss_test:0.06520, lr:3.15e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.405, tt:6916.960\n",
      "Ep:190, loss:0.00001, loss_test:0.06519, lr:3.12e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.409, tt:6954.034\n",
      "Ep:191, loss:0.00001, loss_test:0.06536, lr:3.09e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.402, tt:6989.219\n",
      "Ep:192, loss:0.00001, loss_test:0.06528, lr:3.05e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.387, tt:7022.606\n",
      "Ep:193, loss:0.00001, loss_test:0.06520, lr:3.02e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.368, tt:7055.326\n",
      "Ep:194, loss:0.00001, loss_test:0.06526, lr:2.99e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.341, tt:7086.473\n",
      "Ep:195, loss:0.00001, loss_test:0.06541, lr:2.96e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.318, tt:7118.316\n",
      "Ep:196, loss:0.00001, loss_test:0.06563, lr:2.93e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.291, tt:7149.407\n",
      "Ep:197, loss:0.00001, loss_test:0.06488, lr:2.90e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.239, tt:7175.391\n",
      "Ep:198, loss:0.00001, loss_test:0.06569, lr:2.88e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.203, tt:7204.465\n",
      "Ep:199, loss:0.00001, loss_test:0.06568, lr:2.85e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.204, tt:7240.760\n",
      "Ep:200, loss:0.00001, loss_test:0.06503, lr:2.82e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.202, tt:7276.603\n",
      "Ep:201, loss:0.00001, loss_test:0.06540, lr:2.79e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.210, tt:7314.366\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02052, lr:6.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:28.350, tt:28.350\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02260, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:27.635, tt:55.270\n",
      "Ep:2, loss:0.00005, loss_test:0.02547, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.654, tt:85.961\n",
      "Ep:3, loss:0.00005, loss_test:0.02594, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.521, tt:118.085\n",
      "Ep:4, loss:0.00005, loss_test:0.02480, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.442, tt:147.208\n",
      "Ep:5, loss:0.00005, loss_test:0.02314, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:29.793, tt:178.758\n",
      "Ep:6, loss:0.00005, loss_test:0.02133, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:30.045, tt:210.317\n",
      "Ep:7, loss:0.00005, loss_test:0.01987, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:30.055, tt:240.442\n",
      "Ep:8, loss:0.00005, loss_test:0.01907, lr:6.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:30.044, tt:270.394\n",
      "Ep:9, loss:0.00004, loss_test:0.01879, lr:6.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:30.211, tt:302.114\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01856, lr:6.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:30.169, tt:331.863\n",
      "Ep:11, loss:0.00004, loss_test:0.01826, lr:6.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:30.298, tt:363.576\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01820, lr:6.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:30.258, tt:393.354\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:30.223, tt:423.117\n",
      "Ep:14, loss:0.00004, loss_test:0.01822, lr:6.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:30.297, tt:454.453\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:30.306, tt:484.902\n",
      "Ep:16, loss:0.00004, loss_test:0.01807, lr:6.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:30.385, tt:516.537\n",
      "Ep:17, loss:0.00004, loss_test:0.01794, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:30.432, tt:547.777\n",
      "Ep:18, loss:0.00004, loss_test:0.01779, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:30.423, tt:578.040\n",
      "Ep:19, loss:0.00004, loss_test:0.01764, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:30.307, tt:606.146\n",
      "Ep:20, loss:0.00004, loss_test:0.01749, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:30.365, tt:637.665\n",
      "Ep:21, loss:0.00004, loss_test:0.01734, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:30.386, tt:668.481\n",
      "Ep:22, loss:0.00004, loss_test:0.01719, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:30.400, tt:699.201\n",
      "Ep:23, loss:0.00004, loss_test:0.01699, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:30.425, tt:730.197\n",
      "Ep:24, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:30.409, tt:760.226\n",
      "Ep:25, loss:0.00003, loss_test:0.01664, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:30.421, tt:790.958\n",
      "Ep:26, loss:0.00003, loss_test:0.01645, lr:5.94e-02, fs:0.71901 (r=0.879,p=0.608),  time:30.395, tt:820.678\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01628, lr:5.94e-02, fs:0.72199 (r=0.879,p=0.613),  time:30.398, tt:851.143\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01613, lr:5.94e-02, fs:0.73109 (r=0.879,p=0.626),  time:30.406, tt:881.762\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01597, lr:5.94e-02, fs:0.73729 (r=0.879,p=0.635),  time:30.388, tt:911.655\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01578, lr:5.94e-02, fs:0.75745 (r=0.899,p=0.654),  time:30.433, tt:943.408\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01558, lr:5.94e-02, fs:0.76793 (r=0.919,p=0.659),  time:30.459, tt:974.678\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01540, lr:5.94e-02, fs:0.77637 (r=0.929,p=0.667),  time:30.457, tt:1005.075\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01530, lr:5.94e-02, fs:0.76724 (r=0.899,p=0.669),  time:30.456, tt:1035.507\n",
      "Ep:34, loss:0.00003, loss_test:0.01521, lr:5.94e-02, fs:0.73913 (r=0.859,p=0.649),  time:30.473, tt:1066.552\n",
      "Ep:35, loss:0.00003, loss_test:0.01513, lr:5.94e-02, fs:0.73362 (r=0.848,p=0.646),  time:30.489, tt:1097.595\n",
      "Ep:36, loss:0.00002, loss_test:0.01511, lr:5.94e-02, fs:0.74009 (r=0.848,p=0.656),  time:30.465, tt:1127.211\n",
      "Ep:37, loss:0.00002, loss_test:0.01504, lr:5.94e-02, fs:0.75556 (r=0.859,p=0.675),  time:30.421, tt:1155.980\n",
      "Ep:38, loss:0.00002, loss_test:0.01494, lr:5.94e-02, fs:0.76106 (r=0.869,p=0.677),  time:30.443, tt:1187.283\n",
      "Ep:39, loss:0.00002, loss_test:0.01487, lr:5.94e-02, fs:0.76786 (r=0.869,p=0.688),  time:30.469, tt:1218.766\n",
      "Ep:40, loss:0.00002, loss_test:0.01477, lr:5.94e-02, fs:0.78222 (r=0.889,p=0.698),  time:30.506, tt:1250.749\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01467, lr:5.94e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.514, tt:1281.596\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01459, lr:5.94e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.503, tt:1311.615\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01457, lr:5.94e-02, fs:0.80909 (r=0.899,p=0.736),  time:30.528, tt:1343.214\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01459, lr:5.94e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.524, tt:1373.589\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01444, lr:5.94e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.568, tt:1406.113\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01435, lr:5.94e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.569, tt:1436.752\n",
      "Ep:47, loss:0.00002, loss_test:0.01432, lr:5.94e-02, fs:0.80734 (r=0.889,p=0.739),  time:30.583, tt:1467.969\n",
      "Ep:48, loss:0.00002, loss_test:0.01425, lr:5.94e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.597, tt:1499.235\n",
      "Ep:49, loss:0.00001, loss_test:0.01408, lr:5.94e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.587, tt:1529.374\n",
      "Ep:50, loss:0.00001, loss_test:0.01411, lr:5.94e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.589, tt:1560.045\n",
      "Ep:51, loss:0.00001, loss_test:0.01411, lr:5.94e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.583, tt:1590.316\n",
      "Ep:52, loss:0.00001, loss_test:0.01405, lr:5.94e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.608, tt:1622.232\n",
      "Ep:53, loss:0.00001, loss_test:0.01409, lr:5.94e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.603, tt:1652.576\n",
      "Ep:54, loss:0.00001, loss_test:0.01401, lr:5.94e-02, fs:0.79412 (r=0.818,p=0.771),  time:30.609, tt:1683.488\n",
      "Ep:55, loss:0.00001, loss_test:0.01401, lr:5.94e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.595, tt:1713.315\n",
      "Ep:56, loss:0.00001, loss_test:0.01400, lr:5.94e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.582, tt:1743.199\n",
      "Ep:57, loss:0.00001, loss_test:0.01396, lr:5.88e-02, fs:0.80000 (r=0.788,p=0.812),  time:30.575, tt:1773.374\n",
      "Ep:58, loss:0.00001, loss_test:0.01389, lr:5.82e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.606, tt:1805.773\n",
      "Ep:59, loss:0.00001, loss_test:0.01402, lr:5.76e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.600, tt:1835.992\n",
      "Ep:60, loss:0.00001, loss_test:0.01404, lr:5.71e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.595, tt:1866.277\n",
      "Ep:61, loss:0.00001, loss_test:0.01395, lr:5.65e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.601, tt:1897.252\n",
      "Ep:62, loss:0.00001, loss_test:0.01400, lr:5.59e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.579, tt:1926.454\n",
      "Ep:63, loss:0.00001, loss_test:0.01410, lr:5.54e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.554, tt:1955.444\n",
      "Ep:64, loss:0.00001, loss_test:0.01391, lr:5.48e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.527, tt:1984.280\n",
      "Ep:65, loss:0.00001, loss_test:0.01401, lr:5.43e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.535, tt:2015.287\n",
      "Ep:66, loss:0.00001, loss_test:0.01405, lr:5.37e-02, fs:0.79144 (r=0.747,p=0.841),  time:30.534, tt:2045.779\n",
      "Ep:67, loss:0.00001, loss_test:0.01402, lr:5.32e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.513, tt:2074.878\n",
      "Ep:68, loss:0.00001, loss_test:0.01417, lr:5.27e-02, fs:0.79144 (r=0.747,p=0.841),  time:30.508, tt:2105.021\n",
      "Ep:69, loss:0.00001, loss_test:0.01415, lr:5.21e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.491, tt:2134.394\n",
      "Ep:70, loss:0.00001, loss_test:0.01412, lr:5.16e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.491, tt:2164.882\n",
      "Ep:71, loss:0.00001, loss_test:0.01427, lr:5.11e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.478, tt:2194.414\n",
      "Ep:72, loss:0.00001, loss_test:0.01425, lr:5.06e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.472, tt:2224.481\n",
      "Ep:73, loss:0.00001, loss_test:0.01430, lr:5.01e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.449, tt:2253.242\n",
      "Ep:74, loss:0.00001, loss_test:0.01429, lr:4.96e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.441, tt:2283.069\n",
      "Ep:75, loss:0.00001, loss_test:0.01429, lr:4.91e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.439, tt:2313.330\n",
      "Ep:76, loss:0.00001, loss_test:0.01437, lr:4.86e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.425, tt:2342.689\n",
      "Ep:77, loss:0.00001, loss_test:0.01437, lr:4.81e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.414, tt:2372.288\n",
      "Ep:78, loss:0.00001, loss_test:0.01440, lr:4.76e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.401, tt:2401.660\n",
      "Ep:79, loss:0.00001, loss_test:0.01442, lr:4.71e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.395, tt:2431.636\n",
      "Ep:80, loss:0.00001, loss_test:0.01457, lr:4.67e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.400, tt:2462.424\n",
      "Ep:81, loss:0.00001, loss_test:0.01458, lr:4.62e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.391, tt:2492.087\n",
      "Ep:82, loss:0.00001, loss_test:0.01455, lr:4.57e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.382, tt:2521.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.01456, lr:4.53e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.364, tt:2550.554\n",
      "Ep:84, loss:0.00001, loss_test:0.01466, lr:4.48e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.369, tt:2581.356\n",
      "Ep:85, loss:0.00001, loss_test:0.01471, lr:4.44e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.369, tt:2611.699\n",
      "Ep:86, loss:0.00001, loss_test:0.01466, lr:4.39e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.352, tt:2640.582\n",
      "Ep:87, loss:0.00001, loss_test:0.01469, lr:4.35e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.334, tt:2669.349\n",
      "Ep:88, loss:0.00001, loss_test:0.01475, lr:4.31e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.327, tt:2699.068\n",
      "Ep:89, loss:0.00001, loss_test:0.01476, lr:4.26e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.320, tt:2728.784\n",
      "Ep:90, loss:0.00001, loss_test:0.01479, lr:4.22e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.301, tt:2757.375\n",
      "Ep:91, loss:0.00001, loss_test:0.01498, lr:4.18e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.300, tt:2787.593\n",
      "Ep:92, loss:0.00001, loss_test:0.01477, lr:4.14e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.300, tt:2817.892\n",
      "Ep:93, loss:0.00001, loss_test:0.01482, lr:4.10e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.295, tt:2847.747\n",
      "Ep:94, loss:0.00001, loss_test:0.01506, lr:4.05e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.282, tt:2876.759\n",
      "Ep:95, loss:0.00001, loss_test:0.01491, lr:4.01e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.287, tt:2907.518\n",
      "Ep:96, loss:0.00001, loss_test:0.01490, lr:3.97e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.288, tt:2937.904\n",
      "Ep:97, loss:0.00001, loss_test:0.01515, lr:3.93e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.282, tt:2967.641\n",
      "Ep:98, loss:0.00001, loss_test:0.01503, lr:3.89e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.286, tt:2998.324\n",
      "Ep:99, loss:0.00001, loss_test:0.01504, lr:3.86e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.290, tt:3028.988\n",
      "Ep:100, loss:0.00000, loss_test:0.01506, lr:3.82e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.288, tt:3059.108\n",
      "Ep:101, loss:0.00000, loss_test:0.01521, lr:3.78e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.275, tt:3088.094\n",
      "Ep:102, loss:0.00000, loss_test:0.01518, lr:3.74e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.253, tt:3116.042\n",
      "Ep:103, loss:0.00000, loss_test:0.01518, lr:3.70e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.245, tt:3145.462\n",
      "Ep:104, loss:0.00000, loss_test:0.01522, lr:3.67e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.230, tt:3174.167\n",
      "Ep:105, loss:0.00000, loss_test:0.01534, lr:3.63e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.227, tt:3204.026\n",
      "Ep:106, loss:0.00000, loss_test:0.01528, lr:3.59e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.225, tt:3234.037\n",
      "Ep:107, loss:0.00000, loss_test:0.01523, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.220, tt:3263.797\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.01545, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.218, tt:3293.752\n",
      "Ep:109, loss:0.00000, loss_test:0.01549, lr:3.56e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.221, tt:3324.289\n",
      "Ep:110, loss:0.00000, loss_test:0.01535, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.224, tt:3354.912\n",
      "Ep:111, loss:0.00000, loss_test:0.01548, lr:3.56e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.212, tt:3383.775\n",
      "Ep:112, loss:0.00000, loss_test:0.01559, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.194, tt:3411.960\n",
      "Ep:113, loss:0.00000, loss_test:0.01556, lr:3.56e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.181, tt:3440.602\n",
      "Ep:114, loss:0.00000, loss_test:0.01557, lr:3.56e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.162, tt:3468.665\n",
      "Ep:115, loss:0.00000, loss_test:0.01565, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.154, tt:3497.850\n",
      "Ep:116, loss:0.00000, loss_test:0.01571, lr:3.56e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.148, tt:3527.362\n",
      "Ep:117, loss:0.00000, loss_test:0.01572, lr:3.56e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.150, tt:3557.701\n",
      "Ep:118, loss:0.00000, loss_test:0.01574, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.160, tt:3589.000\n",
      "Ep:119, loss:0.00000, loss_test:0.01589, lr:3.52e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.159, tt:3619.072\n",
      "Ep:120, loss:0.00000, loss_test:0.01587, lr:3.49e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.161, tt:3649.499\n",
      "Ep:121, loss:0.00000, loss_test:0.01588, lr:3.45e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.163, tt:3679.890\n",
      "Ep:122, loss:0.00000, loss_test:0.01594, lr:3.42e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.166, tt:3710.356\n",
      "Ep:123, loss:0.00000, loss_test:0.01594, lr:3.38e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.156, tt:3739.324\n",
      "Ep:124, loss:0.00000, loss_test:0.01604, lr:3.35e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.139, tt:3767.437\n",
      "Ep:125, loss:0.00000, loss_test:0.01610, lr:3.32e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.144, tt:3798.204\n",
      "Ep:126, loss:0.00000, loss_test:0.01608, lr:3.28e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.144, tt:3828.332\n",
      "Ep:127, loss:0.00000, loss_test:0.01614, lr:3.25e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.142, tt:3858.155\n",
      "Ep:128, loss:0.00000, loss_test:0.01613, lr:3.22e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.136, tt:3887.603\n",
      "Ep:129, loss:0.00000, loss_test:0.01629, lr:3.19e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.142, tt:3918.459\n",
      "Ep:130, loss:0.00000, loss_test:0.01629, lr:3.15e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.131, tt:3947.162\n",
      "Ep:131, loss:0.00000, loss_test:0.01627, lr:3.12e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.121, tt:3975.924\n",
      "Ep:132, loss:0.00000, loss_test:0.01635, lr:3.09e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.112, tt:4004.843\n",
      "Ep:133, loss:0.00000, loss_test:0.01640, lr:3.06e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.113, tt:4035.139\n",
      "Ep:134, loss:0.00000, loss_test:0.01643, lr:3.03e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.116, tt:4065.638\n",
      "Ep:135, loss:0.00000, loss_test:0.01646, lr:3.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.116, tt:4095.717\n",
      "Ep:136, loss:0.00000, loss_test:0.01655, lr:2.97e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.105, tt:4124.351\n",
      "Ep:137, loss:0.00000, loss_test:0.01655, lr:2.94e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.107, tt:4154.782\n",
      "Ep:138, loss:0.00000, loss_test:0.01659, lr:2.91e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.096, tt:4183.389\n",
      "Ep:139, loss:0.00000, loss_test:0.01661, lr:2.88e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.089, tt:4212.415\n",
      "Ep:140, loss:0.00000, loss_test:0.01672, lr:2.85e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.086, tt:4242.062\n",
      "Ep:141, loss:0.00000, loss_test:0.01681, lr:2.82e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.090, tt:4272.794\n",
      "Ep:142, loss:0.00000, loss_test:0.01678, lr:2.80e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.084, tt:4301.959\n",
      "Ep:143, loss:0.00000, loss_test:0.01677, lr:2.77e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.086, tt:4332.453\n",
      "Ep:144, loss:0.00000, loss_test:0.01685, lr:2.74e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.085, tt:4362.398\n",
      "Ep:145, loss:0.00000, loss_test:0.01694, lr:2.71e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.081, tt:4391.764\n",
      "Ep:146, loss:0.00000, loss_test:0.01695, lr:2.69e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.077, tt:4421.326\n",
      "Ep:147, loss:0.00000, loss_test:0.01697, lr:2.66e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.071, tt:4450.498\n",
      "Ep:148, loss:0.00000, loss_test:0.01708, lr:2.63e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.062, tt:4479.253\n",
      "Ep:149, loss:0.00000, loss_test:0.01705, lr:2.61e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.062, tt:4509.321\n",
      "Ep:150, loss:0.00000, loss_test:0.01707, lr:2.58e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.062, tt:4539.316\n",
      "Ep:151, loss:0.00000, loss_test:0.01720, lr:2.55e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.063, tt:4569.589\n",
      "Ep:152, loss:0.00000, loss_test:0.01714, lr:2.53e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.065, tt:4600.001\n",
      "Ep:153, loss:0.00000, loss_test:0.01714, lr:2.50e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.054, tt:4628.353\n",
      "Ep:154, loss:0.00000, loss_test:0.01729, lr:2.48e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.047, tt:4657.344\n",
      "Ep:155, loss:0.00000, loss_test:0.01730, lr:2.45e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.051, tt:4688.023\n",
      "Ep:156, loss:0.00000, loss_test:0.01730, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.053, tt:4718.335\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:157, loss:0.00000, loss_test:0.01735, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.053, tt:4748.321\n",
      "Ep:158, loss:0.00000, loss_test:0.01739, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.068, tt:4780.814\n",
      "Ep:159, loss:0.00000, loss_test:0.01740, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.075, tt:4812.071\n",
      "Ep:160, loss:0.00000, loss_test:0.01743, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.072, tt:4841.609\n",
      "Ep:161, loss:0.00000, loss_test:0.01751, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.078, tt:4872.592\n",
      "Ep:162, loss:0.00000, loss_test:0.01748, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.080, tt:4903.047\n",
      "Ep:163, loss:0.00000, loss_test:0.01751, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.079, tt:4933.011\n",
      "Ep:164, loss:0.00000, loss_test:0.01758, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.083, tt:4963.667\n",
      "Ep:165, loss:0.00000, loss_test:0.01760, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.081, tt:4993.526\n",
      "Ep:166, loss:0.00000, loss_test:0.01762, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.083, tt:5023.850\n",
      "Ep:167, loss:0.00000, loss_test:0.01774, lr:2.43e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.087, tt:5054.593\n",
      "Ep:168, loss:0.00000, loss_test:0.01773, lr:2.40e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.081, tt:5083.680\n",
      "Ep:169, loss:0.00000, loss_test:0.01769, lr:2.38e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.078, tt:5113.333\n",
      "Ep:170, loss:0.00000, loss_test:0.01783, lr:2.36e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.079, tt:5143.481\n",
      "Ep:171, loss:0.00000, loss_test:0.01782, lr:2.33e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.089, tt:5175.295\n",
      "Ep:172, loss:0.00000, loss_test:0.01790, lr:2.31e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.090, tt:5205.510\n",
      "Ep:173, loss:0.00000, loss_test:0.01793, lr:2.29e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.088, tt:5235.258\n",
      "Ep:174, loss:0.00000, loss_test:0.01797, lr:2.26e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.086, tt:5265.062\n",
      "Ep:175, loss:0.00000, loss_test:0.01797, lr:2.24e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.079, tt:5293.843\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00000, loss_test:0.01794, lr:2.24e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.080, tt:5324.188\n",
      "Ep:177, loss:0.00000, loss_test:0.01804, lr:2.24e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.077, tt:5353.671\n",
      "Ep:178, loss:0.00000, loss_test:0.01808, lr:2.24e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.077, tt:5383.853\n",
      "Ep:179, loss:0.00000, loss_test:0.01812, lr:2.24e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.076, tt:5413.725\n",
      "Ep:180, loss:0.00000, loss_test:0.01815, lr:2.24e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.075, tt:5443.596\n",
      "Ep:181, loss:0.00000, loss_test:0.01818, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.091, tt:5476.613\n",
      "##########Best model found so far##########\n",
      "Ep:182, loss:0.00000, loss_test:0.01820, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.089, tt:5506.231\n",
      "Ep:183, loss:0.00000, loss_test:0.01824, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.082, tt:5535.150\n",
      "Ep:184, loss:0.00000, loss_test:0.01832, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.084, tt:5565.469\n",
      "Ep:185, loss:0.00000, loss_test:0.01832, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.078, tt:5594.563\n",
      "Ep:186, loss:0.00000, loss_test:0.01835, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.072, tt:5623.457\n",
      "Ep:187, loss:0.00000, loss_test:0.01843, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.066, tt:5652.469\n",
      "Ep:188, loss:0.00000, loss_test:0.01843, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.055, tt:5680.300\n",
      "Ep:189, loss:0.00000, loss_test:0.01846, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.060, tt:5711.416\n",
      "Ep:190, loss:0.00000, loss_test:0.01854, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.052, tt:5739.884\n",
      "Ep:191, loss:0.00000, loss_test:0.01851, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.031, tt:5765.929\n",
      "Ep:192, loss:0.00000, loss_test:0.01856, lr:2.24e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.023, tt:5794.501\n",
      "Ep:193, loss:0.00000, loss_test:0.01859, lr:2.22e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.009, tt:5821.836\n",
      "Ep:194, loss:0.00000, loss_test:0.01863, lr:2.20e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.982, tt:5846.504\n",
      "Ep:195, loss:0.00000, loss_test:0.01866, lr:2.17e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.961, tt:5872.311\n",
      "Ep:196, loss:0.00000, loss_test:0.01867, lr:2.15e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.959, tt:5902.010\n",
      "Ep:197, loss:0.00000, loss_test:0.01873, lr:2.13e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.959, tt:5931.949\n",
      "Ep:198, loss:0.00000, loss_test:0.01872, lr:2.11e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.965, tt:5963.050\n",
      "Ep:199, loss:0.00000, loss_test:0.01876, lr:2.09e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.973, tt:5994.609\n",
      "Ep:200, loss:0.00000, loss_test:0.01883, lr:2.07e-02, fs:0.82955 (r=0.737,p=0.948),  time:29.976, tt:6025.094\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12671, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:29.100, tt:29.100\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12199, lr:1.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:29.195, tt:58.390\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11550, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:30.484, tt:91.452\n",
      "Ep:3, loss:0.00026, loss_test:0.10912, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:30.351, tt:121.405\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.10468, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:30.523, tt:152.614\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.10164, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:30.877, tt:185.264\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.09912, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:30.502, tt:213.512\n",
      "Ep:7, loss:0.00024, loss_test:0.09847, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:30.414, tt:243.311\n",
      "Ep:8, loss:0.00023, loss_test:0.09791, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:30.509, tt:274.578\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.09725, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:30.378, tt:303.775\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.09647, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:30.162, tt:331.785\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.09575, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:30.161, tt:361.930\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09482, lr:1.00e-02, fs:0.75000 (r=0.848,p=0.672),  time:30.219, tt:392.852\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.09402, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:30.157, tt:422.197\n",
      "Ep:14, loss:0.00020, loss_test:0.09342, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:30.160, tt:452.393\n",
      "Ep:15, loss:0.00020, loss_test:0.09293, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:30.075, tt:481.197\n",
      "Ep:16, loss:0.00020, loss_test:0.09281, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:30.003, tt:510.044\n",
      "Ep:17, loss:0.00019, loss_test:0.09242, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:29.986, tt:539.743\n",
      "Ep:18, loss:0.00018, loss_test:0.09237, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:30.063, tt:571.205\n",
      "Ep:19, loss:0.00018, loss_test:0.09156, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:30.097, tt:601.945\n",
      "Ep:20, loss:0.00017, loss_test:0.09082, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:30.128, tt:632.697\n",
      "Ep:21, loss:0.00017, loss_test:0.08973, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:30.190, tt:664.188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00016, loss_test:0.08950, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:30.204, tt:694.687\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08775, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:30.263, tt:726.309\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08595, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.312, tt:757.806\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08556, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.337, tt:788.775\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08540, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:30.319, tt:818.619\n",
      "Ep:27, loss:0.00014, loss_test:0.08345, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.332, tt:849.282\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08237, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.304, tt:878.811\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08199, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.331, tt:909.945\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08191, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.404, tt:942.523\n",
      "Ep:31, loss:0.00012, loss_test:0.08099, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.429, tt:973.726\n",
      "Ep:32, loss:0.00011, loss_test:0.07867, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.426, tt:1004.050\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08258, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.467, tt:1035.886\n",
      "Ep:34, loss:0.00011, loss_test:0.08166, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.527, tt:1068.457\n",
      "Ep:35, loss:0.00010, loss_test:0.07844, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.513, tt:1098.481\n",
      "Ep:36, loss:0.00009, loss_test:0.07936, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.525, tt:1129.440\n",
      "Ep:37, loss:0.00009, loss_test:0.07862, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.573, tt:1161.771\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08100, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.608, tt:1193.729\n",
      "Ep:39, loss:0.00008, loss_test:0.07882, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.629, tt:1225.152\n",
      "Ep:40, loss:0.00008, loss_test:0.07986, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.639, tt:1256.191\n",
      "Ep:41, loss:0.00008, loss_test:0.08026, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.656, tt:1287.531\n",
      "Ep:42, loss:0.00007, loss_test:0.08039, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.673, tt:1318.954\n",
      "Ep:43, loss:0.00007, loss_test:0.07695, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.694, tt:1350.538\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.07790, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.712, tt:1382.058\n",
      "Ep:45, loss:0.00007, loss_test:0.08442, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.755, tt:1414.741\n",
      "Ep:46, loss:0.00007, loss_test:0.08031, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.764, tt:1445.890\n",
      "Ep:47, loss:0.00006, loss_test:0.07482, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.783, tt:1477.576\n",
      "Ep:48, loss:0.00007, loss_test:0.08546, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.793, tt:1508.875\n",
      "Ep:49, loss:0.00007, loss_test:0.07710, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.803, tt:1540.146\n",
      "Ep:50, loss:0.00006, loss_test:0.08021, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.787, tt:1570.134\n",
      "Ep:51, loss:0.00006, loss_test:0.07678, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:30.808, tt:1602.028\n",
      "Ep:52, loss:0.00006, loss_test:0.07725, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.840, tt:1634.524\n",
      "Ep:53, loss:0.00005, loss_test:0.07807, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.833, tt:1664.991\n",
      "Ep:54, loss:0.00005, loss_test:0.07596, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.854, tt:1696.995\n",
      "Ep:55, loss:0.00005, loss_test:0.07623, lr:9.90e-03, fs:0.81111 (r=0.737,p=0.901),  time:30.854, tt:1727.826\n",
      "Ep:56, loss:0.00005, loss_test:0.07253, lr:9.80e-03, fs:0.89005 (r=0.859,p=0.924),  time:30.883, tt:1760.315\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.07797, lr:9.80e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.892, tt:1791.752\n",
      "Ep:58, loss:0.00004, loss_test:0.07582, lr:9.80e-03, fs:0.81768 (r=0.747,p=0.902),  time:30.872, tt:1821.440\n",
      "Ep:59, loss:0.00004, loss_test:0.07574, lr:9.80e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.889, tt:1853.319\n",
      "Ep:60, loss:0.00004, loss_test:0.07473, lr:9.80e-03, fs:0.79545 (r=0.707,p=0.909),  time:30.887, tt:1884.131\n",
      "Ep:61, loss:0.00004, loss_test:0.07493, lr:9.80e-03, fs:0.80663 (r=0.737,p=0.890),  time:30.896, tt:1915.562\n",
      "Ep:62, loss:0.00004, loss_test:0.07548, lr:9.80e-03, fs:0.80000 (r=0.707,p=0.921),  time:30.902, tt:1946.838\n",
      "Ep:63, loss:0.00004, loss_test:0.07698, lr:9.80e-03, fs:0.79096 (r=0.707,p=0.897),  time:30.910, tt:1978.245\n",
      "Ep:64, loss:0.00003, loss_test:0.07492, lr:9.80e-03, fs:0.80000 (r=0.727,p=0.889),  time:30.912, tt:2009.294\n",
      "Ep:65, loss:0.00003, loss_test:0.07544, lr:9.80e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.944, tt:2042.287\n",
      "Ep:66, loss:0.00003, loss_test:0.07576, lr:9.80e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.968, tt:2074.823\n",
      "Ep:67, loss:0.00003, loss_test:0.07787, lr:9.80e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.984, tt:2106.894\n",
      "Ep:68, loss:0.00003, loss_test:0.07461, lr:9.70e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.012, tt:2139.796\n",
      "Ep:69, loss:0.00003, loss_test:0.07588, lr:9.61e-03, fs:0.78889 (r=0.717,p=0.877),  time:31.008, tt:2170.526\n",
      "Ep:70, loss:0.00003, loss_test:0.07542, lr:9.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.003, tt:2201.186\n",
      "Ep:71, loss:0.00003, loss_test:0.07673, lr:9.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.001, tt:2232.090\n",
      "Ep:72, loss:0.00003, loss_test:0.07660, lr:9.32e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.014, tt:2264.011\n",
      "Ep:73, loss:0.00003, loss_test:0.07573, lr:9.23e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.017, tt:2295.254\n",
      "Ep:74, loss:0.00003, loss_test:0.07930, lr:9.14e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.003, tt:2325.221\n",
      "Ep:75, loss:0.00003, loss_test:0.07406, lr:9.04e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.015, tt:2357.124\n",
      "Ep:76, loss:0.00003, loss_test:0.07798, lr:8.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.026, tt:2389.029\n",
      "Ep:77, loss:0.00002, loss_test:0.07509, lr:8.86e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.038, tt:2420.949\n",
      "Ep:78, loss:0.00002, loss_test:0.07816, lr:8.78e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.045, tt:2452.584\n",
      "Ep:79, loss:0.00002, loss_test:0.07494, lr:8.69e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.055, tt:2484.396\n",
      "Ep:80, loss:0.00002, loss_test:0.07617, lr:8.60e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.073, tt:2516.941\n",
      "Ep:81, loss:0.00002, loss_test:0.07655, lr:8.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.070, tt:2547.767\n",
      "Ep:82, loss:0.00002, loss_test:0.07442, lr:8.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.076, tt:2579.330\n",
      "Ep:83, loss:0.00002, loss_test:0.07644, lr:8.35e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.080, tt:2610.757\n",
      "Ep:84, loss:0.00002, loss_test:0.07508, lr:8.26e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.080, tt:2641.790\n",
      "Ep:85, loss:0.00002, loss_test:0.07767, lr:8.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.079, tt:2672.818\n",
      "Ep:86, loss:0.00002, loss_test:0.07566, lr:8.10e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.086, tt:2704.489\n",
      "Ep:87, loss:0.00002, loss_test:0.07665, lr:8.02e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.088, tt:2735.765\n",
      "Ep:88, loss:0.00002, loss_test:0.07510, lr:7.94e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.107, tt:2768.536\n",
      "Ep:89, loss:0.00002, loss_test:0.07718, lr:7.86e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.120, tt:2800.788\n",
      "Ep:90, loss:0.00002, loss_test:0.07619, lr:7.78e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.128, tt:2832.642\n",
      "Ep:91, loss:0.00002, loss_test:0.07553, lr:7.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.138, tt:2864.706\n",
      "Ep:92, loss:0.00002, loss_test:0.07938, lr:7.62e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.148, tt:2896.729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00002, loss_test:0.07423, lr:7.55e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.144, tt:2927.492\n",
      "Ep:94, loss:0.00002, loss_test:0.08207, lr:7.47e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.139, tt:2958.177\n",
      "Ep:95, loss:0.00002, loss_test:0.07557, lr:7.40e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.108, tt:2986.335\n",
      "Ep:96, loss:0.00002, loss_test:0.08005, lr:7.32e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.110, tt:3017.682\n",
      "Ep:97, loss:0.00002, loss_test:0.07590, lr:7.25e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.107, tt:3048.449\n",
      "Ep:98, loss:0.00002, loss_test:0.08052, lr:7.18e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.111, tt:3079.976\n",
      "Ep:99, loss:0.00002, loss_test:0.07731, lr:7.11e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.113, tt:3111.255\n",
      "Ep:100, loss:0.00002, loss_test:0.07860, lr:7.03e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.117, tt:3142.818\n",
      "Ep:101, loss:0.00002, loss_test:0.07911, lr:6.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.108, tt:3173.062\n",
      "Ep:102, loss:0.00002, loss_test:0.07548, lr:6.89e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.126, tt:3205.961\n",
      "Ep:103, loss:0.00002, loss_test:0.07964, lr:6.83e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.130, tt:3237.524\n",
      "Ep:104, loss:0.00002, loss_test:0.07657, lr:6.76e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.148, tt:3270.539\n",
      "Ep:105, loss:0.00001, loss_test:0.07619, lr:6.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.144, tt:3301.286\n",
      "Ep:106, loss:0.00001, loss_test:0.07723, lr:6.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.152, tt:3333.306\n",
      "Ep:107, loss:0.00001, loss_test:0.07669, lr:6.56e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.172, tt:3366.600\n",
      "Ep:108, loss:0.00001, loss_test:0.07654, lr:6.49e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.166, tt:3397.119\n",
      "Ep:109, loss:0.00001, loss_test:0.07621, lr:6.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.173, tt:3428.987\n",
      "Ep:110, loss:0.00001, loss_test:0.07581, lr:6.36e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.204, tt:3463.642\n",
      "Ep:111, loss:0.00001, loss_test:0.07677, lr:6.30e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.211, tt:3495.595\n",
      "Ep:112, loss:0.00001, loss_test:0.07612, lr:6.24e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.216, tt:3527.354\n",
      "Ep:113, loss:0.00001, loss_test:0.07696, lr:6.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.227, tt:3559.881\n",
      "Ep:114, loss:0.00001, loss_test:0.07531, lr:6.11e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.236, tt:3592.152\n",
      "Ep:115, loss:0.00001, loss_test:0.07665, lr:6.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.239, tt:3623.709\n",
      "Ep:116, loss:0.00001, loss_test:0.07633, lr:5.99e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.249, tt:3656.183\n",
      "Ep:117, loss:0.00001, loss_test:0.07622, lr:5.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.261, tt:3688.781\n",
      "Ep:118, loss:0.00001, loss_test:0.07535, lr:5.87e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.268, tt:3720.920\n",
      "Ep:119, loss:0.00001, loss_test:0.07629, lr:5.81e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.270, tt:3752.359\n",
      "Ep:120, loss:0.00001, loss_test:0.07577, lr:5.75e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.271, tt:3783.735\n",
      "Ep:121, loss:0.00001, loss_test:0.07607, lr:5.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.275, tt:3815.523\n",
      "Ep:122, loss:0.00001, loss_test:0.07591, lr:5.64e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.282, tt:3847.656\n",
      "Ep:123, loss:0.00001, loss_test:0.07604, lr:5.58e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.288, tt:3879.739\n",
      "Ep:124, loss:0.00001, loss_test:0.07635, lr:5.53e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.291, tt:3911.346\n",
      "Ep:125, loss:0.00001, loss_test:0.07639, lr:5.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.295, tt:3943.113\n",
      "Ep:126, loss:0.00001, loss_test:0.07524, lr:5.42e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.300, tt:3975.092\n",
      "Ep:127, loss:0.00001, loss_test:0.07786, lr:5.36e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.313, tt:4008.005\n",
      "Ep:128, loss:0.00001, loss_test:0.07545, lr:5.31e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.318, tt:4040.071\n",
      "Ep:129, loss:0.00001, loss_test:0.07648, lr:5.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.334, tt:4073.426\n",
      "Ep:130, loss:0.00001, loss_test:0.07571, lr:5.20e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.347, tt:4106.446\n",
      "Ep:131, loss:0.00001, loss_test:0.07574, lr:5.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.345, tt:4137.565\n",
      "Ep:132, loss:0.00001, loss_test:0.07684, lr:5.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.363, tt:4171.323\n",
      "Ep:133, loss:0.00001, loss_test:0.07465, lr:5.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.360, tt:4202.267\n",
      "Ep:134, loss:0.00001, loss_test:0.07759, lr:5.00e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.366, tt:4234.354\n",
      "Ep:135, loss:0.00001, loss_test:0.07503, lr:4.95e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.369, tt:4266.185\n",
      "Ep:136, loss:0.00001, loss_test:0.07627, lr:4.90e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.374, tt:4298.222\n",
      "Ep:137, loss:0.00001, loss_test:0.07567, lr:4.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.374, tt:4329.650\n",
      "Ep:138, loss:0.00001, loss_test:0.07644, lr:4.80e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.371, tt:4360.529\n",
      "Ep:139, loss:0.00001, loss_test:0.07560, lr:4.75e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.372, tt:4392.100\n",
      "Ep:140, loss:0.00001, loss_test:0.07541, lr:4.71e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.377, tt:4424.115\n",
      "Ep:141, loss:0.00001, loss_test:0.07471, lr:4.66e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.382, tt:4456.251\n",
      "Ep:142, loss:0.00001, loss_test:0.07565, lr:4.61e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.393, tt:4489.206\n",
      "Ep:143, loss:0.00001, loss_test:0.07553, lr:4.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.377, tt:4518.239\n",
      "Ep:144, loss:0.00001, loss_test:0.07533, lr:4.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.370, tt:4548.614\n",
      "Ep:145, loss:0.00001, loss_test:0.07560, lr:4.48e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.355, tt:4577.882\n",
      "Ep:146, loss:0.00001, loss_test:0.07522, lr:4.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.363, tt:4610.342\n",
      "Ep:147, loss:0.00001, loss_test:0.07511, lr:4.39e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.366, tt:4642.176\n",
      "Ep:148, loss:0.00001, loss_test:0.07610, lr:4.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.366, tt:4673.492\n",
      "Ep:149, loss:0.00001, loss_test:0.07508, lr:4.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.382, tt:4707.282\n",
      "Ep:150, loss:0.00001, loss_test:0.07509, lr:4.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.386, tt:4739.314\n",
      "Ep:151, loss:0.00001, loss_test:0.07549, lr:4.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.394, tt:4771.932\n",
      "Ep:152, loss:0.00001, loss_test:0.07521, lr:4.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.402, tt:4804.567\n",
      "Ep:153, loss:0.00001, loss_test:0.07561, lr:4.13e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.407, tt:4836.691\n",
      "Ep:154, loss:0.00001, loss_test:0.07461, lr:4.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.418, tt:4869.734\n",
      "Ep:155, loss:0.00001, loss_test:0.07592, lr:4.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.416, tt:4900.912\n",
      "Ep:156, loss:0.00001, loss_test:0.07558, lr:4.01e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.424, tt:4933.556\n",
      "Ep:157, loss:0.00001, loss_test:0.07594, lr:3.97e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.427, tt:4965.445\n",
      "Ep:158, loss:0.00001, loss_test:0.07508, lr:3.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.423, tt:4996.316\n",
      "Ep:159, loss:0.00001, loss_test:0.07543, lr:3.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.428, tt:5028.550\n",
      "Ep:160, loss:0.00001, loss_test:0.07510, lr:3.85e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.435, tt:5061.084\n",
      "Ep:161, loss:0.00001, loss_test:0.07563, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.430, tt:5091.637\n",
      "Ep:162, loss:0.00001, loss_test:0.07489, lr:3.77e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.433, tt:5123.507\n",
      "Ep:163, loss:0.00001, loss_test:0.07557, lr:3.73e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.435, tt:5155.382\n",
      "Ep:164, loss:0.00001, loss_test:0.07465, lr:3.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.443, tt:5188.144\n",
      "Ep:165, loss:0.00001, loss_test:0.07564, lr:3.66e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.449, tt:5220.522\n",
      "Ep:166, loss:0.00001, loss_test:0.07447, lr:3.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.452, tt:5252.409\n",
      "Ep:167, loss:0.00001, loss_test:0.07615, lr:3.59e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.454, tt:5284.193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00001, loss_test:0.07469, lr:3.55e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.452, tt:5315.348\n",
      "Ep:169, loss:0.00001, loss_test:0.07512, lr:3.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.451, tt:5346.587\n",
      "Ep:170, loss:0.00001, loss_test:0.07553, lr:3.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.457, tt:5379.074\n",
      "Ep:171, loss:0.00001, loss_test:0.07464, lr:3.45e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.457, tt:5410.614\n",
      "Ep:172, loss:0.00001, loss_test:0.07593, lr:3.41e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.455, tt:5441.733\n",
      "Ep:173, loss:0.00001, loss_test:0.07443, lr:3.38e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.461, tt:5474.192\n",
      "Ep:174, loss:0.00001, loss_test:0.07606, lr:3.34e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.462, tt:5505.776\n",
      "Ep:175, loss:0.00001, loss_test:0.07533, lr:3.31e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.467, tt:5538.135\n",
      "Ep:176, loss:0.00001, loss_test:0.07539, lr:3.28e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.466, tt:5569.562\n",
      "Ep:177, loss:0.00001, loss_test:0.07556, lr:3.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.471, tt:5601.869\n",
      "Ep:178, loss:0.00001, loss_test:0.07406, lr:3.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.473, tt:5633.725\n",
      "Ep:179, loss:0.00001, loss_test:0.07543, lr:3.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.479, tt:5666.152\n",
      "Ep:180, loss:0.00001, loss_test:0.07456, lr:3.15e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.483, tt:5698.416\n",
      "Ep:181, loss:0.00001, loss_test:0.07565, lr:3.12e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.488, tt:5730.831\n",
      "Ep:182, loss:0.00001, loss_test:0.07463, lr:3.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.485, tt:5761.766\n",
      "Ep:183, loss:0.00001, loss_test:0.07560, lr:3.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.485, tt:5793.197\n",
      "Ep:184, loss:0.00001, loss_test:0.07503, lr:3.02e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.495, tt:5826.580\n",
      "Ep:185, loss:0.00001, loss_test:0.07516, lr:2.99e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.505, tt:5859.920\n",
      "Ep:186, loss:0.00001, loss_test:0.07504, lr:2.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.514, tt:5893.035\n",
      "Ep:187, loss:0.00001, loss_test:0.07497, lr:2.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.516, tt:5924.935\n",
      "Ep:188, loss:0.00001, loss_test:0.07478, lr:2.90e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.500, tt:5953.585\n",
      "Ep:189, loss:0.00001, loss_test:0.07498, lr:2.88e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.497, tt:5984.423\n",
      "Ep:190, loss:0.00001, loss_test:0.07415, lr:2.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.473, tt:6011.295\n",
      "Ep:191, loss:0.00001, loss_test:0.07551, lr:2.82e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.459, tt:6040.159\n",
      "Ep:192, loss:0.00001, loss_test:0.07485, lr:2.79e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.433, tt:6066.519\n",
      "Ep:193, loss:0.00001, loss_test:0.07536, lr:2.76e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.398, tt:6091.226\n",
      "Ep:194, loss:0.00001, loss_test:0.07494, lr:2.73e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.350, tt:6113.194\n",
      "Ep:195, loss:0.00001, loss_test:0.07480, lr:2.71e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.307, tt:6136.206\n",
      "Ep:196, loss:0.00001, loss_test:0.07453, lr:2.68e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.289, tt:6163.875\n",
      "Ep:197, loss:0.00001, loss_test:0.07529, lr:2.65e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.276, tt:6192.610\n",
      "Ep:198, loss:0.00001, loss_test:0.07445, lr:2.63e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.252, tt:6219.197\n",
      "Ep:199, loss:0.00001, loss_test:0.07586, lr:2.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.255, tt:6251.096\n",
      "Ep:200, loss:0.00001, loss_test:0.07479, lr:2.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.243, tt:6279.905\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.01918, lr:6.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:20.041, tt:20.041\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02218, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.612, tt:43.224\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02505, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.375, tt:73.125\n",
      "Ep:3, loss:0.00005, loss_test:0.02599, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.922, tt:111.688\n",
      "Ep:4, loss:0.00005, loss_test:0.02599, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.676, tt:153.379\n",
      "Ep:5, loss:0.00005, loss_test:0.02514, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.968, tt:191.810\n",
      "Ep:6, loss:0.00005, loss_test:0.02363, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.139, tt:231.972\n",
      "Ep:7, loss:0.00005, loss_test:0.02168, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:33.786, tt:270.287\n",
      "Ep:8, loss:0.00004, loss_test:0.01966, lr:6.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:34.766, tt:312.895\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01826, lr:6.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:35.308, tt:353.081\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01786, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:35.602, tt:391.624\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01786, lr:6.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:36.020, tt:432.242\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01741, lr:6.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:36.388, tt:473.050\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01677, lr:6.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:36.551, tt:511.707\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:36.788, tt:551.825\n",
      "Ep:15, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:36.935, tt:590.958\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:37.052, tt:629.887\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:37.364, tt:672.544\n",
      "Ep:18, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:37.484, tt:712.193\n",
      "Ep:19, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:37.557, tt:751.131\n",
      "Ep:20, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:37.613, tt:789.875\n",
      "Ep:21, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:37.758, tt:830.677\n",
      "Ep:22, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:37.895, tt:871.595\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:37.944, tt:910.648\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01545, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:38.016, tt:950.405\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:38.095, tt:990.466\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:38.193, tt:1031.201\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:38.289, tt:1072.083\n",
      "Ep:28, loss:0.00002, loss_test:0.01498, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:38.370, tt:1112.722\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:38.465, tt:1153.961\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:38.434, tt:1191.459\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:38.493, tt:1231.776\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:38.504, tt:1270.641\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01447, lr:6.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:38.527, tt:1309.908\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01437, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:38.565, tt:1349.788\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01428, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:38.633, tt:1390.777\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:38.627, tt:1429.210\n",
      "Ep:37, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:38.708, tt:1470.904\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:38.763, tt:1511.776\n",
      "Ep:39, loss:0.00001, loss_test:0.01394, lr:6.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:38.806, tt:1552.256\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.856, tt:1593.107\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01385, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.911, tt:1634.252\n",
      "Ep:42, loss:0.00001, loss_test:0.01381, lr:6.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:38.933, tt:1674.108\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01379, lr:6.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:38.968, tt:1714.601\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01376, lr:6.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:39.003, tt:1755.130\n",
      "Ep:45, loss:0.00001, loss_test:0.01372, lr:6.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:39.035, tt:1795.601\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01368, lr:6.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:39.131, tt:1839.170\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01366, lr:6.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:39.167, tt:1880.027\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01362, lr:6.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:39.188, tt:1920.222\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01358, lr:6.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:39.198, tt:1959.885\n",
      "Ep:50, loss:0.00001, loss_test:0.01355, lr:6.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:39.201, tt:1999.229\n",
      "Ep:51, loss:0.00001, loss_test:0.01352, lr:6.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:39.265, tt:2041.769\n",
      "Ep:52, loss:0.00001, loss_test:0.01350, lr:6.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:39.283, tt:2082.009\n",
      "Ep:53, loss:0.00001, loss_test:0.01347, lr:6.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:39.313, tt:2122.924\n",
      "Ep:54, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:39.489, tt:2171.911\n",
      "Ep:55, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:39.522, tt:2213.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00001, loss_test:0.01345, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:39.556, tt:2254.683\n",
      "Ep:57, loss:0.00001, loss_test:0.01344, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:39.559, tt:2294.445\n",
      "Ep:58, loss:0.00001, loss_test:0.01344, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:39.590, tt:2335.836\n",
      "Ep:59, loss:0.00001, loss_test:0.01342, lr:6.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:39.627, tt:2377.623\n",
      "Ep:60, loss:0.00001, loss_test:0.01339, lr:5.94e-02, fs:0.90155 (r=0.879,p=0.926),  time:39.658, tt:2419.113\n",
      "Ep:61, loss:0.00001, loss_test:0.01341, lr:5.88e-02, fs:0.90155 (r=0.879,p=0.926),  time:39.672, tt:2459.637\n",
      "Ep:62, loss:0.00001, loss_test:0.01340, lr:5.82e-02, fs:0.90155 (r=0.879,p=0.926),  time:39.665, tt:2498.894\n",
      "Ep:63, loss:0.00001, loss_test:0.01340, lr:5.76e-02, fs:0.90155 (r=0.879,p=0.926),  time:39.687, tt:2539.993\n",
      "Ep:64, loss:0.00001, loss_test:0.01343, lr:5.71e-02, fs:0.89583 (r=0.869,p=0.925),  time:39.732, tt:2582.587\n",
      "Ep:65, loss:0.00001, loss_test:0.01342, lr:5.65e-02, fs:0.89583 (r=0.869,p=0.925),  time:39.740, tt:2622.834\n",
      "Ep:66, loss:0.00001, loss_test:0.01342, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:39.748, tt:2663.124\n",
      "Ep:67, loss:0.00001, loss_test:0.01341, lr:5.54e-02, fs:0.89583 (r=0.869,p=0.925),  time:39.773, tt:2704.531\n",
      "Ep:68, loss:0.00001, loss_test:0.01340, lr:5.48e-02, fs:0.89005 (r=0.859,p=0.924),  time:39.750, tt:2742.727\n",
      "Ep:69, loss:0.00001, loss_test:0.01342, lr:5.43e-02, fs:0.89005 (r=0.859,p=0.924),  time:39.750, tt:2782.487\n",
      "Ep:70, loss:0.00001, loss_test:0.01342, lr:5.37e-02, fs:0.89005 (r=0.859,p=0.924),  time:39.749, tt:2822.191\n",
      "Ep:71, loss:0.00001, loss_test:0.01340, lr:5.32e-02, fs:0.89005 (r=0.859,p=0.924),  time:39.783, tt:2864.410\n",
      "Ep:72, loss:0.00001, loss_test:0.01342, lr:5.27e-02, fs:0.87831 (r=0.838,p=0.922),  time:39.822, tt:2907.012\n",
      "Ep:73, loss:0.00001, loss_test:0.01343, lr:5.21e-02, fs:0.87234 (r=0.828,p=0.921),  time:39.848, tt:2948.719\n",
      "Ep:74, loss:0.00001, loss_test:0.01345, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:39.851, tt:2988.835\n",
      "Ep:75, loss:0.00001, loss_test:0.01346, lr:5.11e-02, fs:0.86022 (r=0.808,p=0.920),  time:39.869, tt:3030.071\n",
      "Ep:76, loss:0.00001, loss_test:0.01345, lr:5.06e-02, fs:0.85405 (r=0.798,p=0.919),  time:39.888, tt:3071.403\n",
      "Ep:77, loss:0.00001, loss_test:0.01346, lr:5.01e-02, fs:0.84783 (r=0.788,p=0.918),  time:39.873, tt:3110.103\n",
      "Ep:78, loss:0.00001, loss_test:0.01348, lr:4.96e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.865, tt:3149.349\n",
      "Ep:79, loss:0.00001, loss_test:0.01349, lr:4.91e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.863, tt:3189.052\n",
      "Ep:80, loss:0.00001, loss_test:0.01348, lr:4.86e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.867, tt:3229.258\n",
      "Ep:81, loss:0.00001, loss_test:0.01349, lr:4.81e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.854, tt:3268.012\n",
      "Ep:82, loss:0.00001, loss_test:0.01352, lr:4.76e-02, fs:0.82222 (r=0.747,p=0.914),  time:39.869, tt:3309.088\n",
      "Ep:83, loss:0.00001, loss_test:0.01354, lr:4.71e-02, fs:0.82222 (r=0.747,p=0.914),  time:39.860, tt:3348.250\n",
      "Ep:84, loss:0.00001, loss_test:0.01357, lr:4.67e-02, fs:0.81356 (r=0.727,p=0.923),  time:39.849, tt:3387.126\n",
      "Ep:85, loss:0.00001, loss_test:0.01359, lr:4.62e-02, fs:0.81356 (r=0.727,p=0.923),  time:39.843, tt:3426.518\n",
      "Ep:86, loss:0.00001, loss_test:0.01360, lr:4.57e-02, fs:0.80682 (r=0.717,p=0.922),  time:39.837, tt:3465.809\n",
      "Ep:87, loss:0.00001, loss_test:0.01362, lr:4.53e-02, fs:0.80000 (r=0.707,p=0.921),  time:39.834, tt:3505.348\n",
      "Ep:88, loss:0.00001, loss_test:0.01361, lr:4.48e-02, fs:0.80000 (r=0.707,p=0.921),  time:39.830, tt:3544.825\n",
      "Ep:89, loss:0.00001, loss_test:0.01362, lr:4.44e-02, fs:0.80000 (r=0.707,p=0.921),  time:39.831, tt:3584.750\n",
      "Ep:90, loss:0.00001, loss_test:0.01364, lr:4.39e-02, fs:0.80000 (r=0.707,p=0.921),  time:39.857, tt:3626.984\n",
      "Ep:91, loss:0.00001, loss_test:0.01366, lr:4.35e-02, fs:0.80000 (r=0.707,p=0.921),  time:39.838, tt:3665.066\n",
      "Ep:92, loss:0.00001, loss_test:0.01368, lr:4.31e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.836, tt:3704.741\n",
      "Ep:93, loss:0.00001, loss_test:0.01370, lr:4.26e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.830, tt:3744.024\n",
      "Ep:94, loss:0.00000, loss_test:0.01371, lr:4.22e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.828, tt:3783.622\n",
      "Ep:95, loss:0.00000, loss_test:0.01374, lr:4.18e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.818, tt:3822.515\n",
      "Ep:96, loss:0.00000, loss_test:0.01376, lr:4.14e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.817, tt:3862.278\n",
      "Ep:97, loss:0.00000, loss_test:0.01378, lr:4.10e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.807, tt:3901.083\n",
      "Ep:98, loss:0.00000, loss_test:0.01379, lr:4.05e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.808, tt:3941.027\n",
      "Ep:99, loss:0.00000, loss_test:0.01380, lr:4.01e-02, fs:0.79532 (r=0.687,p=0.944),  time:39.812, tt:3981.160\n",
      "Ep:100, loss:0.00000, loss_test:0.01383, lr:3.97e-02, fs:0.79532 (r=0.687,p=0.944),  time:39.828, tt:4022.636\n",
      "Ep:101, loss:0.00000, loss_test:0.01384, lr:3.93e-02, fs:0.79532 (r=0.687,p=0.944),  time:39.825, tt:4062.187\n",
      "Ep:102, loss:0.00000, loss_test:0.01385, lr:3.89e-02, fs:0.79532 (r=0.687,p=0.944),  time:39.809, tt:4100.297\n",
      "Ep:103, loss:0.00000, loss_test:0.01386, lr:3.86e-02, fs:0.79532 (r=0.687,p=0.944),  time:39.795, tt:4138.699\n",
      "Ep:104, loss:0.00000, loss_test:0.01389, lr:3.82e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.796, tt:4178.563\n",
      "Ep:105, loss:0.00000, loss_test:0.01393, lr:3.78e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.805, tt:4219.361\n",
      "Ep:106, loss:0.00000, loss_test:0.01395, lr:3.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.805, tt:4259.116\n",
      "Ep:107, loss:0.00000, loss_test:0.01396, lr:3.70e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.805, tt:4298.917\n",
      "Ep:108, loss:0.00000, loss_test:0.01397, lr:3.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.799, tt:4338.073\n",
      "Ep:109, loss:0.00000, loss_test:0.01399, lr:3.63e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.808, tt:4378.909\n",
      "Ep:110, loss:0.00000, loss_test:0.01400, lr:3.59e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.803, tt:4418.104\n",
      "Ep:111, loss:0.00000, loss_test:0.01402, lr:3.56e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.814, tt:4459.163\n",
      "Ep:112, loss:0.00000, loss_test:0.01404, lr:3.52e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.844, tt:4502.402\n",
      "Ep:113, loss:0.00000, loss_test:0.01405, lr:3.49e-02, fs:0.78824 (r=0.677,p=0.944),  time:39.835, tt:4541.196\n",
      "Ep:114, loss:0.00000, loss_test:0.01407, lr:3.45e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.839, tt:4581.539\n",
      "Ep:115, loss:0.00000, loss_test:0.01409, lr:3.42e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.850, tt:4622.620\n",
      "Ep:116, loss:0.00000, loss_test:0.01412, lr:3.38e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.857, tt:4663.224\n",
      "Ep:117, loss:0.00000, loss_test:0.01414, lr:3.35e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.879, tt:4705.734\n",
      "Ep:118, loss:0.00000, loss_test:0.01416, lr:3.32e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.892, tt:4747.180\n",
      "Ep:119, loss:0.00000, loss_test:0.01417, lr:3.28e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.901, tt:4788.119\n",
      "Ep:120, loss:0.00000, loss_test:0.01418, lr:3.25e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.919, tt:4830.229\n",
      "Ep:121, loss:0.00000, loss_test:0.01419, lr:3.22e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.929, tt:4871.348\n",
      "Ep:122, loss:0.00000, loss_test:0.01421, lr:3.19e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.946, tt:4913.337\n",
      "Ep:123, loss:0.00000, loss_test:0.01424, lr:3.15e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.963, tt:4955.354\n",
      "Ep:124, loss:0.00000, loss_test:0.01425, lr:3.12e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.978, tt:4997.304\n",
      "Ep:125, loss:0.00000, loss_test:0.01427, lr:3.09e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.986, tt:5038.196\n",
      "Ep:126, loss:0.00000, loss_test:0.01429, lr:3.06e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.985, tt:5078.142\n",
      "Ep:127, loss:0.00000, loss_test:0.01431, lr:3.03e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.985, tt:5118.108\n",
      "Ep:128, loss:0.00000, loss_test:0.01433, lr:3.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:39.987, tt:5158.333\n",
      "Ep:129, loss:0.00000, loss_test:0.01436, lr:2.97e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.965, tt:5195.444\n",
      "Ep:130, loss:0.00000, loss_test:0.01437, lr:2.94e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.967, tt:5235.678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.01439, lr:2.91e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.975, tt:5276.728\n",
      "Ep:132, loss:0.00000, loss_test:0.01440, lr:2.88e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.983, tt:5317.708\n",
      "Ep:133, loss:0.00000, loss_test:0.01442, lr:2.85e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.977, tt:5356.947\n",
      "Ep:134, loss:0.00000, loss_test:0.01442, lr:2.82e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.978, tt:5397.010\n",
      "Ep:135, loss:0.00000, loss_test:0.01444, lr:2.80e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.967, tt:5435.453\n",
      "Ep:136, loss:0.00000, loss_test:0.01445, lr:2.77e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.955, tt:5473.817\n",
      "Ep:137, loss:0.00000, loss_test:0.01447, lr:2.74e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.952, tt:5513.427\n",
      "Ep:138, loss:0.00000, loss_test:0.01449, lr:2.71e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.955, tt:5553.687\n",
      "Ep:139, loss:0.00000, loss_test:0.01450, lr:2.69e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.968, tt:5595.550\n",
      "Ep:140, loss:0.00000, loss_test:0.01451, lr:2.66e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.963, tt:5634.785\n",
      "Ep:141, loss:0.00000, loss_test:0.01453, lr:2.63e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.953, tt:5673.324\n",
      "Ep:142, loss:0.00000, loss_test:0.01454, lr:2.61e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.956, tt:5713.682\n",
      "Ep:143, loss:0.00000, loss_test:0.01454, lr:2.58e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.945, tt:5752.095\n",
      "Ep:144, loss:0.00000, loss_test:0.01456, lr:2.55e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.942, tt:5791.607\n",
      "Ep:145, loss:0.00000, loss_test:0.01458, lr:2.53e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.960, tt:5834.214\n",
      "Ep:146, loss:0.00000, loss_test:0.01459, lr:2.50e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.950, tt:5872.692\n",
      "Ep:147, loss:0.00000, loss_test:0.01461, lr:2.48e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.948, tt:5912.338\n",
      "Ep:148, loss:0.00000, loss_test:0.01462, lr:2.45e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.944, tt:5951.717\n",
      "Ep:149, loss:0.00000, loss_test:0.01464, lr:2.43e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.949, tt:5992.283\n",
      "Ep:150, loss:0.00000, loss_test:0.01465, lr:2.40e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.949, tt:6032.229\n",
      "Ep:151, loss:0.00000, loss_test:0.01467, lr:2.38e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.950, tt:6072.384\n",
      "Ep:152, loss:0.00000, loss_test:0.01469, lr:2.36e-02, fs:0.78571 (r=0.667,p=0.957),  time:39.953, tt:6112.835\n",
      "Ep:153, loss:0.00000, loss_test:0.01470, lr:2.33e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.949, tt:6152.195\n",
      "Ep:154, loss:0.00000, loss_test:0.01471, lr:2.31e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.936, tt:6190.031\n",
      "Ep:155, loss:0.00000, loss_test:0.01472, lr:2.29e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.935, tt:6229.846\n",
      "Ep:156, loss:0.00000, loss_test:0.01473, lr:2.26e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.943, tt:6271.121\n",
      "Ep:157, loss:0.00000, loss_test:0.01475, lr:2.24e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.940, tt:6310.496\n",
      "Ep:158, loss:0.00000, loss_test:0.01476, lr:2.22e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.977, tt:6356.307\n",
      "Ep:159, loss:0.00000, loss_test:0.01477, lr:2.20e-02, fs:0.79042 (r=0.667,p=0.971),  time:39.991, tt:6398.492\n",
      "Ep:160, loss:0.00000, loss_test:0.01478, lr:2.17e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.002, tt:6440.360\n",
      "Ep:161, loss:0.00000, loss_test:0.01480, lr:2.15e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.001, tt:6480.083\n",
      "Ep:162, loss:0.00000, loss_test:0.01481, lr:2.13e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.016, tt:6522.579\n",
      "Ep:163, loss:0.00000, loss_test:0.01481, lr:2.11e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.017, tt:6562.722\n",
      "Ep:164, loss:0.00000, loss_test:0.01483, lr:2.09e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.019, tt:6603.097\n",
      "Ep:165, loss:0.00000, loss_test:0.01484, lr:2.07e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.030, tt:6645.030\n",
      "Ep:166, loss:0.00000, loss_test:0.01486, lr:2.05e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.043, tt:6687.116\n",
      "Ep:167, loss:0.00000, loss_test:0.01487, lr:2.03e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.048, tt:6728.041\n",
      "Ep:168, loss:0.00000, loss_test:0.01489, lr:2.01e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.048, tt:6768.154\n",
      "Ep:169, loss:0.00000, loss_test:0.01490, lr:1.99e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.057, tt:6809.733\n",
      "Ep:170, loss:0.00000, loss_test:0.01491, lr:1.97e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.051, tt:6848.739\n",
      "Ep:171, loss:0.00000, loss_test:0.01492, lr:1.95e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.049, tt:6888.387\n",
      "Ep:172, loss:0.00000, loss_test:0.01493, lr:1.93e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.057, tt:6929.786\n",
      "Ep:173, loss:0.00000, loss_test:0.01495, lr:1.91e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.060, tt:6970.503\n",
      "Ep:174, loss:0.00000, loss_test:0.01495, lr:1.89e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.054, tt:7009.385\n",
      "Ep:175, loss:0.00000, loss_test:0.01497, lr:1.87e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.055, tt:7049.651\n",
      "Ep:176, loss:0.00000, loss_test:0.01498, lr:1.85e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.055, tt:7089.693\n",
      "Ep:177, loss:0.00000, loss_test:0.01499, lr:1.83e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.042, tt:7127.498\n",
      "Ep:178, loss:0.00000, loss_test:0.01501, lr:1.81e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.046, tt:7168.154\n",
      "Ep:179, loss:0.00000, loss_test:0.01501, lr:1.80e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.054, tt:7209.776\n",
      "Ep:180, loss:0.00000, loss_test:0.01502, lr:1.78e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.051, tt:7249.156\n",
      "Ep:181, loss:0.00000, loss_test:0.01503, lr:1.76e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.056, tt:7290.176\n",
      "Ep:182, loss:0.00000, loss_test:0.01504, lr:1.74e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.057, tt:7330.375\n",
      "Ep:183, loss:0.00000, loss_test:0.01505, lr:1.73e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.061, tt:7371.178\n",
      "Ep:184, loss:0.00000, loss_test:0.01506, lr:1.71e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.063, tt:7411.724\n",
      "Ep:185, loss:0.00000, loss_test:0.01506, lr:1.69e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.067, tt:7452.486\n",
      "Ep:186, loss:0.00000, loss_test:0.01507, lr:1.67e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.061, tt:7491.389\n",
      "Ep:187, loss:0.00000, loss_test:0.01508, lr:1.66e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.062, tt:7531.605\n",
      "Ep:188, loss:0.00000, loss_test:0.01509, lr:1.64e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.049, tt:7569.300\n",
      "Ep:189, loss:0.00000, loss_test:0.01511, lr:1.62e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.052, tt:7609.926\n",
      "Ep:190, loss:0.00000, loss_test:0.01512, lr:1.61e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.057, tt:7650.842\n",
      "Ep:191, loss:0.00000, loss_test:0.01513, lr:1.59e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.059, tt:7691.334\n",
      "Ep:192, loss:0.00000, loss_test:0.01514, lr:1.58e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.061, tt:7731.862\n",
      "Ep:193, loss:0.00000, loss_test:0.01514, lr:1.56e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.061, tt:7771.797\n",
      "Ep:194, loss:0.00000, loss_test:0.01515, lr:1.54e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.065, tt:7812.600\n",
      "Ep:195, loss:0.00000, loss_test:0.01516, lr:1.53e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.062, tt:7852.158\n",
      "Ep:196, loss:0.00000, loss_test:0.01517, lr:1.51e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.068, tt:7893.463\n",
      "Ep:197, loss:0.00000, loss_test:0.01518, lr:1.50e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.073, tt:7934.514\n",
      "Ep:198, loss:0.00000, loss_test:0.01519, lr:1.48e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.070, tt:7973.909\n",
      "Ep:199, loss:0.00000, loss_test:0.01520, lr:1.47e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.095, tt:8018.932\n",
      "Ep:200, loss:0.00000, loss_test:0.01520, lr:1.45e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.105, tt:8061.013\n",
      "Ep:201, loss:0.00000, loss_test:0.01521, lr:1.44e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.091, tt:8098.460\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13604, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.166, tt:33.166\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13374, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.031, tt:62.062\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12951, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:35.246, tt:105.738\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12268, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:36.714, tt:146.855\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11461, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:37.644, tt:188.221\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10950, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:38.019, tt:228.114\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10731, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:38.603, tt:270.221\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10514, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:38.912, tt:311.297\n",
      "Ep:8, loss:0.00021, loss_test:0.10448, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:39.108, tt:351.969\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10325, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:39.371, tt:393.711\n",
      "Ep:10, loss:0.00019, loss_test:0.10245, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:39.283, tt:432.111\n",
      "Ep:11, loss:0.00018, loss_test:0.10137, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:39.504, tt:474.046\n",
      "Ep:12, loss:0.00017, loss_test:0.10054, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:39.588, tt:514.645\n",
      "Ep:13, loss:0.00017, loss_test:0.09915, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:39.788, tt:557.030\n",
      "Ep:14, loss:0.00016, loss_test:0.09743, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:39.885, tt:598.272\n",
      "Ep:15, loss:0.00015, loss_test:0.09540, lr:1.00e-02, fs:0.72414 (r=0.636,p=0.840),  time:40.126, tt:642.020\n",
      "Ep:16, loss:0.00014, loss_test:0.09365, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:40.275, tt:684.668\n",
      "Ep:17, loss:0.00014, loss_test:0.09158, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.527, tt:729.483\n",
      "Ep:18, loss:0.00013, loss_test:0.08996, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:40.519, tt:769.866\n",
      "Ep:19, loss:0.00012, loss_test:0.08870, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:40.633, tt:812.669\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.08713, lr:1.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:40.675, tt:854.183\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.08666, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:40.720, tt:895.831\n",
      "Ep:22, loss:0.00010, loss_test:0.08544, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:40.670, tt:935.402\n",
      "Ep:23, loss:0.00010, loss_test:0.08397, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:40.754, tt:978.085\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00009, loss_test:0.08369, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:40.761, tt:1019.020\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.08280, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:40.797, tt:1060.724\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00008, loss_test:0.08186, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:40.803, tt:1101.693\n",
      "Ep:27, loss:0.00008, loss_test:0.08152, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:40.798, tt:1142.350\n",
      "Ep:28, loss:0.00008, loss_test:0.08150, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:40.754, tt:1181.856\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00007, loss_test:0.08136, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:40.776, tt:1223.274\n",
      "Ep:30, loss:0.00007, loss_test:0.08150, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:40.818, tt:1265.344\n",
      "Ep:31, loss:0.00007, loss_test:0.08062, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:40.867, tt:1307.740\n",
      "Ep:32, loss:0.00006, loss_test:0.08047, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:40.911, tt:1350.052\n",
      "Ep:33, loss:0.00006, loss_test:0.08048, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:40.982, tt:1393.383\n",
      "Ep:34, loss:0.00006, loss_test:0.07990, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:40.987, tt:1434.545\n",
      "Ep:35, loss:0.00005, loss_test:0.08168, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:40.934, tt:1473.613\n",
      "Ep:36, loss:0.00005, loss_test:0.07962, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:40.886, tt:1512.787\n",
      "Ep:37, loss:0.00005, loss_test:0.07966, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:40.860, tt:1552.682\n",
      "Ep:38, loss:0.00005, loss_test:0.08071, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:40.885, tt:1594.521\n",
      "Ep:39, loss:0.00005, loss_test:0.07925, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:40.867, tt:1634.671\n",
      "Ep:40, loss:0.00004, loss_test:0.07963, lr:9.90e-03, fs:0.77714 (r=0.687,p=0.895),  time:40.902, tt:1676.990\n",
      "Ep:41, loss:0.00004, loss_test:0.07964, lr:9.80e-03, fs:0.78409 (r=0.697,p=0.896),  time:40.868, tt:1716.462\n",
      "Ep:42, loss:0.00004, loss_test:0.07892, lr:9.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:40.892, tt:1758.341\n",
      "Ep:43, loss:0.00004, loss_test:0.07841, lr:9.61e-03, fs:0.80899 (r=0.727,p=0.911),  time:40.899, tt:1799.564\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.07983, lr:9.61e-03, fs:0.79545 (r=0.707,p=0.909),  time:40.910, tt:1840.932\n",
      "Ep:45, loss:0.00004, loss_test:0.07788, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:40.897, tt:1881.284\n",
      "Ep:46, loss:0.00003, loss_test:0.07858, lr:9.61e-03, fs:0.78857 (r=0.697,p=0.908),  time:40.891, tt:1921.866\n",
      "Ep:47, loss:0.00003, loss_test:0.07984, lr:9.61e-03, fs:0.78161 (r=0.687,p=0.907),  time:40.884, tt:1962.425\n",
      "Ep:48, loss:0.00003, loss_test:0.07741, lr:9.61e-03, fs:0.81564 (r=0.737,p=0.912),  time:40.858, tt:2002.066\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.07838, lr:9.61e-03, fs:0.77457 (r=0.677,p=0.905),  time:40.880, tt:2043.976\n",
      "Ep:50, loss:0.00003, loss_test:0.07916, lr:9.61e-03, fs:0.77457 (r=0.677,p=0.905),  time:40.885, tt:2085.131\n",
      "Ep:51, loss:0.00003, loss_test:0.07741, lr:9.61e-03, fs:0.77907 (r=0.677,p=0.918),  time:40.910, tt:2127.295\n",
      "Ep:52, loss:0.00003, loss_test:0.07795, lr:9.61e-03, fs:0.77907 (r=0.677,p=0.918),  time:40.914, tt:2168.420\n",
      "Ep:53, loss:0.00003, loss_test:0.07932, lr:9.61e-03, fs:0.74699 (r=0.626,p=0.925),  time:40.912, tt:2209.266\n",
      "Ep:54, loss:0.00003, loss_test:0.07645, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:40.884, tt:2248.598\n",
      "Ep:55, loss:0.00002, loss_test:0.08111, lr:9.61e-03, fs:0.74251 (r=0.626,p=0.912),  time:40.915, tt:2291.261\n",
      "Ep:56, loss:0.00002, loss_test:0.07935, lr:9.61e-03, fs:0.74251 (r=0.626,p=0.912),  time:40.937, tt:2333.411\n",
      "Ep:57, loss:0.00002, loss_test:0.07843, lr:9.61e-03, fs:0.74699 (r=0.626,p=0.925),  time:40.990, tt:2377.410\n",
      "Ep:58, loss:0.00002, loss_test:0.08185, lr:9.61e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.013, tt:2419.753\n",
      "Ep:59, loss:0.00002, loss_test:0.07846, lr:9.61e-03, fs:0.74251 (r=0.626,p=0.912),  time:41.040, tt:2462.382\n",
      "Ep:60, loss:0.00002, loss_test:0.07976, lr:9.51e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.076, tt:2505.641\n",
      "Ep:61, loss:0.00002, loss_test:0.08047, lr:9.41e-03, fs:0.74251 (r=0.626,p=0.912),  time:41.083, tt:2547.136\n",
      "Ep:62, loss:0.00002, loss_test:0.07823, lr:9.32e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.079, tt:2587.994\n",
      "Ep:63, loss:0.00002, loss_test:0.07922, lr:9.23e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.088, tt:2629.654\n",
      "Ep:64, loss:0.00002, loss_test:0.08023, lr:9.14e-03, fs:0.74251 (r=0.626,p=0.912),  time:41.115, tt:2672.484\n",
      "Ep:65, loss:0.00002, loss_test:0.07936, lr:9.04e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.119, tt:2713.839\n",
      "Ep:66, loss:0.00002, loss_test:0.07896, lr:8.95e-03, fs:0.74251 (r=0.626,p=0.912),  time:41.162, tt:2757.874\n",
      "Ep:67, loss:0.00002, loss_test:0.07951, lr:8.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.161, tt:2798.921\n",
      "Ep:68, loss:0.00002, loss_test:0.07927, lr:8.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.177, tt:2841.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00002, loss_test:0.07979, lr:8.69e-03, fs:0.74251 (r=0.626,p=0.912),  time:41.211, tt:2884.763\n",
      "Ep:70, loss:0.00002, loss_test:0.07984, lr:8.60e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.206, tt:2925.626\n",
      "Ep:71, loss:0.00002, loss_test:0.07894, lr:8.51e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.229, tt:2968.485\n",
      "Ep:72, loss:0.00001, loss_test:0.08122, lr:8.43e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.265, tt:3012.348\n",
      "Ep:73, loss:0.00001, loss_test:0.08081, lr:8.35e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.258, tt:3053.063\n",
      "Ep:74, loss:0.00001, loss_test:0.07796, lr:8.26e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.262, tt:3094.631\n",
      "Ep:75, loss:0.00001, loss_test:0.08131, lr:8.18e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.274, tt:3136.821\n",
      "Ep:76, loss:0.00001, loss_test:0.08241, lr:8.10e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.278, tt:3178.443\n",
      "Ep:77, loss:0.00001, loss_test:0.07885, lr:8.02e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.296, tt:3221.054\n",
      "Ep:78, loss:0.00001, loss_test:0.07910, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.307, tt:3263.270\n",
      "Ep:79, loss:0.00001, loss_test:0.08113, lr:7.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.301, tt:3304.078\n",
      "Ep:80, loss:0.00001, loss_test:0.08061, lr:7.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.317, tt:3346.668\n",
      "Ep:81, loss:0.00001, loss_test:0.07933, lr:7.70e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.335, tt:3389.485\n",
      "Ep:82, loss:0.00001, loss_test:0.07982, lr:7.62e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.346, tt:3431.690\n",
      "Ep:83, loss:0.00001, loss_test:0.07990, lr:7.55e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.347, tt:3473.184\n",
      "Ep:84, loss:0.00001, loss_test:0.07983, lr:7.47e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.350, tt:3514.742\n",
      "Ep:85, loss:0.00001, loss_test:0.08100, lr:7.40e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.408, tt:3561.077\n",
      "Ep:86, loss:0.00001, loss_test:0.07976, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.499, tt:3610.396\n",
      "Ep:87, loss:0.00001, loss_test:0.07920, lr:7.25e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.535, tt:3655.122\n",
      "Ep:88, loss:0.00001, loss_test:0.08051, lr:7.18e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.583, tt:3700.845\n",
      "Ep:89, loss:0.00001, loss_test:0.08075, lr:7.11e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.609, tt:3744.852\n",
      "Ep:90, loss:0.00001, loss_test:0.07931, lr:7.03e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.634, tt:3788.687\n",
      "Ep:91, loss:0.00001, loss_test:0.07983, lr:6.96e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.646, tt:3831.425\n",
      "Ep:92, loss:0.00001, loss_test:0.08071, lr:6.89e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.674, tt:3875.672\n",
      "Ep:93, loss:0.00001, loss_test:0.08026, lr:6.83e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.705, tt:3920.301\n",
      "Ep:94, loss:0.00001, loss_test:0.08047, lr:6.76e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.713, tt:3962.776\n",
      "Ep:95, loss:0.00001, loss_test:0.08100, lr:6.69e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.738, tt:4006.844\n",
      "Ep:96, loss:0.00001, loss_test:0.08020, lr:6.62e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.757, tt:4050.474\n",
      "Ep:97, loss:0.00001, loss_test:0.08052, lr:6.56e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.793, tt:4095.676\n",
      "Ep:98, loss:0.00001, loss_test:0.08163, lr:6.49e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.801, tt:4138.253\n",
      "Ep:99, loss:0.00001, loss_test:0.08103, lr:6.43e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.815, tt:4181.452\n",
      "Ep:100, loss:0.00001, loss_test:0.08040, lr:6.36e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.850, tt:4226.811\n",
      "Ep:101, loss:0.00001, loss_test:0.08091, lr:6.30e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.856, tt:4269.345\n",
      "Ep:102, loss:0.00001, loss_test:0.08133, lr:6.24e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.849, tt:4310.483\n",
      "Ep:103, loss:0.00001, loss_test:0.08126, lr:6.17e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.861, tt:4353.566\n",
      "Ep:104, loss:0.00001, loss_test:0.08124, lr:6.11e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.870, tt:4396.297\n",
      "Ep:105, loss:0.00001, loss_test:0.08153, lr:6.05e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.913, tt:4442.825\n",
      "Ep:106, loss:0.00001, loss_test:0.08161, lr:5.99e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.922, tt:4485.669\n",
      "Ep:107, loss:0.00001, loss_test:0.08121, lr:5.93e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.926, tt:4527.999\n",
      "Ep:108, loss:0.00001, loss_test:0.08211, lr:5.87e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.938, tt:4571.266\n",
      "Ep:109, loss:0.00001, loss_test:0.08242, lr:5.81e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.953, tt:4614.844\n",
      "Ep:110, loss:0.00001, loss_test:0.08195, lr:5.75e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.949, tt:4656.298\n",
      "Ep:111, loss:0.00001, loss_test:0.08173, lr:5.70e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.951, tt:4698.490\n",
      "Ep:112, loss:0.00001, loss_test:0.08282, lr:5.64e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.957, tt:4741.171\n",
      "Ep:113, loss:0.00001, loss_test:0.08241, lr:5.58e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.963, tt:4783.751\n",
      "Ep:114, loss:0.00001, loss_test:0.08219, lr:5.53e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.973, tt:4826.913\n",
      "Ep:115, loss:0.00001, loss_test:0.08265, lr:5.47e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.972, tt:4868.720\n",
      "Ep:116, loss:0.00001, loss_test:0.08243, lr:5.42e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.963, tt:4909.620\n",
      "Ep:117, loss:0.00001, loss_test:0.08273, lr:5.36e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.966, tt:4951.967\n",
      "Ep:118, loss:0.00001, loss_test:0.08225, lr:5.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.978, tt:4995.394\n",
      "Ep:119, loss:0.00001, loss_test:0.08279, lr:5.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.984, tt:5038.042\n",
      "Ep:120, loss:0.00001, loss_test:0.08234, lr:5.20e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.013, tt:5083.556\n",
      "Ep:121, loss:0.00001, loss_test:0.08243, lr:5.15e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.026, tt:5127.164\n",
      "Ep:122, loss:0.00001, loss_test:0.08287, lr:5.10e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.051, tt:5172.325\n",
      "Ep:123, loss:0.00001, loss_test:0.08265, lr:5.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.087, tt:5218.745\n",
      "Ep:124, loss:0.00001, loss_test:0.08229, lr:5.00e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.084, tt:5260.446\n",
      "Ep:125, loss:0.00001, loss_test:0.08218, lr:4.95e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.112, tt:5306.085\n",
      "Ep:126, loss:0.00001, loss_test:0.08234, lr:4.90e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.122, tt:5349.477\n",
      "Ep:127, loss:0.00000, loss_test:0.08227, lr:4.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.151, tt:5395.286\n",
      "Ep:128, loss:0.00000, loss_test:0.08213, lr:4.80e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.154, tt:5437.869\n",
      "Ep:129, loss:0.00000, loss_test:0.08217, lr:4.75e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.171, tt:5482.215\n",
      "Ep:130, loss:0.00000, loss_test:0.08263, lr:4.71e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.174, tt:5524.849\n",
      "Ep:131, loss:0.00000, loss_test:0.08267, lr:4.66e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.134, tt:5561.664\n",
      "Ep:132, loss:0.00000, loss_test:0.08167, lr:4.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.118, tt:5601.752\n",
      "Ep:133, loss:0.00000, loss_test:0.08250, lr:4.57e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.129, tt:5645.269\n",
      "Ep:134, loss:0.00000, loss_test:0.08267, lr:4.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.136, tt:5688.370\n",
      "Ep:135, loss:0.00000, loss_test:0.08168, lr:4.48e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.137, tt:5730.597\n",
      "Ep:136, loss:0.00000, loss_test:0.08194, lr:4.43e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.125, tt:5771.101\n",
      "Ep:137, loss:0.00000, loss_test:0.08243, lr:4.39e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.117, tt:5812.094\n",
      "Ep:138, loss:0.00000, loss_test:0.08204, lr:4.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.104, tt:5852.465\n",
      "Ep:139, loss:0.00000, loss_test:0.08193, lr:4.30e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.114, tt:5895.915\n",
      "Ep:140, loss:0.00000, loss_test:0.08213, lr:4.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.123, tt:5939.411\n",
      "Ep:141, loss:0.00000, loss_test:0.08235, lr:4.21e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.145, tt:5984.654\n",
      "Ep:142, loss:0.00000, loss_test:0.08223, lr:4.17e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.157, tt:6028.402\n",
      "Ep:143, loss:0.00000, loss_test:0.08199, lr:4.13e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.123, tt:6065.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.08210, lr:4.09e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.112, tt:6106.181\n",
      "Ep:145, loss:0.00000, loss_test:0.08164, lr:4.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.127, tt:6150.533\n",
      "Ep:146, loss:0.00000, loss_test:0.08232, lr:4.01e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.118, tt:6191.328\n",
      "Ep:147, loss:0.00000, loss_test:0.08222, lr:3.97e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.114, tt:6232.867\n",
      "Ep:148, loss:0.00000, loss_test:0.08215, lr:3.93e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.092, tt:6271.765\n",
      "Ep:149, loss:0.00000, loss_test:0.08205, lr:3.89e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.092, tt:6313.742\n",
      "Ep:150, loss:0.00000, loss_test:0.08196, lr:3.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.095, tt:6356.305\n",
      "Ep:151, loss:0.00000, loss_test:0.08239, lr:3.81e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.081, tt:6396.382\n",
      "Ep:152, loss:0.00000, loss_test:0.08210, lr:3.77e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.081, tt:6438.442\n",
      "Ep:153, loss:0.00000, loss_test:0.08219, lr:3.73e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.080, tt:6480.320\n",
      "Ep:154, loss:0.00000, loss_test:0.08217, lr:3.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.075, tt:6521.624\n",
      "Ep:155, loss:0.00000, loss_test:0.08199, lr:3.66e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.068, tt:6562.664\n",
      "Ep:156, loss:0.00000, loss_test:0.08212, lr:3.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.073, tt:6605.431\n",
      "Ep:157, loss:0.00000, loss_test:0.08246, lr:3.59e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.060, tt:6645.488\n",
      "Ep:158, loss:0.00000, loss_test:0.08250, lr:3.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.063, tt:6688.023\n",
      "Ep:159, loss:0.00000, loss_test:0.08197, lr:3.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.066, tt:6730.624\n",
      "Ep:160, loss:0.00000, loss_test:0.08229, lr:3.48e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.064, tt:6772.315\n",
      "Ep:161, loss:0.00000, loss_test:0.08286, lr:3.45e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.071, tt:6815.430\n",
      "Ep:162, loss:0.00000, loss_test:0.08239, lr:3.41e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.061, tt:6855.949\n",
      "Ep:163, loss:0.00000, loss_test:0.08193, lr:3.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.048, tt:6895.855\n",
      "Ep:164, loss:0.00000, loss_test:0.08246, lr:3.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.043, tt:6937.175\n",
      "Ep:165, loss:0.00000, loss_test:0.08298, lr:3.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.046, tt:6979.706\n",
      "Ep:166, loss:0.00000, loss_test:0.08242, lr:3.28e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.032, tt:7019.425\n",
      "Ep:167, loss:0.00000, loss_test:0.08201, lr:3.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.019, tt:7059.124\n",
      "Ep:168, loss:0.00000, loss_test:0.08262, lr:3.21e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.014, tt:7100.430\n",
      "Ep:169, loss:0.00000, loss_test:0.08269, lr:3.18e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.011, tt:7141.917\n",
      "Ep:170, loss:0.00000, loss_test:0.08241, lr:3.15e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.015, tt:7184.607\n",
      "Ep:171, loss:0.00000, loss_test:0.08248, lr:3.12e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.008, tt:7225.390\n",
      "Ep:172, loss:0.00000, loss_test:0.08285, lr:3.09e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.005, tt:7266.861\n",
      "Ep:173, loss:0.00000, loss_test:0.08281, lr:3.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.004, tt:7308.751\n",
      "Ep:174, loss:0.00000, loss_test:0.08218, lr:3.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.003, tt:7350.498\n",
      "Ep:175, loss:0.00000, loss_test:0.08267, lr:2.99e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.989, tt:7389.983\n",
      "Ep:176, loss:0.00000, loss_test:0.08334, lr:2.96e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.981, tt:7430.558\n",
      "Ep:177, loss:0.00000, loss_test:0.08326, lr:2.93e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.975, tt:7471.538\n",
      "Ep:178, loss:0.00000, loss_test:0.08266, lr:2.90e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.978, tt:7514.086\n",
      "Ep:179, loss:0.00000, loss_test:0.08220, lr:2.88e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.970, tt:7554.567\n",
      "Ep:180, loss:0.00000, loss_test:0.08282, lr:2.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.965, tt:7595.623\n",
      "Ep:181, loss:0.00000, loss_test:0.08283, lr:2.82e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.958, tt:7636.358\n",
      "Ep:182, loss:0.00000, loss_test:0.08242, lr:2.79e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.959, tt:7678.412\n",
      "Ep:183, loss:0.00000, loss_test:0.08271, lr:2.76e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.967, tt:7722.011\n",
      "Ep:184, loss:0.00000, loss_test:0.08322, lr:2.73e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.975, tt:7765.314\n",
      "Ep:185, loss:0.00000, loss_test:0.08296, lr:2.71e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.986, tt:7809.321\n",
      "Ep:186, loss:0.00000, loss_test:0.08237, lr:2.68e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.999, tt:7853.867\n",
      "Ep:187, loss:0.00000, loss_test:0.08244, lr:2.65e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.008, tt:7897.486\n",
      "Ep:188, loss:0.00000, loss_test:0.08299, lr:2.63e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.012, tt:7940.205\n",
      "Ep:189, loss:0.00000, loss_test:0.08314, lr:2.60e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.020, tt:7983.793\n",
      "Ep:190, loss:0.00000, loss_test:0.08275, lr:2.57e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.016, tt:8024.997\n",
      "Ep:191, loss:0.00000, loss_test:0.08268, lr:2.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.017, tt:8067.250\n",
      "Ep:192, loss:0.00000, loss_test:0.08313, lr:2.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.010, tt:8107.917\n",
      "Ep:193, loss:0.00000, loss_test:0.08314, lr:2.50e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.018, tt:8151.475\n",
      "Ep:194, loss:0.00000, loss_test:0.08295, lr:2.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.032, tt:8196.254\n",
      "Ep:195, loss:0.00000, loss_test:0.08263, lr:2.45e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.035, tt:8238.844\n",
      "Ep:196, loss:0.00000, loss_test:0.08282, lr:2.42e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.031, tt:8280.084\n",
      "Ep:197, loss:0.00000, loss_test:0.08290, lr:2.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.028, tt:8321.462\n",
      "Ep:198, loss:0.00000, loss_test:0.08278, lr:2.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.029, tt:8363.821\n",
      "Ep:199, loss:0.00000, loss_test:0.08280, lr:2.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.033, tt:8406.586\n",
      "Ep:200, loss:0.00000, loss_test:0.08285, lr:2.33e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.019, tt:8445.839\n",
      "Ep:201, loss:0.00000, loss_test:0.08292, lr:2.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:42.017, tt:8487.360\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01954, lr:6.00e-02, fs:0.62879 (r=0.838,p=0.503),  time:22.299, tt:22.299\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02213, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.344, tt:44.688\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02326, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.439, tt:67.317\n",
      "Ep:3, loss:0.00005, loss_test:0.02265, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.435, tt:97.740\n",
      "Ep:4, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.715, tt:128.576\n",
      "Ep:5, loss:0.00004, loss_test:0.01896, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:27.264, tt:163.581\n",
      "Ep:6, loss:0.00004, loss_test:0.01789, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:28.208, tt:197.459\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01780, lr:6.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:28.773, tt:230.188\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00004, loss_test:0.01767, lr:6.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:29.461, tt:265.147\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01734, lr:6.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:29.930, tt:299.300\n",
      "Ep:10, loss:0.00003, loss_test:0.01727, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:30.418, tt:334.600\n",
      "Ep:11, loss:0.00003, loss_test:0.01724, lr:6.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:30.731, tt:368.774\n",
      "Ep:12, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:30.953, tt:402.393\n",
      "Ep:13, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:31.255, tt:437.565\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:31.341, tt:470.122\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:31.444, tt:503.110\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:31.467, tt:534.946\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01630, lr:6.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:31.679, tt:570.223\n",
      "Ep:18, loss:0.00003, loss_test:0.01616, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:31.776, tt:603.742\n",
      "Ep:19, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:31.846, tt:636.917\n",
      "Ep:20, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:31.957, tt:671.101\n",
      "Ep:21, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:32.045, tt:704.992\n",
      "Ep:22, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:32.098, tt:738.251\n",
      "Ep:23, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:32.333, tt:776.002\n",
      "Ep:24, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:32.500, tt:812.489\n",
      "Ep:25, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:32.579, tt:847.043\n",
      "Ep:26, loss:0.00002, loss_test:0.01603, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:32.660, tt:881.832\n",
      "Ep:27, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:32.729, tt:916.420\n",
      "Ep:28, loss:0.00002, loss_test:0.01594, lr:5.94e-02, fs:0.76415 (r=0.818,p=0.717),  time:32.772, tt:950.395\n",
      "Ep:29, loss:0.00002, loss_test:0.01587, lr:5.88e-02, fs:0.77934 (r=0.838,p=0.728),  time:32.847, tt:985.410\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01578, lr:5.88e-02, fs:0.78505 (r=0.848,p=0.730),  time:32.925, tt:1020.688\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01573, lr:5.88e-02, fs:0.80000 (r=0.848,p=0.757),  time:33.000, tt:1056.014\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01566, lr:5.88e-02, fs:0.80383 (r=0.848,p=0.764),  time:33.015, tt:1089.479\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01560, lr:5.88e-02, fs:0.79612 (r=0.828,p=0.766),  time:33.037, tt:1123.275\n",
      "Ep:34, loss:0.00002, loss_test:0.01553, lr:5.88e-02, fs:0.79612 (r=0.828,p=0.766),  time:33.078, tt:1157.746\n",
      "Ep:35, loss:0.00002, loss_test:0.01550, lr:5.88e-02, fs:0.79024 (r=0.818,p=0.764),  time:33.130, tt:1192.689\n",
      "Ep:36, loss:0.00002, loss_test:0.01552, lr:5.88e-02, fs:0.78818 (r=0.808,p=0.769),  time:33.173, tt:1227.400\n",
      "Ep:37, loss:0.00002, loss_test:0.01552, lr:5.88e-02, fs:0.78607 (r=0.798,p=0.775),  time:33.180, tt:1260.856\n",
      "Ep:38, loss:0.00001, loss_test:0.01551, lr:5.88e-02, fs:0.78607 (r=0.798,p=0.775),  time:33.245, tt:1296.566\n",
      "Ep:39, loss:0.00001, loss_test:0.01547, lr:5.88e-02, fs:0.79000 (r=0.798,p=0.782),  time:33.280, tt:1331.197\n",
      "Ep:40, loss:0.00001, loss_test:0.01548, lr:5.88e-02, fs:0.79397 (r=0.798,p=0.790),  time:33.287, tt:1364.764\n",
      "Ep:41, loss:0.00001, loss_test:0.01546, lr:5.88e-02, fs:0.80000 (r=0.808,p=0.792),  time:33.322, tt:1399.531\n",
      "Ep:42, loss:0.00001, loss_test:0.01545, lr:5.88e-02, fs:0.79798 (r=0.798,p=0.798),  time:33.377, tt:1435.214\n",
      "Ep:43, loss:0.00001, loss_test:0.01546, lr:5.88e-02, fs:0.79592 (r=0.788,p=0.804),  time:33.421, tt:1470.505\n",
      "Ep:44, loss:0.00001, loss_test:0.01549, lr:5.82e-02, fs:0.79381 (r=0.778,p=0.811),  time:33.423, tt:1504.031\n",
      "Ep:45, loss:0.00001, loss_test:0.01551, lr:5.76e-02, fs:0.78756 (r=0.768,p=0.809),  time:33.440, tt:1538.255\n",
      "Ep:46, loss:0.00001, loss_test:0.01550, lr:5.71e-02, fs:0.78756 (r=0.768,p=0.809),  time:33.435, tt:1571.457\n",
      "Ep:47, loss:0.00001, loss_test:0.01551, lr:5.65e-02, fs:0.78125 (r=0.758,p=0.806),  time:33.453, tt:1605.752\n",
      "Ep:48, loss:0.00001, loss_test:0.01552, lr:5.59e-02, fs:0.77487 (r=0.747,p=0.804),  time:33.491, tt:1641.047\n",
      "Ep:49, loss:0.00001, loss_test:0.01553, lr:5.54e-02, fs:0.77487 (r=0.747,p=0.804),  time:33.539, tt:1676.975\n",
      "Ep:50, loss:0.00001, loss_test:0.01557, lr:5.48e-02, fs:0.77487 (r=0.747,p=0.804),  time:33.589, tt:1713.061\n",
      "Ep:51, loss:0.00001, loss_test:0.01563, lr:5.43e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.592, tt:1746.759\n",
      "Ep:52, loss:0.00001, loss_test:0.01567, lr:5.37e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.617, tt:1781.690\n",
      "Ep:53, loss:0.00001, loss_test:0.01570, lr:5.32e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.620, tt:1815.457\n",
      "Ep:54, loss:0.00001, loss_test:0.01569, lr:5.27e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.643, tt:1850.372\n",
      "Ep:55, loss:0.00001, loss_test:0.01574, lr:5.21e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.677, tt:1885.917\n",
      "Ep:56, loss:0.00001, loss_test:0.01578, lr:5.16e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.706, tt:1921.256\n",
      "Ep:57, loss:0.00001, loss_test:0.01580, lr:5.11e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.703, tt:1954.763\n",
      "Ep:58, loss:0.00001, loss_test:0.01584, lr:5.06e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.741, tt:1990.722\n",
      "Ep:59, loss:0.00001, loss_test:0.01588, lr:5.01e-02, fs:0.77660 (r=0.737,p=0.820),  time:33.766, tt:2025.981\n",
      "Ep:60, loss:0.00001, loss_test:0.01588, lr:4.96e-02, fs:0.77249 (r=0.737,p=0.811),  time:33.760, tt:2059.385\n",
      "Ep:61, loss:0.00001, loss_test:0.01593, lr:4.91e-02, fs:0.77660 (r=0.737,p=0.820),  time:33.769, tt:2093.648\n",
      "Ep:62, loss:0.00001, loss_test:0.01598, lr:4.86e-02, fs:0.78075 (r=0.737,p=0.830),  time:33.782, tt:2128.271\n",
      "Ep:63, loss:0.00001, loss_test:0.01600, lr:4.81e-02, fs:0.78075 (r=0.737,p=0.830),  time:33.794, tt:2162.842\n",
      "Ep:64, loss:0.00001, loss_test:0.01601, lr:4.76e-02, fs:0.78075 (r=0.737,p=0.830),  time:33.792, tt:2196.458\n",
      "Ep:65, loss:0.00001, loss_test:0.01603, lr:4.71e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.791, tt:2230.173\n",
      "Ep:66, loss:0.00001, loss_test:0.01605, lr:4.67e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.792, tt:2264.049\n",
      "Ep:67, loss:0.00001, loss_test:0.01610, lr:4.62e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.830, tt:2300.416\n",
      "Ep:68, loss:0.00001, loss_test:0.01616, lr:4.57e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.834, tt:2334.539\n",
      "Ep:69, loss:0.00001, loss_test:0.01623, lr:4.53e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.822, tt:2367.530\n",
      "Ep:70, loss:0.00001, loss_test:0.01626, lr:4.48e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.834, tt:2402.235\n",
      "Ep:71, loss:0.00001, loss_test:0.01630, lr:4.44e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.837, tt:2436.254\n",
      "Ep:72, loss:0.00001, loss_test:0.01634, lr:4.39e-02, fs:0.76596 (r=0.727,p=0.809),  time:33.837, tt:2470.109\n",
      "Ep:73, loss:0.00001, loss_test:0.01636, lr:4.35e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.833, tt:2503.652\n",
      "Ep:74, loss:0.00001, loss_test:0.01641, lr:4.31e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.836, tt:2537.678\n",
      "Ep:75, loss:0.00001, loss_test:0.01644, lr:4.26e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.831, tt:2571.185\n",
      "Ep:76, loss:0.00001, loss_test:0.01648, lr:4.22e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.852, tt:2606.589\n",
      "Ep:77, loss:0.00001, loss_test:0.01650, lr:4.18e-02, fs:0.76596 (r=0.727,p=0.809),  time:33.851, tt:2640.403\n",
      "Ep:78, loss:0.00001, loss_test:0.01656, lr:4.14e-02, fs:0.77005 (r=0.727,p=0.818),  time:33.865, tt:2675.323\n",
      "Ep:79, loss:0.00001, loss_test:0.01660, lr:4.10e-02, fs:0.77419 (r=0.727,p=0.828),  time:33.884, tt:2710.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00001, loss_test:0.01664, lr:4.05e-02, fs:0.77005 (r=0.727,p=0.818),  time:33.889, tt:2745.035\n",
      "Ep:81, loss:0.00001, loss_test:0.01668, lr:4.01e-02, fs:0.76757 (r=0.717,p=0.826),  time:33.900, tt:2779.762\n",
      "Ep:82, loss:0.00001, loss_test:0.01671, lr:3.97e-02, fs:0.76757 (r=0.717,p=0.826),  time:33.900, tt:2813.717\n",
      "Ep:83, loss:0.00001, loss_test:0.01674, lr:3.93e-02, fs:0.76344 (r=0.717,p=0.816),  time:33.889, tt:2846.697\n",
      "Ep:84, loss:0.00001, loss_test:0.01677, lr:3.89e-02, fs:0.76503 (r=0.707,p=0.833),  time:33.881, tt:2879.847\n",
      "Ep:85, loss:0.00001, loss_test:0.01680, lr:3.86e-02, fs:0.76503 (r=0.707,p=0.833),  time:33.884, tt:2914.054\n",
      "Ep:86, loss:0.00001, loss_test:0.01681, lr:3.82e-02, fs:0.76503 (r=0.707,p=0.833),  time:33.879, tt:2947.509\n",
      "Ep:87, loss:0.00001, loss_test:0.01684, lr:3.78e-02, fs:0.76503 (r=0.707,p=0.833),  time:33.897, tt:2982.952\n",
      "Ep:88, loss:0.00001, loss_test:0.01689, lr:3.74e-02, fs:0.76923 (r=0.707,p=0.843),  time:33.910, tt:3017.995\n",
      "Ep:89, loss:0.00001, loss_test:0.01693, lr:3.70e-02, fs:0.76923 (r=0.707,p=0.843),  time:33.904, tt:3051.402\n",
      "Ep:90, loss:0.00001, loss_test:0.01698, lr:3.67e-02, fs:0.76923 (r=0.707,p=0.843),  time:33.911, tt:3085.902\n",
      "Ep:91, loss:0.00001, loss_test:0.01700, lr:3.63e-02, fs:0.76923 (r=0.707,p=0.843),  time:33.899, tt:3118.713\n",
      "Ep:92, loss:0.00001, loss_test:0.01702, lr:3.59e-02, fs:0.76923 (r=0.707,p=0.843),  time:33.909, tt:3153.552\n",
      "Ep:93, loss:0.00001, loss_test:0.01704, lr:3.56e-02, fs:0.76243 (r=0.697,p=0.841),  time:33.914, tt:3187.876\n",
      "Ep:94, loss:0.00001, loss_test:0.01706, lr:3.52e-02, fs:0.76243 (r=0.697,p=0.841),  time:33.918, tt:3222.171\n",
      "Ep:95, loss:0.00001, loss_test:0.01709, lr:3.49e-02, fs:0.75556 (r=0.687,p=0.840),  time:33.934, tt:3257.683\n",
      "Ep:96, loss:0.00001, loss_test:0.01713, lr:3.45e-02, fs:0.74860 (r=0.677,p=0.838),  time:33.925, tt:3290.679\n",
      "Ep:97, loss:0.00001, loss_test:0.01716, lr:3.42e-02, fs:0.74157 (r=0.667,p=0.835),  time:33.918, tt:3323.918\n",
      "Ep:98, loss:0.00001, loss_test:0.01720, lr:3.38e-02, fs:0.74157 (r=0.667,p=0.835),  time:33.933, tt:3359.405\n",
      "Ep:99, loss:0.00001, loss_test:0.01723, lr:3.35e-02, fs:0.74157 (r=0.667,p=0.835),  time:33.935, tt:3393.460\n",
      "Ep:100, loss:0.00001, loss_test:0.01727, lr:3.32e-02, fs:0.74576 (r=0.667,p=0.846),  time:33.937, tt:3427.595\n",
      "Ep:101, loss:0.00001, loss_test:0.01732, lr:3.28e-02, fs:0.74576 (r=0.667,p=0.846),  time:33.950, tt:3462.909\n",
      "Ep:102, loss:0.00001, loss_test:0.01734, lr:3.25e-02, fs:0.73864 (r=0.657,p=0.844),  time:33.942, tt:3496.016\n",
      "Ep:103, loss:0.00001, loss_test:0.01738, lr:3.22e-02, fs:0.73864 (r=0.657,p=0.844),  time:33.961, tt:3531.920\n",
      "Ep:104, loss:0.00001, loss_test:0.01742, lr:3.19e-02, fs:0.73143 (r=0.646,p=0.842),  time:33.968, tt:3566.669\n",
      "Ep:105, loss:0.00001, loss_test:0.01744, lr:3.15e-02, fs:0.73143 (r=0.646,p=0.842),  time:33.971, tt:3600.927\n",
      "Ep:106, loss:0.00001, loss_test:0.01748, lr:3.12e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.011, tt:3639.142\n",
      "Ep:107, loss:0.00001, loss_test:0.01751, lr:3.09e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.018, tt:3673.916\n",
      "Ep:108, loss:0.00001, loss_test:0.01753, lr:3.06e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.019, tt:3708.047\n",
      "Ep:109, loss:0.00001, loss_test:0.01756, lr:3.03e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.014, tt:3741.537\n",
      "Ep:110, loss:0.00000, loss_test:0.01758, lr:3.00e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.020, tt:3776.211\n",
      "Ep:111, loss:0.00000, loss_test:0.01762, lr:2.97e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.034, tt:3811.806\n",
      "Ep:112, loss:0.00000, loss_test:0.01765, lr:2.94e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.040, tt:3846.526\n",
      "Ep:113, loss:0.00000, loss_test:0.01768, lr:2.91e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.046, tt:3881.205\n",
      "Ep:114, loss:0.00000, loss_test:0.01770, lr:2.88e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.041, tt:3914.771\n",
      "Ep:115, loss:0.00000, loss_test:0.01774, lr:2.85e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.057, tt:3950.570\n",
      "Ep:116, loss:0.00000, loss_test:0.01775, lr:2.82e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.069, tt:3986.038\n",
      "Ep:117, loss:0.00000, loss_test:0.01775, lr:2.80e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.064, tt:4019.573\n",
      "Ep:118, loss:0.00000, loss_test:0.01779, lr:2.77e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.071, tt:4054.435\n",
      "Ep:119, loss:0.00000, loss_test:0.01783, lr:2.74e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.082, tt:4089.898\n",
      "Ep:120, loss:0.00000, loss_test:0.01785, lr:2.71e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.080, tt:4123.726\n",
      "Ep:121, loss:0.00000, loss_test:0.01789, lr:2.69e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.083, tt:4158.089\n",
      "Ep:122, loss:0.00000, loss_test:0.01791, lr:2.66e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.091, tt:4193.216\n",
      "Ep:123, loss:0.00000, loss_test:0.01794, lr:2.63e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.108, tt:4229.367\n",
      "Ep:124, loss:0.00000, loss_test:0.01795, lr:2.61e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.109, tt:4263.590\n",
      "Ep:125, loss:0.00000, loss_test:0.01798, lr:2.58e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.112, tt:4298.161\n",
      "Ep:126, loss:0.00000, loss_test:0.01801, lr:2.55e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.129, tt:4334.321\n",
      "Ep:127, loss:0.00000, loss_test:0.01804, lr:2.53e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.150, tt:4371.157\n",
      "Ep:128, loss:0.00000, loss_test:0.01807, lr:2.50e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.159, tt:4406.496\n",
      "Ep:129, loss:0.00000, loss_test:0.01808, lr:2.48e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.169, tt:4441.951\n",
      "Ep:130, loss:0.00000, loss_test:0.01809, lr:2.45e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.167, tt:4475.854\n",
      "Ep:131, loss:0.00000, loss_test:0.01812, lr:2.43e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.171, tt:4510.620\n",
      "Ep:132, loss:0.00000, loss_test:0.01816, lr:2.40e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.185, tt:4546.596\n",
      "Ep:133, loss:0.00000, loss_test:0.01820, lr:2.38e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.198, tt:4582.554\n",
      "Ep:134, loss:0.00000, loss_test:0.01821, lr:2.36e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.210, tt:4618.309\n",
      "Ep:135, loss:0.00000, loss_test:0.01823, lr:2.33e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.213, tt:4652.969\n",
      "Ep:136, loss:0.00000, loss_test:0.01825, lr:2.31e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.238, tt:4690.640\n",
      "Ep:137, loss:0.00000, loss_test:0.01828, lr:2.29e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.243, tt:4725.528\n",
      "Ep:138, loss:0.00000, loss_test:0.01830, lr:2.26e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.260, tt:4762.116\n",
      "Ep:139, loss:0.00000, loss_test:0.01832, lr:2.24e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.263, tt:4796.827\n",
      "Ep:140, loss:0.00000, loss_test:0.01834, lr:2.22e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.272, tt:4832.296\n",
      "Ep:141, loss:0.00000, loss_test:0.01837, lr:2.20e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.275, tt:4867.101\n",
      "Ep:142, loss:0.00000, loss_test:0.01839, lr:2.17e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.286, tt:4902.888\n",
      "Ep:143, loss:0.00000, loss_test:0.01841, lr:2.15e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.287, tt:4937.259\n",
      "Ep:144, loss:0.00000, loss_test:0.01843, lr:2.13e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.288, tt:4971.733\n",
      "Ep:145, loss:0.00000, loss_test:0.01846, lr:2.11e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.290, tt:5006.288\n",
      "Ep:146, loss:0.00000, loss_test:0.01848, lr:2.09e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.302, tt:5042.462\n",
      "Ep:147, loss:0.00000, loss_test:0.01849, lr:2.07e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.299, tt:5076.214\n",
      "Ep:148, loss:0.00000, loss_test:0.01852, lr:2.05e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.303, tt:5111.188\n",
      "Ep:149, loss:0.00000, loss_test:0.01854, lr:2.03e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.303, tt:5145.382\n",
      "Ep:150, loss:0.00000, loss_test:0.01855, lr:2.01e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.295, tt:5178.565\n",
      "Ep:151, loss:0.00000, loss_test:0.01856, lr:1.99e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.305, tt:5214.301\n",
      "Ep:152, loss:0.00000, loss_test:0.01858, lr:1.97e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.307, tt:5248.941\n",
      "Ep:153, loss:0.00000, loss_test:0.01860, lr:1.95e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.304, tt:5282.805\n",
      "Ep:154, loss:0.00000, loss_test:0.01862, lr:1.93e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.307, tt:5317.609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.01865, lr:1.91e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.313, tt:5352.796\n",
      "Ep:156, loss:0.00000, loss_test:0.01866, lr:1.89e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.313, tt:5387.176\n",
      "Ep:157, loss:0.00000, loss_test:0.01868, lr:1.87e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.308, tt:5420.727\n",
      "Ep:158, loss:0.00000, loss_test:0.01868, lr:1.85e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.302, tt:5453.963\n",
      "Ep:159, loss:0.00000, loss_test:0.01871, lr:1.83e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.308, tt:5489.292\n",
      "Ep:160, loss:0.00000, loss_test:0.01873, lr:1.81e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.323, tt:5525.955\n",
      "Ep:161, loss:0.00000, loss_test:0.01874, lr:1.80e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.319, tt:5559.649\n",
      "Ep:162, loss:0.00000, loss_test:0.01876, lr:1.78e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.321, tt:5594.316\n",
      "Ep:163, loss:0.00000, loss_test:0.01878, lr:1.76e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.315, tt:5627.687\n",
      "Ep:164, loss:0.00000, loss_test:0.01879, lr:1.74e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.317, tt:5662.371\n",
      "Ep:165, loss:0.00000, loss_test:0.01882, lr:1.73e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.318, tt:5696.866\n",
      "Ep:166, loss:0.00000, loss_test:0.01884, lr:1.71e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.322, tt:5731.780\n",
      "Ep:167, loss:0.00000, loss_test:0.01886, lr:1.69e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.322, tt:5766.146\n",
      "Ep:168, loss:0.00000, loss_test:0.01887, lr:1.67e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.320, tt:5800.033\n",
      "Ep:169, loss:0.00000, loss_test:0.01888, lr:1.66e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.315, tt:5833.616\n",
      "Ep:170, loss:0.00000, loss_test:0.01890, lr:1.64e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.313, tt:5867.449\n",
      "Ep:171, loss:0.00000, loss_test:0.01891, lr:1.62e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.304, tt:5900.261\n",
      "Ep:172, loss:0.00000, loss_test:0.01892, lr:1.61e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.306, tt:5934.987\n",
      "Ep:173, loss:0.00000, loss_test:0.01894, lr:1.59e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.302, tt:5968.560\n",
      "Ep:174, loss:0.00000, loss_test:0.01896, lr:1.58e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.294, tt:6001.459\n",
      "Ep:175, loss:0.00000, loss_test:0.01899, lr:1.56e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.291, tt:6035.202\n",
      "Ep:176, loss:0.00000, loss_test:0.01900, lr:1.54e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.284, tt:6068.183\n",
      "Ep:177, loss:0.00000, loss_test:0.01902, lr:1.53e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.292, tt:6104.002\n",
      "Ep:178, loss:0.00000, loss_test:0.01903, lr:1.51e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.291, tt:6137.999\n",
      "Ep:179, loss:0.00000, loss_test:0.01904, lr:1.50e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.293, tt:6172.794\n",
      "Ep:180, loss:0.00000, loss_test:0.01906, lr:1.48e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.318, tt:6211.570\n",
      "Ep:181, loss:0.00000, loss_test:0.01907, lr:1.47e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.317, tt:6245.681\n",
      "Ep:182, loss:0.00000, loss_test:0.01908, lr:1.45e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.318, tt:6280.178\n",
      "Ep:183, loss:0.00000, loss_test:0.01909, lr:1.44e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.327, tt:6316.086\n",
      "Ep:184, loss:0.00000, loss_test:0.01911, lr:1.43e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.330, tt:6350.984\n",
      "Ep:185, loss:0.00000, loss_test:0.01912, lr:1.41e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.328, tt:6385.028\n",
      "Ep:186, loss:0.00000, loss_test:0.01913, lr:1.40e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.325, tt:6418.730\n",
      "Ep:187, loss:0.00000, loss_test:0.01915, lr:1.38e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.327, tt:6453.566\n",
      "Ep:188, loss:0.00000, loss_test:0.01917, lr:1.37e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.319, tt:6486.297\n",
      "Ep:189, loss:0.00000, loss_test:0.01919, lr:1.36e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.314, tt:6519.587\n",
      "Ep:190, loss:0.00000, loss_test:0.01919, lr:1.34e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.306, tt:6552.538\n",
      "Ep:191, loss:0.00000, loss_test:0.01920, lr:1.33e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.306, tt:6586.714\n",
      "Ep:192, loss:0.00000, loss_test:0.01922, lr:1.32e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.300, tt:6619.921\n",
      "Ep:193, loss:0.00000, loss_test:0.01923, lr:1.30e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.302, tt:6654.664\n",
      "Ep:194, loss:0.00000, loss_test:0.01925, lr:1.29e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.295, tt:6687.499\n",
      "Ep:195, loss:0.00000, loss_test:0.01926, lr:1.28e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.289, tt:6720.715\n",
      "Ep:196, loss:0.00000, loss_test:0.01928, lr:1.26e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.282, tt:6753.587\n",
      "Ep:197, loss:0.00000, loss_test:0.01930, lr:1.25e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.270, tt:6785.514\n",
      "Ep:198, loss:0.00000, loss_test:0.01931, lr:1.24e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.269, tt:6819.455\n",
      "Ep:199, loss:0.00000, loss_test:0.01933, lr:1.23e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.265, tt:6853.062\n",
      "Ep:200, loss:0.00000, loss_test:0.01933, lr:1.21e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.257, tt:6885.740\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13592, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.871, tt:32.871\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13260, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:29.981, tt:59.961\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12592, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:29.819, tt:89.457\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11514, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:29.804, tt:119.218\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.10628, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:31.063, tt:155.315\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.10546, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:31.788, tt:190.728\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10296, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:32.400, tt:226.803\n",
      "Ep:7, loss:0.00022, loss_test:0.10311, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:33.004, tt:264.034\n",
      "Ep:8, loss:0.00022, loss_test:0.10214, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:33.479, tt:301.314\n",
      "Ep:9, loss:0.00021, loss_test:0.10180, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:33.953, tt:339.529\n",
      "Ep:10, loss:0.00020, loss_test:0.10172, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:34.134, tt:375.472\n",
      "Ep:11, loss:0.00019, loss_test:0.10185, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:34.313, tt:411.755\n",
      "Ep:12, loss:0.00019, loss_test:0.09986, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:34.508, tt:448.610\n",
      "Ep:13, loss:0.00018, loss_test:0.09848, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:34.647, tt:485.051\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09687, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:34.693, tt:520.388\n",
      "Ep:15, loss:0.00016, loss_test:0.09546, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:34.939, tt:559.018\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09291, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:35.116, tt:596.971\n",
      "Ep:17, loss:0.00015, loss_test:0.09102, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:35.213, tt:633.826\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08992, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:35.285, tt:670.414\n",
      "Ep:19, loss:0.00013, loss_test:0.08901, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:35.382, tt:707.637\n",
      "Ep:20, loss:0.00013, loss_test:0.08819, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:35.519, tt:745.900\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00012, loss_test:0.08829, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.610, tt:783.424\n",
      "Ep:22, loss:0.00011, loss_test:0.08715, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:35.714, tt:821.422\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08685, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:35.743, tt:857.820\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08590, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:35.848, tt:896.196\n",
      "Ep:25, loss:0.00010, loss_test:0.08493, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.912, tt:933.723\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.08408, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.950, tt:970.659\n",
      "Ep:27, loss:0.00009, loss_test:0.08360, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:35.948, tt:1006.535\n",
      "Ep:28, loss:0.00008, loss_test:0.08288, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:35.957, tt:1042.761\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.08126, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.924, tt:1077.724\n",
      "Ep:30, loss:0.00008, loss_test:0.08135, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:35.962, tt:1114.836\n",
      "Ep:31, loss:0.00007, loss_test:0.08048, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:36.047, tt:1153.516\n",
      "Ep:32, loss:0.00007, loss_test:0.07843, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:36.062, tt:1190.046\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.07966, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:36.052, tt:1225.776\n",
      "Ep:34, loss:0.00006, loss_test:0.07683, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.051, tt:1261.770\n",
      "Ep:35, loss:0.00006, loss_test:0.07807, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:36.030, tt:1297.082\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.07527, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:36.036, tt:1333.350\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.07643, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.077, tt:1370.944\n",
      "Ep:38, loss:0.00005, loss_test:0.07601, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.048, tt:1405.855\n",
      "Ep:39, loss:0.00005, loss_test:0.07643, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:36.047, tt:1441.867\n",
      "Ep:40, loss:0.00005, loss_test:0.07546, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:36.037, tt:1477.534\n",
      "Ep:41, loss:0.00005, loss_test:0.07622, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:36.046, tt:1513.945\n",
      "Ep:42, loss:0.00005, loss_test:0.07408, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:36.024, tt:1549.012\n",
      "Ep:43, loss:0.00004, loss_test:0.07318, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:36.013, tt:1584.553\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.07163, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.034, tt:1621.513\n",
      "Ep:45, loss:0.00004, loss_test:0.07300, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.006, tt:1656.256\n",
      "Ep:46, loss:0.00004, loss_test:0.07178, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.943, tt:1689.343\n",
      "Ep:47, loss:0.00004, loss_test:0.07209, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.950, tt:1725.611\n",
      "Ep:48, loss:0.00004, loss_test:0.07254, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.919, tt:1760.014\n",
      "Ep:49, loss:0.00003, loss_test:0.07128, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.953, tt:1797.641\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.07190, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.048, tt:1838.463\n",
      "Ep:51, loss:0.00003, loss_test:0.06998, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.986, tt:1871.254\n",
      "Ep:52, loss:0.00003, loss_test:0.07072, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.936, tt:1904.626\n",
      "Ep:53, loss:0.00003, loss_test:0.06975, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.940, tt:1940.741\n",
      "Ep:54, loss:0.00003, loss_test:0.07102, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.900, tt:1974.522\n",
      "Ep:55, loss:0.00003, loss_test:0.06959, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.868, tt:2008.616\n",
      "Ep:56, loss:0.00003, loss_test:0.07086, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.841, tt:2042.924\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.06864, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.795, tt:2076.104\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.06810, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.771, tt:2110.507\n",
      "Ep:59, loss:0.00002, loss_test:0.06713, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.745, tt:2144.714\n",
      "Ep:60, loss:0.00002, loss_test:0.07027, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.728, tt:2179.413\n",
      "Ep:61, loss:0.00002, loss_test:0.06880, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.723, tt:2214.856\n",
      "Ep:62, loss:0.00002, loss_test:0.06914, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.678, tt:2247.734\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.06914, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:35.674, tt:2283.149\n",
      "Ep:64, loss:0.00002, loss_test:0.06905, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.671, tt:2318.600\n",
      "Ep:65, loss:0.00002, loss_test:0.06808, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.684, tt:2355.134\n",
      "Ep:66, loss:0.00002, loss_test:0.07059, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.670, tt:2389.874\n",
      "Ep:67, loss:0.00002, loss_test:0.06890, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.667, tt:2425.324\n",
      "Ep:68, loss:0.00002, loss_test:0.06902, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.670, tt:2461.243\n",
      "Ep:69, loss:0.00002, loss_test:0.06798, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.658, tt:2496.030\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.07130, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:35.658, tt:2531.733\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.06936, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.650, tt:2566.780\n",
      "Ep:72, loss:0.00001, loss_test:0.06985, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.660, tt:2603.206\n",
      "Ep:73, loss:0.00001, loss_test:0.06971, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.645, tt:2637.763\n",
      "Ep:74, loss:0.00001, loss_test:0.06757, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.649, tt:2673.657\n",
      "Ep:75, loss:0.00001, loss_test:0.07031, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.631, tt:2707.972\n",
      "Ep:76, loss:0.00001, loss_test:0.06817, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.608, tt:2741.812\n",
      "Ep:77, loss:0.00001, loss_test:0.06930, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.608, tt:2777.386\n",
      "Ep:78, loss:0.00001, loss_test:0.06710, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.608, tt:2813.057\n",
      "Ep:79, loss:0.00001, loss_test:0.06928, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.608, tt:2848.643\n",
      "Ep:80, loss:0.00001, loss_test:0.06725, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.603, tt:2883.806\n",
      "Ep:81, loss:0.00001, loss_test:0.07193, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.605, tt:2919.598\n",
      "Ep:82, loss:0.00001, loss_test:0.06964, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.596, tt:2954.477\n",
      "Ep:83, loss:0.00001, loss_test:0.06761, lr:9.80e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.593, tt:2989.817\n",
      "Ep:84, loss:0.00001, loss_test:0.06739, lr:9.70e-03, fs:0.86339 (r=0.798,p=0.940),  time:35.596, tt:3025.666\n",
      "Ep:85, loss:0.00001, loss_test:0.06688, lr:9.61e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.612, tt:3062.598\n",
      "Ep:86, loss:0.00001, loss_test:0.06753, lr:9.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.614, tt:3098.437\n",
      "Ep:87, loss:0.00001, loss_test:0.06777, lr:9.41e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.621, tt:3134.624\n",
      "Ep:88, loss:0.00001, loss_test:0.06819, lr:9.32e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.620, tt:3170.194\n",
      "Ep:89, loss:0.00001, loss_test:0.06658, lr:9.23e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.613, tt:3205.204\n",
      "Ep:90, loss:0.00001, loss_test:0.06726, lr:9.14e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.615, tt:3240.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:91, loss:0.00001, loss_test:0.06750, lr:9.04e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.605, tt:3275.704\n",
      "Ep:92, loss:0.00001, loss_test:0.06739, lr:8.95e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.606, tt:3311.320\n",
      "Ep:93, loss:0.00001, loss_test:0.06718, lr:8.86e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.612, tt:3347.488\n",
      "Ep:94, loss:0.00001, loss_test:0.06804, lr:8.78e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.599, tt:3381.914\n",
      "Ep:95, loss:0.00001, loss_test:0.06758, lr:8.69e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.599, tt:3417.546\n",
      "Ep:96, loss:0.00001, loss_test:0.06713, lr:8.60e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.596, tt:3452.853\n",
      "Ep:97, loss:0.00001, loss_test:0.06761, lr:8.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:35.583, tt:3487.093\n",
      "Ep:98, loss:0.00001, loss_test:0.06662, lr:8.43e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.581, tt:3522.564\n",
      "Ep:99, loss:0.00001, loss_test:0.06697, lr:8.35e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.587, tt:3558.703\n",
      "Ep:100, loss:0.00001, loss_test:0.06807, lr:8.26e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.576, tt:3593.219\n",
      "Ep:101, loss:0.00001, loss_test:0.06729, lr:8.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.554, tt:3626.550\n",
      "Ep:102, loss:0.00001, loss_test:0.06712, lr:8.10e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.600, tt:3666.825\n",
      "Ep:103, loss:0.00001, loss_test:0.06850, lr:8.02e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.584, tt:3700.706\n",
      "Ep:104, loss:0.00001, loss_test:0.06887, lr:7.94e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.596, tt:3737.565\n",
      "Ep:105, loss:0.00001, loss_test:0.06830, lr:7.86e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.579, tt:3771.405\n",
      "Ep:106, loss:0.00000, loss_test:0.06768, lr:7.78e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.578, tt:3806.883\n",
      "Ep:107, loss:0.00000, loss_test:0.06880, lr:7.70e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.583, tt:3843.006\n",
      "Ep:108, loss:0.00000, loss_test:0.06798, lr:7.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.572, tt:3877.390\n",
      "Ep:109, loss:0.00000, loss_test:0.06818, lr:7.55e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.572, tt:3912.916\n",
      "Ep:110, loss:0.00000, loss_test:0.06801, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.555, tt:3946.575\n",
      "Ep:111, loss:0.00000, loss_test:0.06894, lr:7.40e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.546, tt:3981.194\n",
      "Ep:112, loss:0.00000, loss_test:0.06942, lr:7.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:35.551, tt:4017.285\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.06884, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.546, tt:4052.266\n",
      "Ep:114, loss:0.00000, loss_test:0.06885, lr:7.32e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.539, tt:4087.040\n",
      "Ep:115, loss:0.00000, loss_test:0.06928, lr:7.32e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.547, tt:4123.432\n",
      "Ep:116, loss:0.00000, loss_test:0.06939, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.544, tt:4158.668\n",
      "Ep:117, loss:0.00000, loss_test:0.06809, lr:7.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.525, tt:4191.991\n",
      "Ep:118, loss:0.00000, loss_test:0.06904, lr:7.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.477, tt:4221.804\n",
      "Ep:119, loss:0.00000, loss_test:0.06952, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.441, tt:4252.860\n",
      "Ep:120, loss:0.00000, loss_test:0.06792, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.398, tt:4283.203\n",
      "Ep:121, loss:0.00000, loss_test:0.06792, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.370, tt:4315.102\n",
      "Ep:122, loss:0.00000, loss_test:0.06901, lr:7.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:35.337, tt:4346.425\n",
      "Ep:123, loss:0.00000, loss_test:0.07011, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.305, tt:4377.853\n",
      "Ep:124, loss:0.00000, loss_test:0.06897, lr:7.25e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.291, tt:4411.357\n",
      "Ep:125, loss:0.00000, loss_test:0.06832, lr:7.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.270, tt:4444.063\n",
      "Ep:126, loss:0.00000, loss_test:0.06885, lr:7.11e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.239, tt:4475.365\n",
      "Ep:127, loss:0.00000, loss_test:0.06820, lr:7.03e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.202, tt:4505.910\n",
      "Ep:128, loss:0.00000, loss_test:0.06826, lr:6.96e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.189, tt:4539.388\n",
      "Ep:129, loss:0.00000, loss_test:0.06846, lr:6.89e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.166, tt:4571.596\n",
      "Ep:130, loss:0.00000, loss_test:0.06859, lr:6.83e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.144, tt:4603.912\n",
      "Ep:131, loss:0.00000, loss_test:0.06827, lr:6.76e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.126, tt:4636.681\n",
      "Ep:132, loss:0.00000, loss_test:0.06855, lr:6.69e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.095, tt:4667.659\n",
      "Ep:133, loss:0.00000, loss_test:0.06923, lr:6.62e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.102, tt:4703.718\n",
      "Ep:134, loss:0.00000, loss_test:0.06857, lr:6.56e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.089, tt:4736.993\n",
      "Ep:135, loss:0.00000, loss_test:0.06813, lr:6.49e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.085, tt:4771.622\n",
      "Ep:136, loss:0.00000, loss_test:0.06829, lr:6.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.057, tt:4802.812\n",
      "Ep:137, loss:0.00000, loss_test:0.06859, lr:6.36e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.056, tt:4837.756\n",
      "Ep:138, loss:0.00000, loss_test:0.06876, lr:6.30e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.043, tt:4871.008\n",
      "Ep:139, loss:0.00000, loss_test:0.06861, lr:6.24e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.016, tt:4902.172\n",
      "Ep:140, loss:0.00000, loss_test:0.06886, lr:6.17e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.991, tt:4933.800\n",
      "Ep:141, loss:0.00000, loss_test:0.06885, lr:6.11e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.983, tt:4967.586\n",
      "Ep:142, loss:0.00000, loss_test:0.06841, lr:6.05e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.955, tt:4998.634\n",
      "Ep:143, loss:0.00000, loss_test:0.06858, lr:5.99e-03, fs:0.87432 (r=0.808,p=0.952),  time:34.947, tt:5032.361\n",
      "Ep:144, loss:0.00000, loss_test:0.06864, lr:5.93e-03, fs:0.87432 (r=0.808,p=0.952),  time:34.955, tt:5068.543\n",
      "Ep:145, loss:0.00000, loss_test:0.06830, lr:5.87e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.953, tt:5103.112\n",
      "Ep:146, loss:0.00000, loss_test:0.06884, lr:5.81e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.947, tt:5137.260\n",
      "Ep:147, loss:0.00000, loss_test:0.06897, lr:5.75e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.926, tt:5169.114\n",
      "Ep:148, loss:0.00000, loss_test:0.06865, lr:5.70e-03, fs:0.87432 (r=0.808,p=0.952),  time:34.906, tt:5200.934\n",
      "Ep:149, loss:0.00000, loss_test:0.06844, lr:5.64e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.894, tt:5234.085\n",
      "Ep:150, loss:0.00000, loss_test:0.06863, lr:5.58e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.879, tt:5266.685\n",
      "Ep:151, loss:0.00000, loss_test:0.06881, lr:5.53e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.864, tt:5299.348\n",
      "Ep:152, loss:0.00000, loss_test:0.06877, lr:5.47e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.832, tt:5329.323\n",
      "Ep:153, loss:0.00000, loss_test:0.06882, lr:5.42e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.806, tt:5360.139\n",
      "Ep:154, loss:0.00000, loss_test:0.06870, lr:5.36e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.783, tt:5391.383\n",
      "Ep:155, loss:0.00000, loss_test:0.06868, lr:5.31e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.761, tt:5422.694\n",
      "Ep:156, loss:0.00000, loss_test:0.06874, lr:5.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.734, tt:5453.267\n",
      "Ep:157, loss:0.00000, loss_test:0.06877, lr:5.20e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.721, tt:5485.874\n",
      "Ep:158, loss:0.00000, loss_test:0.06888, lr:5.15e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.697, tt:5516.773\n",
      "Ep:159, loss:0.00000, loss_test:0.06890, lr:5.10e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.670, tt:5547.125\n",
      "Ep:160, loss:0.00000, loss_test:0.06898, lr:5.05e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.652, tt:5578.994\n",
      "Ep:161, loss:0.00000, loss_test:0.06902, lr:5.00e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.638, tt:5611.309\n",
      "Ep:162, loss:0.00000, loss_test:0.06911, lr:4.95e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.620, tt:5643.137\n",
      "Ep:163, loss:0.00000, loss_test:0.06907, lr:4.90e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.605, tt:5675.153\n",
      "Ep:164, loss:0.00000, loss_test:0.06894, lr:4.85e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.592, tt:5707.701\n",
      "Ep:165, loss:0.00000, loss_test:0.06892, lr:4.80e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.576, tt:5739.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:166, loss:0.00000, loss_test:0.06914, lr:4.75e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.564, tt:5772.167\n",
      "Ep:167, loss:0.00000, loss_test:0.06913, lr:4.71e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.550, tt:5804.338\n",
      "Ep:168, loss:0.00000, loss_test:0.06897, lr:4.66e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.537, tt:5836.709\n",
      "Ep:169, loss:0.00000, loss_test:0.06906, lr:4.61e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.526, tt:5869.488\n",
      "Ep:170, loss:0.00000, loss_test:0.06930, lr:4.57e-03, fs:0.87293 (r=0.798,p=0.963),  time:34.517, tt:5902.344\n",
      "Ep:171, loss:0.00000, loss_test:0.06952, lr:4.52e-03, fs:0.87293 (r=0.798,p=0.963),  time:34.500, tt:5933.961\n",
      "Ep:172, loss:0.00000, loss_test:0.06930, lr:4.48e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.474, tt:5964.008\n",
      "Ep:173, loss:0.00000, loss_test:0.06898, lr:4.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.452, tt:5994.631\n",
      "Ep:174, loss:0.00000, loss_test:0.06891, lr:4.39e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.434, tt:6025.999\n",
      "Ep:175, loss:0.00000, loss_test:0.06897, lr:4.34e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.421, tt:6058.062\n",
      "Ep:176, loss:0.00000, loss_test:0.06917, lr:4.30e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.406, tt:6089.841\n",
      "Ep:177, loss:0.00000, loss_test:0.06928, lr:4.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.392, tt:6121.848\n",
      "Ep:178, loss:0.00000, loss_test:0.06903, lr:4.21e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.373, tt:6152.855\n",
      "Ep:179, loss:0.00000, loss_test:0.06886, lr:4.17e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.344, tt:6181.839\n",
      "Ep:180, loss:0.00000, loss_test:0.06895, lr:4.13e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.334, tt:6214.483\n",
      "Ep:181, loss:0.00000, loss_test:0.06912, lr:4.09e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.308, tt:6244.047\n",
      "Ep:182, loss:0.00000, loss_test:0.06905, lr:4.05e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.278, tt:6272.932\n",
      "Ep:183, loss:0.00000, loss_test:0.06914, lr:4.01e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.264, tt:6304.639\n",
      "Ep:184, loss:0.00000, loss_test:0.06907, lr:3.97e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.248, tt:6335.842\n",
      "Ep:185, loss:0.00000, loss_test:0.06902, lr:3.93e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.226, tt:6366.059\n",
      "Ep:186, loss:0.00000, loss_test:0.06900, lr:3.89e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.207, tt:6396.779\n",
      "Ep:187, loss:0.00000, loss_test:0.06882, lr:3.85e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.194, tt:6428.400\n",
      "Ep:188, loss:0.00000, loss_test:0.06865, lr:3.81e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.172, tt:6458.559\n",
      "Ep:189, loss:0.00000, loss_test:0.06890, lr:3.77e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.152, tt:6488.967\n",
      "Ep:190, loss:0.00000, loss_test:0.06900, lr:3.73e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.118, tt:6516.542\n",
      "Ep:191, loss:0.00000, loss_test:0.06914, lr:3.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.096, tt:6546.442\n",
      "Ep:192, loss:0.00000, loss_test:0.06903, lr:3.66e-03, fs:0.87293 (r=0.798,p=0.963),  time:34.081, tt:6577.635\n",
      "Ep:193, loss:0.00000, loss_test:0.06883, lr:3.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.067, tt:6609.082\n",
      "Ep:194, loss:0.00000, loss_test:0.06881, lr:3.59e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.056, tt:6640.941\n",
      "Ep:195, loss:0.00000, loss_test:0.06892, lr:3.55e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.042, tt:6672.165\n",
      "Ep:196, loss:0.00000, loss_test:0.06912, lr:3.52e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.024, tt:6702.758\n",
      "Ep:197, loss:0.00000, loss_test:0.06905, lr:3.48e-03, fs:0.87912 (r=0.808,p=0.964),  time:34.007, tt:6733.392\n",
      "Ep:198, loss:0.00000, loss_test:0.06866, lr:3.45e-03, fs:0.87912 (r=0.808,p=0.964),  time:33.967, tt:6759.376\n",
      "Ep:199, loss:0.00000, loss_test:0.06887, lr:3.41e-03, fs:0.87912 (r=0.808,p=0.964),  time:33.929, tt:6785.788\n",
      "Ep:200, loss:0.00000, loss_test:0.06903, lr:3.38e-03, fs:0.87912 (r=0.808,p=0.964),  time:33.888, tt:6811.407\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02174, lr:6.00e-02, fs:0.61468 (r=0.770,p=0.511),  time:17.837, tt:17.837\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02302, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.221, tt:42.442\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02396, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.982, tt:74.945\n",
      "Ep:3, loss:0.00005, loss_test:0.02331, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.552, tt:114.209\n",
      "Ep:4, loss:0.00004, loss_test:0.02181, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:30.898, tt:154.492\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02021, lr:6.00e-02, fs:0.66932 (r=0.966,p=0.512),  time:32.316, tt:193.896\n",
      "Ep:6, loss:0.00004, loss_test:0.01932, lr:6.00e-02, fs:0.66968 (r=0.851,p=0.552),  time:33.460, tt:234.223\n",
      "Ep:7, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.67662 (r=0.782,p=0.596),  time:34.084, tt:272.668\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02032, lr:6.00e-02, fs:0.68367 (r=0.770,p=0.615),  time:35.195, tt:316.757\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.02029, lr:6.00e-02, fs:0.66332 (r=0.759,p=0.589),  time:35.796, tt:357.956\n",
      "Ep:10, loss:0.00003, loss_test:0.02011, lr:6.00e-02, fs:0.67925 (r=0.828,p=0.576),  time:36.064, tt:396.707\n",
      "Ep:11, loss:0.00003, loss_test:0.02007, lr:6.00e-02, fs:0.67593 (r=0.839,p=0.566),  time:36.473, tt:437.681\n",
      "Ep:12, loss:0.00003, loss_test:0.01997, lr:6.00e-02, fs:0.66977 (r=0.828,p=0.562),  time:36.665, tt:476.648\n",
      "Ep:13, loss:0.00003, loss_test:0.01994, lr:6.00e-02, fs:0.66341 (r=0.782,p=0.576),  time:36.861, tt:516.052\n",
      "Ep:14, loss:0.00003, loss_test:0.02002, lr:6.00e-02, fs:0.67327 (r=0.782,p=0.591),  time:37.057, tt:555.850\n",
      "Ep:15, loss:0.00003, loss_test:0.02006, lr:6.00e-02, fs:0.67358 (r=0.747,p=0.613),  time:37.327, tt:597.232\n",
      "Ep:16, loss:0.00003, loss_test:0.01986, lr:6.00e-02, fs:0.68421 (r=0.747,p=0.631),  time:37.390, tt:635.623\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01934, lr:6.00e-02, fs:0.68063 (r=0.747,p=0.625),  time:37.449, tt:674.083\n",
      "Ep:18, loss:0.00003, loss_test:0.01891, lr:6.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:37.590, tt:714.211\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01873, lr:6.00e-02, fs:0.69072 (r=0.770,p=0.626),  time:37.760, tt:755.210\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01873, lr:6.00e-02, fs:0.69841 (r=0.759,p=0.647),  time:37.891, tt:795.710\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01890, lr:6.00e-02, fs:0.72131 (r=0.759,p=0.688),  time:38.013, tt:836.294\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01915, lr:6.00e-02, fs:0.70718 (r=0.736,p=0.681),  time:38.145, tt:877.337\n",
      "Ep:23, loss:0.00002, loss_test:0.01932, lr:6.00e-02, fs:0.70718 (r=0.736,p=0.681),  time:38.267, tt:918.415\n",
      "Ep:24, loss:0.00002, loss_test:0.01935, lr:6.00e-02, fs:0.70718 (r=0.736,p=0.681),  time:38.298, tt:957.444\n",
      "Ep:25, loss:0.00002, loss_test:0.01927, lr:6.00e-02, fs:0.71111 (r=0.736,p=0.688),  time:38.582, tt:1003.120\n",
      "Ep:26, loss:0.00002, loss_test:0.01921, lr:6.00e-02, fs:0.71508 (r=0.736,p=0.696),  time:38.636, tt:1043.164\n",
      "Ep:27, loss:0.00002, loss_test:0.01926, lr:6.00e-02, fs:0.70787 (r=0.724,p=0.692),  time:38.858, tt:1088.023\n",
      "Ep:28, loss:0.00002, loss_test:0.01938, lr:6.00e-02, fs:0.71186 (r=0.724,p=0.700),  time:39.000, tt:1130.991\n",
      "Ep:29, loss:0.00002, loss_test:0.01944, lr:6.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:39.060, tt:1171.794\n",
      "Ep:30, loss:0.00002, loss_test:0.01940, lr:6.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:39.202, tt:1215.254\n",
      "Ep:31, loss:0.00002, loss_test:0.01946, lr:6.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:39.312, tt:1257.991\n",
      "Ep:32, loss:0.00002, loss_test:0.01957, lr:6.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:39.400, tt:1300.198\n",
      "Ep:33, loss:0.00002, loss_test:0.01971, lr:5.94e-02, fs:0.72727 (r=0.736,p=0.719),  time:39.430, tt:1340.632\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01989, lr:5.94e-02, fs:0.72414 (r=0.724,p=0.724),  time:39.473, tt:1381.553\n",
      "Ep:35, loss:0.00002, loss_test:0.02003, lr:5.94e-02, fs:0.72832 (r=0.724,p=0.733),  time:39.519, tt:1422.676\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.02008, lr:5.94e-02, fs:0.72832 (r=0.724,p=0.733),  time:39.568, tt:1464.003\n",
      "Ep:37, loss:0.00002, loss_test:0.02010, lr:5.94e-02, fs:0.72832 (r=0.724,p=0.733),  time:39.695, tt:1508.420\n",
      "Ep:38, loss:0.00002, loss_test:0.02023, lr:5.94e-02, fs:0.72832 (r=0.724,p=0.733),  time:39.785, tt:1551.603\n",
      "Ep:39, loss:0.00002, loss_test:0.02030, lr:5.94e-02, fs:0.73256 (r=0.724,p=0.741),  time:39.839, tt:1593.565\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.02032, lr:5.94e-02, fs:0.73256 (r=0.724,p=0.741),  time:39.903, tt:1636.008\n",
      "Ep:41, loss:0.00002, loss_test:0.02053, lr:5.94e-02, fs:0.72515 (r=0.713,p=0.738),  time:39.965, tt:1678.549\n",
      "Ep:42, loss:0.00002, loss_test:0.02065, lr:5.94e-02, fs:0.72515 (r=0.713,p=0.738),  time:39.984, tt:1719.328\n",
      "Ep:43, loss:0.00001, loss_test:0.02072, lr:5.94e-02, fs:0.72515 (r=0.713,p=0.738),  time:40.066, tt:1762.926\n",
      "Ep:44, loss:0.00001, loss_test:0.02072, lr:5.94e-02, fs:0.73684 (r=0.724,p=0.750),  time:40.105, tt:1804.721\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.02082, lr:5.94e-02, fs:0.74251 (r=0.713,p=0.775),  time:40.105, tt:1844.842\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.02088, lr:5.94e-02, fs:0.72727 (r=0.690,p=0.769),  time:40.156, tt:1887.328\n",
      "Ep:47, loss:0.00001, loss_test:0.02095, lr:5.94e-02, fs:0.72727 (r=0.690,p=0.769),  time:40.223, tt:1930.695\n",
      "Ep:48, loss:0.00001, loss_test:0.02095, lr:5.94e-02, fs:0.74251 (r=0.713,p=0.775),  time:40.267, tt:1973.066\n",
      "Ep:49, loss:0.00001, loss_test:0.02098, lr:5.94e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.293, tt:2014.638\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.02114, lr:5.94e-02, fs:0.72727 (r=0.690,p=0.769),  time:40.336, tt:2057.147\n",
      "Ep:51, loss:0.00001, loss_test:0.02130, lr:5.94e-02, fs:0.73620 (r=0.690,p=0.789),  time:40.331, tt:2097.202\n",
      "Ep:52, loss:0.00001, loss_test:0.02146, lr:5.94e-02, fs:0.73171 (r=0.690,p=0.779),  time:40.335, tt:2137.742\n",
      "Ep:53, loss:0.00001, loss_test:0.02153, lr:5.94e-02, fs:0.73939 (r=0.701,p=0.782),  time:40.379, tt:2180.445\n",
      "Ep:54, loss:0.00001, loss_test:0.02152, lr:5.94e-02, fs:0.73939 (r=0.701,p=0.782),  time:40.355, tt:2219.499\n",
      "Ep:55, loss:0.00001, loss_test:0.02160, lr:5.94e-02, fs:0.73171 (r=0.690,p=0.779),  time:40.342, tt:2259.178\n",
      "Ep:56, loss:0.00001, loss_test:0.02168, lr:5.94e-02, fs:0.73171 (r=0.690,p=0.779),  time:40.358, tt:2300.421\n",
      "Ep:57, loss:0.00001, loss_test:0.02180, lr:5.94e-02, fs:0.73620 (r=0.690,p=0.789),  time:40.337, tt:2339.559\n",
      "Ep:58, loss:0.00001, loss_test:0.02197, lr:5.94e-02, fs:0.74074 (r=0.690,p=0.800),  time:40.360, tt:2381.217\n",
      "Ep:59, loss:0.00001, loss_test:0.02214, lr:5.94e-02, fs:0.75000 (r=0.690,p=0.822),  time:40.343, tt:2420.574\n",
      "Ep:60, loss:0.00001, loss_test:0.02219, lr:5.94e-02, fs:0.74534 (r=0.690,p=0.811),  time:40.322, tt:2459.660\n",
      "Ep:61, loss:0.00001, loss_test:0.02220, lr:5.88e-02, fs:0.75472 (r=0.690,p=0.833),  time:40.341, tt:2501.167\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.02231, lr:5.88e-02, fs:0.75472 (r=0.690,p=0.833),  time:40.351, tt:2542.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.02247, lr:5.88e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.356, tt:2582.778\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.02257, lr:5.88e-02, fs:0.75159 (r=0.678,p=0.843),  time:40.322, tt:2620.924\n",
      "Ep:65, loss:0.00001, loss_test:0.02261, lr:5.88e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.313, tt:2660.671\n",
      "Ep:66, loss:0.00001, loss_test:0.02275, lr:5.88e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.315, tt:2701.105\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.02285, lr:5.88e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.312, tt:2741.194\n",
      "Ep:68, loss:0.00001, loss_test:0.02294, lr:5.88e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.314, tt:2781.696\n",
      "Ep:69, loss:0.00001, loss_test:0.02312, lr:5.88e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.324, tt:2822.696\n",
      "Ep:70, loss:0.00001, loss_test:0.02319, lr:5.88e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.316, tt:2862.419\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.02342, lr:5.88e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.339, tt:2904.442\n",
      "Ep:72, loss:0.00001, loss_test:0.02353, lr:5.88e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.334, tt:2944.417\n",
      "Ep:73, loss:0.00001, loss_test:0.02371, lr:5.88e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.351, tt:2985.948\n",
      "Ep:74, loss:0.00001, loss_test:0.02381, lr:5.88e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.373, tt:3027.955\n",
      "Ep:75, loss:0.00001, loss_test:0.02363, lr:5.88e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.423, tt:3072.182\n",
      "Ep:76, loss:0.00001, loss_test:0.02381, lr:5.88e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.427, tt:3112.846\n",
      "Ep:77, loss:0.00001, loss_test:0.02405, lr:5.88e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.431, tt:3153.619\n",
      "Ep:78, loss:0.00001, loss_test:0.02425, lr:5.88e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.426, tt:3193.635\n",
      "Ep:79, loss:0.00001, loss_test:0.02420, lr:5.88e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.448, tt:3235.870\n",
      "Ep:80, loss:0.00001, loss_test:0.02434, lr:5.88e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.475, tt:3278.438\n",
      "Ep:81, loss:0.00001, loss_test:0.02448, lr:5.88e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.486, tt:3319.842\n",
      "Ep:82, loss:0.00001, loss_test:0.02450, lr:5.82e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.511, tt:3362.373\n",
      "Ep:83, loss:0.00001, loss_test:0.02460, lr:5.76e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.524, tt:3404.019\n",
      "Ep:84, loss:0.00001, loss_test:0.02466, lr:5.71e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.526, tt:3444.695\n",
      "Ep:85, loss:0.00001, loss_test:0.02487, lr:5.65e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.541, tt:3486.510\n",
      "Ep:86, loss:0.00001, loss_test:0.02494, lr:5.59e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.548, tt:3527.641\n",
      "Ep:87, loss:0.00001, loss_test:0.02518, lr:5.54e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.612, tt:3573.847\n",
      "Ep:88, loss:0.00001, loss_test:0.02535, lr:5.48e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.649, tt:3617.749\n",
      "Ep:89, loss:0.00001, loss_test:0.02529, lr:5.43e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.668, tt:3660.127\n",
      "Ep:90, loss:0.00001, loss_test:0.02536, lr:5.37e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.699, tt:3703.650\n",
      "Ep:91, loss:0.00001, loss_test:0.02561, lr:5.32e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.701, tt:3744.494\n",
      "Ep:92, loss:0.00001, loss_test:0.02564, lr:5.27e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.710, tt:3786.057\n",
      "Ep:93, loss:0.00001, loss_test:0.02571, lr:5.21e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.729, tt:3828.552\n",
      "Ep:94, loss:0.00001, loss_test:0.02587, lr:5.16e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.711, tt:3867.553\n",
      "Ep:95, loss:0.00001, loss_test:0.02614, lr:5.11e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.708, tt:3907.972\n",
      "Ep:96, loss:0.00001, loss_test:0.02626, lr:5.06e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.719, tt:3949.710\n",
      "Ep:97, loss:0.00001, loss_test:0.02640, lr:5.01e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.720, tt:3990.606\n",
      "Ep:98, loss:0.00001, loss_test:0.02650, lr:4.96e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.739, tt:4033.185\n",
      "Ep:99, loss:0.00001, loss_test:0.02664, lr:4.91e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.762, tt:4076.192\n",
      "Ep:100, loss:0.00001, loss_test:0.02673, lr:4.86e-02, fs:0.75497 (r=0.655,p=0.891),  time:40.767, tt:4117.479\n",
      "Ep:101, loss:0.00001, loss_test:0.02686, lr:4.81e-02, fs:0.75497 (r=0.655,p=0.891),  time:40.781, tt:4159.686\n",
      "Ep:102, loss:0.00001, loss_test:0.02702, lr:4.76e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.785, tt:4200.853\n",
      "Ep:103, loss:0.00001, loss_test:0.02697, lr:4.71e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.796, tt:4242.744\n",
      "Ep:104, loss:0.00001, loss_test:0.02719, lr:4.67e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.794, tt:4283.367\n",
      "Ep:105, loss:0.00001, loss_test:0.02744, lr:4.62e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.803, tt:4325.114\n",
      "Ep:106, loss:0.00001, loss_test:0.02741, lr:4.57e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.807, tt:4366.321\n",
      "Ep:107, loss:0.00001, loss_test:0.02749, lr:4.53e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.790, tt:4405.326\n",
      "Ep:108, loss:0.00001, loss_test:0.02758, lr:4.48e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.834, tt:4450.865\n",
      "Ep:109, loss:0.00001, loss_test:0.02772, lr:4.44e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.840, tt:4492.377\n",
      "Ep:110, loss:0.00001, loss_test:0.02788, lr:4.39e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.846, tt:4533.856\n",
      "Ep:111, loss:0.00001, loss_test:0.02795, lr:4.35e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.876, tt:4578.146\n",
      "Ep:112, loss:0.00000, loss_test:0.02805, lr:4.31e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.880, tt:4619.465\n",
      "Ep:113, loss:0.00000, loss_test:0.02806, lr:4.26e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.888, tt:4661.252\n",
      "Ep:114, loss:0.00000, loss_test:0.02832, lr:4.22e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.895, tt:4702.948\n",
      "Ep:115, loss:0.00000, loss_test:0.02844, lr:4.18e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.881, tt:4742.204\n",
      "Ep:116, loss:0.00000, loss_test:0.02837, lr:4.14e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.886, tt:4783.624\n",
      "Ep:117, loss:0.00000, loss_test:0.02856, lr:4.10e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.917, tt:4828.163\n",
      "Ep:118, loss:0.00000, loss_test:0.02879, lr:4.05e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.893, tt:4866.258\n",
      "Ep:119, loss:0.00000, loss_test:0.02889, lr:4.01e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.891, tt:4906.889\n",
      "Ep:120, loss:0.00000, loss_test:0.02898, lr:3.97e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.908, tt:4949.925\n",
      "Ep:121, loss:0.00000, loss_test:0.02903, lr:3.93e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.925, tt:4992.844\n",
      "Ep:122, loss:0.00000, loss_test:0.02909, lr:3.89e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.933, tt:5034.783\n",
      "Ep:123, loss:0.00000, loss_test:0.02927, lr:3.86e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.940, tt:5076.585\n",
      "Ep:124, loss:0.00000, loss_test:0.02936, lr:3.82e-02, fs:0.76190 (r=0.644,p=0.933),  time:40.942, tt:5117.810\n",
      "Ep:125, loss:0.00000, loss_test:0.02934, lr:3.78e-02, fs:0.76190 (r=0.644,p=0.933),  time:40.955, tt:5160.350\n",
      "Ep:126, loss:0.00000, loss_test:0.02955, lr:3.74e-02, fs:0.76190 (r=0.644,p=0.933),  time:40.966, tt:5202.657\n",
      "Ep:127, loss:0.00000, loss_test:0.02970, lr:3.70e-02, fs:0.76190 (r=0.644,p=0.933),  time:40.967, tt:5243.804\n",
      "Ep:128, loss:0.00000, loss_test:0.02973, lr:3.67e-02, fs:0.76190 (r=0.644,p=0.933),  time:40.972, tt:5285.422\n",
      "Ep:129, loss:0.00000, loss_test:0.02986, lr:3.63e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.025, tt:5333.238\n",
      "Ep:130, loss:0.00000, loss_test:0.03000, lr:3.59e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.037, tt:5375.872\n",
      "Ep:131, loss:0.00000, loss_test:0.03002, lr:3.56e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.029, tt:5415.820\n",
      "Ep:132, loss:0.00000, loss_test:0.03015, lr:3.52e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.031, tt:5457.079\n",
      "Ep:133, loss:0.00000, loss_test:0.03027, lr:3.49e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.041, tt:5499.513\n",
      "Ep:134, loss:0.00000, loss_test:0.03039, lr:3.45e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.043, tt:5540.852\n",
      "Ep:135, loss:0.00000, loss_test:0.03046, lr:3.42e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.051, tt:5582.902\n",
      "Ep:136, loss:0.00000, loss_test:0.03040, lr:3.38e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.049, tt:5623.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.03050, lr:3.35e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.049, tt:5664.710\n",
      "Ep:138, loss:0.00000, loss_test:0.03075, lr:3.32e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.049, tt:5705.859\n",
      "Ep:139, loss:0.00000, loss_test:0.03078, lr:3.28e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.052, tt:5747.238\n",
      "Ep:140, loss:0.00000, loss_test:0.03089, lr:3.25e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.052, tt:5788.342\n",
      "Ep:141, loss:0.00000, loss_test:0.03099, lr:3.22e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.059, tt:5830.365\n",
      "Ep:142, loss:0.00000, loss_test:0.03104, lr:3.19e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.056, tt:5871.049\n",
      "Ep:143, loss:0.00000, loss_test:0.03117, lr:3.15e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.058, tt:5912.415\n",
      "Ep:144, loss:0.00000, loss_test:0.03122, lr:3.12e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.052, tt:5952.600\n",
      "Ep:145, loss:0.00000, loss_test:0.03129, lr:3.09e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.055, tt:5994.006\n",
      "Ep:146, loss:0.00000, loss_test:0.03144, lr:3.06e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.060, tt:6035.785\n",
      "Ep:147, loss:0.00000, loss_test:0.03154, lr:3.03e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.052, tt:6075.636\n",
      "Ep:148, loss:0.00000, loss_test:0.03152, lr:3.00e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.058, tt:6117.663\n",
      "Ep:149, loss:0.00000, loss_test:0.03156, lr:2.97e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.051, tt:6157.689\n",
      "Ep:150, loss:0.00000, loss_test:0.03159, lr:2.94e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.104, tt:6206.680\n",
      "Ep:151, loss:0.00000, loss_test:0.03168, lr:2.91e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.105, tt:6247.990\n",
      "Ep:152, loss:0.00000, loss_test:0.03179, lr:2.88e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.113, tt:6290.316\n",
      "Ep:153, loss:0.00000, loss_test:0.03195, lr:2.85e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.121, tt:6332.628\n",
      "Ep:154, loss:0.00000, loss_test:0.03201, lr:2.82e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.116, tt:6372.935\n",
      "Ep:155, loss:0.00000, loss_test:0.03197, lr:2.80e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.119, tt:6414.547\n",
      "Ep:156, loss:0.00000, loss_test:0.03211, lr:2.77e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.123, tt:6456.316\n",
      "Ep:157, loss:0.00000, loss_test:0.03214, lr:2.74e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.118, tt:6496.621\n",
      "Ep:158, loss:0.00000, loss_test:0.03224, lr:2.71e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.119, tt:6537.844\n",
      "Ep:159, loss:0.00000, loss_test:0.03234, lr:2.69e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.126, tt:6580.206\n",
      "Ep:160, loss:0.00000, loss_test:0.03244, lr:2.66e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.122, tt:6620.653\n",
      "Ep:161, loss:0.00000, loss_test:0.03247, lr:2.63e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.125, tt:6662.173\n",
      "Ep:162, loss:0.00000, loss_test:0.03251, lr:2.61e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.131, tt:6704.392\n",
      "Ep:163, loss:0.00000, loss_test:0.03260, lr:2.58e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.140, tt:6747.023\n",
      "Ep:164, loss:0.00000, loss_test:0.03271, lr:2.55e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.142, tt:6788.506\n",
      "Ep:165, loss:0.00000, loss_test:0.03272, lr:2.53e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.155, tt:6831.809\n",
      "Ep:166, loss:0.00000, loss_test:0.03278, lr:2.50e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.153, tt:6872.573\n",
      "Ep:167, loss:0.00000, loss_test:0.03287, lr:2.48e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.147, tt:6912.736\n",
      "Ep:168, loss:0.00000, loss_test:0.03286, lr:2.45e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.160, tt:6956.051\n",
      "Ep:169, loss:0.00000, loss_test:0.03302, lr:2.43e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.170, tt:6998.950\n",
      "Ep:170, loss:0.00000, loss_test:0.03306, lr:2.40e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.184, tt:7042.545\n",
      "Ep:171, loss:0.00000, loss_test:0.03305, lr:2.38e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.212, tt:7088.530\n",
      "Ep:172, loss:0.00000, loss_test:0.03310, lr:2.36e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.226, tt:7132.038\n",
      "Ep:173, loss:0.00000, loss_test:0.03322, lr:2.33e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.232, tt:7174.403\n",
      "Ep:174, loss:0.00000, loss_test:0.03329, lr:2.31e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.245, tt:7217.823\n",
      "Ep:175, loss:0.00000, loss_test:0.03331, lr:2.29e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.259, tt:7261.521\n",
      "Ep:176, loss:0.00000, loss_test:0.03336, lr:2.26e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.264, tt:7303.811\n",
      "Ep:177, loss:0.00000, loss_test:0.03348, lr:2.24e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.261, tt:7344.542\n",
      "Ep:178, loss:0.00000, loss_test:0.03354, lr:2.22e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.266, tt:7386.663\n",
      "Ep:179, loss:0.00000, loss_test:0.03356, lr:2.20e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.273, tt:7429.182\n",
      "Ep:180, loss:0.00000, loss_test:0.03362, lr:2.17e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.272, tt:7470.169\n",
      "Ep:181, loss:0.00000, loss_test:0.03366, lr:2.15e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.271, tt:7511.368\n",
      "Ep:182, loss:0.00000, loss_test:0.03367, lr:2.13e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.267, tt:7551.806\n",
      "Ep:183, loss:0.00000, loss_test:0.03374, lr:2.11e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.269, tt:7593.505\n",
      "Ep:184, loss:0.00000, loss_test:0.03383, lr:2.09e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.268, tt:7634.592\n",
      "Ep:185, loss:0.00000, loss_test:0.03390, lr:2.07e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.272, tt:7676.542\n",
      "Ep:186, loss:0.00000, loss_test:0.03394, lr:2.05e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.266, tt:7716.769\n",
      "Ep:187, loss:0.00000, loss_test:0.03398, lr:2.03e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.269, tt:7758.663\n",
      "Ep:188, loss:0.00000, loss_test:0.03404, lr:2.01e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.277, tt:7801.411\n",
      "Ep:189, loss:0.00000, loss_test:0.03405, lr:1.99e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.270, tt:7841.266\n",
      "Ep:190, loss:0.00000, loss_test:0.03411, lr:1.97e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.265, tt:7881.668\n",
      "Ep:191, loss:0.00000, loss_test:0.03417, lr:1.95e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.293, tt:7928.275\n",
      "Ep:192, loss:0.00000, loss_test:0.03420, lr:1.93e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.288, tt:7968.605\n",
      "Ep:193, loss:0.00000, loss_test:0.03425, lr:1.91e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.286, tt:8009.487\n",
      "Ep:194, loss:0.00000, loss_test:0.03433, lr:1.89e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.286, tt:8050.768\n",
      "Ep:195, loss:0.00000, loss_test:0.03438, lr:1.87e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.286, tt:8092.064\n",
      "Ep:196, loss:0.00000, loss_test:0.03443, lr:1.85e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.290, tt:8134.094\n",
      "Ep:197, loss:0.00000, loss_test:0.03444, lr:1.83e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.289, tt:8175.137\n",
      "Ep:198, loss:0.00000, loss_test:0.03444, lr:1.81e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.286, tt:8215.887\n",
      "Ep:199, loss:0.00000, loss_test:0.03453, lr:1.80e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.288, tt:8257.505\n",
      "Ep:200, loss:0.00000, loss_test:0.03462, lr:1.78e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.280, tt:8297.311\n",
      "Ep:201, loss:0.00000, loss_test:0.03461, lr:1.76e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.281, tt:8338.677\n",
      "Ep:202, loss:0.00000, loss_test:0.03463, lr:1.74e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.289, tt:8381.696\n",
      "Ep:203, loss:0.00000, loss_test:0.03468, lr:1.73e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.280, tt:8421.080\n",
      "Ep:204, loss:0.00000, loss_test:0.03475, lr:1.71e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.281, tt:8462.530\n",
      "Ep:205, loss:0.00000, loss_test:0.03478, lr:1.69e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.284, tt:8504.474\n",
      "Ep:206, loss:0.00000, loss_test:0.03482, lr:1.67e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.280, tt:8544.950\n",
      "Ep:207, loss:0.00000, loss_test:0.03485, lr:1.66e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.286, tt:8587.460\n",
      "Ep:208, loss:0.00000, loss_test:0.03492, lr:1.64e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.286, tt:8628.828\n",
      "Ep:209, loss:0.00000, loss_test:0.03491, lr:1.62e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.291, tt:8671.085\n",
      "Ep:210, loss:0.00000, loss_test:0.03495, lr:1.61e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.298, tt:8713.971\n",
      "Ep:211, loss:0.00000, loss_test:0.03501, lr:1.59e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.293, tt:8754.128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00000, loss_test:0.03504, lr:1.58e-02, fs:0.76712 (r=0.644,p=0.949),  time:41.290, tt:8794.863\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14370, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.305, tt:35.305\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14256, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.091, tt:74.182\n",
      "Ep:2, loss:0.00028, loss_test:0.14056, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.986, tt:101.957\n",
      "Ep:3, loss:0.00027, loss_test:0.13710, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:35.937, tt:143.748\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13116, lr:1.00e-02, fs:0.66122 (r=0.931,p=0.513),  time:37.333, tt:186.664\n",
      "Ep:5, loss:0.00025, loss_test:0.12204, lr:1.00e-02, fs:0.67290 (r=0.828,p=0.567),  time:38.027, tt:228.163\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11671, lr:1.00e-02, fs:0.67797 (r=0.690,p=0.667),  time:38.890, tt:272.230\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11546, lr:1.00e-02, fs:0.63415 (r=0.598,p=0.675),  time:39.278, tt:314.227\n",
      "Ep:8, loss:0.00021, loss_test:0.11320, lr:1.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:39.791, tt:358.116\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11158, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:40.129, tt:401.290\n",
      "Ep:10, loss:0.00020, loss_test:0.11005, lr:1.00e-02, fs:0.69880 (r=0.667,p=0.734),  time:40.535, tt:445.885\n",
      "Ep:11, loss:0.00019, loss_test:0.10707, lr:1.00e-02, fs:0.71856 (r=0.690,p=0.750),  time:40.727, tt:488.723\n",
      "Ep:12, loss:0.00018, loss_test:0.10441, lr:1.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:40.800, tt:530.398\n",
      "Ep:13, loss:0.00017, loss_test:0.10352, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:40.875, tt:572.246\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10013, lr:1.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.982, tt:614.734\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09775, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:41.359, tt:661.740\n",
      "Ep:16, loss:0.00016, loss_test:0.09746, lr:1.00e-02, fs:0.73171 (r=0.690,p=0.779),  time:41.494, tt:705.395\n",
      "Ep:17, loss:0.00015, loss_test:0.09524, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:41.550, tt:747.897\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09530, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:41.609, tt:790.575\n",
      "Ep:19, loss:0.00014, loss_test:0.09470, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:41.618, tt:832.369\n",
      "Ep:20, loss:0.00013, loss_test:0.09200, lr:1.00e-02, fs:0.76744 (r=0.759,p=0.776),  time:41.607, tt:873.746\n",
      "Ep:21, loss:0.00013, loss_test:0.09505, lr:1.00e-02, fs:0.76190 (r=0.736,p=0.790),  time:41.524, tt:913.527\n",
      "Ep:22, loss:0.00012, loss_test:0.09396, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:41.522, tt:955.017\n",
      "Ep:23, loss:0.00012, loss_test:0.09499, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:41.566, tt:997.592\n",
      "Ep:24, loss:0.00011, loss_test:0.09366, lr:1.00e-02, fs:0.76744 (r=0.759,p=0.776),  time:41.665, tt:1041.619\n",
      "Ep:25, loss:0.00011, loss_test:0.09414, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:41.746, tt:1085.405\n",
      "Ep:26, loss:0.00011, loss_test:0.09306, lr:1.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:41.835, tt:1129.532\n",
      "Ep:27, loss:0.00010, loss_test:0.09444, lr:1.00e-02, fs:0.78313 (r=0.747,p=0.823),  time:41.918, tt:1173.707\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.09291, lr:1.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:41.906, tt:1215.277\n",
      "Ep:29, loss:0.00009, loss_test:0.09259, lr:1.00e-02, fs:0.79042 (r=0.759,p=0.825),  time:41.934, tt:1258.016\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.09303, lr:1.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:41.913, tt:1299.291\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.09399, lr:1.00e-02, fs:0.79268 (r=0.747,p=0.844),  time:41.866, tt:1339.727\n",
      "Ep:32, loss:0.00008, loss_test:0.09054, lr:1.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:41.926, tt:1383.551\n",
      "Ep:33, loss:0.00008, loss_test:0.09590, lr:1.00e-02, fs:0.78750 (r=0.724,p=0.863),  time:41.880, tt:1423.904\n",
      "Ep:34, loss:0.00008, loss_test:0.09026, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:41.851, tt:1464.771\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.09637, lr:1.00e-02, fs:0.80000 (r=0.736,p=0.877),  time:41.870, tt:1507.329\n",
      "Ep:36, loss:0.00007, loss_test:0.09068, lr:1.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:41.914, tt:1550.827\n",
      "Ep:37, loss:0.00007, loss_test:0.09755, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:41.922, tt:1593.046\n",
      "Ep:38, loss:0.00007, loss_test:0.09007, lr:1.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:41.959, tt:1636.382\n",
      "Ep:39, loss:0.00006, loss_test:0.09931, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:41.969, tt:1678.780\n",
      "Ep:40, loss:0.00006, loss_test:0.09346, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:41.978, tt:1721.086\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.09950, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:41.987, tt:1763.437\n",
      "Ep:42, loss:0.00006, loss_test:0.09151, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.960, tt:1804.273\n",
      "Ep:43, loss:0.00005, loss_test:0.09930, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:41.987, tt:1847.408\n",
      "Ep:44, loss:0.00005, loss_test:0.09265, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:41.975, tt:1888.888\n",
      "Ep:45, loss:0.00005, loss_test:0.10207, lr:1.00e-02, fs:0.78205 (r=0.701,p=0.884),  time:41.983, tt:1931.203\n",
      "Ep:46, loss:0.00005, loss_test:0.09406, lr:1.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.998, tt:1973.906\n",
      "Ep:47, loss:0.00005, loss_test:0.09969, lr:1.00e-02, fs:0.78205 (r=0.701,p=0.884),  time:42.003, tt:2016.155\n",
      "Ep:48, loss:0.00004, loss_test:0.09655, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:41.977, tt:2056.858\n",
      "Ep:49, loss:0.00004, loss_test:0.09699, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:41.919, tt:2095.949\n",
      "Ep:50, loss:0.00004, loss_test:0.10136, lr:1.00e-02, fs:0.78205 (r=0.701,p=0.884),  time:41.908, tt:2137.317\n",
      "Ep:51, loss:0.00004, loss_test:0.09547, lr:1.00e-02, fs:0.79245 (r=0.724,p=0.875),  time:41.936, tt:2180.655\n",
      "Ep:52, loss:0.00004, loss_test:0.10166, lr:9.90e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.919, tt:2221.717\n",
      "Ep:53, loss:0.00004, loss_test:0.09576, lr:9.80e-03, fs:0.80000 (r=0.736,p=0.877),  time:41.886, tt:2261.820\n",
      "Ep:54, loss:0.00003, loss_test:0.09849, lr:9.70e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.874, tt:2303.064\n",
      "Ep:55, loss:0.00003, loss_test:0.09782, lr:9.61e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.868, tt:2344.615\n",
      "Ep:56, loss:0.00003, loss_test:0.09657, lr:9.51e-03, fs:0.79245 (r=0.724,p=0.875),  time:41.841, tt:2384.925\n",
      "Ep:57, loss:0.00003, loss_test:0.10042, lr:9.41e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.850, tt:2427.280\n",
      "Ep:58, loss:0.00003, loss_test:0.09784, lr:9.32e-03, fs:0.79245 (r=0.724,p=0.875),  time:41.854, tt:2469.379\n",
      "Ep:59, loss:0.00003, loss_test:0.10063, lr:9.23e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.866, tt:2511.969\n",
      "Ep:60, loss:0.00003, loss_test:0.09575, lr:9.14e-03, fs:0.78481 (r=0.713,p=0.873),  time:41.845, tt:2552.545\n",
      "Ep:61, loss:0.00003, loss_test:0.10277, lr:9.04e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.857, tt:2595.133\n",
      "Ep:62, loss:0.00003, loss_test:0.09241, lr:8.95e-03, fs:0.78981 (r=0.713,p=0.886),  time:41.831, tt:2635.336\n",
      "Ep:63, loss:0.00003, loss_test:0.10089, lr:8.86e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.850, tt:2678.388\n",
      "Ep:64, loss:0.00002, loss_test:0.09695, lr:8.78e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.857, tt:2720.691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00002, loss_test:0.09795, lr:8.69e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.849, tt:2762.006\n",
      "Ep:66, loss:0.00002, loss_test:0.10058, lr:8.60e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.859, tt:2804.572\n",
      "Ep:67, loss:0.00002, loss_test:0.09691, lr:8.51e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.866, tt:2846.899\n",
      "Ep:68, loss:0.00002, loss_test:0.09818, lr:8.43e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.863, tt:2888.537\n",
      "Ep:69, loss:0.00002, loss_test:0.10038, lr:8.35e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.827, tt:2927.907\n",
      "Ep:70, loss:0.00002, loss_test:0.09586, lr:8.26e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.822, tt:2969.398\n",
      "Ep:71, loss:0.00002, loss_test:0.10044, lr:8.18e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.828, tt:3011.646\n",
      "Ep:72, loss:0.00002, loss_test:0.09754, lr:8.10e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.820, tt:3052.833\n",
      "Ep:73, loss:0.00002, loss_test:0.09555, lr:8.02e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.833, tt:3095.635\n",
      "Ep:74, loss:0.00002, loss_test:0.09967, lr:7.94e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.844, tt:3138.277\n",
      "Ep:75, loss:0.00002, loss_test:0.10015, lr:7.86e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.882, tt:3183.016\n",
      "Ep:76, loss:0.00002, loss_test:0.09791, lr:7.78e-03, fs:0.78205 (r=0.701,p=0.884),  time:41.885, tt:3225.119\n",
      "Ep:77, loss:0.00002, loss_test:0.10244, lr:7.70e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.879, tt:3266.573\n",
      "Ep:78, loss:0.00002, loss_test:0.09457, lr:7.62e-03, fs:0.80000 (r=0.713,p=0.912),  time:41.907, tt:3310.619\n",
      "Ep:79, loss:0.00002, loss_test:0.10252, lr:7.55e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.950, tt:3355.961\n",
      "Ep:80, loss:0.00002, loss_test:0.10264, lr:7.47e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.965, tt:3399.177\n",
      "Ep:81, loss:0.00002, loss_test:0.09601, lr:7.40e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.987, tt:3442.950\n",
      "Ep:82, loss:0.00002, loss_test:0.10141, lr:7.32e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.983, tt:3484.601\n",
      "Ep:83, loss:0.00002, loss_test:0.10310, lr:7.25e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.990, tt:3527.119\n",
      "Ep:84, loss:0.00002, loss_test:0.09721, lr:7.18e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.982, tt:3568.442\n",
      "Ep:85, loss:0.00001, loss_test:0.09992, lr:7.11e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.003, tt:3612.220\n",
      "Ep:86, loss:0.00001, loss_test:0.09955, lr:7.03e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.024, tt:3656.103\n",
      "Ep:87, loss:0.00001, loss_test:0.10128, lr:6.96e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.049, tt:3700.279\n",
      "Ep:88, loss:0.00001, loss_test:0.09601, lr:6.89e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.073, tt:3744.530\n",
      "Ep:89, loss:0.00001, loss_test:0.10434, lr:6.83e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.085, tt:3787.689\n",
      "Ep:90, loss:0.00001, loss_test:0.09871, lr:6.76e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.067, tt:3828.135\n",
      "Ep:91, loss:0.00001, loss_test:0.10179, lr:6.69e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.065, tt:3870.021\n",
      "Ep:92, loss:0.00001, loss_test:0.10355, lr:6.62e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.062, tt:3911.764\n",
      "Ep:93, loss:0.00001, loss_test:0.09594, lr:6.56e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.047, tt:3952.455\n",
      "Ep:94, loss:0.00001, loss_test:0.10362, lr:6.49e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.078, tt:3997.438\n",
      "Ep:95, loss:0.00001, loss_test:0.09978, lr:6.43e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.067, tt:4038.465\n",
      "Ep:96, loss:0.00001, loss_test:0.09857, lr:6.36e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.076, tt:4081.396\n",
      "Ep:97, loss:0.00001, loss_test:0.10074, lr:6.30e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.104, tt:4126.222\n",
      "Ep:98, loss:0.00001, loss_test:0.10024, lr:6.24e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.147, tt:4172.553\n",
      "Ep:99, loss:0.00001, loss_test:0.10147, lr:6.17e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.146, tt:4214.632\n",
      "Ep:100, loss:0.00001, loss_test:0.09917, lr:6.11e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.130, tt:4255.120\n",
      "Ep:101, loss:0.00001, loss_test:0.10076, lr:6.05e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.124, tt:4296.671\n",
      "Ep:102, loss:0.00001, loss_test:0.10262, lr:5.99e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.097, tt:4335.955\n",
      "Ep:103, loss:0.00001, loss_test:0.09892, lr:5.93e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.084, tt:4376.685\n",
      "Ep:104, loss:0.00001, loss_test:0.10139, lr:5.87e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.097, tt:4420.189\n",
      "Ep:105, loss:0.00001, loss_test:0.10103, lr:5.81e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.095, tt:4462.062\n",
      "Ep:106, loss:0.00001, loss_test:0.10016, lr:5.75e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.093, tt:4503.912\n",
      "Ep:107, loss:0.00001, loss_test:0.10130, lr:5.70e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.097, tt:4546.462\n",
      "Ep:108, loss:0.00001, loss_test:0.10019, lr:5.64e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.091, tt:4587.905\n",
      "Ep:109, loss:0.00001, loss_test:0.10073, lr:5.58e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.103, tt:4631.384\n",
      "Ep:110, loss:0.00001, loss_test:0.10240, lr:5.53e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.112, tt:4674.431\n",
      "Ep:111, loss:0.00001, loss_test:0.10048, lr:5.47e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.091, tt:4714.221\n",
      "Ep:112, loss:0.00001, loss_test:0.10040, lr:5.42e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.090, tt:4756.186\n",
      "Ep:113, loss:0.00001, loss_test:0.10118, lr:5.36e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.093, tt:4798.632\n",
      "Ep:114, loss:0.00001, loss_test:0.09978, lr:5.31e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.082, tt:4839.406\n",
      "Ep:115, loss:0.00001, loss_test:0.10192, lr:5.26e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.094, tt:4882.877\n",
      "Ep:116, loss:0.00001, loss_test:0.10317, lr:5.20e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.107, tt:4926.508\n",
      "Ep:117, loss:0.00001, loss_test:0.09965, lr:5.15e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.089, tt:4966.540\n",
      "Ep:118, loss:0.00001, loss_test:0.10234, lr:5.10e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.147, tt:5015.445\n",
      "Ep:119, loss:0.00001, loss_test:0.10168, lr:5.05e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.151, tt:5058.134\n",
      "Ep:120, loss:0.00001, loss_test:0.10079, lr:5.00e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.138, tt:5098.735\n",
      "Ep:121, loss:0.00001, loss_test:0.10154, lr:4.95e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.126, tt:5139.327\n",
      "Ep:122, loss:0.00001, loss_test:0.10099, lr:4.90e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.116, tt:5180.209\n",
      "Ep:123, loss:0.00001, loss_test:0.10087, lr:4.85e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.124, tt:5223.373\n",
      "Ep:124, loss:0.00001, loss_test:0.10183, lr:4.80e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.144, tt:5267.976\n",
      "Ep:125, loss:0.00001, loss_test:0.10187, lr:4.75e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.158, tt:5311.926\n",
      "Ep:126, loss:0.00001, loss_test:0.10189, lr:4.71e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.163, tt:5354.713\n",
      "Ep:127, loss:0.00001, loss_test:0.10143, lr:4.66e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.160, tt:5396.472\n",
      "Ep:128, loss:0.00001, loss_test:0.10169, lr:4.61e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.146, tt:5436.887\n",
      "Ep:129, loss:0.00001, loss_test:0.10216, lr:4.57e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.165, tt:5481.449\n",
      "Ep:130, loss:0.00001, loss_test:0.10183, lr:4.52e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.165, tt:5523.609\n",
      "Ep:131, loss:0.00001, loss_test:0.10226, lr:4.48e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.170, tt:5566.449\n",
      "Ep:132, loss:0.00001, loss_test:0.10205, lr:4.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.172, tt:5608.876\n",
      "Ep:133, loss:0.00001, loss_test:0.10151, lr:4.39e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.169, tt:5650.699\n",
      "Ep:134, loss:0.00001, loss_test:0.10286, lr:4.34e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.161, tt:5691.803\n",
      "Ep:135, loss:0.00001, loss_test:0.10200, lr:4.30e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.155, tt:5733.129\n",
      "Ep:136, loss:0.00001, loss_test:0.10342, lr:4.26e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.134, tt:5772.362\n",
      "Ep:137, loss:0.00001, loss_test:0.10483, lr:4.21e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.143, tt:5815.676\n",
      "Ep:138, loss:0.00001, loss_test:0.10147, lr:4.17e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.127, tt:5855.585\n",
      "Ep:139, loss:0.00001, loss_test:0.10346, lr:4.13e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.119, tt:5896.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.10447, lr:4.09e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.105, tt:5936.865\n",
      "Ep:141, loss:0.00001, loss_test:0.10180, lr:4.05e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.105, tt:5978.967\n",
      "Ep:142, loss:0.00001, loss_test:0.10311, lr:4.01e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.105, tt:6020.971\n",
      "Ep:143, loss:0.00001, loss_test:0.10547, lr:3.97e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.109, tt:6063.626\n",
      "Ep:144, loss:0.00001, loss_test:0.10294, lr:3.93e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.112, tt:6106.245\n",
      "Ep:145, loss:0.00001, loss_test:0.10194, lr:3.89e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.126, tt:6150.461\n",
      "Ep:146, loss:0.00001, loss_test:0.10441, lr:3.85e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.125, tt:6192.401\n",
      "Ep:147, loss:0.00001, loss_test:0.10351, lr:3.81e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.130, tt:6235.307\n",
      "Ep:148, loss:0.00001, loss_test:0.10188, lr:3.77e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.143, tt:6279.358\n",
      "Ep:149, loss:0.00001, loss_test:0.10438, lr:3.73e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.157, tt:6323.574\n",
      "Ep:150, loss:0.00001, loss_test:0.10513, lr:3.70e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.154, tt:6365.186\n",
      "Ep:151, loss:0.00001, loss_test:0.10295, lr:3.66e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.163, tt:6408.782\n",
      "Ep:152, loss:0.00001, loss_test:0.10293, lr:3.62e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.169, tt:6451.841\n",
      "Ep:153, loss:0.00001, loss_test:0.10404, lr:3.59e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.176, tt:6495.103\n",
      "Ep:154, loss:0.00001, loss_test:0.10354, lr:3.55e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.175, tt:6537.159\n",
      "Ep:155, loss:0.00001, loss_test:0.10336, lr:3.52e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.176, tt:6579.409\n",
      "Ep:156, loss:0.00001, loss_test:0.10358, lr:3.48e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.181, tt:6622.381\n",
      "Ep:157, loss:0.00001, loss_test:0.10391, lr:3.45e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.179, tt:6664.213\n",
      "Ep:158, loss:0.00001, loss_test:0.10402, lr:3.41e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.191, tt:6708.308\n",
      "Ep:159, loss:0.00001, loss_test:0.10330, lr:3.38e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.190, tt:6750.339\n",
      "Ep:160, loss:0.00001, loss_test:0.10398, lr:3.34e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.193, tt:6793.104\n",
      "Ep:161, loss:0.00001, loss_test:0.10366, lr:3.31e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.204, tt:6837.036\n",
      "Ep:162, loss:0.00001, loss_test:0.10376, lr:3.28e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.220, tt:6881.826\n",
      "Ep:163, loss:0.00001, loss_test:0.10404, lr:3.24e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.229, tt:6925.621\n",
      "Ep:164, loss:0.00001, loss_test:0.10396, lr:3.21e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.243, tt:6970.128\n",
      "Ep:165, loss:0.00001, loss_test:0.10424, lr:3.18e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.240, tt:7011.807\n",
      "Ep:166, loss:0.00001, loss_test:0.10493, lr:3.15e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.245, tt:7054.925\n",
      "Ep:167, loss:0.00001, loss_test:0.10415, lr:3.12e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.242, tt:7096.572\n",
      "Ep:168, loss:0.00001, loss_test:0.10349, lr:3.09e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.222, tt:7135.523\n",
      "Ep:169, loss:0.00001, loss_test:0.10513, lr:3.05e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.222, tt:7177.802\n",
      "Ep:170, loss:0.00001, loss_test:0.10550, lr:3.02e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.223, tt:7220.169\n",
      "Ep:171, loss:0.00001, loss_test:0.10432, lr:2.99e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.220, tt:7261.873\n",
      "Ep:172, loss:0.00001, loss_test:0.10428, lr:2.96e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.218, tt:7303.732\n",
      "Ep:173, loss:0.00001, loss_test:0.10478, lr:2.93e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.215, tt:7345.459\n",
      "Ep:174, loss:0.00001, loss_test:0.10450, lr:2.90e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.212, tt:7387.174\n",
      "Ep:175, loss:0.00001, loss_test:0.10514, lr:2.88e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.217, tt:7430.217\n",
      "Ep:176, loss:0.00001, loss_test:0.10478, lr:2.85e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.226, tt:7474.044\n",
      "Ep:177, loss:0.00001, loss_test:0.10438, lr:2.82e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.222, tt:7515.511\n",
      "Ep:178, loss:0.00001, loss_test:0.10479, lr:2.79e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.209, tt:7555.351\n",
      "Ep:179, loss:0.00001, loss_test:0.10492, lr:2.76e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.206, tt:7597.000\n",
      "Ep:180, loss:0.00001, loss_test:0.10473, lr:2.73e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.202, tt:7638.599\n",
      "Ep:181, loss:0.00001, loss_test:0.10523, lr:2.71e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.202, tt:7680.703\n",
      "Ep:182, loss:0.00001, loss_test:0.10516, lr:2.68e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.201, tt:7722.854\n",
      "Ep:183, loss:0.00001, loss_test:0.10503, lr:2.65e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.194, tt:7763.652\n",
      "Ep:184, loss:0.00001, loss_test:0.10484, lr:2.63e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.196, tt:7806.218\n",
      "Ep:185, loss:0.00001, loss_test:0.10536, lr:2.60e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.191, tt:7847.603\n",
      "Ep:186, loss:0.00001, loss_test:0.10590, lr:2.57e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.190, tt:7889.616\n",
      "Ep:187, loss:0.00001, loss_test:0.10554, lr:2.55e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.193, tt:7932.333\n",
      "Ep:188, loss:0.00001, loss_test:0.10498, lr:2.52e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.179, tt:7971.827\n",
      "Ep:189, loss:0.00001, loss_test:0.10513, lr:2.50e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.154, tt:8009.323\n",
      "Ep:190, loss:0.00001, loss_test:0.10534, lr:2.47e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.142, tt:8049.054\n",
      "Ep:191, loss:0.00001, loss_test:0.10542, lr:2.45e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.136, tt:8090.033\n",
      "Ep:192, loss:0.00001, loss_test:0.10541, lr:2.42e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.136, tt:8132.258\n",
      "Ep:193, loss:0.00001, loss_test:0.10530, lr:2.40e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.125, tt:8172.303\n",
      "Ep:194, loss:0.00001, loss_test:0.10542, lr:2.38e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.114, tt:8212.220\n",
      "Ep:195, loss:0.00001, loss_test:0.10571, lr:2.35e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.103, tt:8252.119\n",
      "Ep:196, loss:0.00001, loss_test:0.10637, lr:2.33e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.101, tt:8293.802\n",
      "Ep:197, loss:0.00001, loss_test:0.10602, lr:2.31e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.096, tt:8335.024\n",
      "Ep:198, loss:0.00001, loss_test:0.10534, lr:2.28e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.094, tt:8376.777\n",
      "Ep:199, loss:0.00000, loss_test:0.10563, lr:2.26e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.088, tt:8417.650\n",
      "Ep:200, loss:0.00000, loss_test:0.10587, lr:2.24e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.085, tt:8459.118\n",
      "Ep:201, loss:0.00000, loss_test:0.10542, lr:2.21e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.082, tt:8500.608\n",
      "Ep:202, loss:0.00000, loss_test:0.10548, lr:2.19e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.077, tt:8541.591\n",
      "Ep:203, loss:0.00000, loss_test:0.10605, lr:2.17e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.083, tt:8584.899\n",
      "Ep:204, loss:0.00000, loss_test:0.10575, lr:2.15e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.077, tt:8625.722\n",
      "Ep:205, loss:0.00000, loss_test:0.10566, lr:2.13e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.074, tt:8667.209\n",
      "Ep:206, loss:0.00000, loss_test:0.10574, lr:2.11e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.068, tt:8708.063\n",
      "Ep:207, loss:0.00000, loss_test:0.10584, lr:2.08e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.063, tt:8749.177\n",
      "Ep:208, loss:0.00000, loss_test:0.10559, lr:2.06e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.063, tt:8791.072\n",
      "Ep:209, loss:0.00000, loss_test:0.10581, lr:2.04e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.059, tt:8832.488\n",
      "Ep:210, loss:0.00000, loss_test:0.10599, lr:2.02e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.061, tt:8874.818\n",
      "Ep:211, loss:0.00000, loss_test:0.10618, lr:2.00e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.048, tt:8914.189\n",
      "Ep:212, loss:0.00000, loss_test:0.10581, lr:1.98e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.043, tt:8955.153\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02053, lr:6.00e-02, fs:0.67857 (r=0.874,p=0.555),  time:27.020, tt:27.020\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02232, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:27.940, tt:55.881\n",
      "Ep:2, loss:0.00004, loss_test:0.02309, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.472, tt:85.416\n",
      "Ep:3, loss:0.00005, loss_test:0.02225, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:29.720, tt:118.879\n",
      "Ep:4, loss:0.00004, loss_test:0.02079, lr:6.00e-02, fs:0.67969 (r=1.000,p=0.515),  time:32.146, tt:160.730\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01939, lr:6.00e-02, fs:0.68644 (r=0.931,p=0.544),  time:33.704, tt:202.222\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01887, lr:6.00e-02, fs:0.71429 (r=0.920,p=0.584),  time:34.673, tt:242.713\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01914, lr:6.00e-02, fs:0.71498 (r=0.851,p=0.617),  time:35.226, tt:281.812\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01907, lr:6.00e-02, fs:0.69903 (r=0.828,p=0.605),  time:35.797, tt:322.177\n",
      "Ep:9, loss:0.00004, loss_test:0.01863, lr:6.00e-02, fs:0.70476 (r=0.851,p=0.602),  time:36.290, tt:362.904\n",
      "Ep:10, loss:0.00003, loss_test:0.01846, lr:6.00e-02, fs:0.72072 (r=0.920,p=0.593),  time:36.785, tt:404.636\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01836, lr:6.00e-02, fs:0.70852 (r=0.908,p=0.581),  time:37.081, tt:444.978\n",
      "Ep:12, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.70642 (r=0.885,p=0.588),  time:37.303, tt:484.937\n",
      "Ep:13, loss:0.00003, loss_test:0.01801, lr:6.00e-02, fs:0.71429 (r=0.862,p=0.610),  time:37.541, tt:525.576\n",
      "Ep:14, loss:0.00003, loss_test:0.01778, lr:6.00e-02, fs:0.72277 (r=0.839,p=0.635),  time:37.883, tt:568.249\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01745, lr:6.00e-02, fs:0.73737 (r=0.839,p=0.658),  time:38.131, tt:610.092\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01705, lr:6.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:38.343, tt:651.839\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01666, lr:6.00e-02, fs:0.76238 (r=0.885,p=0.670),  time:38.473, tt:692.519\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.76238 (r=0.885,p=0.670),  time:38.698, tt:735.265\n",
      "Ep:19, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.77612 (r=0.897,p=0.684),  time:38.856, tt:777.124\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.78000 (r=0.897,p=0.690),  time:39.005, tt:819.106\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.78788 (r=0.897,p=0.703),  time:39.144, tt:861.170\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.80000 (r=0.897,p=0.722),  time:39.291, tt:903.686\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.80412 (r=0.897,p=0.729),  time:39.381, tt:945.155\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01530, lr:6.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:39.465, tt:986.615\n",
      "Ep:25, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:39.465, tt:1026.101\n",
      "Ep:26, loss:0.00002, loss_test:0.01504, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:39.565, tt:1068.259\n",
      "Ep:27, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:39.602, tt:1108.849\n",
      "Ep:28, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:39.558, tt:1147.194\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01492, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:39.598, tt:1187.937\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:39.659, tt:1229.433\n",
      "Ep:31, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:39.673, tt:1269.522\n",
      "Ep:32, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:39.717, tt:1310.670\n",
      "Ep:33, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:39.722, tt:1350.554\n",
      "Ep:34, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.81675 (r=0.897,p=0.750),  time:39.732, tt:1390.626\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.82105 (r=0.897,p=0.757),  time:39.777, tt:1431.966\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.82540 (r=0.897,p=0.765),  time:39.805, tt:1472.784\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01440, lr:6.00e-02, fs:0.83158 (r=0.908,p=0.767),  time:39.823, tt:1513.290\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.83598 (r=0.908,p=0.775),  time:39.847, tt:1554.022\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01435, lr:6.00e-02, fs:0.84043 (r=0.908,p=0.782),  time:39.871, tt:1594.851\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.84946 (r=0.908,p=0.798),  time:39.892, tt:1635.552\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:39.940, tt:1677.479\n",
      "Ep:42, loss:0.00001, loss_test:0.01427, lr:6.00e-02, fs:0.84656 (r=0.920,p=0.784),  time:39.957, tt:1718.170\n",
      "Ep:43, loss:0.00001, loss_test:0.01422, lr:6.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:39.982, tt:1759.194\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01424, lr:6.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:39.993, tt:1799.696\n",
      "Ep:45, loss:0.00001, loss_test:0.01424, lr:6.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:40.000, tt:1839.996\n",
      "Ep:46, loss:0.00001, loss_test:0.01426, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.008, tt:1880.365\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01423, lr:6.00e-02, fs:0.84946 (r=0.908,p=0.798),  time:40.020, tt:1920.964\n",
      "Ep:48, loss:0.00001, loss_test:0.01427, lr:6.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:40.059, tt:1962.911\n",
      "Ep:49, loss:0.00001, loss_test:0.01428, lr:6.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:40.089, tt:2004.435\n",
      "Ep:50, loss:0.00001, loss_test:0.01425, lr:6.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:40.103, tt:2045.262\n",
      "Ep:51, loss:0.00001, loss_test:0.01432, lr:6.00e-02, fs:0.85246 (r=0.897,p=0.812),  time:40.127, tt:2086.612\n",
      "Ep:52, loss:0.00001, loss_test:0.01442, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:40.120, tt:2126.358\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01439, lr:6.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:40.099, tt:2165.357\n",
      "Ep:54, loss:0.00001, loss_test:0.01442, lr:6.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:40.092, tt:2205.067\n",
      "Ep:55, loss:0.00001, loss_test:0.01451, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:40.064, tt:2243.612\n",
      "Ep:56, loss:0.00001, loss_test:0.01457, lr:6.00e-02, fs:0.86034 (r=0.885,p=0.837),  time:40.086, tt:2284.903\n",
      "Ep:57, loss:0.00001, loss_test:0.01455, lr:6.00e-02, fs:0.86034 (r=0.885,p=0.837),  time:40.074, tt:2324.283\n",
      "Ep:58, loss:0.00001, loss_test:0.01464, lr:6.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:40.118, tt:2366.969\n",
      "Ep:59, loss:0.00001, loss_test:0.01475, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:40.147, tt:2408.833\n",
      "Ep:60, loss:0.00001, loss_test:0.01469, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:40.146, tt:2448.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01475, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:40.157, tt:2489.725\n",
      "Ep:62, loss:0.00001, loss_test:0.01499, lr:6.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:40.160, tt:2530.092\n",
      "Ep:63, loss:0.00001, loss_test:0.01505, lr:6.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:40.163, tt:2570.461\n",
      "Ep:64, loss:0.00001, loss_test:0.01504, lr:5.94e-02, fs:0.79518 (r=0.759,p=0.835),  time:40.161, tt:2610.436\n",
      "Ep:65, loss:0.00001, loss_test:0.01512, lr:5.88e-02, fs:0.79518 (r=0.759,p=0.835),  time:40.180, tt:2651.895\n",
      "Ep:66, loss:0.00001, loss_test:0.01521, lr:5.82e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.207, tt:2693.837\n",
      "Ep:67, loss:0.00001, loss_test:0.01518, lr:5.76e-02, fs:0.78788 (r=0.747,p=0.833),  time:40.206, tt:2734.040\n",
      "Ep:68, loss:0.00001, loss_test:0.01531, lr:5.71e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.223, tt:2775.415\n",
      "Ep:69, loss:0.00001, loss_test:0.01543, lr:5.65e-02, fs:0.79012 (r=0.736,p=0.853),  time:40.223, tt:2815.615\n",
      "Ep:70, loss:0.00001, loss_test:0.01549, lr:5.59e-02, fs:0.79012 (r=0.736,p=0.853),  time:40.237, tt:2856.852\n",
      "Ep:71, loss:0.00001, loss_test:0.01560, lr:5.54e-02, fs:0.77987 (r=0.713,p=0.861),  time:40.260, tt:2898.751\n",
      "Ep:72, loss:0.00001, loss_test:0.01563, lr:5.48e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.277, tt:2940.222\n",
      "Ep:73, loss:0.00001, loss_test:0.01565, lr:5.43e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.298, tt:2982.060\n",
      "Ep:74, loss:0.00001, loss_test:0.01582, lr:5.37e-02, fs:0.74839 (r=0.667,p=0.853),  time:40.287, tt:3021.556\n",
      "Ep:75, loss:0.00001, loss_test:0.01585, lr:5.32e-02, fs:0.75159 (r=0.678,p=0.843),  time:40.293, tt:3062.291\n",
      "Ep:76, loss:0.00001, loss_test:0.01595, lr:5.27e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.336, tt:3105.861\n",
      "Ep:77, loss:0.00001, loss_test:0.01603, lr:5.21e-02, fs:0.74839 (r=0.667,p=0.853),  time:40.349, tt:3147.253\n",
      "Ep:78, loss:0.00001, loss_test:0.01601, lr:5.16e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.352, tt:3187.833\n",
      "Ep:79, loss:0.00001, loss_test:0.01606, lr:5.11e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.362, tt:3228.928\n",
      "Ep:80, loss:0.00001, loss_test:0.01619, lr:5.06e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.366, tt:3269.676\n",
      "Ep:81, loss:0.00001, loss_test:0.01632, lr:5.01e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.343, tt:3308.108\n",
      "Ep:82, loss:0.00001, loss_test:0.01637, lr:4.96e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.353, tt:3349.298\n",
      "Ep:83, loss:0.00001, loss_test:0.01645, lr:4.91e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.371, tt:3391.128\n",
      "Ep:84, loss:0.00001, loss_test:0.01641, lr:4.86e-02, fs:0.74359 (r=0.667,p=0.841),  time:40.350, tt:3429.747\n",
      "Ep:85, loss:0.00001, loss_test:0.01653, lr:4.81e-02, fs:0.74839 (r=0.667,p=0.853),  time:40.361, tt:3471.026\n",
      "Ep:86, loss:0.00001, loss_test:0.01661, lr:4.76e-02, fs:0.74026 (r=0.655,p=0.851),  time:40.386, tt:3513.588\n",
      "Ep:87, loss:0.00001, loss_test:0.01668, lr:4.71e-02, fs:0.72848 (r=0.632,p=0.859),  time:40.393, tt:3554.614\n",
      "Ep:88, loss:0.00001, loss_test:0.01680, lr:4.67e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.398, tt:3595.427\n",
      "Ep:89, loss:0.00001, loss_test:0.01681, lr:4.62e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.408, tt:3636.763\n",
      "Ep:90, loss:0.00001, loss_test:0.01691, lr:4.57e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.408, tt:3677.166\n",
      "Ep:91, loss:0.00001, loss_test:0.01699, lr:4.53e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.405, tt:3717.241\n",
      "Ep:92, loss:0.00001, loss_test:0.01703, lr:4.48e-02, fs:0.72368 (r=0.632,p=0.846),  time:40.398, tt:3756.984\n",
      "Ep:93, loss:0.00001, loss_test:0.01710, lr:4.44e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.397, tt:3797.324\n",
      "Ep:94, loss:0.00001, loss_test:0.01716, lr:4.39e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.390, tt:3837.038\n",
      "Ep:95, loss:0.00001, loss_test:0.01727, lr:4.35e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.405, tt:3878.880\n",
      "Ep:96, loss:0.00001, loss_test:0.01732, lr:4.31e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.429, tt:3921.571\n",
      "Ep:97, loss:0.00001, loss_test:0.01742, lr:4.26e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.441, tt:3963.237\n",
      "Ep:98, loss:0.00001, loss_test:0.01746, lr:4.22e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.448, tt:4004.356\n",
      "Ep:99, loss:0.00001, loss_test:0.01753, lr:4.18e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.448, tt:4044.766\n",
      "Ep:100, loss:0.00001, loss_test:0.01758, lr:4.14e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.451, tt:4085.546\n",
      "Ep:101, loss:0.00001, loss_test:0.01765, lr:4.10e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.461, tt:4126.973\n",
      "Ep:102, loss:0.00001, loss_test:0.01773, lr:4.05e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.467, tt:4168.109\n",
      "Ep:103, loss:0.00001, loss_test:0.01778, lr:4.01e-02, fs:0.70667 (r=0.609,p=0.841),  time:40.456, tt:4207.372\n",
      "Ep:104, loss:0.00001, loss_test:0.01789, lr:3.97e-02, fs:0.71523 (r=0.621,p=0.844),  time:40.453, tt:4247.546\n",
      "Ep:105, loss:0.00001, loss_test:0.01792, lr:3.93e-02, fs:0.71141 (r=0.609,p=0.855),  time:40.449, tt:4287.550\n",
      "Ep:106, loss:0.00000, loss_test:0.01796, lr:3.89e-02, fs:0.70667 (r=0.609,p=0.841),  time:40.454, tt:4328.552\n",
      "Ep:107, loss:0.00000, loss_test:0.01809, lr:3.86e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.452, tt:4368.824\n",
      "Ep:108, loss:0.00000, loss_test:0.01811, lr:3.82e-02, fs:0.72000 (r=0.621,p=0.857),  time:40.456, tt:4409.662\n",
      "Ep:109, loss:0.00000, loss_test:0.01816, lr:3.78e-02, fs:0.71141 (r=0.609,p=0.855),  time:40.456, tt:4450.187\n",
      "Ep:110, loss:0.00000, loss_test:0.01822, lr:3.74e-02, fs:0.71622 (r=0.609,p=0.869),  time:40.458, tt:4490.838\n",
      "Ep:111, loss:0.00000, loss_test:0.01827, lr:3.70e-02, fs:0.71622 (r=0.609,p=0.869),  time:40.443, tt:4529.663\n",
      "Ep:112, loss:0.00000, loss_test:0.01834, lr:3.67e-02, fs:0.71141 (r=0.609,p=0.855),  time:40.428, tt:4568.319\n",
      "Ep:113, loss:0.00000, loss_test:0.01843, lr:3.63e-02, fs:0.70270 (r=0.598,p=0.852),  time:40.424, tt:4608.333\n",
      "Ep:114, loss:0.00000, loss_test:0.01847, lr:3.59e-02, fs:0.71233 (r=0.598,p=0.881),  time:40.473, tt:4654.371\n",
      "Ep:115, loss:0.00000, loss_test:0.01854, lr:3.56e-02, fs:0.71233 (r=0.598,p=0.881),  time:40.467, tt:4694.181\n",
      "Ep:116, loss:0.00000, loss_test:0.01858, lr:3.52e-02, fs:0.70748 (r=0.598,p=0.867),  time:40.461, tt:4733.898\n",
      "Ep:117, loss:0.00000, loss_test:0.01866, lr:3.49e-02, fs:0.71233 (r=0.598,p=0.881),  time:40.455, tt:4773.667\n",
      "Ep:118, loss:0.00000, loss_test:0.01872, lr:3.45e-02, fs:0.70748 (r=0.598,p=0.867),  time:40.442, tt:4812.545\n",
      "Ep:119, loss:0.00000, loss_test:0.01878, lr:3.42e-02, fs:0.70748 (r=0.598,p=0.867),  time:40.427, tt:4851.254\n",
      "Ep:120, loss:0.00000, loss_test:0.01882, lr:3.38e-02, fs:0.70748 (r=0.598,p=0.867),  time:40.415, tt:4890.193\n",
      "Ep:121, loss:0.00000, loss_test:0.01883, lr:3.35e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.406, tt:4929.476\n",
      "Ep:122, loss:0.00000, loss_test:0.01885, lr:3.32e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.404, tt:4969.647\n",
      "Ep:123, loss:0.00000, loss_test:0.01891, lr:3.28e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.386, tt:5007.885\n",
      "Ep:124, loss:0.00000, loss_test:0.01904, lr:3.25e-02, fs:0.70345 (r=0.586,p=0.879),  time:40.372, tt:5046.446\n",
      "Ep:125, loss:0.00000, loss_test:0.01913, lr:3.22e-02, fs:0.70345 (r=0.586,p=0.879),  time:40.358, tt:5085.121\n",
      "Ep:126, loss:0.00000, loss_test:0.01916, lr:3.19e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.325, tt:5121.263\n",
      "Ep:127, loss:0.00000, loss_test:0.01915, lr:3.15e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.318, tt:5160.663\n",
      "Ep:128, loss:0.00000, loss_test:0.01917, lr:3.12e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.301, tt:5198.890\n",
      "Ep:129, loss:0.00000, loss_test:0.01926, lr:3.09e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.302, tt:5239.248\n",
      "Ep:130, loss:0.00000, loss_test:0.01930, lr:3.06e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.297, tt:5278.948\n",
      "Ep:131, loss:0.00000, loss_test:0.01932, lr:3.03e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.335, tt:5324.195\n",
      "Ep:132, loss:0.00000, loss_test:0.01940, lr:3.00e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.328, tt:5363.589\n",
      "Ep:133, loss:0.00000, loss_test:0.01949, lr:2.97e-02, fs:0.70345 (r=0.586,p=0.879),  time:40.325, tt:5403.549\n",
      "Ep:134, loss:0.00000, loss_test:0.01950, lr:2.94e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.310, tt:5441.893\n",
      "Ep:135, loss:0.00000, loss_test:0.01953, lr:2.91e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.305, tt:5481.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.01960, lr:2.88e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.312, tt:5522.730\n",
      "Ep:137, loss:0.00000, loss_test:0.01964, lr:2.85e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.319, tt:5564.058\n",
      "Ep:138, loss:0.00000, loss_test:0.01966, lr:2.82e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.307, tt:5602.605\n",
      "Ep:139, loss:0.00000, loss_test:0.01967, lr:2.80e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.303, tt:5642.401\n",
      "Ep:140, loss:0.00000, loss_test:0.01975, lr:2.77e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.290, tt:5680.904\n",
      "Ep:141, loss:0.00000, loss_test:0.01982, lr:2.74e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.284, tt:5720.339\n",
      "Ep:142, loss:0.00000, loss_test:0.01985, lr:2.71e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.280, tt:5760.051\n",
      "Ep:143, loss:0.00000, loss_test:0.01985, lr:2.69e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.270, tt:5798.950\n",
      "Ep:144, loss:0.00000, loss_test:0.01986, lr:2.66e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.272, tt:5839.504\n",
      "Ep:145, loss:0.00000, loss_test:0.01991, lr:2.63e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.273, tt:5879.808\n",
      "Ep:146, loss:0.00000, loss_test:0.01998, lr:2.61e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.270, tt:5919.743\n",
      "Ep:147, loss:0.00000, loss_test:0.02001, lr:2.58e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.242, tt:5955.793\n",
      "Ep:148, loss:0.00000, loss_test:0.02008, lr:2.55e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.258, tt:5998.444\n",
      "Ep:149, loss:0.00000, loss_test:0.02010, lr:2.53e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.259, tt:6038.858\n",
      "Ep:150, loss:0.00000, loss_test:0.02015, lr:2.50e-02, fs:0.68966 (r=0.575,p=0.862),  time:40.269, tt:6080.661\n",
      "Ep:151, loss:0.00000, loss_test:0.02018, lr:2.48e-02, fs:0.69863 (r=0.586,p=0.864),  time:40.269, tt:6120.856\n",
      "Ep:152, loss:0.00000, loss_test:0.02024, lr:2.45e-02, fs:0.68966 (r=0.575,p=0.862),  time:40.260, tt:6159.832\n",
      "Ep:153, loss:0.00000, loss_test:0.02024, lr:2.43e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.265, tt:6200.752\n",
      "Ep:154, loss:0.00000, loss_test:0.02029, lr:2.40e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.258, tt:6239.924\n",
      "Ep:155, loss:0.00000, loss_test:0.02031, lr:2.38e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.261, tt:6280.659\n",
      "Ep:156, loss:0.00000, loss_test:0.02038, lr:2.36e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.268, tt:6322.105\n",
      "Ep:157, loss:0.00000, loss_test:0.02038, lr:2.33e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.267, tt:6362.196\n",
      "Ep:158, loss:0.00000, loss_test:0.02042, lr:2.31e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.279, tt:6404.432\n",
      "Ep:159, loss:0.00000, loss_test:0.02044, lr:2.29e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.286, tt:6445.751\n",
      "Ep:160, loss:0.00000, loss_test:0.02051, lr:2.26e-02, fs:0.68056 (r=0.563,p=0.860),  time:40.289, tt:6486.526\n",
      "Ep:161, loss:0.00000, loss_test:0.02050, lr:2.24e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.288, tt:6526.590\n",
      "Ep:162, loss:0.00000, loss_test:0.02051, lr:2.22e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.294, tt:6567.899\n",
      "Ep:163, loss:0.00000, loss_test:0.02055, lr:2.20e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.291, tt:6607.672\n",
      "Ep:164, loss:0.00000, loss_test:0.02060, lr:2.17e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.289, tt:6647.610\n",
      "Ep:165, loss:0.00000, loss_test:0.02061, lr:2.15e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.292, tt:6688.438\n",
      "Ep:166, loss:0.00000, loss_test:0.02065, lr:2.13e-02, fs:0.68531 (r=0.563,p=0.875),  time:40.290, tt:6728.358\n",
      "Ep:167, loss:0.00000, loss_test:0.02067, lr:2.11e-02, fs:0.67606 (r=0.552,p=0.873),  time:40.294, tt:6769.440\n",
      "Ep:168, loss:0.00000, loss_test:0.02069, lr:2.09e-02, fs:0.67606 (r=0.552,p=0.873),  time:40.291, tt:6809.160\n",
      "Ep:169, loss:0.00000, loss_test:0.02075, lr:2.07e-02, fs:0.67606 (r=0.552,p=0.873),  time:40.288, tt:6849.036\n",
      "Ep:170, loss:0.00000, loss_test:0.02080, lr:2.05e-02, fs:0.67606 (r=0.552,p=0.873),  time:40.288, tt:6889.216\n",
      "Ep:171, loss:0.00000, loss_test:0.02080, lr:2.03e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.283, tt:6928.734\n",
      "Ep:172, loss:0.00000, loss_test:0.02082, lr:2.01e-02, fs:0.67606 (r=0.552,p=0.873),  time:40.286, tt:6969.500\n",
      "Ep:173, loss:0.00000, loss_test:0.02087, lr:1.99e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.288, tt:7010.175\n",
      "Ep:174, loss:0.00000, loss_test:0.02090, lr:1.97e-02, fs:0.67606 (r=0.552,p=0.873),  time:40.282, tt:7049.371\n",
      "Ep:175, loss:0.00000, loss_test:0.02091, lr:1.95e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.286, tt:7090.301\n",
      "Ep:176, loss:0.00000, loss_test:0.02096, lr:1.93e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.287, tt:7130.752\n",
      "Ep:177, loss:0.00000, loss_test:0.02101, lr:1.91e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.293, tt:7172.087\n",
      "Ep:178, loss:0.00000, loss_test:0.02099, lr:1.89e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.299, tt:7213.462\n",
      "Ep:179, loss:0.00000, loss_test:0.02102, lr:1.87e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.304, tt:7254.645\n",
      "Ep:180, loss:0.00000, loss_test:0.02102, lr:1.85e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.321, tt:7298.020\n",
      "Ep:181, loss:0.00000, loss_test:0.02107, lr:1.83e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.333, tt:7340.538\n",
      "Ep:182, loss:0.00000, loss_test:0.02111, lr:1.81e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.362, tt:7386.162\n",
      "Ep:183, loss:0.00000, loss_test:0.02112, lr:1.80e-02, fs:0.66667 (r=0.540,p=0.870),  time:40.367, tt:7427.469\n",
      "Ep:184, loss:0.00000, loss_test:0.02116, lr:1.78e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.375, tt:7469.384\n",
      "Ep:185, loss:0.00000, loss_test:0.02118, lr:1.76e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.361, tt:7507.222\n",
      "Ep:186, loss:0.00000, loss_test:0.02119, lr:1.74e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.368, tt:7548.766\n",
      "Ep:187, loss:0.00000, loss_test:0.02123, lr:1.73e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.373, tt:7590.085\n",
      "Ep:188, loss:0.00000, loss_test:0.02124, lr:1.71e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.370, tt:7629.888\n",
      "Ep:189, loss:0.00000, loss_test:0.02125, lr:1.69e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.374, tt:7671.097\n",
      "Ep:190, loss:0.00000, loss_test:0.02127, lr:1.67e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.377, tt:7711.917\n",
      "Ep:191, loss:0.00000, loss_test:0.02131, lr:1.66e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.385, tt:7753.951\n",
      "Ep:192, loss:0.00000, loss_test:0.02135, lr:1.64e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.393, tt:7795.846\n",
      "Ep:193, loss:0.00000, loss_test:0.02135, lr:1.62e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.399, tt:7837.314\n",
      "Ep:194, loss:0.00000, loss_test:0.02137, lr:1.61e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.405, tt:7878.881\n",
      "Ep:195, loss:0.00000, loss_test:0.02140, lr:1.59e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.407, tt:7919.726\n",
      "Ep:196, loss:0.00000, loss_test:0.02141, lr:1.58e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.417, tt:7962.153\n",
      "Ep:197, loss:0.00000, loss_test:0.02142, lr:1.56e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.422, tt:8003.512\n",
      "Ep:198, loss:0.00000, loss_test:0.02146, lr:1.54e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.420, tt:8043.578\n",
      "Ep:199, loss:0.00000, loss_test:0.02150, lr:1.53e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.413, tt:8082.501\n",
      "Ep:200, loss:0.00000, loss_test:0.02151, lr:1.51e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.419, tt:8124.176\n",
      "Ep:201, loss:0.00000, loss_test:0.02152, lr:1.50e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.421, tt:8165.123\n",
      "Ep:202, loss:0.00000, loss_test:0.02156, lr:1.48e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.427, tt:8206.642\n",
      "Ep:203, loss:0.00000, loss_test:0.02157, lr:1.47e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.429, tt:8247.433\n",
      "Ep:204, loss:0.00000, loss_test:0.02159, lr:1.45e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.438, tt:8289.862\n",
      "Ep:205, loss:0.00000, loss_test:0.02162, lr:1.44e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.443, tt:8331.229\n",
      "Ep:206, loss:0.00000, loss_test:0.02163, lr:1.43e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.455, tt:8374.149\n",
      "Ep:207, loss:0.00000, loss_test:0.02165, lr:1.41e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.461, tt:8415.844\n",
      "Ep:208, loss:0.00000, loss_test:0.02167, lr:1.40e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.471, tt:8458.436\n",
      "Ep:209, loss:0.00000, loss_test:0.02168, lr:1.38e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.470, tt:8498.607\n",
      "Ep:210, loss:0.00000, loss_test:0.02171, lr:1.37e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.474, tt:8540.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:211, loss:0.00000, loss_test:0.02172, lr:1.36e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.486, tt:8583.047\n",
      "Ep:212, loss:0.00000, loss_test:0.02173, lr:1.34e-02, fs:0.66187 (r=0.529,p=0.885),  time:40.482, tt:8622.683\n",
      "Ep:213, loss:0.00000, loss_test:0.02175, lr:1.33e-02, fs:0.66667 (r=0.529,p=0.902),  time:40.486, tt:8663.948\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13977, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.893, tt:37.893\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13740, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:37.349, tt:74.698\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13289, lr:1.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:36.214, tt:108.642\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12520, lr:1.00e-02, fs:0.68033 (r=0.954,p=0.529),  time:36.699, tt:146.795\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11711, lr:1.00e-02, fs:0.66355 (r=0.816,p=0.559),  time:36.509, tt:182.544\n",
      "Ep:5, loss:0.00024, loss_test:0.11521, lr:1.00e-02, fs:0.69149 (r=0.747,p=0.644),  time:37.559, tt:225.355\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11597, lr:1.00e-02, fs:0.69274 (r=0.713,p=0.674),  time:38.185, tt:267.297\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11408, lr:1.00e-02, fs:0.68085 (r=0.736,p=0.634),  time:38.579, tt:308.635\n",
      "Ep:8, loss:0.00022, loss_test:0.11420, lr:1.00e-02, fs:0.69072 (r=0.770,p=0.626),  time:38.978, tt:350.798\n",
      "Ep:9, loss:0.00022, loss_test:0.11409, lr:1.00e-02, fs:0.68449 (r=0.736,p=0.640),  time:39.301, tt:393.009\n",
      "Ep:10, loss:0.00021, loss_test:0.11308, lr:1.00e-02, fs:0.63030 (r=0.598,p=0.667),  time:39.643, tt:436.076\n",
      "Ep:11, loss:0.00020, loss_test:0.11039, lr:1.00e-02, fs:0.64242 (r=0.609,p=0.679),  time:39.663, tt:475.961\n",
      "Ep:12, loss:0.00019, loss_test:0.10721, lr:1.00e-02, fs:0.65497 (r=0.644,p=0.667),  time:40.033, tt:520.436\n",
      "Ep:13, loss:0.00019, loss_test:0.10451, lr:1.00e-02, fs:0.68293 (r=0.644,p=0.727),  time:40.082, tt:561.151\n",
      "Ep:14, loss:0.00018, loss_test:0.10297, lr:1.00e-02, fs:0.66667 (r=0.609,p=0.736),  time:40.258, tt:603.870\n",
      "Ep:15, loss:0.00017, loss_test:0.10101, lr:1.00e-02, fs:0.69136 (r=0.644,p=0.747),  time:40.488, tt:647.808\n",
      "Ep:16, loss:0.00016, loss_test:0.09916, lr:1.00e-02, fs:0.72840 (r=0.678,p=0.787),  time:40.547, tt:689.290\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09665, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:40.706, tt:732.703\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09620, lr:1.00e-02, fs:0.75472 (r=0.690,p=0.833),  time:40.890, tt:776.908\n",
      "Ep:19, loss:0.00014, loss_test:0.09387, lr:1.00e-02, fs:0.76543 (r=0.713,p=0.827),  time:40.919, tt:818.371\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09348, lr:1.00e-02, fs:0.75159 (r=0.678,p=0.843),  time:40.991, tt:860.812\n",
      "Ep:21, loss:0.00013, loss_test:0.09131, lr:1.00e-02, fs:0.78750 (r=0.724,p=0.863),  time:41.106, tt:904.323\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08983, lr:1.00e-02, fs:0.78750 (r=0.724,p=0.863),  time:41.113, tt:945.600\n",
      "Ep:23, loss:0.00012, loss_test:0.09048, lr:1.00e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.111, tt:986.655\n",
      "Ep:24, loss:0.00012, loss_test:0.08842, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:41.129, tt:1028.215\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08831, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:41.072, tt:1067.865\n",
      "Ep:26, loss:0.00011, loss_test:0.08796, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:40.988, tt:1106.685\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.08455, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:41.072, tt:1150.028\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.08679, lr:1.00e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.073, tt:1191.103\n",
      "Ep:29, loss:0.00010, loss_test:0.08575, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:41.109, tt:1233.267\n",
      "Ep:30, loss:0.00009, loss_test:0.08381, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:41.160, tt:1275.970\n",
      "Ep:31, loss:0.00009, loss_test:0.08656, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:41.218, tt:1318.976\n",
      "Ep:32, loss:0.00008, loss_test:0.08230, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:41.175, tt:1358.783\n",
      "Ep:33, loss:0.00008, loss_test:0.08418, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:41.254, tt:1402.638\n",
      "Ep:34, loss:0.00008, loss_test:0.08265, lr:1.00e-02, fs:0.79739 (r=0.701,p=0.924),  time:41.232, tt:1443.125\n",
      "Ep:35, loss:0.00008, loss_test:0.08278, lr:1.00e-02, fs:0.81290 (r=0.724,p=0.926),  time:41.219, tt:1483.897\n",
      "Ep:36, loss:0.00007, loss_test:0.08225, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:41.231, tt:1525.544\n",
      "Ep:37, loss:0.00007, loss_test:0.08119, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:41.245, tt:1567.310\n",
      "Ep:38, loss:0.00007, loss_test:0.08026, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:41.251, tt:1608.801\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.08367, lr:1.00e-02, fs:0.78947 (r=0.690,p=0.923),  time:41.304, tt:1652.142\n",
      "Ep:40, loss:0.00006, loss_test:0.08197, lr:1.00e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.314, tt:1693.892\n",
      "Ep:41, loss:0.00006, loss_test:0.08154, lr:1.00e-02, fs:0.80519 (r=0.713,p=0.925),  time:41.315, tt:1735.247\n",
      "Ep:42, loss:0.00006, loss_test:0.08324, lr:1.00e-02, fs:0.80503 (r=0.736,p=0.889),  time:41.313, tt:1776.438\n",
      "Ep:43, loss:0.00005, loss_test:0.08408, lr:1.00e-02, fs:0.79739 (r=0.701,p=0.924),  time:41.377, tt:1820.576\n",
      "Ep:44, loss:0.00005, loss_test:0.08181, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:41.405, tt:1863.231\n",
      "Ep:45, loss:0.00005, loss_test:0.08830, lr:1.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.468, tt:1907.522\n",
      "Ep:46, loss:0.00005, loss_test:0.08325, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:41.473, tt:1949.214\n",
      "Ep:47, loss:0.00005, loss_test:0.08452, lr:1.00e-02, fs:0.80503 (r=0.736,p=0.889),  time:41.549, tt:1994.346\n",
      "Ep:48, loss:0.00004, loss_test:0.08804, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:41.585, tt:2037.665\n",
      "Ep:49, loss:0.00004, loss_test:0.08387, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:41.611, tt:2080.551\n",
      "Ep:50, loss:0.00004, loss_test:0.09164, lr:9.90e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.618, tt:2122.499\n",
      "Ep:51, loss:0.00004, loss_test:0.08299, lr:9.80e-03, fs:0.82209 (r=0.770,p=0.882),  time:41.658, tt:2166.219\n",
      "Ep:52, loss:0.00004, loss_test:0.09077, lr:9.70e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.696, tt:2209.899\n",
      "Ep:53, loss:0.00004, loss_test:0.08608, lr:9.61e-03, fs:0.81761 (r=0.747,p=0.903),  time:41.763, tt:2255.178\n",
      "Ep:54, loss:0.00004, loss_test:0.09145, lr:9.51e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.787, tt:2298.283\n",
      "Ep:55, loss:0.00004, loss_test:0.08597, lr:9.41e-03, fs:0.81988 (r=0.759,p=0.892),  time:41.833, tt:2342.646\n",
      "Ep:56, loss:0.00004, loss_test:0.09047, lr:9.32e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.871, tt:2386.656\n",
      "Ep:57, loss:0.00003, loss_test:0.08871, lr:9.23e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.898, tt:2430.056\n",
      "Ep:58, loss:0.00003, loss_test:0.08733, lr:9.14e-03, fs:0.83019 (r=0.759,p=0.917),  time:41.938, tt:2474.332\n",
      "Ep:59, loss:0.00003, loss_test:0.09360, lr:9.04e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.934, tt:2516.020\n",
      "Ep:60, loss:0.00003, loss_test:0.08692, lr:8.95e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.946, tt:2558.721\n",
      "Ep:61, loss:0.00003, loss_test:0.09021, lr:8.86e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.958, tt:2601.415\n",
      "Ep:62, loss:0.00003, loss_test:0.08880, lr:8.78e-03, fs:0.80769 (r=0.724,p=0.913),  time:41.988, tt:2645.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.08777, lr:8.69e-03, fs:0.83544 (r=0.759,p=0.930),  time:42.005, tt:2688.340\n",
      "Ep:64, loss:0.00003, loss_test:0.09233, lr:8.60e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.022, tt:2731.445\n",
      "Ep:65, loss:0.00003, loss_test:0.08696, lr:8.51e-03, fs:0.84472 (r=0.782,p=0.919),  time:42.032, tt:2774.095\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00003, loss_test:0.09044, lr:8.51e-03, fs:0.69565 (r=0.552,p=0.941),  time:42.012, tt:2814.784\n",
      "Ep:67, loss:0.00003, loss_test:0.09027, lr:8.51e-03, fs:0.80000 (r=0.713,p=0.912),  time:42.039, tt:2858.638\n",
      "Ep:68, loss:0.00002, loss_test:0.09084, lr:8.51e-03, fs:0.75000 (r=0.621,p=0.947),  time:42.048, tt:2901.305\n",
      "Ep:69, loss:0.00002, loss_test:0.09387, lr:8.51e-03, fs:0.71429 (r=0.575,p=0.943),  time:42.081, tt:2945.687\n",
      "Ep:70, loss:0.00002, loss_test:0.08745, lr:8.51e-03, fs:0.82353 (r=0.724,p=0.955),  time:42.088, tt:2988.215\n",
      "Ep:71, loss:0.00002, loss_test:0.09444, lr:8.51e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.108, tt:3031.785\n",
      "Ep:72, loss:0.00002, loss_test:0.08877, lr:8.51e-03, fs:0.80519 (r=0.713,p=0.925),  time:42.097, tt:3073.056\n",
      "Ep:73, loss:0.00002, loss_test:0.09352, lr:8.51e-03, fs:0.67647 (r=0.529,p=0.939),  time:42.089, tt:3114.576\n",
      "Ep:74, loss:0.00002, loss_test:0.09113, lr:8.51e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.102, tt:3157.658\n",
      "Ep:75, loss:0.00002, loss_test:0.09023, lr:8.51e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.120, tt:3201.145\n",
      "Ep:76, loss:0.00002, loss_test:0.09813, lr:8.51e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.140, tt:3244.808\n",
      "Ep:77, loss:0.00002, loss_test:0.08730, lr:8.43e-03, fs:0.80000 (r=0.713,p=0.912),  time:42.155, tt:3288.056\n",
      "Ep:78, loss:0.00002, loss_test:0.09807, lr:8.35e-03, fs:0.63636 (r=0.483,p=0.933),  time:42.165, tt:3331.035\n",
      "Ep:79, loss:0.00002, loss_test:0.09354, lr:8.26e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.189, tt:3375.149\n",
      "Ep:80, loss:0.00002, loss_test:0.08967, lr:8.18e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.191, tt:3417.453\n",
      "Ep:81, loss:0.00002, loss_test:0.09692, lr:8.10e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.220, tt:3462.024\n",
      "Ep:82, loss:0.00002, loss_test:0.09173, lr:8.02e-03, fs:0.69565 (r=0.552,p=0.941),  time:42.230, tt:3505.107\n",
      "Ep:83, loss:0.00002, loss_test:0.09467, lr:7.94e-03, fs:0.67647 (r=0.529,p=0.939),  time:42.255, tt:3549.431\n",
      "Ep:84, loss:0.00002, loss_test:0.09623, lr:7.86e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.288, tt:3594.439\n",
      "Ep:85, loss:0.00002, loss_test:0.09080, lr:7.78e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.272, tt:3635.426\n",
      "Ep:86, loss:0.00002, loss_test:0.09610, lr:7.70e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.268, tt:3677.313\n",
      "Ep:87, loss:0.00002, loss_test:0.09508, lr:7.62e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.282, tt:3720.828\n",
      "Ep:88, loss:0.00001, loss_test:0.09391, lr:7.55e-03, fs:0.65152 (r=0.494,p=0.956),  time:42.286, tt:3763.459\n",
      "Ep:89, loss:0.00001, loss_test:0.09393, lr:7.47e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.293, tt:3806.411\n",
      "Ep:90, loss:0.00001, loss_test:0.09658, lr:7.40e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.299, tt:3849.193\n",
      "Ep:91, loss:0.00001, loss_test:0.09278, lr:7.32e-03, fs:0.69565 (r=0.552,p=0.941),  time:42.289, tt:3890.554\n",
      "Ep:92, loss:0.00001, loss_test:0.09645, lr:7.25e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.307, tt:3934.572\n",
      "Ep:93, loss:0.00001, loss_test:0.09591, lr:7.18e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.318, tt:3977.863\n",
      "Ep:94, loss:0.00001, loss_test:0.09397, lr:7.11e-03, fs:0.65152 (r=0.494,p=0.956),  time:42.319, tt:4020.317\n",
      "Ep:95, loss:0.00001, loss_test:0.09713, lr:7.03e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.316, tt:4062.325\n",
      "Ep:96, loss:0.00001, loss_test:0.09622, lr:6.96e-03, fs:0.60938 (r=0.448,p=0.951),  time:42.310, tt:4104.033\n",
      "Ep:97, loss:0.00001, loss_test:0.09733, lr:6.89e-03, fs:0.62016 (r=0.460,p=0.952),  time:42.304, tt:4145.792\n",
      "Ep:98, loss:0.00001, loss_test:0.09816, lr:6.83e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.289, tt:4186.567\n",
      "Ep:99, loss:0.00001, loss_test:0.09561, lr:6.76e-03, fs:0.65152 (r=0.494,p=0.956),  time:42.275, tt:4227.506\n",
      "Ep:100, loss:0.00001, loss_test:0.09826, lr:6.69e-03, fs:0.62016 (r=0.460,p=0.952),  time:42.274, tt:4269.650\n",
      "Ep:101, loss:0.00001, loss_test:0.09888, lr:6.62e-03, fs:0.60938 (r=0.448,p=0.951),  time:42.286, tt:4313.174\n",
      "Ep:102, loss:0.00001, loss_test:0.09677, lr:6.56e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.267, tt:4353.487\n",
      "Ep:103, loss:0.00001, loss_test:0.09972, lr:6.49e-03, fs:0.63077 (r=0.471,p=0.953),  time:42.252, tt:4394.203\n",
      "Ep:104, loss:0.00001, loss_test:0.09703, lr:6.43e-03, fs:0.64122 (r=0.483,p=0.955),  time:42.238, tt:4435.018\n",
      "Ep:105, loss:0.00001, loss_test:0.09845, lr:6.36e-03, fs:0.65152 (r=0.494,p=0.956),  time:42.241, tt:4477.585\n",
      "Ep:106, loss:0.00001, loss_test:0.09804, lr:6.30e-03, fs:0.57600 (r=0.414,p=0.947),  time:42.254, tt:4521.152\n",
      "Ep:107, loss:0.00001, loss_test:0.10053, lr:6.24e-03, fs:0.56452 (r=0.402,p=0.946),  time:42.245, tt:4562.445\n",
      "Ep:108, loss:0.00001, loss_test:0.09733, lr:6.17e-03, fs:0.64122 (r=0.483,p=0.955),  time:42.247, tt:4604.955\n",
      "Ep:109, loss:0.00001, loss_test:0.10155, lr:6.11e-03, fs:0.62500 (r=0.460,p=0.976),  time:42.272, tt:4649.882\n",
      "Ep:110, loss:0.00001, loss_test:0.10148, lr:6.05e-03, fs:0.59200 (r=0.425,p=0.974),  time:42.266, tt:4691.557\n",
      "Ep:111, loss:0.00001, loss_test:0.09599, lr:5.99e-03, fs:0.64122 (r=0.483,p=0.955),  time:42.265, tt:4733.664\n",
      "Ep:112, loss:0.00001, loss_test:0.10031, lr:5.93e-03, fs:0.62500 (r=0.460,p=0.976),  time:42.248, tt:4774.079\n",
      "Ep:113, loss:0.00001, loss_test:0.09966, lr:5.87e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.249, tt:4816.374\n",
      "Ep:114, loss:0.00001, loss_test:0.09930, lr:5.81e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.250, tt:4858.741\n",
      "Ep:115, loss:0.00001, loss_test:0.09964, lr:5.75e-03, fs:0.61417 (r=0.448,p=0.975),  time:42.257, tt:4901.804\n",
      "Ep:116, loss:0.00001, loss_test:0.09944, lr:5.70e-03, fs:0.63566 (r=0.471,p=0.976),  time:42.247, tt:4942.892\n",
      "Ep:117, loss:0.00001, loss_test:0.09929, lr:5.64e-03, fs:0.62500 (r=0.460,p=0.976),  time:42.235, tt:4983.759\n",
      "Ep:118, loss:0.00001, loss_test:0.10246, lr:5.58e-03, fs:0.58065 (r=0.414,p=0.973),  time:42.219, tt:5024.005\n",
      "Ep:119, loss:0.00001, loss_test:0.10047, lr:5.53e-03, fs:0.61417 (r=0.448,p=0.975),  time:42.207, tt:5064.823\n",
      "Ep:120, loss:0.00001, loss_test:0.10195, lr:5.47e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.196, tt:5105.749\n",
      "Ep:121, loss:0.00001, loss_test:0.10205, lr:5.42e-03, fs:0.48696 (r=0.322,p=1.000),  time:42.205, tt:5149.056\n",
      "Ep:122, loss:0.00001, loss_test:0.09992, lr:5.36e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.218, tt:5192.850\n",
      "Ep:123, loss:0.00001, loss_test:0.10171, lr:5.31e-03, fs:0.56198 (r=0.391,p=1.000),  time:42.233, tt:5236.931\n",
      "Ep:124, loss:0.00001, loss_test:0.10118, lr:5.26e-03, fs:0.59677 (r=0.425,p=1.000),  time:42.229, tt:5278.565\n",
      "Ep:125, loss:0.00001, loss_test:0.10096, lr:5.20e-03, fs:0.62500 (r=0.460,p=0.976),  time:42.225, tt:5320.350\n",
      "Ep:126, loss:0.00001, loss_test:0.10169, lr:5.15e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.220, tt:5361.967\n",
      "Ep:127, loss:0.00001, loss_test:0.10245, lr:5.10e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.209, tt:5402.779\n",
      "Ep:128, loss:0.00001, loss_test:0.10140, lr:5.05e-03, fs:0.60317 (r=0.437,p=0.974),  time:42.204, tt:5444.268\n",
      "Ep:129, loss:0.00001, loss_test:0.10127, lr:5.00e-03, fs:0.56198 (r=0.391,p=1.000),  time:42.193, tt:5485.112\n",
      "Ep:130, loss:0.00001, loss_test:0.10111, lr:4.95e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.154, tt:5522.151\n",
      "Ep:131, loss:0.00001, loss_test:0.10134, lr:4.90e-03, fs:0.62992 (r=0.460,p=1.000),  time:42.145, tt:5563.078\n",
      "Ep:132, loss:0.00001, loss_test:0.10046, lr:4.85e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.145, tt:5605.233\n",
      "Ep:133, loss:0.00001, loss_test:0.10200, lr:4.80e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.121, tt:5644.181\n",
      "Ep:134, loss:0.00001, loss_test:0.10256, lr:4.75e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.108, tt:5684.602\n",
      "Ep:135, loss:0.00001, loss_test:0.10166, lr:4.71e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.111, tt:5727.157\n",
      "Ep:136, loss:0.00001, loss_test:0.10241, lr:4.66e-03, fs:0.59677 (r=0.425,p=1.000),  time:42.109, tt:5768.968\n",
      "Ep:137, loss:0.00001, loss_test:0.10172, lr:4.61e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.087, tt:5807.963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00001, loss_test:0.10296, lr:4.57e-03, fs:0.59677 (r=0.425,p=1.000),  time:42.063, tt:5846.786\n",
      "Ep:139, loss:0.00000, loss_test:0.10292, lr:4.52e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.053, tt:5887.356\n",
      "Ep:140, loss:0.00000, loss_test:0.10359, lr:4.48e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.054, tt:5929.659\n",
      "Ep:141, loss:0.00000, loss_test:0.10229, lr:4.43e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.032, tt:5968.534\n",
      "Ep:142, loss:0.00000, loss_test:0.10291, lr:4.39e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.028, tt:6010.010\n",
      "Ep:143, loss:0.00000, loss_test:0.10266, lr:4.34e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.021, tt:6050.993\n",
      "Ep:144, loss:0.00000, loss_test:0.10366, lr:4.30e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.024, tt:6093.537\n",
      "Ep:145, loss:0.00000, loss_test:0.10308, lr:4.26e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.022, tt:6135.178\n",
      "Ep:146, loss:0.00000, loss_test:0.10442, lr:4.21e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.007, tt:6174.985\n",
      "Ep:147, loss:0.00000, loss_test:0.10276, lr:4.17e-03, fs:0.60800 (r=0.437,p=1.000),  time:42.009, tt:6217.284\n",
      "Ep:148, loss:0.00000, loss_test:0.10373, lr:4.13e-03, fs:0.58537 (r=0.414,p=1.000),  time:42.003, tt:6258.458\n",
      "Ep:149, loss:0.00000, loss_test:0.10532, lr:4.09e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.994, tt:6299.096\n",
      "Ep:150, loss:0.00000, loss_test:0.10535, lr:4.05e-03, fs:0.58537 (r=0.414,p=1.000),  time:41.981, tt:6339.154\n",
      "Ep:151, loss:0.00000, loss_test:0.10520, lr:4.01e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.995, tt:6383.267\n",
      "Ep:152, loss:0.00000, loss_test:0.10542, lr:3.97e-03, fs:0.58537 (r=0.414,p=1.000),  time:41.990, tt:6424.449\n",
      "Ep:153, loss:0.00000, loss_test:0.10426, lr:3.93e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.992, tt:6466.775\n",
      "Ep:154, loss:0.00000, loss_test:0.10602, lr:3.89e-03, fs:0.58537 (r=0.414,p=1.000),  time:41.985, tt:6507.687\n",
      "Ep:155, loss:0.00000, loss_test:0.10673, lr:3.85e-03, fs:0.58537 (r=0.414,p=1.000),  time:41.979, tt:6548.755\n",
      "Ep:156, loss:0.00000, loss_test:0.10492, lr:3.81e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.968, tt:6588.944\n",
      "Ep:157, loss:0.00000, loss_test:0.10531, lr:3.77e-03, fs:0.58537 (r=0.414,p=1.000),  time:41.957, tt:6629.172\n",
      "Ep:158, loss:0.00000, loss_test:0.10635, lr:3.73e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.946, tt:6669.395\n",
      "Ep:159, loss:0.00000, loss_test:0.10613, lr:3.70e-03, fs:0.59677 (r=0.425,p=1.000),  time:41.952, tt:6712.266\n",
      "Ep:160, loss:0.00000, loss_test:0.10624, lr:3.66e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.956, tt:6754.978\n",
      "Ep:161, loss:0.00000, loss_test:0.10612, lr:3.62e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.930, tt:6792.721\n",
      "Ep:162, loss:0.00000, loss_test:0.10557, lr:3.59e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.930, tt:6834.588\n",
      "Ep:163, loss:0.00000, loss_test:0.10479, lr:3.55e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.921, tt:6875.111\n",
      "Ep:164, loss:0.00000, loss_test:0.10589, lr:3.52e-03, fs:0.59677 (r=0.425,p=1.000),  time:41.923, tt:6917.338\n",
      "Ep:165, loss:0.00000, loss_test:0.10644, lr:3.48e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.910, tt:6957.107\n",
      "Ep:166, loss:0.00000, loss_test:0.10683, lr:3.45e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.897, tt:6996.826\n",
      "Ep:167, loss:0.00000, loss_test:0.10595, lr:3.41e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.893, tt:7037.958\n",
      "Ep:168, loss:0.00000, loss_test:0.10625, lr:3.38e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.895, tt:7080.329\n",
      "Ep:169, loss:0.00000, loss_test:0.10696, lr:3.34e-03, fs:0.59677 (r=0.425,p=1.000),  time:41.884, tt:7120.276\n",
      "Ep:170, loss:0.00000, loss_test:0.10670, lr:3.31e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.882, tt:7161.739\n",
      "Ep:171, loss:0.00000, loss_test:0.10640, lr:3.28e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.876, tt:7202.590\n",
      "Ep:172, loss:0.00000, loss_test:0.10671, lr:3.24e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.871, tt:7243.693\n",
      "Ep:173, loss:0.00000, loss_test:0.10694, lr:3.21e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.871, tt:7285.556\n",
      "Ep:174, loss:0.00000, loss_test:0.10652, lr:3.18e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.865, tt:7326.308\n",
      "Ep:175, loss:0.00000, loss_test:0.10696, lr:3.15e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.860, tt:7367.435\n",
      "Ep:176, loss:0.00000, loss_test:0.10857, lr:3.12e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.861, tt:7409.440\n",
      "Ep:177, loss:0.00000, loss_test:0.10735, lr:3.09e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.860, tt:7451.096\n",
      "Ep:178, loss:0.00000, loss_test:0.10657, lr:3.05e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.860, tt:7493.023\n",
      "Ep:179, loss:0.00000, loss_test:0.10904, lr:3.02e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.847, tt:7532.450\n",
      "Ep:180, loss:0.00000, loss_test:0.10853, lr:2.99e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.856, tt:7575.889\n",
      "Ep:181, loss:0.00000, loss_test:0.10776, lr:2.96e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.857, tt:7617.969\n",
      "Ep:182, loss:0.00000, loss_test:0.10795, lr:2.93e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.857, tt:7659.764\n",
      "Ep:183, loss:0.00000, loss_test:0.10891, lr:2.90e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.859, tt:7702.044\n",
      "Ep:184, loss:0.00000, loss_test:0.10873, lr:2.88e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.857, tt:7743.583\n",
      "Ep:185, loss:0.00000, loss_test:0.10827, lr:2.85e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.859, tt:7785.694\n",
      "Ep:186, loss:0.00000, loss_test:0.10890, lr:2.82e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.864, tt:7828.653\n",
      "Ep:187, loss:0.00000, loss_test:0.10860, lr:2.79e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.860, tt:7869.728\n",
      "Ep:188, loss:0.00000, loss_test:0.10821, lr:2.76e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.857, tt:7910.990\n",
      "Ep:189, loss:0.00000, loss_test:0.10847, lr:2.73e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.855, tt:7952.469\n",
      "Ep:190, loss:0.00000, loss_test:0.10861, lr:2.71e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.867, tt:7996.609\n",
      "Ep:191, loss:0.00000, loss_test:0.10886, lr:2.68e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.870, tt:8038.991\n",
      "Ep:192, loss:0.00000, loss_test:0.10898, lr:2.65e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.866, tt:8080.169\n",
      "Ep:193, loss:0.00000, loss_test:0.10915, lr:2.63e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.861, tt:8120.952\n",
      "Ep:194, loss:0.00000, loss_test:0.10963, lr:2.60e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.859, tt:8162.555\n",
      "Ep:195, loss:0.00000, loss_test:0.10936, lr:2.57e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.856, tt:8203.831\n",
      "Ep:196, loss:0.00000, loss_test:0.10935, lr:2.55e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.848, tt:8244.025\n",
      "Ep:197, loss:0.00000, loss_test:0.10933, lr:2.52e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.854, tt:8287.052\n",
      "Ep:198, loss:0.00000, loss_test:0.10919, lr:2.50e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.853, tt:8328.686\n",
      "Ep:199, loss:0.00000, loss_test:0.10862, lr:2.47e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.856, tt:8371.259\n",
      "Ep:200, loss:0.00000, loss_test:0.10907, lr:2.45e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.857, tt:8413.183\n",
      "Ep:201, loss:0.00000, loss_test:0.11026, lr:2.42e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.858, tt:8455.413\n",
      "Ep:202, loss:0.00000, loss_test:0.10919, lr:2.40e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.868, tt:8499.187\n",
      "Ep:203, loss:0.00000, loss_test:0.10942, lr:2.38e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.866, tt:8540.718\n",
      "Ep:204, loss:0.00000, loss_test:0.11045, lr:2.35e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.869, tt:8583.221\n",
      "Ep:205, loss:0.00000, loss_test:0.10854, lr:2.33e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.876, tt:8626.380\n",
      "Ep:206, loss:0.00000, loss_test:0.10869, lr:2.31e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.871, tt:8667.344\n",
      "Ep:207, loss:0.00000, loss_test:0.10981, lr:2.28e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.876, tt:8710.243\n",
      "Ep:208, loss:0.00000, loss_test:0.10919, lr:2.26e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.883, tt:8753.614\n",
      "Ep:209, loss:0.00000, loss_test:0.10845, lr:2.24e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.893, tt:8797.551\n",
      "Ep:210, loss:0.00000, loss_test:0.11094, lr:2.21e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.913, tt:8843.610\n",
      "Ep:211, loss:0.00000, loss_test:0.11063, lr:2.19e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.922, tt:8887.436\n",
      "Ep:212, loss:0.00000, loss_test:0.10904, lr:2.17e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.928, tt:8930.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:213, loss:0.00000, loss_test:0.11004, lr:2.15e-03, fs:0.60800 (r=0.437,p=1.000),  time:41.928, tt:8972.665\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02109, lr:6.00e-02, fs:0.64815 (r=0.805,p=0.543),  time:31.231, tt:31.231\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02234, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:32.411, tt:64.823\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02286, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.512, tt:100.536\n",
      "Ep:3, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:34.823, tt:139.293\n",
      "Ep:4, loss:0.00004, loss_test:0.02008, lr:6.00e-02, fs:0.69076 (r=0.989,p=0.531),  time:35.203, tt:176.013\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.70742 (r=0.931,p=0.570),  time:36.331, tt:217.986\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01924, lr:6.00e-02, fs:0.69608 (r=0.816,p=0.607),  time:37.022, tt:259.154\n",
      "Ep:7, loss:0.00004, loss_test:0.01940, lr:6.00e-02, fs:0.70408 (r=0.793,p=0.633),  time:37.779, tt:302.234\n",
      "Ep:8, loss:0.00003, loss_test:0.01877, lr:6.00e-02, fs:0.73430 (r=0.874,p=0.633),  time:38.221, tt:343.985\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01833, lr:6.00e-02, fs:0.72646 (r=0.931,p=0.596),  time:38.569, tt:385.685\n",
      "Ep:10, loss:0.00003, loss_test:0.01813, lr:6.00e-02, fs:0.72000 (r=0.931,p=0.587),  time:38.945, tt:428.392\n",
      "Ep:11, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.73778 (r=0.954,p=0.601),  time:39.146, tt:469.748\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.72986 (r=0.885,p=0.621),  time:39.355, tt:511.618\n",
      "Ep:13, loss:0.00003, loss_test:0.01759, lr:6.00e-02, fs:0.73529 (r=0.862,p=0.641),  time:39.581, tt:554.132\n",
      "Ep:14, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.75377 (r=0.862,p=0.670),  time:40.038, tt:600.569\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01717, lr:6.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:40.540, tt:648.637\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01694, lr:6.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:40.677, tt:691.501\n",
      "Ep:17, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.76382 (r=0.874,p=0.679),  time:40.741, tt:733.344\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.76382 (r=0.874,p=0.679),  time:40.749, tt:774.235\n",
      "Ep:19, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.75258 (r=0.839,p=0.682),  time:40.736, tt:814.710\n",
      "Ep:20, loss:0.00002, loss_test:0.01651, lr:6.00e-02, fs:0.75393 (r=0.828,p=0.692),  time:40.767, tt:856.117\n",
      "Ep:21, loss:0.00002, loss_test:0.01630, lr:6.00e-02, fs:0.75000 (r=0.828,p=0.686),  time:40.755, tt:896.599\n",
      "Ep:22, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.75000 (r=0.828,p=0.686),  time:40.805, tt:938.509\n",
      "Ep:23, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.75393 (r=0.828,p=0.692),  time:40.772, tt:978.521\n",
      "Ep:24, loss:0.00002, loss_test:0.01601, lr:6.00e-02, fs:0.75393 (r=0.828,p=0.692),  time:40.780, tt:1019.496\n",
      "Ep:25, loss:0.00002, loss_test:0.01595, lr:6.00e-02, fs:0.75532 (r=0.816,p=0.703),  time:40.878, tt:1062.835\n",
      "Ep:26, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.75132 (r=0.816,p=0.696),  time:40.864, tt:1103.322\n",
      "Ep:27, loss:0.00002, loss_test:0.01579, lr:6.00e-02, fs:0.75132 (r=0.816,p=0.696),  time:40.907, tt:1145.398\n",
      "Ep:28, loss:0.00002, loss_test:0.01580, lr:6.00e-02, fs:0.75936 (r=0.816,p=0.710),  time:40.901, tt:1186.125\n",
      "Ep:29, loss:0.00002, loss_test:0.01575, lr:5.94e-02, fs:0.76344 (r=0.816,p=0.717),  time:40.893, tt:1226.799\n",
      "Ep:30, loss:0.00002, loss_test:0.01572, lr:5.88e-02, fs:0.76757 (r=0.816,p=0.724),  time:40.904, tt:1268.032\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01566, lr:5.88e-02, fs:0.76344 (r=0.816,p=0.717),  time:40.931, tt:1309.782\n",
      "Ep:32, loss:0.00002, loss_test:0.01567, lr:5.88e-02, fs:0.76344 (r=0.816,p=0.717),  time:40.918, tt:1350.292\n",
      "Ep:33, loss:0.00002, loss_test:0.01575, lr:5.88e-02, fs:0.76757 (r=0.816,p=0.724),  time:40.908, tt:1390.863\n",
      "Ep:34, loss:0.00002, loss_test:0.01576, lr:5.88e-02, fs:0.76757 (r=0.816,p=0.724),  time:40.904, tt:1431.634\n",
      "Ep:35, loss:0.00002, loss_test:0.01567, lr:5.88e-02, fs:0.76344 (r=0.816,p=0.717),  time:40.893, tt:1472.153\n",
      "Ep:36, loss:0.00002, loss_test:0.01562, lr:5.88e-02, fs:0.77005 (r=0.828,p=0.720),  time:40.868, tt:1512.120\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01561, lr:5.88e-02, fs:0.78075 (r=0.839,p=0.730),  time:40.874, tt:1553.224\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01560, lr:5.88e-02, fs:0.78075 (r=0.839,p=0.730),  time:40.914, tt:1595.634\n",
      "Ep:39, loss:0.00002, loss_test:0.01566, lr:5.88e-02, fs:0.78495 (r=0.839,p=0.737),  time:40.949, tt:1637.946\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01571, lr:5.88e-02, fs:0.78495 (r=0.839,p=0.737),  time:40.947, tt:1678.816\n",
      "Ep:41, loss:0.00001, loss_test:0.01564, lr:5.88e-02, fs:0.77838 (r=0.828,p=0.735),  time:40.949, tt:1719.859\n",
      "Ep:42, loss:0.00001, loss_test:0.01572, lr:5.88e-02, fs:0.79348 (r=0.839,p=0.753),  time:40.954, tt:1761.001\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01570, lr:5.88e-02, fs:0.79781 (r=0.839,p=0.760),  time:40.937, tt:1801.244\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01580, lr:5.88e-02, fs:0.80220 (r=0.839,p=0.768),  time:40.862, tt:1838.791\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01579, lr:5.88e-02, fs:0.80220 (r=0.839,p=0.768),  time:40.866, tt:1879.827\n",
      "Ep:46, loss:0.00001, loss_test:0.01573, lr:5.88e-02, fs:0.79781 (r=0.839,p=0.760),  time:40.856, tt:1920.243\n",
      "Ep:47, loss:0.00001, loss_test:0.01581, lr:5.88e-02, fs:0.81111 (r=0.839,p=0.785),  time:40.887, tt:1962.570\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01578, lr:5.88e-02, fs:0.81768 (r=0.851,p=0.787),  time:40.904, tt:2004.301\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01577, lr:5.88e-02, fs:0.81768 (r=0.851,p=0.787),  time:40.933, tt:2046.632\n",
      "Ep:50, loss:0.00001, loss_test:0.01584, lr:5.88e-02, fs:0.82222 (r=0.851,p=0.796),  time:40.906, tt:2086.203\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01586, lr:5.88e-02, fs:0.82222 (r=0.851,p=0.796),  time:40.894, tt:2126.489\n",
      "Ep:52, loss:0.00001, loss_test:0.01594, lr:5.88e-02, fs:0.82222 (r=0.851,p=0.796),  time:40.863, tt:2165.740\n",
      "Ep:53, loss:0.00001, loss_test:0.01589, lr:5.88e-02, fs:0.82222 (r=0.851,p=0.796),  time:40.888, tt:2207.926\n",
      "Ep:54, loss:0.00001, loss_test:0.01599, lr:5.88e-02, fs:0.82682 (r=0.851,p=0.804),  time:40.864, tt:2247.532\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01604, lr:5.88e-02, fs:0.82682 (r=0.851,p=0.804),  time:40.857, tt:2288.015\n",
      "Ep:56, loss:0.00001, loss_test:0.01614, lr:5.88e-02, fs:0.82682 (r=0.851,p=0.804),  time:40.817, tt:2326.587\n",
      "Ep:57, loss:0.00001, loss_test:0.01620, lr:5.88e-02, fs:0.82682 (r=0.851,p=0.804),  time:40.789, tt:2365.748\n",
      "Ep:58, loss:0.00001, loss_test:0.01614, lr:5.88e-02, fs:0.82682 (r=0.851,p=0.804),  time:40.747, tt:2404.096\n",
      "Ep:59, loss:0.00001, loss_test:0.01633, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.724, tt:2443.463\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01631, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.712, tt:2483.404\n",
      "Ep:61, loss:0.00001, loss_test:0.01620, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.725, tt:2524.935\n",
      "Ep:62, loss:0.00001, loss_test:0.01655, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.735, tt:2566.283\n",
      "Ep:63, loss:0.00001, loss_test:0.01637, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.758, tt:2608.510\n",
      "Ep:64, loss:0.00001, loss_test:0.01650, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.725, tt:2647.093\n",
      "Ep:65, loss:0.00001, loss_test:0.01654, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.725, tt:2687.844\n",
      "Ep:66, loss:0.00001, loss_test:0.01653, lr:5.88e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.697, tt:2726.695\n",
      "Ep:67, loss:0.00001, loss_test:0.01680, lr:5.88e-02, fs:0.81609 (r=0.816,p=0.816),  time:40.699, tt:2767.525\n",
      "Ep:68, loss:0.00001, loss_test:0.01675, lr:5.88e-02, fs:0.81609 (r=0.816,p=0.816),  time:40.692, tt:2807.761\n",
      "Ep:69, loss:0.00001, loss_test:0.01682, lr:5.88e-02, fs:0.81609 (r=0.816,p=0.816),  time:40.700, tt:2848.975\n",
      "Ep:70, loss:0.00001, loss_test:0.01681, lr:5.88e-02, fs:0.81609 (r=0.816,p=0.816),  time:40.670, tt:2887.541\n",
      "Ep:71, loss:0.00001, loss_test:0.01687, lr:5.82e-02, fs:0.82081 (r=0.816,p=0.826),  time:40.648, tt:2926.628\n",
      "Ep:72, loss:0.00001, loss_test:0.01702, lr:5.76e-02, fs:0.82558 (r=0.816,p=0.835),  time:40.629, tt:2965.883\n",
      "Ep:73, loss:0.00001, loss_test:0.01697, lr:5.71e-02, fs:0.82558 (r=0.816,p=0.835),  time:40.618, tt:3005.747\n",
      "Ep:74, loss:0.00001, loss_test:0.01713, lr:5.65e-02, fs:0.82558 (r=0.816,p=0.835),  time:40.604, tt:3045.298\n",
      "Ep:75, loss:0.00001, loss_test:0.01721, lr:5.59e-02, fs:0.82558 (r=0.816,p=0.835),  time:40.592, tt:3084.970\n",
      "Ep:76, loss:0.00001, loss_test:0.01731, lr:5.54e-02, fs:0.81871 (r=0.805,p=0.833),  time:40.625, tt:3128.149\n",
      "Ep:77, loss:0.00001, loss_test:0.01736, lr:5.48e-02, fs:0.83041 (r=0.816,p=0.845),  time:40.607, tt:3167.372\n",
      "Ep:78, loss:0.00001, loss_test:0.01738, lr:5.43e-02, fs:0.83041 (r=0.816,p=0.845),  time:40.601, tt:3207.452\n",
      "Ep:79, loss:0.00001, loss_test:0.01752, lr:5.37e-02, fs:0.82353 (r=0.805,p=0.843),  time:40.597, tt:3247.799\n",
      "Ep:80, loss:0.00001, loss_test:0.01756, lr:5.32e-02, fs:0.83041 (r=0.816,p=0.845),  time:40.588, tt:3287.665\n",
      "Ep:81, loss:0.00001, loss_test:0.01767, lr:5.27e-02, fs:0.82143 (r=0.793,p=0.852),  time:40.582, tt:3327.695\n",
      "Ep:82, loss:0.00001, loss_test:0.01769, lr:5.21e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.587, tt:3368.756\n",
      "Ep:83, loss:0.00001, loss_test:0.01775, lr:5.16e-02, fs:0.80952 (r=0.782,p=0.840),  time:40.571, tt:3407.979\n",
      "Ep:84, loss:0.00001, loss_test:0.01778, lr:5.11e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.570, tt:3448.474\n",
      "Ep:85, loss:0.00001, loss_test:0.01788, lr:5.06e-02, fs:0.75472 (r=0.690,p=0.833),  time:40.598, tt:3491.394\n",
      "Ep:86, loss:0.00001, loss_test:0.01804, lr:5.01e-02, fs:0.73885 (r=0.667,p=0.829),  time:40.607, tt:3532.834\n",
      "Ep:87, loss:0.00001, loss_test:0.01805, lr:4.96e-02, fs:0.73885 (r=0.667,p=0.829),  time:40.628, tt:3575.290\n",
      "Ep:88, loss:0.00001, loss_test:0.01801, lr:4.91e-02, fs:0.71429 (r=0.632,p=0.821),  time:40.644, tt:3617.273\n",
      "Ep:89, loss:0.00001, loss_test:0.01815, lr:4.86e-02, fs:0.70588 (r=0.621,p=0.818),  time:40.639, tt:3657.475\n",
      "Ep:90, loss:0.00001, loss_test:0.01819, lr:4.81e-02, fs:0.70588 (r=0.621,p=0.818),  time:40.642, tt:3698.418\n",
      "Ep:91, loss:0.00001, loss_test:0.01838, lr:4.76e-02, fs:0.68000 (r=0.586,p=0.810),  time:40.671, tt:3741.766\n",
      "Ep:92, loss:0.00001, loss_test:0.01828, lr:4.71e-02, fs:0.69737 (r=0.609,p=0.815),  time:40.678, tt:3783.029\n",
      "Ep:93, loss:0.00001, loss_test:0.01852, lr:4.67e-02, fs:0.67568 (r=0.575,p=0.820),  time:40.683, tt:3824.238\n",
      "Ep:94, loss:0.00001, loss_test:0.01848, lr:4.62e-02, fs:0.67114 (r=0.575,p=0.806),  time:40.696, tt:3866.078\n",
      "Ep:95, loss:0.00001, loss_test:0.01856, lr:4.57e-02, fs:0.67568 (r=0.575,p=0.820),  time:40.707, tt:3907.829\n",
      "Ep:96, loss:0.00001, loss_test:0.01868, lr:4.53e-02, fs:0.67568 (r=0.575,p=0.820),  time:40.739, tt:3951.719\n",
      "Ep:97, loss:0.00001, loss_test:0.01868, lr:4.48e-02, fs:0.66216 (r=0.563,p=0.803),  time:40.733, tt:3991.806\n",
      "Ep:98, loss:0.00001, loss_test:0.01876, lr:4.44e-02, fs:0.66216 (r=0.563,p=0.803),  time:40.724, tt:4031.681\n",
      "Ep:99, loss:0.00001, loss_test:0.01890, lr:4.39e-02, fs:0.66667 (r=0.563,p=0.817),  time:40.742, tt:4074.234\n",
      "Ep:100, loss:0.00000, loss_test:0.01888, lr:4.35e-02, fs:0.67123 (r=0.563,p=0.831),  time:40.749, tt:4115.665\n",
      "Ep:101, loss:0.00000, loss_test:0.01907, lr:4.31e-02, fs:0.65753 (r=0.552,p=0.814),  time:40.767, tt:4158.228\n",
      "Ep:102, loss:0.00000, loss_test:0.01908, lr:4.26e-02, fs:0.65753 (r=0.552,p=0.814),  time:40.791, tt:4201.439\n",
      "Ep:103, loss:0.00000, loss_test:0.01915, lr:4.22e-02, fs:0.66207 (r=0.552,p=0.828),  time:40.793, tt:4242.458\n",
      "Ep:104, loss:0.00000, loss_test:0.01926, lr:4.18e-02, fs:0.66207 (r=0.552,p=0.828),  time:40.832, tt:4287.372\n",
      "Ep:105, loss:0.00000, loss_test:0.01921, lr:4.14e-02, fs:0.65278 (r=0.540,p=0.825),  time:40.845, tt:4329.597\n",
      "Ep:106, loss:0.00000, loss_test:0.01932, lr:4.10e-02, fs:0.66207 (r=0.552,p=0.828),  time:40.887, tt:4374.871\n",
      "Ep:107, loss:0.00000, loss_test:0.01934, lr:4.05e-02, fs:0.65734 (r=0.540,p=0.839),  time:40.888, tt:4415.898\n",
      "Ep:108, loss:0.00000, loss_test:0.01940, lr:4.01e-02, fs:0.65734 (r=0.540,p=0.839),  time:40.901, tt:4458.261\n",
      "Ep:109, loss:0.00000, loss_test:0.01953, lr:3.97e-02, fs:0.65248 (r=0.529,p=0.852),  time:40.932, tt:4502.569\n",
      "Ep:110, loss:0.00000, loss_test:0.01954, lr:3.93e-02, fs:0.66197 (r=0.540,p=0.855),  time:40.927, tt:4542.919\n",
      "Ep:111, loss:0.00000, loss_test:0.01969, lr:3.89e-02, fs:0.65248 (r=0.529,p=0.852),  time:40.921, tt:4583.126\n",
      "Ep:112, loss:0.00000, loss_test:0.01964, lr:3.86e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.916, tt:4623.541\n",
      "Ep:113, loss:0.00000, loss_test:0.01982, lr:3.82e-02, fs:0.65248 (r=0.529,p=0.852),  time:40.901, tt:4662.677\n",
      "Ep:114, loss:0.00000, loss_test:0.01981, lr:3.78e-02, fs:0.65248 (r=0.529,p=0.852),  time:40.905, tt:4704.108\n",
      "Ep:115, loss:0.00000, loss_test:0.02000, lr:3.74e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.921, tt:4746.783\n",
      "Ep:116, loss:0.00000, loss_test:0.01995, lr:3.70e-02, fs:0.65714 (r=0.529,p=0.868),  time:40.933, tt:4789.202\n",
      "Ep:117, loss:0.00000, loss_test:0.02004, lr:3.67e-02, fs:0.64748 (r=0.517,p=0.865),  time:40.947, tt:4831.705\n",
      "Ep:118, loss:0.00000, loss_test:0.02006, lr:3.63e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.952, tt:4873.275\n",
      "Ep:119, loss:0.00000, loss_test:0.02021, lr:3.59e-02, fs:0.64748 (r=0.517,p=0.865),  time:40.943, tt:4913.138\n",
      "Ep:120, loss:0.00000, loss_test:0.02020, lr:3.56e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.949, tt:4954.781\n",
      "Ep:121, loss:0.00000, loss_test:0.02022, lr:3.52e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.944, tt:4995.140\n",
      "Ep:122, loss:0.00000, loss_test:0.02035, lr:3.49e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.960, tt:5038.025\n",
      "Ep:123, loss:0.00000, loss_test:0.02032, lr:3.45e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.970, tt:5080.336\n",
      "Ep:124, loss:0.00000, loss_test:0.02050, lr:3.42e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.972, tt:5121.484\n",
      "Ep:125, loss:0.00000, loss_test:0.02052, lr:3.38e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.968, tt:5161.943\n",
      "Ep:126, loss:0.00000, loss_test:0.02054, lr:3.35e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.970, tt:5203.178\n",
      "Ep:127, loss:0.00000, loss_test:0.02072, lr:3.32e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.968, tt:5243.853\n",
      "Ep:128, loss:0.00000, loss_test:0.02068, lr:3.28e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.973, tt:5285.548\n",
      "Ep:129, loss:0.00000, loss_test:0.02073, lr:3.25e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.975, tt:5326.740\n",
      "Ep:130, loss:0.00000, loss_test:0.02082, lr:3.22e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.979, tt:5368.247\n",
      "Ep:131, loss:0.00000, loss_test:0.02083, lr:3.19e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.978, tt:5409.139\n",
      "Ep:132, loss:0.00000, loss_test:0.02094, lr:3.15e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.968, tt:5448.755\n",
      "Ep:133, loss:0.00000, loss_test:0.02093, lr:3.12e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.968, tt:5489.669\n",
      "Ep:134, loss:0.00000, loss_test:0.02099, lr:3.09e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.976, tt:5531.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.02112, lr:3.06e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.974, tt:5572.504\n",
      "Ep:136, loss:0.00000, loss_test:0.02114, lr:3.03e-02, fs:0.65217 (r=0.517,p=0.882),  time:40.981, tt:5614.456\n",
      "Ep:137, loss:0.00000, loss_test:0.02121, lr:3.00e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.982, tt:5655.560\n",
      "Ep:138, loss:0.00000, loss_test:0.02124, lr:2.97e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.982, tt:5696.553\n",
      "Ep:139, loss:0.00000, loss_test:0.02125, lr:2.94e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.986, tt:5738.012\n",
      "Ep:140, loss:0.00000, loss_test:0.02133, lr:2.91e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.986, tt:5779.071\n",
      "Ep:141, loss:0.00000, loss_test:0.02133, lr:2.88e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.970, tt:5817.714\n",
      "Ep:142, loss:0.00000, loss_test:0.02142, lr:2.85e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.965, tt:5857.945\n",
      "Ep:143, loss:0.00000, loss_test:0.02144, lr:2.82e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.941, tt:5895.556\n",
      "Ep:144, loss:0.00000, loss_test:0.02155, lr:2.80e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.933, tt:5935.236\n",
      "Ep:145, loss:0.00000, loss_test:0.02153, lr:2.77e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.940, tt:5977.252\n",
      "Ep:146, loss:0.00000, loss_test:0.02157, lr:2.74e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.947, tt:6019.200\n",
      "Ep:147, loss:0.00000, loss_test:0.02167, lr:2.71e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.949, tt:6060.422\n",
      "Ep:148, loss:0.00000, loss_test:0.02171, lr:2.69e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.952, tt:6101.908\n",
      "Ep:149, loss:0.00000, loss_test:0.02166, lr:2.66e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.945, tt:6141.716\n",
      "Ep:150, loss:0.00000, loss_test:0.02180, lr:2.63e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.919, tt:6178.811\n",
      "Ep:151, loss:0.00000, loss_test:0.02180, lr:2.61e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.922, tt:6220.130\n",
      "Ep:152, loss:0.00000, loss_test:0.02186, lr:2.58e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.921, tt:6260.976\n",
      "Ep:153, loss:0.00000, loss_test:0.02199, lr:2.55e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.922, tt:6301.936\n",
      "Ep:154, loss:0.00000, loss_test:0.02192, lr:2.53e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.927, tt:6343.644\n",
      "Ep:155, loss:0.00000, loss_test:0.02194, lr:2.50e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.927, tt:6384.598\n",
      "Ep:156, loss:0.00000, loss_test:0.02209, lr:2.48e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.927, tt:6425.573\n",
      "Ep:157, loss:0.00000, loss_test:0.02203, lr:2.45e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.916, tt:6464.761\n",
      "Ep:158, loss:0.00000, loss_test:0.02209, lr:2.43e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.926, tt:6507.188\n",
      "Ep:159, loss:0.00000, loss_test:0.02215, lr:2.40e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.920, tt:6547.137\n",
      "Ep:160, loss:0.00000, loss_test:0.02212, lr:2.38e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.917, tt:6587.568\n",
      "Ep:161, loss:0.00000, loss_test:0.02219, lr:2.36e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.920, tt:6629.096\n",
      "Ep:162, loss:0.00000, loss_test:0.02227, lr:2.33e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.919, tt:6669.719\n",
      "Ep:163, loss:0.00000, loss_test:0.02226, lr:2.31e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.913, tt:6709.701\n",
      "Ep:164, loss:0.00000, loss_test:0.02236, lr:2.29e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.906, tt:6749.553\n",
      "Ep:165, loss:0.00000, loss_test:0.02241, lr:2.26e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.917, tt:6792.271\n",
      "Ep:166, loss:0.00000, loss_test:0.02241, lr:2.24e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.926, tt:6834.590\n",
      "Ep:167, loss:0.00000, loss_test:0.02242, lr:2.22e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.915, tt:6873.736\n",
      "Ep:168, loss:0.00000, loss_test:0.02246, lr:2.20e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.928, tt:6916.766\n",
      "Ep:169, loss:0.00000, loss_test:0.02250, lr:2.17e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.942, tt:6960.076\n",
      "Ep:170, loss:0.00000, loss_test:0.02251, lr:2.15e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.938, tt:7000.320\n",
      "Ep:171, loss:0.00000, loss_test:0.02254, lr:2.13e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.933, tt:7040.447\n",
      "Ep:172, loss:0.00000, loss_test:0.02258, lr:2.11e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.932, tt:7081.154\n",
      "Ep:173, loss:0.00000, loss_test:0.02261, lr:2.09e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.937, tt:7122.980\n",
      "Ep:174, loss:0.00000, loss_test:0.02266, lr:2.07e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.922, tt:7161.288\n",
      "Ep:175, loss:0.00000, loss_test:0.02267, lr:2.05e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.911, tt:7200.327\n",
      "Ep:176, loss:0.00000, loss_test:0.02270, lr:2.03e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.917, tt:7242.245\n",
      "Ep:177, loss:0.00000, loss_test:0.02275, lr:2.01e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.917, tt:7283.307\n",
      "Ep:178, loss:0.00000, loss_test:0.02278, lr:1.99e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.915, tt:7323.856\n",
      "Ep:179, loss:0.00000, loss_test:0.02279, lr:1.97e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.902, tt:7362.326\n",
      "Ep:180, loss:0.00000, loss_test:0.02283, lr:1.95e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.892, tt:7401.526\n",
      "Ep:181, loss:0.00000, loss_test:0.02283, lr:1.93e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.893, tt:7442.456\n",
      "Ep:182, loss:0.00000, loss_test:0.02290, lr:1.91e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.886, tt:7482.135\n",
      "Ep:183, loss:0.00000, loss_test:0.02294, lr:1.89e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.898, tt:7525.229\n",
      "Ep:184, loss:0.00000, loss_test:0.02289, lr:1.87e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.902, tt:7566.959\n",
      "Ep:185, loss:0.00000, loss_test:0.02299, lr:1.85e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.898, tt:7606.970\n",
      "Ep:186, loss:0.00000, loss_test:0.02303, lr:1.83e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.893, tt:7646.933\n",
      "Ep:187, loss:0.00000, loss_test:0.02300, lr:1.81e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.889, tt:7687.216\n",
      "Ep:188, loss:0.00000, loss_test:0.02305, lr:1.80e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.888, tt:7727.902\n",
      "Ep:189, loss:0.00000, loss_test:0.02307, lr:1.78e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.898, tt:7770.654\n",
      "Ep:190, loss:0.00000, loss_test:0.02310, lr:1.76e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.881, tt:7808.317\n",
      "Ep:191, loss:0.00000, loss_test:0.02310, lr:1.74e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.877, tt:7848.372\n",
      "Ep:192, loss:0.00000, loss_test:0.02317, lr:1.73e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.871, tt:7888.016\n",
      "Ep:193, loss:0.00000, loss_test:0.02316, lr:1.71e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.869, tt:7928.657\n",
      "Ep:194, loss:0.00000, loss_test:0.02320, lr:1.69e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.877, tt:7971.024\n",
      "Ep:195, loss:0.00000, loss_test:0.02323, lr:1.67e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.882, tt:8012.924\n",
      "Ep:196, loss:0.00000, loss_test:0.02327, lr:1.66e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.887, tt:8054.710\n",
      "Ep:197, loss:0.00000, loss_test:0.02325, lr:1.64e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.890, tt:8096.304\n",
      "Ep:198, loss:0.00000, loss_test:0.02330, lr:1.62e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.885, tt:8136.111\n",
      "Ep:199, loss:0.00000, loss_test:0.02337, lr:1.61e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.880, tt:8175.937\n",
      "Ep:200, loss:0.00000, loss_test:0.02332, lr:1.59e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.869, tt:8214.626\n",
      "Ep:201, loss:0.00000, loss_test:0.02334, lr:1.58e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.863, tt:8254.294\n",
      "Ep:202, loss:0.00000, loss_test:0.02340, lr:1.56e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.856, tt:8293.765\n",
      "Ep:203, loss:0.00000, loss_test:0.02343, lr:1.54e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.860, tt:8335.340\n",
      "Ep:204, loss:0.00000, loss_test:0.02341, lr:1.53e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.859, tt:8376.002\n",
      "Ep:205, loss:0.00000, loss_test:0.02345, lr:1.51e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.861, tt:8417.397\n",
      "Ep:206, loss:0.00000, loss_test:0.02351, lr:1.50e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.856, tt:8457.151\n",
      "Ep:207, loss:0.00000, loss_test:0.02350, lr:1.48e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.863, tt:8499.593\n",
      "Ep:208, loss:0.00000, loss_test:0.02351, lr:1.47e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.864, tt:8540.587\n",
      "Ep:209, loss:0.00000, loss_test:0.02354, lr:1.45e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.871, tt:8582.848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.02358, lr:1.44e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.867, tt:8622.836\n",
      "Ep:211, loss:0.00000, loss_test:0.02357, lr:1.43e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.857, tt:8661.727\n",
      "Ep:212, loss:0.00000, loss_test:0.02359, lr:1.41e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.855, tt:8702.127\n",
      "Ep:213, loss:0.00000, loss_test:0.02362, lr:1.40e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.853, tt:8742.462\n",
      "Ep:214, loss:0.00000, loss_test:0.02363, lr:1.38e-02, fs:0.64234 (r=0.506,p=0.880),  time:40.857, tt:8784.150\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13328, lr:1.00e-02, fs:0.67717 (r=0.989,p=0.515),  time:29.957, tt:29.957\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12817, lr:1.00e-02, fs:0.68293 (r=0.966,p=0.528),  time:34.561, tt:69.122\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12128, lr:1.00e-02, fs:0.66960 (r=0.874,p=0.543),  time:35.780, tt:107.339\n",
      "Ep:3, loss:0.00025, loss_test:0.11598, lr:1.00e-02, fs:0.68599 (r=0.816,p=0.592),  time:36.602, tt:146.407\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11282, lr:1.00e-02, fs:0.70157 (r=0.770,p=0.644),  time:37.317, tt:186.586\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11207, lr:1.00e-02, fs:0.68852 (r=0.724,p=0.656),  time:37.669, tt:226.016\n",
      "Ep:6, loss:0.00022, loss_test:0.11164, lr:1.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:38.101, tt:266.710\n",
      "Ep:7, loss:0.00022, loss_test:0.11117, lr:1.00e-02, fs:0.67039 (r=0.690,p=0.652),  time:38.606, tt:308.852\n",
      "Ep:8, loss:0.00021, loss_test:0.11033, lr:1.00e-02, fs:0.67456 (r=0.655,p=0.695),  time:38.978, tt:350.800\n",
      "Ep:9, loss:0.00020, loss_test:0.10723, lr:1.00e-02, fs:0.68263 (r=0.655,p=0.713),  time:39.132, tt:391.318\n",
      "Ep:10, loss:0.00019, loss_test:0.10469, lr:1.00e-02, fs:0.69048 (r=0.667,p=0.716),  time:39.417, tt:433.585\n",
      "Ep:11, loss:0.00019, loss_test:0.10202, lr:1.00e-02, fs:0.69822 (r=0.678,p=0.720),  time:39.433, tt:473.193\n",
      "Ep:12, loss:0.00018, loss_test:0.09929, lr:1.00e-02, fs:0.69091 (r=0.655,p=0.731),  time:39.797, tt:517.361\n",
      "Ep:13, loss:0.00017, loss_test:0.09706, lr:1.00e-02, fs:0.73684 (r=0.724,p=0.750),  time:40.016, tt:560.220\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09561, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:40.599, tt:608.979\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09478, lr:1.00e-02, fs:0.77457 (r=0.770,p=0.779),  time:40.682, tt:650.918\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09277, lr:1.00e-02, fs:0.80220 (r=0.839,p=0.768),  time:40.803, tt:693.653\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09210, lr:1.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:40.944, tt:736.999\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09109, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:41.102, tt:780.933\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09031, lr:1.00e-02, fs:0.82286 (r=0.828,p=0.818),  time:41.075, tt:821.505\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08864, lr:1.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:41.124, tt:863.596\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08974, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:41.243, tt:907.346\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08589, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:41.292, tt:949.726\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08786, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.326, tt:991.821\n",
      "Ep:24, loss:0.00011, loss_test:0.08347, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:41.432, tt:1035.791\n",
      "Ep:25, loss:0.00011, loss_test:0.08705, lr:1.00e-02, fs:0.86420 (r=0.805,p=0.933),  time:41.477, tt:1078.399\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.08196, lr:1.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:41.529, tt:1121.272\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.08393, lr:1.00e-02, fs:0.87425 (r=0.839,p=0.912),  time:41.591, tt:1164.534\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.08093, lr:1.00e-02, fs:0.88506 (r=0.885,p=0.885),  time:41.648, tt:1207.806\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.08210, lr:1.00e-02, fs:0.86905 (r=0.839,p=0.901),  time:41.648, tt:1249.427\n",
      "Ep:30, loss:0.00009, loss_test:0.08381, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.681, tt:1292.097\n",
      "Ep:31, loss:0.00008, loss_test:0.08046, lr:1.00e-02, fs:0.88136 (r=0.897,p=0.867),  time:41.692, tt:1334.143\n",
      "Ep:32, loss:0.00008, loss_test:0.08299, lr:1.00e-02, fs:0.86747 (r=0.828,p=0.911),  time:41.724, tt:1376.879\n",
      "Ep:33, loss:0.00008, loss_test:0.08241, lr:1.00e-02, fs:0.86391 (r=0.839,p=0.890),  time:41.748, tt:1419.419\n",
      "Ep:34, loss:0.00007, loss_test:0.08358, lr:1.00e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.788, tt:1462.589\n",
      "Ep:35, loss:0.00007, loss_test:0.08230, lr:1.00e-02, fs:0.87719 (r=0.862,p=0.893),  time:41.804, tt:1504.935\n",
      "Ep:36, loss:0.00007, loss_test:0.08164, lr:1.00e-02, fs:0.89412 (r=0.874,p=0.916),  time:41.809, tt:1546.950\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.09200, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:41.754, tt:1586.668\n",
      "Ep:38, loss:0.00006, loss_test:0.08003, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:41.760, tt:1628.631\n",
      "Ep:39, loss:0.00006, loss_test:0.09402, lr:1.00e-02, fs:0.79730 (r=0.678,p=0.967),  time:41.723, tt:1668.938\n",
      "Ep:40, loss:0.00006, loss_test:0.07838, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:41.712, tt:1710.194\n",
      "Ep:41, loss:0.00006, loss_test:0.08996, lr:1.00e-02, fs:0.80519 (r=0.713,p=0.925),  time:41.699, tt:1751.354\n",
      "Ep:42, loss:0.00005, loss_test:0.08222, lr:1.00e-02, fs:0.87719 (r=0.862,p=0.893),  time:41.709, tt:1793.480\n",
      "Ep:43, loss:0.00005, loss_test:0.08465, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.724, tt:1835.860\n",
      "Ep:44, loss:0.00005, loss_test:0.08288, lr:1.00e-02, fs:0.87574 (r=0.851,p=0.902),  time:41.703, tt:1876.635\n",
      "Ep:45, loss:0.00005, loss_test:0.08519, lr:1.00e-02, fs:0.85366 (r=0.805,p=0.909),  time:41.712, tt:1918.763\n",
      "Ep:46, loss:0.00004, loss_test:0.08270, lr:1.00e-02, fs:0.88095 (r=0.851,p=0.914),  time:41.668, tt:1958.395\n",
      "Ep:47, loss:0.00004, loss_test:0.08664, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:41.669, tt:2000.116\n",
      "Ep:48, loss:0.00004, loss_test:0.08306, lr:9.90e-03, fs:0.89157 (r=0.851,p=0.937),  time:41.665, tt:2041.575\n",
      "Ep:49, loss:0.00004, loss_test:0.08793, lr:9.80e-03, fs:0.78146 (r=0.678,p=0.922),  time:41.619, tt:2080.974\n",
      "Ep:50, loss:0.00004, loss_test:0.08330, lr:9.70e-03, fs:0.88757 (r=0.862,p=0.915),  time:41.638, tt:2123.560\n",
      "Ep:51, loss:0.00004, loss_test:0.09011, lr:9.61e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.650, tt:2165.793\n",
      "Ep:52, loss:0.00003, loss_test:0.08293, lr:9.51e-03, fs:0.86061 (r=0.816,p=0.910),  time:41.662, tt:2208.076\n",
      "Ep:53, loss:0.00003, loss_test:0.09087, lr:9.41e-03, fs:0.77027 (r=0.655,p=0.934),  time:41.703, tt:2251.979\n",
      "Ep:54, loss:0.00003, loss_test:0.08512, lr:9.32e-03, fs:0.82051 (r=0.736,p=0.928),  time:41.717, tt:2294.429\n",
      "Ep:55, loss:0.00003, loss_test:0.09006, lr:9.23e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.719, tt:2336.284\n",
      "Ep:56, loss:0.00003, loss_test:0.08588, lr:9.14e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.698, tt:2376.791\n",
      "Ep:57, loss:0.00003, loss_test:0.09184, lr:9.04e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.683, tt:2417.591\n",
      "Ep:58, loss:0.00003, loss_test:0.08776, lr:8.95e-03, fs:0.83333 (r=0.747,p=0.942),  time:41.700, tt:2460.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.08980, lr:8.86e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.662, tt:2499.708\n",
      "Ep:60, loss:0.00003, loss_test:0.09361, lr:8.78e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.669, tt:2541.781\n",
      "Ep:61, loss:0.00003, loss_test:0.08851, lr:8.69e-03, fs:0.78667 (r=0.678,p=0.937),  time:41.662, tt:2583.016\n",
      "Ep:62, loss:0.00003, loss_test:0.08961, lr:8.60e-03, fs:0.76712 (r=0.644,p=0.949),  time:41.746, tt:2629.978\n",
      "Ep:63, loss:0.00003, loss_test:0.08801, lr:8.51e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.778, tt:2673.821\n",
      "Ep:64, loss:0.00002, loss_test:0.09449, lr:8.43e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.815, tt:2717.955\n",
      "Ep:65, loss:0.00002, loss_test:0.08509, lr:8.35e-03, fs:0.83333 (r=0.747,p=0.942),  time:41.819, tt:2760.045\n",
      "Ep:66, loss:0.00002, loss_test:0.09516, lr:8.26e-03, fs:0.76712 (r=0.644,p=0.949),  time:41.859, tt:2804.586\n",
      "Ep:67, loss:0.00002, loss_test:0.09140, lr:8.18e-03, fs:0.73611 (r=0.609,p=0.930),  time:41.864, tt:2846.731\n",
      "Ep:68, loss:0.00002, loss_test:0.08895, lr:8.10e-03, fs:0.77632 (r=0.678,p=0.908),  time:41.896, tt:2890.845\n",
      "Ep:69, loss:0.00002, loss_test:0.09812, lr:8.02e-03, fs:0.75000 (r=0.621,p=0.947),  time:41.929, tt:2935.012\n",
      "Ep:70, loss:0.00002, loss_test:0.08759, lr:7.94e-03, fs:0.76821 (r=0.667,p=0.906),  time:41.954, tt:2978.732\n",
      "Ep:71, loss:0.00002, loss_test:0.09611, lr:7.86e-03, fs:0.74483 (r=0.621,p=0.931),  time:41.956, tt:3020.843\n",
      "Ep:72, loss:0.00002, loss_test:0.09934, lr:7.78e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.954, tt:3062.630\n",
      "Ep:73, loss:0.00002, loss_test:0.08650, lr:7.70e-03, fs:0.82803 (r=0.747,p=0.929),  time:41.999, tt:3107.936\n",
      "Ep:74, loss:0.00002, loss_test:0.09651, lr:7.62e-03, fs:0.72340 (r=0.586,p=0.944),  time:42.017, tt:3151.256\n",
      "Ep:75, loss:0.00002, loss_test:0.09251, lr:7.55e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.020, tt:3193.482\n",
      "Ep:76, loss:0.00002, loss_test:0.09065, lr:7.47e-03, fs:0.78378 (r=0.667,p=0.951),  time:42.018, tt:3235.398\n",
      "Ep:77, loss:0.00002, loss_test:0.09509, lr:7.40e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.030, tt:3278.360\n",
      "Ep:78, loss:0.00002, loss_test:0.08961, lr:7.32e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.054, tt:3322.243\n",
      "Ep:79, loss:0.00002, loss_test:0.09358, lr:7.25e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.070, tt:3365.609\n",
      "Ep:80, loss:0.00002, loss_test:0.09566, lr:7.18e-03, fs:0.76712 (r=0.644,p=0.949),  time:42.067, tt:3407.444\n",
      "Ep:81, loss:0.00002, loss_test:0.08932, lr:7.11e-03, fs:0.80000 (r=0.690,p=0.952),  time:42.078, tt:3450.427\n",
      "Ep:82, loss:0.00002, loss_test:0.09534, lr:7.03e-03, fs:0.76712 (r=0.644,p=0.949),  time:42.064, tt:3491.311\n",
      "Ep:83, loss:0.00001, loss_test:0.09088, lr:6.96e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.051, tt:3532.326\n",
      "Ep:84, loss:0.00001, loss_test:0.09211, lr:6.89e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.058, tt:3574.945\n",
      "Ep:85, loss:0.00001, loss_test:0.09275, lr:6.83e-03, fs:0.80795 (r=0.701,p=0.953),  time:42.056, tt:3616.781\n",
      "Ep:86, loss:0.00001, loss_test:0.09146, lr:6.76e-03, fs:0.81579 (r=0.713,p=0.954),  time:42.054, tt:3658.711\n",
      "Ep:87, loss:0.00001, loss_test:0.09201, lr:6.69e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.046, tt:3700.015\n",
      "Ep:88, loss:0.00001, loss_test:0.09232, lr:6.62e-03, fs:0.80000 (r=0.690,p=0.952),  time:42.030, tt:3740.649\n",
      "Ep:89, loss:0.00001, loss_test:0.09205, lr:6.56e-03, fs:0.80795 (r=0.701,p=0.953),  time:42.034, tt:3783.045\n",
      "Ep:90, loss:0.00001, loss_test:0.09443, lr:6.49e-03, fs:0.80000 (r=0.690,p=0.952),  time:42.021, tt:3823.951\n",
      "Ep:91, loss:0.00001, loss_test:0.09212, lr:6.43e-03, fs:0.80795 (r=0.701,p=0.953),  time:42.001, tt:3864.091\n",
      "Ep:92, loss:0.00001, loss_test:0.09462, lr:6.36e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.992, tt:3905.271\n",
      "Ep:93, loss:0.00001, loss_test:0.09463, lr:6.30e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.988, tt:3946.836\n",
      "Ep:94, loss:0.00001, loss_test:0.09064, lr:6.24e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.996, tt:3989.630\n",
      "Ep:95, loss:0.00001, loss_test:0.09454, lr:6.17e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.979, tt:4029.950\n",
      "Ep:96, loss:0.00001, loss_test:0.09066, lr:6.11e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.968, tt:4070.877\n",
      "Ep:97, loss:0.00001, loss_test:0.09404, lr:6.05e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.928, tt:4108.898\n",
      "Ep:98, loss:0.00001, loss_test:0.09274, lr:5.99e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.922, tt:4150.236\n",
      "Ep:99, loss:0.00001, loss_test:0.09399, lr:5.93e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.901, tt:4190.059\n",
      "Ep:100, loss:0.00001, loss_test:0.09269, lr:5.87e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.885, tt:4230.390\n",
      "Ep:101, loss:0.00001, loss_test:0.09322, lr:5.81e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.883, tt:4272.056\n",
      "Ep:102, loss:0.00001, loss_test:0.09372, lr:5.75e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.887, tt:4314.332\n",
      "Ep:103, loss:0.00001, loss_test:0.09418, lr:5.70e-03, fs:0.81579 (r=0.713,p=0.954),  time:41.881, tt:4355.583\n",
      "Ep:104, loss:0.00001, loss_test:0.09284, lr:5.64e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.876, tt:4396.990\n",
      "Ep:105, loss:0.00001, loss_test:0.09375, lr:5.58e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.870, tt:4438.167\n",
      "Ep:106, loss:0.00001, loss_test:0.09320, lr:5.53e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.876, tt:4480.712\n",
      "Ep:107, loss:0.00001, loss_test:0.09357, lr:5.47e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.868, tt:4521.763\n",
      "Ep:108, loss:0.00001, loss_test:0.09325, lr:5.42e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.852, tt:4561.818\n",
      "Ep:109, loss:0.00001, loss_test:0.09485, lr:5.36e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.870, tt:4605.680\n",
      "Ep:110, loss:0.00001, loss_test:0.09325, lr:5.31e-03, fs:0.81579 (r=0.713,p=0.954),  time:41.893, tt:4650.173\n",
      "Ep:111, loss:0.00001, loss_test:0.09440, lr:5.26e-03, fs:0.81579 (r=0.713,p=0.954),  time:41.888, tt:4691.465\n",
      "Ep:112, loss:0.00001, loss_test:0.09547, lr:5.20e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.887, tt:4733.225\n",
      "Ep:113, loss:0.00001, loss_test:0.09289, lr:5.15e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.863, tt:4772.329\n",
      "Ep:114, loss:0.00001, loss_test:0.09596, lr:5.10e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.876, tt:4815.684\n",
      "Ep:115, loss:0.00001, loss_test:0.09490, lr:5.05e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.870, tt:4856.954\n",
      "Ep:116, loss:0.00001, loss_test:0.09446, lr:5.00e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.863, tt:4897.922\n",
      "Ep:117, loss:0.00001, loss_test:0.09548, lr:4.95e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.856, tt:4938.952\n",
      "Ep:118, loss:0.00001, loss_test:0.09494, lr:4.90e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.849, tt:4980.090\n",
      "Ep:119, loss:0.00001, loss_test:0.09629, lr:4.85e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.824, tt:5018.861\n",
      "Ep:120, loss:0.00001, loss_test:0.09564, lr:4.80e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.823, tt:5060.562\n",
      "Ep:121, loss:0.00001, loss_test:0.09482, lr:4.75e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.816, tt:5101.608\n",
      "Ep:122, loss:0.00001, loss_test:0.09702, lr:4.71e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.853, tt:5147.880\n",
      "Ep:123, loss:0.00001, loss_test:0.09629, lr:4.66e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.840, tt:5188.136\n",
      "Ep:124, loss:0.00001, loss_test:0.09725, lr:4.61e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.834, tt:5229.208\n",
      "Ep:125, loss:0.00001, loss_test:0.09661, lr:4.57e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.831, tt:5270.707\n",
      "Ep:126, loss:0.00001, loss_test:0.09745, lr:4.52e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.830, tt:5312.388\n",
      "Ep:127, loss:0.00001, loss_test:0.09834, lr:4.48e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.828, tt:5353.969\n",
      "Ep:128, loss:0.00001, loss_test:0.09811, lr:4.43e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.823, tt:5395.216\n",
      "Ep:129, loss:0.00001, loss_test:0.09594, lr:4.39e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.824, tt:5437.058\n",
      "Ep:130, loss:0.00001, loss_test:0.09842, lr:4.34e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.821, tt:5478.519\n",
      "Ep:131, loss:0.00001, loss_test:0.09696, lr:4.30e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.820, tt:5520.198\n",
      "Ep:132, loss:0.00001, loss_test:0.09765, lr:4.26e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.820, tt:5562.024\n",
      "Ep:133, loss:0.00001, loss_test:0.09854, lr:4.21e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.817, tt:5603.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.09661, lr:4.17e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.843, tt:5648.802\n",
      "Ep:135, loss:0.00001, loss_test:0.09875, lr:4.13e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.850, tt:5691.636\n",
      "Ep:136, loss:0.00001, loss_test:0.09921, lr:4.09e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.859, tt:5734.659\n",
      "Ep:137, loss:0.00001, loss_test:0.09682, lr:4.05e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.864, tt:5777.223\n",
      "Ep:138, loss:0.00001, loss_test:0.09887, lr:4.01e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.857, tt:5818.143\n",
      "Ep:139, loss:0.00001, loss_test:0.09937, lr:3.97e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.845, tt:5858.366\n",
      "Ep:140, loss:0.00001, loss_test:0.09734, lr:3.93e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.849, tt:5900.741\n",
      "Ep:141, loss:0.00001, loss_test:0.10008, lr:3.89e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.841, tt:5941.404\n",
      "Ep:142, loss:0.00001, loss_test:0.10121, lr:3.85e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.845, tt:5983.818\n",
      "Ep:143, loss:0.00001, loss_test:0.09835, lr:3.81e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.849, tt:6026.192\n",
      "Ep:144, loss:0.00001, loss_test:0.09759, lr:3.77e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.842, tt:6067.100\n",
      "Ep:145, loss:0.00001, loss_test:0.09881, lr:3.73e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.832, tt:6107.410\n",
      "Ep:146, loss:0.00001, loss_test:0.09830, lr:3.70e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.819, tt:6147.400\n",
      "Ep:147, loss:0.00001, loss_test:0.09778, lr:3.66e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.824, tt:6189.947\n",
      "Ep:148, loss:0.00001, loss_test:0.09885, lr:3.62e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.809, tt:6229.606\n",
      "Ep:149, loss:0.00001, loss_test:0.09845, lr:3.59e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.806, tt:6270.845\n",
      "Ep:150, loss:0.00001, loss_test:0.09809, lr:3.55e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.781, tt:6309.000\n",
      "Ep:151, loss:0.00001, loss_test:0.09858, lr:3.52e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.778, tt:6350.267\n",
      "Ep:152, loss:0.00001, loss_test:0.09867, lr:3.48e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.763, tt:6389.813\n",
      "Ep:153, loss:0.00000, loss_test:0.09793, lr:3.45e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.762, tt:6431.301\n",
      "Ep:154, loss:0.00000, loss_test:0.09958, lr:3.41e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.795, tt:6478.185\n",
      "Ep:155, loss:0.00000, loss_test:0.10059, lr:3.38e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.786, tt:6518.667\n",
      "Ep:156, loss:0.00000, loss_test:0.09886, lr:3.34e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.794, tt:6561.606\n",
      "Ep:157, loss:0.00000, loss_test:0.09786, lr:3.31e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.793, tt:6603.356\n",
      "Ep:158, loss:0.00000, loss_test:0.09990, lr:3.28e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.779, tt:6642.847\n",
      "Ep:159, loss:0.00000, loss_test:0.09940, lr:3.24e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.775, tt:6684.003\n",
      "Ep:160, loss:0.00000, loss_test:0.09895, lr:3.21e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.778, tt:6726.259\n",
      "Ep:161, loss:0.00000, loss_test:0.09951, lr:3.18e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.777, tt:6767.918\n",
      "Ep:162, loss:0.00000, loss_test:0.09898, lr:3.15e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.776, tt:6809.498\n",
      "Ep:163, loss:0.00000, loss_test:0.09997, lr:3.12e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.768, tt:6849.997\n",
      "Ep:164, loss:0.00000, loss_test:0.09914, lr:3.09e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.761, tt:6890.604\n",
      "Ep:165, loss:0.00000, loss_test:0.09887, lr:3.05e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.761, tt:6932.378\n",
      "Ep:166, loss:0.00000, loss_test:0.09945, lr:3.02e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.766, tt:6974.846\n",
      "Ep:167, loss:0.00000, loss_test:0.09906, lr:2.99e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.773, tt:7017.830\n",
      "Ep:168, loss:0.00000, loss_test:0.09900, lr:2.96e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.766, tt:7058.518\n",
      "Ep:169, loss:0.00000, loss_test:0.10022, lr:2.93e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.771, tt:7101.013\n",
      "Ep:170, loss:0.00000, loss_test:0.09946, lr:2.90e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.773, tt:7143.215\n",
      "Ep:171, loss:0.00000, loss_test:0.09965, lr:2.88e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.780, tt:7186.133\n",
      "Ep:172, loss:0.00000, loss_test:0.09995, lr:2.85e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.781, tt:7228.172\n",
      "Ep:173, loss:0.00000, loss_test:0.09920, lr:2.82e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.778, tt:7269.359\n",
      "Ep:174, loss:0.00000, loss_test:0.10007, lr:2.79e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.778, tt:7311.234\n",
      "Ep:175, loss:0.00000, loss_test:0.09986, lr:2.76e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.781, tt:7353.457\n",
      "Ep:176, loss:0.00000, loss_test:0.09922, lr:2.73e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.782, tt:7395.431\n",
      "Ep:177, loss:0.00000, loss_test:0.09982, lr:2.71e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.783, tt:7437.350\n",
      "Ep:178, loss:0.00000, loss_test:0.10044, lr:2.68e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.784, tt:7479.292\n",
      "Ep:179, loss:0.00000, loss_test:0.09959, lr:2.65e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.788, tt:7521.820\n",
      "Ep:180, loss:0.00000, loss_test:0.10013, lr:2.63e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.770, tt:7560.363\n",
      "Ep:181, loss:0.00000, loss_test:0.10053, lr:2.60e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.766, tt:7601.450\n",
      "Ep:182, loss:0.00000, loss_test:0.10045, lr:2.57e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.767, tt:7643.281\n",
      "Ep:183, loss:0.00000, loss_test:0.09966, lr:2.55e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.763, tt:7684.453\n",
      "Ep:184, loss:0.00000, loss_test:0.10013, lr:2.52e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.759, tt:7725.365\n",
      "Ep:185, loss:0.00000, loss_test:0.10038, lr:2.50e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.757, tt:7766.848\n",
      "Ep:186, loss:0.00000, loss_test:0.10029, lr:2.47e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.754, tt:7808.000\n",
      "Ep:187, loss:0.00000, loss_test:0.10035, lr:2.45e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.762, tt:7851.328\n",
      "Ep:188, loss:0.00000, loss_test:0.10097, lr:2.42e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.767, tt:7893.879\n",
      "Ep:189, loss:0.00000, loss_test:0.10028, lr:2.40e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.761, tt:7934.678\n",
      "Ep:190, loss:0.00000, loss_test:0.10013, lr:2.38e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.770, tt:7978.000\n",
      "Ep:191, loss:0.00000, loss_test:0.10217, lr:2.35e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.777, tt:8021.255\n",
      "Ep:192, loss:0.00000, loss_test:0.10174, lr:2.33e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.777, tt:8062.982\n",
      "Ep:193, loss:0.00000, loss_test:0.09966, lr:2.31e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.771, tt:8103.482\n",
      "Ep:194, loss:0.00000, loss_test:0.10088, lr:2.28e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.774, tt:8145.909\n",
      "Ep:195, loss:0.00000, loss_test:0.10125, lr:2.26e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.774, tt:8187.757\n",
      "Ep:196, loss:0.00000, loss_test:0.10051, lr:2.24e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.783, tt:8231.336\n",
      "Ep:197, loss:0.00000, loss_test:0.09993, lr:2.21e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.786, tt:8273.590\n",
      "Ep:198, loss:0.00000, loss_test:0.10108, lr:2.19e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.790, tt:8316.173\n",
      "Ep:199, loss:0.00000, loss_test:0.10124, lr:2.17e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.779, tt:8355.757\n",
      "Ep:200, loss:0.00000, loss_test:0.09988, lr:2.15e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.779, tt:8397.579\n",
      "Ep:201, loss:0.00000, loss_test:0.10099, lr:2.13e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.763, tt:8436.047\n",
      "Ep:202, loss:0.00000, loss_test:0.10190, lr:2.11e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.769, tt:8479.157\n",
      "Ep:203, loss:0.00000, loss_test:0.10115, lr:2.08e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.775, tt:8522.192\n",
      "Ep:204, loss:0.00000, loss_test:0.10052, lr:2.06e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.772, tt:8563.247\n",
      "Ep:205, loss:0.00000, loss_test:0.10145, lr:2.04e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.777, tt:8606.058\n",
      "Ep:206, loss:0.00000, loss_test:0.10248, lr:2.02e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.770, tt:8646.329\n",
      "Ep:207, loss:0.00000, loss_test:0.10166, lr:2.00e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.764, tt:8686.809\n",
      "Ep:208, loss:0.00000, loss_test:0.10075, lr:1.98e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.770, tt:8729.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.10070, lr:1.96e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.766, tt:8770.794\n",
      "Ep:210, loss:0.00000, loss_test:0.10089, lr:1.94e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.777, tt:8814.949\n",
      "Ep:211, loss:0.00000, loss_test:0.10115, lr:1.92e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.782, tt:8857.704\n",
      "Ep:212, loss:0.00000, loss_test:0.10074, lr:1.90e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.781, tt:8899.344\n",
      "Ep:213, loss:0.00000, loss_test:0.10050, lr:1.89e-03, fs:0.79730 (r=0.678,p=0.967),  time:41.769, tt:8938.620\n",
      "Ep:214, loss:0.00000, loss_test:0.10096, lr:1.87e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.743, tt:8974.788\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.01837, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:28.276, tt:28.276\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02025, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:30.372, tt:60.744\n",
      "Ep:2, loss:0.00004, loss_test:0.02091, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:33.942, tt:101.825\n",
      "Ep:3, loss:0.00004, loss_test:0.01999, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:35.084, tt:140.336\n",
      "Ep:4, loss:0.00004, loss_test:0.01833, lr:6.00e-02, fs:0.68990 (r=1.000,p=0.527),  time:36.492, tt:182.459\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01700, lr:6.00e-02, fs:0.71161 (r=0.960,p=0.565),  time:36.974, tt:221.843\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01671, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:37.622, tt:263.355\n",
      "Ep:7, loss:0.00004, loss_test:0.01660, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:37.928, tt:303.425\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:38.371, tt:345.341\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:38.664, tt:386.641\n",
      "Ep:10, loss:0.00003, loss_test:0.01578, lr:6.00e-02, fs:0.73962 (r=0.990,p=0.590),  time:38.919, tt:428.104\n",
      "Ep:11, loss:0.00003, loss_test:0.01546, lr:6.00e-02, fs:0.74809 (r=0.990,p=0.601),  time:38.919, tt:467.033\n",
      "Ep:12, loss:0.00003, loss_test:0.01507, lr:6.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:38.977, tt:506.707\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01485, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:39.080, tt:547.126\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01476, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:39.239, tt:588.590\n",
      "Ep:15, loss:0.00003, loss_test:0.01472, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:39.205, tt:627.284\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01473, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:39.219, tt:666.728\n",
      "Ep:17, loss:0.00003, loss_test:0.01473, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:39.298, tt:707.359\n",
      "Ep:18, loss:0.00003, loss_test:0.01467, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:39.306, tt:746.814\n",
      "Ep:19, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:39.349, tt:786.973\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:39.384, tt:827.072\n",
      "Ep:21, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:39.439, tt:867.660\n",
      "Ep:22, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:39.431, tt:906.903\n",
      "Ep:23, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:39.453, tt:946.878\n",
      "Ep:24, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:39.533, tt:988.332\n",
      "Ep:25, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:39.508, tt:1027.216\n",
      "Ep:26, loss:0.00002, loss_test:0.01470, lr:6.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:39.557, tt:1068.036\n",
      "Ep:27, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:39.549, tt:1107.372\n",
      "Ep:28, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:39.691, tt:1151.048\n",
      "Ep:29, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:39.715, tt:1191.443\n",
      "Ep:30, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:39.684, tt:1230.217\n",
      "Ep:31, loss:0.00002, loss_test:0.01454, lr:5.94e-02, fs:0.80383 (r=0.848,p=0.764),  time:39.748, tt:1271.951\n",
      "Ep:32, loss:0.00002, loss_test:0.01453, lr:5.88e-02, fs:0.81159 (r=0.848,p=0.778),  time:39.806, tt:1313.582\n",
      "Ep:33, loss:0.00002, loss_test:0.01453, lr:5.82e-02, fs:0.81553 (r=0.848,p=0.785),  time:39.859, tt:1355.216\n",
      "Ep:34, loss:0.00002, loss_test:0.01448, lr:5.76e-02, fs:0.81159 (r=0.848,p=0.778),  time:39.869, tt:1395.400\n",
      "Ep:35, loss:0.00002, loss_test:0.01449, lr:5.71e-02, fs:0.80583 (r=0.838,p=0.776),  time:39.896, tt:1436.267\n",
      "Ep:36, loss:0.00002, loss_test:0.01447, lr:5.65e-02, fs:0.80000 (r=0.828,p=0.774),  time:39.961, tt:1478.551\n",
      "Ep:37, loss:0.00002, loss_test:0.01448, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:39.972, tt:1518.932\n",
      "Ep:38, loss:0.00002, loss_test:0.01445, lr:5.54e-02, fs:0.80392 (r=0.828,p=0.781),  time:39.990, tt:1559.627\n",
      "Ep:39, loss:0.00002, loss_test:0.01444, lr:5.48e-02, fs:0.80392 (r=0.828,p=0.781),  time:40.001, tt:1600.022\n",
      "Ep:40, loss:0.00002, loss_test:0.01443, lr:5.43e-02, fs:0.80788 (r=0.828,p=0.788),  time:40.009, tt:1640.366\n",
      "Ep:41, loss:0.00001, loss_test:0.01440, lr:5.37e-02, fs:0.82587 (r=0.838,p=0.814),  time:40.045, tt:1681.909\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01434, lr:5.37e-02, fs:0.82178 (r=0.838,p=0.806),  time:40.081, tt:1723.501\n",
      "Ep:43, loss:0.00001, loss_test:0.01439, lr:5.37e-02, fs:0.83000 (r=0.838,p=0.822),  time:40.090, tt:1763.947\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01443, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:40.123, tt:1805.517\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01440, lr:5.37e-02, fs:0.83838 (r=0.838,p=0.838),  time:40.096, tt:1844.434\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01434, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:40.101, tt:1884.737\n",
      "Ep:47, loss:0.00001, loss_test:0.01432, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:40.126, tt:1926.032\n",
      "Ep:48, loss:0.00001, loss_test:0.01432, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:40.172, tt:1968.417\n",
      "Ep:49, loss:0.00001, loss_test:0.01437, lr:5.37e-02, fs:0.83838 (r=0.838,p=0.838),  time:40.224, tt:2011.212\n",
      "Ep:50, loss:0.00001, loss_test:0.01436, lr:5.37e-02, fs:0.83838 (r=0.838,p=0.838),  time:40.247, tt:2052.574\n",
      "Ep:51, loss:0.00001, loss_test:0.01431, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:40.289, tt:2095.035\n",
      "Ep:52, loss:0.00001, loss_test:0.01432, lr:5.37e-02, fs:0.83838 (r=0.838,p=0.838),  time:40.351, tt:2138.618\n",
      "Ep:53, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.83838 (r=0.838,p=0.838),  time:40.363, tt:2179.617\n",
      "Ep:54, loss:0.00001, loss_test:0.01426, lr:5.37e-02, fs:0.84422 (r=0.848,p=0.840),  time:40.373, tt:2220.535\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01434, lr:5.37e-02, fs:0.84264 (r=0.838,p=0.847),  time:40.406, tt:2262.750\n",
      "Ep:56, loss:0.00001, loss_test:0.01429, lr:5.37e-02, fs:0.84848 (r=0.848,p=0.848),  time:40.427, tt:2304.354\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.84848 (r=0.848,p=0.848),  time:40.477, tt:2347.660\n",
      "Ep:58, loss:0.00001, loss_test:0.01433, lr:5.37e-02, fs:0.84848 (r=0.848,p=0.848),  time:40.500, tt:2389.495\n",
      "Ep:59, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.505, tt:2430.299\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01431, lr:5.37e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.505, tt:2470.800\n",
      "Ep:61, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.505, tt:2511.339\n",
      "Ep:62, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.86294 (r=0.859,p=0.867),  time:40.522, tt:2552.910\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.85859 (r=0.859,p=0.859),  time:40.530, tt:2593.939\n",
      "Ep:64, loss:0.00001, loss_test:0.01441, lr:5.37e-02, fs:0.84974 (r=0.828,p=0.872),  time:40.529, tt:2634.387\n",
      "Ep:65, loss:0.00001, loss_test:0.01441, lr:5.37e-02, fs:0.84974 (r=0.828,p=0.872),  time:40.521, tt:2674.361\n",
      "Ep:66, loss:0.00001, loss_test:0.01441, lr:5.37e-02, fs:0.84974 (r=0.828,p=0.872),  time:40.547, tt:2716.632\n",
      "Ep:67, loss:0.00001, loss_test:0.01448, lr:5.37e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.522, tt:2755.469\n",
      "Ep:68, loss:0.00001, loss_test:0.01447, lr:5.37e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.538, tt:2797.100\n",
      "Ep:69, loss:0.00001, loss_test:0.01442, lr:5.37e-02, fs:0.84974 (r=0.828,p=0.872),  time:40.563, tt:2839.403\n",
      "Ep:70, loss:0.00001, loss_test:0.01447, lr:5.37e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.572, tt:2880.629\n",
      "Ep:71, loss:0.00001, loss_test:0.01451, lr:5.37e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.568, tt:2920.885\n",
      "Ep:72, loss:0.00001, loss_test:0.01453, lr:5.37e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.583, tt:2962.576\n",
      "Ep:73, loss:0.00001, loss_test:0.01456, lr:5.37e-02, fs:0.85864 (r=0.828,p=0.891),  time:40.597, tt:3004.179\n",
      "Ep:74, loss:0.00001, loss_test:0.01462, lr:5.32e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.672, tt:3050.391\n",
      "Ep:75, loss:0.00001, loss_test:0.01458, lr:5.27e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.688, tt:3092.319\n",
      "Ep:76, loss:0.00001, loss_test:0.01463, lr:5.21e-02, fs:0.85864 (r=0.828,p=0.891),  time:40.692, tt:3133.310\n",
      "Ep:77, loss:0.00001, loss_test:0.01462, lr:5.16e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.688, tt:3173.638\n",
      "Ep:78, loss:0.00001, loss_test:0.01457, lr:5.11e-02, fs:0.85864 (r=0.828,p=0.891),  time:40.672, tt:3213.063\n",
      "Ep:79, loss:0.00001, loss_test:0.01464, lr:5.06e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.659, tt:3252.709\n",
      "Ep:80, loss:0.00001, loss_test:0.01471, lr:5.01e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.668, tt:3294.136\n",
      "Ep:81, loss:0.00001, loss_test:0.01477, lr:4.96e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.691, tt:3336.622\n",
      "Ep:82, loss:0.00001, loss_test:0.01478, lr:4.91e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.666, tt:3375.297\n",
      "Ep:83, loss:0.00001, loss_test:0.01478, lr:4.86e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.661, tt:3415.544\n",
      "Ep:84, loss:0.00001, loss_test:0.01484, lr:4.81e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.663, tt:3456.365\n",
      "Ep:85, loss:0.00001, loss_test:0.01486, lr:4.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.680, tt:3498.473\n",
      "Ep:86, loss:0.00001, loss_test:0.01489, lr:4.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.671, tt:3538.349\n",
      "Ep:87, loss:0.00001, loss_test:0.01491, lr:4.67e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.750, tt:3586.000\n",
      "Ep:88, loss:0.00001, loss_test:0.01495, lr:4.62e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.766, tt:3628.188\n",
      "Ep:89, loss:0.00001, loss_test:0.01499, lr:4.57e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.766, tt:3668.939\n",
      "Ep:90, loss:0.00001, loss_test:0.01499, lr:4.53e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.761, tt:3709.210\n",
      "Ep:91, loss:0.00001, loss_test:0.01505, lr:4.48e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.750, tt:3749.031\n",
      "Ep:92, loss:0.00001, loss_test:0.01503, lr:4.44e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.752, tt:3789.943\n",
      "Ep:93, loss:0.00001, loss_test:0.01508, lr:4.39e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.747, tt:3830.210\n",
      "Ep:94, loss:0.00001, loss_test:0.01514, lr:4.35e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.751, tt:3871.331\n",
      "Ep:95, loss:0.00001, loss_test:0.01519, lr:4.31e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.736, tt:3910.659\n",
      "Ep:96, loss:0.00001, loss_test:0.01521, lr:4.26e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.737, tt:3951.492\n",
      "Ep:97, loss:0.00001, loss_test:0.01527, lr:4.22e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.735, tt:3992.003\n",
      "Ep:98, loss:0.00001, loss_test:0.01531, lr:4.18e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.721, tt:4031.406\n",
      "Ep:99, loss:0.00001, loss_test:0.01534, lr:4.14e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.725, tt:4072.509\n",
      "Ep:100, loss:0.00001, loss_test:0.01539, lr:4.10e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.741, tt:4114.880\n",
      "Ep:101, loss:0.00001, loss_test:0.01539, lr:4.05e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.726, tt:4154.077\n",
      "Ep:102, loss:0.00001, loss_test:0.01541, lr:4.01e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.728, tt:4195.004\n",
      "Ep:103, loss:0.00001, loss_test:0.01544, lr:3.97e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.734, tt:4236.288\n",
      "Ep:104, loss:0.00001, loss_test:0.01551, lr:3.93e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.729, tt:4276.578\n",
      "Ep:105, loss:0.00001, loss_test:0.01553, lr:3.89e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.720, tt:4316.282\n",
      "Ep:106, loss:0.00001, loss_test:0.01558, lr:3.86e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.724, tt:4357.498\n",
      "Ep:107, loss:0.00001, loss_test:0.01559, lr:3.82e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.726, tt:4398.394\n",
      "Ep:108, loss:0.00001, loss_test:0.01564, lr:3.78e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.787, tt:4445.818\n",
      "Ep:109, loss:0.00001, loss_test:0.01568, lr:3.74e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.798, tt:4487.754\n",
      "Ep:110, loss:0.00001, loss_test:0.01571, lr:3.70e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.801, tt:4528.948\n",
      "Ep:111, loss:0.00001, loss_test:0.01577, lr:3.67e-02, fs:0.82873 (r=0.758,p=0.915),  time:40.786, tt:4568.063\n",
      "Ep:112, loss:0.00001, loss_test:0.01574, lr:3.63e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.789, tt:4609.159\n",
      "Ep:113, loss:0.00001, loss_test:0.01579, lr:3.59e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.800, tt:4651.183\n",
      "Ep:114, loss:0.00001, loss_test:0.01585, lr:3.56e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.784, tt:4690.187\n",
      "Ep:115, loss:0.00001, loss_test:0.01587, lr:3.52e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.788, tt:4731.361\n",
      "Ep:116, loss:0.00000, loss_test:0.01588, lr:3.49e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.796, tt:4773.165\n",
      "Ep:117, loss:0.00000, loss_test:0.01590, lr:3.45e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.799, tt:4814.329\n",
      "Ep:118, loss:0.00000, loss_test:0.01596, lr:3.42e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.802, tt:4855.488\n",
      "Ep:119, loss:0.00000, loss_test:0.01596, lr:3.38e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.790, tt:4894.783\n",
      "Ep:120, loss:0.00000, loss_test:0.01600, lr:3.35e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.793, tt:4935.901\n",
      "Ep:121, loss:0.00000, loss_test:0.01602, lr:3.32e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.804, tt:4978.132\n",
      "Ep:122, loss:0.00000, loss_test:0.01603, lr:3.28e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.804, tt:5018.930\n",
      "Ep:123, loss:0.00000, loss_test:0.01606, lr:3.25e-02, fs:0.82418 (r=0.758,p=0.904),  time:40.810, tt:5060.474\n",
      "Ep:124, loss:0.00000, loss_test:0.01611, lr:3.22e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.814, tt:5101.702\n",
      "Ep:125, loss:0.00000, loss_test:0.01614, lr:3.19e-02, fs:0.81111 (r=0.737,p=0.901),  time:40.808, tt:5141.853\n",
      "Ep:126, loss:0.00000, loss_test:0.01614, lr:3.15e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.796, tt:5181.116\n",
      "Ep:127, loss:0.00000, loss_test:0.01618, lr:3.12e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.777, tt:5219.439\n",
      "Ep:128, loss:0.00000, loss_test:0.01619, lr:3.09e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.757, tt:5257.702\n",
      "Ep:129, loss:0.00000, loss_test:0.01621, lr:3.06e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.776, tt:5300.945\n",
      "Ep:130, loss:0.00000, loss_test:0.01629, lr:3.03e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.782, tt:5342.398\n",
      "Ep:131, loss:0.00000, loss_test:0.01627, lr:3.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.775, tt:5382.239\n",
      "Ep:132, loss:0.00000, loss_test:0.01633, lr:2.97e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.772, tt:5422.682\n",
      "Ep:133, loss:0.00000, loss_test:0.01631, lr:2.94e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.759, tt:5461.702\n",
      "Ep:134, loss:0.00000, loss_test:0.01638, lr:2.91e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.772, tt:5504.153\n",
      "Ep:135, loss:0.00000, loss_test:0.01642, lr:2.88e-02, fs:0.81356 (r=0.727,p=0.923),  time:40.770, tt:5544.688\n",
      "Ep:136, loss:0.00000, loss_test:0.01641, lr:2.85e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.775, tt:5586.168\n",
      "Ep:137, loss:0.00000, loss_test:0.01642, lr:2.82e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.786, tt:5628.443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.01646, lr:2.80e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.790, tt:5669.752\n",
      "Ep:139, loss:0.00000, loss_test:0.01646, lr:2.77e-02, fs:0.81356 (r=0.727,p=0.923),  time:40.788, tt:5710.383\n",
      "Ep:140, loss:0.00000, loss_test:0.01648, lr:2.74e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.777, tt:5749.496\n",
      "Ep:141, loss:0.00000, loss_test:0.01654, lr:2.71e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.762, tt:5788.159\n",
      "Ep:142, loss:0.00000, loss_test:0.01658, lr:2.69e-02, fs:0.81356 (r=0.727,p=0.923),  time:40.746, tt:5826.731\n",
      "Ep:143, loss:0.00000, loss_test:0.01657, lr:2.66e-02, fs:0.81356 (r=0.727,p=0.923),  time:40.732, tt:5865.415\n",
      "Ep:144, loss:0.00000, loss_test:0.01661, lr:2.63e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.744, tt:5907.911\n",
      "Ep:145, loss:0.00000, loss_test:0.01661, lr:2.61e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.738, tt:5947.684\n",
      "Ep:146, loss:0.00000, loss_test:0.01662, lr:2.58e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.733, tt:5987.803\n",
      "Ep:147, loss:0.00000, loss_test:0.01668, lr:2.55e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.721, tt:6026.729\n",
      "Ep:148, loss:0.00000, loss_test:0.01669, lr:2.53e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.714, tt:6066.376\n",
      "Ep:149, loss:0.00000, loss_test:0.01672, lr:2.50e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.705, tt:6105.679\n",
      "Ep:150, loss:0.00000, loss_test:0.01673, lr:2.48e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.694, tt:6144.805\n",
      "Ep:151, loss:0.00000, loss_test:0.01677, lr:2.45e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.683, tt:6183.847\n",
      "Ep:152, loss:0.00000, loss_test:0.01678, lr:2.43e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.675, tt:6223.343\n",
      "Ep:153, loss:0.00000, loss_test:0.01681, lr:2.40e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.647, tt:6259.577\n",
      "Ep:154, loss:0.00000, loss_test:0.01685, lr:2.38e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.634, tt:6298.239\n",
      "Ep:155, loss:0.00000, loss_test:0.01686, lr:2.36e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.631, tt:6338.416\n",
      "Ep:156, loss:0.00000, loss_test:0.01687, lr:2.33e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.620, tt:6377.283\n",
      "Ep:157, loss:0.00000, loss_test:0.01692, lr:2.31e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.613, tt:6416.822\n",
      "Ep:158, loss:0.00000, loss_test:0.01694, lr:2.29e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.620, tt:6458.653\n",
      "Ep:159, loss:0.00000, loss_test:0.01697, lr:2.26e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.622, tt:6499.583\n",
      "Ep:160, loss:0.00000, loss_test:0.01695, lr:2.24e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.619, tt:6539.589\n",
      "Ep:161, loss:0.00000, loss_test:0.01699, lr:2.22e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.609, tt:6578.691\n",
      "Ep:162, loss:0.00000, loss_test:0.01701, lr:2.20e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.605, tt:6618.692\n",
      "Ep:163, loss:0.00000, loss_test:0.01705, lr:2.17e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.605, tt:6659.165\n",
      "Ep:164, loss:0.00000, loss_test:0.01705, lr:2.15e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.605, tt:6699.768\n",
      "Ep:165, loss:0.00000, loss_test:0.01708, lr:2.13e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.602, tt:6739.955\n",
      "Ep:166, loss:0.00000, loss_test:0.01712, lr:2.11e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.596, tt:6779.603\n",
      "Ep:167, loss:0.00000, loss_test:0.01714, lr:2.09e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.593, tt:6819.627\n",
      "Ep:168, loss:0.00000, loss_test:0.01718, lr:2.07e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.585, tt:6858.838\n",
      "Ep:169, loss:0.00000, loss_test:0.01720, lr:2.05e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.583, tt:6899.088\n",
      "Ep:170, loss:0.00000, loss_test:0.01717, lr:2.03e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.579, tt:6938.932\n",
      "Ep:171, loss:0.00000, loss_test:0.01719, lr:2.01e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.575, tt:6978.920\n",
      "Ep:172, loss:0.00000, loss_test:0.01722, lr:1.99e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.573, tt:7019.128\n",
      "Ep:173, loss:0.00000, loss_test:0.01721, lr:1.97e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.573, tt:7059.734\n",
      "Ep:174, loss:0.00000, loss_test:0.01726, lr:1.95e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.572, tt:7100.129\n",
      "Ep:175, loss:0.00000, loss_test:0.01729, lr:1.93e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.571, tt:7140.536\n",
      "Ep:176, loss:0.00000, loss_test:0.01731, lr:1.91e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.573, tt:7181.386\n",
      "Ep:177, loss:0.00000, loss_test:0.01732, lr:1.89e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.573, tt:7221.934\n",
      "Ep:178, loss:0.00000, loss_test:0.01734, lr:1.87e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.558, tt:7259.954\n",
      "Ep:179, loss:0.00000, loss_test:0.01737, lr:1.85e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.601, tt:7308.182\n",
      "Ep:180, loss:0.00000, loss_test:0.01737, lr:1.83e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.596, tt:7347.852\n",
      "Ep:181, loss:0.00000, loss_test:0.01740, lr:1.81e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.588, tt:7386.959\n",
      "Ep:182, loss:0.00000, loss_test:0.01745, lr:1.80e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.581, tt:7426.392\n",
      "Ep:183, loss:0.00000, loss_test:0.01747, lr:1.78e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.576, tt:7465.927\n",
      "Ep:184, loss:0.00000, loss_test:0.01746, lr:1.76e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.570, tt:7505.413\n",
      "Ep:185, loss:0.00000, loss_test:0.01748, lr:1.74e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.568, tt:7545.687\n",
      "Ep:186, loss:0.00000, loss_test:0.01749, lr:1.73e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.571, tt:7586.810\n",
      "Ep:187, loss:0.00000, loss_test:0.01749, lr:1.71e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.569, tt:7626.878\n",
      "Ep:188, loss:0.00000, loss_test:0.01750, lr:1.69e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.573, tt:7668.315\n",
      "Ep:189, loss:0.00000, loss_test:0.01754, lr:1.67e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.575, tt:7709.263\n",
      "Ep:190, loss:0.00000, loss_test:0.01758, lr:1.66e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.572, tt:7749.324\n",
      "Ep:191, loss:0.00000, loss_test:0.01756, lr:1.64e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.557, tt:7786.896\n",
      "Ep:192, loss:0.00000, loss_test:0.01758, lr:1.62e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.557, tt:7827.475\n",
      "Ep:193, loss:0.00000, loss_test:0.01762, lr:1.61e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.550, tt:7866.767\n",
      "Ep:194, loss:0.00000, loss_test:0.01764, lr:1.59e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.550, tt:7907.231\n",
      "Ep:195, loss:0.00000, loss_test:0.01763, lr:1.58e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.555, tt:7948.775\n",
      "Ep:196, loss:0.00000, loss_test:0.01765, lr:1.56e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.554, tt:7989.041\n",
      "Ep:197, loss:0.00000, loss_test:0.01768, lr:1.54e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.549, tt:8028.794\n",
      "Ep:198, loss:0.00000, loss_test:0.01768, lr:1.53e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.546, tt:8068.728\n",
      "Ep:199, loss:0.00000, loss_test:0.01769, lr:1.51e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.553, tt:8110.546\n",
      "Ep:200, loss:0.00000, loss_test:0.01773, lr:1.50e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.555, tt:8151.529\n",
      "Ep:201, loss:0.00000, loss_test:0.01776, lr:1.48e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.552, tt:8191.575\n",
      "Ep:202, loss:0.00000, loss_test:0.01774, lr:1.47e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.537, tt:8229.021\n",
      "Ep:203, loss:0.00000, loss_test:0.01776, lr:1.45e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.532, tt:8268.623\n",
      "Ep:204, loss:0.00000, loss_test:0.01778, lr:1.44e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.535, tt:8309.762\n",
      "Ep:205, loss:0.00000, loss_test:0.01781, lr:1.43e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.535, tt:8350.189\n",
      "Ep:206, loss:0.00000, loss_test:0.01781, lr:1.41e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.538, tt:8391.272\n",
      "Ep:207, loss:0.00000, loss_test:0.01782, lr:1.40e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.535, tt:8431.380\n",
      "Ep:208, loss:0.00000, loss_test:0.01785, lr:1.38e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.538, tt:8472.363\n",
      "Ep:209, loss:0.00000, loss_test:0.01786, lr:1.37e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.542, tt:8513.831\n",
      "Ep:210, loss:0.00000, loss_test:0.01787, lr:1.36e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.525, tt:8550.878\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13806, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.298, tt:34.298\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13576, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.325, tt:64.650\n",
      "Ep:2, loss:0.00027, loss_test:0.13158, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:34.640, tt:103.921\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12458, lr:1.00e-02, fs:0.68070 (r=0.980,p=0.522),  time:36.547, tt:146.190\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11405, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:37.394, tt:186.969\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10447, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:37.836, tt:227.013\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.09964, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:38.240, tt:267.677\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.09657, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:38.753, tt:310.027\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.09497, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:38.991, tt:350.920\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09263, lr:1.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:39.349, tt:393.494\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.08970, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:39.515, tt:434.663\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.08770, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:39.682, tt:476.180\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.08673, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:39.704, tt:516.154\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.08596, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:39.699, tt:555.786\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.08560, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:39.665, tt:594.979\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08444, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:39.708, tt:635.323\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08355, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:39.730, tt:675.407\n",
      "Ep:17, loss:0.00016, loss_test:0.08318, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:39.696, tt:714.530\n",
      "Ep:18, loss:0.00015, loss_test:0.08198, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:39.830, tt:756.761\n",
      "Ep:19, loss:0.00015, loss_test:0.08124, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:39.960, tt:799.208\n",
      "Ep:20, loss:0.00014, loss_test:0.07941, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:39.945, tt:838.851\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07804, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:39.883, tt:877.433\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.07746, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:39.853, tt:916.622\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.07682, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:39.890, tt:957.368\n",
      "Ep:24, loss:0.00013, loss_test:0.07561, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:39.848, tt:996.194\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.07452, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:39.887, tt:1037.057\n",
      "Ep:26, loss:0.00012, loss_test:0.07506, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:39.892, tt:1077.080\n",
      "Ep:27, loss:0.00011, loss_test:0.07291, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:39.930, tt:1118.032\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.07218, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:39.977, tt:1159.322\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.07090, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.018, tt:1200.526\n",
      "Ep:30, loss:0.00010, loss_test:0.07150, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:40.146, tt:1244.514\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.06901, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:40.158, tt:1285.063\n",
      "Ep:32, loss:0.00010, loss_test:0.06914, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.243, tt:1328.024\n",
      "Ep:33, loss:0.00009, loss_test:0.06902, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.283, tt:1369.608\n",
      "Ep:34, loss:0.00009, loss_test:0.06845, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:40.301, tt:1410.523\n",
      "Ep:35, loss:0.00009, loss_test:0.06946, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:40.292, tt:1450.520\n",
      "Ep:36, loss:0.00008, loss_test:0.06673, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:40.330, tt:1492.214\n",
      "Ep:37, loss:0.00008, loss_test:0.06626, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:40.307, tt:1531.664\n",
      "Ep:38, loss:0.00008, loss_test:0.06467, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:40.294, tt:1571.480\n",
      "Ep:39, loss:0.00007, loss_test:0.06829, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.290, tt:1611.619\n",
      "Ep:40, loss:0.00007, loss_test:0.06295, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:40.283, tt:1651.622\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.06672, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.345, tt:1694.502\n",
      "Ep:42, loss:0.00007, loss_test:0.06254, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:40.369, tt:1735.885\n",
      "Ep:43, loss:0.00006, loss_test:0.06468, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:40.422, tt:1778.588\n",
      "Ep:44, loss:0.00006, loss_test:0.06646, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:40.405, tt:1818.236\n",
      "Ep:45, loss:0.00006, loss_test:0.06132, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:40.401, tt:1858.454\n",
      "Ep:46, loss:0.00006, loss_test:0.06244, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:40.422, tt:1899.810\n",
      "Ep:47, loss:0.00006, loss_test:0.06248, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:40.398, tt:1939.085\n",
      "Ep:48, loss:0.00005, loss_test:0.06056, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:40.421, tt:1980.644\n",
      "Ep:49, loss:0.00005, loss_test:0.07288, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:40.406, tt:2020.283\n",
      "Ep:50, loss:0.00007, loss_test:0.05912, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:40.437, tt:2062.311\n",
      "Ep:51, loss:0.00006, loss_test:0.07167, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:40.426, tt:2102.150\n",
      "Ep:52, loss:0.00006, loss_test:0.06101, lr:9.90e-03, fs:0.89109 (r=0.909,p=0.874),  time:40.412, tt:2141.861\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06697, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:40.426, tt:2183.007\n",
      "Ep:54, loss:0.00006, loss_test:0.06198, lr:9.90e-03, fs:0.89340 (r=0.889,p=0.898),  time:40.457, tt:2225.138\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.06400, lr:9.90e-03, fs:0.86339 (r=0.798,p=0.940),  time:40.481, tt:2266.943\n",
      "Ep:56, loss:0.00005, loss_test:0.05917, lr:9.90e-03, fs:0.86170 (r=0.818,p=0.910),  time:40.561, tt:2312.001\n",
      "Ep:57, loss:0.00005, loss_test:0.06008, lr:9.90e-03, fs:0.86486 (r=0.808,p=0.930),  time:40.577, tt:2353.490\n",
      "Ep:58, loss:0.00005, loss_test:0.06026, lr:9.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:40.578, tt:2394.109\n",
      "Ep:59, loss:0.00004, loss_test:0.06055, lr:9.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:40.552, tt:2433.149\n",
      "Ep:60, loss:0.00004, loss_test:0.05770, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.554, tt:2473.822\n",
      "Ep:61, loss:0.00004, loss_test:0.05953, lr:9.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:40.571, tt:2515.402\n",
      "Ep:62, loss:0.00004, loss_test:0.05964, lr:9.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:40.568, tt:2555.801\n",
      "Ep:63, loss:0.00003, loss_test:0.05715, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.579, tt:2597.060\n",
      "Ep:64, loss:0.00003, loss_test:0.06025, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.593, tt:2638.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00003, loss_test:0.05771, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:40.590, tt:2678.926\n",
      "Ep:66, loss:0.00003, loss_test:0.06027, lr:9.80e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.628, tt:2722.096\n",
      "Ep:67, loss:0.00003, loss_test:0.05617, lr:9.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:40.640, tt:2763.519\n",
      "Ep:68, loss:0.00003, loss_test:0.05756, lr:9.61e-03, fs:0.87568 (r=0.818,p=0.942),  time:40.652, tt:2804.992\n",
      "Ep:69, loss:0.00003, loss_test:0.05994, lr:9.51e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.639, tt:2844.713\n",
      "Ep:70, loss:0.00003, loss_test:0.05847, lr:9.41e-03, fs:0.88043 (r=0.818,p=0.953),  time:40.636, tt:2885.134\n",
      "Ep:71, loss:0.00003, loss_test:0.05724, lr:9.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:40.666, tt:2927.966\n",
      "Ep:72, loss:0.00003, loss_test:0.05760, lr:9.23e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.686, tt:2970.050\n",
      "Ep:73, loss:0.00003, loss_test:0.05719, lr:9.14e-03, fs:0.88043 (r=0.818,p=0.953),  time:40.707, tt:3012.349\n",
      "Ep:74, loss:0.00002, loss_test:0.05733, lr:9.04e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.721, tt:3054.055\n",
      "Ep:75, loss:0.00002, loss_test:0.05774, lr:8.95e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.722, tt:3094.891\n",
      "Ep:76, loss:0.00002, loss_test:0.05644, lr:8.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.719, tt:3135.331\n",
      "Ep:77, loss:0.00002, loss_test:0.05771, lr:8.78e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.743, tt:3177.931\n",
      "Ep:78, loss:0.00002, loss_test:0.05932, lr:8.69e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.770, tt:3220.793\n",
      "Ep:79, loss:0.00002, loss_test:0.05674, lr:8.60e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.792, tt:3263.348\n",
      "Ep:80, loss:0.00002, loss_test:0.05975, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.810, tt:3305.642\n",
      "Ep:81, loss:0.00002, loss_test:0.05878, lr:8.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.821, tt:3347.289\n",
      "Ep:82, loss:0.00002, loss_test:0.05877, lr:8.35e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.816, tt:3387.704\n",
      "Ep:83, loss:0.00002, loss_test:0.06035, lr:8.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.820, tt:3428.879\n",
      "Ep:84, loss:0.00002, loss_test:0.05752, lr:8.18e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.806, tt:3468.530\n",
      "Ep:85, loss:0.00002, loss_test:0.05736, lr:8.10e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.818, tt:3510.341\n",
      "Ep:86, loss:0.00002, loss_test:0.05966, lr:8.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.807, tt:3550.201\n",
      "Ep:87, loss:0.00002, loss_test:0.05822, lr:7.94e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.820, tt:3592.188\n",
      "Ep:88, loss:0.00002, loss_test:0.05744, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.861, tt:3636.622\n",
      "Ep:89, loss:0.00002, loss_test:0.05912, lr:7.78e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.860, tt:3677.368\n",
      "Ep:90, loss:0.00002, loss_test:0.05637, lr:7.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.871, tt:3719.238\n",
      "Ep:91, loss:0.00002, loss_test:0.06020, lr:7.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.882, tt:3761.161\n",
      "Ep:92, loss:0.00002, loss_test:0.05672, lr:7.55e-03, fs:0.88525 (r=0.818,p=0.964),  time:40.916, tt:3805.179\n",
      "Ep:93, loss:0.00001, loss_test:0.05833, lr:7.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.931, tt:3847.555\n",
      "Ep:94, loss:0.00001, loss_test:0.05784, lr:7.40e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.946, tt:3889.849\n",
      "Ep:95, loss:0.00001, loss_test:0.05742, lr:7.32e-03, fs:0.89011 (r=0.818,p=0.976),  time:40.999, tt:3935.905\n",
      "Ep:96, loss:0.00001, loss_test:0.05646, lr:7.25e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.007, tt:3977.643\n",
      "Ep:97, loss:0.00001, loss_test:0.05830, lr:7.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.026, tt:4020.559\n",
      "Ep:98, loss:0.00001, loss_test:0.05776, lr:7.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.060, tt:4064.951\n",
      "Ep:99, loss:0.00001, loss_test:0.05790, lr:7.03e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.082, tt:4108.166\n",
      "Ep:100, loss:0.00001, loss_test:0.05660, lr:6.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.076, tt:4148.679\n",
      "Ep:101, loss:0.00001, loss_test:0.05759, lr:6.89e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.084, tt:4190.562\n",
      "Ep:102, loss:0.00001, loss_test:0.05725, lr:6.83e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.110, tt:4234.290\n",
      "Ep:103, loss:0.00001, loss_test:0.05851, lr:6.76e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.119, tt:4276.339\n",
      "Ep:104, loss:0.00001, loss_test:0.05712, lr:6.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.115, tt:4317.118\n",
      "Ep:105, loss:0.00001, loss_test:0.05750, lr:6.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.132, tt:4360.025\n",
      "Ep:106, loss:0.00001, loss_test:0.05776, lr:6.56e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.151, tt:4403.169\n",
      "Ep:107, loss:0.00001, loss_test:0.05746, lr:6.49e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.165, tt:4445.857\n",
      "Ep:108, loss:0.00001, loss_test:0.05767, lr:6.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.163, tt:4486.743\n",
      "Ep:109, loss:0.00001, loss_test:0.05819, lr:6.36e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.164, tt:4528.011\n",
      "Ep:110, loss:0.00001, loss_test:0.05747, lr:6.30e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.161, tt:4568.829\n",
      "Ep:111, loss:0.00001, loss_test:0.05910, lr:6.24e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.182, tt:4612.348\n",
      "Ep:112, loss:0.00001, loss_test:0.05951, lr:6.17e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.197, tt:4655.238\n",
      "Ep:113, loss:0.00001, loss_test:0.05745, lr:6.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.206, tt:4697.504\n",
      "Ep:114, loss:0.00001, loss_test:0.05819, lr:6.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.199, tt:4737.935\n",
      "Ep:115, loss:0.00001, loss_test:0.05989, lr:5.99e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.203, tt:4779.550\n",
      "Ep:116, loss:0.00001, loss_test:0.05854, lr:5.93e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.204, tt:4820.925\n",
      "Ep:117, loss:0.00001, loss_test:0.05867, lr:5.87e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.223, tt:4864.276\n",
      "Ep:118, loss:0.00001, loss_test:0.05893, lr:5.81e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.225, tt:4905.763\n",
      "Ep:119, loss:0.00001, loss_test:0.06005, lr:5.75e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.233, tt:4948.003\n",
      "Ep:120, loss:0.00001, loss_test:0.05852, lr:5.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.240, tt:4990.098\n",
      "Ep:121, loss:0.00001, loss_test:0.06014, lr:5.64e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.238, tt:5031.028\n",
      "Ep:122, loss:0.00001, loss_test:0.05917, lr:5.58e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.251, tt:5073.923\n",
      "Ep:123, loss:0.00001, loss_test:0.05871, lr:5.53e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.258, tt:5116.001\n",
      "Ep:124, loss:0.00001, loss_test:0.05924, lr:5.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.261, tt:5157.672\n",
      "Ep:125, loss:0.00001, loss_test:0.05889, lr:5.42e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.270, tt:5200.035\n",
      "Ep:126, loss:0.00001, loss_test:0.05919, lr:5.36e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.279, tt:5242.449\n",
      "Ep:127, loss:0.00001, loss_test:0.05860, lr:5.31e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.286, tt:5284.612\n",
      "Ep:128, loss:0.00001, loss_test:0.05939, lr:5.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.293, tt:5326.768\n",
      "Ep:129, loss:0.00001, loss_test:0.05902, lr:5.20e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.306, tt:5369.785\n",
      "Ep:130, loss:0.00001, loss_test:0.05954, lr:5.15e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.322, tt:5413.171\n",
      "Ep:131, loss:0.00001, loss_test:0.05914, lr:5.10e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.322, tt:5454.478\n",
      "Ep:132, loss:0.00001, loss_test:0.05929, lr:5.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.345, tt:5498.893\n",
      "Ep:133, loss:0.00001, loss_test:0.05934, lr:5.00e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.340, tt:5539.567\n",
      "Ep:134, loss:0.00001, loss_test:0.05927, lr:4.95e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.348, tt:5582.046\n",
      "Ep:135, loss:0.00001, loss_test:0.05934, lr:4.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.363, tt:5625.385\n",
      "Ep:136, loss:0.00001, loss_test:0.05962, lr:4.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.374, tt:5668.224\n",
      "Ep:137, loss:0.00001, loss_test:0.05972, lr:4.80e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.383, tt:5710.821\n",
      "Ep:138, loss:0.00001, loss_test:0.05957, lr:4.75e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.385, tt:5752.524\n",
      "Ep:139, loss:0.00001, loss_test:0.05994, lr:4.71e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.385, tt:5793.948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.06003, lr:4.66e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.389, tt:5835.851\n",
      "Ep:141, loss:0.00001, loss_test:0.05968, lr:4.61e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.410, tt:5880.242\n",
      "Ep:142, loss:0.00001, loss_test:0.05950, lr:4.57e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.433, tt:5924.878\n",
      "Ep:143, loss:0.00001, loss_test:0.05987, lr:4.52e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.437, tt:5966.870\n",
      "Ep:144, loss:0.00001, loss_test:0.06037, lr:4.48e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.449, tt:6010.160\n",
      "Ep:145, loss:0.00001, loss_test:0.05991, lr:4.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.452, tt:6052.002\n",
      "Ep:146, loss:0.00001, loss_test:0.05997, lr:4.39e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.455, tt:6093.949\n",
      "Ep:147, loss:0.00001, loss_test:0.05970, lr:4.34e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.463, tt:6136.575\n",
      "Ep:148, loss:0.00001, loss_test:0.06014, lr:4.30e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.468, tt:6178.666\n",
      "Ep:149, loss:0.00001, loss_test:0.05965, lr:4.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.444, tt:6216.601\n",
      "Ep:150, loss:0.00001, loss_test:0.06016, lr:4.21e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.454, tt:6259.600\n",
      "Ep:151, loss:0.00001, loss_test:0.06052, lr:4.17e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.471, tt:6303.583\n",
      "Ep:152, loss:0.00001, loss_test:0.05965, lr:4.13e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.476, tt:6345.755\n",
      "Ep:153, loss:0.00001, loss_test:0.06006, lr:4.09e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.471, tt:6386.599\n",
      "Ep:154, loss:0.00001, loss_test:0.06048, lr:4.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.472, tt:6428.209\n",
      "Ep:155, loss:0.00001, loss_test:0.06060, lr:4.01e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.464, tt:6468.360\n",
      "Ep:156, loss:0.00001, loss_test:0.06029, lr:3.97e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.474, tt:6511.494\n",
      "Ep:157, loss:0.00001, loss_test:0.06047, lr:3.93e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.479, tt:6553.661\n",
      "Ep:158, loss:0.00001, loss_test:0.06094, lr:3.89e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.490, tt:6596.933\n",
      "Ep:159, loss:0.00001, loss_test:0.06038, lr:3.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.505, tt:6640.857\n",
      "Ep:160, loss:0.00001, loss_test:0.06050, lr:3.81e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.519, tt:6684.528\n",
      "Ep:161, loss:0.00001, loss_test:0.06037, lr:3.77e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.532, tt:6728.206\n",
      "Ep:162, loss:0.00001, loss_test:0.06038, lr:3.73e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.545, tt:6771.817\n",
      "Ep:163, loss:0.00001, loss_test:0.06101, lr:3.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.551, tt:6814.357\n",
      "Ep:164, loss:0.00001, loss_test:0.06092, lr:3.66e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.566, tt:6858.417\n",
      "Ep:165, loss:0.00001, loss_test:0.06025, lr:3.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.575, tt:6901.484\n",
      "Ep:166, loss:0.00001, loss_test:0.06046, lr:3.59e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.615, tt:6949.719\n",
      "Ep:167, loss:0.00001, loss_test:0.06078, lr:3.55e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.619, tt:6992.004\n",
      "Ep:168, loss:0.00001, loss_test:0.06075, lr:3.52e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.622, tt:7034.090\n",
      "Ep:169, loss:0.00001, loss_test:0.06095, lr:3.48e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.631, tt:7077.310\n",
      "Ep:170, loss:0.00001, loss_test:0.06062, lr:3.45e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.635, tt:7119.663\n",
      "Ep:171, loss:0.00001, loss_test:0.06084, lr:3.41e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.654, tt:7164.495\n",
      "Ep:172, loss:0.00001, loss_test:0.06131, lr:3.38e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.658, tt:7206.824\n",
      "Ep:173, loss:0.00001, loss_test:0.06086, lr:3.34e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.664, tt:7249.508\n",
      "Ep:174, loss:0.00001, loss_test:0.06063, lr:3.31e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.675, tt:7293.056\n",
      "Ep:175, loss:0.00001, loss_test:0.06104, lr:3.28e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.687, tt:7336.851\n",
      "Ep:176, loss:0.00001, loss_test:0.06097, lr:3.24e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.700, tt:7380.834\n",
      "Ep:177, loss:0.00001, loss_test:0.06117, lr:3.21e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.719, tt:7425.911\n",
      "Ep:178, loss:0.00001, loss_test:0.06108, lr:3.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.730, tt:7469.598\n",
      "Ep:179, loss:0.00001, loss_test:0.06088, lr:3.15e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.724, tt:7510.298\n",
      "Ep:180, loss:0.00000, loss_test:0.06126, lr:3.12e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.738, tt:7554.629\n",
      "Ep:181, loss:0.00000, loss_test:0.06112, lr:3.09e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.747, tt:7597.952\n",
      "Ep:182, loss:0.00000, loss_test:0.06128, lr:3.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.765, tt:7642.971\n",
      "Ep:183, loss:0.00000, loss_test:0.06167, lr:3.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.777, tt:7686.998\n",
      "Ep:184, loss:0.00000, loss_test:0.06130, lr:2.99e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.790, tt:7731.165\n",
      "Ep:185, loss:0.00000, loss_test:0.06145, lr:2.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.795, tt:7773.951\n",
      "Ep:186, loss:0.00000, loss_test:0.06147, lr:2.93e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.819, tt:7820.066\n",
      "Ep:187, loss:0.00000, loss_test:0.06122, lr:2.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.827, tt:7863.433\n",
      "Ep:188, loss:0.00000, loss_test:0.06160, lr:2.88e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.847, tt:7909.000\n",
      "Ep:189, loss:0.00000, loss_test:0.06135, lr:2.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.868, tt:7954.829\n",
      "Ep:190, loss:0.00000, loss_test:0.06144, lr:2.82e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.878, tt:7998.659\n",
      "Ep:191, loss:0.00000, loss_test:0.06152, lr:2.79e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.888, tt:8042.541\n",
      "Ep:192, loss:0.00000, loss_test:0.06174, lr:2.76e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.895, tt:8085.691\n",
      "Ep:193, loss:0.00000, loss_test:0.06162, lr:2.73e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.908, tt:8130.099\n",
      "Ep:194, loss:0.00000, loss_test:0.06146, lr:2.71e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.920, tt:8174.498\n",
      "Ep:195, loss:0.00000, loss_test:0.06163, lr:2.68e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.938, tt:8219.750\n",
      "Ep:196, loss:0.00000, loss_test:0.06191, lr:2.65e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.940, tt:8262.176\n",
      "Ep:197, loss:0.00000, loss_test:0.06158, lr:2.63e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.949, tt:8305.986\n",
      "Ep:198, loss:0.00000, loss_test:0.06151, lr:2.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.985, tt:8355.027\n",
      "Ep:199, loss:0.00000, loss_test:0.06185, lr:2.57e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.995, tt:8399.072\n",
      "Ep:200, loss:0.00000, loss_test:0.06201, lr:2.55e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.015, tt:8445.040\n",
      "Ep:201, loss:0.00000, loss_test:0.06185, lr:2.52e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.018, tt:8487.636\n",
      "Ep:202, loss:0.00000, loss_test:0.06164, lr:2.50e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.029, tt:8531.807\n",
      "Ep:203, loss:0.00000, loss_test:0.06191, lr:2.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.040, tt:8576.117\n",
      "Ep:204, loss:0.00000, loss_test:0.06180, lr:2.45e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.053, tt:8620.836\n",
      "Ep:205, loss:0.00000, loss_test:0.06207, lr:2.42e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.067, tt:8665.731\n",
      "Ep:206, loss:0.00000, loss_test:0.06257, lr:2.40e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.075, tt:8709.578\n",
      "Ep:207, loss:0.00000, loss_test:0.06207, lr:2.38e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.093, tt:8755.404\n",
      "Ep:208, loss:0.00000, loss_test:0.06190, lr:2.35e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.103, tt:8799.558\n",
      "Ep:209, loss:0.00000, loss_test:0.06222, lr:2.33e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.115, tt:8844.077\n",
      "Ep:210, loss:0.00000, loss_test:0.06220, lr:2.31e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.095, tt:8881.996\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01928, lr:6.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:30.033, tt:30.033\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02298, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.236, tt:54.472\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02434, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.090, tt:87.269\n",
      "Ep:3, loss:0.00005, loss_test:0.02380, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.634, tt:126.537\n",
      "Ep:4, loss:0.00005, loss_test:0.02226, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.414, tt:172.068\n",
      "Ep:5, loss:0.00004, loss_test:0.02030, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:35.845, tt:215.072\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01854, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:37.175, tt:260.224\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01763, lr:6.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:38.217, tt:305.737\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01730, lr:6.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:38.609, tt:347.484\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01684, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:38.997, tt:389.967\n",
      "Ep:10, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:39.217, tt:431.382\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:39.635, tt:475.621\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:39.873, tt:518.349\n",
      "Ep:13, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.74131 (r=0.970,p=0.600),  time:40.144, tt:562.009\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:40.670, tt:610.053\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:40.760, tt:652.156\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:40.837, tt:694.222\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:40.904, tt:736.270\n",
      "Ep:18, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:40.998, tt:778.956\n",
      "Ep:19, loss:0.00003, loss_test:0.01576, lr:6.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:41.016, tt:820.327\n",
      "Ep:20, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:41.051, tt:862.065\n",
      "Ep:21, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.76596 (r=0.909,p=0.662),  time:41.122, tt:904.684\n",
      "Ep:22, loss:0.00002, loss_test:0.01581, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:41.211, tt:947.848\n",
      "Ep:23, loss:0.00002, loss_test:0.01584, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:41.317, tt:991.599\n",
      "Ep:24, loss:0.00002, loss_test:0.01586, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:41.339, tt:1033.464\n",
      "Ep:25, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:41.361, tt:1075.390\n",
      "Ep:26, loss:0.00002, loss_test:0.01580, lr:6.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:41.414, tt:1118.174\n",
      "Ep:27, loss:0.00002, loss_test:0.01574, lr:6.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:41.475, tt:1161.312\n",
      "Ep:28, loss:0.00002, loss_test:0.01570, lr:5.94e-02, fs:0.76444 (r=0.869,p=0.683),  time:41.498, tt:1203.445\n",
      "Ep:29, loss:0.00002, loss_test:0.01564, lr:5.88e-02, fs:0.76577 (r=0.859,p=0.691),  time:41.569, tt:1247.077\n",
      "Ep:30, loss:0.00002, loss_test:0.01563, lr:5.82e-02, fs:0.76923 (r=0.859,p=0.697),  time:41.539, tt:1287.709\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01560, lr:5.82e-02, fs:0.77273 (r=0.859,p=0.702),  time:41.527, tt:1328.852\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01555, lr:5.82e-02, fs:0.77828 (r=0.869,p=0.705),  time:41.601, tt:1372.844\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01553, lr:5.82e-02, fs:0.77828 (r=0.869,p=0.705),  time:41.609, tt:1414.702\n",
      "Ep:34, loss:0.00002, loss_test:0.01553, lr:5.82e-02, fs:0.77982 (r=0.859,p=0.714),  time:41.641, tt:1457.437\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01551, lr:5.82e-02, fs:0.78341 (r=0.859,p=0.720),  time:41.743, tt:1502.752\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01549, lr:5.82e-02, fs:0.77778 (r=0.848,p=0.718),  time:41.805, tt:1546.769\n",
      "Ep:37, loss:0.00002, loss_test:0.01551, lr:5.82e-02, fs:0.78140 (r=0.848,p=0.724),  time:41.839, tt:1589.876\n",
      "Ep:38, loss:0.00002, loss_test:0.01551, lr:5.82e-02, fs:0.77570 (r=0.838,p=0.722),  time:41.854, tt:1632.318\n",
      "Ep:39, loss:0.00002, loss_test:0.01547, lr:5.82e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.862, tt:1674.497\n",
      "Ep:40, loss:0.00002, loss_test:0.01540, lr:5.82e-02, fs:0.77358 (r=0.828,p=0.726),  time:41.923, tt:1718.834\n",
      "Ep:41, loss:0.00002, loss_test:0.01533, lr:5.82e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.916, tt:1760.480\n",
      "Ep:42, loss:0.00002, loss_test:0.01533, lr:5.82e-02, fs:0.78673 (r=0.838,p=0.741),  time:41.927, tt:1802.867\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01530, lr:5.82e-02, fs:0.79048 (r=0.838,p=0.748),  time:41.948, tt:1845.729\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01529, lr:5.82e-02, fs:0.79048 (r=0.838,p=0.748),  time:41.993, tt:1889.663\n",
      "Ep:45, loss:0.00001, loss_test:0.01533, lr:5.82e-02, fs:0.79426 (r=0.838,p=0.755),  time:41.989, tt:1931.507\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01532, lr:5.82e-02, fs:0.79808 (r=0.838,p=0.761),  time:42.009, tt:1974.417\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01527, lr:5.82e-02, fs:0.79808 (r=0.838,p=0.761),  time:42.010, tt:2016.462\n",
      "Ep:48, loss:0.00001, loss_test:0.01527, lr:5.82e-02, fs:0.80193 (r=0.838,p=0.769),  time:42.023, tt:2059.150\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01524, lr:5.82e-02, fs:0.80583 (r=0.838,p=0.776),  time:42.018, tt:2100.888\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01525, lr:5.82e-02, fs:0.80976 (r=0.838,p=0.783),  time:41.970, tt:2140.493\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01530, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:41.982, tt:2183.076\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01529, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:41.989, tt:2225.422\n",
      "Ep:53, loss:0.00001, loss_test:0.01530, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:42.001, tt:2268.051\n",
      "Ep:54, loss:0.00001, loss_test:0.01529, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:41.961, tt:2307.848\n",
      "Ep:55, loss:0.00001, loss_test:0.01530, lr:5.82e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.986, tt:2351.234\n",
      "Ep:56, loss:0.00001, loss_test:0.01536, lr:5.82e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.961, tt:2391.758\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01536, lr:5.82e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.948, tt:2432.970\n",
      "Ep:58, loss:0.00001, loss_test:0.01535, lr:5.82e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.954, tt:2475.281\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01537, lr:5.82e-02, fs:0.83249 (r=0.828,p=0.837),  time:41.921, tt:2515.237\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01530, lr:5.82e-02, fs:0.82653 (r=0.818,p=0.835),  time:41.899, tt:2555.817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01531, lr:5.82e-02, fs:0.82412 (r=0.828,p=0.820),  time:41.894, tt:2597.455\n",
      "Ep:62, loss:0.00001, loss_test:0.01538, lr:5.82e-02, fs:0.81818 (r=0.818,p=0.818),  time:41.899, tt:2639.650\n",
      "Ep:63, loss:0.00001, loss_test:0.01533, lr:5.82e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.913, tt:2682.461\n",
      "Ep:64, loss:0.00001, loss_test:0.01528, lr:5.82e-02, fs:0.83000 (r=0.838,p=0.822),  time:41.889, tt:2722.778\n",
      "Ep:65, loss:0.00001, loss_test:0.01532, lr:5.82e-02, fs:0.83000 (r=0.838,p=0.822),  time:41.907, tt:2765.887\n",
      "Ep:66, loss:0.00001, loss_test:0.01540, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:41.913, tt:2808.198\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01541, lr:5.82e-02, fs:0.83417 (r=0.838,p=0.830),  time:41.916, tt:2850.307\n",
      "Ep:68, loss:0.00001, loss_test:0.01543, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:41.900, tt:2891.072\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01544, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:41.888, tt:2932.192\n",
      "Ep:70, loss:0.00001, loss_test:0.01547, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:41.902, tt:2975.019\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01547, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.868, tt:3014.509\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01549, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.871, tt:3056.600\n",
      "Ep:73, loss:0.00001, loss_test:0.01552, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.856, tt:3097.367\n",
      "Ep:74, loss:0.00001, loss_test:0.01551, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.845, tt:3138.401\n",
      "Ep:75, loss:0.00001, loss_test:0.01557, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.838, tt:3179.668\n",
      "Ep:76, loss:0.00001, loss_test:0.01565, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.841, tt:3221.735\n",
      "Ep:77, loss:0.00001, loss_test:0.01564, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.824, tt:3262.293\n",
      "Ep:78, loss:0.00001, loss_test:0.01573, lr:5.82e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.798, tt:3302.008\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01572, lr:5.82e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.808, tt:3344.671\n",
      "Ep:80, loss:0.00001, loss_test:0.01573, lr:5.82e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.802, tt:3385.923\n",
      "Ep:81, loss:0.00001, loss_test:0.01577, lr:5.82e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.777, tt:3425.691\n",
      "Ep:82, loss:0.00001, loss_test:0.01584, lr:5.82e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.763, tt:3466.326\n",
      "Ep:83, loss:0.00001, loss_test:0.01591, lr:5.82e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.741, tt:3506.250\n",
      "Ep:84, loss:0.00001, loss_test:0.01592, lr:5.82e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.755, tt:3549.206\n",
      "Ep:85, loss:0.00001, loss_test:0.01599, lr:5.82e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.774, tt:3592.564\n",
      "Ep:86, loss:0.00001, loss_test:0.01602, lr:5.82e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.778, tt:3634.672\n",
      "Ep:87, loss:0.00001, loss_test:0.01606, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.802, tt:3678.618\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01613, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.834, tt:3723.185\n",
      "Ep:89, loss:0.00001, loss_test:0.01612, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.862, tt:3767.556\n",
      "Ep:90, loss:0.00001, loss_test:0.01615, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.877, tt:3810.833\n",
      "Ep:91, loss:0.00001, loss_test:0.01627, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.904, tt:3855.136\n",
      "Ep:92, loss:0.00001, loss_test:0.01629, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.928, tt:3899.282\n",
      "Ep:93, loss:0.00001, loss_test:0.01633, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.923, tt:3940.772\n",
      "Ep:94, loss:0.00001, loss_test:0.01637, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.930, tt:3983.343\n",
      "Ep:95, loss:0.00001, loss_test:0.01646, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.925, tt:4024.835\n",
      "Ep:96, loss:0.00001, loss_test:0.01649, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.929, tt:4067.101\n",
      "Ep:97, loss:0.00001, loss_test:0.01647, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.934, tt:4109.495\n",
      "Ep:98, loss:0.00001, loss_test:0.01656, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.931, tt:4151.165\n",
      "Ep:99, loss:0.00001, loss_test:0.01663, lr:5.76e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.934, tt:4193.405\n",
      "Ep:100, loss:0.00001, loss_test:0.01663, lr:5.71e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.935, tt:4235.460\n",
      "Ep:101, loss:0.00001, loss_test:0.01674, lr:5.65e-02, fs:0.86458 (r=0.838,p=0.892),  time:41.953, tt:4279.220\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01677, lr:5.65e-02, fs:0.86911 (r=0.838,p=0.902),  time:41.946, tt:4320.445\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.01679, lr:5.65e-02, fs:0.86911 (r=0.838,p=0.902),  time:41.945, tt:4362.296\n",
      "Ep:104, loss:0.00001, loss_test:0.01686, lr:5.65e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.929, tt:4402.508\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.01688, lr:5.65e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.916, tt:4443.059\n",
      "Ep:106, loss:0.00000, loss_test:0.01693, lr:5.65e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.922, tt:4485.624\n",
      "Ep:107, loss:0.00000, loss_test:0.01693, lr:5.65e-02, fs:0.86911 (r=0.838,p=0.902),  time:41.920, tt:4527.371\n",
      "Ep:108, loss:0.00000, loss_test:0.01699, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.925, tt:4569.790\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.01702, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.916, tt:4610.803\n",
      "Ep:110, loss:0.00000, loss_test:0.01709, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.903, tt:4651.219\n",
      "Ep:111, loss:0.00000, loss_test:0.01713, lr:5.65e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.891, tt:4691.841\n",
      "Ep:112, loss:0.00000, loss_test:0.01719, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.861, tt:4730.243\n",
      "Ep:113, loss:0.00000, loss_test:0.01724, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.851, tt:4771.027\n",
      "Ep:114, loss:0.00000, loss_test:0.01724, lr:5.65e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.818, tt:4809.095\n",
      "Ep:115, loss:0.00000, loss_test:0.01729, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.797, tt:4848.453\n",
      "Ep:116, loss:0.00000, loss_test:0.01733, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.789, tt:4889.365\n",
      "Ep:117, loss:0.00000, loss_test:0.01745, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.779, tt:4929.876\n",
      "Ep:118, loss:0.00000, loss_test:0.01745, lr:5.65e-02, fs:0.88298 (r=0.838,p=0.933),  time:41.752, tt:4968.496\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00000, loss_test:0.01752, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.739, tt:5008.699\n",
      "Ep:120, loss:0.00000, loss_test:0.01752, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.735, tt:5049.951\n",
      "Ep:121, loss:0.00000, loss_test:0.01763, lr:5.65e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.719, tt:5089.690\n",
      "Ep:122, loss:0.00000, loss_test:0.01773, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.713, tt:5130.753\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01769, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.711, tt:5172.170\n",
      "Ep:124, loss:0.00000, loss_test:0.01773, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.703, tt:5212.905\n",
      "Ep:125, loss:0.00000, loss_test:0.01781, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.703, tt:5254.616\n",
      "Ep:126, loss:0.00000, loss_test:0.01793, lr:5.65e-02, fs:0.88298 (r=0.838,p=0.933),  time:41.671, tt:5292.176\n",
      "Ep:127, loss:0.00000, loss_test:0.01791, lr:5.65e-02, fs:0.89247 (r=0.838,p=0.954),  time:41.685, tt:5335.618\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.01800, lr:5.65e-02, fs:0.89247 (r=0.838,p=0.954),  time:41.676, tt:5376.163\n",
      "Ep:129, loss:0.00000, loss_test:0.01804, lr:5.65e-02, fs:0.89247 (r=0.838,p=0.954),  time:41.668, tt:5416.793\n",
      "Ep:130, loss:0.00000, loss_test:0.01810, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.650, tt:5456.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.01813, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.645, tt:5497.166\n",
      "Ep:132, loss:0.00000, loss_test:0.01821, lr:5.65e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.635, tt:5537.433\n",
      "Ep:133, loss:0.00000, loss_test:0.01824, lr:5.65e-02, fs:0.89247 (r=0.838,p=0.954),  time:41.635, tt:5579.057\n",
      "Ep:134, loss:0.00000, loss_test:0.01832, lr:5.65e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.630, tt:5620.101\n",
      "Ep:135, loss:0.00000, loss_test:0.01835, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.622, tt:5660.620\n",
      "Ep:136, loss:0.00000, loss_test:0.01843, lr:5.65e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.624, tt:5702.447\n",
      "Ep:137, loss:0.00000, loss_test:0.01846, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.620, tt:5743.554\n",
      "Ep:138, loss:0.00000, loss_test:0.01854, lr:5.65e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.608, tt:5783.481\n",
      "Ep:139, loss:0.00000, loss_test:0.01861, lr:5.59e-02, fs:0.86957 (r=0.808,p=0.941),  time:41.602, tt:5824.328\n",
      "Ep:140, loss:0.00000, loss_test:0.01870, lr:5.54e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.598, tt:5865.378\n",
      "Ep:141, loss:0.00000, loss_test:0.01871, lr:5.48e-02, fs:0.86957 (r=0.808,p=0.941),  time:41.599, tt:5907.026\n",
      "Ep:142, loss:0.00000, loss_test:0.01880, lr:5.43e-02, fs:0.86957 (r=0.808,p=0.941),  time:41.578, tt:5945.633\n",
      "Ep:143, loss:0.00000, loss_test:0.01883, lr:5.37e-02, fs:0.86957 (r=0.808,p=0.941),  time:41.572, tt:5986.399\n",
      "Ep:144, loss:0.00000, loss_test:0.01884, lr:5.32e-02, fs:0.86339 (r=0.798,p=0.940),  time:41.574, tt:6028.176\n",
      "Ep:145, loss:0.00000, loss_test:0.01894, lr:5.27e-02, fs:0.86957 (r=0.808,p=0.941),  time:41.555, tt:6066.998\n",
      "Ep:146, loss:0.00000, loss_test:0.01893, lr:5.21e-02, fs:0.85083 (r=0.778,p=0.939),  time:41.531, tt:6105.036\n",
      "Ep:147, loss:0.00000, loss_test:0.01905, lr:5.16e-02, fs:0.85083 (r=0.778,p=0.939),  time:41.525, tt:6145.760\n",
      "Ep:148, loss:0.00000, loss_test:0.01911, lr:5.11e-02, fs:0.83799 (r=0.758,p=0.938),  time:41.519, tt:6186.325\n",
      "Ep:149, loss:0.00000, loss_test:0.01910, lr:5.06e-02, fs:0.84444 (r=0.768,p=0.938),  time:41.508, tt:6226.210\n",
      "Ep:150, loss:0.00000, loss_test:0.01918, lr:5.01e-02, fs:0.85083 (r=0.778,p=0.939),  time:41.493, tt:6265.448\n",
      "Ep:151, loss:0.00000, loss_test:0.01918, lr:4.96e-02, fs:0.81818 (r=0.727,p=0.935),  time:41.475, tt:6304.205\n",
      "Ep:152, loss:0.00000, loss_test:0.01930, lr:4.91e-02, fs:0.81143 (r=0.717,p=0.934),  time:41.467, tt:6344.412\n",
      "Ep:153, loss:0.00000, loss_test:0.01928, lr:4.86e-02, fs:0.82486 (r=0.737,p=0.936),  time:41.453, tt:6383.818\n",
      "Ep:154, loss:0.00000, loss_test:0.01939, lr:4.81e-02, fs:0.80460 (r=0.707,p=0.933),  time:41.451, tt:6424.925\n",
      "Ep:155, loss:0.00000, loss_test:0.01939, lr:4.76e-02, fs:0.80460 (r=0.707,p=0.933),  time:41.452, tt:6466.583\n",
      "Ep:156, loss:0.00000, loss_test:0.01943, lr:4.71e-02, fs:0.78363 (r=0.677,p=0.931),  time:41.452, tt:6507.905\n",
      "Ep:157, loss:0.00000, loss_test:0.01949, lr:4.67e-02, fs:0.78363 (r=0.677,p=0.931),  time:41.447, tt:6548.584\n",
      "Ep:158, loss:0.00000, loss_test:0.01953, lr:4.62e-02, fs:0.77647 (r=0.667,p=0.930),  time:41.440, tt:6588.947\n",
      "Ep:159, loss:0.00000, loss_test:0.01952, lr:4.57e-02, fs:0.79070 (r=0.687,p=0.932),  time:41.435, tt:6629.589\n",
      "Ep:160, loss:0.00000, loss_test:0.01957, lr:4.53e-02, fs:0.79070 (r=0.687,p=0.932),  time:41.441, tt:6672.072\n",
      "Ep:161, loss:0.00000, loss_test:0.01966, lr:4.48e-02, fs:0.77647 (r=0.667,p=0.930),  time:41.438, tt:6712.940\n",
      "Ep:162, loss:0.00000, loss_test:0.01968, lr:4.44e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.428, tt:6752.784\n",
      "Ep:163, loss:0.00000, loss_test:0.01968, lr:4.39e-02, fs:0.77647 (r=0.667,p=0.930),  time:41.411, tt:6791.468\n",
      "Ep:164, loss:0.00000, loss_test:0.01975, lr:4.35e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.408, tt:6832.390\n",
      "Ep:165, loss:0.00000, loss_test:0.01978, lr:4.31e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.405, tt:6873.189\n",
      "Ep:166, loss:0.00000, loss_test:0.01981, lr:4.26e-02, fs:0.76923 (r=0.657,p=0.929),  time:41.394, tt:6912.864\n",
      "Ep:167, loss:0.00000, loss_test:0.01979, lr:4.22e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.389, tt:6953.392\n",
      "Ep:168, loss:0.00000, loss_test:0.01989, lr:4.18e-02, fs:0.76923 (r=0.657,p=0.929),  time:41.381, tt:6993.427\n",
      "Ep:169, loss:0.00000, loss_test:0.01994, lr:4.14e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.381, tt:7034.826\n",
      "Ep:170, loss:0.00000, loss_test:0.01993, lr:4.10e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.369, tt:7074.052\n",
      "Ep:171, loss:0.00000, loss_test:0.02000, lr:4.05e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.352, tt:7112.613\n",
      "Ep:172, loss:0.00000, loss_test:0.02002, lr:4.01e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.348, tt:7153.125\n",
      "Ep:173, loss:0.00000, loss_test:0.02005, lr:3.97e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.338, tt:7192.812\n",
      "Ep:174, loss:0.00000, loss_test:0.02007, lr:3.93e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.332, tt:7233.122\n",
      "Ep:175, loss:0.00000, loss_test:0.02012, lr:3.89e-02, fs:0.76190 (r=0.646,p=0.928),  time:41.323, tt:7272.761\n",
      "Ep:176, loss:0.00000, loss_test:0.02016, lr:3.86e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.320, tt:7313.585\n",
      "Ep:177, loss:0.00000, loss_test:0.02022, lr:3.82e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.330, tt:7356.752\n",
      "Ep:178, loss:0.00000, loss_test:0.02019, lr:3.78e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.334, tt:7398.787\n",
      "Ep:179, loss:0.00000, loss_test:0.02028, lr:3.74e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.336, tt:7440.429\n",
      "Ep:180, loss:0.00000, loss_test:0.02033, lr:3.70e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.336, tt:7481.852\n",
      "Ep:181, loss:0.00000, loss_test:0.02035, lr:3.67e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.338, tt:7523.558\n",
      "Ep:182, loss:0.00000, loss_test:0.02036, lr:3.63e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.330, tt:7563.310\n",
      "Ep:183, loss:0.00000, loss_test:0.02035, lr:3.59e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.322, tt:7603.178\n",
      "Ep:184, loss:0.00000, loss_test:0.02039, lr:3.56e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.325, tt:7645.080\n",
      "Ep:185, loss:0.00000, loss_test:0.02044, lr:3.52e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.329, tt:7687.283\n",
      "Ep:186, loss:0.00000, loss_test:0.02048, lr:3.49e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.316, tt:7726.062\n",
      "Ep:187, loss:0.00000, loss_test:0.02050, lr:3.45e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.313, tt:7766.765\n",
      "Ep:188, loss:0.00000, loss_test:0.02051, lr:3.42e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.307, tt:7806.975\n",
      "Ep:189, loss:0.00000, loss_test:0.02057, lr:3.38e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.305, tt:7847.902\n",
      "Ep:190, loss:0.00000, loss_test:0.02060, lr:3.35e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.302, tt:7888.588\n",
      "Ep:191, loss:0.00000, loss_test:0.02058, lr:3.32e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.303, tt:7930.193\n",
      "Ep:192, loss:0.00000, loss_test:0.02064, lr:3.28e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.294, tt:7969.781\n",
      "Ep:193, loss:0.00000, loss_test:0.02070, lr:3.25e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.281, tt:8008.458\n",
      "Ep:194, loss:0.00000, loss_test:0.02073, lr:3.22e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.267, tt:8046.978\n",
      "Ep:195, loss:0.00000, loss_test:0.02071, lr:3.19e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.265, tt:8087.876\n",
      "Ep:196, loss:0.00000, loss_test:0.02072, lr:3.15e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.247, tt:8125.677\n",
      "Ep:197, loss:0.00000, loss_test:0.02076, lr:3.12e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.243, tt:8166.154\n",
      "Ep:198, loss:0.00000, loss_test:0.02083, lr:3.09e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.266, tt:8211.991\n",
      "Ep:199, loss:0.00000, loss_test:0.02084, lr:3.06e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.264, tt:8252.878\n",
      "Ep:200, loss:0.00000, loss_test:0.02082, lr:3.03e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.252, tt:8291.731\n",
      "Ep:201, loss:0.00000, loss_test:0.02087, lr:3.00e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.237, tt:8329.826\n",
      "Ep:202, loss:0.00000, loss_test:0.02090, lr:2.97e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.232, tt:8370.114\n",
      "Ep:203, loss:0.00000, loss_test:0.02096, lr:2.94e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.229, tt:8410.720\n",
      "Ep:204, loss:0.00000, loss_test:0.02094, lr:2.91e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.220, tt:8450.071\n",
      "Ep:205, loss:0.00000, loss_test:0.02096, lr:2.88e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.211, tt:8489.407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.02099, lr:2.85e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.209, tt:8530.250\n",
      "Ep:207, loss:0.00000, loss_test:0.02101, lr:2.82e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.198, tt:8569.141\n",
      "Ep:208, loss:0.00000, loss_test:0.02107, lr:2.80e-02, fs:0.73171 (r=0.606,p=0.923),  time:41.185, tt:8607.598\n",
      "Ep:209, loss:0.00000, loss_test:0.02104, lr:2.77e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.178, tt:8647.360\n",
      "Ep:210, loss:0.00000, loss_test:0.02108, lr:2.74e-02, fs:0.73171 (r=0.606,p=0.923),  time:41.159, tt:8684.627\n",
      "Ep:211, loss:0.00000, loss_test:0.02108, lr:2.71e-02, fs:0.73939 (r=0.616,p=0.924),  time:41.131, tt:8719.870\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14129, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.175, tt:30.175\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14006, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.255, tt:60.510\n",
      "Ep:2, loss:0.00028, loss_test:0.13789, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.906, tt:95.717\n",
      "Ep:3, loss:0.00028, loss_test:0.13437, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.333, tt:137.332\n",
      "Ep:4, loss:0.00027, loss_test:0.12849, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:35.353, tt:176.767\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.11915, lr:1.00e-02, fs:0.68613 (r=0.949,p=0.537),  time:36.015, tt:216.092\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.10905, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:36.798, tt:257.585\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10525, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:37.900, tt:303.203\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10256, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:38.198, tt:343.779\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10182, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:38.471, tt:384.711\n",
      "Ep:10, loss:0.00022, loss_test:0.10143, lr:1.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:38.877, tt:427.646\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09679, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:39.189, tt:470.272\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09330, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:39.353, tt:511.584\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09298, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:39.489, tt:552.843\n",
      "Ep:14, loss:0.00019, loss_test:0.09159, lr:1.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:39.656, tt:594.834\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08960, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:39.688, tt:635.016\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08946, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:39.858, tt:677.583\n",
      "Ep:17, loss:0.00017, loss_test:0.08674, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:40.035, tt:720.638\n",
      "Ep:18, loss:0.00016, loss_test:0.08604, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:40.047, tt:760.902\n",
      "Ep:19, loss:0.00015, loss_test:0.08738, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:40.051, tt:801.029\n",
      "Ep:20, loss:0.00015, loss_test:0.08465, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:40.061, tt:841.279\n",
      "Ep:21, loss:0.00014, loss_test:0.08499, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:40.052, tt:881.138\n",
      "Ep:22, loss:0.00014, loss_test:0.08139, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:40.088, tt:922.024\n",
      "Ep:23, loss:0.00013, loss_test:0.08054, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:40.135, tt:963.230\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07848, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.225, tt:1005.633\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.07712, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:40.262, tt:1046.799\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.07571, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:40.300, tt:1088.099\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.07418, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.340, tt:1129.527\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.07324, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:40.331, tt:1169.598\n",
      "Ep:29, loss:0.00010, loss_test:0.07292, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.459, tt:1213.769\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.07100, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:40.494, tt:1255.325\n",
      "Ep:31, loss:0.00009, loss_test:0.07245, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:40.573, tt:1298.328\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06943, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.662, tt:1341.847\n",
      "Ep:33, loss:0.00009, loss_test:0.06901, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.696, tt:1383.667\n",
      "Ep:34, loss:0.00008, loss_test:0.07173, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:40.741, tt:1425.922\n",
      "Ep:35, loss:0.00008, loss_test:0.06821, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:40.780, tt:1468.063\n",
      "Ep:36, loss:0.00008, loss_test:0.07090, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.754, tt:1507.883\n",
      "Ep:37, loss:0.00008, loss_test:0.06707, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:40.808, tt:1550.700\n",
      "Ep:38, loss:0.00007, loss_test:0.06985, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:40.840, tt:1592.759\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.06794, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:40.907, tt:1636.266\n",
      "Ep:40, loss:0.00007, loss_test:0.06711, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.954, tt:1679.112\n",
      "Ep:41, loss:0.00007, loss_test:0.06403, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.971, tt:1720.795\n",
      "Ep:42, loss:0.00006, loss_test:0.06614, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:41.025, tt:1764.094\n",
      "Ep:43, loss:0.00006, loss_test:0.06508, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:41.062, tt:1806.718\n",
      "Ep:44, loss:0.00006, loss_test:0.06477, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:41.100, tt:1849.489\n",
      "Ep:45, loss:0.00006, loss_test:0.06574, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:41.150, tt:1892.901\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.06468, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:41.169, tt:1934.945\n",
      "Ep:47, loss:0.00005, loss_test:0.06731, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:41.203, tt:1977.740\n",
      "Ep:48, loss:0.00005, loss_test:0.06151, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.205, tt:2019.036\n",
      "Ep:49, loss:0.00005, loss_test:0.06611, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:41.230, tt:2061.495\n",
      "Ep:50, loss:0.00005, loss_test:0.06070, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:41.192, tt:2100.779\n",
      "Ep:51, loss:0.00004, loss_test:0.06632, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.221, tt:2143.495\n",
      "Ep:52, loss:0.00004, loss_test:0.06181, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:41.214, tt:2184.354\n",
      "Ep:53, loss:0.00004, loss_test:0.06575, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:41.177, tt:2223.542\n",
      "Ep:54, loss:0.00004, loss_test:0.06165, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:41.156, tt:2263.577\n",
      "Ep:55, loss:0.00004, loss_test:0.06655, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.184, tt:2306.331\n",
      "Ep:56, loss:0.00004, loss_test:0.06121, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:41.202, tt:2348.486\n",
      "Ep:57, loss:0.00004, loss_test:0.06548, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.253, tt:2392.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00004, loss_test:0.06096, lr:9.80e-03, fs:0.83060 (r=0.768,p=0.905),  time:41.252, tt:2433.854\n",
      "Ep:59, loss:0.00003, loss_test:0.06488, lr:9.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.265, tt:2475.924\n",
      "Ep:60, loss:0.00003, loss_test:0.06251, lr:9.61e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.290, tt:2518.680\n",
      "Ep:61, loss:0.00003, loss_test:0.06533, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.313, tt:2561.406\n",
      "Ep:62, loss:0.00003, loss_test:0.06220, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:41.331, tt:2603.842\n",
      "Ep:63, loss:0.00003, loss_test:0.06501, lr:9.32e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.382, tt:2648.449\n",
      "Ep:64, loss:0.00003, loss_test:0.06249, lr:9.23e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.407, tt:2691.460\n",
      "Ep:65, loss:0.00003, loss_test:0.06414, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.398, tt:2732.260\n",
      "Ep:66, loss:0.00003, loss_test:0.06448, lr:9.04e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.412, tt:2774.590\n",
      "Ep:67, loss:0.00003, loss_test:0.06512, lr:8.95e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.460, tt:2819.248\n",
      "Ep:68, loss:0.00002, loss_test:0.06204, lr:8.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.480, tt:2862.131\n",
      "Ep:69, loss:0.00002, loss_test:0.06418, lr:8.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.488, tt:2904.182\n",
      "Ep:70, loss:0.00002, loss_test:0.06355, lr:8.69e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.494, tt:2946.061\n",
      "Ep:71, loss:0.00002, loss_test:0.06317, lr:8.60e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.502, tt:2988.157\n",
      "Ep:72, loss:0.00002, loss_test:0.06769, lr:8.51e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.496, tt:3029.207\n",
      "Ep:73, loss:0.00002, loss_test:0.06347, lr:8.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.483, tt:3069.754\n",
      "Ep:74, loss:0.00002, loss_test:0.06341, lr:8.35e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.484, tt:3111.290\n",
      "Ep:75, loss:0.00002, loss_test:0.06608, lr:8.26e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.509, tt:3154.701\n",
      "Ep:76, loss:0.00002, loss_test:0.06344, lr:8.18e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.507, tt:3196.060\n",
      "Ep:77, loss:0.00002, loss_test:0.06403, lr:8.10e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.478, tt:3235.280\n",
      "Ep:78, loss:0.00002, loss_test:0.06544, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.480, tt:3276.915\n",
      "Ep:79, loss:0.00002, loss_test:0.06389, lr:7.94e-03, fs:0.80460 (r=0.707,p=0.933),  time:41.503, tt:3320.218\n",
      "Ep:80, loss:0.00002, loss_test:0.06352, lr:7.86e-03, fs:0.82486 (r=0.737,p=0.936),  time:41.505, tt:3361.941\n",
      "Ep:81, loss:0.00002, loss_test:0.06559, lr:7.78e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.477, tt:3401.117\n",
      "Ep:82, loss:0.00001, loss_test:0.06455, lr:7.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.484, tt:3443.161\n",
      "Ep:83, loss:0.00001, loss_test:0.06448, lr:7.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:41.473, tt:3483.760\n",
      "Ep:84, loss:0.00001, loss_test:0.06513, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.497, tt:3527.239\n",
      "Ep:85, loss:0.00001, loss_test:0.06512, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.517, tt:3570.490\n",
      "Ep:86, loss:0.00001, loss_test:0.06642, lr:7.40e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.519, tt:3612.157\n",
      "Ep:87, loss:0.00001, loss_test:0.06531, lr:7.32e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.527, tt:3654.383\n",
      "Ep:88, loss:0.00001, loss_test:0.06428, lr:7.25e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.529, tt:3696.082\n",
      "Ep:89, loss:0.00001, loss_test:0.06596, lr:7.18e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.514, tt:3736.235\n",
      "Ep:90, loss:0.00001, loss_test:0.06567, lr:7.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.522, tt:3778.526\n",
      "Ep:91, loss:0.00001, loss_test:0.06574, lr:7.03e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.528, tt:3820.561\n",
      "Ep:92, loss:0.00001, loss_test:0.06439, lr:6.96e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.510, tt:3860.443\n",
      "Ep:93, loss:0.00001, loss_test:0.06591, lr:6.89e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.502, tt:3901.230\n",
      "Ep:94, loss:0.00001, loss_test:0.06593, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.483, tt:3940.847\n",
      "Ep:95, loss:0.00001, loss_test:0.06714, lr:6.76e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.468, tt:3980.921\n",
      "Ep:96, loss:0.00001, loss_test:0.06672, lr:6.69e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.458, tt:4021.390\n",
      "Ep:97, loss:0.00001, loss_test:0.06590, lr:6.62e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.458, tt:4062.879\n",
      "Ep:98, loss:0.00001, loss_test:0.06554, lr:6.56e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.467, tt:4105.242\n",
      "Ep:99, loss:0.00001, loss_test:0.06701, lr:6.49e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.467, tt:4146.704\n",
      "Ep:100, loss:0.00001, loss_test:0.06725, lr:6.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.466, tt:4188.039\n",
      "Ep:101, loss:0.00001, loss_test:0.06569, lr:6.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.445, tt:4227.391\n",
      "Ep:102, loss:0.00001, loss_test:0.06875, lr:6.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.426, tt:4266.886\n",
      "Ep:103, loss:0.00001, loss_test:0.06627, lr:6.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.407, tt:4306.325\n",
      "Ep:104, loss:0.00001, loss_test:0.06529, lr:6.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.401, tt:4347.147\n",
      "Ep:105, loss:0.00001, loss_test:0.06982, lr:6.11e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.400, tt:4388.377\n",
      "Ep:106, loss:0.00001, loss_test:0.06698, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.400, tt:4429.839\n",
      "Ep:107, loss:0.00001, loss_test:0.06736, lr:5.99e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.421, tt:4473.503\n",
      "Ep:108, loss:0.00001, loss_test:0.06546, lr:5.93e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.430, tt:4515.839\n",
      "Ep:109, loss:0.00001, loss_test:0.06787, lr:5.87e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.425, tt:4556.783\n",
      "Ep:110, loss:0.00001, loss_test:0.06627, lr:5.81e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.435, tt:4599.245\n",
      "Ep:111, loss:0.00001, loss_test:0.06692, lr:5.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.444, tt:4641.768\n",
      "Ep:112, loss:0.00001, loss_test:0.06656, lr:5.70e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.436, tt:4682.224\n",
      "Ep:113, loss:0.00001, loss_test:0.06831, lr:5.64e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.450, tt:4725.292\n",
      "Ep:114, loss:0.00001, loss_test:0.06590, lr:5.58e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.440, tt:4765.594\n",
      "Ep:115, loss:0.00001, loss_test:0.06902, lr:5.53e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.460, tt:4809.314\n",
      "Ep:116, loss:0.00001, loss_test:0.06677, lr:5.47e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.465, tt:4851.353\n",
      "Ep:117, loss:0.00001, loss_test:0.06755, lr:5.42e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.472, tt:4893.721\n",
      "Ep:118, loss:0.00001, loss_test:0.06647, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.480, tt:4936.097\n",
      "Ep:119, loss:0.00001, loss_test:0.06927, lr:5.31e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.481, tt:4977.768\n",
      "Ep:120, loss:0.00001, loss_test:0.06656, lr:5.26e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.486, tt:5019.747\n",
      "Ep:121, loss:0.00001, loss_test:0.06683, lr:5.20e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.484, tt:5061.097\n",
      "Ep:122, loss:0.00001, loss_test:0.06721, lr:5.15e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.486, tt:5102.741\n",
      "Ep:123, loss:0.00001, loss_test:0.06814, lr:5.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.480, tt:5143.516\n",
      "Ep:124, loss:0.00001, loss_test:0.06628, lr:5.05e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.489, tt:5186.163\n",
      "Ep:125, loss:0.00001, loss_test:0.06745, lr:5.00e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.493, tt:5228.113\n",
      "Ep:126, loss:0.00001, loss_test:0.06717, lr:4.95e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.498, tt:5270.196\n",
      "Ep:127, loss:0.00000, loss_test:0.06689, lr:4.90e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.510, tt:5313.234\n",
      "Ep:128, loss:0.00000, loss_test:0.06709, lr:4.85e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.518, tt:5355.832\n",
      "Ep:129, loss:0.00000, loss_test:0.06661, lr:4.80e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.528, tt:5398.594\n",
      "Ep:130, loss:0.00000, loss_test:0.06858, lr:4.75e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.518, tt:5438.853\n",
      "Ep:131, loss:0.00000, loss_test:0.06688, lr:4.71e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.513, tt:5479.688\n",
      "Ep:132, loss:0.00000, loss_test:0.06790, lr:4.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.516, tt:5521.674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.06814, lr:4.61e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.521, tt:5563.785\n",
      "Ep:134, loss:0.00000, loss_test:0.06774, lr:4.57e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.510, tt:5603.813\n",
      "Ep:135, loss:0.00000, loss_test:0.06742, lr:4.52e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.513, tt:5645.803\n",
      "Ep:136, loss:0.00000, loss_test:0.06752, lr:4.48e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.523, tt:5688.643\n",
      "Ep:137, loss:0.00000, loss_test:0.06769, lr:4.43e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.534, tt:5731.665\n",
      "Ep:138, loss:0.00000, loss_test:0.06718, lr:4.39e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.540, tt:5774.013\n",
      "Ep:139, loss:0.00000, loss_test:0.06792, lr:4.34e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.545, tt:5816.305\n",
      "Ep:140, loss:0.00000, loss_test:0.06691, lr:4.30e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.557, tt:5859.522\n",
      "Ep:141, loss:0.00000, loss_test:0.06915, lr:4.26e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.564, tt:5902.086\n",
      "Ep:142, loss:0.00000, loss_test:0.06878, lr:4.21e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.557, tt:5942.609\n",
      "Ep:143, loss:0.00000, loss_test:0.06727, lr:4.17e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.561, tt:5984.751\n",
      "Ep:144, loss:0.00000, loss_test:0.06801, lr:4.13e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.570, tt:6027.709\n",
      "Ep:145, loss:0.00000, loss_test:0.06833, lr:4.09e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.576, tt:6070.124\n",
      "Ep:146, loss:0.00000, loss_test:0.06841, lr:4.05e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.582, tt:6112.602\n",
      "Ep:147, loss:0.00000, loss_test:0.06708, lr:4.01e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.584, tt:6154.473\n",
      "Ep:148, loss:0.00000, loss_test:0.06880, lr:3.97e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.611, tt:6200.073\n",
      "Ep:149, loss:0.00000, loss_test:0.06769, lr:3.93e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.621, tt:6243.200\n",
      "Ep:150, loss:0.00000, loss_test:0.06830, lr:3.89e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.631, tt:6286.258\n",
      "Ep:151, loss:0.00000, loss_test:0.06743, lr:3.85e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.632, tt:6328.044\n",
      "Ep:152, loss:0.00000, loss_test:0.06803, lr:3.81e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.633, tt:6369.779\n",
      "Ep:153, loss:0.00000, loss_test:0.06855, lr:3.77e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.632, tt:6411.317\n",
      "Ep:154, loss:0.00000, loss_test:0.06748, lr:3.73e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.637, tt:6453.756\n",
      "Ep:155, loss:0.00000, loss_test:0.06710, lr:3.70e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.644, tt:6496.412\n",
      "Ep:156, loss:0.00000, loss_test:0.06781, lr:3.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.643, tt:6538.012\n",
      "Ep:157, loss:0.00000, loss_test:0.06796, lr:3.62e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.640, tt:6579.085\n",
      "Ep:158, loss:0.00000, loss_test:0.06716, lr:3.59e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.639, tt:6620.644\n",
      "Ep:159, loss:0.00000, loss_test:0.06810, lr:3.55e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.646, tt:6663.282\n",
      "Ep:160, loss:0.00000, loss_test:0.06786, lr:3.52e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.634, tt:6703.153\n",
      "Ep:161, loss:0.00000, loss_test:0.06777, lr:3.48e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.630, tt:6744.042\n",
      "Ep:162, loss:0.00000, loss_test:0.06719, lr:3.45e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.627, tt:6785.238\n",
      "Ep:163, loss:0.00000, loss_test:0.06797, lr:3.41e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.614, tt:6824.765\n",
      "Ep:164, loss:0.00000, loss_test:0.06739, lr:3.38e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.622, tt:6867.665\n",
      "Ep:165, loss:0.00000, loss_test:0.06809, lr:3.34e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.621, tt:6909.087\n",
      "Ep:166, loss:0.00000, loss_test:0.06839, lr:3.31e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.604, tt:6947.908\n",
      "Ep:167, loss:0.00000, loss_test:0.06754, lr:3.28e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.600, tt:6988.808\n",
      "Ep:168, loss:0.00000, loss_test:0.06825, lr:3.24e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.620, tt:7033.695\n",
      "Ep:169, loss:0.00000, loss_test:0.06730, lr:3.21e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.619, tt:7075.286\n",
      "Ep:170, loss:0.00000, loss_test:0.06795, lr:3.18e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.622, tt:7117.396\n",
      "Ep:171, loss:0.00000, loss_test:0.06763, lr:3.15e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.624, tt:7159.397\n",
      "Ep:172, loss:0.00000, loss_test:0.06788, lr:3.12e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.606, tt:7197.872\n",
      "Ep:173, loss:0.00000, loss_test:0.06796, lr:3.09e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.602, tt:7238.663\n",
      "Ep:174, loss:0.00000, loss_test:0.06789, lr:3.05e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.591, tt:7278.427\n",
      "Ep:175, loss:0.00000, loss_test:0.06866, lr:3.02e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.583, tt:7318.625\n",
      "Ep:176, loss:0.00000, loss_test:0.06752, lr:2.99e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.577, tt:7359.210\n",
      "Ep:177, loss:0.00000, loss_test:0.06790, lr:2.96e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.562, tt:7398.113\n",
      "Ep:178, loss:0.00000, loss_test:0.06842, lr:2.93e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.558, tt:7438.930\n",
      "Ep:179, loss:0.00000, loss_test:0.06765, lr:2.90e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.560, tt:7480.868\n",
      "Ep:180, loss:0.00000, loss_test:0.06793, lr:2.88e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.562, tt:7522.763\n",
      "Ep:181, loss:0.00000, loss_test:0.06770, lr:2.85e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.557, tt:7563.335\n",
      "Ep:182, loss:0.00000, loss_test:0.06762, lr:2.82e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.555, tt:7604.569\n",
      "Ep:183, loss:0.00000, loss_test:0.06792, lr:2.79e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.558, tt:7646.681\n",
      "Ep:184, loss:0.00000, loss_test:0.06754, lr:2.76e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.569, tt:7690.238\n",
      "Ep:185, loss:0.00000, loss_test:0.06789, lr:2.73e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.584, tt:7734.541\n",
      "Ep:186, loss:0.00000, loss_test:0.06768, lr:2.71e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.588, tt:7777.010\n",
      "Ep:187, loss:0.00000, loss_test:0.06756, lr:2.68e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.588, tt:7818.634\n",
      "Ep:188, loss:0.00000, loss_test:0.06773, lr:2.65e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.585, tt:7859.537\n",
      "Ep:189, loss:0.00000, loss_test:0.06772, lr:2.63e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.583, tt:7900.851\n",
      "Ep:190, loss:0.00000, loss_test:0.06751, lr:2.60e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.589, tt:7943.466\n",
      "Ep:191, loss:0.00000, loss_test:0.06795, lr:2.57e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.597, tt:7986.558\n",
      "Ep:192, loss:0.00000, loss_test:0.06838, lr:2.55e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.606, tt:8030.020\n",
      "Ep:193, loss:0.00000, loss_test:0.06777, lr:2.52e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.610, tt:8072.418\n",
      "Ep:194, loss:0.00000, loss_test:0.06775, lr:2.50e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.608, tt:8113.621\n",
      "Ep:195, loss:0.00000, loss_test:0.06851, lr:2.47e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.612, tt:8155.925\n",
      "Ep:196, loss:0.00000, loss_test:0.06808, lr:2.45e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.625, tt:8200.073\n",
      "Ep:197, loss:0.00000, loss_test:0.06752, lr:2.42e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.628, tt:8242.302\n",
      "Ep:198, loss:0.00000, loss_test:0.06801, lr:2.40e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.630, tt:8284.441\n",
      "Ep:199, loss:0.00000, loss_test:0.06793, lr:2.38e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.629, tt:8325.747\n",
      "Ep:200, loss:0.00000, loss_test:0.06762, lr:2.35e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.628, tt:8367.180\n",
      "Ep:201, loss:0.00000, loss_test:0.06763, lr:2.33e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.634, tt:8409.979\n",
      "Ep:202, loss:0.00000, loss_test:0.06774, lr:2.31e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.637, tt:8452.343\n",
      "Ep:203, loss:0.00000, loss_test:0.06770, lr:2.28e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.653, tt:8497.181\n",
      "Ep:204, loss:0.00000, loss_test:0.06797, lr:2.26e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.652, tt:8538.652\n",
      "Ep:205, loss:0.00000, loss_test:0.06778, lr:2.24e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.657, tt:8581.282\n",
      "Ep:206, loss:0.00000, loss_test:0.06754, lr:2.21e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.662, tt:8624.050\n",
      "Ep:207, loss:0.00000, loss_test:0.06762, lr:2.19e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.662, tt:8665.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.06754, lr:2.17e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.664, tt:8707.844\n",
      "Ep:209, loss:0.00000, loss_test:0.06737, lr:2.15e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.667, tt:8750.035\n",
      "Ep:210, loss:0.00000, loss_test:0.06795, lr:2.13e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.662, tt:8790.773\n",
      "Ep:211, loss:0.00000, loss_test:0.06762, lr:2.11e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.622, tt:8823.959\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02034, lr:6.00e-02, fs:0.64435 (r=0.885,p=0.507),  time:21.087, tt:21.087\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02274, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.332, tt:50.664\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02352, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.531, tt:88.594\n",
      "Ep:3, loss:0.00004, loss_test:0.02270, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.843, tt:127.372\n",
      "Ep:4, loss:0.00004, loss_test:0.02108, lr:6.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:33.197, tt:165.986\n",
      "Ep:5, loss:0.00004, loss_test:0.01962, lr:6.00e-02, fs:0.65306 (r=0.920,p=0.506),  time:34.152, tt:204.913\n",
      "Ep:6, loss:0.00004, loss_test:0.01895, lr:6.00e-02, fs:0.68103 (r=0.908,p=0.545),  time:34.814, tt:243.699\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01847, lr:6.00e-02, fs:0.70642 (r=0.885,p=0.588),  time:35.278, tt:282.224\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01788, lr:6.00e-02, fs:0.70796 (r=0.920,p=0.576),  time:35.514, tt:319.626\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.70339 (r=0.954,p=0.557),  time:35.671, tt:356.715\n",
      "Ep:10, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.70000 (r=0.966,p=0.549),  time:36.066, tt:396.722\n",
      "Ep:11, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.70886 (r=0.966,p=0.560),  time:36.359, tt:436.313\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01640, lr:6.00e-02, fs:0.74009 (r=0.966,p=0.600),  time:36.594, tt:475.723\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01595, lr:6.00e-02, fs:0.73239 (r=0.897,p=0.619),  time:36.788, tt:515.026\n",
      "Ep:14, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.74038 (r=0.885,p=0.636),  time:36.922, tt:553.826\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.74766 (r=0.920,p=0.630),  time:37.109, tt:593.750\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.75701 (r=0.931,p=0.638),  time:37.169, tt:631.867\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01443, lr:6.00e-02, fs:0.76777 (r=0.931,p=0.653),  time:37.239, tt:670.311\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01416, lr:6.00e-02, fs:0.77143 (r=0.931,p=0.659),  time:37.328, tt:709.231\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01393, lr:6.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:37.365, tt:747.293\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.79208 (r=0.920,p=0.696),  time:37.314, tt:783.584\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.79208 (r=0.920,p=0.696),  time:37.402, tt:822.846\n",
      "Ep:22, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.80788 (r=0.943,p=0.707),  time:37.420, tt:860.665\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.82178 (r=0.954,p=0.722),  time:37.428, tt:898.271\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.83838 (r=0.954,p=0.748),  time:37.463, tt:936.578\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.84264 (r=0.954,p=0.755),  time:37.479, tt:974.462\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01266, lr:6.00e-02, fs:0.85567 (r=0.954,p=0.776),  time:37.551, tt:1013.882\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:37.585, tt:1052.387\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.86154 (r=0.966,p=0.778),  time:37.638, tt:1091.506\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01235, lr:6.00e-02, fs:0.86458 (r=0.954,p=0.790),  time:37.713, tt:1131.401\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:37.731, tt:1169.672\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01221, lr:6.00e-02, fs:0.86911 (r=0.954,p=0.798),  time:37.798, tt:1209.523\n",
      "Ep:32, loss:0.00002, loss_test:0.01214, lr:6.00e-02, fs:0.85714 (r=0.931,p=0.794),  time:37.850, tt:1249.035\n",
      "Ep:33, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.86772 (r=0.943,p=0.804),  time:37.889, tt:1288.234\n",
      "Ep:34, loss:0.00001, loss_test:0.01198, lr:6.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:37.880, tt:1325.805\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:37.889, tt:1364.010\n",
      "Ep:36, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:37.967, tt:1404.765\n",
      "Ep:37, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:38.022, tt:1444.819\n",
      "Ep:38, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:38.031, tt:1483.227\n",
      "Ep:39, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:38.023, tt:1520.913\n",
      "Ep:40, loss:0.00001, loss_test:0.01192, lr:6.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:38.069, tt:1560.829\n",
      "Ep:41, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:38.109, tt:1600.593\n",
      "Ep:42, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:38.128, tt:1639.508\n",
      "Ep:43, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:38.172, tt:1679.547\n",
      "Ep:44, loss:0.00001, loss_test:0.01189, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:38.183, tt:1718.242\n",
      "Ep:45, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:38.245, tt:1759.270\n",
      "Ep:46, loss:0.00001, loss_test:0.01201, lr:5.94e-02, fs:0.80000 (r=0.782,p=0.819),  time:38.258, tt:1798.121\n",
      "Ep:47, loss:0.00001, loss_test:0.01199, lr:5.88e-02, fs:0.80473 (r=0.782,p=0.829),  time:38.294, tt:1838.115\n",
      "Ep:48, loss:0.00001, loss_test:0.01203, lr:5.82e-02, fs:0.79762 (r=0.770,p=0.827),  time:38.329, tt:1878.141\n",
      "Ep:49, loss:0.00001, loss_test:0.01207, lr:5.76e-02, fs:0.79762 (r=0.770,p=0.827),  time:38.369, tt:1918.440\n",
      "Ep:50, loss:0.00001, loss_test:0.01214, lr:5.71e-02, fs:0.79042 (r=0.759,p=0.825),  time:38.456, tt:1961.231\n",
      "Ep:51, loss:0.00001, loss_test:0.01209, lr:5.65e-02, fs:0.79518 (r=0.759,p=0.835),  time:38.513, tt:2002.678\n",
      "Ep:52, loss:0.00001, loss_test:0.01221, lr:5.59e-02, fs:0.78788 (r=0.747,p=0.833),  time:38.547, tt:2042.965\n",
      "Ep:53, loss:0.00001, loss_test:0.01229, lr:5.54e-02, fs:0.78788 (r=0.747,p=0.833),  time:38.647, tt:2086.928\n",
      "Ep:54, loss:0.00001, loss_test:0.01228, lr:5.48e-02, fs:0.78788 (r=0.747,p=0.833),  time:38.701, tt:2128.579\n",
      "Ep:55, loss:0.00001, loss_test:0.01237, lr:5.43e-02, fs:0.78049 (r=0.736,p=0.831),  time:38.759, tt:2170.498\n",
      "Ep:56, loss:0.00001, loss_test:0.01244, lr:5.37e-02, fs:0.78049 (r=0.736,p=0.831),  time:38.793, tt:2211.190\n",
      "Ep:57, loss:0.00001, loss_test:0.01248, lr:5.32e-02, fs:0.78528 (r=0.736,p=0.842),  time:38.817, tt:2251.394\n",
      "Ep:58, loss:0.00001, loss_test:0.01254, lr:5.27e-02, fs:0.78528 (r=0.736,p=0.842),  time:38.865, tt:2293.013\n",
      "Ep:59, loss:0.00001, loss_test:0.01261, lr:5.21e-02, fs:0.77778 (r=0.724,p=0.840),  time:38.892, tt:2333.536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01271, lr:5.16e-02, fs:0.77778 (r=0.724,p=0.840),  time:38.931, tt:2374.808\n",
      "Ep:61, loss:0.00001, loss_test:0.01276, lr:5.11e-02, fs:0.77778 (r=0.724,p=0.840),  time:38.928, tt:2413.548\n",
      "Ep:62, loss:0.00001, loss_test:0.01281, lr:5.06e-02, fs:0.78261 (r=0.724,p=0.851),  time:38.941, tt:2453.267\n",
      "Ep:63, loss:0.00001, loss_test:0.01292, lr:5.01e-02, fs:0.78261 (r=0.724,p=0.851),  time:38.952, tt:2492.930\n",
      "Ep:64, loss:0.00001, loss_test:0.01299, lr:4.96e-02, fs:0.78261 (r=0.724,p=0.851),  time:38.979, tt:2533.659\n",
      "Ep:65, loss:0.00001, loss_test:0.01307, lr:4.91e-02, fs:0.77500 (r=0.713,p=0.849),  time:39.013, tt:2574.831\n",
      "Ep:66, loss:0.00001, loss_test:0.01314, lr:4.86e-02, fs:0.77500 (r=0.713,p=0.849),  time:39.051, tt:2616.450\n",
      "Ep:67, loss:0.00001, loss_test:0.01317, lr:4.81e-02, fs:0.77987 (r=0.713,p=0.861),  time:39.086, tt:2657.844\n",
      "Ep:68, loss:0.00001, loss_test:0.01331, lr:4.76e-02, fs:0.78981 (r=0.713,p=0.886),  time:39.123, tt:2699.514\n",
      "Ep:69, loss:0.00000, loss_test:0.01338, lr:4.71e-02, fs:0.78981 (r=0.713,p=0.886),  time:39.117, tt:2738.213\n",
      "Ep:70, loss:0.00000, loss_test:0.01343, lr:4.67e-02, fs:0.78981 (r=0.713,p=0.886),  time:39.262, tt:2787.624\n",
      "Ep:71, loss:0.00000, loss_test:0.01349, lr:4.62e-02, fs:0.78981 (r=0.713,p=0.886),  time:39.274, tt:2827.701\n",
      "Ep:72, loss:0.00000, loss_test:0.01356, lr:4.57e-02, fs:0.79487 (r=0.713,p=0.899),  time:39.267, tt:2866.461\n",
      "Ep:73, loss:0.00000, loss_test:0.01365, lr:4.53e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.274, tt:2906.252\n",
      "Ep:74, loss:0.00000, loss_test:0.01373, lr:4.48e-02, fs:0.79487 (r=0.713,p=0.899),  time:39.276, tt:2945.719\n",
      "Ep:75, loss:0.00000, loss_test:0.01379, lr:4.44e-02, fs:0.79487 (r=0.713,p=0.899),  time:39.298, tt:2986.643\n",
      "Ep:76, loss:0.00000, loss_test:0.01378, lr:4.39e-02, fs:0.79487 (r=0.713,p=0.899),  time:39.316, tt:3027.330\n",
      "Ep:77, loss:0.00000, loss_test:0.01395, lr:4.35e-02, fs:0.79487 (r=0.713,p=0.899),  time:39.327, tt:3067.535\n",
      "Ep:78, loss:0.00000, loss_test:0.01394, lr:4.31e-02, fs:0.79487 (r=0.713,p=0.899),  time:39.356, tt:3109.091\n",
      "Ep:79, loss:0.00000, loss_test:0.01402, lr:4.26e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.378, tt:3150.250\n",
      "Ep:80, loss:0.00000, loss_test:0.01410, lr:4.22e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.387, tt:3190.349\n",
      "Ep:81, loss:0.00000, loss_test:0.01417, lr:4.18e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.414, tt:3231.989\n",
      "Ep:82, loss:0.00000, loss_test:0.01427, lr:4.14e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.433, tt:3272.926\n",
      "Ep:83, loss:0.00000, loss_test:0.01426, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.452, tt:3313.960\n",
      "Ep:84, loss:0.00000, loss_test:0.01439, lr:4.05e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.492, tt:3356.851\n",
      "Ep:85, loss:0.00000, loss_test:0.01441, lr:4.01e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.464, tt:3393.866\n",
      "Ep:86, loss:0.00000, loss_test:0.01445, lr:3.97e-02, fs:0.77922 (r=0.690,p=0.896),  time:39.441, tt:3431.387\n",
      "Ep:87, loss:0.00000, loss_test:0.01456, lr:3.93e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.440, tt:3470.727\n",
      "Ep:88, loss:0.00000, loss_test:0.01456, lr:3.89e-02, fs:0.78710 (r=0.701,p=0.897),  time:39.449, tt:3510.938\n",
      "Ep:89, loss:0.00000, loss_test:0.01464, lr:3.86e-02, fs:0.77922 (r=0.690,p=0.896),  time:39.469, tt:3552.236\n",
      "Ep:90, loss:0.00000, loss_test:0.01474, lr:3.82e-02, fs:0.77922 (r=0.690,p=0.896),  time:39.460, tt:3590.884\n",
      "Ep:91, loss:0.00000, loss_test:0.01474, lr:3.78e-02, fs:0.77922 (r=0.690,p=0.896),  time:39.457, tt:3630.057\n",
      "Ep:92, loss:0.00000, loss_test:0.01477, lr:3.74e-02, fs:0.77922 (r=0.690,p=0.896),  time:39.474, tt:3671.079\n",
      "Ep:93, loss:0.00000, loss_test:0.01490, lr:3.70e-02, fs:0.77922 (r=0.690,p=0.896),  time:39.481, tt:3711.215\n",
      "Ep:94, loss:0.00000, loss_test:0.01491, lr:3.67e-02, fs:0.78431 (r=0.690,p=0.909),  time:39.503, tt:3752.815\n",
      "Ep:95, loss:0.00000, loss_test:0.01495, lr:3.63e-02, fs:0.78431 (r=0.690,p=0.909),  time:39.516, tt:3793.554\n",
      "Ep:96, loss:0.00000, loss_test:0.01503, lr:3.59e-02, fs:0.78431 (r=0.690,p=0.909),  time:39.533, tt:3834.669\n",
      "Ep:97, loss:0.00000, loss_test:0.01506, lr:3.56e-02, fs:0.78431 (r=0.690,p=0.909),  time:39.547, tt:3875.645\n",
      "Ep:98, loss:0.00000, loss_test:0.01514, lr:3.52e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.556, tt:3916.060\n",
      "Ep:99, loss:0.00000, loss_test:0.01520, lr:3.49e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.572, tt:3957.247\n",
      "Ep:100, loss:0.00000, loss_test:0.01522, lr:3.45e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.577, tt:3997.256\n",
      "Ep:101, loss:0.00000, loss_test:0.01528, lr:3.42e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.591, tt:4038.327\n",
      "Ep:102, loss:0.00000, loss_test:0.01535, lr:3.38e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.613, tt:4080.178\n",
      "Ep:103, loss:0.00000, loss_test:0.01538, lr:3.35e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.613, tt:4119.800\n",
      "Ep:104, loss:0.00000, loss_test:0.01545, lr:3.32e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.630, tt:4161.190\n",
      "Ep:105, loss:0.00000, loss_test:0.01549, lr:3.28e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.638, tt:4201.617\n",
      "Ep:106, loss:0.00000, loss_test:0.01550, lr:3.25e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.652, tt:4242.802\n",
      "Ep:107, loss:0.00000, loss_test:0.01555, lr:3.22e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.642, tt:4281.325\n",
      "Ep:108, loss:0.00000, loss_test:0.01561, lr:3.19e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.663, tt:4323.237\n",
      "Ep:109, loss:0.00000, loss_test:0.01564, lr:3.15e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.673, tt:4364.036\n",
      "Ep:110, loss:0.00000, loss_test:0.01568, lr:3.12e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.677, tt:4404.156\n",
      "Ep:111, loss:0.00000, loss_test:0.01576, lr:3.09e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.672, tt:4443.264\n",
      "Ep:112, loss:0.00000, loss_test:0.01579, lr:3.06e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.672, tt:4482.992\n",
      "Ep:113, loss:0.00000, loss_test:0.01581, lr:3.03e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.716, tt:4527.598\n",
      "Ep:114, loss:0.00000, loss_test:0.01585, lr:3.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.732, tt:4569.222\n",
      "Ep:115, loss:0.00000, loss_test:0.01590, lr:2.97e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.726, tt:4608.246\n",
      "Ep:116, loss:0.00000, loss_test:0.01595, lr:2.94e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.735, tt:4648.968\n",
      "Ep:117, loss:0.00000, loss_test:0.01596, lr:2.91e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.736, tt:4688.879\n",
      "Ep:118, loss:0.00000, loss_test:0.01602, lr:2.88e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.735, tt:4728.450\n",
      "Ep:119, loss:0.00000, loss_test:0.01605, lr:2.85e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.739, tt:4768.666\n",
      "Ep:120, loss:0.00000, loss_test:0.01605, lr:2.82e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.749, tt:4809.621\n",
      "Ep:121, loss:0.00000, loss_test:0.01610, lr:2.80e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.746, tt:4849.056\n",
      "Ep:122, loss:0.00000, loss_test:0.01615, lr:2.77e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.744, tt:4888.523\n",
      "Ep:123, loss:0.00000, loss_test:0.01617, lr:2.74e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.742, tt:4928.067\n",
      "Ep:124, loss:0.00000, loss_test:0.01619, lr:2.71e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.754, tt:4969.244\n",
      "Ep:125, loss:0.00000, loss_test:0.01622, lr:2.69e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.760, tt:5009.766\n",
      "Ep:126, loss:0.00000, loss_test:0.01625, lr:2.66e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.757, tt:5049.126\n",
      "Ep:127, loss:0.00000, loss_test:0.01629, lr:2.63e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.758, tt:5089.057\n",
      "Ep:128, loss:0.00000, loss_test:0.01638, lr:2.61e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.747, tt:5127.387\n",
      "Ep:129, loss:0.00000, loss_test:0.01635, lr:2.58e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.750, tt:5167.522\n",
      "Ep:130, loss:0.00000, loss_test:0.01640, lr:2.55e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.747, tt:5206.894\n",
      "Ep:131, loss:0.00000, loss_test:0.01646, lr:2.53e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.727, tt:5244.029\n",
      "Ep:132, loss:0.00000, loss_test:0.01646, lr:2.50e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.734, tt:5284.628\n",
      "Ep:133, loss:0.00000, loss_test:0.01650, lr:2.48e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.744, tt:5325.656\n",
      "Ep:134, loss:0.00000, loss_test:0.01652, lr:2.45e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.761, tt:5367.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.01658, lr:2.43e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.754, tt:5406.594\n",
      "Ep:136, loss:0.00000, loss_test:0.01657, lr:2.40e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.742, tt:5444.669\n",
      "Ep:137, loss:0.00000, loss_test:0.01659, lr:2.38e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.744, tt:5484.685\n",
      "Ep:138, loss:0.00000, loss_test:0.01664, lr:2.36e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.742, tt:5524.167\n",
      "Ep:139, loss:0.00000, loss_test:0.01666, lr:2.33e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.745, tt:5564.359\n",
      "Ep:140, loss:0.00000, loss_test:0.01668, lr:2.31e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.745, tt:5604.083\n",
      "Ep:141, loss:0.00000, loss_test:0.01670, lr:2.29e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.742, tt:5643.327\n",
      "Ep:142, loss:0.00000, loss_test:0.01674, lr:2.26e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.743, tt:5683.269\n",
      "Ep:143, loss:0.00000, loss_test:0.01675, lr:2.24e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.757, tt:5725.024\n",
      "Ep:144, loss:0.00000, loss_test:0.01679, lr:2.22e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.760, tt:5765.207\n",
      "Ep:145, loss:0.00000, loss_test:0.01682, lr:2.20e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.756, tt:5804.438\n",
      "Ep:146, loss:0.00000, loss_test:0.01683, lr:2.17e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.762, tt:5845.073\n",
      "Ep:147, loss:0.00000, loss_test:0.01686, lr:2.15e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.748, tt:5882.655\n",
      "Ep:148, loss:0.00000, loss_test:0.01685, lr:2.13e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.768, tt:5925.502\n",
      "Ep:149, loss:0.00000, loss_test:0.01691, lr:2.11e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.786, tt:5967.965\n",
      "Ep:150, loss:0.00000, loss_test:0.01693, lr:2.09e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.800, tt:6009.821\n",
      "Ep:151, loss:0.00000, loss_test:0.01690, lr:2.07e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.822, tt:6052.958\n",
      "Ep:152, loss:0.00000, loss_test:0.01693, lr:2.05e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.848, tt:6096.681\n",
      "Ep:153, loss:0.00000, loss_test:0.01698, lr:2.03e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.867, tt:6139.517\n",
      "Ep:154, loss:0.00000, loss_test:0.01699, lr:2.01e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.898, tt:6184.199\n",
      "Ep:155, loss:0.00000, loss_test:0.01699, lr:1.99e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.916, tt:6226.933\n",
      "Ep:156, loss:0.00000, loss_test:0.01703, lr:1.97e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.947, tt:6271.615\n",
      "Ep:157, loss:0.00000, loss_test:0.01706, lr:1.95e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.966, tt:6314.602\n",
      "Ep:158, loss:0.00000, loss_test:0.01705, lr:1.93e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.974, tt:6355.896\n",
      "Ep:159, loss:0.00000, loss_test:0.01708, lr:1.91e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.986, tt:6397.699\n",
      "Ep:160, loss:0.00000, loss_test:0.01712, lr:1.89e-02, fs:0.74830 (r=0.632,p=0.917),  time:39.999, tt:6439.826\n",
      "Ep:161, loss:0.00000, loss_test:0.01712, lr:1.87e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.027, tt:6484.297\n",
      "Ep:162, loss:0.00000, loss_test:0.01713, lr:1.85e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.048, tt:6527.906\n",
      "Ep:163, loss:0.00000, loss_test:0.01715, lr:1.83e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.064, tt:6570.454\n",
      "Ep:164, loss:0.00000, loss_test:0.01716, lr:1.81e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.087, tt:6614.272\n",
      "Ep:165, loss:0.00000, loss_test:0.01717, lr:1.80e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.093, tt:6655.499\n",
      "Ep:166, loss:0.00000, loss_test:0.01718, lr:1.78e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.104, tt:6697.427\n",
      "Ep:167, loss:0.00000, loss_test:0.01721, lr:1.76e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.107, tt:6737.906\n",
      "Ep:168, loss:0.00000, loss_test:0.01723, lr:1.74e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.121, tt:6780.531\n",
      "Ep:169, loss:0.00000, loss_test:0.01724, lr:1.73e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.136, tt:6823.188\n",
      "Ep:170, loss:0.00000, loss_test:0.01726, lr:1.71e-02, fs:0.75676 (r=0.644,p=0.918),  time:40.150, tt:6865.687\n",
      "Ep:171, loss:0.00000, loss_test:0.01727, lr:1.69e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.150, tt:6905.831\n",
      "Ep:172, loss:0.00000, loss_test:0.01728, lr:1.67e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.141, tt:6944.351\n",
      "Ep:173, loss:0.00000, loss_test:0.01730, lr:1.66e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.145, tt:6985.208\n",
      "Ep:174, loss:0.00000, loss_test:0.01732, lr:1.64e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.141, tt:7024.687\n",
      "Ep:175, loss:0.00000, loss_test:0.01732, lr:1.62e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.141, tt:7064.893\n",
      "Ep:176, loss:0.00000, loss_test:0.01733, lr:1.61e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.145, tt:7105.716\n",
      "Ep:177, loss:0.00000, loss_test:0.01733, lr:1.59e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.148, tt:7146.379\n",
      "Ep:178, loss:0.00000, loss_test:0.01736, lr:1.58e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.153, tt:7187.394\n",
      "Ep:179, loss:0.00000, loss_test:0.01738, lr:1.56e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.159, tt:7228.677\n",
      "Ep:180, loss:0.00000, loss_test:0.01739, lr:1.54e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.169, tt:7270.583\n",
      "Ep:181, loss:0.00000, loss_test:0.01739, lr:1.53e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.173, tt:7311.563\n",
      "Ep:182, loss:0.00000, loss_test:0.01740, lr:1.51e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.172, tt:7351.433\n",
      "Ep:183, loss:0.00000, loss_test:0.01741, lr:1.50e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.170, tt:7391.356\n",
      "Ep:184, loss:0.00000, loss_test:0.01743, lr:1.48e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.181, tt:7433.519\n",
      "Ep:185, loss:0.00000, loss_test:0.01745, lr:1.47e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.165, tt:7470.708\n",
      "Ep:186, loss:0.00000, loss_test:0.01746, lr:1.45e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.158, tt:7509.557\n",
      "Ep:187, loss:0.00000, loss_test:0.01745, lr:1.44e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.163, tt:7550.640\n",
      "Ep:188, loss:0.00000, loss_test:0.01746, lr:1.43e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.167, tt:7591.486\n",
      "Ep:189, loss:0.00000, loss_test:0.01750, lr:1.41e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.182, tt:7634.557\n",
      "Ep:190, loss:0.00000, loss_test:0.01750, lr:1.40e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.184, tt:7675.174\n",
      "Ep:191, loss:0.00000, loss_test:0.01750, lr:1.38e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.173, tt:7713.274\n",
      "Ep:192, loss:0.00000, loss_test:0.01751, lr:1.37e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.172, tt:7753.196\n",
      "Ep:193, loss:0.00000, loss_test:0.01754, lr:1.36e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.175, tt:7793.960\n",
      "Ep:194, loss:0.00000, loss_test:0.01754, lr:1.34e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.155, tt:7830.151\n",
      "Ep:195, loss:0.00000, loss_test:0.01754, lr:1.33e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.155, tt:7870.310\n",
      "Ep:196, loss:0.00000, loss_test:0.01754, lr:1.32e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.151, tt:7909.729\n",
      "Ep:197, loss:0.00000, loss_test:0.01757, lr:1.30e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.148, tt:7949.392\n",
      "Ep:198, loss:0.00000, loss_test:0.01758, lr:1.29e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.143, tt:7988.376\n",
      "Ep:199, loss:0.00000, loss_test:0.01759, lr:1.28e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.139, tt:8027.886\n",
      "Ep:200, loss:0.00000, loss_test:0.01759, lr:1.26e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.134, tt:8066.922\n",
      "Ep:201, loss:0.00000, loss_test:0.01760, lr:1.25e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.118, tt:8103.785\n",
      "Ep:202, loss:0.00000, loss_test:0.01761, lr:1.24e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.110, tt:8142.325\n",
      "Ep:203, loss:0.00000, loss_test:0.01761, lr:1.23e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.108, tt:8182.134\n",
      "Ep:204, loss:0.00000, loss_test:0.01763, lr:1.21e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.100, tt:8220.435\n",
      "Ep:205, loss:0.00000, loss_test:0.01763, lr:1.20e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.094, tt:8259.458\n",
      "Ep:206, loss:0.00000, loss_test:0.01763, lr:1.19e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.074, tt:8295.307\n",
      "Ep:207, loss:0.00000, loss_test:0.01764, lr:1.18e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.070, tt:8334.502\n",
      "Ep:208, loss:0.00000, loss_test:0.01765, lr:1.17e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.057, tt:8371.873\n",
      "Ep:209, loss:0.00000, loss_test:0.01766, lr:1.15e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.045, tt:8409.387\n",
      "Model and results saved\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14204, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:31.031, tt:31.031\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14014, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:31.990, tt:63.980\n",
      "Ep:2, loss:0.00027, loss_test:0.13629, lr:1.00e-02, fs:0.66148 (r=0.977,p=0.500),  time:34.548, tt:103.643\n",
      "Ep:3, loss:0.00026, loss_test:0.12904, lr:1.00e-02, fs:0.66935 (r=0.954,p=0.516),  time:36.328, tt:145.310\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11835, lr:1.00e-02, fs:0.68545 (r=0.839,p=0.579),  time:37.125, tt:185.626\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11201, lr:1.00e-02, fs:0.68539 (r=0.701,p=0.670),  time:38.168, tt:229.010\n",
      "Ep:6, loss:0.00022, loss_test:0.10974, lr:1.00e-02, fs:0.66310 (r=0.713,p=0.620),  time:38.351, tt:268.459\n",
      "Ep:7, loss:0.00022, loss_test:0.11032, lr:1.00e-02, fs:0.70476 (r=0.851,p=0.602),  time:39.491, tt:315.925\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10620, lr:1.00e-02, fs:0.72115 (r=0.862,p=0.620),  time:39.713, tt:357.417\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.09960, lr:1.00e-02, fs:0.72727 (r=0.782,p=0.680),  time:40.050, tt:400.495\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09634, lr:1.00e-02, fs:0.70455 (r=0.713,p=0.697),  time:40.186, tt:442.051\n",
      "Ep:11, loss:0.00019, loss_test:0.09400, lr:1.00e-02, fs:0.77083 (r=0.851,p=0.705),  time:40.355, tt:484.257\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09046, lr:1.00e-02, fs:0.78919 (r=0.839,p=0.745),  time:40.527, tt:526.852\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.08834, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:40.722, tt:570.114\n",
      "Ep:14, loss:0.00017, loss_test:0.08647, lr:1.00e-02, fs:0.79348 (r=0.839,p=0.753),  time:40.710, tt:610.657\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08376, lr:1.00e-02, fs:0.81081 (r=0.862,p=0.765),  time:40.780, tt:652.486\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08242, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:40.711, tt:692.079\n",
      "Ep:17, loss:0.00015, loss_test:0.08105, lr:1.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:40.715, tt:732.871\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08028, lr:1.00e-02, fs:0.77714 (r=0.782,p=0.773),  time:40.749, tt:774.223\n",
      "Ep:19, loss:0.00014, loss_test:0.07845, lr:1.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:40.777, tt:815.549\n",
      "Ep:20, loss:0.00013, loss_test:0.07822, lr:1.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.950, tt:859.944\n",
      "Ep:21, loss:0.00012, loss_test:0.07648, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:41.039, tt:902.848\n",
      "Ep:22, loss:0.00012, loss_test:0.07682, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:41.094, tt:945.163\n",
      "Ep:23, loss:0.00011, loss_test:0.07430, lr:1.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:41.196, tt:988.698\n",
      "Ep:24, loss:0.00010, loss_test:0.07554, lr:1.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:41.219, tt:1030.480\n",
      "Ep:25, loss:0.00010, loss_test:0.07128, lr:1.00e-02, fs:0.79070 (r=0.782,p=0.800),  time:41.186, tt:1070.843\n",
      "Ep:26, loss:0.00009, loss_test:0.07234, lr:1.00e-02, fs:0.78788 (r=0.747,p=0.833),  time:41.288, tt:1114.769\n",
      "Ep:27, loss:0.00009, loss_test:0.07266, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.402, tt:1159.245\n",
      "Ep:28, loss:0.00008, loss_test:0.06907, lr:1.00e-02, fs:0.78788 (r=0.747,p=0.833),  time:41.410, tt:1200.904\n",
      "Ep:29, loss:0.00008, loss_test:0.06953, lr:9.90e-03, fs:0.80982 (r=0.759,p=0.868),  time:41.414, tt:1242.407\n",
      "Ep:30, loss:0.00007, loss_test:0.07435, lr:9.80e-03, fs:0.79245 (r=0.724,p=0.875),  time:41.449, tt:1284.911\n",
      "Ep:31, loss:0.00007, loss_test:0.06741, lr:9.70e-03, fs:0.79755 (r=0.747,p=0.855),  time:41.502, tt:1328.058\n",
      "Ep:32, loss:0.00006, loss_test:0.06984, lr:9.61e-03, fs:0.80745 (r=0.747,p=0.878),  time:41.515, tt:1369.988\n",
      "Ep:33, loss:0.00006, loss_test:0.07082, lr:9.51e-03, fs:0.80000 (r=0.736,p=0.877),  time:41.549, tt:1412.664\n",
      "Ep:34, loss:0.00005, loss_test:0.06767, lr:9.41e-03, fs:0.80745 (r=0.747,p=0.878),  time:41.578, tt:1455.232\n",
      "Ep:35, loss:0.00005, loss_test:0.07169, lr:9.32e-03, fs:0.81761 (r=0.747,p=0.903),  time:41.629, tt:1498.659\n",
      "Ep:36, loss:0.00005, loss_test:0.07147, lr:9.23e-03, fs:0.81250 (r=0.747,p=0.890),  time:41.677, tt:1542.031\n",
      "Ep:37, loss:0.00004, loss_test:0.07105, lr:9.14e-03, fs:0.80745 (r=0.747,p=0.878),  time:41.709, tt:1584.938\n",
      "Ep:38, loss:0.00004, loss_test:0.07257, lr:9.04e-03, fs:0.81761 (r=0.747,p=0.903),  time:41.764, tt:1628.804\n",
      "Ep:39, loss:0.00004, loss_test:0.07016, lr:8.95e-03, fs:0.79747 (r=0.724,p=0.887),  time:41.797, tt:1671.863\n",
      "Ep:40, loss:0.00004, loss_test:0.07111, lr:8.86e-03, fs:0.82500 (r=0.759,p=0.904),  time:41.808, tt:1714.110\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.07830, lr:8.86e-03, fs:0.83019 (r=0.759,p=0.917),  time:41.799, tt:1755.572\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.07142, lr:8.86e-03, fs:0.81988 (r=0.759,p=0.892),  time:41.817, tt:1798.138\n",
      "Ep:43, loss:0.00003, loss_test:0.08007, lr:8.86e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.842, tt:1841.063\n",
      "Ep:44, loss:0.00003, loss_test:0.07044, lr:8.86e-03, fs:0.81761 (r=0.747,p=0.903),  time:41.888, tt:1884.966\n",
      "Ep:45, loss:0.00003, loss_test:0.08137, lr:8.86e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.856, tt:1925.368\n",
      "Ep:46, loss:0.00003, loss_test:0.07252, lr:8.86e-03, fs:0.82500 (r=0.759,p=0.904),  time:41.893, tt:1968.948\n",
      "Ep:47, loss:0.00002, loss_test:0.08179, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.923, tt:2012.284\n",
      "Ep:48, loss:0.00002, loss_test:0.07262, lr:8.86e-03, fs:0.83019 (r=0.759,p=0.917),  time:41.919, tt:2054.028\n",
      "Ep:49, loss:0.00002, loss_test:0.07911, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.917, tt:2095.860\n",
      "Ep:50, loss:0.00002, loss_test:0.07739, lr:8.86e-03, fs:0.82803 (r=0.747,p=0.929),  time:41.922, tt:2138.026\n",
      "Ep:51, loss:0.00002, loss_test:0.08165, lr:8.86e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.907, tt:2179.165\n",
      "Ep:52, loss:0.00002, loss_test:0.07436, lr:8.86e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.910, tt:2221.243\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.08560, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.913, tt:2263.281\n",
      "Ep:54, loss:0.00001, loss_test:0.07597, lr:8.86e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.879, tt:2303.324\n",
      "Ep:55, loss:0.00001, loss_test:0.08512, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.891, tt:2345.873\n",
      "Ep:56, loss:0.00001, loss_test:0.07846, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.903, tt:2388.484\n",
      "Ep:57, loss:0.00001, loss_test:0.08089, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.888, tt:2429.532\n",
      "Ep:58, loss:0.00001, loss_test:0.08277, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.897, tt:2471.939\n",
      "Ep:59, loss:0.00001, loss_test:0.07899, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.886, tt:2513.154\n",
      "Ep:60, loss:0.00001, loss_test:0.08459, lr:8.86e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.894, tt:2555.550\n",
      "Ep:61, loss:0.00001, loss_test:0.07852, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.893, tt:2597.393\n",
      "Ep:62, loss:0.00001, loss_test:0.08664, lr:8.86e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.868, tt:2637.693\n",
      "Ep:63, loss:0.00001, loss_test:0.08263, lr:8.86e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.868, tt:2679.528\n",
      "Ep:64, loss:0.00001, loss_test:0.08339, lr:8.78e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.842, tt:2719.744\n",
      "Ep:65, loss:0.00001, loss_test:0.08304, lr:8.69e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.810, tt:2759.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00001, loss_test:0.08238, lr:8.60e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.794, tt:2800.186\n",
      "Ep:67, loss:0.00001, loss_test:0.08442, lr:8.51e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.775, tt:2840.716\n",
      "Ep:68, loss:0.00001, loss_test:0.08072, lr:8.43e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.729, tt:2879.272\n",
      "Ep:69, loss:0.00001, loss_test:0.08537, lr:8.35e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.736, tt:2921.511\n",
      "Ep:70, loss:0.00001, loss_test:0.08539, lr:8.26e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.724, tt:2962.387\n",
      "Ep:71, loss:0.00001, loss_test:0.08270, lr:8.18e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.739, tt:3005.222\n",
      "Ep:72, loss:0.00001, loss_test:0.08511, lr:8.10e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.719, tt:3045.483\n",
      "Ep:73, loss:0.00001, loss_test:0.08211, lr:8.02e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.721, tt:3087.362\n",
      "Ep:74, loss:0.00000, loss_test:0.08378, lr:7.94e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.714, tt:3128.577\n",
      "Ep:75, loss:0.00000, loss_test:0.08265, lr:7.86e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.706, tt:3169.640\n",
      "Ep:76, loss:0.00000, loss_test:0.08213, lr:7.78e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.715, tt:3212.035\n",
      "Ep:77, loss:0.00000, loss_test:0.08281, lr:7.70e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.723, tt:3254.406\n",
      "Ep:78, loss:0.00000, loss_test:0.08135, lr:7.62e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.715, tt:3295.469\n",
      "Ep:79, loss:0.00000, loss_test:0.08480, lr:7.55e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.720, tt:3337.592\n",
      "Ep:80, loss:0.00000, loss_test:0.08119, lr:7.47e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.714, tt:3378.824\n",
      "Ep:81, loss:0.00000, loss_test:0.08379, lr:7.40e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.713, tt:3420.467\n",
      "Ep:82, loss:0.00000, loss_test:0.08330, lr:7.32e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.690, tt:3460.234\n",
      "Ep:83, loss:0.00000, loss_test:0.08110, lr:7.25e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.659, tt:3499.323\n",
      "Ep:84, loss:0.00000, loss_test:0.08339, lr:7.18e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.639, tt:3539.333\n",
      "Ep:85, loss:0.00000, loss_test:0.08137, lr:7.11e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.652, tt:3582.057\n",
      "Ep:86, loss:0.00000, loss_test:0.08252, lr:7.03e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.634, tt:3622.200\n",
      "Ep:87, loss:0.00000, loss_test:0.08126, lr:6.96e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.628, tt:3663.286\n",
      "Ep:88, loss:0.00000, loss_test:0.08165, lr:6.89e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.599, tt:3702.314\n",
      "Ep:89, loss:0.00000, loss_test:0.08264, lr:6.83e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.580, tt:3742.182\n",
      "Ep:90, loss:0.00000, loss_test:0.08118, lr:6.76e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.559, tt:3781.892\n",
      "Ep:91, loss:0.00000, loss_test:0.08130, lr:6.69e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.547, tt:3822.311\n",
      "Ep:92, loss:0.00000, loss_test:0.08232, lr:6.62e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.528, tt:3862.098\n",
      "Ep:93, loss:0.00000, loss_test:0.08224, lr:6.56e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.513, tt:3902.218\n",
      "Ep:94, loss:0.00000, loss_test:0.08079, lr:6.49e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.498, tt:3942.269\n",
      "Ep:95, loss:0.00000, loss_test:0.08150, lr:6.43e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.465, tt:3980.687\n",
      "Ep:96, loss:0.00000, loss_test:0.08137, lr:6.36e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.476, tt:4023.186\n",
      "Ep:97, loss:0.00000, loss_test:0.08224, lr:6.30e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.461, tt:4063.141\n",
      "Ep:98, loss:0.00000, loss_test:0.08035, lr:6.24e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.433, tt:4101.913\n",
      "Ep:99, loss:0.00000, loss_test:0.08184, lr:6.17e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.408, tt:4140.761\n",
      "Ep:100, loss:0.00000, loss_test:0.08209, lr:6.11e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.385, tt:4179.932\n",
      "Ep:101, loss:0.00000, loss_test:0.08029, lr:6.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.357, tt:4218.463\n",
      "Ep:102, loss:0.00000, loss_test:0.08247, lr:5.99e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.349, tt:4258.991\n",
      "Ep:103, loss:0.00000, loss_test:0.08111, lr:5.93e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.345, tt:4299.878\n",
      "Ep:104, loss:0.00000, loss_test:0.08119, lr:5.87e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.341, tt:4340.769\n",
      "Ep:105, loss:0.00000, loss_test:0.08243, lr:5.81e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.337, tt:4381.684\n",
      "Ep:106, loss:0.00000, loss_test:0.08083, lr:5.75e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.323, tt:4421.594\n",
      "Ep:107, loss:0.00000, loss_test:0.08145, lr:5.70e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.327, tt:4463.277\n",
      "Ep:108, loss:0.00000, loss_test:0.08153, lr:5.64e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.313, tt:4503.087\n",
      "Ep:109, loss:0.00000, loss_test:0.08052, lr:5.58e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.298, tt:4542.831\n",
      "Ep:110, loss:0.00000, loss_test:0.08163, lr:5.53e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.271, tt:4581.095\n",
      "Ep:111, loss:0.00000, loss_test:0.08140, lr:5.47e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.267, tt:4621.858\n",
      "Ep:112, loss:0.00000, loss_test:0.08014, lr:5.42e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.305, tt:4667.410\n",
      "Ep:113, loss:0.00000, loss_test:0.08206, lr:5.36e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.304, tt:4708.615\n",
      "Ep:114, loss:0.00000, loss_test:0.08092, lr:5.31e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.278, tt:4746.972\n",
      "Ep:115, loss:0.00000, loss_test:0.08051, lr:5.26e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.279, tt:4788.391\n",
      "Ep:116, loss:0.00000, loss_test:0.08164, lr:5.20e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.261, tt:4827.558\n",
      "Ep:117, loss:0.00000, loss_test:0.08058, lr:5.15e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.255, tt:4868.126\n",
      "Ep:118, loss:0.00000, loss_test:0.08160, lr:5.10e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.256, tt:4909.426\n",
      "Ep:119, loss:0.00000, loss_test:0.08153, lr:5.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.254, tt:4950.462\n",
      "Ep:120, loss:0.00000, loss_test:0.08096, lr:5.00e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.261, tt:4992.540\n",
      "Ep:121, loss:0.00000, loss_test:0.08122, lr:4.95e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.247, tt:5032.087\n",
      "Ep:122, loss:0.00000, loss_test:0.08107, lr:4.90e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.246, tt:5073.215\n",
      "Ep:123, loss:0.00000, loss_test:0.08085, lr:4.85e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.242, tt:5113.981\n",
      "Ep:124, loss:0.00000, loss_test:0.08115, lr:4.80e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.231, tt:5153.872\n",
      "Ep:125, loss:0.00000, loss_test:0.08241, lr:4.75e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.223, tt:5194.104\n",
      "Ep:126, loss:0.00000, loss_test:0.08063, lr:4.71e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.211, tt:5233.836\n",
      "Ep:127, loss:0.00000, loss_test:0.08128, lr:4.66e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.201, tt:5273.719\n",
      "Ep:128, loss:0.00000, loss_test:0.08114, lr:4.61e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.200, tt:5314.738\n",
      "Ep:129, loss:0.00000, loss_test:0.08128, lr:4.57e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.198, tt:5355.708\n",
      "Ep:130, loss:0.00000, loss_test:0.08017, lr:4.52e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.190, tt:5395.831\n",
      "Ep:131, loss:0.00000, loss_test:0.08052, lr:4.48e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.177, tt:5435.325\n",
      "Ep:132, loss:0.00000, loss_test:0.08121, lr:4.43e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.179, tt:5476.831\n",
      "Ep:133, loss:0.00000, loss_test:0.08082, lr:4.39e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.220, tt:5523.510\n",
      "Ep:134, loss:0.00000, loss_test:0.07990, lr:4.34e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.228, tt:5565.820\n",
      "Ep:135, loss:0.00000, loss_test:0.08109, lr:4.30e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.227, tt:5606.897\n",
      "Ep:136, loss:0.00000, loss_test:0.08083, lr:4.26e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.235, tt:5649.257\n",
      "Ep:137, loss:0.00000, loss_test:0.08098, lr:4.21e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.233, tt:5690.092\n",
      "Ep:138, loss:0.00000, loss_test:0.08093, lr:4.17e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.242, tt:5732.663\n",
      "Ep:139, loss:0.00000, loss_test:0.08197, lr:4.13e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.241, tt:5773.794\n",
      "Ep:140, loss:0.00000, loss_test:0.08083, lr:4.09e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.253, tt:5816.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.07936, lr:4.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.242, tt:5856.375\n",
      "Ep:142, loss:0.00000, loss_test:0.08124, lr:4.01e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.223, tt:5894.935\n",
      "Ep:143, loss:0.00000, loss_test:0.08108, lr:3.97e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.220, tt:5935.652\n",
      "Ep:144, loss:0.00000, loss_test:0.08046, lr:3.93e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.214, tt:5975.962\n",
      "Ep:145, loss:0.00000, loss_test:0.08118, lr:3.89e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.219, tt:6017.985\n",
      "Ep:146, loss:0.00000, loss_test:0.08017, lr:3.85e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.219, tt:6059.137\n",
      "Ep:147, loss:0.00000, loss_test:0.07987, lr:3.81e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.211, tt:6099.263\n",
      "Ep:148, loss:0.00000, loss_test:0.08102, lr:3.77e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.216, tt:6141.233\n",
      "Ep:149, loss:0.00000, loss_test:0.08012, lr:3.73e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.217, tt:6182.504\n",
      "Ep:150, loss:0.00000, loss_test:0.08021, lr:3.70e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.212, tt:6223.052\n",
      "Ep:151, loss:0.00000, loss_test:0.08122, lr:3.66e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.219, tt:6265.276\n",
      "Ep:152, loss:0.00000, loss_test:0.08191, lr:3.62e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.217, tt:6306.194\n",
      "Ep:153, loss:0.00000, loss_test:0.08103, lr:3.59e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.240, tt:6350.990\n",
      "Ep:154, loss:0.00000, loss_test:0.08002, lr:3.55e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.233, tt:6391.172\n",
      "Ep:155, loss:0.00000, loss_test:0.08047, lr:3.52e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.240, tt:6433.419\n",
      "Ep:156, loss:0.00000, loss_test:0.08126, lr:3.48e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.248, tt:6475.865\n",
      "Ep:157, loss:0.00000, loss_test:0.08013, lr:3.45e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.251, tt:6517.627\n",
      "Ep:158, loss:0.00000, loss_test:0.08000, lr:3.41e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.246, tt:6558.177\n",
      "Ep:159, loss:0.00000, loss_test:0.08007, lr:3.38e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.233, tt:6597.232\n",
      "Ep:160, loss:0.00000, loss_test:0.08007, lr:3.34e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.227, tt:6637.568\n",
      "Ep:161, loss:0.00000, loss_test:0.08047, lr:3.31e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.226, tt:6678.603\n",
      "Ep:162, loss:0.00000, loss_test:0.08011, lr:3.28e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.233, tt:6720.979\n",
      "Ep:163, loss:0.00000, loss_test:0.08011, lr:3.24e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.240, tt:6763.359\n",
      "Ep:164, loss:0.00000, loss_test:0.08043, lr:3.21e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.236, tt:6803.971\n",
      "Ep:165, loss:0.00000, loss_test:0.08015, lr:3.18e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.236, tt:6845.101\n",
      "Ep:166, loss:0.00000, loss_test:0.08048, lr:3.15e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.223, tt:6884.283\n",
      "Ep:167, loss:0.00000, loss_test:0.08082, lr:3.12e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.225, tt:6925.811\n",
      "Ep:168, loss:0.00000, loss_test:0.08031, lr:3.09e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.220, tt:6966.099\n",
      "Ep:169, loss:0.00000, loss_test:0.08031, lr:3.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.219, tt:7007.169\n",
      "Ep:170, loss:0.00000, loss_test:0.07986, lr:3.02e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.217, tt:7048.187\n",
      "Ep:171, loss:0.00000, loss_test:0.08061, lr:2.99e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.218, tt:7089.447\n",
      "Ep:172, loss:0.00000, loss_test:0.08038, lr:2.96e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.233, tt:7133.277\n",
      "Ep:173, loss:0.00000, loss_test:0.07983, lr:2.93e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.232, tt:7174.387\n",
      "Ep:174, loss:0.00000, loss_test:0.08035, lr:2.90e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.264, tt:7221.257\n",
      "Ep:175, loss:0.00000, loss_test:0.08004, lr:2.88e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.261, tt:7262.014\n",
      "Ep:176, loss:0.00000, loss_test:0.07971, lr:2.85e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.270, tt:7304.811\n",
      "Ep:177, loss:0.00000, loss_test:0.07994, lr:2.82e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.276, tt:7347.053\n",
      "Ep:178, loss:0.00000, loss_test:0.07992, lr:2.79e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.285, tt:7389.925\n",
      "Ep:179, loss:0.00000, loss_test:0.08026, lr:2.76e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.290, tt:7432.112\n",
      "Ep:180, loss:0.00000, loss_test:0.08036, lr:2.73e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.299, tt:7475.172\n",
      "Ep:181, loss:0.00000, loss_test:0.07988, lr:2.71e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.309, tt:7518.223\n",
      "Ep:182, loss:0.00000, loss_test:0.07994, lr:2.68e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.308, tt:7559.373\n",
      "Ep:183, loss:0.00000, loss_test:0.07984, lr:2.65e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.316, tt:7602.168\n",
      "Ep:184, loss:0.00000, loss_test:0.07973, lr:2.63e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.320, tt:7644.175\n",
      "Ep:185, loss:0.00000, loss_test:0.08014, lr:2.60e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.316, tt:7684.699\n",
      "Ep:186, loss:0.00000, loss_test:0.08010, lr:2.57e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.317, tt:7726.318\n",
      "Ep:187, loss:0.00000, loss_test:0.07987, lr:2.55e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.318, tt:7767.797\n",
      "Ep:188, loss:0.00000, loss_test:0.08035, lr:2.52e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.318, tt:7809.089\n",
      "Ep:189, loss:0.00000, loss_test:0.08023, lr:2.50e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.315, tt:7849.908\n",
      "Ep:190, loss:0.00000, loss_test:0.07974, lr:2.47e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.301, tt:7888.508\n",
      "Ep:191, loss:0.00000, loss_test:0.07986, lr:2.45e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.304, tt:7930.455\n",
      "Ep:192, loss:0.00000, loss_test:0.07976, lr:2.42e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.312, tt:7973.129\n",
      "Ep:193, loss:0.00000, loss_test:0.07966, lr:2.40e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.313, tt:8014.770\n",
      "Ep:194, loss:0.00000, loss_test:0.08007, lr:2.38e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.343, tt:8061.914\n",
      "Ep:195, loss:0.00000, loss_test:0.07998, lr:2.35e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.351, tt:8104.759\n",
      "Ep:196, loss:0.00000, loss_test:0.07970, lr:2.33e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.366, tt:8149.127\n",
      "Ep:197, loss:0.00000, loss_test:0.08015, lr:2.31e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.357, tt:8188.595\n",
      "Ep:198, loss:0.00000, loss_test:0.08056, lr:2.28e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.369, tt:8232.493\n",
      "Ep:199, loss:0.00000, loss_test:0.08011, lr:2.26e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.376, tt:8275.244\n",
      "Ep:200, loss:0.00000, loss_test:0.07968, lr:2.24e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.378, tt:8317.006\n",
      "Ep:201, loss:0.00000, loss_test:0.08033, lr:2.21e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.379, tt:8358.536\n",
      "Ep:202, loss:0.00000, loss_test:0.08070, lr:2.19e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.380, tt:8400.107\n",
      "Ep:203, loss:0.00000, loss_test:0.08034, lr:2.17e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.392, tt:8443.974\n",
      "Ep:204, loss:0.00000, loss_test:0.07974, lr:2.15e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.396, tt:8486.244\n",
      "Ep:205, loss:0.00000, loss_test:0.08014, lr:2.13e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.374, tt:8523.094\n",
      "Ep:206, loss:0.00000, loss_test:0.08070, lr:2.11e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.341, tt:8557.608\n",
      "Ep:207, loss:0.00000, loss_test:0.08038, lr:2.08e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.327, tt:8596.034\n",
      "Ep:208, loss:0.00000, loss_test:0.07963, lr:2.06e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.304, tt:8632.468\n",
      "Ep:209, loss:0.00000, loss_test:0.07985, lr:2.04e-03, fs:0.81081 (r=0.690,p=0.984),  time:41.286, tt:8669.975\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02077, lr:6.00e-02, fs:0.65079 (r=0.943,p=0.497),  time:22.351, tt:22.351\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02452, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.961, tt:39.922\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.496, tt:58.487\n",
      "Ep:3, loss:0.00005, loss_test:0.02522, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.480, tt:81.921\n",
      "Ep:4, loss:0.00005, loss_test:0.02392, lr:6.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:21.821, tt:109.104\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02234, lr:6.00e-02, fs:0.66400 (r=0.954,p=0.509),  time:22.959, tt:137.756\n",
      "Ep:6, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66116 (r=0.920,p=0.516),  time:23.576, tt:165.029\n",
      "Ep:7, loss:0.00004, loss_test:0.02063, lr:6.00e-02, fs:0.65487 (r=0.851,p=0.532),  time:24.472, tt:195.777\n",
      "Ep:8, loss:0.00004, loss_test:0.01990, lr:6.00e-02, fs:0.66667 (r=0.862,p=0.543),  time:24.784, tt:223.053\n",
      "Ep:9, loss:0.00004, loss_test:0.01909, lr:6.00e-02, fs:0.68398 (r=0.908,p=0.549),  time:25.258, tt:252.580\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.68619 (r=0.943,p=0.539),  time:25.420, tt:279.616\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01813, lr:6.00e-02, fs:0.66946 (r=0.920,p=0.526),  time:25.859, tt:310.305\n",
      "Ep:12, loss:0.00003, loss_test:0.01747, lr:6.00e-02, fs:0.67532 (r=0.897,p=0.542),  time:26.215, tt:340.796\n",
      "Ep:13, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.70270 (r=0.897,p=0.578),  time:26.481, tt:370.733\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.75926 (r=0.943,p=0.636),  time:26.757, tt:401.350\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.75799 (r=0.954,p=0.629),  time:26.938, tt:431.008\n",
      "Ep:16, loss:0.00003, loss_test:0.01570, lr:6.00e-02, fs:0.76147 (r=0.954,p=0.634),  time:27.126, tt:461.147\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01534, lr:6.00e-02, fs:0.77273 (r=0.977,p=0.639),  time:27.229, tt:490.131\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.80569 (r=0.977,p=0.685),  time:27.460, tt:521.746\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.80193 (r=0.954,p=0.692),  time:27.724, tt:554.486\n",
      "Ep:20, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.81188 (r=0.943,p=0.713),  time:27.951, tt:586.966\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.81373 (r=0.954,p=0.709),  time:28.090, tt:617.981\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.81553 (r=0.966,p=0.706),  time:28.148, tt:647.395\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.81373 (r=0.954,p=0.709),  time:28.249, tt:677.966\n",
      "Ep:24, loss:0.00002, loss_test:0.01375, lr:6.00e-02, fs:0.81818 (r=0.931,p=0.730),  time:28.391, tt:709.778\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.83077 (r=0.931,p=0.750),  time:28.546, tt:742.201\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01337, lr:6.00e-02, fs:0.83938 (r=0.931,p=0.764),  time:28.565, tt:771.254\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.84536 (r=0.943,p=0.766),  time:28.637, tt:801.826\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.84375 (r=0.931,p=0.771),  time:28.693, tt:832.098\n",
      "Ep:29, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.85263 (r=0.931,p=0.786),  time:28.807, tt:864.201\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01304, lr:6.00e-02, fs:0.84656 (r=0.920,p=0.784),  time:28.975, tt:898.240\n",
      "Ep:31, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.84043 (r=0.908,p=0.782),  time:29.007, tt:928.235\n",
      "Ep:32, loss:0.00002, loss_test:0.01288, lr:6.00e-02, fs:0.83422 (r=0.897,p=0.780),  time:29.063, tt:959.084\n",
      "Ep:33, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.83243 (r=0.885,p=0.786),  time:29.081, tt:988.762\n",
      "Ep:34, loss:0.00001, loss_test:0.01282, lr:6.00e-02, fs:0.81319 (r=0.851,p=0.779),  time:29.098, tt:1018.441\n",
      "Ep:35, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:29.058, tt:1046.078\n",
      "Ep:36, loss:0.00001, loss_test:0.01277, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:29.104, tt:1076.841\n",
      "Ep:37, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.151, tt:1107.756\n",
      "Ep:38, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.167, tt:1137.529\n",
      "Ep:39, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.274, tt:1170.951\n",
      "Ep:40, loss:0.00001, loss_test:0.01262, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.321, tt:1202.172\n",
      "Ep:41, loss:0.00001, loss_test:0.01258, lr:5.94e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.347, tt:1232.589\n",
      "Ep:42, loss:0.00001, loss_test:0.01258, lr:5.88e-02, fs:0.80000 (r=0.805,p=0.795),  time:29.433, tt:1265.608\n",
      "Ep:43, loss:0.00001, loss_test:0.01257, lr:5.82e-02, fs:0.79310 (r=0.793,p=0.793),  time:29.436, tt:1295.191\n",
      "Ep:44, loss:0.00001, loss_test:0.01260, lr:5.76e-02, fs:0.78363 (r=0.770,p=0.798),  time:29.456, tt:1325.529\n",
      "Ep:45, loss:0.00001, loss_test:0.01268, lr:5.71e-02, fs:0.77647 (r=0.759,p=0.795),  time:29.448, tt:1354.592\n",
      "Ep:46, loss:0.00001, loss_test:0.01267, lr:5.65e-02, fs:0.78107 (r=0.759,p=0.805),  time:29.450, tt:1384.143\n",
      "Ep:47, loss:0.00001, loss_test:0.01266, lr:5.59e-02, fs:0.77381 (r=0.747,p=0.802),  time:29.504, tt:1416.171\n",
      "Ep:48, loss:0.00001, loss_test:0.01266, lr:5.54e-02, fs:0.77381 (r=0.747,p=0.802),  time:29.521, tt:1446.514\n",
      "Ep:49, loss:0.00001, loss_test:0.01271, lr:5.48e-02, fs:0.77844 (r=0.747,p=0.812),  time:29.549, tt:1477.441\n",
      "Ep:50, loss:0.00001, loss_test:0.01279, lr:5.43e-02, fs:0.79268 (r=0.747,p=0.844),  time:29.532, tt:1506.125\n",
      "Ep:51, loss:0.00001, loss_test:0.01284, lr:5.37e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.491, tt:1533.554\n",
      "Ep:52, loss:0.00001, loss_test:0.01284, lr:5.32e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.502, tt:1563.588\n",
      "Ep:53, loss:0.00001, loss_test:0.01287, lr:5.27e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.537, tt:1594.987\n",
      "Ep:54, loss:0.00001, loss_test:0.01295, lr:5.21e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.568, tt:1626.242\n",
      "Ep:55, loss:0.00001, loss_test:0.01303, lr:5.16e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.604, tt:1657.810\n",
      "Ep:56, loss:0.00001, loss_test:0.01304, lr:5.11e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.620, tt:1688.363\n",
      "Ep:57, loss:0.00001, loss_test:0.01312, lr:5.06e-02, fs:0.77778 (r=0.724,p=0.840),  time:29.609, tt:1717.318\n",
      "Ep:58, loss:0.00001, loss_test:0.01324, lr:5.01e-02, fs:0.78261 (r=0.724,p=0.851),  time:29.603, tt:1746.589\n",
      "Ep:59, loss:0.00001, loss_test:0.01327, lr:4.96e-02, fs:0.78750 (r=0.724,p=0.863),  time:29.640, tt:1778.421\n",
      "Ep:60, loss:0.00001, loss_test:0.01340, lr:4.91e-02, fs:0.78750 (r=0.724,p=0.863),  time:29.657, tt:1809.108\n",
      "Ep:61, loss:0.00001, loss_test:0.01338, lr:4.86e-02, fs:0.77987 (r=0.713,p=0.861),  time:29.630, tt:1837.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01349, lr:4.81e-02, fs:0.77987 (r=0.713,p=0.861),  time:29.603, tt:1865.005\n",
      "Ep:63, loss:0.00001, loss_test:0.01359, lr:4.76e-02, fs:0.78481 (r=0.713,p=0.873),  time:29.587, tt:1893.549\n",
      "Ep:64, loss:0.00001, loss_test:0.01356, lr:4.71e-02, fs:0.78481 (r=0.713,p=0.873),  time:29.587, tt:1923.185\n",
      "Ep:65, loss:0.00001, loss_test:0.01376, lr:4.67e-02, fs:0.77707 (r=0.701,p=0.871),  time:29.603, tt:1953.789\n",
      "Ep:66, loss:0.00001, loss_test:0.01371, lr:4.62e-02, fs:0.77707 (r=0.701,p=0.871),  time:29.601, tt:1983.284\n",
      "Ep:67, loss:0.00001, loss_test:0.01380, lr:4.57e-02, fs:0.78205 (r=0.701,p=0.884),  time:29.591, tt:2012.181\n",
      "Ep:68, loss:0.00001, loss_test:0.01396, lr:4.53e-02, fs:0.78205 (r=0.701,p=0.884),  time:29.584, tt:2041.303\n",
      "Ep:69, loss:0.00001, loss_test:0.01404, lr:4.48e-02, fs:0.78205 (r=0.701,p=0.884),  time:29.590, tt:2071.285\n",
      "Ep:70, loss:0.00001, loss_test:0.01407, lr:4.44e-02, fs:0.78205 (r=0.701,p=0.884),  time:29.603, tt:2101.788\n",
      "Ep:71, loss:0.00000, loss_test:0.01417, lr:4.39e-02, fs:0.78205 (r=0.701,p=0.884),  time:29.629, tt:2133.255\n",
      "Ep:72, loss:0.00000, loss_test:0.01419, lr:4.35e-02, fs:0.78205 (r=0.701,p=0.884),  time:29.624, tt:2162.546\n",
      "Ep:73, loss:0.00000, loss_test:0.01432, lr:4.31e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.614, tt:2191.439\n",
      "Ep:74, loss:0.00000, loss_test:0.01435, lr:4.26e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.601, tt:2220.062\n",
      "Ep:75, loss:0.00000, loss_test:0.01440, lr:4.22e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.642, tt:2252.783\n",
      "Ep:76, loss:0.00000, loss_test:0.01449, lr:4.18e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.641, tt:2282.337\n",
      "Ep:77, loss:0.00000, loss_test:0.01453, lr:4.14e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.637, tt:2311.661\n",
      "Ep:78, loss:0.00000, loss_test:0.01465, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.616, tt:2339.676\n",
      "Ep:79, loss:0.00000, loss_test:0.01469, lr:4.05e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.599, tt:2367.927\n",
      "Ep:80, loss:0.00000, loss_test:0.01475, lr:4.01e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.614, tt:2398.694\n",
      "Ep:81, loss:0.00000, loss_test:0.01481, lr:3.97e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.610, tt:2428.059\n",
      "Ep:82, loss:0.00000, loss_test:0.01484, lr:3.93e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.586, tt:2455.662\n",
      "Ep:83, loss:0.00000, loss_test:0.01495, lr:3.89e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.593, tt:2485.846\n",
      "Ep:84, loss:0.00000, loss_test:0.01494, lr:3.86e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.573, tt:2513.723\n",
      "Ep:85, loss:0.00000, loss_test:0.01504, lr:3.82e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.587, tt:2544.479\n",
      "Ep:86, loss:0.00000, loss_test:0.01512, lr:3.78e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.578, tt:2573.316\n",
      "Ep:87, loss:0.00000, loss_test:0.01509, lr:3.74e-02, fs:0.78710 (r=0.701,p=0.897),  time:29.556, tt:2600.908\n",
      "Ep:88, loss:0.00000, loss_test:0.01524, lr:3.70e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.563, tt:2631.140\n",
      "Ep:89, loss:0.00000, loss_test:0.01532, lr:3.67e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.569, tt:2661.247\n",
      "Ep:90, loss:0.00000, loss_test:0.01532, lr:3.63e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.586, tt:2692.298\n",
      "Ep:91, loss:0.00000, loss_test:0.01542, lr:3.59e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.607, tt:2723.831\n",
      "Ep:92, loss:0.00000, loss_test:0.01545, lr:3.56e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.613, tt:2754.001\n",
      "Ep:93, loss:0.00000, loss_test:0.01551, lr:3.52e-02, fs:0.77124 (r=0.678,p=0.894),  time:29.611, tt:2783.472\n",
      "Ep:94, loss:0.00000, loss_test:0.01558, lr:3.49e-02, fs:0.77124 (r=0.678,p=0.894),  time:29.618, tt:2813.688\n",
      "Ep:95, loss:0.00000, loss_test:0.01559, lr:3.45e-02, fs:0.77124 (r=0.678,p=0.894),  time:29.619, tt:2843.419\n",
      "Ep:96, loss:0.00000, loss_test:0.01563, lr:3.42e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.618, tt:2872.971\n",
      "Ep:97, loss:0.00000, loss_test:0.01570, lr:3.38e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.650, tt:2905.741\n",
      "Ep:98, loss:0.00000, loss_test:0.01573, lr:3.35e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.654, tt:2935.702\n",
      "Ep:99, loss:0.00000, loss_test:0.01574, lr:3.32e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.648, tt:2964.755\n",
      "Ep:100, loss:0.00000, loss_test:0.01581, lr:3.28e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.656, tt:2995.305\n",
      "Ep:101, loss:0.00000, loss_test:0.01590, lr:3.25e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.642, tt:3023.511\n",
      "Ep:102, loss:0.00000, loss_test:0.01586, lr:3.22e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.654, tt:3054.313\n",
      "Ep:103, loss:0.00000, loss_test:0.01601, lr:3.19e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.662, tt:3084.893\n",
      "Ep:104, loss:0.00000, loss_test:0.01603, lr:3.15e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.640, tt:3112.217\n",
      "Ep:105, loss:0.00000, loss_test:0.01605, lr:3.12e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.629, tt:3140.663\n",
      "Ep:106, loss:0.00000, loss_test:0.01609, lr:3.09e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.638, tt:3171.271\n",
      "Ep:107, loss:0.00000, loss_test:0.01615, lr:3.06e-02, fs:0.75497 (r=0.655,p=0.891),  time:29.649, tt:3202.123\n",
      "Ep:108, loss:0.00000, loss_test:0.01617, lr:3.03e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.640, tt:3230.718\n",
      "Ep:109, loss:0.00000, loss_test:0.01618, lr:3.00e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.638, tt:3260.217\n",
      "Ep:110, loss:0.00000, loss_test:0.01622, lr:2.97e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.635, tt:3289.434\n",
      "Ep:111, loss:0.00000, loss_test:0.01627, lr:2.94e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.643, tt:3320.010\n",
      "Ep:112, loss:0.00000, loss_test:0.01634, lr:2.91e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.630, tt:3348.229\n",
      "Ep:113, loss:0.00000, loss_test:0.01637, lr:2.88e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.646, tt:3379.606\n",
      "Ep:114, loss:0.00000, loss_test:0.01640, lr:2.85e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.652, tt:3409.997\n",
      "Ep:115, loss:0.00000, loss_test:0.01644, lr:2.82e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.658, tt:3440.300\n",
      "Ep:116, loss:0.00000, loss_test:0.01646, lr:2.80e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.659, tt:3470.107\n",
      "Ep:117, loss:0.00000, loss_test:0.01650, lr:2.77e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.667, tt:3500.725\n",
      "Ep:118, loss:0.00000, loss_test:0.01654, lr:2.74e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.684, tt:3532.354\n",
      "Ep:119, loss:0.00000, loss_test:0.01656, lr:2.71e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.697, tt:3563.628\n",
      "Ep:120, loss:0.00000, loss_test:0.01659, lr:2.69e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.706, tt:3594.439\n",
      "Ep:121, loss:0.00000, loss_test:0.01664, lr:2.66e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.699, tt:3623.230\n",
      "Ep:122, loss:0.00000, loss_test:0.01668, lr:2.63e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.716, tt:3655.081\n",
      "Ep:123, loss:0.00000, loss_test:0.01668, lr:2.61e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.719, tt:3685.179\n",
      "Ep:124, loss:0.00000, loss_test:0.01673, lr:2.58e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.739, tt:3717.403\n",
      "Ep:125, loss:0.00000, loss_test:0.01678, lr:2.55e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.779, tt:3752.203\n",
      "Ep:126, loss:0.00000, loss_test:0.01678, lr:2.53e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.794, tt:3783.850\n",
      "Ep:127, loss:0.00000, loss_test:0.01684, lr:2.50e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.811, tt:3815.770\n",
      "Ep:128, loss:0.00000, loss_test:0.01685, lr:2.48e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.832, tt:3848.313\n",
      "Ep:129, loss:0.00000, loss_test:0.01687, lr:2.45e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.849, tt:3880.352\n",
      "Ep:130, loss:0.00000, loss_test:0.01690, lr:2.43e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.849, tt:3910.189\n",
      "Ep:131, loss:0.00000, loss_test:0.01695, lr:2.40e-02, fs:0.74667 (r=0.644,p=0.889),  time:29.859, tt:3941.405\n",
      "Ep:132, loss:0.00000, loss_test:0.01696, lr:2.38e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.877, tt:3973.584\n",
      "Ep:133, loss:0.00000, loss_test:0.01696, lr:2.36e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.894, tt:4005.799\n",
      "Ep:134, loss:0.00000, loss_test:0.01703, lr:2.33e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.887, tt:4034.715\n",
      "Ep:135, loss:0.00000, loss_test:0.01704, lr:2.31e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.901, tt:4066.489\n",
      "Ep:136, loss:0.00000, loss_test:0.01705, lr:2.29e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.908, tt:4097.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.01712, lr:2.26e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.932, tt:4130.677\n",
      "Ep:138, loss:0.00000, loss_test:0.01712, lr:2.24e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.952, tt:4163.344\n",
      "Ep:139, loss:0.00000, loss_test:0.01714, lr:2.22e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.944, tt:4192.157\n",
      "Ep:140, loss:0.00000, loss_test:0.01716, lr:2.20e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.950, tt:4223.015\n",
      "Ep:141, loss:0.00000, loss_test:0.01716, lr:2.17e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.953, tt:4253.338\n",
      "Ep:142, loss:0.00000, loss_test:0.01720, lr:2.15e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.961, tt:4284.441\n",
      "Ep:143, loss:0.00000, loss_test:0.01721, lr:2.13e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.954, tt:4313.305\n",
      "Ep:144, loss:0.00000, loss_test:0.01725, lr:2.11e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.960, tt:4344.217\n",
      "Ep:145, loss:0.00000, loss_test:0.01728, lr:2.09e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.958, tt:4373.857\n",
      "Ep:146, loss:0.00000, loss_test:0.01730, lr:2.07e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.964, tt:4404.733\n",
      "Ep:147, loss:0.00000, loss_test:0.01732, lr:2.05e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.975, tt:4436.353\n",
      "Ep:148, loss:0.00000, loss_test:0.01733, lr:2.03e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.981, tt:4467.225\n",
      "Ep:149, loss:0.00000, loss_test:0.01732, lr:2.01e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.986, tt:4497.877\n",
      "Ep:150, loss:0.00000, loss_test:0.01738, lr:1.99e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.001, tt:4530.218\n",
      "Ep:151, loss:0.00000, loss_test:0.01741, lr:1.97e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.008, tt:4561.204\n",
      "Ep:152, loss:0.00000, loss_test:0.01740, lr:1.95e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.018, tt:4592.796\n",
      "Ep:153, loss:0.00000, loss_test:0.01743, lr:1.93e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.037, tt:4625.745\n",
      "Ep:154, loss:0.00000, loss_test:0.01746, lr:1.91e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.045, tt:4657.012\n",
      "Ep:155, loss:0.00000, loss_test:0.01748, lr:1.89e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.053, tt:4688.326\n",
      "Ep:156, loss:0.00000, loss_test:0.01748, lr:1.87e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.053, tt:4718.258\n",
      "Ep:157, loss:0.00000, loss_test:0.01752, lr:1.85e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.038, tt:4745.939\n",
      "Ep:158, loss:0.00000, loss_test:0.01753, lr:1.83e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.027, tt:4774.338\n",
      "Ep:159, loss:0.00000, loss_test:0.01755, lr:1.81e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.026, tt:4804.085\n",
      "Ep:160, loss:0.00000, loss_test:0.01758, lr:1.80e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.012, tt:4831.883\n",
      "Ep:161, loss:0.00000, loss_test:0.01758, lr:1.78e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.998, tt:4859.706\n",
      "Ep:162, loss:0.00000, loss_test:0.01758, lr:1.76e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.997, tt:4889.510\n",
      "Ep:163, loss:0.00000, loss_test:0.01759, lr:1.74e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.993, tt:4918.897\n",
      "Ep:164, loss:0.00000, loss_test:0.01762, lr:1.73e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.980, tt:4946.693\n",
      "Ep:165, loss:0.00000, loss_test:0.01765, lr:1.71e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.968, tt:4974.633\n",
      "Ep:166, loss:0.00000, loss_test:0.01763, lr:1.69e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.972, tt:5005.287\n",
      "Ep:167, loss:0.00000, loss_test:0.01765, lr:1.67e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.955, tt:5032.452\n",
      "Ep:168, loss:0.00000, loss_test:0.01772, lr:1.66e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.951, tt:5061.658\n",
      "Ep:169, loss:0.00000, loss_test:0.01769, lr:1.64e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.953, tt:5091.929\n",
      "Ep:170, loss:0.00000, loss_test:0.01771, lr:1.62e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.965, tt:5123.990\n",
      "Ep:171, loss:0.00000, loss_test:0.01774, lr:1.61e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.962, tt:5153.514\n",
      "Ep:172, loss:0.00000, loss_test:0.01777, lr:1.59e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.954, tt:5182.022\n",
      "Ep:173, loss:0.00000, loss_test:0.01775, lr:1.58e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.954, tt:5211.943\n",
      "Ep:174, loss:0.00000, loss_test:0.01775, lr:1.56e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.952, tt:5241.535\n",
      "Ep:175, loss:0.00000, loss_test:0.01778, lr:1.54e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.953, tt:5271.693\n",
      "Ep:176, loss:0.00000, loss_test:0.01781, lr:1.53e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.965, tt:5303.720\n",
      "Ep:177, loss:0.00000, loss_test:0.01779, lr:1.51e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.966, tt:5333.952\n",
      "Ep:178, loss:0.00000, loss_test:0.01781, lr:1.50e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.975, tt:5365.588\n",
      "Ep:179, loss:0.00000, loss_test:0.01784, lr:1.48e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.981, tt:5396.522\n",
      "Ep:180, loss:0.00000, loss_test:0.01785, lr:1.47e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.989, tt:5427.984\n",
      "Ep:181, loss:0.00000, loss_test:0.01785, lr:1.45e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.022, tt:5463.998\n",
      "Ep:182, loss:0.00000, loss_test:0.01787, lr:1.44e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.018, tt:5493.356\n",
      "Ep:183, loss:0.00000, loss_test:0.01789, lr:1.43e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.006, tt:5521.190\n",
      "Ep:184, loss:0.00000, loss_test:0.01789, lr:1.41e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.999, tt:5549.842\n",
      "Ep:185, loss:0.00000, loss_test:0.01788, lr:1.40e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.997, tt:5579.354\n",
      "Ep:186, loss:0.00000, loss_test:0.01793, lr:1.38e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.992, tt:5608.586\n",
      "Ep:187, loss:0.00000, loss_test:0.01792, lr:1.37e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.005, tt:5640.869\n",
      "Ep:188, loss:0.00000, loss_test:0.01792, lr:1.36e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.000, tt:5670.027\n",
      "Ep:189, loss:0.00000, loss_test:0.01794, lr:1.34e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.012, tt:5702.213\n",
      "Ep:190, loss:0.00000, loss_test:0.01796, lr:1.33e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.013, tt:5732.551\n",
      "Ep:191, loss:0.00000, loss_test:0.01795, lr:1.32e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.011, tt:5762.184\n",
      "Ep:192, loss:0.00000, loss_test:0.01798, lr:1.30e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.011, tt:5792.155\n",
      "Ep:193, loss:0.00000, loss_test:0.01798, lr:1.29e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.015, tt:5822.872\n",
      "Ep:194, loss:0.00000, loss_test:0.01799, lr:1.28e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.016, tt:5853.151\n",
      "Ep:195, loss:0.00000, loss_test:0.01800, lr:1.26e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.006, tt:5881.239\n",
      "Ep:196, loss:0.00000, loss_test:0.01800, lr:1.25e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.015, tt:5913.037\n",
      "Ep:197, loss:0.00000, loss_test:0.01800, lr:1.24e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.004, tt:5940.857\n",
      "Ep:198, loss:0.00000, loss_test:0.01803, lr:1.23e-02, fs:0.73826 (r=0.632,p=0.887),  time:30.002, tt:5970.323\n",
      "Ep:199, loss:0.00000, loss_test:0.01804, lr:1.21e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.991, tt:5998.163\n",
      "Ep:200, loss:0.00000, loss_test:0.01803, lr:1.20e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.987, tt:6027.366\n",
      "Ep:201, loss:0.00000, loss_test:0.01805, lr:1.19e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.987, tt:6057.313\n",
      "Ep:202, loss:0.00000, loss_test:0.01806, lr:1.18e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.988, tt:6087.556\n",
      "Ep:203, loss:0.00000, loss_test:0.01806, lr:1.17e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.986, tt:6117.062\n",
      "Ep:204, loss:0.00000, loss_test:0.01808, lr:1.15e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.974, tt:6144.582\n",
      "Ep:205, loss:0.00000, loss_test:0.01810, lr:1.14e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.979, tt:6175.596\n",
      "Ep:206, loss:0.00000, loss_test:0.01809, lr:1.13e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.977, tt:6205.269\n",
      "Ep:207, loss:0.00000, loss_test:0.01808, lr:1.12e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.970, tt:6233.659\n",
      "Ep:208, loss:0.00000, loss_test:0.01813, lr:1.11e-02, fs:0.73826 (r=0.632,p=0.887),  time:29.961, tt:6261.887\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14369, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:28.756, tt:28.756\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14229, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:30.314, tt:60.628\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13971, lr:1.00e-02, fs:0.66406 (r=0.977,p=0.503),  time:29.245, tt:87.734\n",
      "Ep:3, loss:0.00026, loss_test:0.13548, lr:1.00e-02, fs:0.65041 (r=0.920,p=0.503),  time:28.284, tt:113.138\n",
      "Ep:4, loss:0.00025, loss_test:0.13043, lr:1.00e-02, fs:0.64935 (r=0.862,p=0.521),  time:28.283, tt:141.416\n",
      "Ep:5, loss:0.00024, loss_test:0.12414, lr:1.00e-02, fs:0.66038 (r=0.805,p=0.560),  time:27.721, tt:166.323\n",
      "Ep:6, loss:0.00023, loss_test:0.11938, lr:1.00e-02, fs:0.66346 (r=0.793,p=0.570),  time:27.509, tt:192.562\n",
      "Ep:7, loss:0.00022, loss_test:0.11831, lr:1.00e-02, fs:0.65714 (r=0.793,p=0.561),  time:27.665, tt:221.317\n",
      "Ep:8, loss:0.00022, loss_test:0.11294, lr:1.00e-02, fs:0.67662 (r=0.782,p=0.596),  time:28.102, tt:252.916\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11029, lr:1.00e-02, fs:0.70769 (r=0.793,p=0.639),  time:28.589, tt:285.891\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10598, lr:1.00e-02, fs:0.70466 (r=0.782,p=0.642),  time:29.058, tt:319.638\n",
      "Ep:11, loss:0.00019, loss_test:0.10164, lr:1.00e-02, fs:0.72727 (r=0.782,p=0.680),  time:29.211, tt:350.531\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09699, lr:1.00e-02, fs:0.75676 (r=0.805,p=0.714),  time:29.236, tt:380.068\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09398, lr:1.00e-02, fs:0.77174 (r=0.816,p=0.732),  time:29.243, tt:409.402\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09168, lr:1.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:29.527, tt:442.902\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08935, lr:1.00e-02, fs:0.77966 (r=0.793,p=0.767),  time:29.585, tt:473.354\n",
      "Ep:16, loss:0.00015, loss_test:0.08710, lr:1.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.968, tt:509.461\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08588, lr:1.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:30.026, tt:540.476\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08345, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:30.164, tt:573.120\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.08268, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:30.277, tt:605.531\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08001, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:30.259, tt:635.435\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07840, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:30.414, tt:669.105\n",
      "Ep:22, loss:0.00012, loss_test:0.07662, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:30.453, tt:700.416\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.07664, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:30.519, tt:732.454\n",
      "Ep:24, loss:0.00010, loss_test:0.07419, lr:1.00e-02, fs:0.82286 (r=0.828,p=0.818),  time:30.587, tt:764.685\n",
      "Ep:25, loss:0.00010, loss_test:0.07396, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:30.571, tt:794.845\n",
      "Ep:26, loss:0.00009, loss_test:0.07371, lr:1.00e-02, fs:0.78528 (r=0.736,p=0.842),  time:30.681, tt:828.389\n",
      "Ep:27, loss:0.00009, loss_test:0.07264, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:30.719, tt:860.129\n",
      "Ep:28, loss:0.00008, loss_test:0.07279, lr:1.00e-02, fs:0.79245 (r=0.724,p=0.875),  time:30.691, tt:890.046\n",
      "Ep:29, loss:0.00008, loss_test:0.07067, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:30.694, tt:920.810\n",
      "Ep:30, loss:0.00008, loss_test:0.07071, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:30.717, tt:952.222\n",
      "Ep:31, loss:0.00007, loss_test:0.07181, lr:1.00e-02, fs:0.76923 (r=0.690,p=0.870),  time:30.628, tt:980.086\n",
      "Ep:32, loss:0.00007, loss_test:0.06895, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:30.605, tt:1009.977\n",
      "Ep:33, loss:0.00006, loss_test:0.07634, lr:1.00e-02, fs:0.77922 (r=0.690,p=0.896),  time:30.604, tt:1040.549\n",
      "Ep:34, loss:0.00006, loss_test:0.07150, lr:9.90e-03, fs:0.77419 (r=0.690,p=0.882),  time:30.630, tt:1072.037\n",
      "Ep:35, loss:0.00006, loss_test:0.06911, lr:9.80e-03, fs:0.78205 (r=0.701,p=0.884),  time:30.656, tt:1103.601\n",
      "Ep:36, loss:0.00005, loss_test:0.07150, lr:9.70e-03, fs:0.77419 (r=0.690,p=0.882),  time:30.645, tt:1133.873\n",
      "Ep:37, loss:0.00005, loss_test:0.06952, lr:9.61e-03, fs:0.77419 (r=0.690,p=0.882),  time:30.644, tt:1164.459\n",
      "Ep:38, loss:0.00005, loss_test:0.06871, lr:9.51e-03, fs:0.76623 (r=0.678,p=0.881),  time:30.689, tt:1196.869\n",
      "Ep:39, loss:0.00004, loss_test:0.07010, lr:9.41e-03, fs:0.76623 (r=0.678,p=0.881),  time:30.701, tt:1228.045\n",
      "Ep:40, loss:0.00004, loss_test:0.06942, lr:9.32e-03, fs:0.77124 (r=0.678,p=0.894),  time:30.740, tt:1260.345\n",
      "Ep:41, loss:0.00004, loss_test:0.07174, lr:9.23e-03, fs:0.78146 (r=0.678,p=0.922),  time:30.769, tt:1292.293\n",
      "Ep:42, loss:0.00004, loss_test:0.07571, lr:9.14e-03, fs:0.78667 (r=0.678,p=0.937),  time:30.799, tt:1324.377\n",
      "Ep:43, loss:0.00004, loss_test:0.06925, lr:9.04e-03, fs:0.77124 (r=0.678,p=0.894),  time:30.902, tt:1359.692\n",
      "Ep:44, loss:0.00003, loss_test:0.08221, lr:8.95e-03, fs:0.78912 (r=0.667,p=0.967),  time:30.939, tt:1392.255\n",
      "Ep:45, loss:0.00003, loss_test:0.07498, lr:8.86e-03, fs:0.78667 (r=0.678,p=0.937),  time:30.955, tt:1423.921\n",
      "Ep:46, loss:0.00003, loss_test:0.07468, lr:8.78e-03, fs:0.78146 (r=0.678,p=0.922),  time:30.989, tt:1456.489\n",
      "Ep:47, loss:0.00003, loss_test:0.07892, lr:8.69e-03, fs:0.78912 (r=0.667,p=0.967),  time:30.987, tt:1487.363\n",
      "Ep:48, loss:0.00003, loss_test:0.07669, lr:8.60e-03, fs:0.76821 (r=0.667,p=0.906),  time:31.025, tt:1520.222\n",
      "Ep:49, loss:0.00003, loss_test:0.07971, lr:8.51e-03, fs:0.80272 (r=0.678,p=0.983),  time:31.031, tt:1551.541\n",
      "Ep:50, loss:0.00002, loss_test:0.07580, lr:8.43e-03, fs:0.77852 (r=0.667,p=0.935),  time:31.027, tt:1582.376\n",
      "Ep:51, loss:0.00002, loss_test:0.08272, lr:8.35e-03, fs:0.78621 (r=0.655,p=0.983),  time:31.067, tt:1615.503\n",
      "Ep:52, loss:0.00002, loss_test:0.07736, lr:8.26e-03, fs:0.77551 (r=0.655,p=0.950),  time:31.090, tt:1647.793\n",
      "Ep:53, loss:0.00002, loss_test:0.07618, lr:8.18e-03, fs:0.80000 (r=0.690,p=0.952),  time:31.091, tt:1678.903\n",
      "Ep:54, loss:0.00002, loss_test:0.08554, lr:8.10e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.091, tt:1709.992\n",
      "Ep:55, loss:0.00002, loss_test:0.07575, lr:8.02e-03, fs:0.79470 (r=0.690,p=0.938),  time:31.057, tt:1739.187\n",
      "Ep:56, loss:0.00002, loss_test:0.08200, lr:7.94e-03, fs:0.77241 (r=0.644,p=0.966),  time:31.083, tt:1771.711\n",
      "Ep:57, loss:0.00002, loss_test:0.07971, lr:7.86e-03, fs:0.79730 (r=0.678,p=0.967),  time:31.023, tt:1799.354\n",
      "Ep:58, loss:0.00002, loss_test:0.08468, lr:7.78e-03, fs:0.77241 (r=0.644,p=0.966),  time:31.067, tt:1832.935\n",
      "Ep:59, loss:0.00001, loss_test:0.08119, lr:7.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.124, tt:1867.468\n",
      "Ep:60, loss:0.00001, loss_test:0.07967, lr:7.62e-03, fs:0.77241 (r=0.644,p=0.966),  time:31.128, tt:1898.788\n",
      "Ep:61, loss:0.00001, loss_test:0.08252, lr:7.55e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.092, tt:1927.728\n",
      "Ep:62, loss:0.00001, loss_test:0.08149, lr:7.47e-03, fs:0.77241 (r=0.644,p=0.966),  time:31.080, tt:1958.048\n",
      "Ep:63, loss:0.00001, loss_test:0.07880, lr:7.40e-03, fs:0.78621 (r=0.655,p=0.983),  time:31.028, tt:1985.767\n",
      "Ep:64, loss:0.00001, loss_test:0.08252, lr:7.32e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.040, tt:2017.628\n",
      "Ep:65, loss:0.00001, loss_test:0.07730, lr:7.25e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.091, tt:2052.023\n",
      "Ep:66, loss:0.00001, loss_test:0.08518, lr:7.18e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.149, tt:2086.978\n",
      "Ep:67, loss:0.00001, loss_test:0.08345, lr:7.11e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.220, tt:2122.940\n",
      "Ep:68, loss:0.00001, loss_test:0.07934, lr:7.03e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.265, tt:2157.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.08651, lr:6.96e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.333, tt:2193.289\n",
      "Ep:70, loss:0.00001, loss_test:0.08089, lr:6.89e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.376, tt:2227.723\n",
      "Ep:71, loss:0.00001, loss_test:0.09156, lr:6.83e-03, fs:0.78621 (r=0.655,p=0.983),  time:31.400, tt:2260.818\n",
      "Ep:72, loss:0.00001, loss_test:0.08248, lr:6.76e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.454, tt:2296.131\n",
      "Ep:73, loss:0.00001, loss_test:0.08741, lr:6.69e-03, fs:0.77241 (r=0.644,p=0.966),  time:31.510, tt:2331.746\n",
      "Ep:74, loss:0.00001, loss_test:0.08153, lr:6.62e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.578, tt:2368.342\n",
      "Ep:75, loss:0.00001, loss_test:0.08675, lr:6.56e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.633, tt:2404.125\n",
      "Ep:76, loss:0.00001, loss_test:0.08305, lr:6.49e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.669, tt:2438.489\n",
      "Ep:77, loss:0.00001, loss_test:0.08306, lr:6.43e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.700, tt:2472.565\n",
      "Ep:78, loss:0.00001, loss_test:0.08387, lr:6.36e-03, fs:0.77778 (r=0.644,p=0.982),  time:31.775, tt:2510.188\n",
      "Ep:79, loss:0.00001, loss_test:0.08313, lr:6.30e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.810, tt:2544.827\n",
      "Ep:80, loss:0.00001, loss_test:0.08438, lr:6.24e-03, fs:0.78621 (r=0.655,p=0.983),  time:31.859, tt:2580.575\n",
      "Ep:81, loss:0.00001, loss_test:0.08203, lr:6.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.926, tt:2617.939\n",
      "Ep:82, loss:0.00001, loss_test:0.08510, lr:6.11e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.958, tt:2652.526\n",
      "Ep:83, loss:0.00001, loss_test:0.08424, lr:6.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.019, tt:2689.627\n",
      "Ep:84, loss:0.00001, loss_test:0.08453, lr:5.99e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.089, tt:2727.546\n",
      "Ep:85, loss:0.00001, loss_test:0.08180, lr:5.93e-03, fs:0.77778 (r=0.644,p=0.982),  time:32.119, tt:2762.217\n",
      "Ep:86, loss:0.00001, loss_test:0.08514, lr:5.87e-03, fs:0.76389 (r=0.632,p=0.965),  time:32.132, tt:2795.515\n",
      "Ep:87, loss:0.00001, loss_test:0.08136, lr:5.81e-03, fs:0.80272 (r=0.678,p=0.983),  time:32.194, tt:2833.115\n",
      "Ep:88, loss:0.00000, loss_test:0.08677, lr:5.75e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.230, tt:2868.455\n",
      "Ep:89, loss:0.00000, loss_test:0.08120, lr:5.70e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.265, tt:2903.851\n",
      "Ep:90, loss:0.00000, loss_test:0.08296, lr:5.64e-03, fs:0.77778 (r=0.644,p=0.982),  time:32.319, tt:2941.065\n",
      "Ep:91, loss:0.00000, loss_test:0.08315, lr:5.58e-03, fs:0.76389 (r=0.632,p=0.965),  time:32.346, tt:2975.872\n",
      "Ep:92, loss:0.00000, loss_test:0.07942, lr:5.53e-03, fs:0.80272 (r=0.678,p=0.983),  time:32.379, tt:3011.283\n",
      "Ep:93, loss:0.00000, loss_test:0.08474, lr:5.47e-03, fs:0.76389 (r=0.632,p=0.965),  time:32.412, tt:3046.740\n",
      "Ep:94, loss:0.00000, loss_test:0.08177, lr:5.42e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.455, tt:3083.271\n",
      "Ep:95, loss:0.00000, loss_test:0.08356, lr:5.36e-03, fs:0.77778 (r=0.644,p=0.982),  time:32.492, tt:3119.207\n",
      "Ep:96, loss:0.00000, loss_test:0.08019, lr:5.31e-03, fs:0.76389 (r=0.632,p=0.965),  time:32.541, tt:3156.450\n",
      "Ep:97, loss:0.00000, loss_test:0.08298, lr:5.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.566, tt:3191.509\n",
      "Ep:98, loss:0.00000, loss_test:0.08139, lr:5.20e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.611, tt:3228.456\n",
      "Ep:99, loss:0.00000, loss_test:0.07997, lr:5.15e-03, fs:0.76389 (r=0.632,p=0.965),  time:32.638, tt:3263.811\n",
      "Ep:100, loss:0.00000, loss_test:0.08210, lr:5.10e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.659, tt:3298.599\n",
      "Ep:101, loss:0.00000, loss_test:0.08445, lr:5.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.683, tt:3333.662\n",
      "Ep:102, loss:0.00000, loss_test:0.08124, lr:5.00e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.739, tt:3372.097\n",
      "Ep:103, loss:0.00000, loss_test:0.08136, lr:4.95e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.751, tt:3406.120\n",
      "Ep:104, loss:0.00000, loss_test:0.08084, lr:4.90e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.771, tt:3440.980\n",
      "Ep:105, loss:0.00000, loss_test:0.08335, lr:4.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.805, tt:3477.337\n",
      "Ep:106, loss:0.00000, loss_test:0.08059, lr:4.80e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.828, tt:3512.600\n",
      "Ep:107, loss:0.00000, loss_test:0.08317, lr:4.75e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.841, tt:3546.867\n",
      "Ep:108, loss:0.00000, loss_test:0.08216, lr:4.71e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.889, tt:3584.859\n",
      "Ep:109, loss:0.00000, loss_test:0.08087, lr:4.66e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.926, tt:3621.821\n",
      "Ep:110, loss:0.00000, loss_test:0.08268, lr:4.61e-03, fs:0.76389 (r=0.632,p=0.965),  time:32.950, tt:3657.421\n",
      "Ep:111, loss:0.00000, loss_test:0.08026, lr:4.57e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.990, tt:3694.891\n",
      "Ep:112, loss:0.00000, loss_test:0.08332, lr:4.52e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.018, tt:3731.080\n",
      "Ep:113, loss:0.00000, loss_test:0.08063, lr:4.48e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.052, tt:3767.936\n",
      "Ep:114, loss:0.00000, loss_test:0.08130, lr:4.43e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.089, tt:3805.215\n",
      "Ep:115, loss:0.00000, loss_test:0.08295, lr:4.39e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.132, tt:3843.358\n",
      "Ep:116, loss:0.00000, loss_test:0.08020, lr:4.34e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.164, tt:3880.200\n",
      "Ep:117, loss:0.00000, loss_test:0.08269, lr:4.30e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.209, tt:3918.660\n",
      "Ep:118, loss:0.00000, loss_test:0.08074, lr:4.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.244, tt:3956.022\n",
      "Ep:119, loss:0.00000, loss_test:0.08069, lr:4.21e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.278, tt:3993.349\n",
      "Ep:120, loss:0.00000, loss_test:0.08108, lr:4.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.311, tt:4030.624\n",
      "Ep:121, loss:0.00000, loss_test:0.07959, lr:4.13e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.344, tt:4067.999\n",
      "Ep:122, loss:0.00000, loss_test:0.08067, lr:4.09e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.360, tt:4103.256\n",
      "Ep:123, loss:0.00000, loss_test:0.08049, lr:4.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.405, tt:4142.195\n",
      "Ep:124, loss:0.00000, loss_test:0.07998, lr:4.01e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.430, tt:4178.802\n",
      "Ep:125, loss:0.00000, loss_test:0.08051, lr:3.97e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.472, tt:4217.437\n",
      "Ep:126, loss:0.00000, loss_test:0.07995, lr:3.93e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.489, tt:4253.152\n",
      "Ep:127, loss:0.00000, loss_test:0.08056, lr:3.89e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.505, tt:4288.598\n",
      "Ep:128, loss:0.00000, loss_test:0.07948, lr:3.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.524, tt:4324.602\n",
      "Ep:129, loss:0.00000, loss_test:0.08101, lr:3.81e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.534, tt:4359.381\n",
      "Ep:130, loss:0.00000, loss_test:0.08104, lr:3.77e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.559, tt:4396.292\n",
      "Ep:131, loss:0.00000, loss_test:0.08141, lr:3.73e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.591, tt:4434.049\n",
      "Ep:132, loss:0.00000, loss_test:0.08054, lr:3.70e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.620, tt:4471.397\n",
      "Ep:133, loss:0.00000, loss_test:0.08005, lr:3.66e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.659, tt:4510.284\n",
      "Ep:134, loss:0.00000, loss_test:0.08065, lr:3.62e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.677, tt:4546.451\n",
      "Ep:135, loss:0.00000, loss_test:0.08048, lr:3.59e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.700, tt:4583.182\n",
      "Ep:136, loss:0.00000, loss_test:0.08108, lr:3.55e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.714, tt:4618.850\n",
      "Ep:137, loss:0.00000, loss_test:0.08055, lr:3.52e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.724, tt:4653.920\n",
      "Ep:138, loss:0.00000, loss_test:0.08004, lr:3.48e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.721, tt:4687.179\n",
      "Ep:139, loss:0.00000, loss_test:0.08077, lr:3.45e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.773, tt:4728.267\n",
      "Ep:140, loss:0.00000, loss_test:0.08014, lr:3.41e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.796, tt:4765.177\n",
      "Ep:141, loss:0.00000, loss_test:0.08027, lr:3.38e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.803, tt:4800.024\n",
      "Ep:142, loss:0.00000, loss_test:0.08082, lr:3.34e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.818, tt:4836.004\n",
      "Ep:143, loss:0.00000, loss_test:0.08035, lr:3.31e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.848, tt:4874.127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.08075, lr:3.28e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.871, tt:4911.346\n",
      "Ep:145, loss:0.00000, loss_test:0.08088, lr:3.24e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.880, tt:4946.426\n",
      "Ep:146, loss:0.00000, loss_test:0.08020, lr:3.21e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.882, tt:4980.600\n",
      "Ep:147, loss:0.00000, loss_test:0.08065, lr:3.18e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.908, tt:5018.316\n",
      "Ep:148, loss:0.00000, loss_test:0.08075, lr:3.15e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.926, tt:5054.903\n",
      "Ep:149, loss:0.00000, loss_test:0.08024, lr:3.12e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.952, tt:5092.741\n",
      "Ep:150, loss:0.00000, loss_test:0.07984, lr:3.09e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.957, tt:5127.481\n",
      "Ep:151, loss:0.00000, loss_test:0.08032, lr:3.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.974, tt:5164.000\n",
      "Ep:152, loss:0.00000, loss_test:0.07978, lr:3.02e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.995, tt:5201.172\n",
      "Ep:153, loss:0.00000, loss_test:0.07943, lr:2.99e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.016, tt:5238.451\n",
      "Ep:154, loss:0.00000, loss_test:0.08001, lr:2.96e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.025, tt:5273.942\n",
      "Ep:155, loss:0.00000, loss_test:0.08009, lr:2.93e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.042, tt:5310.564\n",
      "Ep:156, loss:0.00000, loss_test:0.08022, lr:2.90e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.057, tt:5346.884\n",
      "Ep:157, loss:0.00000, loss_test:0.08000, lr:2.88e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.066, tt:5382.461\n",
      "Ep:158, loss:0.00000, loss_test:0.08026, lr:2.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.083, tt:5419.211\n",
      "Ep:159, loss:0.00000, loss_test:0.07980, lr:2.82e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.098, tt:5455.706\n",
      "Ep:160, loss:0.00000, loss_test:0.08004, lr:2.79e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.107, tt:5491.238\n",
      "Ep:161, loss:0.00000, loss_test:0.07976, lr:2.76e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.129, tt:5528.844\n",
      "Ep:162, loss:0.00000, loss_test:0.07987, lr:2.73e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.145, tt:5565.604\n",
      "Ep:163, loss:0.00000, loss_test:0.07989, lr:2.71e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.137, tt:5598.387\n",
      "Ep:164, loss:0.00000, loss_test:0.08030, lr:2.68e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.138, tt:5632.700\n",
      "Ep:165, loss:0.00000, loss_test:0.08008, lr:2.65e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.149, tt:5668.747\n",
      "Ep:166, loss:0.00000, loss_test:0.08099, lr:2.63e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.153, tt:5703.512\n",
      "Ep:167, loss:0.00000, loss_test:0.08062, lr:2.60e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.158, tt:5738.535\n",
      "Ep:168, loss:0.00000, loss_test:0.08015, lr:2.57e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.167, tt:5774.257\n",
      "Ep:169, loss:0.00000, loss_test:0.08117, lr:2.55e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.178, tt:5810.246\n",
      "Ep:170, loss:0.00000, loss_test:0.08100, lr:2.52e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.194, tt:5847.090\n",
      "Ep:171, loss:0.00000, loss_test:0.08012, lr:2.50e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.214, tt:5884.856\n",
      "Ep:172, loss:0.00000, loss_test:0.08055, lr:2.47e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.225, tt:5920.931\n",
      "Ep:173, loss:0.00000, loss_test:0.08057, lr:2.45e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.235, tt:5956.904\n",
      "Ep:174, loss:0.00000, loss_test:0.08009, lr:2.42e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.234, tt:5990.951\n",
      "Ep:175, loss:0.00000, loss_test:0.08004, lr:2.40e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.237, tt:6025.737\n",
      "Ep:176, loss:0.00000, loss_test:0.08025, lr:2.38e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.256, tt:6063.340\n",
      "Ep:177, loss:0.00000, loss_test:0.07987, lr:2.35e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.254, tt:6097.240\n",
      "Ep:178, loss:0.00000, loss_test:0.07951, lr:2.33e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.262, tt:6132.938\n",
      "Ep:179, loss:0.00000, loss_test:0.07985, lr:2.31e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.258, tt:6166.440\n",
      "Ep:180, loss:0.00000, loss_test:0.07972, lr:2.28e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.261, tt:6201.218\n",
      "Ep:181, loss:0.00000, loss_test:0.07938, lr:2.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.261, tt:6235.509\n",
      "Ep:182, loss:0.00000, loss_test:0.08024, lr:2.24e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.263, tt:6270.125\n",
      "Ep:183, loss:0.00000, loss_test:0.08038, lr:2.21e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.260, tt:6303.795\n",
      "Ep:184, loss:0.00000, loss_test:0.07995, lr:2.19e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.258, tt:6337.818\n",
      "Ep:185, loss:0.00000, loss_test:0.07999, lr:2.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.245, tt:6369.638\n",
      "Ep:186, loss:0.00000, loss_test:0.07968, lr:2.15e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.243, tt:6403.356\n",
      "Ep:187, loss:0.00000, loss_test:0.07998, lr:2.13e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.235, tt:6436.119\n",
      "Ep:188, loss:0.00000, loss_test:0.08031, lr:2.11e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.246, tt:6472.480\n",
      "Ep:189, loss:0.00000, loss_test:0.08025, lr:2.08e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.239, tt:6505.440\n",
      "Ep:190, loss:0.00000, loss_test:0.08007, lr:2.06e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.250, tt:6541.840\n",
      "Ep:191, loss:0.00000, loss_test:0.07965, lr:2.04e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.239, tt:6573.807\n",
      "Ep:192, loss:0.00000, loss_test:0.07941, lr:2.02e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.240, tt:6608.229\n",
      "Ep:193, loss:0.00000, loss_test:0.07996, lr:2.00e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.244, tt:6643.240\n",
      "Ep:194, loss:0.00000, loss_test:0.07987, lr:1.98e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.249, tt:6678.588\n",
      "Ep:195, loss:0.00000, loss_test:0.07999, lr:1.96e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.260, tt:6714.947\n",
      "Ep:196, loss:0.00000, loss_test:0.08024, lr:1.94e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.263, tt:6749.879\n",
      "Ep:197, loss:0.00000, loss_test:0.07972, lr:1.92e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.262, tt:6783.914\n",
      "Ep:198, loss:0.00000, loss_test:0.08004, lr:1.90e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.271, tt:6819.869\n",
      "Ep:199, loss:0.00000, loss_test:0.08017, lr:1.89e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.281, tt:6856.191\n",
      "Ep:200, loss:0.00000, loss_test:0.07991, lr:1.87e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.296, tt:6893.547\n",
      "Ep:201, loss:0.00000, loss_test:0.07983, lr:1.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.296, tt:6927.875\n",
      "Ep:202, loss:0.00000, loss_test:0.08011, lr:1.83e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.294, tt:6961.717\n",
      "Ep:203, loss:0.00000, loss_test:0.07977, lr:1.81e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.297, tt:6996.593\n",
      "Ep:204, loss:0.00000, loss_test:0.07992, lr:1.79e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.310, tt:7033.463\n",
      "Ep:205, loss:0.00000, loss_test:0.07980, lr:1.78e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.314, tt:7068.637\n",
      "Ep:206, loss:0.00000, loss_test:0.07972, lr:1.76e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.319, tt:7103.972\n",
      "Ep:207, loss:0.00000, loss_test:0.07972, lr:1.74e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.325, tt:7139.542\n",
      "Ep:208, loss:0.00000, loss_test:0.07967, lr:1.72e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.313, tt:7171.409\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02106, lr:6.00e-02, fs:0.65587 (r=0.931,p=0.506),  time:16.644, tt:16.644\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02433, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.501, tt:43.002\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02555, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.676, tt:71.028\n",
      "Ep:3, loss:0.00005, loss_test:0.02490, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.604, tt:106.415\n",
      "Ep:4, loss:0.00005, loss_test:0.02354, lr:6.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:28.544, tt:142.722\n",
      "Ep:5, loss:0.00004, loss_test:0.02196, lr:6.00e-02, fs:0.67729 (r=0.977,p=0.518),  time:29.746, tt:178.477\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02099, lr:6.00e-02, fs:0.65306 (r=0.920,p=0.506),  time:30.461, tt:213.229\n",
      "Ep:7, loss:0.00004, loss_test:0.02047, lr:6.00e-02, fs:0.66379 (r=0.885,p=0.531),  time:31.287, tt:250.300\n",
      "Ep:8, loss:0.00004, loss_test:0.01985, lr:6.00e-02, fs:0.65471 (r=0.839,p=0.537),  time:31.626, tt:284.635\n",
      "Ep:9, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.66087 (r=0.874,p=0.531),  time:32.013, tt:320.132\n",
      "Ep:10, loss:0.00003, loss_test:0.01871, lr:6.00e-02, fs:0.67797 (r=0.920,p=0.537),  time:32.377, tt:356.151\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01835, lr:6.00e-02, fs:0.67797 (r=0.920,p=0.537),  time:32.502, tt:390.025\n",
      "Ep:12, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.68722 (r=0.897,p=0.557),  time:32.608, tt:423.908\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01747, lr:6.00e-02, fs:0.70046 (r=0.874,p=0.585),  time:32.730, tt:458.220\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.69565 (r=0.828,p=0.600),  time:32.916, tt:493.736\n",
      "Ep:15, loss:0.00003, loss_test:0.01696, lr:6.00e-02, fs:0.70647 (r=0.816,p=0.623),  time:33.062, tt:528.996\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01675, lr:6.00e-02, fs:0.70647 (r=0.816,p=0.623),  time:33.214, tt:564.633\n",
      "Ep:17, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.71921 (r=0.839,p=0.629),  time:33.310, tt:599.583\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.73892 (r=0.862,p=0.647),  time:33.401, tt:634.624\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01603, lr:6.00e-02, fs:0.75000 (r=0.862,p=0.664),  time:33.510, tt:670.209\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.75000 (r=0.862,p=0.664),  time:33.507, tt:703.645\n",
      "Ep:21, loss:0.00003, loss_test:0.01561, lr:6.00e-02, fs:0.76684 (r=0.851,p=0.698),  time:33.599, tt:739.173\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.76842 (r=0.839,p=0.709),  time:33.685, tt:774.755\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.77174 (r=0.816,p=0.732),  time:33.698, tt:808.755\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01489, lr:6.00e-02, fs:0.78495 (r=0.839,p=0.737),  time:33.690, tt:842.243\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:33.715, tt:876.599\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:33.746, tt:911.144\n",
      "Ep:27, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.78453 (r=0.816,p=0.755),  time:33.717, tt:944.062\n",
      "Ep:28, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.77778 (r=0.805,p=0.753),  time:33.795, tt:980.061\n",
      "Ep:29, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.77095 (r=0.793,p=0.750),  time:33.783, tt:1013.504\n",
      "Ep:30, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.77095 (r=0.793,p=0.750),  time:33.853, tt:1049.456\n",
      "Ep:31, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.77528 (r=0.793,p=0.758),  time:33.868, tt:1083.783\n",
      "Ep:32, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:33.917, tt:1119.258\n",
      "Ep:33, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:33.972, tt:1155.065\n",
      "Ep:34, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:33.995, tt:1189.816\n",
      "Ep:35, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:34.024, tt:1224.852\n",
      "Ep:36, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.77714 (r=0.782,p=0.773),  time:34.084, tt:1261.090\n",
      "Ep:37, loss:0.00001, loss_test:0.01390, lr:5.94e-02, fs:0.77714 (r=0.782,p=0.773),  time:34.126, tt:1296.807\n",
      "Ep:38, loss:0.00001, loss_test:0.01393, lr:5.88e-02, fs:0.77714 (r=0.782,p=0.773),  time:34.187, tt:1333.287\n",
      "Ep:39, loss:0.00001, loss_test:0.01394, lr:5.82e-02, fs:0.77714 (r=0.782,p=0.773),  time:34.264, tt:1370.578\n",
      "Ep:40, loss:0.00001, loss_test:0.01390, lr:5.76e-02, fs:0.76301 (r=0.759,p=0.767),  time:34.294, tt:1406.041\n",
      "Ep:41, loss:0.00001, loss_test:0.01383, lr:5.71e-02, fs:0.76301 (r=0.759,p=0.767),  time:34.322, tt:1441.525\n",
      "Ep:42, loss:0.00001, loss_test:0.01395, lr:5.65e-02, fs:0.78363 (r=0.770,p=0.798),  time:34.334, tt:1476.349\n",
      "Ep:43, loss:0.00001, loss_test:0.01394, lr:5.59e-02, fs:0.78363 (r=0.770,p=0.798),  time:34.302, tt:1509.304\n",
      "Ep:44, loss:0.00001, loss_test:0.01399, lr:5.54e-02, fs:0.78363 (r=0.770,p=0.798),  time:34.319, tt:1544.370\n",
      "Ep:45, loss:0.00001, loss_test:0.01395, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.413, tt:1583.017\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01394, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.431, tt:1618.272\n",
      "Ep:47, loss:0.00001, loss_test:0.01400, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.450, tt:1653.611\n",
      "Ep:48, loss:0.00001, loss_test:0.01405, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.455, tt:1688.285\n",
      "Ep:49, loss:0.00001, loss_test:0.01413, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.458, tt:1722.897\n",
      "Ep:50, loss:0.00001, loss_test:0.01412, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.463, tt:1757.636\n",
      "Ep:51, loss:0.00001, loss_test:0.01407, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.461, tt:1791.987\n",
      "Ep:52, loss:0.00001, loss_test:0.01416, lr:5.48e-02, fs:0.78824 (r=0.770,p=0.807),  time:34.467, tt:1826.766\n",
      "Ep:53, loss:0.00001, loss_test:0.01430, lr:5.48e-02, fs:0.79290 (r=0.770,p=0.817),  time:34.472, tt:1861.489\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01421, lr:5.48e-02, fs:0.79762 (r=0.770,p=0.827),  time:34.486, tt:1896.710\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01425, lr:5.48e-02, fs:0.80240 (r=0.770,p=0.838),  time:34.495, tt:1931.724\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01438, lr:5.48e-02, fs:0.80240 (r=0.770,p=0.838),  time:34.527, tt:1968.014\n",
      "Ep:57, loss:0.00001, loss_test:0.01446, lr:5.48e-02, fs:0.80240 (r=0.770,p=0.838),  time:34.520, tt:2002.141\n",
      "Ep:58, loss:0.00001, loss_test:0.01453, lr:5.48e-02, fs:0.80723 (r=0.770,p=0.848),  time:34.519, tt:2036.618\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01460, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.538, tt:2072.285\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01460, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.529, tt:2106.252\n",
      "Ep:61, loss:0.00001, loss_test:0.01464, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.521, tt:2140.272\n",
      "Ep:62, loss:0.00001, loss_test:0.01470, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.525, tt:2175.087\n",
      "Ep:63, loss:0.00001, loss_test:0.01476, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.581, tt:2213.203\n",
      "Ep:64, loss:0.00001, loss_test:0.01482, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.728, tt:2257.310\n",
      "Ep:65, loss:0.00001, loss_test:0.01482, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:34.742, tt:2292.989\n",
      "Ep:66, loss:0.00001, loss_test:0.01494, lr:5.48e-02, fs:0.81707 (r=0.770,p=0.870),  time:34.751, tt:2328.323\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01502, lr:5.48e-02, fs:0.81707 (r=0.770,p=0.870),  time:34.803, tt:2366.585\n",
      "Ep:68, loss:0.00001, loss_test:0.01496, lr:5.48e-02, fs:0.81707 (r=0.770,p=0.870),  time:34.836, tt:2403.657\n",
      "Ep:69, loss:0.00001, loss_test:0.01502, lr:5.48e-02, fs:0.82209 (r=0.770,p=0.882),  time:34.854, tt:2439.746\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01513, lr:5.48e-02, fs:0.82716 (r=0.770,p=0.893),  time:34.865, tt:2475.432\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00000, loss_test:0.01522, lr:5.48e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.912, tt:2513.662\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00000, loss_test:0.01524, lr:5.48e-02, fs:0.83230 (r=0.770,p=0.905),  time:34.919, tt:2549.097\n",
      "Ep:73, loss:0.00000, loss_test:0.01535, lr:5.48e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.937, tt:2585.308\n",
      "Ep:74, loss:0.00000, loss_test:0.01538, lr:5.48e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.957, tt:2621.800\n",
      "Ep:75, loss:0.00000, loss_test:0.01548, lr:5.48e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.963, tt:2657.200\n",
      "Ep:76, loss:0.00000, loss_test:0.01552, lr:5.48e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.982, tt:2693.631\n",
      "Ep:77, loss:0.00000, loss_test:0.01556, lr:5.48e-02, fs:0.84277 (r=0.770,p=0.931),  time:35.008, tt:2730.657\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00000, loss_test:0.01566, lr:5.48e-02, fs:0.84277 (r=0.770,p=0.931),  time:35.009, tt:2765.723\n",
      "Ep:79, loss:0.00000, loss_test:0.01568, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.032, tt:2802.574\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00000, loss_test:0.01571, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.043, tt:2838.452\n",
      "Ep:81, loss:0.00000, loss_test:0.01578, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.052, tt:2874.253\n",
      "Ep:82, loss:0.00000, loss_test:0.01578, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.061, tt:2910.036\n",
      "Ep:83, loss:0.00000, loss_test:0.01585, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.086, tt:2947.183\n",
      "Ep:84, loss:0.00000, loss_test:0.01599, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.111, tt:2984.443\n",
      "Ep:85, loss:0.00000, loss_test:0.01601, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.134, tt:3021.482\n",
      "Ep:86, loss:0.00000, loss_test:0.01602, lr:5.48e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.157, tt:3058.633\n",
      "Ep:87, loss:0.00000, loss_test:0.01618, lr:5.48e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.212, tt:3098.617\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00000, loss_test:0.01624, lr:5.48e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.229, tt:3135.384\n",
      "Ep:89, loss:0.00000, loss_test:0.01629, lr:5.48e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.216, tt:3169.415\n",
      "Ep:90, loss:0.00000, loss_test:0.01635, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.220, tt:3205.006\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00000, loss_test:0.01640, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.233, tt:3241.435\n",
      "Ep:92, loss:0.00000, loss_test:0.01655, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.230, tt:3276.351\n",
      "Ep:93, loss:0.00000, loss_test:0.01662, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.253, tt:3313.810\n",
      "Ep:94, loss:0.00000, loss_test:0.01664, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.266, tt:3350.242\n",
      "Ep:95, loss:0.00000, loss_test:0.01666, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.278, tt:3386.717\n",
      "Ep:96, loss:0.00000, loss_test:0.01679, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.298, tt:3423.904\n",
      "Ep:97, loss:0.00000, loss_test:0.01680, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.326, tt:3461.943\n",
      "Ep:98, loss:0.00000, loss_test:0.01685, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.341, tt:3498.750\n",
      "Ep:99, loss:0.00000, loss_test:0.01696, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.341, tt:3534.132\n",
      "Ep:100, loss:0.00000, loss_test:0.01700, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.346, tt:3569.930\n",
      "Ep:101, loss:0.00000, loss_test:0.01708, lr:5.48e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.335, tt:3604.153\n",
      "Ep:102, loss:0.00000, loss_test:0.01714, lr:5.43e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.335, tt:3639.539\n",
      "Ep:103, loss:0.00000, loss_test:0.01718, lr:5.37e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.331, tt:3674.467\n",
      "Ep:104, loss:0.00000, loss_test:0.01724, lr:5.32e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.338, tt:3710.466\n",
      "Ep:105, loss:0.00000, loss_test:0.01730, lr:5.27e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.335, tt:3745.489\n",
      "Ep:106, loss:0.00000, loss_test:0.01736, lr:5.21e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.358, tt:3783.325\n",
      "Ep:107, loss:0.00000, loss_test:0.01742, lr:5.16e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.360, tt:3818.928\n",
      "Ep:108, loss:0.00000, loss_test:0.01750, lr:5.11e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.338, tt:3851.883\n",
      "Ep:109, loss:0.00000, loss_test:0.01747, lr:5.06e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.305, tt:3883.498\n",
      "Ep:110, loss:0.00000, loss_test:0.01748, lr:5.01e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.275, tt:3915.519\n",
      "Ep:111, loss:0.00000, loss_test:0.01762, lr:4.96e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.245, tt:3947.478\n",
      "Ep:112, loss:0.00000, loss_test:0.01763, lr:4.91e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.190, tt:3976.517\n",
      "Ep:113, loss:0.00000, loss_test:0.01762, lr:4.86e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.153, tt:4007.420\n",
      "Ep:114, loss:0.00000, loss_test:0.01768, lr:4.81e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.131, tt:4040.082\n",
      "Ep:115, loss:0.00000, loss_test:0.01772, lr:4.76e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.089, tt:4070.315\n",
      "Ep:116, loss:0.00000, loss_test:0.01772, lr:4.71e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.141, tt:4111.535\n",
      "Ep:117, loss:0.00000, loss_test:0.01778, lr:4.67e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.146, tt:4147.267\n",
      "Ep:118, loss:0.00000, loss_test:0.01783, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.156, tt:4183.578\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00000, loss_test:0.01790, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.170, tt:4220.379\n",
      "Ep:120, loss:0.00000, loss_test:0.01786, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.165, tt:4255.015\n",
      "Ep:121, loss:0.00000, loss_test:0.01794, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.168, tt:4290.518\n",
      "Ep:122, loss:0.00000, loss_test:0.01798, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.174, tt:4326.363\n",
      "Ep:123, loss:0.00000, loss_test:0.01796, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.169, tt:4360.982\n",
      "Ep:124, loss:0.00000, loss_test:0.01805, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.189, tt:4398.672\n",
      "Ep:125, loss:0.00000, loss_test:0.01812, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.211, tt:4436.547\n",
      "Ep:126, loss:0.00000, loss_test:0.01812, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.208, tt:4471.410\n",
      "Ep:127, loss:0.00000, loss_test:0.01812, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.214, tt:4507.342\n",
      "Ep:128, loss:0.00000, loss_test:0.01820, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.204, tt:4541.325\n",
      "Ep:129, loss:0.00000, loss_test:0.01825, lr:4.62e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.212, tt:4577.553\n",
      "Ep:130, loss:0.00000, loss_test:0.01825, lr:4.57e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.205, tt:4611.803\n",
      "Ep:131, loss:0.00000, loss_test:0.01827, lr:4.53e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.199, tt:4646.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01833, lr:4.48e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.202, tt:4681.925\n",
      "Ep:133, loss:0.00000, loss_test:0.01835, lr:4.44e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.212, tt:4718.469\n",
      "Ep:134, loss:0.00000, loss_test:0.01838, lr:4.39e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.217, tt:4754.271\n",
      "Ep:135, loss:0.00000, loss_test:0.01838, lr:4.35e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.227, tt:4790.922\n",
      "Ep:136, loss:0.00000, loss_test:0.01845, lr:4.31e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.240, tt:4827.825\n",
      "Ep:137, loss:0.00000, loss_test:0.01850, lr:4.26e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.248, tt:4864.172\n",
      "Ep:138, loss:0.00000, loss_test:0.01850, lr:4.22e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.250, tt:4899.719\n",
      "Ep:139, loss:0.00000, loss_test:0.01854, lr:4.18e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.251, tt:4935.198\n",
      "Ep:140, loss:0.00000, loss_test:0.01855, lr:4.14e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.320, tt:4980.149\n",
      "Ep:141, loss:0.00000, loss_test:0.01862, lr:4.10e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.324, tt:5015.994\n",
      "Ep:142, loss:0.00000, loss_test:0.01863, lr:4.05e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.345, tt:5054.309\n",
      "Ep:143, loss:0.00000, loss_test:0.01865, lr:4.01e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.360, tt:5091.845\n",
      "Ep:144, loss:0.00000, loss_test:0.01865, lr:3.97e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.393, tt:5131.953\n",
      "Ep:145, loss:0.00000, loss_test:0.01867, lr:3.93e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.404, tt:5169.048\n",
      "Ep:146, loss:0.00000, loss_test:0.01872, lr:3.89e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.406, tt:5204.710\n",
      "Ep:147, loss:0.00000, loss_test:0.01873, lr:3.86e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.416, tt:5241.637\n",
      "Ep:148, loss:0.00000, loss_test:0.01874, lr:3.82e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.419, tt:5277.384\n",
      "Ep:149, loss:0.00000, loss_test:0.01877, lr:3.78e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.426, tt:5313.907\n",
      "Ep:150, loss:0.00000, loss_test:0.01878, lr:3.74e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.426, tt:5349.352\n",
      "Ep:151, loss:0.00000, loss_test:0.01879, lr:3.70e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.423, tt:5384.247\n",
      "Ep:152, loss:0.00000, loss_test:0.01885, lr:3.67e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.424, tt:5419.917\n",
      "Ep:153, loss:0.00000, loss_test:0.01888, lr:3.63e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.413, tt:5453.576\n",
      "Ep:154, loss:0.00000, loss_test:0.01888, lr:3.59e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.415, tt:5489.251\n",
      "Ep:155, loss:0.00000, loss_test:0.01888, lr:3.56e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.413, tt:5524.434\n",
      "Ep:156, loss:0.00000, loss_test:0.01891, lr:3.52e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.413, tt:5559.796\n",
      "Ep:157, loss:0.00000, loss_test:0.01892, lr:3.49e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.413, tt:5595.272\n",
      "Ep:158, loss:0.00000, loss_test:0.01894, lr:3.45e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.417, tt:5631.375\n",
      "Ep:159, loss:0.00000, loss_test:0.01898, lr:3.42e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.421, tt:5667.283\n",
      "Ep:160, loss:0.00000, loss_test:0.01901, lr:3.38e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.423, tt:5703.094\n",
      "Ep:161, loss:0.00000, loss_test:0.01896, lr:3.35e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.428, tt:5739.370\n",
      "Ep:162, loss:0.00000, loss_test:0.01897, lr:3.32e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.438, tt:5776.462\n",
      "Ep:163, loss:0.00000, loss_test:0.01904, lr:3.28e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.441, tt:5812.374\n",
      "Ep:164, loss:0.00000, loss_test:0.01905, lr:3.25e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.448, tt:5848.945\n",
      "Ep:165, loss:0.00000, loss_test:0.01905, lr:3.22e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.449, tt:5884.596\n",
      "Ep:166, loss:0.00000, loss_test:0.01907, lr:3.19e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.448, tt:5919.864\n",
      "Ep:167, loss:0.00000, loss_test:0.01908, lr:3.15e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.455, tt:5956.516\n",
      "Ep:168, loss:0.00000, loss_test:0.01909, lr:3.12e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.465, tt:5993.559\n",
      "Ep:169, loss:0.00000, loss_test:0.01908, lr:3.09e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.469, tt:6029.790\n",
      "Ep:170, loss:0.00000, loss_test:0.01906, lr:3.06e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.482, tt:6067.448\n",
      "Ep:171, loss:0.00000, loss_test:0.01909, lr:3.03e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.483, tt:6103.035\n",
      "Ep:172, loss:0.00000, loss_test:0.01913, lr:3.00e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.493, tt:6140.366\n",
      "Ep:173, loss:0.00000, loss_test:0.01914, lr:2.97e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.504, tt:6177.655\n",
      "Ep:174, loss:0.00000, loss_test:0.01913, lr:2.94e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.496, tt:6211.791\n",
      "Ep:175, loss:0.00000, loss_test:0.01915, lr:2.91e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.499, tt:6247.742\n",
      "Ep:176, loss:0.00000, loss_test:0.01918, lr:2.88e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.490, tt:6281.705\n",
      "Ep:177, loss:0.00000, loss_test:0.01918, lr:2.85e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.490, tt:6317.172\n",
      "Ep:178, loss:0.00000, loss_test:0.01920, lr:2.82e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.490, tt:6352.679\n",
      "Ep:179, loss:0.00000, loss_test:0.01921, lr:2.80e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.494, tt:6388.946\n",
      "Ep:180, loss:0.00000, loss_test:0.01922, lr:2.77e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.500, tt:6425.437\n",
      "Ep:181, loss:0.00000, loss_test:0.01922, lr:2.74e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.508, tt:6462.404\n",
      "Ep:182, loss:0.00000, loss_test:0.01924, lr:2.71e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.508, tt:6497.880\n",
      "Ep:183, loss:0.00000, loss_test:0.01925, lr:2.69e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.501, tt:6532.139\n",
      "Ep:184, loss:0.00000, loss_test:0.01926, lr:2.66e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.495, tt:6566.585\n",
      "Ep:185, loss:0.00000, loss_test:0.01927, lr:2.63e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.486, tt:6600.344\n",
      "Ep:186, loss:0.00000, loss_test:0.01929, lr:2.61e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.487, tt:6636.103\n",
      "Ep:187, loss:0.00000, loss_test:0.01928, lr:2.58e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.492, tt:6672.435\n",
      "Ep:188, loss:0.00000, loss_test:0.01930, lr:2.55e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.502, tt:6709.786\n",
      "Ep:189, loss:0.00000, loss_test:0.01931, lr:2.53e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.505, tt:6745.909\n",
      "Ep:190, loss:0.00000, loss_test:0.01930, lr:2.50e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.514, tt:6783.163\n",
      "Ep:191, loss:0.00000, loss_test:0.01932, lr:2.48e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.513, tt:6818.510\n",
      "Ep:192, loss:0.00000, loss_test:0.01934, lr:2.45e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.516, tt:6854.583\n",
      "Ep:193, loss:0.00000, loss_test:0.01935, lr:2.43e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.517, tt:6890.222\n",
      "Ep:194, loss:0.00000, loss_test:0.01935, lr:2.40e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.518, tt:6926.049\n",
      "Ep:195, loss:0.00000, loss_test:0.01935, lr:2.38e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.523, tt:6962.468\n",
      "Ep:196, loss:0.00000, loss_test:0.01937, lr:2.36e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.525, tt:6998.330\n",
      "Ep:197, loss:0.00000, loss_test:0.01938, lr:2.33e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.523, tt:7033.592\n",
      "Ep:198, loss:0.00000, loss_test:0.01939, lr:2.31e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.523, tt:7068.991\n",
      "Ep:199, loss:0.00000, loss_test:0.01940, lr:2.29e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.518, tt:7103.503\n",
      "Ep:200, loss:0.00000, loss_test:0.01940, lr:2.26e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.513, tt:7138.094\n",
      "Ep:201, loss:0.00000, loss_test:0.01942, lr:2.24e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.508, tt:7172.605\n",
      "Ep:202, loss:0.00000, loss_test:0.01942, lr:2.22e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.508, tt:7208.072\n",
      "Ep:203, loss:0.00000, loss_test:0.01943, lr:2.20e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.507, tt:7243.362\n",
      "Ep:204, loss:0.00000, loss_test:0.01944, lr:2.17e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.517, tt:7280.918\n",
      "Ep:205, loss:0.00000, loss_test:0.01944, lr:2.15e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.524, tt:7318.033\n",
      "Ep:206, loss:0.00000, loss_test:0.01945, lr:2.13e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.521, tt:7352.831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.01947, lr:2.11e-02, fs:0.86452 (r=0.770,p=0.985),  time:35.508, tt:7385.581\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14373, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.254, tt:37.254\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14256, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:34.851, tt:69.701\n",
      "Ep:2, loss:0.00027, loss_test:0.14039, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:34.431, tt:103.293\n",
      "Ep:3, loss:0.00027, loss_test:0.13667, lr:1.00e-02, fs:0.66406 (r=0.977,p=0.503),  time:34.903, tt:139.612\n",
      "Ep:4, loss:0.00026, loss_test:0.13071, lr:1.00e-02, fs:0.65000 (r=0.897,p=0.510),  time:34.642, tt:173.212\n",
      "Ep:5, loss:0.00024, loss_test:0.12205, lr:1.00e-02, fs:0.66977 (r=0.828,p=0.562),  time:34.843, tt:209.060\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11401, lr:1.00e-02, fs:0.64000 (r=0.644,p=0.636),  time:35.128, tt:245.893\n",
      "Ep:7, loss:0.00022, loss_test:0.11059, lr:1.00e-02, fs:0.67760 (r=0.713,p=0.646),  time:35.146, tt:281.166\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.11042, lr:1.00e-02, fs:0.66667 (r=0.782,p=0.581),  time:35.143, tt:316.289\n",
      "Ep:9, loss:0.00021, loss_test:0.10520, lr:1.00e-02, fs:0.68449 (r=0.736,p=0.640),  time:35.355, tt:353.551\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10088, lr:1.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:35.523, tt:390.754\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09743, lr:1.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:35.603, tt:427.240\n",
      "Ep:12, loss:0.00018, loss_test:0.09559, lr:1.00e-02, fs:0.70588 (r=0.690,p=0.723),  time:35.665, tt:463.649\n",
      "Ep:13, loss:0.00018, loss_test:0.09390, lr:1.00e-02, fs:0.73620 (r=0.690,p=0.789),  time:35.765, tt:500.716\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09259, lr:1.00e-02, fs:0.73620 (r=0.690,p=0.789),  time:35.774, tt:536.617\n",
      "Ep:15, loss:0.00016, loss_test:0.08935, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:35.953, tt:575.244\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08775, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:35.956, tt:611.260\n",
      "Ep:17, loss:0.00015, loss_test:0.08733, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:35.952, tt:647.143\n",
      "Ep:18, loss:0.00014, loss_test:0.08388, lr:1.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:35.955, tt:683.151\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08503, lr:1.00e-02, fs:0.75610 (r=0.713,p=0.805),  time:36.062, tt:721.235\n",
      "Ep:20, loss:0.00013, loss_test:0.08278, lr:1.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:36.094, tt:757.964\n",
      "Ep:21, loss:0.00012, loss_test:0.08300, lr:1.00e-02, fs:0.75610 (r=0.713,p=0.805),  time:36.096, tt:794.121\n",
      "Ep:22, loss:0.00012, loss_test:0.08046, lr:1.00e-02, fs:0.76829 (r=0.724,p=0.818),  time:35.953, tt:826.924\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08306, lr:1.00e-02, fs:0.77301 (r=0.724,p=0.829),  time:35.935, tt:862.434\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08141, lr:1.00e-02, fs:0.78528 (r=0.736,p=0.842),  time:35.837, tt:895.926\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.08088, lr:1.00e-02, fs:0.78049 (r=0.736,p=0.831),  time:35.828, tt:931.522\n",
      "Ep:26, loss:0.00009, loss_test:0.08262, lr:1.00e-02, fs:0.78750 (r=0.724,p=0.863),  time:35.796, tt:966.493\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.08222, lr:1.00e-02, fs:0.78261 (r=0.724,p=0.851),  time:35.728, tt:1000.396\n",
      "Ep:28, loss:0.00008, loss_test:0.08111, lr:1.00e-02, fs:0.78750 (r=0.724,p=0.863),  time:35.735, tt:1036.308\n",
      "Ep:29, loss:0.00008, loss_test:0.08171, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:35.759, tt:1072.767\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00007, loss_test:0.08151, lr:1.00e-02, fs:0.80503 (r=0.736,p=0.889),  time:35.791, tt:1109.515\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.07846, lr:1.00e-02, fs:0.80503 (r=0.736,p=0.889),  time:35.838, tt:1146.802\n",
      "Ep:32, loss:0.00007, loss_test:0.08261, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:35.868, tt:1183.646\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.07768, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:35.847, tt:1218.785\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.08690, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:35.862, tt:1255.169\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.07366, lr:1.00e-02, fs:0.83019 (r=0.759,p=0.917),  time:35.875, tt:1291.492\n",
      "Ep:36, loss:0.00005, loss_test:0.08579, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:35.783, tt:1323.955\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.07518, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:35.737, tt:1358.016\n",
      "Ep:38, loss:0.00004, loss_test:0.08587, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.805, tt:1396.397\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00004, loss_test:0.07781, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:35.780, tt:1431.219\n",
      "Ep:40, loss:0.00004, loss_test:0.07739, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.746, tt:1465.594\n",
      "Ep:41, loss:0.00004, loss_test:0.08309, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.767, tt:1502.217\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.07027, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:35.783, tt:1538.676\n",
      "Ep:43, loss:0.00003, loss_test:0.08885, lr:1.00e-02, fs:0.85161 (r=0.759,p=0.971),  time:35.824, tt:1576.263\n",
      "Ep:44, loss:0.00003, loss_test:0.07107, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.837, tt:1612.657\n",
      "Ep:45, loss:0.00003, loss_test:0.08583, lr:1.00e-02, fs:0.82119 (r=0.713,p=0.969),  time:35.781, tt:1645.928\n",
      "Ep:46, loss:0.00003, loss_test:0.07797, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.756, tt:1680.527\n",
      "Ep:47, loss:0.00002, loss_test:0.07755, lr:1.00e-02, fs:0.85161 (r=0.759,p=0.971),  time:35.808, tt:1718.778\n",
      "Ep:48, loss:0.00002, loss_test:0.08295, lr:1.00e-02, fs:0.80537 (r=0.690,p=0.968),  time:35.816, tt:1755.005\n",
      "Ep:49, loss:0.00002, loss_test:0.07102, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.821, tt:1791.069\n",
      "Ep:50, loss:0.00002, loss_test:0.08170, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:35.800, tt:1825.808\n",
      "Ep:51, loss:0.00002, loss_test:0.07519, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:35.822, tt:1862.768\n",
      "Ep:52, loss:0.00002, loss_test:0.07839, lr:1.00e-02, fs:0.80537 (r=0.690,p=0.968),  time:35.796, tt:1897.183\n",
      "Ep:53, loss:0.00001, loss_test:0.07983, lr:9.90e-03, fs:0.85714 (r=0.759,p=0.985),  time:35.812, tt:1933.845\n",
      "Ep:54, loss:0.00001, loss_test:0.07791, lr:9.80e-03, fs:0.85161 (r=0.759,p=0.971),  time:35.801, tt:1969.040\n",
      "Ep:55, loss:0.00001, loss_test:0.07680, lr:9.70e-03, fs:0.84211 (r=0.736,p=0.985),  time:35.825, tt:2006.223\n",
      "Ep:56, loss:0.00001, loss_test:0.07720, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.863, tt:2044.182\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.07967, lr:9.61e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.926, tt:2083.715\n",
      "Ep:58, loss:0.00001, loss_test:0.07591, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.919, tt:2119.247\n",
      "Ep:59, loss:0.00001, loss_test:0.07826, lr:9.61e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.932, tt:2155.909\n",
      "Ep:60, loss:0.00001, loss_test:0.07957, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.915, tt:2190.812\n",
      "Ep:61, loss:0.00001, loss_test:0.07612, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.928, tt:2227.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.07894, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.945, tt:2264.557\n",
      "Ep:63, loss:0.00001, loss_test:0.07707, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.969, tt:2301.993\n",
      "Ep:64, loss:0.00001, loss_test:0.07979, lr:9.61e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.978, tt:2338.587\n",
      "Ep:65, loss:0.00001, loss_test:0.07845, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.006, tt:2376.411\n",
      "Ep:66, loss:0.00001, loss_test:0.07848, lr:9.61e-03, fs:0.84211 (r=0.736,p=0.985),  time:36.029, tt:2413.918\n",
      "Ep:67, loss:0.00001, loss_test:0.07923, lr:9.61e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.019, tt:2449.292\n",
      "Ep:68, loss:0.00001, loss_test:0.08034, lr:9.51e-03, fs:0.81081 (r=0.690,p=0.984),  time:36.028, tt:2485.941\n",
      "Ep:69, loss:0.00001, loss_test:0.08189, lr:9.41e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.033, tt:2522.312\n",
      "Ep:70, loss:0.00001, loss_test:0.08025, lr:9.32e-03, fs:0.81081 (r=0.690,p=0.984),  time:36.028, tt:2557.983\n",
      "Ep:71, loss:0.00001, loss_test:0.08111, lr:9.23e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.050, tt:2595.626\n",
      "Ep:72, loss:0.00001, loss_test:0.08022, lr:9.14e-03, fs:0.83444 (r=0.724,p=0.984),  time:36.061, tt:2632.467\n",
      "Ep:73, loss:0.00000, loss_test:0.08058, lr:9.04e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.071, tt:2669.226\n",
      "Ep:74, loss:0.00000, loss_test:0.08020, lr:8.95e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.099, tt:2707.399\n",
      "Ep:75, loss:0.00000, loss_test:0.07910, lr:8.86e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.115, tt:2744.776\n",
      "Ep:76, loss:0.00000, loss_test:0.07935, lr:8.78e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.130, tt:2781.988\n",
      "Ep:77, loss:0.00000, loss_test:0.07771, lr:8.69e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.129, tt:2818.071\n",
      "Ep:78, loss:0.00000, loss_test:0.07905, lr:8.60e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.110, tt:2852.727\n",
      "Ep:79, loss:0.00000, loss_test:0.08038, lr:8.51e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.104, tt:2888.326\n",
      "Ep:80, loss:0.00000, loss_test:0.07776, lr:8.43e-03, fs:0.84211 (r=0.736,p=0.985),  time:36.075, tt:2922.106\n",
      "Ep:81, loss:0.00000, loss_test:0.08051, lr:8.35e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.070, tt:2957.734\n",
      "Ep:82, loss:0.00000, loss_test:0.08030, lr:8.26e-03, fs:0.81081 (r=0.690,p=0.984),  time:36.074, tt:2994.177\n",
      "Ep:83, loss:0.00000, loss_test:0.07887, lr:8.18e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.077, tt:3030.439\n",
      "Ep:84, loss:0.00000, loss_test:0.08105, lr:8.10e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.091, tt:3067.766\n",
      "Ep:85, loss:0.00000, loss_test:0.07979, lr:8.02e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.082, tt:3103.029\n",
      "Ep:86, loss:0.00000, loss_test:0.07872, lr:7.94e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.082, tt:3139.123\n",
      "Ep:87, loss:0.00000, loss_test:0.08020, lr:7.86e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.092, tt:3176.054\n",
      "Ep:88, loss:0.00000, loss_test:0.07924, lr:7.78e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.091, tt:3212.123\n",
      "Ep:89, loss:0.00000, loss_test:0.07882, lr:7.70e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.115, tt:3250.374\n",
      "Ep:90, loss:0.00000, loss_test:0.07856, lr:7.62e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.147, tt:3289.369\n",
      "Ep:91, loss:0.00000, loss_test:0.07839, lr:7.55e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.150, tt:3325.793\n",
      "Ep:92, loss:0.00000, loss_test:0.07823, lr:7.47e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.174, tt:3364.228\n",
      "Ep:93, loss:0.00000, loss_test:0.07883, lr:7.40e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.212, tt:3403.903\n",
      "Ep:94, loss:0.00000, loss_test:0.07840, lr:7.32e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.215, tt:3440.465\n",
      "Ep:95, loss:0.00000, loss_test:0.07793, lr:7.25e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.242, tt:3479.265\n",
      "Ep:96, loss:0.00000, loss_test:0.07854, lr:7.18e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.245, tt:3515.773\n",
      "Ep:97, loss:0.00000, loss_test:0.07827, lr:7.11e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.252, tt:3552.729\n",
      "Ep:98, loss:0.00000, loss_test:0.07908, lr:7.03e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.268, tt:3590.564\n",
      "Ep:99, loss:0.00000, loss_test:0.07943, lr:6.96e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.271, tt:3627.066\n",
      "Ep:100, loss:0.00000, loss_test:0.07840, lr:6.89e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.273, tt:3663.593\n",
      "Ep:101, loss:0.00000, loss_test:0.07889, lr:6.83e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.267, tt:3699.226\n",
      "Ep:102, loss:0.00000, loss_test:0.07928, lr:6.76e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.242, tt:3732.925\n",
      "Ep:103, loss:0.00000, loss_test:0.07842, lr:6.69e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.241, tt:3769.084\n",
      "Ep:104, loss:0.00000, loss_test:0.07840, lr:6.62e-03, fs:0.82667 (r=0.713,p=0.984),  time:36.243, tt:3805.515\n",
      "Ep:105, loss:0.00000, loss_test:0.07917, lr:6.56e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.235, tt:3840.926\n",
      "Ep:106, loss:0.00000, loss_test:0.07859, lr:6.49e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.213, tt:3874.793\n",
      "Ep:107, loss:0.00000, loss_test:0.07861, lr:6.43e-03, fs:0.84967 (r=0.747,p=0.985),  time:36.168, tt:3906.176\n",
      "Ep:108, loss:0.00000, loss_test:0.07865, lr:6.36e-03, fs:0.86452 (r=0.770,p=0.985),  time:36.136, tt:3938.828\n",
      "Ep:109, loss:0.00000, loss_test:0.07891, lr:6.30e-03, fs:0.82667 (r=0.713,p=0.984),  time:36.125, tt:3973.713\n",
      "Ep:110, loss:0.00000, loss_test:0.07864, lr:6.24e-03, fs:0.85714 (r=0.759,p=0.985),  time:36.083, tt:4005.262\n",
      "Ep:111, loss:0.00000, loss_test:0.07880, lr:6.17e-03, fs:0.81081 (r=0.690,p=0.984),  time:36.036, tt:4036.010\n",
      "Ep:112, loss:0.00000, loss_test:0.07939, lr:6.11e-03, fs:0.81879 (r=0.701,p=0.984),  time:35.997, tt:4067.622\n",
      "Ep:113, loss:0.00000, loss_test:0.07901, lr:6.05e-03, fs:0.81879 (r=0.701,p=0.984),  time:35.961, tt:4099.572\n",
      "Ep:114, loss:0.00000, loss_test:0.07901, lr:5.99e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.931, tt:4132.019\n",
      "Ep:115, loss:0.00000, loss_test:0.07917, lr:5.93e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.910, tt:4165.582\n",
      "Ep:116, loss:0.00000, loss_test:0.07901, lr:5.87e-03, fs:0.81879 (r=0.701,p=0.984),  time:35.872, tt:4197.001\n",
      "Ep:117, loss:0.00000, loss_test:0.07910, lr:5.81e-03, fs:0.81879 (r=0.701,p=0.984),  time:35.850, tt:4230.296\n",
      "Ep:118, loss:0.00000, loss_test:0.07958, lr:5.75e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.834, tt:4264.243\n",
      "Ep:119, loss:0.00000, loss_test:0.07927, lr:5.70e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.781, tt:4293.714\n",
      "Ep:120, loss:0.00000, loss_test:0.07903, lr:5.64e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.739, tt:4324.449\n",
      "Ep:121, loss:0.00000, loss_test:0.07914, lr:5.58e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.714, tt:4357.077\n",
      "Ep:122, loss:0.00000, loss_test:0.07918, lr:5.53e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.689, tt:4389.709\n",
      "Ep:123, loss:0.00000, loss_test:0.07965, lr:5.47e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.661, tt:4421.932\n",
      "Ep:124, loss:0.00000, loss_test:0.07963, lr:5.42e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.621, tt:4452.585\n",
      "Ep:125, loss:0.00000, loss_test:0.07963, lr:5.36e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.598, tt:4485.397\n",
      "Ep:126, loss:0.00000, loss_test:0.07958, lr:5.31e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.570, tt:4517.414\n",
      "Ep:127, loss:0.00000, loss_test:0.07913, lr:5.26e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.536, tt:4548.644\n",
      "Ep:128, loss:0.00000, loss_test:0.07880, lr:5.20e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.516, tt:4581.531\n",
      "Ep:129, loss:0.00000, loss_test:0.07924, lr:5.15e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.490, tt:4613.726\n",
      "Ep:130, loss:0.00000, loss_test:0.07946, lr:5.10e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.482, tt:4648.169\n",
      "Ep:131, loss:0.00000, loss_test:0.07897, lr:5.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.472, tt:4682.242\n",
      "Ep:132, loss:0.00000, loss_test:0.07895, lr:5.00e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.440, tt:4713.574\n",
      "Ep:133, loss:0.00000, loss_test:0.07905, lr:4.95e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.408, tt:4744.713\n",
      "Ep:134, loss:0.00000, loss_test:0.07868, lr:4.90e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.396, tt:4778.431\n",
      "Ep:135, loss:0.00000, loss_test:0.07884, lr:4.85e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.385, tt:4812.395\n",
      "Ep:136, loss:0.00000, loss_test:0.07910, lr:4.80e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.360, tt:4844.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.07899, lr:4.75e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.337, tt:4876.522\n",
      "Ep:138, loss:0.00000, loss_test:0.07890, lr:4.71e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.312, tt:4908.300\n",
      "Ep:139, loss:0.00000, loss_test:0.07887, lr:4.66e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.279, tt:4939.099\n",
      "Ep:140, loss:0.00000, loss_test:0.07894, lr:4.61e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.244, tt:4969.383\n",
      "Ep:141, loss:0.00000, loss_test:0.07936, lr:4.57e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.213, tt:5000.310\n",
      "Ep:142, loss:0.00000, loss_test:0.07965, lr:4.52e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.194, tt:5032.693\n",
      "Ep:143, loss:0.00000, loss_test:0.07926, lr:4.48e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.160, tt:5063.005\n",
      "Ep:144, loss:0.00000, loss_test:0.07899, lr:4.43e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.114, tt:5091.485\n",
      "Ep:145, loss:0.00000, loss_test:0.07942, lr:4.39e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.086, tt:5122.575\n",
      "Ep:146, loss:0.00000, loss_test:0.08001, lr:4.34e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.080, tt:5156.766\n",
      "Ep:147, loss:0.00000, loss_test:0.08073, lr:4.30e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.038, tt:5185.633\n",
      "Ep:148, loss:0.00000, loss_test:0.08090, lr:4.26e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.020, tt:5217.985\n",
      "Ep:149, loss:0.00000, loss_test:0.08067, lr:4.21e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.992, tt:5248.747\n",
      "Ep:150, loss:0.00000, loss_test:0.07999, lr:4.17e-03, fs:0.81879 (r=0.701,p=0.984),  time:34.973, tt:5280.906\n",
      "Ep:151, loss:0.00000, loss_test:0.07972, lr:4.13e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.951, tt:5312.565\n",
      "Ep:152, loss:0.00000, loss_test:0.08009, lr:4.09e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.920, tt:5342.773\n",
      "Ep:153, loss:0.00000, loss_test:0.07986, lr:4.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.911, tt:5376.340\n",
      "Ep:154, loss:0.00000, loss_test:0.07969, lr:4.01e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.886, tt:5407.284\n",
      "Ep:155, loss:0.00000, loss_test:0.07973, lr:3.97e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.871, tt:5439.918\n",
      "Ep:156, loss:0.00000, loss_test:0.07963, lr:3.93e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.855, tt:5472.302\n",
      "Ep:157, loss:0.00000, loss_test:0.07936, lr:3.89e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.836, tt:5504.024\n",
      "Ep:158, loss:0.00000, loss_test:0.07946, lr:3.85e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.818, tt:5536.051\n",
      "Ep:159, loss:0.00000, loss_test:0.07972, lr:3.81e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.780, tt:5564.794\n",
      "Ep:160, loss:0.00000, loss_test:0.07981, lr:3.77e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.739, tt:5592.996\n",
      "Ep:161, loss:0.00000, loss_test:0.07938, lr:3.73e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.706, tt:5622.375\n",
      "Ep:162, loss:0.00000, loss_test:0.07920, lr:3.70e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.678, tt:5652.495\n",
      "Ep:163, loss:0.00000, loss_test:0.07949, lr:3.66e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.652, tt:5682.959\n",
      "Ep:164, loss:0.00000, loss_test:0.07922, lr:3.62e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.635, tt:5714.817\n",
      "Ep:165, loss:0.00000, loss_test:0.07892, lr:3.59e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.607, tt:5744.827\n",
      "Ep:166, loss:0.00000, loss_test:0.07925, lr:3.55e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.576, tt:5774.205\n",
      "Ep:167, loss:0.00000, loss_test:0.07965, lr:3.52e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.555, tt:5805.184\n",
      "Ep:168, loss:0.00000, loss_test:0.07973, lr:3.48e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.529, tt:5835.459\n",
      "Ep:169, loss:0.00000, loss_test:0.07911, lr:3.45e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.512, tt:5867.037\n",
      "Ep:170, loss:0.00000, loss_test:0.07891, lr:3.41e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.478, tt:5895.734\n",
      "Ep:171, loss:0.00000, loss_test:0.07915, lr:3.38e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.443, tt:5924.270\n",
      "Ep:172, loss:0.00000, loss_test:0.07918, lr:3.34e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.422, tt:5955.089\n",
      "Ep:173, loss:0.00000, loss_test:0.07912, lr:3.31e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.395, tt:5984.733\n",
      "Ep:174, loss:0.00000, loss_test:0.07893, lr:3.28e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.382, tt:6016.931\n",
      "Ep:175, loss:0.00000, loss_test:0.07881, lr:3.24e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.381, tt:6051.139\n",
      "Ep:176, loss:0.00000, loss_test:0.07886, lr:3.21e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.369, tt:6083.364\n",
      "Ep:177, loss:0.00000, loss_test:0.07892, lr:3.18e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.348, tt:6113.947\n",
      "Ep:178, loss:0.00000, loss_test:0.07886, lr:3.15e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.335, tt:6145.990\n",
      "Ep:179, loss:0.00000, loss_test:0.07897, lr:3.12e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.310, tt:6175.762\n",
      "Ep:180, loss:0.00000, loss_test:0.07903, lr:3.09e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.292, tt:6206.790\n",
      "Ep:181, loss:0.00000, loss_test:0.07878, lr:3.05e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.273, tt:6237.753\n",
      "Ep:182, loss:0.00000, loss_test:0.07910, lr:3.02e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.264, tt:6270.393\n",
      "Ep:183, loss:0.00000, loss_test:0.07931, lr:2.99e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.229, tt:6298.144\n",
      "Ep:184, loss:0.00000, loss_test:0.07937, lr:2.96e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.204, tt:6327.799\n",
      "Ep:185, loss:0.00000, loss_test:0.07924, lr:2.93e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.173, tt:6356.254\n",
      "Ep:186, loss:0.00000, loss_test:0.07907, lr:2.90e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.149, tt:6385.944\n",
      "Ep:187, loss:0.00000, loss_test:0.07879, lr:2.88e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.127, tt:6415.858\n",
      "Ep:188, loss:0.00000, loss_test:0.07872, lr:2.85e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.117, tt:6448.157\n",
      "Ep:189, loss:0.00000, loss_test:0.07890, lr:2.82e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.112, tt:6481.348\n",
      "Ep:190, loss:0.00000, loss_test:0.07888, lr:2.79e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.104, tt:6513.835\n",
      "Ep:191, loss:0.00000, loss_test:0.07898, lr:2.76e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.100, tt:6547.184\n",
      "Ep:192, loss:0.00000, loss_test:0.07881, lr:2.73e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.083, tt:6577.939\n",
      "Ep:193, loss:0.00000, loss_test:0.07878, lr:2.71e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.073, tt:6610.110\n",
      "Ep:194, loss:0.00000, loss_test:0.07885, lr:2.68e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.065, tt:6642.597\n",
      "Ep:195, loss:0.00000, loss_test:0.07885, lr:2.65e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.057, tt:6675.177\n",
      "Ep:196, loss:0.00000, loss_test:0.07870, lr:2.63e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.049, tt:6707.588\n",
      "Ep:197, loss:0.00000, loss_test:0.07879, lr:2.60e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.044, tt:6740.629\n",
      "Ep:198, loss:0.00000, loss_test:0.07910, lr:2.57e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.037, tt:6773.458\n",
      "Ep:199, loss:0.00000, loss_test:0.07899, lr:2.55e-03, fs:0.81081 (r=0.690,p=0.984),  time:34.014, tt:6802.810\n",
      "Ep:200, loss:0.00000, loss_test:0.07886, lr:2.52e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.991, tt:6832.242\n",
      "Ep:201, loss:0.00000, loss_test:0.07879, lr:2.50e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.970, tt:6862.017\n",
      "Ep:202, loss:0.00000, loss_test:0.07867, lr:2.47e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.956, tt:6893.111\n",
      "Ep:203, loss:0.00000, loss_test:0.07872, lr:2.45e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.950, tt:6925.858\n",
      "Ep:204, loss:0.00000, loss_test:0.07862, lr:2.42e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.940, tt:6957.678\n",
      "Ep:205, loss:0.00000, loss_test:0.07867, lr:2.40e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.939, tt:6991.526\n",
      "Ep:206, loss:0.00000, loss_test:0.07885, lr:2.38e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.911, tt:7019.665\n",
      "Ep:207, loss:0.00000, loss_test:0.07878, lr:2.35e-03, fs:0.81081 (r=0.690,p=0.984),  time:33.874, tt:7045.732\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02021, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:21.798, tt:21.798\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02236, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.215, tt:58.431\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02317, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.190, tt:93.570\n",
      "Ep:3, loss:0.00005, loss_test:0.02220, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.967, tt:131.869\n",
      "Ep:4, loss:0.00004, loss_test:0.02040, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:34.542, tt:172.708\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01858, lr:6.00e-02, fs:0.68100 (r=0.960,p=0.528),  time:35.640, tt:213.841\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01749, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.060, tt:252.423\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01706, lr:6.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:36.960, tt:295.683\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01655, lr:6.00e-02, fs:0.70130 (r=0.818,p=0.614),  time:37.154, tt:334.385\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01616, lr:6.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:37.104, tt:371.039\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:36.920, tt:406.124\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01591, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:36.874, tt:442.488\n",
      "Ep:12, loss:0.00003, loss_test:0.01571, lr:6.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:36.701, tt:477.115\n",
      "Ep:13, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:36.822, tt:515.510\n",
      "Ep:14, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:36.709, tt:550.637\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01520, lr:6.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:36.624, tt:585.979\n",
      "Ep:16, loss:0.00003, loss_test:0.01509, lr:6.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:36.606, tt:622.294\n",
      "Ep:17, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:36.513, tt:657.226\n",
      "Ep:18, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:36.430, tt:692.177\n",
      "Ep:19, loss:0.00003, loss_test:0.01507, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:36.371, tt:727.420\n",
      "Ep:20, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:36.299, tt:762.272\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:36.298, tt:798.553\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:36.277, tt:834.369\n",
      "Ep:23, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:36.235, tt:869.639\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.200, tt:904.996\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.136, tt:939.543\n",
      "Ep:26, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:36.164, tt:976.423\n",
      "Ep:27, loss:0.00002, loss_test:0.01482, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:36.124, tt:1011.473\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:36.165, tt:1048.781\n",
      "Ep:29, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:36.097, tt:1082.920\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:36.055, tt:1117.690\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:36.056, tt:1153.797\n",
      "Ep:32, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:36.059, tt:1189.943\n",
      "Ep:33, loss:0.00002, loss_test:0.01460, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:35.995, tt:1223.839\n",
      "Ep:34, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:35.969, tt:1258.918\n",
      "Ep:35, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.925, tt:1293.313\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.798, tt:1324.524\n",
      "Ep:37, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:35.783, tt:1359.739\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:35.763, tt:1394.765\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01439, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:35.705, tt:1428.196\n",
      "Ep:40, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:35.758, tt:1466.076\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:35.772, tt:1502.422\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01428, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:35.775, tt:1538.337\n",
      "Ep:43, loss:0.00001, loss_test:0.01422, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:35.749, tt:1572.976\n",
      "Ep:44, loss:0.00001, loss_test:0.01420, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:35.696, tt:1606.331\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01419, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:35.684, tt:1641.479\n",
      "Ep:46, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.673, tt:1676.654\n",
      "Ep:47, loss:0.00001, loss_test:0.01419, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.695, tt:1713.344\n",
      "Ep:48, loss:0.00001, loss_test:0.01413, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.671, tt:1747.872\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01402, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.647, tt:1782.360\n",
      "Ep:50, loss:0.00001, loss_test:0.01404, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:35.640, tt:1817.643\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01404, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:35.625, tt:1852.516\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01400, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.627, tt:1888.255\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01396, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.610, tt:1922.955\n",
      "Ep:54, loss:0.00001, loss_test:0.01398, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.601, tt:1958.032\n",
      "Ep:55, loss:0.00001, loss_test:0.01399, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.568, tt:1991.808\n",
      "Ep:56, loss:0.00001, loss_test:0.01398, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:35.497, tt:2023.308\n",
      "Ep:57, loss:0.00001, loss_test:0.01395, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.465, tt:2056.944\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01394, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.476, tt:2093.068\n",
      "Ep:59, loss:0.00001, loss_test:0.01393, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:35.455, tt:2127.295\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01389, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:35.441, tt:2161.918\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:35.416, tt:2195.795\n",
      "Ep:62, loss:0.00001, loss_test:0.01392, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:35.384, tt:2229.210\n",
      "Ep:63, loss:0.00001, loss_test:0.01387, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:35.367, tt:2263.459\n",
      "Ep:64, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:35.362, tt:2298.529\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01392, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.325, tt:2331.472\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01395, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.306, tt:2365.521\n",
      "Ep:67, loss:0.00001, loss_test:0.01394, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.288, tt:2399.604\n",
      "Ep:68, loss:0.00001, loss_test:0.01391, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.273, tt:2433.848\n",
      "Ep:69, loss:0.00001, loss_test:0.01395, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.260, tt:2468.179\n",
      "Ep:70, loss:0.00001, loss_test:0.01397, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.228, tt:2501.198\n",
      "Ep:71, loss:0.00001, loss_test:0.01400, lr:6.00e-02, fs:0.90256 (r=0.889,p=0.917),  time:35.225, tt:2536.212\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01400, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.209, tt:2570.266\n",
      "Ep:73, loss:0.00001, loss_test:0.01393, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:35.183, tt:2603.565\n",
      "Ep:74, loss:0.00001, loss_test:0.01396, lr:6.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.158, tt:2636.833\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01404, lr:6.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:35.162, tt:2672.279\n",
      "Ep:76, loss:0.00001, loss_test:0.01406, lr:6.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.120, tt:2704.270\n",
      "Ep:77, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.093, tt:2737.257\n",
      "Ep:78, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.078, tt:2771.196\n",
      "Ep:79, loss:0.00001, loss_test:0.01409, lr:6.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.091, tt:2807.280\n",
      "Ep:80, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:35.086, tt:2842.003\n",
      "Ep:81, loss:0.00001, loss_test:0.01411, lr:6.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:35.071, tt:2875.810\n",
      "Ep:82, loss:0.00001, loss_test:0.01413, lr:6.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:35.049, tt:2909.100\n",
      "Ep:83, loss:0.00001, loss_test:0.01412, lr:6.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:35.054, tt:2944.563\n",
      "Ep:84, loss:0.00001, loss_test:0.01419, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.042, tt:2978.611\n",
      "Ep:85, loss:0.00001, loss_test:0.01420, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.029, tt:3012.522\n",
      "Ep:86, loss:0.00001, loss_test:0.01420, lr:5.94e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.048, tt:3049.144\n",
      "Ep:87, loss:0.00001, loss_test:0.01428, lr:5.88e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.036, tt:3083.151\n",
      "Ep:88, loss:0.00001, loss_test:0.01432, lr:5.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.041, tt:3118.667\n",
      "Ep:89, loss:0.00001, loss_test:0.01429, lr:5.76e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.037, tt:3153.317\n",
      "Ep:90, loss:0.00001, loss_test:0.01433, lr:5.71e-02, fs:0.88770 (r=0.838,p=0.943),  time:35.032, tt:3187.871\n",
      "Ep:91, loss:0.00001, loss_test:0.01442, lr:5.65e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.023, tt:3222.143\n",
      "Ep:92, loss:0.00001, loss_test:0.01441, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.012, tt:3256.129\n",
      "Ep:93, loss:0.00001, loss_test:0.01445, lr:5.54e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.990, tt:3289.020\n",
      "Ep:94, loss:0.00001, loss_test:0.01447, lr:5.48e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.974, tt:3322.522\n",
      "Ep:95, loss:0.00001, loss_test:0.01453, lr:5.43e-02, fs:0.88172 (r=0.828,p=0.943),  time:34.962, tt:3356.332\n",
      "Ep:96, loss:0.00001, loss_test:0.01456, lr:5.37e-02, fs:0.88172 (r=0.828,p=0.943),  time:34.966, tt:3391.739\n",
      "Ep:97, loss:0.00001, loss_test:0.01463, lr:5.32e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.937, tt:3423.862\n",
      "Ep:98, loss:0.00001, loss_test:0.01464, lr:5.27e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.924, tt:3457.498\n",
      "Ep:99, loss:0.00001, loss_test:0.01463, lr:5.21e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.921, tt:3492.096\n",
      "Ep:100, loss:0.00001, loss_test:0.01467, lr:5.16e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.937, tt:3528.642\n",
      "Ep:101, loss:0.00001, loss_test:0.01472, lr:5.11e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.937, tt:3563.572\n",
      "Ep:102, loss:0.00001, loss_test:0.01478, lr:5.06e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.912, tt:3595.970\n",
      "Ep:103, loss:0.00001, loss_test:0.01481, lr:5.01e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.916, tt:3631.269\n",
      "Ep:104, loss:0.00001, loss_test:0.01484, lr:4.96e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.921, tt:3666.733\n",
      "Ep:105, loss:0.00000, loss_test:0.01482, lr:4.91e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.893, tt:3698.695\n",
      "Ep:106, loss:0.00000, loss_test:0.01491, lr:4.86e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.875, tt:3731.653\n",
      "Ep:107, loss:0.00000, loss_test:0.01498, lr:4.81e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.885, tt:3767.528\n",
      "Ep:108, loss:0.00000, loss_test:0.01496, lr:4.76e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.872, tt:3801.034\n",
      "Ep:109, loss:0.00000, loss_test:0.01503, lr:4.71e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.859, tt:3834.438\n",
      "Ep:110, loss:0.00000, loss_test:0.01506, lr:4.67e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.860, tt:3869.409\n",
      "Ep:111, loss:0.00000, loss_test:0.01507, lr:4.62e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.857, tt:3903.976\n",
      "Ep:112, loss:0.00000, loss_test:0.01512, lr:4.57e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.846, tt:3937.611\n",
      "Ep:113, loss:0.00000, loss_test:0.01517, lr:4.53e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.842, tt:3971.982\n",
      "Ep:114, loss:0.00000, loss_test:0.01517, lr:4.48e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.820, tt:4004.261\n",
      "Ep:115, loss:0.00000, loss_test:0.01520, lr:4.44e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.787, tt:4035.332\n",
      "Ep:116, loss:0.00000, loss_test:0.01527, lr:4.39e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.791, tt:4070.597\n",
      "Ep:117, loss:0.00000, loss_test:0.01531, lr:4.35e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.770, tt:4102.853\n",
      "Ep:118, loss:0.00000, loss_test:0.01531, lr:4.31e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.788, tt:4139.740\n",
      "Ep:119, loss:0.00000, loss_test:0.01535, lr:4.26e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.800, tt:4175.958\n",
      "Ep:120, loss:0.00000, loss_test:0.01540, lr:4.22e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.795, tt:4210.146\n",
      "Ep:121, loss:0.00000, loss_test:0.01543, lr:4.18e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.788, tt:4244.121\n",
      "Ep:122, loss:0.00000, loss_test:0.01544, lr:4.14e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.772, tt:4277.016\n",
      "Ep:123, loss:0.00000, loss_test:0.01547, lr:4.10e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.762, tt:4310.506\n",
      "Ep:124, loss:0.00000, loss_test:0.01554, lr:4.05e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.744, tt:4342.991\n",
      "Ep:125, loss:0.00000, loss_test:0.01556, lr:4.01e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.742, tt:4377.439\n",
      "Ep:126, loss:0.00000, loss_test:0.01555, lr:3.97e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.730, tt:4410.739\n",
      "Ep:127, loss:0.00000, loss_test:0.01559, lr:3.93e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.730, tt:4445.487\n",
      "Ep:128, loss:0.00000, loss_test:0.01569, lr:3.89e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.727, tt:4479.800\n",
      "Ep:129, loss:0.00000, loss_test:0.01569, lr:3.86e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.737, tt:4515.811\n",
      "Ep:130, loss:0.00000, loss_test:0.01569, lr:3.82e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.739, tt:4550.752\n",
      "Ep:131, loss:0.00000, loss_test:0.01576, lr:3.78e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.744, tt:4586.200\n",
      "Ep:132, loss:0.00000, loss_test:0.01580, lr:3.74e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.720, tt:4617.791\n",
      "Ep:133, loss:0.00000, loss_test:0.01580, lr:3.70e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.721, tt:4652.651\n",
      "Ep:134, loss:0.00000, loss_test:0.01584, lr:3.67e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.725, tt:4687.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.01587, lr:3.63e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.731, tt:4723.397\n",
      "Ep:136, loss:0.00000, loss_test:0.01587, lr:3.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.738, tt:4759.058\n",
      "Ep:137, loss:0.00000, loss_test:0.01590, lr:3.56e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.746, tt:4794.923\n",
      "Ep:138, loss:0.00000, loss_test:0.01592, lr:3.52e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.750, tt:4830.224\n",
      "Ep:139, loss:0.00000, loss_test:0.01597, lr:3.49e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.761, tt:4866.552\n",
      "Ep:140, loss:0.00000, loss_test:0.01599, lr:3.45e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.753, tt:4900.224\n",
      "Ep:141, loss:0.00000, loss_test:0.01602, lr:3.42e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.760, tt:4935.901\n",
      "Ep:142, loss:0.00000, loss_test:0.01605, lr:3.38e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.799, tt:4976.192\n",
      "Ep:143, loss:0.00000, loss_test:0.01606, lr:3.35e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.788, tt:5009.438\n",
      "Ep:144, loss:0.00000, loss_test:0.01609, lr:3.32e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.778, tt:5042.740\n",
      "Ep:145, loss:0.00000, loss_test:0.01613, lr:3.28e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.794, tt:5079.851\n",
      "Ep:146, loss:0.00000, loss_test:0.01615, lr:3.25e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.796, tt:5115.018\n",
      "Ep:147, loss:0.00000, loss_test:0.01618, lr:3.22e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.808, tt:5151.513\n",
      "Ep:148, loss:0.00000, loss_test:0.01621, lr:3.19e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.806, tt:5186.069\n",
      "Ep:149, loss:0.00000, loss_test:0.01624, lr:3.15e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.802, tt:5220.298\n",
      "Ep:150, loss:0.00000, loss_test:0.01625, lr:3.12e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.807, tt:5255.874\n",
      "Ep:151, loss:0.00000, loss_test:0.01629, lr:3.09e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.810, tt:5291.098\n",
      "Ep:152, loss:0.00000, loss_test:0.01630, lr:3.06e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.815, tt:5326.725\n",
      "Ep:153, loss:0.00000, loss_test:0.01630, lr:3.03e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.804, tt:5359.793\n",
      "Ep:154, loss:0.00000, loss_test:0.01632, lr:3.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.804, tt:5394.572\n",
      "Ep:155, loss:0.00000, loss_test:0.01635, lr:2.97e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.803, tt:5429.307\n",
      "Ep:156, loss:0.00000, loss_test:0.01639, lr:2.94e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.802, tt:5463.955\n",
      "Ep:157, loss:0.00000, loss_test:0.01641, lr:2.91e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.812, tt:5500.282\n",
      "Ep:158, loss:0.00000, loss_test:0.01642, lr:2.88e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.816, tt:5535.712\n",
      "Ep:159, loss:0.00000, loss_test:0.01644, lr:2.85e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.816, tt:5570.584\n",
      "Ep:160, loss:0.00000, loss_test:0.01647, lr:2.82e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.820, tt:5605.984\n",
      "Ep:161, loss:0.00000, loss_test:0.01648, lr:2.80e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.814, tt:5639.885\n",
      "Ep:162, loss:0.00000, loss_test:0.01649, lr:2.77e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.807, tt:5673.577\n",
      "Ep:163, loss:0.00000, loss_test:0.01652, lr:2.74e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.815, tt:5709.617\n",
      "Ep:164, loss:0.00000, loss_test:0.01653, lr:2.71e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.818, tt:5745.005\n",
      "Ep:165, loss:0.00000, loss_test:0.01655, lr:2.69e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.823, tt:5780.695\n",
      "Ep:166, loss:0.00000, loss_test:0.01658, lr:2.66e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.855, tt:5820.859\n",
      "Ep:167, loss:0.00000, loss_test:0.01659, lr:2.63e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.853, tt:5855.341\n",
      "Ep:168, loss:0.00000, loss_test:0.01661, lr:2.61e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.853, tt:5890.190\n",
      "Ep:169, loss:0.00000, loss_test:0.01663, lr:2.58e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.855, tt:5925.379\n",
      "Ep:170, loss:0.00000, loss_test:0.01667, lr:2.55e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.861, tt:5961.189\n",
      "Ep:171, loss:0.00000, loss_test:0.01668, lr:2.53e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.863, tt:5996.498\n",
      "Ep:172, loss:0.00000, loss_test:0.01670, lr:2.50e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.866, tt:6031.897\n",
      "Ep:173, loss:0.00000, loss_test:0.01671, lr:2.48e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.871, tt:6067.489\n",
      "Ep:174, loss:0.00000, loss_test:0.01671, lr:2.45e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.869, tt:6102.092\n",
      "Ep:175, loss:0.00000, loss_test:0.01673, lr:2.43e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.880, tt:6138.860\n",
      "Ep:176, loss:0.00000, loss_test:0.01677, lr:2.40e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.892, tt:6175.831\n",
      "Ep:177, loss:0.00000, loss_test:0.01679, lr:2.38e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.902, tt:6212.558\n",
      "Ep:178, loss:0.00000, loss_test:0.01679, lr:2.36e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.908, tt:6248.512\n",
      "Ep:179, loss:0.00000, loss_test:0.01682, lr:2.33e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.916, tt:6284.798\n",
      "Ep:180, loss:0.00000, loss_test:0.01684, lr:2.31e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.924, tt:6321.300\n",
      "Ep:181, loss:0.00000, loss_test:0.01686, lr:2.29e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.940, tt:6359.072\n",
      "Ep:182, loss:0.00000, loss_test:0.01689, lr:2.26e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.947, tt:6395.357\n",
      "Ep:183, loss:0.00000, loss_test:0.01690, lr:2.24e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.945, tt:6429.797\n",
      "Ep:184, loss:0.00000, loss_test:0.01691, lr:2.22e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.949, tt:6465.569\n",
      "Ep:185, loss:0.00000, loss_test:0.01691, lr:2.20e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.953, tt:6501.338\n",
      "Ep:186, loss:0.00000, loss_test:0.01693, lr:2.17e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.951, tt:6535.833\n",
      "Ep:187, loss:0.00000, loss_test:0.01696, lr:2.15e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.948, tt:6570.216\n",
      "Ep:188, loss:0.00000, loss_test:0.01697, lr:2.13e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.945, tt:6604.600\n",
      "Ep:189, loss:0.00000, loss_test:0.01699, lr:2.11e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.954, tt:6641.326\n",
      "Ep:190, loss:0.00000, loss_test:0.01701, lr:2.09e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.985, tt:6682.105\n",
      "Ep:191, loss:0.00000, loss_test:0.01704, lr:2.07e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.989, tt:6717.933\n",
      "Ep:192, loss:0.00000, loss_test:0.01705, lr:2.05e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.993, tt:6753.554\n",
      "Ep:193, loss:0.00000, loss_test:0.01704, lr:2.03e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.986, tt:6787.193\n",
      "Ep:194, loss:0.00000, loss_test:0.01707, lr:2.01e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.983, tt:6821.619\n",
      "Ep:195, loss:0.00000, loss_test:0.01709, lr:1.99e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.988, tt:6857.647\n",
      "Ep:196, loss:0.00000, loss_test:0.01710, lr:1.97e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.981, tt:6891.258\n",
      "Ep:197, loss:0.00000, loss_test:0.01710, lr:1.95e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.978, tt:6925.608\n",
      "Ep:198, loss:0.00000, loss_test:0.01712, lr:1.93e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.976, tt:6960.215\n",
      "Ep:199, loss:0.00000, loss_test:0.01715, lr:1.91e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.974, tt:6994.826\n",
      "Ep:200, loss:0.00000, loss_test:0.01717, lr:1.89e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.981, tt:7031.085\n",
      "Ep:201, loss:0.00000, loss_test:0.01717, lr:1.87e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.987, tt:7067.463\n",
      "Ep:202, loss:0.00000, loss_test:0.01717, lr:1.85e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.986, tt:7102.066\n",
      "Ep:203, loss:0.00000, loss_test:0.01720, lr:1.83e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.983, tt:7136.586\n",
      "Ep:204, loss:0.00000, loss_test:0.01721, lr:1.81e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.981, tt:7171.193\n",
      "Ep:205, loss:0.00000, loss_test:0.01722, lr:1.80e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.979, tt:7205.588\n",
      "Ep:206, loss:0.00000, loss_test:0.01725, lr:1.78e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.964, tt:7237.519\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03392, lr:1.00e-02, fs:0.66667 (r=0.556,p=0.833),  time:21.003, tt:21.003\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.02220, lr:1.00e-02, fs:0.64186 (r=0.697,p=0.595),  time:24.335, tt:48.670\n",
      "Ep:2, loss:0.00005, loss_test:0.02010, lr:1.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:27.915, tt:83.745\n",
      "Ep:3, loss:0.00004, loss_test:0.02096, lr:1.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:30.293, tt:121.170\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02211, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:31.228, tt:156.139\n",
      "Ep:5, loss:0.00005, loss_test:0.02285, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:31.532, tt:189.194\n",
      "Ep:6, loss:0.00005, loss_test:0.02318, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:31.685, tt:221.797\n",
      "Ep:7, loss:0.00005, loss_test:0.02314, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:32.125, tt:256.997\n",
      "Ep:8, loss:0.00005, loss_test:0.02286, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:32.364, tt:291.273\n",
      "Ep:9, loss:0.00005, loss_test:0.02240, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:32.509, tt:325.092\n",
      "Ep:10, loss:0.00005, loss_test:0.02185, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:32.761, tt:360.375\n",
      "Ep:11, loss:0.00004, loss_test:0.02122, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:32.980, tt:395.754\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02054, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:33.118, tt:430.535\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01986, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:33.228, tt:465.187\n",
      "Ep:14, loss:0.00004, loss_test:0.01920, lr:1.00e-02, fs:0.67857 (r=0.960,p=0.525),  time:33.375, tt:500.618\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01861, lr:1.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:33.395, tt:534.317\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01811, lr:1.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:33.339, tt:566.757\n",
      "Ep:17, loss:0.00004, loss_test:0.01770, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:33.457, tt:602.218\n",
      "Ep:18, loss:0.00004, loss_test:0.01739, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:33.545, tt:637.353\n",
      "Ep:19, loss:0.00004, loss_test:0.01716, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:33.611, tt:672.216\n",
      "Ep:20, loss:0.00004, loss_test:0.01700, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:33.659, tt:706.831\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01688, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:33.616, tt:739.548\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01677, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:33.836, tt:778.232\n",
      "Ep:23, loss:0.00004, loss_test:0.01668, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:33.835, tt:812.028\n",
      "Ep:24, loss:0.00004, loss_test:0.01659, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:33.863, tt:846.568\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01650, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:33.869, tt:880.599\n",
      "Ep:26, loss:0.00004, loss_test:0.01643, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:33.891, tt:915.062\n",
      "Ep:27, loss:0.00004, loss_test:0.01636, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:33.849, tt:947.761\n",
      "Ep:28, loss:0.00004, loss_test:0.01629, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:33.860, tt:981.944\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01622, lr:1.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:33.880, tt:1016.397\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01615, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:33.857, tt:1049.552\n",
      "Ep:31, loss:0.00003, loss_test:0.01609, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:33.858, tt:1083.458\n",
      "Ep:32, loss:0.00003, loss_test:0.01603, lr:1.00e-02, fs:0.71318 (r=0.929,p=0.579),  time:33.887, tt:1118.265\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01597, lr:1.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:33.906, tt:1152.812\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01592, lr:1.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:33.935, tt:1187.717\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01587, lr:1.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:33.934, tt:1221.628\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01582, lr:1.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:33.927, tt:1255.287\n",
      "Ep:37, loss:0.00003, loss_test:0.01578, lr:1.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:33.925, tt:1289.167\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01575, lr:1.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:33.894, tt:1321.848\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01571, lr:1.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:33.923, tt:1356.908\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01568, lr:1.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:33.952, tt:1392.032\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01566, lr:1.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.004, tt:1428.182\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01563, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.000, tt:1462.018\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01561, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.008, tt:1496.354\n",
      "Ep:44, loss:0.00003, loss_test:0.01559, lr:1.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:33.992, tt:1529.643\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01558, lr:1.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:33.986, tt:1563.339\n",
      "Ep:46, loss:0.00003, loss_test:0.01557, lr:1.00e-02, fs:0.75314 (r=0.909,p=0.643),  time:33.988, tt:1597.437\n",
      "Ep:47, loss:0.00003, loss_test:0.01557, lr:1.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:33.999, tt:1631.936\n",
      "Ep:48, loss:0.00003, loss_test:0.01556, lr:1.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:33.986, tt:1665.320\n",
      "Ep:49, loss:0.00003, loss_test:0.01554, lr:1.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:33.987, tt:1699.375\n",
      "Ep:50, loss:0.00003, loss_test:0.01554, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.012, tt:1734.607\n",
      "Ep:51, loss:0.00003, loss_test:0.01554, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.018, tt:1768.931\n",
      "Ep:52, loss:0.00003, loss_test:0.01553, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.061, tt:1805.242\n",
      "Ep:53, loss:0.00003, loss_test:0.01553, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.088, tt:1840.776\n",
      "Ep:54, loss:0.00003, loss_test:0.01552, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.116, tt:1876.378\n",
      "Ep:55, loss:0.00003, loss_test:0.01551, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.153, tt:1912.573\n",
      "Ep:56, loss:0.00003, loss_test:0.01551, lr:9.90e-03, fs:0.74043 (r=0.879,p=0.640),  time:34.144, tt:1946.217\n",
      "Ep:57, loss:0.00003, loss_test:0.01551, lr:9.80e-03, fs:0.74359 (r=0.879,p=0.644),  time:34.173, tt:1982.036\n",
      "Ep:58, loss:0.00003, loss_test:0.01551, lr:9.70e-03, fs:0.74359 (r=0.879,p=0.644),  time:34.179, tt:2016.552\n",
      "Ep:59, loss:0.00003, loss_test:0.01551, lr:9.61e-03, fs:0.74678 (r=0.879,p=0.649),  time:34.216, tt:2052.963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.01550, lr:9.51e-03, fs:0.74678 (r=0.879,p=0.649),  time:34.237, tt:2088.461\n",
      "Ep:61, loss:0.00003, loss_test:0.01550, lr:9.41e-03, fs:0.74678 (r=0.879,p=0.649),  time:34.240, tt:2122.908\n",
      "Ep:62, loss:0.00003, loss_test:0.01551, lr:9.32e-03, fs:0.74678 (r=0.879,p=0.649),  time:34.251, tt:2157.832\n",
      "Ep:63, loss:0.00003, loss_test:0.01551, lr:9.23e-03, fs:0.74678 (r=0.879,p=0.649),  time:34.274, tt:2193.522\n",
      "Ep:64, loss:0.00003, loss_test:0.01550, lr:9.14e-03, fs:0.74359 (r=0.879,p=0.644),  time:34.298, tt:2229.401\n",
      "Ep:65, loss:0.00003, loss_test:0.01551, lr:9.04e-03, fs:0.74894 (r=0.889,p=0.647),  time:34.349, tt:2267.065\n",
      "Ep:66, loss:0.00003, loss_test:0.01552, lr:8.95e-03, fs:0.74894 (r=0.889,p=0.647),  time:34.353, tt:2301.657\n",
      "Ep:67, loss:0.00003, loss_test:0.01552, lr:8.86e-03, fs:0.74894 (r=0.889,p=0.647),  time:34.341, tt:2335.157\n",
      "Ep:68, loss:0.00003, loss_test:0.01552, lr:8.78e-03, fs:0.74894 (r=0.889,p=0.647),  time:34.367, tt:2371.344\n",
      "Ep:69, loss:0.00003, loss_test:0.01552, lr:8.69e-03, fs:0.74894 (r=0.889,p=0.647),  time:34.371, tt:2405.986\n",
      "Ep:70, loss:0.00003, loss_test:0.01552, lr:8.60e-03, fs:0.75424 (r=0.899,p=0.650),  time:34.368, tt:2440.146\n",
      "Ep:71, loss:0.00003, loss_test:0.01552, lr:8.51e-03, fs:0.75424 (r=0.899,p=0.650),  time:34.363, tt:2474.149\n",
      "Ep:72, loss:0.00003, loss_test:0.01552, lr:8.43e-03, fs:0.75424 (r=0.899,p=0.650),  time:34.362, tt:2508.408\n",
      "Ep:73, loss:0.00003, loss_test:0.01553, lr:8.35e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.385, tt:2544.490\n",
      "Ep:74, loss:0.00003, loss_test:0.01553, lr:8.26e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.410, tt:2580.729\n",
      "Ep:75, loss:0.00003, loss_test:0.01553, lr:8.18e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.436, tt:2617.124\n",
      "Ep:76, loss:0.00003, loss_test:0.01553, lr:8.10e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.453, tt:2652.866\n",
      "Ep:77, loss:0.00003, loss_test:0.01552, lr:8.02e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.457, tt:2687.645\n",
      "Ep:78, loss:0.00002, loss_test:0.01553, lr:7.94e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.465, tt:2722.719\n",
      "Ep:79, loss:0.00002, loss_test:0.01553, lr:7.86e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.485, tt:2758.826\n",
      "Ep:80, loss:0.00002, loss_test:0.01553, lr:7.78e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.498, tt:2794.338\n",
      "Ep:81, loss:0.00002, loss_test:0.01553, lr:7.70e-03, fs:0.75745 (r=0.899,p=0.654),  time:34.529, tt:2831.349\n",
      "Ep:82, loss:0.00002, loss_test:0.01553, lr:7.62e-03, fs:0.76395 (r=0.899,p=0.664),  time:34.557, tt:2868.271\n",
      "Ep:83, loss:0.00002, loss_test:0.01553, lr:7.55e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.572, tt:2904.014\n",
      "Ep:84, loss:0.00002, loss_test:0.01554, lr:7.47e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.589, tt:2940.030\n",
      "Ep:85, loss:0.00002, loss_test:0.01554, lr:7.40e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.623, tt:2977.560\n",
      "Ep:86, loss:0.00002, loss_test:0.01554, lr:7.32e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.615, tt:3011.472\n",
      "Ep:87, loss:0.00002, loss_test:0.01554, lr:7.25e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.622, tt:3046.731\n",
      "Ep:88, loss:0.00002, loss_test:0.01554, lr:7.18e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.632, tt:3082.204\n",
      "Ep:89, loss:0.00002, loss_test:0.01554, lr:7.11e-03, fs:0.76724 (r=0.899,p=0.669),  time:34.647, tt:3118.255\n",
      "Ep:90, loss:0.00002, loss_test:0.01554, lr:7.03e-03, fs:0.77056 (r=0.899,p=0.674),  time:34.656, tt:3153.697\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.01554, lr:7.03e-03, fs:0.77056 (r=0.899,p=0.674),  time:34.664, tt:3189.094\n",
      "Ep:92, loss:0.00002, loss_test:0.01554, lr:7.03e-03, fs:0.77056 (r=0.899,p=0.674),  time:34.669, tt:3224.197\n",
      "Ep:93, loss:0.00002, loss_test:0.01554, lr:7.03e-03, fs:0.77056 (r=0.899,p=0.674),  time:34.685, tt:3260.357\n",
      "Ep:94, loss:0.00002, loss_test:0.01555, lr:7.03e-03, fs:0.77391 (r=0.899,p=0.679),  time:34.675, tt:3294.097\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.01555, lr:7.03e-03, fs:0.76856 (r=0.889,p=0.677),  time:34.692, tt:3330.467\n",
      "Ep:96, loss:0.00002, loss_test:0.01555, lr:7.03e-03, fs:0.76856 (r=0.889,p=0.677),  time:34.691, tt:3365.001\n",
      "Ep:97, loss:0.00002, loss_test:0.01555, lr:7.03e-03, fs:0.76856 (r=0.889,p=0.677),  time:34.690, tt:3399.653\n",
      "Ep:98, loss:0.00002, loss_test:0.01555, lr:7.03e-03, fs:0.76856 (r=0.889,p=0.677),  time:34.688, tt:3434.064\n",
      "Ep:99, loss:0.00002, loss_test:0.01556, lr:7.03e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.694, tt:3469.374\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.696, tt:3504.272\n",
      "Ep:101, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.691, tt:3538.447\n",
      "Ep:102, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.670, tt:3571.026\n",
      "Ep:103, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.78070 (r=0.899,p=0.690),  time:34.666, tt:3605.293\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.78070 (r=0.899,p=0.690),  time:34.680, tt:3641.397\n",
      "Ep:105, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.78070 (r=0.899,p=0.690),  time:34.684, tt:3676.524\n",
      "Ep:106, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.694, tt:3712.259\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.685, tt:3745.991\n",
      "Ep:108, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.682, tt:3780.318\n",
      "Ep:109, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.678, tt:3814.616\n",
      "Ep:110, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.673, tt:3848.703\n",
      "Ep:111, loss:0.00002, loss_test:0.01557, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.672, tt:3883.266\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.670, tt:3917.764\n",
      "Ep:113, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.687, tt:3954.336\n",
      "Ep:114, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.693, tt:3989.646\n",
      "Ep:115, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.687, tt:4023.749\n",
      "Ep:116, loss:0.00002, loss_test:0.01558, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.678, tt:4057.309\n",
      "Ep:117, loss:0.00002, loss_test:0.01559, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.667, tt:4090.710\n",
      "Ep:118, loss:0.00002, loss_test:0.01559, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.683, tt:4127.321\n",
      "Ep:119, loss:0.00002, loss_test:0.01559, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.686, tt:4162.368\n",
      "Ep:120, loss:0.00002, loss_test:0.01560, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.690, tt:4197.468\n",
      "Ep:121, loss:0.00002, loss_test:0.01560, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.681, tt:4231.083\n",
      "Ep:122, loss:0.00002, loss_test:0.01561, lr:7.03e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.664, tt:4263.651\n",
      "Ep:123, loss:0.00002, loss_test:0.01561, lr:6.96e-03, fs:0.79111 (r=0.899,p=0.706),  time:34.670, tt:4299.089\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.01561, lr:6.96e-03, fs:0.79111 (r=0.899,p=0.706),  time:34.663, tt:4332.901\n",
      "Ep:125, loss:0.00002, loss_test:0.01562, lr:6.96e-03, fs:0.79111 (r=0.899,p=0.706),  time:34.658, tt:4366.936\n",
      "Ep:126, loss:0.00002, loss_test:0.01562, lr:6.96e-03, fs:0.79111 (r=0.899,p=0.706),  time:34.652, tt:4400.837\n",
      "Ep:127, loss:0.00002, loss_test:0.01562, lr:6.96e-03, fs:0.79464 (r=0.899,p=0.712),  time:34.658, tt:4436.204\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00002, loss_test:0.01563, lr:6.96e-03, fs:0.79464 (r=0.899,p=0.712),  time:34.671, tt:4472.547\n",
      "Ep:129, loss:0.00002, loss_test:0.01564, lr:6.96e-03, fs:0.79464 (r=0.899,p=0.712),  time:34.675, tt:4507.815\n",
      "Ep:130, loss:0.00002, loss_test:0.01564, lr:6.96e-03, fs:0.79821 (r=0.899,p=0.718),  time:34.667, tt:4541.438\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00002, loss_test:0.01564, lr:6.96e-03, fs:0.79821 (r=0.899,p=0.718),  time:34.674, tt:4576.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00002, loss_test:0.01564, lr:6.96e-03, fs:0.79821 (r=0.899,p=0.718),  time:34.675, tt:4611.818\n",
      "Ep:133, loss:0.00002, loss_test:0.01565, lr:6.96e-03, fs:0.79821 (r=0.899,p=0.718),  time:34.667, tt:4645.398\n",
      "Ep:134, loss:0.00002, loss_test:0.01566, lr:6.96e-03, fs:0.79821 (r=0.899,p=0.718),  time:34.664, tt:4679.637\n",
      "Ep:135, loss:0.00002, loss_test:0.01566, lr:6.96e-03, fs:0.79821 (r=0.899,p=0.718),  time:34.658, tt:4713.489\n",
      "Ep:136, loss:0.00002, loss_test:0.01567, lr:6.96e-03, fs:0.80180 (r=0.899,p=0.724),  time:34.663, tt:4748.770\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00002, loss_test:0.01568, lr:6.96e-03, fs:0.80543 (r=0.899,p=0.730),  time:34.665, tt:4783.802\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00002, loss_test:0.01568, lr:6.96e-03, fs:0.80543 (r=0.899,p=0.730),  time:34.671, tt:4819.305\n",
      "Ep:139, loss:0.00002, loss_test:0.01568, lr:6.96e-03, fs:0.80543 (r=0.899,p=0.730),  time:34.658, tt:4852.105\n",
      "Ep:140, loss:0.00002, loss_test:0.01568, lr:6.96e-03, fs:0.80543 (r=0.899,p=0.730),  time:34.650, tt:4885.607\n",
      "Ep:141, loss:0.00002, loss_test:0.01569, lr:6.96e-03, fs:0.80909 (r=0.899,p=0.736),  time:34.640, tt:4918.922\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00002, loss_test:0.01570, lr:6.96e-03, fs:0.80909 (r=0.899,p=0.736),  time:34.636, tt:4952.881\n",
      "Ep:143, loss:0.00002, loss_test:0.01571, lr:6.96e-03, fs:0.80909 (r=0.899,p=0.736),  time:34.636, tt:4987.593\n",
      "Ep:144, loss:0.00002, loss_test:0.01571, lr:6.96e-03, fs:0.80909 (r=0.899,p=0.736),  time:34.638, tt:5022.524\n",
      "Ep:145, loss:0.00002, loss_test:0.01572, lr:6.96e-03, fs:0.80909 (r=0.899,p=0.736),  time:34.635, tt:5056.648\n",
      "Ep:146, loss:0.00002, loss_test:0.01572, lr:6.96e-03, fs:0.80909 (r=0.899,p=0.736),  time:34.632, tt:5090.970\n",
      "Ep:147, loss:0.00002, loss_test:0.01573, lr:6.96e-03, fs:0.81448 (r=0.909,p=0.738),  time:34.632, tt:5125.490\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00002, loss_test:0.01573, lr:6.96e-03, fs:0.81448 (r=0.909,p=0.738),  time:34.619, tt:5158.268\n",
      "Ep:149, loss:0.00002, loss_test:0.01574, lr:6.96e-03, fs:0.81818 (r=0.909,p=0.744),  time:34.622, tt:5193.264\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00002, loss_test:0.01575, lr:6.96e-03, fs:0.81818 (r=0.909,p=0.744),  time:34.620, tt:5227.657\n",
      "Ep:151, loss:0.00002, loss_test:0.01575, lr:6.96e-03, fs:0.81818 (r=0.909,p=0.744),  time:34.610, tt:5260.765\n",
      "Ep:152, loss:0.00002, loss_test:0.01575, lr:6.96e-03, fs:0.81818 (r=0.909,p=0.744),  time:34.613, tt:5295.844\n",
      "Ep:153, loss:0.00002, loss_test:0.01577, lr:6.96e-03, fs:0.81818 (r=0.909,p=0.744),  time:34.614, tt:5330.612\n",
      "Ep:154, loss:0.00002, loss_test:0.01577, lr:6.96e-03, fs:0.81818 (r=0.909,p=0.744),  time:34.617, tt:5365.703\n",
      "Ep:155, loss:0.00002, loss_test:0.01578, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.611, tt:5399.248\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00002, loss_test:0.01579, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.614, tt:5434.470\n",
      "Ep:157, loss:0.00002, loss_test:0.01579, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.610, tt:5468.348\n",
      "Ep:158, loss:0.00002, loss_test:0.01580, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.613, tt:5503.483\n",
      "Ep:159, loss:0.00002, loss_test:0.01580, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.609, tt:5537.382\n",
      "Ep:160, loss:0.00002, loss_test:0.01581, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.604, tt:5571.281\n",
      "Ep:161, loss:0.00002, loss_test:0.01581, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.627, tt:5609.540\n",
      "Ep:162, loss:0.00002, loss_test:0.01581, lr:6.96e-03, fs:0.82192 (r=0.909,p=0.750),  time:34.627, tt:5644.119\n",
      "Ep:163, loss:0.00002, loss_test:0.01583, lr:6.96e-03, fs:0.82569 (r=0.909,p=0.756),  time:34.626, tt:5678.663\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00002, loss_test:0.01584, lr:6.96e-03, fs:0.82569 (r=0.909,p=0.756),  time:34.625, tt:5713.056\n",
      "Ep:165, loss:0.00002, loss_test:0.01584, lr:6.96e-03, fs:0.82569 (r=0.909,p=0.756),  time:34.622, tt:5747.332\n",
      "Ep:166, loss:0.00002, loss_test:0.01584, lr:6.96e-03, fs:0.82569 (r=0.909,p=0.756),  time:34.619, tt:5781.411\n",
      "Ep:167, loss:0.00002, loss_test:0.01585, lr:6.96e-03, fs:0.82569 (r=0.909,p=0.756),  time:34.621, tt:5816.303\n",
      "Ep:168, loss:0.00002, loss_test:0.01586, lr:6.96e-03, fs:0.83105 (r=0.919,p=0.758),  time:34.614, tt:5849.834\n",
      "##########Best model found so far##########\n",
      "Ep:169, loss:0.00002, loss_test:0.01587, lr:6.96e-03, fs:0.83105 (r=0.919,p=0.758),  time:34.605, tt:5882.867\n",
      "Ep:170, loss:0.00002, loss_test:0.01588, lr:6.96e-03, fs:0.83105 (r=0.919,p=0.758),  time:34.596, tt:5915.863\n",
      "Ep:171, loss:0.00002, loss_test:0.01588, lr:6.96e-03, fs:0.83105 (r=0.919,p=0.758),  time:34.595, tt:5950.342\n",
      "Ep:172, loss:0.00002, loss_test:0.01589, lr:6.96e-03, fs:0.83105 (r=0.919,p=0.758),  time:34.597, tt:5985.245\n",
      "Ep:173, loss:0.00002, loss_test:0.01591, lr:6.96e-03, fs:0.83105 (r=0.919,p=0.758),  time:34.595, tt:6019.556\n",
      "Ep:174, loss:0.00002, loss_test:0.01591, lr:6.96e-03, fs:0.83486 (r=0.919,p=0.765),  time:34.593, tt:6053.820\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00002, loss_test:0.01592, lr:6.96e-03, fs:0.83486 (r=0.919,p=0.765),  time:34.591, tt:6088.015\n",
      "Ep:176, loss:0.00002, loss_test:0.01592, lr:6.96e-03, fs:0.83486 (r=0.919,p=0.765),  time:34.595, tt:6123.362\n",
      "Ep:177, loss:0.00002, loss_test:0.01593, lr:6.96e-03, fs:0.83486 (r=0.919,p=0.765),  time:34.600, tt:6158.733\n",
      "Ep:178, loss:0.00002, loss_test:0.01593, lr:6.96e-03, fs:0.83486 (r=0.919,p=0.765),  time:34.608, tt:6194.832\n",
      "Ep:179, loss:0.00002, loss_test:0.01593, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.607, tt:6229.296\n",
      "Ep:180, loss:0.00002, loss_test:0.01594, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.608, tt:6264.107\n",
      "Ep:181, loss:0.00002, loss_test:0.01596, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.607, tt:6298.557\n",
      "Ep:182, loss:0.00002, loss_test:0.01596, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.613, tt:6334.115\n",
      "Ep:183, loss:0.00002, loss_test:0.01597, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.617, tt:6369.578\n",
      "Ep:184, loss:0.00002, loss_test:0.01597, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.624, tt:6405.381\n",
      "Ep:185, loss:0.00002, loss_test:0.01597, lr:6.96e-03, fs:0.82949 (r=0.909,p=0.763),  time:34.627, tt:6440.548\n",
      "Ep:186, loss:0.00002, loss_test:0.01599, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.636, tt:6476.859\n",
      "##########Best model found so far##########\n",
      "Ep:187, loss:0.00002, loss_test:0.01600, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.643, tt:6512.957\n",
      "Ep:188, loss:0.00002, loss_test:0.01601, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.656, tt:6549.920\n",
      "Ep:189, loss:0.00002, loss_test:0.01601, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.655, tt:6584.416\n",
      "Ep:190, loss:0.00002, loss_test:0.01602, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.678, tt:6623.573\n",
      "Ep:191, loss:0.00002, loss_test:0.01603, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.683, tt:6659.157\n",
      "Ep:192, loss:0.00001, loss_test:0.01604, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.690, tt:6695.153\n",
      "Ep:193, loss:0.00001, loss_test:0.01604, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.694, tt:6730.555\n",
      "Ep:194, loss:0.00001, loss_test:0.01604, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.700, tt:6766.502\n",
      "Ep:195, loss:0.00001, loss_test:0.01605, lr:6.89e-03, fs:0.83721 (r=0.909,p=0.776),  time:34.706, tt:6802.305\n",
      "Ep:196, loss:0.00001, loss_test:0.01606, lr:6.89e-03, fs:0.84112 (r=0.909,p=0.783),  time:34.704, tt:6836.761\n",
      "##########Best model found so far##########\n",
      "Ep:197, loss:0.00001, loss_test:0.01607, lr:6.89e-03, fs:0.84507 (r=0.909,p=0.789),  time:34.705, tt:6871.609\n",
      "##########Best model found so far##########\n",
      "Ep:198, loss:0.00001, loss_test:0.01608, lr:6.89e-03, fs:0.84507 (r=0.909,p=0.789),  time:34.703, tt:6905.912\n",
      "Ep:199, loss:0.00001, loss_test:0.01608, lr:6.89e-03, fs:0.84507 (r=0.909,p=0.789),  time:34.709, tt:6941.823\n",
      "Ep:200, loss:0.00001, loss_test:0.01610, lr:6.89e-03, fs:0.84507 (r=0.909,p=0.789),  time:34.710, tt:6976.734\n",
      "Ep:201, loss:0.00001, loss_test:0.01611, lr:6.89e-03, fs:0.84507 (r=0.909,p=0.789),  time:34.712, tt:7011.897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00001, loss_test:0.01611, lr:6.89e-03, fs:0.84906 (r=0.909,p=0.796),  time:34.706, tt:7045.409\n",
      "##########Best model found so far##########\n",
      "Ep:203, loss:0.00001, loss_test:0.01612, lr:6.89e-03, fs:0.84906 (r=0.909,p=0.796),  time:34.699, tt:7078.548\n",
      "Ep:204, loss:0.00001, loss_test:0.01613, lr:6.89e-03, fs:0.84906 (r=0.909,p=0.796),  time:34.686, tt:7110.651\n",
      "Ep:205, loss:0.00001, loss_test:0.01613, lr:6.89e-03, fs:0.84906 (r=0.909,p=0.796),  time:34.691, tt:7146.282\n",
      "Ep:206, loss:0.00001, loss_test:0.01614, lr:6.89e-03, fs:0.84906 (r=0.909,p=0.796),  time:34.661, tt:7174.813\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.03281, lr:1.00e-02, fs:0.56738 (r=0.404,p=0.952),  time:30.476, tt:30.476\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02137, lr:1.00e-02, fs:0.63107 (r=0.657,p=0.607),  time:31.264, tt:62.528\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.01964, lr:1.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:33.172, tt:99.517\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02078, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.750, tt:138.999\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02197, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.740, tt:178.700\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02266, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.229, tt:217.373\n",
      "Ep:6, loss:0.00004, loss_test:0.02288, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.971, tt:258.800\n",
      "Ep:7, loss:0.00004, loss_test:0.02277, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.347, tt:298.774\n",
      "Ep:8, loss:0.00004, loss_test:0.02241, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.502, tt:337.522\n",
      "Ep:9, loss:0.00004, loss_test:0.02189, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.456, tt:374.558\n",
      "Ep:10, loss:0.00004, loss_test:0.02127, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.484, tt:412.326\n",
      "Ep:11, loss:0.00004, loss_test:0.02057, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:37.551, tt:450.615\n",
      "Ep:12, loss:0.00004, loss_test:0.01987, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:37.649, tt:489.442\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01922, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:37.727, tt:528.185\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01868, lr:1.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:37.780, tt:566.700\n",
      "Ep:15, loss:0.00004, loss_test:0.01826, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:37.869, tt:605.902\n",
      "Ep:16, loss:0.00004, loss_test:0.01797, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:37.782, tt:642.286\n",
      "Ep:17, loss:0.00004, loss_test:0.01779, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:37.913, tt:682.430\n",
      "Ep:18, loss:0.00004, loss_test:0.01766, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:38.019, tt:722.364\n",
      "Ep:19, loss:0.00004, loss_test:0.01756, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:38.123, tt:762.451\n",
      "Ep:20, loss:0.00004, loss_test:0.01747, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:38.081, tt:799.701\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01737, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:38.108, tt:838.385\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01728, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:38.111, tt:876.545\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01719, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:38.086, tt:914.065\n",
      "Ep:24, loss:0.00003, loss_test:0.01711, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:38.125, tt:953.137\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01704, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:38.165, tt:992.293\n",
      "Ep:26, loss:0.00003, loss_test:0.01699, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:38.236, tt:1032.378\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01693, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:38.329, tt:1073.212\n",
      "Ep:28, loss:0.00003, loss_test:0.01687, lr:1.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:38.389, tt:1113.275\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01681, lr:1.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:38.418, tt:1152.529\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01676, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:38.339, tt:1188.509\n",
      "Ep:31, loss:0.00003, loss_test:0.01670, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:38.416, tt:1229.312\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01665, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:38.487, tt:1270.055\n",
      "Ep:33, loss:0.00003, loss_test:0.01661, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:38.564, tt:1311.186\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01657, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:38.601, tt:1351.033\n",
      "Ep:35, loss:0.00003, loss_test:0.01654, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:38.653, tt:1391.509\n",
      "Ep:36, loss:0.00003, loss_test:0.01650, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:38.654, tt:1430.206\n",
      "Ep:37, loss:0.00003, loss_test:0.01646, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:38.657, tt:1468.966\n",
      "Ep:38, loss:0.00003, loss_test:0.01642, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:38.739, tt:1510.828\n",
      "Ep:39, loss:0.00003, loss_test:0.01638, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:38.802, tt:1552.060\n",
      "Ep:40, loss:0.00003, loss_test:0.01634, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:38.842, tt:1592.515\n",
      "Ep:41, loss:0.00003, loss_test:0.01631, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:38.877, tt:1632.836\n",
      "Ep:42, loss:0.00003, loss_test:0.01627, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:38.891, tt:1672.315\n",
      "Ep:43, loss:0.00003, loss_test:0.01624, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:38.884, tt:1710.899\n",
      "Ep:44, loss:0.00003, loss_test:0.01620, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:38.896, tt:1750.298\n",
      "Ep:45, loss:0.00003, loss_test:0.01617, lr:9.90e-03, fs:0.70130 (r=0.818,p=0.614),  time:38.898, tt:1789.289\n",
      "Ep:46, loss:0.00003, loss_test:0.01614, lr:9.80e-03, fs:0.71053 (r=0.818,p=0.628),  time:38.876, tt:1827.151\n",
      "Ep:47, loss:0.00003, loss_test:0.01611, lr:9.70e-03, fs:0.71930 (r=0.828,p=0.636),  time:38.913, tt:1867.823\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01608, lr:9.70e-03, fs:0.72566 (r=0.828,p=0.646),  time:38.927, tt:1907.423\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01606, lr:9.70e-03, fs:0.72566 (r=0.828,p=0.646),  time:38.980, tt:1948.989\n",
      "Ep:50, loss:0.00003, loss_test:0.01605, lr:9.70e-03, fs:0.72889 (r=0.828,p=0.651),  time:39.002, tt:1989.080\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00003, loss_test:0.01603, lr:9.70e-03, fs:0.73214 (r=0.828,p=0.656),  time:39.031, tt:2029.591\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.01600, lr:9.70e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.046, tt:2069.435\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01598, lr:9.70e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.082, tt:2110.444\n",
      "Ep:54, loss:0.00003, loss_test:0.01596, lr:9.70e-03, fs:0.73543 (r=0.828,p=0.661),  time:39.060, tt:2148.323\n",
      "Ep:55, loss:0.00003, loss_test:0.01593, lr:9.70e-03, fs:0.72973 (r=0.818,p=0.659),  time:39.061, tt:2187.409\n",
      "Ep:56, loss:0.00003, loss_test:0.01591, lr:9.70e-03, fs:0.72973 (r=0.818,p=0.659),  time:39.075, tt:2227.248\n",
      "Ep:57, loss:0.00003, loss_test:0.01590, lr:9.70e-03, fs:0.72973 (r=0.818,p=0.659),  time:39.083, tt:2266.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00003, loss_test:0.01587, lr:9.70e-03, fs:0.72973 (r=0.818,p=0.659),  time:39.086, tt:2306.090\n",
      "Ep:59, loss:0.00003, loss_test:0.01585, lr:9.70e-03, fs:0.72973 (r=0.818,p=0.659),  time:39.088, tt:2345.269\n",
      "Ep:60, loss:0.00003, loss_test:0.01583, lr:9.70e-03, fs:0.74439 (r=0.838,p=0.669),  time:39.095, tt:2384.792\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.01581, lr:9.70e-03, fs:0.75336 (r=0.848,p=0.677),  time:39.091, tt:2423.623\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00003, loss_test:0.01579, lr:9.70e-03, fs:0.76233 (r=0.859,p=0.685),  time:39.091, tt:2462.722\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01577, lr:9.70e-03, fs:0.77477 (r=0.869,p=0.699),  time:39.092, tt:2501.865\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.01575, lr:9.70e-03, fs:0.77477 (r=0.869,p=0.699),  time:39.108, tt:2542.035\n",
      "Ep:65, loss:0.00002, loss_test:0.01573, lr:9.70e-03, fs:0.77477 (r=0.869,p=0.699),  time:39.116, tt:2581.658\n",
      "Ep:66, loss:0.00002, loss_test:0.01571, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:39.158, tt:2623.555\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.01570, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:39.137, tt:2661.335\n",
      "Ep:68, loss:0.00002, loss_test:0.01568, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:39.142, tt:2700.831\n",
      "Ep:69, loss:0.00002, loss_test:0.01567, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:39.140, tt:2739.802\n",
      "Ep:70, loss:0.00002, loss_test:0.01565, lr:9.70e-03, fs:0.78378 (r=0.879,p=0.707),  time:39.156, tt:2780.061\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.01563, lr:9.70e-03, fs:0.78733 (r=0.879,p=0.713),  time:39.165, tt:2819.879\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.01562, lr:9.70e-03, fs:0.78733 (r=0.879,p=0.713),  time:39.202, tt:2861.767\n",
      "Ep:73, loss:0.00002, loss_test:0.01560, lr:9.70e-03, fs:0.79091 (r=0.879,p=0.719),  time:39.233, tt:2903.279\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01558, lr:9.70e-03, fs:0.80365 (r=0.889,p=0.733),  time:39.260, tt:2944.520\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.01556, lr:9.70e-03, fs:0.80365 (r=0.889,p=0.733),  time:39.284, tt:2985.611\n",
      "Ep:76, loss:0.00002, loss_test:0.01555, lr:9.70e-03, fs:0.80365 (r=0.889,p=0.733),  time:39.292, tt:3025.467\n",
      "Ep:77, loss:0.00002, loss_test:0.01553, lr:9.70e-03, fs:0.80734 (r=0.889,p=0.739),  time:39.309, tt:3066.091\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.01552, lr:9.70e-03, fs:0.80734 (r=0.889,p=0.739),  time:39.314, tt:3105.777\n",
      "Ep:79, loss:0.00002, loss_test:0.01550, lr:9.70e-03, fs:0.80734 (r=0.889,p=0.739),  time:39.335, tt:3146.808\n",
      "Ep:80, loss:0.00002, loss_test:0.01549, lr:9.70e-03, fs:0.81481 (r=0.889,p=0.752),  time:39.342, tt:3186.711\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.01548, lr:9.70e-03, fs:0.81481 (r=0.889,p=0.752),  time:39.346, tt:3226.365\n",
      "Ep:82, loss:0.00002, loss_test:0.01546, lr:9.70e-03, fs:0.82028 (r=0.899,p=0.754),  time:39.359, tt:3266.809\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.01545, lr:9.70e-03, fs:0.82028 (r=0.899,p=0.754),  time:39.361, tt:3306.308\n",
      "Ep:84, loss:0.00002, loss_test:0.01544, lr:9.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.357, tt:3345.315\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.01543, lr:9.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.362, tt:3385.169\n",
      "Ep:86, loss:0.00002, loss_test:0.01542, lr:9.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.351, tt:3423.577\n",
      "Ep:87, loss:0.00002, loss_test:0.01542, lr:9.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.345, tt:3462.337\n",
      "Ep:88, loss:0.00002, loss_test:0.01541, lr:9.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.344, tt:3501.617\n",
      "Ep:89, loss:0.00002, loss_test:0.01541, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.336, tt:3540.200\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.01540, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.324, tt:3578.492\n",
      "Ep:91, loss:0.00002, loss_test:0.01540, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.321, tt:3617.563\n",
      "Ep:92, loss:0.00002, loss_test:0.01540, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.314, tt:3656.195\n",
      "Ep:93, loss:0.00002, loss_test:0.01539, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.292, tt:3693.438\n",
      "Ep:94, loss:0.00002, loss_test:0.01539, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:39.314, tt:3734.793\n",
      "Ep:95, loss:0.00002, loss_test:0.01539, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.318, tt:3774.548\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.01539, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.345, tt:3816.450\n",
      "Ep:97, loss:0.00002, loss_test:0.01539, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.349, tt:3856.208\n",
      "Ep:98, loss:0.00002, loss_test:0.01538, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.347, tt:3895.359\n",
      "Ep:99, loss:0.00002, loss_test:0.01538, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.357, tt:3935.672\n",
      "Ep:100, loss:0.00002, loss_test:0.01538, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.338, tt:3973.118\n",
      "Ep:101, loss:0.00002, loss_test:0.01537, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.329, tt:4011.543\n",
      "Ep:102, loss:0.00002, loss_test:0.01536, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:39.300, tt:4047.879\n",
      "Ep:103, loss:0.00002, loss_test:0.01535, lr:9.70e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.274, tt:4084.537\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.01534, lr:9.70e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.277, tt:4124.073\n",
      "Ep:105, loss:0.00002, loss_test:0.01534, lr:9.70e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.271, tt:4162.681\n",
      "Ep:106, loss:0.00002, loss_test:0.01533, lr:9.70e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.243, tt:4199.033\n",
      "Ep:107, loss:0.00002, loss_test:0.01532, lr:9.70e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.252, tt:4239.237\n",
      "Ep:108, loss:0.00002, loss_test:0.01532, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.247, tt:4277.948\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00002, loss_test:0.01531, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.251, tt:4317.559\n",
      "Ep:110, loss:0.00002, loss_test:0.01531, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.225, tt:4354.020\n",
      "Ep:111, loss:0.00002, loss_test:0.01531, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.203, tt:4390.754\n",
      "Ep:112, loss:0.00002, loss_test:0.01530, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.206, tt:4430.305\n",
      "Ep:113, loss:0.00002, loss_test:0.01529, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.199, tt:4468.636\n",
      "Ep:114, loss:0.00002, loss_test:0.01529, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.200, tt:4508.012\n",
      "Ep:115, loss:0.00002, loss_test:0.01529, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.188, tt:4545.859\n",
      "Ep:116, loss:0.00002, loss_test:0.01528, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.195, tt:4585.771\n",
      "Ep:117, loss:0.00002, loss_test:0.01528, lr:9.70e-03, fs:0.83962 (r=0.899,p=0.788),  time:39.202, tt:4625.850\n",
      "Ep:118, loss:0.00002, loss_test:0.01528, lr:9.70e-03, fs:0.84360 (r=0.899,p=0.795),  time:39.198, tt:4664.615\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.01527, lr:9.70e-03, fs:0.84360 (r=0.899,p=0.795),  time:39.199, tt:4703.871\n",
      "Ep:120, loss:0.00002, loss_test:0.01527, lr:9.70e-03, fs:0.84360 (r=0.899,p=0.795),  time:39.207, tt:4743.993\n",
      "Ep:121, loss:0.00002, loss_test:0.01527, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.193, tt:4781.588\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00002, loss_test:0.01526, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.206, tt:4822.345\n",
      "Ep:123, loss:0.00002, loss_test:0.01526, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.195, tt:4860.165\n",
      "Ep:124, loss:0.00002, loss_test:0.01525, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.198, tt:4899.768\n",
      "Ep:125, loss:0.00002, loss_test:0.01526, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.183, tt:4937.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00002, loss_test:0.01525, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.183, tt:4976.279\n",
      "Ep:127, loss:0.00002, loss_test:0.01525, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.186, tt:5015.819\n",
      "Ep:128, loss:0.00002, loss_test:0.01524, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.190, tt:5055.558\n",
      "Ep:129, loss:0.00002, loss_test:0.01524, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.193, tt:5095.061\n",
      "Ep:130, loss:0.00002, loss_test:0.01525, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.183, tt:5132.967\n",
      "Ep:131, loss:0.00002, loss_test:0.01524, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.185, tt:5172.484\n",
      "Ep:132, loss:0.00002, loss_test:0.01524, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.179, tt:5210.811\n",
      "Ep:133, loss:0.00002, loss_test:0.01524, lr:9.61e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.168, tt:5248.448\n",
      "Ep:134, loss:0.00002, loss_test:0.01524, lr:9.51e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.187, tt:5290.207\n",
      "Ep:135, loss:0.00002, loss_test:0.01524, lr:9.41e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.185, tt:5329.130\n",
      "Ep:136, loss:0.00002, loss_test:0.01524, lr:9.32e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.187, tt:5368.670\n",
      "Ep:137, loss:0.00002, loss_test:0.01523, lr:9.23e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.177, tt:5406.389\n",
      "Ep:138, loss:0.00002, loss_test:0.01523, lr:9.14e-03, fs:0.84906 (r=0.909,p=0.796),  time:39.168, tt:5444.390\n",
      "Ep:139, loss:0.00002, loss_test:0.01523, lr:9.04e-03, fs:0.84360 (r=0.899,p=0.795),  time:39.177, tt:5484.725\n",
      "Ep:140, loss:0.00002, loss_test:0.01523, lr:8.95e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.183, tt:5524.776\n",
      "Ep:141, loss:0.00002, loss_test:0.01522, lr:8.86e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.175, tt:5562.900\n",
      "Ep:142, loss:0.00002, loss_test:0.01522, lr:8.78e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.179, tt:5602.574\n",
      "Ep:143, loss:0.00002, loss_test:0.01523, lr:8.69e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.206, tt:5645.609\n",
      "Ep:144, loss:0.00002, loss_test:0.01522, lr:8.60e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.213, tt:5685.932\n",
      "Ep:145, loss:0.00002, loss_test:0.01523, lr:8.51e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.219, tt:5725.952\n",
      "Ep:146, loss:0.00002, loss_test:0.01523, lr:8.43e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.222, tt:5765.595\n",
      "Ep:147, loss:0.00002, loss_test:0.01523, lr:8.35e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.221, tt:5804.665\n",
      "Ep:148, loss:0.00002, loss_test:0.01523, lr:8.26e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.214, tt:5842.916\n",
      "Ep:149, loss:0.00002, loss_test:0.01523, lr:8.18e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.212, tt:5881.817\n",
      "Ep:150, loss:0.00002, loss_test:0.01523, lr:8.10e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.217, tt:5921.828\n",
      "Ep:151, loss:0.00002, loss_test:0.01523, lr:8.02e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.211, tt:5960.079\n",
      "Ep:152, loss:0.00002, loss_test:0.01524, lr:7.94e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.194, tt:5996.677\n",
      "Ep:153, loss:0.00002, loss_test:0.01524, lr:7.86e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.173, tt:6032.716\n",
      "Ep:154, loss:0.00002, loss_test:0.01523, lr:7.78e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.158, tt:6069.459\n",
      "Ep:155, loss:0.00002, loss_test:0.01524, lr:7.70e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.151, tt:6107.566\n",
      "Ep:156, loss:0.00002, loss_test:0.01524, lr:7.62e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.143, tt:6145.444\n",
      "Ep:157, loss:0.00002, loss_test:0.01524, lr:7.55e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.136, tt:6183.463\n",
      "Ep:158, loss:0.00002, loss_test:0.01525, lr:7.47e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.133, tt:6222.111\n",
      "Ep:159, loss:0.00002, loss_test:0.01524, lr:7.40e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.118, tt:6258.938\n",
      "Ep:160, loss:0.00002, loss_test:0.01525, lr:7.32e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.125, tt:6299.096\n",
      "Ep:161, loss:0.00002, loss_test:0.01525, lr:7.25e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.112, tt:6336.184\n",
      "Ep:162, loss:0.00002, loss_test:0.01525, lr:7.18e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.124, tt:6377.136\n",
      "Ep:163, loss:0.00002, loss_test:0.01524, lr:7.11e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.123, tt:6416.144\n",
      "Ep:164, loss:0.00002, loss_test:0.01524, lr:7.03e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.118, tt:6454.531\n",
      "Ep:165, loss:0.00002, loss_test:0.01525, lr:6.96e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.101, tt:6490.763\n",
      "Ep:166, loss:0.00002, loss_test:0.01525, lr:6.89e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.095, tt:6528.797\n",
      "Ep:167, loss:0.00002, loss_test:0.01525, lr:6.83e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.097, tt:6568.372\n",
      "Ep:168, loss:0.00002, loss_test:0.01525, lr:6.76e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.100, tt:6607.852\n",
      "Ep:169, loss:0.00002, loss_test:0.01525, lr:6.69e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.101, tt:6647.151\n",
      "Ep:170, loss:0.00002, loss_test:0.01525, lr:6.62e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.108, tt:6687.482\n",
      "Ep:171, loss:0.00002, loss_test:0.01525, lr:6.56e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.102, tt:6725.612\n",
      "Ep:172, loss:0.00001, loss_test:0.01526, lr:6.49e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.110, tt:6765.972\n",
      "Ep:173, loss:0.00001, loss_test:0.01526, lr:6.43e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.113, tt:6805.740\n",
      "Ep:174, loss:0.00001, loss_test:0.01526, lr:6.36e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.124, tt:6846.674\n",
      "Ep:175, loss:0.00001, loss_test:0.01526, lr:6.30e-03, fs:0.84762 (r=0.899,p=0.802),  time:39.129, tt:6886.673\n",
      "Ep:176, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.125, tt:6925.173\n",
      "##########Best model found so far##########\n",
      "Ep:177, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.146, tt:6968.070\n",
      "Ep:178, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.150, tt:7007.885\n",
      "Ep:179, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.143, tt:7045.748\n",
      "Ep:180, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.139, tt:7084.088\n",
      "Ep:181, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.130, tt:7121.668\n",
      "Ep:182, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.129, tt:7160.632\n",
      "##########Best model found so far##########\n",
      "Ep:183, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.140, tt:7201.720\n",
      "Ep:184, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.131, tt:7239.211\n",
      "Ep:185, loss:0.00001, loss_test:0.01527, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.123, tt:7276.967\n",
      "Ep:186, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.111, tt:7313.698\n",
      "Ep:187, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.103, tt:7351.389\n",
      "Ep:188, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.108, tt:7391.477\n",
      "Ep:189, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.109, tt:7430.768\n",
      "Ep:190, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.096, tt:7467.403\n",
      "Ep:191, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.092, tt:7505.719\n",
      "Ep:192, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.093, tt:7544.934\n",
      "Ep:193, loss:0.00001, loss_test:0.01526, lr:6.24e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.087, tt:7582.890\n",
      "Ep:194, loss:0.00001, loss_test:0.01526, lr:6.17e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.102, tt:7624.885\n",
      "Ep:195, loss:0.00001, loss_test:0.01527, lr:6.11e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.098, tt:7663.279\n",
      "Ep:196, loss:0.00001, loss_test:0.01526, lr:6.05e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.093, tt:7701.411\n",
      "Ep:197, loss:0.00001, loss_test:0.01526, lr:5.99e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.094, tt:7740.541\n",
      "Ep:198, loss:0.00001, loss_test:0.01526, lr:5.93e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.090, tt:7778.868\n",
      "Ep:199, loss:0.00001, loss_test:0.01527, lr:5.87e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.091, tt:7818.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00001, loss_test:0.01527, lr:5.81e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.087, tt:7856.482\n",
      "Ep:201, loss:0.00001, loss_test:0.01528, lr:5.75e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.085, tt:7895.254\n",
      "Ep:202, loss:0.00001, loss_test:0.01528, lr:5.70e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.076, tt:7932.474\n",
      "Ep:203, loss:0.00001, loss_test:0.01528, lr:5.64e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.077, tt:7971.709\n",
      "Ep:204, loss:0.00001, loss_test:0.01528, lr:5.58e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.066, tt:8008.439\n",
      "Ep:205, loss:0.00001, loss_test:0.01528, lr:5.53e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.056, tt:8045.463\n",
      "Ep:206, loss:0.00001, loss_test:0.01528, lr:5.47e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.018, tt:8076.742\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13683, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:31.036, tt:31.036\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13456, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:32.697, tt:65.394\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13060, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:32.546, tt:97.638\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12493, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:32.974, tt:131.895\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11873, lr:1.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:33.710, tt:168.552\n",
      "Ep:5, loss:0.00025, loss_test:0.11264, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:34.176, tt:205.059\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.10759, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:34.536, tt:241.752\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10498, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:34.861, tt:278.885\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.10330, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:35.130, tt:316.170\n",
      "Ep:9, loss:0.00023, loss_test:0.09994, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:35.675, tt:356.751\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.09667, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:35.779, tt:393.567\n",
      "Ep:11, loss:0.00022, loss_test:0.09418, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:35.848, tt:430.174\n",
      "Ep:12, loss:0.00021, loss_test:0.09242, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:35.819, tt:465.648\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09104, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:35.878, tt:502.290\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09044, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:35.927, tt:538.904\n",
      "Ep:15, loss:0.00019, loss_test:0.08939, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:36.075, tt:577.196\n",
      "Ep:16, loss:0.00019, loss_test:0.08857, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:36.020, tt:612.340\n",
      "Ep:17, loss:0.00018, loss_test:0.08865, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:36.099, tt:649.779\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08783, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:36.099, tt:685.890\n",
      "Ep:19, loss:0.00017, loss_test:0.08707, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:36.075, tt:721.509\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08670, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:36.144, tt:759.017\n",
      "Ep:21, loss:0.00016, loss_test:0.08641, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:36.107, tt:794.346\n",
      "Ep:22, loss:0.00016, loss_test:0.08639, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:36.169, tt:831.885\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08594, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:36.207, tt:868.968\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08541, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:36.249, tt:906.221\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08453, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:36.351, tt:945.137\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08441, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.485, tt:985.104\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08373, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:36.470, tt:1021.150\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08315, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:36.517, tt:1059.006\n",
      "Ep:29, loss:0.00013, loss_test:0.08304, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:36.519, tt:1095.581\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08241, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.498, tt:1131.441\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08170, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.517, tt:1168.538\n",
      "Ep:32, loss:0.00012, loss_test:0.08185, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:36.535, tt:1205.653\n",
      "Ep:33, loss:0.00011, loss_test:0.08057, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:36.467, tt:1239.877\n",
      "Ep:34, loss:0.00011, loss_test:0.08118, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:36.512, tt:1277.924\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.08023, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:36.503, tt:1314.123\n",
      "Ep:36, loss:0.00010, loss_test:0.08015, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:36.461, tt:1349.069\n",
      "Ep:37, loss:0.00010, loss_test:0.07929, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:36.466, tt:1385.693\n",
      "Ep:38, loss:0.00009, loss_test:0.07866, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:36.463, tt:1422.060\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07810, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:36.439, tt:1457.572\n",
      "Ep:40, loss:0.00009, loss_test:0.08082, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:36.465, tt:1495.046\n",
      "Ep:41, loss:0.00009, loss_test:0.07785, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:36.506, tt:1533.257\n",
      "Ep:42, loss:0.00009, loss_test:0.07807, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.536, tt:1571.064\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.07569, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:36.548, tt:1608.107\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.07846, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:36.588, tt:1646.439\n",
      "Ep:45, loss:0.00008, loss_test:0.07476, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:36.614, tt:1684.254\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.07720, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:36.634, tt:1721.781\n",
      "Ep:47, loss:0.00007, loss_test:0.07372, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:36.631, tt:1758.308\n",
      "Ep:48, loss:0.00007, loss_test:0.07371, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:36.646, tt:1795.652\n",
      "Ep:49, loss:0.00007, loss_test:0.07310, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:36.626, tt:1831.291\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07544, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:36.639, tt:1868.607\n",
      "Ep:51, loss:0.00006, loss_test:0.07261, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.631, tt:1904.814\n",
      "Ep:52, loss:0.00006, loss_test:0.07543, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:36.652, tt:1942.542\n",
      "Ep:53, loss:0.00006, loss_test:0.07399, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:36.675, tt:1980.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00006, loss_test:0.07349, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:36.675, tt:2017.142\n",
      "Ep:55, loss:0.00006, loss_test:0.07507, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:36.672, tt:2053.605\n",
      "Ep:56, loss:0.00005, loss_test:0.07164, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:36.705, tt:2092.161\n",
      "Ep:57, loss:0.00005, loss_test:0.07399, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:36.714, tt:2129.427\n",
      "Ep:58, loss:0.00005, loss_test:0.07235, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:36.720, tt:2166.479\n",
      "Ep:59, loss:0.00005, loss_test:0.07105, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:36.762, tt:2205.691\n",
      "Ep:60, loss:0.00005, loss_test:0.07502, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:36.732, tt:2240.648\n",
      "Ep:61, loss:0.00005, loss_test:0.07045, lr:9.90e-03, fs:0.86316 (r=0.828,p=0.901),  time:36.736, tt:2277.658\n",
      "Ep:62, loss:0.00005, loss_test:0.07620, lr:9.80e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.728, tt:2313.835\n",
      "Ep:63, loss:0.00005, loss_test:0.07137, lr:9.70e-03, fs:0.85864 (r=0.828,p=0.891),  time:36.747, tt:2351.818\n",
      "Ep:64, loss:0.00004, loss_test:0.07207, lr:9.61e-03, fs:0.85106 (r=0.808,p=0.899),  time:36.758, tt:2389.273\n",
      "Ep:65, loss:0.00004, loss_test:0.07400, lr:9.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.774, tt:2427.099\n",
      "Ep:66, loss:0.00004, loss_test:0.07175, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.791, tt:2464.988\n",
      "Ep:67, loss:0.00004, loss_test:0.07429, lr:9.32e-03, fs:0.85561 (r=0.808,p=0.909),  time:36.797, tt:2502.187\n",
      "Ep:68, loss:0.00004, loss_test:0.07174, lr:9.23e-03, fs:0.84974 (r=0.828,p=0.872),  time:36.815, tt:2540.256\n",
      "Ep:69, loss:0.00004, loss_test:0.07213, lr:9.14e-03, fs:0.87432 (r=0.808,p=0.952),  time:36.835, tt:2578.431\n",
      "Ep:70, loss:0.00004, loss_test:0.07131, lr:9.04e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.821, tt:2614.279\n",
      "Ep:71, loss:0.00004, loss_test:0.07157, lr:8.95e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.844, tt:2652.786\n",
      "Ep:72, loss:0.00004, loss_test:0.07160, lr:8.86e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.858, tt:2690.619\n",
      "Ep:73, loss:0.00003, loss_test:0.07172, lr:8.78e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.871, tt:2728.479\n",
      "Ep:74, loss:0.00003, loss_test:0.07165, lr:8.69e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.865, tt:2764.891\n",
      "Ep:75, loss:0.00003, loss_test:0.07084, lr:8.60e-03, fs:0.84946 (r=0.798,p=0.908),  time:36.885, tt:2803.251\n",
      "Ep:76, loss:0.00003, loss_test:0.07231, lr:8.51e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.903, tt:2841.567\n",
      "Ep:77, loss:0.00003, loss_test:0.07008, lr:8.43e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.919, tt:2879.705\n",
      "Ep:78, loss:0.00003, loss_test:0.07068, lr:8.35e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.924, tt:2916.964\n",
      "Ep:79, loss:0.00003, loss_test:0.07141, lr:8.26e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.924, tt:2953.951\n",
      "Ep:80, loss:0.00003, loss_test:0.06930, lr:8.18e-03, fs:0.86772 (r=0.828,p=0.911),  time:36.950, tt:2992.926\n",
      "Ep:81, loss:0.00003, loss_test:0.07336, lr:8.10e-03, fs:0.86957 (r=0.808,p=0.941),  time:36.976, tt:3032.017\n",
      "Ep:82, loss:0.00003, loss_test:0.06877, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.005, tt:3071.437\n",
      "Ep:83, loss:0.00003, loss_test:0.07253, lr:7.94e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.023, tt:3109.936\n",
      "Ep:84, loss:0.00003, loss_test:0.07036, lr:7.86e-03, fs:0.86486 (r=0.808,p=0.930),  time:37.038, tt:3148.218\n",
      "Ep:85, loss:0.00003, loss_test:0.06954, lr:7.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.042, tt:3185.639\n",
      "Ep:86, loss:0.00003, loss_test:0.07249, lr:7.70e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.065, tt:3224.673\n",
      "Ep:87, loss:0.00003, loss_test:0.06959, lr:7.62e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.061, tt:3261.333\n",
      "Ep:88, loss:0.00003, loss_test:0.07122, lr:7.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.068, tt:3299.013\n",
      "Ep:89, loss:0.00003, loss_test:0.07157, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.091, tt:3338.154\n",
      "Ep:90, loss:0.00003, loss_test:0.06858, lr:7.40e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.100, tt:3376.134\n",
      "Ep:91, loss:0.00003, loss_test:0.07116, lr:7.32e-03, fs:0.85561 (r=0.808,p=0.909),  time:37.093, tt:3412.550\n",
      "Ep:92, loss:0.00003, loss_test:0.07236, lr:7.25e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.099, tt:3450.169\n",
      "Ep:93, loss:0.00002, loss_test:0.07015, lr:7.18e-03, fs:0.86957 (r=0.808,p=0.941),  time:37.113, tt:3488.658\n",
      "Ep:94, loss:0.00002, loss_test:0.07098, lr:7.11e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.126, tt:3526.981\n",
      "Ep:95, loss:0.00002, loss_test:0.07261, lr:7.03e-03, fs:0.87912 (r=0.808,p=0.964),  time:37.136, tt:3565.046\n",
      "Ep:96, loss:0.00002, loss_test:0.06926, lr:6.96e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.164, tt:3604.872\n",
      "Ep:97, loss:0.00002, loss_test:0.07381, lr:6.89e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.182, tt:3643.828\n",
      "Ep:98, loss:0.00002, loss_test:0.06972, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.181, tt:3680.915\n",
      "Ep:99, loss:0.00002, loss_test:0.07091, lr:6.76e-03, fs:0.86957 (r=0.808,p=0.941),  time:37.184, tt:3718.387\n",
      "Ep:100, loss:0.00002, loss_test:0.07182, lr:6.69e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.182, tt:3755.362\n",
      "Ep:101, loss:0.00002, loss_test:0.07144, lr:6.62e-03, fs:0.86957 (r=0.808,p=0.941),  time:37.187, tt:3793.077\n",
      "Ep:102, loss:0.00002, loss_test:0.07015, lr:6.56e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.185, tt:3830.025\n",
      "Ep:103, loss:0.00002, loss_test:0.07182, lr:6.49e-03, fs:0.86188 (r=0.788,p=0.951),  time:37.176, tt:3866.253\n",
      "Ep:104, loss:0.00002, loss_test:0.07097, lr:6.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.178, tt:3903.644\n",
      "Ep:105, loss:0.00002, loss_test:0.07089, lr:6.36e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.182, tt:3941.281\n",
      "Ep:106, loss:0.00002, loss_test:0.07145, lr:6.30e-03, fs:0.86188 (r=0.788,p=0.951),  time:37.190, tt:3979.333\n",
      "Ep:107, loss:0.00002, loss_test:0.07199, lr:6.24e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.186, tt:4016.113\n",
      "Ep:108, loss:0.00002, loss_test:0.07180, lr:6.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.192, tt:4053.903\n",
      "Ep:109, loss:0.00002, loss_test:0.07102, lr:6.11e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.204, tt:4092.456\n",
      "Ep:110, loss:0.00002, loss_test:0.07179, lr:6.05e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.217, tt:4131.119\n",
      "Ep:111, loss:0.00002, loss_test:0.07092, lr:5.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.231, tt:4169.926\n",
      "Ep:112, loss:0.00002, loss_test:0.07178, lr:5.93e-03, fs:0.87912 (r=0.808,p=0.964),  time:37.247, tt:4208.873\n",
      "Ep:113, loss:0.00002, loss_test:0.07120, lr:5.87e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.241, tt:4245.524\n",
      "Ep:114, loss:0.00002, loss_test:0.07219, lr:5.81e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.266, tt:4285.570\n",
      "Ep:115, loss:0.00002, loss_test:0.07116, lr:5.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.280, tt:4324.497\n",
      "Ep:116, loss:0.00002, loss_test:0.07218, lr:5.70e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.278, tt:4361.520\n",
      "Ep:117, loss:0.00002, loss_test:0.07232, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.278, tt:4398.764\n",
      "Ep:118, loss:0.00002, loss_test:0.07109, lr:5.58e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.280, tt:4436.333\n",
      "Ep:119, loss:0.00002, loss_test:0.07301, lr:5.53e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.297, tt:4475.697\n",
      "Ep:120, loss:0.00002, loss_test:0.07189, lr:5.47e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.307, tt:4514.123\n",
      "Ep:121, loss:0.00002, loss_test:0.07146, lr:5.42e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.314, tt:4552.265\n",
      "Ep:122, loss:0.00002, loss_test:0.07264, lr:5.36e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.316, tt:4589.848\n",
      "Ep:123, loss:0.00002, loss_test:0.07187, lr:5.31e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.332, tt:4629.147\n",
      "Ep:124, loss:0.00002, loss_test:0.07215, lr:5.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.331, tt:4666.415\n",
      "Ep:125, loss:0.00002, loss_test:0.07254, lr:5.20e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.324, tt:4702.846\n",
      "Ep:126, loss:0.00002, loss_test:0.07144, lr:5.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.326, tt:4740.359\n",
      "Ep:127, loss:0.00002, loss_test:0.07225, lr:5.10e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.323, tt:4777.378\n",
      "Ep:128, loss:0.00002, loss_test:0.07249, lr:5.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.334, tt:4816.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00002, loss_test:0.07186, lr:5.00e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.336, tt:4853.680\n",
      "Ep:130, loss:0.00002, loss_test:0.07189, lr:4.95e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.342, tt:4891.755\n",
      "Ep:131, loss:0.00002, loss_test:0.07247, lr:4.90e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.331, tt:4927.759\n",
      "Ep:132, loss:0.00002, loss_test:0.07193, lr:4.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.337, tt:4965.811\n",
      "Ep:133, loss:0.00002, loss_test:0.07177, lr:4.80e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.373, tt:5008.007\n",
      "Ep:134, loss:0.00002, loss_test:0.07274, lr:4.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.372, tt:5045.245\n",
      "Ep:135, loss:0.00002, loss_test:0.07202, lr:4.71e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.360, tt:5080.947\n",
      "Ep:136, loss:0.00002, loss_test:0.07253, lr:4.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.356, tt:5117.819\n",
      "Ep:137, loss:0.00002, loss_test:0.07260, lr:4.61e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.347, tt:5153.897\n",
      "Ep:138, loss:0.00002, loss_test:0.07262, lr:4.57e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.344, tt:5190.751\n",
      "Ep:139, loss:0.00001, loss_test:0.07223, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.333, tt:5226.589\n",
      "Ep:140, loss:0.00001, loss_test:0.07248, lr:4.48e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.336, tt:5264.318\n",
      "Ep:141, loss:0.00001, loss_test:0.07283, lr:4.43e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.323, tt:5299.865\n",
      "Ep:142, loss:0.00001, loss_test:0.07196, lr:4.39e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.308, tt:5334.996\n",
      "Ep:143, loss:0.00001, loss_test:0.07269, lr:4.34e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.290, tt:5369.791\n",
      "Ep:144, loss:0.00001, loss_test:0.07240, lr:4.30e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.284, tt:5406.147\n",
      "Ep:145, loss:0.00001, loss_test:0.07269, lr:4.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.274, tt:5442.014\n",
      "Ep:146, loss:0.00001, loss_test:0.07286, lr:4.21e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.272, tt:5478.911\n",
      "Ep:147, loss:0.00001, loss_test:0.07267, lr:4.17e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.275, tt:5516.686\n",
      "Ep:148, loss:0.00001, loss_test:0.07275, lr:4.13e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.267, tt:5552.857\n",
      "Ep:149, loss:0.00001, loss_test:0.07271, lr:4.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.268, tt:5590.196\n",
      "Ep:150, loss:0.00001, loss_test:0.07263, lr:4.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.267, tt:5627.346\n",
      "Ep:151, loss:0.00001, loss_test:0.07262, lr:4.01e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.269, tt:5664.870\n",
      "Ep:152, loss:0.00001, loss_test:0.07258, lr:3.97e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.277, tt:5703.439\n",
      "Ep:153, loss:0.00001, loss_test:0.07263, lr:3.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.279, tt:5741.026\n",
      "Ep:154, loss:0.00001, loss_test:0.07304, lr:3.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.275, tt:5777.625\n",
      "Ep:155, loss:0.00001, loss_test:0.07310, lr:3.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.267, tt:5813.629\n",
      "Ep:156, loss:0.00001, loss_test:0.07271, lr:3.81e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.296, tt:5855.428\n",
      "Ep:157, loss:0.00001, loss_test:0.07301, lr:3.77e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.294, tt:5892.506\n",
      "Ep:158, loss:0.00001, loss_test:0.07377, lr:3.73e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.292, tt:5929.499\n",
      "Ep:159, loss:0.00001, loss_test:0.07271, lr:3.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.292, tt:5966.797\n",
      "Ep:160, loss:0.00001, loss_test:0.07285, lr:3.66e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.294, tt:6004.273\n",
      "Ep:161, loss:0.00001, loss_test:0.07342, lr:3.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.286, tt:6040.413\n",
      "Ep:162, loss:0.00001, loss_test:0.07302, lr:3.59e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.281, tt:6076.792\n",
      "Ep:163, loss:0.00001, loss_test:0.07304, lr:3.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.278, tt:6113.600\n",
      "Ep:164, loss:0.00001, loss_test:0.07353, lr:3.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.279, tt:6150.967\n",
      "Ep:165, loss:0.00001, loss_test:0.07303, lr:3.48e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.258, tt:6184.819\n",
      "Ep:166, loss:0.00001, loss_test:0.07289, lr:3.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.257, tt:6221.897\n",
      "Ep:167, loss:0.00001, loss_test:0.07316, lr:3.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.257, tt:6259.129\n",
      "Ep:168, loss:0.00001, loss_test:0.07304, lr:3.38e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.252, tt:6295.513\n",
      "Ep:169, loss:0.00001, loss_test:0.07304, lr:3.34e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.252, tt:6332.839\n",
      "Ep:170, loss:0.00001, loss_test:0.07329, lr:3.31e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.251, tt:6369.838\n",
      "Ep:171, loss:0.00001, loss_test:0.07315, lr:3.28e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.249, tt:6406.893\n",
      "Ep:172, loss:0.00001, loss_test:0.07306, lr:3.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.252, tt:6444.660\n",
      "Ep:173, loss:0.00001, loss_test:0.07341, lr:3.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.259, tt:6483.019\n",
      "Ep:174, loss:0.00001, loss_test:0.07377, lr:3.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.250, tt:6518.814\n",
      "Ep:175, loss:0.00001, loss_test:0.07323, lr:3.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.257, tt:6557.199\n",
      "Ep:176, loss:0.00001, loss_test:0.07312, lr:3.12e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.266, tt:6596.125\n",
      "Ep:177, loss:0.00001, loss_test:0.07382, lr:3.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.269, tt:6633.805\n",
      "Ep:178, loss:0.00001, loss_test:0.07351, lr:3.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.271, tt:6671.432\n",
      "Ep:179, loss:0.00001, loss_test:0.07310, lr:3.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.292, tt:6712.488\n",
      "Ep:180, loss:0.00001, loss_test:0.07373, lr:2.99e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.293, tt:6749.990\n",
      "Ep:181, loss:0.00001, loss_test:0.07367, lr:2.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.306, tt:6789.697\n",
      "Ep:182, loss:0.00001, loss_test:0.07340, lr:2.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.307, tt:6827.267\n",
      "Ep:183, loss:0.00001, loss_test:0.07329, lr:2.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.311, tt:6865.174\n",
      "Ep:184, loss:0.00001, loss_test:0.07335, lr:2.88e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.313, tt:6902.857\n",
      "Ep:185, loss:0.00001, loss_test:0.07375, lr:2.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.308, tt:6939.355\n",
      "Ep:186, loss:0.00001, loss_test:0.07371, lr:2.82e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.305, tt:6976.113\n",
      "Ep:187, loss:0.00001, loss_test:0.07389, lr:2.79e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.311, tt:7014.408\n",
      "Ep:188, loss:0.00001, loss_test:0.07408, lr:2.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.315, tt:7052.446\n",
      "Ep:189, loss:0.00001, loss_test:0.07335, lr:2.73e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.313, tt:7089.393\n",
      "Ep:190, loss:0.00001, loss_test:0.07394, lr:2.71e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.316, tt:7127.417\n",
      "Ep:191, loss:0.00001, loss_test:0.07408, lr:2.68e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.322, tt:7165.808\n",
      "Ep:192, loss:0.00001, loss_test:0.07374, lr:2.65e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.326, tt:7203.956\n",
      "Ep:193, loss:0.00001, loss_test:0.07398, lr:2.63e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.337, tt:7243.465\n",
      "Ep:194, loss:0.00001, loss_test:0.07408, lr:2.60e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.338, tt:7280.956\n",
      "Ep:195, loss:0.00001, loss_test:0.07390, lr:2.57e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.335, tt:7317.715\n",
      "Ep:196, loss:0.00001, loss_test:0.07383, lr:2.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.343, tt:7356.561\n",
      "Ep:197, loss:0.00001, loss_test:0.07396, lr:2.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.348, tt:7394.965\n",
      "Ep:198, loss:0.00001, loss_test:0.07416, lr:2.50e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.354, tt:7433.451\n",
      "Ep:199, loss:0.00001, loss_test:0.07423, lr:2.47e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.354, tt:7470.754\n",
      "Ep:200, loss:0.00001, loss_test:0.07404, lr:2.45e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.365, tt:7510.318\n",
      "Ep:201, loss:0.00001, loss_test:0.07417, lr:2.42e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.376, tt:7549.851\n",
      "Ep:202, loss:0.00001, loss_test:0.07429, lr:2.40e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.403, tt:7592.773\n",
      "Ep:203, loss:0.00001, loss_test:0.07412, lr:2.38e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.412, tt:7632.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00001, loss_test:0.07433, lr:2.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.420, tt:7671.160\n",
      "Ep:205, loss:0.00001, loss_test:0.07416, lr:2.33e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.416, tt:7707.773\n",
      "Ep:206, loss:0.00001, loss_test:0.07415, lr:2.31e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.419, tt:7745.809\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13742, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.340, tt:37.340\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13451, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.995, tt:73.990\n",
      "Ep:2, loss:0.00027, loss_test:0.12936, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:35.730, tt:107.190\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12124, lr:1.00e-02, fs:0.67883 (r=0.939,p=0.531),  time:36.672, tt:146.687\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11232, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:37.205, tt:186.027\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.10632, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:37.310, tt:223.861\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10436, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:37.599, tt:263.194\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10425, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:37.539, tt:300.309\n",
      "Ep:8, loss:0.00021, loss_test:0.09938, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:37.593, tt:338.332\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.09557, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:37.721, tt:377.209\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.09415, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:37.747, tt:415.216\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.09229, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:37.755, tt:453.055\n",
      "Ep:12, loss:0.00018, loss_test:0.09112, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:37.703, tt:490.138\n",
      "Ep:13, loss:0.00017, loss_test:0.08966, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:37.809, tt:529.329\n",
      "Ep:14, loss:0.00016, loss_test:0.08853, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:37.766, tt:566.495\n",
      "Ep:15, loss:0.00016, loss_test:0.08816, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:37.711, tt:603.382\n",
      "Ep:16, loss:0.00015, loss_test:0.08749, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:37.736, tt:641.506\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08559, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:37.817, tt:680.699\n",
      "Ep:18, loss:0.00014, loss_test:0.08449, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:37.843, tt:719.026\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08335, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:37.795, tt:755.894\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08129, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:37.777, tt:793.320\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08004, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:37.723, tt:829.901\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08028, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:37.710, tt:867.329\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07888, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:37.652, tt:903.646\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07798, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:37.624, tt:940.606\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07703, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:37.660, tt:979.157\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07659, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:37.609, tt:1015.441\n",
      "Ep:27, loss:0.00010, loss_test:0.07555, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:37.635, tt:1053.769\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.07459, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:37.655, tt:1092.005\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.07544, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:37.632, tt:1128.969\n",
      "Ep:30, loss:0.00009, loss_test:0.07411, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:37.691, tt:1168.428\n",
      "Ep:31, loss:0.00008, loss_test:0.07521, lr:1.00e-02, fs:0.84091 (r=0.747,p=0.961),  time:37.737, tt:1207.587\n",
      "Ep:32, loss:0.00008, loss_test:0.07238, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:37.708, tt:1244.378\n",
      "Ep:33, loss:0.00008, loss_test:0.07322, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:37.819, tt:1285.849\n",
      "Ep:34, loss:0.00007, loss_test:0.07162, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:37.783, tt:1322.393\n",
      "Ep:35, loss:0.00007, loss_test:0.07132, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:37.751, tt:1359.021\n",
      "Ep:36, loss:0.00007, loss_test:0.07262, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:37.734, tt:1396.156\n",
      "Ep:37, loss:0.00007, loss_test:0.07029, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:37.754, tt:1434.666\n",
      "Ep:38, loss:0.00006, loss_test:0.07259, lr:1.00e-02, fs:0.86364 (r=0.768,p=0.987),  time:37.742, tt:1471.936\n",
      "Ep:39, loss:0.00006, loss_test:0.06946, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.713, tt:1508.529\n",
      "Ep:40, loss:0.00006, loss_test:0.07068, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.707, tt:1545.984\n",
      "Ep:41, loss:0.00005, loss_test:0.06712, lr:9.80e-03, fs:0.87568 (r=0.818,p=0.942),  time:37.662, tt:1581.815\n",
      "Ep:42, loss:0.00005, loss_test:0.07107, lr:9.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:37.639, tt:1618.495\n",
      "Ep:43, loss:0.00005, loss_test:0.06694, lr:9.61e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.628, tt:1655.634\n",
      "Ep:44, loss:0.00005, loss_test:0.06959, lr:9.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.599, tt:1691.952\n",
      "Ep:45, loss:0.00005, loss_test:0.06774, lr:9.41e-03, fs:0.87778 (r=0.798,p=0.975),  time:37.575, tt:1728.431\n",
      "Ep:46, loss:0.00005, loss_test:0.06758, lr:9.32e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.572, tt:1765.868\n",
      "Ep:47, loss:0.00004, loss_test:0.06860, lr:9.23e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.597, tt:1804.634\n",
      "Ep:48, loss:0.00004, loss_test:0.06474, lr:9.14e-03, fs:0.87568 (r=0.818,p=0.942),  time:37.645, tt:1844.618\n",
      "Ep:49, loss:0.00004, loss_test:0.06723, lr:9.04e-03, fs:0.89011 (r=0.818,p=0.976),  time:37.667, tt:1883.369\n",
      "Ep:50, loss:0.00004, loss_test:0.06318, lr:8.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.674, tt:1921.385\n",
      "Ep:51, loss:0.00004, loss_test:0.06549, lr:8.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.652, tt:1957.892\n",
      "Ep:52, loss:0.00004, loss_test:0.06389, lr:8.78e-03, fs:0.88398 (r=0.808,p=0.976),  time:37.631, tt:1994.464\n",
      "Ep:53, loss:0.00004, loss_test:0.06265, lr:8.69e-03, fs:0.88525 (r=0.818,p=0.964),  time:37.655, tt:2033.387\n",
      "Ep:54, loss:0.00003, loss_test:0.06585, lr:8.60e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.680, tt:2072.417\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.06115, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:37.716, tt:2112.122\n",
      "Ep:56, loss:0.00003, loss_test:0.06342, lr:8.60e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.725, tt:2150.313\n",
      "Ep:57, loss:0.00003, loss_test:0.06329, lr:8.60e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.745, tt:2189.208\n",
      "Ep:58, loss:0.00003, loss_test:0.06268, lr:8.60e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.723, tt:2225.681\n",
      "Ep:59, loss:0.00003, loss_test:0.06231, lr:8.60e-03, fs:0.88525 (r=0.818,p=0.964),  time:37.700, tt:2262.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.06222, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:37.684, tt:2298.743\n",
      "Ep:61, loss:0.00003, loss_test:0.06102, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:37.728, tt:2339.140\n",
      "Ep:62, loss:0.00003, loss_test:0.06324, lr:8.60e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.731, tt:2377.067\n",
      "Ep:63, loss:0.00002, loss_test:0.06157, lr:8.60e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.742, tt:2415.474\n",
      "Ep:64, loss:0.00002, loss_test:0.06248, lr:8.60e-03, fs:0.88525 (r=0.818,p=0.964),  time:37.730, tt:2452.457\n",
      "Ep:65, loss:0.00002, loss_test:0.06198, lr:8.60e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.729, tt:2490.113\n",
      "Ep:66, loss:0.00002, loss_test:0.06158, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:37.744, tt:2528.828\n",
      "Ep:67, loss:0.00002, loss_test:0.06534, lr:8.43e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.740, tt:2566.312\n",
      "Ep:68, loss:0.00002, loss_test:0.05914, lr:8.35e-03, fs:0.88525 (r=0.818,p=0.964),  time:37.722, tt:2602.840\n",
      "Ep:69, loss:0.00002, loss_test:0.06531, lr:8.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.731, tt:2641.203\n",
      "Ep:70, loss:0.00002, loss_test:0.06089, lr:8.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:37.752, tt:2680.363\n",
      "Ep:71, loss:0.00002, loss_test:0.06263, lr:8.10e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.746, tt:2717.701\n",
      "Ep:72, loss:0.00002, loss_test:0.06421, lr:8.02e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.730, tt:2754.289\n",
      "Ep:73, loss:0.00002, loss_test:0.06023, lr:7.94e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.686, tt:2788.746\n",
      "Ep:74, loss:0.00002, loss_test:0.06274, lr:7.86e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.672, tt:2825.400\n",
      "Ep:75, loss:0.00002, loss_test:0.06350, lr:7.78e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.625, tt:2859.487\n",
      "Ep:76, loss:0.00002, loss_test:0.06046, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.641, tt:2898.343\n",
      "Ep:77, loss:0.00002, loss_test:0.06317, lr:7.62e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.615, tt:2933.987\n",
      "Ep:78, loss:0.00002, loss_test:0.06202, lr:7.55e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.634, tt:2973.120\n",
      "Ep:79, loss:0.00002, loss_test:0.06110, lr:7.47e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.636, tt:3010.842\n",
      "Ep:80, loss:0.00002, loss_test:0.06363, lr:7.40e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.637, tt:3048.629\n",
      "Ep:81, loss:0.00001, loss_test:0.06262, lr:7.32e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.602, tt:3083.347\n",
      "Ep:82, loss:0.00001, loss_test:0.06169, lr:7.25e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.589, tt:3119.923\n",
      "Ep:83, loss:0.00001, loss_test:0.06552, lr:7.18e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.596, tt:3158.069\n",
      "Ep:84, loss:0.00001, loss_test:0.06165, lr:7.11e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.567, tt:3193.172\n",
      "Ep:85, loss:0.00001, loss_test:0.06694, lr:7.03e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.574, tt:3231.349\n",
      "Ep:86, loss:0.00001, loss_test:0.06537, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.545, tt:3266.400\n",
      "Ep:87, loss:0.00001, loss_test:0.06057, lr:6.89e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.521, tt:3301.884\n",
      "Ep:88, loss:0.00001, loss_test:0.07050, lr:6.83e-03, fs:0.84393 (r=0.737,p=0.986),  time:37.521, tt:3339.362\n",
      "Ep:89, loss:0.00001, loss_test:0.06320, lr:6.76e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.506, tt:3375.521\n",
      "Ep:90, loss:0.00001, loss_test:0.06287, lr:6.69e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.490, tt:3411.577\n",
      "Ep:91, loss:0.00001, loss_test:0.06471, lr:6.62e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.481, tt:3448.256\n",
      "Ep:92, loss:0.00001, loss_test:0.06480, lr:6.56e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.485, tt:3486.132\n",
      "Ep:93, loss:0.00001, loss_test:0.06206, lr:6.49e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.478, tt:3522.927\n",
      "Ep:94, loss:0.00001, loss_test:0.06399, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.466, tt:3559.290\n",
      "Ep:95, loss:0.00001, loss_test:0.06606, lr:6.36e-03, fs:0.88889 (r=0.808,p=0.988),  time:37.464, tt:3596.565\n",
      "Ep:96, loss:0.00001, loss_test:0.06120, lr:6.30e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.457, tt:3633.304\n",
      "Ep:97, loss:0.00001, loss_test:0.06378, lr:6.24e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.446, tt:3669.667\n",
      "Ep:98, loss:0.00001, loss_test:0.06301, lr:6.17e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.440, tt:3706.583\n",
      "Ep:99, loss:0.00001, loss_test:0.06366, lr:6.11e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.432, tt:3743.230\n",
      "Ep:100, loss:0.00001, loss_test:0.06208, lr:6.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.411, tt:3778.481\n",
      "Ep:101, loss:0.00001, loss_test:0.06362, lr:5.99e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.399, tt:3814.746\n",
      "Ep:102, loss:0.00001, loss_test:0.06377, lr:5.93e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.369, tt:3848.984\n",
      "Ep:103, loss:0.00001, loss_test:0.06223, lr:5.87e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.353, tt:3884.743\n",
      "Ep:104, loss:0.00001, loss_test:0.06393, lr:5.81e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.366, tt:3923.387\n",
      "Ep:105, loss:0.00001, loss_test:0.06361, lr:5.75e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.385, tt:3962.843\n",
      "Ep:106, loss:0.00001, loss_test:0.06226, lr:5.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.393, tt:4001.024\n",
      "Ep:107, loss:0.00001, loss_test:0.06407, lr:5.64e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.392, tt:4038.299\n",
      "Ep:108, loss:0.00001, loss_test:0.06348, lr:5.58e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.371, tt:4073.386\n",
      "Ep:109, loss:0.00001, loss_test:0.06422, lr:5.53e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.357, tt:4109.222\n",
      "Ep:110, loss:0.00001, loss_test:0.06395, lr:5.47e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.335, tt:4144.208\n",
      "Ep:111, loss:0.00001, loss_test:0.06413, lr:5.42e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.339, tt:4181.931\n",
      "Ep:112, loss:0.00001, loss_test:0.06492, lr:5.36e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.348, tt:4220.314\n",
      "Ep:113, loss:0.00001, loss_test:0.06270, lr:5.31e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.360, tt:4259.035\n",
      "Ep:114, loss:0.00001, loss_test:0.06506, lr:5.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.350, tt:4295.279\n",
      "Ep:115, loss:0.00001, loss_test:0.06507, lr:5.20e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.355, tt:4333.174\n",
      "Ep:116, loss:0.00001, loss_test:0.06388, lr:5.15e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.363, tt:4371.525\n",
      "Ep:117, loss:0.00001, loss_test:0.06379, lr:5.10e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.369, tt:4409.564\n",
      "Ep:118, loss:0.00001, loss_test:0.06431, lr:5.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.401, tt:4450.722\n",
      "Ep:119, loss:0.00001, loss_test:0.06309, lr:5.00e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.395, tt:4487.422\n",
      "Ep:120, loss:0.00001, loss_test:0.06481, lr:4.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.396, tt:4524.889\n",
      "Ep:121, loss:0.00001, loss_test:0.06437, lr:4.90e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.394, tt:4562.014\n",
      "Ep:122, loss:0.00001, loss_test:0.06487, lr:4.85e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.378, tt:4597.437\n",
      "Ep:123, loss:0.00001, loss_test:0.06440, lr:4.80e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.355, tt:4632.020\n",
      "Ep:124, loss:0.00001, loss_test:0.06474, lr:4.75e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.374, tt:4671.788\n",
      "Ep:125, loss:0.00001, loss_test:0.06608, lr:4.71e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.379, tt:4709.776\n",
      "Ep:126, loss:0.00001, loss_test:0.06501, lr:4.66e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.380, tt:4747.212\n",
      "Ep:127, loss:0.00001, loss_test:0.06511, lr:4.61e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.375, tt:4784.003\n",
      "Ep:128, loss:0.00001, loss_test:0.06600, lr:4.57e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.354, tt:4818.684\n",
      "Ep:129, loss:0.00001, loss_test:0.06456, lr:4.52e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.341, tt:4854.278\n",
      "Ep:130, loss:0.00001, loss_test:0.06523, lr:4.48e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.327, tt:4889.863\n",
      "Ep:131, loss:0.00001, loss_test:0.06672, lr:4.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.326, tt:4927.009\n",
      "Ep:132, loss:0.00001, loss_test:0.06536, lr:4.39e-03, fs:0.89503 (r=0.818,p=0.988),  time:37.311, tt:4962.363\n",
      "Ep:133, loss:0.00001, loss_test:0.06510, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.301, tt:4998.335\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00001, loss_test:0.06653, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.299, tt:5035.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.06635, lr:4.34e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.294, tt:5071.954\n",
      "Ep:136, loss:0.00001, loss_test:0.06513, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.279, tt:5107.238\n",
      "Ep:137, loss:0.00001, loss_test:0.06698, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.282, tt:5144.920\n",
      "Ep:138, loss:0.00001, loss_test:0.06706, lr:4.34e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.288, tt:5182.972\n",
      "Ep:139, loss:0.00000, loss_test:0.06545, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.275, tt:5218.441\n",
      "Ep:140, loss:0.00000, loss_test:0.06672, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.268, tt:5254.734\n",
      "Ep:141, loss:0.00000, loss_test:0.06568, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.273, tt:5292.814\n",
      "Ep:142, loss:0.00000, loss_test:0.06596, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.273, tt:5329.992\n",
      "Ep:143, loss:0.00000, loss_test:0.06645, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.268, tt:5366.586\n",
      "Ep:144, loss:0.00000, loss_test:0.06607, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.266, tt:5403.590\n",
      "Ep:145, loss:0.00000, loss_test:0.06629, lr:4.30e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.264, tt:5440.512\n",
      "Ep:146, loss:0.00000, loss_test:0.06609, lr:4.26e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.267, tt:5478.207\n",
      "Ep:147, loss:0.00000, loss_test:0.06631, lr:4.21e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.256, tt:5513.961\n",
      "Ep:148, loss:0.00000, loss_test:0.06700, lr:4.17e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.258, tt:5551.387\n",
      "Ep:149, loss:0.00000, loss_test:0.06658, lr:4.13e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.258, tt:5588.756\n",
      "Ep:150, loss:0.00000, loss_test:0.06688, lr:4.09e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.253, tt:5625.147\n",
      "Ep:151, loss:0.00000, loss_test:0.06670, lr:4.05e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.265, tt:5664.218\n",
      "Ep:152, loss:0.00000, loss_test:0.06658, lr:4.01e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.269, tt:5702.160\n",
      "Ep:153, loss:0.00000, loss_test:0.06732, lr:3.97e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.271, tt:5739.684\n",
      "Ep:154, loss:0.00000, loss_test:0.06589, lr:3.93e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.265, tt:5776.019\n",
      "Ep:155, loss:0.00000, loss_test:0.06706, lr:3.89e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.274, tt:5814.739\n",
      "Ep:156, loss:0.00000, loss_test:0.06693, lr:3.85e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.284, tt:5853.578\n",
      "Ep:157, loss:0.00000, loss_test:0.06647, lr:3.81e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.280, tt:5890.263\n",
      "Ep:158, loss:0.00000, loss_test:0.06714, lr:3.77e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.291, tt:5929.286\n",
      "Ep:159, loss:0.00000, loss_test:0.06641, lr:3.73e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.295, tt:5967.145\n",
      "Ep:160, loss:0.00000, loss_test:0.06641, lr:3.70e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.291, tt:6003.860\n",
      "Ep:161, loss:0.00000, loss_test:0.06675, lr:3.66e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.298, tt:6042.248\n",
      "Ep:162, loss:0.00000, loss_test:0.06609, lr:3.62e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.301, tt:6080.033\n",
      "Ep:163, loss:0.00000, loss_test:0.06706, lr:3.59e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.300, tt:6117.227\n",
      "Ep:164, loss:0.00000, loss_test:0.06790, lr:3.55e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.299, tt:6154.368\n",
      "Ep:165, loss:0.00000, loss_test:0.06669, lr:3.52e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.301, tt:6191.941\n",
      "Ep:166, loss:0.00000, loss_test:0.06648, lr:3.48e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.304, tt:6229.712\n",
      "Ep:167, loss:0.00000, loss_test:0.06827, lr:3.45e-03, fs:0.87500 (r=0.778,p=1.000),  time:37.309, tt:6267.915\n",
      "Ep:168, loss:0.00000, loss_test:0.06669, lr:3.41e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.320, tt:6307.011\n",
      "Ep:169, loss:0.00000, loss_test:0.06704, lr:3.38e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.317, tt:6343.946\n",
      "Ep:170, loss:0.00000, loss_test:0.06732, lr:3.34e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.309, tt:6379.754\n",
      "Ep:171, loss:0.00000, loss_test:0.06687, lr:3.31e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.296, tt:6414.952\n",
      "Ep:172, loss:0.00000, loss_test:0.06784, lr:3.28e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.291, tt:6451.308\n",
      "Ep:173, loss:0.00000, loss_test:0.06717, lr:3.24e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.281, tt:6486.851\n",
      "Ep:174, loss:0.00000, loss_test:0.06669, lr:3.21e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.284, tt:6524.700\n",
      "Ep:175, loss:0.00000, loss_test:0.06745, lr:3.18e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.284, tt:6562.035\n",
      "Ep:176, loss:0.00000, loss_test:0.06710, lr:3.15e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.275, tt:6597.728\n",
      "Ep:177, loss:0.00000, loss_test:0.06690, lr:3.12e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.265, tt:6633.209\n",
      "Ep:178, loss:0.00000, loss_test:0.06756, lr:3.09e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.267, tt:6670.723\n",
      "Ep:179, loss:0.00000, loss_test:0.06745, lr:3.05e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.257, tt:6706.313\n",
      "Ep:180, loss:0.00000, loss_test:0.06666, lr:3.02e-03, fs:0.90000 (r=0.818,p=1.000),  time:37.266, tt:6745.228\n",
      "Ep:181, loss:0.00000, loss_test:0.06716, lr:2.99e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.276, tt:6784.315\n",
      "Ep:182, loss:0.00000, loss_test:0.06759, lr:2.96e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.278, tt:6821.858\n",
      "Ep:183, loss:0.00000, loss_test:0.06771, lr:2.93e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.287, tt:6860.734\n",
      "Ep:184, loss:0.00000, loss_test:0.06721, lr:2.90e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.275, tt:6895.845\n",
      "Ep:185, loss:0.00000, loss_test:0.06661, lr:2.88e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.277, tt:6933.492\n",
      "Ep:186, loss:0.00000, loss_test:0.06775, lr:2.85e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.281, tt:6971.548\n",
      "Ep:187, loss:0.00000, loss_test:0.06800, lr:2.82e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.276, tt:7007.975\n",
      "Ep:188, loss:0.00000, loss_test:0.06756, lr:2.79e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.287, tt:7047.255\n",
      "Ep:189, loss:0.00000, loss_test:0.06701, lr:2.76e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.289, tt:7084.919\n",
      "Ep:190, loss:0.00000, loss_test:0.06699, lr:2.73e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.295, tt:7123.270\n",
      "Ep:191, loss:0.00000, loss_test:0.06830, lr:2.71e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.297, tt:7160.969\n",
      "Ep:192, loss:0.00000, loss_test:0.06783, lr:2.68e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.296, tt:7198.197\n",
      "Ep:193, loss:0.00000, loss_test:0.06670, lr:2.65e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.293, tt:7234.861\n",
      "Ep:194, loss:0.00000, loss_test:0.06760, lr:2.63e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.278, tt:7269.186\n",
      "Ep:195, loss:0.00000, loss_test:0.06805, lr:2.60e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.279, tt:7306.597\n",
      "Ep:196, loss:0.00000, loss_test:0.06771, lr:2.57e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.276, tt:7343.444\n",
      "Ep:197, loss:0.00000, loss_test:0.06789, lr:2.55e-03, fs:0.88764 (r=0.798,p=1.000),  time:37.278, tt:7380.979\n",
      "Ep:198, loss:0.00000, loss_test:0.06722, lr:2.52e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.277, tt:7418.162\n",
      "Ep:199, loss:0.00000, loss_test:0.06816, lr:2.50e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.282, tt:7456.365\n",
      "Ep:200, loss:0.00000, loss_test:0.06828, lr:2.47e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.278, tt:7492.796\n",
      "Ep:201, loss:0.00000, loss_test:0.06743, lr:2.45e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.284, tt:7531.376\n",
      "Ep:202, loss:0.00000, loss_test:0.06692, lr:2.42e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.287, tt:7569.316\n",
      "Ep:203, loss:0.00000, loss_test:0.06791, lr:2.40e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.293, tt:7607.771\n",
      "Ep:204, loss:0.00000, loss_test:0.06859, lr:2.38e-03, fs:0.88136 (r=0.788,p=1.000),  time:37.293, tt:7645.141\n",
      "Ep:205, loss:0.00000, loss_test:0.06773, lr:2.35e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.295, tt:7682.761\n",
      "Ep:206, loss:0.00000, loss_test:0.06756, lr:2.33e-03, fs:0.89385 (r=0.808,p=1.000),  time:37.283, tt:7717.527\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00085, loss_test:0.02084, lr:1.00e-02, fs:0.69406 (r=0.874,p=0.576),  time:609.300, tt:609.300\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01847, lr:1.00e-02, fs:0.73684 (r=0.885,p=0.631),  time:637.175, tt:1274.350\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.01673, lr:1.00e-02, fs:0.76238 (r=0.885,p=0.670),  time:647.766, tt:1943.298\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.01582, lr:1.00e-02, fs:0.78571 (r=0.885,p=0.706),  time:648.496, tt:2593.982\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00042, loss_test:0.01520, lr:1.00e-02, fs:0.76190 (r=0.828,p=0.706),  time:651.303, tt:3256.514\n",
      "Ep:5, loss:0.00037, loss_test:0.01485, lr:1.00e-02, fs:0.78022 (r=0.816,p=0.747),  time:652.933, tt:3917.595\n",
      "Ep:6, loss:0.00033, loss_test:0.01476, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:653.272, tt:4572.901\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.01480, lr:1.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:654.367, tt:5234.933\n",
      "Ep:8, loss:0.00027, loss_test:0.01514, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:655.363, tt:5898.265\n",
      "Ep:9, loss:0.00024, loss_test:0.01534, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:656.059, tt:6560.588\n",
      "Ep:10, loss:0.00022, loss_test:0.01577, lr:1.00e-02, fs:0.73620 (r=0.690,p=0.789),  time:654.937, tt:7204.310\n",
      "Ep:11, loss:0.00020, loss_test:0.01621, lr:1.00e-02, fs:0.71250 (r=0.655,p=0.781),  time:654.598, tt:7855.180\n",
      "Ep:12, loss:0.00018, loss_test:0.01665, lr:1.00e-02, fs:0.70886 (r=0.644,p=0.789),  time:654.270, tt:8505.507\n",
      "Ep:13, loss:0.00017, loss_test:0.01716, lr:1.00e-02, fs:0.70886 (r=0.644,p=0.789),  time:653.985, tt:9155.784\n",
      "Ep:14, loss:0.00015, loss_test:0.01762, lr:1.00e-02, fs:0.71338 (r=0.644,p=0.800),  time:653.631, tt:9804.471\n",
      "Ep:15, loss:0.00014, loss_test:0.01822, lr:1.00e-02, fs:0.72727 (r=0.644,p=0.836),  time:653.405, tt:10454.484\n",
      "Ep:16, loss:0.00013, loss_test:0.01873, lr:1.00e-02, fs:0.72368 (r=0.632,p=0.846),  time:653.341, tt:11106.795\n",
      "Ep:17, loss:0.00012, loss_test:0.01919, lr:1.00e-02, fs:0.72848 (r=0.632,p=0.859),  time:653.148, tt:11756.664\n",
      "Ep:18, loss:0.00011, loss_test:0.01965, lr:9.90e-03, fs:0.72848 (r=0.632,p=0.859),  time:653.840, tt:12422.953\n",
      "Ep:19, loss:0.00010, loss_test:0.02030, lr:9.80e-03, fs:0.70270 (r=0.598,p=0.852),  time:653.677, tt:13073.531\n",
      "Ep:20, loss:0.00010, loss_test:0.02068, lr:9.70e-03, fs:0.65753 (r=0.552,p=0.814),  time:653.517, tt:13723.854\n",
      "Ep:21, loss:0.00009, loss_test:0.02141, lr:9.61e-03, fs:0.61429 (r=0.494,p=0.811),  time:654.183, tt:14392.033\n",
      "Ep:22, loss:0.00009, loss_test:0.02180, lr:9.51e-03, fs:0.57353 (r=0.448,p=0.796),  time:654.440, tt:15052.111\n",
      "Ep:23, loss:0.00008, loss_test:0.02205, lr:9.41e-03, fs:0.55385 (r=0.414,p=0.837),  time:654.880, tt:15717.109\n",
      "Ep:24, loss:0.00008, loss_test:0.02260, lr:9.32e-03, fs:0.53125 (r=0.391,p=0.829),  time:655.108, tt:16377.701\n",
      "Ep:25, loss:0.00007, loss_test:0.02311, lr:9.23e-03, fs:0.52381 (r=0.379,p=0.846),  time:655.366, tt:17039.515\n",
      "Ep:26, loss:0.00007, loss_test:0.02337, lr:9.14e-03, fs:0.52800 (r=0.379,p=0.868),  time:655.047, tt:17686.269\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00080, loss_test:0.02032, lr:1.00e-02, fs:0.68246 (r=0.828,p=0.581),  time:644.611, tt:644.611\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01748, lr:1.00e-02, fs:0.72727 (r=0.874,p=0.623),  time:639.064, tt:1278.129\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.01591, lr:1.00e-02, fs:0.77451 (r=0.908,p=0.675),  time:634.863, tt:1904.590\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.01491, lr:1.00e-02, fs:0.80402 (r=0.920,p=0.714),  time:636.056, tt:2544.222\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00039, loss_test:0.01454, lr:1.00e-02, fs:0.81865 (r=0.908,p=0.745),  time:633.808, tt:3169.041\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00035, loss_test:0.01435, lr:1.00e-02, fs:0.82979 (r=0.897,p=0.772),  time:636.602, tt:3819.612\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.01431, lr:1.00e-02, fs:0.83516 (r=0.874,p=0.800),  time:636.870, tt:4458.093\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00028, loss_test:0.01451, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:637.070, tt:5096.559\n",
      "Ep:8, loss:0.00025, loss_test:0.01498, lr:1.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:638.497, tt:5746.474\n",
      "Ep:9, loss:0.00023, loss_test:0.01538, lr:1.00e-02, fs:0.75776 (r=0.701,p=0.824),  time:638.644, tt:6386.438\n",
      "Ep:10, loss:0.00020, loss_test:0.01585, lr:1.00e-02, fs:0.75472 (r=0.690,p=0.833),  time:638.905, tt:7027.955\n",
      "Ep:11, loss:0.00019, loss_test:0.01652, lr:1.00e-02, fs:0.72368 (r=0.632,p=0.846),  time:639.505, tt:7674.062\n",
      "Ep:12, loss:0.00017, loss_test:0.01709, lr:1.00e-02, fs:0.70270 (r=0.598,p=0.852),  time:639.861, tt:8318.197\n",
      "Ep:13, loss:0.00016, loss_test:0.01771, lr:1.00e-02, fs:0.68493 (r=0.575,p=0.847),  time:640.555, tt:8967.768\n",
      "Ep:14, loss:0.00015, loss_test:0.01839, lr:1.00e-02, fs:0.66197 (r=0.540,p=0.855),  time:640.333, tt:9604.992\n",
      "Ep:15, loss:0.00014, loss_test:0.01891, lr:1.00e-02, fs:0.65248 (r=0.529,p=0.852),  time:640.587, tt:10249.394\n",
      "Ep:16, loss:0.00013, loss_test:0.01949, lr:1.00e-02, fs:0.65248 (r=0.529,p=0.852),  time:640.564, tt:10889.582\n",
      "Ep:17, loss:0.00012, loss_test:0.02031, lr:1.00e-02, fs:0.63768 (r=0.506,p=0.863),  time:640.930, tt:11536.745\n",
      "Ep:18, loss:0.00011, loss_test:0.02120, lr:9.90e-03, fs:0.61765 (r=0.483,p=0.857),  time:641.209, tt:12182.980\n",
      "Ep:19, loss:0.00010, loss_test:0.02169, lr:9.80e-03, fs:0.63704 (r=0.494,p=0.896),  time:641.352, tt:12827.034\n",
      "Ep:20, loss:0.00010, loss_test:0.02212, lr:9.70e-03, fs:0.63636 (r=0.483,p=0.933),  time:641.312, tt:13467.558\n",
      "Ep:21, loss:0.00009, loss_test:0.02301, lr:9.61e-03, fs:0.63636 (r=0.483,p=0.933),  time:641.137, tt:14105.018\n",
      "Ep:22, loss:0.00009, loss_test:0.02339, lr:9.51e-03, fs:0.62595 (r=0.471,p=0.932),  time:640.806, tt:14738.532\n",
      "Ep:23, loss:0.00008, loss_test:0.02388, lr:9.41e-03, fs:0.62595 (r=0.471,p=0.932),  time:640.513, tt:15372.315\n",
      "Ep:24, loss:0.00008, loss_test:0.02453, lr:9.32e-03, fs:0.60317 (r=0.437,p=0.974),  time:640.121, tt:16003.030\n",
      "Ep:25, loss:0.00007, loss_test:0.02508, lr:9.23e-03, fs:0.56911 (r=0.402,p=0.972),  time:639.818, tt:16635.277\n",
      "Ep:26, loss:0.00007, loss_test:0.02580, lr:9.14e-03, fs:0.59200 (r=0.425,p=0.974),  time:638.217, tt:17231.859\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00076, loss_test:0.01924, lr:1.00e-02, fs:0.69231 (r=0.931,p=0.551),  time:659.746, tt:659.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01804, lr:1.00e-02, fs:0.73059 (r=0.920,p=0.606),  time:657.090, tt:1314.180\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01696, lr:1.00e-02, fs:0.77725 (r=0.943,p=0.661),  time:659.495, tt:1978.486\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.01615, lr:1.00e-02, fs:0.81773 (r=0.954,p=0.716),  time:659.911, tt:2639.643\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.01562, lr:1.00e-02, fs:0.83417 (r=0.954,p=0.741),  time:658.036, tt:3290.182\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.01521, lr:1.00e-02, fs:0.84848 (r=0.966,p=0.757),  time:657.856, tt:3947.136\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.01490, lr:1.00e-02, fs:0.84848 (r=0.966,p=0.757),  time:656.965, tt:4598.754\n",
      "Ep:7, loss:0.00039, loss_test:0.01474, lr:1.00e-02, fs:0.84974 (r=0.943,p=0.774),  time:656.597, tt:5252.773\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.01459, lr:1.00e-02, fs:0.84656 (r=0.920,p=0.784),  time:657.077, tt:5913.697\n",
      "Ep:9, loss:0.00034, loss_test:0.01449, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:657.305, tt:6573.048\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.01443, lr:1.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:657.117, tt:7228.288\n",
      "Ep:11, loss:0.00031, loss_test:0.01452, lr:1.00e-02, fs:0.84615 (r=0.885,p=0.811),  time:658.148, tt:7897.774\n",
      "Ep:12, loss:0.00029, loss_test:0.01451, lr:1.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:658.242, tt:8557.145\n",
      "Ep:13, loss:0.00027, loss_test:0.01459, lr:1.00e-02, fs:0.85556 (r=0.885,p=0.828),  time:657.785, tt:9208.989\n",
      "Ep:14, loss:0.00026, loss_test:0.01473, lr:1.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:657.922, tt:9868.832\n",
      "Ep:15, loss:0.00024, loss_test:0.01489, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:658.018, tt:10528.290\n",
      "Ep:16, loss:0.00023, loss_test:0.01507, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:658.332, tt:11191.636\n",
      "Ep:17, loss:0.00022, loss_test:0.01520, lr:1.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:658.675, tt:11856.147\n",
      "Ep:18, loss:0.00021, loss_test:0.01539, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:659.223, tt:12525.233\n",
      "Ep:19, loss:0.00020, loss_test:0.01553, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:659.569, tt:13191.386\n",
      "Ep:20, loss:0.00019, loss_test:0.01572, lr:1.00e-02, fs:0.77500 (r=0.713,p=0.849),  time:659.755, tt:13854.858\n",
      "Ep:21, loss:0.00018, loss_test:0.01595, lr:9.90e-03, fs:0.75325 (r=0.667,p=0.866),  time:659.765, tt:14514.820\n",
      "Ep:22, loss:0.00017, loss_test:0.01623, lr:9.80e-03, fs:0.69863 (r=0.586,p=0.864),  time:659.824, tt:15175.946\n",
      "Ep:23, loss:0.00016, loss_test:0.01631, lr:9.70e-03, fs:0.68056 (r=0.563,p=0.860),  time:660.358, tt:15848.594\n",
      "Ep:24, loss:0.00015, loss_test:0.01659, lr:9.61e-03, fs:0.69014 (r=0.563,p=0.891),  time:660.063, tt:16501.580\n",
      "Ep:25, loss:0.00015, loss_test:0.01680, lr:9.51e-03, fs:0.68116 (r=0.540,p=0.922),  time:660.209, tt:17165.440\n",
      "Ep:26, loss:0.00014, loss_test:0.01708, lr:9.41e-03, fs:0.65185 (r=0.506,p=0.917),  time:660.160, tt:17824.332\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.01905, lr:1.00e-02, fs:0.70042 (r=0.954,p=0.553),  time:646.460, tt:646.460\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01867, lr:1.00e-02, fs:0.71770 (r=0.862,p=0.615),  time:644.569, tt:1289.138\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00059, loss_test:0.01796, lr:1.00e-02, fs:0.75862 (r=0.885,p=0.664),  time:651.873, tt:1955.618\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00056, loss_test:0.01745, lr:1.00e-02, fs:0.78974 (r=0.885,p=0.713),  time:652.913, tt:2611.652\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00053, loss_test:0.01699, lr:1.00e-02, fs:0.80000 (r=0.897,p=0.722),  time:653.581, tt:3267.906\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00051, loss_test:0.01658, lr:1.00e-02, fs:0.82292 (r=0.908,p=0.752),  time:653.570, tt:3921.418\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00049, loss_test:0.01626, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:654.104, tt:4578.725\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00047, loss_test:0.01598, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:657.921, tt:5263.370\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00045, loss_test:0.01574, lr:1.00e-02, fs:0.85405 (r=0.908,p=0.806),  time:662.086, tt:5958.778\n",
      "Ep:9, loss:0.00043, loss_test:0.01549, lr:1.00e-02, fs:0.86772 (r=0.943,p=0.804),  time:662.384, tt:6623.840\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.01536, lr:1.00e-02, fs:0.85246 (r=0.897,p=0.812),  time:663.177, tt:7294.950\n",
      "Ep:11, loss:0.00040, loss_test:0.01516, lr:1.00e-02, fs:0.86486 (r=0.920,p=0.816),  time:663.275, tt:7959.295\n",
      "Ep:12, loss:0.00039, loss_test:0.01506, lr:1.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:663.160, tt:8621.075\n",
      "Ep:13, loss:0.00037, loss_test:0.01494, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:663.387, tt:9287.415\n",
      "Ep:14, loss:0.00036, loss_test:0.01486, lr:1.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:664.207, tt:9963.109\n",
      "Ep:15, loss:0.00035, loss_test:0.01477, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:664.414, tt:10630.628\n",
      "Ep:16, loss:0.00034, loss_test:0.01473, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:664.848, tt:11302.422\n",
      "Ep:17, loss:0.00033, loss_test:0.01468, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:665.361, tt:11976.502\n",
      "Ep:18, loss:0.00032, loss_test:0.01462, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:665.752, tt:12649.281\n",
      "Ep:19, loss:0.00031, loss_test:0.01467, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:665.949, tt:13318.976\n",
      "Ep:20, loss:0.00030, loss_test:0.01461, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:665.652, tt:13978.688\n",
      "Ep:21, loss:0.00029, loss_test:0.01452, lr:9.90e-03, fs:0.84524 (r=0.816,p=0.877),  time:665.605, tt:14643.313\n",
      "Ep:22, loss:0.00028, loss_test:0.01452, lr:9.80e-03, fs:0.84524 (r=0.816,p=0.877),  time:665.961, tt:15317.103\n",
      "Ep:23, loss:0.00027, loss_test:0.01456, lr:9.70e-03, fs:0.83832 (r=0.805,p=0.875),  time:666.316, tt:15991.586\n",
      "Ep:24, loss:0.00026, loss_test:0.01456, lr:9.61e-03, fs:0.83832 (r=0.805,p=0.875),  time:666.498, tt:16662.456\n",
      "Ep:25, loss:0.00026, loss_test:0.01462, lr:9.51e-03, fs:0.83636 (r=0.793,p=0.885),  time:666.285, tt:17323.408\n",
      "Ep:26, loss:0.00025, loss_test:0.01457, lr:9.41e-03, fs:0.83133 (r=0.793,p=0.873),  time:666.222, tt:17987.999\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.01893, lr:1.00e-02, fs:0.67568 (r=0.862,p=0.556),  time:535.626, tt:535.626\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01791, lr:1.00e-02, fs:0.72811 (r=0.908,p=0.608),  time:541.201, tt:1082.402\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01711, lr:1.00e-02, fs:0.73934 (r=0.897,p=0.629),  time:540.765, tt:1622.294\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.01650, lr:1.00e-02, fs:0.77612 (r=0.897,p=0.684),  time:544.072, tt:2176.287\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01609, lr:1.00e-02, fs:0.79381 (r=0.885,p=0.720),  time:545.199, tt:2725.997\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00047, loss_test:0.01574, lr:1.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:549.032, tt:3294.195\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.01547, lr:1.00e-02, fs:0.80851 (r=0.874,p=0.752),  time:550.329, tt:3852.304\n",
      "Ep:7, loss:0.00042, loss_test:0.01523, lr:1.00e-02, fs:0.81283 (r=0.874,p=0.760),  time:550.147, tt:4401.175\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00040, loss_test:0.01517, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:550.121, tt:4951.089\n",
      "Ep:9, loss:0.00037, loss_test:0.01512, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:550.693, tt:5506.933\n",
      "Ep:10, loss:0.00035, loss_test:0.01514, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:550.870, tt:6059.571\n",
      "Ep:11, loss:0.00034, loss_test:0.01515, lr:1.00e-02, fs:0.77966 (r=0.793,p=0.767),  time:551.175, tt:6614.099\n",
      "Ep:12, loss:0.00032, loss_test:0.01512, lr:1.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:551.378, tt:7167.917\n",
      "Ep:13, loss:0.00030, loss_test:0.01517, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:551.909, tt:7726.719\n",
      "Ep:14, loss:0.00029, loss_test:0.01522, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:552.568, tt:8288.523\n",
      "Ep:15, loss:0.00027, loss_test:0.01529, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:552.405, tt:8838.483\n",
      "Ep:16, loss:0.00026, loss_test:0.01533, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:552.235, tt:9387.995\n",
      "Ep:17, loss:0.00025, loss_test:0.01545, lr:1.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:552.883, tt:9951.893\n",
      "Ep:18, loss:0.00023, loss_test:0.01548, lr:1.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:553.244, tt:10511.634\n",
      "Ep:19, loss:0.00022, loss_test:0.01565, lr:9.90e-03, fs:0.76923 (r=0.747,p=0.793),  time:553.934, tt:11078.681\n",
      "Ep:20, loss:0.00021, loss_test:0.01566, lr:9.80e-03, fs:0.77844 (r=0.747,p=0.812),  time:554.073, tt:11635.536\n",
      "Ep:21, loss:0.00020, loss_test:0.01580, lr:9.70e-03, fs:0.78788 (r=0.747,p=0.833),  time:554.015, tt:12188.340\n",
      "Ep:22, loss:0.00019, loss_test:0.01593, lr:9.61e-03, fs:0.79755 (r=0.747,p=0.855),  time:554.383, tt:12750.805\n",
      "Ep:23, loss:0.00019, loss_test:0.01612, lr:9.51e-03, fs:0.79755 (r=0.747,p=0.855),  time:554.751, tt:13314.020\n",
      "Ep:24, loss:0.00018, loss_test:0.01617, lr:9.41e-03, fs:0.77500 (r=0.713,p=0.849),  time:554.559, tt:13863.986\n",
      "Ep:25, loss:0.00017, loss_test:0.01634, lr:9.32e-03, fs:0.76730 (r=0.701,p=0.847),  time:554.617, tt:14420.032\n",
      "Ep:26, loss:0.00016, loss_test:0.01650, lr:9.23e-03, fs:0.75949 (r=0.690,p=0.845),  time:554.884, tt:14981.858\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00089, loss_test:0.02139, lr:1.00e-02, fs:0.69683 (r=0.885,p=0.575),  time:630.312, tt:630.312\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00064, loss_test:0.01839, lr:1.00e-02, fs:0.70909 (r=0.897,p=0.586),  time:617.356, tt:1234.713\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.01662, lr:1.00e-02, fs:0.75349 (r=0.931,p=0.633),  time:595.134, tt:1785.402\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.01563, lr:1.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:588.163, tt:2352.653\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00039, loss_test:0.01510, lr:1.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:581.776, tt:2908.881\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.01510, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:577.749, tt:3466.497\n",
      "Ep:6, loss:0.00028, loss_test:0.01566, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:577.420, tt:4041.941\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00023, loss_test:0.01632, lr:1.00e-02, fs:0.77778 (r=0.724,p=0.840),  time:575.969, tt:4607.755\n",
      "Ep:8, loss:0.00020, loss_test:0.01720, lr:1.00e-02, fs:0.61972 (r=0.506,p=0.800),  time:574.666, tt:5171.991\n",
      "Ep:9, loss:0.00017, loss_test:0.01813, lr:1.00e-02, fs:0.63380 (r=0.517,p=0.818),  time:573.813, tt:5738.132\n",
      "Ep:10, loss:0.00015, loss_test:0.01906, lr:1.00e-02, fs:0.63309 (r=0.506,p=0.846),  time:572.957, tt:6302.525\n",
      "Ep:11, loss:0.00013, loss_test:0.01967, lr:1.00e-02, fs:0.63235 (r=0.494,p=0.878),  time:571.774, tt:6861.291\n",
      "Ep:12, loss:0.00011, loss_test:0.02038, lr:1.00e-02, fs:0.63704 (r=0.494,p=0.896),  time:571.136, tt:7424.773\n",
      "Ep:13, loss:0.00010, loss_test:0.02103, lr:1.00e-02, fs:0.61194 (r=0.471,p=0.872),  time:570.533, tt:7987.459\n",
      "Ep:14, loss:0.00009, loss_test:0.02224, lr:1.00e-02, fs:0.61194 (r=0.471,p=0.872),  time:570.457, tt:8556.852\n",
      "Ep:15, loss:0.00008, loss_test:0.02323, lr:1.00e-02, fs:0.61654 (r=0.471,p=0.891),  time:570.565, tt:9129.042\n",
      "Ep:16, loss:0.00007, loss_test:0.02422, lr:1.00e-02, fs:0.57364 (r=0.425,p=0.881),  time:570.195, tt:9693.318\n",
      "Ep:17, loss:0.00007, loss_test:0.02494, lr:1.00e-02, fs:0.53226 (r=0.379,p=0.892),  time:569.479, tt:10250.630\n",
      "Ep:18, loss:0.00006, loss_test:0.02586, lr:9.90e-03, fs:0.53226 (r=0.379,p=0.892),  time:569.424, tt:10819.054\n",
      "Ep:19, loss:0.00005, loss_test:0.02662, lr:9.80e-03, fs:0.53659 (r=0.379,p=0.917),  time:569.105, tt:11382.098\n",
      "Ep:20, loss:0.00005, loss_test:0.02725, lr:9.70e-03, fs:0.53659 (r=0.379,p=0.917),  time:569.165, tt:11952.462\n",
      "Ep:21, loss:0.00005, loss_test:0.02804, lr:9.61e-03, fs:0.53659 (r=0.379,p=0.917),  time:568.952, tt:12516.947\n",
      "Ep:22, loss:0.00004, loss_test:0.02866, lr:9.51e-03, fs:0.53659 (r=0.379,p=0.917),  time:568.690, tt:13079.863\n",
      "Ep:23, loss:0.00004, loss_test:0.02944, lr:9.41e-03, fs:0.53659 (r=0.379,p=0.917),  time:568.729, tt:13649.502\n",
      "Ep:24, loss:0.00004, loss_test:0.03011, lr:9.32e-03, fs:0.53659 (r=0.379,p=0.917),  time:568.575, tt:14214.378\n",
      "Ep:25, loss:0.00003, loss_test:0.03078, lr:9.23e-03, fs:0.53659 (r=0.379,p=0.917),  time:567.804, tt:14762.914\n",
      "Ep:26, loss:0.00003, loss_test:0.03128, lr:9.14e-03, fs:0.53659 (r=0.379,p=0.917),  time:565.603, tt:15271.270\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00074, loss_test:0.01848, lr:1.00e-02, fs:0.70874 (r=0.839,p=0.613),  time:634.119, tt:634.119\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.01647, lr:1.00e-02, fs:0.80000 (r=0.943,p=0.695),  time:636.446, tt:1272.893\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.01555, lr:1.00e-02, fs:0.83000 (r=0.954,p=0.735),  time:637.885, tt:1913.656\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00044, loss_test:0.01517, lr:1.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:638.560, tt:2554.241\n",
      "Ep:4, loss:0.00040, loss_test:0.01476, lr:1.00e-02, fs:0.82723 (r=0.908,p=0.760),  time:639.420, tt:3197.099\n",
      "Ep:5, loss:0.00036, loss_test:0.01448, lr:1.00e-02, fs:0.83243 (r=0.885,p=0.786),  time:637.822, tt:3826.933\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.01436, lr:1.00e-02, fs:0.83516 (r=0.874,p=0.800),  time:637.720, tt:4464.037\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.01422, lr:1.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:641.955, tt:5135.643\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00027, loss_test:0.01436, lr:1.00e-02, fs:0.80925 (r=0.805,p=0.814),  time:649.832, tt:5848.484\n",
      "Ep:9, loss:0.00024, loss_test:0.01464, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:658.021, tt:6580.215\n",
      "Ep:10, loss:0.00022, loss_test:0.01481, lr:1.00e-02, fs:0.78261 (r=0.724,p=0.851),  time:663.340, tt:7296.739\n",
      "Ep:11, loss:0.00020, loss_test:0.01526, lr:1.00e-02, fs:0.74359 (r=0.667,p=0.841),  time:667.718, tt:8012.611\n",
      "Ep:12, loss:0.00019, loss_test:0.01549, lr:1.00e-02, fs:0.74839 (r=0.667,p=0.853),  time:671.612, tt:8730.957\n",
      "Ep:13, loss:0.00017, loss_test:0.01589, lr:1.00e-02, fs:0.74026 (r=0.655,p=0.851),  time:675.398, tt:9455.574\n",
      "Ep:14, loss:0.00016, loss_test:0.01617, lr:1.00e-02, fs:0.74026 (r=0.655,p=0.851),  time:679.115, tt:10186.725\n",
      "Ep:15, loss:0.00015, loss_test:0.01662, lr:1.00e-02, fs:0.74172 (r=0.644,p=0.875),  time:681.714, tt:10907.417\n",
      "Ep:16, loss:0.00014, loss_test:0.01713, lr:1.00e-02, fs:0.73826 (r=0.632,p=0.887),  time:683.482, tt:11619.195\n",
      "Ep:17, loss:0.00013, loss_test:0.01755, lr:1.00e-02, fs:0.75000 (r=0.621,p=0.947),  time:685.586, tt:12340.553\n",
      "Ep:18, loss:0.00012, loss_test:0.01810, lr:1.00e-02, fs:0.72857 (r=0.586,p=0.962),  time:687.061, tt:13054.156\n",
      "Ep:19, loss:0.00011, loss_test:0.01833, lr:9.90e-03, fs:0.70073 (r=0.552,p=0.960),  time:688.631, tt:13772.628\n",
      "Ep:20, loss:0.00010, loss_test:0.01879, lr:9.80e-03, fs:0.69118 (r=0.540,p=0.959),  time:690.225, tt:14494.729\n",
      "Ep:21, loss:0.00010, loss_test:0.01919, lr:9.70e-03, fs:0.69118 (r=0.540,p=0.959),  time:691.586, tt:15214.900\n",
      "Ep:22, loss:0.00009, loss_test:0.01979, lr:9.61e-03, fs:0.66165 (r=0.506,p=0.957),  time:693.369, tt:15947.483\n",
      "Ep:23, loss:0.00009, loss_test:0.02021, lr:9.51e-03, fs:0.65152 (r=0.494,p=0.956),  time:694.853, tt:16676.469\n",
      "Ep:24, loss:0.00008, loss_test:0.02042, lr:9.41e-03, fs:0.65152 (r=0.494,p=0.956),  time:695.839, tt:17395.972\n",
      "Ep:25, loss:0.00008, loss_test:0.02102, lr:9.32e-03, fs:0.65152 (r=0.494,p=0.956),  time:696.068, tt:18097.762\n",
      "Ep:26, loss:0.00007, loss_test:0.02135, lr:9.23e-03, fs:0.65649 (r=0.494,p=0.977),  time:697.292, tt:18826.881\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"3-3\"\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.02295, lr:6.00e-02, fs:0.63277 (r=0.644,p=0.622),  time:8.629, tt:8.629\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.02057, lr:6.00e-02, fs:0.64000 (r=0.920,p=0.491),  time:8.757, tt:17.513\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00000, loss_test:0.02196, lr:6.00e-02, fs:0.65637 (r=0.977,p=0.494),  time:8.825, tt:26.474\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00000, loss_test:0.02334, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.807, tt:35.226\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00000, loss_test:0.02411, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.757, tt:43.783\n",
      "Ep:5, loss:0.00000, loss_test:0.02431, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.714, tt:52.286\n",
      "Ep:6, loss:0.00000, loss_test:0.02407, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.682, tt:60.773\n",
      "Ep:7, loss:0.00000, loss_test:0.02353, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.695, tt:69.561\n",
      "Ep:8, loss:0.00000, loss_test:0.02280, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.709, tt:78.383\n",
      "Ep:9, loss:0.00000, loss_test:0.02199, lr:6.00e-02, fs:0.65637 (r=0.977,p=0.494),  time:8.715, tt:87.150\n",
      "Ep:10, loss:0.00000, loss_test:0.02117, lr:6.00e-02, fs:0.65637 (r=0.977,p=0.494),  time:8.702, tt:95.725\n",
      "Ep:11, loss:0.00000, loss_test:0.02044, lr:6.00e-02, fs:0.66135 (r=0.954,p=0.506),  time:8.687, tt:104.248\n",
      "Ep:12, loss:0.00000, loss_test:0.01994, lr:6.00e-02, fs:0.66667 (r=0.908,p=0.527),  time:8.667, tt:112.665\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00000, loss_test:0.01972, lr:6.00e-02, fs:0.66079 (r=0.862,p=0.536),  time:8.669, tt:121.367\n",
      "Ep:14, loss:0.00000, loss_test:0.01974, lr:6.00e-02, fs:0.67290 (r=0.828,p=0.567),  time:8.670, tt:130.056\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00000, loss_test:0.01984, lr:6.00e-02, fs:0.67961 (r=0.805,p=0.588),  time:8.662, tt:138.590\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00000, loss_test:0.01987, lr:6.00e-02, fs:0.69307 (r=0.805,p=0.609),  time:8.652, tt:147.084\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00000, loss_test:0.01976, lr:6.00e-02, fs:0.68657 (r=0.793,p=0.605),  time:8.642, tt:155.564\n",
      "Ep:18, loss:0.00000, loss_test:0.01944, lr:6.00e-02, fs:0.68293 (r=0.805,p=0.593),  time:8.639, tt:164.149\n",
      "Ep:19, loss:0.00000, loss_test:0.01906, lr:6.00e-02, fs:0.70476 (r=0.851,p=0.602),  time:8.632, tt:172.643\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00000, loss_test:0.01873, lr:6.00e-02, fs:0.70046 (r=0.874,p=0.585),  time:8.646, tt:181.565\n",
      "Ep:21, loss:0.00000, loss_test:0.01845, lr:6.00e-02, fs:0.69955 (r=0.897,p=0.574),  time:8.657, tt:190.458\n",
      "Ep:22, loss:0.00000, loss_test:0.01820, lr:6.00e-02, fs:0.70536 (r=0.908,p=0.577),  time:8.658, tt:199.134\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.01798, lr:6.00e-02, fs:0.70536 (r=0.908,p=0.577),  time:8.660, tt:207.840\n",
      "Ep:24, loss:0.00000, loss_test:0.01776, lr:6.00e-02, fs:0.71493 (r=0.908,p=0.590),  time:8.655, tt:216.377\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00000, loss_test:0.01754, lr:6.00e-02, fs:0.72477 (r=0.908,p=0.603),  time:8.665, tt:225.300\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00000, loss_test:0.01733, lr:6.00e-02, fs:0.72811 (r=0.908,p=0.608),  time:8.684, tt:234.474\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00000, loss_test:0.01715, lr:6.00e-02, fs:0.73148 (r=0.908,p=0.612),  time:8.686, tt:243.211\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00000, loss_test:0.01702, lr:6.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:8.690, tt:252.011\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.01690, lr:6.00e-02, fs:0.75728 (r=0.897,p=0.655),  time:8.680, tt:260.406\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.01678, lr:6.00e-02, fs:0.76471 (r=0.897,p=0.667),  time:8.667, tt:268.689\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.01664, lr:6.00e-02, fs:0.77000 (r=0.885,p=0.681),  time:8.672, tt:277.501\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.01647, lr:6.00e-02, fs:0.77157 (r=0.874,p=0.691),  time:8.673, tt:286.216\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.01628, lr:6.00e-02, fs:0.78392 (r=0.897,p=0.696),  time:8.674, tt:294.926\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.01608, lr:6.00e-02, fs:0.78000 (r=0.897,p=0.690),  time:8.674, tt:303.587\n",
      "Ep:35, loss:0.00000, loss_test:0.01590, lr:6.00e-02, fs:0.78000 (r=0.897,p=0.690),  time:8.666, tt:311.966\n",
      "Ep:36, loss:0.00000, loss_test:0.01573, lr:6.00e-02, fs:0.77228 (r=0.897,p=0.678),  time:8.662, tt:320.495\n",
      "Ep:37, loss:0.00000, loss_test:0.01557, lr:6.00e-02, fs:0.78218 (r=0.908,p=0.687),  time:8.664, tt:329.239\n",
      "Ep:38, loss:0.00000, loss_test:0.01542, lr:6.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:8.664, tt:337.892\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.01528, lr:6.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:8.668, tt:346.739\n",
      "Ep:40, loss:0.00000, loss_test:0.01514, lr:6.00e-02, fs:0.79602 (r=0.920,p=0.702),  time:8.672, tt:355.533\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00000, loss_test:0.01502, lr:6.00e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.667, tt:363.993\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00000, loss_test:0.01492, lr:6.00e-02, fs:0.80808 (r=0.920,p=0.721),  time:8.671, tt:372.855\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.01484, lr:6.00e-02, fs:0.80612 (r=0.908,p=0.725),  time:8.673, tt:381.592\n",
      "Ep:44, loss:0.00000, loss_test:0.01476, lr:6.00e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.695, tt:391.271\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.01468, lr:6.00e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.700, tt:400.207\n",
      "Ep:46, loss:0.00000, loss_test:0.01459, lr:6.00e-02, fs:0.80412 (r=0.897,p=0.729),  time:8.695, tt:408.654\n",
      "Ep:47, loss:0.00000, loss_test:0.01451, lr:6.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:8.686, tt:416.916\n",
      "Ep:48, loss:0.00000, loss_test:0.01443, lr:6.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:8.680, tt:425.318\n",
      "Ep:49, loss:0.00000, loss_test:0.01435, lr:6.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:8.678, tt:433.911\n",
      "Ep:50, loss:0.00000, loss_test:0.01427, lr:6.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:8.673, tt:442.317\n",
      "Ep:51, loss:0.00000, loss_test:0.01421, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:8.669, tt:450.779\n",
      "Ep:52, loss:0.00000, loss_test:0.01414, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:8.667, tt:459.345\n",
      "Ep:53, loss:0.00000, loss_test:0.01410, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:8.668, tt:468.066\n",
      "Ep:54, loss:0.00000, loss_test:0.01406, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:8.667, tt:476.702\n",
      "Ep:55, loss:0.00000, loss_test:0.01404, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:8.674, tt:485.720\n",
      "Ep:56, loss:0.00000, loss_test:0.01402, lr:5.94e-02, fs:0.80628 (r=0.885,p=0.740),  time:8.673, tt:494.358\n",
      "Ep:57, loss:0.00000, loss_test:0.01399, lr:5.88e-02, fs:0.81053 (r=0.885,p=0.748),  time:8.673, tt:503.024\n",
      "Ep:58, loss:0.00000, loss_test:0.01395, lr:5.82e-02, fs:0.81053 (r=0.885,p=0.748),  time:8.670, tt:511.506\n",
      "Ep:59, loss:0.00000, loss_test:0.01390, lr:5.76e-02, fs:0.81481 (r=0.885,p=0.755),  time:8.666, tt:519.938\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00000, loss_test:0.01384, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.667, tt:528.685\n",
      "Ep:61, loss:0.00000, loss_test:0.01378, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.668, tt:537.419\n",
      "Ep:62, loss:0.00000, loss_test:0.01372, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.671, tt:546.293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00000, loss_test:0.01367, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.674, tt:555.145\n",
      "Ep:64, loss:0.00000, loss_test:0.01362, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.676, tt:563.915\n",
      "Ep:65, loss:0.00000, loss_test:0.01358, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.677, tt:572.709\n",
      "Ep:66, loss:0.00000, loss_test:0.01354, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.680, tt:581.538\n",
      "Ep:67, loss:0.00000, loss_test:0.01351, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.681, tt:590.301\n",
      "Ep:68, loss:0.00000, loss_test:0.01348, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.685, tt:599.255\n",
      "Ep:69, loss:0.00000, loss_test:0.01344, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.686, tt:608.044\n",
      "Ep:70, loss:0.00000, loss_test:0.01340, lr:5.76e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.683, tt:616.498\n",
      "Ep:71, loss:0.00000, loss_test:0.01334, lr:5.71e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.681, tt:625.014\n",
      "Ep:72, loss:0.00000, loss_test:0.01330, lr:5.65e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.682, tt:633.808\n",
      "Ep:73, loss:0.00000, loss_test:0.01326, lr:5.59e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.683, tt:642.522\n",
      "Ep:74, loss:0.00000, loss_test:0.01323, lr:5.54e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.684, tt:651.324\n",
      "Ep:75, loss:0.00000, loss_test:0.01321, lr:5.48e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.687, tt:660.223\n",
      "Ep:76, loss:0.00000, loss_test:0.01319, lr:5.43e-02, fs:0.80214 (r=0.862,p=0.750),  time:8.692, tt:669.279\n",
      "Ep:77, loss:0.00000, loss_test:0.01317, lr:5.37e-02, fs:0.79570 (r=0.851,p=0.747),  time:8.690, tt:677.851\n",
      "Ep:78, loss:0.00000, loss_test:0.01315, lr:5.32e-02, fs:0.79570 (r=0.851,p=0.747),  time:8.694, tt:686.844\n",
      "Ep:79, loss:0.00000, loss_test:0.01314, lr:5.27e-02, fs:0.79570 (r=0.851,p=0.747),  time:8.695, tt:695.596\n",
      "Ep:80, loss:0.00000, loss_test:0.01313, lr:5.21e-02, fs:0.80435 (r=0.851,p=0.763),  time:8.697, tt:704.457\n",
      "Ep:81, loss:0.00000, loss_test:0.01311, lr:5.16e-02, fs:0.80435 (r=0.851,p=0.763),  time:8.698, tt:713.246\n",
      "Ep:82, loss:0.00000, loss_test:0.01310, lr:5.11e-02, fs:0.80435 (r=0.851,p=0.763),  time:8.699, tt:722.040\n",
      "Ep:83, loss:0.00000, loss_test:0.01309, lr:5.06e-02, fs:0.80874 (r=0.851,p=0.771),  time:8.700, tt:730.809\n",
      "Ep:84, loss:0.00000, loss_test:0.01308, lr:5.01e-02, fs:0.80874 (r=0.851,p=0.771),  time:8.698, tt:739.356\n",
      "Ep:85, loss:0.00000, loss_test:0.01307, lr:4.96e-02, fs:0.80874 (r=0.851,p=0.771),  time:8.697, tt:747.985\n",
      "Ep:86, loss:0.00000, loss_test:0.01306, lr:4.91e-02, fs:0.80220 (r=0.839,p=0.768),  time:8.697, tt:756.681\n",
      "Ep:87, loss:0.00000, loss_test:0.01305, lr:4.86e-02, fs:0.80663 (r=0.839,p=0.777),  time:8.697, tt:765.380\n",
      "Ep:88, loss:0.00000, loss_test:0.01305, lr:4.81e-02, fs:0.80663 (r=0.839,p=0.777),  time:8.701, tt:774.413\n",
      "Ep:89, loss:0.00000, loss_test:0.01305, lr:4.76e-02, fs:0.80663 (r=0.839,p=0.777),  time:8.701, tt:783.085\n",
      "Ep:90, loss:0.00000, loss_test:0.01306, lr:4.71e-02, fs:0.80663 (r=0.839,p=0.777),  time:8.702, tt:791.880\n",
      "Ep:91, loss:0.00000, loss_test:0.01306, lr:4.67e-02, fs:0.80663 (r=0.839,p=0.777),  time:8.702, tt:800.609\n",
      "Ep:92, loss:0.00000, loss_test:0.01305, lr:4.62e-02, fs:0.80663 (r=0.839,p=0.777),  time:8.735, tt:812.376\n",
      "Ep:93, loss:0.00000, loss_test:0.01304, lr:4.57e-02, fs:0.81111 (r=0.839,p=0.785),  time:8.736, tt:821.146\n",
      "Ep:94, loss:0.00000, loss_test:0.01303, lr:4.53e-02, fs:0.81111 (r=0.839,p=0.785),  time:8.735, tt:829.860\n",
      "Ep:95, loss:0.00000, loss_test:0.01301, lr:4.48e-02, fs:0.81564 (r=0.839,p=0.793),  time:8.736, tt:838.643\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00000, loss_test:0.01300, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.734, tt:847.167\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00000, loss_test:0.01300, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.732, tt:855.691\n",
      "Ep:98, loss:0.00000, loss_test:0.01300, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.731, tt:864.361\n",
      "Ep:99, loss:0.00000, loss_test:0.01300, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.732, tt:873.184\n",
      "Ep:100, loss:0.00000, loss_test:0.01300, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.732, tt:881.940\n",
      "Ep:101, loss:0.00000, loss_test:0.01301, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.731, tt:890.590\n",
      "Ep:102, loss:0.00000, loss_test:0.01302, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.730, tt:899.211\n",
      "Ep:103, loss:0.00000, loss_test:0.01303, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.728, tt:907.745\n",
      "Ep:104, loss:0.00000, loss_test:0.01303, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.727, tt:916.306\n",
      "Ep:105, loss:0.00000, loss_test:0.01303, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.724, tt:924.781\n",
      "Ep:106, loss:0.00000, loss_test:0.01303, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.725, tt:933.556\n",
      "Ep:107, loss:0.00000, loss_test:0.01304, lr:4.48e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.727, tt:942.487\n",
      "Ep:108, loss:0.00000, loss_test:0.01304, lr:4.44e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.727, tt:951.267\n",
      "Ep:109, loss:0.00000, loss_test:0.01305, lr:4.39e-02, fs:0.82022 (r=0.839,p=0.802),  time:8.726, tt:959.868\n",
      "Ep:110, loss:0.00000, loss_test:0.01306, lr:4.35e-02, fs:0.82486 (r=0.839,p=0.811),  time:8.727, tt:968.645\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.01306, lr:4.35e-02, fs:0.82486 (r=0.839,p=0.811),  time:8.728, tt:977.518\n",
      "Ep:112, loss:0.00000, loss_test:0.01307, lr:4.35e-02, fs:0.82486 (r=0.839,p=0.811),  time:8.729, tt:986.367\n",
      "Ep:113, loss:0.00000, loss_test:0.01307, lr:4.35e-02, fs:0.82486 (r=0.839,p=0.811),  time:8.729, tt:995.073\n",
      "Ep:114, loss:0.00000, loss_test:0.01308, lr:4.35e-02, fs:0.82486 (r=0.839,p=0.811),  time:8.732, tt:1004.142\n",
      "Ep:115, loss:0.00000, loss_test:0.01308, lr:4.35e-02, fs:0.82486 (r=0.839,p=0.811),  time:8.734, tt:1013.156\n",
      "Ep:116, loss:0.00000, loss_test:0.01309, lr:4.35e-02, fs:0.81818 (r=0.828,p=0.809),  time:8.735, tt:1021.947\n",
      "Ep:117, loss:0.00000, loss_test:0.01310, lr:4.35e-02, fs:0.81818 (r=0.828,p=0.809),  time:8.733, tt:1030.491\n",
      "Ep:118, loss:0.00000, loss_test:0.01312, lr:4.35e-02, fs:0.81818 (r=0.828,p=0.809),  time:8.733, tt:1039.182\n",
      "Ep:119, loss:0.00000, loss_test:0.01313, lr:4.35e-02, fs:0.82286 (r=0.828,p=0.818),  time:8.733, tt:1047.928\n",
      "Ep:120, loss:0.00000, loss_test:0.01315, lr:4.35e-02, fs:0.82286 (r=0.828,p=0.818),  time:8.738, tt:1057.248\n",
      "Ep:121, loss:0.00000, loss_test:0.01316, lr:4.35e-02, fs:0.82286 (r=0.828,p=0.818),  time:8.749, tt:1067.362\n",
      "Ep:122, loss:0.00000, loss_test:0.01317, lr:4.31e-02, fs:0.82286 (r=0.828,p=0.818),  time:8.801, tt:1082.493\n",
      "Ep:123, loss:0.00000, loss_test:0.01319, lr:4.26e-02, fs:0.82286 (r=0.828,p=0.818),  time:8.918, tt:1105.853\n",
      "Ep:124, loss:0.00000, loss_test:0.01320, lr:4.22e-02, fs:0.82286 (r=0.828,p=0.818),  time:9.070, tt:1133.759\n",
      "Ep:125, loss:0.00000, loss_test:0.01322, lr:4.18e-02, fs:0.82286 (r=0.828,p=0.818),  time:9.223, tt:1162.078\n",
      "Ep:126, loss:0.00000, loss_test:0.01324, lr:4.14e-02, fs:0.82286 (r=0.828,p=0.818),  time:9.366, tt:1189.425\n",
      "Ep:127, loss:0.00000, loss_test:0.01325, lr:4.10e-02, fs:0.82286 (r=0.828,p=0.818),  time:9.511, tt:1217.421\n",
      "Ep:128, loss:0.00000, loss_test:0.01326, lr:4.05e-02, fs:0.82759 (r=0.828,p=0.828),  time:9.658, tt:1245.919\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00000, loss_test:0.01327, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:9.794, tt:1273.261\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00000, loss_test:0.01328, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:9.933, tt:1301.272\n",
      "Ep:131, loss:0.00000, loss_test:0.01329, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.077, tt:1330.196\n",
      "Ep:132, loss:0.00000, loss_test:0.01330, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.210, tt:1357.975\n",
      "Ep:133, loss:0.00000, loss_test:0.01331, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.359, tt:1388.042\n",
      "Ep:134, loss:0.00000, loss_test:0.01333, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.476, tt:1414.265\n",
      "Ep:135, loss:0.00000, loss_test:0.01334, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.588, tt:1439.931\n",
      "Ep:136, loss:0.00000, loss_test:0.01336, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.699, tt:1465.702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.01338, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.808, tt:1491.462\n",
      "Ep:138, loss:0.00000, loss_test:0.01340, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:10.906, tt:1515.915\n",
      "Ep:139, loss:0.00000, loss_test:0.01341, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.026, tt:1543.627\n",
      "Ep:140, loss:0.00000, loss_test:0.01343, lr:4.05e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.133, tt:1569.706\n",
      "Ep:141, loss:0.00000, loss_test:0.01345, lr:4.01e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.230, tt:1594.613\n",
      "Ep:142, loss:0.00000, loss_test:0.01348, lr:3.97e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.333, tt:1620.657\n",
      "Ep:143, loss:0.00000, loss_test:0.01350, lr:3.93e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.434, tt:1646.470\n",
      "Ep:144, loss:0.00000, loss_test:0.01352, lr:3.89e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.533, tt:1672.244\n",
      "Ep:145, loss:0.00000, loss_test:0.01353, lr:3.86e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.617, tt:1696.131\n",
      "Ep:146, loss:0.00000, loss_test:0.01354, lr:3.82e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.717, tt:1722.350\n",
      "Ep:147, loss:0.00000, loss_test:0.01356, lr:3.78e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.806, tt:1747.221\n",
      "Ep:148, loss:0.00000, loss_test:0.01358, lr:3.74e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.887, tt:1771.170\n",
      "Ep:149, loss:0.00000, loss_test:0.01360, lr:3.70e-02, fs:0.83237 (r=0.828,p=0.837),  time:11.980, tt:1797.005\n",
      "Ep:150, loss:0.00000, loss_test:0.01361, lr:3.67e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.067, tt:1822.133\n",
      "Ep:151, loss:0.00000, loss_test:0.01363, lr:3.63e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.152, tt:1847.130\n",
      "Ep:152, loss:0.00000, loss_test:0.01364, lr:3.59e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.257, tt:1875.253\n",
      "Ep:153, loss:0.00000, loss_test:0.01365, lr:3.56e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.331, tt:1899.001\n",
      "Ep:154, loss:0.00000, loss_test:0.01367, lr:3.52e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.416, tt:1924.499\n",
      "Ep:155, loss:0.00000, loss_test:0.01369, lr:3.49e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.485, tt:1947.589\n",
      "Ep:156, loss:0.00000, loss_test:0.01371, lr:3.45e-02, fs:0.83237 (r=0.828,p=0.837),  time:12.564, tt:1972.489\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=40000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.02956, lr:2.00e-02, fs:0.58209 (r=0.448,p=0.830),  time:8.987, tt:8.987\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.02305, lr:2.00e-02, fs:0.59429 (r=0.598,p=0.591),  time:9.030, tt:18.060\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00000, loss_test:0.02057, lr:2.00e-02, fs:0.63063 (r=0.805,p=0.519),  time:9.063, tt:27.190\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00000, loss_test:0.02053, lr:2.00e-02, fs:0.65354 (r=0.954,p=0.497),  time:9.048, tt:36.193\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00000, loss_test:0.02126, lr:2.00e-02, fs:0.65891 (r=0.977,p=0.497),  time:9.074, tt:45.372\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00000, loss_test:0.02203, lr:2.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:9.037, tt:54.224\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00000, loss_test:0.02263, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.018, tt:63.127\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00000, loss_test:0.02304, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.020, tt:72.157\n",
      "Ep:8, loss:0.00000, loss_test:0.02325, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.021, tt:81.191\n",
      "Ep:9, loss:0.00000, loss_test:0.02330, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.000, tt:90.003\n",
      "Ep:10, loss:0.00000, loss_test:0.02319, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.984, tt:98.821\n",
      "Ep:11, loss:0.00000, loss_test:0.02300, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.958, tt:107.498\n",
      "Ep:12, loss:0.00000, loss_test:0.02274, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.964, tt:116.534\n",
      "Ep:13, loss:0.00000, loss_test:0.02243, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.923, tt:124.925\n",
      "Ep:14, loss:0.00000, loss_test:0.02206, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.912, tt:133.678\n",
      "Ep:15, loss:0.00000, loss_test:0.02165, lr:2.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.899, tt:142.389\n",
      "Ep:16, loss:0.00000, loss_test:0.02120, lr:2.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:8.897, tt:151.244\n",
      "Ep:17, loss:0.00000, loss_test:0.02074, lr:2.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:8.898, tt:160.157\n",
      "Ep:18, loss:0.00000, loss_test:0.02029, lr:1.98e-02, fs:0.65637 (r=0.977,p=0.494),  time:8.895, tt:169.011\n",
      "Ep:19, loss:0.00000, loss_test:0.01986, lr:1.96e-02, fs:0.65882 (r=0.966,p=0.500),  time:8.885, tt:177.701\n",
      "Ep:20, loss:0.00000, loss_test:0.01947, lr:1.94e-02, fs:0.66403 (r=0.966,p=0.506),  time:8.878, tt:186.437\n",
      "Ep:21, loss:0.00000, loss_test:0.01912, lr:1.92e-02, fs:0.66667 (r=0.943,p=0.516),  time:8.882, tt:195.401\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00000, loss_test:0.01882, lr:1.92e-02, fs:0.67220 (r=0.931,p=0.526),  time:8.864, tt:203.876\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.01857, lr:1.92e-02, fs:0.67234 (r=0.908,p=0.534),  time:8.864, tt:212.742\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00000, loss_test:0.01838, lr:1.92e-02, fs:0.67841 (r=0.885,p=0.550),  time:8.861, tt:221.515\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00000, loss_test:0.01824, lr:1.92e-02, fs:0.69091 (r=0.874,p=0.571),  time:8.863, tt:230.427\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00000, loss_test:0.01813, lr:1.92e-02, fs:0.69767 (r=0.862,p=0.586),  time:8.872, tt:239.557\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00000, loss_test:0.01806, lr:1.92e-02, fs:0.70755 (r=0.862,p=0.600),  time:8.874, tt:248.486\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00000, loss_test:0.01800, lr:1.92e-02, fs:0.71429 (r=0.862,p=0.610),  time:8.858, tt:256.894\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.01793, lr:1.92e-02, fs:0.71770 (r=0.862,p=0.615),  time:8.860, tt:265.814\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.01786, lr:1.92e-02, fs:0.72115 (r=0.862,p=0.620),  time:8.855, tt:274.504\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.01777, lr:1.92e-02, fs:0.71770 (r=0.862,p=0.615),  time:8.851, tt:283.217\n",
      "Ep:32, loss:0.00000, loss_test:0.01767, lr:1.92e-02, fs:0.71770 (r=0.862,p=0.615),  time:8.849, tt:292.028\n",
      "Ep:33, loss:0.00000, loss_test:0.01758, lr:1.92e-02, fs:0.72038 (r=0.874,p=0.613),  time:8.845, tt:300.738\n",
      "Ep:34, loss:0.00000, loss_test:0.01749, lr:1.92e-02, fs:0.71963 (r=0.885,p=0.606),  time:8.842, tt:309.485\n",
      "Ep:35, loss:0.00000, loss_test:0.01740, lr:1.92e-02, fs:0.71628 (r=0.885,p=0.602),  time:8.843, tt:318.364\n",
      "Ep:36, loss:0.00000, loss_test:0.01730, lr:1.92e-02, fs:0.72811 (r=0.908,p=0.608),  time:8.833, tt:326.816\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.01722, lr:1.92e-02, fs:0.72811 (r=0.908,p=0.608),  time:8.828, tt:335.468\n",
      "Ep:38, loss:0.00000, loss_test:0.01714, lr:1.92e-02, fs:0.72398 (r=0.920,p=0.597),  time:8.822, tt:344.059\n",
      "Ep:39, loss:0.00000, loss_test:0.01708, lr:1.92e-02, fs:0.72973 (r=0.931,p=0.600),  time:8.822, tt:352.885\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.01701, lr:1.92e-02, fs:0.72646 (r=0.931,p=0.596),  time:8.822, tt:361.690\n",
      "Ep:41, loss:0.00000, loss_test:0.01695, lr:1.92e-02, fs:0.72646 (r=0.931,p=0.596),  time:8.818, tt:370.345\n",
      "Ep:42, loss:0.00000, loss_test:0.01688, lr:1.92e-02, fs:0.72973 (r=0.931,p=0.600),  time:8.815, tt:379.056\n",
      "Ep:43, loss:0.00000, loss_test:0.01682, lr:1.92e-02, fs:0.73636 (r=0.931,p=0.609),  time:8.816, tt:387.898\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00000, loss_test:0.01676, lr:1.92e-02, fs:0.73973 (r=0.931,p=0.614),  time:8.814, tt:396.644\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.01671, lr:1.92e-02, fs:0.75000 (r=0.931,p=0.628),  time:8.816, tt:405.549\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00000, loss_test:0.01667, lr:1.92e-02, fs:0.75000 (r=0.931,p=0.628),  time:8.817, tt:414.392\n",
      "Ep:47, loss:0.00000, loss_test:0.01663, lr:1.92e-02, fs:0.75349 (r=0.931,p=0.633),  time:8.817, tt:423.223\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00000, loss_test:0.01659, lr:1.92e-02, fs:0.75349 (r=0.931,p=0.633),  time:8.814, tt:431.889\n",
      "Ep:49, loss:0.00000, loss_test:0.01654, lr:1.92e-02, fs:0.75829 (r=0.920,p=0.645),  time:8.808, tt:440.422\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00000, loss_test:0.01648, lr:1.92e-02, fs:0.76923 (r=0.920,p=0.661),  time:8.801, tt:448.830\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00000, loss_test:0.01643, lr:1.92e-02, fs:0.76329 (r=0.908,p=0.658),  time:8.799, tt:457.570\n",
      "Ep:52, loss:0.00000, loss_test:0.01637, lr:1.92e-02, fs:0.75728 (r=0.897,p=0.655),  time:8.802, tt:466.486\n",
      "Ep:53, loss:0.00000, loss_test:0.01630, lr:1.92e-02, fs:0.75728 (r=0.897,p=0.655),  time:8.804, tt:475.429\n",
      "Ep:54, loss:0.00000, loss_test:0.01623, lr:1.92e-02, fs:0.75728 (r=0.897,p=0.655),  time:8.799, tt:483.967\n",
      "Ep:55, loss:0.00000, loss_test:0.01616, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.793, tt:492.431\n",
      "Ep:56, loss:0.00000, loss_test:0.01608, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.787, tt:500.886\n",
      "Ep:57, loss:0.00000, loss_test:0.01601, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.786, tt:509.595\n",
      "Ep:58, loss:0.00000, loss_test:0.01595, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.787, tt:518.407\n",
      "Ep:59, loss:0.00000, loss_test:0.01588, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.783, tt:526.988\n",
      "Ep:60, loss:0.00000, loss_test:0.01582, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.781, tt:535.650\n",
      "Ep:61, loss:0.00000, loss_test:0.01576, lr:1.92e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.775, tt:544.047\n",
      "Ep:62, loss:0.00000, loss_test:0.01570, lr:1.90e-02, fs:0.75962 (r=0.908,p=0.653),  time:8.777, tt:552.948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00000, loss_test:0.01565, lr:1.88e-02, fs:0.76555 (r=0.920,p=0.656),  time:8.777, tt:561.723\n",
      "Ep:64, loss:0.00000, loss_test:0.01560, lr:1.86e-02, fs:0.77295 (r=0.920,p=0.667),  time:8.778, tt:570.589\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00000, loss_test:0.01557, lr:1.86e-02, fs:0.77295 (r=0.920,p=0.667),  time:8.777, tt:579.278\n",
      "Ep:66, loss:0.00000, loss_test:0.01553, lr:1.86e-02, fs:0.77670 (r=0.920,p=0.672),  time:8.776, tt:587.970\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00000, loss_test:0.01550, lr:1.86e-02, fs:0.78818 (r=0.920,p=0.690),  time:8.777, tt:596.816\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00000, loss_test:0.01547, lr:1.86e-02, fs:0.79208 (r=0.920,p=0.696),  time:8.774, tt:605.372\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00000, loss_test:0.01544, lr:1.86e-02, fs:0.79208 (r=0.920,p=0.696),  time:8.772, tt:614.037\n",
      "Ep:70, loss:0.00000, loss_test:0.01541, lr:1.86e-02, fs:0.79602 (r=0.920,p=0.702),  time:8.773, tt:622.904\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00000, loss_test:0.01538, lr:1.86e-02, fs:0.79602 (r=0.920,p=0.702),  time:8.772, tt:631.564\n",
      "Ep:72, loss:0.00000, loss_test:0.01534, lr:1.86e-02, fs:0.80000 (r=0.920,p=0.708),  time:8.774, tt:640.479\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00000, loss_test:0.01531, lr:1.86e-02, fs:0.80000 (r=0.920,p=0.708),  time:8.806, tt:651.652\n",
      "Ep:74, loss:0.00000, loss_test:0.01527, lr:1.86e-02, fs:0.80000 (r=0.920,p=0.708),  time:8.806, tt:660.449\n",
      "Ep:75, loss:0.00000, loss_test:0.01524, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.804, tt:669.083\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00000, loss_test:0.01520, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.803, tt:677.803\n",
      "Ep:77, loss:0.00000, loss_test:0.01516, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.806, tt:686.898\n",
      "Ep:78, loss:0.00000, loss_test:0.01513, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.810, tt:695.958\n",
      "Ep:79, loss:0.00000, loss_test:0.01509, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.808, tt:704.654\n",
      "Ep:80, loss:0.00000, loss_test:0.01506, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.805, tt:713.177\n",
      "Ep:81, loss:0.00000, loss_test:0.01502, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.801, tt:721.680\n",
      "Ep:82, loss:0.00000, loss_test:0.01499, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.798, tt:730.194\n",
      "Ep:83, loss:0.00000, loss_test:0.01495, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.795, tt:738.779\n",
      "Ep:84, loss:0.00000, loss_test:0.01492, lr:1.86e-02, fs:0.80402 (r=0.920,p=0.714),  time:8.792, tt:747.321\n",
      "Ep:85, loss:0.00000, loss_test:0.01488, lr:1.86e-02, fs:0.80808 (r=0.920,p=0.721),  time:8.789, tt:755.833\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00000, loss_test:0.01485, lr:1.86e-02, fs:0.80808 (r=0.920,p=0.721),  time:8.789, tt:764.613\n",
      "Ep:87, loss:0.00000, loss_test:0.01481, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.787, tt:773.237\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00000, loss_test:0.01478, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.784, tt:781.820\n",
      "Ep:89, loss:0.00000, loss_test:0.01474, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.781, tt:790.328\n",
      "Ep:90, loss:0.00000, loss_test:0.01471, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.782, tt:799.121\n",
      "Ep:91, loss:0.00000, loss_test:0.01468, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.780, tt:807.714\n",
      "Ep:92, loss:0.00000, loss_test:0.01464, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.776, tt:816.211\n",
      "Ep:93, loss:0.00000, loss_test:0.01461, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.778, tt:825.135\n",
      "Ep:94, loss:0.00000, loss_test:0.01459, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.777, tt:833.837\n",
      "Ep:95, loss:0.00000, loss_test:0.01456, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.776, tt:842.537\n",
      "Ep:96, loss:0.00000, loss_test:0.01453, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.776, tt:851.299\n",
      "Ep:97, loss:0.00000, loss_test:0.01451, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.774, tt:859.833\n",
      "Ep:98, loss:0.00000, loss_test:0.01448, lr:1.86e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.772, tt:868.383\n",
      "Ep:99, loss:0.00000, loss_test:0.01445, lr:1.85e-02, fs:0.81218 (r=0.920,p=0.727),  time:8.770, tt:877.007\n",
      "Ep:100, loss:0.00000, loss_test:0.01443, lr:1.83e-02, fs:0.81633 (r=0.920,p=0.734),  time:8.773, tt:886.114\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00000, loss_test:0.01440, lr:1.83e-02, fs:0.81633 (r=0.920,p=0.734),  time:8.774, tt:894.965\n",
      "Ep:102, loss:0.00000, loss_test:0.01437, lr:1.83e-02, fs:0.81633 (r=0.920,p=0.734),  time:8.774, tt:903.725\n",
      "Ep:103, loss:0.00000, loss_test:0.01435, lr:1.83e-02, fs:0.81633 (r=0.920,p=0.734),  time:8.773, tt:912.421\n",
      "Ep:104, loss:0.00000, loss_test:0.01432, lr:1.83e-02, fs:0.81026 (r=0.908,p=0.731),  time:8.775, tt:921.394\n",
      "Ep:105, loss:0.00000, loss_test:0.01429, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.778, tt:930.437\n",
      "Ep:106, loss:0.00000, loss_test:0.01427, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.777, tt:939.188\n",
      "Ep:107, loss:0.00000, loss_test:0.01425, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.779, tt:948.121\n",
      "Ep:108, loss:0.00000, loss_test:0.01422, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.779, tt:956.915\n",
      "Ep:109, loss:0.00000, loss_test:0.01420, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.777, tt:965.522\n",
      "Ep:110, loss:0.00000, loss_test:0.01418, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.775, tt:973.986\n",
      "Ep:111, loss:0.00000, loss_test:0.01415, lr:1.83e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.774, tt:982.709\n",
      "Ep:112, loss:0.00000, loss_test:0.01413, lr:1.81e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.775, tt:991.537\n",
      "Ep:113, loss:0.00000, loss_test:0.01411, lr:1.79e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.773, tt:1000.170\n",
      "Ep:114, loss:0.00000, loss_test:0.01409, lr:1.77e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.774, tt:1008.955\n",
      "Ep:115, loss:0.00000, loss_test:0.01407, lr:1.76e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.771, tt:1017.434\n",
      "Ep:116, loss:0.00000, loss_test:0.01405, lr:1.74e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.770, tt:1026.140\n",
      "Ep:117, loss:0.00000, loss_test:0.01404, lr:1.72e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.770, tt:1034.831\n",
      "Ep:118, loss:0.00000, loss_test:0.01403, lr:1.70e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.768, tt:1043.381\n",
      "Ep:119, loss:0.00000, loss_test:0.01401, lr:1.69e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.768, tt:1052.102\n",
      "Ep:120, loss:0.00000, loss_test:0.01400, lr:1.67e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.766, tt:1060.723\n",
      "Ep:121, loss:0.00000, loss_test:0.01399, lr:1.65e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.767, tt:1069.599\n",
      "Ep:122, loss:0.00000, loss_test:0.01398, lr:1.64e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.765, tt:1078.066\n",
      "Ep:123, loss:0.00000, loss_test:0.01396, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.764, tt:1086.722\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00000, loss_test:0.01395, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.766, tt:1095.706\n",
      "Ep:125, loss:0.00000, loss_test:0.01394, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.765, tt:1104.395\n",
      "Ep:126, loss:0.00000, loss_test:0.01393, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.766, tt:1113.274\n",
      "Ep:127, loss:0.00000, loss_test:0.01391, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.765, tt:1121.929\n",
      "Ep:128, loss:0.00000, loss_test:0.01390, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.764, tt:1130.607\n",
      "Ep:129, loss:0.00000, loss_test:0.01389, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.766, tt:1139.523\n",
      "Ep:130, loss:0.00000, loss_test:0.01388, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.765, tt:1148.191\n",
      "Ep:131, loss:0.00000, loss_test:0.01386, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.767, tt:1157.260\n",
      "Ep:132, loss:0.00000, loss_test:0.01385, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.766, tt:1165.911\n",
      "Ep:133, loss:0.00000, loss_test:0.01384, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.766, tt:1174.594\n",
      "Ep:134, loss:0.00000, loss_test:0.01383, lr:1.62e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.764, tt:1183.176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.01382, lr:1.60e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.764, tt:1191.839\n",
      "Ep:136, loss:0.00000, loss_test:0.01381, lr:1.59e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.762, tt:1200.451\n",
      "Ep:137, loss:0.00000, loss_test:0.01379, lr:1.57e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.761, tt:1209.028\n",
      "Ep:138, loss:0.00000, loss_test:0.01378, lr:1.56e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.773, tt:1219.394\n",
      "Ep:139, loss:0.00000, loss_test:0.01377, lr:1.54e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.771, tt:1227.985\n",
      "Ep:140, loss:0.00000, loss_test:0.01376, lr:1.52e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.772, tt:1236.838\n",
      "Ep:141, loss:0.00000, loss_test:0.01375, lr:1.51e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.770, tt:1245.386\n",
      "Ep:142, loss:0.00000, loss_test:0.01374, lr:1.49e-02, fs:0.81443 (r=0.908,p=0.738),  time:8.772, tt:1254.333\n",
      "Ep:143, loss:0.00000, loss_test:0.01372, lr:1.48e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.773, tt:1263.325\n",
      "Ep:144, loss:0.00000, loss_test:0.01371, lr:1.46e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.771, tt:1271.820\n",
      "Ep:145, loss:0.00000, loss_test:0.01370, lr:1.45e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.772, tt:1280.758\n",
      "Ep:146, loss:0.00000, loss_test:0.01369, lr:1.44e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.774, tt:1289.832\n",
      "Ep:147, loss:0.00000, loss_test:0.01368, lr:1.42e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.774, tt:1298.603\n",
      "Ep:148, loss:0.00000, loss_test:0.01367, lr:1.41e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.776, tt:1307.552\n",
      "Ep:149, loss:0.00000, loss_test:0.01365, lr:1.39e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.775, tt:1316.192\n",
      "Ep:150, loss:0.00000, loss_test:0.01364, lr:1.38e-02, fs:0.82051 (r=0.920,p=0.741),  time:8.774, tt:1324.823\n",
      "Ep:151, loss:0.00000, loss_test:0.01363, lr:1.37e-02, fs:0.82474 (r=0.920,p=0.748),  time:8.774, tt:1333.589\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00000, loss_test:0.01362, lr:1.37e-02, fs:0.82474 (r=0.920,p=0.748),  time:8.771, tt:1341.974\n",
      "Ep:153, loss:0.00000, loss_test:0.01361, lr:1.37e-02, fs:0.82474 (r=0.920,p=0.748),  time:8.771, tt:1350.665\n",
      "Ep:154, loss:0.00000, loss_test:0.01360, lr:1.37e-02, fs:0.82474 (r=0.920,p=0.748),  time:8.770, tt:1359.422\n",
      "Ep:155, loss:0.00000, loss_test:0.01359, lr:1.37e-02, fs:0.82902 (r=0.920,p=0.755),  time:8.770, tt:1368.059\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00000, loss_test:0.01358, lr:1.37e-02, fs:0.82902 (r=0.920,p=0.755),  time:8.768, tt:1376.599\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=40000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=2e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 20000: \n",
      "Ep:0, loss:0.00000, loss_test:0.03031, lr:1.00e-02, fs:0.51515 (r=0.391,p=0.756),  time:14.552, tt:14.552\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.02202, lr:1.00e-02, fs:0.62009 (r=0.816,p=0.500),  time:14.835, tt:29.671\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00000, loss_test:0.02192, lr:1.00e-02, fs:0.65098 (r=0.954,p=0.494),  time:14.794, tt:44.383\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00000, loss_test:0.02308, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.218, tt:56.873\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00000, loss_test:0.02394, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.860, tt:69.301\n",
      "Ep:5, loss:0.00000, loss_test:0.02432, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.610, tt:81.662\n",
      "Ep:6, loss:0.00000, loss_test:0.02431, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.016, tt:98.115\n",
      "Ep:7, loss:0.00000, loss_test:0.02405, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.799, tt:110.389\n",
      "Ep:8, loss:0.00000, loss_test:0.02359, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.655, tt:122.892\n",
      "Ep:9, loss:0.00000, loss_test:0.02302, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.511, tt:135.114\n",
      "Ep:10, loss:0.00000, loss_test:0.02240, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.377, tt:147.145\n",
      "Ep:11, loss:0.00000, loss_test:0.02175, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:13.296, tt:159.547\n",
      "Ep:12, loss:0.00000, loss_test:0.02112, lr:1.00e-02, fs:0.65637 (r=0.977,p=0.494),  time:13.245, tt:172.190\n",
      "Ep:13, loss:0.00000, loss_test:0.02055, lr:1.00e-02, fs:0.65625 (r=0.966,p=0.497),  time:13.183, tt:184.559\n",
      "Ep:14, loss:0.00000, loss_test:0.02006, lr:1.00e-02, fs:0.65873 (r=0.954,p=0.503),  time:13.130, tt:196.954\n",
      "Ep:15, loss:0.00000, loss_test:0.01971, lr:9.90e-03, fs:0.65306 (r=0.920,p=0.506),  time:13.087, tt:209.388\n",
      "Ep:16, loss:0.00000, loss_test:0.01947, lr:9.80e-03, fs:0.66667 (r=0.908,p=0.527),  time:13.044, tt:221.751\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00000, loss_test:0.01930, lr:9.80e-03, fs:0.67257 (r=0.874,p=0.547),  time:13.013, tt:234.229\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00000, loss_test:0.01919, lr:9.80e-03, fs:0.68468 (r=0.874,p=0.563),  time:12.973, tt:246.493\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00000, loss_test:0.01908, lr:9.80e-03, fs:0.68807 (r=0.862,p=0.573),  time:12.946, tt:258.914\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00000, loss_test:0.01896, lr:9.80e-03, fs:0.68837 (r=0.851,p=0.578),  time:12.920, tt:271.321\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00000, loss_test:0.01883, lr:9.80e-03, fs:0.69444 (r=0.862,p=0.581),  time:12.899, tt:283.773\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00000, loss_test:0.01870, lr:9.80e-03, fs:0.69767 (r=0.862,p=0.586),  time:12.870, tt:296.003\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.01859, lr:9.80e-03, fs:0.70642 (r=0.885,p=0.588),  time:12.843, tt:308.232\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00000, loss_test:0.01849, lr:9.80e-03, fs:0.70000 (r=0.885,p=0.579),  time:12.826, tt:320.646\n",
      "Ep:25, loss:0.00000, loss_test:0.01839, lr:9.80e-03, fs:0.69683 (r=0.885,p=0.575),  time:12.812, tt:333.102\n",
      "Ep:26, loss:0.00000, loss_test:0.01829, lr:9.80e-03, fs:0.70270 (r=0.897,p=0.578),  time:12.799, tt:345.571\n",
      "Ep:27, loss:0.00000, loss_test:0.01820, lr:9.80e-03, fs:0.70588 (r=0.897,p=0.582),  time:12.788, tt:358.066\n",
      "Ep:28, loss:0.00000, loss_test:0.01811, lr:9.80e-03, fs:0.71233 (r=0.897,p=0.591),  time:12.782, tt:370.672\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.01801, lr:9.80e-03, fs:0.71889 (r=0.897,p=0.600),  time:12.775, tt:383.244\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.01792, lr:9.80e-03, fs:0.71963 (r=0.885,p=0.606),  time:12.764, tt:395.679\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.01783, lr:9.80e-03, fs:0.73333 (r=0.885,p=0.626),  time:12.753, tt:408.111\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.01774, lr:9.80e-03, fs:0.73684 (r=0.885,p=0.631),  time:12.745, tt:420.586\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.01765, lr:9.80e-03, fs:0.73077 (r=0.874,p=0.628),  time:12.736, tt:433.007\n",
      "Ep:34, loss:0.00000, loss_test:0.01755, lr:9.80e-03, fs:0.73077 (r=0.874,p=0.628),  time:12.728, tt:445.489\n",
      "Ep:35, loss:0.00000, loss_test:0.01745, lr:9.80e-03, fs:0.73430 (r=0.874,p=0.633),  time:12.720, tt:457.924\n",
      "Ep:36, loss:0.00000, loss_test:0.01735, lr:9.80e-03, fs:0.73786 (r=0.874,p=0.639),  time:12.713, tt:470.388\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.01726, lr:9.80e-03, fs:0.74146 (r=0.874,p=0.644),  time:12.709, tt:482.928\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00000, loss_test:0.01717, lr:9.80e-03, fs:0.74510 (r=0.874,p=0.650),  time:12.703, tt:495.422\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.01708, lr:9.80e-03, fs:0.74510 (r=0.874,p=0.650),  time:12.698, tt:507.929\n",
      "Ep:40, loss:0.00000, loss_test:0.01700, lr:9.80e-03, fs:0.74510 (r=0.874,p=0.650),  time:12.694, tt:520.435\n",
      "Ep:41, loss:0.00000, loss_test:0.01692, lr:9.80e-03, fs:0.74510 (r=0.874,p=0.650),  time:12.690, tt:532.979\n",
      "Ep:42, loss:0.00000, loss_test:0.01685, lr:9.80e-03, fs:0.74510 (r=0.874,p=0.650),  time:12.685, tt:545.476\n",
      "Ep:43, loss:0.00000, loss_test:0.01678, lr:9.80e-03, fs:0.74877 (r=0.874,p=0.655),  time:12.682, tt:558.017\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00000, loss_test:0.01671, lr:9.80e-03, fs:0.75490 (r=0.885,p=0.658),  time:12.679, tt:570.543\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.01664, lr:9.80e-03, fs:0.76238 (r=0.885,p=0.670),  time:12.676, tt:583.110\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00000, loss_test:0.01658, lr:9.80e-03, fs:0.76238 (r=0.885,p=0.670),  time:12.675, tt:595.743\n",
      "Ep:47, loss:0.00000, loss_test:0.01651, lr:9.80e-03, fs:0.76617 (r=0.885,p=0.675),  time:12.699, tt:609.555\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00000, loss_test:0.01644, lr:9.80e-03, fs:0.76617 (r=0.885,p=0.675),  time:12.748, tt:624.643\n",
      "Ep:49, loss:0.00000, loss_test:0.01638, lr:9.80e-03, fs:0.76617 (r=0.885,p=0.675),  time:12.791, tt:639.551\n",
      "Ep:50, loss:0.00000, loss_test:0.01631, lr:9.80e-03, fs:0.76617 (r=0.885,p=0.675),  time:12.826, tt:654.136\n",
      "Ep:51, loss:0.00000, loss_test:0.01625, lr:9.80e-03, fs:0.77228 (r=0.897,p=0.678),  time:12.865, tt:668.997\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00000, loss_test:0.01619, lr:9.80e-03, fs:0.77228 (r=0.897,p=0.678),  time:12.902, tt:683.811\n",
      "Ep:53, loss:0.00000, loss_test:0.01613, lr:9.80e-03, fs:0.76847 (r=0.897,p=0.672),  time:12.937, tt:698.618\n",
      "Ep:54, loss:0.00000, loss_test:0.01607, lr:9.80e-03, fs:0.76847 (r=0.897,p=0.672),  time:12.973, tt:713.541\n",
      "Ep:55, loss:0.00000, loss_test:0.01601, lr:9.80e-03, fs:0.77228 (r=0.897,p=0.678),  time:13.010, tt:728.552\n",
      "Ep:56, loss:0.00000, loss_test:0.01595, lr:9.80e-03, fs:0.77228 (r=0.897,p=0.678),  time:13.041, tt:743.327\n",
      "Ep:57, loss:0.00000, loss_test:0.01590, lr:9.80e-03, fs:0.77228 (r=0.897,p=0.678),  time:13.079, tt:758.562\n",
      "Ep:58, loss:0.00000, loss_test:0.01585, lr:9.80e-03, fs:0.77833 (r=0.908,p=0.681),  time:13.098, tt:772.808\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00000, loss_test:0.01580, lr:9.80e-03, fs:0.78218 (r=0.908,p=0.687),  time:13.121, tt:787.274\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00000, loss_test:0.01574, lr:9.80e-03, fs:0.78607 (r=0.908,p=0.693),  time:13.147, tt:801.977\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00000, loss_test:0.01569, lr:9.80e-03, fs:0.78607 (r=0.908,p=0.693),  time:13.171, tt:816.597\n",
      "Ep:62, loss:0.00000, loss_test:0.01564, lr:9.80e-03, fs:0.78218 (r=0.908,p=0.687),  time:13.193, tt:831.179\n",
      "Ep:63, loss:0.00000, loss_test:0.01559, lr:9.80e-03, fs:0.78218 (r=0.908,p=0.687),  time:13.219, tt:845.997\n",
      "Ep:64, loss:0.00000, loss_test:0.01554, lr:9.80e-03, fs:0.78218 (r=0.908,p=0.687),  time:13.244, tt:860.888\n",
      "Ep:65, loss:0.00000, loss_test:0.01549, lr:9.80e-03, fs:0.79000 (r=0.908,p=0.699),  time:13.273, tt:876.036\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00000, loss_test:0.01544, lr:9.80e-03, fs:0.79000 (r=0.908,p=0.699),  time:13.298, tt:890.974\n",
      "Ep:67, loss:0.00000, loss_test:0.01540, lr:9.80e-03, fs:0.79000 (r=0.908,p=0.699),  time:13.320, tt:905.794\n",
      "Ep:68, loss:0.00000, loss_test:0.01535, lr:9.80e-03, fs:0.79000 (r=0.908,p=0.699),  time:13.346, tt:920.879\n",
      "Ep:69, loss:0.00000, loss_test:0.01530, lr:9.80e-03, fs:0.79000 (r=0.908,p=0.699),  time:13.366, tt:935.628\n",
      "Ep:70, loss:0.00000, loss_test:0.01526, lr:9.80e-03, fs:0.79397 (r=0.908,p=0.705),  time:13.385, tt:950.367\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00000, loss_test:0.01521, lr:9.80e-03, fs:0.79397 (r=0.908,p=0.705),  time:13.405, tt:965.145\n",
      "Ep:72, loss:0.00000, loss_test:0.01517, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.423, tt:979.871\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00000, loss_test:0.01514, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.440, tt:994.566\n",
      "Ep:74, loss:0.00000, loss_test:0.01509, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.459, tt:1009.424\n",
      "Ep:75, loss:0.00000, loss_test:0.01505, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.477, tt:1024.228\n",
      "Ep:76, loss:0.00000, loss_test:0.01501, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.494, tt:1039.053\n",
      "Ep:77, loss:0.00000, loss_test:0.01497, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.513, tt:1054.039\n",
      "Ep:78, loss:0.00000, loss_test:0.01493, lr:9.80e-03, fs:0.79798 (r=0.908,p=0.712),  time:13.529, tt:1068.807\n",
      "Ep:79, loss:0.00000, loss_test:0.01489, lr:9.80e-03, fs:0.78571 (r=0.885,p=0.706),  time:13.546, tt:1083.643\n",
      "Ep:80, loss:0.00000, loss_test:0.01485, lr:9.80e-03, fs:0.78974 (r=0.885,p=0.713),  time:13.609, tt:1102.297\n",
      "Ep:81, loss:0.00000, loss_test:0.01482, lr:9.80e-03, fs:0.78974 (r=0.885,p=0.713),  time:13.622, tt:1116.991\n",
      "Ep:82, loss:0.00000, loss_test:0.01478, lr:9.80e-03, fs:0.80000 (r=0.897,p=0.722),  time:13.638, tt:1131.964\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00000, loss_test:0.01475, lr:9.80e-03, fs:0.80000 (r=0.897,p=0.722),  time:13.655, tt:1147.053\n",
      "Ep:84, loss:0.00000, loss_test:0.01472, lr:9.80e-03, fs:0.80000 (r=0.897,p=0.722),  time:13.666, tt:1161.637\n",
      "Ep:85, loss:0.00000, loss_test:0.01469, lr:9.80e-03, fs:0.80829 (r=0.897,p=0.736),  time:13.677, tt:1176.227\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00000, loss_test:0.01466, lr:9.80e-03, fs:0.80829 (r=0.897,p=0.736),  time:13.689, tt:1190.965\n",
      "Ep:87, loss:0.00000, loss_test:0.01463, lr:9.80e-03, fs:0.80208 (r=0.885,p=0.733),  time:13.699, tt:1205.504\n",
      "Ep:88, loss:0.00000, loss_test:0.01460, lr:9.80e-03, fs:0.80208 (r=0.885,p=0.733),  time:13.707, tt:1219.922\n",
      "Ep:89, loss:0.00000, loss_test:0.01457, lr:9.80e-03, fs:0.80208 (r=0.885,p=0.733),  time:13.721, tt:1234.881\n",
      "Ep:90, loss:0.00000, loss_test:0.01455, lr:9.80e-03, fs:0.80208 (r=0.885,p=0.733),  time:13.733, tt:1249.673\n",
      "Ep:91, loss:0.00000, loss_test:0.01452, lr:9.80e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.741, tt:1264.127\n",
      "Ep:92, loss:0.00000, loss_test:0.01449, lr:9.80e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.753, tt:1279.020\n",
      "Ep:93, loss:0.00000, loss_test:0.01446, lr:9.80e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.768, tt:1294.158\n",
      "Ep:94, loss:0.00000, loss_test:0.01444, lr:9.80e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.780, tt:1309.132\n",
      "Ep:95, loss:0.00000, loss_test:0.01441, lr:9.80e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.794, tt:1324.271\n",
      "Ep:96, loss:0.00000, loss_test:0.01439, lr:9.80e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.807, tt:1339.265\n",
      "Ep:97, loss:0.00000, loss_test:0.01437, lr:9.70e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.818, tt:1354.160\n",
      "Ep:98, loss:0.00000, loss_test:0.01435, lr:9.61e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.827, tt:1368.829\n",
      "Ep:99, loss:0.00000, loss_test:0.01432, lr:9.51e-03, fs:0.79581 (r=0.874,p=0.731),  time:13.838, tt:1383.830\n",
      "Ep:100, loss:0.00000, loss_test:0.01430, lr:9.41e-03, fs:0.80628 (r=0.885,p=0.740),  time:13.848, tt:1398.677\n",
      "Ep:101, loss:0.00000, loss_test:0.01429, lr:9.32e-03, fs:0.80628 (r=0.885,p=0.740),  time:13.858, tt:1413.532\n",
      "Ep:102, loss:0.00000, loss_test:0.01427, lr:9.23e-03, fs:0.80628 (r=0.885,p=0.740),  time:13.872, tt:1428.846\n",
      "Ep:103, loss:0.00000, loss_test:0.01425, lr:9.14e-03, fs:0.80000 (r=0.874,p=0.738),  time:13.883, tt:1443.856\n",
      "Ep:104, loss:0.00000, loss_test:0.01423, lr:9.04e-03, fs:0.80000 (r=0.874,p=0.738),  time:13.893, tt:1458.775\n",
      "Ep:105, loss:0.00000, loss_test:0.01421, lr:8.95e-03, fs:0.79365 (r=0.862,p=0.735),  time:13.903, tt:1473.693\n",
      "Ep:106, loss:0.00000, loss_test:0.01419, lr:8.86e-03, fs:0.79365 (r=0.862,p=0.735),  time:13.909, tt:1488.311\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14630, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.304, tt:37.304\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14579, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.451, tt:76.901\n",
      "Ep:2, loss:0.00001, loss_test:0.14495, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.056, tt:123.169\n",
      "Ep:3, loss:0.00001, loss_test:0.14367, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.472, tt:169.886\n",
      "Ep:4, loss:0.00001, loss_test:0.14166, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:43.611, tt:218.057\n",
      "Ep:5, loss:0.00001, loss_test:0.13831, lr:1.00e-02, fs:0.65370 (r=0.966,p=0.494),  time:44.037, tt:264.220\n",
      "Ep:6, loss:0.00001, loss_test:0.13196, lr:1.00e-02, fs:0.66667 (r=0.931,p=0.519),  time:44.485, tt:311.392\n",
      "Ep:7, loss:0.00001, loss_test:0.12412, lr:1.00e-02, fs:0.65366 (r=0.770,p=0.568),  time:45.002, tt:360.019\n",
      "Ep:8, loss:0.00001, loss_test:0.12525, lr:1.00e-02, fs:0.58182 (r=0.552,p=0.615),  time:45.182, tt:406.637\n",
      "Ep:9, loss:0.00001, loss_test:0.12205, lr:1.00e-02, fs:0.61714 (r=0.621,p=0.614),  time:45.279, tt:452.788\n",
      "Ep:10, loss:0.00001, loss_test:0.12138, lr:1.00e-02, fs:0.66332 (r=0.759,p=0.589),  time:45.389, tt:499.280\n",
      "Ep:11, loss:0.00001, loss_test:0.11995, lr:1.00e-02, fs:0.62222 (r=0.644,p=0.602),  time:45.423, tt:545.080\n",
      "Ep:12, loss:0.00001, loss_test:0.11977, lr:9.90e-03, fs:0.61988 (r=0.609,p=0.631),  time:45.634, tt:593.240\n",
      "Ep:13, loss:0.00001, loss_test:0.11518, lr:9.80e-03, fs:0.62069 (r=0.621,p=0.621),  time:45.830, tt:641.615\n",
      "Ep:14, loss:0.00001, loss_test:0.11062, lr:9.70e-03, fs:0.64407 (r=0.655,p=0.633),  time:46.022, tt:690.335\n",
      "Ep:15, loss:0.00001, loss_test:0.10834, lr:9.61e-03, fs:0.64286 (r=0.621,p=0.667),  time:46.138, tt:738.206\n",
      "Ep:16, loss:0.00001, loss_test:0.10674, lr:9.51e-03, fs:0.64671 (r=0.621,p=0.675),  time:46.608, tt:792.341\n",
      "Ep:17, loss:0.00001, loss_test:0.10534, lr:9.41e-03, fs:0.68571 (r=0.690,p=0.682),  time:46.721, tt:840.982\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.10569, lr:9.41e-03, fs:0.63804 (r=0.598,p=0.684),  time:46.681, tt:886.939\n",
      "Ep:19, loss:0.00001, loss_test:0.10152, lr:9.41e-03, fs:0.65060 (r=0.621,p=0.684),  time:46.674, tt:933.475\n",
      "Ep:20, loss:0.00001, loss_test:0.09973, lr:9.41e-03, fs:0.65060 (r=0.621,p=0.684),  time:46.603, tt:978.657\n",
      "Ep:21, loss:0.00001, loss_test:0.09926, lr:9.41e-03, fs:0.66667 (r=0.621,p=0.720),  time:46.695, tt:1027.289\n",
      "Ep:22, loss:0.00001, loss_test:0.09658, lr:9.41e-03, fs:0.66667 (r=0.632,p=0.705),  time:46.707, tt:1074.269\n",
      "Ep:23, loss:0.00001, loss_test:0.09679, lr:9.41e-03, fs:0.66242 (r=0.598,p=0.743),  time:46.753, tt:1122.067\n",
      "Ep:24, loss:0.00001, loss_test:0.09468, lr:9.41e-03, fs:0.66250 (r=0.609,p=0.726),  time:46.843, tt:1171.086\n",
      "Ep:25, loss:0.00001, loss_test:0.09393, lr:9.41e-03, fs:0.65823 (r=0.598,p=0.732),  time:46.895, tt:1219.273\n",
      "Ep:26, loss:0.00001, loss_test:0.09260, lr:9.41e-03, fs:0.67089 (r=0.609,p=0.746),  time:46.915, tt:1266.696\n",
      "Ep:27, loss:0.00001, loss_test:0.09227, lr:9.41e-03, fs:0.67974 (r=0.598,p=0.788),  time:46.876, tt:1312.524\n",
      "Ep:28, loss:0.00001, loss_test:0.09140, lr:9.41e-03, fs:0.67974 (r=0.598,p=0.788),  time:46.828, tt:1358.011\n",
      "Ep:29, loss:0.00001, loss_test:0.09056, lr:9.32e-03, fs:0.68387 (r=0.609,p=0.779),  time:46.852, tt:1405.553\n",
      "Ep:30, loss:0.00001, loss_test:0.09041, lr:9.23e-03, fs:0.69281 (r=0.609,p=0.803),  time:46.877, tt:1453.185\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00001, loss_test:0.08970, lr:9.23e-03, fs:0.69281 (r=0.609,p=0.803),  time:46.852, tt:1499.264\n",
      "Ep:32, loss:0.00001, loss_test:0.08970, lr:9.23e-03, fs:0.70130 (r=0.621,p=0.806),  time:46.873, tt:1546.807\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.08898, lr:9.23e-03, fs:0.70130 (r=0.621,p=0.806),  time:46.828, tt:1592.161\n",
      "Ep:34, loss:0.00000, loss_test:0.08912, lr:9.23e-03, fs:0.69281 (r=0.609,p=0.803),  time:46.780, tt:1637.303\n",
      "Ep:35, loss:0.00000, loss_test:0.08834, lr:9.23e-03, fs:0.69281 (r=0.609,p=0.803),  time:46.792, tt:1684.498\n",
      "Ep:36, loss:0.00000, loss_test:0.09003, lr:9.23e-03, fs:0.69737 (r=0.609,p=0.815),  time:46.751, tt:1729.793\n",
      "Ep:37, loss:0.00000, loss_test:0.08852, lr:9.23e-03, fs:0.69737 (r=0.609,p=0.815),  time:46.768, tt:1777.166\n",
      "Ep:38, loss:0.00000, loss_test:0.08927, lr:9.23e-03, fs:0.69737 (r=0.609,p=0.815),  time:46.823, tt:1826.085\n",
      "Ep:39, loss:0.00000, loss_test:0.08802, lr:9.23e-03, fs:0.69737 (r=0.609,p=0.815),  time:46.862, tt:1874.488\n",
      "Ep:40, loss:0.00000, loss_test:0.08846, lr:9.23e-03, fs:0.70199 (r=0.609,p=0.828),  time:46.869, tt:1921.636\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00000, loss_test:0.08859, lr:9.23e-03, fs:0.71141 (r=0.609,p=0.855),  time:46.917, tt:1970.501\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00000, loss_test:0.08963, lr:9.23e-03, fs:0.71141 (r=0.609,p=0.855),  time:46.970, tt:2019.722\n",
      "Ep:43, loss:0.00000, loss_test:0.08695, lr:9.23e-03, fs:0.70667 (r=0.609,p=0.841),  time:47.017, tt:2068.734\n",
      "Ep:44, loss:0.00000, loss_test:0.08962, lr:9.23e-03, fs:0.72109 (r=0.609,p=0.883),  time:47.019, tt:2115.837\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.08881, lr:9.23e-03, fs:0.72109 (r=0.609,p=0.883),  time:46.944, tt:2159.408\n",
      "Ep:46, loss:0.00000, loss_test:0.09136, lr:9.23e-03, fs:0.72603 (r=0.609,p=0.898),  time:46.989, tt:2208.481\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00000, loss_test:0.08903, lr:9.23e-03, fs:0.72109 (r=0.609,p=0.883),  time:47.021, tt:2257.011\n",
      "Ep:48, loss:0.00000, loss_test:0.09179, lr:9.23e-03, fs:0.72603 (r=0.609,p=0.898),  time:47.037, tt:2304.802\n",
      "Ep:49, loss:0.00000, loss_test:0.09198, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.112, tt:2355.621\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00000, loss_test:0.09143, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.121, tt:2403.175\n",
      "Ep:51, loss:0.00000, loss_test:0.09366, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.153, tt:2451.980\n",
      "Ep:52, loss:0.00000, loss_test:0.09476, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.145, tt:2498.703\n",
      "Ep:53, loss:0.00000, loss_test:0.09053, lr:9.23e-03, fs:0.72603 (r=0.609,p=0.898),  time:47.210, tt:2549.330\n",
      "Ep:54, loss:0.00000, loss_test:0.09519, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.240, tt:2598.201\n",
      "Ep:55, loss:0.00000, loss_test:0.09461, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.261, tt:2646.636\n",
      "Ep:56, loss:0.00000, loss_test:0.09292, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.296, tt:2695.848\n",
      "Ep:57, loss:0.00000, loss_test:0.09411, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.292, tt:2742.932\n",
      "Ep:58, loss:0.00000, loss_test:0.09475, lr:9.23e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.306, tt:2791.029\n",
      "Ep:59, loss:0.00000, loss_test:0.09753, lr:9.23e-03, fs:0.73611 (r=0.609,p=0.930),  time:47.342, tt:2840.541\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00000, loss_test:0.09604, lr:9.23e-03, fs:0.73611 (r=0.609,p=0.930),  time:47.359, tt:2888.899\n",
      "Ep:61, loss:0.00000, loss_test:0.09440, lr:9.23e-03, fs:0.73611 (r=0.609,p=0.930),  time:47.365, tt:2936.623\n",
      "Ep:62, loss:0.00000, loss_test:0.09850, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.411, tt:2986.890\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00000, loss_test:0.09674, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.437, tt:3035.996\n",
      "Ep:64, loss:0.00000, loss_test:0.09653, lr:9.23e-03, fs:0.73611 (r=0.609,p=0.930),  time:47.471, tt:3085.611\n",
      "Ep:65, loss:0.00000, loss_test:0.09683, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.502, tt:3135.126\n",
      "Ep:66, loss:0.00000, loss_test:0.09926, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.513, tt:3183.377\n",
      "Ep:67, loss:0.00000, loss_test:0.09997, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.501, tt:3230.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00000, loss_test:0.10030, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.498, tt:3277.358\n",
      "Ep:69, loss:0.00000, loss_test:0.10158, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.494, tt:3324.586\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00000, loss_test:0.10274, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.502, tt:3372.656\n",
      "Ep:71, loss:0.00000, loss_test:0.09919, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.492, tt:3419.436\n",
      "Ep:72, loss:0.00000, loss_test:0.10156, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.474, tt:3465.630\n",
      "Ep:73, loss:0.00000, loss_test:0.10485, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.457, tt:3511.824\n",
      "Ep:74, loss:0.00000, loss_test:0.10098, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.468, tt:3560.100\n",
      "Ep:75, loss:0.00000, loss_test:0.10245, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.467, tt:3607.514\n",
      "Ep:76, loss:0.00000, loss_test:0.10244, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.477, tt:3655.729\n",
      "Ep:77, loss:0.00000, loss_test:0.10671, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.479, tt:3703.337\n",
      "Ep:78, loss:0.00000, loss_test:0.10094, lr:9.23e-03, fs:0.74126 (r=0.609,p=0.946),  time:47.482, tt:3751.116\n",
      "Ep:79, loss:0.00000, loss_test:0.10651, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.481, tt:3798.457\n",
      "Ep:80, loss:0.00000, loss_test:0.10490, lr:9.23e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.479, tt:3845.815\n",
      "Ep:81, loss:0.00000, loss_test:0.10470, lr:9.14e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.513, tt:3896.074\n",
      "Ep:82, loss:0.00000, loss_test:0.10389, lr:9.04e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.534, tt:3945.325\n",
      "Ep:83, loss:0.00000, loss_test:0.10671, lr:8.95e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.547, tt:3993.968\n",
      "Ep:84, loss:0.00000, loss_test:0.10409, lr:8.86e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.531, tt:4040.140\n",
      "Ep:85, loss:0.00000, loss_test:0.10741, lr:8.78e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.537, tt:4088.200\n",
      "Ep:86, loss:0.00000, loss_test:0.10610, lr:8.69e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.542, tt:4136.119\n",
      "Ep:87, loss:0.00000, loss_test:0.10767, lr:8.60e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.536, tt:4183.209\n",
      "Ep:88, loss:0.00000, loss_test:0.10754, lr:8.51e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.540, tt:4231.100\n",
      "Ep:89, loss:0.00000, loss_test:0.10729, lr:8.43e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.533, tt:4277.940\n",
      "Ep:90, loss:0.00000, loss_test:0.10882, lr:8.35e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.526, tt:4324.903\n",
      "Ep:91, loss:0.00000, loss_test:0.10804, lr:8.26e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.529, tt:4372.653\n",
      "Ep:92, loss:0.00000, loss_test:0.10827, lr:8.18e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.538, tt:4421.073\n",
      "Ep:93, loss:0.00000, loss_test:0.10861, lr:8.10e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.482, tt:4463.343\n",
      "Ep:94, loss:0.00000, loss_test:0.10946, lr:8.02e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.422, tt:4505.107\n",
      "Ep:95, loss:0.00000, loss_test:0.10866, lr:7.94e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.389, tt:4549.372\n",
      "Ep:96, loss:0.00000, loss_test:0.10994, lr:7.86e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.340, tt:4591.967\n",
      "Ep:97, loss:0.00000, loss_test:0.10920, lr:7.78e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.292, tt:4634.650\n",
      "Ep:98, loss:0.00000, loss_test:0.10964, lr:7.70e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.247, tt:4677.421\n",
      "Ep:99, loss:0.00000, loss_test:0.11064, lr:7.62e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.195, tt:4719.484\n",
      "Ep:100, loss:0.00000, loss_test:0.10933, lr:7.55e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.146, tt:4761.752\n",
      "Ep:101, loss:0.00000, loss_test:0.11052, lr:7.47e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.110, tt:4805.186\n",
      "Ep:102, loss:0.00000, loss_test:0.10964, lr:7.40e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.070, tt:4848.173\n",
      "Ep:103, loss:0.00000, loss_test:0.11053, lr:7.32e-03, fs:0.74648 (r=0.609,p=0.964),  time:47.020, tt:4890.085\n",
      "Ep:104, loss:0.00000, loss_test:0.11110, lr:7.25e-03, fs:0.75177 (r=0.609,p=0.981),  time:46.966, tt:4931.425\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.11170, lr:7.25e-03, fs:0.74648 (r=0.609,p=0.964),  time:46.985, tt:4980.415\n",
      "Ep:106, loss:0.00000, loss_test:0.11190, lr:7.25e-03, fs:0.75177 (r=0.609,p=0.981),  time:46.897, tt:5017.978\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14091, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:24.451, tt:24.451\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.13866, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:30.367, tt:60.734\n",
      "Ep:2, loss:0.00001, loss_test:0.13438, lr:1.00e-02, fs:0.65882 (r=0.966,p=0.500),  time:35.281, tt:105.844\n",
      "Ep:3, loss:0.00001, loss_test:0.12709, lr:1.00e-02, fs:0.67769 (r=0.943,p=0.529),  time:38.756, tt:155.024\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.11859, lr:1.00e-02, fs:0.65327 (r=0.747,p=0.580),  time:40.554, tt:202.768\n",
      "Ep:5, loss:0.00001, loss_test:0.11678, lr:1.00e-02, fs:0.63277 (r=0.644,p=0.622),  time:41.717, tt:250.302\n",
      "Ep:6, loss:0.00001, loss_test:0.11684, lr:1.00e-02, fs:0.62791 (r=0.621,p=0.635),  time:42.374, tt:296.620\n",
      "Ep:7, loss:0.00001, loss_test:0.11600, lr:1.00e-02, fs:0.65957 (r=0.713,p=0.614),  time:43.146, tt:345.166\n",
      "Ep:8, loss:0.00001, loss_test:0.11292, lr:1.00e-02, fs:0.65934 (r=0.690,p=0.632),  time:44.628, tt:401.649\n",
      "Ep:9, loss:0.00001, loss_test:0.11085, lr:1.00e-02, fs:0.64706 (r=0.632,p=0.663),  time:44.716, tt:447.155\n",
      "Ep:10, loss:0.00001, loss_test:0.11125, lr:1.00e-02, fs:0.62195 (r=0.586,p=0.662),  time:44.998, tt:494.974\n",
      "Ep:11, loss:0.00001, loss_test:0.10931, lr:1.00e-02, fs:0.64327 (r=0.632,p=0.655),  time:45.187, tt:542.244\n",
      "Ep:12, loss:0.00001, loss_test:0.10655, lr:1.00e-02, fs:0.65896 (r=0.655,p=0.663),  time:45.336, tt:589.362\n",
      "Ep:13, loss:0.00001, loss_test:0.10504, lr:1.00e-02, fs:0.64634 (r=0.609,p=0.688),  time:45.525, tt:637.356\n",
      "Ep:14, loss:0.00001, loss_test:0.10329, lr:1.00e-02, fs:0.65854 (r=0.621,p=0.701),  time:45.736, tt:686.040\n",
      "Ep:15, loss:0.00001, loss_test:0.10183, lr:9.90e-03, fs:0.66265 (r=0.632,p=0.696),  time:45.783, tt:732.525\n",
      "Ep:16, loss:0.00001, loss_test:0.10156, lr:9.80e-03, fs:0.66258 (r=0.621,p=0.711),  time:45.968, tt:781.455\n",
      "Ep:17, loss:0.00001, loss_test:0.10055, lr:9.70e-03, fs:0.66258 (r=0.621,p=0.711),  time:45.959, tt:827.266\n",
      "Ep:18, loss:0.00001, loss_test:0.09903, lr:9.61e-03, fs:0.66258 (r=0.621,p=0.711),  time:46.080, tt:875.513\n",
      "Ep:19, loss:0.00001, loss_test:0.09907, lr:9.51e-03, fs:0.67081 (r=0.621,p=0.730),  time:46.145, tt:922.893\n",
      "Ep:20, loss:0.00001, loss_test:0.09848, lr:9.41e-03, fs:0.67081 (r=0.621,p=0.730),  time:46.223, tt:970.679\n",
      "Ep:21, loss:0.00001, loss_test:0.09797, lr:9.32e-03, fs:0.69136 (r=0.644,p=0.747),  time:46.253, tt:1017.569\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.09780, lr:9.32e-03, fs:0.70370 (r=0.655,p=0.760),  time:46.344, tt:1065.923\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.09705, lr:9.32e-03, fs:0.70807 (r=0.655,p=0.770),  time:46.460, tt:1115.046\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00001, loss_test:0.09739, lr:9.32e-03, fs:0.71250 (r=0.655,p=0.781),  time:46.491, tt:1162.276\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.09616, lr:9.32e-03, fs:0.72611 (r=0.655,p=0.814),  time:46.515, tt:1209.384\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.09550, lr:9.32e-03, fs:0.72611 (r=0.655,p=0.814),  time:46.590, tt:1257.929\n",
      "Ep:27, loss:0.00001, loss_test:0.09461, lr:9.32e-03, fs:0.72611 (r=0.655,p=0.814),  time:46.579, tt:1304.222\n",
      "Ep:28, loss:0.00001, loss_test:0.09512, lr:9.32e-03, fs:0.73077 (r=0.655,p=0.826),  time:46.595, tt:1351.242\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.09456, lr:9.32e-03, fs:0.73548 (r=0.655,p=0.838),  time:46.559, tt:1396.781\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.09552, lr:9.32e-03, fs:0.73548 (r=0.655,p=0.838),  time:46.608, tt:1444.846\n",
      "Ep:31, loss:0.00000, loss_test:0.09530, lr:9.32e-03, fs:0.73548 (r=0.655,p=0.838),  time:46.643, tt:1492.589\n",
      "Ep:32, loss:0.00000, loss_test:0.09534, lr:9.32e-03, fs:0.72727 (r=0.644,p=0.836),  time:46.585, tt:1537.316\n",
      "Ep:33, loss:0.00000, loss_test:0.09545, lr:9.32e-03, fs:0.73548 (r=0.655,p=0.838),  time:46.551, tt:1582.727\n",
      "Ep:34, loss:0.00000, loss_test:0.09500, lr:9.32e-03, fs:0.73885 (r=0.667,p=0.829),  time:46.568, tt:1629.864\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00000, loss_test:0.09525, lr:9.32e-03, fs:0.73885 (r=0.667,p=0.829),  time:46.595, tt:1677.403\n",
      "Ep:36, loss:0.00000, loss_test:0.09490, lr:9.32e-03, fs:0.74359 (r=0.667,p=0.841),  time:46.610, tt:1724.585\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.09591, lr:9.32e-03, fs:0.74359 (r=0.667,p=0.841),  time:46.606, tt:1771.019\n",
      "Ep:38, loss:0.00000, loss_test:0.09552, lr:9.32e-03, fs:0.75325 (r=0.667,p=0.866),  time:46.648, tt:1819.258\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.09662, lr:9.32e-03, fs:0.75325 (r=0.667,p=0.866),  time:46.690, tt:1867.590\n",
      "Ep:40, loss:0.00000, loss_test:0.09617, lr:9.32e-03, fs:0.75817 (r=0.667,p=0.879),  time:46.672, tt:1913.570\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00000, loss_test:0.09637, lr:9.32e-03, fs:0.75817 (r=0.667,p=0.879),  time:46.715, tt:1962.023\n",
      "Ep:42, loss:0.00000, loss_test:0.09735, lr:9.32e-03, fs:0.76316 (r=0.667,p=0.892),  time:46.723, tt:2009.108\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.09705, lr:9.32e-03, fs:0.76316 (r=0.667,p=0.892),  time:46.766, tt:2057.722\n",
      "Ep:44, loss:0.00000, loss_test:0.09830, lr:9.32e-03, fs:0.76316 (r=0.667,p=0.892),  time:46.678, tt:2100.529\n",
      "Ep:45, loss:0.00000, loss_test:0.09859, lr:9.32e-03, fs:0.76316 (r=0.667,p=0.892),  time:46.615, tt:2144.289\n",
      "Ep:46, loss:0.00000, loss_test:0.09957, lr:9.32e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.559, tt:2188.255\n",
      "Ep:47, loss:0.00000, loss_test:0.09928, lr:9.32e-03, fs:0.75817 (r=0.667,p=0.879),  time:46.518, tt:2232.874\n",
      "Ep:48, loss:0.00000, loss_test:0.09918, lr:9.32e-03, fs:0.75817 (r=0.667,p=0.879),  time:46.467, tt:2276.881\n",
      "Ep:49, loss:0.00000, loss_test:0.09943, lr:9.32e-03, fs:0.75817 (r=0.667,p=0.879),  time:46.457, tt:2322.840\n",
      "Ep:50, loss:0.00000, loss_test:0.09989, lr:9.32e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.475, tt:2370.238\n",
      "Ep:51, loss:0.00000, loss_test:0.09940, lr:9.32e-03, fs:0.75000 (r=0.655,p=0.877),  time:46.455, tt:2415.645\n",
      "Ep:52, loss:0.00000, loss_test:0.10030, lr:9.32e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.467, tt:2462.725\n",
      "Ep:53, loss:0.00000, loss_test:0.09963, lr:9.32e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.492, tt:2510.557\n",
      "Ep:54, loss:0.00000, loss_test:0.10035, lr:9.23e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.511, tt:2558.117\n",
      "Ep:55, loss:0.00000, loss_test:0.09944, lr:9.14e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.534, tt:2605.888\n",
      "Ep:56, loss:0.00000, loss_test:0.10034, lr:9.04e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.578, tt:2654.964\n",
      "Ep:57, loss:0.00000, loss_test:0.09997, lr:8.95e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.588, tt:2702.124\n",
      "Ep:58, loss:0.00000, loss_test:0.10212, lr:8.86e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.605, tt:2749.711\n",
      "Ep:59, loss:0.00000, loss_test:0.10023, lr:8.78e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.636, tt:2798.159\n",
      "Ep:60, loss:0.00000, loss_test:0.10134, lr:8.69e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.647, tt:2845.467\n",
      "Ep:61, loss:0.00000, loss_test:0.10161, lr:8.60e-03, fs:0.75497 (r=0.655,p=0.891),  time:46.653, tt:2892.496\n",
      "Ep:62, loss:0.00000, loss_test:0.10213, lr:8.51e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.674, tt:2940.470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00000, loss_test:0.10175, lr:8.43e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.743, tt:2991.572\n",
      "Ep:64, loss:0.00000, loss_test:0.10189, lr:8.35e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.774, tt:3040.314\n",
      "Ep:65, loss:0.00000, loss_test:0.10175, lr:8.26e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.802, tt:3088.962\n",
      "Ep:66, loss:0.00000, loss_test:0.10235, lr:8.18e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.800, tt:3135.601\n",
      "Ep:67, loss:0.00000, loss_test:0.10233, lr:8.10e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.801, tt:3182.481\n",
      "Ep:68, loss:0.00000, loss_test:0.10234, lr:8.02e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.786, tt:3228.233\n",
      "Ep:69, loss:0.00000, loss_test:0.10210, lr:7.94e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.781, tt:3274.680\n",
      "Ep:70, loss:0.00000, loss_test:0.10288, lr:7.86e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.755, tt:3319.603\n",
      "Ep:71, loss:0.00000, loss_test:0.10282, lr:7.78e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.757, tt:3366.502\n",
      "Ep:72, loss:0.00000, loss_test:0.10237, lr:7.70e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.766, tt:3413.913\n",
      "Ep:73, loss:0.00000, loss_test:0.10353, lr:7.62e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.773, tt:3461.180\n",
      "Ep:74, loss:0.00000, loss_test:0.10266, lr:7.55e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.774, tt:3508.015\n",
      "Ep:75, loss:0.00000, loss_test:0.10262, lr:7.47e-03, fs:0.76000 (r=0.655,p=0.905),  time:46.753, tt:3553.238\n",
      "Ep:76, loss:0.00000, loss_test:0.10348, lr:7.40e-03, fs:0.76510 (r=0.655,p=0.919),  time:46.743, tt:3599.192\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00000, loss_test:0.10274, lr:7.40e-03, fs:0.76510 (r=0.655,p=0.919),  time:46.760, tt:3647.243\n",
      "Ep:78, loss:0.00000, loss_test:0.10398, lr:7.40e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.841, tt:3700.414\n",
      "Ep:79, loss:0.00000, loss_test:0.10255, lr:7.40e-03, fs:0.76510 (r=0.655,p=0.919),  time:46.832, tt:3746.554\n",
      "Ep:80, loss:0.00000, loss_test:0.10335, lr:7.40e-03, fs:0.74830 (r=0.632,p=0.917),  time:46.837, tt:3793.793\n",
      "Ep:81, loss:0.00000, loss_test:0.10310, lr:7.40e-03, fs:0.76510 (r=0.655,p=0.919),  time:46.837, tt:3840.670\n",
      "Ep:82, loss:0.00000, loss_test:0.10375, lr:7.40e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.831, tt:3887.013\n",
      "Ep:83, loss:0.00000, loss_test:0.10352, lr:7.40e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.806, tt:3931.672\n",
      "Ep:84, loss:0.00000, loss_test:0.10421, lr:7.40e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.794, tt:3977.475\n",
      "Ep:85, loss:0.00000, loss_test:0.10373, lr:7.40e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.768, tt:4022.059\n",
      "Ep:86, loss:0.00000, loss_test:0.10474, lr:7.40e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.744, tt:4066.729\n",
      "Ep:87, loss:0.00000, loss_test:0.10490, lr:7.40e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.730, tt:4112.273\n",
      "Ep:88, loss:0.00000, loss_test:0.10462, lr:7.32e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.719, tt:4158.008\n",
      "Ep:89, loss:0.00000, loss_test:0.10538, lr:7.25e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.720, tt:4204.766\n",
      "Ep:90, loss:0.00000, loss_test:0.10531, lr:7.18e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.727, tt:4252.156\n",
      "Ep:91, loss:0.00000, loss_test:0.10550, lr:7.11e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.705, tt:4296.867\n",
      "Ep:92, loss:0.00000, loss_test:0.10577, lr:7.03e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.700, tt:4343.104\n",
      "Ep:93, loss:0.00000, loss_test:0.10595, lr:6.96e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.756, tt:4395.028\n",
      "Ep:94, loss:0.00000, loss_test:0.10572, lr:6.89e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.767, tt:4442.876\n",
      "Ep:95, loss:0.00000, loss_test:0.10652, lr:6.83e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.774, tt:4490.343\n",
      "Ep:96, loss:0.00000, loss_test:0.10633, lr:6.76e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.798, tt:4539.389\n",
      "Ep:97, loss:0.00000, loss_test:0.10712, lr:6.69e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.819, tt:4588.223\n",
      "Ep:98, loss:0.00000, loss_test:0.10672, lr:6.62e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.782, tt:4631.410\n",
      "Ep:99, loss:0.00000, loss_test:0.10754, lr:6.56e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.749, tt:4674.901\n",
      "Ep:100, loss:0.00000, loss_test:0.10736, lr:6.49e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.717, tt:4718.397\n",
      "Ep:101, loss:0.00000, loss_test:0.10787, lr:6.43e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.682, tt:4761.579\n",
      "Ep:102, loss:0.00000, loss_test:0.10796, lr:6.36e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.656, tt:4805.522\n",
      "Ep:103, loss:0.00000, loss_test:0.10834, lr:6.30e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.611, tt:4847.549\n",
      "Ep:104, loss:0.00000, loss_test:0.10853, lr:6.24e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.539, tt:4886.583\n",
      "Ep:105, loss:0.00000, loss_test:0.10860, lr:6.17e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.519, tt:4930.973\n",
      "Ep:106, loss:0.00000, loss_test:0.10906, lr:6.11e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.531, tt:4978.816\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00342, loss_test:0.11570, lr:4.00e-03, fs:0.68722 (r=0.788,p=0.609),  time:587.138, tt:587.138\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00244, loss_test:0.09422, lr:4.00e-03, fs:0.76617 (r=0.778,p=0.755),  time:580.642, tt:1161.283\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00180, loss_test:0.08323, lr:4.00e-03, fs:0.82723 (r=0.798,p=0.859),  time:581.958, tt:1745.875\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00128, loss_test:0.07702, lr:4.00e-03, fs:0.84783 (r=0.788,p=0.918),  time:585.112, tt:2340.448\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00084, loss_test:0.07474, lr:4.00e-03, fs:0.86188 (r=0.788,p=0.951),  time:585.505, tt:2927.523\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00049, loss_test:0.08013, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:578.078, tt:3468.470\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.08208, lr:4.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:569.400, tt:3985.803\n",
      "Ep:7, loss:0.00015, loss_test:0.08528, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:563.140, tt:4505.118\n",
      "Ep:8, loss:0.00009, loss_test:0.08802, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:558.426, tt:5025.837\n",
      "Ep:9, loss:0.00006, loss_test:0.08778, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:555.583, tt:5555.832\n",
      "Ep:10, loss:0.00004, loss_test:0.08662, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:552.655, tt:6079.202\n",
      "Ep:11, loss:0.00003, loss_test:0.08688, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:548.798, tt:6585.573\n",
      "Ep:12, loss:0.00003, loss_test:0.08619, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:519.983, tt:6759.779\n",
      "Ep:13, loss:0.00002, loss_test:0.08669, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:493.442, tt:6908.187\n",
      "Ep:14, loss:0.00002, loss_test:0.08706, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:470.588, tt:7058.825\n",
      "Ep:15, loss:0.00002, loss_test:0.08526, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:450.508, tt:7208.122\n",
      "Ep:16, loss:0.00001, loss_test:0.08416, lr:4.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:432.853, tt:7358.504\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14721, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:83.927, tt:83.927\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.14491, lr:1.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:84.016, tt:168.032\n",
      "Ep:2, loss:0.00047, loss_test:0.15590, lr:1.00e-02, fs:0.54082 (r=0.535,p=0.546),  time:86.214, tt:258.642\n",
      "Ep:3, loss:0.00043, loss_test:0.14921, lr:1.00e-02, fs:0.53000 (r=0.535,p=0.525),  time:85.418, tt:341.671\n",
      "Ep:4, loss:0.00040, loss_test:0.14471, lr:1.00e-02, fs:0.52459 (r=0.485,p=0.571),  time:84.793, tt:423.965\n",
      "Ep:5, loss:0.00037, loss_test:0.13597, lr:1.00e-02, fs:0.55435 (r=0.515,p=0.600),  time:84.775, tt:508.648\n",
      "Ep:6, loss:0.00034, loss_test:0.13693, lr:1.00e-02, fs:0.49412 (r=0.424,p=0.592),  time:84.754, tt:593.280\n",
      "Ep:7, loss:0.00031, loss_test:0.12834, lr:1.00e-02, fs:0.58824 (r=0.556,p=0.625),  time:85.249, tt:681.991\n",
      "Ep:8, loss:0.00029, loss_test:0.13471, lr:1.00e-02, fs:0.52174 (r=0.424,p=0.677),  time:85.142, tt:766.278\n",
      "Ep:9, loss:0.00027, loss_test:0.13027, lr:1.00e-02, fs:0.54545 (r=0.455,p=0.682),  time:85.116, tt:851.156\n",
      "Ep:10, loss:0.00025, loss_test:0.12931, lr:1.00e-02, fs:0.56287 (r=0.475,p=0.691),  time:85.025, tt:935.274\n",
      "Ep:11, loss:0.00023, loss_test:0.12923, lr:1.00e-02, fs:0.54321 (r=0.444,p=0.698),  time:85.146, tt:1021.753\n",
      "Ep:12, loss:0.00020, loss_test:0.12664, lr:9.90e-03, fs:0.55215 (r=0.455,p=0.703),  time:85.302, tt:1108.925\n",
      "Ep:13, loss:0.00018, loss_test:0.12819, lr:9.80e-03, fs:0.55696 (r=0.444,p=0.746),  time:85.122, tt:1191.708\n",
      "Ep:14, loss:0.00017, loss_test:0.13305, lr:9.70e-03, fs:0.56209 (r=0.434,p=0.796),  time:85.195, tt:1277.923\n",
      "Ep:15, loss:0.00015, loss_test:0.13511, lr:9.61e-03, fs:0.53691 (r=0.404,p=0.800),  time:85.069, tt:1361.099\n",
      "Ep:16, loss:0.00013, loss_test:0.13584, lr:9.51e-03, fs:0.54422 (r=0.404,p=0.833),  time:85.024, tt:1445.403\n",
      "Ep:17, loss:0.00012, loss_test:0.14357, lr:9.41e-03, fs:0.52113 (r=0.374,p=0.860),  time:84.800, tt:1526.401\n",
      "Ep:18, loss:0.00011, loss_test:0.14892, lr:9.32e-03, fs:0.48529 (r=0.333,p=0.892),  time:84.623, tt:1607.828\n",
      "Ep:19, loss:0.00009, loss_test:0.14708, lr:9.23e-03, fs:0.50000 (r=0.354,p=0.854),  time:84.715, tt:1694.298\n",
      "Ep:20, loss:0.00008, loss_test:0.14505, lr:9.14e-03, fs:0.46715 (r=0.323,p=0.842),  time:84.581, tt:1776.198\n",
      "Ep:21, loss:0.00007, loss_test:0.15275, lr:9.04e-03, fs:0.45926 (r=0.313,p=0.861),  time:84.596, tt:1861.109\n",
      "Ep:22, loss:0.00007, loss_test:0.16332, lr:8.95e-03, fs:0.42187 (r=0.273,p=0.931),  time:84.695, tt:1947.992\n",
      "Ep:23, loss:0.00006, loss_test:0.16324, lr:8.86e-03, fs:0.42187 (r=0.273,p=0.931),  time:84.758, tt:2034.203\n",
      "Ep:24, loss:0.00005, loss_test:0.15828, lr:8.78e-03, fs:0.41221 (r=0.273,p=0.844),  time:84.761, tt:2119.025\n",
      "Ep:25, loss:0.00005, loss_test:0.15781, lr:8.69e-03, fs:0.41860 (r=0.273,p=0.900),  time:84.723, tt:2202.793\n",
      "Ep:26, loss:0.00004, loss_test:0.16208, lr:8.60e-03, fs:0.44615 (r=0.293,p=0.935),  time:84.376, tt:2278.144\n",
      "Ep:27, loss:0.00004, loss_test:0.16695, lr:8.51e-03, fs:0.35772 (r=0.222,p=0.917),  time:83.868, tt:2348.295\n",
      "Ep:28, loss:0.00004, loss_test:0.16241, lr:8.43e-03, fs:0.43411 (r=0.283,p=0.933),  time:83.005, tt:2407.146\n",
      "Ep:29, loss:0.00003, loss_test:0.16170, lr:8.35e-03, fs:0.39683 (r=0.253,p=0.926),  time:82.682, tt:2480.470\n",
      "Ep:30, loss:0.00003, loss_test:0.16458, lr:8.26e-03, fs:0.37097 (r=0.232,p=0.920),  time:82.772, tt:2565.933\n",
      "Ep:31, loss:0.00003, loss_test:0.17111, lr:8.18e-03, fs:0.37097 (r=0.232,p=0.920),  time:83.000, tt:2655.996\n",
      "Ep:32, loss:0.00002, loss_test:0.17523, lr:8.10e-03, fs:0.37097 (r=0.232,p=0.920),  time:83.145, tt:2743.777\n",
      "Ep:33, loss:0.00002, loss_test:0.17164, lr:8.02e-03, fs:0.42520 (r=0.273,p=0.964),  time:83.254, tt:2830.652\n",
      "Ep:34, loss:0.00002, loss_test:0.17593, lr:7.94e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.212, tt:2912.427\n",
      "Ep:35, loss:0.00002, loss_test:0.17835, lr:7.86e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.226, tt:2996.120\n",
      "Ep:36, loss:0.00002, loss_test:0.16875, lr:7.78e-03, fs:0.39683 (r=0.253,p=0.926),  time:83.309, tt:3082.451\n",
      "Ep:37, loss:0.00002, loss_test:0.17349, lr:7.70e-03, fs:0.46970 (r=0.313,p=0.939),  time:83.545, tt:3174.702\n",
      "Ep:38, loss:0.00001, loss_test:0.17316, lr:7.62e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.605, tt:3260.590\n",
      "Ep:39, loss:0.00001, loss_test:0.17358, lr:7.55e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.710, tt:3348.388\n",
      "Ep:40, loss:0.00001, loss_test:0.17291, lr:7.47e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.817, tt:3436.511\n",
      "Ep:41, loss:0.00001, loss_test:0.17146, lr:7.40e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.803, tt:3519.746\n",
      "Ep:42, loss:0.00001, loss_test:0.17299, lr:7.32e-03, fs:0.49254 (r=0.333,p=0.943),  time:83.785, tt:3602.763\n",
      "Ep:43, loss:0.00001, loss_test:0.17388, lr:7.25e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.800, tt:3687.188\n",
      "Ep:44, loss:0.00001, loss_test:0.17402, lr:7.18e-03, fs:0.42520 (r=0.273,p=0.964),  time:83.849, tt:3773.184\n",
      "Ep:45, loss:0.00001, loss_test:0.17776, lr:7.11e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.943, tt:3861.399\n",
      "Ep:46, loss:0.00001, loss_test:0.17217, lr:7.03e-03, fs:0.42187 (r=0.273,p=0.931),  time:83.995, tt:3947.762\n",
      "Ep:47, loss:0.00001, loss_test:0.17277, lr:6.96e-03, fs:0.46970 (r=0.313,p=0.939),  time:84.046, tt:4034.193\n",
      "Ep:48, loss:0.00001, loss_test:0.17374, lr:6.89e-03, fs:0.42187 (r=0.273,p=0.931),  time:84.131, tt:4122.396\n",
      "Ep:49, loss:0.00001, loss_test:0.17551, lr:6.83e-03, fs:0.42520 (r=0.273,p=0.964),  time:84.217, tt:4210.827\n",
      "Ep:50, loss:0.00001, loss_test:0.17690, lr:6.76e-03, fs:0.42520 (r=0.273,p=0.964),  time:84.243, tt:4296.410\n",
      "Ep:51, loss:0.00001, loss_test:0.17478, lr:6.69e-03, fs:0.42187 (r=0.273,p=0.931),  time:84.291, tt:4383.149\n",
      "Ep:52, loss:0.00001, loss_test:0.17086, lr:6.62e-03, fs:0.46970 (r=0.313,p=0.939),  time:84.358, tt:4470.989\n",
      "Ep:53, loss:0.00001, loss_test:0.17482, lr:6.56e-03, fs:0.42187 (r=0.273,p=0.931),  time:84.380, tt:4556.528\n",
      "Ep:54, loss:0.00001, loss_test:0.17321, lr:6.49e-03, fs:0.39683 (r=0.253,p=0.926),  time:84.416, tt:4642.878\n",
      "Ep:55, loss:0.00001, loss_test:0.17612, lr:6.43e-03, fs:0.45802 (r=0.303,p=0.938),  time:84.460, tt:4729.741\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"2-2\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00392, loss_test:0.08622, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:641.863, tt:641.863\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00207, loss_test:0.06136, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:699.026, tt:1398.053\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00098, loss_test:0.05862, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:710.789, tt:2132.366\n",
      "Ep:3, loss:0.00047, loss_test:0.07091, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:721.501, tt:2886.004\n",
      "Ep:4, loss:0.00021, loss_test:0.07436, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:725.414, tt:3627.072\n",
      "Ep:5, loss:0.00010, loss_test:0.07461, lr:1.00e-02, fs:0.83721 (r=0.727,p=0.986),  time:729.554, tt:4377.326\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6ed6c8c7f096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"2-2\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00384, loss_test:0.08730, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:747.007, tt:747.007\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00202, loss_test:0.06437, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:747.668, tt:1495.336\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00099, loss_test:0.06760, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:749.421, tt:2248.264\n",
      "Ep:3, loss:0.00051, loss_test:0.06771, lr:1.00e-02, fs:0.85057 (r=0.747,p=0.987),  time:749.094, tt:2996.377\n",
      "Ep:4, loss:0.00025, loss_test:0.07091, lr:1.00e-02, fs:0.83721 (r=0.727,p=0.986),  time:752.351, tt:3761.756\n",
      "Ep:5, loss:0.00013, loss_test:0.07569, lr:1.00e-02, fs:0.83721 (r=0.727,p=0.986),  time:750.597, tt:4503.583\n",
      "Ep:6, loss:0.00008, loss_test:0.07981, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:749.562, tt:5246.935\n",
      "Ep:7, loss:0.00005, loss_test:0.07866, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:748.541, tt:5988.325\n",
      "Ep:8, loss:0.00003, loss_test:0.08071, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:747.242, tt:6725.180\n",
      "Ep:9, loss:0.00002, loss_test:0.08036, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:747.558, tt:7475.582\n",
      "Ep:10, loss:0.00002, loss_test:0.07755, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:747.069, tt:8217.760\n",
      "Ep:11, loss:0.00001, loss_test:0.07852, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:747.549, tt:8970.588\n",
      "Ep:12, loss:0.00001, loss_test:0.07938, lr:1.00e-02, fs:0.84211 (r=0.727,p=1.000),  time:748.742, tt:9733.652\n",
      "Ep:13, loss:0.00001, loss_test:0.07650, lr:9.90e-03, fs:0.84211 (r=0.727,p=1.000),  time:749.341, tt:10490.768\n",
      "Ep:14, loss:0.00001, loss_test:0.07580, lr:9.80e-03, fs:0.84211 (r=0.727,p=1.000),  time:750.247, tt:11253.702\n",
      "Ep:15, loss:0.00001, loss_test:0.07554, lr:9.70e-03, fs:0.84211 (r=0.727,p=1.000),  time:751.528, tt:12024.451\n",
      "Ep:16, loss:0.00001, loss_test:0.07489, lr:9.61e-03, fs:0.84211 (r=0.727,p=1.000),  time:751.929, tt:12782.795\n",
      "Ep:17, loss:0.00001, loss_test:0.07455, lr:9.51e-03, fs:0.84211 (r=0.727,p=1.000),  time:752.470, tt:13544.461\n",
      "Ep:18, loss:0.00001, loss_test:0.07439, lr:9.41e-03, fs:0.84211 (r=0.727,p=1.000),  time:752.942, tt:14305.895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14416, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.677, tt:9.677\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14387, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.447, tt:22.893\n",
      "Ep:2, loss:0.00004, loss_test:0.14342, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.542, tt:43.625\n",
      "Ep:3, loss:0.00004, loss_test:0.14281, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.101, tt:64.404\n",
      "Ep:4, loss:0.00004, loss_test:0.14198, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.827, tt:84.135\n",
      "Ep:5, loss:0.00004, loss_test:0.14088, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:17.122, tt:102.730\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13942, lr:1.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:17.554, tt:122.876\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.13755, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:17.981, tt:143.852\n",
      "Ep:8, loss:0.00004, loss_test:0.13521, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:18.179, tt:163.615\n",
      "Ep:9, loss:0.00004, loss_test:0.13245, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:18.216, tt:182.159\n",
      "Ep:10, loss:0.00003, loss_test:0.13014, lr:1.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:18.394, tt:202.330\n",
      "Ep:11, loss:0.00003, loss_test:0.12851, lr:1.00e-02, fs:0.62100 (r=0.687,p=0.567),  time:18.591, tt:223.089\n",
      "Ep:12, loss:0.00003, loss_test:0.12864, lr:1.00e-02, fs:0.58763 (r=0.576,p=0.600),  time:18.914, tt:245.878\n",
      "Ep:13, loss:0.00003, loss_test:0.13064, lr:1.00e-02, fs:0.54749 (r=0.495,p=0.613),  time:18.957, tt:265.402\n",
      "Ep:14, loss:0.00003, loss_test:0.13067, lr:1.00e-02, fs:0.52874 (r=0.465,p=0.613),  time:19.076, tt:286.133\n",
      "Ep:15, loss:0.00003, loss_test:0.12822, lr:1.00e-02, fs:0.54023 (r=0.475,p=0.627),  time:19.177, tt:306.828\n",
      "Ep:16, loss:0.00003, loss_test:0.12483, lr:1.00e-02, fs:0.57143 (r=0.545,p=0.600),  time:19.153, tt:325.607\n",
      "Ep:17, loss:0.00003, loss_test:0.12299, lr:1.00e-02, fs:0.60606 (r=0.606,p=0.606),  time:19.180, tt:345.239\n",
      "Ep:18, loss:0.00003, loss_test:0.12195, lr:9.90e-03, fs:0.60396 (r=0.616,p=0.592),  time:19.204, tt:364.877\n",
      "Ep:19, loss:0.00003, loss_test:0.12129, lr:9.80e-03, fs:0.60104 (r=0.586,p=0.617),  time:19.205, tt:384.097\n",
      "Ep:20, loss:0.00003, loss_test:0.12148, lr:9.70e-03, fs:0.59341 (r=0.545,p=0.651),  time:19.242, tt:404.092\n",
      "Ep:21, loss:0.00003, loss_test:0.12187, lr:9.61e-03, fs:0.59770 (r=0.525,p=0.693),  time:19.223, tt:422.908\n",
      "Ep:22, loss:0.00003, loss_test:0.12104, lr:9.51e-03, fs:0.60819 (r=0.525,p=0.722),  time:19.276, tt:443.339\n",
      "Ep:23, loss:0.00003, loss_test:0.11879, lr:9.41e-03, fs:0.61714 (r=0.545,p=0.711),  time:19.364, tt:464.730\n",
      "Ep:24, loss:0.00003, loss_test:0.11663, lr:9.32e-03, fs:0.62637 (r=0.576,p=0.687),  time:19.444, tt:486.100\n",
      "Ep:25, loss:0.00002, loss_test:0.11516, lr:9.23e-03, fs:0.63388 (r=0.586,p=0.690),  time:19.484, tt:506.587\n",
      "Ep:26, loss:0.00002, loss_test:0.11423, lr:9.14e-03, fs:0.64088 (r=0.586,p=0.707),  time:19.504, tt:526.618\n",
      "Ep:27, loss:0.00002, loss_test:0.11398, lr:9.04e-03, fs:0.64368 (r=0.566,p=0.747),  time:19.514, tt:546.401\n",
      "Ep:28, loss:0.00002, loss_test:0.11380, lr:8.95e-03, fs:0.60714 (r=0.515,p=0.739),  time:19.542, tt:566.715\n",
      "Ep:29, loss:0.00002, loss_test:0.11267, lr:8.86e-03, fs:0.62353 (r=0.535,p=0.746),  time:19.547, tt:586.402\n",
      "Ep:30, loss:0.00002, loss_test:0.11067, lr:8.78e-03, fs:0.66286 (r=0.586,p=0.763),  time:19.580, tt:606.966\n",
      "Ep:31, loss:0.00002, loss_test:0.10910, lr:8.69e-03, fs:0.65922 (r=0.596,p=0.738),  time:19.618, tt:627.780\n",
      "Ep:32, loss:0.00002, loss_test:0.10813, lr:8.60e-03, fs:0.65909 (r=0.586,p=0.753),  time:19.623, tt:647.570\n",
      "Ep:33, loss:0.00002, loss_test:0.10768, lr:8.51e-03, fs:0.65896 (r=0.576,p=0.770),  time:19.636, tt:667.608\n",
      "Ep:34, loss:0.00002, loss_test:0.10751, lr:8.43e-03, fs:0.65116 (r=0.566,p=0.767),  time:19.618, tt:686.643\n",
      "Ep:35, loss:0.00002, loss_test:0.10676, lr:8.35e-03, fs:0.65497 (r=0.566,p=0.778),  time:19.591, tt:705.259\n",
      "Ep:36, loss:0.00002, loss_test:0.10558, lr:8.26e-03, fs:0.70391 (r=0.636,p=0.787),  time:19.580, tt:724.461\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.10450, lr:8.26e-03, fs:0.70718 (r=0.646,p=0.780),  time:19.602, tt:744.893\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.10405, lr:8.26e-03, fs:0.70391 (r=0.636,p=0.787),  time:19.628, tt:765.503\n",
      "Ep:39, loss:0.00002, loss_test:0.10366, lr:8.26e-03, fs:0.70787 (r=0.636,p=0.797),  time:19.663, tt:786.517\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10266, lr:8.26e-03, fs:0.71111 (r=0.646,p=0.790),  time:19.682, tt:806.966\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.10138, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.688, tt:826.889\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10054, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.684, tt:846.432\n",
      "Ep:43, loss:0.00002, loss_test:0.10017, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.699, tt:866.739\n",
      "Ep:44, loss:0.00002, loss_test:0.10000, lr:8.26e-03, fs:0.74033 (r=0.677,p=0.817),  time:19.719, tt:887.338\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.09925, lr:8.26e-03, fs:0.73626 (r=0.677,p=0.807),  time:19.697, tt:906.076\n",
      "Ep:46, loss:0.00002, loss_test:0.09832, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.706, tt:926.191\n",
      "Ep:47, loss:0.00002, loss_test:0.09793, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.657, tt:943.514\n",
      "Ep:48, loss:0.00002, loss_test:0.09783, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.647, tt:962.725\n",
      "Ep:49, loss:0.00002, loss_test:0.09768, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.620, tt:980.987\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.09708, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.642, tt:1001.722\n",
      "Ep:51, loss:0.00002, loss_test:0.09646, lr:8.26e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.696, tt:1024.194\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.09624, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.683, tt:1043.218\n",
      "Ep:53, loss:0.00002, loss_test:0.09568, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.683, tt:1062.859\n",
      "Ep:54, loss:0.00001, loss_test:0.09488, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.650, tt:1080.773\n",
      "Ep:55, loss:0.00001, loss_test:0.09450, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.626, tt:1099.053\n",
      "Ep:56, loss:0.00001, loss_test:0.09400, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.599, tt:1117.153\n",
      "Ep:57, loss:0.00001, loss_test:0.09340, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.610, tt:1137.353\n",
      "Ep:58, loss:0.00001, loss_test:0.09320, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.603, tt:1156.571\n",
      "Ep:59, loss:0.00001, loss_test:0.09262, lr:8.26e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.573, tt:1174.406\n",
      "Ep:60, loss:0.00001, loss_test:0.09224, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.569, tt:1193.735\n",
      "Ep:61, loss:0.00001, loss_test:0.09172, lr:8.26e-03, fs:0.74595 (r=0.697,p=0.802),  time:19.566, tt:1213.067\n",
      "Ep:62, loss:0.00001, loss_test:0.09167, lr:8.26e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.550, tt:1231.634\n",
      "Ep:63, loss:0.00001, loss_test:0.09150, lr:8.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.542, tt:1250.717\n",
      "Ep:64, loss:0.00001, loss_test:0.09103, lr:8.10e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.545, tt:1270.424\n",
      "Ep:65, loss:0.00001, loss_test:0.09061, lr:8.02e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.540, tt:1289.651\n",
      "Ep:66, loss:0.00001, loss_test:0.09070, lr:7.94e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.546, tt:1309.593\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.09044, lr:7.94e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.533, tt:1328.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.09002, lr:7.94e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.536, tt:1348.000\n",
      "Ep:69, loss:0.00001, loss_test:0.08949, lr:7.94e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.521, tt:1366.488\n",
      "Ep:70, loss:0.00001, loss_test:0.08950, lr:7.94e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.518, tt:1385.744\n",
      "Ep:71, loss:0.00001, loss_test:0.08910, lr:7.94e-03, fs:0.75410 (r=0.697,p=0.821),  time:19.563, tt:1408.534\n",
      "Ep:72, loss:0.00001, loss_test:0.08840, lr:7.94e-03, fs:0.75410 (r=0.697,p=0.821),  time:19.550, tt:1427.175\n",
      "Ep:73, loss:0.00001, loss_test:0.08790, lr:7.94e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.569, tt:1448.110\n",
      "Ep:74, loss:0.00001, loss_test:0.08813, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.551, tt:1466.334\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.08790, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.554, tt:1486.112\n",
      "Ep:76, loss:0.00001, loss_test:0.08725, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.537, tt:1504.383\n",
      "Ep:77, loss:0.00001, loss_test:0.08660, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.545, tt:1524.534\n",
      "Ep:78, loss:0.00001, loss_test:0.08692, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.546, tt:1544.097\n",
      "Ep:79, loss:0.00001, loss_test:0.08710, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.555, tt:1564.398\n",
      "Ep:80, loss:0.00001, loss_test:0.08670, lr:7.94e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.557, tt:1584.145\n",
      "Ep:81, loss:0.00001, loss_test:0.08597, lr:7.94e-03, fs:0.76757 (r=0.717,p=0.826),  time:19.568, tt:1604.600\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.08585, lr:7.94e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.555, tt:1623.090\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.08623, lr:7.94e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.565, tt:1643.479\n",
      "Ep:84, loss:0.00001, loss_test:0.08594, lr:7.94e-03, fs:0.76923 (r=0.707,p=0.843),  time:19.537, tt:1660.678\n",
      "Ep:85, loss:0.00001, loss_test:0.08541, lr:7.94e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.532, tt:1679.768\n",
      "Ep:86, loss:0.00001, loss_test:0.08535, lr:7.94e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.526, tt:1698.785\n",
      "Ep:87, loss:0.00001, loss_test:0.08506, lr:7.94e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.524, tt:1718.093\n",
      "Ep:88, loss:0.00001, loss_test:0.08482, lr:7.94e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.501, tt:1735.555\n",
      "Ep:89, loss:0.00001, loss_test:0.08488, lr:7.94e-03, fs:0.77838 (r=0.727,p=0.837),  time:19.494, tt:1754.463\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.08462, lr:7.94e-03, fs:0.79121 (r=0.727,p=0.867),  time:19.505, tt:1774.977\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.08391, lr:7.94e-03, fs:0.79348 (r=0.737,p=0.859),  time:19.505, tt:1794.498\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.08367, lr:7.94e-03, fs:0.78495 (r=0.737,p=0.839),  time:19.518, tt:1815.172\n",
      "Ep:93, loss:0.00001, loss_test:0.08427, lr:7.94e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.529, tt:1835.765\n",
      "Ep:94, loss:0.00001, loss_test:0.08417, lr:7.94e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.549, tt:1857.176\n",
      "Ep:95, loss:0.00001, loss_test:0.08349, lr:7.94e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.560, tt:1877.802\n",
      "Ep:96, loss:0.00001, loss_test:0.08351, lr:7.94e-03, fs:0.77778 (r=0.707,p=0.864),  time:19.555, tt:1896.842\n",
      "Ep:97, loss:0.00001, loss_test:0.08361, lr:7.94e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.553, tt:1916.159\n",
      "Ep:98, loss:0.00001, loss_test:0.08322, lr:7.94e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.558, tt:1936.245\n",
      "Ep:99, loss:0.00001, loss_test:0.08326, lr:7.94e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.564, tt:1956.447\n",
      "Ep:100, loss:0.00001, loss_test:0.08289, lr:7.94e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.562, tt:1975.759\n",
      "Ep:101, loss:0.00001, loss_test:0.08263, lr:7.94e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.558, tt:1994.907\n",
      "Ep:102, loss:0.00001, loss_test:0.08333, lr:7.94e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.571, tt:2015.766\n",
      "Ep:103, loss:0.00001, loss_test:0.08331, lr:7.86e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.574, tt:2035.717\n",
      "Ep:104, loss:0.00001, loss_test:0.08293, lr:7.78e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.573, tt:2055.204\n",
      "Ep:105, loss:0.00001, loss_test:0.08337, lr:7.70e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.580, tt:2075.495\n",
      "Ep:106, loss:0.00001, loss_test:0.08351, lr:7.62e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.572, tt:2094.217\n",
      "Ep:107, loss:0.00001, loss_test:0.08275, lr:7.55e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.579, tt:2114.558\n",
      "Ep:108, loss:0.00001, loss_test:0.08357, lr:7.47e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.588, tt:2135.051\n",
      "Ep:109, loss:0.00001, loss_test:0.08363, lr:7.40e-03, fs:0.79096 (r=0.707,p=0.897),  time:19.577, tt:2153.433\n",
      "Ep:110, loss:0.00001, loss_test:0.08222, lr:7.32e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.583, tt:2173.767\n",
      "Ep:111, loss:0.00001, loss_test:0.08167, lr:7.25e-03, fs:0.76923 (r=0.707,p=0.843),  time:19.588, tt:2193.844\n",
      "Ep:112, loss:0.00001, loss_test:0.08279, lr:7.18e-03, fs:0.79096 (r=0.707,p=0.897),  time:19.599, tt:2214.696\n",
      "Ep:113, loss:0.00001, loss_test:0.08309, lr:7.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.592, tt:2233.544\n",
      "Ep:114, loss:0.00001, loss_test:0.08206, lr:7.03e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.587, tt:2252.539\n",
      "Ep:115, loss:0.00001, loss_test:0.08149, lr:6.96e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.587, tt:2272.107\n",
      "Ep:116, loss:0.00001, loss_test:0.08179, lr:6.89e-03, fs:0.79545 (r=0.707,p=0.909),  time:19.593, tt:2292.438\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.08174, lr:6.89e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.679, tt:2322.166\n",
      "Ep:118, loss:0.00001, loss_test:0.08199, lr:6.89e-03, fs:0.77778 (r=0.707,p=0.864),  time:19.683, tt:2342.265\n",
      "Ep:119, loss:0.00001, loss_test:0.08319, lr:6.89e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.685, tt:2362.172\n",
      "Ep:120, loss:0.00001, loss_test:0.08251, lr:6.89e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.685, tt:2381.875\n",
      "Ep:121, loss:0.00001, loss_test:0.08143, lr:6.89e-03, fs:0.77778 (r=0.707,p=0.864),  time:19.694, tt:2402.713\n",
      "Ep:122, loss:0.00001, loss_test:0.08291, lr:6.89e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.690, tt:2421.880\n",
      "Ep:123, loss:0.00001, loss_test:0.08308, lr:6.89e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.704, tt:2443.251\n",
      "Ep:124, loss:0.00001, loss_test:0.08210, lr:6.89e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.713, tt:2464.082\n",
      "Ep:125, loss:0.00001, loss_test:0.08277, lr:6.89e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.725, tt:2485.347\n",
      "Ep:126, loss:0.00001, loss_test:0.08306, lr:6.89e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.732, tt:2505.959\n",
      "Ep:127, loss:0.00001, loss_test:0.08267, lr:6.89e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.736, tt:2526.171\n",
      "Ep:128, loss:0.00001, loss_test:0.08303, lr:6.83e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.736, tt:2545.970\n",
      "Ep:129, loss:0.00001, loss_test:0.08266, lr:6.76e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.739, tt:2566.026\n",
      "Ep:130, loss:0.00001, loss_test:0.08242, lr:6.69e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.745, tt:2586.541\n",
      "Ep:131, loss:0.00001, loss_test:0.08278, lr:6.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.745, tt:2606.342\n",
      "Ep:132, loss:0.00001, loss_test:0.08349, lr:6.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.743, tt:2625.785\n",
      "Ep:133, loss:0.00001, loss_test:0.08286, lr:6.49e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.754, tt:2647.081\n",
      "Ep:134, loss:0.00001, loss_test:0.08194, lr:6.43e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.756, tt:2667.065\n",
      "Ep:135, loss:0.00001, loss_test:0.08353, lr:6.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.767, tt:2688.259\n",
      "Ep:136, loss:0.00001, loss_test:0.08354, lr:6.30e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.773, tt:2708.894\n",
      "Ep:137, loss:0.00000, loss_test:0.08221, lr:6.24e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.778, tt:2729.350\n",
      "Ep:138, loss:0.00000, loss_test:0.08290, lr:6.17e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.783, tt:2749.897\n",
      "Ep:139, loss:0.00000, loss_test:0.08349, lr:6.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.788, tt:2770.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.08330, lr:6.05e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.788, tt:2790.094\n",
      "Ep:141, loss:0.00000, loss_test:0.08235, lr:5.99e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.779, tt:2808.681\n",
      "Ep:142, loss:0.00000, loss_test:0.08276, lr:5.93e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.777, tt:2828.181\n",
      "Ep:143, loss:0.00000, loss_test:0.08307, lr:5.87e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.775, tt:2847.605\n",
      "Ep:144, loss:0.00000, loss_test:0.08257, lr:5.81e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.768, tt:2866.396\n",
      "Ep:145, loss:0.00000, loss_test:0.08304, lr:5.75e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.762, tt:2885.296\n",
      "Ep:146, loss:0.00000, loss_test:0.08238, lr:5.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.763, tt:2905.089\n",
      "Ep:147, loss:0.00000, loss_test:0.08246, lr:5.64e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.765, tt:2925.220\n",
      "Ep:148, loss:0.00000, loss_test:0.08315, lr:5.58e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.767, tt:2945.275\n",
      "Ep:149, loss:0.00000, loss_test:0.08237, lr:5.53e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.756, tt:2963.366\n",
      "Ep:150, loss:0.00000, loss_test:0.08217, lr:5.47e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.778, tt:2986.479\n",
      "Ep:151, loss:0.00000, loss_test:0.08358, lr:5.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.758, tt:3003.259\n",
      "Ep:152, loss:0.00000, loss_test:0.08301, lr:5.36e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.751, tt:3021.908\n",
      "Ep:153, loss:0.00000, loss_test:0.08155, lr:5.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.743, tt:3040.482\n",
      "Ep:154, loss:0.00000, loss_test:0.08338, lr:5.26e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.731, tt:3058.268\n",
      "Ep:155, loss:0.00000, loss_test:0.08385, lr:5.20e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.710, tt:3074.801\n",
      "Ep:156, loss:0.00000, loss_test:0.08273, lr:5.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.709, tt:3094.284\n",
      "Ep:157, loss:0.00000, loss_test:0.08118, lr:5.10e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.704, tt:3113.306\n",
      "Ep:158, loss:0.00000, loss_test:0.08292, lr:5.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.695, tt:3131.522\n",
      "Ep:159, loss:0.00000, loss_test:0.08372, lr:5.00e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.689, tt:3150.313\n",
      "Ep:160, loss:0.00000, loss_test:0.08287, lr:4.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.693, tt:3170.579\n",
      "Ep:161, loss:0.00000, loss_test:0.08151, lr:4.90e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.684, tt:3188.758\n",
      "Ep:162, loss:0.00000, loss_test:0.08215, lr:4.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.679, tt:3207.721\n",
      "Ep:163, loss:0.00000, loss_test:0.08309, lr:4.80e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.664, tt:3224.920\n",
      "Ep:164, loss:0.00000, loss_test:0.08259, lr:4.75e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.664, tt:3244.580\n",
      "Ep:165, loss:0.00000, loss_test:0.08164, lr:4.71e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.662, tt:3263.867\n",
      "Ep:166, loss:0.00000, loss_test:0.08177, lr:4.66e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.661, tt:3283.446\n",
      "Ep:167, loss:0.00000, loss_test:0.08247, lr:4.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.660, tt:3302.817\n",
      "Ep:168, loss:0.00000, loss_test:0.08286, lr:4.57e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.653, tt:3321.366\n",
      "Ep:169, loss:0.00000, loss_test:0.08231, lr:4.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.646, tt:3339.793\n",
      "Ep:170, loss:0.00000, loss_test:0.08145, lr:4.48e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.648, tt:3359.864\n",
      "Ep:171, loss:0.00000, loss_test:0.08248, lr:4.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.649, tt:3379.617\n",
      "Ep:172, loss:0.00000, loss_test:0.08249, lr:4.39e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.656, tt:3400.430\n",
      "Ep:173, loss:0.00000, loss_test:0.08140, lr:4.34e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.656, tt:3420.157\n",
      "Ep:174, loss:0.00000, loss_test:0.08149, lr:4.30e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.654, tt:3439.433\n",
      "Ep:175, loss:0.00000, loss_test:0.08302, lr:4.26e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.651, tt:3458.624\n",
      "Ep:176, loss:0.00000, loss_test:0.08324, lr:4.21e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.647, tt:3477.579\n",
      "Ep:177, loss:0.00000, loss_test:0.08217, lr:4.17e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.647, tt:3497.187\n",
      "Ep:178, loss:0.00000, loss_test:0.08181, lr:4.13e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.645, tt:3516.517\n",
      "Ep:179, loss:0.00000, loss_test:0.08174, lr:4.09e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.637, tt:3534.704\n",
      "Ep:180, loss:0.00000, loss_test:0.08190, lr:4.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.633, tt:3553.499\n",
      "Ep:181, loss:0.00000, loss_test:0.08210, lr:4.01e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.625, tt:3571.795\n",
      "Ep:182, loss:0.00000, loss_test:0.08249, lr:3.97e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.625, tt:3591.431\n",
      "Ep:183, loss:0.00000, loss_test:0.08235, lr:3.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.619, tt:3609.853\n",
      "Ep:184, loss:0.00000, loss_test:0.08192, lr:3.89e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.616, tt:3628.968\n",
      "Ep:185, loss:0.00000, loss_test:0.08287, lr:3.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.607, tt:3646.982\n",
      "Ep:186, loss:0.00000, loss_test:0.08275, lr:3.81e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.594, tt:3664.066\n",
      "Ep:187, loss:0.00000, loss_test:0.08180, lr:3.77e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.584, tt:3681.765\n",
      "Ep:188, loss:0.00000, loss_test:0.08168, lr:3.73e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.583, tt:3701.205\n",
      "Ep:189, loss:0.00000, loss_test:0.08236, lr:3.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.579, tt:3720.053\n",
      "Ep:190, loss:0.00000, loss_test:0.08245, lr:3.66e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.566, tt:3737.171\n",
      "Ep:191, loss:0.00000, loss_test:0.08204, lr:3.62e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.563, tt:3756.158\n",
      "Ep:192, loss:0.00000, loss_test:0.08235, lr:3.59e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.556, tt:3774.357\n",
      "Ep:193, loss:0.00000, loss_test:0.08229, lr:3.55e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.547, tt:3792.040\n",
      "Ep:194, loss:0.00000, loss_test:0.08200, lr:3.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.542, tt:3810.739\n",
      "Ep:195, loss:0.00000, loss_test:0.08273, lr:3.48e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.533, tt:3828.417\n",
      "Ep:196, loss:0.00000, loss_test:0.08276, lr:3.45e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.524, tt:3846.220\n",
      "Ep:197, loss:0.00000, loss_test:0.08223, lr:3.41e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.520, tt:3864.923\n",
      "Ep:198, loss:0.00000, loss_test:0.08215, lr:3.38e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.520, tt:3884.558\n",
      "Ep:199, loss:0.00000, loss_test:0.08195, lr:3.34e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.519, tt:3903.725\n",
      "Ep:200, loss:0.00000, loss_test:0.08215, lr:3.31e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.516, tt:3922.676\n",
      "Ep:201, loss:0.00000, loss_test:0.08306, lr:3.28e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.511, tt:3941.191\n",
      "Ep:202, loss:0.00000, loss_test:0.08320, lr:3.24e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.508, tt:3960.022\n",
      "Ep:203, loss:0.00000, loss_test:0.08300, lr:3.21e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.494, tt:3976.737\n",
      "Ep:204, loss:0.00000, loss_test:0.08246, lr:3.18e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.486, tt:3994.683\n",
      "Ep:205, loss:0.00000, loss_test:0.08246, lr:3.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.481, tt:4013.179\n",
      "Ep:206, loss:0.00000, loss_test:0.08249, lr:3.12e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.473, tt:4030.974\n",
      "Ep:207, loss:0.00000, loss_test:0.08254, lr:3.09e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.469, tt:4049.479\n",
      "Ep:208, loss:0.00000, loss_test:0.08289, lr:3.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.467, tt:4068.609\n",
      "Ep:209, loss:0.00000, loss_test:0.08287, lr:3.02e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.462, tt:4086.916\n",
      "Ep:210, loss:0.00000, loss_test:0.08260, lr:2.99e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.466, tt:4107.243\n",
      "Ep:211, loss:0.00000, loss_test:0.08293, lr:2.96e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.463, tt:4126.226\n",
      "Ep:212, loss:0.00000, loss_test:0.08283, lr:2.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.461, tt:4145.142\n",
      "Ep:213, loss:0.00000, loss_test:0.08257, lr:2.90e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.458, tt:4164.081\n",
      "Ep:214, loss:0.00000, loss_test:0.08269, lr:2.88e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.461, tt:4184.127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:215, loss:0.00000, loss_test:0.08368, lr:2.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.481, tt:4207.896\n",
      "Ep:216, loss:0.00000, loss_test:0.08399, lr:2.82e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.478, tt:4226.626\n",
      "Ep:217, loss:0.00000, loss_test:0.08364, lr:2.79e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.478, tt:4246.247\n",
      "Ep:218, loss:0.00000, loss_test:0.08288, lr:2.76e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.473, tt:4264.507\n",
      "Ep:219, loss:0.00000, loss_test:0.08272, lr:2.73e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.468, tt:4282.963\n",
      "Ep:220, loss:0.00000, loss_test:0.08334, lr:2.71e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.467, tt:4302.178\n",
      "Ep:221, loss:0.00000, loss_test:0.08350, lr:2.68e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.468, tt:4321.860\n",
      "Ep:222, loss:0.00000, loss_test:0.08321, lr:2.65e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.465, tt:4340.647\n",
      "Ep:223, loss:0.00000, loss_test:0.08267, lr:2.63e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.467, tt:4360.634\n",
      "Ep:224, loss:0.00000, loss_test:0.08284, lr:2.60e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.467, tt:4380.122\n",
      "Ep:225, loss:0.00000, loss_test:0.08352, lr:2.57e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.463, tt:4398.617\n",
      "Ep:226, loss:0.00000, loss_test:0.08375, lr:2.55e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.462, tt:4417.957\n",
      "Ep:227, loss:0.00000, loss_test:0.08346, lr:2.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.463, tt:4437.645\n",
      "Ep:228, loss:0.00000, loss_test:0.08285, lr:2.50e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.464, tt:4457.304\n",
      "Ep:229, loss:0.00000, loss_test:0.08269, lr:2.47e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.468, tt:4477.595\n",
      "Ep:230, loss:0.00000, loss_test:0.08312, lr:2.45e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.467, tt:4496.778\n",
      "Ep:231, loss:0.00000, loss_test:0.08331, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.465, tt:4515.994\n",
      "Ep:232, loss:0.00000, loss_test:0.08318, lr:2.40e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.465, tt:4535.290\n",
      "Ep:233, loss:0.00000, loss_test:0.08284, lr:2.38e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.462, tt:4554.071\n",
      "Ep:234, loss:0.00000, loss_test:0.08314, lr:2.35e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.465, tt:4574.166\n",
      "Ep:235, loss:0.00000, loss_test:0.08329, lr:2.33e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.470, tt:4594.832\n",
      "Ep:236, loss:0.00000, loss_test:0.08314, lr:2.31e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.468, tt:4613.839\n",
      "Ep:237, loss:0.00000, loss_test:0.08286, lr:2.28e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.465, tt:4632.671\n",
      "Ep:238, loss:0.00000, loss_test:0.08294, lr:2.26e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.469, tt:4652.986\n",
      "Ep:239, loss:0.00000, loss_test:0.08354, lr:2.24e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.470, tt:4672.905\n",
      "Ep:240, loss:0.00000, loss_test:0.08376, lr:2.21e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.473, tt:4693.051\n",
      "Ep:241, loss:0.00000, loss_test:0.08361, lr:2.19e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.472, tt:4712.281\n",
      "Ep:242, loss:0.00000, loss_test:0.08314, lr:2.17e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.471, tt:4731.555\n",
      "Ep:243, loss:0.00000, loss_test:0.08305, lr:2.15e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.473, tt:4751.502\n",
      "Ep:244, loss:0.00000, loss_test:0.08319, lr:2.13e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.465, tt:4769.034\n",
      "Ep:245, loss:0.00000, loss_test:0.08328, lr:2.11e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.467, tt:4788.897\n",
      "Ep:246, loss:0.00000, loss_test:0.08332, lr:2.08e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.467, tt:4808.351\n",
      "Ep:247, loss:0.00000, loss_test:0.08315, lr:2.06e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.467, tt:4827.846\n",
      "Ep:248, loss:0.00000, loss_test:0.08303, lr:2.04e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.475, tt:4849.397\n",
      "Ep:249, loss:0.00000, loss_test:0.08297, lr:2.02e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.476, tt:4869.044\n",
      "Ep:250, loss:0.00000, loss_test:0.08294, lr:2.00e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.480, tt:4889.510\n",
      "Ep:251, loss:0.00000, loss_test:0.08336, lr:1.98e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.480, tt:4908.880\n",
      "Ep:252, loss:0.00000, loss_test:0.08336, lr:1.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.480, tt:4928.364\n",
      "Ep:253, loss:0.00000, loss_test:0.08298, lr:1.94e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.481, tt:4948.203\n",
      "Ep:254, loss:0.00000, loss_test:0.08272, lr:1.92e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.504, tt:4973.422\n",
      "Ep:255, loss:0.00000, loss_test:0.08339, lr:1.90e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.499, tt:4991.794\n",
      "Ep:256, loss:0.00000, loss_test:0.08370, lr:1.89e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.495, tt:5010.254\n",
      "Ep:257, loss:0.00000, loss_test:0.08354, lr:1.87e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.495, tt:5029.749\n",
      "Ep:258, loss:0.00000, loss_test:0.08302, lr:1.85e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.492, tt:5048.392\n",
      "Ep:259, loss:0.00000, loss_test:0.08279, lr:1.83e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.491, tt:5067.707\n",
      "Ep:260, loss:0.00000, loss_test:0.08352, lr:1.81e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.489, tt:5086.577\n",
      "Ep:261, loss:0.00000, loss_test:0.08389, lr:1.79e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.493, tt:5107.256\n",
      "Ep:262, loss:0.00000, loss_test:0.08381, lr:1.78e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.497, tt:5127.778\n",
      "Ep:263, loss:0.00000, loss_test:0.08336, lr:1.76e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.499, tt:5147.653\n",
      "Ep:264, loss:0.00000, loss_test:0.08299, lr:1.74e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.499, tt:5167.327\n",
      "Ep:265, loss:0.00000, loss_test:0.08326, lr:1.72e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.498, tt:5186.396\n",
      "Ep:266, loss:0.00000, loss_test:0.08361, lr:1.71e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.498, tt:5206.023\n",
      "Ep:267, loss:0.00000, loss_test:0.08362, lr:1.69e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.497, tt:5225.204\n",
      "Ep:268, loss:0.00000, loss_test:0.08328, lr:1.67e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.503, tt:5246.335\n",
      "Ep:269, loss:0.00000, loss_test:0.08287, lr:1.65e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.505, tt:5266.398\n",
      "Ep:270, loss:0.00000, loss_test:0.08284, lr:1.64e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.511, tt:5287.555\n",
      "Ep:271, loss:0.00000, loss_test:0.08346, lr:1.62e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.513, tt:5307.532\n",
      "Ep:272, loss:0.00000, loss_test:0.08376, lr:1.61e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.514, tt:5327.226\n",
      "Ep:273, loss:0.00000, loss_test:0.08362, lr:1.59e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.514, tt:5346.901\n",
      "Ep:274, loss:0.00000, loss_test:0.08313, lr:1.57e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.518, tt:5367.485\n",
      "Ep:275, loss:0.00000, loss_test:0.08259, lr:1.56e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.522, tt:5388.169\n",
      "Ep:276, loss:0.00000, loss_test:0.08276, lr:1.54e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.525, tt:5408.452\n",
      "Ep:277, loss:0.00000, loss_test:0.08323, lr:1.53e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.528, tt:5428.730\n",
      "Ep:278, loss:0.00000, loss_test:0.08342, lr:1.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.531, tt:5449.133\n",
      "Ep:279, loss:0.00000, loss_test:0.08329, lr:1.50e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.530, tt:5468.326\n",
      "Ep:280, loss:0.00000, loss_test:0.08301, lr:1.48e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.528, tt:5487.488\n",
      "Ep:281, loss:0.00000, loss_test:0.08289, lr:1.47e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.526, tt:5506.419\n",
      "Ep:282, loss:0.00000, loss_test:0.08293, lr:1.45e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.521, tt:5524.390\n",
      "Ep:283, loss:0.00000, loss_test:0.08302, lr:1.44e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.524, tt:5544.890\n",
      "Ep:284, loss:0.00000, loss_test:0.08309, lr:1.42e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.527, tt:5565.152\n",
      "Ep:285, loss:0.00000, loss_test:0.08318, lr:1.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.530, tt:5585.632\n",
      "Ep:286, loss:0.00000, loss_test:0.08316, lr:1.39e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.529, tt:5604.962\n",
      "Ep:287, loss:0.00000, loss_test:0.08310, lr:1.38e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.528, tt:5624.177\n",
      "Ep:288, loss:0.00000, loss_test:0.08291, lr:1.37e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.528, tt:5643.595\n",
      "Ep:289, loss:0.00000, loss_test:0.08297, lr:1.35e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.528, tt:5663.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:290, loss:0.00000, loss_test:0.08315, lr:1.34e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.532, tt:5683.839\n",
      "Ep:291, loss:0.00000, loss_test:0.08311, lr:1.33e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.537, tt:5704.734\n",
      "Ep:292, loss:0.00000, loss_test:0.08297, lr:1.31e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.540, tt:5725.096\n",
      "Ep:293, loss:0.00000, loss_test:0.08303, lr:1.30e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.547, tt:5746.763\n",
      "Ep:294, loss:0.00000, loss_test:0.08309, lr:1.29e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.549, tt:5766.862\n",
      "Ep:295, loss:0.00000, loss_test:0.08300, lr:1.27e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.540, tt:5783.787\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13667, lr:1.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:10.812, tt:10.812\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13577, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:13.503, tt:27.005\n",
      "Ep:2, loss:0.00004, loss_test:0.13439, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:14.826, tt:44.477\n",
      "Ep:3, loss:0.00004, loss_test:0.13257, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:15.301, tt:61.205\n",
      "Ep:4, loss:0.00004, loss_test:0.13065, lr:1.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:15.366, tt:76.829\n",
      "Ep:5, loss:0.00004, loss_test:0.12944, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:15.767, tt:94.600\n",
      "Ep:6, loss:0.00004, loss_test:0.12880, lr:1.00e-02, fs:0.66939 (r=0.828,p=0.562),  time:16.040, tt:112.282\n",
      "Ep:7, loss:0.00004, loss_test:0.12885, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:16.212, tt:129.693\n",
      "Ep:8, loss:0.00003, loss_test:0.12957, lr:1.00e-02, fs:0.63348 (r=0.707,p=0.574),  time:16.336, tt:147.027\n",
      "Ep:9, loss:0.00003, loss_test:0.13011, lr:1.00e-02, fs:0.60185 (r=0.657,p=0.556),  time:16.429, tt:164.294\n",
      "Ep:10, loss:0.00003, loss_test:0.13048, lr:1.00e-02, fs:0.59813 (r=0.646,p=0.557),  time:16.399, tt:180.385\n",
      "Ep:11, loss:0.00003, loss_test:0.13047, lr:1.00e-02, fs:0.60377 (r=0.646,p=0.566),  time:16.452, tt:197.426\n",
      "Ep:12, loss:0.00003, loss_test:0.13022, lr:9.90e-03, fs:0.60287 (r=0.636,p=0.573),  time:16.481, tt:214.254\n",
      "Ep:13, loss:0.00003, loss_test:0.12958, lr:9.80e-03, fs:0.60952 (r=0.646,p=0.577),  time:16.599, tt:232.389\n",
      "Ep:14, loss:0.00003, loss_test:0.12879, lr:9.70e-03, fs:0.60664 (r=0.646,p=0.571),  time:16.657, tt:249.862\n",
      "Ep:15, loss:0.00003, loss_test:0.12792, lr:9.61e-03, fs:0.61244 (r=0.646,p=0.582),  time:16.658, tt:266.529\n",
      "Ep:16, loss:0.00003, loss_test:0.12716, lr:9.51e-03, fs:0.62745 (r=0.646,p=0.610),  time:16.746, tt:284.686\n",
      "Ep:17, loss:0.00003, loss_test:0.12642, lr:9.41e-03, fs:0.61386 (r=0.626,p=0.602),  time:16.827, tt:302.882\n",
      "Ep:18, loss:0.00003, loss_test:0.12572, lr:9.32e-03, fs:0.62944 (r=0.626,p=0.633),  time:16.836, tt:319.893\n",
      "Ep:19, loss:0.00003, loss_test:0.12491, lr:9.23e-03, fs:0.62564 (r=0.616,p=0.635),  time:16.830, tt:336.592\n",
      "Ep:20, loss:0.00003, loss_test:0.12421, lr:9.14e-03, fs:0.61538 (r=0.606,p=0.625),  time:16.904, tt:354.988\n",
      "Ep:21, loss:0.00003, loss_test:0.12375, lr:9.04e-03, fs:0.61856 (r=0.606,p=0.632),  time:16.950, tt:372.903\n",
      "Ep:22, loss:0.00003, loss_test:0.12334, lr:8.95e-03, fs:0.61780 (r=0.596,p=0.641),  time:17.028, tt:391.638\n",
      "Ep:23, loss:0.00003, loss_test:0.12284, lr:8.86e-03, fs:0.62434 (r=0.596,p=0.656),  time:17.087, tt:410.085\n",
      "Ep:24, loss:0.00003, loss_test:0.12225, lr:8.78e-03, fs:0.61290 (r=0.576,p=0.655),  time:17.115, tt:427.884\n",
      "Ep:25, loss:0.00003, loss_test:0.12127, lr:8.69e-03, fs:0.61290 (r=0.576,p=0.655),  time:17.215, tt:447.600\n",
      "Ep:26, loss:0.00003, loss_test:0.12022, lr:8.60e-03, fs:0.61290 (r=0.576,p=0.655),  time:17.249, tt:465.718\n",
      "Ep:27, loss:0.00003, loss_test:0.11926, lr:8.51e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.318, tt:484.903\n",
      "Ep:28, loss:0.00003, loss_test:0.11832, lr:8.43e-03, fs:0.60638 (r=0.576,p=0.640),  time:17.356, tt:503.334\n",
      "Ep:29, loss:0.00002, loss_test:0.11760, lr:8.35e-03, fs:0.60638 (r=0.576,p=0.640),  time:17.407, tt:522.222\n",
      "Ep:30, loss:0.00002, loss_test:0.11691, lr:8.26e-03, fs:0.59893 (r=0.566,p=0.636),  time:17.462, tt:541.320\n",
      "Ep:31, loss:0.00002, loss_test:0.11616, lr:8.18e-03, fs:0.60215 (r=0.566,p=0.644),  time:17.466, tt:558.914\n",
      "Ep:32, loss:0.00002, loss_test:0.11538, lr:8.10e-03, fs:0.60215 (r=0.566,p=0.644),  time:17.472, tt:576.562\n",
      "Ep:33, loss:0.00002, loss_test:0.11443, lr:8.02e-03, fs:0.61376 (r=0.586,p=0.644),  time:17.490, tt:594.654\n",
      "Ep:34, loss:0.00002, loss_test:0.11336, lr:7.94e-03, fs:0.62827 (r=0.606,p=0.652),  time:17.505, tt:612.666\n",
      "Ep:35, loss:0.00002, loss_test:0.11226, lr:7.86e-03, fs:0.63492 (r=0.606,p=0.667),  time:17.542, tt:631.526\n",
      "Ep:36, loss:0.00002, loss_test:0.11124, lr:7.78e-03, fs:0.63784 (r=0.596,p=0.686),  time:17.574, tt:650.245\n",
      "Ep:37, loss:0.00002, loss_test:0.11036, lr:7.70e-03, fs:0.63784 (r=0.596,p=0.686),  time:17.599, tt:668.772\n",
      "Ep:38, loss:0.00002, loss_test:0.10966, lr:7.62e-03, fs:0.64516 (r=0.606,p=0.690),  time:17.612, tt:686.882\n",
      "Ep:39, loss:0.00002, loss_test:0.10911, lr:7.55e-03, fs:0.64171 (r=0.606,p=0.682),  time:17.616, tt:704.654\n",
      "Ep:40, loss:0.00002, loss_test:0.10880, lr:7.47e-03, fs:0.64894 (r=0.616,p=0.685),  time:17.657, tt:723.946\n",
      "Ep:41, loss:0.00002, loss_test:0.10873, lr:7.40e-03, fs:0.64865 (r=0.606,p=0.698),  time:17.678, tt:742.465\n",
      "Ep:42, loss:0.00002, loss_test:0.10869, lr:7.32e-03, fs:0.64481 (r=0.596,p=0.702),  time:17.708, tt:761.444\n",
      "Ep:43, loss:0.00002, loss_test:0.10854, lr:7.25e-03, fs:0.65574 (r=0.606,p=0.714),  time:17.725, tt:779.901\n",
      "Ep:44, loss:0.00002, loss_test:0.10822, lr:7.18e-03, fs:0.67742 (r=0.636,p=0.724),  time:17.742, tt:798.372\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.10766, lr:7.18e-03, fs:0.68449 (r=0.646,p=0.727),  time:17.756, tt:816.764\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.10705, lr:7.18e-03, fs:0.68817 (r=0.646,p=0.736),  time:17.775, tt:835.404\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.10653, lr:7.18e-03, fs:0.69189 (r=0.646,p=0.744),  time:17.799, tt:854.342\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.10604, lr:7.18e-03, fs:0.68478 (r=0.636,p=0.741),  time:17.829, tt:873.643\n",
      "Ep:49, loss:0.00002, loss_test:0.10531, lr:7.18e-03, fs:0.68817 (r=0.646,p=0.736),  time:17.867, tt:893.366\n",
      "Ep:50, loss:0.00002, loss_test:0.10453, lr:7.18e-03, fs:0.68817 (r=0.646,p=0.736),  time:17.894, tt:912.613\n",
      "Ep:51, loss:0.00002, loss_test:0.10390, lr:7.18e-03, fs:0.68478 (r=0.636,p=0.741),  time:17.892, tt:930.376\n",
      "Ep:52, loss:0.00002, loss_test:0.10342, lr:7.18e-03, fs:0.69231 (r=0.636,p=0.759),  time:17.934, tt:950.480\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.10262, lr:7.18e-03, fs:0.69945 (r=0.646,p=0.762),  time:17.943, tt:968.932\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.10196, lr:7.18e-03, fs:0.70652 (r=0.657,p=0.765),  time:17.966, tt:988.112\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.10164, lr:7.18e-03, fs:0.70652 (r=0.657,p=0.765),  time:17.980, tt:1006.866\n",
      "Ep:56, loss:0.00002, loss_test:0.10127, lr:7.18e-03, fs:0.72043 (r=0.677,p=0.770),  time:17.951, tt:1023.234\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.10050, lr:7.18e-03, fs:0.72043 (r=0.677,p=0.770),  time:17.939, tt:1040.443\n",
      "Ep:58, loss:0.00002, loss_test:0.09980, lr:7.18e-03, fs:0.72727 (r=0.687,p=0.773),  time:17.952, tt:1059.194\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.09936, lr:7.18e-03, fs:0.73404 (r=0.697,p=0.775),  time:17.946, tt:1076.753\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.09882, lr:7.18e-03, fs:0.73797 (r=0.697,p=0.784),  time:17.971, tt:1096.247\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00002, loss_test:0.09800, lr:7.18e-03, fs:0.74468 (r=0.707,p=0.787),  time:18.012, tt:1116.741\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.09741, lr:7.18e-03, fs:0.74468 (r=0.707,p=0.787),  time:18.012, tt:1134.756\n",
      "Ep:63, loss:0.00001, loss_test:0.09705, lr:7.18e-03, fs:0.74866 (r=0.707,p=0.795),  time:18.008, tt:1152.544\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.09660, lr:7.18e-03, fs:0.74866 (r=0.707,p=0.795),  time:18.017, tt:1171.078\n",
      "Ep:65, loss:0.00001, loss_test:0.09606, lr:7.18e-03, fs:0.74194 (r=0.697,p=0.793),  time:18.013, tt:1188.878\n",
      "Ep:66, loss:0.00001, loss_test:0.09561, lr:7.18e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.018, tt:1207.220\n",
      "Ep:67, loss:0.00001, loss_test:0.09511, lr:7.18e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.024, tt:1225.602\n",
      "Ep:68, loss:0.00001, loss_test:0.09461, lr:7.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:18.024, tt:1243.625\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09441, lr:7.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:18.024, tt:1261.711\n",
      "Ep:70, loss:0.00001, loss_test:0.09431, lr:7.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:18.034, tt:1280.399\n",
      "Ep:71, loss:0.00001, loss_test:0.09394, lr:7.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:18.022, tt:1297.575\n",
      "Ep:72, loss:0.00001, loss_test:0.09408, lr:7.18e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.012, tt:1314.907\n",
      "Ep:73, loss:0.00001, loss_test:0.09386, lr:7.18e-03, fs:0.75000 (r=0.697,p=0.812),  time:18.012, tt:1332.854\n",
      "Ep:74, loss:0.00001, loss_test:0.09315, lr:7.18e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.010, tt:1350.731\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.09324, lr:7.18e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.024, tt:1369.812\n",
      "Ep:76, loss:0.00001, loss_test:0.09267, lr:7.18e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.021, tt:1387.596\n",
      "Ep:77, loss:0.00001, loss_test:0.09234, lr:7.18e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.022, tt:1405.685\n",
      "Ep:78, loss:0.00001, loss_test:0.09296, lr:7.18e-03, fs:0.74033 (r=0.677,p=0.817),  time:18.025, tt:1423.969\n",
      "Ep:79, loss:0.00001, loss_test:0.09266, lr:7.18e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.027, tt:1442.132\n",
      "Ep:80, loss:0.00001, loss_test:0.09192, lr:7.18e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.034, tt:1460.763\n",
      "Ep:81, loss:0.00001, loss_test:0.09320, lr:7.18e-03, fs:0.75556 (r=0.687,p=0.840),  time:18.035, tt:1478.834\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.09272, lr:7.18e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.032, tt:1496.672\n",
      "Ep:83, loss:0.00001, loss_test:0.09135, lr:7.18e-03, fs:0.76087 (r=0.707,p=0.824),  time:18.035, tt:1514.982\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.09320, lr:7.18e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.053, tt:1534.493\n",
      "Ep:85, loss:0.00001, loss_test:0.09267, lr:7.18e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.065, tt:1553.628\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.09068, lr:7.18e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.079, tt:1572.833\n",
      "Ep:87, loss:0.00001, loss_test:0.09158, lr:7.18e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.070, tt:1590.136\n",
      "Ep:88, loss:0.00001, loss_test:0.09286, lr:7.18e-03, fs:0.75281 (r=0.677,p=0.848),  time:18.063, tt:1607.572\n",
      "Ep:89, loss:0.00001, loss_test:0.09143, lr:7.18e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.059, tt:1625.280\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.09076, lr:7.18e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.061, tt:1643.576\n",
      "Ep:91, loss:0.00001, loss_test:0.09169, lr:7.18e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.067, tt:1662.123\n",
      "Ep:92, loss:0.00001, loss_test:0.09181, lr:7.18e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.070, tt:1680.529\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.09062, lr:7.18e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.068, tt:1698.393\n",
      "Ep:94, loss:0.00001, loss_test:0.09163, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.063, tt:1716.028\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.09211, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.062, tt:1733.920\n",
      "Ep:96, loss:0.00001, loss_test:0.08982, lr:7.18e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.062, tt:1752.055\n",
      "Ep:97, loss:0.00001, loss_test:0.09150, lr:7.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.058, tt:1769.667\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.09063, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.048, tt:1786.796\n",
      "Ep:99, loss:0.00001, loss_test:0.08975, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.042, tt:1804.195\n",
      "Ep:100, loss:0.00001, loss_test:0.09112, lr:7.18e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.037, tt:1821.747\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.08999, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.036, tt:1839.718\n",
      "Ep:102, loss:0.00001, loss_test:0.08992, lr:7.18e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.031, tt:1857.153\n",
      "Ep:103, loss:0.00001, loss_test:0.09034, lr:7.18e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.016, tt:1873.692\n",
      "Ep:104, loss:0.00001, loss_test:0.08882, lr:7.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.005, tt:1890.539\n",
      "Ep:105, loss:0.00001, loss_test:0.08918, lr:7.18e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.003, tt:1908.285\n",
      "Ep:106, loss:0.00001, loss_test:0.08913, lr:7.18e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.001, tt:1926.076\n",
      "Ep:107, loss:0.00001, loss_test:0.08812, lr:7.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.008, tt:1944.859\n",
      "Ep:108, loss:0.00001, loss_test:0.08922, lr:7.18e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.004, tt:1962.443\n",
      "Ep:109, loss:0.00001, loss_test:0.08769, lr:7.18e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.996, tt:1979.545\n",
      "Ep:110, loss:0.00001, loss_test:0.08811, lr:7.18e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.996, tt:1997.537\n",
      "Ep:111, loss:0.00001, loss_test:0.08893, lr:7.18e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.996, tt:2015.604\n",
      "Ep:112, loss:0.00001, loss_test:0.08664, lr:7.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:17.978, tt:2031.519\n",
      "Ep:113, loss:0.00001, loss_test:0.09018, lr:7.03e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.988, tt:2050.661\n",
      "Ep:114, loss:0.00001, loss_test:0.08805, lr:6.96e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.987, tt:2068.531\n",
      "Ep:115, loss:0.00001, loss_test:0.08630, lr:6.89e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.977, tt:2085.301\n",
      "Ep:116, loss:0.00001, loss_test:0.09189, lr:6.83e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.976, tt:2103.183\n",
      "Ep:117, loss:0.00001, loss_test:0.08988, lr:6.76e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.969, tt:2120.382\n",
      "Ep:118, loss:0.00001, loss_test:0.08507, lr:6.69e-03, fs:0.76136 (r=0.677,p=0.870),  time:17.966, tt:2137.956\n",
      "Ep:119, loss:0.00001, loss_test:0.09139, lr:6.62e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.968, tt:2156.121\n",
      "Ep:120, loss:0.00001, loss_test:0.09112, lr:6.56e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.971, tt:2174.473\n",
      "Ep:121, loss:0.00001, loss_test:0.08635, lr:6.49e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.970, tt:2192.367\n",
      "Ep:122, loss:0.00001, loss_test:0.08894, lr:6.43e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.980, tt:2211.518\n",
      "Ep:123, loss:0.00001, loss_test:0.09012, lr:6.36e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.973, tt:2228.661\n",
      "Ep:124, loss:0.00001, loss_test:0.08768, lr:6.30e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.969, tt:2246.079\n",
      "Ep:125, loss:0.00001, loss_test:0.08591, lr:6.24e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.969, tt:2264.132\n",
      "Ep:126, loss:0.00001, loss_test:0.09071, lr:6.17e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.979, tt:2283.359\n",
      "Ep:127, loss:0.00001, loss_test:0.09027, lr:6.11e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.983, tt:2301.841\n",
      "Ep:128, loss:0.00001, loss_test:0.08569, lr:6.05e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.988, tt:2320.402\n",
      "Ep:129, loss:0.00001, loss_test:0.08755, lr:5.99e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.990, tt:2338.724\n",
      "Ep:130, loss:0.00001, loss_test:0.08860, lr:5.93e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.989, tt:2356.545\n",
      "Ep:131, loss:0.00001, loss_test:0.08687, lr:5.87e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.988, tt:2374.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.08558, lr:5.81e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.984, tt:2391.924\n",
      "Ep:133, loss:0.00001, loss_test:0.08830, lr:5.75e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.985, tt:2410.011\n",
      "Ep:134, loss:0.00001, loss_test:0.08830, lr:5.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.984, tt:2427.802\n",
      "Ep:135, loss:0.00001, loss_test:0.08600, lr:5.64e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.986, tt:2446.111\n",
      "Ep:136, loss:0.00001, loss_test:0.08619, lr:5.58e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.985, tt:2463.918\n",
      "Ep:137, loss:0.00001, loss_test:0.08825, lr:5.53e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.988, tt:2482.312\n",
      "Ep:138, loss:0.00001, loss_test:0.08694, lr:5.47e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.979, tt:2499.133\n",
      "Ep:139, loss:0.00001, loss_test:0.08507, lr:5.42e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.977, tt:2516.728\n",
      "Ep:140, loss:0.00001, loss_test:0.08771, lr:5.36e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.976, tt:2534.578\n",
      "Ep:141, loss:0.00001, loss_test:0.08791, lr:5.31e-03, fs:0.77011 (r=0.677,p=0.893),  time:17.985, tt:2553.819\n",
      "Ep:142, loss:0.00001, loss_test:0.08523, lr:5.26e-03, fs:0.76571 (r=0.677,p=0.882),  time:17.986, tt:2572.053\n",
      "Ep:143, loss:0.00001, loss_test:0.08721, lr:5.20e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.005, tt:2592.713\n",
      "Ep:144, loss:0.00001, loss_test:0.08791, lr:5.15e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.007, tt:2611.041\n",
      "Ep:145, loss:0.00001, loss_test:0.08532, lr:5.10e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.007, tt:2629.083\n",
      "Ep:146, loss:0.00001, loss_test:0.08522, lr:5.05e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.016, tt:2648.339\n",
      "Ep:147, loss:0.00001, loss_test:0.08773, lr:5.00e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.027, tt:2668.065\n",
      "Ep:148, loss:0.00001, loss_test:0.08693, lr:4.95e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.034, tt:2687.128\n",
      "Ep:149, loss:0.00001, loss_test:0.08556, lr:4.90e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.046, tt:2706.915\n",
      "Ep:150, loss:0.00001, loss_test:0.08711, lr:4.85e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.051, tt:2725.748\n",
      "Ep:151, loss:0.00001, loss_test:0.08653, lr:4.80e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.062, tt:2745.387\n",
      "Ep:152, loss:0.00001, loss_test:0.08458, lr:4.75e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.069, tt:2764.594\n",
      "Ep:153, loss:0.00001, loss_test:0.08770, lr:4.71e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.073, tt:2783.257\n",
      "Ep:154, loss:0.00001, loss_test:0.08742, lr:4.66e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.075, tt:2801.629\n",
      "Ep:155, loss:0.00001, loss_test:0.08409, lr:4.61e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.079, tt:2820.317\n",
      "Ep:156, loss:0.00001, loss_test:0.08643, lr:4.57e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.080, tt:2838.603\n",
      "Ep:157, loss:0.00001, loss_test:0.08749, lr:4.52e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.083, tt:2857.037\n",
      "Ep:158, loss:0.00001, loss_test:0.08560, lr:4.48e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.090, tt:2876.232\n",
      "Ep:159, loss:0.00001, loss_test:0.08514, lr:4.43e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.094, tt:2895.035\n",
      "Ep:160, loss:0.00001, loss_test:0.08691, lr:4.39e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.094, tt:2913.055\n",
      "Ep:161, loss:0.00001, loss_test:0.08612, lr:4.34e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.100, tt:2932.223\n",
      "Ep:162, loss:0.00000, loss_test:0.08380, lr:4.30e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.110, tt:2951.998\n",
      "Ep:163, loss:0.00001, loss_test:0.08704, lr:4.26e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.120, tt:2971.697\n",
      "Ep:164, loss:0.00000, loss_test:0.08740, lr:4.21e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.132, tt:2991.835\n",
      "Ep:165, loss:0.00000, loss_test:0.08480, lr:4.17e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.139, tt:3011.139\n",
      "Ep:166, loss:0.00000, loss_test:0.08571, lr:4.13e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.149, tt:3030.813\n",
      "Ep:167, loss:0.00000, loss_test:0.08664, lr:4.09e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.157, tt:3050.305\n",
      "Ep:168, loss:0.00000, loss_test:0.08579, lr:4.05e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.171, tt:3070.835\n",
      "Ep:169, loss:0.00000, loss_test:0.08536, lr:4.01e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.180, tt:3090.558\n",
      "Ep:170, loss:0.00000, loss_test:0.08773, lr:3.97e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.190, tt:3110.533\n",
      "Ep:171, loss:0.00000, loss_test:0.08699, lr:3.93e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.198, tt:3129.977\n",
      "Ep:172, loss:0.00000, loss_test:0.08434, lr:3.89e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.206, tt:3149.640\n",
      "Ep:173, loss:0.00000, loss_test:0.08593, lr:3.85e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.217, tt:3169.728\n",
      "Ep:174, loss:0.00000, loss_test:0.08661, lr:3.81e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.225, tt:3189.382\n",
      "Ep:175, loss:0.00000, loss_test:0.08575, lr:3.77e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.227, tt:3207.903\n",
      "Ep:176, loss:0.00000, loss_test:0.08558, lr:3.73e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.231, tt:3226.893\n",
      "Ep:177, loss:0.00000, loss_test:0.08631, lr:3.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.239, tt:3246.566\n",
      "Ep:178, loss:0.00000, loss_test:0.08623, lr:3.66e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.247, tt:3266.237\n",
      "Ep:179, loss:0.00000, loss_test:0.08594, lr:3.62e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.249, tt:3284.900\n",
      "Ep:180, loss:0.00000, loss_test:0.08613, lr:3.59e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.250, tt:3303.284\n",
      "Ep:181, loss:0.00000, loss_test:0.08585, lr:3.55e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.256, tt:3322.511\n",
      "Ep:182, loss:0.00000, loss_test:0.08550, lr:3.52e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.259, tt:3341.454\n",
      "Ep:183, loss:0.00000, loss_test:0.08619, lr:3.48e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.265, tt:3360.733\n",
      "Ep:184, loss:0.00000, loss_test:0.08617, lr:3.45e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.271, tt:3380.095\n",
      "Ep:185, loss:0.00000, loss_test:0.08550, lr:3.41e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.276, tt:3399.302\n",
      "Ep:186, loss:0.00000, loss_test:0.08702, lr:3.38e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.280, tt:3418.437\n",
      "Ep:187, loss:0.00000, loss_test:0.08679, lr:3.34e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.285, tt:3437.621\n",
      "Ep:188, loss:0.00000, loss_test:0.08533, lr:3.31e-03, fs:0.74419 (r=0.646,p=0.877),  time:18.289, tt:3456.610\n",
      "Ep:189, loss:0.00000, loss_test:0.08744, lr:3.28e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.295, tt:3476.016\n",
      "Ep:190, loss:0.00000, loss_test:0.08715, lr:3.24e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.295, tt:3494.437\n",
      "Ep:191, loss:0.00000, loss_test:0.08505, lr:3.21e-03, fs:0.74419 (r=0.646,p=0.877),  time:18.301, tt:3513.786\n",
      "Ep:192, loss:0.00000, loss_test:0.08618, lr:3.18e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.316, tt:3534.993\n",
      "Ep:193, loss:0.00000, loss_test:0.08699, lr:3.15e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.322, tt:3554.472\n",
      "Ep:194, loss:0.00000, loss_test:0.08630, lr:3.12e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.322, tt:3572.773\n",
      "Ep:195, loss:0.00000, loss_test:0.08544, lr:3.09e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.323, tt:3591.370\n",
      "Ep:196, loss:0.00000, loss_test:0.08683, lr:3.05e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.331, tt:3611.181\n",
      "Ep:197, loss:0.00000, loss_test:0.08711, lr:3.02e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.342, tt:3631.741\n",
      "Ep:198, loss:0.00000, loss_test:0.08591, lr:2.99e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.346, tt:3650.755\n",
      "Ep:199, loss:0.00000, loss_test:0.08538, lr:2.96e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.348, tt:3669.573\n",
      "Ep:200, loss:0.00000, loss_test:0.08760, lr:2.93e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.355, tt:3689.353\n",
      "Ep:201, loss:0.00000, loss_test:0.08788, lr:2.90e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.358, tt:3708.268\n",
      "Ep:202, loss:0.00000, loss_test:0.08654, lr:2.88e-03, fs:0.74854 (r=0.646,p=0.889),  time:18.364, tt:3727.852\n",
      "Ep:203, loss:0.00000, loss_test:0.08514, lr:2.85e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.369, tt:3747.351\n",
      "Ep:204, loss:0.00000, loss_test:0.08754, lr:2.82e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.376, tt:3767.074\n",
      "Ep:205, loss:0.00000, loss_test:0.08787, lr:2.79e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.381, tt:3786.388\n",
      "Ep:206, loss:0.00000, loss_test:0.08642, lr:2.76e-03, fs:0.74419 (r=0.646,p=0.877),  time:18.386, tt:3805.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.08591, lr:2.73e-03, fs:0.74419 (r=0.646,p=0.877),  time:18.398, tt:3826.715\n",
      "Ep:208, loss:0.00000, loss_test:0.08780, lr:2.71e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.401, tt:3845.826\n",
      "Ep:209, loss:0.00000, loss_test:0.08805, lr:2.68e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.403, tt:3864.706\n",
      "Ep:210, loss:0.00000, loss_test:0.08662, lr:2.65e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.408, tt:3883.988\n",
      "Ep:211, loss:0.00000, loss_test:0.08510, lr:2.63e-03, fs:0.74419 (r=0.646,p=0.877),  time:18.413, tt:3903.547\n",
      "Ep:212, loss:0.00000, loss_test:0.08762, lr:2.60e-03, fs:0.75740 (r=0.646,p=0.914),  time:18.417, tt:3922.894\n",
      "Ep:213, loss:0.00000, loss_test:0.08911, lr:2.57e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.417, tt:3941.244\n",
      "Ep:214, loss:0.00000, loss_test:0.08845, lr:2.55e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.422, tt:3960.747\n",
      "Ep:215, loss:0.00000, loss_test:0.08618, lr:2.52e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.415, tt:3977.725\n",
      "Ep:216, loss:0.00000, loss_test:0.08465, lr:2.50e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.417, tt:3996.436\n",
      "Ep:217, loss:0.00000, loss_test:0.08780, lr:2.47e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.421, tt:4015.879\n",
      "Ep:218, loss:0.00000, loss_test:0.08935, lr:2.45e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.423, tt:4034.638\n",
      "Ep:219, loss:0.00000, loss_test:0.08860, lr:2.42e-03, fs:0.75740 (r=0.646,p=0.914),  time:18.422, tt:4052.861\n",
      "Ep:220, loss:0.00000, loss_test:0.08643, lr:2.40e-03, fs:0.74854 (r=0.646,p=0.889),  time:18.422, tt:4071.244\n",
      "Ep:221, loss:0.00000, loss_test:0.08546, lr:2.38e-03, fs:0.74854 (r=0.646,p=0.889),  time:18.439, tt:4093.474\n",
      "Ep:222, loss:0.00000, loss_test:0.08713, lr:2.35e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.441, tt:4112.352\n",
      "Ep:223, loss:0.00000, loss_test:0.08802, lr:2.33e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.444, tt:4131.475\n",
      "Ep:224, loss:0.00000, loss_test:0.08749, lr:2.31e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.442, tt:4149.377\n",
      "Ep:225, loss:0.00000, loss_test:0.08616, lr:2.28e-03, fs:0.75294 (r=0.646,p=0.901),  time:18.440, tt:4167.443\n",
      "Ep:226, loss:0.00000, loss_test:0.08610, lr:2.26e-03, fs:0.74854 (r=0.646,p=0.889),  time:18.437, tt:4185.195\n",
      "Ep:227, loss:0.00000, loss_test:0.08754, lr:2.24e-03, fs:0.74854 (r=0.646,p=0.889),  time:18.434, tt:4203.016\n",
      "Ep:228, loss:0.00000, loss_test:0.08823, lr:2.21e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.428, tt:4220.072\n",
      "Ep:229, loss:0.00000, loss_test:0.08753, lr:2.19e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.424, tt:4237.450\n",
      "Ep:230, loss:0.00000, loss_test:0.08652, lr:2.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.425, tt:4256.078\n",
      "Ep:231, loss:0.00000, loss_test:0.08624, lr:2.15e-03, fs:0.74854 (r=0.646,p=0.889),  time:18.424, tt:4274.356\n",
      "Ep:232, loss:0.00000, loss_test:0.08733, lr:2.13e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.422, tt:4292.428\n",
      "Ep:233, loss:0.00000, loss_test:0.08802, lr:2.11e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.422, tt:4310.689\n",
      "Ep:234, loss:0.00000, loss_test:0.08760, lr:2.08e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.419, tt:4328.493\n",
      "Ep:235, loss:0.00000, loss_test:0.08643, lr:2.06e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.411, tt:4344.981\n",
      "Ep:236, loss:0.00000, loss_test:0.08637, lr:2.04e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.406, tt:4362.260\n",
      "Ep:237, loss:0.00000, loss_test:0.08745, lr:2.02e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.403, tt:4379.903\n",
      "Ep:238, loss:0.00000, loss_test:0.08796, lr:2.00e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.396, tt:4396.693\n",
      "Ep:239, loss:0.00000, loss_test:0.08744, lr:1.98e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.392, tt:4414.095\n",
      "Ep:240, loss:0.00000, loss_test:0.08627, lr:1.96e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.387, tt:4431.362\n",
      "Ep:241, loss:0.00000, loss_test:0.08606, lr:1.94e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.382, tt:4448.326\n",
      "Ep:242, loss:0.00000, loss_test:0.08759, lr:1.92e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.374, tt:4464.789\n",
      "Ep:243, loss:0.00000, loss_test:0.08807, lr:1.90e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.375, tt:4483.535\n",
      "Ep:244, loss:0.00000, loss_test:0.08735, lr:1.89e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.370, tt:4500.536\n",
      "Ep:245, loss:0.00000, loss_test:0.08633, lr:1.87e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.366, tt:4518.154\n",
      "Ep:246, loss:0.00000, loss_test:0.08639, lr:1.85e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.358, tt:4534.310\n",
      "Ep:247, loss:0.00000, loss_test:0.08715, lr:1.83e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.353, tt:4551.518\n",
      "Ep:248, loss:0.00000, loss_test:0.08758, lr:1.81e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.346, tt:4568.189\n",
      "Ep:249, loss:0.00000, loss_test:0.08715, lr:1.79e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.342, tt:4585.569\n",
      "Ep:250, loss:0.00000, loss_test:0.08656, lr:1.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.334, tt:4601.916\n",
      "Ep:251, loss:0.00000, loss_test:0.08695, lr:1.76e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.329, tt:4619.027\n",
      "Ep:252, loss:0.00000, loss_test:0.08731, lr:1.74e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.325, tt:4636.333\n",
      "Ep:253, loss:0.00000, loss_test:0.08698, lr:1.72e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.320, tt:4653.212\n",
      "Ep:254, loss:0.00000, loss_test:0.08647, lr:1.71e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.314, tt:4670.004\n",
      "Ep:255, loss:0.00000, loss_test:0.08653, lr:1.69e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.305, tt:4686.067\n",
      "Ep:256, loss:0.00000, loss_test:0.08706, lr:1.67e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.296, tt:4702.174\n",
      "Ep:257, loss:0.00000, loss_test:0.08712, lr:1.65e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.293, tt:4719.480\n",
      "Ep:258, loss:0.00000, loss_test:0.08655, lr:1.64e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.292, tt:4737.543\n",
      "Ep:259, loss:0.00000, loss_test:0.08636, lr:1.62e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.284, tt:4753.710\n",
      "Ep:260, loss:0.00000, loss_test:0.08737, lr:1.61e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.281, tt:4771.360\n",
      "Ep:261, loss:0.00000, loss_test:0.08769, lr:1.59e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.275, tt:4788.108\n",
      "Ep:262, loss:0.00000, loss_test:0.08711, lr:1.57e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.275, tt:4806.236\n",
      "Ep:263, loss:0.00000, loss_test:0.08628, lr:1.56e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.279, tt:4825.528\n",
      "Ep:264, loss:0.00000, loss_test:0.08673, lr:1.54e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.279, tt:4843.927\n",
      "Ep:265, loss:0.00000, loss_test:0.08713, lr:1.53e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.278, tt:4861.908\n",
      "Ep:266, loss:0.00000, loss_test:0.08711, lr:1.51e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.278, tt:4880.124\n",
      "Ep:267, loss:0.00000, loss_test:0.08692, lr:1.50e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.279, tt:4898.659\n",
      "Ep:268, loss:0.00000, loss_test:0.08670, lr:1.48e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.281, tt:4917.546\n",
      "Ep:269, loss:0.00000, loss_test:0.08681, lr:1.47e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.281, tt:4935.828\n",
      "Ep:270, loss:0.00000, loss_test:0.08710, lr:1.45e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.282, tt:4954.415\n",
      "Ep:271, loss:0.00000, loss_test:0.08712, lr:1.44e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.282, tt:4972.749\n",
      "Ep:272, loss:0.00000, loss_test:0.08680, lr:1.42e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.282, tt:4990.891\n",
      "Ep:273, loss:0.00000, loss_test:0.08658, lr:1.41e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.277, tt:5007.959\n",
      "Ep:274, loss:0.00000, loss_test:0.08679, lr:1.39e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.274, tt:5025.357\n",
      "Ep:275, loss:0.00000, loss_test:0.08691, lr:1.38e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.276, tt:5044.156\n",
      "Ep:276, loss:0.00000, loss_test:0.08688, lr:1.37e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.274, tt:5061.765\n",
      "Ep:277, loss:0.00000, loss_test:0.08692, lr:1.35e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.273, tt:5079.943\n",
      "Ep:278, loss:0.00000, loss_test:0.08690, lr:1.34e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.274, tt:5098.342\n",
      "Ep:279, loss:0.00000, loss_test:0.08686, lr:1.33e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.272, tt:5116.032\n",
      "Ep:280, loss:0.00000, loss_test:0.08721, lr:1.31e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.271, tt:5134.079\n",
      "Ep:281, loss:0.00000, loss_test:0.08711, lr:1.30e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.275, tt:5153.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:282, loss:0.00000, loss_test:0.08661, lr:1.29e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.277, tt:5172.342\n",
      "Ep:283, loss:0.00000, loss_test:0.08669, lr:1.27e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.277, tt:5190.557\n",
      "Ep:284, loss:0.00000, loss_test:0.08701, lr:1.26e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.280, tt:5209.877\n",
      "Ep:285, loss:0.00000, loss_test:0.08687, lr:1.25e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.286, tt:5229.692\n",
      "Ep:286, loss:0.00000, loss_test:0.08661, lr:1.24e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.290, tt:5249.180\n",
      "Ep:287, loss:0.00000, loss_test:0.08692, lr:1.22e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.296, tt:5269.371\n",
      "Ep:288, loss:0.00000, loss_test:0.08690, lr:1.21e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.298, tt:5288.145\n",
      "Ep:289, loss:0.00000, loss_test:0.08661, lr:1.20e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.297, tt:5306.171\n",
      "Ep:290, loss:0.00000, loss_test:0.08681, lr:1.19e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.299, tt:5325.131\n",
      "Ep:291, loss:0.00000, loss_test:0.08683, lr:1.18e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.301, tt:5343.897\n",
      "Ep:292, loss:0.00000, loss_test:0.08639, lr:1.16e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.299, tt:5361.595\n",
      "Ep:293, loss:0.00000, loss_test:0.08647, lr:1.15e-03, fs:0.75862 (r=0.667,p=0.880),  time:18.295, tt:5378.859\n",
      "Ep:294, loss:0.00000, loss_test:0.08664, lr:1.14e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.289, tt:5395.232\n",
      "Ep:295, loss:0.00000, loss_test:0.08664, lr:1.13e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.274, tt:5409.251\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14210, lr:1.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:5.835, tt:5.835\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14039, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:6.769, tt:13.537\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.13922, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:8.445, tt:25.334\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.13888, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:10.412, tt:41.647\n",
      "Ep:4, loss:0.00004, loss_test:0.13920, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:11.784, tt:58.920\n",
      "Ep:5, loss:0.00004, loss_test:0.13954, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:12.652, tt:75.912\n",
      "Ep:6, loss:0.00004, loss_test:0.13961, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:13.362, tt:93.536\n",
      "Ep:7, loss:0.00004, loss_test:0.13937, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:13.944, tt:111.550\n",
      "Ep:8, loss:0.00004, loss_test:0.13889, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:14.362, tt:129.255\n",
      "Ep:9, loss:0.00004, loss_test:0.13816, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:14.677, tt:146.771\n",
      "Ep:10, loss:0.00004, loss_test:0.13716, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:14.945, tt:164.400\n",
      "Ep:11, loss:0.00004, loss_test:0.13619, lr:1.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:15.134, tt:181.604\n",
      "Ep:12, loss:0.00004, loss_test:0.13556, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:15.254, tt:198.301\n",
      "Ep:13, loss:0.00004, loss_test:0.13500, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:15.390, tt:215.465\n",
      "Ep:14, loss:0.00004, loss_test:0.13449, lr:9.90e-03, fs:0.67164 (r=0.909,p=0.533),  time:15.434, tt:231.509\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.13391, lr:9.90e-03, fs:0.67164 (r=0.909,p=0.533),  time:15.486, tt:247.775\n",
      "Ep:16, loss:0.00003, loss_test:0.13331, lr:9.90e-03, fs:0.67164 (r=0.909,p=0.533),  time:15.587, tt:264.978\n",
      "Ep:17, loss:0.00003, loss_test:0.13278, lr:9.90e-03, fs:0.67164 (r=0.909,p=0.533),  time:15.595, tt:280.706\n",
      "Ep:18, loss:0.00003, loss_test:0.13230, lr:9.90e-03, fs:0.67164 (r=0.909,p=0.533),  time:15.645, tt:297.249\n",
      "Ep:19, loss:0.00003, loss_test:0.13197, lr:9.90e-03, fs:0.66667 (r=0.909,p=0.526),  time:15.718, tt:314.357\n",
      "Ep:20, loss:0.00003, loss_test:0.13158, lr:9.90e-03, fs:0.66667 (r=0.909,p=0.526),  time:15.816, tt:332.136\n",
      "Ep:21, loss:0.00003, loss_test:0.13108, lr:9.90e-03, fs:0.66667 (r=0.909,p=0.526),  time:15.880, tt:349.357\n",
      "Ep:22, loss:0.00003, loss_test:0.13027, lr:9.90e-03, fs:0.66667 (r=0.909,p=0.526),  time:15.911, tt:365.946\n",
      "Ep:23, loss:0.00003, loss_test:0.12921, lr:9.90e-03, fs:0.66914 (r=0.909,p=0.529),  time:15.930, tt:382.322\n",
      "Ep:24, loss:0.00003, loss_test:0.12800, lr:9.90e-03, fs:0.67416 (r=0.909,p=0.536),  time:16.000, tt:400.006\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.12685, lr:9.90e-03, fs:0.67170 (r=0.899,p=0.536),  time:16.072, tt:417.867\n",
      "Ep:26, loss:0.00003, loss_test:0.12556, lr:9.90e-03, fs:0.67424 (r=0.899,p=0.539),  time:16.129, tt:435.490\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.12426, lr:9.90e-03, fs:0.67681 (r=0.899,p=0.543),  time:16.149, tt:452.186\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.12294, lr:9.90e-03, fs:0.68441 (r=0.909,p=0.549),  time:16.178, tt:469.148\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.12167, lr:9.90e-03, fs:0.68966 (r=0.909,p=0.556),  time:16.166, tt:484.986\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.12035, lr:9.90e-03, fs:0.69498 (r=0.909,p=0.562),  time:16.151, tt:500.694\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.11860, lr:9.90e-03, fs:0.69531 (r=0.899,p=0.567),  time:16.172, tt:517.498\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.11649, lr:9.90e-03, fs:0.69804 (r=0.899,p=0.571),  time:16.192, tt:534.341\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.11439, lr:9.90e-03, fs:0.69323 (r=0.879,p=0.572),  time:16.243, tt:552.261\n",
      "Ep:34, loss:0.00003, loss_test:0.11270, lr:9.90e-03, fs:0.69355 (r=0.869,p=0.577),  time:16.250, tt:568.734\n",
      "Ep:35, loss:0.00003, loss_test:0.11114, lr:9.90e-03, fs:0.70204 (r=0.869,p=0.589),  time:16.261, tt:585.406\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.10978, lr:9.90e-03, fs:0.70492 (r=0.869,p=0.593),  time:16.268, tt:601.900\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.10841, lr:9.90e-03, fs:0.71074 (r=0.869,p=0.601),  time:16.285, tt:618.842\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.10703, lr:9.90e-03, fs:0.71667 (r=0.869,p=0.610),  time:16.296, tt:635.540\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.10566, lr:9.90e-03, fs:0.71429 (r=0.859,p=0.612),  time:16.306, tt:652.226\n",
      "Ep:40, loss:0.00003, loss_test:0.10421, lr:9.90e-03, fs:0.71795 (r=0.848,p=0.622),  time:16.340, tt:669.941\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.10281, lr:9.90e-03, fs:0.72414 (r=0.848,p=0.632),  time:16.391, tt:688.422\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.10128, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:16.412, tt:705.731\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.09975, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:16.420, tt:722.462\n",
      "Ep:44, loss:0.00003, loss_test:0.09822, lr:9.90e-03, fs:0.72807 (r=0.838,p=0.643),  time:16.459, tt:740.642\n",
      "Ep:45, loss:0.00003, loss_test:0.09708, lr:9.90e-03, fs:0.73362 (r=0.848,p=0.646),  time:16.491, tt:758.592\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.09611, lr:9.90e-03, fs:0.73913 (r=0.859,p=0.649),  time:16.534, tt:777.117\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.09523, lr:9.90e-03, fs:0.74236 (r=0.859,p=0.654),  time:16.590, tt:796.302\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09443, lr:9.90e-03, fs:0.74236 (r=0.859,p=0.654),  time:16.608, tt:813.815\n",
      "Ep:49, loss:0.00002, loss_test:0.09378, lr:9.90e-03, fs:0.75439 (r=0.869,p=0.667),  time:16.669, tt:833.446\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.09306, lr:9.90e-03, fs:0.75983 (r=0.879,p=0.669),  time:16.733, tt:853.384\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.09226, lr:9.90e-03, fs:0.75439 (r=0.869,p=0.667),  time:16.741, tt:870.547\n",
      "Ep:52, loss:0.00002, loss_test:0.09136, lr:9.90e-03, fs:0.74890 (r=0.859,p=0.664),  time:16.742, tt:887.327\n",
      "Ep:53, loss:0.00002, loss_test:0.09048, lr:9.90e-03, fs:0.75676 (r=0.848,p=0.683),  time:16.762, tt:905.128\n",
      "Ep:54, loss:0.00002, loss_test:0.08953, lr:9.90e-03, fs:0.76018 (r=0.848,p=0.689),  time:16.791, tt:923.524\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.08889, lr:9.90e-03, fs:0.77626 (r=0.859,p=0.708),  time:16.834, tt:942.689\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.08867, lr:9.90e-03, fs:0.77064 (r=0.848,p=0.706),  time:16.856, tt:960.795\n",
      "Ep:57, loss:0.00002, loss_test:0.08822, lr:9.90e-03, fs:0.77982 (r=0.859,p=0.714),  time:16.911, tt:980.858\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.08760, lr:9.90e-03, fs:0.77419 (r=0.848,p=0.712),  time:16.935, tt:999.140\n",
      "Ep:59, loss:0.00002, loss_test:0.08706, lr:9.90e-03, fs:0.77209 (r=0.838,p=0.716),  time:16.972, tt:1018.323\n",
      "Ep:60, loss:0.00002, loss_test:0.08657, lr:9.90e-03, fs:0.76415 (r=0.818,p=0.717),  time:17.018, tt:1038.105\n",
      "Ep:61, loss:0.00002, loss_test:0.08597, lr:9.90e-03, fs:0.76636 (r=0.828,p=0.713),  time:17.027, tt:1055.678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00002, loss_test:0.08528, lr:9.90e-03, fs:0.76056 (r=0.818,p=0.711),  time:17.067, tt:1075.251\n",
      "Ep:63, loss:0.00002, loss_test:0.08415, lr:9.90e-03, fs:0.76056 (r=0.818,p=0.711),  time:17.088, tt:1093.630\n",
      "Ep:64, loss:0.00002, loss_test:0.08356, lr:9.90e-03, fs:0.78140 (r=0.848,p=0.724),  time:17.119, tt:1112.733\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.08378, lr:9.90e-03, fs:0.75362 (r=0.788,p=0.722),  time:17.148, tt:1131.745\n",
      "Ep:66, loss:0.00002, loss_test:0.08347, lr:9.90e-03, fs:0.80000 (r=0.869,p=0.741),  time:17.170, tt:1150.407\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.08503, lr:9.90e-03, fs:0.75248 (r=0.768,p=0.738),  time:17.193, tt:1169.103\n",
      "Ep:68, loss:0.00002, loss_test:0.08502, lr:9.90e-03, fs:0.81651 (r=0.899,p=0.748),  time:17.221, tt:1188.271\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.08291, lr:9.90e-03, fs:0.75000 (r=0.758,p=0.743),  time:17.249, tt:1207.456\n",
      "Ep:70, loss:0.00002, loss_test:0.08327, lr:9.90e-03, fs:0.81651 (r=0.899,p=0.748),  time:17.280, tt:1226.902\n",
      "Ep:71, loss:0.00002, loss_test:0.08054, lr:9.90e-03, fs:0.76699 (r=0.798,p=0.738),  time:17.302, tt:1245.751\n",
      "Ep:72, loss:0.00001, loss_test:0.08164, lr:9.90e-03, fs:0.80189 (r=0.859,p=0.752),  time:17.330, tt:1265.067\n",
      "Ep:73, loss:0.00001, loss_test:0.08358, lr:9.90e-03, fs:0.80189 (r=0.859,p=0.752),  time:17.363, tt:1284.831\n",
      "Ep:74, loss:0.00001, loss_test:0.08348, lr:9.90e-03, fs:0.75127 (r=0.747,p=0.755),  time:17.388, tt:1304.098\n",
      "Ep:75, loss:0.00001, loss_test:0.08686, lr:9.90e-03, fs:0.81106 (r=0.889,p=0.746),  time:17.408, tt:1322.997\n",
      "Ep:76, loss:0.00001, loss_test:0.08444, lr:9.90e-03, fs:0.77949 (r=0.768,p=0.792),  time:17.440, tt:1342.887\n",
      "Ep:77, loss:0.00001, loss_test:0.09052, lr:9.90e-03, fs:0.79295 (r=0.909,p=0.703),  time:17.466, tt:1362.324\n",
      "Ep:78, loss:0.00001, loss_test:0.08806, lr:9.90e-03, fs:0.77778 (r=0.778,p=0.778),  time:17.491, tt:1381.796\n",
      "Ep:79, loss:0.00001, loss_test:0.08255, lr:9.90e-03, fs:0.84793 (r=0.929,p=0.780),  time:17.500, tt:1400.034\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.08048, lr:9.90e-03, fs:0.80976 (r=0.838,p=0.783),  time:17.523, tt:1419.400\n",
      "Ep:81, loss:0.00001, loss_test:0.08402, lr:9.90e-03, fs:0.78974 (r=0.778,p=0.802),  time:17.553, tt:1439.311\n",
      "Ep:82, loss:0.00001, loss_test:0.08079, lr:9.90e-03, fs:0.83412 (r=0.889,p=0.786),  time:17.563, tt:1457.729\n",
      "Ep:83, loss:0.00001, loss_test:0.07799, lr:9.90e-03, fs:0.85581 (r=0.929,p=0.793),  time:17.589, tt:1477.504\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.07827, lr:9.90e-03, fs:0.79803 (r=0.818,p=0.779),  time:17.616, tt:1497.354\n",
      "Ep:85, loss:0.00001, loss_test:0.07732, lr:9.90e-03, fs:0.82524 (r=0.859,p=0.794),  time:17.681, tt:1520.576\n",
      "Ep:86, loss:0.00001, loss_test:0.07799, lr:9.90e-03, fs:0.81373 (r=0.838,p=0.790),  time:17.711, tt:1540.852\n",
      "Ep:87, loss:0.00001, loss_test:0.07899, lr:9.90e-03, fs:0.79798 (r=0.798,p=0.798),  time:17.719, tt:1559.244\n",
      "Ep:88, loss:0.00001, loss_test:0.07889, lr:9.90e-03, fs:0.80788 (r=0.828,p=0.788),  time:17.742, tt:1579.019\n",
      "Ep:89, loss:0.00001, loss_test:0.08011, lr:9.90e-03, fs:0.80788 (r=0.828,p=0.788),  time:17.750, tt:1597.527\n",
      "Ep:90, loss:0.00001, loss_test:0.08149, lr:9.90e-03, fs:0.80402 (r=0.808,p=0.800),  time:17.750, tt:1615.289\n",
      "Ep:91, loss:0.00001, loss_test:0.07968, lr:9.90e-03, fs:0.82412 (r=0.828,p=0.820),  time:17.740, tt:1632.052\n",
      "Ep:92, loss:0.00001, loss_test:0.07945, lr:9.90e-03, fs:0.81188 (r=0.828,p=0.796),  time:17.751, tt:1650.842\n",
      "Ep:93, loss:0.00001, loss_test:0.07735, lr:9.90e-03, fs:0.86124 (r=0.909,p=0.818),  time:17.753, tt:1668.743\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.08596, lr:9.90e-03, fs:0.80612 (r=0.798,p=0.814),  time:17.759, tt:1687.093\n",
      "Ep:95, loss:0.00001, loss_test:0.09482, lr:9.90e-03, fs:0.77193 (r=0.889,p=0.682),  time:17.758, tt:1704.743\n",
      "Ep:96, loss:0.00001, loss_test:0.08458, lr:9.90e-03, fs:0.77720 (r=0.758,p=0.798),  time:17.768, tt:1723.542\n",
      "Ep:97, loss:0.00001, loss_test:0.08880, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:17.760, tt:1740.449\n",
      "Ep:98, loss:0.00001, loss_test:0.08282, lr:9.90e-03, fs:0.83654 (r=0.879,p=0.798),  time:17.759, tt:1758.116\n",
      "Ep:99, loss:0.00001, loss_test:0.08351, lr:9.90e-03, fs:0.74737 (r=0.717,p=0.780),  time:17.745, tt:1774.506\n",
      "Ep:100, loss:0.00001, loss_test:0.08231, lr:9.90e-03, fs:0.72928 (r=0.667,p=0.805),  time:17.742, tt:1791.982\n",
      "Ep:101, loss:0.00001, loss_test:0.07515, lr:9.90e-03, fs:0.85167 (r=0.899,p=0.809),  time:17.739, tt:1809.332\n",
      "Ep:102, loss:0.00001, loss_test:0.07690, lr:9.90e-03, fs:0.82051 (r=0.808,p=0.833),  time:17.730, tt:1826.171\n",
      "Ep:103, loss:0.00001, loss_test:0.08067, lr:9.90e-03, fs:0.82353 (r=0.848,p=0.800),  time:17.725, tt:1843.430\n",
      "Ep:104, loss:0.00001, loss_test:0.08343, lr:9.90e-03, fs:0.76596 (r=0.727,p=0.809),  time:17.711, tt:1859.630\n",
      "Ep:105, loss:0.00001, loss_test:0.09078, lr:9.80e-03, fs:0.77660 (r=0.737,p=0.820),  time:17.701, tt:1876.275\n",
      "Ep:106, loss:0.00001, loss_test:0.08405, lr:9.70e-03, fs:0.79397 (r=0.798,p=0.790),  time:17.699, tt:1893.822\n",
      "Ep:107, loss:0.00001, loss_test:0.08263, lr:9.61e-03, fs:0.74157 (r=0.667,p=0.835),  time:17.683, tt:1909.710\n",
      "Ep:108, loss:0.00001, loss_test:0.07961, lr:9.51e-03, fs:0.75936 (r=0.717,p=0.807),  time:17.675, tt:1926.622\n",
      "Ep:109, loss:0.00001, loss_test:0.07717, lr:9.41e-03, fs:0.83495 (r=0.869,p=0.804),  time:17.668, tt:1943.497\n",
      "Ep:110, loss:0.00001, loss_test:0.08114, lr:9.32e-03, fs:0.78075 (r=0.737,p=0.830),  time:17.658, tt:1960.001\n",
      "Ep:111, loss:0.00001, loss_test:0.08373, lr:9.23e-03, fs:0.73743 (r=0.667,p=0.825),  time:17.645, tt:1976.288\n",
      "Ep:112, loss:0.00001, loss_test:0.08001, lr:9.14e-03, fs:0.78534 (r=0.758,p=0.815),  time:17.639, tt:1993.201\n",
      "Ep:113, loss:0.00001, loss_test:0.08133, lr:9.04e-03, fs:0.76344 (r=0.717,p=0.816),  time:17.619, tt:2008.550\n",
      "Ep:114, loss:0.00001, loss_test:0.08320, lr:8.95e-03, fs:0.81283 (r=0.768,p=0.864),  time:17.607, tt:2024.781\n",
      "Ep:115, loss:0.00001, loss_test:0.08237, lr:8.86e-03, fs:0.71591 (r=0.636,p=0.818),  time:17.585, tt:2039.888\n",
      "Ep:116, loss:0.00001, loss_test:0.07970, lr:8.78e-03, fs:0.74033 (r=0.677,p=0.817),  time:17.572, tt:2055.932\n",
      "Ep:117, loss:0.00001, loss_test:0.07758, lr:8.69e-03, fs:0.78756 (r=0.768,p=0.809),  time:17.568, tt:2073.066\n",
      "Ep:118, loss:0.00001, loss_test:0.07995, lr:8.60e-03, fs:0.76503 (r=0.707,p=0.833),  time:17.566, tt:2090.366\n",
      "Ep:119, loss:0.00000, loss_test:0.08245, lr:8.51e-03, fs:0.74576 (r=0.667,p=0.846),  time:17.567, tt:2108.060\n",
      "Ep:120, loss:0.00000, loss_test:0.08046, lr:8.43e-03, fs:0.71345 (r=0.616,p=0.847),  time:17.557, tt:2124.448\n",
      "Ep:121, loss:0.00000, loss_test:0.07805, lr:8.35e-03, fs:0.81250 (r=0.788,p=0.839),  time:17.536, tt:2139.450\n",
      "Ep:122, loss:0.00000, loss_test:0.08032, lr:8.26e-03, fs:0.75138 (r=0.687,p=0.829),  time:17.542, tt:2157.706\n",
      "Ep:123, loss:0.00000, loss_test:0.08518, lr:8.18e-03, fs:0.73446 (r=0.657,p=0.833),  time:17.518, tt:2172.262\n",
      "Ep:124, loss:0.00000, loss_test:0.08313, lr:8.10e-03, fs:0.77348 (r=0.707,p=0.854),  time:17.507, tt:2188.319\n",
      "Ep:125, loss:0.00000, loss_test:0.08114, lr:8.02e-03, fs:0.70930 (r=0.616,p=0.836),  time:17.492, tt:2203.944\n",
      "Ep:126, loss:0.00000, loss_test:0.08041, lr:7.94e-03, fs:0.72515 (r=0.626,p=0.861),  time:17.479, tt:2219.851\n",
      "Ep:127, loss:0.00000, loss_test:0.08076, lr:7.86e-03, fs:0.70520 (r=0.616,p=0.824),  time:17.469, tt:2236.077\n",
      "Ep:128, loss:0.00000, loss_test:0.08135, lr:7.78e-03, fs:0.72414 (r=0.636,p=0.840),  time:17.458, tt:2252.119\n",
      "Ep:129, loss:0.00000, loss_test:0.08054, lr:7.70e-03, fs:0.75000 (r=0.667,p=0.857),  time:17.437, tt:2266.853\n",
      "Ep:130, loss:0.00000, loss_test:0.07931, lr:7.62e-03, fs:0.69006 (r=0.596,p=0.819),  time:17.430, tt:2283.348\n",
      "Ep:131, loss:0.00000, loss_test:0.07785, lr:7.55e-03, fs:0.72727 (r=0.646,p=0.831),  time:17.418, tt:2299.171\n",
      "Ep:132, loss:0.00000, loss_test:0.08020, lr:7.47e-03, fs:0.66667 (r=0.556,p=0.833),  time:17.402, tt:2314.517\n",
      "Ep:133, loss:0.00000, loss_test:0.08104, lr:7.40e-03, fs:0.65031 (r=0.535,p=0.828),  time:17.391, tt:2330.459\n",
      "Ep:134, loss:0.00000, loss_test:0.07854, lr:7.32e-03, fs:0.69412 (r=0.596,p=0.831),  time:17.377, tt:2345.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.07815, lr:7.25e-03, fs:0.72000 (r=0.636,p=0.829),  time:17.366, tt:2361.831\n",
      "Ep:136, loss:0.00000, loss_test:0.08011, lr:7.18e-03, fs:0.67456 (r=0.576,p=0.814),  time:17.360, tt:2378.291\n",
      "Ep:137, loss:0.00000, loss_test:0.08346, lr:7.11e-03, fs:0.64596 (r=0.525,p=0.839),  time:17.351, tt:2394.438\n",
      "Ep:138, loss:0.00000, loss_test:0.08254, lr:7.03e-03, fs:0.63804 (r=0.525,p=0.812),  time:17.353, tt:2412.093\n",
      "Ep:139, loss:0.00000, loss_test:0.08112, lr:6.96e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.351, tt:2429.097\n",
      "Ep:140, loss:0.00000, loss_test:0.08020, lr:6.89e-03, fs:0.64634 (r=0.535,p=0.815),  time:17.346, tt:2445.832\n",
      "Ep:141, loss:0.00000, loss_test:0.08119, lr:6.83e-03, fs:0.69822 (r=0.596,p=0.843),  time:17.351, tt:2463.857\n",
      "Ep:142, loss:0.00000, loss_test:0.08488, lr:6.76e-03, fs:0.65031 (r=0.535,p=0.828),  time:17.345, tt:2480.360\n",
      "Ep:143, loss:0.00000, loss_test:0.08383, lr:6.69e-03, fs:0.64596 (r=0.525,p=0.839),  time:17.342, tt:2497.258\n",
      "Ep:144, loss:0.00000, loss_test:0.08174, lr:6.62e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.332, tt:2513.150\n",
      "Ep:145, loss:0.00000, loss_test:0.08113, lr:6.56e-03, fs:0.66667 (r=0.556,p=0.833),  time:17.320, tt:2528.691\n",
      "Ep:146, loss:0.00000, loss_test:0.08328, lr:6.49e-03, fs:0.64596 (r=0.525,p=0.839),  time:17.307, tt:2544.157\n",
      "Ep:147, loss:0.00000, loss_test:0.08401, lr:6.43e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.295, tt:2559.649\n",
      "Ep:148, loss:0.00000, loss_test:0.08147, lr:6.36e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.285, tt:2575.530\n",
      "Ep:149, loss:0.00000, loss_test:0.08120, lr:6.30e-03, fs:0.66265 (r=0.556,p=0.821),  time:17.283, tt:2592.441\n",
      "Ep:150, loss:0.00000, loss_test:0.08477, lr:6.24e-03, fs:0.67073 (r=0.556,p=0.846),  time:17.276, tt:2608.626\n",
      "Ep:151, loss:0.00000, loss_test:0.08619, lr:6.17e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.273, tt:2625.453\n",
      "Ep:152, loss:0.00000, loss_test:0.08446, lr:6.11e-03, fs:0.65031 (r=0.535,p=0.828),  time:17.280, tt:2643.877\n",
      "Ep:153, loss:0.00000, loss_test:0.08478, lr:6.05e-03, fs:0.65854 (r=0.545,p=0.831),  time:17.285, tt:2661.965\n",
      "Ep:154, loss:0.00000, loss_test:0.08519, lr:5.99e-03, fs:0.64596 (r=0.525,p=0.839),  time:17.281, tt:2678.553\n",
      "Ep:155, loss:0.00000, loss_test:0.08522, lr:5.93e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.281, tt:2695.878\n",
      "Ep:156, loss:0.00000, loss_test:0.08770, lr:5.87e-03, fs:0.62893 (r=0.505,p=0.833),  time:17.282, tt:2713.285\n",
      "Ep:157, loss:0.00000, loss_test:0.08901, lr:5.81e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.287, tt:2731.279\n",
      "Ep:158, loss:0.00000, loss_test:0.08623, lr:5.75e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.285, tt:2748.318\n",
      "Ep:159, loss:0.00000, loss_test:0.08518, lr:5.70e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.310, tt:2769.617\n",
      "Ep:160, loss:0.00000, loss_test:0.08585, lr:5.64e-03, fs:0.65031 (r=0.535,p=0.828),  time:17.315, tt:2787.708\n",
      "Ep:161, loss:0.00000, loss_test:0.08590, lr:5.58e-03, fs:0.63291 (r=0.505,p=0.847),  time:17.319, tt:2805.675\n",
      "Ep:162, loss:0.00000, loss_test:0.08738, lr:5.53e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.318, tt:2822.774\n",
      "Ep:163, loss:0.00000, loss_test:0.08718, lr:5.47e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.316, tt:2839.808\n",
      "Ep:164, loss:0.00000, loss_test:0.08638, lr:5.42e-03, fs:0.65432 (r=0.535,p=0.841),  time:17.322, tt:2858.127\n",
      "Ep:165, loss:0.00000, loss_test:0.08598, lr:5.36e-03, fs:0.63354 (r=0.515,p=0.823),  time:17.321, tt:2875.264\n",
      "Ep:166, loss:0.00000, loss_test:0.08746, lr:5.31e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.315, tt:2891.599\n",
      "Ep:167, loss:0.00000, loss_test:0.08826, lr:5.26e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.320, tt:2909.829\n",
      "Ep:168, loss:0.00000, loss_test:0.08743, lr:5.20e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.331, tt:2928.946\n",
      "Ep:169, loss:0.00000, loss_test:0.08725, lr:5.15e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.340, tt:2947.839\n",
      "Ep:170, loss:0.00000, loss_test:0.08858, lr:5.10e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.340, tt:2965.099\n",
      "Ep:171, loss:0.00000, loss_test:0.08908, lr:5.05e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.344, tt:2983.108\n",
      "Ep:172, loss:0.00000, loss_test:0.08766, lr:5.00e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.349, tt:3001.294\n",
      "Ep:173, loss:0.00000, loss_test:0.08745, lr:4.95e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.351, tt:3019.159\n",
      "Ep:174, loss:0.00000, loss_test:0.08946, lr:4.90e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.358, tt:3037.706\n",
      "Ep:175, loss:0.00000, loss_test:0.09152, lr:4.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.365, tt:3056.295\n",
      "Ep:176, loss:0.00000, loss_test:0.09085, lr:4.80e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.374, tt:3075.258\n",
      "Ep:177, loss:0.00000, loss_test:0.08974, lr:4.75e-03, fs:0.63750 (r=0.515,p=0.836),  time:17.386, tt:3094.659\n",
      "Ep:178, loss:0.00000, loss_test:0.08967, lr:4.71e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.396, tt:3113.851\n",
      "Ep:179, loss:0.00000, loss_test:0.08936, lr:4.66e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.408, tt:3133.450\n",
      "Ep:180, loss:0.00000, loss_test:0.08965, lr:4.61e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.413, tt:3151.782\n",
      "Ep:181, loss:0.00000, loss_test:0.09168, lr:4.57e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.423, tt:3170.923\n",
      "Ep:182, loss:0.00000, loss_test:0.09250, lr:4.52e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.428, tt:3189.388\n",
      "Ep:183, loss:0.00000, loss_test:0.09139, lr:4.48e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.438, tt:3208.549\n",
      "Ep:184, loss:0.00000, loss_test:0.09030, lr:4.43e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.449, tt:3228.123\n",
      "Ep:185, loss:0.00000, loss_test:0.09129, lr:4.39e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.459, tt:3247.445\n",
      "Ep:186, loss:0.00000, loss_test:0.09305, lr:4.34e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.468, tt:3266.587\n",
      "Ep:187, loss:0.00000, loss_test:0.09314, lr:4.30e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.477, tt:3285.749\n",
      "Ep:188, loss:0.00000, loss_test:0.09196, lr:4.26e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.486, tt:3304.864\n",
      "Ep:189, loss:0.00000, loss_test:0.09102, lr:4.21e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.494, tt:3323.849\n",
      "Ep:190, loss:0.00000, loss_test:0.09191, lr:4.17e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.502, tt:3342.970\n",
      "Ep:191, loss:0.00000, loss_test:0.09293, lr:4.13e-03, fs:0.64151 (r=0.515,p=0.850),  time:17.510, tt:3361.899\n",
      "Ep:192, loss:0.00000, loss_test:0.09332, lr:4.09e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.517, tt:3380.762\n",
      "Ep:193, loss:0.00000, loss_test:0.09314, lr:4.05e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.521, tt:3399.121\n",
      "Ep:194, loss:0.00000, loss_test:0.09286, lr:4.01e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.528, tt:3417.947\n",
      "Ep:195, loss:0.00000, loss_test:0.09288, lr:3.97e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.545, tt:3438.787\n",
      "Ep:196, loss:0.00000, loss_test:0.09409, lr:3.93e-03, fs:0.64557 (r=0.515,p=0.864),  time:17.575, tt:3462.178\n",
      "Ep:197, loss:0.00000, loss_test:0.09527, lr:3.89e-03, fs:0.64968 (r=0.515,p=0.879),  time:17.587, tt:3482.141\n",
      "Ep:198, loss:0.00000, loss_test:0.09542, lr:3.85e-03, fs:0.64968 (r=0.515,p=0.879),  time:17.597, tt:3501.707\n",
      "Ep:199, loss:0.00000, loss_test:0.09453, lr:3.81e-03, fs:0.64968 (r=0.515,p=0.879),  time:17.602, tt:3520.447\n",
      "Ep:200, loss:0.00000, loss_test:0.09365, lr:3.77e-03, fs:0.64968 (r=0.515,p=0.879),  time:17.612, tt:3539.965\n",
      "Ep:201, loss:0.00000, loss_test:0.09448, lr:3.73e-03, fs:0.65385 (r=0.515,p=0.895),  time:17.616, tt:3558.452\n",
      "Ep:202, loss:0.00000, loss_test:0.09630, lr:3.70e-03, fs:0.65385 (r=0.515,p=0.895),  time:17.624, tt:3577.590\n",
      "Ep:203, loss:0.00000, loss_test:0.09690, lr:3.66e-03, fs:0.65385 (r=0.515,p=0.895),  time:17.627, tt:3595.939\n",
      "Ep:204, loss:0.00000, loss_test:0.09621, lr:3.62e-03, fs:0.64968 (r=0.515,p=0.879),  time:17.639, tt:3616.012\n",
      "Ep:205, loss:0.00000, loss_test:0.09574, lr:3.59e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.647, tt:3635.380\n",
      "Ep:206, loss:0.00000, loss_test:0.09582, lr:3.55e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.657, tt:3655.048\n",
      "Ep:207, loss:0.00000, loss_test:0.09623, lr:3.52e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.665, tt:3674.232\n",
      "Ep:208, loss:0.00000, loss_test:0.09728, lr:3.48e-03, fs:0.64103 (r=0.505,p=0.877),  time:17.675, tt:3694.054\n",
      "Ep:209, loss:0.00000, loss_test:0.09765, lr:3.45e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.683, tt:3713.382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.09713, lr:3.41e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.692, tt:3733.041\n",
      "Ep:211, loss:0.00000, loss_test:0.09679, lr:3.38e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.699, tt:3752.229\n",
      "Ep:212, loss:0.00000, loss_test:0.09725, lr:3.34e-03, fs:0.64516 (r=0.505,p=0.893),  time:17.710, tt:3772.289\n",
      "Ep:213, loss:0.00000, loss_test:0.09794, lr:3.31e-03, fs:0.63636 (r=0.495,p=0.891),  time:17.718, tt:3791.675\n",
      "Ep:214, loss:0.00000, loss_test:0.09835, lr:3.28e-03, fs:0.62745 (r=0.485,p=0.889),  time:17.727, tt:3811.278\n",
      "Ep:215, loss:0.00000, loss_test:0.09831, lr:3.24e-03, fs:0.63636 (r=0.495,p=0.891),  time:17.732, tt:3830.201\n",
      "Ep:216, loss:0.00000, loss_test:0.09779, lr:3.21e-03, fs:0.63636 (r=0.495,p=0.891),  time:17.744, tt:3850.402\n",
      "Ep:217, loss:0.00000, loss_test:0.09741, lr:3.18e-03, fs:0.63636 (r=0.495,p=0.891),  time:17.747, tt:3868.765\n",
      "Ep:218, loss:0.00000, loss_test:0.09833, lr:3.15e-03, fs:0.63636 (r=0.495,p=0.891),  time:17.752, tt:3887.627\n",
      "Ep:219, loss:0.00000, loss_test:0.09875, lr:3.12e-03, fs:0.62745 (r=0.485,p=0.889),  time:17.756, tt:3906.297\n",
      "Ep:220, loss:0.00000, loss_test:0.09898, lr:3.09e-03, fs:0.62745 (r=0.485,p=0.889),  time:17.759, tt:3924.787\n",
      "Ep:221, loss:0.00000, loss_test:0.09901, lr:3.05e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.761, tt:3943.008\n",
      "Ep:222, loss:0.00000, loss_test:0.09867, lr:3.02e-03, fs:0.62745 (r=0.485,p=0.889),  time:17.762, tt:3960.889\n",
      "Ep:223, loss:0.00000, loss_test:0.09881, lr:2.99e-03, fs:0.62745 (r=0.485,p=0.889),  time:17.767, tt:3979.823\n",
      "Ep:224, loss:0.00000, loss_test:0.10007, lr:2.96e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.772, tt:3998.762\n",
      "Ep:225, loss:0.00000, loss_test:0.10038, lr:2.93e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.779, tt:4017.956\n",
      "Ep:226, loss:0.00000, loss_test:0.09981, lr:2.90e-03, fs:0.63576 (r=0.485,p=0.923),  time:17.784, tt:4036.993\n",
      "Ep:227, loss:0.00000, loss_test:0.09965, lr:2.88e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.780, tt:4053.761\n",
      "Ep:228, loss:0.00000, loss_test:0.09943, lr:2.85e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.783, tt:4072.228\n",
      "Ep:229, loss:0.00000, loss_test:0.09955, lr:2.82e-03, fs:0.63576 (r=0.485,p=0.923),  time:17.790, tt:4091.652\n",
      "Ep:230, loss:0.00000, loss_test:0.10036, lr:2.79e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.800, tt:4111.782\n",
      "Ep:231, loss:0.00000, loss_test:0.10063, lr:2.76e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.800, tt:4129.667\n",
      "Ep:232, loss:0.00000, loss_test:0.10024, lr:2.73e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.806, tt:4148.739\n",
      "Ep:233, loss:0.00000, loss_test:0.09990, lr:2.71e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.811, tt:4167.843\n",
      "Ep:234, loss:0.00000, loss_test:0.10022, lr:2.68e-03, fs:0.63158 (r=0.485,p=0.906),  time:17.820, tt:4187.719\n",
      "Ep:235, loss:0.00000, loss_test:0.10027, lr:2.65e-03, fs:0.63576 (r=0.485,p=0.923),  time:17.825, tt:4206.803\n",
      "Ep:236, loss:0.00000, loss_test:0.10050, lr:2.63e-03, fs:0.63576 (r=0.485,p=0.923),  time:17.831, tt:4225.968\n",
      "Ep:237, loss:0.00000, loss_test:0.10097, lr:2.60e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.838, tt:4245.559\n",
      "Ep:238, loss:0.00000, loss_test:0.10082, lr:2.57e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.845, tt:4264.963\n",
      "Ep:239, loss:0.00000, loss_test:0.10039, lr:2.55e-03, fs:0.64000 (r=0.485,p=0.941),  time:17.851, tt:4284.209\n",
      "Ep:240, loss:0.00000, loss_test:0.10128, lr:2.52e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.862, tt:4304.669\n",
      "Ep:241, loss:0.00000, loss_test:0.10167, lr:2.50e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.866, tt:4323.533\n",
      "Ep:242, loss:0.00000, loss_test:0.10143, lr:2.47e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.874, tt:4343.313\n",
      "Ep:243, loss:0.00000, loss_test:0.10136, lr:2.45e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.875, tt:4361.453\n",
      "Ep:244, loss:0.00000, loss_test:0.10140, lr:2.42e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.881, tt:4380.754\n",
      "Ep:245, loss:0.00000, loss_test:0.10128, lr:2.40e-03, fs:0.62667 (r=0.475,p=0.922),  time:17.886, tt:4399.912\n",
      "Ep:246, loss:0.00000, loss_test:0.10141, lr:2.38e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.891, tt:4418.959\n",
      "Ep:247, loss:0.00000, loss_test:0.10236, lr:2.35e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.896, tt:4438.166\n",
      "Ep:248, loss:0.00000, loss_test:0.10256, lr:2.33e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.898, tt:4456.583\n",
      "Ep:249, loss:0.00000, loss_test:0.10207, lr:2.31e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.900, tt:4475.075\n",
      "Ep:250, loss:0.00000, loss_test:0.10156, lr:2.28e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.903, tt:4493.711\n",
      "Ep:251, loss:0.00000, loss_test:0.10157, lr:2.26e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.900, tt:4510.823\n",
      "Ep:252, loss:0.00000, loss_test:0.10163, lr:2.24e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.904, tt:4529.807\n",
      "Ep:253, loss:0.00000, loss_test:0.10188, lr:2.21e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.910, tt:4549.183\n",
      "Ep:254, loss:0.00000, loss_test:0.10276, lr:2.19e-03, fs:0.62667 (r=0.475,p=0.922),  time:17.917, tt:4568.779\n",
      "Ep:255, loss:0.00000, loss_test:0.10302, lr:2.17e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.921, tt:4587.870\n",
      "Ep:256, loss:0.00000, loss_test:0.10249, lr:2.15e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.921, tt:4605.811\n",
      "Ep:257, loss:0.00000, loss_test:0.10189, lr:2.13e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.927, tt:4625.260\n",
      "Ep:258, loss:0.00000, loss_test:0.10192, lr:2.11e-03, fs:0.62667 (r=0.475,p=0.922),  time:17.928, tt:4643.386\n",
      "Ep:259, loss:0.00000, loss_test:0.10218, lr:2.08e-03, fs:0.62252 (r=0.475,p=0.904),  time:17.926, tt:4660.641\n",
      "Ep:260, loss:0.00000, loss_test:0.10239, lr:2.06e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.931, tt:4679.922\n",
      "Ep:261, loss:0.00000, loss_test:0.10259, lr:2.04e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.934, tt:4698.710\n",
      "Ep:262, loss:0.00000, loss_test:0.10250, lr:2.02e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.932, tt:4716.201\n",
      "Ep:263, loss:0.00000, loss_test:0.10219, lr:2.00e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.941, tt:4736.525\n",
      "Ep:264, loss:0.00000, loss_test:0.10195, lr:1.98e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.945, tt:4755.319\n",
      "Ep:265, loss:0.00000, loss_test:0.10219, lr:1.96e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.942, tt:4772.674\n",
      "Ep:266, loss:0.00000, loss_test:0.10241, lr:1.94e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.947, tt:4791.936\n",
      "Ep:267, loss:0.00000, loss_test:0.10243, lr:1.92e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.952, tt:4811.119\n",
      "Ep:268, loss:0.00000, loss_test:0.10242, lr:1.90e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.958, tt:4830.612\n",
      "Ep:269, loss:0.00000, loss_test:0.10237, lr:1.89e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.962, tt:4849.798\n",
      "Ep:270, loss:0.00000, loss_test:0.10238, lr:1.87e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.967, tt:4869.042\n",
      "Ep:271, loss:0.00000, loss_test:0.10243, lr:1.85e-03, fs:0.62667 (r=0.475,p=0.922),  time:17.970, tt:4887.782\n",
      "Ep:272, loss:0.00000, loss_test:0.10237, lr:1.83e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.975, tt:4907.199\n",
      "Ep:273, loss:0.00000, loss_test:0.10231, lr:1.81e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.979, tt:4926.363\n",
      "Ep:274, loss:0.00000, loss_test:0.10244, lr:1.79e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.982, tt:4944.999\n",
      "Ep:275, loss:0.00000, loss_test:0.10250, lr:1.78e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.985, tt:4963.963\n",
      "Ep:276, loss:0.00000, loss_test:0.10264, lr:1.76e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.985, tt:4981.978\n",
      "Ep:277, loss:0.00000, loss_test:0.10262, lr:1.74e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.987, tt:5000.294\n",
      "Ep:278, loss:0.00000, loss_test:0.10243, lr:1.72e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.992, tt:5019.862\n",
      "Ep:279, loss:0.00000, loss_test:0.10223, lr:1.71e-03, fs:0.63087 (r=0.475,p=0.940),  time:17.998, tt:5039.456\n",
      "Ep:280, loss:0.00000, loss_test:0.10253, lr:1.69e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.001, tt:5058.256\n",
      "Ep:281, loss:0.00000, loss_test:0.10273, lr:1.67e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.009, tt:5078.458\n",
      "Ep:282, loss:0.00000, loss_test:0.10277, lr:1.65e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.011, tt:5097.131\n",
      "Ep:283, loss:0.00000, loss_test:0.10271, lr:1.64e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.016, tt:5116.594\n",
      "Ep:284, loss:0.00000, loss_test:0.10252, lr:1.62e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.017, tt:5134.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:285, loss:0.00000, loss_test:0.10254, lr:1.61e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.028, tt:5156.034\n",
      "Ep:286, loss:0.00000, loss_test:0.10264, lr:1.59e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.026, tt:5173.344\n",
      "Ep:287, loss:0.00000, loss_test:0.10279, lr:1.57e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.028, tt:5192.139\n",
      "Ep:288, loss:0.00000, loss_test:0.10276, lr:1.56e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.030, tt:5210.587\n",
      "Ep:289, loss:0.00000, loss_test:0.10261, lr:1.54e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.033, tt:5229.468\n",
      "Ep:290, loss:0.00000, loss_test:0.10253, lr:1.53e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.036, tt:5248.342\n",
      "Ep:291, loss:0.00000, loss_test:0.10265, lr:1.51e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.041, tt:5267.854\n",
      "Ep:292, loss:0.00000, loss_test:0.10275, lr:1.50e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.044, tt:5286.814\n",
      "Ep:293, loss:0.00000, loss_test:0.10277, lr:1.48e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.046, tt:5305.474\n",
      "Ep:294, loss:0.00000, loss_test:0.10278, lr:1.47e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.051, tt:5324.971\n",
      "Ep:295, loss:0.00000, loss_test:0.10286, lr:1.45e-03, fs:0.63087 (r=0.475,p=0.940),  time:18.051, tt:5343.184\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14310, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.547, tt:8.547\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14283, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.684, tt:19.367\n",
      "Ep:2, loss:0.00004, loss_test:0.14243, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.016, tt:36.047\n",
      "Ep:3, loss:0.00004, loss_test:0.14188, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.931, tt:51.726\n",
      "Ep:4, loss:0.00004, loss_test:0.14117, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.695, tt:68.476\n",
      "Ep:5, loss:0.00004, loss_test:0.14028, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.206, tt:85.239\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13915, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.407, tt:100.848\n",
      "Ep:7, loss:0.00004, loss_test:0.13770, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.660, tt:117.283\n",
      "Ep:8, loss:0.00004, loss_test:0.13588, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:14.834, tt:133.503\n",
      "Ep:9, loss:0.00004, loss_test:0.13350, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:14.973, tt:149.726\n",
      "Ep:10, loss:0.00004, loss_test:0.13047, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:15.001, tt:165.006\n",
      "Ep:11, loss:0.00003, loss_test:0.12697, lr:1.00e-02, fs:0.63396 (r=0.848,p=0.506),  time:15.125, tt:181.503\n",
      "Ep:12, loss:0.00003, loss_test:0.12323, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:15.177, tt:197.298\n",
      "Ep:13, loss:0.00003, loss_test:0.11953, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:15.384, tt:215.381\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.11715, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:15.443, tt:231.650\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.11643, lr:1.00e-02, fs:0.67000 (r=0.677,p=0.663),  time:15.419, tt:246.708\n",
      "Ep:16, loss:0.00003, loss_test:0.11576, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:15.482, tt:263.195\n",
      "Ep:17, loss:0.00003, loss_test:0.11518, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:15.541, tt:279.734\n",
      "Ep:18, loss:0.00003, loss_test:0.11539, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:15.531, tt:295.092\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11545, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:15.572, tt:311.446\n",
      "Ep:20, loss:0.00003, loss_test:0.11420, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:15.575, tt:327.069\n",
      "Ep:21, loss:0.00003, loss_test:0.11176, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:15.626, tt:343.781\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10955, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:15.676, tt:360.538\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10777, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:15.653, tt:375.663\n",
      "Ep:24, loss:0.00003, loss_test:0.10653, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:15.682, tt:392.058\n",
      "Ep:25, loss:0.00003, loss_test:0.10523, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:15.682, tt:407.720\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.10419, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:15.682, tt:423.420\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.10318, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:15.677, tt:438.961\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.10173, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:15.658, tt:454.074\n",
      "Ep:29, loss:0.00003, loss_test:0.10044, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:15.675, tt:470.245\n",
      "Ep:30, loss:0.00002, loss_test:0.09951, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:15.707, tt:486.924\n",
      "Ep:31, loss:0.00002, loss_test:0.09868, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:15.731, tt:503.383\n",
      "Ep:32, loss:0.00002, loss_test:0.09768, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:15.766, tt:520.270\n",
      "Ep:33, loss:0.00002, loss_test:0.09672, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:15.797, tt:537.103\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.09583, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:15.820, tt:553.702\n",
      "Ep:35, loss:0.00002, loss_test:0.09487, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:15.832, tt:569.945\n",
      "Ep:36, loss:0.00002, loss_test:0.09396, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:15.841, tt:586.105\n",
      "Ep:37, loss:0.00002, loss_test:0.09325, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:15.856, tt:602.536\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.09271, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:15.864, tt:618.708\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.09192, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:15.891, tt:635.643\n",
      "Ep:40, loss:0.00002, loss_test:0.09106, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:15.909, tt:652.263\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.09033, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:15.914, tt:668.372\n",
      "Ep:42, loss:0.00002, loss_test:0.08977, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:15.910, tt:684.139\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.08929, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:15.928, tt:700.813\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.08886, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.936, tt:717.128\n",
      "Ep:45, loss:0.00002, loss_test:0.08839, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:15.957, tt:734.030\n",
      "Ep:46, loss:0.00002, loss_test:0.08792, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:15.946, tt:749.481\n",
      "Ep:47, loss:0.00002, loss_test:0.08744, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:15.937, tt:764.964\n",
      "Ep:48, loss:0.00002, loss_test:0.08697, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:15.952, tt:781.652\n",
      "Ep:49, loss:0.00002, loss_test:0.08661, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:15.934, tt:796.702\n",
      "Ep:50, loss:0.00002, loss_test:0.08641, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:15.900, tt:810.887\n",
      "Ep:51, loss:0.00002, loss_test:0.08619, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.888, tt:826.166\n",
      "Ep:52, loss:0.00002, loss_test:0.08596, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:15.884, tt:841.849\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.08578, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:15.864, tt:856.671\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00002, loss_test:0.08566, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:15.840, tt:871.217\n",
      "Ep:55, loss:0.00002, loss_test:0.08552, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:15.830, tt:886.504\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.08522, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:15.802, tt:900.686\n",
      "Ep:57, loss:0.00002, loss_test:0.08491, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:15.791, tt:915.893\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.08479, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:15.781, tt:931.068\n",
      "Ep:59, loss:0.00002, loss_test:0.08480, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:15.788, tt:947.307\n",
      "Ep:60, loss:0.00002, loss_test:0.08465, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:15.779, tt:962.534\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.08443, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:15.769, tt:977.655\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.08437, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:15.762, tt:992.983\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.08442, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:15.756, tt:1008.355\n",
      "Ep:64, loss:0.00002, loss_test:0.08445, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:15.756, tt:1024.127\n",
      "Ep:65, loss:0.00002, loss_test:0.08439, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:15.730, tt:1038.164\n",
      "Ep:66, loss:0.00002, loss_test:0.08427, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:15.713, tt:1052.805\n",
      "Ep:67, loss:0.00001, loss_test:0.08421, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:15.699, tt:1067.507\n",
      "Ep:68, loss:0.00001, loss_test:0.08422, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:15.678, tt:1081.810\n",
      "Ep:69, loss:0.00001, loss_test:0.08418, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:15.662, tt:1096.312\n",
      "Ep:70, loss:0.00001, loss_test:0.08411, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:15.647, tt:1110.959\n",
      "Ep:71, loss:0.00001, loss_test:0.08406, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:15.643, tt:1126.299\n",
      "Ep:72, loss:0.00001, loss_test:0.08425, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:15.648, tt:1142.270\n",
      "Ep:73, loss:0.00001, loss_test:0.08428, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:15.642, tt:1157.476\n",
      "Ep:74, loss:0.00001, loss_test:0.08425, lr:9.90e-03, fs:0.78307 (r=0.747,p=0.822),  time:15.650, tt:1173.750\n",
      "Ep:75, loss:0.00001, loss_test:0.08430, lr:9.80e-03, fs:0.77895 (r=0.747,p=0.813),  time:15.642, tt:1188.810\n",
      "Ep:76, loss:0.00001, loss_test:0.08446, lr:9.70e-03, fs:0.78307 (r=0.747,p=0.822),  time:15.656, tt:1205.513\n",
      "Ep:77, loss:0.00001, loss_test:0.08445, lr:9.61e-03, fs:0.78307 (r=0.747,p=0.822),  time:15.661, tt:1221.524\n",
      "Ep:78, loss:0.00001, loss_test:0.08418, lr:9.51e-03, fs:0.78307 (r=0.747,p=0.822),  time:15.663, tt:1237.342\n",
      "Ep:79, loss:0.00001, loss_test:0.08412, lr:9.41e-03, fs:0.77895 (r=0.747,p=0.813),  time:15.648, tt:1251.874\n",
      "Ep:80, loss:0.00001, loss_test:0.08431, lr:9.32e-03, fs:0.78723 (r=0.747,p=0.831),  time:15.653, tt:1267.928\n",
      "Ep:81, loss:0.00001, loss_test:0.08433, lr:9.23e-03, fs:0.78307 (r=0.747,p=0.822),  time:15.644, tt:1282.844\n",
      "Ep:82, loss:0.00001, loss_test:0.08424, lr:9.14e-03, fs:0.78307 (r=0.747,p=0.822),  time:15.630, tt:1297.275\n",
      "Ep:83, loss:0.00001, loss_test:0.08419, lr:9.04e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.636, tt:1313.394\n",
      "Ep:84, loss:0.00001, loss_test:0.08418, lr:8.95e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.633, tt:1328.818\n",
      "Ep:85, loss:0.00001, loss_test:0.08415, lr:8.86e-03, fs:0.81250 (r=0.788,p=0.839),  time:15.627, tt:1343.928\n",
      "Ep:86, loss:0.00001, loss_test:0.08412, lr:8.78e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.628, tt:1359.672\n",
      "Ep:87, loss:0.00001, loss_test:0.08419, lr:8.69e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.612, tt:1373.879\n",
      "Ep:88, loss:0.00001, loss_test:0.08428, lr:8.60e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.608, tt:1389.155\n",
      "Ep:89, loss:0.00001, loss_test:0.08437, lr:8.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.580, tt:1402.162\n",
      "Ep:90, loss:0.00001, loss_test:0.08448, lr:8.43e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.572, tt:1417.066\n",
      "Ep:91, loss:0.00001, loss_test:0.08470, lr:8.35e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.565, tt:1431.985\n",
      "Ep:92, loss:0.00001, loss_test:0.08500, lr:8.26e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.565, tt:1447.503\n",
      "Ep:93, loss:0.00001, loss_test:0.08507, lr:8.18e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.563, tt:1462.930\n",
      "Ep:94, loss:0.00001, loss_test:0.08507, lr:8.10e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.554, tt:1477.633\n",
      "Ep:95, loss:0.00001, loss_test:0.08522, lr:8.02e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.563, tt:1494.008\n",
      "Ep:96, loss:0.00001, loss_test:0.08552, lr:7.94e-03, fs:0.78261 (r=0.727,p=0.847),  time:15.575, tt:1510.816\n",
      "Ep:97, loss:0.00001, loss_test:0.08574, lr:7.86e-03, fs:0.78261 (r=0.727,p=0.847),  time:15.580, tt:1526.851\n",
      "Ep:98, loss:0.00001, loss_test:0.08577, lr:7.78e-03, fs:0.78261 (r=0.727,p=0.847),  time:15.593, tt:1543.674\n",
      "Ep:99, loss:0.00001, loss_test:0.08600, lr:7.70e-03, fs:0.78261 (r=0.727,p=0.847),  time:15.596, tt:1559.551\n",
      "Ep:100, loss:0.00001, loss_test:0.08642, lr:7.62e-03, fs:0.77596 (r=0.717,p=0.845),  time:15.623, tt:1577.898\n",
      "Ep:101, loss:0.00001, loss_test:0.08680, lr:7.55e-03, fs:0.76923 (r=0.707,p=0.843),  time:15.629, tt:1594.180\n",
      "Ep:102, loss:0.00001, loss_test:0.08693, lr:7.47e-03, fs:0.76243 (r=0.697,p=0.841),  time:15.640, tt:1610.883\n",
      "Ep:103, loss:0.00001, loss_test:0.08695, lr:7.40e-03, fs:0.76243 (r=0.697,p=0.841),  time:15.638, tt:1626.354\n",
      "Ep:104, loss:0.00001, loss_test:0.08704, lr:7.32e-03, fs:0.76243 (r=0.697,p=0.841),  time:15.649, tt:1643.189\n",
      "Ep:105, loss:0.00001, loss_test:0.08716, lr:7.25e-03, fs:0.76243 (r=0.697,p=0.841),  time:15.655, tt:1659.389\n",
      "Ep:106, loss:0.00001, loss_test:0.08731, lr:7.18e-03, fs:0.74860 (r=0.677,p=0.838),  time:15.662, tt:1675.824\n",
      "Ep:107, loss:0.00001, loss_test:0.08755, lr:7.11e-03, fs:0.74860 (r=0.677,p=0.838),  time:15.671, tt:1692.445\n",
      "Ep:108, loss:0.00001, loss_test:0.08763, lr:7.03e-03, fs:0.75556 (r=0.687,p=0.840),  time:15.670, tt:1708.079\n",
      "Ep:109, loss:0.00001, loss_test:0.08773, lr:6.96e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.665, tt:1723.205\n",
      "Ep:110, loss:0.00001, loss_test:0.08788, lr:6.89e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.673, tt:1739.695\n",
      "Ep:111, loss:0.00001, loss_test:0.08789, lr:6.83e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.667, tt:1754.705\n",
      "Ep:112, loss:0.00001, loss_test:0.08783, lr:6.76e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.661, tt:1769.734\n",
      "Ep:113, loss:0.00001, loss_test:0.08802, lr:6.69e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.665, tt:1785.819\n",
      "Ep:114, loss:0.00001, loss_test:0.08795, lr:6.62e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.679, tt:1803.114\n",
      "Ep:115, loss:0.00001, loss_test:0.08797, lr:6.56e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.676, tt:1818.438\n",
      "Ep:116, loss:0.00001, loss_test:0.08809, lr:6.49e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.665, tt:1832.778\n",
      "Ep:117, loss:0.00001, loss_test:0.08808, lr:6.43e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.658, tt:1847.671\n",
      "Ep:118, loss:0.00001, loss_test:0.08803, lr:6.36e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.666, tt:1864.226\n",
      "Ep:119, loss:0.00001, loss_test:0.08814, lr:6.30e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.660, tt:1879.165\n",
      "Ep:120, loss:0.00001, loss_test:0.08824, lr:6.24e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.654, tt:1894.153\n",
      "Ep:121, loss:0.00001, loss_test:0.08823, lr:6.17e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.651, tt:1909.376\n",
      "Ep:122, loss:0.00001, loss_test:0.08820, lr:6.11e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.654, tt:1925.492\n",
      "Ep:123, loss:0.00001, loss_test:0.08815, lr:6.05e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.650, tt:1940.574\n",
      "Ep:124, loss:0.00001, loss_test:0.08810, lr:5.99e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.649, tt:1956.065\n",
      "Ep:125, loss:0.00001, loss_test:0.08813, lr:5.93e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.648, tt:1971.672\n",
      "Ep:126, loss:0.00001, loss_test:0.08832, lr:5.87e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.641, tt:1986.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00001, loss_test:0.08845, lr:5.81e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.642, tt:2002.140\n",
      "Ep:128, loss:0.00001, loss_test:0.08840, lr:5.75e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.645, tt:2018.231\n",
      "Ep:129, loss:0.00001, loss_test:0.08839, lr:5.70e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.647, tt:2034.167\n",
      "Ep:130, loss:0.00001, loss_test:0.08844, lr:5.64e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.653, tt:2050.565\n",
      "Ep:131, loss:0.00001, loss_test:0.08844, lr:5.58e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.642, tt:2064.793\n",
      "Ep:132, loss:0.00001, loss_test:0.08832, lr:5.53e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.643, tt:2080.544\n",
      "Ep:133, loss:0.00001, loss_test:0.08846, lr:5.47e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.636, tt:2095.231\n",
      "Ep:134, loss:0.00001, loss_test:0.08841, lr:5.42e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.636, tt:2110.903\n",
      "Ep:135, loss:0.00001, loss_test:0.08828, lr:5.36e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.630, tt:2125.683\n",
      "Ep:136, loss:0.00001, loss_test:0.08829, lr:5.31e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.620, tt:2139.907\n",
      "Ep:137, loss:0.00001, loss_test:0.08836, lr:5.26e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.612, tt:2154.464\n",
      "Ep:138, loss:0.00001, loss_test:0.08830, lr:5.20e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.611, tt:2169.955\n",
      "Ep:139, loss:0.00001, loss_test:0.08822, lr:5.15e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.613, tt:2185.782\n",
      "Ep:140, loss:0.00001, loss_test:0.08838, lr:5.10e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.612, tt:2201.288\n",
      "Ep:141, loss:0.00001, loss_test:0.08841, lr:5.05e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.612, tt:2216.901\n",
      "Ep:142, loss:0.00001, loss_test:0.08829, lr:5.00e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.613, tt:2232.631\n",
      "Ep:143, loss:0.00001, loss_test:0.08846, lr:4.95e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.620, tt:2249.230\n",
      "Ep:144, loss:0.00001, loss_test:0.08857, lr:4.90e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.614, tt:2264.077\n",
      "Ep:145, loss:0.00001, loss_test:0.08862, lr:4.85e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.613, tt:2279.520\n",
      "Ep:146, loss:0.00001, loss_test:0.08865, lr:4.80e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.615, tt:2295.372\n",
      "Ep:147, loss:0.00001, loss_test:0.08875, lr:4.75e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.612, tt:2310.511\n",
      "Ep:148, loss:0.00001, loss_test:0.08882, lr:4.71e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.608, tt:2325.655\n",
      "Ep:149, loss:0.00001, loss_test:0.08895, lr:4.66e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.608, tt:2341.151\n",
      "Ep:150, loss:0.00001, loss_test:0.08912, lr:4.61e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.607, tt:2356.600\n",
      "Ep:151, loss:0.00001, loss_test:0.08916, lr:4.57e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.604, tt:2371.824\n",
      "Ep:152, loss:0.00001, loss_test:0.08910, lr:4.52e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.606, tt:2387.738\n",
      "Ep:153, loss:0.00001, loss_test:0.08911, lr:4.48e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.602, tt:2402.718\n",
      "Ep:154, loss:0.00001, loss_test:0.08916, lr:4.43e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.600, tt:2418.045\n",
      "Ep:155, loss:0.00001, loss_test:0.08918, lr:4.39e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.596, tt:2433.005\n",
      "Ep:156, loss:0.00001, loss_test:0.08932, lr:4.34e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.582, tt:2446.376\n",
      "Ep:157, loss:0.00001, loss_test:0.08934, lr:4.30e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.577, tt:2461.159\n",
      "Ep:158, loss:0.00001, loss_test:0.08929, lr:4.26e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.575, tt:2476.479\n",
      "Ep:159, loss:0.00001, loss_test:0.08932, lr:4.21e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.573, tt:2491.703\n",
      "Ep:160, loss:0.00001, loss_test:0.08940, lr:4.17e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.570, tt:2506.749\n",
      "Ep:161, loss:0.00001, loss_test:0.08946, lr:4.13e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.569, tt:2522.236\n",
      "Ep:162, loss:0.00001, loss_test:0.08950, lr:4.09e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.569, tt:2537.686\n",
      "Ep:163, loss:0.00001, loss_test:0.08950, lr:4.05e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.568, tt:2553.080\n",
      "Ep:164, loss:0.00001, loss_test:0.08943, lr:4.01e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.570, tt:2569.132\n",
      "Ep:165, loss:0.00001, loss_test:0.08946, lr:3.97e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.562, tt:2583.355\n",
      "Ep:166, loss:0.00001, loss_test:0.08953, lr:3.93e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.555, tt:2597.653\n",
      "Ep:167, loss:0.00001, loss_test:0.08948, lr:3.89e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.553, tt:2612.831\n",
      "Ep:168, loss:0.00001, loss_test:0.08943, lr:3.85e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.545, tt:2627.081\n",
      "Ep:169, loss:0.00001, loss_test:0.08948, lr:3.81e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.546, tt:2642.772\n",
      "Ep:170, loss:0.00001, loss_test:0.08950, lr:3.77e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.547, tt:2658.508\n",
      "Ep:171, loss:0.00001, loss_test:0.08946, lr:3.73e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.546, tt:2673.879\n",
      "Ep:172, loss:0.00001, loss_test:0.08948, lr:3.70e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.544, tt:2689.190\n",
      "Ep:173, loss:0.00001, loss_test:0.08954, lr:3.66e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.549, tt:2705.473\n",
      "Ep:174, loss:0.00001, loss_test:0.08953, lr:3.62e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.549, tt:2720.996\n",
      "Ep:175, loss:0.00001, loss_test:0.08952, lr:3.59e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.549, tt:2736.619\n",
      "Ep:176, loss:0.00001, loss_test:0.08960, lr:3.55e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.550, tt:2752.368\n",
      "Ep:177, loss:0.00001, loss_test:0.08961, lr:3.52e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.550, tt:2767.853\n",
      "Ep:178, loss:0.00001, loss_test:0.08967, lr:3.48e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.546, tt:2782.684\n",
      "Ep:179, loss:0.00001, loss_test:0.08969, lr:3.45e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.547, tt:2798.427\n",
      "Ep:180, loss:0.00001, loss_test:0.08965, lr:3.41e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.548, tt:2814.147\n",
      "Ep:181, loss:0.00001, loss_test:0.08971, lr:3.38e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.552, tt:2830.381\n",
      "Ep:182, loss:0.00001, loss_test:0.08979, lr:3.34e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.548, tt:2845.290\n",
      "Ep:183, loss:0.00001, loss_test:0.08975, lr:3.31e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.549, tt:2860.961\n",
      "Ep:184, loss:0.00001, loss_test:0.08968, lr:3.28e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.551, tt:2876.868\n",
      "Ep:185, loss:0.00001, loss_test:0.08993, lr:3.24e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.548, tt:2891.967\n",
      "Ep:186, loss:0.00001, loss_test:0.09005, lr:3.21e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.546, tt:2907.138\n",
      "Ep:187, loss:0.00001, loss_test:0.09005, lr:3.18e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.550, tt:2923.349\n",
      "Ep:188, loss:0.00001, loss_test:0.09003, lr:3.15e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.552, tt:2939.308\n",
      "Ep:189, loss:0.00001, loss_test:0.09020, lr:3.12e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.554, tt:2955.293\n",
      "Ep:190, loss:0.00001, loss_test:0.09023, lr:3.09e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.550, tt:2970.020\n",
      "Ep:191, loss:0.00001, loss_test:0.09013, lr:3.05e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.548, tt:2985.303\n",
      "Ep:192, loss:0.00001, loss_test:0.09020, lr:3.02e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.542, tt:2999.548\n",
      "Ep:193, loss:0.00001, loss_test:0.09033, lr:2.99e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.538, tt:3014.360\n",
      "Ep:194, loss:0.00001, loss_test:0.09033, lr:2.96e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.539, tt:3030.022\n",
      "Ep:195, loss:0.00001, loss_test:0.09024, lr:2.93e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.540, tt:3045.853\n",
      "Ep:196, loss:0.00001, loss_test:0.09023, lr:2.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.541, tt:3061.587\n",
      "Ep:197, loss:0.00001, loss_test:0.09033, lr:2.88e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.557, tt:3080.270\n",
      "Ep:198, loss:0.00001, loss_test:0.09039, lr:2.85e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.563, tt:3097.036\n",
      "Ep:199, loss:0.00001, loss_test:0.09037, lr:2.82e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.562, tt:3112.439\n",
      "Ep:200, loss:0.00001, loss_test:0.09038, lr:2.79e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.561, tt:3127.766\n",
      "Ep:201, loss:0.00001, loss_test:0.09044, lr:2.76e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.563, tt:3143.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00001, loss_test:0.09052, lr:2.73e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.561, tt:3158.885\n",
      "Ep:203, loss:0.00001, loss_test:0.09050, lr:2.71e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.562, tt:3174.696\n",
      "Ep:204, loss:0.00001, loss_test:0.09059, lr:2.68e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.566, tt:3191.041\n",
      "Ep:205, loss:0.00001, loss_test:0.09064, lr:2.65e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.564, tt:3206.156\n",
      "Ep:206, loss:0.00001, loss_test:0.09052, lr:2.63e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.563, tt:3221.575\n",
      "Ep:207, loss:0.00001, loss_test:0.09056, lr:2.60e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.564, tt:3237.359\n",
      "Ep:208, loss:0.00001, loss_test:0.09064, lr:2.57e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.565, tt:3253.119\n",
      "Ep:209, loss:0.00001, loss_test:0.09065, lr:2.55e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.566, tt:3268.954\n",
      "Ep:210, loss:0.00001, loss_test:0.09061, lr:2.52e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.567, tt:3284.670\n",
      "Ep:211, loss:0.00001, loss_test:0.09065, lr:2.50e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.568, tt:3300.469\n",
      "Ep:212, loss:0.00001, loss_test:0.09070, lr:2.47e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.573, tt:3316.944\n",
      "Ep:213, loss:0.00001, loss_test:0.09068, lr:2.45e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.574, tt:3332.867\n",
      "Ep:214, loss:0.00001, loss_test:0.09063, lr:2.42e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.577, tt:3349.017\n",
      "Ep:215, loss:0.00001, loss_test:0.09069, lr:2.40e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.582, tt:3365.780\n",
      "Ep:216, loss:0.00001, loss_test:0.09076, lr:2.38e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.584, tt:3381.825\n",
      "Ep:217, loss:0.00001, loss_test:0.09075, lr:2.35e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.586, tt:3397.824\n",
      "Ep:218, loss:0.00001, loss_test:0.09065, lr:2.33e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.587, tt:3413.448\n",
      "Ep:219, loss:0.00001, loss_test:0.09074, lr:2.31e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.588, tt:3429.279\n",
      "Ep:220, loss:0.00001, loss_test:0.09089, lr:2.28e-03, fs:0.73256 (r=0.636,p=0.863),  time:15.593, tt:3446.038\n",
      "Ep:221, loss:0.00001, loss_test:0.09083, lr:2.26e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.594, tt:3461.777\n",
      "Ep:222, loss:0.00001, loss_test:0.09069, lr:2.24e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.599, tt:3478.473\n",
      "Ep:223, loss:0.00001, loss_test:0.09072, lr:2.21e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.603, tt:3495.013\n",
      "Ep:224, loss:0.00001, loss_test:0.09082, lr:2.19e-03, fs:0.73256 (r=0.636,p=0.863),  time:15.604, tt:3511.004\n",
      "Ep:225, loss:0.00001, loss_test:0.09078, lr:2.17e-03, fs:0.73256 (r=0.636,p=0.863),  time:15.605, tt:3526.721\n",
      "Ep:226, loss:0.00001, loss_test:0.09061, lr:2.15e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.604, tt:3542.187\n",
      "Ep:227, loss:0.00001, loss_test:0.09064, lr:2.13e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.606, tt:3558.066\n",
      "Ep:228, loss:0.00001, loss_test:0.09080, lr:2.11e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.606, tt:3573.689\n",
      "Ep:229, loss:0.00001, loss_test:0.09082, lr:2.08e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.605, tt:3589.124\n",
      "Ep:230, loss:0.00001, loss_test:0.09072, lr:2.06e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.603, tt:3604.254\n",
      "Ep:231, loss:0.00001, loss_test:0.09060, lr:2.04e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.601, tt:3619.337\n",
      "Ep:232, loss:0.00001, loss_test:0.09065, lr:2.02e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.599, tt:3634.599\n",
      "Ep:233, loss:0.00001, loss_test:0.09076, lr:2.00e-03, fs:0.73256 (r=0.636,p=0.863),  time:15.599, tt:3650.118\n",
      "Ep:234, loss:0.00001, loss_test:0.09077, lr:1.98e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.598, tt:3665.537\n",
      "Ep:235, loss:0.00001, loss_test:0.09071, lr:1.96e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.596, tt:3680.700\n",
      "Ep:236, loss:0.00001, loss_test:0.09071, lr:1.94e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.599, tt:3696.851\n",
      "Ep:237, loss:0.00001, loss_test:0.09078, lr:1.92e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.614, tt:3716.186\n",
      "Ep:238, loss:0.00001, loss_test:0.09080, lr:1.90e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.613, tt:3731.463\n",
      "Ep:239, loss:0.00001, loss_test:0.09074, lr:1.89e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.612, tt:3746.910\n",
      "Ep:240, loss:0.00001, loss_test:0.09075, lr:1.87e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.613, tt:3762.852\n",
      "Ep:241, loss:0.00001, loss_test:0.09084, lr:1.85e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.614, tt:3778.640\n",
      "Ep:242, loss:0.00001, loss_test:0.09079, lr:1.83e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.620, tt:3795.578\n",
      "Ep:243, loss:0.00001, loss_test:0.09071, lr:1.81e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.622, tt:3811.872\n",
      "Ep:244, loss:0.00001, loss_test:0.09074, lr:1.79e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.623, tt:3827.555\n",
      "Ep:245, loss:0.00001, loss_test:0.09078, lr:1.78e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.626, tt:3843.898\n",
      "Ep:246, loss:0.00001, loss_test:0.09078, lr:1.76e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.623, tt:3858.849\n",
      "Ep:247, loss:0.00001, loss_test:0.09076, lr:1.74e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.623, tt:3874.418\n",
      "Ep:248, loss:0.00001, loss_test:0.09082, lr:1.72e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.622, tt:3889.796\n",
      "Ep:249, loss:0.00001, loss_test:0.09082, lr:1.71e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.621, tt:3905.319\n",
      "Ep:250, loss:0.00001, loss_test:0.09079, lr:1.69e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.620, tt:3920.655\n",
      "Ep:251, loss:0.00001, loss_test:0.09081, lr:1.67e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.623, tt:3937.022\n",
      "Ep:252, loss:0.00001, loss_test:0.09083, lr:1.65e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.624, tt:3952.926\n",
      "Ep:253, loss:0.00001, loss_test:0.09084, lr:1.64e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.628, tt:3969.613\n",
      "Ep:254, loss:0.00001, loss_test:0.09084, lr:1.62e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.632, tt:3986.080\n",
      "Ep:255, loss:0.00001, loss_test:0.09080, lr:1.61e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.630, tt:4001.174\n",
      "Ep:256, loss:0.00001, loss_test:0.09087, lr:1.59e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.630, tt:4016.826\n",
      "Ep:257, loss:0.00001, loss_test:0.09084, lr:1.57e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.631, tt:4032.833\n",
      "Ep:258, loss:0.00001, loss_test:0.09082, lr:1.56e-03, fs:0.72093 (r=0.626,p=0.849),  time:15.627, tt:4047.487\n",
      "Ep:259, loss:0.00001, loss_test:0.09089, lr:1.54e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.630, tt:4063.915\n",
      "Ep:260, loss:0.00001, loss_test:0.09091, lr:1.53e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.630, tt:4079.334\n",
      "Ep:261, loss:0.00001, loss_test:0.09082, lr:1.51e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.628, tt:4094.462\n",
      "Ep:262, loss:0.00001, loss_test:0.09084, lr:1.50e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.625, tt:4109.480\n",
      "Ep:263, loss:0.00001, loss_test:0.09092, lr:1.48e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.624, tt:4124.696\n",
      "Ep:264, loss:0.00001, loss_test:0.09095, lr:1.47e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.615, tt:4137.920\n",
      "Ep:265, loss:0.00001, loss_test:0.09090, lr:1.45e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.614, tt:4153.191\n",
      "Ep:266, loss:0.00001, loss_test:0.09088, lr:1.44e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.613, tt:4168.605\n",
      "Ep:267, loss:0.00001, loss_test:0.09093, lr:1.42e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.610, tt:4183.524\n",
      "Ep:268, loss:0.00001, loss_test:0.09097, lr:1.41e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.610, tt:4198.987\n",
      "Ep:269, loss:0.00001, loss_test:0.09098, lr:1.39e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.605, tt:4213.409\n",
      "Ep:270, loss:0.00001, loss_test:0.09097, lr:1.38e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.604, tt:4228.568\n",
      "Ep:271, loss:0.00001, loss_test:0.09100, lr:1.37e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.599, tt:4243.009\n",
      "Ep:272, loss:0.00001, loss_test:0.09103, lr:1.35e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.595, tt:4257.520\n",
      "Ep:273, loss:0.00001, loss_test:0.09104, lr:1.34e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.595, tt:4272.930\n",
      "Ep:274, loss:0.00001, loss_test:0.09107, lr:1.33e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.593, tt:4288.026\n",
      "Ep:275, loss:0.00001, loss_test:0.09108, lr:1.31e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.590, tt:4302.798\n",
      "Ep:276, loss:0.00001, loss_test:0.09107, lr:1.30e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.587, tt:4317.729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:277, loss:0.00001, loss_test:0.09107, lr:1.29e-03, fs:0.72515 (r=0.626,p=0.861),  time:15.601, tt:4337.189\n",
      "Ep:278, loss:0.00001, loss_test:0.09111, lr:1.27e-03, fs:0.72941 (r=0.626,p=0.873),  time:15.598, tt:4351.923\n",
      "Ep:279, loss:0.00001, loss_test:0.09113, lr:1.26e-03, fs:0.72941 (r=0.626,p=0.873),  time:15.598, tt:4367.486\n",
      "Ep:280, loss:0.00001, loss_test:0.09113, lr:1.25e-03, fs:0.72941 (r=0.626,p=0.873),  time:15.599, tt:4383.397\n",
      "Ep:281, loss:0.00001, loss_test:0.09115, lr:1.24e-03, fs:0.72941 (r=0.626,p=0.873),  time:15.596, tt:4398.172\n",
      "Ep:282, loss:0.00001, loss_test:0.09118, lr:1.22e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.593, tt:4412.934\n",
      "Ep:283, loss:0.00001, loss_test:0.09120, lr:1.21e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.592, tt:4428.092\n",
      "Ep:284, loss:0.00001, loss_test:0.09119, lr:1.20e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.593, tt:4444.084\n",
      "Ep:285, loss:0.00001, loss_test:0.09121, lr:1.19e-03, fs:0.73373 (r=0.626,p=0.886),  time:15.596, tt:4460.472\n",
      "Ep:286, loss:0.00001, loss_test:0.09125, lr:1.18e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.591, tt:4474.749\n",
      "Ep:287, loss:0.00001, loss_test:0.09127, lr:1.16e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.590, tt:4489.940\n",
      "Ep:288, loss:0.00001, loss_test:0.09126, lr:1.15e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.585, tt:4504.167\n",
      "Ep:289, loss:0.00001, loss_test:0.09127, lr:1.14e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.584, tt:4519.425\n",
      "Ep:290, loss:0.00001, loss_test:0.09131, lr:1.13e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.586, tt:4535.639\n",
      "Ep:291, loss:0.00001, loss_test:0.09132, lr:1.12e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.584, tt:4550.663\n",
      "Ep:292, loss:0.00001, loss_test:0.09132, lr:1.11e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.581, tt:4565.282\n",
      "Ep:293, loss:0.00001, loss_test:0.09134, lr:1.10e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.580, tt:4580.459\n",
      "Ep:294, loss:0.00001, loss_test:0.09135, lr:1.08e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.573, tt:4594.110\n",
      "Ep:295, loss:0.00001, loss_test:0.09135, lr:1.07e-03, fs:0.73810 (r=0.626,p=0.899),  time:15.566, tt:4607.621\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14517, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.577, tt:14.577\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14489, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.003, tt:34.006\n",
      "Ep:2, loss:0.00004, loss_test:0.14446, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.182, tt:54.545\n",
      "Ep:3, loss:0.00004, loss_test:0.14385, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.786, tt:75.143\n",
      "Ep:4, loss:0.00004, loss_test:0.14302, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.693, tt:93.466\n",
      "Ep:5, loss:0.00004, loss_test:0.14194, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:19.036, tt:114.218\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.14045, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:19.172, tt:134.204\n",
      "Ep:7, loss:0.00004, loss_test:0.13837, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:19.180, tt:153.443\n",
      "Ep:8, loss:0.00004, loss_test:0.13564, lr:1.00e-02, fs:0.64311 (r=0.919,p=0.495),  time:19.331, tt:173.978\n",
      "Ep:9, loss:0.00004, loss_test:0.13236, lr:1.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:19.427, tt:194.269\n",
      "Ep:10, loss:0.00003, loss_test:0.12842, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:19.441, tt:213.853\n",
      "Ep:11, loss:0.00003, loss_test:0.12507, lr:1.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:19.472, tt:233.660\n",
      "Ep:12, loss:0.00003, loss_test:0.12293, lr:1.00e-02, fs:0.63725 (r=0.657,p=0.619),  time:19.552, tt:254.172\n",
      "Ep:13, loss:0.00003, loss_test:0.12109, lr:1.00e-02, fs:0.62857 (r=0.667,p=0.595),  time:19.625, tt:274.755\n",
      "Ep:14, loss:0.00003, loss_test:0.11992, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:19.713, tt:295.702\n",
      "Ep:15, loss:0.00003, loss_test:0.12009, lr:1.00e-02, fs:0.64706 (r=0.778,p=0.554),  time:19.757, tt:316.113\n",
      "Ep:16, loss:0.00003, loss_test:0.11925, lr:1.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:20.073, tt:341.244\n",
      "Ep:17, loss:0.00003, loss_test:0.11646, lr:9.90e-03, fs:0.67234 (r=0.798,p=0.581),  time:20.087, tt:361.572\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.11296, lr:9.90e-03, fs:0.67580 (r=0.747,p=0.617),  time:20.104, tt:381.972\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11080, lr:9.90e-03, fs:0.66990 (r=0.697,p=0.645),  time:20.128, tt:402.556\n",
      "Ep:20, loss:0.00003, loss_test:0.10934, lr:9.90e-03, fs:0.66667 (r=0.687,p=0.648),  time:20.146, tt:423.073\n",
      "Ep:21, loss:0.00003, loss_test:0.10770, lr:9.90e-03, fs:0.68269 (r=0.717,p=0.651),  time:20.172, tt:443.776\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10655, lr:9.90e-03, fs:0.69767 (r=0.758,p=0.647),  time:20.177, tt:464.072\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10524, lr:9.90e-03, fs:0.70909 (r=0.788,p=0.645),  time:20.192, tt:484.608\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.10294, lr:9.90e-03, fs:0.70968 (r=0.778,p=0.653),  time:20.238, tt:505.952\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.10019, lr:9.90e-03, fs:0.70588 (r=0.727,p=0.686),  time:20.292, tt:527.601\n",
      "Ep:26, loss:0.00002, loss_test:0.09830, lr:9.90e-03, fs:0.70647 (r=0.717,p=0.696),  time:20.294, tt:547.948\n",
      "Ep:27, loss:0.00002, loss_test:0.09658, lr:9.90e-03, fs:0.73000 (r=0.737,p=0.723),  time:20.327, tt:569.167\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.09515, lr:9.90e-03, fs:0.75122 (r=0.778,p=0.726),  time:20.329, tt:589.540\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.09392, lr:9.90e-03, fs:0.75962 (r=0.798,p=0.725),  time:20.312, tt:609.351\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.09232, lr:9.90e-03, fs:0.76847 (r=0.788,p=0.750),  time:20.327, tt:630.137\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.09093, lr:9.90e-03, fs:0.76382 (r=0.768,p=0.760),  time:20.337, tt:650.780\n",
      "Ep:32, loss:0.00002, loss_test:0.08966, lr:9.90e-03, fs:0.76382 (r=0.768,p=0.760),  time:20.338, tt:671.143\n",
      "Ep:33, loss:0.00002, loss_test:0.08834, lr:9.90e-03, fs:0.77000 (r=0.778,p=0.762),  time:20.342, tt:691.627\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.08729, lr:9.90e-03, fs:0.79227 (r=0.828,p=0.759),  time:20.359, tt:712.574\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.08614, lr:9.90e-03, fs:0.78641 (r=0.818,p=0.757),  time:20.342, tt:732.296\n",
      "Ep:36, loss:0.00002, loss_test:0.08521, lr:9.90e-03, fs:0.78818 (r=0.808,p=0.769),  time:20.323, tt:751.956\n",
      "Ep:37, loss:0.00002, loss_test:0.08416, lr:9.90e-03, fs:0.80392 (r=0.828,p=0.781),  time:20.315, tt:771.973\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.08296, lr:9.90e-03, fs:0.81731 (r=0.859,p=0.780),  time:20.288, tt:791.232\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.08192, lr:9.90e-03, fs:0.81159 (r=0.848,p=0.778),  time:20.291, tt:811.655\n",
      "Ep:40, loss:0.00002, loss_test:0.08090, lr:9.90e-03, fs:0.81592 (r=0.828,p=0.804),  time:20.302, tt:832.382\n",
      "Ep:41, loss:0.00002, loss_test:0.08014, lr:9.90e-03, fs:0.80203 (r=0.798,p=0.806),  time:20.292, tt:852.245\n",
      "Ep:42, loss:0.00002, loss_test:0.07925, lr:9.90e-03, fs:0.83902 (r=0.869,p=0.811),  time:20.327, tt:874.042\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.07854, lr:9.90e-03, fs:0.83902 (r=0.869,p=0.811),  time:20.331, tt:894.555\n",
      "Ep:44, loss:0.00002, loss_test:0.07793, lr:9.90e-03, fs:0.82412 (r=0.828,p=0.820),  time:20.337, tt:915.163\n",
      "Ep:45, loss:0.00002, loss_test:0.07757, lr:9.90e-03, fs:0.82587 (r=0.838,p=0.814),  time:20.348, tt:935.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00002, loss_test:0.07684, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:20.345, tt:956.204\n",
      "Ep:47, loss:0.00002, loss_test:0.07638, lr:9.90e-03, fs:0.84158 (r=0.859,p=0.825),  time:20.364, tt:977.452\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.07592, lr:9.90e-03, fs:0.84158 (r=0.859,p=0.825),  time:20.372, tt:998.230\n",
      "Ep:49, loss:0.00001, loss_test:0.07535, lr:9.90e-03, fs:0.84158 (r=0.859,p=0.825),  time:20.361, tt:1018.052\n",
      "Ep:50, loss:0.00001, loss_test:0.07482, lr:9.90e-03, fs:0.84729 (r=0.869,p=0.827),  time:20.357, tt:1038.195\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.07418, lr:9.90e-03, fs:0.86000 (r=0.869,p=0.851),  time:20.366, tt:1059.018\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.07339, lr:9.90e-03, fs:0.85149 (r=0.869,p=0.835),  time:20.366, tt:1079.398\n",
      "Ep:53, loss:0.00001, loss_test:0.07279, lr:9.90e-03, fs:0.85294 (r=0.879,p=0.829),  time:20.383, tt:1100.706\n",
      "Ep:54, loss:0.00001, loss_test:0.07229, lr:9.90e-03, fs:0.85294 (r=0.879,p=0.829),  time:20.359, tt:1119.765\n",
      "Ep:55, loss:0.00001, loss_test:0.07172, lr:9.90e-03, fs:0.85714 (r=0.879,p=0.837),  time:20.351, tt:1139.677\n",
      "Ep:56, loss:0.00001, loss_test:0.07096, lr:9.90e-03, fs:0.85854 (r=0.889,p=0.830),  time:20.361, tt:1160.576\n",
      "Ep:57, loss:0.00001, loss_test:0.07087, lr:9.90e-03, fs:0.85714 (r=0.879,p=0.837),  time:20.360, tt:1180.855\n",
      "Ep:58, loss:0.00001, loss_test:0.07052, lr:9.90e-03, fs:0.85714 (r=0.879,p=0.837),  time:20.360, tt:1201.253\n",
      "Ep:59, loss:0.00001, loss_test:0.07025, lr:9.90e-03, fs:0.86275 (r=0.889,p=0.838),  time:20.355, tt:1221.280\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.07024, lr:9.90e-03, fs:0.85714 (r=0.879,p=0.837),  time:20.356, tt:1241.714\n",
      "Ep:61, loss:0.00001, loss_test:0.06999, lr:9.90e-03, fs:0.85714 (r=0.879,p=0.837),  time:20.369, tt:1262.854\n",
      "Ep:62, loss:0.00001, loss_test:0.06986, lr:9.90e-03, fs:0.86275 (r=0.889,p=0.838),  time:20.373, tt:1283.480\n",
      "Ep:63, loss:0.00001, loss_test:0.06978, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.376, tt:1304.055\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.06957, lr:9.90e-03, fs:0.86275 (r=0.889,p=0.838),  time:20.401, tt:1326.093\n",
      "Ep:65, loss:0.00001, loss_test:0.06945, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.412, tt:1347.165\n",
      "Ep:66, loss:0.00001, loss_test:0.06917, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.444, tt:1369.724\n",
      "Ep:67, loss:0.00001, loss_test:0.06925, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.448, tt:1390.493\n",
      "Ep:68, loss:0.00001, loss_test:0.06942, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.453, tt:1411.249\n",
      "Ep:69, loss:0.00001, loss_test:0.06900, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.459, tt:1432.148\n",
      "Ep:70, loss:0.00001, loss_test:0.06874, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.468, tt:1453.211\n",
      "Ep:71, loss:0.00001, loss_test:0.06878, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.469, tt:1473.786\n",
      "Ep:72, loss:0.00001, loss_test:0.06829, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.475, tt:1494.694\n",
      "Ep:73, loss:0.00001, loss_test:0.06882, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.472, tt:1514.934\n",
      "Ep:74, loss:0.00001, loss_test:0.06860, lr:9.90e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.472, tt:1535.367\n",
      "Ep:75, loss:0.00001, loss_test:0.06859, lr:9.80e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.468, tt:1555.570\n",
      "Ep:76, loss:0.00001, loss_test:0.06912, lr:9.70e-03, fs:0.87129 (r=0.889,p=0.854),  time:20.461, tt:1575.474\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.06871, lr:9.70e-03, fs:0.87129 (r=0.889,p=0.854),  time:20.464, tt:1596.230\n",
      "Ep:78, loss:0.00001, loss_test:0.06862, lr:9.70e-03, fs:0.86700 (r=0.889,p=0.846),  time:20.465, tt:1616.768\n",
      "Ep:79, loss:0.00001, loss_test:0.06887, lr:9.70e-03, fs:0.87562 (r=0.889,p=0.863),  time:20.453, tt:1636.219\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.06899, lr:9.70e-03, fs:0.87562 (r=0.889,p=0.863),  time:20.451, tt:1656.567\n",
      "Ep:81, loss:0.00001, loss_test:0.06885, lr:9.70e-03, fs:0.87562 (r=0.889,p=0.863),  time:20.447, tt:1676.615\n",
      "Ep:82, loss:0.00001, loss_test:0.06919, lr:9.70e-03, fs:0.87562 (r=0.889,p=0.863),  time:20.444, tt:1696.831\n",
      "Ep:83, loss:0.00001, loss_test:0.06931, lr:9.70e-03, fs:0.87562 (r=0.889,p=0.863),  time:20.433, tt:1716.406\n",
      "Ep:84, loss:0.00001, loss_test:0.06900, lr:9.70e-03, fs:0.88000 (r=0.889,p=0.871),  time:20.427, tt:1736.314\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.06928, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.433, tt:1757.199\n",
      "Ep:86, loss:0.00001, loss_test:0.06921, lr:9.70e-03, fs:0.86869 (r=0.869,p=0.869),  time:20.430, tt:1777.375\n",
      "Ep:87, loss:0.00001, loss_test:0.06894, lr:9.70e-03, fs:0.86869 (r=0.869,p=0.869),  time:20.435, tt:1798.262\n",
      "Ep:88, loss:0.00001, loss_test:0.06912, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.438, tt:1819.013\n",
      "Ep:89, loss:0.00001, loss_test:0.06880, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.445, tt:1840.046\n",
      "Ep:90, loss:0.00001, loss_test:0.06842, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.437, tt:1859.807\n",
      "Ep:91, loss:0.00001, loss_test:0.06824, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.441, tt:1880.545\n",
      "Ep:92, loss:0.00001, loss_test:0.06867, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.440, tt:1900.911\n",
      "Ep:93, loss:0.00001, loss_test:0.06785, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.434, tt:1920.831\n",
      "Ep:94, loss:0.00001, loss_test:0.06846, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.438, tt:1941.562\n",
      "Ep:95, loss:0.00001, loss_test:0.06873, lr:9.70e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.435, tt:1961.749\n",
      "Ep:96, loss:0.00001, loss_test:0.06789, lr:9.61e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.434, tt:1982.120\n",
      "Ep:97, loss:0.00001, loss_test:0.06820, lr:9.51e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.416, tt:2000.737\n",
      "Ep:98, loss:0.00001, loss_test:0.06862, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:20.410, tt:2020.609\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.06834, lr:9.41e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.407, tt:2040.716\n",
      "Ep:100, loss:0.00001, loss_test:0.06800, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:20.410, tt:2061.418\n",
      "Ep:101, loss:0.00001, loss_test:0.06831, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:20.414, tt:2082.221\n",
      "Ep:102, loss:0.00001, loss_test:0.06821, lr:9.41e-03, fs:0.87437 (r=0.879,p=0.870),  time:20.414, tt:2102.648\n",
      "Ep:103, loss:0.00001, loss_test:0.06784, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:20.411, tt:2122.707\n",
      "Ep:104, loss:0.00001, loss_test:0.06782, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:20.412, tt:2143.242\n",
      "Ep:105, loss:0.00001, loss_test:0.06776, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:20.394, tt:2161.730\n",
      "Ep:106, loss:0.00001, loss_test:0.06767, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:20.392, tt:2181.926\n",
      "Ep:107, loss:0.00001, loss_test:0.06816, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:20.392, tt:2202.289\n",
      "Ep:108, loss:0.00000, loss_test:0.06785, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:20.392, tt:2222.737\n",
      "Ep:109, loss:0.00000, loss_test:0.06800, lr:9.41e-03, fs:0.88776 (r=0.879,p=0.897),  time:20.394, tt:2243.384\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.06817, lr:9.41e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.390, tt:2263.285\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.06701, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:20.389, tt:2283.520\n",
      "Ep:112, loss:0.00000, loss_test:0.06811, lr:9.41e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.387, tt:2303.771\n",
      "Ep:113, loss:0.00000, loss_test:0.06805, lr:9.41e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.382, tt:2323.549\n",
      "Ep:114, loss:0.00000, loss_test:0.06689, lr:9.41e-03, fs:0.88776 (r=0.879,p=0.897),  time:20.379, tt:2343.568\n",
      "Ep:115, loss:0.00000, loss_test:0.06845, lr:9.41e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.379, tt:2363.987\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00000, loss_test:0.06787, lr:9.41e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.366, tt:2382.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:117, loss:0.00000, loss_test:0.06780, lr:9.41e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.349, tt:2401.168\n",
      "Ep:118, loss:0.00000, loss_test:0.06770, lr:9.41e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.352, tt:2421.891\n",
      "Ep:119, loss:0.00000, loss_test:0.06774, lr:9.41e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.329, tt:2439.440\n",
      "Ep:120, loss:0.00000, loss_test:0.06737, lr:9.41e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.317, tt:2458.389\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00000, loss_test:0.06772, lr:9.41e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.309, tt:2477.704\n",
      "Ep:122, loss:0.00000, loss_test:0.06728, lr:9.41e-03, fs:0.91579 (r=0.879,p=0.956),  time:20.297, tt:2496.496\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.06667, lr:9.41e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.285, tt:2515.398\n",
      "Ep:124, loss:0.00000, loss_test:0.06852, lr:9.41e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.285, tt:2535.593\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00000, loss_test:0.06694, lr:9.41e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.282, tt:2555.547\n",
      "Ep:126, loss:0.00000, loss_test:0.06728, lr:9.41e-03, fs:0.91579 (r=0.879,p=0.956),  time:20.279, tt:2575.434\n",
      "Ep:127, loss:0.00000, loss_test:0.06715, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:20.275, tt:2595.204\n",
      "Ep:128, loss:0.00000, loss_test:0.06666, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:20.270, tt:2614.815\n",
      "Ep:129, loss:0.00000, loss_test:0.06758, lr:9.41e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.251, tt:2632.623\n",
      "Ep:130, loss:0.00000, loss_test:0.06672, lr:9.41e-03, fs:0.91579 (r=0.879,p=0.956),  time:20.252, tt:2653.074\n",
      "Ep:131, loss:0.00000, loss_test:0.06821, lr:9.41e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.249, tt:2672.854\n",
      "Ep:132, loss:0.00000, loss_test:0.06733, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:20.248, tt:2693.033\n",
      "Ep:133, loss:0.00000, loss_test:0.06724, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:20.245, tt:2712.796\n",
      "Ep:134, loss:0.00000, loss_test:0.06690, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:20.240, tt:2732.366\n",
      "Ep:135, loss:0.00000, loss_test:0.06699, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:20.226, tt:2750.789\n",
      "Ep:136, loss:0.00000, loss_test:0.06874, lr:9.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.216, tt:2769.583\n",
      "Ep:137, loss:0.00000, loss_test:0.06696, lr:9.23e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.201, tt:2787.699\n",
      "Ep:138, loss:0.00000, loss_test:0.07011, lr:9.14e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.191, tt:2806.583\n",
      "Ep:139, loss:0.00000, loss_test:0.06869, lr:9.04e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.199, tt:2827.876\n",
      "Ep:140, loss:0.00000, loss_test:0.06887, lr:8.95e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.196, tt:2847.622\n",
      "Ep:141, loss:0.00000, loss_test:0.06907, lr:8.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.191, tt:2867.057\n",
      "Ep:142, loss:0.00000, loss_test:0.06806, lr:8.78e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.181, tt:2885.949\n",
      "Ep:143, loss:0.00000, loss_test:0.06997, lr:8.69e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.170, tt:2904.437\n",
      "Ep:144, loss:0.00000, loss_test:0.06870, lr:8.60e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.165, tt:2923.968\n",
      "Ep:145, loss:0.00000, loss_test:0.06771, lr:8.51e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.170, tt:2944.755\n",
      "Ep:146, loss:0.00000, loss_test:0.07098, lr:8.43e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.172, tt:2965.302\n",
      "Ep:147, loss:0.00000, loss_test:0.06939, lr:8.35e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.170, tt:2985.160\n",
      "Ep:148, loss:0.00000, loss_test:0.06801, lr:8.26e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.160, tt:3003.823\n",
      "Ep:149, loss:0.00000, loss_test:0.06908, lr:8.18e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.156, tt:3023.474\n",
      "Ep:150, loss:0.00000, loss_test:0.06923, lr:8.10e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.151, tt:3042.744\n",
      "Ep:151, loss:0.00000, loss_test:0.06853, lr:8.02e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.143, tt:3061.680\n",
      "Ep:152, loss:0.00000, loss_test:0.06866, lr:7.94e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.135, tt:3080.600\n",
      "Ep:153, loss:0.00000, loss_test:0.06825, lr:7.86e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.124, tt:3099.071\n",
      "Ep:154, loss:0.00000, loss_test:0.06925, lr:7.78e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.114, tt:3117.630\n",
      "Ep:155, loss:0.00000, loss_test:0.06977, lr:7.70e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.115, tt:3137.985\n",
      "Ep:156, loss:0.00000, loss_test:0.06810, lr:7.62e-03, fs:0.92553 (r=0.879,p=0.978),  time:20.111, tt:3157.477\n",
      "Ep:157, loss:0.00000, loss_test:0.06885, lr:7.55e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.101, tt:3175.944\n",
      "Ep:158, loss:0.00000, loss_test:0.07012, lr:7.47e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.084, tt:3193.312\n",
      "Ep:159, loss:0.00000, loss_test:0.06896, lr:7.40e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.085, tt:3213.651\n",
      "Ep:160, loss:0.00000, loss_test:0.06801, lr:7.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.084, tt:3233.448\n",
      "Ep:161, loss:0.00000, loss_test:0.06916, lr:7.25e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.073, tt:3251.855\n",
      "Ep:162, loss:0.00000, loss_test:0.07021, lr:7.18e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.069, tt:3271.182\n",
      "Ep:163, loss:0.00000, loss_test:0.06874, lr:7.11e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.061, tt:3290.000\n",
      "Ep:164, loss:0.00000, loss_test:0.06809, lr:7.03e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.054, tt:3308.834\n",
      "Ep:165, loss:0.00000, loss_test:0.06995, lr:6.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.053, tt:3328.825\n",
      "Ep:166, loss:0.00000, loss_test:0.07019, lr:6.89e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.048, tt:3348.087\n",
      "Ep:167, loss:0.00000, loss_test:0.06919, lr:6.83e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.042, tt:3366.978\n",
      "Ep:168, loss:0.00000, loss_test:0.06826, lr:6.76e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.041, tt:3386.930\n",
      "Ep:169, loss:0.00000, loss_test:0.06967, lr:6.69e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.037, tt:3406.293\n",
      "Ep:170, loss:0.00000, loss_test:0.07056, lr:6.62e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.033, tt:3425.579\n",
      "Ep:171, loss:0.00000, loss_test:0.06926, lr:6.56e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.032, tt:3445.521\n",
      "Ep:172, loss:0.00000, loss_test:0.06896, lr:6.49e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.026, tt:3464.412\n",
      "Ep:173, loss:0.00000, loss_test:0.07002, lr:6.43e-03, fs:0.93548 (r=0.879,p=1.000),  time:20.013, tt:3482.264\n",
      "Ep:174, loss:0.00000, loss_test:0.07023, lr:6.36e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.006, tt:3501.104\n",
      "Ep:175, loss:0.00000, loss_test:0.06913, lr:6.30e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.006, tt:3521.016\n",
      "Ep:176, loss:0.00000, loss_test:0.06885, lr:6.24e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.007, tt:3541.258\n",
      "Ep:177, loss:0.00000, loss_test:0.07000, lr:6.17e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.005, tt:3560.830\n",
      "Ep:178, loss:0.00000, loss_test:0.07059, lr:6.11e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.009, tt:3581.595\n",
      "Ep:179, loss:0.00000, loss_test:0.06954, lr:6.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.014, tt:3602.483\n",
      "Ep:180, loss:0.00000, loss_test:0.06909, lr:5.99e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.015, tt:3622.806\n",
      "Ep:181, loss:0.00000, loss_test:0.06958, lr:5.93e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.011, tt:3641.923\n",
      "Ep:182, loss:0.00000, loss_test:0.07055, lr:5.87e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.009, tt:3661.736\n",
      "Ep:183, loss:0.00000, loss_test:0.07019, lr:5.81e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.005, tt:3680.976\n",
      "Ep:184, loss:0.00000, loss_test:0.06949, lr:5.75e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.018, tt:3703.327\n",
      "Ep:185, loss:0.00000, loss_test:0.07000, lr:5.70e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.013, tt:3722.396\n",
      "Ep:186, loss:0.00000, loss_test:0.07024, lr:5.64e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.011, tt:3741.992\n",
      "Ep:187, loss:0.00000, loss_test:0.06992, lr:5.58e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.004, tt:3760.771\n",
      "Ep:188, loss:0.00000, loss_test:0.07002, lr:5.53e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.004, tt:3780.753\n",
      "Ep:189, loss:0.00000, loss_test:0.06992, lr:5.47e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.999, tt:3799.717\n",
      "Ep:190, loss:0.00000, loss_test:0.06974, lr:5.42e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.996, tt:3819.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00000, loss_test:0.06981, lr:5.36e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.995, tt:3838.983\n",
      "Ep:192, loss:0.00000, loss_test:0.07011, lr:5.31e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.992, tt:3858.465\n",
      "Ep:193, loss:0.00000, loss_test:0.07061, lr:5.26e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.990, tt:3878.024\n",
      "Ep:194, loss:0.00000, loss_test:0.07053, lr:5.20e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.991, tt:3898.187\n",
      "Ep:195, loss:0.00000, loss_test:0.06995, lr:5.15e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.986, tt:3917.284\n",
      "Ep:196, loss:0.00000, loss_test:0.07023, lr:5.10e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.986, tt:3937.263\n",
      "Ep:197, loss:0.00000, loss_test:0.07041, lr:5.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.987, tt:3957.395\n",
      "Ep:198, loss:0.00000, loss_test:0.07052, lr:5.00e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.990, tt:3978.081\n",
      "Ep:199, loss:0.00000, loss_test:0.07063, lr:4.95e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.988, tt:3997.585\n",
      "Ep:200, loss:0.00000, loss_test:0.07112, lr:4.90e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.983, tt:4016.633\n",
      "Ep:201, loss:0.00000, loss_test:0.07074, lr:4.85e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.984, tt:4036.779\n",
      "Ep:202, loss:0.00000, loss_test:0.06996, lr:4.80e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.980, tt:4055.974\n",
      "Ep:203, loss:0.00000, loss_test:0.07086, lr:4.75e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.972, tt:4074.361\n",
      "Ep:204, loss:0.00000, loss_test:0.07135, lr:4.71e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.969, tt:4093.719\n",
      "Ep:205, loss:0.00000, loss_test:0.07082, lr:4.66e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.969, tt:4113.602\n",
      "Ep:206, loss:0.00000, loss_test:0.07067, lr:4.61e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.963, tt:4132.270\n",
      "Ep:207, loss:0.00000, loss_test:0.07057, lr:4.57e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.962, tt:4152.069\n",
      "Ep:208, loss:0.00000, loss_test:0.07069, lr:4.52e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.959, tt:4171.351\n",
      "Ep:209, loss:0.00000, loss_test:0.07164, lr:4.48e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.952, tt:4189.955\n",
      "Ep:210, loss:0.00000, loss_test:0.07145, lr:4.43e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.952, tt:4209.834\n",
      "Ep:211, loss:0.00000, loss_test:0.07051, lr:4.39e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.952, tt:4229.749\n",
      "Ep:212, loss:0.00000, loss_test:0.07094, lr:4.34e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.949, tt:4249.204\n",
      "Ep:213, loss:0.00000, loss_test:0.07129, lr:4.30e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.946, tt:4268.439\n",
      "Ep:214, loss:0.00000, loss_test:0.07118, lr:4.26e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.941, tt:4287.216\n",
      "Ep:215, loss:0.00000, loss_test:0.07168, lr:4.21e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.940, tt:4306.943\n",
      "Ep:216, loss:0.00000, loss_test:0.07190, lr:4.17e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.937, tt:4326.254\n",
      "Ep:217, loss:0.00000, loss_test:0.07108, lr:4.13e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.936, tt:4345.972\n",
      "Ep:218, loss:0.00000, loss_test:0.07054, lr:4.09e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.938, tt:4366.326\n",
      "Ep:219, loss:0.00000, loss_test:0.07114, lr:4.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.942, tt:4387.189\n",
      "Ep:220, loss:0.00000, loss_test:0.07145, lr:4.01e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.939, tt:4406.433\n",
      "Ep:221, loss:0.00000, loss_test:0.07129, lr:3.97e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.939, tt:4426.399\n",
      "Ep:222, loss:0.00000, loss_test:0.07115, lr:3.93e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.932, tt:4444.931\n",
      "Ep:223, loss:0.00000, loss_test:0.07135, lr:3.89e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.934, tt:4465.245\n",
      "Ep:224, loss:0.00000, loss_test:0.07119, lr:3.85e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.928, tt:4483.904\n",
      "Ep:225, loss:0.00000, loss_test:0.07158, lr:3.81e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.927, tt:4503.448\n",
      "Ep:226, loss:0.00000, loss_test:0.07153, lr:3.77e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.917, tt:4521.256\n",
      "Ep:227, loss:0.00000, loss_test:0.07130, lr:3.73e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.922, tt:4542.259\n",
      "Ep:228, loss:0.00000, loss_test:0.07187, lr:3.70e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.925, tt:4562.741\n",
      "Ep:229, loss:0.00000, loss_test:0.07223, lr:3.66e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.927, tt:4583.163\n",
      "Ep:230, loss:0.00000, loss_test:0.07177, lr:3.62e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.921, tt:4601.857\n",
      "Ep:231, loss:0.00000, loss_test:0.07106, lr:3.59e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.923, tt:4622.221\n",
      "Ep:232, loss:0.00000, loss_test:0.07162, lr:3.55e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.925, tt:4642.508\n",
      "Ep:233, loss:0.00000, loss_test:0.07200, lr:3.52e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.925, tt:4662.511\n",
      "Ep:234, loss:0.00000, loss_test:0.07176, lr:3.48e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.926, tt:4682.670\n",
      "Ep:235, loss:0.00000, loss_test:0.07183, lr:3.45e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.927, tt:4702.691\n",
      "Ep:236, loss:0.00000, loss_test:0.07207, lr:3.41e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.928, tt:4722.873\n",
      "Ep:237, loss:0.00000, loss_test:0.07198, lr:3.38e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.924, tt:4741.985\n",
      "Ep:238, loss:0.00000, loss_test:0.07161, lr:3.34e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.929, tt:4763.120\n",
      "Ep:239, loss:0.00000, loss_test:0.07188, lr:3.31e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.931, tt:4783.379\n",
      "Ep:240, loss:0.00000, loss_test:0.07202, lr:3.28e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.929, tt:4802.886\n",
      "Ep:241, loss:0.00000, loss_test:0.07181, lr:3.24e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.932, tt:4823.618\n",
      "Ep:242, loss:0.00000, loss_test:0.07199, lr:3.21e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.939, tt:4845.193\n",
      "Ep:243, loss:0.00000, loss_test:0.07221, lr:3.18e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.938, tt:4864.873\n",
      "Ep:244, loss:0.00000, loss_test:0.07215, lr:3.15e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.938, tt:4884.752\n",
      "Ep:245, loss:0.00000, loss_test:0.07197, lr:3.12e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.937, tt:4904.524\n",
      "Ep:246, loss:0.00000, loss_test:0.07209, lr:3.09e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.940, tt:4925.138\n",
      "Ep:247, loss:0.00000, loss_test:0.07225, lr:3.05e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.943, tt:4945.801\n",
      "Ep:248, loss:0.00000, loss_test:0.07224, lr:3.02e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.940, tt:4965.072\n",
      "Ep:249, loss:0.00000, loss_test:0.07241, lr:2.99e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.958, tt:4989.487\n",
      "Ep:250, loss:0.00000, loss_test:0.07266, lr:2.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.962, tt:5010.493\n",
      "Ep:251, loss:0.00000, loss_test:0.07242, lr:2.93e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.967, tt:5031.648\n",
      "Ep:252, loss:0.00000, loss_test:0.07197, lr:2.90e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.963, tt:5050.519\n",
      "Ep:253, loss:0.00000, loss_test:0.07229, lr:2.88e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.967, tt:5071.727\n",
      "Ep:254, loss:0.00000, loss_test:0.07263, lr:2.85e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.967, tt:5091.618\n",
      "Ep:255, loss:0.00000, loss_test:0.07270, lr:2.82e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.966, tt:5111.201\n",
      "Ep:256, loss:0.00000, loss_test:0.07254, lr:2.79e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.969, tt:5131.963\n",
      "Ep:257, loss:0.00000, loss_test:0.07258, lr:2.76e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.973, tt:5152.946\n",
      "Ep:258, loss:0.00000, loss_test:0.07270, lr:2.73e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.974, tt:5173.234\n",
      "Ep:259, loss:0.00000, loss_test:0.07261, lr:2.71e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.978, tt:5194.261\n",
      "Ep:260, loss:0.00000, loss_test:0.07283, lr:2.68e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.985, tt:5216.092\n",
      "Ep:261, loss:0.00000, loss_test:0.07274, lr:2.65e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.986, tt:5236.275\n",
      "Ep:262, loss:0.00000, loss_test:0.07259, lr:2.63e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.984, tt:5255.699\n",
      "Ep:263, loss:0.00000, loss_test:0.07282, lr:2.60e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.982, tt:5275.285\n",
      "Ep:264, loss:0.00000, loss_test:0.07306, lr:2.57e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.983, tt:5295.410\n",
      "Ep:265, loss:0.00000, loss_test:0.07302, lr:2.55e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.985, tt:5315.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:266, loss:0.00000, loss_test:0.07289, lr:2.52e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.990, tt:5337.224\n",
      "Ep:267, loss:0.00000, loss_test:0.07296, lr:2.50e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.992, tt:5357.856\n",
      "Ep:268, loss:0.00000, loss_test:0.07300, lr:2.47e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.996, tt:5379.010\n",
      "Ep:269, loss:0.00000, loss_test:0.07302, lr:2.45e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.991, tt:5397.701\n",
      "Ep:270, loss:0.00000, loss_test:0.07322, lr:2.42e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.995, tt:5418.774\n",
      "Ep:271, loss:0.00000, loss_test:0.07327, lr:2.40e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.993, tt:5438.111\n",
      "Ep:272, loss:0.00000, loss_test:0.07309, lr:2.38e-03, fs:0.93048 (r=0.879,p=0.989),  time:19.999, tt:5459.622\n",
      "Ep:273, loss:0.00000, loss_test:0.07297, lr:2.35e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.004, tt:5480.987\n",
      "Ep:274, loss:0.00000, loss_test:0.07323, lr:2.33e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.004, tt:5501.070\n",
      "Ep:275, loss:0.00000, loss_test:0.07329, lr:2.31e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.009, tt:5522.592\n",
      "Ep:276, loss:0.00000, loss_test:0.07314, lr:2.28e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.008, tt:5542.091\n",
      "Ep:277, loss:0.00000, loss_test:0.07312, lr:2.26e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.015, tt:5564.071\n",
      "Ep:278, loss:0.00000, loss_test:0.07328, lr:2.24e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.020, tt:5585.654\n",
      "Ep:279, loss:0.00000, loss_test:0.07329, lr:2.21e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.026, tt:5607.237\n",
      "Ep:280, loss:0.00000, loss_test:0.07309, lr:2.19e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.028, tt:5627.819\n",
      "Ep:281, loss:0.00000, loss_test:0.07308, lr:2.17e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.037, tt:5650.410\n",
      "Ep:282, loss:0.00000, loss_test:0.07323, lr:2.15e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.040, tt:5671.272\n",
      "Ep:283, loss:0.00000, loss_test:0.07326, lr:2.13e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.044, tt:5692.372\n",
      "Ep:284, loss:0.00000, loss_test:0.07309, lr:2.11e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.044, tt:5712.552\n",
      "Ep:285, loss:0.00000, loss_test:0.07319, lr:2.08e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.044, tt:5732.689\n",
      "Ep:286, loss:0.00000, loss_test:0.07336, lr:2.06e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.047, tt:5753.366\n",
      "Ep:287, loss:0.00000, loss_test:0.07340, lr:2.04e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.047, tt:5773.565\n",
      "Ep:288, loss:0.00000, loss_test:0.07335, lr:2.02e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.050, tt:5794.369\n",
      "Ep:289, loss:0.00000, loss_test:0.07333, lr:2.00e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.054, tt:5815.542\n",
      "Ep:290, loss:0.00000, loss_test:0.07334, lr:1.98e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.054, tt:5835.594\n",
      "Ep:291, loss:0.00000, loss_test:0.07331, lr:1.96e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.054, tt:5855.694\n",
      "Ep:292, loss:0.00000, loss_test:0.07318, lr:1.94e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.057, tt:5876.840\n",
      "Ep:293, loss:0.00000, loss_test:0.07314, lr:1.92e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.057, tt:5896.760\n",
      "Ep:294, loss:0.00000, loss_test:0.07319, lr:1.90e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.061, tt:5918.118\n",
      "Ep:295, loss:0.00000, loss_test:0.07329, lr:1.89e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.051, tt:5935.019\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14272, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:14.462, tt:14.462\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14215, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:15.756, tt:31.512\n",
      "Ep:2, loss:0.00004, loss_test:0.14126, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:16.446, tt:49.339\n",
      "Ep:3, loss:0.00004, loss_test:0.14007, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:17.040, tt:68.158\n",
      "Ep:4, loss:0.00004, loss_test:0.13869, lr:1.00e-02, fs:0.64311 (r=0.919,p=0.495),  time:17.282, tt:86.410\n",
      "Ep:5, loss:0.00004, loss_test:0.13697, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:17.363, tt:104.179\n",
      "Ep:6, loss:0.00004, loss_test:0.13512, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:17.410, tt:121.870\n",
      "Ep:7, loss:0.00004, loss_test:0.13334, lr:1.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:17.495, tt:139.957\n",
      "Ep:8, loss:0.00004, loss_test:0.13216, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:17.650, tt:158.853\n",
      "Ep:9, loss:0.00004, loss_test:0.13157, lr:1.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:17.634, tt:176.336\n",
      "Ep:10, loss:0.00003, loss_test:0.13119, lr:1.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:17.650, tt:194.155\n",
      "Ep:11, loss:0.00003, loss_test:0.13077, lr:1.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:17.650, tt:211.805\n",
      "Ep:12, loss:0.00003, loss_test:0.13016, lr:9.90e-03, fs:0.64591 (r=0.838,p=0.525),  time:17.682, tt:229.862\n",
      "Ep:13, loss:0.00003, loss_test:0.12968, lr:9.80e-03, fs:0.64865 (r=0.848,p=0.525),  time:17.665, tt:247.315\n",
      "Ep:14, loss:0.00003, loss_test:0.12907, lr:9.70e-03, fs:0.65116 (r=0.848,p=0.528),  time:17.722, tt:265.836\n",
      "Ep:15, loss:0.00003, loss_test:0.12792, lr:9.61e-03, fs:0.65098 (r=0.838,p=0.532),  time:17.808, tt:284.926\n",
      "Ep:16, loss:0.00003, loss_test:0.12635, lr:9.51e-03, fs:0.65079 (r=0.828,p=0.536),  time:17.773, tt:302.137\n",
      "Ep:17, loss:0.00003, loss_test:0.12443, lr:9.41e-03, fs:0.64800 (r=0.818,p=0.536),  time:17.814, tt:320.648\n",
      "Ep:18, loss:0.00003, loss_test:0.12255, lr:9.32e-03, fs:0.66122 (r=0.818,p=0.555),  time:17.946, tt:340.972\n",
      "Ep:19, loss:0.00003, loss_test:0.12084, lr:9.23e-03, fs:0.67220 (r=0.818,p=0.570),  time:18.013, tt:360.267\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.11932, lr:9.23e-03, fs:0.66667 (r=0.808,p=0.567),  time:18.009, tt:378.196\n",
      "Ep:21, loss:0.00003, loss_test:0.11815, lr:9.23e-03, fs:0.65833 (r=0.798,p=0.560),  time:18.027, tt:396.600\n",
      "Ep:22, loss:0.00003, loss_test:0.11705, lr:9.23e-03, fs:0.66109 (r=0.798,p=0.564),  time:18.067, tt:415.543\n",
      "Ep:23, loss:0.00003, loss_test:0.11595, lr:9.23e-03, fs:0.66387 (r=0.798,p=0.568),  time:18.093, tt:434.227\n",
      "Ep:24, loss:0.00003, loss_test:0.11475, lr:9.23e-03, fs:0.66949 (r=0.798,p=0.577),  time:18.111, tt:452.785\n",
      "Ep:25, loss:0.00003, loss_test:0.11350, lr:9.23e-03, fs:0.67521 (r=0.798,p=0.585),  time:18.152, tt:471.965\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.11229, lr:9.23e-03, fs:0.67241 (r=0.788,p=0.586),  time:18.130, tt:489.505\n",
      "Ep:27, loss:0.00003, loss_test:0.11113, lr:9.23e-03, fs:0.67241 (r=0.788,p=0.586),  time:18.077, tt:506.158\n",
      "Ep:28, loss:0.00003, loss_test:0.11008, lr:9.23e-03, fs:0.68122 (r=0.788,p=0.600),  time:18.022, tt:522.650\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.10906, lr:9.23e-03, fs:0.69027 (r=0.788,p=0.614),  time:17.986, tt:539.582\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.10802, lr:9.23e-03, fs:0.68722 (r=0.788,p=0.609),  time:17.978, tt:557.309\n",
      "Ep:31, loss:0.00003, loss_test:0.10698, lr:9.23e-03, fs:0.69027 (r=0.788,p=0.614),  time:17.932, tt:573.832\n",
      "Ep:32, loss:0.00003, loss_test:0.10580, lr:9.23e-03, fs:0.70222 (r=0.798,p=0.627),  time:17.887, tt:590.282\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.10445, lr:9.23e-03, fs:0.70222 (r=0.798,p=0.627),  time:17.865, tt:607.398\n",
      "Ep:34, loss:0.00003, loss_test:0.10303, lr:9.23e-03, fs:0.71429 (r=0.808,p=0.640),  time:17.841, tt:624.441\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.10162, lr:9.23e-03, fs:0.71749 (r=0.808,p=0.645),  time:17.796, tt:640.642\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.10037, lr:9.23e-03, fs:0.71749 (r=0.808,p=0.645),  time:17.771, tt:657.514\n",
      "Ep:37, loss:0.00002, loss_test:0.09940, lr:9.23e-03, fs:0.73394 (r=0.808,p=0.672),  time:17.725, tt:673.554\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00002, loss_test:0.09854, lr:9.23e-03, fs:0.72558 (r=0.788,p=0.672),  time:17.677, tt:689.385\n",
      "Ep:39, loss:0.00002, loss_test:0.09781, lr:9.23e-03, fs:0.72558 (r=0.788,p=0.672),  time:17.632, tt:705.282\n",
      "Ep:40, loss:0.00002, loss_test:0.09699, lr:9.23e-03, fs:0.72811 (r=0.798,p=0.669),  time:17.577, tt:720.670\n",
      "Ep:41, loss:0.00002, loss_test:0.09603, lr:9.23e-03, fs:0.74074 (r=0.808,p=0.684),  time:17.557, tt:737.401\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.09515, lr:9.23e-03, fs:0.74074 (r=0.808,p=0.684),  time:17.577, tt:755.801\n",
      "Ep:43, loss:0.00002, loss_test:0.09427, lr:9.23e-03, fs:0.74419 (r=0.808,p=0.690),  time:17.556, tt:772.452\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.09334, lr:9.23e-03, fs:0.75701 (r=0.818,p=0.704),  time:17.521, tt:788.443\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.09240, lr:9.23e-03, fs:0.76056 (r=0.818,p=0.711),  time:17.467, tt:803.500\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.09154, lr:9.23e-03, fs:0.76636 (r=0.828,p=0.713),  time:17.464, tt:820.804\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.09085, lr:9.23e-03, fs:0.77570 (r=0.838,p=0.722),  time:17.451, tt:837.654\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09012, lr:9.23e-03, fs:0.77358 (r=0.828,p=0.726),  time:17.417, tt:853.438\n",
      "Ep:49, loss:0.00002, loss_test:0.08942, lr:9.23e-03, fs:0.77358 (r=0.828,p=0.726),  time:17.395, tt:869.770\n",
      "Ep:50, loss:0.00002, loss_test:0.08882, lr:9.23e-03, fs:0.77358 (r=0.828,p=0.726),  time:17.403, tt:887.548\n",
      "Ep:51, loss:0.00002, loss_test:0.08835, lr:9.23e-03, fs:0.76777 (r=0.818,p=0.723),  time:17.410, tt:905.336\n",
      "Ep:52, loss:0.00002, loss_test:0.08800, lr:9.23e-03, fs:0.76190 (r=0.808,p=0.721),  time:17.408, tt:922.646\n",
      "Ep:53, loss:0.00002, loss_test:0.08773, lr:9.23e-03, fs:0.74757 (r=0.778,p=0.720),  time:17.400, tt:939.601\n",
      "Ep:54, loss:0.00002, loss_test:0.08739, lr:9.23e-03, fs:0.76329 (r=0.798,p=0.731),  time:17.422, tt:958.217\n",
      "Ep:55, loss:0.00002, loss_test:0.08687, lr:9.23e-03, fs:0.76098 (r=0.788,p=0.736),  time:17.412, tt:975.092\n",
      "Ep:56, loss:0.00002, loss_test:0.08634, lr:9.23e-03, fs:0.76471 (r=0.788,p=0.743),  time:17.427, tt:993.364\n",
      "Ep:57, loss:0.00002, loss_test:0.08609, lr:9.23e-03, fs:0.77000 (r=0.778,p=0.762),  time:17.447, tt:1011.947\n",
      "Ep:58, loss:0.00002, loss_test:0.08587, lr:9.23e-03, fs:0.76000 (r=0.768,p=0.752),  time:17.470, tt:1030.703\n",
      "Ep:59, loss:0.00002, loss_test:0.08547, lr:9.14e-03, fs:0.76000 (r=0.768,p=0.752),  time:17.482, tt:1048.914\n",
      "Ep:60, loss:0.00002, loss_test:0.08497, lr:9.04e-03, fs:0.76617 (r=0.778,p=0.755),  time:17.496, tt:1067.265\n",
      "Ep:61, loss:0.00002, loss_test:0.08451, lr:8.95e-03, fs:0.77228 (r=0.788,p=0.757),  time:17.534, tt:1087.119\n",
      "Ep:62, loss:0.00002, loss_test:0.08428, lr:8.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:17.564, tt:1106.516\n",
      "Ep:63, loss:0.00002, loss_test:0.08425, lr:8.78e-03, fs:0.76382 (r=0.768,p=0.760),  time:17.585, tt:1125.431\n",
      "Ep:64, loss:0.00002, loss_test:0.08399, lr:8.69e-03, fs:0.76768 (r=0.768,p=0.768),  time:17.605, tt:1144.316\n",
      "Ep:65, loss:0.00002, loss_test:0.08341, lr:8.60e-03, fs:0.77157 (r=0.768,p=0.776),  time:17.630, tt:1163.611\n",
      "Ep:66, loss:0.00002, loss_test:0.08278, lr:8.51e-03, fs:0.77778 (r=0.778,p=0.778),  time:17.639, tt:1181.834\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.08244, lr:8.51e-03, fs:0.78392 (r=0.788,p=0.780),  time:17.648, tt:1200.038\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.08217, lr:8.51e-03, fs:0.78392 (r=0.788,p=0.780),  time:17.670, tt:1219.253\n",
      "Ep:69, loss:0.00002, loss_test:0.08168, lr:8.51e-03, fs:0.79397 (r=0.798,p=0.790),  time:17.689, tt:1238.222\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.08115, lr:8.51e-03, fs:0.80000 (r=0.808,p=0.792),  time:17.706, tt:1257.091\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.08087, lr:8.51e-03, fs:0.79397 (r=0.798,p=0.790),  time:17.720, tt:1275.814\n",
      "Ep:72, loss:0.00001, loss_test:0.08063, lr:8.51e-03, fs:0.79397 (r=0.798,p=0.790),  time:17.732, tt:1294.413\n",
      "Ep:73, loss:0.00001, loss_test:0.08025, lr:8.51e-03, fs:0.80000 (r=0.808,p=0.792),  time:17.748, tt:1313.383\n",
      "Ep:74, loss:0.00001, loss_test:0.07985, lr:8.51e-03, fs:0.80000 (r=0.808,p=0.792),  time:17.761, tt:1332.090\n",
      "Ep:75, loss:0.00001, loss_test:0.07960, lr:8.51e-03, fs:0.80000 (r=0.808,p=0.792),  time:17.799, tt:1352.758\n",
      "Ep:76, loss:0.00001, loss_test:0.07955, lr:8.51e-03, fs:0.80402 (r=0.808,p=0.800),  time:17.824, tt:1372.430\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.07956, lr:8.51e-03, fs:0.80402 (r=0.808,p=0.800),  time:17.851, tt:1392.360\n",
      "Ep:78, loss:0.00001, loss_test:0.07933, lr:8.51e-03, fs:0.80402 (r=0.808,p=0.800),  time:17.877, tt:1412.300\n",
      "Ep:79, loss:0.00001, loss_test:0.07914, lr:8.51e-03, fs:0.80402 (r=0.808,p=0.800),  time:17.900, tt:1431.971\n",
      "Ep:80, loss:0.00001, loss_test:0.07909, lr:8.51e-03, fs:0.80402 (r=0.808,p=0.800),  time:17.917, tt:1451.258\n",
      "Ep:81, loss:0.00001, loss_test:0.07890, lr:8.51e-03, fs:0.81000 (r=0.818,p=0.802),  time:17.928, tt:1470.133\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.07894, lr:8.51e-03, fs:0.81000 (r=0.818,p=0.802),  time:17.957, tt:1490.394\n",
      "Ep:83, loss:0.00001, loss_test:0.07884, lr:8.51e-03, fs:0.81000 (r=0.818,p=0.802),  time:17.981, tt:1510.432\n",
      "Ep:84, loss:0.00001, loss_test:0.07882, lr:8.51e-03, fs:0.81000 (r=0.818,p=0.802),  time:18.001, tt:1530.123\n",
      "Ep:85, loss:0.00001, loss_test:0.07846, lr:8.51e-03, fs:0.81407 (r=0.818,p=0.810),  time:17.999, tt:1547.937\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.07879, lr:8.51e-03, fs:0.80808 (r=0.808,p=0.808),  time:18.012, tt:1567.081\n",
      "Ep:87, loss:0.00001, loss_test:0.07850, lr:8.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:18.037, tt:1587.265\n",
      "Ep:88, loss:0.00001, loss_test:0.07815, lr:8.51e-03, fs:0.82000 (r=0.828,p=0.812),  time:18.045, tt:1606.044\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.07831, lr:8.51e-03, fs:0.82000 (r=0.828,p=0.812),  time:18.051, tt:1624.563\n",
      "Ep:90, loss:0.00001, loss_test:0.07870, lr:8.51e-03, fs:0.82000 (r=0.828,p=0.812),  time:18.059, tt:1643.405\n",
      "Ep:91, loss:0.00001, loss_test:0.07859, lr:8.51e-03, fs:0.82587 (r=0.838,p=0.814),  time:18.066, tt:1662.036\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.07846, lr:8.51e-03, fs:0.82587 (r=0.838,p=0.814),  time:18.077, tt:1681.175\n",
      "Ep:93, loss:0.00001, loss_test:0.07884, lr:8.51e-03, fs:0.83000 (r=0.838,p=0.822),  time:18.097, tt:1701.082\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.07859, lr:8.51e-03, fs:0.83000 (r=0.838,p=0.822),  time:18.114, tt:1720.792\n",
      "Ep:95, loss:0.00001, loss_test:0.07831, lr:8.51e-03, fs:0.83582 (r=0.848,p=0.824),  time:18.132, tt:1740.692\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.07857, lr:8.51e-03, fs:0.83417 (r=0.838,p=0.830),  time:18.147, tt:1760.261\n",
      "Ep:97, loss:0.00001, loss_test:0.07824, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.161, tt:1779.756\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.07812, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.164, tt:1798.263\n",
      "Ep:99, loss:0.00001, loss_test:0.07793, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.167, tt:1816.651\n",
      "Ep:100, loss:0.00001, loss_test:0.07760, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.178, tt:1835.948\n",
      "Ep:101, loss:0.00001, loss_test:0.07761, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.180, tt:1854.406\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.07703, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.195, tt:1874.051\n",
      "Ep:103, loss:0.00001, loss_test:0.07793, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.202, tt:1892.986\n",
      "Ep:104, loss:0.00001, loss_test:0.07740, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.214, tt:1912.521\n",
      "Ep:105, loss:0.00001, loss_test:0.07776, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.226, tt:1931.921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00001, loss_test:0.07737, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.237, tt:1951.399\n",
      "Ep:107, loss:0.00001, loss_test:0.07725, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.246, tt:1970.606\n",
      "Ep:108, loss:0.00001, loss_test:0.07842, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.256, tt:1989.878\n",
      "Ep:109, loss:0.00001, loss_test:0.07751, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.259, tt:2008.467\n",
      "Ep:110, loss:0.00001, loss_test:0.07731, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.268, tt:2027.743\n",
      "Ep:111, loss:0.00001, loss_test:0.07817, lr:8.51e-03, fs:0.84577 (r=0.859,p=0.833),  time:18.270, tt:2046.223\n",
      "Ep:112, loss:0.00001, loss_test:0.07752, lr:8.51e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.274, tt:2064.973\n",
      "Ep:113, loss:0.00001, loss_test:0.07754, lr:8.43e-03, fs:0.84000 (r=0.848,p=0.832),  time:18.280, tt:2083.966\n",
      "Ep:114, loss:0.00001, loss_test:0.07844, lr:8.35e-03, fs:0.85427 (r=0.859,p=0.850),  time:18.289, tt:2103.292\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.07812, lr:8.35e-03, fs:0.83838 (r=0.838,p=0.838),  time:18.310, tt:2123.952\n",
      "Ep:116, loss:0.00001, loss_test:0.07772, lr:8.35e-03, fs:0.83838 (r=0.838,p=0.838),  time:18.324, tt:2143.887\n",
      "Ep:117, loss:0.00001, loss_test:0.07815, lr:8.35e-03, fs:0.84848 (r=0.848,p=0.848),  time:18.337, tt:2163.726\n",
      "Ep:118, loss:0.00001, loss_test:0.07795, lr:8.35e-03, fs:0.84848 (r=0.848,p=0.848),  time:18.344, tt:2182.890\n",
      "Ep:119, loss:0.00001, loss_test:0.07848, lr:8.35e-03, fs:0.84264 (r=0.838,p=0.847),  time:18.354, tt:2202.516\n",
      "Ep:120, loss:0.00001, loss_test:0.07890, lr:8.35e-03, fs:0.84264 (r=0.838,p=0.847),  time:18.368, tt:2222.475\n",
      "Ep:121, loss:0.00001, loss_test:0.07840, lr:8.35e-03, fs:0.84264 (r=0.838,p=0.847),  time:18.382, tt:2242.558\n",
      "Ep:122, loss:0.00001, loss_test:0.07981, lr:8.35e-03, fs:0.84264 (r=0.838,p=0.847),  time:18.386, tt:2261.493\n",
      "Ep:123, loss:0.00001, loss_test:0.07962, lr:8.35e-03, fs:0.84264 (r=0.838,p=0.847),  time:18.403, tt:2281.966\n",
      "Ep:124, loss:0.00001, loss_test:0.07953, lr:8.35e-03, fs:0.83673 (r=0.828,p=0.845),  time:18.422, tt:2302.793\n",
      "Ep:125, loss:0.00001, loss_test:0.07991, lr:8.35e-03, fs:0.83077 (r=0.818,p=0.844),  time:18.433, tt:2322.605\n",
      "Ep:126, loss:0.00001, loss_test:0.07956, lr:8.26e-03, fs:0.83673 (r=0.828,p=0.845),  time:18.437, tt:2341.548\n",
      "Ep:127, loss:0.00001, loss_test:0.08020, lr:8.18e-03, fs:0.83673 (r=0.828,p=0.845),  time:18.443, tt:2360.709\n",
      "Ep:128, loss:0.00001, loss_test:0.07962, lr:8.10e-03, fs:0.83673 (r=0.828,p=0.845),  time:18.446, tt:2379.527\n",
      "Ep:129, loss:0.00001, loss_test:0.08027, lr:8.02e-03, fs:0.83077 (r=0.818,p=0.844),  time:18.446, tt:2397.961\n",
      "Ep:130, loss:0.00001, loss_test:0.08022, lr:7.94e-03, fs:0.83077 (r=0.818,p=0.844),  time:18.450, tt:2416.904\n",
      "Ep:131, loss:0.00001, loss_test:0.07986, lr:7.86e-03, fs:0.83505 (r=0.818,p=0.853),  time:18.460, tt:2436.745\n",
      "Ep:132, loss:0.00001, loss_test:0.08005, lr:7.78e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.464, tt:2455.688\n",
      "Ep:133, loss:0.00001, loss_test:0.07997, lr:7.70e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.468, tt:2474.687\n",
      "Ep:134, loss:0.00001, loss_test:0.08015, lr:7.62e-03, fs:0.83938 (r=0.818,p=0.862),  time:18.472, tt:2493.738\n",
      "Ep:135, loss:0.00001, loss_test:0.08033, lr:7.55e-03, fs:0.81481 (r=0.778,p=0.856),  time:18.474, tt:2512.493\n",
      "Ep:136, loss:0.00001, loss_test:0.07998, lr:7.47e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.480, tt:2531.811\n",
      "Ep:137, loss:0.00001, loss_test:0.08010, lr:7.40e-03, fs:0.82540 (r=0.788,p=0.867),  time:18.486, tt:2551.094\n",
      "Ep:138, loss:0.00001, loss_test:0.08043, lr:7.32e-03, fs:0.83158 (r=0.798,p=0.868),  time:18.499, tt:2571.372\n",
      "Ep:139, loss:0.00001, loss_test:0.07993, lr:7.25e-03, fs:0.82540 (r=0.788,p=0.867),  time:18.507, tt:2591.014\n",
      "Ep:140, loss:0.00001, loss_test:0.08059, lr:7.18e-03, fs:0.81720 (r=0.768,p=0.874),  time:18.510, tt:2609.917\n",
      "Ep:141, loss:0.00001, loss_test:0.08046, lr:7.11e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.515, tt:2629.075\n",
      "Ep:142, loss:0.00001, loss_test:0.08033, lr:7.03e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.526, tt:2649.233\n",
      "Ep:143, loss:0.00001, loss_test:0.08065, lr:6.96e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.536, tt:2669.116\n",
      "Ep:144, loss:0.00001, loss_test:0.08037, lr:6.89e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.539, tt:2688.143\n",
      "Ep:145, loss:0.00001, loss_test:0.08109, lr:6.83e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.544, tt:2707.382\n",
      "Ep:146, loss:0.00001, loss_test:0.08097, lr:6.76e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.553, tt:2727.246\n",
      "Ep:147, loss:0.00001, loss_test:0.08117, lr:6.69e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.551, tt:2745.529\n",
      "Ep:148, loss:0.00001, loss_test:0.08154, lr:6.62e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.554, tt:2764.520\n",
      "Ep:149, loss:0.00001, loss_test:0.08113, lr:6.56e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.555, tt:2783.275\n",
      "Ep:150, loss:0.00001, loss_test:0.08158, lr:6.49e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.559, tt:2802.419\n",
      "Ep:151, loss:0.00000, loss_test:0.08155, lr:6.43e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.565, tt:2821.861\n",
      "Ep:152, loss:0.00000, loss_test:0.08144, lr:6.36e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.567, tt:2840.769\n",
      "Ep:153, loss:0.00000, loss_test:0.08174, lr:6.30e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.568, tt:2859.503\n",
      "Ep:154, loss:0.00000, loss_test:0.08166, lr:6.24e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.572, tt:2878.651\n",
      "Ep:155, loss:0.00000, loss_test:0.08171, lr:6.17e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.576, tt:2897.782\n",
      "Ep:156, loss:0.00000, loss_test:0.08191, lr:6.11e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.580, tt:2917.129\n",
      "Ep:157, loss:0.00000, loss_test:0.08213, lr:6.05e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.585, tt:2936.456\n",
      "Ep:158, loss:0.00000, loss_test:0.08229, lr:5.99e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.590, tt:2955.859\n",
      "Ep:159, loss:0.00000, loss_test:0.08179, lr:5.93e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.596, tt:2975.282\n",
      "Ep:160, loss:0.00000, loss_test:0.08223, lr:5.87e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.598, tt:2994.337\n",
      "Ep:161, loss:0.00000, loss_test:0.08254, lr:5.81e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.596, tt:3012.472\n",
      "Ep:162, loss:0.00000, loss_test:0.08213, lr:5.75e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.597, tt:3031.290\n",
      "Ep:163, loss:0.00000, loss_test:0.08206, lr:5.70e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.602, tt:3050.743\n",
      "Ep:164, loss:0.00000, loss_test:0.08238, lr:5.64e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.602, tt:3069.406\n",
      "Ep:165, loss:0.00000, loss_test:0.08252, lr:5.58e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.604, tt:3088.229\n",
      "Ep:166, loss:0.00000, loss_test:0.08209, lr:5.53e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.607, tt:3107.355\n",
      "Ep:167, loss:0.00000, loss_test:0.08214, lr:5.47e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.615, tt:3127.360\n",
      "Ep:168, loss:0.00000, loss_test:0.08275, lr:5.42e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.614, tt:3145.775\n",
      "Ep:169, loss:0.00000, loss_test:0.08241, lr:5.36e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.618, tt:3165.058\n",
      "Ep:170, loss:0.00000, loss_test:0.08243, lr:5.31e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.620, tt:3183.952\n",
      "Ep:171, loss:0.00000, loss_test:0.08270, lr:5.26e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.619, tt:3202.455\n",
      "Ep:172, loss:0.00000, loss_test:0.08232, lr:5.20e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.617, tt:3220.806\n",
      "Ep:173, loss:0.00000, loss_test:0.08297, lr:5.15e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.618, tt:3239.553\n",
      "Ep:174, loss:0.00000, loss_test:0.08283, lr:5.10e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.621, tt:3258.607\n",
      "Ep:175, loss:0.00000, loss_test:0.08302, lr:5.05e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.620, tt:3277.207\n",
      "Ep:176, loss:0.00000, loss_test:0.08294, lr:5.00e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.621, tt:3295.858\n",
      "Ep:177, loss:0.00000, loss_test:0.08310, lr:4.95e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.624, tt:3315.069\n",
      "Ep:178, loss:0.00000, loss_test:0.08321, lr:4.90e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.628, tt:3334.345\n",
      "Ep:179, loss:0.00000, loss_test:0.08304, lr:4.85e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.630, tt:3353.451\n",
      "Ep:180, loss:0.00000, loss_test:0.08326, lr:4.80e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.628, tt:3371.641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:181, loss:0.00000, loss_test:0.08319, lr:4.75e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.627, tt:3390.067\n",
      "Ep:182, loss:0.00000, loss_test:0.08326, lr:4.71e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.634, tt:3410.010\n",
      "Ep:183, loss:0.00000, loss_test:0.08331, lr:4.66e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.637, tt:3429.221\n",
      "Ep:184, loss:0.00000, loss_test:0.08324, lr:4.61e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.638, tt:3448.085\n",
      "Ep:185, loss:0.00000, loss_test:0.08341, lr:4.57e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.638, tt:3466.639\n",
      "Ep:186, loss:0.00000, loss_test:0.08338, lr:4.52e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.640, tt:3485.702\n",
      "Ep:187, loss:0.00000, loss_test:0.08355, lr:4.48e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.645, tt:3505.180\n",
      "Ep:188, loss:0.00000, loss_test:0.08344, lr:4.43e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.649, tt:3524.708\n",
      "Ep:189, loss:0.00000, loss_test:0.08337, lr:4.39e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.658, tt:3544.929\n",
      "Ep:190, loss:0.00000, loss_test:0.08376, lr:4.34e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.662, tt:3564.484\n",
      "Ep:191, loss:0.00000, loss_test:0.08367, lr:4.30e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.666, tt:3583.890\n",
      "Ep:192, loss:0.00000, loss_test:0.08388, lr:4.26e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.673, tt:3603.811\n",
      "Ep:193, loss:0.00000, loss_test:0.08389, lr:4.21e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.672, tt:3622.342\n",
      "Ep:194, loss:0.00000, loss_test:0.08382, lr:4.17e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.677, tt:3641.949\n",
      "Ep:195, loss:0.00000, loss_test:0.08416, lr:4.13e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.674, tt:3660.137\n",
      "Ep:196, loss:0.00000, loss_test:0.08410, lr:4.09e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.676, tt:3679.224\n",
      "Ep:197, loss:0.00000, loss_test:0.08425, lr:4.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.674, tt:3697.526\n",
      "Ep:198, loss:0.00000, loss_test:0.08441, lr:4.01e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.675, tt:3716.289\n",
      "Ep:199, loss:0.00000, loss_test:0.08414, lr:3.97e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.674, tt:3734.814\n",
      "Ep:200, loss:0.00000, loss_test:0.08427, lr:3.93e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.683, tt:3755.257\n",
      "Ep:201, loss:0.00000, loss_test:0.08440, lr:3.89e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.688, tt:3774.912\n",
      "Ep:202, loss:0.00000, loss_test:0.08442, lr:3.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.697, tt:3795.459\n",
      "Ep:203, loss:0.00000, loss_test:0.08438, lr:3.81e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.702, tt:3815.207\n",
      "Ep:204, loss:0.00000, loss_test:0.08450, lr:3.77e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.700, tt:3833.543\n",
      "Ep:205, loss:0.00000, loss_test:0.08441, lr:3.73e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.700, tt:3852.266\n",
      "Ep:206, loss:0.00000, loss_test:0.08476, lr:3.70e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.702, tt:3871.352\n",
      "Ep:207, loss:0.00000, loss_test:0.08481, lr:3.66e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.708, tt:3891.354\n",
      "Ep:208, loss:0.00000, loss_test:0.08454, lr:3.62e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.712, tt:3910.724\n",
      "Ep:209, loss:0.00000, loss_test:0.08477, lr:3.59e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.716, tt:3930.362\n",
      "Ep:210, loss:0.00000, loss_test:0.08508, lr:3.55e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.719, tt:3949.674\n",
      "Ep:211, loss:0.00000, loss_test:0.08475, lr:3.52e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.718, tt:3968.222\n",
      "Ep:212, loss:0.00000, loss_test:0.08466, lr:3.48e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.736, tt:3990.805\n",
      "Ep:213, loss:0.00000, loss_test:0.08498, lr:3.45e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.736, tt:4009.596\n",
      "Ep:214, loss:0.00000, loss_test:0.08500, lr:3.41e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.742, tt:4029.632\n",
      "Ep:215, loss:0.00000, loss_test:0.08478, lr:3.38e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.746, tt:4049.055\n",
      "Ep:216, loss:0.00000, loss_test:0.08491, lr:3.34e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.750, tt:4068.814\n",
      "Ep:217, loss:0.00000, loss_test:0.08503, lr:3.31e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.752, tt:4087.933\n",
      "Ep:218, loss:0.00000, loss_test:0.08499, lr:3.28e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.757, tt:4107.687\n",
      "Ep:219, loss:0.00000, loss_test:0.08498, lr:3.24e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.757, tt:4126.598\n",
      "Ep:220, loss:0.00000, loss_test:0.08501, lr:3.21e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.762, tt:4146.457\n",
      "Ep:221, loss:0.00000, loss_test:0.08498, lr:3.18e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.760, tt:4164.652\n",
      "Ep:222, loss:0.00000, loss_test:0.08505, lr:3.15e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.761, tt:4183.739\n",
      "Ep:223, loss:0.00000, loss_test:0.08516, lr:3.12e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.757, tt:4201.458\n",
      "Ep:224, loss:0.00000, loss_test:0.08510, lr:3.09e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.756, tt:4220.058\n",
      "Ep:225, loss:0.00000, loss_test:0.08499, lr:3.05e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.760, tt:4239.814\n",
      "Ep:226, loss:0.00000, loss_test:0.08523, lr:3.02e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.764, tt:4259.493\n",
      "Ep:227, loss:0.00000, loss_test:0.08530, lr:2.99e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.771, tt:4279.855\n",
      "Ep:228, loss:0.00000, loss_test:0.08526, lr:2.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.779, tt:4300.478\n",
      "Ep:229, loss:0.00000, loss_test:0.08525, lr:2.93e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.787, tt:4321.029\n",
      "Ep:230, loss:0.00000, loss_test:0.08530, lr:2.90e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.793, tt:4341.282\n",
      "Ep:231, loss:0.00000, loss_test:0.08551, lr:2.88e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.795, tt:4360.410\n",
      "Ep:232, loss:0.00000, loss_test:0.08548, lr:2.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.798, tt:4379.910\n",
      "Ep:233, loss:0.00000, loss_test:0.08543, lr:2.82e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.801, tt:4399.548\n",
      "Ep:234, loss:0.00000, loss_test:0.08555, lr:2.79e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.805, tt:4419.246\n",
      "Ep:235, loss:0.00000, loss_test:0.08568, lr:2.76e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.809, tt:4438.899\n",
      "Ep:236, loss:0.00000, loss_test:0.08566, lr:2.73e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.810, tt:4457.979\n",
      "Ep:237, loss:0.00000, loss_test:0.08560, lr:2.71e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.816, tt:4478.219\n",
      "Ep:238, loss:0.00000, loss_test:0.08572, lr:2.68e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.817, tt:4497.206\n",
      "Ep:239, loss:0.00000, loss_test:0.08581, lr:2.65e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.821, tt:4517.109\n",
      "Ep:240, loss:0.00000, loss_test:0.08573, lr:2.63e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.824, tt:4536.693\n",
      "Ep:241, loss:0.00000, loss_test:0.08581, lr:2.60e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.837, tt:4558.480\n",
      "Ep:242, loss:0.00000, loss_test:0.08583, lr:2.57e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.840, tt:4578.059\n",
      "Ep:243, loss:0.00000, loss_test:0.08576, lr:2.55e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.843, tt:4597.598\n",
      "Ep:244, loss:0.00000, loss_test:0.08597, lr:2.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.842, tt:4616.216\n",
      "Ep:245, loss:0.00000, loss_test:0.08606, lr:2.50e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.848, tt:4636.674\n",
      "Ep:246, loss:0.00000, loss_test:0.08590, lr:2.47e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.851, tt:4656.165\n",
      "Ep:247, loss:0.00000, loss_test:0.08599, lr:2.45e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.850, tt:4674.796\n",
      "Ep:248, loss:0.00000, loss_test:0.08610, lr:2.42e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.851, tt:4694.022\n",
      "Ep:249, loss:0.00000, loss_test:0.08609, lr:2.40e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.855, tt:4713.848\n",
      "Ep:250, loss:0.00000, loss_test:0.08611, lr:2.38e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.859, tt:4733.590\n",
      "Ep:251, loss:0.00000, loss_test:0.08622, lr:2.35e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.860, tt:4752.693\n",
      "Ep:252, loss:0.00000, loss_test:0.08613, lr:2.33e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.863, tt:4772.285\n",
      "Ep:253, loss:0.00000, loss_test:0.08626, lr:2.31e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.859, tt:4790.092\n",
      "Ep:254, loss:0.00000, loss_test:0.08628, lr:2.28e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.862, tt:4809.870\n",
      "Ep:255, loss:0.00000, loss_test:0.08636, lr:2.26e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.863, tt:4828.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:256, loss:0.00000, loss_test:0.08629, lr:2.24e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.866, tt:4848.532\n",
      "Ep:257, loss:0.00000, loss_test:0.08639, lr:2.21e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.868, tt:4867.907\n",
      "Ep:258, loss:0.00000, loss_test:0.08639, lr:2.19e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.865, tt:4886.162\n",
      "Ep:259, loss:0.00000, loss_test:0.08645, lr:2.17e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.865, tt:4905.004\n",
      "Ep:260, loss:0.00000, loss_test:0.08644, lr:2.15e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.864, tt:4923.399\n",
      "Ep:261, loss:0.00000, loss_test:0.08647, lr:2.13e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.856, tt:4940.326\n",
      "Ep:262, loss:0.00000, loss_test:0.08662, lr:2.11e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.857, tt:4959.324\n",
      "Ep:263, loss:0.00000, loss_test:0.08660, lr:2.08e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.858, tt:4978.467\n",
      "Ep:264, loss:0.00000, loss_test:0.08643, lr:2.06e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.857, tt:4997.063\n",
      "Ep:265, loss:0.00000, loss_test:0.08657, lr:2.04e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.859, tt:5016.438\n",
      "Ep:266, loss:0.00000, loss_test:0.08678, lr:2.02e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.854, tt:5033.960\n",
      "Ep:267, loss:0.00000, loss_test:0.08662, lr:2.00e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.851, tt:5051.954\n",
      "Ep:268, loss:0.00000, loss_test:0.08652, lr:1.98e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.857, tt:5072.465\n",
      "Ep:269, loss:0.00000, loss_test:0.08667, lr:1.96e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.854, tt:5090.662\n",
      "Ep:270, loss:0.00000, loss_test:0.08673, lr:1.94e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.863, tt:5111.764\n",
      "Ep:271, loss:0.00000, loss_test:0.08671, lr:1.92e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.866, tt:5131.613\n",
      "Ep:272, loss:0.00000, loss_test:0.08675, lr:1.90e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.869, tt:5151.312\n",
      "Ep:273, loss:0.00000, loss_test:0.08681, lr:1.89e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.870, tt:5170.245\n",
      "Ep:274, loss:0.00000, loss_test:0.08686, lr:1.87e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.871, tt:5189.493\n",
      "Ep:275, loss:0.00000, loss_test:0.08684, lr:1.85e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.869, tt:5207.731\n",
      "Ep:276, loss:0.00000, loss_test:0.08686, lr:1.83e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.867, tt:5226.282\n",
      "Ep:277, loss:0.00000, loss_test:0.08682, lr:1.81e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.868, tt:5245.241\n",
      "Ep:278, loss:0.00000, loss_test:0.08689, lr:1.79e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.867, tt:5264.019\n",
      "Ep:279, loss:0.00000, loss_test:0.08700, lr:1.78e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.870, tt:5283.595\n",
      "Ep:280, loss:0.00000, loss_test:0.08690, lr:1.76e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.872, tt:5303.007\n",
      "Ep:281, loss:0.00000, loss_test:0.08698, lr:1.74e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.870, tt:5321.301\n",
      "Ep:282, loss:0.00000, loss_test:0.08702, lr:1.72e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.866, tt:5339.180\n",
      "Ep:283, loss:0.00000, loss_test:0.08704, lr:1.71e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.866, tt:5357.963\n",
      "Ep:284, loss:0.00000, loss_test:0.08705, lr:1.69e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.867, tt:5377.051\n",
      "Ep:285, loss:0.00000, loss_test:0.08695, lr:1.67e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.866, tt:5395.804\n",
      "Ep:286, loss:0.00000, loss_test:0.08702, lr:1.65e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.868, tt:5415.077\n",
      "Ep:287, loss:0.00000, loss_test:0.08720, lr:1.64e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.866, tt:5433.536\n",
      "Ep:288, loss:0.00000, loss_test:0.08704, lr:1.62e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.866, tt:5452.146\n",
      "Ep:289, loss:0.00000, loss_test:0.08699, lr:1.61e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.866, tt:5471.224\n",
      "Ep:290, loss:0.00000, loss_test:0.08719, lr:1.59e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.868, tt:5490.570\n",
      "Ep:291, loss:0.00000, loss_test:0.08717, lr:1.57e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.869, tt:5509.889\n",
      "Ep:292, loss:0.00000, loss_test:0.08703, lr:1.56e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.870, tt:5528.884\n",
      "Ep:293, loss:0.00000, loss_test:0.08711, lr:1.54e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.874, tt:5548.915\n",
      "Ep:294, loss:0.00000, loss_test:0.08722, lr:1.53e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.870, tt:5566.762\n",
      "Ep:295, loss:0.00000, loss_test:0.08721, lr:1.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.845, tt:5578.098\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14196, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:20.680, tt:20.680\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.13572, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:22.987, tt:45.974\n",
      "Ep:2, loss:0.00049, loss_test:0.12603, lr:1.00e-02, fs:0.61472 (r=0.717,p=0.538),  time:26.407, tt:79.221\n",
      "Ep:3, loss:0.00045, loss_test:0.12186, lr:1.00e-02, fs:0.63265 (r=0.626,p=0.639),  time:31.283, tt:125.133\n",
      "Ep:4, loss:0.00043, loss_test:0.11719, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:37.051, tt:185.254\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.11330, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:41.800, tt:250.799\n",
      "Ep:6, loss:0.00038, loss_test:0.11059, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:45.420, tt:317.939\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00036, loss_test:0.10685, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:48.250, tt:386.001\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00034, loss_test:0.10384, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:50.209, tt:451.881\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00032, loss_test:0.10118, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:51.757, tt:517.567\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00030, loss_test:0.09939, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:53.607, tt:589.681\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00029, loss_test:0.09821, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:54.717, tt:656.606\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.09414, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:55.621, tt:723.075\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.09658, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:56.480, tt:790.716\n",
      "Ep:14, loss:0.00025, loss_test:0.09086, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:57.206, tt:858.083\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.09197, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:57.843, tt:925.495\n",
      "Ep:16, loss:0.00023, loss_test:0.08877, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:58.245, tt:990.164\n",
      "Ep:17, loss:0.00022, loss_test:0.08808, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:58.639, tt:1055.511\n",
      "Ep:18, loss:0.00021, loss_test:0.08672, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:59.112, tt:1123.133\n",
      "Ep:19, loss:0.00020, loss_test:0.08431, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:59.412, tt:1188.240\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.08538, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:59.852, tt:1256.882\n",
      "Ep:21, loss:0.00018, loss_test:0.08374, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:60.186, tt:1324.103\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.08205, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:60.416, tt:1389.579\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08049, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:60.639, tt:1455.347\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.08106, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:60.844, tt:1521.099\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08300, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:61.081, tt:1588.100\n",
      "Ep:26, loss:0.00015, loss_test:0.07760, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:61.294, tt:1654.943\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.07742, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:61.517, tt:1722.479\n",
      "Ep:28, loss:0.00014, loss_test:0.07894, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:61.741, tt:1790.502\n",
      "Ep:29, loss:0.00013, loss_test:0.07726, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:61.923, tt:1857.701\n",
      "Ep:30, loss:0.00013, loss_test:0.07525, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:61.987, tt:1921.591\n",
      "Ep:31, loss:0.00012, loss_test:0.07698, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:62.083, tt:1986.661\n",
      "Ep:32, loss:0.00012, loss_test:0.07671, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:62.219, tt:2053.232\n",
      "Ep:33, loss:0.00011, loss_test:0.07485, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:62.334, tt:2119.356\n",
      "Ep:34, loss:0.00011, loss_test:0.07212, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:62.403, tt:2184.119\n",
      "Ep:35, loss:0.00010, loss_test:0.07372, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:62.481, tt:2249.332\n",
      "Ep:36, loss:0.00010, loss_test:0.07093, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:62.653, tt:2318.171\n",
      "Ep:37, loss:0.00010, loss_test:0.07248, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:62.781, tt:2385.677\n",
      "Ep:38, loss:0.00009, loss_test:0.07082, lr:9.90e-03, fs:0.83422 (r=0.788,p=0.886),  time:62.870, tt:2451.924\n",
      "Ep:39, loss:0.00009, loss_test:0.07329, lr:9.80e-03, fs:0.81522 (r=0.758,p=0.882),  time:62.985, tt:2519.397\n",
      "Ep:40, loss:0.00009, loss_test:0.07486, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:63.143, tt:2588.852\n",
      "Ep:41, loss:0.00008, loss_test:0.07217, lr:9.61e-03, fs:0.82609 (r=0.768,p=0.894),  time:63.258, tt:2656.835\n",
      "Ep:42, loss:0.00008, loss_test:0.06923, lr:9.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:63.306, tt:2722.146\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.07034, lr:9.51e-03, fs:0.86517 (r=0.778,p=0.975),  time:63.333, tt:2786.657\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.06811, lr:9.51e-03, fs:0.85714 (r=0.788,p=0.940),  time:63.393, tt:2852.695\n",
      "Ep:45, loss:0.00007, loss_test:0.06823, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:63.452, tt:2918.799\n",
      "Ep:46, loss:0.00007, loss_test:0.06773, lr:9.51e-03, fs:0.87151 (r=0.788,p=0.975),  time:63.487, tt:2983.894\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.06718, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:63.527, tt:3049.298\n",
      "Ep:48, loss:0.00006, loss_test:0.06713, lr:9.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:63.600, tt:3116.385\n",
      "Ep:49, loss:0.00006, loss_test:0.06653, lr:9.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:63.668, tt:3183.395\n",
      "Ep:50, loss:0.00006, loss_test:0.06664, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:63.712, tt:3249.294\n",
      "Ep:51, loss:0.00006, loss_test:0.06699, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:63.801, tt:3317.645\n",
      "Ep:52, loss:0.00005, loss_test:0.06910, lr:9.51e-03, fs:0.80240 (r=0.677,p=0.985),  time:63.851, tt:3384.088\n",
      "Ep:53, loss:0.00005, loss_test:0.06863, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:63.883, tt:3449.688\n",
      "Ep:54, loss:0.00005, loss_test:0.07106, lr:9.51e-03, fs:0.79042 (r=0.667,p=0.971),  time:63.895, tt:3514.226\n",
      "Ep:55, loss:0.00005, loss_test:0.06966, lr:9.51e-03, fs:0.78571 (r=0.667,p=0.957),  time:63.915, tt:3579.261\n",
      "Ep:56, loss:0.00005, loss_test:0.06951, lr:9.51e-03, fs:0.83041 (r=0.717,p=0.986),  time:63.944, tt:3644.800\n",
      "Ep:57, loss:0.00005, loss_test:0.06824, lr:9.51e-03, fs:0.87500 (r=0.778,p=1.000),  time:64.056, tt:3715.263\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00004, loss_test:0.06767, lr:9.51e-03, fs:0.87500 (r=0.778,p=1.000),  time:64.111, tt:3782.563\n",
      "Ep:59, loss:0.00004, loss_test:0.06635, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:64.125, tt:3847.524\n",
      "Ep:60, loss:0.00004, loss_test:0.07039, lr:9.51e-03, fs:0.78528 (r=0.646,p=1.000),  time:64.159, tt:3913.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00004, loss_test:0.06917, lr:9.51e-03, fs:0.86207 (r=0.758,p=1.000),  time:64.230, tt:3982.234\n",
      "Ep:62, loss:0.00004, loss_test:0.06912, lr:9.51e-03, fs:0.79268 (r=0.657,p=1.000),  time:64.231, tt:4046.564\n",
      "Ep:63, loss:0.00004, loss_test:0.07110, lr:9.51e-03, fs:0.77301 (r=0.636,p=0.984),  time:64.257, tt:4112.448\n",
      "Ep:64, loss:0.00004, loss_test:0.06919, lr:9.51e-03, fs:0.78049 (r=0.646,p=0.985),  time:64.314, tt:4180.419\n",
      "Ep:65, loss:0.00003, loss_test:0.06946, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:64.363, tt:4247.934\n",
      "Ep:66, loss:0.00003, loss_test:0.06861, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:64.390, tt:4314.125\n",
      "Ep:67, loss:0.00003, loss_test:0.07017, lr:9.51e-03, fs:0.78788 (r=0.657,p=0.985),  time:64.409, tt:4379.801\n",
      "Ep:68, loss:0.00003, loss_test:0.07292, lr:9.51e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.422, tt:4445.096\n",
      "Ep:69, loss:0.00003, loss_test:0.07232, lr:9.41e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.504, tt:4515.315\n",
      "Ep:70, loss:0.00003, loss_test:0.07342, lr:9.32e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.514, tt:4580.482\n",
      "Ep:71, loss:0.00003, loss_test:0.07392, lr:9.23e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.536, tt:4646.610\n",
      "Ep:72, loss:0.00003, loss_test:0.07109, lr:9.14e-03, fs:0.78528 (r=0.646,p=1.000),  time:64.568, tt:4713.434\n",
      "Ep:73, loss:0.00003, loss_test:0.07003, lr:9.04e-03, fs:0.85549 (r=0.747,p=1.000),  time:64.600, tt:4780.404\n",
      "Ep:74, loss:0.00002, loss_test:0.07176, lr:8.95e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.621, tt:4846.563\n",
      "Ep:75, loss:0.00002, loss_test:0.07234, lr:8.86e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.653, tt:4913.658\n",
      "Ep:76, loss:0.00002, loss_test:0.07103, lr:8.78e-03, fs:0.78528 (r=0.646,p=1.000),  time:64.663, tt:4979.081\n",
      "Ep:77, loss:0.00002, loss_test:0.06992, lr:8.69e-03, fs:0.86207 (r=0.758,p=1.000),  time:64.689, tt:5045.748\n",
      "Ep:78, loss:0.00002, loss_test:0.06932, lr:8.60e-03, fs:0.86207 (r=0.758,p=1.000),  time:64.713, tt:5112.351\n",
      "Ep:79, loss:0.00002, loss_test:0.07320, lr:8.51e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.730, tt:5178.394\n",
      "Ep:80, loss:0.00002, loss_test:0.07566, lr:8.43e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.741, tt:5243.991\n",
      "Ep:81, loss:0.00002, loss_test:0.07390, lr:8.35e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.812, tt:5314.594\n",
      "Ep:82, loss:0.00002, loss_test:0.07364, lr:8.26e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.840, tt:5381.679\n",
      "Ep:83, loss:0.00002, loss_test:0.07252, lr:8.18e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.867, tt:5448.830\n",
      "Ep:84, loss:0.00002, loss_test:0.07240, lr:8.10e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.877, tt:5514.585\n",
      "Ep:85, loss:0.00002, loss_test:0.07535, lr:8.02e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.885, tt:5580.148\n",
      "Ep:86, loss:0.00002, loss_test:0.07426, lr:7.94e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.894, tt:5645.736\n",
      "Ep:87, loss:0.00002, loss_test:0.07546, lr:7.86e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.923, tt:5713.203\n",
      "Ep:88, loss:0.00002, loss_test:0.07130, lr:7.78e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.910, tt:5776.994\n",
      "Ep:89, loss:0.00002, loss_test:0.07186, lr:7.70e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.953, tt:5845.762\n",
      "Ep:90, loss:0.00002, loss_test:0.07498, lr:7.62e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.960, tt:5911.337\n",
      "Ep:91, loss:0.00002, loss_test:0.07507, lr:7.55e-03, fs:0.77778 (r=0.636,p=1.000),  time:64.981, tt:5978.248\n",
      "Ep:92, loss:0.00002, loss_test:0.07258, lr:7.47e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.002, tt:6045.219\n",
      "Ep:93, loss:0.00001, loss_test:0.07263, lr:7.40e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.058, tt:6115.482\n",
      "Ep:94, loss:0.00001, loss_test:0.07403, lr:7.32e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.063, tt:6180.960\n",
      "Ep:95, loss:0.00001, loss_test:0.07493, lr:7.25e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.088, tt:6248.470\n",
      "Ep:96, loss:0.00001, loss_test:0.07535, lr:7.18e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.100, tt:6314.670\n",
      "Ep:97, loss:0.00001, loss_test:0.07318, lr:7.11e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.119, tt:6381.641\n",
      "Ep:98, loss:0.00001, loss_test:0.07206, lr:7.03e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.132, tt:6448.084\n",
      "Ep:99, loss:0.00001, loss_test:0.07407, lr:6.96e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.156, tt:6515.593\n",
      "Ep:100, loss:0.00001, loss_test:0.07588, lr:6.89e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.201, tt:6585.324\n",
      "Ep:101, loss:0.00001, loss_test:0.07589, lr:6.83e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.228, tt:6653.263\n",
      "Ep:102, loss:0.00001, loss_test:0.07432, lr:6.76e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.249, tt:6720.644\n",
      "Ep:103, loss:0.00001, loss_test:0.07365, lr:6.69e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.261, tt:6787.110\n",
      "Ep:104, loss:0.00001, loss_test:0.07434, lr:6.62e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.268, tt:6853.148\n",
      "Ep:105, loss:0.00001, loss_test:0.07429, lr:6.56e-03, fs:0.77778 (r=0.636,p=1.000),  time:65.302, tt:6922.064\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14391, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:74.396, tt:74.396\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13902, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:73.240, tt:146.481\n",
      "Ep:2, loss:0.00051, loss_test:0.12438, lr:1.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:74.733, tt:224.199\n",
      "Ep:3, loss:0.00046, loss_test:0.11908, lr:1.00e-02, fs:0.63415 (r=0.657,p=0.613),  time:75.444, tt:301.775\n",
      "Ep:4, loss:0.00043, loss_test:0.11549, lr:1.00e-02, fs:0.64253 (r=0.717,p=0.582),  time:76.936, tt:384.678\n",
      "Ep:5, loss:0.00040, loss_test:0.10867, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:78.095, tt:468.569\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00037, loss_test:0.10256, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:78.983, tt:552.881\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00034, loss_test:0.09840, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:79.293, tt:634.342\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00031, loss_test:0.09475, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:79.729, tt:717.557\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.09080, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:79.954, tt:799.537\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00026, loss_test:0.08865, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:80.313, tt:883.443\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.08723, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:80.687, tt:968.243\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.08659, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:80.954, tt:1052.407\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.08180, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:81.009, tt:1134.124\n",
      "Ep:14, loss:0.00019, loss_test:0.08249, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:81.354, tt:1220.316\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08267, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:81.583, tt:1305.328\n",
      "Ep:16, loss:0.00016, loss_test:0.08255, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:81.707, tt:1389.012\n",
      "Ep:17, loss:0.00015, loss_test:0.08062, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:81.759, tt:1471.671\n",
      "Ep:18, loss:0.00014, loss_test:0.07724, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:81.749, tt:1553.237\n",
      "Ep:19, loss:0.00013, loss_test:0.07970, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:81.741, tt:1634.816\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.08068, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:81.842, tt:1718.678\n",
      "Ep:21, loss:0.00011, loss_test:0.08082, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:81.903, tt:1801.866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00010, loss_test:0.07741, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:81.910, tt:1883.941\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.07830, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:81.966, tt:1967.193\n",
      "Ep:24, loss:0.00008, loss_test:0.07674, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:82.025, tt:2050.633\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.07761, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:82.169, tt:2136.404\n",
      "Ep:26, loss:0.00007, loss_test:0.07603, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:82.221, tt:2219.980\n",
      "Ep:27, loss:0.00006, loss_test:0.07684, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:82.277, tt:2303.748\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00006, loss_test:0.07553, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:82.185, tt:2383.374\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00005, loss_test:0.07696, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:82.215, tt:2466.438\n",
      "Ep:30, loss:0.00005, loss_test:0.08343, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:82.164, tt:2547.075\n",
      "Ep:31, loss:0.00005, loss_test:0.09133, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:82.214, tt:2630.852\n",
      "Ep:32, loss:0.00004, loss_test:0.07549, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:82.272, tt:2714.968\n",
      "Ep:33, loss:0.00004, loss_test:0.08246, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:82.273, tt:2797.276\n",
      "Ep:34, loss:0.00004, loss_test:0.07792, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:82.263, tt:2879.215\n",
      "Ep:35, loss:0.00003, loss_test:0.07956, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:82.420, tt:2967.104\n",
      "Ep:36, loss:0.00003, loss_test:0.08373, lr:1.00e-02, fs:0.77108 (r=0.646,p=0.955),  time:82.438, tt:3050.196\n",
      "Ep:37, loss:0.00003, loss_test:0.08813, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:82.434, tt:3132.499\n",
      "Ep:38, loss:0.00003, loss_test:0.09061, lr:1.00e-02, fs:0.76829 (r=0.636,p=0.969),  time:82.461, tt:3215.993\n",
      "Ep:39, loss:0.00003, loss_test:0.09108, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:82.486, tt:3299.444\n",
      "Ep:40, loss:0.00002, loss_test:0.08845, lr:9.90e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.520, tt:3383.314\n",
      "Ep:41, loss:0.00002, loss_test:0.08746, lr:9.80e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.507, tt:3465.277\n",
      "Ep:42, loss:0.00002, loss_test:0.09383, lr:9.70e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.493, tt:3547.193\n",
      "Ep:43, loss:0.00002, loss_test:0.09177, lr:9.61e-03, fs:0.76829 (r=0.636,p=0.969),  time:82.489, tt:3629.511\n",
      "Ep:44, loss:0.00002, loss_test:0.09273, lr:9.51e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.599, tt:3716.966\n",
      "Ep:45, loss:0.00002, loss_test:0.09237, lr:9.41e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.671, tt:3802.859\n",
      "Ep:46, loss:0.00001, loss_test:0.08664, lr:9.32e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.711, tt:3887.409\n",
      "Ep:47, loss:0.00001, loss_test:0.09135, lr:9.23e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.721, tt:3970.605\n",
      "Ep:48, loss:0.00001, loss_test:0.09514, lr:9.14e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.648, tt:4049.761\n",
      "Ep:49, loss:0.00001, loss_test:0.08929, lr:9.04e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.661, tt:4133.029\n",
      "Ep:50, loss:0.00001, loss_test:0.09325, lr:8.95e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.627, tt:4213.989\n",
      "Ep:51, loss:0.00001, loss_test:0.09282, lr:8.86e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.610, tt:4295.740\n",
      "Ep:52, loss:0.00001, loss_test:0.09177, lr:8.78e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.617, tt:4378.684\n",
      "Ep:53, loss:0.00001, loss_test:0.09412, lr:8.69e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.642, tt:4462.660\n",
      "Ep:54, loss:0.00001, loss_test:0.09410, lr:8.60e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.700, tt:4548.523\n",
      "Ep:55, loss:0.00001, loss_test:0.09296, lr:8.51e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.698, tt:4631.106\n",
      "Ep:56, loss:0.00001, loss_test:0.09741, lr:8.43e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.715, tt:4714.745\n",
      "Ep:57, loss:0.00001, loss_test:0.09354, lr:8.35e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.697, tt:4796.408\n",
      "Ep:58, loss:0.00001, loss_test:0.09567, lr:8.26e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.678, tt:4878.031\n",
      "Ep:59, loss:0.00001, loss_test:0.09668, lr:8.18e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.682, tt:4960.903\n",
      "Ep:60, loss:0.00000, loss_test:0.09496, lr:8.10e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.654, tt:5041.907\n",
      "Ep:61, loss:0.00000, loss_test:0.09626, lr:8.02e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.629, tt:5122.985\n",
      "Ep:62, loss:0.00000, loss_test:0.09498, lr:7.94e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.613, tt:5204.596\n",
      "Ep:63, loss:0.00000, loss_test:0.10005, lr:7.86e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.559, tt:5283.779\n",
      "Ep:64, loss:0.00000, loss_test:0.09549, lr:7.78e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.547, tt:5365.535\n",
      "Ep:65, loss:0.00000, loss_test:0.09723, lr:7.70e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.536, tt:5447.401\n",
      "Ep:66, loss:0.00000, loss_test:0.09633, lr:7.62e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.523, tt:5529.017\n",
      "Ep:67, loss:0.00000, loss_test:0.09729, lr:7.55e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.459, tt:5607.232\n",
      "Ep:68, loss:0.00000, loss_test:0.09789, lr:7.47e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.446, tt:5688.760\n",
      "Ep:69, loss:0.00000, loss_test:0.09999, lr:7.40e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.454, tt:5771.767\n",
      "Ep:70, loss:0.00000, loss_test:0.09863, lr:7.32e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.423, tt:5852.063\n",
      "Ep:71, loss:0.00000, loss_test:0.09770, lr:7.25e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.410, tt:5933.529\n",
      "Ep:72, loss:0.00000, loss_test:0.09828, lr:7.18e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.385, tt:6014.101\n",
      "Ep:73, loss:0.00000, loss_test:0.09995, lr:7.11e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.380, tt:6096.087\n",
      "Ep:74, loss:0.00000, loss_test:0.09736, lr:7.03e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.382, tt:6178.631\n",
      "Ep:75, loss:0.00000, loss_test:0.10099, lr:6.96e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.376, tt:6260.545\n",
      "Ep:76, loss:0.00000, loss_test:0.10032, lr:6.89e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.403, tt:6345.061\n",
      "Ep:77, loss:0.00000, loss_test:0.09953, lr:6.83e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.375, tt:6425.217\n",
      "Ep:78, loss:0.00000, loss_test:0.09958, lr:6.76e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.378, tt:6507.857\n",
      "Ep:79, loss:0.00000, loss_test:0.10126, lr:6.69e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.357, tt:6588.573\n",
      "Ep:80, loss:0.00000, loss_test:0.09943, lr:6.62e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.408, tt:6675.068\n",
      "Ep:81, loss:0.00000, loss_test:0.10075, lr:6.56e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.377, tt:6754.925\n",
      "Ep:82, loss:0.00000, loss_test:0.10070, lr:6.49e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.399, tt:6839.112\n",
      "Ep:83, loss:0.00000, loss_test:0.09982, lr:6.43e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.404, tt:6921.918\n",
      "Ep:84, loss:0.00000, loss_test:0.09856, lr:6.36e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.416, tt:7005.402\n",
      "Ep:85, loss:0.00000, loss_test:0.10155, lr:6.30e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.400, tt:7086.392\n",
      "Ep:86, loss:0.00000, loss_test:0.09935, lr:6.24e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.370, tt:7166.181\n",
      "Ep:87, loss:0.00000, loss_test:0.09927, lr:6.17e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.388, tt:7250.156\n",
      "Ep:88, loss:0.00000, loss_test:0.09928, lr:6.11e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.382, tt:7332.004\n",
      "Ep:89, loss:0.00000, loss_test:0.10037, lr:6.05e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.358, tt:7412.183\n",
      "Ep:90, loss:0.00000, loss_test:0.09990, lr:5.99e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.333, tt:7492.330\n",
      "Ep:91, loss:0.00000, loss_test:0.10129, lr:5.93e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.339, tt:7575.202\n",
      "Ep:92, loss:0.00000, loss_test:0.09898, lr:5.87e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.341, tt:7657.731\n",
      "Ep:93, loss:0.00000, loss_test:0.09955, lr:5.81e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.349, tt:7740.773\n",
      "Ep:94, loss:0.00000, loss_test:0.09843, lr:5.75e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.351, tt:7823.336\n",
      "Ep:95, loss:0.00000, loss_test:0.09905, lr:5.70e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.353, tt:7905.858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00000, loss_test:0.10077, lr:5.64e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.394, tt:7992.181\n",
      "Ep:97, loss:0.00000, loss_test:0.09895, lr:5.58e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.429, tt:8078.004\n",
      "Ep:98, loss:0.00000, loss_test:0.10074, lr:5.53e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.446, tt:8162.179\n",
      "Ep:99, loss:0.00000, loss_test:0.09921, lr:5.47e-03, fs:0.77301 (r=0.636,p=0.984),  time:82.477, tt:8247.690\n",
      "Ep:100, loss:0.00000, loss_test:0.09859, lr:5.42e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.470, tt:8329.433\n",
      "Ep:101, loss:0.00000, loss_test:0.10023, lr:5.36e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.468, tt:8411.701\n",
      "Ep:102, loss:0.00000, loss_test:0.09914, lr:5.31e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.465, tt:8493.937\n",
      "Ep:103, loss:0.00000, loss_test:0.09846, lr:5.26e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.442, tt:8573.953\n",
      "Ep:104, loss:0.00000, loss_test:0.09914, lr:5.20e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.443, tt:8656.543\n",
      "Ep:105, loss:0.00000, loss_test:0.09907, lr:5.15e-03, fs:0.77778 (r=0.636,p=1.000),  time:82.414, tt:8735.922\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00053, loss_test:0.13768, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:68.951, tt:68.951\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00051, loss_test:0.12925, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:65.978, tt:131.957\n",
      "Ep:2, loss:0.00048, loss_test:0.12361, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:66.798, tt:200.393\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.11941, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:66.474, tt:265.897\n",
      "Ep:4, loss:0.00044, loss_test:0.11524, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:67.798, tt:338.992\n",
      "Ep:5, loss:0.00041, loss_test:0.11195, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:69.184, tt:415.104\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00038, loss_test:0.10784, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:70.692, tt:494.843\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00036, loss_test:0.10342, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:71.458, tt:571.660\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00034, loss_test:0.10094, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:72.113, tt:649.013\n",
      "Ep:9, loss:0.00032, loss_test:0.09713, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:72.358, tt:723.584\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00030, loss_test:0.09426, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:72.857, tt:801.429\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00029, loss_test:0.09229, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:73.126, tt:877.510\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.09118, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:73.377, tt:953.901\n",
      "Ep:13, loss:0.00025, loss_test:0.09018, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:73.386, tt:1027.406\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.08873, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:73.431, tt:1101.467\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.08706, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:73.681, tt:1178.900\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.08648, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:73.981, tt:1257.679\n",
      "Ep:17, loss:0.00019, loss_test:0.08473, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:74.065, tt:1333.170\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08461, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:74.198, tt:1409.761\n",
      "Ep:19, loss:0.00017, loss_test:0.08634, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:74.301, tt:1486.028\n",
      "Ep:20, loss:0.00016, loss_test:0.08239, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:74.372, tt:1561.811\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07936, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:74.525, tt:1639.555\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.07754, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:74.568, tt:1715.066\n",
      "Ep:23, loss:0.00013, loss_test:0.07636, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:74.615, tt:1790.751\n",
      "Ep:24, loss:0.00012, loss_test:0.07801, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:74.552, tt:1863.807\n",
      "Ep:25, loss:0.00012, loss_test:0.07368, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:74.595, tt:1939.462\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07618, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:74.549, tt:2012.818\n",
      "Ep:27, loss:0.00011, loss_test:0.08167, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:74.589, tt:2088.502\n",
      "Ep:28, loss:0.00011, loss_test:0.08333, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:74.553, tt:2162.028\n",
      "Ep:29, loss:0.00010, loss_test:0.08047, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:74.503, tt:2235.104\n",
      "Ep:30, loss:0.00009, loss_test:0.08136, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:74.470, tt:2308.575\n",
      "Ep:31, loss:0.00008, loss_test:0.07540, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:74.496, tt:2383.866\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07133, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:74.499, tt:2458.456\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.07128, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:74.512, tt:2533.398\n",
      "Ep:34, loss:0.00008, loss_test:0.07909, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:74.518, tt:2608.117\n",
      "Ep:35, loss:0.00007, loss_test:0.08332, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:74.524, tt:2682.859\n",
      "Ep:36, loss:0.00007, loss_test:0.07779, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:74.508, tt:2756.782\n",
      "Ep:37, loss:0.00007, loss_test:0.07257, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:74.466, tt:2829.709\n",
      "Ep:38, loss:0.00007, loss_test:0.07493, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:74.465, tt:2904.133\n",
      "Ep:39, loss:0.00006, loss_test:0.07169, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:74.412, tt:2976.461\n",
      "Ep:40, loss:0.00006, loss_test:0.06992, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:74.373, tt:3049.280\n",
      "Ep:41, loss:0.00006, loss_test:0.06934, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:74.358, tt:3123.024\n",
      "Ep:42, loss:0.00005, loss_test:0.07094, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:74.367, tt:3197.764\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.07257, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:74.385, tt:3272.938\n",
      "Ep:44, loss:0.00005, loss_test:0.07432, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:74.404, tt:3348.189\n",
      "Ep:45, loss:0.00005, loss_test:0.07563, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:74.392, tt:3422.040\n",
      "Ep:46, loss:0.00004, loss_test:0.07356, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:74.394, tt:3496.529\n",
      "Ep:47, loss:0.00004, loss_test:0.07552, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:74.433, tt:3572.808\n",
      "Ep:48, loss:0.00004, loss_test:0.07230, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:74.456, tt:3648.362\n",
      "Ep:49, loss:0.00004, loss_test:0.07162, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:74.421, tt:3721.057\n",
      "Ep:50, loss:0.00004, loss_test:0.07212, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:74.420, tt:3795.404\n",
      "Ep:51, loss:0.00004, loss_test:0.07179, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:74.444, tt:3871.091\n",
      "Ep:52, loss:0.00003, loss_test:0.07377, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:74.426, tt:3944.599\n",
      "Ep:53, loss:0.00003, loss_test:0.07497, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:74.531, tt:4024.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00003, loss_test:0.07792, lr:9.90e-03, fs:0.79070 (r=0.687,p=0.932),  time:74.583, tt:4102.086\n",
      "Ep:55, loss:0.00003, loss_test:0.07729, lr:9.80e-03, fs:0.77907 (r=0.677,p=0.918),  time:74.644, tt:4180.057\n",
      "Ep:56, loss:0.00003, loss_test:0.07235, lr:9.70e-03, fs:0.78613 (r=0.687,p=0.919),  time:74.709, tt:4258.424\n",
      "Ep:57, loss:0.00003, loss_test:0.06885, lr:9.61e-03, fs:0.84615 (r=0.778,p=0.928),  time:74.735, tt:4334.623\n",
      "Ep:58, loss:0.00003, loss_test:0.06997, lr:9.51e-03, fs:0.85870 (r=0.798,p=0.929),  time:74.737, tt:4409.507\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.07186, lr:9.51e-03, fs:0.85714 (r=0.788,p=0.940),  time:74.731, tt:4483.885\n",
      "Ep:60, loss:0.00003, loss_test:0.07513, lr:9.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.721, tt:4557.952\n",
      "Ep:61, loss:0.00003, loss_test:0.07729, lr:9.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:74.723, tt:4632.811\n",
      "Ep:62, loss:0.00003, loss_test:0.07337, lr:9.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.767, tt:4710.322\n",
      "Ep:63, loss:0.00002, loss_test:0.07020, lr:9.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:74.792, tt:4786.694\n",
      "Ep:64, loss:0.00002, loss_test:0.07160, lr:9.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:74.778, tt:4860.561\n",
      "Ep:65, loss:0.00002, loss_test:0.07358, lr:9.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.768, tt:4934.686\n",
      "Ep:66, loss:0.00002, loss_test:0.07842, lr:9.51e-03, fs:0.77907 (r=0.677,p=0.918),  time:74.752, tt:5008.356\n",
      "Ep:67, loss:0.00002, loss_test:0.07375, lr:9.51e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.748, tt:5082.831\n",
      "Ep:68, loss:0.00002, loss_test:0.07175, lr:9.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.753, tt:5157.933\n",
      "Ep:69, loss:0.00002, loss_test:0.07283, lr:9.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.785, tt:5234.917\n",
      "Ep:70, loss:0.00002, loss_test:0.07466, lr:9.41e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.779, tt:5309.343\n",
      "Ep:71, loss:0.00002, loss_test:0.07775, lr:9.32e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.764, tt:5382.974\n",
      "Ep:72, loss:0.00002, loss_test:0.07433, lr:9.23e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.757, tt:5457.265\n",
      "Ep:73, loss:0.00002, loss_test:0.07127, lr:9.14e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.767, tt:5532.753\n",
      "Ep:74, loss:0.00002, loss_test:0.07340, lr:9.04e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.752, tt:5606.428\n",
      "Ep:75, loss:0.00002, loss_test:0.07539, lr:8.95e-03, fs:0.77907 (r=0.677,p=0.918),  time:74.736, tt:5679.932\n",
      "Ep:76, loss:0.00002, loss_test:0.07991, lr:8.86e-03, fs:0.77457 (r=0.677,p=0.905),  time:74.759, tt:5756.428\n",
      "Ep:77, loss:0.00002, loss_test:0.07856, lr:8.78e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.742, tt:5829.908\n",
      "Ep:78, loss:0.00002, loss_test:0.07605, lr:8.69e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.725, tt:5903.248\n",
      "Ep:79, loss:0.00002, loss_test:0.07437, lr:8.60e-03, fs:0.78363 (r=0.677,p=0.931),  time:74.727, tt:5978.123\n",
      "Ep:80, loss:0.00002, loss_test:0.07491, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.764, tt:6055.924\n",
      "Ep:81, loss:0.00001, loss_test:0.07439, lr:8.43e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.754, tt:6129.831\n",
      "Ep:82, loss:0.00001, loss_test:0.07672, lr:8.35e-03, fs:0.78107 (r=0.667,p=0.943),  time:74.758, tt:6204.874\n",
      "Ep:83, loss:0.00001, loss_test:0.07664, lr:8.26e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.761, tt:6279.909\n",
      "Ep:84, loss:0.00001, loss_test:0.07639, lr:8.18e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.751, tt:6353.828\n",
      "Ep:85, loss:0.00001, loss_test:0.07327, lr:8.10e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.760, tt:6429.400\n",
      "Ep:86, loss:0.00001, loss_test:0.07647, lr:8.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.743, tt:6502.622\n",
      "Ep:87, loss:0.00001, loss_test:0.07769, lr:7.94e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.756, tt:6578.538\n",
      "Ep:88, loss:0.00001, loss_test:0.07916, lr:7.86e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.743, tt:6652.121\n",
      "Ep:89, loss:0.00001, loss_test:0.07584, lr:7.78e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.737, tt:6726.323\n",
      "Ep:90, loss:0.00001, loss_test:0.07580, lr:7.70e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.764, tt:6803.555\n",
      "Ep:91, loss:0.00001, loss_test:0.07638, lr:7.62e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.795, tt:6881.132\n",
      "Ep:92, loss:0.00001, loss_test:0.07765, lr:7.55e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.798, tt:6956.190\n",
      "Ep:93, loss:0.00001, loss_test:0.07667, lr:7.47e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.818, tt:7032.889\n",
      "Ep:94, loss:0.00001, loss_test:0.07578, lr:7.40e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.824, tt:7108.265\n",
      "Ep:95, loss:0.00001, loss_test:0.07710, lr:7.32e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.826, tt:7183.250\n",
      "Ep:96, loss:0.00001, loss_test:0.07792, lr:7.25e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.837, tt:7259.185\n",
      "Ep:97, loss:0.00001, loss_test:0.07579, lr:7.18e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.860, tt:7336.257\n",
      "Ep:98, loss:0.00001, loss_test:0.07609, lr:7.11e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.882, tt:7413.295\n",
      "Ep:99, loss:0.00001, loss_test:0.07707, lr:7.03e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.896, tt:7489.553\n",
      "Ep:100, loss:0.00001, loss_test:0.07798, lr:6.96e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.885, tt:7563.394\n",
      "Ep:101, loss:0.00001, loss_test:0.07788, lr:6.89e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.925, tt:7642.369\n",
      "Ep:102, loss:0.00001, loss_test:0.07768, lr:6.83e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.918, tt:7716.589\n",
      "Ep:103, loss:0.00001, loss_test:0.07762, lr:6.76e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.907, tt:7790.365\n",
      "Ep:104, loss:0.00001, loss_test:0.07524, lr:6.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.905, tt:7865.016\n",
      "Ep:105, loss:0.00001, loss_test:0.07737, lr:6.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.867, tt:7935.909\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"2-2\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02389, lr:6.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:11.067, tt:11.067\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02617, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:12.062, tt:24.125\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02771, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.768, tt:44.304\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02779, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:17.103, tt:68.412\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02716, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:19.105, tt:95.526\n",
      "Ep:5, loss:0.00005, loss_test:0.02634, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:21.521, tt:129.126\n",
      "Ep:6, loss:0.00005, loss_test:0.02555, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:23.205, tt:162.435\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02503, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:24.543, tt:196.342\n",
      "Ep:8, loss:0.00005, loss_test:0.02468, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:25.650, tt:230.850\n",
      "Ep:9, loss:0.00005, loss_test:0.02432, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:26.468, tt:264.681\n",
      "Ep:10, loss:0.00005, loss_test:0.02395, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:27.121, tt:298.335\n",
      "Ep:11, loss:0.00005, loss_test:0.02373, lr:6.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:27.586, tt:331.033\n",
      "Ep:12, loss:0.00005, loss_test:0.02343, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:28.066, tt:364.860\n",
      "Ep:13, loss:0.00005, loss_test:0.02290, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:28.482, tt:398.743\n",
      "Ep:14, loss:0.00004, loss_test:0.02242, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:28.898, tt:433.476\n",
      "Ep:15, loss:0.00004, loss_test:0.02202, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:29.255, tt:468.084\n",
      "Ep:16, loss:0.00004, loss_test:0.02173, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:29.635, tt:503.801\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02154, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:29.887, tt:537.961\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.02132, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:30.086, tt:571.627\n",
      "Ep:19, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:30.306, tt:606.122\n",
      "Ep:20, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:30.460, tt:639.658\n",
      "Ep:21, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:30.672, tt:674.786\n",
      "Ep:22, loss:0.00004, loss_test:0.02088, lr:6.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:30.829, tt:709.072\n",
      "Ep:23, loss:0.00003, loss_test:0.02081, lr:6.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:31.008, tt:744.182\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.02073, lr:6.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:31.147, tt:778.666\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.02048, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:31.335, tt:814.722\n",
      "Ep:26, loss:0.00003, loss_test:0.02034, lr:6.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:31.496, tt:850.397\n",
      "Ep:27, loss:0.00003, loss_test:0.02006, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:31.624, tt:885.459\n",
      "Ep:28, loss:0.00003, loss_test:0.01981, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:31.755, tt:920.900\n",
      "Ep:29, loss:0.00003, loss_test:0.01936, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:31.849, tt:955.460\n",
      "Ep:30, loss:0.00003, loss_test:0.01912, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:31.965, tt:990.916\n",
      "Ep:31, loss:0.00003, loss_test:0.01875, lr:6.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:32.040, tt:1025.269\n",
      "Ep:32, loss:0.00003, loss_test:0.01835, lr:6.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:32.125, tt:1060.116\n",
      "Ep:33, loss:0.00003, loss_test:0.01791, lr:6.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:32.201, tt:1094.820\n",
      "Ep:34, loss:0.00003, loss_test:0.01746, lr:6.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:32.306, tt:1130.713\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:32.369, tt:1165.283\n",
      "Ep:36, loss:0.00002, loss_test:0.01724, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:32.466, tt:1201.260\n",
      "Ep:37, loss:0.00002, loss_test:0.01697, lr:6.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:32.527, tt:1236.015\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01629, lr:6.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:32.606, tt:1271.618\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01621, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:32.655, tt:1306.203\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:32.753, tt:1342.888\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:32.833, tt:1378.972\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:32.903, tt:1414.815\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:32.962, tt:1450.333\n",
      "Ep:44, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:33.016, tt:1485.712\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01443, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:33.051, tt:1520.346\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:33.080, tt:1554.780\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:33.109, tt:1589.217\n",
      "Ep:48, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:33.150, tt:1624.365\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:33.178, tt:1658.908\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:33.215, tt:1693.974\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01341, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:33.264, tt:1729.714\n",
      "Ep:52, loss:0.00001, loss_test:0.01344, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:33.300, tt:1764.882\n",
      "Ep:53, loss:0.00001, loss_test:0.01319, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:33.364, tt:1801.682\n",
      "Ep:54, loss:0.00001, loss_test:0.01283, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:33.384, tt:1836.123\n",
      "Ep:55, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:33.416, tt:1871.281\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01255, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:33.438, tt:1905.967\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:33.486, tt:1942.165\n",
      "Ep:58, loss:0.00001, loss_test:0.01371, lr:6.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:33.509, tt:1977.044\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01662, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:33.552, tt:2013.116\n",
      "Ep:60, loss:0.00001, loss_test:0.01319, lr:6.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:33.577, tt:2048.219\n",
      "Ep:61, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:33.608, tt:2083.711\n",
      "Ep:62, loss:0.00001, loss_test:0.01495, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:33.622, tt:2118.217\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01382, lr:6.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:33.646, tt:2153.348\n",
      "Ep:64, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:33.692, tt:2189.993\n",
      "Ep:65, loss:0.00001, loss_test:0.01468, lr:6.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:33.721, tt:2225.553\n",
      "Ep:66, loss:0.00001, loss_test:0.01519, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:33.739, tt:2260.530\n",
      "Ep:67, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:33.743, tt:2294.510\n",
      "Ep:68, loss:0.00001, loss_test:0.01403, lr:6.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:33.764, tt:2329.726\n",
      "Ep:69, loss:0.00001, loss_test:0.01393, lr:6.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:33.781, tt:2364.695\n",
      "Ep:70, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:33.809, tt:2400.455\n",
      "Ep:71, loss:0.00001, loss_test:0.01386, lr:6.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:33.821, tt:2435.103\n",
      "Ep:72, loss:0.00001, loss_test:0.01487, lr:6.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:33.849, tt:2471.001\n",
      "Ep:73, loss:0.00001, loss_test:0.01680, lr:6.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:33.858, tt:2505.527\n",
      "Ep:74, loss:0.00001, loss_test:0.01609, lr:5.94e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.896, tt:2542.209\n",
      "Ep:75, loss:0.00001, loss_test:0.01666, lr:5.88e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.897, tt:2576.187\n",
      "Ep:76, loss:0.00001, loss_test:0.01537, lr:5.82e-02, fs:0.81053 (r=0.778,p=0.846),  time:33.899, tt:2610.238\n",
      "Ep:77, loss:0.00001, loss_test:0.01460, lr:5.76e-02, fs:0.78125 (r=0.758,p=0.806),  time:33.939, tt:2647.227\n",
      "Ep:78, loss:0.00001, loss_test:0.01472, lr:5.71e-02, fs:0.79381 (r=0.778,p=0.811),  time:33.945, tt:2681.636\n",
      "Ep:79, loss:0.00001, loss_test:0.01592, lr:5.65e-02, fs:0.80628 (r=0.778,p=0.837),  time:33.946, tt:2715.709\n",
      "Ep:80, loss:0.00001, loss_test:0.01727, lr:5.59e-02, fs:0.80214 (r=0.758,p=0.852),  time:33.959, tt:2750.673\n",
      "Ep:81, loss:0.00001, loss_test:0.01571, lr:5.54e-02, fs:0.80208 (r=0.778,p=0.828),  time:33.970, tt:2785.544\n",
      "Ep:82, loss:0.00001, loss_test:0.01524, lr:5.48e-02, fs:0.79793 (r=0.778,p=0.819),  time:33.990, tt:2821.163\n",
      "Ep:83, loss:0.00001, loss_test:0.01685, lr:5.43e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.008, tt:2856.704\n",
      "Ep:84, loss:0.00001, loss_test:0.01747, lr:5.37e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.029, tt:2892.502\n",
      "Ep:85, loss:0.00001, loss_test:0.01601, lr:5.32e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.040, tt:2927.443\n",
      "Ep:86, loss:0.00001, loss_test:0.01625, lr:5.27e-02, fs:0.79787 (r=0.758,p=0.843),  time:34.074, tt:2964.432\n",
      "Ep:87, loss:0.00001, loss_test:0.01670, lr:5.21e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.078, tt:2998.904\n",
      "Ep:88, loss:0.00000, loss_test:0.01730, lr:5.16e-02, fs:0.81053 (r=0.778,p=0.846),  time:34.085, tt:3033.596\n",
      "Ep:89, loss:0.00000, loss_test:0.01737, lr:5.11e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.108, tt:3069.734\n",
      "Ep:90, loss:0.00000, loss_test:0.01694, lr:5.06e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.124, tt:3105.274\n",
      "Ep:91, loss:0.00000, loss_test:0.01668, lr:5.01e-02, fs:0.79787 (r=0.758,p=0.843),  time:34.123, tt:3139.359\n",
      "Ep:92, loss:0.00000, loss_test:0.01668, lr:4.96e-02, fs:0.79787 (r=0.758,p=0.843),  time:34.127, tt:3173.774\n",
      "Ep:93, loss:0.00000, loss_test:0.01688, lr:4.91e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.132, tt:3208.416\n",
      "Ep:94, loss:0.00000, loss_test:0.01963, lr:4.86e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.154, tt:3244.584\n",
      "Ep:95, loss:0.00001, loss_test:0.01802, lr:4.81e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.157, tt:3279.099\n",
      "Ep:96, loss:0.00000, loss_test:0.01743, lr:4.76e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.175, tt:3315.020\n",
      "Ep:97, loss:0.00000, loss_test:0.01727, lr:4.71e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.180, tt:3349.643\n",
      "Ep:98, loss:0.00000, loss_test:0.01828, lr:4.67e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.176, tt:3383.381\n",
      "Ep:99, loss:0.00000, loss_test:0.02015, lr:4.62e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.182, tt:3418.172\n",
      "Ep:100, loss:0.00001, loss_test:0.01890, lr:4.57e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.197, tt:3453.883\n",
      "Ep:101, loss:0.00000, loss_test:0.01757, lr:4.53e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.200, tt:3488.437\n",
      "Ep:102, loss:0.00000, loss_test:0.01815, lr:4.48e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.210, tt:3523.637\n",
      "Ep:103, loss:0.00000, loss_test:0.01964, lr:4.44e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.221, tt:3558.972\n",
      "Ep:104, loss:0.00000, loss_test:0.01779, lr:4.39e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.228, tt:3593.968\n",
      "Ep:105, loss:0.00000, loss_test:0.01828, lr:4.35e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.258, tt:3631.307\n",
      "Ep:106, loss:0.00000, loss_test:0.01860, lr:4.31e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.272, tt:3667.064\n",
      "Ep:107, loss:0.00000, loss_test:0.01825, lr:4.26e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.282, tt:3702.419\n",
      "Ep:108, loss:0.00000, loss_test:0.01822, lr:4.22e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.292, tt:3737.827\n",
      "Ep:109, loss:0.00000, loss_test:0.02027, lr:4.18e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.314, tt:3774.504\n",
      "Ep:110, loss:0.00000, loss_test:0.01861, lr:4.14e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.332, tt:3810.804\n",
      "Ep:111, loss:0.00000, loss_test:0.01849, lr:4.10e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.334, tt:3845.458\n",
      "Ep:112, loss:0.00000, loss_test:0.01943, lr:4.05e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.337, tt:3880.098\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.02028, lr:4.05e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.351, tt:3916.004\n",
      "Ep:114, loss:0.00000, loss_test:0.01888, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.354, tt:3950.754\n",
      "Ep:115, loss:0.00000, loss_test:0.01934, lr:4.05e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.371, tt:3987.056\n",
      "Ep:116, loss:0.00000, loss_test:0.01964, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.375, tt:4021.828\n",
      "Ep:117, loss:0.00000, loss_test:0.01959, lr:4.05e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.376, tt:4056.349\n",
      "Ep:118, loss:0.00000, loss_test:0.01874, lr:4.05e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.384, tt:4091.696\n",
      "Ep:119, loss:0.00000, loss_test:0.01977, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.388, tt:4126.611\n",
      "Ep:120, loss:0.00000, loss_test:0.01933, lr:4.05e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.397, tt:4162.028\n",
      "Ep:121, loss:0.00000, loss_test:0.02025, lr:4.05e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.410, tt:4197.998\n",
      "Ep:122, loss:0.00000, loss_test:0.01977, lr:4.05e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.402, tt:4231.454\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01986, lr:4.05e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.414, tt:4267.398\n",
      "Ep:124, loss:0.00000, loss_test:0.01955, lr:4.05e-02, fs:0.81768 (r=0.747,p=0.902),  time:34.425, tt:4303.175\n",
      "Ep:125, loss:0.00000, loss_test:0.01971, lr:4.05e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.424, tt:4337.481\n",
      "Ep:126, loss:0.00000, loss_test:0.02026, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.427, tt:4372.287\n",
      "Ep:127, loss:0.00000, loss_test:0.02116, lr:4.05e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.434, tt:4407.567\n",
      "Ep:128, loss:0.00000, loss_test:0.01962, lr:4.05e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.452, tt:4444.316\n",
      "Ep:129, loss:0.00000, loss_test:0.01963, lr:4.05e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.454, tt:4479.069\n",
      "Ep:130, loss:0.00000, loss_test:0.02006, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.443, tt:4512.008\n",
      "Ep:131, loss:0.00000, loss_test:0.02045, lr:4.05e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.450, tt:4547.340\n",
      "Ep:132, loss:0.00000, loss_test:0.01976, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.451, tt:4581.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01914, lr:4.05e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.484, tt:4620.904\n",
      "Ep:134, loss:0.00000, loss_test:0.01995, lr:4.01e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.487, tt:4655.795\n",
      "Ep:135, loss:0.00000, loss_test:0.02032, lr:3.97e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.496, tt:4691.426\n",
      "Ep:136, loss:0.00000, loss_test:0.02095, lr:3.93e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.495, tt:4725.856\n",
      "Ep:137, loss:0.00000, loss_test:0.01937, lr:3.89e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.492, tt:4759.936\n",
      "Ep:138, loss:0.00000, loss_test:0.02053, lr:3.86e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.498, tt:4795.161\n",
      "Ep:139, loss:0.00000, loss_test:0.02010, lr:3.82e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.500, tt:4829.974\n",
      "Ep:140, loss:0.00000, loss_test:0.02018, lr:3.78e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.507, tt:4865.428\n",
      "Ep:141, loss:0.00000, loss_test:0.02026, lr:3.74e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.517, tt:4901.411\n",
      "Ep:142, loss:0.00000, loss_test:0.02048, lr:3.70e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.523, tt:4936.810\n",
      "Ep:143, loss:0.00000, loss_test:0.02030, lr:3.67e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.534, tt:4972.960\n",
      "Ep:144, loss:0.00000, loss_test:0.02055, lr:3.63e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.532, tt:5007.120\n",
      "Ep:145, loss:0.00000, loss_test:0.02007, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.531, tt:5041.516\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00000, loss_test:0.02064, lr:3.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.545, tt:5078.083\n",
      "Ep:147, loss:0.00000, loss_test:0.02078, lr:3.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:34.550, tt:5113.342\n",
      "Ep:148, loss:0.00000, loss_test:0.02098, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.554, tt:5148.543\n",
      "Ep:149, loss:0.00000, loss_test:0.02075, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.554, tt:5183.167\n",
      "Ep:150, loss:0.00000, loss_test:0.02019, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.554, tt:5217.627\n",
      "Ep:151, loss:0.00000, loss_test:0.02087, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.544, tt:5250.650\n",
      "Ep:152, loss:0.00000, loss_test:0.02051, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.550, tt:5286.074\n",
      "Ep:153, loss:0.00000, loss_test:0.02123, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.553, tt:5321.155\n",
      "Ep:154, loss:0.00000, loss_test:0.02072, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.551, tt:5355.345\n",
      "Ep:155, loss:0.00000, loss_test:0.02135, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.550, tt:5389.805\n",
      "Ep:156, loss:0.00000, loss_test:0.02070, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.547, tt:5423.946\n",
      "##########Best model found so far##########\n",
      "Ep:157, loss:0.00000, loss_test:0.02134, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.540, tt:5457.308\n",
      "Ep:158, loss:0.00000, loss_test:0.02077, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.533, tt:5490.820\n",
      "Ep:159, loss:0.00000, loss_test:0.02175, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.534, tt:5525.372\n",
      "Ep:160, loss:0.00000, loss_test:0.02106, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.530, tt:5559.343\n",
      "Ep:161, loss:0.00000, loss_test:0.02123, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.529, tt:5593.651\n",
      "Ep:162, loss:0.00000, loss_test:0.02137, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.533, tt:5628.840\n",
      "Ep:163, loss:0.00000, loss_test:0.02179, lr:3.59e-02, fs:0.84091 (r=0.747,p=0.961),  time:34.532, tt:5663.228\n",
      "Ep:164, loss:0.00000, loss_test:0.02211, lr:3.59e-02, fs:0.83616 (r=0.747,p=0.949),  time:34.529, tt:5697.265\n",
      "Ep:165, loss:0.00000, loss_test:0.02124, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.532, tt:5732.361\n",
      "Ep:166, loss:0.00000, loss_test:0.02138, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.531, tt:5766.726\n",
      "Ep:167, loss:0.00000, loss_test:0.02101, lr:3.59e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.539, tt:5802.510\n",
      "Ep:168, loss:0.00000, loss_test:0.02155, lr:3.56e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.548, tt:5838.537\n",
      "Ep:169, loss:0.00000, loss_test:0.02124, lr:3.52e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.555, tt:5874.304\n",
      "Ep:170, loss:0.00000, loss_test:0.02170, lr:3.49e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.565, tt:5910.628\n",
      "Ep:171, loss:0.00000, loss_test:0.02149, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.572, tt:5946.321\n",
      "##########Best model found so far##########\n",
      "Ep:172, loss:0.00000, loss_test:0.02189, lr:3.45e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.575, tt:5981.486\n",
      "Ep:173, loss:0.00000, loss_test:0.02142, lr:3.45e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.573, tt:6015.637\n",
      "##########Best model found so far##########\n",
      "Ep:174, loss:0.00000, loss_test:0.02197, lr:3.45e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.582, tt:6051.809\n",
      "Ep:175, loss:0.00000, loss_test:0.02192, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.595, tt:6088.684\n",
      "Ep:176, loss:0.00000, loss_test:0.02210, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.600, tt:6124.136\n",
      "Ep:177, loss:0.00000, loss_test:0.02235, lr:3.45e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.607, tt:6160.085\n",
      "Ep:178, loss:0.00000, loss_test:0.02199, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.609, tt:6195.057\n",
      "Ep:179, loss:0.00000, loss_test:0.02173, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.618, tt:6231.186\n",
      "Ep:180, loss:0.00000, loss_test:0.02161, lr:3.45e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.617, tt:6265.605\n",
      "Ep:181, loss:0.00000, loss_test:0.02223, lr:3.45e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.625, tt:6301.725\n",
      "Ep:182, loss:0.00000, loss_test:0.02247, lr:3.45e-02, fs:0.83429 (r=0.737,p=0.961),  time:34.624, tt:6336.222\n",
      "Ep:183, loss:0.00000, loss_test:0.02221, lr:3.45e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.633, tt:6372.446\n",
      "Ep:184, loss:0.00000, loss_test:0.02156, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.637, tt:6407.919\n",
      "Ep:185, loss:0.00000, loss_test:0.02199, lr:3.42e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.642, tt:6443.355\n",
      "Ep:186, loss:0.00000, loss_test:0.02184, lr:3.38e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.644, tt:6478.382\n",
      "Ep:187, loss:0.00000, loss_test:0.02199, lr:3.35e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.643, tt:6512.954\n",
      "Ep:188, loss:0.00000, loss_test:0.02169, lr:3.32e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.653, tt:6549.347\n",
      "Ep:189, loss:0.00000, loss_test:0.02169, lr:3.28e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.648, tt:6583.085\n",
      "Ep:190, loss:0.00000, loss_test:0.02180, lr:3.25e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.650, tt:6618.179\n",
      "Ep:191, loss:0.00000, loss_test:0.02226, lr:3.22e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.659, tt:6654.496\n",
      "Ep:192, loss:0.00000, loss_test:0.02201, lr:3.19e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.665, tt:6690.360\n",
      "Ep:193, loss:0.00000, loss_test:0.02198, lr:3.15e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.670, tt:6725.921\n",
      "Ep:194, loss:0.00000, loss_test:0.02222, lr:3.12e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.663, tt:6759.373\n",
      "Ep:195, loss:0.00000, loss_test:0.02217, lr:3.09e-02, fs:0.86517 (r=0.778,p=0.975),  time:34.659, tt:6793.226\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02047, lr:6.00e-02, fs:0.63677 (r=0.717,p=0.573),  time:23.081, tt:23.081\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:26.090, tt:52.181\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02215, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.398, tt:79.195\n",
      "Ep:3, loss:0.00004, loss_test:0.02274, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.497, tt:109.986\n",
      "Ep:4, loss:0.00004, loss_test:0.02223, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.925, tt:139.623\n",
      "Ep:5, loss:0.00004, loss_test:0.02109, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:28.425, tt:170.549\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:28.678, tt:200.743\n",
      "Ep:7, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:29.050, tt:232.399\n",
      "Ep:8, loss:0.00004, loss_test:0.01867, lr:6.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:29.313, tt:263.816\n",
      "Ep:9, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:29.550, tt:295.500\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01859, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:29.649, tt:326.141\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01827, lr:6.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:29.739, tt:356.864\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01793, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:29.800, tt:387.398\n",
      "Ep:13, loss:0.00003, loss_test:0.01779, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:29.794, tt:417.120\n",
      "Ep:14, loss:0.00003, loss_test:0.01772, lr:6.00e-02, fs:0.66667 (r=0.879,p=0.537),  time:29.939, tt:449.092\n",
      "Ep:15, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:30.067, tt:481.068\n",
      "Ep:16, loss:0.00003, loss_test:0.01772, lr:6.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:30.251, tt:514.274\n",
      "Ep:17, loss:0.00003, loss_test:0.01781, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:30.356, tt:546.408\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01784, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:30.440, tt:578.364\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01775, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:30.507, tt:610.149\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01761, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:30.551, tt:641.563\n",
      "Ep:21, loss:0.00003, loss_test:0.01746, lr:6.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:30.616, tt:673.541\n",
      "Ep:22, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:30.645, tt:704.833\n",
      "Ep:23, loss:0.00003, loss_test:0.01734, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:30.661, tt:735.859\n",
      "Ep:24, loss:0.00002, loss_test:0.01733, lr:6.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:30.654, tt:766.346\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01737, lr:6.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:30.625, tt:796.247\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01738, lr:6.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:30.630, tt:827.003\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01732, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:30.701, tt:859.624\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01720, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:30.713, tt:890.668\n",
      "Ep:29, loss:0.00002, loss_test:0.01708, lr:6.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:30.720, tt:921.605\n",
      "Ep:30, loss:0.00002, loss_test:0.01696, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:30.724, tt:952.431\n",
      "Ep:31, loss:0.00002, loss_test:0.01693, lr:6.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:30.720, tt:983.035\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01695, lr:6.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:30.766, tt:1015.264\n",
      "Ep:33, loss:0.00002, loss_test:0.01693, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:30.780, tt:1046.530\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01691, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:30.796, tt:1077.875\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01686, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:30.828, tt:1109.794\n",
      "Ep:36, loss:0.00002, loss_test:0.01683, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.838, tt:1141.018\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01679, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.872, tt:1173.141\n",
      "Ep:38, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.941, tt:1206.712\n",
      "Ep:39, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.920, tt:1236.810\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.879, tt:1266.034\n",
      "Ep:41, loss:0.00002, loss_test:0.01670, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.860, tt:1296.119\n",
      "Ep:42, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.867, tt:1327.263\n",
      "Ep:43, loss:0.00002, loss_test:0.01665, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.850, tt:1357.394\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.857, tt:1388.550\n",
      "Ep:45, loss:0.00002, loss_test:0.01668, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.817, tt:1417.592\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01670, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:30.783, tt:1446.781\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01670, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:30.783, tt:1477.593\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:30.789, tt:1508.656\n",
      "Ep:49, loss:0.00002, loss_test:0.01665, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:30.777, tt:1538.842\n",
      "Ep:50, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.767, tt:1569.119\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01663, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.740, tt:1598.498\n",
      "Ep:52, loss:0.00002, loss_test:0.01665, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.767, tt:1630.670\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01672, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.777, tt:1661.936\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.745, tt:1690.963\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.759, tt:1722.530\n",
      "Ep:56, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.751, tt:1752.793\n",
      "Ep:57, loss:0.00001, loss_test:0.01673, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.727, tt:1782.176\n",
      "Ep:58, loss:0.00001, loss_test:0.01674, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.741, tt:1813.726\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01676, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.727, tt:1843.648\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01672, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.776, tt:1877.310\n",
      "Ep:61, loss:0.00001, loss_test:0.01675, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.772, tt:1907.845\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01678, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.775, tt:1938.797\n",
      "Ep:63, loss:0.00001, loss_test:0.01680, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.765, tt:1968.988\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01684, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.754, tt:1999.006\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01685, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.753, tt:2029.686\n",
      "Ep:66, loss:0.00001, loss_test:0.01682, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.763, tt:2061.112\n",
      "Ep:67, loss:0.00001, loss_test:0.01686, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.763, tt:2091.892\n",
      "Ep:68, loss:0.00001, loss_test:0.01691, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.756, tt:2122.161\n",
      "Ep:69, loss:0.00001, loss_test:0.01693, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.758, tt:2153.061\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00001, loss_test:0.01693, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.757, tt:2183.733\n",
      "Ep:71, loss:0.00001, loss_test:0.01698, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.734, tt:2212.815\n",
      "Ep:72, loss:0.00001, loss_test:0.01701, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.725, tt:2242.945\n",
      "Ep:73, loss:0.00001, loss_test:0.01698, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.718, tt:2273.140\n",
      "Ep:74, loss:0.00001, loss_test:0.01703, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.698, tt:2302.347\n",
      "Ep:75, loss:0.00001, loss_test:0.01713, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.698, tt:2333.014\n",
      "Ep:76, loss:0.00001, loss_test:0.01711, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.701, tt:2363.954\n",
      "Ep:77, loss:0.00001, loss_test:0.01713, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.705, tt:2394.970\n",
      "Ep:78, loss:0.00001, loss_test:0.01720, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.709, tt:2425.981\n",
      "Ep:79, loss:0.00001, loss_test:0.01723, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.691, tt:2455.280\n",
      "Ep:80, loss:0.00001, loss_test:0.01729, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.701, tt:2486.761\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01730, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.703, tt:2517.644\n",
      "Ep:82, loss:0.00001, loss_test:0.01738, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.704, tt:2548.447\n",
      "Ep:83, loss:0.00001, loss_test:0.01744, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.707, tt:2579.364\n",
      "Ep:84, loss:0.00001, loss_test:0.01749, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.708, tt:2610.191\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01749, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.712, tt:2641.233\n",
      "Ep:86, loss:0.00001, loss_test:0.01754, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.723, tt:2672.873\n",
      "Ep:87, loss:0.00001, loss_test:0.01759, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.730, tt:2704.279\n",
      "Ep:88, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.741, tt:2735.969\n",
      "Ep:89, loss:0.00001, loss_test:0.01774, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.747, tt:2767.260\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01778, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.735, tt:2796.882\n",
      "Ep:91, loss:0.00001, loss_test:0.01783, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.731, tt:2827.222\n",
      "Ep:92, loss:0.00001, loss_test:0.01786, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.724, tt:2857.354\n",
      "Ep:93, loss:0.00001, loss_test:0.01790, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.719, tt:2887.599\n",
      "Ep:94, loss:0.00001, loss_test:0.01800, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.717, tt:2918.084\n",
      "Ep:95, loss:0.00001, loss_test:0.01805, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.708, tt:2947.995\n",
      "Ep:96, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.704, tt:2978.334\n",
      "Ep:97, loss:0.00001, loss_test:0.01813, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.696, tt:3008.221\n",
      "Ep:98, loss:0.00001, loss_test:0.01824, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.682, tt:3037.508\n",
      "Ep:99, loss:0.00001, loss_test:0.01826, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.656, tt:3065.639\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01833, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.639, tt:3094.545\n",
      "Ep:101, loss:0.00001, loss_test:0.01840, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.633, tt:3124.530\n",
      "Ep:102, loss:0.00001, loss_test:0.01851, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.630, tt:3154.871\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.01857, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.627, tt:3185.213\n",
      "Ep:104, loss:0.00001, loss_test:0.01859, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.641, tt:3217.314\n",
      "Ep:105, loss:0.00001, loss_test:0.01868, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.644, tt:3248.250\n",
      "Ep:106, loss:0.00001, loss_test:0.01869, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.644, tt:3278.936\n",
      "Ep:107, loss:0.00001, loss_test:0.01876, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.646, tt:3309.819\n",
      "Ep:108, loss:0.00001, loss_test:0.01887, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.638, tt:3339.591\n",
      "Ep:109, loss:0.00001, loss_test:0.01896, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.652, tt:3371.773\n",
      "Ep:110, loss:0.00001, loss_test:0.01900, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.652, tt:3402.372\n",
      "Ep:111, loss:0.00001, loss_test:0.01905, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.659, tt:3433.766\n",
      "Ep:112, loss:0.00001, loss_test:0.01911, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.650, tt:3463.473\n",
      "Ep:113, loss:0.00001, loss_test:0.01917, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.642, tt:3493.203\n",
      "Ep:114, loss:0.00001, loss_test:0.01921, lr:5.94e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.632, tt:3522.641\n",
      "Ep:115, loss:0.00001, loss_test:0.01928, lr:5.88e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.638, tt:3554.036\n",
      "Ep:116, loss:0.00001, loss_test:0.01941, lr:5.82e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.649, tt:3585.915\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01946, lr:5.82e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.651, tt:3616.785\n",
      "Ep:118, loss:0.00001, loss_test:0.01954, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.660, tt:3648.581\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.01953, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.669, tt:3680.294\n",
      "Ep:120, loss:0.00001, loss_test:0.01964, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.668, tt:3710.877\n",
      "Ep:121, loss:0.00001, loss_test:0.01976, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.665, tt:3741.188\n",
      "Ep:122, loss:0.00001, loss_test:0.01982, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.675, tt:3773.026\n",
      "Ep:123, loss:0.00001, loss_test:0.01989, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.676, tt:3803.813\n",
      "Ep:124, loss:0.00001, loss_test:0.01998, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.679, tt:3834.901\n",
      "Ep:125, loss:0.00001, loss_test:0.02003, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.692, tt:3867.168\n",
      "Ep:126, loss:0.00001, loss_test:0.02014, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.693, tt:3898.016\n",
      "Ep:127, loss:0.00001, loss_test:0.02024, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.703, tt:3929.983\n",
      "Ep:128, loss:0.00001, loss_test:0.02036, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.712, tt:3961.875\n",
      "Ep:129, loss:0.00001, loss_test:0.02043, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.709, tt:3992.161\n",
      "Ep:130, loss:0.00001, loss_test:0.02049, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.704, tt:4022.228\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.02058, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.723, tt:4055.390\n",
      "Ep:132, loss:0.00001, loss_test:0.02060, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.717, tt:4085.377\n",
      "Ep:133, loss:0.00001, loss_test:0.02069, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.709, tt:4115.073\n",
      "Ep:134, loss:0.00001, loss_test:0.02075, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.696, tt:4143.898\n",
      "Ep:135, loss:0.00001, loss_test:0.02082, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.703, tt:4175.587\n",
      "Ep:136, loss:0.00001, loss_test:0.02094, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.702, tt:4206.178\n",
      "Ep:137, loss:0.00001, loss_test:0.02104, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.700, tt:4236.651\n",
      "Ep:138, loss:0.00001, loss_test:0.02111, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.707, tt:4268.234\n",
      "Ep:139, loss:0.00001, loss_test:0.02119, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.692, tt:4296.884\n",
      "Ep:140, loss:0.00001, loss_test:0.02131, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.695, tt:4327.983\n",
      "Ep:141, loss:0.00001, loss_test:0.02140, lr:5.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.692, tt:4358.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.02142, lr:5.71e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.699, tt:4389.920\n",
      "Ep:143, loss:0.00001, loss_test:0.02157, lr:5.65e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.694, tt:4420.003\n",
      "Ep:144, loss:0.00001, loss_test:0.02161, lr:5.59e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.699, tt:4451.322\n",
      "Ep:145, loss:0.00001, loss_test:0.02171, lr:5.54e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.697, tt:4481.800\n",
      "Ep:146, loss:0.00001, loss_test:0.02178, lr:5.48e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.706, tt:4513.768\n",
      "Ep:147, loss:0.00001, loss_test:0.02189, lr:5.43e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.698, tt:4543.355\n",
      "Ep:148, loss:0.00000, loss_test:0.02199, lr:5.37e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.708, tt:4575.533\n",
      "Ep:149, loss:0.00000, loss_test:0.02201, lr:5.32e-02, fs:0.87500 (r=0.848,p=0.903),  time:30.705, tt:4605.773\n",
      "Ep:150, loss:0.00000, loss_test:0.02209, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.708, tt:4636.889\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00000, loss_test:0.02219, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.709, tt:4667.808\n",
      "Ep:152, loss:0.00000, loss_test:0.02222, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.721, tt:4700.242\n",
      "Ep:153, loss:0.00000, loss_test:0.02232, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.717, tt:4730.479\n",
      "Ep:154, loss:0.00000, loss_test:0.02237, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.718, tt:4761.317\n",
      "Ep:155, loss:0.00000, loss_test:0.02250, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.718, tt:4791.941\n",
      "Ep:156, loss:0.00000, loss_test:0.02252, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.721, tt:4823.184\n",
      "Ep:157, loss:0.00000, loss_test:0.02260, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.717, tt:4853.225\n",
      "Ep:158, loss:0.00000, loss_test:0.02270, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.715, tt:4883.677\n",
      "Ep:159, loss:0.00000, loss_test:0.02272, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.713, tt:4914.096\n",
      "Ep:160, loss:0.00000, loss_test:0.02285, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.715, tt:4945.132\n",
      "Ep:161, loss:0.00000, loss_test:0.02297, lr:5.27e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.712, tt:4975.360\n",
      "Ep:162, loss:0.00000, loss_test:0.02300, lr:5.21e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.718, tt:5007.079\n",
      "Ep:163, loss:0.00000, loss_test:0.02306, lr:5.16e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.724, tt:5038.690\n",
      "Ep:164, loss:0.00000, loss_test:0.02318, lr:5.11e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.720, tt:5068.873\n",
      "Ep:165, loss:0.00000, loss_test:0.02324, lr:5.06e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.716, tt:5098.821\n",
      "Ep:166, loss:0.00000, loss_test:0.02325, lr:5.01e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.714, tt:5129.192\n",
      "Ep:167, loss:0.00000, loss_test:0.02334, lr:4.96e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.713, tt:5159.727\n",
      "Ep:168, loss:0.00000, loss_test:0.02343, lr:4.91e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.710, tt:5189.913\n",
      "Ep:169, loss:0.00000, loss_test:0.02350, lr:4.86e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.709, tt:5220.604\n",
      "Ep:170, loss:0.00000, loss_test:0.02361, lr:4.81e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.713, tt:5251.940\n",
      "Ep:171, loss:0.00000, loss_test:0.02372, lr:4.76e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.712, tt:5282.431\n",
      "Ep:172, loss:0.00000, loss_test:0.02373, lr:4.71e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.704, tt:5311.784\n",
      "Ep:173, loss:0.00000, loss_test:0.02383, lr:4.67e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.715, tt:5344.407\n",
      "Ep:174, loss:0.00000, loss_test:0.02389, lr:4.62e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.710, tt:5374.293\n",
      "Ep:175, loss:0.00000, loss_test:0.02399, lr:4.57e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.710, tt:5404.933\n",
      "Ep:176, loss:0.00000, loss_test:0.02408, lr:4.53e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.706, tt:5435.040\n",
      "Ep:177, loss:0.00000, loss_test:0.02415, lr:4.48e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.705, tt:5465.467\n",
      "Ep:178, loss:0.00000, loss_test:0.02414, lr:4.44e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.693, tt:5494.090\n",
      "Ep:179, loss:0.00000, loss_test:0.02415, lr:4.39e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.693, tt:5524.824\n",
      "Ep:180, loss:0.00000, loss_test:0.02422, lr:4.35e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.697, tt:5556.076\n",
      "Ep:181, loss:0.00000, loss_test:0.02427, lr:4.31e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.692, tt:5586.024\n",
      "Ep:182, loss:0.00000, loss_test:0.02436, lr:4.26e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.693, tt:5616.786\n",
      "Ep:183, loss:0.00000, loss_test:0.02445, lr:4.22e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.695, tt:5647.956\n",
      "Ep:184, loss:0.00000, loss_test:0.02452, lr:4.18e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.690, tt:5677.643\n",
      "Ep:185, loss:0.00000, loss_test:0.02458, lr:4.14e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.691, tt:5708.469\n",
      "Ep:186, loss:0.00000, loss_test:0.02467, lr:4.10e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.688, tt:5738.632\n",
      "Ep:187, loss:0.00000, loss_test:0.02474, lr:4.05e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.684, tt:5768.574\n",
      "Ep:188, loss:0.00000, loss_test:0.02479, lr:4.01e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.686, tt:5799.713\n",
      "Ep:189, loss:0.00000, loss_test:0.02482, lr:3.97e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.683, tt:5829.735\n",
      "Ep:190, loss:0.00000, loss_test:0.02488, lr:3.93e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.682, tt:5860.243\n",
      "Ep:191, loss:0.00000, loss_test:0.02493, lr:3.89e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.684, tt:5891.333\n",
      "Ep:192, loss:0.00000, loss_test:0.02502, lr:3.86e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.678, tt:5920.840\n",
      "Ep:193, loss:0.00000, loss_test:0.02511, lr:3.82e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.669, tt:5949.855\n",
      "Ep:194, loss:0.00000, loss_test:0.02513, lr:3.78e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.652, tt:5977.051\n",
      "Ep:195, loss:0.00000, loss_test:0.02519, lr:3.74e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.647, tt:6006.867\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.01985, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:32.498, tt:32.498\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02390, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.283, tt:70.567\n",
      "Ep:2, loss:0.00005, loss_test:0.02545, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.125, tt:105.376\n",
      "Ep:3, loss:0.00005, loss_test:0.02530, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.875, tt:143.498\n",
      "Ep:4, loss:0.00005, loss_test:0.02430, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.264, tt:181.321\n",
      "Ep:5, loss:0.00005, loss_test:0.02283, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:36.395, tt:218.369\n",
      "Ep:6, loss:0.00004, loss_test:0.02123, lr:6.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:36.585, tt:256.098\n",
      "Ep:7, loss:0.00004, loss_test:0.02008, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:36.806, tt:294.444\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:36.788, tt:331.089\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01940, lr:6.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:37.079, tt:370.787\n",
      "Ep:10, loss:0.00004, loss_test:0.01902, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:37.272, tt:409.992\n",
      "Ep:11, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:37.370, tt:448.434\n",
      "Ep:12, loss:0.00003, loss_test:0.01842, lr:6.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:37.509, tt:487.616\n",
      "Ep:13, loss:0.00003, loss_test:0.01816, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:37.632, tt:526.848\n",
      "Ep:14, loss:0.00003, loss_test:0.01790, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:37.843, tt:567.652\n",
      "Ep:15, loss:0.00003, loss_test:0.01778, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:37.858, tt:605.734\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00003, loss_test:0.01774, lr:6.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:37.843, tt:643.323\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01766, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:38.024, tt:684.435\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:38.030, tt:722.567\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:38.064, tt:761.287\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01716, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:38.040, tt:798.844\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01706, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:38.133, tt:838.924\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:38.186, tt:878.270\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01681, lr:6.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:38.173, tt:916.159\n",
      "Ep:24, loss:0.00002, loss_test:0.01657, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:38.174, tt:954.362\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01635, lr:6.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:38.237, tt:994.166\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01623, lr:6.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:38.309, tt:1034.334\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:38.311, tt:1072.702\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01604, lr:6.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:38.338, tt:1111.788\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01599, lr:6.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:38.310, tt:1149.300\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01594, lr:6.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:38.330, tt:1188.234\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01585, lr:6.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:38.321, tt:1226.258\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01573, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:38.324, tt:1264.696\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:38.348, tt:1303.828\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:38.373, tt:1343.040\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:38.394, tt:1382.169\n",
      "Ep:36, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:38.384, tt:1420.209\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:38.397, tt:1459.067\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:38.398, tt:1497.509\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:38.448, tt:1537.923\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:38.468, tt:1577.194\n",
      "Ep:41, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:38.462, tt:1615.425\n",
      "Ep:42, loss:0.00002, loss_test:0.01577, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:38.472, tt:1654.288\n",
      "Ep:43, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:38.489, tt:1693.535\n",
      "Ep:44, loss:0.00002, loss_test:0.01596, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:38.554, tt:1734.932\n",
      "Ep:45, loss:0.00001, loss_test:0.01602, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:38.570, tt:1774.231\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01609, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:38.545, tt:1811.609\n",
      "Ep:47, loss:0.00001, loss_test:0.01618, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:38.528, tt:1849.341\n",
      "Ep:48, loss:0.00001, loss_test:0.01624, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:38.519, tt:1887.441\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:38.542, tt:1927.094\n",
      "Ep:50, loss:0.00001, loss_test:0.01645, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:38.537, tt:1965.396\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01657, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:38.548, tt:2004.512\n",
      "Ep:52, loss:0.00001, loss_test:0.01659, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:38.543, tt:2042.787\n",
      "Ep:53, loss:0.00001, loss_test:0.01662, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:38.545, tt:2081.415\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01677, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:38.558, tt:2120.672\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01682, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:38.543, tt:2158.414\n",
      "Ep:56, loss:0.00001, loss_test:0.01692, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:38.601, tt:2200.250\n",
      "Ep:57, loss:0.00001, loss_test:0.01707, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:38.590, tt:2238.208\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01712, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:38.610, tt:2278.014\n",
      "Ep:59, loss:0.00001, loss_test:0.01721, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:38.595, tt:2315.720\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01730, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:38.626, tt:2356.197\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01739, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.615, tt:2394.131\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01736, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:38.609, tt:2432.385\n",
      "Ep:63, loss:0.00001, loss_test:0.01748, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:38.611, tt:2471.094\n",
      "Ep:64, loss:0.00001, loss_test:0.01759, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.603, tt:2509.217\n",
      "Ep:65, loss:0.00001, loss_test:0.01769, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.608, tt:2548.133\n",
      "Ep:66, loss:0.00001, loss_test:0.01772, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.615, tt:2587.232\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.624, tt:2626.461\n",
      "Ep:68, loss:0.00001, loss_test:0.01769, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.627, tt:2665.292\n",
      "Ep:69, loss:0.00001, loss_test:0.01780, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.609, tt:2702.654\n",
      "Ep:70, loss:0.00001, loss_test:0.01792, lr:6.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.615, tt:2741.644\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01804, lr:6.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.592, tt:2778.642\n",
      "Ep:72, loss:0.00001, loss_test:0.01811, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.593, tt:2817.259\n",
      "Ep:73, loss:0.00001, loss_test:0.01818, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.635, tt:2858.974\n",
      "Ep:74, loss:0.00001, loss_test:0.01825, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.629, tt:2897.142\n",
      "Ep:75, loss:0.00001, loss_test:0.01824, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.630, tt:2935.865\n",
      "Ep:76, loss:0.00001, loss_test:0.01830, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.622, tt:2973.881\n",
      "Ep:77, loss:0.00001, loss_test:0.01839, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.611, tt:3011.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00001, loss_test:0.01853, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.622, tt:3051.169\n",
      "Ep:79, loss:0.00001, loss_test:0.01854, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.624, tt:3089.940\n",
      "Ep:80, loss:0.00001, loss_test:0.01856, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.624, tt:3128.546\n",
      "Ep:81, loss:0.00001, loss_test:0.01864, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.618, tt:3166.677\n",
      "Ep:82, loss:0.00001, loss_test:0.01874, lr:5.94e-02, fs:0.86598 (r=0.848,p=0.884),  time:38.606, tt:3204.335\n",
      "Ep:83, loss:0.00001, loss_test:0.01877, lr:5.88e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.612, tt:3243.441\n",
      "Ep:84, loss:0.00001, loss_test:0.01885, lr:5.82e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.578, tt:3279.172\n",
      "Ep:85, loss:0.00001, loss_test:0.01893, lr:5.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.569, tt:3316.930\n",
      "Ep:86, loss:0.00001, loss_test:0.01904, lr:5.71e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.591, tt:3357.398\n",
      "Ep:87, loss:0.00001, loss_test:0.01915, lr:5.65e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.592, tt:3396.133\n",
      "Ep:88, loss:0.00001, loss_test:0.01925, lr:5.59e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.561, tt:3431.971\n",
      "Ep:89, loss:0.00001, loss_test:0.01925, lr:5.54e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.532, tt:3467.895\n",
      "Ep:90, loss:0.00001, loss_test:0.01932, lr:5.48e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.510, tt:3504.451\n",
      "Ep:91, loss:0.00001, loss_test:0.01939, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.488, tt:3540.859\n",
      "Ep:92, loss:0.00001, loss_test:0.01939, lr:5.37e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.483, tt:3578.885\n",
      "Ep:93, loss:0.00001, loss_test:0.01954, lr:5.32e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.460, tt:3615.211\n",
      "Ep:94, loss:0.00001, loss_test:0.01961, lr:5.27e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.474, tt:3654.990\n",
      "Ep:95, loss:0.00001, loss_test:0.01971, lr:5.21e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.485, tt:3694.570\n",
      "Ep:96, loss:0.00001, loss_test:0.01972, lr:5.16e-02, fs:0.87047 (r=0.848,p=0.894),  time:38.477, tt:3732.262\n",
      "Ep:97, loss:0.00001, loss_test:0.01981, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.469, tt:3769.924\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01986, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.479, tt:3809.384\n",
      "Ep:99, loss:0.00001, loss_test:0.01994, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.487, tt:3848.707\n",
      "Ep:100, loss:0.00001, loss_test:0.01998, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.477, tt:3886.163\n",
      "Ep:101, loss:0.00001, loss_test:0.02003, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.478, tt:3924.785\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.02011, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.480, tt:3963.484\n",
      "Ep:103, loss:0.00001, loss_test:0.02020, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.491, tt:4003.099\n",
      "Ep:104, loss:0.00001, loss_test:0.02031, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.486, tt:4041.042\n",
      "Ep:105, loss:0.00001, loss_test:0.02040, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.498, tt:4080.818\n",
      "Ep:106, loss:0.00001, loss_test:0.02041, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.492, tt:4118.685\n",
      "Ep:107, loss:0.00001, loss_test:0.02053, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.494, tt:4157.301\n",
      "Ep:108, loss:0.00001, loss_test:0.02065, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.508, tt:4197.342\n",
      "Ep:109, loss:0.00001, loss_test:0.02072, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.517, tt:4236.817\n",
      "Ep:110, loss:0.00000, loss_test:0.02077, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.504, tt:4273.977\n",
      "Ep:111, loss:0.00000, loss_test:0.02086, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.483, tt:4310.085\n",
      "Ep:112, loss:0.00000, loss_test:0.02090, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.489, tt:4349.237\n",
      "Ep:113, loss:0.00000, loss_test:0.02100, lr:5.06e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.479, tt:4386.552\n",
      "Ep:114, loss:0.00000, loss_test:0.02096, lr:5.01e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.470, tt:4424.047\n",
      "Ep:115, loss:0.00000, loss_test:0.02112, lr:4.96e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.485, tt:4464.253\n",
      "Ep:116, loss:0.00000, loss_test:0.02123, lr:4.91e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.490, tt:4503.301\n",
      "Ep:117, loss:0.00000, loss_test:0.02125, lr:4.86e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.505, tt:4543.600\n",
      "Ep:118, loss:0.00000, loss_test:0.02135, lr:4.81e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.516, tt:4583.427\n",
      "Ep:119, loss:0.00000, loss_test:0.02142, lr:4.76e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.513, tt:4621.512\n",
      "Ep:120, loss:0.00000, loss_test:0.02143, lr:4.71e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.517, tt:4660.601\n",
      "Ep:121, loss:0.00000, loss_test:0.02153, lr:4.67e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.523, tt:4699.786\n",
      "Ep:122, loss:0.00000, loss_test:0.02165, lr:4.62e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.530, tt:4739.145\n",
      "Ep:123, loss:0.00000, loss_test:0.02166, lr:4.57e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.539, tt:4778.779\n",
      "Ep:124, loss:0.00000, loss_test:0.02174, lr:4.53e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.548, tt:4818.514\n",
      "Ep:125, loss:0.00000, loss_test:0.02185, lr:4.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.561, tt:4858.729\n",
      "Ep:126, loss:0.00000, loss_test:0.02180, lr:4.44e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.561, tt:4897.212\n",
      "Ep:127, loss:0.00000, loss_test:0.02189, lr:4.39e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.562, tt:4935.952\n",
      "Ep:128, loss:0.00000, loss_test:0.02195, lr:4.35e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.563, tt:4974.588\n",
      "Ep:129, loss:0.00000, loss_test:0.02203, lr:4.31e-02, fs:0.88889 (r=0.848,p=0.933),  time:38.566, tt:5013.620\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00000, loss_test:0.02207, lr:4.31e-02, fs:0.88889 (r=0.848,p=0.933),  time:38.565, tt:5052.014\n",
      "Ep:131, loss:0.00000, loss_test:0.02212, lr:4.31e-02, fs:0.88889 (r=0.848,p=0.933),  time:38.562, tt:5090.236\n",
      "Ep:132, loss:0.00000, loss_test:0.02216, lr:4.31e-02, fs:0.88889 (r=0.848,p=0.933),  time:38.571, tt:5129.996\n",
      "Ep:133, loss:0.00000, loss_test:0.02228, lr:4.31e-02, fs:0.88889 (r=0.848,p=0.933),  time:38.566, tt:5167.804\n",
      "Ep:134, loss:0.00000, loss_test:0.02234, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.553, tt:5204.684\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00000, loss_test:0.02240, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.558, tt:5243.823\n",
      "Ep:136, loss:0.00000, loss_test:0.02254, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.560, tt:5282.680\n",
      "Ep:137, loss:0.00000, loss_test:0.02258, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.560, tt:5321.233\n",
      "Ep:138, loss:0.00000, loss_test:0.02260, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.546, tt:5357.886\n",
      "Ep:139, loss:0.00000, loss_test:0.02268, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.542, tt:5395.882\n",
      "Ep:140, loss:0.00000, loss_test:0.02272, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.538, tt:5433.856\n",
      "Ep:141, loss:0.00000, loss_test:0.02276, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.536, tt:5472.073\n",
      "Ep:142, loss:0.00000, loss_test:0.02285, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.542, tt:5511.472\n",
      "Ep:143, loss:0.00000, loss_test:0.02290, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.541, tt:5549.847\n",
      "Ep:144, loss:0.00000, loss_test:0.02296, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.545, tt:5589.093\n",
      "Ep:145, loss:0.00000, loss_test:0.02299, lr:4.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.554, tt:5628.894\n",
      "Ep:146, loss:0.00000, loss_test:0.02302, lr:4.26e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.551, tt:5666.976\n",
      "Ep:147, loss:0.00000, loss_test:0.02312, lr:4.22e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.552, tt:5705.727\n",
      "Ep:148, loss:0.00000, loss_test:0.02316, lr:4.18e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.558, tt:5745.157\n",
      "Ep:149, loss:0.00000, loss_test:0.02320, lr:4.14e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.567, tt:5785.088\n",
      "Ep:150, loss:0.00000, loss_test:0.02326, lr:4.10e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.578, tt:5825.275\n",
      "Ep:151, loss:0.00000, loss_test:0.02329, lr:4.05e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.581, tt:5864.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.02340, lr:4.01e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.603, tt:5906.319\n",
      "Ep:153, loss:0.00000, loss_test:0.02351, lr:3.97e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.607, tt:5945.550\n",
      "Ep:154, loss:0.00000, loss_test:0.02354, lr:3.93e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.608, tt:5984.315\n",
      "Ep:155, loss:0.00000, loss_test:0.02356, lr:3.89e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.610, tt:6023.108\n",
      "Ep:156, loss:0.00000, loss_test:0.02364, lr:3.86e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.608, tt:6061.528\n",
      "Ep:157, loss:0.00000, loss_test:0.02363, lr:3.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.607, tt:6099.951\n",
      "Ep:158, loss:0.00000, loss_test:0.02376, lr:3.78e-02, fs:0.89362 (r=0.848,p=0.944),  time:38.604, tt:6137.971\n",
      "Ep:159, loss:0.00000, loss_test:0.02374, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.599, tt:6175.785\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00000, loss_test:0.02375, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.600, tt:6214.629\n",
      "Ep:161, loss:0.00000, loss_test:0.02386, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.603, tt:6253.720\n",
      "Ep:162, loss:0.00000, loss_test:0.02390, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.603, tt:6292.307\n",
      "Ep:163, loss:0.00000, loss_test:0.02397, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.609, tt:6331.922\n",
      "Ep:164, loss:0.00000, loss_test:0.02402, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.595, tt:6368.173\n",
      "Ep:165, loss:0.00000, loss_test:0.02406, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.597, tt:6407.088\n",
      "Ep:166, loss:0.00000, loss_test:0.02408, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.591, tt:6444.719\n",
      "Ep:167, loss:0.00000, loss_test:0.02413, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.601, tt:6484.913\n",
      "Ep:168, loss:0.00000, loss_test:0.02419, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.586, tt:6520.978\n",
      "Ep:169, loss:0.00000, loss_test:0.02424, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.584, tt:6559.355\n",
      "Ep:170, loss:0.00000, loss_test:0.02429, lr:3.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.589, tt:6598.635\n",
      "Ep:171, loss:0.00000, loss_test:0.02430, lr:3.70e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.597, tt:6638.702\n",
      "Ep:172, loss:0.00000, loss_test:0.02435, lr:3.67e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.588, tt:6675.712\n",
      "Ep:173, loss:0.00000, loss_test:0.02441, lr:3.63e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.596, tt:6715.636\n",
      "Ep:174, loss:0.00000, loss_test:0.02446, lr:3.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.602, tt:6755.349\n",
      "Ep:175, loss:0.00000, loss_test:0.02451, lr:3.56e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.587, tt:6791.361\n",
      "Ep:176, loss:0.00000, loss_test:0.02459, lr:3.52e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.583, tt:6829.153\n",
      "Ep:177, loss:0.00000, loss_test:0.02465, lr:3.49e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.579, tt:6867.131\n",
      "Ep:178, loss:0.00000, loss_test:0.02466, lr:3.45e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.584, tt:6906.450\n",
      "Ep:179, loss:0.00000, loss_test:0.02473, lr:3.42e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.584, tt:6945.062\n",
      "Ep:180, loss:0.00000, loss_test:0.02474, lr:3.38e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.599, tt:6986.354\n",
      "Ep:181, loss:0.00000, loss_test:0.02476, lr:3.35e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.589, tt:7023.113\n",
      "Ep:182, loss:0.00000, loss_test:0.02482, lr:3.32e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.606, tt:7064.851\n",
      "Ep:183, loss:0.00000, loss_test:0.02488, lr:3.28e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.610, tt:7104.283\n",
      "Ep:184, loss:0.00000, loss_test:0.02490, lr:3.25e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.606, tt:7142.046\n",
      "Ep:185, loss:0.00000, loss_test:0.02497, lr:3.22e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.601, tt:7179.765\n",
      "Ep:186, loss:0.00000, loss_test:0.02504, lr:3.19e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.598, tt:7217.831\n",
      "Ep:187, loss:0.00000, loss_test:0.02504, lr:3.15e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.584, tt:7253.854\n",
      "Ep:188, loss:0.00000, loss_test:0.02506, lr:3.12e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.574, tt:7290.512\n",
      "Ep:189, loss:0.00000, loss_test:0.02513, lr:3.09e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.582, tt:7330.609\n",
      "Ep:190, loss:0.00000, loss_test:0.02516, lr:3.06e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.579, tt:7368.636\n",
      "Ep:191, loss:0.00000, loss_test:0.02518, lr:3.03e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.569, tt:7405.241\n",
      "Ep:192, loss:0.00000, loss_test:0.02523, lr:3.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.569, tt:7443.808\n",
      "Ep:193, loss:0.00000, loss_test:0.02529, lr:2.97e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.566, tt:7481.772\n",
      "Ep:194, loss:0.00000, loss_test:0.02533, lr:2.94e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.557, tt:7518.688\n",
      "Ep:195, loss:0.00000, loss_test:0.02536, lr:2.91e-02, fs:0.89840 (r=0.848,p=0.955),  time:38.546, tt:7555.027\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02122, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:24.448, tt:24.448\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02609, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.032, tt:58.063\n",
      "Ep:2, loss:0.00005, loss_test:0.02925, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.910, tt:92.728\n",
      "Ep:3, loss:0.00006, loss_test:0.03014, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.551, tt:126.203\n",
      "Ep:4, loss:0.00006, loss_test:0.02992, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.429, tt:162.147\n",
      "Ep:5, loss:0.00006, loss_test:0.02884, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.925, tt:197.550\n",
      "Ep:6, loss:0.00006, loss_test:0.02740, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:33.331, tt:233.316\n",
      "Ep:7, loss:0.00005, loss_test:0.02562, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:33.529, tt:268.235\n",
      "Ep:8, loss:0.00005, loss_test:0.02390, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:33.764, tt:303.879\n",
      "Ep:9, loss:0.00005, loss_test:0.02283, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:34.049, tt:340.494\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00005, loss_test:0.02246, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:34.140, tt:375.541\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00005, loss_test:0.02222, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:34.231, tt:410.770\n",
      "Ep:12, loss:0.00004, loss_test:0.02196, lr:6.00e-02, fs:0.66667 (r=0.879,p=0.537),  time:34.433, tt:447.633\n",
      "Ep:13, loss:0.00004, loss_test:0.02176, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:34.533, tt:483.463\n",
      "Ep:14, loss:0.00004, loss_test:0.02143, lr:6.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:34.667, tt:520.011\n",
      "Ep:15, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:34.703, tt:555.254\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02082, lr:6.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:34.753, tt:590.805\n",
      "Ep:17, loss:0.00004, loss_test:0.02064, lr:6.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:34.825, tt:626.844\n",
      "Ep:18, loss:0.00004, loss_test:0.02039, lr:6.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:34.803, tt:661.263\n",
      "Ep:19, loss:0.00004, loss_test:0.02010, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:34.800, tt:696.006\n",
      "Ep:20, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.749, tt:729.731\n",
      "Ep:21, loss:0.00004, loss_test:0.01953, lr:6.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:34.737, tt:764.219\n",
      "Ep:22, loss:0.00003, loss_test:0.01927, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:34.810, tt:800.623\n",
      "Ep:23, loss:0.00003, loss_test:0.01906, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:34.815, tt:835.550\n",
      "Ep:24, loss:0.00003, loss_test:0.01881, lr:6.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:34.803, tt:870.085\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00003, loss_test:0.01859, lr:6.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:34.803, tt:904.875\n",
      "Ep:26, loss:0.00003, loss_test:0.01847, lr:6.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:34.837, tt:940.598\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01834, lr:6.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:34.845, tt:975.672\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01819, lr:6.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:34.824, tt:1009.884\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01796, lr:6.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:34.879, tt:1046.365\n",
      "Ep:30, loss:0.00003, loss_test:0.01777, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:34.837, tt:1079.960\n",
      "Ep:31, loss:0.00003, loss_test:0.01756, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:34.797, tt:1113.491\n",
      "Ep:32, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:34.783, tt:1147.838\n",
      "Ep:33, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:34.744, tt:1181.304\n",
      "Ep:34, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:34.697, tt:1214.383\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01719, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:34.663, tt:1247.862\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01704, lr:6.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.655, tt:1282.251\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01691, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:34.671, tt:1317.507\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01693, lr:6.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:34.670, tt:1352.149\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01705, lr:6.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:34.681, tt:1387.229\n",
      "Ep:40, loss:0.00002, loss_test:0.01691, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:34.694, tt:1422.456\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01672, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:34.685, tt:1456.790\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01671, lr:6.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:34.700, tt:1492.104\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01675, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:34.692, tt:1526.438\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01661, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:34.695, tt:1561.291\n",
      "Ep:45, loss:0.00002, loss_test:0.01651, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:34.722, tt:1597.226\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01644, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:34.724, tt:1632.041\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01652, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:34.785, tt:1669.682\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01636, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:34.809, tt:1705.628\n",
      "Ep:49, loss:0.00002, loss_test:0.01640, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:34.800, tt:1740.006\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01642, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:34.783, tt:1773.939\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01633, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:34.818, tt:1810.520\n",
      "Ep:52, loss:0.00002, loss_test:0.01637, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:34.832, tt:1846.099\n",
      "Ep:53, loss:0.00002, loss_test:0.01632, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:34.877, tt:1883.378\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01625, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:34.898, tt:1919.366\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.912, tt:1955.089\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01602, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.911, tt:1989.938\n",
      "Ep:57, loss:0.00001, loss_test:0.01607, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.938, tt:2026.394\n",
      "Ep:58, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.941, tt:2061.509\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01628, lr:6.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.951, tt:2097.042\n",
      "Ep:60, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.933, tt:2130.922\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01646, lr:6.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:34.949, tt:2166.866\n",
      "Ep:62, loss:0.00001, loss_test:0.01674, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.947, tt:2201.659\n",
      "Ep:63, loss:0.00001, loss_test:0.01665, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.957, tt:2237.258\n",
      "Ep:64, loss:0.00001, loss_test:0.01672, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.974, tt:2273.333\n",
      "Ep:65, loss:0.00001, loss_test:0.01696, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.993, tt:2309.543\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01706, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.999, tt:2344.928\n",
      "Ep:67, loss:0.00001, loss_test:0.01707, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.003, tt:2380.224\n",
      "Ep:68, loss:0.00001, loss_test:0.01723, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.016, tt:2416.083\n",
      "Ep:69, loss:0.00001, loss_test:0.01733, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.032, tt:2452.209\n",
      "Ep:70, loss:0.00001, loss_test:0.01728, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.038, tt:2487.716\n",
      "Ep:71, loss:0.00001, loss_test:0.01731, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.052, tt:2523.762\n",
      "Ep:72, loss:0.00001, loss_test:0.01748, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.067, tt:2559.912\n",
      "Ep:73, loss:0.00001, loss_test:0.01759, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.064, tt:2594.728\n",
      "Ep:74, loss:0.00001, loss_test:0.01748, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.069, tt:2630.144\n",
      "Ep:75, loss:0.00001, loss_test:0.01787, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.078, tt:2665.907\n",
      "Ep:76, loss:0.00001, loss_test:0.01790, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.077, tt:2700.892\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01797, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.086, tt:2736.746\n",
      "Ep:78, loss:0.00001, loss_test:0.01802, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.092, tt:2772.273\n",
      "Ep:79, loss:0.00001, loss_test:0.01821, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:35.093, tt:2807.403\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01821, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:35.096, tt:2842.796\n",
      "Ep:81, loss:0.00001, loss_test:0.01855, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.065, tt:2875.319\n",
      "Ep:82, loss:0.00001, loss_test:0.01841, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.056, tt:2909.671\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01864, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.042, tt:2943.511\n",
      "Ep:84, loss:0.00001, loss_test:0.01884, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.049, tt:2979.123\n",
      "Ep:85, loss:0.00001, loss_test:0.01895, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.063, tt:3015.457\n",
      "Ep:86, loss:0.00001, loss_test:0.01901, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.059, tt:3050.175\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01927, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.068, tt:3085.955\n",
      "Ep:88, loss:0.00001, loss_test:0.01926, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.064, tt:3120.686\n",
      "Ep:89, loss:0.00001, loss_test:0.01953, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.073, tt:3156.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.01951, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.067, tt:3191.087\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01981, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.065, tt:3225.957\n",
      "Ep:92, loss:0.00001, loss_test:0.02017, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.076, tt:3262.108\n",
      "Ep:93, loss:0.00001, loss_test:0.02014, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.080, tt:3297.499\n",
      "Ep:94, loss:0.00001, loss_test:0.02007, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.073, tt:3331.959\n",
      "Ep:95, loss:0.00001, loss_test:0.02045, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.087, tt:3368.341\n",
      "Ep:96, loss:0.00001, loss_test:0.02063, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.090, tt:3403.733\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.02070, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.112, tt:3441.012\n",
      "Ep:98, loss:0.00001, loss_test:0.02092, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.128, tt:3477.718\n",
      "Ep:99, loss:0.00001, loss_test:0.02106, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.139, tt:3513.864\n",
      "Ep:100, loss:0.00001, loss_test:0.02127, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.151, tt:3550.287\n",
      "Ep:101, loss:0.00001, loss_test:0.02128, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.167, tt:3587.029\n",
      "Ep:102, loss:0.00000, loss_test:0.02143, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.168, tt:3622.287\n",
      "Ep:103, loss:0.00000, loss_test:0.02155, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.165, tt:3657.142\n",
      "Ep:104, loss:0.00000, loss_test:0.02144, lr:6.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.152, tt:3690.944\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.02239, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.158, tt:3726.719\n",
      "Ep:106, loss:0.00000, loss_test:0.02148, lr:6.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.157, tt:3761.808\n",
      "Ep:107, loss:0.00000, loss_test:0.02237, lr:6.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.159, tt:3797.147\n",
      "Ep:108, loss:0.00000, loss_test:0.02232, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.176, tt:3834.178\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.02252, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.195, tt:3871.413\n",
      "Ep:110, loss:0.00000, loss_test:0.02295, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.203, tt:3907.499\n",
      "Ep:111, loss:0.00000, loss_test:0.02290, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.203, tt:3942.721\n",
      "Ep:112, loss:0.00000, loss_test:0.02325, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.211, tt:3978.844\n",
      "Ep:113, loss:0.00000, loss_test:0.02308, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.214, tt:4014.437\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00000, loss_test:0.02357, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.224, tt:4050.768\n",
      "Ep:115, loss:0.00000, loss_test:0.02395, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.244, tt:4088.335\n",
      "Ep:116, loss:0.00000, loss_test:0.02385, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.249, tt:4124.077\n",
      "Ep:117, loss:0.00000, loss_test:0.02431, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.248, tt:4159.271\n",
      "Ep:118, loss:0.00000, loss_test:0.02444, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.260, tt:4195.954\n",
      "Ep:119, loss:0.00000, loss_test:0.02431, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.272, tt:4232.590\n",
      "Ep:120, loss:0.00000, loss_test:0.02493, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.272, tt:4267.894\n",
      "Ep:121, loss:0.00000, loss_test:0.02456, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.271, tt:4303.113\n",
      "Ep:122, loss:0.00000, loss_test:0.02517, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.276, tt:4338.960\n",
      "Ep:123, loss:0.00000, loss_test:0.02560, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.270, tt:4373.510\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00000, loss_test:0.02517, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.286, tt:4410.747\n",
      "Ep:125, loss:0.00000, loss_test:0.02626, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.287, tt:4446.209\n",
      "Ep:126, loss:0.00000, loss_test:0.02596, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.289, tt:4481.662\n",
      "Ep:127, loss:0.00000, loss_test:0.02590, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.296, tt:4517.885\n",
      "Ep:128, loss:0.00000, loss_test:0.02645, lr:6.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.301, tt:4553.835\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00000, loss_test:0.02644, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.298, tt:4588.737\n",
      "Ep:130, loss:0.00000, loss_test:0.02661, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.296, tt:4623.713\n",
      "Ep:131, loss:0.00000, loss_test:0.02740, lr:6.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.297, tt:4659.183\n",
      "Ep:132, loss:0.00000, loss_test:0.02693, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.293, tt:4693.978\n",
      "Ep:133, loss:0.00000, loss_test:0.02742, lr:6.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.297, tt:4729.741\n",
      "Ep:134, loss:0.00000, loss_test:0.02788, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.293, tt:4764.567\n",
      "Ep:135, loss:0.00000, loss_test:0.02691, lr:6.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.302, tt:4801.126\n",
      "Ep:136, loss:0.00000, loss_test:0.02868, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.301, tt:4836.173\n",
      "Ep:137, loss:0.00000, loss_test:0.02793, lr:6.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.288, tt:4869.755\n",
      "Ep:138, loss:0.00000, loss_test:0.02812, lr:6.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.283, tt:4904.341\n",
      "Ep:139, loss:0.00000, loss_test:0.02881, lr:6.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.274, tt:4938.406\n",
      "Ep:140, loss:0.00000, loss_test:0.02871, lr:5.94e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.277, tt:4974.044\n",
      "Ep:141, loss:0.00000, loss_test:0.02923, lr:5.88e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.270, tt:5008.339\n",
      "Ep:142, loss:0.00000, loss_test:0.02965, lr:5.82e-02, fs:0.88770 (r=0.838,p=0.943),  time:35.264, tt:5042.818\n",
      "Ep:143, loss:0.00000, loss_test:0.02923, lr:5.76e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.259, tt:5077.268\n",
      "Ep:144, loss:0.00000, loss_test:0.02988, lr:5.71e-02, fs:0.88770 (r=0.838,p=0.943),  time:35.253, tt:5111.634\n",
      "Ep:145, loss:0.00000, loss_test:0.02997, lr:5.65e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.256, tt:5147.334\n",
      "Ep:146, loss:0.00000, loss_test:0.02981, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.248, tt:5181.385\n",
      "Ep:147, loss:0.00000, loss_test:0.03091, lr:5.54e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.246, tt:5216.384\n",
      "Ep:148, loss:0.00000, loss_test:0.03006, lr:5.48e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.236, tt:5250.168\n",
      "Ep:149, loss:0.00000, loss_test:0.03082, lr:5.43e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.241, tt:5286.093\n",
      "Ep:150, loss:0.00000, loss_test:0.03088, lr:5.37e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.234, tt:5320.270\n",
      "Ep:151, loss:0.00000, loss_test:0.03060, lr:5.32e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.233, tt:5355.374\n",
      "Ep:152, loss:0.00000, loss_test:0.03171, lr:5.27e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.209, tt:5387.052\n",
      "Ep:153, loss:0.00000, loss_test:0.03094, lr:5.21e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.203, tt:5421.198\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00000, loss_test:0.03170, lr:5.21e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.199, tt:5455.771\n",
      "Ep:155, loss:0.00000, loss_test:0.03184, lr:5.21e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.193, tt:5490.118\n",
      "Ep:156, loss:0.00000, loss_test:0.03158, lr:5.21e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.179, tt:5523.097\n",
      "Ep:157, loss:0.00000, loss_test:0.03232, lr:5.21e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.170, tt:5556.883\n",
      "Ep:158, loss:0.00000, loss_test:0.03196, lr:5.21e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.157, tt:5589.953\n",
      "Ep:159, loss:0.00000, loss_test:0.03256, lr:5.21e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.152, tt:5624.380\n",
      "Ep:160, loss:0.00000, loss_test:0.03279, lr:5.21e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.143, tt:5657.986\n",
      "Ep:161, loss:0.00000, loss_test:0.03258, lr:5.21e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.143, tt:5693.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:162, loss:0.00000, loss_test:0.03315, lr:5.21e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.133, tt:5726.738\n",
      "Ep:163, loss:0.00000, loss_test:0.03320, lr:5.21e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.120, tt:5759.709\n",
      "Ep:164, loss:0.00000, loss_test:0.03321, lr:5.21e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.108, tt:5792.830\n",
      "Ep:165, loss:0.00000, loss_test:0.03358, lr:5.16e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.100, tt:5826.634\n",
      "Ep:166, loss:0.00000, loss_test:0.03352, lr:5.11e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.098, tt:5861.302\n",
      "Ep:167, loss:0.00000, loss_test:0.03413, lr:5.06e-02, fs:0.90323 (r=0.848,p=0.966),  time:35.089, tt:5894.889\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00000, loss_test:0.03375, lr:5.06e-02, fs:0.88525 (r=0.818,p=0.964),  time:35.092, tt:5930.603\n",
      "Ep:169, loss:0.00000, loss_test:0.03424, lr:5.06e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.088, tt:5964.989\n",
      "Ep:170, loss:0.00000, loss_test:0.03426, lr:5.06e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.075, tt:5997.828\n",
      "Ep:171, loss:0.00000, loss_test:0.03450, lr:5.06e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.067, tt:6031.490\n",
      "Ep:172, loss:0.00000, loss_test:0.03460, lr:5.06e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.058, tt:6065.105\n",
      "Ep:173, loss:0.00000, loss_test:0.03489, lr:5.06e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.050, tt:6098.613\n",
      "Ep:174, loss:0.00000, loss_test:0.03468, lr:5.06e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.035, tt:6131.049\n",
      "Ep:175, loss:0.00000, loss_test:0.03485, lr:5.06e-02, fs:0.88525 (r=0.818,p=0.964),  time:35.030, tt:6165.267\n",
      "Ep:176, loss:0.00000, loss_test:0.03540, lr:5.06e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.022, tt:6198.886\n",
      "Ep:177, loss:0.00000, loss_test:0.03499, lr:5.06e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.018, tt:6233.157\n",
      "Ep:178, loss:0.00000, loss_test:0.03557, lr:5.06e-02, fs:0.89130 (r=0.828,p=0.965),  time:35.018, tt:6268.184\n",
      "Ep:179, loss:0.00000, loss_test:0.03565, lr:5.01e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.010, tt:6301.732\n",
      "Ep:180, loss:0.00000, loss_test:0.03534, lr:4.96e-02, fs:0.87912 (r=0.808,p=0.964),  time:35.011, tt:6336.964\n",
      "Ep:181, loss:0.00000, loss_test:0.03612, lr:4.91e-02, fs:0.89730 (r=0.838,p=0.965),  time:35.001, tt:6370.212\n",
      "Ep:182, loss:0.00000, loss_test:0.03575, lr:4.86e-02, fs:0.87912 (r=0.808,p=0.964),  time:35.000, tt:6404.939\n",
      "Ep:183, loss:0.00000, loss_test:0.03599, lr:4.81e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.997, tt:6439.390\n",
      "Ep:184, loss:0.00000, loss_test:0.03640, lr:4.76e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.981, tt:6471.398\n",
      "Ep:185, loss:0.00000, loss_test:0.03655, lr:4.71e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.973, tt:6504.930\n",
      "Ep:186, loss:0.00000, loss_test:0.03599, lr:4.67e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.971, tt:6539.484\n",
      "Ep:187, loss:0.00000, loss_test:0.03682, lr:4.62e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.964, tt:6573.205\n",
      "Ep:188, loss:0.00000, loss_test:0.03661, lr:4.57e-02, fs:0.87912 (r=0.808,p=0.964),  time:34.999, tt:6614.748\n",
      "Ep:189, loss:0.00000, loss_test:0.03679, lr:4.53e-02, fs:0.88525 (r=0.818,p=0.964),  time:35.000, tt:6650.022\n",
      "Ep:190, loss:0.00000, loss_test:0.03726, lr:4.48e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.993, tt:6683.588\n",
      "Ep:191, loss:0.00000, loss_test:0.03679, lr:4.44e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.988, tt:6717.690\n",
      "Ep:192, loss:0.00000, loss_test:0.03703, lr:4.39e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.984, tt:6751.933\n",
      "Ep:193, loss:0.00000, loss_test:0.03721, lr:4.35e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.970, tt:6784.224\n",
      "Ep:194, loss:0.00000, loss_test:0.03754, lr:4.31e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.969, tt:6818.911\n",
      "Ep:195, loss:0.00000, loss_test:0.03763, lr:4.26e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.930, tt:6846.195\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"2-2\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14613, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.081, tt:42.081\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14555, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.374, tt:86.747\n",
      "Ep:2, loss:0.00028, loss_test:0.14450, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.160, tt:138.479\n",
      "Ep:3, loss:0.00028, loss_test:0.14281, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.472, tt:189.889\n",
      "Ep:4, loss:0.00027, loss_test:0.13996, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.260, tt:241.300\n",
      "Ep:5, loss:0.00026, loss_test:0.13471, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:48.544, tt:291.266\n",
      "Ep:6, loss:0.00024, loss_test:0.12465, lr:1.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:48.869, tt:342.086\n",
      "Ep:7, loss:0.00022, loss_test:0.12047, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:49.473, tt:395.780\n",
      "Ep:8, loss:0.00021, loss_test:0.11596, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:49.812, tt:448.308\n",
      "Ep:9, loss:0.00020, loss_test:0.11449, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:50.206, tt:502.056\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11378, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:50.644, tt:557.080\n",
      "Ep:11, loss:0.00019, loss_test:0.11366, lr:1.00e-02, fs:0.63810 (r=0.677,p=0.604),  time:51.059, tt:612.706\n",
      "Ep:12, loss:0.00019, loss_test:0.10990, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:51.062, tt:663.802\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10924, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:51.117, tt:715.642\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10931, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:51.154, tt:767.304\n",
      "Ep:15, loss:0.00017, loss_test:0.10845, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:51.261, tt:820.180\n",
      "Ep:16, loss:0.00016, loss_test:0.10550, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:51.332, tt:872.636\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.10466, lr:1.00e-02, fs:0.68868 (r=0.737,p=0.646),  time:51.450, tt:926.097\n",
      "Ep:18, loss:0.00016, loss_test:0.10503, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:51.549, tt:979.437\n",
      "Ep:19, loss:0.00015, loss_test:0.10162, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:51.441, tt:1028.829\n",
      "Ep:20, loss:0.00015, loss_test:0.10200, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:51.484, tt:1081.173\n",
      "Ep:21, loss:0.00014, loss_test:0.10070, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:51.513, tt:1133.275\n",
      "Ep:22, loss:0.00014, loss_test:0.09866, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:51.539, tt:1185.391\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09858, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:51.476, tt:1235.420\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.09725, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:51.463, tt:1286.565\n",
      "Ep:25, loss:0.00013, loss_test:0.09519, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:51.515, tt:1339.399\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.09512, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:51.491, tt:1390.266\n",
      "Ep:27, loss:0.00012, loss_test:0.09255, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:51.468, tt:1441.117\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.09498, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:51.447, tt:1491.960\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.09030, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:51.444, tt:1543.329\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.09181, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:51.571, tt:1598.690\n",
      "Ep:31, loss:0.00010, loss_test:0.09339, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:51.645, tt:1652.653\n",
      "Ep:32, loss:0.00010, loss_test:0.08928, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:51.652, tt:1704.510\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.09188, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:51.617, tt:1754.981\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.09171, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:51.592, tt:1805.717\n",
      "Ep:35, loss:0.00009, loss_test:0.08679, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:51.580, tt:1856.880\n",
      "Ep:36, loss:0.00009, loss_test:0.08792, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:51.589, tt:1908.801\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.08991, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:51.590, tt:1960.424\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.08585, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:51.571, tt:2011.263\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.09671, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:51.587, tt:2063.495\n",
      "Ep:40, loss:0.00008, loss_test:0.08715, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:51.592, tt:2115.284\n",
      "Ep:41, loss:0.00007, loss_test:0.08684, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:51.577, tt:2166.246\n",
      "Ep:42, loss:0.00007, loss_test:0.09381, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:51.629, tt:2220.026\n",
      "Ep:43, loss:0.00007, loss_test:0.08379, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:51.608, tt:2270.765\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.08932, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:51.603, tt:2322.124\n",
      "Ep:45, loss:0.00006, loss_test:0.09488, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:51.644, tt:2375.627\n",
      "Ep:46, loss:0.00006, loss_test:0.09455, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:51.640, tt:2427.066\n",
      "Ep:47, loss:0.00006, loss_test:0.08259, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:51.621, tt:2477.824\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.09308, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:51.618, tt:2529.291\n",
      "Ep:49, loss:0.00006, loss_test:0.09657, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:51.585, tt:2579.240\n",
      "Ep:50, loss:0.00005, loss_test:0.08744, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:51.584, tt:2630.800\n",
      "Ep:51, loss:0.00005, loss_test:0.08855, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:51.581, tt:2682.213\n",
      "Ep:52, loss:0.00005, loss_test:0.09282, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:51.587, tt:2734.102\n",
      "Ep:53, loss:0.00004, loss_test:0.08334, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:51.606, tt:2786.751\n",
      "Ep:54, loss:0.00005, loss_test:0.09071, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:51.571, tt:2836.426\n",
      "Ep:55, loss:0.00004, loss_test:0.09542, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:51.595, tt:2889.341\n",
      "Ep:56, loss:0.00004, loss_test:0.08828, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:51.574, tt:2939.713\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.08384, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:51.588, tt:2992.110\n",
      "Ep:58, loss:0.00004, loss_test:0.08997, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:51.619, tt:3045.507\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00004, loss_test:0.08681, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:51.606, tt:3096.366\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.08834, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:51.610, tt:3148.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.08297, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:51.623, tt:3200.629\n",
      "Ep:62, loss:0.00003, loss_test:0.09044, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:51.634, tt:3252.944\n",
      "Ep:63, loss:0.00003, loss_test:0.10204, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:51.655, tt:3305.900\n",
      "Ep:64, loss:0.00003, loss_test:0.08231, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:51.652, tt:3357.352\n",
      "Ep:65, loss:0.00003, loss_test:0.10054, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:51.628, tt:3407.460\n",
      "Ep:66, loss:0.00003, loss_test:0.09303, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:51.632, tt:3459.323\n",
      "Ep:67, loss:0.00003, loss_test:0.08886, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:51.640, tt:3511.487\n",
      "Ep:68, loss:0.00003, loss_test:0.09656, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:51.643, tt:3563.395\n",
      "Ep:69, loss:0.00003, loss_test:0.08538, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:51.668, tt:3616.730\n",
      "Ep:70, loss:0.00003, loss_test:0.09333, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:51.661, tt:3667.954\n",
      "Ep:71, loss:0.00003, loss_test:0.09491, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:51.697, tt:3722.161\n",
      "Ep:72, loss:0.00002, loss_test:0.08728, lr:9.80e-03, fs:0.81564 (r=0.737,p=0.912),  time:51.689, tt:3773.290\n",
      "Ep:73, loss:0.00002, loss_test:0.09402, lr:9.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:51.699, tt:3825.730\n",
      "Ep:74, loss:0.00002, loss_test:0.08641, lr:9.61e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.699, tt:3877.454\n",
      "Ep:75, loss:0.00002, loss_test:0.09212, lr:9.51e-03, fs:0.72956 (r=0.586,p=0.967),  time:51.724, tt:3930.992\n",
      "Ep:76, loss:0.00002, loss_test:0.09261, lr:9.41e-03, fs:0.79310 (r=0.697,p=0.920),  time:51.738, tt:3983.819\n",
      "Ep:77, loss:0.00002, loss_test:0.09297, lr:9.32e-03, fs:0.79290 (r=0.677,p=0.957),  time:51.730, tt:4034.971\n",
      "Ep:78, loss:0.00002, loss_test:0.08569, lr:9.23e-03, fs:0.82022 (r=0.737,p=0.924),  time:51.722, tt:4086.058\n",
      "Ep:79, loss:0.00002, loss_test:0.10101, lr:9.14e-03, fs:0.72050 (r=0.586,p=0.935),  time:51.727, tt:4138.141\n",
      "Ep:80, loss:0.00002, loss_test:0.08581, lr:9.04e-03, fs:0.82955 (r=0.737,p=0.948),  time:51.746, tt:4191.404\n",
      "Ep:81, loss:0.00002, loss_test:0.09822, lr:8.95e-03, fs:0.75904 (r=0.636,p=0.940),  time:51.756, tt:4243.966\n",
      "Ep:82, loss:0.00002, loss_test:0.08755, lr:8.86e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.758, tt:4295.931\n",
      "Ep:83, loss:0.00002, loss_test:0.09148, lr:8.78e-03, fs:0.74074 (r=0.606,p=0.952),  time:51.754, tt:4347.368\n",
      "Ep:84, loss:0.00001, loss_test:0.08810, lr:8.69e-03, fs:0.81564 (r=0.737,p=0.912),  time:51.760, tt:4399.607\n",
      "Ep:85, loss:0.00001, loss_test:0.09542, lr:8.60e-03, fs:0.73292 (r=0.596,p=0.952),  time:51.759, tt:4451.255\n",
      "Ep:86, loss:0.00001, loss_test:0.08856, lr:8.51e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.761, tt:4503.201\n",
      "Ep:87, loss:0.00001, loss_test:0.08910, lr:8.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.745, tt:4553.590\n",
      "Ep:88, loss:0.00001, loss_test:0.09193, lr:8.35e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.763, tt:4606.948\n",
      "Ep:89, loss:0.00001, loss_test:0.08257, lr:8.26e-03, fs:0.82486 (r=0.737,p=0.936),  time:51.771, tt:4659.420\n",
      "Ep:90, loss:0.00001, loss_test:0.08998, lr:8.18e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.761, tt:4710.244\n",
      "Ep:91, loss:0.00001, loss_test:0.08428, lr:8.10e-03, fs:0.82955 (r=0.737,p=0.948),  time:51.767, tt:4762.582\n",
      "Ep:92, loss:0.00001, loss_test:0.08879, lr:8.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.776, tt:4815.187\n",
      "Ep:93, loss:0.00001, loss_test:0.08670, lr:7.94e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.781, tt:4867.374\n",
      "Ep:94, loss:0.00001, loss_test:0.08735, lr:7.86e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.772, tt:4918.376\n",
      "Ep:95, loss:0.00001, loss_test:0.08593, lr:7.78e-03, fs:0.82081 (r=0.717,p=0.959),  time:51.786, tt:4971.444\n",
      "Ep:96, loss:0.00001, loss_test:0.09202, lr:7.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.775, tt:5022.219\n",
      "Ep:97, loss:0.00001, loss_test:0.08742, lr:7.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.797, tt:5076.077\n",
      "Ep:98, loss:0.00001, loss_test:0.09126, lr:7.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:51.806, tt:5128.766\n",
      "Ep:99, loss:0.00001, loss_test:0.08786, lr:7.47e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.800, tt:5180.026\n",
      "Ep:100, loss:0.00001, loss_test:0.08857, lr:7.40e-03, fs:0.80233 (r=0.697,p=0.945),  time:51.791, tt:5230.873\n",
      "Ep:101, loss:0.00001, loss_test:0.08624, lr:7.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.792, tt:5282.817\n",
      "Ep:102, loss:0.00001, loss_test:0.09218, lr:7.25e-03, fs:0.81176 (r=0.697,p=0.972),  time:51.803, tt:5335.670\n",
      "Ep:103, loss:0.00001, loss_test:0.08853, lr:7.18e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.837, tt:5391.043\n",
      "Ep:104, loss:0.00001, loss_test:0.08732, lr:7.11e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.837, tt:5442.875\n",
      "Ep:105, loss:0.00000, loss_test:0.09049, lr:7.03e-03, fs:0.81176 (r=0.697,p=0.972),  time:51.828, tt:5493.810\n",
      "Ep:106, loss:0.00000, loss_test:0.08696, lr:6.96e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.833, tt:5546.162\n",
      "Ep:107, loss:0.00000, loss_test:0.09120, lr:6.89e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.842, tt:5598.901\n",
      "Ep:108, loss:0.00000, loss_test:0.08732, lr:6.83e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.868, tt:5653.634\n",
      "Ep:109, loss:0.00000, loss_test:0.08960, lr:6.76e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.865, tt:5705.158\n",
      "Ep:110, loss:0.00000, loss_test:0.08956, lr:6.69e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.870, tt:5757.540\n",
      "Ep:111, loss:0.00000, loss_test:0.08760, lr:6.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.880, tt:5810.554\n",
      "Ep:112, loss:0.00000, loss_test:0.08955, lr:6.56e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.877, tt:5862.105\n",
      "Ep:113, loss:0.00000, loss_test:0.08897, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.865, tt:5912.606\n",
      "Ep:114, loss:0.00000, loss_test:0.08857, lr:6.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.868, tt:5964.860\n",
      "Ep:115, loss:0.00000, loss_test:0.09007, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.870, tt:6016.872\n",
      "Ep:116, loss:0.00000, loss_test:0.08899, lr:6.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.881, tt:6070.107\n",
      "Ep:117, loss:0.00000, loss_test:0.08788, lr:6.24e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.875, tt:6121.286\n",
      "Ep:118, loss:0.00000, loss_test:0.08751, lr:6.17e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.875, tt:6173.069\n",
      "Ep:119, loss:0.00000, loss_test:0.08850, lr:6.11e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.877, tt:6225.243\n",
      "Ep:120, loss:0.00000, loss_test:0.08843, lr:6.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.876, tt:6276.991\n",
      "Ep:121, loss:0.00000, loss_test:0.08876, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.895, tt:6331.247\n",
      "Ep:122, loss:0.00000, loss_test:0.09066, lr:5.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.882, tt:6381.516\n",
      "Ep:123, loss:0.00000, loss_test:0.08989, lr:5.87e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.875, tt:6432.454\n",
      "Ep:124, loss:0.00000, loss_test:0.08627, lr:5.81e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.874, tt:6484.277\n",
      "Ep:125, loss:0.00000, loss_test:0.08769, lr:5.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.860, tt:6534.334\n",
      "Ep:126, loss:0.00000, loss_test:0.08842, lr:5.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.851, tt:6585.047\n",
      "Ep:127, loss:0.00000, loss_test:0.08791, lr:5.64e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.860, tt:6638.028\n",
      "Ep:128, loss:0.00000, loss_test:0.08867, lr:5.58e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.860, tt:6689.885\n",
      "Ep:129, loss:0.00000, loss_test:0.08647, lr:5.53e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.897, tt:6746.633\n",
      "Ep:130, loss:0.00000, loss_test:0.08808, lr:5.47e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.923, tt:6801.970\n",
      "Ep:131, loss:0.00000, loss_test:0.08709, lr:5.42e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.953, tt:6857.781\n",
      "Ep:132, loss:0.00000, loss_test:0.08800, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.973, tt:6912.379\n",
      "Ep:133, loss:0.00000, loss_test:0.08921, lr:5.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.978, tt:6965.070\n",
      "Ep:134, loss:0.00000, loss_test:0.09020, lr:5.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.003, tt:7020.350\n",
      "Ep:135, loss:0.00000, loss_test:0.08762, lr:5.20e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.014, tt:7073.837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.08932, lr:5.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.032, tt:7128.427\n",
      "Ep:137, loss:0.00000, loss_test:0.08821, lr:5.10e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.051, tt:7183.078\n",
      "Ep:138, loss:0.00000, loss_test:0.09023, lr:5.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.071, tt:7237.905\n",
      "Ep:139, loss:0.00000, loss_test:0.08932, lr:5.00e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.075, tt:7290.432\n",
      "Ep:140, loss:0.00000, loss_test:0.08836, lr:4.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.097, tt:7345.629\n",
      "Ep:141, loss:0.00000, loss_test:0.08949, lr:4.90e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.096, tt:7397.686\n",
      "Ep:142, loss:0.00000, loss_test:0.08754, lr:4.85e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.100, tt:7450.362\n",
      "Ep:143, loss:0.00000, loss_test:0.09066, lr:4.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.123, tt:7505.778\n",
      "Ep:144, loss:0.00000, loss_test:0.09052, lr:4.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.129, tt:7558.699\n",
      "Ep:145, loss:0.00000, loss_test:0.08747, lr:4.71e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.141, tt:7612.594\n",
      "Ep:146, loss:0.00000, loss_test:0.08956, lr:4.66e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.144, tt:7665.113\n",
      "Ep:147, loss:0.00000, loss_test:0.08983, lr:4.61e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.140, tt:7716.664\n",
      "Ep:148, loss:0.00000, loss_test:0.08846, lr:4.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.136, tt:7768.271\n",
      "Ep:149, loss:0.00000, loss_test:0.08818, lr:4.52e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.143, tt:7821.507\n",
      "Ep:150, loss:0.00000, loss_test:0.08518, lr:4.48e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.138, tt:7872.898\n",
      "Ep:151, loss:0.00000, loss_test:0.08804, lr:4.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.144, tt:7925.850\n",
      "Ep:152, loss:0.00000, loss_test:0.08887, lr:4.39e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.147, tt:7978.529\n",
      "Ep:153, loss:0.00000, loss_test:0.08711, lr:4.34e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.165, tt:8033.458\n",
      "Ep:154, loss:0.00000, loss_test:0.08847, lr:4.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.166, tt:8085.798\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14341, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.785, tt:49.785\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14236, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.360, tt:92.720\n",
      "Ep:2, loss:0.00028, loss_test:0.14054, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.817, tt:143.452\n",
      "Ep:3, loss:0.00028, loss_test:0.13762, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.944, tt:195.777\n",
      "Ep:4, loss:0.00027, loss_test:0.13250, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:50.036, tt:250.180\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12285, lr:1.00e-02, fs:0.68531 (r=0.990,p=0.524),  time:50.626, tt:303.759\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10794, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:50.932, tt:356.522\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10344, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:51.087, tt:408.698\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10181, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:51.286, tt:461.576\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10107, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:51.729, tt:517.293\n",
      "Ep:10, loss:0.00020, loss_test:0.09686, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:51.994, tt:571.936\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09484, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:52.010, tt:624.125\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09513, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:52.060, tt:676.778\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09167, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:52.234, tt:731.280\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08945, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:52.332, tt:784.983\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09095, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:52.470, tt:839.514\n",
      "Ep:16, loss:0.00016, loss_test:0.08831, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:52.511, tt:892.681\n",
      "Ep:17, loss:0.00016, loss_test:0.08749, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:52.543, tt:945.776\n",
      "Ep:18, loss:0.00015, loss_test:0.08775, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:52.699, tt:1001.288\n",
      "Ep:19, loss:0.00015, loss_test:0.08556, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:52.718, tt:1054.356\n",
      "Ep:20, loss:0.00015, loss_test:0.08488, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:52.738, tt:1107.499\n",
      "Ep:21, loss:0.00014, loss_test:0.08479, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:52.541, tt:1155.903\n",
      "Ep:22, loss:0.00014, loss_test:0.08463, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:52.613, tt:1210.098\n",
      "Ep:23, loss:0.00013, loss_test:0.08478, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:52.449, tt:1258.785\n",
      "Ep:24, loss:0.00013, loss_test:0.08342, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:52.446, tt:1311.158\n",
      "Ep:25, loss:0.00013, loss_test:0.08223, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:52.414, tt:1362.772\n",
      "Ep:26, loss:0.00012, loss_test:0.08107, lr:9.90e-03, fs:0.80788 (r=0.828,p=0.788),  time:52.443, tt:1415.963\n",
      "Ep:27, loss:0.00012, loss_test:0.08171, lr:9.80e-03, fs:0.80000 (r=0.788,p=0.812),  time:52.527, tt:1470.761\n",
      "Ep:28, loss:0.00011, loss_test:0.08067, lr:9.70e-03, fs:0.80597 (r=0.818,p=0.794),  time:52.537, tt:1523.586\n",
      "Ep:29, loss:0.00011, loss_test:0.08133, lr:9.61e-03, fs:0.81026 (r=0.798,p=0.823),  time:52.504, tt:1575.134\n",
      "Ep:30, loss:0.00011, loss_test:0.08131, lr:9.51e-03, fs:0.81633 (r=0.808,p=0.825),  time:52.520, tt:1628.132\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.07932, lr:9.51e-03, fs:0.81026 (r=0.798,p=0.823),  time:52.503, tt:1680.108\n",
      "Ep:32, loss:0.00010, loss_test:0.08432, lr:9.51e-03, fs:0.80214 (r=0.758,p=0.852),  time:52.523, tt:1733.256\n",
      "Ep:33, loss:0.00010, loss_test:0.07867, lr:9.51e-03, fs:0.81905 (r=0.869,p=0.775),  time:52.678, tt:1791.043\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.08420, lr:9.51e-03, fs:0.80214 (r=0.758,p=0.852),  time:52.795, tt:1847.815\n",
      "Ep:35, loss:0.00009, loss_test:0.08045, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:52.820, tt:1901.502\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07923, lr:9.51e-03, fs:0.81188 (r=0.828,p=0.796),  time:52.833, tt:1954.806\n",
      "Ep:37, loss:0.00009, loss_test:0.08224, lr:9.51e-03, fs:0.82353 (r=0.848,p=0.800),  time:52.831, tt:2007.582\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07679, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:52.831, tt:2060.418\n",
      "Ep:39, loss:0.00008, loss_test:0.09263, lr:9.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:52.920, tt:2116.809\n",
      "Ep:40, loss:0.00008, loss_test:0.07878, lr:9.51e-03, fs:0.80751 (r=0.869,p=0.754),  time:52.979, tt:2172.122\n",
      "Ep:41, loss:0.00008, loss_test:0.08587, lr:9.51e-03, fs:0.82353 (r=0.778,p=0.875),  time:53.079, tt:2229.328\n",
      "Ep:42, loss:0.00007, loss_test:0.07769, lr:9.51e-03, fs:0.82051 (r=0.808,p=0.833),  time:53.167, tt:2286.171\n",
      "Ep:43, loss:0.00007, loss_test:0.08753, lr:9.51e-03, fs:0.78756 (r=0.768,p=0.809),  time:53.173, tt:2339.623\n",
      "Ep:44, loss:0.00007, loss_test:0.07712, lr:9.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:53.170, tt:2392.641\n",
      "Ep:45, loss:0.00007, loss_test:0.08504, lr:9.51e-03, fs:0.83243 (r=0.778,p=0.895),  time:53.123, tt:2443.640\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00006, loss_test:0.07955, lr:9.51e-03, fs:0.80612 (r=0.798,p=0.814),  time:53.125, tt:2496.852\n",
      "Ep:47, loss:0.00006, loss_test:0.08430, lr:9.51e-03, fs:0.81283 (r=0.768,p=0.864),  time:53.133, tt:2550.395\n",
      "Ep:48, loss:0.00006, loss_test:0.08469, lr:9.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:53.103, tt:2602.063\n",
      "Ep:49, loss:0.00005, loss_test:0.08175, lr:9.51e-03, fs:0.80214 (r=0.758,p=0.852),  time:53.120, tt:2656.015\n",
      "Ep:50, loss:0.00005, loss_test:0.09181, lr:9.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:53.123, tt:2709.274\n",
      "Ep:51, loss:0.00005, loss_test:0.07900, lr:9.51e-03, fs:0.78392 (r=0.788,p=0.780),  time:53.156, tt:2764.098\n",
      "Ep:52, loss:0.00006, loss_test:0.09170, lr:9.51e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.201, tt:2819.677\n",
      "Ep:53, loss:0.00005, loss_test:0.08137, lr:9.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:53.202, tt:2872.895\n",
      "Ep:54, loss:0.00005, loss_test:0.09601, lr:9.51e-03, fs:0.82222 (r=0.747,p=0.914),  time:53.205, tt:2926.271\n",
      "Ep:55, loss:0.00004, loss_test:0.08274, lr:9.51e-03, fs:0.80423 (r=0.768,p=0.844),  time:53.184, tt:2978.303\n",
      "Ep:56, loss:0.00004, loss_test:0.09290, lr:9.51e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.158, tt:3029.988\n",
      "Ep:57, loss:0.00004, loss_test:0.08369, lr:9.41e-03, fs:0.80423 (r=0.768,p=0.844),  time:53.166, tt:3083.624\n",
      "Ep:58, loss:0.00004, loss_test:0.09319, lr:9.32e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.178, tt:3137.500\n",
      "Ep:59, loss:0.00004, loss_test:0.08395, lr:9.23e-03, fs:0.80645 (r=0.758,p=0.862),  time:53.200, tt:3191.996\n",
      "Ep:60, loss:0.00004, loss_test:0.09171, lr:9.14e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.181, tt:3244.067\n",
      "Ep:61, loss:0.00004, loss_test:0.08707, lr:9.04e-03, fs:0.79787 (r=0.758,p=0.843),  time:53.175, tt:3296.830\n",
      "Ep:62, loss:0.00003, loss_test:0.09288, lr:8.95e-03, fs:0.81768 (r=0.747,p=0.902),  time:53.173, tt:3349.881\n",
      "Ep:63, loss:0.00003, loss_test:0.08581, lr:8.86e-03, fs:0.80645 (r=0.758,p=0.862),  time:53.184, tt:3403.800\n",
      "Ep:64, loss:0.00003, loss_test:0.09268, lr:8.78e-03, fs:0.80435 (r=0.747,p=0.871),  time:53.206, tt:3458.408\n",
      "Ep:65, loss:0.00003, loss_test:0.09021, lr:8.69e-03, fs:0.81522 (r=0.758,p=0.882),  time:53.193, tt:3510.723\n",
      "Ep:66, loss:0.00003, loss_test:0.09308, lr:8.60e-03, fs:0.80874 (r=0.747,p=0.881),  time:53.190, tt:3563.737\n",
      "Ep:67, loss:0.00003, loss_test:0.09073, lr:8.51e-03, fs:0.82418 (r=0.758,p=0.904),  time:53.197, tt:3617.397\n",
      "Ep:68, loss:0.00003, loss_test:0.09436, lr:8.43e-03, fs:0.82222 (r=0.747,p=0.914),  time:53.187, tt:3669.888\n",
      "Ep:69, loss:0.00003, loss_test:0.09176, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:53.139, tt:3719.707\n",
      "Ep:70, loss:0.00002, loss_test:0.09823, lr:8.26e-03, fs:0.82486 (r=0.737,p=0.936),  time:53.110, tt:3770.799\n",
      "Ep:71, loss:0.00003, loss_test:0.09006, lr:8.18e-03, fs:0.80645 (r=0.758,p=0.862),  time:53.090, tt:3822.470\n",
      "Ep:72, loss:0.00003, loss_test:0.09962, lr:8.10e-03, fs:0.84091 (r=0.747,p=0.961),  time:53.100, tt:3876.306\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.09344, lr:8.10e-03, fs:0.82873 (r=0.758,p=0.915),  time:53.098, tt:3929.277\n",
      "Ep:74, loss:0.00002, loss_test:0.09509, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.107, tt:3983.009\n",
      "Ep:75, loss:0.00002, loss_test:0.09440, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:53.133, tt:4038.070\n",
      "Ep:76, loss:0.00002, loss_test:0.09277, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:53.090, tt:4087.915\n",
      "Ep:77, loss:0.00002, loss_test:0.09421, lr:8.10e-03, fs:0.81564 (r=0.737,p=0.912),  time:53.106, tt:4142.250\n",
      "Ep:78, loss:0.00002, loss_test:0.09637, lr:8.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.097, tt:4194.641\n",
      "Ep:79, loss:0.00002, loss_test:0.09609, lr:8.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.106, tt:4248.461\n",
      "Ep:80, loss:0.00002, loss_test:0.09104, lr:8.10e-03, fs:0.82609 (r=0.768,p=0.894),  time:53.111, tt:4301.972\n",
      "Ep:81, loss:0.00002, loss_test:0.10282, lr:8.10e-03, fs:0.82682 (r=0.747,p=0.925),  time:53.087, tt:4353.125\n",
      "Ep:82, loss:0.00002, loss_test:0.09514, lr:8.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:53.026, tt:4401.158\n",
      "Ep:83, loss:0.00002, loss_test:0.09674, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:52.954, tt:4448.172\n",
      "Ep:84, loss:0.00002, loss_test:0.10139, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.876, tt:4494.475\n",
      "Ep:85, loss:0.00002, loss_test:0.09731, lr:7.94e-03, fs:0.81768 (r=0.747,p=0.902),  time:52.814, tt:4542.023\n",
      "Ep:86, loss:0.00002, loss_test:0.09365, lr:7.86e-03, fs:0.81768 (r=0.747,p=0.902),  time:52.791, tt:4592.859\n",
      "Ep:87, loss:0.00001, loss_test:0.09759, lr:7.78e-03, fs:0.82022 (r=0.737,p=0.924),  time:52.783, tt:4644.894\n",
      "Ep:88, loss:0.00001, loss_test:0.09638, lr:7.70e-03, fs:0.80447 (r=0.727,p=0.900),  time:52.803, tt:4699.494\n",
      "Ep:89, loss:0.00001, loss_test:0.09676, lr:7.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:52.806, tt:4752.534\n",
      "Ep:90, loss:0.00001, loss_test:0.09303, lr:7.55e-03, fs:0.80447 (r=0.727,p=0.900),  time:52.791, tt:4803.953\n",
      "Ep:91, loss:0.00001, loss_test:0.10187, lr:7.47e-03, fs:0.82022 (r=0.737,p=0.924),  time:52.814, tt:4858.865\n",
      "Ep:92, loss:0.00001, loss_test:0.09307, lr:7.40e-03, fs:0.81111 (r=0.737,p=0.901),  time:52.810, tt:4911.315\n",
      "Ep:93, loss:0.00001, loss_test:0.10044, lr:7.32e-03, fs:0.83616 (r=0.747,p=0.949),  time:52.797, tt:4962.891\n",
      "Ep:94, loss:0.00001, loss_test:0.09815, lr:7.25e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.781, tt:5014.198\n",
      "Ep:95, loss:0.00001, loss_test:0.09377, lr:7.18e-03, fs:0.81111 (r=0.737,p=0.901),  time:52.779, tt:5066.751\n",
      "Ep:96, loss:0.00001, loss_test:0.09844, lr:7.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.758, tt:5117.572\n",
      "Ep:97, loss:0.00001, loss_test:0.09650, lr:7.03e-03, fs:0.80899 (r=0.727,p=0.911),  time:52.749, tt:5169.436\n",
      "Ep:98, loss:0.00001, loss_test:0.09886, lr:6.96e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.746, tt:5221.816\n",
      "Ep:99, loss:0.00001, loss_test:0.09596, lr:6.89e-03, fs:0.80460 (r=0.707,p=0.933),  time:52.749, tt:5274.912\n",
      "Ep:100, loss:0.00001, loss_test:0.09683, lr:6.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.729, tt:5325.624\n",
      "Ep:101, loss:0.00001, loss_test:0.09591, lr:6.76e-03, fs:0.79775 (r=0.717,p=0.899),  time:52.719, tt:5377.356\n",
      "Ep:102, loss:0.00001, loss_test:0.09894, lr:6.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.709, tt:5429.047\n",
      "Ep:103, loss:0.00001, loss_test:0.09611, lr:6.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.709, tt:5481.727\n",
      "Ep:104, loss:0.00001, loss_test:0.09806, lr:6.56e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.705, tt:5534.033\n",
      "Ep:105, loss:0.00001, loss_test:0.09712, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.689, tt:5585.045\n",
      "Ep:106, loss:0.00001, loss_test:0.09577, lr:6.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.692, tt:5638.074\n",
      "Ep:107, loss:0.00001, loss_test:0.09971, lr:6.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.680, tt:5689.479\n",
      "Ep:108, loss:0.00001, loss_test:0.09415, lr:6.30e-03, fs:0.81143 (r=0.717,p=0.934),  time:52.693, tt:5743.560\n",
      "Ep:109, loss:0.00001, loss_test:0.10263, lr:6.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.677, tt:5794.502\n",
      "Ep:110, loss:0.00001, loss_test:0.09638, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.685, tt:5848.070\n",
      "Ep:111, loss:0.00001, loss_test:0.09816, lr:6.11e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.682, tt:5900.409\n",
      "Ep:112, loss:0.00001, loss_test:0.09790, lr:6.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.680, tt:5952.862\n",
      "Ep:113, loss:0.00001, loss_test:0.09679, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.665, tt:6003.790\n",
      "Ep:114, loss:0.00001, loss_test:0.09686, lr:5.93e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.657, tt:6055.590\n",
      "Ep:115, loss:0.00001, loss_test:0.09697, lr:5.87e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.640, tt:6106.287\n",
      "Ep:116, loss:0.00001, loss_test:0.09744, lr:5.81e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.635, tt:6158.293\n",
      "Ep:117, loss:0.00001, loss_test:0.09781, lr:5.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.631, tt:6210.463\n",
      "Ep:118, loss:0.00001, loss_test:0.10012, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.614, tt:6261.113\n",
      "Ep:119, loss:0.00001, loss_test:0.09739, lr:5.64e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.619, tt:6314.333\n",
      "Ep:120, loss:0.00001, loss_test:0.09761, lr:5.58e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.623, tt:6367.425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.09895, lr:5.53e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.624, tt:6420.104\n",
      "Ep:122, loss:0.00001, loss_test:0.09571, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.638, tt:6474.528\n",
      "Ep:123, loss:0.00001, loss_test:0.10063, lr:5.42e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.641, tt:6527.490\n",
      "Ep:124, loss:0.00001, loss_test:0.09738, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.628, tt:6578.528\n",
      "Ep:125, loss:0.00000, loss_test:0.09701, lr:5.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.616, tt:6629.655\n",
      "Ep:126, loss:0.00000, loss_test:0.09881, lr:5.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.613, tt:6681.813\n",
      "Ep:127, loss:0.00000, loss_test:0.09557, lr:5.20e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.605, tt:6733.502\n",
      "Ep:128, loss:0.00000, loss_test:0.09826, lr:5.15e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.606, tt:6786.225\n",
      "Ep:129, loss:0.00000, loss_test:0.09863, lr:5.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.601, tt:6838.170\n",
      "Ep:130, loss:0.00000, loss_test:0.09594, lr:5.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.605, tt:6891.290\n",
      "Ep:131, loss:0.00000, loss_test:0.09753, lr:5.00e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.615, tt:6945.233\n",
      "Ep:132, loss:0.00000, loss_test:0.09716, lr:4.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.612, tt:6997.452\n",
      "Ep:133, loss:0.00000, loss_test:0.09767, lr:4.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.610, tt:7049.722\n",
      "Ep:134, loss:0.00000, loss_test:0.09813, lr:4.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.616, tt:7103.141\n",
      "Ep:135, loss:0.00000, loss_test:0.09617, lr:4.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.629, tt:7157.532\n",
      "Ep:136, loss:0.00000, loss_test:0.09706, lr:4.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.624, tt:7209.440\n",
      "Ep:137, loss:0.00000, loss_test:0.09709, lr:4.71e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.613, tt:7260.607\n",
      "Ep:138, loss:0.00000, loss_test:0.09706, lr:4.66e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.610, tt:7312.826\n",
      "Ep:139, loss:0.00000, loss_test:0.09803, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.606, tt:7364.793\n",
      "Ep:140, loss:0.00000, loss_test:0.09642, lr:4.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.628, tt:7420.488\n",
      "Ep:141, loss:0.00000, loss_test:0.09794, lr:4.52e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.655, tt:7476.977\n",
      "Ep:142, loss:0.00000, loss_test:0.09725, lr:4.48e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.649, tt:7528.801\n",
      "Ep:143, loss:0.00000, loss_test:0.09549, lr:4.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.634, tt:7579.236\n",
      "Ep:144, loss:0.00000, loss_test:0.09730, lr:4.39e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.637, tt:7632.311\n",
      "Ep:145, loss:0.00000, loss_test:0.09661, lr:4.34e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.638, tt:7685.218\n",
      "Ep:146, loss:0.00000, loss_test:0.09689, lr:4.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.629, tt:7736.486\n",
      "Ep:147, loss:0.00000, loss_test:0.09848, lr:4.26e-03, fs:0.81657 (r=0.697,p=0.986),  time:52.632, tt:7789.600\n",
      "Ep:148, loss:0.00000, loss_test:0.09636, lr:4.21e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.639, tt:7843.283\n",
      "Ep:149, loss:0.00000, loss_test:0.09700, lr:4.17e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.644, tt:7896.568\n",
      "Ep:150, loss:0.00000, loss_test:0.09742, lr:4.13e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.650, tt:7950.215\n",
      "Ep:151, loss:0.00000, loss_test:0.09629, lr:4.09e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.661, tt:8004.411\n",
      "Ep:152, loss:0.00000, loss_test:0.09700, lr:4.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.658, tt:8056.621\n",
      "Ep:153, loss:0.00000, loss_test:0.09823, lr:4.01e-03, fs:0.81657 (r=0.697,p=0.986),  time:52.666, tt:8110.496\n",
      "Ep:154, loss:0.00000, loss_test:0.09618, lr:3.97e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.674, tt:8164.400\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14101, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.152, tt:21.152\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13954, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:19.110, tt:38.219\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13681, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:18.397, tt:55.190\n",
      "Ep:3, loss:0.00027, loss_test:0.13252, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:18.443, tt:73.773\n",
      "Ep:4, loss:0.00026, loss_test:0.12571, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:19.093, tt:95.465\n",
      "Ep:5, loss:0.00025, loss_test:0.11806, lr:1.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:19.360, tt:116.160\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11462, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:19.792, tt:138.546\n",
      "Ep:7, loss:0.00023, loss_test:0.11297, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:20.218, tt:161.746\n",
      "Ep:8, loss:0.00022, loss_test:0.11062, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:20.426, tt:183.834\n",
      "Ep:9, loss:0.00021, loss_test:0.10661, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:20.657, tt:206.571\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10347, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:20.779, tt:228.572\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10063, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:20.660, tt:247.919\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09794, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:20.618, tt:268.040\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09609, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:20.594, tt:288.312\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09389, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:20.492, tt:307.375\n",
      "Ep:15, loss:0.00016, loss_test:0.09201, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:20.573, tt:329.166\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09015, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:20.544, tt:349.253\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08728, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:20.495, tt:368.917\n",
      "Ep:18, loss:0.00014, loss_test:0.08582, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:20.512, tt:389.737\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.08262, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:20.507, tt:410.136\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08166, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:20.604, tt:432.676\n",
      "Ep:21, loss:0.00012, loss_test:0.08038, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:20.663, tt:454.588\n",
      "Ep:22, loss:0.00012, loss_test:0.07800, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:20.715, tt:476.455\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.07697, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:20.738, tt:497.721\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07535, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:20.721, tt:518.025\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.07380, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:20.730, tt:538.978\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07430, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:20.775, tt:560.917\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07179, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:20.790, tt:582.118\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:28, loss:0.00009, loss_test:0.07061, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:20.798, tt:603.141\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.07113, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:20.805, tt:624.135\n",
      "Ep:30, loss:0.00008, loss_test:0.06969, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:20.747, tt:643.151\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06910, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:20.763, tt:664.419\n",
      "Ep:32, loss:0.00008, loss_test:0.06973, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:20.803, tt:686.515\n",
      "Ep:33, loss:0.00007, loss_test:0.06656, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:20.790, tt:706.865\n",
      "Ep:34, loss:0.00007, loss_test:0.06777, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:20.792, tt:727.730\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06562, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:20.866, tt:751.170\n",
      "Ep:36, loss:0.00007, loss_test:0.06654, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:20.831, tt:770.746\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.06705, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:20.800, tt:790.385\n",
      "Ep:38, loss:0.00006, loss_test:0.06504, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:20.766, tt:809.873\n",
      "Ep:39, loss:0.00006, loss_test:0.06493, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:20.788, tt:831.521\n",
      "Ep:40, loss:0.00006, loss_test:0.06655, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:20.793, tt:852.524\n",
      "Ep:41, loss:0.00006, loss_test:0.06514, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:20.816, tt:874.270\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06553, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:20.776, tt:893.378\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.06429, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:20.757, tt:913.320\n",
      "Ep:44, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:20.725, tt:932.631\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.06478, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:20.681, tt:951.322\n",
      "Ep:46, loss:0.00005, loss_test:0.06564, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:20.707, tt:973.247\n",
      "Ep:47, loss:0.00004, loss_test:0.06461, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:20.711, tt:994.130\n",
      "Ep:48, loss:0.00004, loss_test:0.06810, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:20.804, tt:1019.406\n",
      "Ep:49, loss:0.00004, loss_test:0.06488, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:20.816, tt:1040.822\n",
      "Ep:50, loss:0.00004, loss_test:0.06881, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:20.823, tt:1061.991\n",
      "Ep:51, loss:0.00004, loss_test:0.06361, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:20.860, tt:1084.738\n",
      "Ep:52, loss:0.00004, loss_test:0.06747, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:20.892, tt:1107.274\n",
      "Ep:53, loss:0.00004, loss_test:0.06459, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:20.913, tt:1129.323\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00004, loss_test:0.06576, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:20.939, tt:1151.640\n",
      "Ep:55, loss:0.00003, loss_test:0.06418, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:20.944, tt:1172.863\n",
      "Ep:56, loss:0.00003, loss_test:0.06577, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:20.975, tt:1195.569\n",
      "Ep:57, loss:0.00003, loss_test:0.06516, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:20.975, tt:1216.551\n",
      "Ep:58, loss:0.00003, loss_test:0.06521, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:20.968, tt:1237.111\n",
      "Ep:59, loss:0.00003, loss_test:0.06529, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:20.964, tt:1257.827\n",
      "Ep:60, loss:0.00003, loss_test:0.06548, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:20.945, tt:1277.631\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.06614, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:20.930, tt:1297.672\n",
      "Ep:62, loss:0.00003, loss_test:0.06452, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:20.928, tt:1318.495\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.06457, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:20.956, tt:1341.159\n",
      "Ep:64, loss:0.00002, loss_test:0.06460, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.032, tt:1367.068\n",
      "Ep:65, loss:0.00002, loss_test:0.06411, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:21.042, tt:1388.779\n",
      "Ep:66, loss:0.00002, loss_test:0.06501, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.059, tt:1410.949\n",
      "Ep:67, loss:0.00002, loss_test:0.06592, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:21.084, tt:1433.701\n",
      "Ep:68, loss:0.00002, loss_test:0.06251, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.094, tt:1455.491\n",
      "Ep:69, loss:0.00002, loss_test:0.06624, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:21.116, tt:1478.126\n",
      "Ep:70, loss:0.00002, loss_test:0.06255, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:21.101, tt:1498.181\n",
      "Ep:71, loss:0.00002, loss_test:0.06721, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.096, tt:1518.905\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.06460, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:21.074, tt:1538.422\n",
      "Ep:73, loss:0.00002, loss_test:0.06323, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.070, tt:1559.172\n",
      "Ep:74, loss:0.00002, loss_test:0.06751, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:21.083, tt:1581.195\n",
      "Ep:75, loss:0.00002, loss_test:0.06214, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.092, tt:1602.959\n",
      "Ep:76, loss:0.00002, loss_test:0.06463, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:21.105, tt:1625.094\n",
      "Ep:77, loss:0.00002, loss_test:0.06439, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:21.110, tt:1646.583\n",
      "Ep:78, loss:0.00002, loss_test:0.06146, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.135, tt:1669.640\n",
      "Ep:79, loss:0.00002, loss_test:0.06567, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:21.150, tt:1692.004\n",
      "Ep:80, loss:0.00002, loss_test:0.06122, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.123, tt:1710.956\n",
      "Ep:81, loss:0.00002, loss_test:0.06692, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:21.106, tt:1730.716\n",
      "Ep:82, loss:0.00002, loss_test:0.06461, lr:1.00e-02, fs:0.86667 (r=0.788,p=0.963),  time:21.101, tt:1751.391\n",
      "Ep:83, loss:0.00001, loss_test:0.06058, lr:9.90e-03, fs:0.89247 (r=0.838,p=0.954),  time:21.100, tt:1772.403\n",
      "Ep:84, loss:0.00001, loss_test:0.06669, lr:9.80e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.094, tt:1792.979\n",
      "Ep:85, loss:0.00001, loss_test:0.06331, lr:9.70e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.097, tt:1814.363\n",
      "Ep:86, loss:0.00001, loss_test:0.06179, lr:9.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.080, tt:1833.942\n",
      "Ep:87, loss:0.00001, loss_test:0.06443, lr:9.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.063, tt:1853.578\n",
      "Ep:88, loss:0.00001, loss_test:0.06137, lr:9.41e-03, fs:0.89247 (r=0.838,p=0.954),  time:21.058, tt:1874.169\n",
      "Ep:89, loss:0.00001, loss_test:0.06407, lr:9.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:21.072, tt:1896.465\n",
      "Ep:90, loss:0.00001, loss_test:0.06319, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.085, tt:1918.717\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.06060, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.070, tt:1938.466\n",
      "Ep:92, loss:0.00001, loss_test:0.06585, lr:9.23e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.063, tt:1958.861\n",
      "Ep:93, loss:0.00001, loss_test:0.06258, lr:9.23e-03, fs:0.87151 (r=0.788,p=0.975),  time:21.056, tt:1979.225\n",
      "Ep:94, loss:0.00001, loss_test:0.06144, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.047, tt:1999.434\n",
      "Ep:95, loss:0.00001, loss_test:0.06508, lr:9.23e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.029, tt:2018.830\n",
      "Ep:96, loss:0.00001, loss_test:0.06201, lr:9.23e-03, fs:0.88398 (r=0.808,p=0.976),  time:21.025, tt:2039.473\n",
      "Ep:97, loss:0.00001, loss_test:0.06338, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.020, tt:2059.984\n",
      "Ep:98, loss:0.00001, loss_test:0.06367, lr:9.23e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.020, tt:2081.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:99, loss:0.00001, loss_test:0.06228, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.018, tt:2101.826\n",
      "Ep:100, loss:0.00001, loss_test:0.06389, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.013, tt:2122.277\n",
      "Ep:101, loss:0.00001, loss_test:0.06358, lr:9.23e-03, fs:0.89617 (r=0.828,p=0.976),  time:20.997, tt:2141.729\n",
      "Ep:102, loss:0.00001, loss_test:0.06232, lr:9.14e-03, fs:0.90811 (r=0.848,p=0.977),  time:20.998, tt:2162.772\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.06329, lr:9.14e-03, fs:0.86517 (r=0.778,p=0.975),  time:20.984, tt:2182.367\n",
      "Ep:104, loss:0.00001, loss_test:0.06382, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.999, tt:2204.847\n",
      "Ep:105, loss:0.00001, loss_test:0.06268, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.998, tt:2225.795\n",
      "Ep:106, loss:0.00001, loss_test:0.06306, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.990, tt:2245.878\n",
      "Ep:107, loss:0.00001, loss_test:0.06370, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.984, tt:2266.225\n",
      "Ep:108, loss:0.00001, loss_test:0.06288, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.974, tt:2286.172\n",
      "Ep:109, loss:0.00001, loss_test:0.06400, lr:9.14e-03, fs:0.89011 (r=0.818,p=0.976),  time:20.964, tt:2306.023\n",
      "Ep:110, loss:0.00001, loss_test:0.06220, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.975, tt:2328.251\n",
      "Ep:111, loss:0.00001, loss_test:0.06386, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.966, tt:2348.202\n",
      "Ep:112, loss:0.00001, loss_test:0.06289, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.953, tt:2367.657\n",
      "Ep:113, loss:0.00001, loss_test:0.06344, lr:9.14e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.957, tt:2389.137\n",
      "Ep:114, loss:0.00001, loss_test:0.06303, lr:9.04e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.965, tt:2410.973\n",
      "Ep:115, loss:0.00001, loss_test:0.06406, lr:8.95e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.991, tt:2434.921\n",
      "Ep:116, loss:0.00001, loss_test:0.06304, lr:8.86e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.992, tt:2456.102\n",
      "Ep:117, loss:0.00000, loss_test:0.06424, lr:8.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:20.997, tt:2477.623\n",
      "Ep:118, loss:0.00000, loss_test:0.06322, lr:8.69e-03, fs:0.87151 (r=0.788,p=0.975),  time:20.990, tt:2497.787\n",
      "Ep:119, loss:0.00000, loss_test:0.06473, lr:8.60e-03, fs:0.90811 (r=0.848,p=0.977),  time:20.989, tt:2518.699\n",
      "Ep:120, loss:0.00000, loss_test:0.06424, lr:8.51e-03, fs:0.86517 (r=0.778,p=0.975),  time:21.009, tt:2542.149\n",
      "Ep:121, loss:0.00000, loss_test:0.06519, lr:8.43e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.014, tt:2563.766\n",
      "Ep:122, loss:0.00000, loss_test:0.06476, lr:8.35e-03, fs:0.86517 (r=0.778,p=0.975),  time:21.007, tt:2583.893\n",
      "Ep:123, loss:0.00000, loss_test:0.06482, lr:8.26e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.012, tt:2605.488\n",
      "Ep:124, loss:0.00000, loss_test:0.06564, lr:8.18e-03, fs:0.87151 (r=0.788,p=0.975),  time:21.013, tt:2626.683\n",
      "Ep:125, loss:0.00000, loss_test:0.06442, lr:8.10e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.027, tt:2649.371\n",
      "Ep:126, loss:0.00000, loss_test:0.06485, lr:8.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.034, tt:2671.334\n",
      "Ep:127, loss:0.00000, loss_test:0.06581, lr:7.94e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.050, tt:2694.414\n",
      "Ep:128, loss:0.00000, loss_test:0.06365, lr:7.86e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.048, tt:2715.145\n",
      "Ep:129, loss:0.00000, loss_test:0.06576, lr:7.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.057, tt:2737.392\n",
      "Ep:130, loss:0.00000, loss_test:0.06443, lr:7.70e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.064, tt:2759.333\n",
      "Ep:131, loss:0.00000, loss_test:0.06551, lr:7.62e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.058, tt:2779.660\n",
      "Ep:132, loss:0.00000, loss_test:0.06442, lr:7.55e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.050, tt:2799.610\n",
      "Ep:133, loss:0.00000, loss_test:0.06454, lr:7.47e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.062, tt:2822.343\n",
      "Ep:134, loss:0.00000, loss_test:0.06424, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.051, tt:2841.844\n",
      "Ep:135, loss:0.00000, loss_test:0.06548, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.038, tt:2861.171\n",
      "Ep:136, loss:0.00000, loss_test:0.06458, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.015, tt:2879.106\n",
      "Ep:137, loss:0.00000, loss_test:0.06450, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:21.006, tt:2898.785\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00000, loss_test:0.06496, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.991, tt:2917.746\n",
      "Ep:139, loss:0.00000, loss_test:0.06408, lr:7.18e-03, fs:0.90811 (r=0.848,p=0.977),  time:20.997, tt:2939.561\n",
      "Ep:140, loss:0.00000, loss_test:0.06493, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.994, tt:2960.083\n",
      "Ep:141, loss:0.00000, loss_test:0.06431, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.970, tt:2977.691\n",
      "Ep:142, loss:0.00000, loss_test:0.06521, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.962, tt:2997.515\n",
      "Ep:143, loss:0.00000, loss_test:0.06510, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.954, tt:3017.347\n",
      "Ep:144, loss:0.00000, loss_test:0.06425, lr:7.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.966, tt:3040.030\n",
      "Ep:145, loss:0.00000, loss_test:0.06520, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.968, tt:3061.280\n",
      "Ep:146, loss:0.00000, loss_test:0.06430, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.963, tt:3081.538\n",
      "Ep:147, loss:0.00000, loss_test:0.06519, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.959, tt:3101.861\n",
      "Ep:148, loss:0.00000, loss_test:0.06446, lr:7.18e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.956, tt:3122.512\n",
      "Ep:149, loss:0.00000, loss_test:0.06528, lr:7.11e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.957, tt:3143.481\n",
      "Ep:150, loss:0.00000, loss_test:0.06521, lr:7.03e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.953, tt:3163.891\n",
      "Ep:151, loss:0.00000, loss_test:0.06452, lr:6.96e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.966, tt:3186.862\n",
      "Ep:152, loss:0.00000, loss_test:0.06505, lr:6.89e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.964, tt:3207.453\n",
      "Ep:153, loss:0.00000, loss_test:0.06470, lr:6.83e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.973, tt:3229.849\n",
      "Ep:154, loss:0.00000, loss_test:0.06490, lr:6.76e-03, fs:0.91304 (r=0.848,p=0.988),  time:20.968, tt:3250.001\n",
      "Ep:155, loss:0.00000, loss_test:0.06537, lr:6.69e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.969, tt:3271.164\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13982, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.452, tt:20.452\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13799, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.274, tt:40.548\n",
      "Ep:2, loss:0.00028, loss_test:0.13471, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:19.222, tt:57.667\n",
      "Ep:3, loss:0.00027, loss_test:0.12939, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:18.834, tt:75.335\n",
      "Ep:4, loss:0.00026, loss_test:0.12111, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:19.280, tt:96.398\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11207, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:19.425, tt:116.548\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10338, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:19.937, tt:139.557\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.09932, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:19.920, tt:159.357\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.09762, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:20.191, tt:181.717\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09697, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:20.171, tt:201.708\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00020, loss_test:0.09363, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:20.258, tt:222.843\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09158, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:20.337, tt:244.039\n",
      "Ep:12, loss:0.00019, loss_test:0.08989, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:20.353, tt:264.586\n",
      "Ep:13, loss:0.00018, loss_test:0.08876, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:20.497, tt:286.962\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08689, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:20.418, tt:306.268\n",
      "Ep:15, loss:0.00017, loss_test:0.08449, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:20.553, tt:328.856\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08280, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:20.614, tt:350.436\n",
      "Ep:17, loss:0.00015, loss_test:0.08163, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:20.727, tt:373.085\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07908, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:20.710, tt:393.485\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.07750, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:20.764, tt:415.271\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07601, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:20.791, tt:436.612\n",
      "Ep:21, loss:0.00013, loss_test:0.07417, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:20.779, tt:457.147\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.07310, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:20.778, tt:477.888\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07218, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:20.757, tt:498.165\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07065, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:20.805, tt:520.122\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07010, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:20.941, tt:544.467\n",
      "Ep:26, loss:0.00011, loss_test:0.06807, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:20.886, tt:563.932\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.06768, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:20.914, tt:585.605\n",
      "Ep:28, loss:0.00010, loss_test:0.06705, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:20.945, tt:607.392\n",
      "Ep:29, loss:0.00009, loss_test:0.06619, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:20.893, tt:626.789\n",
      "Ep:30, loss:0.00009, loss_test:0.06592, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:20.926, tt:648.715\n",
      "Ep:31, loss:0.00008, loss_test:0.06348, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.987, tt:671.581\n",
      "Ep:32, loss:0.00008, loss_test:0.06270, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:20.972, tt:692.087\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.06222, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:21.004, tt:714.125\n",
      "Ep:34, loss:0.00007, loss_test:0.06239, lr:1.00e-02, fs:0.91489 (r=0.869,p=0.966),  time:21.034, tt:736.190\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06116, lr:1.00e-02, fs:0.91489 (r=0.869,p=0.966),  time:21.039, tt:757.413\n",
      "Ep:36, loss:0.00007, loss_test:0.06029, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:21.042, tt:778.536\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.06019, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:21.064, tt:800.438\n",
      "Ep:38, loss:0.00006, loss_test:0.05965, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:21.065, tt:821.533\n",
      "Ep:39, loss:0.00006, loss_test:0.05980, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:21.073, tt:842.911\n",
      "Ep:40, loss:0.00006, loss_test:0.05897, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:21.045, tt:862.843\n",
      "Ep:41, loss:0.00005, loss_test:0.05784, lr:1.00e-02, fs:0.92063 (r=0.879,p=0.967),  time:21.037, tt:883.542\n",
      "Ep:42, loss:0.00005, loss_test:0.05744, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:21.042, tt:904.792\n",
      "Ep:43, loss:0.00005, loss_test:0.05923, lr:1.00e-02, fs:0.90909 (r=0.859,p=0.966),  time:21.036, tt:925.577\n",
      "Ep:44, loss:0.00005, loss_test:0.05686, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:21.028, tt:946.278\n",
      "Ep:45, loss:0.00005, loss_test:0.05797, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:21.049, tt:968.235\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.05637, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:21.050, tt:989.337\n",
      "Ep:47, loss:0.00004, loss_test:0.05861, lr:1.00e-02, fs:0.91979 (r=0.869,p=0.977),  time:21.067, tt:1011.194\n",
      "Ep:48, loss:0.00004, loss_test:0.05649, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:21.060, tt:1031.942\n",
      "Ep:49, loss:0.00004, loss_test:0.05847, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:21.055, tt:1052.734\n",
      "Ep:50, loss:0.00004, loss_test:0.05581, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:21.040, tt:1073.034\n",
      "Ep:51, loss:0.00004, loss_test:0.05776, lr:1.00e-02, fs:0.92473 (r=0.869,p=0.989),  time:21.043, tt:1094.217\n",
      "Ep:52, loss:0.00004, loss_test:0.05511, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:21.048, tt:1115.528\n",
      "Ep:53, loss:0.00003, loss_test:0.05865, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:21.015, tt:1134.831\n",
      "Ep:54, loss:0.00003, loss_test:0.05603, lr:1.00e-02, fs:0.93194 (r=0.899,p=0.967),  time:21.000, tt:1154.997\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.05584, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:20.974, tt:1174.529\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.05630, lr:1.00e-02, fs:0.92063 (r=0.879,p=0.967),  time:20.965, tt:1194.988\n",
      "Ep:57, loss:0.00003, loss_test:0.05611, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:20.985, tt:1217.136\n",
      "Ep:58, loss:0.00003, loss_test:0.05630, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:20.988, tt:1238.266\n",
      "Ep:59, loss:0.00002, loss_test:0.05457, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.024, tt:1261.463\n",
      "Ep:60, loss:0.00002, loss_test:0.05687, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:21.022, tt:1282.354\n",
      "Ep:61, loss:0.00002, loss_test:0.05406, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.019, tt:1303.198\n",
      "Ep:62, loss:0.00002, loss_test:0.05448, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.027, tt:1324.697\n",
      "Ep:63, loss:0.00002, loss_test:0.05719, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:21.018, tt:1345.156\n",
      "Ep:64, loss:0.00002, loss_test:0.05369, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:21.032, tt:1367.075\n",
      "Ep:65, loss:0.00002, loss_test:0.05596, lr:1.00e-02, fs:0.92553 (r=0.879,p=0.978),  time:21.037, tt:1388.455\n",
      "Ep:66, loss:0.00002, loss_test:0.05330, lr:1.00e-02, fs:0.92632 (r=0.889,p=0.967),  time:21.032, tt:1409.131\n",
      "Ep:67, loss:0.00002, loss_test:0.05764, lr:9.90e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.046, tt:1431.159\n",
      "Ep:68, loss:0.00002, loss_test:0.05297, lr:9.80e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.059, tt:1453.075\n",
      "Ep:69, loss:0.00002, loss_test:0.05823, lr:9.70e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.069, tt:1474.848\n",
      "Ep:70, loss:0.00002, loss_test:0.05506, lr:9.61e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.070, tt:1495.960\n",
      "Ep:71, loss:0.00002, loss_test:0.05741, lr:9.51e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.068, tt:1516.921\n",
      "Ep:72, loss:0.00002, loss_test:0.05517, lr:9.41e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.060, tt:1537.377\n",
      "Ep:73, loss:0.00001, loss_test:0.05438, lr:9.32e-03, fs:0.92063 (r=0.879,p=0.967),  time:21.077, tt:1559.728\n",
      "Ep:74, loss:0.00001, loss_test:0.05669, lr:9.23e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.077, tt:1580.779\n",
      "Ep:75, loss:0.00001, loss_test:0.05392, lr:9.14e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.079, tt:1602.022\n",
      "Ep:76, loss:0.00001, loss_test:0.05460, lr:9.04e-03, fs:0.92632 (r=0.889,p=0.967),  time:21.075, tt:1622.757\n",
      "Ep:77, loss:0.00001, loss_test:0.05966, lr:8.95e-03, fs:0.91304 (r=0.848,p=0.988),  time:21.071, tt:1643.560\n",
      "Ep:78, loss:0.00001, loss_test:0.05519, lr:8.86e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.073, tt:1664.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00001, loss_test:0.05751, lr:8.78e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.071, tt:1685.672\n",
      "Ep:80, loss:0.00001, loss_test:0.05455, lr:8.69e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.068, tt:1706.546\n",
      "Ep:81, loss:0.00001, loss_test:0.05794, lr:8.60e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.054, tt:1726.457\n",
      "Ep:82, loss:0.00001, loss_test:0.05500, lr:8.51e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.072, tt:1748.989\n",
      "Ep:83, loss:0.00001, loss_test:0.05684, lr:8.43e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.075, tt:1770.274\n",
      "Ep:84, loss:0.00001, loss_test:0.05481, lr:8.35e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.080, tt:1791.827\n",
      "Ep:85, loss:0.00001, loss_test:0.05652, lr:8.26e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.086, tt:1813.427\n",
      "Ep:86, loss:0.00001, loss_test:0.05581, lr:8.18e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.080, tt:1833.982\n",
      "Ep:87, loss:0.00001, loss_test:0.05670, lr:8.10e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.083, tt:1855.335\n",
      "Ep:88, loss:0.00001, loss_test:0.05517, lr:8.02e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.112, tt:1878.993\n",
      "Ep:89, loss:0.00001, loss_test:0.05719, lr:7.94e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.100, tt:1899.029\n",
      "Ep:90, loss:0.00001, loss_test:0.05794, lr:7.86e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.109, tt:1920.893\n",
      "Ep:91, loss:0.00001, loss_test:0.05602, lr:7.78e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.098, tt:1941.012\n",
      "Ep:92, loss:0.00001, loss_test:0.05813, lr:7.70e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.093, tt:1961.624\n",
      "Ep:93, loss:0.00001, loss_test:0.05534, lr:7.62e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.085, tt:1981.977\n",
      "Ep:94, loss:0.00001, loss_test:0.05740, lr:7.55e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.100, tt:2004.477\n",
      "Ep:95, loss:0.00001, loss_test:0.05567, lr:7.47e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.093, tt:2024.928\n",
      "Ep:96, loss:0.00001, loss_test:0.05747, lr:7.40e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.091, tt:2045.871\n",
      "Ep:97, loss:0.00001, loss_test:0.05594, lr:7.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.099, tt:2067.658\n",
      "Ep:98, loss:0.00001, loss_test:0.05783, lr:7.25e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.093, tt:2088.223\n",
      "Ep:99, loss:0.00001, loss_test:0.05709, lr:7.18e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.104, tt:2110.396\n",
      "Ep:100, loss:0.00001, loss_test:0.05850, lr:7.11e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.122, tt:2133.337\n",
      "Ep:101, loss:0.00001, loss_test:0.05757, lr:7.03e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.133, tt:2155.548\n",
      "Ep:102, loss:0.00001, loss_test:0.05761, lr:6.96e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.129, tt:2176.271\n",
      "Ep:103, loss:0.00001, loss_test:0.05772, lr:6.89e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.132, tt:2197.766\n",
      "Ep:104, loss:0.00001, loss_test:0.05714, lr:6.83e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.132, tt:2218.892\n",
      "Ep:105, loss:0.00000, loss_test:0.05802, lr:6.76e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.153, tt:2242.192\n",
      "Ep:106, loss:0.00000, loss_test:0.05750, lr:6.69e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.156, tt:2263.738\n",
      "Ep:107, loss:0.00000, loss_test:0.05763, lr:6.62e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.139, tt:2283.045\n",
      "Ep:108, loss:0.00000, loss_test:0.05782, lr:6.56e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.113, tt:2301.284\n",
      "Ep:109, loss:0.00000, loss_test:0.05818, lr:6.49e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.083, tt:2319.099\n",
      "Ep:110, loss:0.00000, loss_test:0.05789, lr:6.43e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.092, tt:2341.195\n",
      "Ep:111, loss:0.00000, loss_test:0.05801, lr:6.36e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.090, tt:2362.058\n",
      "Ep:112, loss:0.00000, loss_test:0.05803, lr:6.30e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.084, tt:2382.461\n",
      "Ep:113, loss:0.00000, loss_test:0.05926, lr:6.24e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.055, tt:2400.297\n",
      "Ep:114, loss:0.00000, loss_test:0.05862, lr:6.17e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.033, tt:2418.757\n",
      "Ep:115, loss:0.00000, loss_test:0.05907, lr:6.11e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.035, tt:2440.083\n",
      "Ep:116, loss:0.00000, loss_test:0.05988, lr:6.05e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.055, tt:2463.474\n",
      "Ep:117, loss:0.00000, loss_test:0.05830, lr:5.99e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.053, tt:2484.234\n",
      "Ep:118, loss:0.00000, loss_test:0.05955, lr:5.93e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.061, tt:2506.249\n",
      "Ep:119, loss:0.00000, loss_test:0.05887, lr:5.87e-03, fs:0.93048 (r=0.879,p=0.989),  time:21.051, tt:2526.136\n",
      "Ep:120, loss:0.00000, loss_test:0.06052, lr:5.81e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.044, tt:2546.327\n",
      "Ep:121, loss:0.00000, loss_test:0.05800, lr:5.75e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.036, tt:2566.435\n",
      "Ep:122, loss:0.00000, loss_test:0.05993, lr:5.70e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.035, tt:2587.346\n",
      "Ep:123, loss:0.00000, loss_test:0.05943, lr:5.64e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.032, tt:2607.981\n",
      "Ep:124, loss:0.00000, loss_test:0.05844, lr:5.58e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.022, tt:2627.745\n",
      "Ep:125, loss:0.00000, loss_test:0.06011, lr:5.53e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.018, tt:2648.268\n",
      "Ep:126, loss:0.00000, loss_test:0.05826, lr:5.47e-03, fs:0.93617 (r=0.889,p=0.989),  time:21.017, tt:2669.163\n",
      "Ep:127, loss:0.00000, loss_test:0.06038, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.013, tt:2689.726\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.05955, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.010, tt:2710.310\n",
      "Ep:129, loss:0.00000, loss_test:0.05921, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.003, tt:2730.416\n",
      "Ep:130, loss:0.00000, loss_test:0.06023, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.996, tt:2750.501\n",
      "Ep:131, loss:0.00000, loss_test:0.05978, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.009, tt:2773.140\n",
      "Ep:132, loss:0.00000, loss_test:0.06023, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.007, tt:2793.966\n",
      "Ep:133, loss:0.00000, loss_test:0.05981, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.014, tt:2815.892\n",
      "Ep:134, loss:0.00000, loss_test:0.05969, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.020, tt:2837.736\n",
      "Ep:135, loss:0.00000, loss_test:0.06092, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.013, tt:2857.796\n",
      "Ep:136, loss:0.00000, loss_test:0.05922, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.009, tt:2878.248\n",
      "Ep:137, loss:0.00000, loss_test:0.06054, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.003, tt:2898.483\n",
      "Ep:138, loss:0.00000, loss_test:0.06044, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.997, tt:2918.534\n",
      "Ep:139, loss:0.00000, loss_test:0.06032, lr:5.36e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.992, tt:2938.938\n",
      "Ep:140, loss:0.00000, loss_test:0.05986, lr:5.31e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.990, tt:2959.593\n",
      "Ep:141, loss:0.00000, loss_test:0.06044, lr:5.26e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.981, tt:2979.309\n",
      "Ep:142, loss:0.00000, loss_test:0.06051, lr:5.20e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.994, tt:3002.072\n",
      "Ep:143, loss:0.00000, loss_test:0.06011, lr:5.15e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.995, tt:3023.333\n",
      "Ep:144, loss:0.00000, loss_test:0.06029, lr:5.10e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.985, tt:3042.777\n",
      "Ep:145, loss:0.00000, loss_test:0.06028, lr:5.05e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.989, tt:3064.456\n",
      "Ep:146, loss:0.00000, loss_test:0.06059, lr:5.00e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.997, tt:3086.503\n",
      "Ep:147, loss:0.00000, loss_test:0.06036, lr:4.95e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.990, tt:3106.483\n",
      "Ep:148, loss:0.00000, loss_test:0.06065, lr:4.90e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.998, tt:3128.730\n",
      "Ep:149, loss:0.00000, loss_test:0.06064, lr:4.85e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.994, tt:3149.054\n",
      "Ep:150, loss:0.00000, loss_test:0.06033, lr:4.80e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.006, tt:3171.973\n",
      "Ep:151, loss:0.00000, loss_test:0.06078, lr:4.75e-03, fs:0.94118 (r=0.889,p=1.000),  time:21.002, tt:3192.228\n",
      "Ep:152, loss:0.00000, loss_test:0.06047, lr:4.71e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.997, tt:3212.590\n",
      "Ep:153, loss:0.00000, loss_test:0.06082, lr:4.66e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.989, tt:3232.258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00000, loss_test:0.06033, lr:4.61e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.991, tt:3253.561\n",
      "Ep:155, loss:0.00000, loss_test:0.06072, lr:4.57e-03, fs:0.94118 (r=0.889,p=1.000),  time:20.984, tt:3273.565\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14045, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:23.171, tt:23.171\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13748, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:21.687, tt:43.373\n",
      "Ep:2, loss:0.00026, loss_test:0.13166, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:20.931, tt:62.792\n",
      "Ep:3, loss:0.00025, loss_test:0.12578, lr:1.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:22.221, tt:88.884\n",
      "Ep:4, loss:0.00024, loss_test:0.12577, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:22.839, tt:114.194\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12403, lr:1.00e-02, fs:0.64602 (r=0.737,p=0.575),  time:23.216, tt:139.294\n",
      "Ep:6, loss:0.00023, loss_test:0.12260, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:23.497, tt:164.478\n",
      "Ep:7, loss:0.00022, loss_test:0.12059, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:23.666, tt:189.326\n",
      "Ep:8, loss:0.00021, loss_test:0.11990, lr:1.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:23.998, tt:215.978\n",
      "Ep:9, loss:0.00020, loss_test:0.11655, lr:1.00e-02, fs:0.65753 (r=0.727,p=0.600),  time:24.106, tt:241.056\n",
      "Ep:10, loss:0.00020, loss_test:0.11443, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:24.065, tt:264.712\n",
      "Ep:11, loss:0.00019, loss_test:0.11319, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:24.208, tt:290.499\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.11108, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:24.194, tt:314.525\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.10876, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:24.238, tt:339.328\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10651, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:24.254, tt:363.816\n",
      "Ep:15, loss:0.00016, loss_test:0.10498, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:24.198, tt:387.166\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.10354, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:24.340, tt:413.778\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10106, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:24.372, tt:438.692\n",
      "Ep:18, loss:0.00014, loss_test:0.10038, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:24.331, tt:462.288\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.09775, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:24.372, tt:487.430\n",
      "Ep:20, loss:0.00013, loss_test:0.09759, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:24.352, tt:511.402\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.09550, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:24.421, tt:537.258\n",
      "Ep:22, loss:0.00012, loss_test:0.09582, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:24.467, tt:562.745\n",
      "Ep:23, loss:0.00011, loss_test:0.09510, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:24.468, tt:587.229\n",
      "Ep:24, loss:0.00011, loss_test:0.09378, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:24.444, tt:611.093\n",
      "Ep:25, loss:0.00010, loss_test:0.09354, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.439, tt:635.409\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.09161, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.488, tt:661.186\n",
      "Ep:27, loss:0.00009, loss_test:0.09083, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.634, tt:689.743\n",
      "Ep:28, loss:0.00009, loss_test:0.08948, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:24.621, tt:713.995\n",
      "Ep:29, loss:0.00009, loss_test:0.09091, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:24.637, tt:739.100\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.08917, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:24.670, tt:764.774\n",
      "Ep:31, loss:0.00008, loss_test:0.08946, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:24.674, tt:789.561\n",
      "Ep:32, loss:0.00008, loss_test:0.09038, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:24.678, tt:814.385\n",
      "Ep:33, loss:0.00007, loss_test:0.08877, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:24.665, tt:838.606\n",
      "Ep:34, loss:0.00007, loss_test:0.08939, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:24.678, tt:863.715\n",
      "Ep:35, loss:0.00007, loss_test:0.08967, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:24.688, tt:888.755\n",
      "Ep:36, loss:0.00006, loss_test:0.08841, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:24.756, tt:915.975\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.08864, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:24.733, tt:939.873\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00006, loss_test:0.08765, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:24.763, tt:965.767\n",
      "Ep:39, loss:0.00006, loss_test:0.09152, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:24.808, tt:992.308\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.08457, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:24.801, tt:1016.828\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.08630, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:24.771, tt:1040.382\n",
      "Ep:42, loss:0.00005, loss_test:0.09050, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:24.769, tt:1065.049\n",
      "Ep:43, loss:0.00005, loss_test:0.08370, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.807, tt:1091.508\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.09578, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:24.816, tt:1116.723\n",
      "Ep:45, loss:0.00004, loss_test:0.08188, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.801, tt:1140.847\n",
      "Ep:46, loss:0.00004, loss_test:0.09838, lr:1.00e-02, fs:0.72289 (r=0.606,p=0.896),  time:24.771, tt:1164.244\n",
      "Ep:47, loss:0.00004, loss_test:0.08408, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.759, tt:1188.435\n",
      "Ep:48, loss:0.00004, loss_test:0.09152, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:24.781, tt:1214.260\n",
      "Ep:49, loss:0.00004, loss_test:0.09015, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:24.861, tt:1243.051\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.08378, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:24.858, tt:1267.772\n",
      "Ep:51, loss:0.00003, loss_test:0.09460, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:24.858, tt:1292.593\n",
      "Ep:52, loss:0.00003, loss_test:0.08387, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:24.894, tt:1319.408\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.08728, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:24.951, tt:1347.369\n",
      "Ep:54, loss:0.00003, loss_test:0.09143, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:24.937, tt:1371.509\n",
      "Ep:55, loss:0.00003, loss_test:0.08474, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:24.969, tt:1398.248\n",
      "Ep:56, loss:0.00003, loss_test:0.08869, lr:1.00e-02, fs:0.75449 (r=0.636,p=0.926),  time:24.990, tt:1424.412\n",
      "Ep:57, loss:0.00003, loss_test:0.08729, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:24.991, tt:1449.488\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.08628, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:25.005, tt:1475.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00002, loss_test:0.08946, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:25.014, tt:1500.846\n",
      "Ep:60, loss:0.00002, loss_test:0.08649, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:25.011, tt:1525.665\n",
      "Ep:61, loss:0.00002, loss_test:0.08583, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.006, tt:1550.357\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.08672, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.019, tt:1576.213\n",
      "Ep:63, loss:0.00002, loss_test:0.08337, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.020, tt:1601.296\n",
      "Ep:64, loss:0.00002, loss_test:0.08775, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.001, tt:1625.089\n",
      "Ep:65, loss:0.00002, loss_test:0.08311, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.004, tt:1650.232\n",
      "Ep:66, loss:0.00002, loss_test:0.08784, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:25.001, tt:1675.088\n",
      "Ep:67, loss:0.00002, loss_test:0.08531, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:25.004, tt:1700.278\n",
      "Ep:68, loss:0.00002, loss_test:0.08446, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:24.997, tt:1724.773\n",
      "Ep:69, loss:0.00001, loss_test:0.08717, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:25.004, tt:1750.248\n",
      "Ep:70, loss:0.00001, loss_test:0.08427, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.004, tt:1775.289\n",
      "Ep:71, loss:0.00001, loss_test:0.08651, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:25.001, tt:1800.075\n",
      "Ep:72, loss:0.00001, loss_test:0.08508, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:24.997, tt:1824.755\n",
      "Ep:73, loss:0.00001, loss_test:0.08406, lr:9.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.979, tt:1848.420\n",
      "Ep:74, loss:0.00001, loss_test:0.08553, lr:9.80e-03, fs:0.77381 (r=0.657,p=0.942),  time:25.029, tt:1877.151\n",
      "Ep:75, loss:0.00001, loss_test:0.08249, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.051, tt:1903.856\n",
      "Ep:76, loss:0.00001, loss_test:0.09076, lr:9.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:25.036, tt:1927.787\n",
      "Ep:77, loss:0.00001, loss_test:0.08231, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.026, tt:1951.996\n",
      "Ep:78, loss:0.00001, loss_test:0.08881, lr:9.41e-03, fs:0.75152 (r=0.626,p=0.939),  time:25.018, tt:1976.440\n",
      "Ep:79, loss:0.00001, loss_test:0.08387, lr:9.32e-03, fs:0.78824 (r=0.677,p=0.944),  time:25.017, tt:2001.383\n",
      "Ep:80, loss:0.00001, loss_test:0.08601, lr:9.23e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.001, tt:2025.116\n",
      "Ep:81, loss:0.00001, loss_test:0.08905, lr:9.14e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.996, tt:2049.648\n",
      "Ep:82, loss:0.00001, loss_test:0.08293, lr:9.04e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.997, tt:2074.731\n",
      "Ep:83, loss:0.00001, loss_test:0.08829, lr:8.95e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.998, tt:2099.808\n",
      "Ep:84, loss:0.00001, loss_test:0.08833, lr:8.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:25.010, tt:2125.815\n",
      "Ep:85, loss:0.00001, loss_test:0.08232, lr:8.78e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.013, tt:2151.119\n",
      "Ep:86, loss:0.00001, loss_test:0.08685, lr:8.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.005, tt:2175.464\n",
      "Ep:87, loss:0.00001, loss_test:0.08752, lr:8.60e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.984, tt:2198.588\n",
      "Ep:88, loss:0.00001, loss_test:0.08256, lr:8.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.950, tt:2220.505\n",
      "Ep:89, loss:0.00001, loss_test:0.08535, lr:8.43e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.906, tt:2241.515\n",
      "Ep:90, loss:0.00001, loss_test:0.08561, lr:8.35e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.865, tt:2262.724\n",
      "Ep:91, loss:0.00001, loss_test:0.08302, lr:8.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.816, tt:2283.093\n",
      "Ep:92, loss:0.00001, loss_test:0.08728, lr:8.18e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.785, tt:2304.985\n",
      "Ep:93, loss:0.00001, loss_test:0.08495, lr:8.10e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.762, tt:2327.632\n",
      "Ep:94, loss:0.00001, loss_test:0.08406, lr:8.02e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.716, tt:2348.045\n",
      "Ep:95, loss:0.00001, loss_test:0.08562, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.701, tt:2371.248\n",
      "Ep:96, loss:0.00001, loss_test:0.08404, lr:7.86e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.704, tt:2396.335\n",
      "Ep:97, loss:0.00001, loss_test:0.08565, lr:7.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.713, tt:2421.850\n",
      "Ep:98, loss:0.00001, loss_test:0.08676, lr:7.70e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.708, tt:2446.085\n",
      "Ep:99, loss:0.00001, loss_test:0.08375, lr:7.62e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.706, tt:2470.565\n",
      "Ep:100, loss:0.00001, loss_test:0.08441, lr:7.55e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.703, tt:2495.048\n",
      "Ep:101, loss:0.00001, loss_test:0.08501, lr:7.47e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.726, tt:2522.002\n",
      "Ep:102, loss:0.00001, loss_test:0.08298, lr:7.40e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.709, tt:2544.985\n",
      "Ep:103, loss:0.00001, loss_test:0.08575, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.715, tt:2570.334\n",
      "Ep:104, loss:0.00001, loss_test:0.08663, lr:7.25e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.710, tt:2594.596\n",
      "Ep:105, loss:0.00001, loss_test:0.08448, lr:7.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.718, tt:2620.092\n",
      "Ep:106, loss:0.00001, loss_test:0.08377, lr:7.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.715, tt:2644.534\n",
      "Ep:107, loss:0.00001, loss_test:0.08505, lr:7.03e-03, fs:0.79532 (r=0.687,p=0.944),  time:24.713, tt:2669.008\n",
      "Ep:108, loss:0.00001, loss_test:0.08589, lr:6.96e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.725, tt:2695.035\n",
      "Ep:109, loss:0.00001, loss_test:0.08299, lr:6.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.757, tt:2723.271\n",
      "Ep:110, loss:0.00000, loss_test:0.08652, lr:6.83e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.771, tt:2749.594\n",
      "Ep:111, loss:0.00000, loss_test:0.08490, lr:6.76e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.765, tt:2773.703\n",
      "Ep:112, loss:0.00000, loss_test:0.08454, lr:6.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.779, tt:2800.041\n",
      "Ep:113, loss:0.00000, loss_test:0.08375, lr:6.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.786, tt:2825.584\n",
      "Ep:114, loss:0.00000, loss_test:0.08399, lr:6.56e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.801, tt:2852.075\n",
      "Ep:115, loss:0.00000, loss_test:0.08432, lr:6.49e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.800, tt:2876.752\n",
      "Ep:116, loss:0.00000, loss_test:0.08341, lr:6.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.802, tt:2901.775\n",
      "Ep:117, loss:0.00000, loss_test:0.08420, lr:6.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.793, tt:2925.593\n",
      "Ep:118, loss:0.00000, loss_test:0.08474, lr:6.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.798, tt:2951.003\n",
      "Ep:119, loss:0.00000, loss_test:0.08373, lr:6.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.803, tt:2976.379\n",
      "Ep:120, loss:0.00000, loss_test:0.08469, lr:6.17e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.799, tt:3000.674\n",
      "Ep:121, loss:0.00000, loss_test:0.08505, lr:6.11e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.808, tt:3026.547\n",
      "Ep:122, loss:0.00000, loss_test:0.08380, lr:6.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.803, tt:3050.826\n",
      "Ep:123, loss:0.00000, loss_test:0.08458, lr:5.99e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.795, tt:3074.541\n",
      "Ep:124, loss:0.00000, loss_test:0.08504, lr:5.93e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.791, tt:3098.902\n",
      "Ep:125, loss:0.00000, loss_test:0.08339, lr:5.87e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.806, tt:3125.550\n",
      "Ep:126, loss:0.00000, loss_test:0.08390, lr:5.81e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.800, tt:3149.644\n",
      "Ep:127, loss:0.00000, loss_test:0.08385, lr:5.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.803, tt:3174.811\n",
      "Ep:128, loss:0.00000, loss_test:0.08424, lr:5.70e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.798, tt:3198.910\n",
      "Ep:129, loss:0.00000, loss_test:0.08456, lr:5.64e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.807, tt:3224.912\n",
      "Ep:130, loss:0.00000, loss_test:0.08333, lr:5.58e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.811, tt:3250.302\n",
      "Ep:131, loss:0.00000, loss_test:0.08455, lr:5.53e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.797, tt:3273.194\n",
      "Ep:132, loss:0.00000, loss_test:0.08475, lr:5.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:24.779, tt:3295.655\n",
      "Ep:133, loss:0.00000, loss_test:0.08394, lr:5.42e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.768, tt:3318.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.08410, lr:5.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.760, tt:3342.659\n",
      "Ep:135, loss:0.00000, loss_test:0.08361, lr:5.31e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.759, tt:3367.245\n",
      "Ep:136, loss:0.00000, loss_test:0.08372, lr:5.26e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.750, tt:3390.756\n",
      "Ep:137, loss:0.00000, loss_test:0.08439, lr:5.20e-03, fs:0.78824 (r=0.677,p=0.944),  time:24.743, tt:3414.509\n",
      "Ep:138, loss:0.00000, loss_test:0.08391, lr:5.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.743, tt:3439.329\n",
      "Ep:139, loss:0.00000, loss_test:0.08413, lr:5.10e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.741, tt:3463.692\n",
      "Ep:140, loss:0.00000, loss_test:0.08423, lr:5.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.741, tt:3488.492\n",
      "Ep:141, loss:0.00000, loss_test:0.08376, lr:5.00e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.735, tt:3512.379\n",
      "Ep:142, loss:0.00000, loss_test:0.08355, lr:4.95e-03, fs:0.84270 (r=0.758,p=0.949),  time:24.741, tt:3538.027\n",
      "Ep:143, loss:0.00000, loss_test:0.08369, lr:4.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.743, tt:3562.970\n",
      "Ep:144, loss:0.00000, loss_test:0.08388, lr:4.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:24.751, tt:3588.873\n",
      "Ep:145, loss:0.00000, loss_test:0.08378, lr:4.80e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.744, tt:3612.569\n",
      "Ep:146, loss:0.00000, loss_test:0.08474, lr:4.75e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.733, tt:3635.781\n",
      "Ep:147, loss:0.00000, loss_test:0.08524, lr:4.71e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.743, tt:3661.987\n",
      "Ep:148, loss:0.00000, loss_test:0.08400, lr:4.66e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.734, tt:3685.415\n",
      "Ep:149, loss:0.00000, loss_test:0.08366, lr:4.61e-03, fs:0.83616 (r=0.747,p=0.949),  time:24.737, tt:3710.524\n",
      "Ep:150, loss:0.00000, loss_test:0.08444, lr:4.57e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.735, tt:3735.036\n",
      "Ep:151, loss:0.00000, loss_test:0.08423, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.731, tt:3759.178\n",
      "Ep:152, loss:0.00000, loss_test:0.08438, lr:4.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:24.726, tt:3783.081\n",
      "Ep:153, loss:0.00000, loss_test:0.08426, lr:4.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:24.728, tt:3808.145\n",
      "Ep:154, loss:0.00000, loss_test:0.08345, lr:4.39e-03, fs:0.85556 (r=0.778,p=0.951),  time:24.719, tt:3831.441\n",
      "Ep:155, loss:0.00000, loss_test:0.08419, lr:4.34e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.715, tt:3855.617\n",
      "Ep:156, loss:0.00000, loss_test:0.08378, lr:4.30e-03, fs:0.82955 (r=0.737,p=0.948),  time:24.714, tt:3880.082\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13554, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:21.839, tt:21.839\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13120, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:22.220, tt:44.440\n",
      "Ep:2, loss:0.00027, loss_test:0.12300, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:21.708, tt:65.123\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11262, lr:1.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:22.312, tt:89.247\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.10769, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:22.847, tt:114.237\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.10442, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:22.948, tt:137.686\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10108, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:23.479, tt:164.354\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.09901, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:23.302, tt:186.415\n",
      "Ep:8, loss:0.00022, loss_test:0.09441, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:23.564, tt:212.076\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09334, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:23.474, tt:234.743\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09324, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:23.527, tt:258.795\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09122, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:23.626, tt:283.508\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.08877, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:23.589, tt:306.658\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.08753, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:23.563, tt:329.887\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08677, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:23.538, tt:353.074\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08547, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:23.592, tt:377.475\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08302, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:23.533, tt:400.060\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08201, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:23.819, tt:428.739\n",
      "Ep:18, loss:0.00014, loss_test:0.08227, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:23.796, tt:452.119\n",
      "Ep:19, loss:0.00013, loss_test:0.07906, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:23.862, tt:477.242\n",
      "Ep:20, loss:0.00013, loss_test:0.07726, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:23.814, tt:500.091\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07745, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:23.767, tt:522.873\n",
      "Ep:22, loss:0.00012, loss_test:0.07493, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:23.826, tt:548.002\n",
      "Ep:23, loss:0.00011, loss_test:0.07326, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:23.864, tt:572.743\n",
      "Ep:24, loss:0.00011, loss_test:0.07373, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:23.921, tt:598.034\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.07135, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:23.935, tt:622.313\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07067, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:23.956, tt:646.820\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.06949, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:23.988, tt:671.650\n",
      "Ep:28, loss:0.00009, loss_test:0.06904, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:24.071, tt:698.058\n",
      "Ep:29, loss:0.00008, loss_test:0.06738, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:24.089, tt:722.682\n",
      "Ep:30, loss:0.00008, loss_test:0.06734, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:24.122, tt:747.780\n",
      "Ep:31, loss:0.00008, loss_test:0.06505, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:24.062, tt:769.998\n",
      "Ep:32, loss:0.00007, loss_test:0.06596, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:24.029, tt:792.950\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.06553, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:24.033, tt:817.114\n",
      "Ep:34, loss:0.00007, loss_test:0.06379, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:24.039, tt:841.378\n",
      "Ep:35, loss:0.00007, loss_test:0.06692, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:24.048, tt:865.714\n",
      "Ep:36, loss:0.00006, loss_test:0.06370, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:24.001, tt:888.046\n",
      "Ep:37, loss:0.00006, loss_test:0.06524, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:24.074, tt:914.797\n",
      "Ep:38, loss:0.00006, loss_test:0.06303, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:24.071, tt:938.765\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.06461, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:24.098, tt:963.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00005, loss_test:0.06294, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:24.099, tt:988.039\n",
      "Ep:41, loss:0.00005, loss_test:0.06308, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.140, tt:1013.891\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06254, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.143, tt:1038.155\n",
      "Ep:43, loss:0.00005, loss_test:0.06112, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:24.158, tt:1062.935\n",
      "Ep:44, loss:0.00005, loss_test:0.06191, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:24.114, tt:1085.123\n",
      "Ep:45, loss:0.00004, loss_test:0.06073, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.070, tt:1107.215\n",
      "Ep:46, loss:0.00004, loss_test:0.06118, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.063, tt:1130.951\n",
      "Ep:47, loss:0.00004, loss_test:0.06041, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.093, tt:1156.455\n",
      "Ep:48, loss:0.00004, loss_test:0.05936, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:24.113, tt:1181.532\n",
      "Ep:49, loss:0.00004, loss_test:0.06187, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:24.090, tt:1204.493\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.05897, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.085, tt:1228.345\n",
      "Ep:51, loss:0.00004, loss_test:0.06071, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.085, tt:1252.401\n",
      "Ep:52, loss:0.00004, loss_test:0.06102, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.098, tt:1277.202\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.05813, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:24.109, tt:1301.875\n",
      "Ep:54, loss:0.00003, loss_test:0.06156, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.147, tt:1328.112\n",
      "Ep:55, loss:0.00003, loss_test:0.06037, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.151, tt:1352.463\n",
      "Ep:56, loss:0.00003, loss_test:0.05874, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:24.144, tt:1376.189\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.06199, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.201, tt:1403.636\n",
      "Ep:58, loss:0.00003, loss_test:0.05749, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:24.174, tt:1426.262\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.05966, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:24.198, tt:1451.904\n",
      "Ep:60, loss:0.00003, loss_test:0.05799, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:24.213, tt:1476.967\n",
      "Ep:61, loss:0.00002, loss_test:0.05911, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.223, tt:1501.819\n",
      "Ep:62, loss:0.00002, loss_test:0.05795, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:24.210, tt:1525.246\n",
      "Ep:63, loss:0.00002, loss_test:0.05534, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:24.206, tt:1549.174\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.05903, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.185, tt:1572.030\n",
      "Ep:65, loss:0.00002, loss_test:0.05769, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:24.213, tt:1598.031\n",
      "Ep:66, loss:0.00002, loss_test:0.05687, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.208, tt:1621.913\n",
      "Ep:67, loss:0.00002, loss_test:0.05817, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:24.227, tt:1647.417\n",
      "Ep:68, loss:0.00002, loss_test:0.05705, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:24.235, tt:1672.197\n",
      "Ep:69, loss:0.00002, loss_test:0.05940, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.267, tt:1698.724\n",
      "Ep:70, loss:0.00002, loss_test:0.05598, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:24.266, tt:1722.874\n",
      "Ep:71, loss:0.00002, loss_test:0.05703, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.279, tt:1748.089\n",
      "Ep:72, loss:0.00002, loss_test:0.05611, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.294, tt:1773.498\n",
      "Ep:73, loss:0.00002, loss_test:0.05459, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:24.310, tt:1798.962\n",
      "Ep:74, loss:0.00002, loss_test:0.05684, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:24.305, tt:1822.911\n",
      "Ep:75, loss:0.00001, loss_test:0.05579, lr:9.90e-03, fs:0.89130 (r=0.828,p=0.965),  time:24.282, tt:1845.410\n",
      "Ep:76, loss:0.00001, loss_test:0.05439, lr:9.80e-03, fs:0.89130 (r=0.828,p=0.965),  time:24.282, tt:1869.743\n",
      "Ep:77, loss:0.00002, loss_test:0.05896, lr:9.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.317, tt:1896.704\n",
      "Ep:78, loss:0.00002, loss_test:0.05579, lr:9.61e-03, fs:0.89617 (r=0.828,p=0.976),  time:24.325, tt:1921.707\n",
      "Ep:79, loss:0.00002, loss_test:0.05480, lr:9.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:24.319, tt:1945.531\n",
      "Ep:80, loss:0.00002, loss_test:0.06070, lr:9.41e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.327, tt:1970.465\n",
      "Ep:81, loss:0.00001, loss_test:0.05363, lr:9.32e-03, fs:0.90323 (r=0.848,p=0.966),  time:24.315, tt:1993.813\n",
      "Ep:82, loss:0.00001, loss_test:0.05787, lr:9.23e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.311, tt:2017.846\n",
      "Ep:83, loss:0.00001, loss_test:0.05490, lr:9.14e-03, fs:0.89730 (r=0.838,p=0.965),  time:24.326, tt:2043.383\n",
      "Ep:84, loss:0.00001, loss_test:0.05512, lr:9.04e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.319, tt:2067.090\n",
      "Ep:85, loss:0.00001, loss_test:0.05604, lr:8.95e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.315, tt:2091.116\n",
      "Ep:86, loss:0.00001, loss_test:0.05560, lr:8.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.311, tt:2115.088\n",
      "Ep:87, loss:0.00001, loss_test:0.05450, lr:8.78e-03, fs:0.89617 (r=0.828,p=0.976),  time:24.335, tt:2141.499\n",
      "Ep:88, loss:0.00001, loss_test:0.05602, lr:8.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.358, tt:2167.879\n",
      "Ep:89, loss:0.00001, loss_test:0.05635, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.351, tt:2191.619\n",
      "Ep:90, loss:0.00001, loss_test:0.05386, lr:8.51e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.371, tt:2217.783\n",
      "Ep:91, loss:0.00001, loss_test:0.05514, lr:8.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.393, tt:2244.202\n",
      "Ep:92, loss:0.00001, loss_test:0.05463, lr:8.35e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.395, tt:2268.702\n",
      "Ep:93, loss:0.00001, loss_test:0.05516, lr:8.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.406, tt:2294.145\n",
      "Ep:94, loss:0.00001, loss_test:0.05444, lr:8.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.410, tt:2318.963\n",
      "Ep:95, loss:0.00001, loss_test:0.05577, lr:8.10e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.445, tt:2346.706\n",
      "Ep:96, loss:0.00001, loss_test:0.05433, lr:8.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.453, tt:2371.914\n",
      "Ep:97, loss:0.00001, loss_test:0.05573, lr:7.94e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.458, tt:2396.873\n",
      "Ep:98, loss:0.00001, loss_test:0.05558, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.444, tt:2419.981\n",
      "Ep:99, loss:0.00001, loss_test:0.05537, lr:7.78e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.439, tt:2443.875\n",
      "Ep:100, loss:0.00001, loss_test:0.05642, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.428, tt:2467.193\n",
      "Ep:101, loss:0.00001, loss_test:0.05462, lr:7.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.419, tt:2490.760\n",
      "Ep:102, loss:0.00001, loss_test:0.05616, lr:7.55e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.419, tt:2515.200\n",
      "Ep:103, loss:0.00001, loss_test:0.05481, lr:7.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:24.429, tt:2540.619\n",
      "Ep:104, loss:0.00001, loss_test:0.05564, lr:7.40e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.447, tt:2566.947\n",
      "Ep:105, loss:0.00001, loss_test:0.05468, lr:7.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.442, tt:2590.839\n",
      "Ep:106, loss:0.00001, loss_test:0.05619, lr:7.25e-03, fs:0.89503 (r=0.818,p=0.988),  time:24.443, tt:2615.439\n",
      "Ep:107, loss:0.00001, loss_test:0.05768, lr:7.18e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.419, tt:2637.199\n",
      "Ep:108, loss:0.00001, loss_test:0.05557, lr:7.11e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.422, tt:2662.029\n",
      "Ep:109, loss:0.00001, loss_test:0.05550, lr:7.03e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.406, tt:2684.713\n",
      "Ep:110, loss:0.00001, loss_test:0.05631, lr:6.96e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.409, tt:2709.416\n",
      "Ep:111, loss:0.00001, loss_test:0.05539, lr:6.89e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.395, tt:2732.284\n",
      "Ep:112, loss:0.00001, loss_test:0.05524, lr:6.83e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.395, tt:2756.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00001, loss_test:0.05608, lr:6.76e-03, fs:0.88398 (r=0.808,p=0.976),  time:24.391, tt:2780.613\n",
      "Ep:114, loss:0.00001, loss_test:0.05584, lr:6.69e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.406, tt:2806.634\n",
      "Ep:115, loss:0.00001, loss_test:0.05560, lr:6.62e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.405, tt:2830.934\n",
      "Ep:116, loss:0.00000, loss_test:0.05680, lr:6.56e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.400, tt:2854.792\n",
      "Ep:117, loss:0.00000, loss_test:0.05671, lr:6.49e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.411, tt:2880.540\n",
      "Ep:118, loss:0.00000, loss_test:0.05561, lr:6.43e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.413, tt:2905.163\n",
      "Ep:119, loss:0.00000, loss_test:0.05682, lr:6.36e-03, fs:0.88268 (r=0.798,p=0.988),  time:24.424, tt:2930.907\n",
      "Ep:120, loss:0.00000, loss_test:0.05604, lr:6.30e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.414, tt:2954.106\n",
      "Ep:121, loss:0.00000, loss_test:0.05691, lr:6.24e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.413, tt:2978.404\n",
      "Ep:122, loss:0.00000, loss_test:0.05670, lr:6.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.415, tt:3003.009\n",
      "Ep:123, loss:0.00000, loss_test:0.05662, lr:6.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.403, tt:3025.941\n",
      "Ep:124, loss:0.00000, loss_test:0.05663, lr:6.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.408, tt:3051.018\n",
      "Ep:125, loss:0.00000, loss_test:0.05633, lr:5.99e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.409, tt:3075.503\n",
      "Ep:126, loss:0.00000, loss_test:0.05692, lr:5.93e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.414, tt:3100.628\n",
      "Ep:127, loss:0.00000, loss_test:0.05654, lr:5.87e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.402, tt:3123.480\n",
      "Ep:128, loss:0.00000, loss_test:0.05708, lr:5.81e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.403, tt:3147.971\n",
      "Ep:129, loss:0.00000, loss_test:0.05725, lr:5.75e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.409, tt:3173.168\n",
      "Ep:130, loss:0.00000, loss_test:0.05633, lr:5.70e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.412, tt:3197.940\n",
      "Ep:131, loss:0.00000, loss_test:0.05737, lr:5.64e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.397, tt:3220.439\n",
      "Ep:132, loss:0.00000, loss_test:0.05750, lr:5.58e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.387, tt:3243.508\n",
      "Ep:133, loss:0.00000, loss_test:0.05741, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.384, tt:3267.463\n",
      "Ep:134, loss:0.00000, loss_test:0.05663, lr:5.47e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.379, tt:3291.223\n",
      "Ep:135, loss:0.00000, loss_test:0.05716, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.389, tt:3316.907\n",
      "Ep:136, loss:0.00000, loss_test:0.05759, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.377, tt:3339.698\n",
      "Ep:137, loss:0.00000, loss_test:0.05706, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.373, tt:3363.439\n",
      "Ep:138, loss:0.00000, loss_test:0.05701, lr:5.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.363, tt:3386.487\n",
      "Ep:139, loss:0.00000, loss_test:0.05716, lr:5.20e-03, fs:0.87006 (r=0.778,p=0.987),  time:24.372, tt:3412.030\n",
      "Ep:140, loss:0.00000, loss_test:0.05739, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.368, tt:3435.899\n",
      "Ep:141, loss:0.00000, loss_test:0.05730, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.374, tt:3461.161\n",
      "Ep:142, loss:0.00000, loss_test:0.05691, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.378, tt:3486.083\n",
      "Ep:143, loss:0.00000, loss_test:0.05790, lr:5.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.400, tt:3513.581\n",
      "Ep:144, loss:0.00000, loss_test:0.05751, lr:4.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.413, tt:3539.855\n",
      "Ep:145, loss:0.00000, loss_test:0.05688, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.417, tt:3564.919\n",
      "Ep:146, loss:0.00000, loss_test:0.05757, lr:4.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.419, tt:3589.545\n",
      "Ep:147, loss:0.00000, loss_test:0.05742, lr:4.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.421, tt:3614.312\n",
      "Ep:148, loss:0.00000, loss_test:0.05736, lr:4.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.422, tt:3638.843\n",
      "Ep:149, loss:0.00000, loss_test:0.05721, lr:4.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.412, tt:3661.827\n",
      "Ep:150, loss:0.00000, loss_test:0.05726, lr:4.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.408, tt:3685.576\n",
      "Ep:151, loss:0.00000, loss_test:0.05744, lr:4.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.397, tt:3708.369\n",
      "Ep:152, loss:0.00000, loss_test:0.05735, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.392, tt:3731.971\n",
      "Ep:153, loss:0.00000, loss_test:0.05724, lr:4.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.388, tt:3755.810\n",
      "Ep:154, loss:0.00000, loss_test:0.05741, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.388, tt:3780.163\n",
      "Ep:155, loss:0.00000, loss_test:0.05724, lr:4.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.392, tt:3805.122\n",
      "Ep:156, loss:0.00000, loss_test:0.05718, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:24.409, tt:3832.219\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14167, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:33.078, tt:33.078\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13937, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:33.492, tt:66.984\n",
      "Ep:2, loss:0.00027, loss_test:0.13524, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:36.685, tt:110.055\n",
      "Ep:3, loss:0.00025, loss_test:0.12865, lr:1.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:37.919, tt:151.678\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.12221, lr:1.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:39.089, tt:195.443\n",
      "Ep:5, loss:0.00022, loss_test:0.11953, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:39.852, tt:239.111\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00021, loss_test:0.11750, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:39.965, tt:279.752\n",
      "Ep:7, loss:0.00021, loss_test:0.11484, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:40.539, tt:324.308\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00020, loss_test:0.11335, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:41.068, tt:369.609\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.11213, lr:1.00e-02, fs:0.68868 (r=0.737,p=0.646),  time:41.334, tt:413.344\n",
      "Ep:10, loss:0.00019, loss_test:0.11001, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:41.518, tt:456.695\n",
      "Ep:11, loss:0.00018, loss_test:0.11000, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:41.610, tt:499.318\n",
      "Ep:12, loss:0.00018, loss_test:0.10908, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:41.519, tt:539.750\n",
      "Ep:13, loss:0.00017, loss_test:0.10774, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:41.580, tt:582.121\n",
      "Ep:14, loss:0.00017, loss_test:0.10804, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:41.602, tt:624.033\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.10856, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:41.743, tt:667.896\n",
      "Ep:16, loss:0.00016, loss_test:0.10724, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:42.010, tt:714.171\n",
      "Ep:17, loss:0.00016, loss_test:0.10688, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:42.062, tt:757.108\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10665, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:42.104, tt:799.975\n",
      "Ep:19, loss:0.00015, loss_test:0.10714, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:42.053, tt:841.051\n",
      "Ep:20, loss:0.00015, loss_test:0.10684, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:42.082, tt:883.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00014, loss_test:0.10588, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:42.157, tt:927.449\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.10624, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:42.188, tt:970.321\n",
      "Ep:23, loss:0.00014, loss_test:0.10595, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.165, tt:1011.952\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.10437, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:42.163, tt:1054.083\n",
      "Ep:25, loss:0.00013, loss_test:0.10484, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.221, tt:1097.735\n",
      "Ep:26, loss:0.00013, loss_test:0.10568, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.228, tt:1140.155\n",
      "Ep:27, loss:0.00013, loss_test:0.10257, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:42.194, tt:1181.425\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.10413, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.161, tt:1222.658\n",
      "Ep:29, loss:0.00012, loss_test:0.10314, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:42.131, tt:1263.935\n",
      "Ep:30, loss:0.00012, loss_test:0.10236, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:42.047, tt:1303.472\n",
      "Ep:31, loss:0.00012, loss_test:0.10370, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:42.042, tt:1345.360\n",
      "Ep:32, loss:0.00012, loss_test:0.10134, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.064, tt:1388.102\n",
      "Ep:33, loss:0.00011, loss_test:0.10278, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:42.075, tt:1430.546\n",
      "Ep:34, loss:0.00011, loss_test:0.10266, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.047, tt:1471.646\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.10014, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:42.080, tt:1514.867\n",
      "Ep:36, loss:0.00011, loss_test:0.10268, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.122, tt:1558.503\n",
      "Ep:37, loss:0.00011, loss_test:0.10054, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:42.090, tt:1599.420\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.10320, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.111, tt:1642.325\n",
      "Ep:39, loss:0.00010, loss_test:0.10026, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:42.157, tt:1686.277\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.10230, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:42.167, tt:1728.866\n",
      "Ep:41, loss:0.00010, loss_test:0.10040, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:42.186, tt:1771.798\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.10010, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:42.188, tt:1814.086\n",
      "Ep:43, loss:0.00009, loss_test:0.10091, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:42.190, tt:1856.353\n",
      "Ep:44, loss:0.00009, loss_test:0.10037, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:42.200, tt:1898.978\n",
      "Ep:45, loss:0.00009, loss_test:0.10099, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:42.182, tt:1940.366\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.09950, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:42.194, tt:1983.096\n",
      "Ep:47, loss:0.00009, loss_test:0.10001, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:42.226, tt:2026.848\n",
      "Ep:48, loss:0.00009, loss_test:0.09958, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:42.253, tt:2070.410\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.10006, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:42.285, tt:2114.273\n",
      "Ep:50, loss:0.00008, loss_test:0.09893, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:42.276, tt:2156.090\n",
      "Ep:51, loss:0.00008, loss_test:0.09815, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:42.305, tt:2199.877\n",
      "Ep:52, loss:0.00008, loss_test:0.09945, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:42.333, tt:2243.669\n",
      "Ep:53, loss:0.00008, loss_test:0.09758, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:42.359, tt:2287.405\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.09796, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:42.342, tt:2328.837\n",
      "Ep:55, loss:0.00007, loss_test:0.09790, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:42.318, tt:2369.804\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.09614, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:42.337, tt:2413.226\n",
      "Ep:57, loss:0.00007, loss_test:0.09799, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:42.341, tt:2455.793\n",
      "Ep:58, loss:0.00007, loss_test:0.09766, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:42.344, tt:2498.289\n",
      "Ep:59, loss:0.00007, loss_test:0.09684, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:42.361, tt:2541.680\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00007, loss_test:0.09604, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:42.378, tt:2585.080\n",
      "Ep:61, loss:0.00006, loss_test:0.09585, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:42.388, tt:2628.056\n",
      "Ep:62, loss:0.00006, loss_test:0.09598, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:42.350, tt:2668.041\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.09698, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:42.318, tt:2708.381\n",
      "Ep:64, loss:0.00008, loss_test:0.09977, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:42.286, tt:2748.623\n",
      "Ep:65, loss:0.00006, loss_test:0.09755, lr:1.00e-02, fs:0.70238 (r=0.596,p=0.855),  time:42.288, tt:2791.037\n",
      "Ep:66, loss:0.00007, loss_test:0.09914, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:42.319, tt:2835.373\n",
      "Ep:67, loss:0.00008, loss_test:0.09855, lr:1.00e-02, fs:0.71084 (r=0.596,p=0.881),  time:42.309, tt:2877.024\n",
      "Ep:68, loss:0.00009, loss_test:0.09254, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.321, tt:2920.131\n",
      "Ep:69, loss:0.00007, loss_test:0.09896, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:42.365, tt:2965.571\n",
      "Ep:70, loss:0.00007, loss_test:0.09127, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:42.358, tt:3007.442\n",
      "Ep:71, loss:0.00006, loss_test:0.09072, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:42.370, tt:3050.609\n",
      "Ep:72, loss:0.00006, loss_test:0.09560, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:42.383, tt:3093.964\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00006, loss_test:0.08993, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.384, tt:3136.431\n",
      "Ep:74, loss:0.00006, loss_test:0.09290, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:42.408, tt:3180.574\n",
      "Ep:75, loss:0.00005, loss_test:0.09053, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:42.380, tt:3220.914\n",
      "Ep:76, loss:0.00005, loss_test:0.09168, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:42.364, tt:3262.065\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.09163, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:42.367, tt:3304.665\n",
      "Ep:78, loss:0.00005, loss_test:0.09125, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:42.363, tt:3346.683\n",
      "Ep:79, loss:0.00005, loss_test:0.09120, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:42.356, tt:3388.502\n",
      "Ep:80, loss:0.00005, loss_test:0.09087, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:42.345, tt:3429.962\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.08914, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:42.362, tt:3473.647\n",
      "Ep:82, loss:0.00005, loss_test:0.08862, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:42.351, tt:3515.170\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00005, loss_test:0.09351, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:42.346, tt:3557.058\n",
      "Ep:84, loss:0.00004, loss_test:0.08949, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:42.363, tt:3600.887\n",
      "Ep:85, loss:0.00004, loss_test:0.09116, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:42.377, tt:3644.415\n",
      "Ep:86, loss:0.00004, loss_test:0.09271, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:42.374, tt:3686.539\n",
      "Ep:87, loss:0.00004, loss_test:0.08830, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:42.395, tt:3730.790\n",
      "Ep:88, loss:0.00004, loss_test:0.09021, lr:1.00e-02, fs:0.70659 (r=0.596,p=0.868),  time:42.414, tt:3774.889\n",
      "Ep:89, loss:0.00004, loss_test:0.09070, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:42.437, tt:3819.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00004, loss_test:0.08657, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:42.429, tt:3861.060\n",
      "Ep:91, loss:0.00004, loss_test:0.09543, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.436, tt:3904.067\n",
      "Ep:92, loss:0.00004, loss_test:0.08627, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:42.422, tt:3945.202\n",
      "Ep:93, loss:0.00004, loss_test:0.09425, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:42.419, tt:3987.402\n",
      "Ep:94, loss:0.00004, loss_test:0.09301, lr:9.90e-03, fs:0.71429 (r=0.606,p=0.870),  time:42.416, tt:4029.493\n",
      "Ep:95, loss:0.00004, loss_test:0.09061, lr:9.80e-03, fs:0.79558 (r=0.727,p=0.878),  time:42.402, tt:4070.552\n",
      "Ep:96, loss:0.00004, loss_test:0.09020, lr:9.70e-03, fs:0.74713 (r=0.657,p=0.867),  time:42.408, tt:4113.531\n",
      "Ep:97, loss:0.00004, loss_test:0.09166, lr:9.61e-03, fs:0.75581 (r=0.657,p=0.890),  time:42.396, tt:4154.817\n",
      "Ep:98, loss:0.00003, loss_test:0.09153, lr:9.51e-03, fs:0.71006 (r=0.606,p=0.857),  time:42.408, tt:4198.409\n",
      "Ep:99, loss:0.00003, loss_test:0.09228, lr:9.41e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.417, tt:4241.654\n",
      "Ep:100, loss:0.00003, loss_test:0.09284, lr:9.32e-03, fs:0.72289 (r=0.606,p=0.896),  time:42.404, tt:4282.776\n",
      "Ep:101, loss:0.00003, loss_test:0.09421, lr:9.23e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.413, tt:4326.136\n",
      "Ep:102, loss:0.00003, loss_test:0.08987, lr:9.14e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.424, tt:4369.700\n",
      "Ep:103, loss:0.00003, loss_test:0.09653, lr:9.04e-03, fs:0.70732 (r=0.586,p=0.892),  time:42.422, tt:4411.927\n",
      "Ep:104, loss:0.00003, loss_test:0.09132, lr:8.95e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.411, tt:4453.174\n",
      "Ep:105, loss:0.00003, loss_test:0.09136, lr:8.86e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.414, tt:4495.839\n",
      "Ep:106, loss:0.00003, loss_test:0.09469, lr:8.78e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.411, tt:4538.025\n",
      "Ep:107, loss:0.00003, loss_test:0.09248, lr:8.69e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.411, tt:4580.350\n",
      "Ep:108, loss:0.00003, loss_test:0.09142, lr:8.60e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.414, tt:4623.160\n",
      "Ep:109, loss:0.00003, loss_test:0.09768, lr:8.51e-03, fs:0.71166 (r=0.586,p=0.906),  time:42.411, tt:4665.228\n",
      "Ep:110, loss:0.00003, loss_test:0.09014, lr:8.43e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.419, tt:4708.511\n",
      "Ep:111, loss:0.00003, loss_test:0.09578, lr:8.35e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.440, tt:4753.235\n",
      "Ep:112, loss:0.00003, loss_test:0.09114, lr:8.26e-03, fs:0.72727 (r=0.606,p=0.909),  time:42.444, tt:4796.143\n",
      "Ep:113, loss:0.00003, loss_test:0.09366, lr:8.18e-03, fs:0.72619 (r=0.616,p=0.884),  time:42.445, tt:4838.733\n",
      "Ep:114, loss:0.00003, loss_test:0.09501, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.465, tt:4883.485\n",
      "Ep:115, loss:0.00003, loss_test:0.09159, lr:8.02e-03, fs:0.81111 (r=0.737,p=0.901),  time:42.458, tt:4925.172\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00003, loss_test:0.09664, lr:8.02e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.449, tt:4966.503\n",
      "Ep:117, loss:0.00003, loss_test:0.09498, lr:8.02e-03, fs:0.71856 (r=0.606,p=0.882),  time:42.456, tt:5009.810\n",
      "Ep:118, loss:0.00003, loss_test:0.09387, lr:8.02e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.470, tt:5053.944\n",
      "Ep:119, loss:0.00003, loss_test:0.09501, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.457, tt:5094.828\n",
      "Ep:120, loss:0.00003, loss_test:0.09528, lr:8.02e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.481, tt:5140.259\n",
      "Ep:121, loss:0.00003, loss_test:0.09401, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.481, tt:5182.625\n",
      "Ep:122, loss:0.00003, loss_test:0.09470, lr:8.02e-03, fs:0.71856 (r=0.606,p=0.882),  time:42.480, tt:5225.040\n",
      "Ep:123, loss:0.00003, loss_test:0.09464, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.473, tt:5266.700\n",
      "Ep:124, loss:0.00003, loss_test:0.09461, lr:8.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.485, tt:5310.617\n",
      "Ep:125, loss:0.00002, loss_test:0.09216, lr:8.02e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.496, tt:5354.485\n",
      "Ep:126, loss:0.00002, loss_test:0.09688, lr:8.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.490, tt:5396.260\n",
      "Ep:127, loss:0.00002, loss_test:0.09109, lr:7.94e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.487, tt:5438.360\n",
      "Ep:128, loss:0.00002, loss_test:0.09939, lr:7.86e-03, fs:0.71250 (r=0.576,p=0.934),  time:42.482, tt:5480.215\n",
      "Ep:129, loss:0.00003, loss_test:0.09208, lr:7.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.495, tt:5524.402\n",
      "Ep:130, loss:0.00002, loss_test:0.09620, lr:7.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.492, tt:5566.438\n",
      "Ep:131, loss:0.00002, loss_test:0.09492, lr:7.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.491, tt:5608.846\n",
      "Ep:132, loss:0.00002, loss_test:0.09471, lr:7.55e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.505, tt:5653.146\n",
      "Ep:133, loss:0.00002, loss_test:0.09440, lr:7.47e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.502, tt:5695.320\n",
      "Ep:134, loss:0.00002, loss_test:0.09600, lr:7.40e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.509, tt:5738.715\n",
      "Ep:135, loss:0.00002, loss_test:0.09229, lr:7.32e-03, fs:0.73494 (r=0.616,p=0.910),  time:42.488, tt:5778.427\n",
      "Ep:136, loss:0.00002, loss_test:0.09625, lr:7.25e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.453, tt:5816.118\n",
      "Ep:137, loss:0.00002, loss_test:0.09280, lr:7.18e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.446, tt:5857.482\n",
      "Ep:138, loss:0.00002, loss_test:0.09744, lr:7.11e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.432, tt:5898.118\n",
      "Ep:139, loss:0.00002, loss_test:0.09318, lr:7.03e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.430, tt:5940.221\n",
      "Ep:140, loss:0.00002, loss_test:0.09414, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.465, tt:5987.568\n",
      "Ep:141, loss:0.00002, loss_test:0.09315, lr:6.89e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.475, tt:6031.499\n",
      "Ep:142, loss:0.00002, loss_test:0.09671, lr:6.83e-03, fs:0.71250 (r=0.576,p=0.934),  time:42.480, tt:6074.590\n",
      "Ep:143, loss:0.00002, loss_test:0.09345, lr:6.76e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.492, tt:6118.837\n",
      "Ep:144, loss:0.00002, loss_test:0.09561, lr:6.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:42.494, tt:6161.582\n",
      "Ep:145, loss:0.00002, loss_test:0.09279, lr:6.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.499, tt:6204.886\n",
      "Ep:146, loss:0.00002, loss_test:0.09563, lr:6.56e-03, fs:0.72393 (r=0.596,p=0.922),  time:42.498, tt:6247.260\n",
      "Ep:147, loss:0.00002, loss_test:0.09442, lr:6.49e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.516, tt:6292.422\n",
      "Ep:148, loss:0.00002, loss_test:0.09407, lr:6.43e-03, fs:0.73939 (r=0.616,p=0.924),  time:42.510, tt:6333.995\n",
      "Ep:149, loss:0.00002, loss_test:0.09408, lr:6.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:42.514, tt:6377.040\n",
      "Ep:150, loss:0.00002, loss_test:0.09661, lr:6.30e-03, fs:0.72393 (r=0.596,p=0.922),  time:42.511, tt:6419.131\n",
      "Ep:151, loss:0.00002, loss_test:0.09547, lr:6.24e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.510, tt:6461.504\n",
      "Ep:152, loss:0.00002, loss_test:0.09414, lr:6.17e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.530, tt:6507.164\n",
      "Ep:153, loss:0.00002, loss_test:0.09572, lr:6.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:42.529, tt:6549.456\n",
      "Ep:154, loss:0.00002, loss_test:0.09515, lr:6.05e-03, fs:0.72840 (r=0.596,p=0.937),  time:42.533, tt:6592.651\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13537, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.815, tt:34.815\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13151, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:34.618, tt:69.236\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12491, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:37.360, tt:112.080\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11417, lr:1.00e-02, fs:0.70896 (r=0.960,p=0.562),  time:39.054, tt:156.217\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00024, loss_test:0.10399, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:39.318, tt:196.592\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.09702, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:39.702, tt:238.212\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.09338, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.218, tt:281.528\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00021, loss_test:0.09394, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:40.504, tt:324.034\n",
      "Ep:8, loss:0.00021, loss_test:0.09161, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:40.709, tt:366.378\n",
      "Ep:9, loss:0.00020, loss_test:0.08896, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:40.996, tt:409.962\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.08929, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:41.179, tt:452.966\n",
      "Ep:11, loss:0.00019, loss_test:0.08757, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:41.263, tt:495.157\n",
      "Ep:12, loss:0.00018, loss_test:0.08444, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:41.442, tt:538.750\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.08286, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:41.763, tt:584.688\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08462, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:41.858, tt:627.863\n",
      "Ep:15, loss:0.00017, loss_test:0.08333, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:42.052, tt:672.834\n",
      "Ep:16, loss:0.00017, loss_test:0.08211, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:42.024, tt:714.403\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08318, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:42.038, tt:756.689\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.08277, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:42.143, tt:800.721\n",
      "Ep:19, loss:0.00015, loss_test:0.08118, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:42.226, tt:844.518\n",
      "Ep:20, loss:0.00015, loss_test:0.07976, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:42.326, tt:888.836\n",
      "Ep:21, loss:0.00015, loss_test:0.07969, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:42.377, tt:932.303\n",
      "Ep:22, loss:0.00014, loss_test:0.07928, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:42.411, tt:975.456\n",
      "Ep:23, loss:0.00014, loss_test:0.07866, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:42.480, tt:1019.528\n",
      "Ep:24, loss:0.00014, loss_test:0.07863, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:42.529, tt:1063.222\n",
      "Ep:25, loss:0.00013, loss_test:0.07890, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:42.622, tt:1108.181\n",
      "Ep:26, loss:0.00013, loss_test:0.07853, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:42.694, tt:1152.735\n",
      "Ep:27, loss:0.00013, loss_test:0.07704, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:42.720, tt:1196.163\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07828, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.685, tt:1237.873\n",
      "Ep:29, loss:0.00012, loss_test:0.07661, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:42.765, tt:1282.945\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07955, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:42.747, tt:1325.155\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07706, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:42.754, tt:1368.128\n",
      "Ep:32, loss:0.00012, loss_test:0.07803, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:42.774, tt:1411.542\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07770, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:42.842, tt:1456.633\n",
      "Ep:34, loss:0.00011, loss_test:0.07816, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:42.848, tt:1499.677\n",
      "Ep:35, loss:0.00011, loss_test:0.07974, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:42.857, tt:1542.868\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07539, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:42.845, tt:1585.258\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08078, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:42.896, tt:1630.042\n",
      "Ep:38, loss:0.00010, loss_test:0.07454, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:42.875, tt:1672.144\n",
      "Ep:39, loss:0.00010, loss_test:0.07959, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.865, tt:1714.581\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07472, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:42.927, tt:1760.012\n",
      "Ep:41, loss:0.00010, loss_test:0.08008, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:42.919, tt:1802.608\n",
      "Ep:42, loss:0.00009, loss_test:0.07479, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:42.902, tt:1844.800\n",
      "Ep:43, loss:0.00009, loss_test:0.07796, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:42.885, tt:1886.938\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.07542, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.895, tt:1930.275\n",
      "Ep:45, loss:0.00009, loss_test:0.07934, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:42.903, tt:1973.535\n",
      "Ep:46, loss:0.00008, loss_test:0.07649, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:42.934, tt:2017.880\n",
      "Ep:47, loss:0.00008, loss_test:0.07821, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.988, tt:2063.436\n",
      "Ep:48, loss:0.00008, loss_test:0.07789, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:43.040, tt:2108.951\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.07955, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:43.051, tt:2152.550\n",
      "Ep:50, loss:0.00008, loss_test:0.07841, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:43.079, tt:2197.014\n",
      "Ep:51, loss:0.00008, loss_test:0.08136, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:43.119, tt:2242.198\n",
      "Ep:52, loss:0.00007, loss_test:0.07595, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:43.141, tt:2286.454\n",
      "Ep:53, loss:0.00007, loss_test:0.08419, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:43.148, tt:2330.018\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07678, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:43.158, tt:2373.684\n",
      "Ep:55, loss:0.00007, loss_test:0.08073, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:43.167, tt:2417.336\n",
      "Ep:56, loss:0.00007, loss_test:0.07974, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:43.196, tt:2462.184\n",
      "Ep:57, loss:0.00007, loss_test:0.07980, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:43.184, tt:2504.660\n",
      "Ep:58, loss:0.00006, loss_test:0.08022, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:43.148, tt:2545.707\n",
      "Ep:59, loss:0.00006, loss_test:0.07891, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:43.150, tt:2589.027\n",
      "Ep:60, loss:0.00006, loss_test:0.08772, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:43.141, tt:2631.576\n",
      "Ep:61, loss:0.00006, loss_test:0.07616, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:43.129, tt:2673.997\n",
      "Ep:62, loss:0.00006, loss_test:0.08568, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:43.090, tt:2714.667\n",
      "Ep:63, loss:0.00006, loss_test:0.07997, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:43.059, tt:2755.798\n",
      "Ep:64, loss:0.00006, loss_test:0.08304, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:43.036, tt:2797.371\n",
      "Ep:65, loss:0.00006, loss_test:0.08518, lr:9.90e-03, fs:0.82979 (r=0.788,p=0.876),  time:43.031, tt:2840.014\n",
      "Ep:66, loss:0.00006, loss_test:0.08246, lr:9.80e-03, fs:0.84817 (r=0.818,p=0.880),  time:43.030, tt:2883.040\n",
      "Ep:67, loss:0.00005, loss_test:0.07792, lr:9.70e-03, fs:0.84264 (r=0.838,p=0.847),  time:43.050, tt:2927.392\n",
      "Ep:68, loss:0.00005, loss_test:0.08643, lr:9.61e-03, fs:0.83422 (r=0.788,p=0.886),  time:43.013, tt:2967.906\n",
      "Ep:69, loss:0.00005, loss_test:0.08109, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.920, tt:3004.365\n",
      "Ep:70, loss:0.00005, loss_test:0.08144, lr:9.41e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.811, tt:3039.613\n",
      "Ep:71, loss:0.00005, loss_test:0.08181, lr:9.32e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.803, tt:3081.836\n",
      "Ep:72, loss:0.00005, loss_test:0.08180, lr:9.23e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.791, tt:3123.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00005, loss_test:0.08330, lr:9.14e-03, fs:0.82979 (r=0.788,p=0.876),  time:42.754, tt:3163.819\n",
      "Ep:74, loss:0.00005, loss_test:0.08323, lr:9.04e-03, fs:0.85128 (r=0.838,p=0.865),  time:42.777, tt:3208.262\n",
      "Ep:75, loss:0.00005, loss_test:0.08323, lr:8.95e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.806, tt:3253.283\n",
      "Ep:76, loss:0.00004, loss_test:0.08303, lr:8.86e-03, fs:0.85864 (r=0.828,p=0.891),  time:42.827, tt:3297.654\n",
      "Ep:77, loss:0.00004, loss_test:0.08328, lr:8.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.839, tt:3341.461\n",
      "Ep:78, loss:0.00004, loss_test:0.08325, lr:8.69e-03, fs:0.86458 (r=0.838,p=0.892),  time:42.835, tt:3383.969\n",
      "Ep:79, loss:0.00004, loss_test:0.08299, lr:8.60e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.889, tt:3431.157\n",
      "Ep:80, loss:0.00004, loss_test:0.08630, lr:8.51e-03, fs:0.82353 (r=0.778,p=0.875),  time:42.882, tt:3473.480\n",
      "Ep:81, loss:0.00004, loss_test:0.08254, lr:8.43e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.886, tt:3516.692\n",
      "Ep:82, loss:0.00004, loss_test:0.08506, lr:8.35e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.896, tt:3560.330\n",
      "Ep:83, loss:0.00004, loss_test:0.08242, lr:8.26e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.884, tt:3602.220\n",
      "Ep:84, loss:0.00004, loss_test:0.08703, lr:8.18e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.876, tt:3644.420\n",
      "Ep:85, loss:0.00004, loss_test:0.08257, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.878, tt:3687.536\n",
      "Ep:86, loss:0.00004, loss_test:0.08458, lr:8.02e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.866, tt:3729.311\n",
      "Ep:87, loss:0.00004, loss_test:0.08644, lr:7.94e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.842, tt:3770.086\n",
      "Ep:88, loss:0.00004, loss_test:0.08316, lr:7.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.839, tt:3812.653\n",
      "Ep:89, loss:0.00004, loss_test:0.08430, lr:7.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.840, tt:3855.619\n",
      "Ep:90, loss:0.00003, loss_test:0.08707, lr:7.70e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.827, tt:3897.256\n",
      "Ep:91, loss:0.00003, loss_test:0.08382, lr:7.62e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.831, tt:3940.482\n",
      "Ep:92, loss:0.00003, loss_test:0.08561, lr:7.55e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.827, tt:3982.907\n",
      "Ep:93, loss:0.00003, loss_test:0.08788, lr:7.47e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.818, tt:4024.935\n",
      "Ep:94, loss:0.00003, loss_test:0.08474, lr:7.40e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.797, tt:4065.701\n",
      "Ep:95, loss:0.00003, loss_test:0.08831, lr:7.32e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.787, tt:4107.549\n",
      "Ep:96, loss:0.00003, loss_test:0.08476, lr:7.25e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.778, tt:4149.486\n",
      "Ep:97, loss:0.00003, loss_test:0.08712, lr:7.18e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.765, tt:4190.944\n",
      "Ep:98, loss:0.00003, loss_test:0.08519, lr:7.11e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.775, tt:4234.748\n",
      "Ep:99, loss:0.00003, loss_test:0.08365, lr:7.03e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.771, tt:4277.112\n",
      "Ep:100, loss:0.00003, loss_test:0.08853, lr:6.96e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.789, tt:4321.664\n",
      "Ep:101, loss:0.00003, loss_test:0.08354, lr:6.89e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.766, tt:4362.171\n",
      "Ep:102, loss:0.00003, loss_test:0.08633, lr:6.83e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.760, tt:4404.266\n",
      "Ep:103, loss:0.00003, loss_test:0.08766, lr:6.76e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.762, tt:4447.244\n",
      "Ep:104, loss:0.00003, loss_test:0.08553, lr:6.69e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.760, tt:4489.831\n",
      "Ep:105, loss:0.00003, loss_test:0.08779, lr:6.62e-03, fs:0.84492 (r=0.798,p=0.898),  time:42.778, tt:4534.510\n",
      "Ep:106, loss:0.00003, loss_test:0.08724, lr:6.56e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.779, tt:4577.353\n",
      "Ep:107, loss:0.00003, loss_test:0.08636, lr:6.49e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.800, tt:4622.368\n",
      "Ep:108, loss:0.00003, loss_test:0.08973, lr:6.43e-03, fs:0.80874 (r=0.747,p=0.881),  time:42.791, tt:4664.196\n",
      "Ep:109, loss:0.00003, loss_test:0.08435, lr:6.36e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.776, tt:4705.383\n",
      "Ep:110, loss:0.00003, loss_test:0.08934, lr:6.30e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.766, tt:4746.997\n",
      "Ep:111, loss:0.00003, loss_test:0.08630, lr:6.24e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.783, tt:4791.696\n",
      "Ep:112, loss:0.00003, loss_test:0.08728, lr:6.17e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.798, tt:4836.131\n",
      "Ep:113, loss:0.00003, loss_test:0.08967, lr:6.11e-03, fs:0.84492 (r=0.798,p=0.898),  time:42.774, tt:4876.288\n",
      "Ep:114, loss:0.00003, loss_test:0.08653, lr:6.05e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.752, tt:4916.531\n",
      "Ep:115, loss:0.00003, loss_test:0.09015, lr:5.99e-03, fs:0.82162 (r=0.768,p=0.884),  time:42.742, tt:4958.118\n",
      "Ep:116, loss:0.00002, loss_test:0.08662, lr:5.93e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.738, tt:5000.302\n",
      "Ep:117, loss:0.00003, loss_test:0.09008, lr:5.87e-03, fs:0.81522 (r=0.758,p=0.882),  time:42.740, tt:5043.312\n",
      "Ep:118, loss:0.00003, loss_test:0.08709, lr:5.81e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.736, tt:5085.635\n",
      "Ep:119, loss:0.00003, loss_test:0.08772, lr:5.75e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.738, tt:5128.534\n",
      "Ep:120, loss:0.00002, loss_test:0.09209, lr:5.70e-03, fs:0.80000 (r=0.727,p=0.889),  time:42.733, tt:5170.645\n",
      "Ep:121, loss:0.00003, loss_test:0.08618, lr:5.64e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.743, tt:5214.700\n",
      "Ep:122, loss:0.00003, loss_test:0.09138, lr:5.58e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.745, tt:5257.619\n",
      "Ep:123, loss:0.00002, loss_test:0.08772, lr:5.53e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.752, tt:5301.203\n",
      "Ep:124, loss:0.00002, loss_test:0.08929, lr:5.47e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.761, tt:5345.091\n",
      "Ep:125, loss:0.00002, loss_test:0.08876, lr:5.42e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.754, tt:5386.984\n",
      "Ep:126, loss:0.00002, loss_test:0.08960, lr:5.36e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.760, tt:5430.473\n",
      "Ep:127, loss:0.00002, loss_test:0.08885, lr:5.31e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.779, tt:5475.705\n",
      "Ep:128, loss:0.00002, loss_test:0.08872, lr:5.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.783, tt:5519.065\n",
      "Ep:129, loss:0.00002, loss_test:0.08999, lr:5.20e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.769, tt:5559.960\n",
      "Ep:130, loss:0.00002, loss_test:0.08973, lr:5.15e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.765, tt:5602.217\n",
      "Ep:131, loss:0.00002, loss_test:0.08898, lr:5.10e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.771, tt:5645.794\n",
      "Ep:132, loss:0.00002, loss_test:0.08880, lr:5.05e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.764, tt:5687.555\n",
      "Ep:133, loss:0.00002, loss_test:0.08979, lr:5.00e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.770, tt:5731.178\n",
      "Ep:134, loss:0.00002, loss_test:0.08957, lr:4.95e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.771, tt:5774.035\n",
      "Ep:135, loss:0.00002, loss_test:0.08846, lr:4.90e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.777, tt:5817.658\n",
      "Ep:136, loss:0.00002, loss_test:0.09068, lr:4.85e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.773, tt:5859.926\n",
      "Ep:137, loss:0.00002, loss_test:0.08924, lr:4.80e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.773, tt:5902.672\n",
      "Ep:138, loss:0.00002, loss_test:0.08930, lr:4.75e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.765, tt:5944.316\n",
      "Ep:139, loss:0.00002, loss_test:0.09051, lr:4.71e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.775, tt:5988.444\n",
      "Ep:140, loss:0.00002, loss_test:0.09090, lr:4.66e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.783, tt:6032.395\n",
      "Ep:141, loss:0.00002, loss_test:0.08965, lr:4.61e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.792, tt:6076.446\n",
      "Ep:142, loss:0.00002, loss_test:0.08982, lr:4.57e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.792, tt:6119.265\n",
      "Ep:143, loss:0.00002, loss_test:0.09000, lr:4.52e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.806, tt:6164.008\n",
      "Ep:144, loss:0.00002, loss_test:0.09105, lr:4.48e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.804, tt:6206.562\n",
      "Ep:145, loss:0.00002, loss_test:0.08924, lr:4.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.798, tt:6248.517\n",
      "Ep:146, loss:0.00002, loss_test:0.09068, lr:4.39e-03, fs:0.82609 (r=0.768,p=0.894),  time:42.806, tt:6292.528\n",
      "Ep:147, loss:0.00002, loss_test:0.09014, lr:4.34e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.822, tt:6337.727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00002, loss_test:0.09164, lr:4.30e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.831, tt:6381.881\n",
      "Ep:149, loss:0.00002, loss_test:0.08883, lr:4.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.844, tt:6426.584\n",
      "Ep:150, loss:0.00002, loss_test:0.09193, lr:4.21e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.847, tt:6469.872\n",
      "Ep:151, loss:0.00002, loss_test:0.09133, lr:4.17e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.841, tt:6511.904\n",
      "Ep:152, loss:0.00002, loss_test:0.08991, lr:4.13e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.831, tt:6553.167\n",
      "Ep:153, loss:0.00002, loss_test:0.09185, lr:4.09e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.825, tt:6595.098\n",
      "Ep:154, loss:0.00002, loss_test:0.09121, lr:4.05e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.824, tt:6637.666\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13751, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:14.679, tt:14.679\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13483, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:15.068, tt:30.137\n",
      "Ep:2, loss:0.00027, loss_test:0.13092, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:15.053, tt:45.159\n",
      "Ep:3, loss:0.00026, loss_test:0.12739, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:14.797, tt:59.189\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12507, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:14.708, tt:73.542\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12480, lr:1.00e-02, fs:0.66942 (r=0.818,p=0.566),  time:14.555, tt:87.331\n",
      "Ep:6, loss:0.00025, loss_test:0.12428, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:14.836, tt:103.853\n",
      "Ep:7, loss:0.00024, loss_test:0.12348, lr:1.00e-02, fs:0.66667 (r=0.818,p=0.562),  time:14.901, tt:119.211\n",
      "Ep:8, loss:0.00024, loss_test:0.12272, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:15.265, tt:137.383\n",
      "Ep:9, loss:0.00023, loss_test:0.12190, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:15.830, tt:158.299\n",
      "Ep:10, loss:0.00023, loss_test:0.12133, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:15.815, tt:173.963\n",
      "Ep:11, loss:0.00022, loss_test:0.12051, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:16.005, tt:192.062\n",
      "Ep:12, loss:0.00021, loss_test:0.11990, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:16.028, tt:208.362\n",
      "Ep:13, loss:0.00021, loss_test:0.11887, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:16.225, tt:227.153\n",
      "Ep:14, loss:0.00020, loss_test:0.11727, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:16.500, tt:247.494\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11560, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:16.487, tt:263.791\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.11369, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:16.628, tt:282.684\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.11171, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:16.604, tt:298.871\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10997, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:16.742, tt:318.106\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10797, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:16.766, tt:335.317\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10659, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.746, tt:351.666\n",
      "Ep:21, loss:0.00016, loss_test:0.10495, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.787, tt:369.318\n",
      "Ep:22, loss:0.00015, loss_test:0.10378, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:16.859, tt:387.764\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.10287, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:16.961, tt:407.065\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.10151, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:17.081, tt:427.035\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09945, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:17.099, tt:444.578\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09845, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:17.148, tt:463.008\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09682, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:17.137, tt:479.839\n",
      "Ep:28, loss:0.00012, loss_test:0.09698, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:17.151, tt:497.366\n",
      "Ep:29, loss:0.00012, loss_test:0.09561, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:17.173, tt:515.178\n",
      "Ep:30, loss:0.00012, loss_test:0.09613, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:17.201, tt:533.225\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.09313, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:17.303, tt:553.705\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.09575, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:17.273, tt:570.003\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.09181, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:17.304, tt:588.352\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.09317, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:17.343, tt:607.008\n",
      "Ep:35, loss:0.00010, loss_test:0.09038, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:17.320, tt:623.520\n",
      "Ep:36, loss:0.00010, loss_test:0.09204, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:17.386, tt:643.277\n",
      "Ep:37, loss:0.00009, loss_test:0.08840, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:17.376, tt:660.301\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08735, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:17.392, tt:678.282\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.09177, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:17.417, tt:696.665\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.08529, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:17.367, tt:712.027\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08917, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:17.399, tt:730.747\n",
      "Ep:42, loss:0.00008, loss_test:0.08662, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:17.399, tt:748.166\n",
      "Ep:43, loss:0.00008, loss_test:0.08491, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:17.417, tt:766.330\n",
      "Ep:44, loss:0.00007, loss_test:0.08736, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:17.439, tt:784.754\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.08148, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:17.447, tt:802.551\n",
      "Ep:46, loss:0.00007, loss_test:0.08781, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:17.489, tt:822.002\n",
      "Ep:47, loss:0.00007, loss_test:0.08261, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:17.466, tt:838.349\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.08350, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:17.496, tt:857.312\n",
      "Ep:49, loss:0.00007, loss_test:0.08916, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:17.535, tt:876.736\n",
      "Ep:50, loss:0.00006, loss_test:0.08206, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:17.513, tt:893.139\n",
      "Ep:51, loss:0.00006, loss_test:0.08193, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:17.520, tt:911.059\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00006, loss_test:0.08581, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:17.497, tt:927.318\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.07884, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:17.531, tt:946.663\n",
      "Ep:54, loss:0.00006, loss_test:0.08420, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:17.530, tt:964.165\n",
      "Ep:55, loss:0.00006, loss_test:0.08295, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:17.534, tt:981.896\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.08255, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:17.581, tt:1002.131\n",
      "Ep:57, loss:0.00005, loss_test:0.08312, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:17.646, tt:1023.476\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.08204, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:17.723, tt:1045.666\n",
      "Ep:59, loss:0.00005, loss_test:0.08256, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:17.785, tt:1067.105\n",
      "Ep:60, loss:0.00005, loss_test:0.08059, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:17.828, tt:1087.525\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.08558, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:17.875, tt:1108.252\n",
      "Ep:62, loss:0.00005, loss_test:0.08088, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:17.865, tt:1125.512\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.08005, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:17.884, tt:1144.604\n",
      "Ep:64, loss:0.00004, loss_test:0.08118, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:17.880, tt:1162.199\n",
      "Ep:65, loss:0.00004, loss_test:0.08361, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:17.889, tt:1180.696\n",
      "Ep:66, loss:0.00004, loss_test:0.07929, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.897, tt:1199.132\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.08138, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:17.875, tt:1215.471\n",
      "Ep:68, loss:0.00004, loss_test:0.08293, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.882, tt:1233.859\n",
      "Ep:69, loss:0.00004, loss_test:0.08057, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.867, tt:1250.683\n",
      "Ep:70, loss:0.00004, loss_test:0.08068, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.867, tt:1268.526\n",
      "Ep:71, loss:0.00004, loss_test:0.07810, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.862, tt:1286.093\n",
      "Ep:72, loss:0.00004, loss_test:0.07906, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.825, tt:1301.207\n",
      "Ep:73, loss:0.00004, loss_test:0.08285, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.835, tt:1319.772\n",
      "Ep:74, loss:0.00004, loss_test:0.08133, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.806, tt:1335.458\n",
      "Ep:75, loss:0.00003, loss_test:0.07571, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.831, tt:1355.131\n",
      "Ep:76, loss:0.00003, loss_test:0.08003, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.853, tt:1374.714\n",
      "Ep:77, loss:0.00003, loss_test:0.08100, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.833, tt:1390.970\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.07683, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.837, tt:1409.085\n",
      "Ep:79, loss:0.00003, loss_test:0.07871, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.828, tt:1426.212\n",
      "Ep:80, loss:0.00003, loss_test:0.07956, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.838, tt:1444.913\n",
      "Ep:81, loss:0.00003, loss_test:0.07906, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.839, tt:1462.799\n",
      "Ep:82, loss:0.00003, loss_test:0.07837, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.827, tt:1479.609\n",
      "Ep:83, loss:0.00003, loss_test:0.07780, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.850, tt:1499.405\n",
      "Ep:84, loss:0.00003, loss_test:0.07733, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.837, tt:1516.120\n",
      "Ep:85, loss:0.00003, loss_test:0.07835, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.825, tt:1532.909\n",
      "Ep:86, loss:0.00003, loss_test:0.08204, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.816, tt:1550.026\n",
      "Ep:87, loss:0.00003, loss_test:0.07561, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.805, tt:1566.822\n",
      "Ep:88, loss:0.00003, loss_test:0.07808, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:17.817, tt:1585.737\n",
      "Ep:89, loss:0.00002, loss_test:0.08130, lr:9.90e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.835, tt:1605.123\n",
      "Ep:90, loss:0.00003, loss_test:0.07409, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.820, tt:1621.638\n",
      "Ep:91, loss:0.00003, loss_test:0.08078, lr:9.70e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.811, tt:1638.642\n",
      "Ep:92, loss:0.00003, loss_test:0.07911, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.784, tt:1653.893\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.07846, lr:9.61e-03, fs:0.84615 (r=0.778,p=0.928),  time:17.768, tt:1670.172\n",
      "Ep:94, loss:0.00002, loss_test:0.07922, lr:9.61e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.777, tt:1688.815\n",
      "Ep:95, loss:0.00002, loss_test:0.07687, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.756, tt:1704.543\n",
      "Ep:96, loss:0.00002, loss_test:0.07928, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.758, tt:1722.497\n",
      "Ep:97, loss:0.00002, loss_test:0.07630, lr:9.61e-03, fs:0.86772 (r=0.828,p=0.911),  time:17.753, tt:1739.760\n",
      "Ep:98, loss:0.00002, loss_test:0.07888, lr:9.61e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.750, tt:1757.239\n",
      "Ep:99, loss:0.00002, loss_test:0.07587, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.755, tt:1775.483\n",
      "Ep:100, loss:0.00002, loss_test:0.07891, lr:9.61e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.741, tt:1791.807\n",
      "Ep:101, loss:0.00002, loss_test:0.07579, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.740, tt:1809.438\n",
      "Ep:102, loss:0.00002, loss_test:0.07923, lr:9.61e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.745, tt:1827.735\n",
      "Ep:103, loss:0.00002, loss_test:0.07436, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.753, tt:1846.346\n",
      "Ep:104, loss:0.00002, loss_test:0.07969, lr:9.51e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.769, tt:1865.761\n",
      "Ep:105, loss:0.00002, loss_test:0.07601, lr:9.41e-03, fs:0.83871 (r=0.788,p=0.897),  time:17.745, tt:1880.951\n",
      "Ep:106, loss:0.00002, loss_test:0.07896, lr:9.32e-03, fs:0.87958 (r=0.848,p=0.913),  time:17.731, tt:1897.255\n",
      "Ep:107, loss:0.00002, loss_test:0.07800, lr:9.23e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.726, tt:1914.390\n",
      "Ep:108, loss:0.00002, loss_test:0.07735, lr:9.14e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.710, tt:1930.371\n",
      "Ep:109, loss:0.00002, loss_test:0.07774, lr:9.04e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.710, tt:1948.076\n",
      "Ep:110, loss:0.00002, loss_test:0.07919, lr:8.95e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.699, tt:1964.624\n",
      "Ep:111, loss:0.00002, loss_test:0.07650, lr:8.86e-03, fs:0.84324 (r=0.788,p=0.907),  time:17.705, tt:1982.955\n",
      "Ep:112, loss:0.00002, loss_test:0.07812, lr:8.78e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.759, tt:2006.749\n",
      "Ep:113, loss:0.00001, loss_test:0.07701, lr:8.69e-03, fs:0.84324 (r=0.788,p=0.907),  time:17.756, tt:2024.235\n",
      "Ep:114, loss:0.00001, loss_test:0.07913, lr:8.60e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.768, tt:2043.280\n",
      "Ep:115, loss:0.00001, loss_test:0.07551, lr:8.51e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.784, tt:2062.976\n",
      "Ep:116, loss:0.00001, loss_test:0.07993, lr:8.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.805, tt:2083.197\n",
      "Ep:117, loss:0.00001, loss_test:0.07612, lr:8.35e-03, fs:0.84946 (r=0.798,p=0.908),  time:17.821, tt:2102.919\n",
      "Ep:118, loss:0.00001, loss_test:0.07900, lr:8.26e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.838, tt:2122.700\n",
      "Ep:119, loss:0.00001, loss_test:0.07764, lr:8.18e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.843, tt:2141.184\n",
      "Ep:120, loss:0.00001, loss_test:0.07860, lr:8.10e-03, fs:0.84043 (r=0.798,p=0.888),  time:17.839, tt:2158.571\n",
      "Ep:121, loss:0.00001, loss_test:0.07837, lr:8.02e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.857, tt:2178.515\n",
      "Ep:122, loss:0.00001, loss_test:0.07925, lr:7.94e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.869, tt:2197.931\n",
      "Ep:123, loss:0.00001, loss_test:0.07696, lr:7.86e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.875, tt:2216.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00001, loss_test:0.07908, lr:7.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.887, tt:2235.835\n",
      "Ep:125, loss:0.00001, loss_test:0.07582, lr:7.70e-03, fs:0.84946 (r=0.798,p=0.908),  time:17.874, tt:2252.083\n",
      "Ep:126, loss:0.00001, loss_test:0.07984, lr:7.62e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.885, tt:2271.359\n",
      "Ep:127, loss:0.00001, loss_test:0.07596, lr:7.55e-03, fs:0.84324 (r=0.788,p=0.907),  time:17.892, tt:2290.127\n",
      "Ep:128, loss:0.00001, loss_test:0.07807, lr:7.47e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.890, tt:2307.786\n",
      "Ep:129, loss:0.00001, loss_test:0.07847, lr:7.40e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.909, tt:2328.118\n",
      "Ep:130, loss:0.00001, loss_test:0.07789, lr:7.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:17.890, tt:2343.569\n",
      "Ep:131, loss:0.00001, loss_test:0.07932, lr:7.25e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.888, tt:2361.245\n",
      "Ep:132, loss:0.00001, loss_test:0.07711, lr:7.18e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.892, tt:2379.684\n",
      "Ep:133, loss:0.00001, loss_test:0.07904, lr:7.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.883, tt:2396.359\n",
      "Ep:134, loss:0.00001, loss_test:0.07765, lr:7.03e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.873, tt:2412.868\n",
      "Ep:135, loss:0.00001, loss_test:0.07872, lr:6.96e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.862, tt:2429.272\n",
      "Ep:136, loss:0.00001, loss_test:0.07737, lr:6.89e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.879, tt:2449.423\n",
      "Ep:137, loss:0.00001, loss_test:0.07926, lr:6.83e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.883, tt:2467.827\n",
      "Ep:138, loss:0.00001, loss_test:0.07741, lr:6.76e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.872, tt:2484.273\n",
      "Ep:139, loss:0.00001, loss_test:0.07908, lr:6.69e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.876, tt:2502.686\n",
      "Ep:140, loss:0.00001, loss_test:0.07873, lr:6.62e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.861, tt:2518.361\n",
      "Ep:141, loss:0.00001, loss_test:0.07733, lr:6.56e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.862, tt:2536.461\n",
      "Ep:142, loss:0.00001, loss_test:0.07909, lr:6.49e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.867, tt:2555.025\n",
      "Ep:143, loss:0.00001, loss_test:0.07872, lr:6.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.861, tt:2572.004\n",
      "Ep:144, loss:0.00001, loss_test:0.07813, lr:6.36e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.868, tt:2590.895\n",
      "Ep:145, loss:0.00001, loss_test:0.07859, lr:6.30e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.872, tt:2609.342\n",
      "Ep:146, loss:0.00001, loss_test:0.07883, lr:6.24e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.869, tt:2626.705\n",
      "Ep:147, loss:0.00001, loss_test:0.07821, lr:6.17e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.863, tt:2643.691\n",
      "Ep:148, loss:0.00001, loss_test:0.07885, lr:6.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.853, tt:2660.075\n",
      "Ep:149, loss:0.00001, loss_test:0.07793, lr:6.05e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.857, tt:2678.582\n",
      "Ep:150, loss:0.00001, loss_test:0.07837, lr:5.99e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.849, tt:2695.150\n",
      "Ep:151, loss:0.00001, loss_test:0.07807, lr:5.93e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.842, tt:2711.922\n",
      "Ep:152, loss:0.00001, loss_test:0.07839, lr:5.87e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.848, tt:2730.717\n",
      "Ep:153, loss:0.00001, loss_test:0.07830, lr:5.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.833, tt:2746.217\n",
      "Ep:154, loss:0.00001, loss_test:0.07944, lr:5.75e-03, fs:0.83696 (r=0.778,p=0.906),  time:17.837, tt:2764.744\n",
      "Ep:155, loss:0.00001, loss_test:0.07794, lr:5.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:17.829, tt:2781.251\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13233, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:18.163, tt:18.163\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12835, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:16.941, tt:33.882\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12273, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:17.422, tt:52.265\n",
      "Ep:3, loss:0.00026, loss_test:0.11772, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:16.316, tt:65.265\n",
      "Ep:4, loss:0.00026, loss_test:0.11335, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:16.222, tt:81.109\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.10974, lr:1.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:16.828, tt:100.966\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.10756, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:16.783, tt:117.480\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10574, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:17.048, tt:136.382\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.10256, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:17.086, tt:153.776\n",
      "Ep:9, loss:0.00023, loss_test:0.09813, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:17.148, tt:171.476\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.09447, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:17.032, tt:187.351\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.09231, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:17.040, tt:204.482\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.09099, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:17.032, tt:221.412\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.08994, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:16.985, tt:237.796\n",
      "Ep:14, loss:0.00021, loss_test:0.08912, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:17.129, tt:256.935\n",
      "Ep:15, loss:0.00020, loss_test:0.08799, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:17.244, tt:275.911\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.08608, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:17.149, tt:291.533\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.08539, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:17.009, tt:306.161\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.08522, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:16.848, tt:320.106\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.08454, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:16.735, tt:334.707\n",
      "Ep:20, loss:0.00017, loss_test:0.08452, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:16.726, tt:351.243\n",
      "Ep:21, loss:0.00017, loss_test:0.08384, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:16.865, tt:371.023\n",
      "Ep:22, loss:0.00016, loss_test:0.08430, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:17.099, tt:393.270\n",
      "Ep:23, loss:0.00016, loss_test:0.08397, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:17.156, tt:411.749\n",
      "Ep:24, loss:0.00015, loss_test:0.08318, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:17.220, tt:430.492\n",
      "Ep:25, loss:0.00015, loss_test:0.08332, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:17.241, tt:448.272\n",
      "Ep:26, loss:0.00014, loss_test:0.08257, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:17.334, tt:468.017\n",
      "Ep:27, loss:0.00014, loss_test:0.08134, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:17.379, tt:486.600\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08058, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:17.506, tt:507.678\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08108, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:17.648, tt:529.455\n",
      "Ep:30, loss:0.00013, loss_test:0.07879, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:17.677, tt:547.994\n",
      "Ep:31, loss:0.00012, loss_test:0.07987, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:17.690, tt:566.080\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07707, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:17.746, tt:585.629\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00011, loss_test:0.07792, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:17.779, tt:604.476\n",
      "Ep:34, loss:0.00011, loss_test:0.07879, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:17.805, tt:623.167\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07503, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:17.844, tt:642.392\n",
      "Ep:36, loss:0.00010, loss_test:0.07741, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:17.917, tt:662.916\n",
      "Ep:37, loss:0.00010, loss_test:0.07414, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:17.902, tt:680.269\n",
      "Ep:38, loss:0.00010, loss_test:0.07611, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:17.940, tt:699.661\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07291, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:18.017, tt:720.697\n",
      "Ep:40, loss:0.00009, loss_test:0.07369, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:18.026, tt:739.075\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07251, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:18.026, tt:757.084\n",
      "Ep:42, loss:0.00009, loss_test:0.06978, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:18.012, tt:774.529\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.07134, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:18.093, tt:796.114\n",
      "Ep:44, loss:0.00008, loss_test:0.07037, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:18.168, tt:817.579\n",
      "Ep:45, loss:0.00008, loss_test:0.06821, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:18.221, tt:838.155\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.06982, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:18.231, tt:856.879\n",
      "Ep:47, loss:0.00007, loss_test:0.06904, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:18.244, tt:875.716\n",
      "Ep:48, loss:0.00007, loss_test:0.06847, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:18.259, tt:894.702\n",
      "Ep:49, loss:0.00007, loss_test:0.06833, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:18.268, tt:913.411\n",
      "Ep:50, loss:0.00007, loss_test:0.06788, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:18.253, tt:930.918\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06850, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:18.259, tt:949.494\n",
      "Ep:52, loss:0.00007, loss_test:0.06791, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:18.240, tt:966.721\n",
      "Ep:53, loss:0.00006, loss_test:0.06660, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:18.241, tt:985.014\n",
      "Ep:54, loss:0.00006, loss_test:0.06530, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:18.227, tt:1002.488\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.06823, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:18.280, tt:1023.677\n",
      "Ep:56, loss:0.00006, loss_test:0.06465, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:18.314, tt:1043.922\n",
      "Ep:57, loss:0.00006, loss_test:0.06683, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:18.345, tt:1063.999\n",
      "Ep:58, loss:0.00006, loss_test:0.06749, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:18.349, tt:1082.575\n",
      "Ep:59, loss:0.00006, loss_test:0.06518, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:18.350, tt:1100.973\n",
      "Ep:60, loss:0.00005, loss_test:0.06700, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.365, tt:1120.241\n",
      "Ep:61, loss:0.00005, loss_test:0.06537, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.394, tt:1140.401\n",
      "Ep:62, loss:0.00005, loss_test:0.06518, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:18.447, tt:1162.130\n",
      "Ep:63, loss:0.00005, loss_test:0.06339, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.471, tt:1182.117\n",
      "Ep:64, loss:0.00005, loss_test:0.06605, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:18.526, tt:1204.212\n",
      "Ep:65, loss:0.00005, loss_test:0.06540, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:18.556, tt:1224.698\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:18.569, tt:1244.131\n",
      "Ep:67, loss:0.00005, loss_test:0.06458, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:18.564, tt:1262.371\n",
      "Ep:68, loss:0.00004, loss_test:0.06639, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:18.543, tt:1279.443\n",
      "Ep:69, loss:0.00004, loss_test:0.06433, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:18.544, tt:1298.075\n",
      "Ep:70, loss:0.00004, loss_test:0.06549, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:18.552, tt:1317.203\n",
      "Ep:71, loss:0.00004, loss_test:0.06486, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.553, tt:1335.851\n",
      "Ep:72, loss:0.00004, loss_test:0.06343, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:18.547, tt:1353.925\n",
      "Ep:73, loss:0.00004, loss_test:0.06600, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.529, tt:1371.162\n",
      "Ep:74, loss:0.00004, loss_test:0.06229, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:18.547, tt:1391.003\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.06785, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:18.544, tt:1409.323\n",
      "Ep:76, loss:0.00004, loss_test:0.06188, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:18.531, tt:1426.894\n",
      "Ep:77, loss:0.00004, loss_test:0.06476, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:18.512, tt:1443.919\n",
      "Ep:78, loss:0.00004, loss_test:0.06493, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:18.533, tt:1464.145\n",
      "Ep:79, loss:0.00003, loss_test:0.06259, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:18.558, tt:1484.652\n",
      "Ep:80, loss:0.00003, loss_test:0.06407, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:18.552, tt:1502.688\n",
      "Ep:81, loss:0.00003, loss_test:0.06160, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:18.550, tt:1521.106\n",
      "Ep:82, loss:0.00003, loss_test:0.06399, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:18.546, tt:1539.279\n",
      "Ep:83, loss:0.00003, loss_test:0.06193, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:18.559, tt:1558.980\n",
      "Ep:84, loss:0.00003, loss_test:0.06275, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:18.569, tt:1578.398\n",
      "Ep:85, loss:0.00003, loss_test:0.06216, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:18.564, tt:1596.487\n",
      "Ep:86, loss:0.00003, loss_test:0.06308, lr:9.90e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.555, tt:1614.253\n",
      "Ep:87, loss:0.00003, loss_test:0.06336, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.547, tt:1632.111\n",
      "Ep:88, loss:0.00003, loss_test:0.06323, lr:9.70e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.581, tt:1653.697\n",
      "Ep:89, loss:0.00003, loss_test:0.06326, lr:9.61e-03, fs:0.87179 (r=0.859,p=0.885),  time:18.561, tt:1670.462\n",
      "Ep:90, loss:0.00003, loss_test:0.06144, lr:9.51e-03, fs:0.90323 (r=0.848,p=0.966),  time:18.560, tt:1688.940\n",
      "Ep:91, loss:0.00003, loss_test:0.06324, lr:9.41e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.561, tt:1707.651\n",
      "Ep:92, loss:0.00003, loss_test:0.06179, lr:9.32e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.544, tt:1724.578\n",
      "Ep:93, loss:0.00003, loss_test:0.06207, lr:9.23e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.547, tt:1743.427\n",
      "Ep:94, loss:0.00003, loss_test:0.06087, lr:9.14e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.541, tt:1761.406\n",
      "Ep:95, loss:0.00003, loss_test:0.06201, lr:9.04e-03, fs:0.87568 (r=0.818,p=0.942),  time:18.533, tt:1779.186\n",
      "Ep:96, loss:0.00002, loss_test:0.06130, lr:8.95e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.534, tt:1797.776\n",
      "Ep:97, loss:0.00002, loss_test:0.06299, lr:8.86e-03, fs:0.84270 (r=0.758,p=0.949),  time:18.546, tt:1817.476\n",
      "Ep:98, loss:0.00002, loss_test:0.06108, lr:8.78e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.543, tt:1835.731\n",
      "Ep:99, loss:0.00002, loss_test:0.06272, lr:8.69e-03, fs:0.87701 (r=0.828,p=0.932),  time:18.532, tt:1853.245\n",
      "Ep:100, loss:0.00002, loss_test:0.06081, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.546, tt:1873.111\n",
      "Ep:101, loss:0.00002, loss_test:0.06138, lr:8.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:18.540, tt:1891.050\n",
      "Ep:102, loss:0.00002, loss_test:0.06065, lr:8.43e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.520, tt:1907.535\n",
      "Ep:103, loss:0.00002, loss_test:0.06179, lr:8.35e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.543, tt:1928.475\n",
      "Ep:104, loss:0.00002, loss_test:0.06098, lr:8.26e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.560, tt:1948.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00002, loss_test:0.06144, lr:8.18e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.541, tt:1965.392\n",
      "Ep:106, loss:0.00002, loss_test:0.06089, lr:8.10e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.527, tt:1982.355\n",
      "Ep:107, loss:0.00002, loss_test:0.06185, lr:8.02e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.513, tt:1999.403\n",
      "Ep:108, loss:0.00002, loss_test:0.06053, lr:7.94e-03, fs:0.89362 (r=0.848,p=0.944),  time:18.511, tt:2017.646\n",
      "Ep:109, loss:0.00002, loss_test:0.06165, lr:7.86e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.541, tt:2039.486\n",
      "Ep:110, loss:0.00002, loss_test:0.06034, lr:7.78e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.536, tt:2057.515\n",
      "Ep:111, loss:0.00002, loss_test:0.06214, lr:7.70e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.529, tt:2075.271\n",
      "Ep:112, loss:0.00002, loss_test:0.06083, lr:7.62e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.525, tt:2093.362\n",
      "Ep:113, loss:0.00002, loss_test:0.06177, lr:7.55e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.525, tt:2111.816\n",
      "Ep:114, loss:0.00002, loss_test:0.06232, lr:7.47e-03, fs:0.89474 (r=0.859,p=0.934),  time:18.523, tt:2130.111\n",
      "Ep:115, loss:0.00002, loss_test:0.06088, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:18.533, tt:2149.817\n",
      "Ep:116, loss:0.00002, loss_test:0.06247, lr:7.32e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.530, tt:2168.014\n",
      "Ep:117, loss:0.00002, loss_test:0.06160, lr:7.25e-03, fs:0.88172 (r=0.828,p=0.943),  time:18.525, tt:2185.965\n",
      "Ep:118, loss:0.00002, loss_test:0.06115, lr:7.18e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.522, tt:2204.075\n",
      "Ep:119, loss:0.00002, loss_test:0.06181, lr:7.11e-03, fs:0.87432 (r=0.808,p=0.952),  time:18.532, tt:2223.805\n",
      "Ep:120, loss:0.00002, loss_test:0.06091, lr:7.03e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.521, tt:2241.045\n",
      "Ep:121, loss:0.00002, loss_test:0.06251, lr:6.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:18.531, tt:2260.770\n",
      "Ep:122, loss:0.00002, loss_test:0.06146, lr:6.89e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.538, tt:2280.210\n",
      "Ep:123, loss:0.00002, loss_test:0.06210, lr:6.83e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.543, tt:2299.312\n",
      "Ep:124, loss:0.00002, loss_test:0.06271, lr:6.76e-03, fs:0.85405 (r=0.798,p=0.919),  time:18.536, tt:2317.016\n",
      "Ep:125, loss:0.00002, loss_test:0.06162, lr:6.69e-03, fs:0.87234 (r=0.828,p=0.921),  time:18.527, tt:2334.363\n",
      "Ep:126, loss:0.00002, loss_test:0.06177, lr:6.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:18.523, tt:2352.470\n",
      "Ep:127, loss:0.00002, loss_test:0.06141, lr:6.56e-03, fs:0.88421 (r=0.848,p=0.923),  time:18.530, tt:2371.837\n",
      "Ep:128, loss:0.00002, loss_test:0.06231, lr:6.49e-03, fs:0.82486 (r=0.737,p=0.936),  time:18.554, tt:2393.428\n",
      "Ep:129, loss:0.00002, loss_test:0.06184, lr:6.43e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.574, tt:2414.580\n",
      "Ep:130, loss:0.00002, loss_test:0.06271, lr:6.36e-03, fs:0.83616 (r=0.747,p=0.949),  time:18.584, tt:2434.515\n",
      "Ep:131, loss:0.00002, loss_test:0.06171, lr:6.30e-03, fs:0.86022 (r=0.808,p=0.920),  time:18.594, tt:2454.356\n",
      "Ep:132, loss:0.00002, loss_test:0.06272, lr:6.24e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.607, tt:2474.706\n",
      "Ep:133, loss:0.00002, loss_test:0.06226, lr:6.17e-03, fs:0.87831 (r=0.838,p=0.922),  time:18.603, tt:2492.813\n",
      "Ep:134, loss:0.00001, loss_test:0.06178, lr:6.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.617, tt:2513.321\n",
      "Ep:135, loss:0.00002, loss_test:0.06256, lr:6.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:18.600, tt:2529.577\n",
      "Ep:136, loss:0.00001, loss_test:0.06141, lr:5.99e-03, fs:0.89362 (r=0.848,p=0.944),  time:18.603, tt:2548.593\n",
      "Ep:137, loss:0.00001, loss_test:0.06267, lr:5.93e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.595, tt:2566.077\n",
      "Ep:138, loss:0.00001, loss_test:0.06110, lr:5.87e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.597, tt:2585.032\n",
      "Ep:139, loss:0.00001, loss_test:0.06246, lr:5.81e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.599, tt:2603.859\n",
      "Ep:140, loss:0.00001, loss_test:0.06247, lr:5.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:18.586, tt:2620.563\n",
      "Ep:141, loss:0.00001, loss_test:0.06116, lr:5.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:18.576, tt:2637.755\n",
      "Ep:142, loss:0.00001, loss_test:0.06371, lr:5.64e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.581, tt:2657.034\n",
      "Ep:143, loss:0.00001, loss_test:0.06080, lr:5.58e-03, fs:0.87568 (r=0.818,p=0.942),  time:18.568, tt:2673.845\n",
      "Ep:144, loss:0.00001, loss_test:0.06274, lr:5.53e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.563, tt:2691.609\n",
      "Ep:145, loss:0.00001, loss_test:0.06171, lr:5.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:18.558, tt:2709.399\n",
      "Ep:146, loss:0.00001, loss_test:0.06118, lr:5.42e-03, fs:0.84091 (r=0.747,p=0.961),  time:18.550, tt:2726.881\n",
      "Ep:147, loss:0.00001, loss_test:0.06270, lr:5.36e-03, fs:0.84746 (r=0.758,p=0.962),  time:18.547, tt:2744.928\n",
      "Ep:148, loss:0.00001, loss_test:0.06187, lr:5.31e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.533, tt:2761.443\n",
      "Ep:149, loss:0.00001, loss_test:0.06131, lr:5.26e-03, fs:0.82955 (r=0.737,p=0.948),  time:18.525, tt:2778.702\n",
      "Ep:150, loss:0.00001, loss_test:0.06277, lr:5.20e-03, fs:0.84091 (r=0.747,p=0.961),  time:18.517, tt:2796.093\n",
      "Ep:151, loss:0.00001, loss_test:0.06171, lr:5.15e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.519, tt:2814.834\n",
      "Ep:152, loss:0.00001, loss_test:0.06167, lr:5.10e-03, fs:0.83908 (r=0.737,p=0.973),  time:18.520, tt:2833.630\n",
      "Ep:153, loss:0.00001, loss_test:0.06279, lr:5.05e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.534, tt:2854.166\n",
      "Ep:154, loss:0.00001, loss_test:0.06185, lr:5.00e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.538, tt:2873.346\n",
      "Ep:155, loss:0.00001, loss_test:0.06224, lr:4.95e-03, fs:0.83908 (r=0.737,p=0.973),  time:18.544, tt:2892.884\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13963, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:21.946, tt:21.946\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13628, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:21.130, tt:42.260\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13072, lr:1.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:19.632, tt:58.895\n",
      "Ep:3, loss:0.00025, loss_test:0.12659, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:18.793, tt:75.171\n",
      "Ep:4, loss:0.00025, loss_test:0.12425, lr:1.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:19.151, tt:95.756\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12260, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:19.699, tt:118.195\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12134, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:20.101, tt:140.704\n",
      "Ep:7, loss:0.00023, loss_test:0.11863, lr:1.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:20.307, tt:162.453\n",
      "Ep:8, loss:0.00022, loss_test:0.11632, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:20.412, tt:183.712\n",
      "Ep:9, loss:0.00021, loss_test:0.11531, lr:1.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:20.476, tt:204.762\n",
      "Ep:10, loss:0.00020, loss_test:0.11304, lr:1.00e-02, fs:0.65487 (r=0.747,p=0.583),  time:20.441, tt:224.851\n",
      "Ep:11, loss:0.00020, loss_test:0.11045, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:20.490, tt:245.879\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10895, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:20.631, tt:268.197\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10675, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:20.580, tt:288.116\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00017, loss_test:0.10446, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:20.478, tt:307.165\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10247, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:20.373, tt:325.962\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.10034, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:20.192, tt:343.271\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09875, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:20.149, tt:362.682\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09540, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:20.163, tt:383.091\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09324, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:20.182, tt:403.648\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09178, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:20.184, tt:423.858\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09031, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:20.212, tt:444.662\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08895, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:20.204, tt:464.700\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08812, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:20.214, tt:485.130\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.08570, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:20.191, tt:504.783\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08572, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:20.167, tt:524.351\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.08420, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:20.130, tt:543.508\n",
      "Ep:27, loss:0.00010, loss_test:0.08259, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:20.144, tt:564.031\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.08204, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:20.290, tt:588.396\n",
      "Ep:29, loss:0.00010, loss_test:0.08245, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:20.325, tt:609.735\n",
      "Ep:30, loss:0.00009, loss_test:0.08064, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:20.318, tt:629.865\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08107, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:20.345, tt:651.040\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.07937, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:20.337, tt:671.136\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.08052, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:20.410, tt:693.936\n",
      "Ep:34, loss:0.00008, loss_test:0.07913, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:20.467, tt:716.331\n",
      "Ep:35, loss:0.00008, loss_test:0.07749, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:20.472, tt:737.001\n",
      "Ep:36, loss:0.00007, loss_test:0.08364, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:20.479, tt:757.736\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.07686, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:20.496, tt:778.863\n",
      "Ep:38, loss:0.00007, loss_test:0.08360, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:20.507, tt:799.788\n",
      "Ep:39, loss:0.00007, loss_test:0.07790, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:20.543, tt:821.715\n",
      "Ep:40, loss:0.00007, loss_test:0.07844, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:20.535, tt:841.916\n",
      "Ep:41, loss:0.00006, loss_test:0.08112, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:20.538, tt:862.603\n",
      "Ep:42, loss:0.00006, loss_test:0.07751, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:20.552, tt:883.727\n",
      "Ep:43, loss:0.00006, loss_test:0.08217, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:20.614, tt:907.016\n",
      "Ep:44, loss:0.00006, loss_test:0.07802, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:20.607, tt:927.331\n",
      "Ep:45, loss:0.00006, loss_test:0.08173, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:20.610, tt:948.082\n",
      "Ep:46, loss:0.00005, loss_test:0.07907, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:20.612, tt:968.757\n",
      "Ep:47, loss:0.00005, loss_test:0.08420, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:20.624, tt:989.969\n",
      "Ep:48, loss:0.00006, loss_test:0.07889, lr:9.90e-03, fs:0.82796 (r=0.778,p=0.885),  time:20.614, tt:1010.109\n",
      "Ep:49, loss:0.00005, loss_test:0.08383, lr:9.80e-03, fs:0.80808 (r=0.808,p=0.808),  time:20.633, tt:1031.652\n",
      "Ep:50, loss:0.00006, loss_test:0.07749, lr:9.70e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.650, tt:1053.146\n",
      "Ep:51, loss:0.00005, loss_test:0.08102, lr:9.61e-03, fs:0.81720 (r=0.768,p=0.874),  time:20.668, tt:1074.721\n",
      "Ep:52, loss:0.00005, loss_test:0.07672, lr:9.51e-03, fs:0.82979 (r=0.788,p=0.876),  time:20.714, tt:1097.863\n",
      "Ep:53, loss:0.00005, loss_test:0.08220, lr:9.41e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.725, tt:1119.136\n",
      "Ep:54, loss:0.00004, loss_test:0.07812, lr:9.32e-03, fs:0.82162 (r=0.768,p=0.884),  time:20.758, tt:1141.701\n",
      "Ep:55, loss:0.00004, loss_test:0.07928, lr:9.23e-03, fs:0.83938 (r=0.818,p=0.862),  time:20.790, tt:1164.259\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00004, loss_test:0.08092, lr:9.23e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.797, tt:1185.432\n",
      "Ep:57, loss:0.00004, loss_test:0.07754, lr:9.23e-03, fs:0.81915 (r=0.778,p=0.865),  time:20.809, tt:1206.935\n",
      "Ep:58, loss:0.00004, loss_test:0.08074, lr:9.23e-03, fs:0.81720 (r=0.768,p=0.874),  time:20.840, tt:1229.570\n",
      "Ep:59, loss:0.00004, loss_test:0.07870, lr:9.23e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.864, tt:1251.858\n",
      "Ep:60, loss:0.00004, loss_test:0.07927, lr:9.23e-03, fs:0.82105 (r=0.788,p=0.857),  time:20.866, tt:1272.845\n",
      "Ep:61, loss:0.00004, loss_test:0.08060, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.883, tt:1294.748\n",
      "Ep:62, loss:0.00004, loss_test:0.08023, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.872, tt:1314.911\n",
      "Ep:63, loss:0.00003, loss_test:0.07781, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.859, tt:1334.971\n",
      "Ep:64, loss:0.00004, loss_test:0.08032, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.868, tt:1356.423\n",
      "Ep:65, loss:0.00003, loss_test:0.08105, lr:9.23e-03, fs:0.81915 (r=0.778,p=0.865),  time:20.871, tt:1377.489\n",
      "Ep:66, loss:0.00003, loss_test:0.07717, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.900, tt:1400.320\n",
      "Ep:67, loss:0.00003, loss_test:0.08033, lr:9.14e-03, fs:0.82162 (r=0.768,p=0.884),  time:20.916, tt:1422.272\n",
      "Ep:68, loss:0.00003, loss_test:0.07757, lr:9.04e-03, fs:0.82162 (r=0.768,p=0.884),  time:20.953, tt:1445.757\n",
      "Ep:69, loss:0.00003, loss_test:0.07913, lr:8.95e-03, fs:0.83060 (r=0.768,p=0.905),  time:20.973, tt:1468.090\n",
      "Ep:70, loss:0.00003, loss_test:0.08143, lr:8.86e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.991, tt:1490.385\n",
      "Ep:71, loss:0.00003, loss_test:0.07503, lr:8.78e-03, fs:0.83243 (r=0.778,p=0.895),  time:20.981, tt:1510.637\n",
      "Ep:72, loss:0.00003, loss_test:0.08581, lr:8.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:21.015, tt:1534.129\n",
      "Ep:73, loss:0.00003, loss_test:0.07440, lr:8.60e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.041, tt:1557.008\n",
      "Ep:74, loss:0.00003, loss_test:0.08460, lr:8.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:21.027, tt:1577.019\n",
      "Ep:75, loss:0.00003, loss_test:0.07709, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.008, tt:1596.615\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00003, loss_test:0.08125, lr:8.43e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.023, tt:1618.737\n",
      "Ep:77, loss:0.00003, loss_test:0.07830, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:20.995, tt:1637.639\n",
      "Ep:78, loss:0.00003, loss_test:0.08183, lr:8.43e-03, fs:0.82162 (r=0.768,p=0.884),  time:20.992, tt:1658.387\n",
      "Ep:79, loss:0.00003, loss_test:0.07729, lr:8.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.009, tt:1680.741\n",
      "Ep:80, loss:0.00003, loss_test:0.08081, lr:8.43e-03, fs:0.83696 (r=0.778,p=0.906),  time:20.992, tt:1700.317\n",
      "Ep:81, loss:0.00003, loss_test:0.08242, lr:8.43e-03, fs:0.83696 (r=0.778,p=0.906),  time:20.998, tt:1721.861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:82, loss:0.00003, loss_test:0.07439, lr:8.43e-03, fs:0.83696 (r=0.778,p=0.906),  time:20.990, tt:1742.138\n",
      "Ep:83, loss:0.00003, loss_test:0.08390, lr:8.43e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.013, tt:1765.101\n",
      "Ep:84, loss:0.00002, loss_test:0.07542, lr:8.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.005, tt:1785.406\n",
      "Ep:85, loss:0.00002, loss_test:0.08291, lr:8.43e-03, fs:0.80435 (r=0.747,p=0.871),  time:21.012, tt:1807.059\n",
      "Ep:86, loss:0.00002, loss_test:0.07681, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.010, tt:1827.898\n",
      "Ep:87, loss:0.00002, loss_test:0.08407, lr:8.35e-03, fs:0.82353 (r=0.778,p=0.875),  time:21.027, tt:1850.335\n",
      "Ep:88, loss:0.00002, loss_test:0.07514, lr:8.26e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.044, tt:1872.922\n",
      "Ep:89, loss:0.00002, loss_test:0.08307, lr:8.18e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.056, tt:1895.078\n",
      "Ep:90, loss:0.00002, loss_test:0.07630, lr:8.10e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.061, tt:1916.533\n",
      "Ep:91, loss:0.00002, loss_test:0.08268, lr:8.02e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.054, tt:1936.952\n",
      "Ep:92, loss:0.00002, loss_test:0.07751, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.064, tt:1958.934\n",
      "Ep:93, loss:0.00002, loss_test:0.08193, lr:7.86e-03, fs:0.82353 (r=0.778,p=0.875),  time:21.101, tt:1983.478\n",
      "Ep:94, loss:0.00002, loss_test:0.07962, lr:7.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.124, tt:2006.774\n",
      "Ep:95, loss:0.00002, loss_test:0.08093, lr:7.70e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.112, tt:2026.709\n",
      "Ep:96, loss:0.00002, loss_test:0.07881, lr:7.62e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.109, tt:2047.596\n",
      "Ep:97, loss:0.00002, loss_test:0.07924, lr:7.55e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.096, tt:2067.415\n",
      "Ep:98, loss:0.00002, loss_test:0.08107, lr:7.47e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.075, tt:2086.435\n",
      "Ep:99, loss:0.00002, loss_test:0.07943, lr:7.40e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.064, tt:2106.374\n",
      "Ep:100, loss:0.00002, loss_test:0.08226, lr:7.32e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.050, tt:2126.021\n",
      "Ep:101, loss:0.00002, loss_test:0.07833, lr:7.25e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.037, tt:2145.736\n",
      "Ep:102, loss:0.00002, loss_test:0.08275, lr:7.18e-03, fs:0.82353 (r=0.778,p=0.875),  time:21.026, tt:2165.667\n",
      "Ep:103, loss:0.00002, loss_test:0.07904, lr:7.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.012, tt:2185.283\n",
      "Ep:104, loss:0.00002, loss_test:0.08150, lr:7.03e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.022, tt:2207.349\n",
      "Ep:105, loss:0.00002, loss_test:0.08151, lr:6.96e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.035, tt:2229.744\n",
      "Ep:106, loss:0.00002, loss_test:0.07938, lr:6.89e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.029, tt:2250.095\n",
      "Ep:107, loss:0.00002, loss_test:0.07927, lr:6.83e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.012, tt:2269.334\n",
      "Ep:108, loss:0.00002, loss_test:0.08285, lr:6.76e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.003, tt:2289.353\n",
      "Ep:109, loss:0.00002, loss_test:0.07839, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.006, tt:2310.654\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.08404, lr:6.69e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.021, tt:2333.279\n",
      "Ep:111, loss:0.00002, loss_test:0.07785, lr:6.69e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.046, tt:2357.183\n",
      "Ep:112, loss:0.00002, loss_test:0.08371, lr:6.69e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.054, tt:2379.070\n",
      "Ep:113, loss:0.00002, loss_test:0.07762, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.089, tt:2404.105\n",
      "Ep:114, loss:0.00002, loss_test:0.08475, lr:6.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.092, tt:2425.553\n",
      "Ep:115, loss:0.00002, loss_test:0.07700, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.108, tt:2448.557\n",
      "Ep:116, loss:0.00002, loss_test:0.08475, lr:6.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.113, tt:2470.231\n",
      "Ep:117, loss:0.00002, loss_test:0.07756, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.100, tt:2489.811\n",
      "Ep:118, loss:0.00002, loss_test:0.08334, lr:6.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.091, tt:2509.780\n",
      "Ep:119, loss:0.00002, loss_test:0.07796, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.079, tt:2529.431\n",
      "Ep:120, loss:0.00002, loss_test:0.08335, lr:6.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.085, tt:2551.257\n",
      "Ep:121, loss:0.00001, loss_test:0.07800, lr:6.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.090, tt:2572.988\n",
      "Ep:122, loss:0.00001, loss_test:0.08358, lr:6.56e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.088, tt:2593.831\n",
      "Ep:123, loss:0.00001, loss_test:0.07785, lr:6.49e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.110, tt:2617.606\n",
      "Ep:124, loss:0.00001, loss_test:0.08335, lr:6.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.102, tt:2637.696\n",
      "Ep:125, loss:0.00001, loss_test:0.07822, lr:6.36e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.102, tt:2658.912\n",
      "Ep:126, loss:0.00001, loss_test:0.08456, lr:6.30e-03, fs:0.82796 (r=0.778,p=0.885),  time:21.111, tt:2681.112\n",
      "Ep:127, loss:0.00001, loss_test:0.07841, lr:6.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.118, tt:2703.070\n",
      "Ep:128, loss:0.00001, loss_test:0.08607, lr:6.17e-03, fs:0.74713 (r=0.657,p=0.867),  time:21.111, tt:2723.370\n",
      "Ep:129, loss:0.00001, loss_test:0.07738, lr:6.11e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.117, tt:2745.168\n",
      "Ep:130, loss:0.00001, loss_test:0.08401, lr:6.05e-03, fs:0.82609 (r=0.768,p=0.894),  time:21.106, tt:2764.915\n",
      "Ep:131, loss:0.00001, loss_test:0.07842, lr:5.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.099, tt:2785.051\n",
      "Ep:132, loss:0.00001, loss_test:0.08244, lr:5.93e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.088, tt:2804.694\n",
      "Ep:133, loss:0.00001, loss_test:0.08019, lr:5.87e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.094, tt:2826.621\n",
      "Ep:134, loss:0.00001, loss_test:0.08063, lr:5.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.091, tt:2847.288\n",
      "Ep:135, loss:0.00001, loss_test:0.08167, lr:5.75e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.105, tt:2870.331\n",
      "Ep:136, loss:0.00001, loss_test:0.07770, lr:5.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.114, tt:2892.561\n",
      "Ep:137, loss:0.00001, loss_test:0.08221, lr:5.64e-03, fs:0.83243 (r=0.778,p=0.895),  time:21.129, tt:2915.769\n",
      "Ep:138, loss:0.00001, loss_test:0.07918, lr:5.58e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.152, tt:2940.147\n",
      "Ep:139, loss:0.00001, loss_test:0.08114, lr:5.53e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.170, tt:2963.738\n",
      "Ep:140, loss:0.00001, loss_test:0.07893, lr:5.47e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.178, tt:2986.069\n",
      "Ep:141, loss:0.00001, loss_test:0.07946, lr:5.42e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.172, tt:3006.480\n",
      "Ep:142, loss:0.00001, loss_test:0.07959, lr:5.36e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.179, tt:3028.543\n",
      "Ep:143, loss:0.00001, loss_test:0.07926, lr:5.31e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.175, tt:3049.244\n",
      "Ep:144, loss:0.00001, loss_test:0.07858, lr:5.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.179, tt:3070.952\n",
      "Ep:145, loss:0.00001, loss_test:0.07923, lr:5.20e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.198, tt:3094.915\n",
      "Ep:146, loss:0.00001, loss_test:0.07953, lr:5.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.203, tt:3116.863\n",
      "Ep:147, loss:0.00001, loss_test:0.07946, lr:5.10e-03, fs:0.84153 (r=0.778,p=0.917),  time:21.207, tt:3138.637\n",
      "Ep:148, loss:0.00001, loss_test:0.07934, lr:5.05e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.214, tt:3160.929\n",
      "Ep:149, loss:0.00001, loss_test:0.07977, lr:5.00e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.220, tt:3182.940\n",
      "Ep:150, loss:0.00001, loss_test:0.07869, lr:4.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:21.216, tt:3203.553\n",
      "Ep:151, loss:0.00001, loss_test:0.08027, lr:4.90e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.212, tt:3224.251\n",
      "Ep:152, loss:0.00001, loss_test:0.07848, lr:4.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.218, tt:3246.395\n",
      "Ep:153, loss:0.00001, loss_test:0.08172, lr:4.80e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.223, tt:3268.354\n",
      "Ep:154, loss:0.00001, loss_test:0.07868, lr:4.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:21.226, tt:3290.029\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.08151, lr:4.75e-03, fs:0.83696 (r=0.778,p=0.906),  time:21.221, tt:3310.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:156, loss:0.00001, loss_test:0.08059, lr:4.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:21.235, tt:3333.861\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13432, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:19.440, tt:19.440\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12943, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:20.967, tt:41.933\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12184, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:21.431, tt:64.293\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11613, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:21.271, tt:85.083\n",
      "Ep:4, loss:0.00025, loss_test:0.11276, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:20.592, tt:102.960\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.10915, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:20.690, tt:124.143\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10683, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:20.753, tt:145.268\n",
      "Ep:7, loss:0.00023, loss_test:0.10489, lr:1.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:20.849, tt:166.791\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10126, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:21.043, tt:189.388\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09789, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:21.142, tt:211.424\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09433, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:21.262, tt:233.885\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09230, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:21.282, tt:255.385\n",
      "Ep:12, loss:0.00019, loss_test:0.09184, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:21.427, tt:278.545\n",
      "Ep:13, loss:0.00019, loss_test:0.09174, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:21.366, tt:299.129\n",
      "Ep:14, loss:0.00018, loss_test:0.08813, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:21.490, tt:322.349\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08608, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:21.436, tt:342.979\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08544, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:21.294, tt:362.000\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08273, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:21.090, tt:379.617\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08144, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:20.772, tt:394.675\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08031, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:20.540, tt:410.805\n",
      "Ep:20, loss:0.00014, loss_test:0.07849, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:20.311, tt:426.521\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.07765, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:20.122, tt:442.684\n",
      "Ep:22, loss:0.00013, loss_test:0.07684, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:19.889, tt:457.452\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07476, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:19.672, tt:472.117\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07361, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:19.541, tt:488.523\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07220, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:19.366, tt:503.505\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07130, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:19.217, tt:518.847\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.06998, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:19.055, tt:533.536\n",
      "Ep:28, loss:0.00010, loss_test:0.06926, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:18.948, tt:549.484\n",
      "Ep:29, loss:0.00009, loss_test:0.06894, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:18.804, tt:564.106\n",
      "Ep:30, loss:0.00009, loss_test:0.06698, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:18.685, tt:579.238\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.06737, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:18.566, tt:594.119\n",
      "Ep:32, loss:0.00008, loss_test:0.06552, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:18.474, tt:609.657\n",
      "Ep:33, loss:0.00008, loss_test:0.06586, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.420, tt:626.265\n",
      "Ep:34, loss:0.00008, loss_test:0.06470, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:18.317, tt:641.101\n",
      "Ep:35, loss:0.00007, loss_test:0.06501, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.222, tt:656.009\n",
      "Ep:36, loss:0.00007, loss_test:0.06432, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.146, tt:671.420\n",
      "Ep:37, loss:0.00007, loss_test:0.06354, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.068, tt:686.568\n",
      "Ep:38, loss:0.00007, loss_test:0.06417, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:17.972, tt:700.911\n",
      "Ep:39, loss:0.00007, loss_test:0.06243, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:17.887, tt:715.500\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.06372, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:17.809, tt:730.176\n",
      "Ep:41, loss:0.00006, loss_test:0.06206, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:17.728, tt:744.585\n",
      "Ep:42, loss:0.00006, loss_test:0.06197, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:17.661, tt:759.417\n",
      "Ep:43, loss:0.00006, loss_test:0.06137, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:17.590, tt:773.973\n",
      "Ep:44, loss:0.00006, loss_test:0.06185, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:17.530, tt:788.873\n",
      "Ep:45, loss:0.00005, loss_test:0.06207, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:17.461, tt:803.205\n",
      "Ep:46, loss:0.00005, loss_test:0.06166, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.396, tt:817.606\n",
      "Ep:47, loss:0.00005, loss_test:0.06148, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:17.368, tt:833.649\n",
      "Ep:48, loss:0.00005, loss_test:0.06111, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.308, tt:848.068\n",
      "Ep:49, loss:0.00005, loss_test:0.06119, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:17.260, tt:862.995\n",
      "Ep:50, loss:0.00005, loss_test:0.06088, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:17.212, tt:877.792\n",
      "Ep:51, loss:0.00005, loss_test:0.06069, lr:9.90e-03, fs:0.87701 (r=0.828,p=0.932),  time:17.167, tt:892.692\n",
      "Ep:52, loss:0.00004, loss_test:0.06259, lr:9.80e-03, fs:0.84375 (r=0.818,p=0.871),  time:17.123, tt:907.513\n",
      "Ep:53, loss:0.00005, loss_test:0.06093, lr:9.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:17.096, tt:923.184\n",
      "Ep:54, loss:0.00005, loss_test:0.06037, lr:9.61e-03, fs:0.87701 (r=0.828,p=0.932),  time:17.046, tt:937.544\n",
      "Ep:55, loss:0.00004, loss_test:0.06146, lr:9.51e-03, fs:0.87097 (r=0.818,p=0.931),  time:16.992, tt:951.539\n",
      "Ep:56, loss:0.00004, loss_test:0.05954, lr:9.41e-03, fs:0.87701 (r=0.828,p=0.932),  time:16.948, tt:966.015\n",
      "Ep:57, loss:0.00004, loss_test:0.06011, lr:9.32e-03, fs:0.87701 (r=0.828,p=0.932),  time:16.925, tt:981.651\n",
      "Ep:58, loss:0.00004, loss_test:0.06001, lr:9.23e-03, fs:0.87701 (r=0.828,p=0.932),  time:16.937, tt:999.296\n",
      "Ep:59, loss:0.00004, loss_test:0.06030, lr:9.14e-03, fs:0.88172 (r=0.828,p=0.943),  time:16.914, tt:1014.827\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00004, loss_test:0.06016, lr:9.14e-03, fs:0.89362 (r=0.848,p=0.944),  time:16.871, tt:1029.109\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.05896, lr:9.14e-03, fs:0.88770 (r=0.838,p=0.943),  time:16.847, tt:1044.511\n",
      "Ep:62, loss:0.00003, loss_test:0.06095, lr:9.14e-03, fs:0.88770 (r=0.838,p=0.943),  time:16.825, tt:1059.944\n",
      "Ep:63, loss:0.00004, loss_test:0.06008, lr:9.14e-03, fs:0.88043 (r=0.818,p=0.953),  time:16.817, tt:1076.265\n",
      "Ep:64, loss:0.00003, loss_test:0.05822, lr:9.14e-03, fs:0.89362 (r=0.848,p=0.944),  time:16.812, tt:1092.786\n",
      "Ep:65, loss:0.00003, loss_test:0.06139, lr:9.14e-03, fs:0.87568 (r=0.818,p=0.942),  time:16.784, tt:1107.738\n",
      "Ep:66, loss:0.00003, loss_test:0.05947, lr:9.14e-03, fs:0.88889 (r=0.848,p=0.933),  time:16.757, tt:1122.732\n",
      "Ep:67, loss:0.00003, loss_test:0.05769, lr:9.14e-03, fs:0.91579 (r=0.879,p=0.956),  time:16.734, tt:1137.921\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.06095, lr:9.14e-03, fs:0.88889 (r=0.848,p=0.933),  time:16.699, tt:1152.236\n",
      "Ep:69, loss:0.00003, loss_test:0.05895, lr:9.14e-03, fs:0.89247 (r=0.838,p=0.954),  time:16.675, tt:1167.272\n",
      "Ep:70, loss:0.00003, loss_test:0.05957, lr:9.14e-03, fs:0.87368 (r=0.838,p=0.912),  time:16.652, tt:1182.319\n",
      "Ep:71, loss:0.00003, loss_test:0.05956, lr:9.14e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.629, tt:1197.293\n",
      "Ep:72, loss:0.00003, loss_test:0.05807, lr:9.14e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.622, tt:1213.432\n",
      "Ep:73, loss:0.00003, loss_test:0.05819, lr:9.14e-03, fs:0.88298 (r=0.838,p=0.933),  time:16.611, tt:1229.214\n",
      "Ep:74, loss:0.00003, loss_test:0.05883, lr:9.14e-03, fs:0.89840 (r=0.848,p=0.955),  time:16.584, tt:1243.809\n",
      "Ep:75, loss:0.00003, loss_test:0.05741, lr:9.14e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.569, tt:1259.249\n",
      "Ep:76, loss:0.00002, loss_test:0.05763, lr:9.14e-03, fs:0.88770 (r=0.838,p=0.943),  time:16.553, tt:1274.585\n",
      "Ep:77, loss:0.00002, loss_test:0.05737, lr:9.14e-03, fs:0.89130 (r=0.828,p=0.965),  time:16.532, tt:1289.524\n",
      "Ep:78, loss:0.00002, loss_test:0.05644, lr:9.14e-03, fs:0.89730 (r=0.838,p=0.965),  time:16.516, tt:1304.743\n",
      "Ep:79, loss:0.00002, loss_test:0.05713, lr:9.04e-03, fs:0.87831 (r=0.838,p=0.922),  time:16.517, tt:1321.321\n",
      "Ep:80, loss:0.00002, loss_test:0.05714, lr:8.95e-03, fs:0.89247 (r=0.838,p=0.954),  time:16.520, tt:1338.135\n",
      "Ep:81, loss:0.00002, loss_test:0.05774, lr:8.86e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.506, tt:1353.483\n",
      "Ep:82, loss:0.00002, loss_test:0.05690, lr:8.78e-03, fs:0.89130 (r=0.828,p=0.965),  time:16.483, tt:1368.101\n",
      "Ep:83, loss:0.00002, loss_test:0.05755, lr:8.69e-03, fs:0.89840 (r=0.848,p=0.955),  time:16.462, tt:1382.799\n",
      "Ep:84, loss:0.00002, loss_test:0.05710, lr:8.60e-03, fs:0.89617 (r=0.828,p=0.976),  time:16.439, tt:1397.321\n",
      "Ep:85, loss:0.00002, loss_test:0.05687, lr:8.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:16.420, tt:1412.097\n",
      "Ep:86, loss:0.00002, loss_test:0.05669, lr:8.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.403, tt:1427.095\n",
      "Ep:87, loss:0.00002, loss_test:0.05681, lr:8.35e-03, fs:0.89247 (r=0.838,p=0.954),  time:16.393, tt:1442.547\n",
      "Ep:88, loss:0.00002, loss_test:0.05730, lr:8.26e-03, fs:0.89130 (r=0.828,p=0.965),  time:16.378, tt:1457.659\n",
      "Ep:89, loss:0.00002, loss_test:0.05743, lr:8.18e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.382, tt:1474.337\n",
      "Ep:90, loss:0.00002, loss_test:0.05854, lr:8.10e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.370, tt:1489.657\n",
      "Ep:91, loss:0.00002, loss_test:0.05694, lr:8.02e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.352, tt:1504.392\n",
      "Ep:92, loss:0.00002, loss_test:0.05774, lr:7.94e-03, fs:0.88649 (r=0.828,p=0.953),  time:16.341, tt:1519.736\n",
      "Ep:93, loss:0.00002, loss_test:0.05683, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.322, tt:1534.283\n",
      "Ep:94, loss:0.00002, loss_test:0.05739, lr:7.78e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.303, tt:1548.813\n",
      "Ep:95, loss:0.00002, loss_test:0.05601, lr:7.70e-03, fs:0.90110 (r=0.828,p=0.988),  time:16.287, tt:1563.591\n",
      "Ep:96, loss:0.00002, loss_test:0.05656, lr:7.62e-03, fs:0.89130 (r=0.828,p=0.965),  time:16.267, tt:1577.858\n",
      "Ep:97, loss:0.00002, loss_test:0.05757, lr:7.55e-03, fs:0.88525 (r=0.818,p=0.964),  time:16.249, tt:1592.409\n",
      "Ep:98, loss:0.00002, loss_test:0.05558, lr:7.47e-03, fs:0.89503 (r=0.818,p=0.988),  time:16.233, tt:1607.024\n",
      "Ep:99, loss:0.00002, loss_test:0.05583, lr:7.40e-03, fs:0.89617 (r=0.828,p=0.976),  time:16.223, tt:1622.307\n",
      "Ep:100, loss:0.00002, loss_test:0.05653, lr:7.32e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.206, tt:1636.768\n",
      "Ep:101, loss:0.00002, loss_test:0.05605, lr:7.25e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.200, tt:1652.409\n",
      "Ep:102, loss:0.00002, loss_test:0.05658, lr:7.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.195, tt:1668.048\n",
      "Ep:103, loss:0.00001, loss_test:0.05646, lr:7.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.186, tt:1683.324\n",
      "Ep:104, loss:0.00001, loss_test:0.05657, lr:7.03e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.190, tt:1699.992\n",
      "Ep:105, loss:0.00001, loss_test:0.05609, lr:6.96e-03, fs:0.89617 (r=0.828,p=0.976),  time:16.181, tt:1715.219\n",
      "Ep:106, loss:0.00001, loss_test:0.05626, lr:6.89e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.172, tt:1730.447\n",
      "Ep:107, loss:0.00001, loss_test:0.05630, lr:6.83e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.166, tt:1745.975\n",
      "Ep:108, loss:0.00001, loss_test:0.05599, lr:6.76e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.154, tt:1760.780\n",
      "Ep:109, loss:0.00001, loss_test:0.05577, lr:6.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.139, tt:1775.235\n",
      "Ep:110, loss:0.00001, loss_test:0.05580, lr:6.62e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.122, tt:1789.511\n",
      "Ep:111, loss:0.00001, loss_test:0.05678, lr:6.56e-03, fs:0.88525 (r=0.818,p=0.964),  time:16.115, tt:1804.922\n",
      "Ep:112, loss:0.00001, loss_test:0.05635, lr:6.49e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.104, tt:1819.783\n",
      "Ep:113, loss:0.00001, loss_test:0.05609, lr:6.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:16.089, tt:1834.161\n",
      "Ep:114, loss:0.00001, loss_test:0.05578, lr:6.36e-03, fs:0.89503 (r=0.818,p=0.988),  time:16.078, tt:1848.993\n",
      "Ep:115, loss:0.00001, loss_test:0.05687, lr:6.30e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.070, tt:1864.148\n",
      "Ep:116, loss:0.00001, loss_test:0.05601, lr:6.24e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.058, tt:1878.816\n",
      "Ep:117, loss:0.00001, loss_test:0.05581, lr:6.17e-03, fs:0.90110 (r=0.828,p=0.988),  time:16.047, tt:1893.509\n",
      "Ep:118, loss:0.00001, loss_test:0.05774, lr:6.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.030, tt:1907.524\n",
      "Ep:119, loss:0.00001, loss_test:0.05772, lr:6.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:16.022, tt:1922.623\n",
      "Ep:120, loss:0.00001, loss_test:0.05679, lr:5.99e-03, fs:0.89011 (r=0.818,p=0.976),  time:16.012, tt:1937.429\n",
      "Ep:121, loss:0.00001, loss_test:0.05669, lr:5.93e-03, fs:0.89503 (r=0.818,p=0.988),  time:16.010, tt:1953.245\n",
      "Ep:122, loss:0.00001, loss_test:0.05727, lr:5.87e-03, fs:0.89503 (r=0.818,p=0.988),  time:16.006, tt:1968.687\n",
      "Ep:123, loss:0.00001, loss_test:0.05780, lr:5.81e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.999, tt:1983.930\n",
      "Ep:124, loss:0.00001, loss_test:0.05604, lr:5.75e-03, fs:0.89503 (r=0.818,p=0.988),  time:15.987, tt:1998.358\n",
      "Ep:125, loss:0.00001, loss_test:0.05637, lr:5.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.978, tt:2013.185\n",
      "Ep:126, loss:0.00001, loss_test:0.05645, lr:5.64e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.970, tt:2028.149\n",
      "Ep:127, loss:0.00001, loss_test:0.05606, lr:5.58e-03, fs:0.89503 (r=0.818,p=0.988),  time:15.965, tt:2043.547\n",
      "Ep:128, loss:0.00001, loss_test:0.05641, lr:5.53e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.957, tt:2058.397\n",
      "Ep:129, loss:0.00001, loss_test:0.05593, lr:5.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.950, tt:2073.464\n",
      "Ep:130, loss:0.00001, loss_test:0.05608, lr:5.42e-03, fs:0.89503 (r=0.818,p=0.988),  time:15.944, tt:2088.660\n",
      "Ep:131, loss:0.00001, loss_test:0.05582, lr:5.36e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.940, tt:2104.026\n",
      "Ep:132, loss:0.00001, loss_test:0.05551, lr:5.31e-03, fs:0.89503 (r=0.818,p=0.988),  time:15.933, tt:2119.093\n",
      "Ep:133, loss:0.00001, loss_test:0.05617, lr:5.26e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.925, tt:2133.932\n",
      "Ep:134, loss:0.00001, loss_test:0.05644, lr:5.20e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.918, tt:2148.996\n",
      "Ep:135, loss:0.00001, loss_test:0.05555, lr:5.15e-03, fs:0.89503 (r=0.818,p=0.988),  time:15.918, tt:2164.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00001, loss_test:0.05567, lr:5.10e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.912, tt:2179.974\n",
      "Ep:137, loss:0.00001, loss_test:0.05649, lr:5.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.902, tt:2194.454\n",
      "Ep:138, loss:0.00001, loss_test:0.05577, lr:5.00e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.899, tt:2209.969\n",
      "Ep:139, loss:0.00001, loss_test:0.05588, lr:4.95e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.894, tt:2225.148\n",
      "Ep:140, loss:0.00001, loss_test:0.05594, lr:4.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.883, tt:2239.538\n",
      "Ep:141, loss:0.00001, loss_test:0.05593, lr:4.85e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.879, tt:2254.786\n",
      "Ep:142, loss:0.00001, loss_test:0.05652, lr:4.80e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.875, tt:2270.072\n",
      "Ep:143, loss:0.00001, loss_test:0.05632, lr:4.75e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.867, tt:2284.800\n",
      "Ep:144, loss:0.00001, loss_test:0.05567, lr:4.71e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.862, tt:2299.942\n",
      "Ep:145, loss:0.00001, loss_test:0.05571, lr:4.66e-03, fs:0.88043 (r=0.818,p=0.953),  time:15.856, tt:2314.932\n",
      "Ep:146, loss:0.00001, loss_test:0.05648, lr:4.61e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.851, tt:2330.167\n",
      "Ep:147, loss:0.00001, loss_test:0.05646, lr:4.57e-03, fs:0.89503 (r=0.818,p=0.988),  time:15.847, tt:2345.355\n",
      "Ep:148, loss:0.00001, loss_test:0.05609, lr:4.52e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.839, tt:2359.988\n",
      "Ep:149, loss:0.00001, loss_test:0.05573, lr:4.48e-03, fs:0.89011 (r=0.818,p=0.976),  time:15.831, tt:2374.672\n",
      "Ep:150, loss:0.00001, loss_test:0.05638, lr:4.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.828, tt:2389.980\n",
      "Ep:151, loss:0.00001, loss_test:0.05651, lr:4.39e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.824, tt:2405.189\n",
      "Ep:152, loss:0.00001, loss_test:0.05575, lr:4.34e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.819, tt:2420.236\n",
      "Ep:153, loss:0.00001, loss_test:0.05584, lr:4.30e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.811, tt:2434.911\n",
      "Ep:154, loss:0.00001, loss_test:0.05599, lr:4.26e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.805, tt:2449.791\n",
      "Ep:155, loss:0.00001, loss_test:0.05612, lr:4.21e-03, fs:0.88525 (r=0.818,p=0.964),  time:15.798, tt:2464.484\n",
      "Ep:156, loss:0.00001, loss_test:0.05608, lr:4.17e-03, fs:0.88043 (r=0.818,p=0.953),  time:15.792, tt:2479.362\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"2-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
